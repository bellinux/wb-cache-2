138|240|Public
50|$|A pirate {{party was}} first founded in Poland {{under the name}} (Partia Piratów) on 7 July 2006, and {{registered}} on 11 November 2007.Due to <b>formal</b> <b>error,</b> the party was de-registered in 2008. The party leaders opted to delay reregistration and focus on recruiting new members and establishing party structure. On 28 December 2009 it {{was removed from the}} register of political parties and ceased its activities outside the Internet.|$|E
50|$|While the {{quadratic}} Frobenius test {{does not}} have <b>formal</b> <b>error</b> bounds beyond that of the Lucas test, {{it can be used}} as the basis for methods with much smaller error bounds. Note that these have more steps, additional requirements, and non-negligible additional computation beyond what is described on this page. It {{is important to note that}} the error bounds for these methods do not apply to the standard or strong Frobenius tests with fixed values of (P,Q) described on this page.|$|E
50|$|R145 is a double-lined spectroscopic {{binary system}} with an orbital period of 159 days. The two stars have an {{eccentric}} orbit with a separation varying {{from less than}} one AU to nearly eight AU. The two stars show almost identical orbital velocities and hence have very similar masses. The exact values depend on the inclination of the orbital plane. The inclination of the R145 orbit calculated using polarimetry is 39°. At this small inclination the <b>formal</b> <b>error</b> of 6° translates into considerable margins of error in the masses. Estimates of the masses of the two stars by other methods give larger values, suggesting that the inclination may be smaller than 39°.|$|E
30|$|Finally, the <b>formal</b> <b>errors</b> of the tropospheric delays {{provided}} by different observation techniques were compared for selected stations. For VLBI and WVR, ZWD <b>formal</b> <b>errors</b> are available, for GPS only those of ZTD. The {{difference in the}} <b>formal</b> <b>errors</b> of ZTD and ZWD depends on the precision of the pressure data used to correct for ZHD. In VLBI analysis, the pressure data is assumed as perfectly known and therefore the a priori standard deviations of the group delays are not adjusted when the hydrostatic delays are subtracted. To be consistent, we have to assume {{the same for the}} GPS data (as we use the same pressure data to convert ZTD to ZWD) and therefore directly compare GPS ZTD <b>formal</b> <b>errors</b> with ZWD <b>formal</b> <b>errors</b> of other techniques. For the RT solutions, no measures of uncertainty were derived.|$|R
30|$|This {{simulation}} {{study has}} assumed {{a very simple}} error model and compared relative changes of <b>formal</b> <b>errors,</b> but that various error sources and the measurement correlations {{should be taken into}} account when we handle an actual observation data set.|$|R
40|$|The {{objective}} of this thesis is to categorise and describe <b>formal</b> <b>errors</b> of sign language interpreters. It focuses on errors committed during interpretation from a sign language into a spoken language, e. g. from the Czech sign language into Czech. Sign language interpreting is usually simultaneous. That is why there is a chapter on the simultaneous interpretation process. Next chapter describes interpreting strategies and roles of simultaneous interpretation process participants. The subsequent part describes the specificity of sign language interpretation. In includes {{a brief history of}} interpreting for the deaf as well as equal competences of both spoken and sign languages interpreters, specific competences of sign language interpreters and an explanation of similarities and differences between spoken and sign language interpretation. The next section is focused on errors of spoken language interpreters and errors of sign language interpreters. Empirical part describes research based on recordings of <b>formals</b> <b>errors</b> of sign language interpreters. This chapter defines the research hypothesis and <b>formal</b> <b>errors</b> resulting from individual research and it contains an analysis of the research itself. There is an exercise for interpreters based on analysis of the research. The final part of the thesis consists of [...] ...|$|R
50|$|Anna Jefferson was {{a member}} of the New York State Senate (22nd D.) in 1983 and 1984. In 1984, the Democratic 22nd Senate {{district}} organization denied Jefferson a re-nomination, and instead nominated Velmanette Montgomery for the seat. Jefferson tried to challenge Montgomery in the Democratic primary but her petition was rejected ultimately by the New York Court of Appeals. The cover sheet of Jefferson's petition showed 5,074 as the total number of signatures while the petition was signed by only 3,831 registered Democrats. Jefferson claimed that a campaign worker made a simple mistake with a calculator, and only 3,000 signatures were necessary to get on the primary ballot. Nevertheless, the court ruled that this <b>formal</b> <b>error</b> invalidated the petition as a whole.|$|E
5000|$|Hinz made {{headlines}} after allegations that she mobbed her employees and faked essential {{parts of her}} curriculum vitae (CV), falsely claiming that she took her A-levels in 1984 and studied Law and Political Science for ten years from 1985 to 1995. Hinz admitted that she faked her CV. She resigned from her Bundestag mandate only after growing public pressure on 24 August 2016, but because of a <b>formal</b> <b>error</b> her request was considered as preliminary invalid by the Bundestag administration. On 30 August, {{it was reported that}} the resignation of her Bundestag seat with effect of 1 September 2016 was now formally accepted. Hinz also announced that she will resign from the SPD party until 5 September 2016, after the party had initiated internal proceedings against her. The case of Petra Hinz was viewed as a [...] "desaster" [...] for the SPD party.|$|E
5000|$|In philosophy, {{the term}} formal fallacy {{is used for}} logical fallacies and defined {{formally}} as: a flaw {{in the structure of}} a deductive argument which renders the argument invalid. The term is preferred as logic is the use of valid reasoning and a fallacy is an argument that uses poor reasoning therefore the term logical fallacy is self-contradictory. However, the same terms are used in informal discourse to mean an argument which is problematic for any reason.A logical form such as [...] "A and B" [...] is independent of any particular conjunction of meaningful propositions. Logical form alone can guarantee that given true premises, a true conclusion must follow. However, formal logic makes no such guarantee if any premise is false; the conclusion can be either true or false. Any <b>formal</b> <b>error</b> or logical fallacy similarly invalidates the deductive guarantee. Both the argument and all its premises must be true for a statement to be true.|$|E
40|$|The {{combination}} of Global Navigation Satellite Systems (GNSS) may improve the {{accuracy and precision}} of estimated coordinates, {{as well as the}} convergence time of Precise Point Positioning (PPP) solutions. The key conditions are the correct functional model and the proper weighting of observations, for which different characteristics of multi-GNSS signals should be taken into account. In post-processing applications, the optimum stochastic model can be obtained through the analysis of post-fit residuals, but for real-time applications the stochastic model has to be defined in advanced. We propose five different weighting schemes for the GPS + GLONASS + Galileo + BeiDou combination, including two schemes with no intra-system differences, and three schemes that are based on signal noise and/or quality of satellite orbits. We perform GPS-only and five multi-GNSS solutions representing each weighting scheme. We analyze <b>formal</b> <b>errors</b> of coordinates, coordinate repeatability, and solution convergence time. We found that improper or equal weighting may improve <b>formal</b> <b>errors</b> but decreases coordinate repeatability when compared to the GPS-only solution. Intra-system weighting based on satellite orbit quality allows for a reduction of <b>formal</b> <b>errors</b> by 40 %, for shortening convergence time by 40 % and 47 % for horizontal and vertical components, respectively, as well as for improving coordinate repeatability by 6 %...|$|R
40|$|In {{a system}} where tens of {{thousands}} of words are made up of a limited number of phonemes, many words are bound to sound alike. This similarity of the words in the lexicon as characterized by phonological neighbourhood density (PhND) has been shown to affect speed and accuracy of word comprehension and production. Whereas there is a consensus about the interfering nature of neighbourhood effects in comprehension, the language production literature offers a more contradictory picture with mainly facilitatory but also interfering effects reported on word production. Here we report both of these two types of effects in the same study. Multiple regression mixed models analyses were conducted on PhND effects on errors produced in a naming task by a group of 21 participants with aphasia. These participants produced more <b>formal</b> <b>errors</b> (interfering effect) for words in dense phonological neighbourhoods, but produced fewer nonwords and semantic errors (a facilitatory effect) with increasing density. In order to investigate the nature of these opposite effects of PhND, we further analysed a subset of <b>formal</b> <b>errors</b> and nonword errors by distinguishing errors differing on a single phoneme from the target (corresponding to the definition of phonological neighbours) from those differing on two or more phonemes. This analysis confirmed that only <b>formal</b> <b>errors</b> that were phonological neighbours of the target increased in dense neighbourhoods, while all other errors decreased. Based on additional observations favouring a lexical origin of these <b>formal</b> <b>errors</b> (they exceeded the probability of producing a real-word error by chance, were of a higher frequency, and preserved the grammatical category of the targets), we suggest that the interfering effect of PhND is due to competition between lexical neighbours and target words in dense neighbourhoods...|$|R
40|$|Abstract This study verifies the {{environmental}} effects on agraphia in {{mild cognitive impairment}} and dementia. We compared elderly Japanese subjects living in Japan and Brazil. Methods: We retrospectively analyzed the database of the Prevalence Study 1998 in Tajiri (n= 497, Miyagi, Japan) and the Prevalence Study 1997 of elderly Japanese immigrants living in Brazil (n= 166, migrated from Japan and living in the São Paulo Metropolitan Area). In three Clinical Dementia Rating (CDR) groups, i. e., CDR 0 (healthy), CDR 0. 5 (questionable dementia), and CDR 1 + (dementia), the Mini-Mental State Examination (MMSE) item of spontaneous writing and the Cognitive Abilities Screening Instrument (CASI) domain of dictation were analyzed {{with regard to the}} number of Kanji and Kana characters. <b>Formal</b> <b>errors</b> in characters and pragmatic errors were also analyzed. Results: The immigrants in Brazil wrote similar numbers of Kanji or Kana characters compared to the residents of Japan. In spontaneous writing, the <b>formal</b> Kanji <b>errors</b> were greater in the CDR 1 + group of immigrants. In writing from dictation, all the immigrant CDR groups made more <b>formal</b> <b>errors</b> in Kana than the Japan residents. No significant differences in pragmatic errors were detected between the two groups. Conclusions: Subjects living in Japan use Kanji frequently, and thus the form of written characters was simplified, which might be assessed as mild <b>formal</b> <b>errors.</b> In immigrants, the deterioration in Kanji and Kana writing was partly due to decreased daily usage of the characters. Lower levels of education of immigrants might also be related to the number of Kanji errors...|$|R
50|$|The {{above is}} typical of the reviews he {{received}} at publication in the UK, yet perhaps Brooks himself contributed to burying this book. He had never been a good salesman of his most personal work (the novels and poems) and, in speaking of Smith, As Hero, he often lamented what he saw as a <b>formal</b> <b>error</b> in the book; this was a foray into metafiction with the introduction in a late chapter of a character called Jeremy Brooks (a device used two decades later by Martin Amis in Money). This experiment was partly driven by his desire to distance himself from the protagonist Bernard Smith, but soon after publication he came {{to think of it as}} a mistake - a hole in what was otherwise a watertight ship. But it was too late. Great reviews did nothing to mollify him - on the contrary, they disturbed him. Typically, he was being too hard on himself (and perhaps also on those reviewers who had failed to upbraid him for his perceived mistake). It may be that to some extent Brooks subsequently 'lost his voice', or his muse, as a novelist and, apart from the four novellas collected in Doing the Voices (1986), never published a major work of fiction again.|$|E
5000|$|On 24 September 2011, Breno {{was arrested}} after the Munich public {{prosecutor}} had issued {{an arrest warrant}} for suspicion of suppression of evidence {{and the fact that}} he may be a possible flight risk. The reasoning for the arrest is [...] "suspicion of aggravated arson" [...] in regards to the almost total destruction of his villa in a suspicious fire. The damage to his villa is estimated to be €1.5 million. Bayern Munich made no comment on the arrest. Club officials had previously advised him to seek help from a psychiatrist in regards to injury frustrations, which some fear are career ending. On 6 October 2011, he was released on bail. On 11 April 2012, German prosecutors charged Breno over arson in connection with the fire that burned down his rented villa. On 4 July 2012, Breno was handed a jail sentence of three years and nine months. After the sentences, German court announced that Breno will be deported to Brazil upon completion of his prison sentence. Breno's sentences was spoken out by sportspersons additionally, sportspersons like Giovane Élber and Uli Hoeneß, though his comment was criticised by 1. FC Nürnberg director of football Martin Bader and Eintracht Frankfurt executive chairman Heribert Bruchhagen. In January 2013, Breno's proposal for his revised sentence was rejected by the German Federal Court of Justice due to his situation did not constitute a <b>formal</b> <b>error</b> of law, after his lawyer says he was under the influence of potentially dangerous medication which could have caused the events which led to his imprisonment.|$|E
30|$|The {{phase delay}} sea level results in Figure  6 {{resemble}} the tide gauge sea level well for GPS and GLONASS at both frequencies. The error bars consist {{of the standard}} deviation (the <b>formal</b> <b>error</b> in the least-squares minimization process) multiplied {{by a factor of}} 10.|$|E
50|$|The President has {{the right}} to refuse his {{signature}} to laws passed by the parliament (veto) in certain circumstances. These may be <b>formal</b> <b>errors</b> in the law-making process or violations of the Basic Law inherent to the new law. This reserve power has been used 8 times as of May 2013.|$|R
40|$|Multiple-choice {{questions}} (MCQs) evaluate factual {{knowledge in}} medical education {{and have a}} high reliability, if performed appropriately. However, many MCQs contain <b>formal</b> <b>errors</b> leading to reduced validity. The authors developed a Web application capable of recognizing and eliminating five fre-quent contraindicated practices in MCQs: negative stem, unfocused stem, cueing words, longest item right item flaw, and stem/item similarities. The authors used simple string algorithms and dynamic comparisons with key-words. The system was successfully validated {{with a sample of}} approxi-mately 800 continuous medical education (CME) questions, showing that our system automatically detects 60 % of all <b>formal</b> didactic <b>errors.</b> Flaw...|$|R
40|$|The {{processing}} of the RDV sessions and problems encountered {{in their analysis}} axe briefly discussed. Results of a VLBA/Mark 4 correlator comparison are presented. Comparison of group delays in session RDV 22 processed by two different correlating/fringing systems shows good agreement, with an RMS of approx. 12 psec. Group delay <b>formal</b> <b>errors</b> may be underestimated in the RDV processing...|$|R
40|$|Human factors {{certification}} {{criteria are}} being developed for large civil aircraft to replace the interim policies currently in place for this purpose. The objective of these initiatives {{is to reduce the}} incidence of design induced error. Many <b>formal</b> <b>error</b> identification and prediction techniques currently exist, however none of these have been validated for their use in an aviation context {{due to a lack of}} validation data. Accident and incident reports do not contain sufficient detail in this respect. This paper describes a survey of commercial pilots to collect data on common, design induced errors on a modern flight deck during the approach and landing phases of flight. These data will subsequently be used in the validation of a <b>formal</b> <b>error</b> prediction technique for use on the flight dec...|$|E
40|$|To {{compare the}} results with Global Po- sitioning System (GPS) Time Transfer and Very Long Baseline Interferometry (VLBI) Time Trans- fer, we {{carried out the}} {{geodetic}} VLBI experi- ments for four times. The averaged <b>formal</b> <b>error</b> (1 σ) of the clock offsets that were estimated every one hour in the geodetic VLBI analysis procedure (CALC/SOLVE), was 33 picoseconds. Especially, {{in the case of}} using K 5 /VSSP 32 system, the aver- aged <b>formal</b> <b>error</b> was 29 picoseconds. The results of the VLBI time transfer were very consistent with the results of the GPS time transfer. The differ- ence of both results was about ± 500 picoseconds. In term of frequency stability, the Allan deviation showed that VLBI time transfer is more stable than GPS time transfer between 2000 seconds to 60000 seconds (uncertainty of under 3 × 10 − 14) ...|$|E
40|$|Using Chang&# 39;E- 1 orbital {{tracking}} data, {{in combination}} with orbital tracking data of SELENE, Lunar Prospector, and historical spacecraft, a lunar gravity field model denoted CEGM 02 is developed. Analyses show that due to its higher orbit altitude (200 km), tracking data of Chang&# 39;E- 1 contribute to the long wavelengths of the lunar gravity field. When compared to SGM 100 h, <b>formal</b> <b>error</b> of CEGM 02 coefficients below degree 5 is reduced {{by a factor of}} about 2. Lunar mean moment of inertia is found to be 0. 393466 +/- 0. 000065, which can be served as a strong constraint in lunar internal structure research. Lunar potential Love number k(2) is estimated to be 0. 0242 +/- 0. 0004 (ten times the <b>formal</b> <b>error),</b> which may provide better constraints on lunar interior by combination with lunar moments of inertia. (C) 2011 Elsevier Ltd. All rights reserved...|$|E
50|$|In late 2009 {{she brought}} herself forward as {{candidate}} for {{the presidency of the}} Lazio Region, in view of the elections of 29 March 2010. She led a centre-right coalition, which was however reduced when its main party, the People of Freedom led by Berlusconi, was excluded from elections in the Province of Rome for some <b>formal</b> <b>errors</b> http://roma.corriere.it/roma/notizie/politica/10_febbraio_28/liste-pdl-ricorso-esclusione-1602569325668.shtml.|$|R
40|$|Preliminary orbit {{determination}} for satellites in the U. S. Department of Defense's Global Positioning System has been performed using GPS carrier phase data collected in March-April 1985 at 10 {{sites in the}} continental United States. The {{data were analyzed using}} a new data processing software package called GIPSY (GPS Inferred Positioning SYstem) and with existing covariance analysis software. Data from one day have been processed with average <b>formal</b> position <b>errors</b> of 1. 4 to 3. 6 meters. The true errors are probably somewhat larger. Covariance results are presented which suggest that the orbits can be obtained with <b>formal</b> <b>errors</b> under 2 meters after certain software issues are resolved...|$|R
40|$|Analysis of very-long-baseline {{interferometer}} (VLBI) observations yielded {{estimates of}} the distances between three radio telescopes in the United States and one in Sweden, with <b>formal</b> standard <b>errors</b> of a few centimeters: Westford, Massachusetts-Onsala, Sweden: 5, 599, 714. 66 + or - 0. 03 m; Green Bank, West Virginia-Onsala, Sweden: 6, 319, 317. 75 + or - 0. 03 m; and Owens Valley, California-Onsala, Sweden: 7, 914, 131. 19 + or - 0. 04 m, where the earth-fixed reference points are defined in each case {{with respect to the}} axes of the telescopes. The actual standard errors are difficult to estimate reliably but are probably not greater than twice the <b>formal</b> <b>errors...</b>|$|R
40|$|The {{calibration}} {{process of}} long baseline stellar interferometers requires {{the use of}} reference stars with accurately determined angular diameters. We present a catalog of 374 carefully chosen stars among the all-sky network of infrared sources provided by Cohen et al. 1999. The catalog benefits from a very good sky coverage and a median <b>formal</b> <b>error</b> on the angular diameters of only 1. 2...|$|E
40|$|Theorem proving Design and {{verification}} a b s t r a c t In {{this work}} we provide a methodology {{for the design}} and verification of a frequency domain equalizer. The performance analysis of the equalizer is conducted using two methods: simulation based verification in Simulink and System Generator and theorem proving techniques in Higher Order Logic. We conduct both floating-point and fixed-point error estimations for the design in Simulink and System Generator, respectively. Then, we use <b>formal</b> <b>error</b> analysis based on the theorem proving to verify an implementa-tion of the frequency domain equalizer based on the Fast LMS algorithm. The <b>formal</b> <b>error</b> analysis and simulation based error estimation of the algorithm intend to show that, when converting from one number domain to another, the algorithm produces the same values with an accepted error margin caused by the round-off error accumulation. This work shows the efficiency of combining simulation and formal verification based methods in verifying complex systems such as the frequency domain equalizer. & 2013 Elsevier Ltd. All rights reserved. 1. Introduction an...|$|E
40|$|Observations of {{the five}} asteroids {{designated}} 3 Juno, 24 Themis, 60 Echo, 261 Prymo, and 863 Benkoela over the 1978 - 1984 period {{have been subjected to}} Fourier analysis to obtain composite lightcurves. The method yields a rotation-period value, mean absolute magnitudes for each night of observation, and Fourier coefficients that define composite-lightcurve shape, with <b>formal</b> <b>error</b> estimates for all quantities. The first three of the asteroids listed exhibit significant variation in surface albedo...|$|E
40|$|The main {{statistical}} astrometric {{properties of}} the Hipparcos Catalogue are reviewed. This includes the overall figures useful to characterize {{the content of the}} Hipparcos Catalogue, meaningful for an average star of 9 mag. The <b>formal</b> <b>errors</b> of the five astrometric parameters are discussed in different coordinate systems {{as a function of the}} position on the sky and of the magnitude of the stars. While there is almost no sizeable effect with the ecliptic longitude, the <b>formal</b> <b>errors</b> of the ecliptic longitude and parallax display large variations with the ecliptic latitude. For the other coordinate systems the precision of all the astrometric parameters is a function of both positional coordinates. A more detailed investigation of the distribution of the parallaxes and their expected errors as a function of the magnitude and of the location of the star on the sky is also carried out with a particular emphasis on the relative error oe ß =ß. Keywords: Astrometry, Hipparcos, Parallaxes. 1. I [...] ...|$|R
40|$|We reanalyse {{the spectra}} used by D. -E. Liebscher (no relation) et al {{with the same}} goal [...] {{determining}} the cosmological parameters [...] and basically the same assumptions but with a different statistical method, which does not rely on binning the data. Also, we correct for selection effects. We basically confirm their result, with somewhat larger but still very small (<b>formal)</b> <b>errors.</b> However, all world models within the 99...|$|R
40|$|The {{internal}} consistency of the baseline-length measurements derived from analysis of several independent VLBI experiments is an estimate of the measurement precision. The paper investigates whether the inclusion of water vapor radiometer (WVR) data as an absolute calibration of the propagation delay due to water vapor improves the precision of VLBI baseline-length measurements. The paper analyzes 28 International Radio Interferometric Surveying runs between June 1988 and January 1989; WVR measurements were made during each session. The addition of WVR data decreased the scatter of the length measurements of the baselines by 5 - 10 percent. The observed reduction in the scatter of the baseline lengths is less than what is expected from the behavior of the <b>formal</b> <b>errors,</b> which suggest that the baseline-length measurement precision should improve 10 - 20 percent if WVR data are included in the analysis. The discrepancy between the <b>formal</b> <b>errors</b> and the baseline-length results can be explained as the consequence of systematic errors in the dry-mapping function parameters, instrumental biases in the WVR and the barometer, or both...|$|R
40|$|We {{present a}} theory and {{numerical}} algorithm to directly determine the time-varying along-track geopotential difference and deflection of the vertical at the Gravity Recovery and Climate Experiment (GRACE) satellite altitude. The determination was implemented using the GEOGRACE computer program using the K-band range rate (KBRR) of GRACE from the Level- 1 B (L 1 B) product. The method treated KBRR, GPS-derived orbit of GRACE and an initial geopotential difference as measurements {{used in the}} least-squares estimation of the geopotential difference and its <b>formal</b> <b>error</b> constrained by the energy conservation principle. The computational procedure consisted of three steps: data reading and interpolation, data calibration and estimations of the geopotential difference and its error. The <b>formal</b> <b>error</b> allowed removal of KBRR outliers that contaminated the gravity solutions. We used the most recent models {{to account for the}} gravity changes from multiple sources. A case study was carried out over India to estimate surface mass anomalies from GEOGRACE-derived geopotential differences. The 10 -day mass changes were consistent with those from the MASCON solutions of NASA (correlation coefficient up to 0. 88). Using the geopotential difference at satellite altitude avoids the errors caused by downward continuation, enabling the detection of small-scale mass changes. </p...|$|E
40|$|AbstractArithmetic {{systems such}} as those based on IEEE {{standards}} currently make no attempt to track the propagation of errors. A <b>formal</b> <b>error</b> analysis, however, can be complicated and is often confined {{to the realm of}} experts in numerical analysis. In recent years, there has been a resurgence of interest in automated methods for accurately monitoring the error propagation. In this article, a floating-point system based on significance arithmetic will be described. Details of the implementation in Mathematica will be given along with examples that illustrate the design goals and differences over conventional fixed-precision floating-point systems...|$|E
40|$|Fourth-order stream-function {{methods are}} {{proposed}} for the time dependent, incompressible Navier-Stokes and Boussinesq equations. Wide difference stencils are used instead of compact ones and the boundary terms are handled by extrapolating the stream-function values inside the computational domain to grid points outside, up to fourth-order in the noslip condition. <b>Formal</b> <b>error</b> analysis is done for a simple model problem, showing that this extrapolation introduces numerical boundary layers at fifth-order in the stream-function. The fourth-order convergence in velocity of the proposed method for the full problem is shown numerically...|$|E
30|$|Next, {{we compare}} the {{distributions}} of the post-fit residuals of STEC after inversion (Additional file 1 : Fig. S 3 bottom panels) {{with the original}} STEC anomalies (Additional file 1 : Fig. S 3 upper panels). In each case, the post-fit residual shows much smaller dispersion, and its standard deviation {{is similar to the}} assumed STEC observation errors (0.2 TECU). Hence, the <b>formal</b> <b>errors</b> in Additional file 1 : Fig. S 2 would not be very unrealistic.|$|R
40|$|The term public {{procurement}} {{refers to a}} contract between public entity and private companies. The {{public procurement}} contracts are regulated by the Public Procurement Act, which specifies the rules under which the public procurement should be performed and sets conditions of award procedures of public contracts. The quality of execution of the award procedure influences the efficiency and the transparency of the contract. The award procedure can be executed by internal employees of the contractor or outsourced. The main aim of this thesis is to analyze whether the contractors behave rationally when they outsource the award procedure; this thesis evaluates the differences between an in-house administration and an outsourced administration in prices, efficiency in terms of number of bidders in the contract and probability of <b>formal</b> <b>errors</b> in the award procedure. The results of the analysis shows that small contractors behave rationally; when they administrate the award procedure in-house they tend to make more <b>formal</b> <b>errors</b> thus they outsource the procedure. On the other hand, the large contractors do not behave rationally, because they outsource the administration of award procedure even if all three indicators show that they administrate the procedure in-house more successfully. The behavior of [...] ...|$|R
40|$|A {{covariance}} analysis {{indicates that}} GPS baseline precision in northern South America is substantially improved when fiducial stations in North America are supplemented by stations in Hawaii, Australia, and New Zealand. The <b>formal</b> <b>errors</b> {{for a variety}} of fiducial networks are calculated. It is found that the systematic error of fiducial stations is dependent on the fiducial network geometry. Sensitivity analysis indicates that the baselines of northern South America are very sensitive to uncertainties in the locations of the closest fiducial stations...|$|R
