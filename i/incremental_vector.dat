5|60|Public
5000|$|The vector [...] {{determination}} {{is related}} to minimization of the quadratic form [...] by <b>incremental</b> <b>vector</b> , i.e.|$|E
40|$|Abstract. This paper {{describes}} {{a method for}} performing kernel smoothing regression in an incremental, adaptive manner. A simple and fast combination of <b>incremental</b> <b>vector</b> quantization with kernel smoothing regression using adaptive bandwidth is shown to be effective for online modeling of environmental datasets. The method is illustrated on openly available datasets corresponding to the Tropical Atmosphere Ocean array and the Helsinki Commission hydrographic database for the Baltic Sea. ...|$|E
40|$|Abstract. We {{present an}} {{architecture}} for the online learning of object representations {{based on a}} visual cortex hierarchy developed earlier. We use the output of a topographical feature hierarchy to provide a viewbased representation of three-dimensional objects {{as a form of}} visual short term memory. Objects are represented in an <b>incremental</b> <b>vector</b> quantization model, that selects and stores representative feature maps of object views together with the object label. New views are added to the representation based on their similarity to already stored views. The realized recognition system is a major step towards shape-based immediate high-performance online recognition capability for arbitrary complex-shaped objects. ...|$|E
5000|$|... and - <b>incremental</b> <b>vectors</b> of co-ordinates of all nodes at axes 1, 2, ...|$|R
40|$|Support vector {{machine is}} a popular method in machine learning. <b>Incremental</b> support <b>vector</b> machine {{algorithm}} is ideal selection {{in the face of}} large learning data set. In this paper a new <b>incremental</b> support <b>vector</b> machine learning algorithm is proposed to improve efficiency of large scale data processing. The model of this incremental learning algorithm is similar to the standard support vector machine. The goal concept is updated by incremental learning. Each training procedure only includes new training data. The time complexity is independent of whole training set. Compared with the other incremental version, the training speed of this approach is improved and the change of hyperplane is reduced. </p...|$|R
30|$|It is {{interesting}} to note that the rotation updates in terms of <b>incremental</b> rotation <b>vector</b> can be easily computed thanks to the additive procedure of updates, θ_n+ 1 ^(i+ 1)=θ_n+ 1 ^(i)+θ_n+ 1 ^(i). Moreover, velocity and acceleration updates in (55) and (57) have formally the same structure for both linear and angular configurations which is the main advantage of the proposed Newmark algorithm for finite rotation.|$|R
40|$|To {{maintain}} data {{consistency and}} eliminate the spatial conflicts brought by spatial database updating,an adaptive method for <b>incremental</b> <b>vector</b> data updating is proposed. Based on the matching of correspondent objects,a change-object detection and incremental updating method is discussed. Considering the constraint of spatial distance,semantic similarity and topology consistency,it is proposed a calculated method for edge matching evaluation. An adaptive edge matching strategy is also designed to maintain the consistency of spatial data. The rule-based detection and manipulation of spatial conflicts is also discussed. Topographical data are used to verify the practicality and efficiency of the method...|$|E
40|$|Abstract. In {{this paper}} {{we present a}} novel {{technique}} to capture Web users ’ behaviour based on their interest-oriented actions. In our approach we utilise the vector space model Random Indexing to identify the latent factors or hidden relationships among Web users ’ navigational behaviour. Random Indexing is an <b>incremental</b> <b>vector</b> space technique that allows for continuous Web usage mining. User requests are modelled by Random Indexing for individual users ’ navigational pattern clustering and common user profile creation. Clustering Web users ’ access patterns may capture common user interests and, in turn, build user profiles for advanced Web applications, such as Web caching and prefetching. We present results from the Web user clustering approach through experiments on a real Web log file with promising results. We also apply our data to a prefetching task and compare that with previous approaches. The results show that Random Indexing provides more accurate prefetchings...|$|E
40|$|Abstract. We {{present a}} {{category}} learning vector quantization (cLVQ) approach for incremental and life-long learning of multiple visual categories where {{we focus on}} approaching the stability-plasticity dilemma. To achieve the life-long learning ability an <b>incremental</b> learning <b>vector</b> quantization approach is combined with a category-specific feature selection method in a novel way to allow several metrical “views ” on the representation space for the same cLVQ nodes. ...|$|R
40|$|A {{number of}} recent studies raised doubts on the {{effectiveness}} of conventional pushover methods, whereby a constant single-mode <b>incremental</b> force <b>vector</b> is applied to the structure, in estimating the seismic demand/capacity of framed buildings subjected to earthquake action, in particular when higher modes are involved in the structural response. The latter motivated the recent development and introduction of the so-called Adaptive Pushover methods whereby the loading vector is updated at each analysis step, reflecting the progressive damage accumulation and resulting modification of the modal parameters that characterise the structural response at increasing loading levels. Within such adaptive framework, the application of a displacement, as opposed to force, <b>incremental</b> loading <b>vector</b> becomes not only feasible, since the latter is updated at each step of the analysis according to the current dynamic characteristics of the structure, but also very appealing, since inline with the present drive for development and code implementation of displacement or, more generally, deformation-based design and assessment methods. Further, such innovative displacement-based pushover algorithm seems to lead to superior response predictions, with little or no additional modelling and computational effort, with respect to conventional pushove...|$|R
40|$|Current {{vector space}} models for {{representing}} lexical semantics rely on sophisticated dimen-sional reduction operations. The complex data reduction step introduces a limitation for these models {{to scale up}} {{to take advantage of}} much larger text corpora. We examine previous work with scalable metrics, and explore the ability of scalable and <b>incremental</b> random <b>vector</b> accumulation (RVA) techniques to learn semantic representations gracefully from massive corpora. We compare RVAs to scal-able metrics (PMI) as well as LSA on stan-dard semantic evaluation tasks. ...|$|R
40|$|Purpose – Aims {{to address}} the issues {{pertaining}} to dynamics of constrained finite rotations as a follow-up from previous considerations in statics. Design/methodology/approach – A conceptual approach is taken. Findings – In this work the corresponding version of the Newmark time-stepping schemes for the dynamics of smooth shells employing constrained finite rotations is developed. Different possibilities to choose the constrained rotation parameters are discussed, with the special attention given to the preferred choice of the <b>incremental</b> rotation <b>vector.</b> Originality/value – The pertinent details of consistent linearization, rotation updates and illustrative numerical simulations are supplied. ...|$|R
40|$|Abstract. The {{well-known}} and very simple MinOver algorithm is reformulated for <b>incremental</b> support <b>vector</b> classification {{with and without}} kernels. A modified proof for its O(t − 1 / 2) convergence is presented, with t {{as the number of}} training steps. Based on this modified proof it is shown that even a convergence of at least O(t − 1) is given. This new convergence bound for MinOver is confirmed by computer experiments on artificial data sets. The computational effort per training step scales as O(N) with the number N of training patterns. ...|$|R
40|$|Abstract. This paper {{presents}} an efficient approach for supporting decremental learning for <b>incremental</b> proximal support <b>vector</b> machines (SVM). The presented decremental algorithm based on decay coefficients is {{compared with an}} existing window-based decremental algorithm, and is shown to perform at a similar level in accuracy, but providing significantly better computational performance. ...|$|R
40|$|Abstract. We propose an {{extension}} of prototype-based classification models to automatically adjust model complexity, thus offering a powerful technique for online, incremental learning tasks. The incremental technique {{is based on the}} notion of the certainty of an observed classification. Unlike previous work, we can incorporate matrix learning into the framework by relying on the cost function of generalised learning vector quantisation (GLVQ) for prototype insertion, deletion, as well as training. In several benchmarks, we demonstrate that the proposed method provides compa-rable results to offline counterparts and an <b>incremental</b> support <b>vector</b> machine, while enabling a better control of the required memory. ...|$|R
40|$|This paper {{presents}} an empirical {{comparison of the}} Multicategory <b>Incremental</b> Proximal Support <b>Vector</b> Machine Classifier (MIPSVM) against the C 4. 5, Naive Bayes, Voted Perceptron, SMO, SVM and Logistic Regression classifiers on several datasets. The datasets are from the UCI Machine Learning repository, a Web Usage Log, and game usage logs from the Zereal Massively Multiplayer Online Game Simulator...|$|R
40|$|OneClassMaxMinOver (OMMO) is {{a simple}} {{incremental}} algorithm for one-class support vector classification. We propose several enhancements and heuristics for improving model selection, including the adaptation of well-known techniques such as kernel caching and {{the evaluation of the}} feasibility gap. Furthermore, we provide a framework for optimising grid search based model selection that compromises of preinitialisation, cache reuse, and optimal path selection. Finally, we derive simple heuristics for choosing the optimal grid search path based on common benchmark datasets. In total, the proposed modifications improve the runtime of model selection significantly while they are still simple and adaptable {{to a wide range of}} <b>incremental</b> support <b>vector</b> algorithms. 1...|$|R
40|$|This paper proposes an <b>incremental</b> support <b>vector</b> machine-trained TS-type fuzzy {{classifier}} (ISVM-FC). The ISVM-FC is a {{fuzzy system}} {{that consists of}} Takagi-Sugeno (TS) -type fuzzy rules. Structure and parameters in the ISVM-FC are trained incrementally from one subset of training data at a time. This incremental training approach avoids the use of large amounts of memory required for storing training data in batch learning, reduces training time, and adapts the classifier to time-dependent classification systems where training data are available sequentially. Initially, there are no fuzzy rules for structure learning with the ISVM-FC. It generates all rules according to {{the distribution of the}} training data. An <b>incremental</b> linear support <b>vector</b> machine (SVM) is used to tune the resulting rule parameters to give the classifier better generalization performance. The use of incremental learning discards past training data adaptively according to its distance to the linear hyperplane, thereby improving learning efficiency. Three simulations are conducted to verify the performance of the ISVM-FC. Comparisons with fuzzy classifiers and Gaussian-kernel SVM with batch and incremental learning modes demonstrate that the ISVM-FC improves training and test times, and reduces memory consumption for classifier storage without deteriorating the generalization ability. (C) 2010 Elsevier B. V. All rights reserved...|$|R
40|$|We {{present a}} new variant of Generalized Learning Vector Quantization (GRLVQ) in a {{computer}} vision scenario. A version with incrementally added prototypes {{is used for the}} non-trivial case of high-dimensional object recognition. Training is based upon a generic set of standard visual features, the learned input weights are used for iterative feature pruning. Thus, prototypes and input space are altered simultaneously, leading to very sparse and task-specific representations. The effectiveness of the approach and the combination of the incremental variant together with pruning was tested on the Coil 100 database. It exhibits excellent performance with regard to codebook size, feature selection and recognition accuracy. Key words: object recognition, relevance learning, feature selection, <b>incremental</b> learning <b>vector</b> quantization, adaptive metric...|$|R
40|$|This paper {{describes}} an on-line method for building epsilon-insensitive support vector machines for regression {{as described in}} (Vapnik, 1995). The method {{is an extension of}} the method developed by (Cauwenberghs & Poggio, 2000) for building <b>incremental</b> support <b>vector</b> machines for classification. Machines obtained by using this approach are equivalent to the ones obtained by applying exact methods like quadratic programming, but they are obtained more quickly and allow the incremental addition of new points, removal of existing points and update of target values for existing data. This development opens the application of SVM regression to areas such as on-line prediction of temporal series or generalization of value functions in reinforcement learning. Postprint (published version...|$|R
40|$|A {{practical}} {{issue in}} the existing transduction methods is expensive and inefficient computation compared to induction methods. This has hindered the use of transduction methods in temporal and real-time data mining. In this paper, we introduce a fast incremental transductive confidence machine (TCM) based on adiabatic <b>incremental</b> support <b>vector</b> machine (SVM) such that critical information from current transduction trial is stored for later use. The algorithm is empirically shown to be computationally efficient and its performance is consistent with standard TCM implementation. Besides being a classifier, TCM provides additional useful statistical information about the data that it processed. These information can be useful for temporal and real-time data mining. We demonstrate the feasibility and usefulness of using such statistical information for stream-based active learning...|$|R
40|$|<b>Incremental</b> Support <b>Vector</b> Machines (SVM) are {{instrumental}} in practical applications of online learning. This work {{focuses on the}} design and analysis of efficient incremental SVM learning, {{with the aim of}} providing a fast, numerically stable and robust implementation. A detailed analysis of convergence and of algorithmic complexity of incremental SVM learning is carried out. Based on this analysis, a new design of storage and numerical operations is proposed, which speeds up the training of an incremental SVM by a factor of 5 to 20. The performance of the new algorithm is demonstrated in two scenarios: learning with limited resources and active learning. Various applications of the algorithm, such as in drug discovery, online monitoring of industrial devices and and surveillance of network traffic, can be foreseen...|$|R
40|$|Abstract. While {{detecting}} anomalies in hyperspectral imagery {{with support}} vector data description (SVDD), {{large numbers of}} operation was run {{because of the high}} dimension character of dataset and the complexity of background and the high miss rate was discovered because of the interfered background by interior anomalies. This paper used <b>incremental</b> support <b>vector</b> data description (ISVDD) method that samples are divided many sub-sample, and incremental study is designed to simplify the computation. On every sub-sample study, optimization is needed according of the support vectors obtained from above sub-sample and current sub-sample data. By the experiment on the HYMAP data, computation complexity of the algorithm decrease obviously and the computation speed increase highly under the similar detection effect compared with SVDD algorithm...|$|R
40|$|Using a {{recently}} introduced proximal support vector ma- chine classi er [4], {{a very fast}} and simple <b>incremental</b> support <b>vector</b> machine (SVM) classi er is proposed which is capable of modifying an existing linear classi er by both retiring old data and adding new data. A very important feature of the proposed single-pass algorithm, which allows it to handle massive datasets, is that huge blocks of data, say {{of the order of}} millions of points, can be stored in blocks of size (n + 1) 2, where n is the usually small (typically less than 100) dimensional input space in which the data resides. To demonstrate the e ectiveness of the algorithm we classify a dataset of 1 billion points in 10 -dimensional input space into tw...|$|R
40|$|The {{performance}} of support vector clustering suffered Due to noisy data. The pre-processing of data play {{important role in}} support vector cluster. In support vector clustering the mapping of data from one sphere to another sphere found some unwanted behaviour of data, these behaviour are boundary point, core and outlier. These data point degrade the performance and efficiency of support vector clustering. For the reduction of core, outlier and boundary value, we combined all dissimilar data and form COB model and data passes through genetic algorithm for collective collection of COB and reduce the COB value in data pre-processing phase. After reduction of COB support vector clustering are applied. Our empirical evaluation shows that our method is better than <b>incremental</b> support <b>vector</b> clustering and SSN-SVC...|$|R
40|$|Abstract- The {{purpose of}} this paper is the study of {{different}} power converters and control techniques to allow power grid connection of modern vertical operation systems, verifying IEC 61000 - 3 - 2. We focus on the harmonic current analysis produced by the industrial standard AC/DC/ 3 -phase AC machines system. Different AC/DC converters and control techniques have been compared to determine the one that minimizes low frequency harmonic current production. An <b>incremental</b> Space <b>Vector</b> Modulator to regulate power grid current flow in electrical reference frame with a full-bridge controlled rectifier has been proven as the best power grid connection system. A general purpose test rig has been designed to evaluate the different power grid interface policies. Experimental results have been provided to show the effectiveness of the method...|$|R
40|$|Learning {{from data}} streams via online {{transduction}} A practical {{issue in the}} existing transduction methods is expensive and inefficient computation compared to induction methods. This has hindered the use of transduction methods in temporal and real-time data mining. In this paper, we introduce a fast incremental transductive confidence machine (TCM) based on adiabatic <b>incremental</b> support <b>vector</b> machine (SVM) such that critical information from current transduction trial is stored for later use. The algorithm is empirically shown to be computationally efficient and its performance is consistent with standard TCM implementation. Besides being a classifier, TCM provides additional useful statistical information about the data that it processed. These information can be useful for temporal and real-time data mining. We demonstrate the feasibility and usefulness of using such statistical information for stream-based active learning. 1...|$|R
40|$|The {{purpose of}} this paper is the study of {{different}} power converters and control techniques to allow power grid connection of modern vertical operation systems, verifying IEC 61000 - 3 - 2. We focus on the harmonic current analysis produced by the industrial standard AC/DC/ 3 -phase AC machines system. Different AC/DC converters and control techniques have been compared to determine the one that minimizes low frequency harmonic current production. An <b>incremental</b> space <b>vector</b> modulator to regulate power grid current flow in electrical reference frame with a full-bridge controlled rectifier has been proven as the best power grid connection system. A general purpose test rig has been designed to evaluate the different power grid interface policies. Experimental results have been provided to show the effectiveness of the method...|$|R
40|$|Abstract Using a {{recently}} introduced proximal support vector ma-chine classier [4], {{a very fast}} and simple <b>incremental</b> support <b>vector</b> machine (SVM) classier is proposed which is capable of modifying an existing linear classier by both retiring old data and adding new data. A very important feature of the proposed single-pass algorithm, which allows it to handle massive datasets, is that huge blocks of data, say {{of the order of}} millions of points, can be stored in blocks of size (n + 1) 2, where n is the usually small (typically less than 100) dimensional input space in which the data resides. To demonstrate the eectiveness of the algorithm we classify a dataset of 1 billion points in 10 -dimensional input space into two classes in less than 2. 5 hours on a 400 MHz Pentium II processor. Keywords incremental classier, massive data classication, sup-port vector machines...|$|R
40|$|This paper proposes {{intelligent}} detection approaches {{based on}} <b>Incremental</b> Support <b>Vector</b> Machine and Artifi-cial Immune System for the spam of e-mail stream. In the approaches, a window {{is used to}} hold several classifiers each of which classifies the e-mail independently and the label of the e-mail is given by a strategy of majority voting. Exceeding margin update technique is also used for the dy-namical update of each classifier in the window. A sliding window is employed for purge of out-of-date knowledge so far. Techniques above endow our algorithm with dynamical and adaptive properties {{as well as the}} ability to trace the changing of the content of e-mails and user’s interests in a continuous way. We conduct many experiments on two pub-lic benchmark corpus called PU 1 and Ling. Experimental results demonstrate that the proposed intelligent detection approaches for spam give a promising performance. 1...|$|R
40|$|Keywords:SVM, <b>incremental</b> training, support <b>vector</b> Abstract. In {{order to}} figure out the {{deficiency}} of the SVM on extensive sample, nature of SV is studied in this paper. An improved incremental training algorithm is put forward based on dimensional of samples. A chosen gene which got by density and distance criterion is used in this method. In this method the number of training samples is decreased and the space information is keeped. So, the training speed is improved while the precision is not reduced. And the simulation proved the efficiency of this method. ...|$|R
40|$|With {{the advent}} of video sharing websites, the amount of videos on the {{internet}} grows rapidly. Web video categorization is an efficient methodology for organizing the huge amount of videos. In this paper we investigate the characteristics of web videos, and make two contributions for the large scale incremental web video categorization. First, we develop an effective semantic feature space Concept Collection for Web Video with Categorization Distinguishability (CCWV-CD), which is consisted of concepts with small semantic gap, and the concept correlations are diffused by a novel Wikipedia Propagation (WP) method. Second, we propose an <b>incremental</b> support <b>vector</b> machine with fixed number of support vectors (n-ISVM) for large scale incremental learning. To evaluate the performance of CCWV-CD, WP and n-ISVM, we conduct extensive experiments on the dataset of 80, 021 most representative videos on a video sharing website. The experiment {{results show that the}} CCWV-CD and WP is more representative for web videos, and the n-ISVM algorithm greatly improves the efficiency in the situation of incremental learning...|$|R
40|$|With {{the advent}} of video sharing websites, the amount of videos on the {{internet}} grows rapidly. Web video categorization is an efficient methodology to organize the huge amount of data. In this paper, we propose an effective web video categorization algorithm for the large scale dataset. It includes two factors: 1) For the great diversity of web videos, we develop an effective semantic feature space called Concept Collection for Web Video Categorization (CCWV-CD) to represent web videos, which consists of concepts with small semantic gap and high distinguishing ability. Meanwhile, the online Wikipedia API is employed to diffuse the concept correlations in this space. 2) We propose an <b>incremental</b> support <b>vector</b> machine with fixed number of support vectors (n-ISVM) to fit the large scale incremental learning problem in web video categorization. Extensive experiments are conducted on the dataset of 80021 most representative videos on YouTube demonstrate that the semantic space with Wikipedia prorogation is more representative for web videos, and n-ISVM outperforms other algorithms in efficiency when performs the incremental learning...|$|R
40|$|Nowadays the {{detection}} of proteins {{plays a crucial role}} for the early diagnosis of diseases. The combination of biosensor application with nanotechnology has offered new alternatives for clinical diagnostic techniques. One of the major public health problems in many developing countries is tuberculosis (TB) susceptibility and Interferon-gamma (IFN-γ) can be used in the diagnosis of this infectious disease. In this study, a prototype graphene based FET structure was employed as a biosensor. Additionally, a PDMS layer was deployed beneath the graphene as a dielectric layer. As a result of the changeability of Ids (drain-source current), the carrier concentration would change when the IFN-γ molecules attach to the surface of graphene. To acquire another pattern for the I-V (current-voltage characteristic), the <b>Incremental</b> Support <b>Vector</b> Regression (ISVR) algorithm was also employed. The comparative study based on the outcomes of the ISVR and pre-existing analytical models with experimental data found that there was acceptable agreement, which was able to substantiate the proposed models. Moreover, the ISVR showed that the proposed method remarkably improved the accuracy of prediction...|$|R
40|$|Increasing {{access to}} large, non-stationary face {{datasets}} and corresponding demands to process, analyze {{and learn from}} this data. This has lead to {{a new class of}} on-line/incremental face recognition problems. While it is ad-vantageous to build large scale learning systems when re-sources permit, a counter problem of learning with limited resources in presence of streaming data arises. We present a budgeted <b>incremental</b> support <b>vector</b> learning method suit-able for online learning applications. Our system can pro-cess one sample at a time and is suitable when dealing with large streams of data. We discuss multiple budget mainte-nance strategies and investigate the problem of incremen-tal unlearning. We propose a novel posterior probability estimation model based on Extreme Value Theory (EVT) and show its suitability for budgeted online learning ap-plications (calibration with limited data). We perform thor-ough analysis of various probability calibration techniques with the help of methods inspired from meteorology. We test our methods on Labeled Faces in the Wild dataset and show suitability of the proposed approach for face verifica-tion/recognition...|$|R
40|$|Performance {{degradation}} will {{be caused}} by a variety of interfering factors for pattern recognition-based myoelectric control methods in the long term. This paper proposes an adaptive learning method with low computational cost to mitigate the effect in unsupervised adaptive learning scenarios. We presents a particle adaptive classifier (PAC), by constructing a particle adaptive learning strategy and universal incremental least square support vector classifier (LS-SVC). We compared PAC performance with <b>incremental</b> support <b>vector</b> classifier (ISVC) and non-adapting SVC (NSVC) in a long-term pattern recognition task in both unsupervised and supervised adaptive learning scenarios. Retraining time cost and recognition accuracy were compared by validating the classification performance on both simulated and realistic long-term EMG data. The classification results of realistic long-term EMG data showed that the PAC significantly decreased the performance degradation in unsupervised adaptive learning scenarios compared with NSVC (9. 03 % ± 2. 23 %, p < 0. 05) and ISVC (13. 38 % ± 2. 62 %, p = 0. 001), and reduced the retraining time cost compared with ISVC (2 ms per updating cycle vs. 50 ms per updating cycle) ...|$|R
