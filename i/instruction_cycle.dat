88|597|Public
2500|$|There was a grass {{airstrip}} at Ban Pa Dong, {{and some}} old wooden buildings {{that had been}} built by the French. It was sited on a ridgeline, at [...] elevation, about [...] south of the Plain of Jars. The altitude would prove problematic for air operations, as an early helicopter crash showed. Flying in to begin the first Operation Momentum <b>instruction</b> <b>cycle,</b> the Air America H-34 carrying Lair ran out of lift to clear a ridge-line. After clipping trees, the helicopter tumbled down a hillside; there were no serious casualties except the demolished helicopter.|$|E
5000|$|<b>Instruction</b> <b>cycle</b> time: 10.8 µs (8 clock cycles / <b>instruction</b> <b>cycle)</b> ...|$|E
50|$|The <b>instruction</b> <b>cycle</b> is {{repeated}} continuously until {{the power is}} turned off.|$|E
50|$|Adding two 8-digit numbers (32 bits each, {{assuming}} 4-bit BCD digits) takes 850 µs - i.e. 79 <b>instruction</b> <b>cycles,</b> about 10 <b>instruction</b> <b>cycles</b> per decimal digit.|$|R
50|$|Instruction {{execution}} time 1 or 2 <b>instruction</b> <b>cycles</b> (10.8 or 21.6 µs), 46300 to 92600 instructions per second.|$|R
40|$|Superscalar {{machines}} fetch multiple scalar <b>instructions</b> per <b>cycle</b> {{from the}} <b>instruction</b> cache. However, machines that fetch {{no more than}} one <b>instruction</b> per <b>cycle</b> from the <b>instruction</b> cache, such as Dynamic Trace Scheduled VLIW (DTSVLIW) machines, have shown performances comparable to that of Superscalars. In this paper, we present experiments that show that fetching a single instruction from the <b>instruction</b> cache per <b>cycle</b> allows the same performance achieved fetching multiple <b>instructions</b> per <b>cycle</b> thanks to the execution locality present in programs. We also present the first direct comparison between the Superscalar, Trace Cache and DTSVLIW architectures. Our results show that a DTSVLIW machine capable of executing up to 16 <b>instructions</b> per <b>cycle</b> can perform 21. 9 % better than a Superscalar and 6. 6 % better than a Trace Cache with equivalent hardware...|$|R
5000|$|Multiple {{arithmetic}} units {{may require}} memory architectures to support several accesses per <b>instruction</b> <b>cycle</b> ...|$|E
50|$|Step 4 of the <b>Instruction</b> <b>Cycle</b> is the Execute Cycle. Here, the {{function}} of the instruction is performed. If the instruction involves arithmetic or logic, the Arithmetic Logic Unit is utilized. This is the only stage of the <b>instruction</b> <b>cycle</b> that is useful {{from the perspective of the}} end user. Everything else is overhead required to make the execute phase happen.|$|E
5000|$|Step 1 of the <b>instruction</b> <b>cycle</b> is fetch cycle, {{which is}} the same for each instruction: ...|$|E
50|$|The Alpha 21264 or Alpha 7 for short, is a four-issue superscalar {{microprocessor}} with {{out-of-order execution}} and speculative execution. It has a peak execution rate of six <b>instructions</b> per <b>cycle</b> and could sustain four <b>instructions</b> per <b>cycle.</b> It has a seven-stage instruction pipeline.|$|R
50|$|Modern {{computer}} {{performance is}} often described in IPC (<b>instructions</b> per <b>cycle).</b> This measures {{the efficiency of the}} architecture at any clock frequency. Since a faster rate can make a faster computer, this is a useful measurement. Older computers had IPC counts as low as 0.1 <b>instructions</b> per <b>cycle.</b> Simple modern processors easily reach near 1. Superscalar processors may reach three to five IPC by executing several <b>instructions</b> per clock <b>cycle.</b>|$|R
40|$|This paper {{presents}} a multithreaded superscalar processor that permits several threads to issue {{instructions to the}} execution units of a wide superscalar processor in a single <b>cycle.</b> <b>Instructions</b> can simultaneously be issued from up to 8 threads with a total issue bandwidth of 8 <b>instructions</b> per <b>cycle.</b> Our {{results show that the}} 8 -threaded 8 -issue processor reaches a throughput of 4. 2 <b>instructions</b> per <b>cycle.</b> 1 Introduction Current microprocessors utilize instruction-level parallelism by a deep processor pipeline and by the superscalar technique that issues up to four <b>instructions</b> per <b>cycle</b> from a single thread. VLSI-technology will allow future generations of microprocessors to exploit instruction-level parallelism up to 8 <b>instructions</b> per <b>cycle,</b> or more. However, the instruction-level parallelism found in a conventional instruction stream is limited. The solution is the additional utilization of more coarse-grained parallelism. The main approaches are the multiprocessor chip and the [...] ...|$|R
50|$|Interrupt latency is {{constant}} at three instruction cycles. External interrupts {{have to be}} synchronized with the four-clock <b>instruction</b> <b>cycle,</b> otherwise {{there can be a}} one <b>instruction</b> <b>cycle</b> jitter. Internal interrupts are already synchronized. The constant interrupt latency allows PICs to achieve interrupt-driven low-jitter timing sequences. An example of this is a video sync pulse generator. This is no longer true in the newest PIC models, because they have a synchronous interrupt latency of three or four cycles.|$|E
50|$|In the <b>{{instruction}}</b> <b>cycle,</b> {{the instruction}} is {{loaded into the}} Instruction register after the processor fetches it from the memory location pointed by the program counter.|$|E
50|$|In the {{simplest}} style of computer architecture, the <b>instruction</b> <b>cycle</b> is very rigid, and runs exactly as {{specified by the}} programmer.In the Instruction Fetch part of the cycle,the contents of the program counter (PC) register are placed on the address bus, {{and sent to the}} memory unit;the memory unit returns the instruction at that address, and it is latched into the Instruction Register (IR);and the contents of the PC are incremented or over-written by a new value (in the case of a Jump or Branch instruction) ready for the next <b>instruction</b> <b>cycle.</b>|$|E
40|$|Includes bibliographical {{references}} (pages [42]- 43) The {{purpose of}} this project was to design and develop an efficient multiprocessor system to implement the Fast Transversal Filter (FTF) using commercially available microprocessors. The system was also designed with some flexibility in it {{to be able to}} run other more common signal-processing algorithms, such as the Least Mean Square (LMS) algorithm, efficiently. Due {{to the nature of the}} application, powerful and fast digital signal processors (DSPs) were chosen for the design. First, an LMS-based Adaptive Line Enhancer (ALE) and the FTF were implemented on a single DSP. This was a reference point for working on reducing the iteration cycle time of the filters. Next, the algorithms were analyzed, noting sequential characteristics and heavy computational bottlenecks that limited the speed at which the algorithms run. Once decomposed, parallelisms inside of the algorithms could be exploited. Parallelism within the FTF and within its vector computations were the target of speedup efforts. The algorithms and the vectors they operate on were appropriately partitioned to reduce the number of <b>instruction</b> <b>cycles</b> per iteration of the algorithms. The final design was chosen to maximize speedup and minimize interprocessor communication all with the minimum number of processors and simplest control logic. It consists of 2 pairs of digital signal processors, 12 latches, and 24 OR-gates as control logic. A prototype of the system was built using four Motorola DSP 56001 fixed-point digital signal processors. The system developed had a speedup factor of nearly 4 over the single processor implementations. The LMS algorithm iteration cycle was reduced from 4 M + 15 toM + 26 <b>instruction</b> <b>cycles</b> using the new multiprocessor design. Each iteration of the FTF algorithm required 15 M + 151 <b>instruction</b> <b>cycles</b> on a single processor and 5. 5 M + 74 <b>instruction</b> <b>cycles</b> using the devised architecture. M. S. (Master of Science...|$|R
5000|$|... #Subtitle level 2: <b>Instructions</b> per <b>cycle</b> {{for various}} {{processors}} ...|$|R
40|$|The authors {{present a}} simple method, {{based on the}} {{principle}} of successive approxmation, of computing a function using a futed-point arithmetic processor. As an example, computing the square root function is considered and the performance is compared with Newton's method, in terms of accuracy and the number of <b>instruction</b> <b>cycles</b> required...|$|R
5000|$|Each PP {{included}} its own {{memory of}} 4096 12-bit words. This memory served for both for I/O buffering and program storage, but the execution units were shared by 10 PPs, in a configuration called the Barrel and slot. This {{meant that the}} execution units (the [...] "slot") would execute one <b>instruction</b> <b>cycle</b> from the first PP, then one <b>instruction</b> <b>cycle</b> from the second PP, etc. in a round robin fashion. This was done both to reduce costs, and because access to CP memory required 10 PP clock cycles: when a PP accesses CP memory, the data is available next time the PP receives its slot time.|$|E
50|$|By {{selecting}} single-step and single-cycle {{mode and}} stepping through a {{program with the}} step button, the user can see exactly what happens during every <b>instruction</b> <b>cycle,</b> observing the program counter, data bus and control signals on their corresponding LEDs.|$|E
5000|$|In Tibetan Buddhism, {{specifically}} in the literature and practice of Dzogchen, the seventeen tantras of the esoteric <b>instruction</b> <b>cycle</b> (...) are a collection of tantras belonging to the textual division known as the [...] "esoteric instruction cycle" [...] (also known variously as: Nyingtik, Upadesha or Menngagde).|$|E
5000|$|Fetches 4 x86 <b>instructions</b> per <b>cycle</b> {{as opposed}} to Intel's 3-5 ...|$|R
5000|$|I= is {{the average}} <b>instructions</b> per <b>cycle</b> (IPC) for this benchmark.|$|R
5000|$|... #Subtitle level 3: Using <b>cycles</b> per <b>instruction</b> and <b>instructions</b> per <b>cycle</b> ...|$|R
50|$|The 4004 {{employs a}} 10 µm process {{silicon-gate}} enhancement load pMOS technology on a 12 mm² die and can execute approximately 92,000 instructions per second; a single <b>instruction</b> <b>cycle</b> is 10.8 microseconds. The original clock rate design goal was 1 MHz, {{the same as}} the IBM 1620 Model I.|$|E
50|$|The 8080 System Design Kit (SDK-80) of 1975 {{provided}} a training and prototype vehicle {{for evaluation of}} the 8080 microcomputer system (MCS-80), clocked at 0.5 MHZ (1.95 uS <b>instruction</b> <b>cycle</b> time). The SDK-80 allowed interface to an existing application or custom interface development. A monitor ROM was provided.|$|E
50|$|Eventually, most machine-language {{programming}} came to {{be generated}} by compilers and report generators. The {{reduced instruction set computer}} returned full-circle to the PDP-8's emphasis on a simple instruction set and achieving multiple actions in a single <b>instruction</b> <b>cycle,</b> in order to maximize execution speed, although the newer computers have much longer instruction words.|$|E
5000|$|This {{specific}} behavior permitted initial {{execution of}} an interrupt routines, since base registers {{would not necessarily}} be set to 0 {{during the first few}} <b>instruction</b> <b>cycles</b> of an interrupt routine. It isn't needed for IPL ("Initial Program Load" [...] or boot), as one can always clear a register without the need to save it.|$|R
50|$|The FMAC units {{take four}} cycles to execute one instruction, {{but as the}} units have a six-stage pipeline, they have a {{throughput}} of one <b>instruction</b> per <b>cycle.</b> The FDIV unit has a nine-stage pipeline and can execute one <b>instruction</b> every seven <b>cycles.</b>|$|R
5000|$|Performance: 4/8-bit {{instructions}} @ 3.08 MIPS (1.54 MIPS, 1 <b>instruction</b> per <b>cycle,</b> per MCU) ...|$|R
50|$|Another unusual feature {{was that}} rather than execute mask, rotate, shift and merge {{instructions}} in the arithmetic logic unit (ALU), {{as is the case}} with most microprocessors, the 8X300 had separate mask, rotate, shift and merge units. Data could therefore be rotated, masked, modified, shifted and merged (in that order), all in one <b>instruction</b> <b>cycle.</b>|$|E
50|$|The basic 77-68 {{comprised}} an 8-inch square {{printed circuit}} board accommodating the microprocessor, Static RAM of 256 8 bit words and the bare essentials in terms of input/output and timing logic to make a working computer. The processor ran with an <b>instruction</b> <b>cycle</b> time of around 1.25 microseconds with most instructions executing in 3 to 7 microseconds.|$|E
50|$|In simpler CPUs the <b>instruction</b> <b>cycle</b> is {{executed}} sequentially, each instruction being processed {{before the}} next one is started. In most modern CPUs the instruction cycles are instead executed concurrently, and often in parallel, through an instruction pipeline: the next instruction starts being processed before the previous instruction has finished, which is possible because the cycle is broken up into separate steps.|$|E
5000|$|In {{computer}} architecture, <b>cycles</b> per <b>instruction</b> (aka clock <b>cycles</b> per <b>instruction,</b> clocks per instruction, or CPI) is {{one aspect}} of a processor's performance: {{the average number of}} clock <b>cycles</b> per <b>instruction</b> for a program or program fragment. [...] It is the multiplicative inverse of <b>instructions</b> per <b>cycle.</b>|$|R
40|$|An {{efficient}} depth image based rendering with edge dependent {{depth filter}} and interpolation is proposed. The proposed method can solve the hole-filling problem in DIBR system efficiently with high quality. The PSNR {{of the proposed}} method {{is better than the}} previous work by 6 dB. And the subjective view shows the quality is better. In addition to that, the number of <b>instruction</b> <b>cycles</b> is 3. 7 percent compared with the previous work. 1...|$|R
50|$|Each of the {{instruction}} queues can accept up to four instructions from the decoder, avoiding any bottlenecks. The instruction queues issue their instructions to their execution units dynamically depending {{on the availability of}} operands and resources. Each of the queues except for the load/store queue can issue up to two <b>instructions</b> every <b>cycle</b> to its execution units. The load/store queue can only issue one instruction. The R10000 can thus issue up to five <b>instructions</b> every <b>cycle.</b>|$|R
