226|140|Public
5|$|It {{provides}} network administrators {{a method}} of creating a computing cluster, which allows them to exploit previously unused computational power for calculations that can be divided easily into smaller operations, such as Mandelbrot maps. The setup of an Xgrid cluster can be achieved at next to no cost, as Xgrid client is pre-installed on all computers running Mac OS X 10.4 to Mac OS X 10.7. The Xgrid client {{was not included in}} Mac OS X 10.8. The Xgrid controller, the <b>job</b> <b>scheduler</b> of the Xgrid operation, is also included within Mac OS X Server and as a free download from Apple. Apple has kept the command-line job control mechanism minimalist while providing an API to develop more sophisticated tools built around it.|$|E
25|$|The {{software}} utility Cron is a time-based <b>job</b> <b>scheduler</b> in Unix-like computer operating systems. People {{who set up}} {{and maintain}} software environments use cron to schedule jobs (commands or shell scripts) to run periodically at fixed times, dates, or intervals. It typically automates system maintenance or administration—though its general-purpose nature makes it useful for things like downloading files from the Internet and downloading email at regular intervals. The origin of the name cron is from the Greek word for time, χρόνος (chronos).|$|E
5000|$|... https://en.wikipedia.org/wiki/List_of_job_scheduler_{{software}} List of <b>job</b> <b>scheduler</b> software ...|$|E
5000|$|Unofficial <b>job</b> <b>schedulers</b> {{that can}} be used with the Globus Toolkit: ...|$|R
50|$|Modern <b>job</b> <b>schedulers,</b> often termed {{workload}} automation, typically {{provide a}} {{graphical user interface}} and a single point of control for definition and monitoring of background executions in a distributed network of computers. Increasingly, <b>job</b> <b>schedulers</b> are required to orchestrate the integration of real-time business activities with traditional background IT processing across different operating system platforms and business application environments.|$|R
5000|$|GRAM (Grid Resource Allocation Manager), a {{component}} of the Globus Toolkit, officially supports the following <b>job</b> <b>schedulers</b> or batch-queuing systems: ...|$|R
50|$|Platform LSF, a {{commercial}} computer software <b>job</b> <b>scheduler.</b>|$|E
50|$|VisualCron is a <b>job</b> <b>scheduler</b> and {{automation}} {{tool for}} Windows.|$|E
5000|$|<b>Job</b> <b>scheduler,</b> an {{enterprise}} software application {{in charge of}} unattended background executions.|$|E
5000|$|An {{important}} {{niche for}} <b>job</b> <b>schedulers</b> is managing the job queue for {{a cluster of}} computers. Typically, the <b>scheduler</b> will schedule <b>jobs</b> from the queue as sufficient resources (cluster nodes) become idle.Some widely used cluster batch systems are ...|$|R
5000|$|Modern schedulers on {{a variety}} of {{architectures}} and operating systems. With standard scheduling tools limited to commands such as at and batch, the need for mainframe standard <b>job</b> <b>schedulers</b> has grown with the increased adoption of distributed computing environments.|$|R
5000|$|Job Scheduling {{has a long}} history. <b>Job</b> <b>Schedulers</b> {{have been}} one of the major {{components}} of IT infrastructure since the early mainframe systems. At first, stacks of punched cards were processed one after the other, hence the term [...] "batch processing".|$|R
50|$|Portable Batch System, a {{computer}} software <b>job</b> <b>scheduler</b> that allocates network resources to batch jobs.|$|E
5000|$|NetworkComputer (NC), {{previously}} {{known as}} Flowtracer/NC, is a commercial <b>job</b> <b>scheduler</b> developed by Runtime Design Automation.|$|E
50|$|HTCondor {{is one of}} the <b>job</b> <b>scheduler</b> {{mechanisms}} {{supported by}} GRAM (Grid Resource Allocation Manager), a component of the Globus Toolkit.|$|E
40|$|Replica {{management}} {{systems have been}} deployed to improve reliability for the permanent storage of scientific data on cooperative networks of commodity hardware. They also offer the capability of improving the scalability of the data service performance of <b>job</b> <b>schedulers,</b> as executing large batches of data-intensive jobs on a distributed computation system quickly exhausts a centralized storage server. Data sets stored on the compute cluster in a distributed way improve the data access rate, but this technique involves several challenges including logical file name resolution, matchmaking jobs with resources efficiently, and data movement. A variety of relevant distributed computation models that tie replica {{management systems}} to <b>job</b> <b>schedulers</b> are described and performance results from a new system are obtained. I...|$|R
30|$|Spark {{is widely}} {{supported}} on commercial clouds such as Amazon EC 2, Microsoft Azure HDInsight, and increasingly in smaller academic clouds. It can therefore exploit {{the scale and}} elasticity of these clouds. There are also Spark <b>job</b> <b>schedulers</b> that can run multiple jobs simultaneously.|$|R
5000|$|MP Synergy [...] - [...] a metascheduler {{based on}} Globus Toolkit {{technology}} that {{allows users to}} perform efficient scheduling within an organization that has multiple <b>job</b> <b>schedulers</b> already deployed and controlling independent clusters. [...] Supported schedulers include Grid MP, Sun Grid Engine, Platform LSF, PBS, LoadLeveler, and Condor.|$|R
50|$|LSF {{is one of}} the <b>job</b> <b>scheduler</b> {{mechanisms}} {{supported by}} the Grid Resource Allocation Manager (GRAM) component of the Globus Toolkit.|$|E
5000|$|There {{are many}} {{concepts}} that {{are central to}} almost every <b>job</b> <b>scheduler</b> implementation and that are widely recognized with minimal variations: ...|$|E
50|$|In system software, a {{job queue}} (sometimes batch queue), is a data {{structure}} maintained by <b>job</b> <b>scheduler</b> software containing jobs to run.|$|E
40|$|State-of-the-art <b>job</b> <b>schedulers</b> have master/slave architecture, {{where the}} master becomes a {{performance}} bottleneck and {{is susceptible to}} single point of failure, especially at petascales • Develop a dynamic distributed scalable job scheduling system at the granularity of node/core levels with distributed load balancing algorithm (work stealing) leading to high throughput and system utilization. Building Block...|$|R
40|$|Traditional batch <b>job</b> <b>schedulers</b> are a poor {{fit for a}} grid {{computing}} environment. In {{order to}} respond to the grid scheduling challenges, the client must perform planning. In this paper, we expound upon the differences between planning versus scheduling, and present two grid projects which utilize a ClassAd matchmaking framework to enable planning on the grid. Planning for purposes of job placement within the EU DataGrid and DZero SAMGrid projects will be explored. ...|$|R
5000|$|<b>Job</b> and <b>scheduler</b> fault {{tolerance}} - Grid Engine continues {{to operate as}} long as there is one or more hosts available ...|$|R
50|$|LLNL {{will use}} the SLURM <b>job</b> <b>scheduler,</b> which is also used by the Dawn {{prototype}} and China's Tianhe-IA, to manage Sequoia's resources.|$|E
50|$|Microsoft Windows {{computer}} cluster Server 2003 {{based on}} the Windows Server platform provides pieces for High Performance Computing like the <b>Job</b> <b>Scheduler,</b> MSMPI library and management tools.|$|E
5000|$|Scheduling: Using a <b>job</b> <b>scheduler</b> {{can greatly}} improve the {{reliability}} and consistency of backups by removing {{part of the human}} element. Many backup software packages include this functionality.|$|E
50|$|BatchMan is batch {{scheduling}} software that was first created 1995. It {{is one of}} the <b>job</b> <b>schedulers</b> for SAP that is completely integrated into SAP and written in ABAP. It integrates seamlessly with other SAP modules like BW or FI and can perform tasks based on time periods, the arrival of files on a server, or SAP events. Batchman resides in its own SAP Namespace /BTCMAN/ since Version 5, formerly it was J5H. Produced by Honico.|$|R
40|$|In {{this article}} we provide brief {{descriptions}} of three classes of schedulers: Operating Systems Process <b>Schedulers,</b> Cluster Systems, <b>Jobs</b> <b>Schedulers</b> and Big Data Schedulers. We describe their evolution from early adoptions to modern implementations, considering both the use and features of algorithms. In summary, we discuss differences between all presented classes of schedulers and discuss their chronological development. In conclusion, we highlight similarities in the focus of scheduling strategies design, applicable to both local and distributed systems...|$|R
40|$|Fairness is an {{important}} aspect in queuing systems. Several fairness measures have been proposed in queuing systems in general and parallel job scheduling in particular. Generally, a scheduler is considered unfair if some jobs are discriminated while others are favored. Some of the metrics used to measure fairness for parallel <b>job</b> <b>schedulers</b> can imply unfairness {{where there is no}} discrimination (and vice versa). This makes them inappropriate. In this paper, we show how the existing misrepresents fairness in practice. We then propose a new approach for measuring fairness for parallel <b>job</b> <b>schedulers.</b> Our approach is based on two principles: (i) since jobs have different resource requirements and find different queue/system states, they need not to have the same performance for the scheduler to be fair and (ii) to compare two schedulers for fairness, we make comparisons of how the <b>schedulers</b> favor/discriminate individual <b>jobs.</b> We use performance and discrimination trends to validate our approach. We observe that our approach can deduce discrimination more accurately. This is true even in cases where the most discriminated jobs are not the worst performing jobs. key words: Fairness, Scheduler, Net benefit 1...|$|R
50|$|The SLURM <b>job</b> <b>scheduler</b> {{which is}} used {{on a number of}} {{supercomputers}} uses a best fit algorithm based on Hilbert curve scheduling in order to optimize locality of task assignments.|$|E
5000|$|PBS is {{supported}} as a <b>job</b> <b>scheduler</b> mechanism by several [...] meta schedulers including Moab by Adaptive Computing Enterprises and GRAM (Grid Resource Allocation Manager), {{a component of}} the Globus Toolkit.|$|E
50|$|Maui Cluster Scheduler is a <b>job</b> <b>scheduler</b> {{for use on}} {{clusters}} and supercomputers initially developed by Cluster Resources, Inc.. Maui is capable of supporting multiple scheduling policies, dynamic priorities, reservations, and fairshare capabilities.|$|E
40|$|Abstract. As virtual {{machines}} (VMs) {{are used}} for {{a wider range of}} applications, we encounter the need to integrate virtual machine provisioning models into the current site resource management infrastructure as seamlessly as possible. To address such requirements, we describe an approach to VM management that uses the ideas of multi-level scheduling to integrate VM provisioning into existing <b>job</b> <b>schedulers.</b> We further describe how VMs provisioned in this way can be turned into useful virtual clusters integrated into the surrounding infrastructure and community. ...|$|R
40|$|Our work to {{meet our}} goal of {{end-to-end}} fault tolerance has focused on two areas: (1) improving fault tolerance in various software currently available and widely used throughout the HEC domain and (2) using fault information exchange and coordination to achieve holistic, systemwide fault tolerance and understanding how to design and implement interfaces for integrating fault tolerance features for multiple layers of the software stack—from the application, math libraries, and programming language runtime to other common system software such as <b>jobs</b> <b>schedulers,</b> resource managers, and monitoring tools...|$|R
40|$|Many {{parallel}} <b>job</b> <b>schedulers</b> {{are designed}} to be operated on a single “head ” node. Hence, if the head node fails the scheduler is no longer active. For many systems, the only way to launch new jobs is through the scheduler. Therefore, when the scheduler is inactive, no new jobs can be launched. This situation leads to the scheduler becoming a single point of failure, and results in lowered system reliability and availability. Two approaches to removing the scheduler from being a single point of failure are to create an “active/hot-standby” or “active/active ” scheduler. Each of these approaches instantiate more than one scheduler, and are able to withstand the failure of at least one scheduler. With the “active/hotstandby” model, a “hot-standby” node is available to take over as the scheduler, but is inactive and not operational unless the active head node fails. In an “active/active” scenario, there are multiple active head nodes, all of which share scheduling duties. The systems can sustain the failure of {{one or more of these}} active head nodes, by operating in a degraded state. In this paper we present performance studies on an open source scheduler (Slurm), aimed at providing information to assess the desirability of the “active/active” versus “active/hot-standby” model in enhancing reliability/availability of <b>job</b> <b>schedulers...</b>|$|R
