79|10000|Public
50|$|To {{construct}} a contour boxplot, <b>data</b> <b>ordering</b> {{is the first}} step. In functional data analysis, each observation is a real function, therefore <b>data</b> <b>ordering</b> {{is different from the}} classical boxplot where scalar data are simply ordered from the smallest sample value to the largest. More generally, data depth, gives a center-outward ordering of data points, and thereby provides a mechanism for constructing rank statistics of various kinds of multidimensional data. For instance, functional data examples can be ordered using the method of band depth or a modified band depth. In contour data analysis, each observation is a feature-set (a subset of the domain), and therefore not a function. Thus, the notion of band depth and modified band depth is further extended to accommodate features that can be expressed as sets but not necessarily as functions. Contour band depth allows for ordering feature-set data from the center outwards and, thus, introduces a measure to define functional quantiles and the centrality or outlyingness of an observation. Having the ranks of feature-set data, the contour boxplot is a natural extension of the classical boxplot which in special cases reduces back to the traditional functional boxplot.|$|E
5000|$|Set band depth (introduced in [...] ), denoted as sBD, is {{a method}} for {{establishing}} a center-outward ordering {{of a collection of}} sets. As with other band depth, <b>data</b> <b>ordering</b> methods, set band depth, computes the probability of whether a sample lies in the band formed by j other samples from the distribution. We say that a set S ∈ E is an element of the band of a collection of j other sets S1, ..., Sj ∈ E if it is bounded by their union and intersection. That is: ...|$|E
50|$|To {{construct}} a functional boxplot, <b>data</b> <b>ordering</b> {{is the first}} step. In functional data analysis, each observation is a real function, therefore, different from the classical boxplot where data are simply ordered from the smallest sample value to the largest, in a functional boxplot, functional data, e.g. curves or images, are ordered by a notion of band depth or a modified band depth. It allows for ordering functional data from the center outwards and, thus, introduces a measure to define functional quantiles and the centrality or outlyingness of an observation. Having the ranks of functional data, the functional boxplot is {{a natural extension of}} the classical boxplot.|$|E
40|$|We {{examine the}} {{technique}} of run-length encoding in combination with <b>data</b> <b>order,</b> where our {{attention is focused on}} good performance of image operations such as, e. g., rotation, reflection, and zooming. To this end we develop a new type of <b>data</b> <b>order</b> that supports these operations well and allows to perform them on a variant of a double-queue automaton directly on the compressed data stream. Becaus...|$|R
40|$|We {{investigate}} {{the power of}} non-determinism in purely functional programming languages with higher-order types. Specifically, we consider cons-free programs of varying <b>data</b> <b>orders,</b> equipped with explicit non-deterministic choice. Cons-freeness roughly means that data constructors cannot occur in function bodies and all manipulation of storage space thus has to happen indirectly using the call stack. While cons-free programs have previously been used by several authors to characterise complexity classes, the work on non-deterministic programs has almost exclusively considered programs of <b>data</b> <b>order</b> 0. Previous work has shown that adding explicit non-determinism to cons-free programs taking <b>data</b> of <b>order</b> 0 does not increase expressivity; we prove that this - dramatically - {{is not the case}} for higher data orders: adding non-determinism to programs with <b>data</b> <b>order</b> at least 1 allows for a characterisation of the entire class of elementary-time decidable sets. Finally we show how, even with non-deterministic choice, the original hierarchy of characterisations is restored by imposing different restrictions. Comment: pre-edition version of a paper accepted for publication at ESOP' 1...|$|R
40|$|A {{description}} and subroutine {{documentation of the}} <b>data</b> <b>order</b> processor, ORHDT is given. As part of the LANDSAT imagery verification and extraction system, ORDHT creates a computer tape containing the AgRISTARS requirements for LANDSAT <b>data</b> to be <b>ordered</b> from Goddard Space Flight Center. A brief description of hardware requirements is also included...|$|R
50|$|In the {{classical}} boxplot, the box itself represents the middle 50% of the data. Since the <b>data</b> <b>ordering</b> in the contour boxplot {{is from the}} center outwards, the 50% central region {{is defined by the}} band delimited by the 50% of deepest, or the most central observations. The border of the 50% central region is defined as the envelope representing the box in a classical boxplot. Thus, this 50% central region is the analog to the interquartile range (IQR) and gives a useful indication of the spread of the central 50% of the curves. This is a robust range for interpretation because the 50% central region is not affected by outliers or extreme values, and gives a less biased visualization of the curves' spread. The observation in the box indicates the median, or the most central observation which is also a robust statistic to measure centrality.|$|E
40|$|Since most DSP {{applications}} access {{large amount}} of data stored in the memory, a DSP code generator must minimize the addressing overhead. In this paper, we propose a method for addressing optimization in loop execution targeted toward DSP processors with autoincrement /decrement feature in their address generation unit. Our optimization methods include a multi-phase <b>data</b> <b>ordering</b> and a graph-based address register allocation. The proposed approaches have been evaluated using a set of core algorithms targeted towards the TI TMS 320 C 40 DSP processor. Experimental results show that our system is indeed more effective compared to a commercial optimizing DSP compiler. 1 Introduction Most DSP processors' address generation units (AGU) {{have more than one}} address registers with autoincrement /decrement capability. Addressing optimization can be achieved via <b>data</b> <b>ordering</b> and address register allocation. <b>Data</b> <b>ordering</b> determines the order of data stored in the memory. Address register allocat [...] ...|$|E
40|$|An {{innovative}} and simple experiment with cross-section <b>data</b> <b>ordering</b> {{is carried out}} to exploit a basic feature between many economic variables – nonlinear scale dependence. The experiment is tried on hedonic price models using two data sets for automobiles and computers respectively. The key findings are: (1) Hedonic price indices can be significantly biased if they are constructed using models which disregard possible nonlinear scale effects latent in data samples; (2) Scale-based <b>data</b> <b>ordering</b> offers considerable potential to filter such scale-dependent information from cross-section samples; (3) The filtering can be easily carried out by systematic adoption of dynamic modelling methods...|$|E
40|$|In {{the paper}} the {{algorithms}} for obtaining the search results in semi-structured <b>data</b> <b>ordered</b> by relevance are analyzed, disadvantages are marked and new {{algorithm is proposed}} {{taking into account the}} scale possibilities. ? ?????? ???????? ?????? ?????????? ??? ????????? ????????????? ?? ????????????? ??????????? ??????????????? ?????? ? ????????????????????? ??????, ???????? ?????????? ? ????????? ????? ???????? ? ?????? ???????????????...|$|R
50|$|Data: Media need {{to back up}} all {{of their}} stories with <b>data</b> in <b>order</b> to remain {{relevant}} and reliable. Reporters prefer to look at raw <b>data</b> in <b>order</b> {{to be able to}} take an unbiased perspective.|$|R
5000|$|Scott domains are {{intended}} to represent partial algebraic <b>data,</b> <b>ordered</b> by information content. An element [...] {{is a piece of}} data that might not be fully defined. The statement [...] means [...] " [...] contains all the information that [...] does".|$|R
40|$|There is {{a strong}} {{motivation}} {{to reduce the amount}} of acquired data necessary to reconstruct clinically useful MR images, since less data means faster acquisition sequences, less time for the patient to remain motionless in the scanner and better time resolution for observing temporal changes within the body. We recently introduced an improvement in image quality for reconstructing parallel MR images by incorporating a <b>data</b> <b>ordering</b> step with compressed sensing (CS) in an algorithm named `PECS'. 1 That method requires a prior estimate of the image to be available. We are extending the algorithm to explore ways of utilising the <b>data</b> <b>ordering</b> step without requiring a prior estimate. The method presented here first reconstructs an initial image x 1 by compressed sensing (with sparsity enhanced by SVD), then derives a <b>data</b> <b>ordering</b> from x 1, R 01, which ranks the voxels of x 1 according to their value. A second reconstruction is then performed which incorporates minimisation of the rst norm of the estimate after ordering by R 01, resulting in a new reconstruction x 2. Preliminary results are encouraging...|$|E
40|$|Abstract—How {{to achieve}} a {{flexible}} data and sensor planning service to schedule, plan, and empower diverse sensors and heterogeneous <b>data</b> <b>ordering</b> systems is a big challenge. In this paper, a service-oriented framework of data and sensor planning service for virtual sensors is proposed. The framework include...|$|E
40|$|We {{present in}} this work a {{scalable}} distributed genetic algorithm of <b>Data</b> <b>Ordering</b> Problem with Inversion using the MapReduce paradigm. This specific topic is appealing for reduction of the power dissipation in VLSI and in bioinformatics. The capacitance and the switching activity influence the power consumption on the software level. The ordering of the data sequences is an unconditional consequence of switching activity. An optimization problem related to this topic is the ordering of sequences such that {{the total number of}} transitions will be minimized – <b>Data</b> <b>Ordering</b> Problem (DOP). Adding the bus-invert paradigm, some sequences can be complemented. The resulting problem is the DOP with Inversion (DOPI). These ordering problems are NP-hard. We establish a scalable distributed genetic approach - MapReduce Parallel Genetic Algorithm (MRPGA) for DOPI, MRPGA_DOPI and draw comparisons with greedy algorithms. The proposed methods are estimated and experiments show the efficiency of MRPGA_DOPI...|$|E
2500|$|Pre-processingBefore a {{computer}} vision method {{can be applied}} to image <b>data</b> in <b>order</b> to extract some specific piece of information, it is usually necessary to process the <b>data</b> in <b>order</b> to assure that it satisfies certain assumptions implied by the method. Examples are ...|$|R
50|$|The {{combination}} of 2 and 3 cannot provide full training <b>data</b> <b>order</b> which {{is needed to}} apply the full SVM algorithm. Instead, it provides {{a part of the}} ranking information of the training data. So the algorithm can be slightly revised as follows.|$|R
50|$|An example {{algorithm}} is the Monocle algorithm that carries out dimensionality {{reduction of the}} data, builds a minimal spanning tree using the transformed <b>data,</b> <b>orders</b> cells in pseudo-time by following the longest connected path of the tree and consequently labels cells by type.|$|R
40|$|Fixed Fix for SRI Falloff {{functions}} with non-default third bodies (issue # 12) Fixed {{removal of}} jac/rate lists before libgen of functional_tester Fixed pywrap module import Changed Issue warning in Cantera parsing if the installed version doesn't {{have access to}} species thermo properties. Added Added significantly more documentation and examples for <b>data</b> <b>ordering,</b> the state vector / Jacobian, and using the python interfac...|$|E
40|$|In this correspondence, {{we propose}} a novel class of {{learning}} vector quantizers (LVQ's) based on multivariate <b>data</b> <b>ordering</b> principles. A special {{cast of the}} navel LVQ class is the median LVQ, which uses either the marginal median or the vector median as a multivariate estimator of location. The performance of the proposed marginal median LVQ in color image quantization is demonstrated by experiments...|$|E
40|$|Part 7 : Genetic AlgorithmsInternational audienceWe {{present in}} this work a {{scalable}} distributed genetic algorithm of <b>Data</b> <b>Ordering</b> Problem with Inversion using the MapReduce paradigm. This specific topic is appealing for reduction of the power dissipation in VLSI and in bioinformatics. The capacitance and the switching activity influence the power consumption on the software level. The ordering of the data sequences is an unconditional consequence of switching activity. An optimization problem related to this topic is the ordering of sequences such that {{the total number of}} transitions will be minimized – <b>Data</b> <b>Ordering</b> Problem (DOP). Adding the bus-invert paradigm, some sequences can be complemented. The resulting problem is the DOP with Inversion (DOPI). These ordering problems are NP-hard. We establish a scalable distributed genetic approach - MapReduce Parallel Genetic Algorithm (MRPGA) for DOPI, MRPGA_DOPI and draw comparisons with greedy algorithms. The proposed methods are estimated and experiments show the efficiency of MRPGA_DOPI...|$|E
5000|$|Pre-processingBefore a {{computer}} vision method {{can be applied}} to image <b>data</b> in <b>order</b> to extract some specific piece of information, it is usually necessary to process the <b>data</b> in <b>order</b> to assure that it satisfies certain assumptions implied by the method. Examples are ...|$|R
5000|$|Claim: Let [...] be a {{sequence}} of <b>data</b> <b>ordered</b> by <. The odd-even sort algorithm correctly sorts this data in [...] passes. (A pass here is defined to be a full sequence of odd-even, or even-odd comparisons. The passes occur in order pass 1: odd-even, pass 2: even-odd, etc.) ...|$|R
30|$|Sort {{the flow}} <b>data</b> in <b>order</b> of {{decreasing}} flow.|$|R
40|$|This paper sheds {{new light}} on the {{well-known}} phenomenon of dwindling wage elasticities for married women in the US over the recent decades. Results of a novel model experiment approach via sample <b>data</b> <b>ordering</b> unveil considerable heterogeneity across different wage groups. Yet surprisingly constant wage elasticity estimates are revealed within certain wage groups over time as well as across two widely used US data sources, the Current Population Survey (CPS) and the Panel Study of Income Dynamics (PSID). These findings refute the assumed presence of a single-valued aggregate wage elasticity for working wives. Although women’s responsiveness to wages remains largely unchanged over time, we find that the composition of working women into different wage groups has changed considerably, resulting in decreasing wage elasticity estimates at the aggregate level. All these findings were methodologically impossible to acquire had we not dismantled and discarded the stereotyped endogeneity-backed instrumental variable route, which has hitherto blocked the way towards sample <b>data</b> <b>ordering...</b>|$|E
40|$|Representation {{of large}} data sets became a key {{question}} of many scientific disciplines in the last decade. Several approaches for network visualization, <b>data</b> <b>ordering</b> and coarse-graining accomplished this goal. However, there was no underlying theoretical framework linking these problems. Here we show an elegant, information theoretic data representation approach as a unified solution of network visualization, <b>data</b> <b>ordering</b> and coarse-graining. The optimal representation is the hardest to distinguish from the original data matrix, measured by the relative entropy. The representation of network nodes as probability distributions provides an efficient visualization method and, in one dimension, an ordering of network nodes and edges. Coarse-grained representations of the input network enable both efficient data compression and hierarchical visualization to achieve high quality representations of larger data sets. Our unified data representation theory will help the analysis of extensive data sets, by revealing the large-scale structure of complex networks in a comprehensible form. Comment: 13 pages, 5 figure...|$|E
40|$|The recent SNIA OSD TWG {{face-to-face}} meeting {{agreed to}} add a scatter/gather capability to OSD- 2 Read and Write commands. However, the attributes-based method for describing the scatter/gather list (see T 10 / 08 - 091 r 1) was found to present <b>data</b> <b>ordering</b> problems in the Data-Out Buffer. A new CDB Continuation method was agreed upon to provide space for the scatter/gather list. The new metho...|$|E
30|$|Next-Frequent: Recommend the K most {{frequent}} trainings that have appeared immediately after c_m {{in the training}} data. That is, find all bigrams of the form 〈 c_m, x 〉 in the training <b>data,</b> <b>order</b> {{them in terms of}} their frequencies and select the second elements from the top K bigrams.|$|R
40|$|I {{argue that}} the current {{financial}} crisis highlights the crucial need of a change of mindset in economics and financial engineering, that should move away from dogmatic axioms and focus more on <b>data,</b> <b>orders</b> of magnitudes, and plausible, albeit non rigorous, arguments. Comment: An edited version of this essay appeared in Natur...|$|R
50|$|Compress {{the visible}} set <b>data</b> in <b>order</b> to {{minimize}} storage overhead.|$|R
40|$|In {{this paper}} {{we present a}} Genetic Algorithm (GA) for the <b>Data</b> <b>Ordering</b> Problem (DOP) where Don't Cares (DCs) are {{assigned}} during optimization. The DOP has large application {{in the area of}} low power design and circuit testing. We implemented a GA to solve this problem and discuss several applications. We carried out a large set of experiments. A comparison of our results to previously published demonstrates the efficiency of our approach. I. Introduction As a general method for solving optimization problems Genetic Algorithms (GAs) [11] are getting more and more popular. Recently, GAs have successfully been applied to several problems in VLSI CAD [6]. In this paper we present a GA that is applied to the <b>Data</b> <b>Ordering</b> Problem (DOP). We discuss the close relation between the DOP and the Travelling Salesman Problem (TSP), that has intensively been studied over the past few years. We describe the details of our GA and combine the GA with the greedy algorithm from [13], i. e. we use hyb [...] ...|$|E
40|$|Writing {{this thesis}} aims {{to build an}} {{management}} information system that can assist in data processing starting from the leasing data, karoseri data, supplier data, customer data, spareparts data, purchase spareparts data, spareparts sales data, the vehicle unit <b>data,</b> <b>ordering</b> vehicle data, and vehicle unit sales data using Iterative methodology in which {{the first stage of}} the authors conducted a survey of the old system, the system analyzes to be made as to what, the third design the new system, the fourth to the manufacture of the new system, implementation of the fifth, sixth and maintenance of the system. Management Information System created by using Visual Basic 2008 Net programming language and stored in a database SQL Server 2005. With the existence of this systemis expected to address the problems that make it easier to manage the leasing data, karoseri data, supplier data, customer data, spareparts data, purchase spareparts data, spareparts sales data, the vehicle unit <b>data,</b> <b>ordering</b> vehicle data, and vehicle unit sales data, so that a report of all activities of the company's management produced good and right in accordance with the data that has been received...|$|E
40|$|With {{the rapid}} {{development}} of computer {{science and the}} expanding use of computers in all facets of American life, there has been made available {{a wide range of}} instructional and informational films on automation, data processing, and computer science. Here is the first annotated bibliography of these and related films, gathered from industrial, institutional, and other sources. This bibliography annotates 244 films, alphabetically arranged by title, with a detailed subject index. Information is also provided concerning the intended audience, rental-purchase <b>data,</b> <b>ordering</b> procedures, and such...|$|E
40|$|International audienceThe {{contingency}} table of X and Y, {{is used to}} construct rules under the form : X=a ==> Y belongs to B(a). According {{to the nature of}} the <b>data</b> (<b>ordered</b> or not ordered), the simplification of these rules is performed, via the clustering of certain modalities. Hierarchical and dynamic programming approaches are used...|$|R
5000|$|Processing: {{performing}} {{operations on}} <b>data</b> in <b>order</b> {{to achieve a}} desired objective.|$|R
5000|$|... tell {{members to}} {{synchronize}} <b>data</b> in <b>order</b> {{to balance the}} data load ...|$|R
