3|23|Public
6000|$|... "Blake {{is as much}} to {{be trusted}} as I am. No, I am forced to a {{practical}} acceptance {{of the theory of}} the fluidic arm, and yet this is a most astounding admission. We must suppose that the psychic was able to read our minds and write down our mingled and confused musical conceptions by means of a supernumerary hand. It happens that I have since seen these etheric hands in action, which makes it easier for me to conceive of such a process. I have seen them dart forth from another medium precisely as described by Scarpa. I have seen them lift a glass of water, and I have had them touch my knees beneath a table while slate-writing was going on--so that, given the power to read my mind, there is nothing impossible (having regard to Bottazzi's <b>definite</b> <b>experiments)</b> in the idea of the etheric hand's setting down the music and reproducing the signature of 'E. A.' In fact, at a recent sitting in a private house with a young male psychic, we had this precise feat performed. Said the psychic to our host, Dr. Towne, 'Think hard of a signature that is very familiar to you,' and Dr. Towne fixed his mind upon the signature of his brother, and immediately, while the young man's material hands were controlled, his etheric hand seized a pencil {{in the middle of the}} table and reproduced the signature." ...|$|E
40|$|Abstract. Based on {{the feature}} map principle, Sparse Kernel Ridge Regression (SKRR) model is proposed. SKRR obtains the sparseness by {{backward}} deletion feature selection procedure that recursively removes the feature {{with the smallest}} leave-one-out score until the stop criterion is satisfied. Besides good generalization performance, the most compelling property of SKRR is rather sparse, and moreover, the kernel function needs not to be positive <b>definite.</b> <b>Experiments</b> on synthetic and benchmark data sets validate the feasibility and validity of SKRR. ...|$|E
40|$|International audienceKernels are {{functions}} {{designed in}} order to capture resemblance between data and they are used {{in a wide range}} of machine learning techniques, including support vector machines (SVMs). In their standard version, commonly used kernels such as the Gaussian one show reasonably good performance in many classification and recognition tasks in computer vision, bioinformatics, and text processing. In the particular task of object recognition, the main deficiency of standard kernels such as the convolution one resides in the lack in capturing the right geometric structure of objects while also being invariant. We focus in this paper on object recognition using a new type of kernel referred to as "context dependent. " Objects, seen as constellations of interest points, are matched by minimizing an energy function mixing 1) a fidelity term which measures the quality of feature matching, 2) a neighborhood criterion which captures the object geometry, and 3) a regularization term. We will show that the fixed point of this energy is a context-dependent kernel which is also positive <b>definite.</b> <b>Experiments</b> conducted on object recognition show that when plugging our kernel into SVMs, we clearly outperform SVMs with context-free kernels...|$|E
40|$|This {{paper is}} {{concerned}} with the solution of block tridiagonal linear systems by the preconditioned conjugate gradient (PCG) method. If we consider a block AGE splitting of the coefficient matrix, it is possible to derive an additive polynomial preconditioner and to give conditions for such preconditioner to be symmetric positive <b>definite.</b> Numerical <b>experiments</b> on diffusion problem are carried out on CRAY Y-MP in order {{to evaluate the effectiveness of}} the parallel polynomial preconditioner...|$|R
40|$|In {{this paper}} a semantic-driven {{algorithm}} for Spanish definite descriptions resolution is presented. The resolution procedure {{consists of two}} main steps: a) the generation of a semantic network using the Spanish WordNet ontology in order to distinguish between anaphoric and non-anaphoric definite description, and b) {{the application of a}} set of constraints and preferences to candidates in order to obtain the correct antecedent of an anaphoric <b>definite</b> description. <b>Experiments</b> show a precision of 88. 8 % and a recall of 83. 9 % for definite description identification (anaphoric or not) and resolution...|$|R
40|$|AbstractIn {{this paper}} a new ILU {{factorization}} preconditioner for solving large sparse linear systems by iterative methods is presented. The factorization {{which is based}} on A-biorthogonalization process is well defined for a general positive <b>definite</b> matrix. Numerical <b>experiments</b> illustrating the performance of the preconditioner are presented. A comparison with the well known preconditioner RIFp of Benzi and Tůma is also included...|$|R
40|$|The {{macrophage}} electrophoretic mobility test {{described by}} Caspary and Field (1971) and modified by Pritchard et al. (1973) {{was investigated in}} various models of cell-mediated immune conditions in the guinea-pig and in cancer in man. No positive results were obtained in 92 guinea-pig experiments. Only 17 of 154 experiments on 74 patients gave <b>definite</b> positives in <b>experiments</b> with human cancer and a few positive results were obtained with normal healthy subjects...|$|R
40|$|The {{generalized}} Stokes problem, which arises {{frequently in}} the simulation of time-dependent Navier–Stokes equations for incompressible fluid flow, gives rise to symmetric linear systems of equations. These systems are indefinite due {{to a set of}} linear constraints on the velocity, causing difficulty for most preconditioners and iterative methods. This paper presents a novel method to obtain a preconditioned linear system from the original one which is then solved by an iterative method. This new method generates a basis for the velocity space and solves a reduced system which is symmetric and positive <b>definite.</b> Numerical <b>experiments</b> indicating superior convergence compared to existing methods are presented. A natural extension of this method to elliptic problems is also proposed, along with theoretical bounds on the rate of convergence, and results of experiments demonstrating robust and effective preconditioning...|$|R
40|$|Data mining {{algorithms}} {{are facing}} the challenge {{to deal with an}} increasing number of complex objects. For graph data, a whole toolbox of data mining algorithms becomes available by defining a kernel function on instances of graphs. Graph kernels based on walks, subtrees and cycles in graphs have been proposed so far. As a general problem, these kernels are either computationally expensive or limited in their expressiveness. We try to overcome this problem by defining expressive graph kernels which are based on paths. As the computation of all paths and longest paths in a graph is NP-hard, we propose graph kernels based on shortest paths. These kernels are computable in polynomial time, retain expressivity and are still positive <b>definite.</b> In <b>experiments</b> on classification of graph models of proteins, our shortest-path kernels show significantly higher classification accuracy than walk-based kernels. ...|$|R
40|$|Background and {{objective}} Immunocompromised patients with malignant tumor always lack of strong anti-tumor immune response, because the antigenicity of tumor cells is weak, and antigen-presenting cell function is low, so {{that can not}} be effectively presenting tumor antigens to the lymphocytes. Therefore, how to effectively induce anti-tumor immune response is the key issue. Through the study on establishing a method to culture dendritic cells (DC) in vitro and to observe the anti-lung cancer immunological effect induced by DC, we provided <b>definite</b> <b>experiment</b> basis for the clinic application of vaccine based on DC. Methods Through the experiment we get the soluble antigen polypeptide from lung cancer cells GLC- 82 by 3 mol/L potassium chloride. DCs are cultured and obtained from peripheral blood mononuclear cell by GM-CSF, IL- 4 and TNF-a. DCs are identified by flow cytometer (FCM) and immunostaining. DCs modified by lung cancer tumor soluble antigen (TSA) and staphylococcal enterotox in A (SEA), DCs modified by TSA or DCs modified by SEA or DCs modified by nothing were cultivated together with T lymphocyte, and the obtained cells are named TSA-SEA-DCL or TSA-DCL or SEA-DCL or DCL as effector cells. The anti-tumor activity of every effector cells against target cells was assayed with MTT method. Shape of DCs and effector cells, and the process of killing target cells were observed in microscope. Results Induced DCs expressed more CD 1 a, CD 80 and HLA-DR, which had typical cell traits such as tree branch. The killing ratio of the TSA-SEA-DCL in vitro to GLC- 82 is larger than TSA-DCL, SEA-DCL and DCL, also larger than to K 562. When the effector cells cultivate with target cells, we can observe the CTL approach and gather to the cancer cell, induce it necrosis and apoptosis. Conclusion Ripe DCs that have typical characteristic and phenotype could be induced successfully. High potency and relatively specific antilung caner effect can be prepared in virtue of DC Bacterin Induced by lung caner TSA and SEA...|$|R
40|$|Abstract. Efficient {{parallel}} iterative {{algorithm is}} investigated for solving block-tridiagonal linear systems on distributed-memory multi-computers. Based on Galerkin theory, the communication only need twice between the adjacent processors per iteration step. Furthermore, the condition for convergence is given when the coefficient matrix A is a symmetric positive <b>definite</b> matrix. Numerical <b>experiments</b> implemented on the cluster verify that our algorithm parallel acceleration rates and efficiency {{are higher than}} the multisplitting one, and has the advantages over the multisplitting method of high efficiency and low memory space. 1...|$|R
30|$|Amsallem et al. [31]–[33], build a {{geometric}} interpolation algorithm of ROM-PODs {{at different}} parametric values, {{in the case}} of parameterized linear structural dynamics problems. The idea is to interpolate various reduced order, symmetric and positive definite matrices of the complete problem, corresponding each one to a set of characteristic parameters. This interpolation is done in the tangent space to the manifold of symmetric positive <b>definite</b> matrices. Numerical <b>experiments</b> show that the obtained reduced order model, is efficient to represent dynamics asssociated with other parametric sets than the reference ones.|$|R
40|$|We {{present a}} new {{theoretical}} framework for describing an impurity in a trapped Bose system in one spatial dimension. The theory handles any external confinement, arbitrary mass ratios, and a weak interaction may be included between the Bose particles. To demonstrate our technique, we calculate the ground state energy and properties {{of a sample}} system with eight bosons and find an excellent agreement with numerically exact results. Our theory can thus provide <b>definite</b> predictions for <b>experiments</b> in cold atomic gases. Comment: 9 pages, 5 figures, published version. Supplemental material included as appendi...|$|R
40|$|The results {{presented}} in this paper were obtained in the field experminent carried out in the years 1999 - 2001 on a soil a very good rye complex. In this <b>experiment</b> <b>definited</b> number of weeds and their floristic species composition. The application of mixtures herbicides decreased of number of weeds as compared with the number obtained for mechanical control of 397 - 500 % {{at the beginning of the}} vegetation and of 180 - 220 % prior to tubers harvest. The herbicides reduced the composition of weed species, moreover...|$|R
40|$|A basic {{disadvantage}} to the symmetric rank one (SR 1) update is {{that the}} SR 1 update may not preserve positive definiteness when starting with a positive definite approximation. A simple remedy to this problem is to restart the update with the initial approximation mostly the identity matrix whenever this difficulty arises. However, numerical experience shows that restart with the identity matrix {{is not a good}} choice. Instead of using the identity matrix we used a positive multiple of the identity matrix. They Used positive scaling factor is the optimal solution of the measure defined by the problem - maximize the determinant subject to a bound of 1 on the largest eigenn value. This measure is motivated by considering the volume of the symmetric diference of the two ellipsoids, which arise from the current and updated quadratic models in quasi-Newton methods. A replacement in the form of positive multiple of identity matrix is provided for the SRI when it is not positive <b>definite.</b> Our <b>experiments</b> indicate that with such simple scale, the efectiveness of the SRI method is increased dramatically...|$|R
40|$|What role does mutual {{knowledge}} {{play in the}} comprehension process? We compare two {{answers to}} this question for the comprehension of definite reference. The Restricted Search hypothesis assumes that addressees rely {{on the principle of}} optimal design and understand definite reference by restricting the search for referents to entities in common ground. The Unrestricted Search hypothesis assumes that the search for referents is not restricted to entities in common ground. Only the Unrestricted Search hypothesis predicts that entities that are not in common ground would interfere with comprehension of <b>definite</b> reference. <b>Experiment</b> 1 reveals such interference in increased errors and verification latencies during the resolution of pronouns. Experiment 2 demonstrates the interference by tracking the addressee’s eye movements during the comprehension of demonstrative reference. We discuss alternative models of comprehension that could account for the results, and we describe the role that common ground plays in each model. We propose a Perspective Adjustment model that assumes a search for referents that is independent of common ground, coupled with a monitoring process that detects violations of common ground and adjusts the interpretation. This model assumes a role for common ground only when a correction is needed. We challenge both the assumption that addressees follow th...|$|R
40|$|Abstract. Visual servoing {{typically}} involves separate feature {{tracking and}} control processes. Feature tracking remains an art, and is generally treated as {{independent of the}} underlying controller. Kernel-based visual servoing (KBVS) is a categorically different approach that eliminates explicit feature tracking. This chapter presents an experimental assessment of the convergence properties (domain of attraction and steady-state error) of the proposed approach. Using smooth weighting functions (the kernels) and Lyapunov theory, we analyze the controllers as they act on im-ages acquired in controlled environments. We ascertain the domain of attraction by finding the largest positive invariant set of the Lyapunov function, inside which its time derivative is negative <b>definite.</b> Our <b>experiments</b> show that KBVS attains a maximum pixel error of one pixel and is commonly {{on the order of}} one tenth of a pixel. 2. 1 Featureless Visual Servoing Typically, visual servoing involves tracking image features and controlling a robot based on the motions of these image features. Usually this involves tuning the fea-ture tracking algorithm and controller independently, with no clear notion of how to co-optimize tracking and control. KBVS is distinguished from traditional visual servoing techniques in two respects, namely the lack of explicit feature tracking at each image frame and the inherent combination of tracking and control. Thes...|$|R
40|$|The {{problem of}} distinguishability of {{identical}} particles is considered from both experimental and theoretical points ofview. It {{is argued that}} distinguishability has to be defined relative to a <b>definite</b> set of <b>experiments</b> and that the criterion by which the particies are distinguished should be specified. Faiiure to do so may cause mismatching between theory and experiment. On the theoretical level a distinction is made between indexed- and unindexed-particle theories, indices being unobserved intrinsic properties of the particles. A fieid theory of indexed particies is constructed and shown to be equivalent to the second quantization formalism, which is an unindexed-particle theory. It was observed by Mirman (1973) that the concepts of "identical particles" and "distinguishability " or "indistinguishability " have been poorly formulated in quantum theory. In nrost textbooks these notions are treated in a rather vague and intuitive way, without a firm relation to experiment. More or les...|$|R
40|$|We {{present results}} from a {{precision}} simulation of the electron cloud (EC) in the Fermilab Main Injector using the code VORPAL. This is a fully 3 d and self consistent treatment of the EC. Both distributions of electrons in 6 D phase-space and E. M. field maps have been generated. This has been done for various configurations of the magnetic fields found around the machine have been studied. Plasma waves associated to the fluctuation density of the cloud have been analyzed. Our results are compared with those obtained with the POSINST code. The response of a Retarding Field Analyzer (RFA) to the EC has been simulated, {{as well as the}} more challenging microwave absorption <b>experiment.</b> <b>Definite</b> predictions of their exact response are difficult to obtain,mostly because of the uncertainties in the secondary emission yield and, {{in the case of the}} RFA, because of the sensitivity of the electron collection efficiency to unknown stray magnetic fields. Nonetheless, our simulations do provide guidance to the experimental program...|$|R
40|$|It {{is known}} {{from the work of}} Cowan (1934) that unmyelinated nerves lose {{potassium}} in anoxia. Similar experiments on vertebrate mydinated nerves are not available except for a few preliminary experiments of Fenn (1934) which showed no <b>definite</b> change. The <b>experiments</b> to be reported here were made on frog nerves largely at the instigation of Dr. Lorente de N 6 (1946), who was studying the relation between potassium loss, the membrane potential, and the capacity for recovery, and who sent us some of his experimental nerves for analysis. The results show definitely that frog nerves do lose potassium in anoxia. Methods The sciatic nerves of two frogs were dissected, with care to avoid stretching, and were put into Ringer's solution. The right nerve of one frog and the left nerve of the other were used for anoxia while the other two nerves served as controls. The nerves were denned of vessds and other non-nervous tissue and were weighed on a torsion balance after absorbing the excess solution with filter paper. Each pair of nerves wa...|$|R
40|$|A short {{survey is}} given {{of the known}} facts {{regarding}} {{the relation between the}} constitution and the antimalarial activity of the chief cinchona alkaloids, and it is concluded that further information on this matter can be obtained in two ways: (1). By investigating the degradation products and some of the simpler derivatives of these alkaloids. (2). By preparing some synthetic substances which contain certain characteristic features. Under heading (2), a large number of compounds of the general formula: [equation] have been synthesised. These all bear, as the formula indicates, marked pictorial resemblance to the essential cinchona structure. The antimalarial activity of the new substances has been determined, and the conclusion is drawn that a second basic centre must be present for a molecule of the above type to possess any marked antimalarial activity. Under heading (2), a number of alkaloid methochlorides have been prepared by a new process, and considerable {{attention has been paid to}} the attempted decarboxylation of quitenine, since the decarboxy-lated product should exhibit <b>definite</b> antimalarial activity. <b>Experiments</b> have also been performed on the preparation of quitenine amide, and of its benzoyl derivative. <p...|$|R
40|$|It {{has been}} known for some time that an analogy exists between the flow of a liquid with a free surface and the flow of a {{compressible}} gas. A less accurate analogy has been shown to obtain between hydraulic jumps and compression shocks. The interaction of shocks can occur in two forms; the regular or two-shock configuration and the Mach or three-shock configuration. The latter configuration is not yet completely understood, either in the case of hydraulic jumps in a free-surface liquid {{or in the case of}} shocks in a compressible gas. This experimental study was primarily concerned with the Mach interactions of hydraulic jumps. The conclusions of this study are: (a) there is a <b>definite</b> disagreement between <b>experiment</b> and existing theory; (b) a depth discontinuity, or wave, rather than a velocity discontinuity separates the region behind the Mach wave from the region behind the reflected wave; (c) there is evidence that, for interactions of weak hydraulic jumps, there is a deviation from constant depth between waves; (d) the Mach wave is convex for the interaction of the stronger hydraulic jumps, but is concave for the interaction of weak hydraulic jumps; (e) measurements should not be made so as to allow for curvature of the Mach without considering the curvature of the incident and reflected waves in the neighborhood of the triple point...|$|R
40|$|Eleven {{years have}} passed since Rous and McMaster (15) {{published}} their paper on the concentrating activity of the gall bladder. This contribution and subsequent ones by them and their associates renewed the interest of investigators in this organ. Two schools have developed, each with a different fundamental concept of gall bladder function. The one, following what would appear to be the more logical concept, maintains that concentrated bile is emptied at intervals into the duodenum. The other, largely from teleological reasoning, believes that the cystic duct is a one-way tube, permitting hepatic bile to flow into the gall bladder, but preventing it from flowing out. Those who accept the latter concept must necessarily adhere to the theory that every constituent of the bile is absorbed through the gall bladder wall. If the latter group is correct there must be an optimum concentration for "different constituents of the bile at which level they are absorbed at a <b>definite</b> rate. The <b>experiments</b> of Rous and McMaster indicated that bile pigment was not absorbed through the gall bladder wall. If this is true, and if the gall bladder has no other way of evacuating itself except by absorption, it would not take long for the lumen to be filled with an inspissated mass of pigment. The experiments on the pigment changes of hepatic bile subjected to gall bladder activity were open to certain errors which Rous and McMaster duly considered. The experiments were not absolutely quantitative in that the amountof hepatic bile entering the gall bladder could not be absolutely measured...|$|R
6000|$|... “When so {{complete}} a change {{takes place in}} public opinion, it may be [...] ascribed to one or other of two causes. It {{may be the result}} of a [...] controversy which has conclusively settled the question, establishing [...] to the satisfaction of all parties a clear preponderance of argument [...] or fact in favor of one opinion, and making that opinion a truism [...] which is accepted by all enlightened men, even though they have not [...] themselves examined the evidence on which it rests. Thus, if any one [...] in a company of ordinarily educated persons were to deny the motion [...] of the earth, or the circulation of the blood, his statement would be [...] received with derision, though it is probable that some of his [...] audience would be unable to demonstrate the first truth, and that [...] very few of them could give sufficient reasons for the second. They [...] may not themselves be able to defend their position; but they are [...] aware that, at certain known periods of history, controversies on [...] those subjects took place, and that known writers then brought [...] forward some <b>definite</b> arguments or <b>experiments,</b> which were ultimately [...] accepted by the whole learned world as rigid and conclusive [...] demonstrations. It is possible, also, for as {{complete a}} change to be [...] effected by what is called the spirit of the age. The general [...] intellectual tendencies pervading the literature of a century [...] profoundly modify the character of the public mind. They form a new [...] tone and habit of thought. They alter the measure of probability. [...] They create new attractions and new antipathies, and they eventually [...] cause as absolute a rejection of certain old opinions as could be [...] produced by the most cogent and definite arguments.” ...|$|R
40|$|Interference {{effects are}} the most {{spectacular}} manifestation of the wave nature of phenomena. This note proposes a systematic search for such effects in the brain. 1. The current discussion on possible new effects playing {{an important role in}} neural processes in the brain is provoking many speculative hypotheses. Among them the suggestion of nonalgorithmic processes taking place in the mind or the quantum nature of information processing is perhaps the most exciting [1]. In our opinion further theoretical development of these ideas requires <b>definite</b> feedback from <b>experiment.</b> In this note we propose a series of experiments testing the possibility of wave phenomena taking place and playing {{an important role in the}} brain. Inspiration for these proposals comes from analogous experiments in physics. 2. The fundamental experiment proving the wave nature of light was performed by Thomas Young in 1801 [2]. Although well known to physicists we describe it briefly because of its central role in further considerations. Put simply, the experimental setup consisted of a (nearly) pointlike light source and two slits between the source and screen (see Fig. 1). Covering one of the two slits (Fig. 1 a) the light travelled through the second slit and hit the screen producing a (slightly diffused) picture opposite the opened slit. Today we know that what we observe is the Huygens principle at work — the open slit works as the source of a spherical wave. Analogically, covering the second slit we observe the picture on the screen opposite the first slit (Fig. 1 b). With both slits opened a spectacular result is observed (Fig. 1 c). It is not the simple sum of both previous pictures, instead an interference pattern of dark and light bands appears. Moreover, at maximum brightness, the signal is not just twice as strong (as one would expect from summin...|$|R
40|$|This thesis {{examined}} the English referring expressions {{used by the}} Chinese children living in Britain and English children matched by English language ability to the Chinese children. Two adult groups (one Chinese and one English) were used as controls. Two experiments were conducted in a year time apart, involving 166 participants in total. In the experiments, participants described stories presented in pictures to listeners who could (El) or could not (E 2) see the pictures. The stories in El described two protagonists of different genders, those in E 2 described two of the same gender. Predictions concerned the use of appropriate referring expressions on first mention of novel entities and on second mention of familiar entities; whether a thematic subject strategy was used; whether Chinese children's choice of specific referring expressions (Bare Nouns, Demonstratives, and Zero Anaphors) was influenced by their first language; and which factors (Fist Language, English Language Ability, Cognitive Ability, and Age) were significant predictors of the children's use of English referring expressions. The main results were as follows: Both groups of children used definite references on second mention more frequently than they used indefinite references on first mention. There were hardly any transcripts showing use of a thematic subject strategy. Instead, participants used either an explicit strategy, in which full explicit noun phrases were used throughout or a strategy in which the subject slot is reserved for the current topic, which may change a the discourse proceeds. English parents predominantly used this second strategy. Regression analyses showed that cognitive ability was {{the best predictor of}} first mention indefinites in both experiments and of second mention definites in El, where definite articles were appropriate for identifying the referent. English language ability was the best predictor of second mention <b>definites</b> in both <b>experiments.</b> These results were discussed in relation to previous studies and the notion of mental models. It was concluded that Chinese children did not use an inter-language that contained information about specific words or phrases. The major effect of first language may be discourse level strategies, but this was only appeared with the parents...|$|R

