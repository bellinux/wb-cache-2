0|29|Public
5000|$|... <b>deinterlacing</b> (used <b>to</b> convert {{interlaced}} {{video to}} progressive video) ...|$|R
50|$|DirectX Video Acceleration (DXVA) is a Microsoft API {{specification}} for the Microsoft Windows and Xbox 360 platforms {{that allows}} video decoding to be hardware accelerated. The pipeline allows certain CPU-intensive operations such as iDCT, motion compensation and <b>deinterlacing</b> <b>to</b> be offloaded to the GPU. DXVA 2.0 allows more operations, including video capturing and processing operations, to be hardware accelerated as well.|$|R
50|$|A Phase Alternating Line (PAL)-based {{television}} set display, for example, scans 50 fields every second (25 odd and 25 even). The {{two sets of}} 25 fields work {{together to create a}} full frame every 1/25 of a second (or 25 frames per second), but with interlacing create a new half frame every 1/50 of a second (or 50 fields per second). To display interlaced video on progressive scan displays, playback applies <b>deinterlacing</b> <b>to</b> the video signal (which adds input lag).|$|R
50|$|As of 2012, most {{consumer}} televisions {{being sold}} provide 1080p inputs, mainly via HDMI, and support full high-definition resolutions. 1080p resolution {{is available in}} all types of television, including plasma, LCD, DLP front and rear projection and LCD projection. For displaying film-based 1080i60 signals, a scheme called 3:2 pulldown reversal (reverse telecine) is beginning to appear in some newer 1080p displays, which can produce a true 1080p quality image from film-based 1080i60 programs. Similarly, 25fps content broadcast at 1080i50 may be <b>deinterlaced</b> <b>to</b> 1080p content with no loss of quality or resolution.|$|R
40|$|When {{interlaced}} scan (IS) {{is used for}} television transmission, the received video must be <b>deinterlaced</b> <b>to</b> be displayed on progressive scan (PS) displays. To achieve good performance, the deinterlacing operation is typically computationally expensive. We propose a receiver compatible approach which performs a deinterlacing operation inexpensively, with good performance. At the transmitter, the system analyzes the video and transmits an additional low bit-rate stream. Existing receivers ignore this information. New receivers utilize this stream and perform a deinterlacing operation inexpensively with good performance. Results indicate that this approach can improve the digital television standard in a receiver compatible manner...|$|R
5000|$|Progressive scan video must be {{properly}} <b>deinterlaced</b> <b>to</b> achieve full vertical resolution {{and to avoid}} interlace artifacts. 25P and 30P video must be deinterlaced with [...] "weave" [...] or [...] "no deinterlacing" [...] algorithm, which means joining two fields of each frame together into one progressive frame. This operation {{can be done in}} most editing tools simply by changing project properties from interlaced to progressive. 24P video must go through film-mode deinterlacing also known as inverse telecine, which throws out judder frames and restores original 24-frame/s progressive video. Many editing tools cannot perform film-mode deinterlacing, requiring usage of a separate converter.|$|R
40|$|In this paper, an {{extended}} intellgient edge-based line average-EIELA is proposed. The EIELA {{could be used}} in intra-field <b>deinterlacing</b> <b>to</b> remove the jagged edges and the blurring effect of the bilinear interpolation or the traditional algorithms. The EIELA could change its performance dynamically according to the user’s requirement. The proposed method can achieve the highest image quality of the traditional ELA if all the taps in the module are enabled, and it also possesses the ability to reduce the taps usage and instruction counts through the turn-off of some calculating submodules. The results and VLSI implementation show the proposed method achieve high image quality and low hardware complexity. 1...|$|R
5000|$|A {{line doubler}} is a device used <b>to</b> <b>deinterlace</b> video signals prior to display.|$|R
5000|$|PAL and SECAM run at 25 {{interlaced}} video [...] "frames" [...] per second, {{which can}} be slowed down or frame-dropped, then <b>deinterlaced,</b> <b>to</b> correlate [...] "frame" [...] for frame with film running at 24 actual frames per second. PAL and SECAM are less complex and demanding than NTSC for film-out. PAL and SECAM conversions do agitate, though, with the unpleasant choice between slowing down video (and audio pitch, noticeably) by four percent, from 25 to 24 frames per second, {{in order to maintain}} a 1:1 frame match, slightly changing the rhythm and feel of the program; or maintaining original speed by periodically dropping frames, thereby creating jerkiness and possible loss of vital detail in fast-moving action or precise edits.|$|R
50|$|There {{are various}} methods <b>to</b> <b>deinterlace</b> video, each {{producing}} different problems or artifacts of its own. Some methods are much cleaner in artifacts than other methods.|$|R
50|$|Before {{interlaced}} {{video is}} {{displayed on a}} progressive-scan device it must be converted to progressive using the process known as deinterlacing. Progressive-scan television sets employ built-in <b>deinterlacing</b> circuits <b>to</b> cope with interlaced broadcast signal, but computer video players rarely have this capability. As such, interlaced video may exhibit ghosting or combing artifacts when watched on a computer.|$|R
40|$|The paper {{discusses}} {{a recent}} test of using High Definition (HD) video camera to obtain aerial mapping images for coastal zone study. Real-Time GPS {{was used to}} capture the ground control. It was revealed that the vibration from the aircraft has an adverse effect on the video footage. Consequently, each video frame was <b>deinterlaced</b> <b>to</b> obtain the odd and even fields as sub-frames. Deinterlacing removes the effect of aircraft vibration; however the process reduces the video frame format size to a sub-frame size which is a half of the original format size. The video camera was calibrated at full format size so the image must be rebuilt to full format size {{in order to achieve}} the required spatial accuracy. Tests show that the stereo-digitized 3 D coordinate of beach features is similar to still-frame digital images at the same flying height. Because videoing does not require precise exposure timing {{as in the case of}} still-frame photography, HD video has a vey important advantage over conventional still-frame aerial photography for aerial mapping. Key words and phrases: HD video, aerial images, coastal zone ecological mapping...|$|R
5000|$|For best results, footage {{should be}} <b>deinterlaced</b> and frame-doubled <b>to</b> 60p. This {{preserves}} {{all of the}} footage's temporal information, which is key in determining what the [...] "missing" [...] points in time should look like when converting to 24 frame/s.|$|R
50|$|Interlacing was {{ubiquitous}} in displays until the 1970s, when {{the needs of}} computer monitors resulted in the reintroduction of progressive scan. Interlace is still used for most standard definition TVs, and the 1080i HDTV broadcast standard, but not for LCD, micromirror (DLP), or most plasma displays; these displays do not use a raster scan to create an image, and so cannot benefit from interlacing: in practice, {{they have to be}} driven with a progressive scan signal. The <b>deinterlacing</b> circuitry <b>to</b> get progressive scan from a normal interlaced broadcast television signal can add to the cost of a television set using such displays. Currently, progressive displays dominate the HDTV market.|$|R
50|$|For {{interlaced}} video, additional processing {{is frequently}} applied <b>to</b> <b>deinterlace</b> {{the image and}} make it seem to be clearer or more detailed than it actually is. This is done by storing several interlaced frames and then applying algorithms to determine areas of motion and stillness, and to either merge interlaced frames for smoothing or extrapolate where pixels are in motion, the resulting calculated frame buffer is then written to the display device.|$|R
50|$|Most modern {{computer}} monitors {{do not support}} interlaced video, besides some legacy text-only display modes. Playing back interlaced video on a computer display requires some form of deinterlacing in the software player, which often uses very simple methods <b>to</b> <b>deinterlace.</b> This means that interlaced video often has visible artifacts on computer systems. Computer systems {{may be used to}} edit interlaced video, but the disparity between computer video display systems and interlaced television signal formats means that the video content being edited cannot be viewed properly without separate video display hardware.|$|R
5000|$|... 1080i is {{directly}} compatible with some CRT HDTVs {{on which it}} can be displayed natively in interlaced form, but for display on progressive-scan—e.g., most new LCD and plasma TVs, it must be deinterlaced. Depending on the television's video processing capabilities, the resulting video quality may vary, but may not necessarily suffer. For example, film material at 25fps may be <b>deinterlaced</b> from 1080i50 <b>to</b> restore a full 1080p resolution at the original frame rate without any loss. Preferably video material with 50 or 60 motion phases/second is to be converted to 50p or 60p before display.|$|R
40|$|Abstract. With {{the advent}} of {{progressive}} format display and broadcast technologies, video deinterlacing has become an important video processing technique. Numerous approaches exist in literature <b>to</b> accomplish <b>deinterlacing.</b> While most earlier methods were simple linear filtering-based approaches, the emergence of faster computing technologies and even dedicated video processing hardware in display units has allowed higher quality, but also more computation-ally intense, <b>deinterlacing</b> algorithms <b>to</b> become practical. Most modern approaches analyze motion and content in video <b>to</b> select different <b>deinterlacing</b> methods for various spatiotemporal regions. In this paper, we introduce a family of deinterlacers that employs spectral residue to choose between and weight control grid interpolation based spatial and temporal deinterlacing methods. The proposed approaches perform better than the prior state-of-the-art based on peak signal-to-noise ratio (PSNR), other visual quality metrics, and simple perception-based subjective evaluations conducted by human viewers. We further study the advantages of using soft and hard decision thresholds on th visual performance...|$|R
30|$|The {{process of}} deinterlacing {{involves}} converting {{a stream of}} interlaced frames within a video sequence to progressive frames [1], to ensure their playback on nowadays progressive devices.Such video processing has been widely studied in the recent literature [2, 3, 4, 5, 6, 7, 8], as the interlaced video format is still preferred for the acquisition systems when high-fidelity motion accuracy is needed. Deinterlacing requires the display device to buffer one or more fields and recombine them to a full progressive frame. There are various methods <b>to</b> <b>deinterlace</b> a video and each method produces its own artifacts, due to the temporal lack of information and {{the dynamics of the}} video sequence.|$|R
40|$|This paper {{presents}} a maximum a posteriori (MAP) based intra-field deinterlacing algorithm. In the proposed algorithm, we propose a hybrid approach composed by point-wise and patch-wise measurements. The {{estimation of the}} missing pixel is formulated as an MAP and minimizing the energy function. By utilizing Bayes theory and some prior knowledge, the missing pixel is estimated with a statistical-based approach and we model the residual of the images as Gaussian and Laplacian distribution. Under the MAP framework, the desired <b>deinterlaced</b> image corresponds <b>to</b> the optimal reconstruction given the interlaced low resolution image. Compared with existing deinterlacing algorithms, the proposed algorithm improves peak signal-to-noise-ratio and the structural similarity while maintaining high efficiency. Incheon National University Research Gran...|$|R
40|$|A coefficient-parameter {{embedding}} method is presented for invert-ible deinterlacing with variable coefficients {{in the application}} to Motion-JPEG 2000 (MJP 2). Invertible deinterlacing, which the au-thors have developed before, {{can be used as}} a preprocess of frame-based video codec, such as MJP 2, for interlaced videos. When the conventional field-interleaving is used instead, comb-tooth artifacts appear around edges of moving objects. On the other hand, the invertible deinterlacing technique allows us to suppress the comb-tooth artifacts and also to recover an original picture on demand. As previous works, the authors have developed a variable coefficient scheme with a motion detector, which realizes adaptability to local characteristics of given pictures. When applying this <b>deinterlacing</b> technique <b>to</b> an image codec, however, it is required to send coef-ficient parameters to receivers for original picture recovery. This work proposes a parameter-embedding technique and constructs a standard stream which consists both of picture data and parame-ters. The parameters are embedded into the first LH subband of the wavelet domain through the ROI (region of interest) function of JPEG 2000, while maintaining the capability of comb-tooth sup-pression and quality recovery. 1...|$|R
40|$|As {{the cost}} of video {{technology}} has fallen, surveillance cameras have {{become an integral part}} of a vast number of security systems. However, even with the introduction of progressive video displays, the majority of these systems still use interlaced scanning so that they may be connected to standard television monitors. When law enforcement officials analyze surveillance video, they are often interested in carefully examining a few frames of interest. However, it is impossible to perform frame-by-frame analysis of interlaced surveillance video without performing interlaced to progressive conversion, also known as deinterlacing. In most surveillance systems, very basic techniques are used for deinterlacing, resulting in a number of severe visual artifacts and greatly limiting the intelligibility of surveillance video. This thesis investigates fourteen <b>deinterlacing</b> algorithms <b>to</b> determine methods that will improve the quality and intelligibility of video sequences acquired by surveillance systems. The advantages and disadvantages of each algorithm are discussed followed by both qualitative and quantitative comparisons. Motion adaptive deinterlacing methods are shown to have the most potential for surveillance video, demonstrating the highest performance both visually and in terms of peak signal-to-noise ratio. by Brian A. HEng. Thesis (S. M.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2001. Includes bibliographical references (p. 91 - 93) ...|$|R
50|$|Interlacing can be {{exploited}} to produce 3D TV programming, {{especially with a}} CRT display and especially for color filtered glasses by transmitting the color keyed picture for each eye in the alternating fields. This does not require significant alterations to existing equipment. Shutter glasses can be adopted as well, obviously with the requirement of achieving synchronisation. If a progressive scan display is used to view such programming, any attempt <b>to</b> <b>deinterlace</b> the picture will render the effect useless. For color filtered glasses the picture has to be either buffered and shown {{as if it was}} progressive with alternating color keyed lines, or each field has to be line-doubled and displayed as discrete frames. The latter procedure {{is the only way to}} suit shutter glasses on a progressive display.|$|R
30|$|A single-field {{interpolation}} algorithm {{based on}} block-wise autoregression that considers mutual influence between the missing high-resolution pixels and the given interlaced, low-resolution pixels in a slip window is introduced in [4]. A method to use different interpolation techniques based on classification of each missing pixel {{into two categories}} according to different local region gradient features is discussed in [5]. Further, a statistical-based approach which uses Bayes theory to model the residual of the images as Gaussian and Laplacian distribution {{can be used to}} estimate the missing pixels in [6]. To improve the accuracy of motion vectors for video deinterlacing by selectively using optical flow results, for assisting the block-based motion estimation is proposed in [12], at a high computational cost. The computational load of block-based compensation can be reduced using predictive area search algorithms, which estimate the motion vectors (MV) of the current block using the MVs of previous blocks [13]. Neural networks and fuzzy logic can also be used as deinterlacing solutions. A way to exploit fuzzy reasoning to reinforce contours for improving an edge-adaptive deinterlacing algorithm without an excessive increase in computational complexity is discussed in [14]. Another approach for fuzzy logic <b>deinterlacing</b> is <b>to</b> use a fuzzy-bilateral filtering method which considers the range and domain filters based on a fuzzy metric [2, 8].|$|R
40|$|We {{propose a}} new {{approach}} for motion-compensated, reduced-order model Kalman filtering for restoration of progressive and interlaced video. In the case of interlaced inputs, the proposed filter also performs <b>deinterlacing.</b> In contrast <b>to</b> the literature, both motion-compensation and reduced-order state modeling are achieved by augmenting the observation equation, as opposed to modifying the state-transition equation. The proposed modeling, which includes the 2 -D ROMKF of Angwin and Kaufman as a special case, results in significant performance improvement in fixed-lag Kalman filtering of space-varying blurred images. This is demonstrated by experimental results. EDICS IP 1. 13 or IP 1. 12 Corresponding Author: Andrew J. Patti Hewlett Packard Labs Palo Alto, CA 94304 - 1126 Phone: (415) 857 - 7895 Fax: (415) 857 - 4691 email: patti@hpl. hp. com This work is {{supported in part by}} a National Science Foundation IUCRC grant and a New York State Science and Technology Foundation grant to the Center for [...] ...|$|R
40|$|Interlacing is {{a widely}} used technique, for {{television}} broadcast and video recording, to double the perceived frame rate without increasing the bandwidth. But it presents annoying visual artifacts, such as flickering and silhouette "serration," during the playback. Existing state-of-the-art deinterlacing methods either ignore the temporal information to provide real-time performance but lower visual quality, or estimate the motion for better deinterlacing but with a trade-off of higher computational cost. In this paper, we present the first and novel deep convolutional neural networks (DCNNs) based method <b>to</b> <b>deinterlace</b> with high visual quality and real-time performance. Unlike existing models for super-resolution problems which relies on the translation-invariant assumption, our proposed DCNN model utilizes the temporal information from both the odd and even half frames to reconstruct only the missing scanlines, and retains the given odd and even scanlines for producing the full deinterlaced frames. By further introducing a layer-sharable architecture, our system can achieve real-time performance on a single GPU. Experiments shows that our method outperforms all existing methods, in terms of reconstruction accuracy and computational performance. Comment: 9 pages, 11 figure...|$|R
5000|$|Live {{programs}} are captured at roughly 60 Hz. In the last 15 years, 30 Hz {{has also become}} a feasible capture rate when a more [...] "film like" [...] look is desired, but ordinary video cameras are used. Capture on video at the film rate of 24 Hz is an even more recent development, and mostly accompanies HDTV production. Unlike 30 Hz capture, 24 Hz cannot be simulated in post production. The camera must be natively capable of capturing at 24 Hz during recording. Because the ~30 Hz material is more [...] "fluid" [...] than 24 Hz material, the choice between ~30 and ~60 rate is not as obvious as that between 25 Hz and 50 Hz. When printing 60 Hz video to film, {{it has always been}} necessary to convert it to 24 Hz using the reverse 3:2 pulldown. The look of the finished product can resemble that of film, however it is not as smooth, (particularly if the result is returned to video) and a badly done <b>deinterlacing</b> causes image <b>to</b> noticeably shake in vertical direction and lose detail.|$|R
40|$|A de-interlacing {{algorithm}} using adaptive 4 -field {{motion compensation}} approach is presented. It consists of blockbased directional edge interpolation, same- parity 4 -field motion detection, 4 -field motion estimation and compensation. The intra field methods are reconstructed the frame {{from the current}} field information. but this method introduce the edge flicker problems and jitter effect. The inter field methods are depends on the previous and future fields for reconstruction of the current frame. This method introduces feathering effect. The edges are sharper when the directional edge interpolation is adopted and jitter effect and the feathering effect eliminated. The motion adaptive deinterlacing scheme is taking the advantages of both intra and inters field methods. First it finds the motion by using motion detection scheme if the field contain motion apply intra field interpolation method if the field contain stationary objects apply the inter field interpolation method. The 3 -field motion detection can not detect the fast motion areas from field to field. The same parity 4 -field motion adaptive deinterlacing and the 4 -field motion compensation detect the static areas and fast motion by four reference fields. The Compensation recovers the interlaced videos to the progressive ones but the feathering effect is not recovered in this method. The adaptive 4 -field motion compensation method removes the feathering effect along with detecting fast motion areas by using four reference fields. Experimental {{results show that the}} peak signal-to-noise ratio of our adaptive 4 -field motion compensation deinterlacing algorithm is 4 to 6 dB higher than that of 3 -field motion adaptive <b>deinterlacing</b> and 2 <b>to</b> 3 dB higher than 4 -field motion compensation deinterlacing and attain the best quality of video...|$|R
40|$|Multimedia {{application}} {{has become}} extremely popular nowadays. Digital video {{products such as}} DVD player, DVD recorder, Digital TV system and Personal Video Recorder are entering everyone's home and bringing an exciting multimedia environment to the consumers. The improvement in the video quality is {{a key factor in}} the success of multimedia industry, which is facilitated by the advancement in multimedia, VLSI and networking technology. With the improvement in VLSI technology, more advanced and computationally complex video processing algorithms can be realized into consumer products and hence, producing high quality multimedia applications. Postprocessing is the technique to enhance the video quality for display. In this thesis, two topics in postprocessing are investigated: error concealment and video format conversion. Nowadays, many multimedia applications are integrated into some existing networks, for examples, video conferencing on the Internet, VOD with your 3 G mobile phone, etc [...] . However, those networks are unreliable and packets may be lost or corrupted during the transmission. The loss of information caused by the transmission errors can produce an adverse degradation in visual quality. Error concealment is a technique to recover the lost information and improve the quality of the corrupted video. In this thesis, we provide two algorithms to address the issue: "Temporal error concealment for video transmission with edge reconstruction" and "A Partitioned Linear Minimum Mean Square Estimator for Error Concealment". In the first algorithm, the edge information is considered in the estimation of the missing motion vector to improve the prediction accuracy. In the second algorithm, the multi-hypothesis motion compensated technique is employed to reduce the prediction error. The second problem in multimedia application is the different display formats in use. For example, the TV transmission system (PAL, NTSC, SECAM) adopts interlaced video while the PC community and internet-broadcast adopts progressive video format. In order to provide interoperability between different systems, postprocessing is needed for conversion between different video formats. In particular, we address the problem of deinterlacing, which convert interlaced video to progressive video for display. In our spatial-temporal deinterlacing algorithm, it estimates the motion of each block and fills the missing field by motion compensation. If the estimated motion is not reliable, our spatial deinterlacing algorithm is invoked, which analyzes the content of a field and choose the most appropriate deinterlacing scheme. In addition <b>to</b> <b>deinterlacing,</b> our frame rate up-conversion algorithm can double the frame rate by interpolating the frame along the motion trajectory...|$|R

