78|1280|Public
5000|$|Vaishnavi {{has made}} major {{contributions}} to the teaching, propagation, and development of design science research methods for information systems and other information and communication technology fields such as computer science, software engineering, and <b>human-computer</b> <b>interface</b> (<b>HCI).</b> Starting in early 1990s, he started focusing his doctoral level seminar course (at Georgia State University) to design science research methods, which he then called [...] "improvement research" [...] taking the novel approach of developing a pattern language for conducting this type of research. This work resulted in {{the introduction of a}} formal course for the teaching of this type of research in 2002 called [...] "Design Science Research Methods in Information Systems," [...] creation of the living AIS design science research page in 2004, last revised in 2015, and publication of the book: Design Science Research Methods and Patterns in 2007, which has been widely used as a reference or textbook; the second revised and expanded edition of this book has been published in 2015. In addition to contributing to design science research methods, he has also contributed to advancing design science theory through his books as well as research papers including the recent EJIS paper and the JAIS paper.|$|E
40|$|Abstract. The {{engineering}} of <b>Human-Computer</b> <b>Interface</b> (<b>HCI)</b> is {{a wide-ranging}} and huge research field. However development models stemming from Software Engineering overlook important aspects {{in terms of}} interactive systems development. That is why an HCI-enriched model, called ∇ model (pronounced nabla model), is envisaged in this paper...|$|E
40|$|A {{major concern}} facing system {{developers}} {{is how well}} the system will operate for the intended user. The aspect which allows a user to interact the system {{is referred to as}} the <b>Human-Computer</b> <b>Interface</b> (<b>HCI).</b> This paper discusses the various approaches advocated by researchers in an attempt to explore the issues surrounding HCI...|$|E
5000|$|Prototyping is {{especially}} good for designing good <b>human-computer</b> <b>interfaces.</b> [...] "One {{of the most}} productive uses of rapid prototyping to date has been {{as a tool for}} iterative user requirements engineering and <b>human-computer</b> <b>interface</b> design." ...|$|R
40|$|<b>Human-computer</b> <b>interface</b> {{development}} tools are interactive systems that support production {{and execution of}} the <b>human-computer</b> <b>interface.</b> With their recent proliferation, evaluations and comparisons are constantly done, but without a formal, structured approach. Addressing these problems is difficult, {{largely because of the}} relative newness of such tools, because of the many different kinds of systems that are called UIMS, and because of their inherent complexity. These tools are complex because <b>human-computer</b> <b>interfaces,</b> which produce tools, are complex...|$|R
5000|$|Jef Raskin (1943-2005), American <b>human-computer</b> <b>interface</b> expert ...|$|R
40|$|This {{deliverable}} {{contains the}} evaluation of the final application prototypes – Collaborative eLearning and Location Based Services. The evaluation takes account of the following viewpoints: <b>Human-Computer</b> <b>Interface</b> (<b>HCI),</b> assurance, legal, economics and social aspects. It also includes evaluations by the application prototypes ’ developers of the suitability of the PRIME Integrated Prototype V 2 as the basis for their identity management functions...|$|E
40|$|The applied {{human factors}} {{research}} program {{performed at the}} NASA Johnson Space Center's Human-Computer Interaction Laboratory is discussed. Research is conducted to advance knowledge in human interaction with computer systems during space crew tasks. In addition, the Laboratory is {{directly involved in the}} specification of the <b>human-computer</b> <b>interface</b> (<b>HCI)</b> for space systems in development (e. g., Space Station Freedom) and is providing guidelines and support for HCI design to current and future space missions...|$|E
40|$|Technology has {{resulted}} {{in our ability to}} control machines for improving our lives. However, large number {{of people around the world}} are unable to use the conventional machine interface devices due to injury, disease, or simply weakness due to aging. This chapter introduces the reader to the requirement and the fundamental concept of <b>human-computer</b> <b>interface</b> (<b>HCI)</b> and lists the different modalities that are available. The different applications of each modality have been discussed and it introduces the reader to the next nine chapters...|$|E
5000|$|... {{communication}} layer between {{models and}} humans (<b>human-computer</b> <b>interface).</b>|$|R
5000|$|The Art of <b>Human-Computer</b> <b>Interface</b> Design, Addison-Wesley (1990) ...|$|R
40|$|The {{application}} of formal methods to the specification {{and design of}} <b>human-computer</b> <b>interfaces</b> is described. A broad outline of <b>human-computer</b> <b>interface</b> problems, {{a description of the}} field of cognitive engineering and two relevant research results, the appropriateness of formal specification techniques, and potential NASA application areas are described...|$|R
40|$|Abstract—In this paper, we {{describe}} a <b>human-computer</b> <b>interface</b> (<b>HCI)</b> system that includes an enabler for controlling gadgets based on signal analysis of brain activities transmitted from the enabler to the gadgets. The enabler is insertable in a user’s ear {{and includes a}} recorder that records brain signals. A processing unit of the system, which is inserted in a gadget, commands the gadget based on decoding the recorded brain signals. The proposed device and system could facilitate a brain-machine interface to control the gadget from electroencephalography signals in the user’s brain. Keywords—Brain-machine interface; Bio-signal computer command; mind-reading device; human-computer interface I...|$|E
40|$|By {{enhancing}} a real {{scene with}} computer generated objects, Augmented Reality (AR), has proven {{itself as a}} valuable <b>Human-Computer</b> <b>Interface</b> (<b>HCI)</b> in numerous application areas such as medical, military, entertainment and manufacturing. It enables higher performance of on-site tasks with seamless presentation of up-to-date, task-related information to the users during the operation. AR has potentials in design because the current interface provided by Computer-aided Design (CAD) packages is less intuitive and reports show {{that the presence of}} physical objects help design thinking and communication. This research explores the use of AR to improve the efficiency of a design process, specifically in mechanical design. Singapore-MIT Alliance (SMA...|$|E
40|$|The Usability Testing and Analysis Facility (UTAF) at the NASA Johnson Space Center has {{identified}} and evaluated a potential automated software interface inspection tool capable of assessing {{the degree to}} which space-related critical and high-risk software system user interfaces meet objective human factors standards across each NASA program and project. Testing consisted of two distinct phases. Phase 1 compared analysis times and similarity of results for the automated tool and for <b>human-computer</b> <b>interface</b> (<b>HCI)</b> experts. In Phase 2, HCI experts critiqued the prototype tool's user interface. Based on this evaluation, it appears that a more fully developed version of the tool will be a promising complement to a human factors-oriented independent verification and validation (IV&V) process...|$|E
40|$|This project {{involves}} {{the development of}} a technique for modeling and analytically evaluating <b>human-computer</b> <b>interfaces.</b> The modeling technique is supported by an extensive set of theorems and algorithms which describe the various model building phases. The theorems and algorithms show that the representations of each <b>human-computer</b> <b>interface</b> converges to a single probabilistic finite state model which accurately represents the human-computer interaction. The resulting probabilistic finite state models are then used as predictors to generate data which can be statistically analyzed to yield a comparison between alternative <b>human-computer</b> <b>interfaces.</b> ^ The technique uses an approach in which probabilistic finite state models of the prospective <b>human-computer</b> <b>interfaces</b> are constructed. Specifications of the <b>human-computer</b> <b>interfaces</b> provide for the partial definitions of initial probabilistic finite state models. Initially, the missing components of the probabilistic finite state models are the time distributions which specify how much time is spent in each state and the probabilities associated with the state transitions. Experiments are required to determine the time distributions and state transition probabilities. For this project a set of experiments was performed using simulated <b>human-computer</b> <b>interfaces</b> to a CASE system component which calculates time performance of software for parallel architectures. The data collected during the experiments were used to complete and refine the probabilistic finite state models. The refined models were then exercised as predictors and the generated data was statistically analyzed to compare the interfaces. The results demonstrated that the modeling and evaluation technique can be used effectively in the design and refinement of <b>human-computer</b> <b>interfaces.</b> ...|$|R
40|$|<b>Human-computer</b> <b>interface</b> {{development}} tools [...] often called user interface management systems or UIMS [...] are interactive systems that support production {{and execution of}} the <b>human-computer</b> <b>interface.</b> Despite their proliferation, no method exists for their systematic evaluation or comparison. We have developed an evaluation procedure that uses a standardized technique to produce quantifiable criteria for evaluating and comparing <b>human-computer</b> <b>interface</b> {{development tools}}. The procedure produces ratings along two dimensions: functionality and usability. Specification/implementation techniques used by the tool are also quantitatively rated. An empirical study indicates that the procedure produces reliable results. The procedure is already being used in one commercial environment...|$|R
40|$|Paper {{presented}} as a panel discussant at The International Workshop on the Next Generation of Information Technologies and Systems, held in Haifa, Israel: July 1993. Before we can extrapolate {{to the next generation}} of <b>human-computer</b> <b>interfaces,</b> a relevant question is 2 ̆ 2 How many generations of <b>human-computer</b> <b>interfaces</b> have there been so far, and what were they? 2 ̆...|$|R
40|$|The safing and failure-detection expert (SAFE) is a {{prototype}} for a malfunction detection, diagnosis, and safing {{system for the}} atmospheric revitalization subsystem (ARS) in the Space Shuttle orbiter. SAFE, whose knowledge was extracted from expert-provided heuristics and documented procedures, automatically manages all phases of failure handling: detection, diagnosis, testing procedures, and recovery instructions. The SAFE architecture allows it to handle correctly sensor failures and multiple malfunctions. Since SAFE is highly interactive, it {{was used as a}} test bed for the evaluation of various advanced <b>human-computer</b> <b>interface</b> (<b>HCI)</b> techniques. The use of such expert systems in the next generation of space vehicles would increase their reliability and autonomy to levels not achievable before...|$|E
40|$|International audienceWe {{have now}} {{sufficient}} {{evidence that the}} use of bioelectric signals in the field of Augmented and Alternative Communication (AAC) is feasible. Moreover they are particularly suitable for people with severe motor disabilities, for example, people with high levels of spinal cord injury or with locked-in syndrome. The development of solutions for this kind of people implies in the finding of ways to use sensors that fit the user needs as well as the constrains involved, translating the intentions of the user in commands. This paper presents a <b>human-computer</b> <b>interface</b> (<b>HCI),</b> based on the acquisition of electromyographic (EMG) signals to interact with an Assistive Communication System (ACS). The developed tool was tested successfully by patients severely disabled by amyotrophic lateral sclerosis (ALS) and other diseases...|$|E
40|$|From online multi-player {{games to}} web search, the web is now {{populated}} by {{a multitude of}} online applications. The main question we try to answer in this paper is which of those applications {{can be characterized as}} traditional services and therefore benefit from the concepts, techniques, and methods developed in traditional services theory. Our answer is to define online service applications as applications where (1) the user does not control most means of production; (2) the user is {{a significant part of the}} input to the production process. We then discuss how some traditional service techniques can be applied to online service applications by considering aspects of the design and evaluation of the <b>human-computer</b> <b>interface</b> (<b>HCI)</b> of online services. 1...|$|E
5000|$|... 1999: Computer History Museum [...] "for his {{fundamental}} {{contributions to}} personal computing and <b>human-computer</b> <b>interface</b> development." ...|$|R
40|$|An {{evaluation}} procedure {{that uses a}} standardized technique to produce quantifiable criteria for evaluating and comparing <b>human-computer</b> <b>interface</b> development tools is described in this paper. An empirical validation study to determine the consistency of ratings produced by this procedure is also presented. These ratings could be used, for example, as important data for the task of choosing a tool for a particular <b>human-computer</b> <b>interface</b> development environment...|$|R
25|$|Raskin {{also wrote}} a book, The Humane Interface (2000), {{in which he}} {{developed}} his ideas about <b>human-computer</b> <b>interfaces.</b>|$|R
40|$|Virtual Environment (VE) system {{offers a}} natural and {{intelligent}} user interface. Hand gesture recognition is more efficient and easier interaction in VE than <b>human-computer</b> <b>interface</b> (<b>HCI)</b> devices like keyboards and mouses. We propose a hand gesture recognition interface that generates commands to control objects directly in a game. Our novel hand gesture recognition system utilizes both Bag-of-features and Support Vector Machine (SVM) to realize user-friendly interaction between human and computers. The HCI based on hand gesture recognition interacts with objects in a 3 D virtual environment. With this interface, the user can control and direct a helicopter {{by a set of}} hand gesture commands controlling the movements of the helicopter. Our system shows the hand gesture recognition interface can attain an enhanced and more intuitive and flexible interaction for the user than other HCI devices...|$|E
40|$|A <b>human-computer</b> <b>interface</b> (<b>HCI)</b> {{system called}} “The Camera Mouse ” is evaluated. It tracks a user’s {{movements}} {{with a video}} camera and translates them to movements of the mouse pointer on the screen [1]. The main objectives for the experimentation were to quantitatively define {{the performance of the}} system for different users, features, and applications, to determine the optimal settings for different kinds of users, and to compare measurements over all users in order to suggest enhancements to a future system of this type. The experiments were conducted with 11 participants including a subject with severe physical disabilities. Each subject repeatedly performed a number of tasks. During each trial, a different feature was tracked and the elapsed time and mouse movement trajectories were measured. These measurements were used to quantify the system’s performance. 1...|$|E
40|$|Described {{here is a}} {{research}} project that uses human factors and computer systems knowledge to explore and help guide the design and creation of an effective <b>Human-Computer</b> <b>Interface</b> (<b>HCI)</b> for spacecraft crew procedures. By having a computer system behind the user interface, {{it is possible to}} have increased procedure automation, related system monitoring, and personalized annotation and help facilities. The research project includes the development of computer-based procedure system HCI prototypes and a testbed for experiments that measure the effectiveness of HCI alternatives in order to make design recommendations. The testbed will include a system for procedure authoring, editing, training, and execution. Progress on developing HCI prototypes for a middeck experiment performed on Space Shuttle Mission STS- 34 and for upcoming medical experiments are discussed. The status of the experimental testbed is also discussed...|$|E
5000|$|... 1. Following the {{standard}} {{convention of the}} <b>human-computer</b> <b>interface,</b> the display area is always divided into multiple frames.|$|R
40|$|<b>Human-{{computer}}</b> <b>interface</b> management, from {{a computer}} science viewpoint, focuses {{on the process of}} developing quality human computer interfaces, including their representation, design, implementation, execution, evaluation, and maintenance. This survey presents important concepts of interface management: dialogue independence, structural modeling, specification, rapid prototyping, holistic software engineering, control structures, and support environments, including User Interface Management System Tools. Several systems for <b>human-computer</b> <b>interface</b> management are presented to illustrate these concepts...|$|R
5000|$|Raskin {{also wrote}} a book, The Humane Interface (Addison-Wesley, 2000), {{in which he}} {{developed}} his ideas about <b>human-computer</b> <b>interfaces.</b>|$|R
40|$|The visual {{representation}} of a product {{and the role of}} visualization have recently become a central issue in design research. By enhancing a real scene with computer generated objects, Augmented Reality (AR), has proven itself as a valuable <b>Human-Computer</b> <b>Interface</b> (<b>HCI)</b> in numerous application areas such as medical, military, entertainment and manufacturing. Also AR has potentials in design because the current interface provided by Computer-Aided Design (CAD) packages is less intuitive and reports show that the presence of physical objects help design. In this paper we proposed approach that user can create own 3 D augmented reality scenes which enables interaction between real world and virtual object at the same time. For this purpose BuildAR software is applied using marker-based camera tracking and 3 D object is obtained with standard CAD system SolidWorks...|$|E
40|$|This survey paper {{investigates the}} current state of the art with respect to {{collaborative}} computing. Specifically, the paper addresses the field of collaborative software engineering and focuses on the background and issues related to distributed software development. The paper begins by exploring collaborative computing in general, discusses synchronous and asynchronous collaboration and communication mechanisms to ensure updates are handled properly, and then focuses on elements that have significant impact on distributed software engineering: mutual exclusion, achieving “undo ” and “redo, ” organizational theory, merging code, and distributed version control. The paper then examines some of the <b>human-computer</b> <b>interface</b> (<b>HCI)</b> issues of such collaborative systems and presents various classification schemes that are helpful in comparing various collaborative domains and applications. The paper concludes by discussing recent and future work in the field...|$|E
40|$|The paper {{presents}} a <b>human-computer</b> <b>interface</b> (<b>HCI)</b> for natural interaction in the Cave Automatic Virtual Environment (CAVE). By tracking hand actions and movements {{with a set}} of six infra-red (IR) cameras, the proposed HCI allows a user to interact directly with virtual objects in the CAVE without the need to attach any complex electronic tracking devices, such as data-gloves, on the user's hands. An intuitive control scheme based on simple and natural hand gestures, including "grab" and "drop", is developed to demonstrate the strengths of the HCI. A case study of using the HCI to facilitate the simulation of fork-lift truck operations in the CAVE system is presented. Finally, the compatibility and benefits of integrating the HCI with virtual reality (VR) simulation systems in the CAVE are discussed. © 2010 CAD Solutions, LLC. link_to_subscribed_fulltex...|$|E
50|$|Other {{terms for}} user {{interface}} are man-machine interface (MMI) {{and when the}} machine in question is a computer <b>human-computer</b> <b>interface.</b>|$|R
40|$|Some of {{the many}} {{analytical}} models in <b>human-computer</b> <b>interface</b> design that are currently being developed are described. The usefulness of analytical models for <b>human-computer</b> <b>interface</b> design is evaluated. Can the use of analytical models be recommended to interface designers? The answer, based on the empirical research summarized here, is: not at this time. There are too many unanswered questions concerning the validity of models {{and their ability to}} meet the practical needs of design organizations...|$|R
30|$|Intelligent {{agents have}} been used in several {{disciplines}} as Artificial Intelligence, in <b>human-computer</b> <b>interface</b> design and in object-based systems (Jennings et al. 1998).|$|R
