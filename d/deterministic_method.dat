486|1611|Public
25|$|Targeted {{proteomics}} using SRM and Data-independent acquisition {{methods are}} often considered alternatives to shotgun proteomics {{in the field}} of bottom-up proteomics. While shotgun proteomics uses data-dependent selection of precursor ions to generate fragment ion scans, the aforementioned methods use a <b>deterministic</b> <b>method</b> for acquisition of fragment ion scans.|$|E
50|$|Information space {{analysis}} is a <b>deterministic</b> <b>method,</b> enhanced by machine intelligence, for locating and assessing resources for team centric efforts.|$|E
5000|$|Elishakoff I., Li Y.W., Starnes J.H., 1994, A <b>deterministic</b> <b>method</b> {{to predict}} the effect of unknown-but-bounded elastic moduli on the {{buckling}} of composite structures. Computer methods in applied mechanics and engineering, Vol.111, pp. 155-167 ...|$|E
40|$|Abstract. This paper mainly {{researches}} the <b>deterministic</b> <b>methods</b> that discriminating threshold by {{signal noise}} ration {{of different kinds}} of genes, approaches the relation between frequency spectrum and signal noise ration under Voss mapping and Z-curve mapping, and concludes the <b>deterministic</b> <b>methods</b> and threshold results {{of different kinds of}} gene thresholds...|$|R
40|$|Questions {{regarding}} {{accuracy and}} efficiency of <b>deterministic</b> transport <b>methods</b> are still on our mind today, even with modern supercomputers. The most versatile and widely used <b>deterministic</b> <b>methods</b> are the PN approximation, the SN method (discrete ordinates method) and their variants. In the discrete ordinates (SN) formulations of the transport equation, {{it is assumed that}} the linearized Boltzmann equation only holds for a set of distinct numerical values of the direction-of-motion variables. In this work, looking forward to confirm the capabilities of <b>deterministic</b> <b>methods</b> in obtaining accurate results, we present a general overview of <b>deterministic</b> <b>methods</b> to solve the Boltzmann transport equation for neutral and charged particles. First, we describe a review in the Laplace transform technique applied to SN two dimensional transport equation in a rectangular domain considering Compton scattering. Next, we solved the Fokker-Planck (FP) equation, an alternative approach for the Boltzmann transport equation, assuming a monoenergetic electron beam in a rectangular domain. The main idea relies on applying the PN approximation, a recent advance in the class of <b>deterministic</b> <b>methods,</b> in the angular variable, to the two dimensional Fokker-Planck equation and then applying the Laplace Transform in the spatial x-variable. Numerical results are given to illustrate the accuracy of <b>deterministic</b> <b>methods</b> presented...|$|R
50|$|Both fixed-source and {{criticality}} calculations can {{be solved}} using <b>deterministic</b> <b>methods</b> or stochastic <b>methods.</b> In <b>deterministic</b> <b>methods</b> the transport equation (or an approximation of it, such as diffusion theory) is solved as a differential equation. In stochastic methods such as Monte Carlo discrete particle histories are tracked and averaged in a random walk directed by measured interaction probabilities. <b>Deterministic</b> <b>methods</b> usually involve multi-group approaches while Monte Carlo can work with multi-group and continuous energy cross-section libraries. Multi-group calculations are usually iterative, because the group constants are calculated using flux-energy profiles, which are determined {{as the result of}} the neutron transport calculation.|$|R
50|$|Inverse {{distance}} weighting (IDW) {{is a type}} of <b>deterministic</b> <b>method</b> for multivariate interpolation with a known scattered set of points. The assigned {{values to}} unknown points are calculated with a weighted average of the values available at the known points.|$|E
50|$|Targeted {{proteomics}} using SRM and Data-independent acquisition {{methods are}} often considered alternatives to shotgun proteomics {{in the field}} of bottom-up proteomics. While shotgun proteomics uses data-dependent selection of precursor ions to generate fragment ion scans, the aforementioned methods use a <b>deterministic</b> <b>method</b> for acquisition of fragment ion scans.|$|E
50|$|The {{distribution}} function, f, is a dimensionless function {{which is}} used to extract all observable of interest and gives a full depiction of electron distribution in both real and k-space. Further, it physically represents the probability of particle occupation of energy k at position r and time t. In addition, due to being a seven-dimensional integro-differential equation (six dimensions in the phase space and one in time) the solution to the BTE is cumbersome and can be solved in closed analytical form under very special restrictions. Numerically, solution to the BTE is employed using either a <b>deterministic</b> <b>method</b> or a stochastic method. <b>Deterministic</b> <b>method</b> solution is based on a grid-based numerical method such as the spherical harmonics approach, whereas the Monte Carlo is the stochastic approach used to solve the BTE.|$|E
5000|$|<b>Deterministic</b> <b>Methods</b> of Seismic Source Identification, Defense Technical Information Center, 1983 ...|$|R
40|$|IF YOU CHANGE YOUR ADDRESS, please notify us (including Building and Room No. where needed). Third Class Mail is {{returned}} to us at our expense if the addressee has moved. If your mail {{is returned}}, your name will be deleted from our distributions until we hear from you. I have found it helpful to keep constantly in mind that there are really two entries {{to be made for}} every transaction) one in terms of immediate dollars and cents, the other in terms of goodwill.) Ralph Hitz <b>Deterministic</b> <b>Methods</b> Seminar/TORT Workshop Program The RSIC Seminar/Workshop on <b>Deterministic</b> <b>Methods</b> to be held in February 1992 will be in two parts. The <b>Deterministic</b> <b>Methods</b> Seminar will take up the first 1 days. The TORT workshop will begin on Wednesday afternoon. A brief overview of the TORT Workshop follows...|$|R
2500|$|... (2003) <b>Deterministic</b> <b>Methods</b> in Systems Hydrology: IHE Delft Lecture Note Series (UNESCO-IHE Delft Lecture Note Series) by Dooge J.C.I. and J.P. O'Kane ...|$|R
50|$|Polymers {{are large}} {{molecules}} {{and thus are}} very complicated for solving using a <b>deterministic</b> <b>method.</b> Yet, statistical approaches can yield results and are often pertinent, since large polymers (i.e., polymers {{with a large number}} of monomers) are describable efficiently in the thermodynamic limit of infinitely many monomers (although the actual size is clearly finite).|$|E
5000|$|The Halton {{sequence}} is constructed {{according to a}} <b>deterministic</b> <b>method</b> that uses coprime numbers as its bases. As a simple example, let's take one dimension of the Halton sequence {{to be based on}} 2 and the other on 3. To generate the sequence for 2, we start by dividing the interval (0,1) in half, then in fourths, eighths, etc., which generates ...|$|E
5000|$|The Varshamov {{construction}} {{above is}} not explicit; that is, {{it does not}} specify the <b>deterministic</b> <b>method</b> to construct the linear code that satisfies the Gilbert-Varshamov bound. The naive {{way that we can}} do is to go over all the generator matrices [...] of size [...] over the field [...] and check if that linear code has the satisfied Hamming distance. That leads to the exponential time algorithm to implement it.|$|E
40|$|We study optimal {{stochastic}} (or Monte Carlo) quadrature formulas for convex functions. While nonadaptive Monte Carlo {{methods are}} not better than <b>deterministic</b> <b>methods</b> we prove that adaptive Monte Carlo methods are much better. 1 Optimal Stochastic Quadrature Formulas For Convex Functions Erich Novak and Knut Petras Abstract. We study optimal stochastic (or Monte Carlo) quadrature formulas for convex functions. While nonadaptive Monte Carlo methods are not better than <b>deterministic</b> <b>methods</b> we prove that adaptive Monte Carlo methods are much better...|$|R
50|$|Subrandom {{numbers have}} an {{advantage}} over pure random numbers in that they cover the domain of interest quickly and evenly. They {{have an advantage}} over purely <b>deterministic</b> <b>methods</b> in that <b>deterministic</b> <b>methods</b> only give high accuracy {{when the number of}} datapoints is pre-set whereas in using subrandom sequences the accuracy typically improves continually as more datapoints are added, with full reuse of the existing points. On the other hand, subrandom sets can have a significant lower discrepancy for a given number of points than subrandom sequences.|$|R
50|$|Determining {{the optimal}} {{solution}} is an NP-complete problem in combinatorial optimization, so in practice heuristic and <b>deterministic</b> <b>methods</b> {{are used to}} find acceptably good solutions for the VRSP.|$|R
50|$|Irresistible grace (or efficacious grace) is a {{doctrine}} in Christian theology particularly associated with Calvinism, which teaches that the saving grace of God is effectually applied to those {{whom he has}} determined to save (the elect) and, in God's timing, overcomes their resistance to obeying {{the call of the}} gospel, bringing them to faith in Christ. It is to be distinguished from prevenient grace particularly associated with Arminianism which teaches that the offer of salvation through grace does not act irresistibly in a purely cause-effect, <b>deterministic</b> <b>method,</b> but rather in an influence-and-response fashion that can be both freely accepted and freely denied.|$|E
5000|$|Grace is resistible: God takes {{initiative}} in the salvation process and his grace comes to all people. This grace (often called prevenient or pre-regenerating grace) acts on all people {{to convince them}} of the Gospel, draw them strongly towards salvation, and enable the possibility of sincere faith. Picirilli states that [...] "indeed this grace {{is so close to}} regeneration that it inevitably leads to regeneration unless finally resisted." [...] The offer of salvation through grace does not act irresistibly in a purely cause-effect, <b>deterministic</b> <b>method</b> but rather in an influence-and-response fashion that can be both freely accepted and freely denied.|$|E
50|$|One {{aspect of}} the problem is that, no matter what method each person uses to decide if they will go to the bar or not, if {{everyone}} uses the same pure strategy it is guaranteed to fail. If everyone uses the same <b>deterministic</b> <b>method,</b> then if that method suggests that the bar will not be crowded, everyone will go, and thus it will be crowded; likewise, if that method suggests that the bar will be crowded, nobody will go, and thus it will not be crowded. Often the solution to such problems in game theory is to permit each player to use a mixed strategy, where a choice is made with a particular probability. In the case of the single-stage El Farol Bar problem, there exists a unique symmetric Nash equilibrium mixed strategy where all players choose to go to the bar with a certain probability that {{is a function of the}} number of players, the threshold for crowdedness, and the relative utility of going to a crowded or an uncrowded bar compared to staying home. There are also multiple Nash equilibria where one or more players use a pure strategy, but these equilibria are not symmetric. Several variants are considered in Game Theory Evolving by Herbert Gintis.|$|E
5000|$|... which {{decreases}} as [...] This {{is standard}} error {{of the mean}} multiplied with [...] This result {{does not depend on}} the number of dimensions of the integral, which is the promised advantage of Monte Carlo integration against most <b>deterministic</b> <b>methods</b> that depend exponentially on the dimension. It is important to notice that, like in <b>deterministic</b> <b>methods,</b> the estimate of the error is not a strict error bound; random sampling may not uncover all the important features of the integrand that can result in an underestimate of the error.|$|R
40|$|<b>Deterministic</b> <b>methods</b> are {{appropriate}} for analyzing specific slopes at site-scale where geotechnical parameters are better known. Probabilistic techniques provide better results than <b>deterministic</b> <b>methods</b> at regional scales (1 : 10, 000 – 1 : 50, 000). However, the performances of <b>deterministic</b> and probabilistic <b>methods</b> at large scales (e. g. 1 : 5000 -scale) are not well-known. We applied GIS-based deterministic (WEDGEFAIL, SAFETYFACTOR, SHALSTAB) and probabilistic (Likelihood ratio) methods to a mountain road of 14 km in the Alpujarras region (S Spain) to investigate the behavior of these models at detailed scales. The studied road stretch was affected by 111 landslides (7 – 8 landslides/km) during the 2009 – 2010 winter {{in a period of}} high precipitation. These landslides cut off the road in several points and disconnected the central region of Alpujarras from the main transport infrastructures. We delimited a small study area with only 4 km 2 restricted to the slopes that cross the road where we gathered as much data as possible. Our results show that <b>deterministic</b> <b>methods</b> have less prediction capability at ~ 1 : 5000 -scale than probabilistic methods and it seems that the needed effort to improve their results is not worthwhile. However, it must take into account that probabilistic methods need an inventory and they could not have been applied before the analyzed landslide event. As our results indicate, the <b>deterministic</b> <b>methods,</b> such as the SHALSTAB model, are reliable tools to make an evaluation of the stability of cut slopes in a roadway at project-scale...|$|R
30|$|After the {{calculation}} of the aridity indices in each station of the study area, the spatial estimation of the indices from the stations’ values were developed via interpolation method. Interpolation predicts values from {{a limited number of}} sample data points to predict unknown geographic point data. There are many interpolation methods to explain territorial variation, mainly grouped as <b>deterministic</b> <b>methods</b> and geostatistical methods (Croitoru et al. 2013). The <b>deterministic</b> <b>methods</b> are based on specified mathematical formulas, while the geostatistical method considers the spatial variation of any continuous variable based on statistical models. Comparing the two interpolation groups, predictions made using geostatistical algorithm interpolations are more accurate than <b>deterministic</b> <b>methods</b> (Moral 2010). However, due to the fewer number of stations, the inverse distance-weighted (IDW) <b>deterministic</b> interpolation <b>method</b> was applied which was also applied in spatial estimation of the climatic indices (Baltas 2007). The IDW is a method of interpolation that predicts cell values by averaging the values of sample data points in the vicinity of each processing cell. The nearest station has a greater weight compared to a station, which is at large distance to the interpolated point. The spatial estimation was done only for De Martonne aridity index and Pinna combinative index because of the limited number stations for spatial estimation of FAO aridity index.|$|R
50|$|The {{start of}} the Great Leap Forward in 1958 came with a vehement attack on pure {{mathematics}} and intellectuals, which prompted Hua to shift towards applied mathematics. Hua developed, with Wang Yuan, a broad interest in linear programming, operations research, and multidimensional numerical integration. In connection {{with the last of}} these, the study of the Monte Carlo method and the role of uniform distribution led them to invent an alternative <b>deterministic</b> <b>method</b> based on ideas from algebraic number theory. Their theory was set out in Applications of Number Theory to Numerical Analysis, which was published much later, in 1978, and by Springer in English translation in 1981. The newfound interest in applicable mathematics took him in the 1960s, accompanied by a team of assistants, all over China to show workers of all kinds how to apply their reasoning faculty to the solution of shop-floor and everyday problems. Whether in ad hoc problem-solving sessions in factories or open-air teachings, he touched his audiences with the spirit of mathematics {{to such an extent that}} he became a national hero and even earned an unsolicited letter of commendation from Mao Zedong, this last a valuable protection in uncertain times. Hua had a commanding presence, a genial personality, and a wonderful way of putting things simply, and the impact of his travels spread his fame and the popularity of mathematics across the land.|$|E
40|$|Master’s thesis {{deals with}} the {{problems}} of heat exchanger network synthesis and compare the present methods with emphasis on Pinch Design Method and <b>deterministic</b> <b>method.</b> Based on theoretical formulation of deterministic model the computer program for heat exchanger network synthesis was developed in the software Maple environment. Developed software implementation of <b>deterministic</b> <b>method</b> has been applied to several case studies...|$|E
40|$|In {{this work}} {{we present a}} Pattern Search optimizer, which being a <b>deterministic</b> <b>method</b> enjoys provable {{convergence}} properties. Furthermore, we develop alternatives and extensions of the standard <b>deterministic</b> <b>method,</b> and innovative hybrid algorithms merging the the Pattern Search with some stochastic approaches. Finally, we apply this method to a real case problem for the pose detection for magnetic-assisted medical applications in order to optimize {{the performance of the}} devic...|$|E
40|$|This {{calculation}} {{evaluates the}} energy deposition rates in silicon, gamma and neutron flux spectra at various locations of interest throughout FHF closure cell. The physical configuration features a complex geometry, with particle flux attenuation of many {{orders of magnitude}} that cannot be modeled by computer codes that use <b>deterministic</b> <b>methods.</b> Therefore, in this calculation the Monte Carlo method was used to solve the photon and neutron transport. In contrast with the <b>deterministic</b> <b>methods,</b> Monte Carlo does not solve an explicit transport equation, but rather obtain answers by simulating individual particles, recording the aspects of interest of their average behavior, and estimates the statistical precision of the results...|$|R
25|$|In {{the late}} 1970s and early 1980s, {{computer}} scientists {{began to realize}} that the deliberate introduction of randomness into computations can be an effective tool for designing better algorithms. In some cases, such randomized algorithms outperform the best <b>deterministic</b> <b>methods.</b>|$|R
30|$|Optimizing {{problems}} can be warranted by different methods which can be split into two major groups; <b>deterministic</b> <b>methods</b> and stochastic methods. Among the latter group genetic algorithm is of more importance because of its ease in use of computers (Chamber 1995).|$|R
40|$|AbstractWe {{compare the}} <b>deterministic</b> <b>method</b> and the {{stochastic}} method for a polymerization network {{when the number}} of available subunits is small. For the stochastic method, we prove there is a recursive method to compute the expected molecule numbers of various components in the reaction network, using the stationary probability distribution of molecule numbers which we illustrate to have a multivariate Poisson form. For the <b>deterministic</b> <b>method,</b> ordinary differential equations for the component concentrations are built following the mass action law. The steady state of the system is extracted to estimate the corresponding molecule numbers. Identities involving the propensity function parameters for the stochastic method and the reaction rate constants in the <b>deterministic</b> <b>method</b> are used to connect the two methods. Computations are conducted for a group of combinations of total number of subunits and reaction rate constant ratios, and the results are compared...|$|E
40|$|We derive a {{deterministic}} particle {{method for}} {{the solution of}} nonlinear reactiondiffusion equations in one spatial dimension. This <b>deterministic</b> <b>method</b> is an analog of a Monte Carlo method for the solution of these problems that has been previously investigated by the author. The <b>deterministic</b> <b>method</b> leads to the consideration {{of a system of}} ordinary differential equations for the positions of suitably defined particles. We then consider the time explicit and implicit methods for this system of ordinary differential equations and we study a Picard and Newton iteration for the solution of the implicit system. Next we solve numerically this system and study the discretization error both analytically and numerically. Numerical computation shows that this <b>deterministic</b> <b>method</b> is automatically adaptive to large gradients in the solution. 1. Introduction. We are interested in numerical methods for the solution of nonlinear reaction-diffusion equations in one species and in one spatial dim [...] ...|$|E
40|$|Though current {{deterministic}} {{safety factors}} are arbitrarily and unaccountably specified, its ratio {{is rooted in}} resistive and applied stress probability distributions. This study approached the <b>deterministic</b> <b>method</b> from a probabilistic concept leading to a more systematic and coherent philosophy and criterion for designing more uniform and reliable high-performance structures. The <b>deterministic</b> <b>method</b> was noted to consist of three safety factors: a standard deviation multiplier of the applied stress distribution; a K-factor for the A- or B-basis material ultimate stress; and the conventional safety factor {{to ensure that the}} applied stress does not operate in the inelastic zone of metallic materials. The conventional safety factor is specifically defined as the ratio of ultimate-to-yield stresses. A deterministic safety index of the combined safety factors was derived from which the corresponding reliability proved the <b>deterministic</b> <b>method</b> is not reliability sensitive. The bases for selecting safety factors are presented and verification requirements are discussed. The suggested deterministic approach is applicable to all NASA, DOD, and commercial high-performance structures under static stresses...|$|E
50|$|It is {{a premier}} {{institute}} in India to provide Medium Range Weather Forecasts through <b>deterministic</b> <b>Methods</b> {{and to offer}} Agro-Advisory Service (AAS) to the farmers. NCMRWF offers research opportunities in Numerical Weather Prediction, Diagnostic Studies, Crop Weather Modeling and Computer Science.|$|R
50|$|In {{the late}} 1970s and early 1980s, {{computer}} scientists {{began to realize}} that the deliberate introduction of randomness into computations can be an effective tool for designing better algorithms. In some cases, such randomized algorithms outperform the best <b>deterministic</b> <b>methods.</b>|$|R
30|$|Although <b>deterministic</b> IP traceback <b>methods</b> {{have higher}} traceback {{accuracy}} {{in comparison to}} probabilistic marking approaches, this accuracy is achieved by marking all the packets in the network. <b>Deterministic</b> <b>methods</b> need to process every packet and obviously, they incur more processing overhead [1]. In our proposed DFM technique, we aim to minimize this overhead. To achieve this, given that all packets in a flow {{belong to the same}} source, we mark every flow, instead of every packet. This leads us to have both advantages of high traceback accuracy of <b>deterministic</b> <b>methods</b> and low processing overhead of probabilistic approaches simultaneously. Our experimental results show that the proposed DFM method has approximately 99 % traceback rate with 0 % false-positive rate, while it may reduce the number of required packets to be marked for tracing back by 90 %.|$|R
