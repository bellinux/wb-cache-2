25|10000|Public
30|$|Dublin Core (DC) [21] has {{appeared}} {{to solve the}} problem of the lack of <b>description</b> <b>of</b> <b>documents</b> on the web. It consists of a set of basic descriptors such as title, creator and date, intentionally kept at a basic nonspecialist level. DC is being widely adopted as part of other web-related standards, such as those for the Semantic Web initiatives [22].|$|E
40|$|Description and {{application}} of metadata and of Resource Description Framework in the web for the <b>description</b> <b>of</b> <b>documents</b> and the improvision of precision in document retrieval. Characteristics of Dublin Core and the metadata element set are discussed. Features and further development that Resource Description Framework provides described. The uses of Resource Description Framework and the opportunities of benefits for the libraries are also described...|$|E
40|$|The {{concepts}} and fundamental {{principles of the}} organization of information are exposed. The characteristics of the documents in Internet, as a fundamental aspect for their description, are approached. The evolution of the traditional bibliographical cataloguing and its influence on the generation of metadata as a process of the <b>description</b> <b>of</b> <b>documents</b> in Internet, its characteristics and functions, as well as the place of the information professionals in the present paradigm, are briefly described...|$|E
40|$|We {{present a}} {{framework}} for media inter-pretation that leverages low-level information extraction {{to a higher level}} of abstraction in order to support semantics-based information retrieval for the Semantic Web. The overall goal of the framework is to provide high-level content <b>descriptions</b> <b>of</b> <b>documents</b> for maxi-mizing precision and recall of semantics-based information retrieval. 1...|$|R
50|$|The Division <b>of</b> <b>Documents</b> Processing and Catalog Maintenance - The {{primary purpose}} of this {{department}} is systematization and bibliographic <b>descriptions</b> <b>of</b> <b>documents</b> that the library obtains. The department is also responsible for organizing and maintaining the systems of electronic and card catalogs {{and the creation of}} specialized directories, which provide greater flexibility when taking into account the interests of users and significantly accelerate search for necessary publications.|$|R
40|$|The article {{contains}} a concise <b>description</b> <b>of</b> <b>document</b> formats used in digital libraries. The text consists of 10 parts: 1 Introduction; 2 Formats in the development cycle digital publishing; 3 Archival formats; 4 Non-archival formats; 4. 1. Text formats, 4. 2. Graphic formats, 4. 3. Hybrid formats; 4. 4. Audio formats; 4. 5. Video formats; 4. 6. other format...|$|R
40|$|Resource level {{metadata}} markup alone cannot {{describe the}} rich, granular, associative and recombinant information objects potentially contained in modern digital libraries. Today, powerful mechanisms for content and structure <b>description</b> <b>of</b> <b>documents</b> {{exists in the}} form of domain specific markup languages such as MatML and MathML. Mechanisms for integrating resource level markup with domain specific markup documents in these languages are required. In the context of the NSDL GREEN digital library, issues and approaches to markup integration are critically discussed...|$|E
30|$|Classically, bag-of-words (BoW) {{methods were}} used to obtain {{representations}} of the documents in a corpus in terms of vectors of term frequencies weighted by inverse document frequency (TF-iDF). While such methods provide a statistical <b>description</b> <b>of</b> <b>documents,</b> they do not carry information about the order or proximity of words to each other since they regard word tokens in an independent manner with no semantic or syntactic relationships considered. Furthermore, BoW representations tend to be high-dimensional and sparse, due to large sizes of word dictionaries and low frequencies of many terms.|$|E
40|$|This study {{starts from}} {{conceptual}} elements developed by intellectual practices of Oral History and Oral Tradition. Its {{objective is to}} propose archival description for oral documents produced by these practices. To use conceptual elements developed by oral history and tradition, {{in the frame of}} multilevel description presented in regulation ISAD-G, is veryuseful for the information specialists. It helps to carry out the <b>description</b> <b>of</b> <b>documents</b> no only in terms of their physical characteristics but also regarding their contents, and it considers that the description work “is basically that of dividing information in comprehensible data to recover information”, thus making easier the process of consultation, research and spread of archives...|$|E
40|$|We study {{models of}} {{incomplete}} information for XML, their computational properties, and query answering. While our approach {{is motivated by}} the study of relational incompleteness, incomplete information in XML documents may appear not only as null values but also as missing structural information. Our goal {{is to provide a}} classification <b>of</b> incomplete <b>descriptions</b> <b>of</b> XML <b>documents,</b> and separate features- or groups of features- that lead to hard computational problems from those that admit efficient algorithms. Our classification of incomplete information is based on the combination of null values with partial structural <b>descriptions</b> <b>of</b> <b>documents.</b> The key computational problems we consider are consistency <b>of</b> partial <b>descriptions,</b> representability <b>of</b> complete <b>documents</b> by incomplete ones, and query answering. We show how factors such as schema information, the presence of node ids, and missing structural information affect the complexity of these main computational problems, and find robust classes <b>of</b> incomplete XML <b>descriptions</b> tha...|$|R
40|$|This paper {{introduces}} {{a new technology}} of information systems creation based on the declarative <b>descriptions</b> <b>of</b> <b>document</b> collections in RDF. This approach is intended {{to improve the quality}} of information published on Web and the interaction between various web-applications. In this framework a model <b>of</b> the <b>document</b> generation is presented, a pictorial example is provided. The benefits and disadvantages of this technology in comparison with traditional XML-based approaches are discussed...|$|R
40|$|ENS-Cachan and INRIA We study {{models of}} {{incomplete}} information for XML, their computational properties, and query answering. While our approach {{is motivated by}} the study of relational incompleteness, incomplete information in XML documents may appear not only as null values but also as missing structural information. Our goal {{is to provide a}} classification <b>of</b> incomplete <b>descriptions</b> <b>of</b> XML <b>documents,</b> and separate features- or groups of features- that lead to hard computational problems from those that admit efficient algorithms. Our classification of incomplete information is based on the combination of null values with partial structural <b>descriptions</b> <b>of</b> <b>documents.</b> The key computational problems we consider are consistency <b>of</b> partial <b>descriptions,</b> representability <b>of</b> complete <b>documents</b> by incomplete ones, and query answering. We show how factors such as schema information, the presence of node ids, and missing structural information affect the complexity of these main computational problems, and find robust classes <b>of</b> incomplete XML <b>descriptions</b> tha...|$|R
40|$|Abstract. Appropriate {{annotation}} {{of documents}} {{is a central}} aspect of efficient media management and retrieval. As ontology-based <b>description</b> <b>of</b> <b>documents</b> and facts enables exchange and reuse of metadata among communities and across applications, the annotation of personal media collections using Semantic Web technologies benefits from existing (and evolving) information sources on the Internet. This paper addresses conceptual and technical issues of Web search within community-built Semantic Web content to retrieve useful information for personal media annotation. After analyzing application scenarios, we introduce a generic and extensible Semantic Web Search Component, which facilitates specific search configurations. As a sample application, we deployed the component within our ontology-based media management system, including evaluation and remarks on {{quantity and quality of}} search results with regard to community-built Semantic Web content. ...|$|E
40|$|Prikazuje se rad na normizaciji u području identifikacije i opisa dokumenata. Opisana je redovita preradba norme ISO 3297 Information and {{documentation}} – International Standard Serial Number (ISSN). Prikazan je tijek rada i različite faze preradbe teksta norme. Izneseni su glavni elementi preradbe i rješenja Radne skupine. Navode se novine u tekstu nacrta odbora u odnosu na tekuće izdanje. The paper gives {{an outline of}} the work on standardization {{in the area of}} identification and <b>description</b> <b>of</b> <b>documents.</b> The regular revision of the standard ISO 3297 Information {{and documentation}} – International Standard Serial Number (ISSN) is described. Different phases of revision are enumerated. The main issues of the revision and the solutions proposed by the ISSN Standard Revision Working Group are presented. The new elements in the text of the committee draft are described...|$|E
40|$|The bachelor's thesis {{focuses on}} the {{historical}} development of fiction as a literary genre, from the early modern period to the present. This trend is observed in the Czech Republic and abroad. Besides the development we can find here as well the definitions of particular genres. The thesis then examines how public libraries are facing to the current trend of popularity of the fiction. The problems associated with the <b>description</b> <b>of</b> <b>documents,</b> construction of the fund, and acquisition are mentioned as well as benefits from the popularity of the genre - when libraries use fiction to their promotion. The conclusion briefly surveys current state of the book market and its share which is occupied by the fiction. In the supplement a brief list of fiction subgenres can be found...|$|E
40|$|Abstract: The {{paper is}} a limited review of {{publications}} (1995 - 2010) related {{to the problem of}} classification of clinical records presented in a free text form. The techniques of indexing and methods of classification are considered. We also pay special attention to the <b>description</b> <b>of</b> <b>document</b> sets used in the mentioned research. Finally, we conclude about the perspective research directions related with the topic...|$|R
40|$|We {{present a}} {{prototype}} of semantic browser-based annotation tool Saha, that eases the process <b>of</b> creating ontological <b>descriptions</b> <b>of</b> <b>documents</b> e. g. for semantic portals. Saha supports collaborative creation of metadata by centrally storing annotations, which can be viewed and edited by different annotators. Concepts defined in external ontologies {{can be used in}} annotations by connecting Saha to ontology servers. The tool is being tested in practical semantic portal projects...|$|R
5000|$|The first {{paragraph}} is a <b>description</b> <b>of</b> the method <b>documented.</b>|$|R
40|$|Semantic {{similarity}} between words or phrases is frequently {{used to find}} matching correlations between search queries and documents when straightforward matching of terms fails. This is particularly important for searching in visual databases, where pictures or video clips have been automatically tagged with a small set of semantic concepts based on analysis and classification of the visual content. Here, the textual <b>description</b> <b>of</b> <b>documents</b> is very limited, and semantic similarity based on WordNet’s cognitive synonym structure, along with information content derived from term frequencies, can help {{to bridge the gap}} between an arbitrary textual query and a limited vocabulary of visual concepts. This approach, termed concept-based retrieval, has received significant attention over the last few years, and its success is highly dependent on the quality of the similarit...|$|E
40|$|Numerous {{approaches}} to information modeling exist within chemical engineering representing product data, work processes, or other information. These models {{have a limited}} scope and were developed independently from each other. Thus, extended and general information models for chemical engineering are still missing as they are needed for the efficient support of work processes and {{for the development of}} domain-specific software tools. In this paper, open issues of information modeling are discussed. These are the integrated representation of information and work processes, the <b>description</b> <b>of</b> <b>documents</b> as carriers of data, and the integration of existing data models. The conceptual model framework CLiP is presented, which holds solution approaches for these three issues. Further, it can serve as an integration basis for existing information models. The paper further presents an overall architecture of a tool supporting the development and integration of information models...|$|E
40|$|As {{the use of}} {{the most}} common {{classification}} systems for the arrangement of library material gives rise to evident problems both in terms of efficiency and user-friendliness, the paper proposes to limit them to the bibliographic <b>description</b> <b>of</b> <b>documents</b> and to make reference to different classification structures specifically aimed at meeting the needs of the physical organization and local access to documents. A possible solution can be the Scientific-Disciplinary Sectors which are the principal structural references both for research and teaching activities. Such a classification, of a purely institutional type, certainly reflects the present-day university situation rather than abstract models, {{but at the same time}} it defines more concrete approaches to knowledge. Furthermore, it can be profitably used to correlate people involved in different ways in the university’s institutional activities with the bibliographic material functional to such activities, thus offering a useful parameter in appraising collections...|$|E
40|$|Abstract. The <b>description</b> <b>of</b> <b>document</b> layers, {{as well as}} <b>of</b> the <b>document</b> {{discourse}} (e. g. {{the scientific}} discourse in scholarly articles) in machine-readable forms is crucial in facilitating semantic publishing and overall comprehension <b>of</b> <b>documents</b> by both users and machines. In this paper we introduce DoCO, the Document Components Ontology, i. e., an OWL 2 DL ontology that provides a general-purpose structured vocabulary <b>of</b> <b>document</b> elements to describe document parts in RDF. In addition to the formal <b>description</b> <b>of</b> the ontology, its utility in practice is showcased through several in-house solutions and other works of the Semantic Publishing community that rely on DoCO to annotate and retrieve <b>document</b> components <b>of</b> scholarly articles...|$|R
25|$|System <b>description</b> :A <b>description</b> <b>of</b> a system, <b>documenting</b> the {{requirements}} <b>of</b> a system.|$|R
50|$|From the {{analysis}} made <b>of</b> unpublished <b>documents</b> and publications, {{as well as}} the archaeological material available both in Mexico and abroad, has been possible to develop a theory about the relationship of these caves with a complex and sophisticated mortuary ritual. This interpretation is {{based on the fact that}} the <b>descriptions</b> <b>of</b> <b>documents</b> match the archaeological material that has survived to our day, and in this comparison a number of characteristics are noted that repeat themselves throughout the centuries, which indicates a systematic disposition of the dead in pre-Hispanic times.|$|R
40|$|With {{the growth}} in the spread of {{computer}} networks the demand by users for document interchange features is becoming increasingly apparent. The prerequirement for the realization of document interchange in a heterogenous computer environment are internationally accepted standards for the <b>description</b> <b>of</b> <b>documents.</b> Already in early 1986, the Standard Generalized Markup Language SGML was published as an international standard for the structuring of documents. The publication of the Office Document Architecture ODA is expected in the course of 1988. The final text is already available. ODA was originally developed for the pure office environment, whereas the concept for SGML addressed the author/publisher environment. This fact is mirrored in the current pilot projects testing the standards: the manufacturers of office and word-processing systems mainly work with ODA, whereas in the technical scientific and publishing sectors SGML is often implemented. Users requiring an interface both to the office sector {{as well as to the}} publishing sector will therefore be confronted with the problems related to working with two different, only partially compatible standards...|$|E
40|$|Abstract. Considering {{innovation}} as {{the result}} of only spontaneous activities is a simplistic vision, because working out inspiration and reaching up to innovation need awareness and knowledge about the application domain and its problems. In this paper, we address the issue of knowledge representation, access and sharing in an enterprise context, by proposing an ontology-based framework (DocOnto) for the semantic <b>description</b> <b>of</b> <b>documents</b> involved in innovation activities. The framework, which is built within the BIVEE European project, is characterized by a customizable approach inspired by the UBL/CCTS, which allows each enterprise to refine the DocOnto at best for its needs. Then UBL-like structures are semantically lifted and used for describing concrete documents. Such a semantic representation enables reasoning services like querying and retrieving of documents, understanding similarities among documents, assessing their status and quality, monitoring innovation activities. The framework is supported by the technological integration of the iSurf eDoCreator, for modelling UBL-like documents structures, and the Production and Innovation Knowledge Repository (PIKR), the semantic knowledge hub of the BIVEE platform...|$|E
40|$|Bibliometric is an {{emerging}} thrust {{area of research}} and {{has now become a}} well established part of information research and a quantitative approach to the <b>description</b> <b>of</b> <b>documents.</b> Bibliometric has grown out of the realization that literature is growing and changing out of a rate with which no librarian or information worker equipped with traditional bibliographic skills and methods could keep abreast. The present study shows that journals are most cited form of communication amongst the library and information scientists and the source journal is the most cited publication. IFLA Journal is one of the premier official journals of the International Federation of Library Associations and Institutions. It is brought out by Sage publications. It has just completed 37 years of its publication. The study aims to present a bibliometric analysis on the various aspects of the Journal, such as its distribution of article by year, authorship patterns, distribution of contributions by institution, subject distributions, citation patterns, length of article, rank of cited authors, and geographical distributions of authors...|$|E
25|$|Service <b>description</b> :A <b>description</b> <b>of</b> a service, <b>documenting</b> the {{requirements}} that describe the service.|$|R
5000|$|... reverse relationship, <b>description</b> <b>of</b> the {{referenced}} <b>document</b> (in one case, otherwise deprecated in microformats) ...|$|R
40|$|This paper {{claims that}} Belief Revision {{can be seen}} as a {{theoretical}} framework for document ranking in Extended Boolean Models. For a model of Information Retrieval based on propositional logic, we propose a similarity measure which is equivalent to a P-Norm case. Therefore it shares the P-Norm good properties and behaviour. Besides, it is theoretically ensured that this measure follows the notion of proximity between the documents and the query. The logical model can naturally deal with incomplete <b>descriptions</b> <b>of</b> <b>documents</b> and the similarity values are also obtained for this case. ...|$|R
40|$|Purpose: Records {{catalogues}} at the National Archives of Iran and {{the level}} of their conformity with the International Standard Archival Description (ISAD). The present research is aimed at identifying descriptive elements of the archival. Methodology: Standards, and interviews are employed for gathering research data. e results are presented in tables and -gures through descriptive statistical methods (frequency and percentage). The research community included researchers and experts in arrangement and description of records, manuals, and cataloging worksheets of the archival records existing in National Library and Archives of Iran. This research was based on analytical survey. A checklist, the rules of archival Findings: The research findings also show that information elements including “Author Name” (16. 62 %) and “Descriptors” (91. 26 %) are consistent with documentation tools. 8. 8 % of these information elements are not documented at all. In the eyes of the experts of arrangement and <b>description</b> <b>of</b> <b>documents,</b> cataloging of archival documents based on ISAD has improved the methods of organizing documents. Conclusion: Applying this standardized method of archival description has led to better retrieval of the related documents. This research displays the conformity of descriptive elements in the studied worksheets...|$|E
40|$|The {{search for}} {{information}} still {{depends on the}} knowledge available on the information sought and their uses. Founded {{on the principle of}} search content, the knowledge available on the information sought will result in the specification of information needs, often in the form of research equation. This principle applies regardless of the search agent (a human being or a search engine) and whatever the source of information (formal source - Internet, databases, etc [...] informal source - humans networks, for example). The principle does not directly specify end-uses of the information sought because these uses are not included in the <b>description</b> <b>of</b> <b>documents.</b> And yet it is the knowledge on the final use of the information that indicates the degree of relevance. We will summarize how the concept of relevance is studied so far and present the concept of economic intelligence to better understand the complexity of the concept of relevance in this context. As we believe that the problems related to the adequacy of information can not be limited to research equations, we will present approaches from ongoing research on the relevance of information in economic intelligence. These approaches are both new approaches for document representation as well as new functionalities for the information retrieavl systems...|$|E
40|$|This text {{presents}} the musical life in Ło´dz´ in years 1947 – 1960 {{on the basis}} of concert programmes of The Ło´dz´ Philharmonic that belong to The Library of the University of Ło´dz´ collections. The programmes are the part of documents of social life. It is the first sample of showing the wealth of musical information in this kind of documents. It is also an opportunity to present a short historical outline of The Philharmonic {{which is one of the}} most important institutions creating cultural life of the city. There is also an outline of history of The Library of the University of Ło´dz´, where the concert programmes are acquired, prepared and circulated. One of the part of this article is devoted to general <b>description</b> <b>of</b> <b>documents</b> of social life, which are always unknown and underestimated documents. First of all, the text shows the concert programmes of The Ło´dz´ Philharmonic in which you can find a lot of very interesting musical problems. Analyzing them, one can know the work of The Philharmonic and its educational role, composers and players, musical works, Ło´dz´ melomaniacs and their needs and many other things connected with reactivation of musical and cultural life in Ło´dz´ in this period...|$|E
40|$|The use of MPI in {{implementing}} algorithms for Parallel Information Retrieval Systems is outlined. We include descriptions on methods for Indexing, Search and Update of Inverted Indexes {{as well as}} a method for Information Filtering. In Indexing we describe both local build and distributed build methods. Our <b>description</b> <b>of</b> <b>Document</b> Search includes that for Term Weighting, Boolean, Proximity and Passage Retrieval Operations. Document Update issues are centred on how partitioning methods are supported. We describe the implementation of term selection algorithms for Information Filtering and finally work in progress is outlined...|$|R
40|$|This work {{deals with}} the {{implementation}} of a logical model of Information Retrieval. Specifically, we present algorithms for document ranking within the Belief Revision framework. Therefore, the logical model that stands on the basis of our proposal can be efficiently implemented within realistic systems. Besides the inherent advantages introduced by logic, the expressiveness is extended with respect to classical systems because documents are represented as unrestricted propositional formulas. As well as representing classical vectors, the model can deal with partial <b>descriptions</b> <b>of</b> <b>documents.</b> Scenarios that can benefit from these more expressive representations are discussed...|$|R
40|$|The paper {{provides}} a semantic vector retrieval model for desktop documents {{based on the}} ontology. Comparing with traditional vector space model, the semantic model using semantic and ontology technology to solve several problems that traditional model could not overcome such as the shortcomings of weight computing based on statistical method, the expression of semantic relations between different keywords, the <b>description</b> <b>of</b> <b>document</b> semantic vectors and the similarity calculating, etc. Finally, the experimental {{results show that the}} retrieval ability of our new model has significant improvement both on recall and precision...|$|R
