313|986|Public
25|$|The <b>incremental</b> <b>method</b> {{with reduced}} {{rounding}} errors {{can also be}} applied, with some additional complexity.|$|E
25|$|If a {{polyhedral}} graph {{does not}} contain a triangular face, its dual graph does contain a triangle and is also polyhedral, so one can realize the dual in this way and then realize the original graph as the polar polyhedron of the dual realization. It is also possible to realize any polyhedral graph directly by choosing the outer face to be any face with at most five vertices (something that exists in all polyhedral graphs) and choosing more carefully the fixed shape of this face {{in such a way}} that the Tutte embedding can be lifted, or by using an <b>incremental</b> <b>method</b> instead of Tutte's method to find a liftable planar drawing that does not have equal weights for all the interior edges.|$|E
2500|$|... 1956-57 - Just outside Amboasary Sud, bestriding the Mandrare {{river at}} a 15m height, Paindavoine Sarl launch, by the <b>incremental</b> <b>method,</b> a 414 m long, design-improved and appropriate, {{licensed}} Callender-Hamilton bridge. Holding up the steel girders - six 69 m long spans - the [...] massive reinforced concrete 5 piles and 2 abuttals (some of them, on compressed air-caisson foundations) were erected by Anciens Ets Eiffel, {{who designed the}} work. The Direction Générale des Travaux Publics de Madagascar was the Owner and the Construction Supervisor. It was financed by FIDES credits (public investments' fund of the French Union Overseas Ministry) for 400 million fCFA (around US$2 million). The Pont du Mandrare provides the first all-year-long road link between the Anosy and Androy regions (RIG 13).|$|E
40|$|Current {{methods for}} {{learning}} Bayesian Networks are mainly batch methods. That is, {{they are supposed}} to act in a single step over the complete set of data. We remark the need to develop new approaches that do not require this to happen. <b>Incremental</b> <b>methods</b> do proceed on the supposition that information is fed to the algorithm in a step by step fashion. We propose a formalization for <b>incremental</b> <b>methods,</b> compare it to the most used one in other areas of machine learning and spot several specific peculiarities of Bayesian networks. Present <b>incremental</b> <b>methods</b> are reviewed and criticized in terms of the problems they present for dealing with order effects, and varying sizes of partial data sets. Finally we present BANDOLER a new framework for learning Bayesian Networks incrementally. Postprint (published version...|$|R
5000|$|<b>Incremental</b> Analysis <b>methods</b> {{start with}} the mesh of the flat blank and {{simulate}} the deformation of the blank inside of tools modeled to represent a proposed manufacturing process. This incremental forming is computed [...] "forward" [...] from initial shape to final, and is calculated {{over a number of}} time increments for start to finish. The time increments can be either explicitly or implicitly defined depending on the finite element software being applied. As the <b>incremental</b> <b>methods</b> include the model of the tooling and allow for the definition of boundary conditions which more fully replicate the manufacturing proposal, <b>incremental</b> <b>methods</b> are more commonly used for process validation. Inverse One-step with its lack of tooling and therefore poor representation of process is limited to geometry based feasibility checks.|$|R
40|$|We {{consider}} the minimization of a sum ∑ m i= 1 fi(x) {{consisting of a}} large number of convex component functions fi. For this problem, <b>incremental</b> <b>methods</b> consisting of gradient or subgradient iterations applied to single components have proved very effective. We propose new proximal versions of <b>incremental</b> <b>methods,</b> consisting of proximal iterations applied to single components, as well as combinations of gradient, subgradient, and proximal iterations. We provide a convergence and rate of convergence analysis of a variety of such methods, including some that involve randomization in the selection of components. We also discuss applications in various contexts, including signal processing and inference/machine learning. 1...|$|R
50|$|The <b>incremental</b> <b>method</b> {{with reduced}} {{rounding}} errors {{can also be}} applied, with some additional complexity.|$|E
5000|$|Where {{the work}} is contracted, Iterative Design {{provides}} an <b>incremental</b> <b>method</b> for more effectively involving the client in the complexities that often surround the design process.|$|E
5000|$|The term [...] "agile management" [...] {{is applied}} to an iterative, <b>incremental</b> <b>method</b> of {{managing}} the design and build activities of engineering, information technology and other business areas that aim to provide new product or service development in a highly flexible and interactive manner, based on the principles expressed in the Manifesto for Agile Software Development.|$|E
40|$|Recently, {{there has}} been growing {{interest}} in developing optimization methods for solving large-scale machine learning problems. Most of these problems boil down {{to the problem of}} minimizing an average of a finite set of smooth and strongly convex functions where the number of functions $n$ is large. Gradient descent method (GD) is successful in minimizing convex problems at a fast linear rate; however, it is not applicable to the considered large-scale optimization setting because of the high computational complexity. <b>Incremental</b> <b>methods</b> resolve this drawback of gradient methods by replacing the required gradient for the descent direction with an incremental gradient approximation. They operate by evaluating one gradient per iteration and executing the average of the $n$ available gradients as a gradient approximate. Although, <b>incremental</b> <b>methods</b> reduce the computational cost of GD, their convergence rates do not justify their advantage relative to GD in terms {{of the total number of}} gradient evaluations until convergence. In this paper, we introduce a Double <b>Incremental</b> Aggregated Gradient <b>method</b> (DIAG) that computes the gradient of only one function at each iteration, which is chosen based on a cyclic scheme, and uses the aggregated average gradient of all the functions to approximate the full gradient. The iterates of the proposed DIAG method uses averages of both iterates and gradients in oppose to classic <b>incremental</b> <b>methods</b> that utilize gradient averages but do not utilize iterate averages. We prove that not only the proposed DIAG method converges linearly to the optimal solution, but also its linear convergence factor justifies the advantage of <b>incremental</b> <b>methods</b> on GD. In particular, we prove that the worst case performance of DIAG is better than the worst case performance of GD...|$|R
40|$|Abstract. We {{consider}} a simple advection equation in space dimension {{one and the}} linearized shallow water equations in space dimension two and describe and implement two different mul-tilevel finite volume discretizations {{in the context of}} the utilization of the <b>incremental</b> <b>methods</b> with time explicit or semi-explicit schemes...|$|R
40|$|Maximum Power Point {{techniques}} (MPPT) of Photovoltaic array {{are used}} to continuously deliver highest possible power to the load when variation in solar irradiation and temperature occur. This is achieved by many algorithms such as perturbs and observer <b>method,</b> <b>incremental</b> conductance <b>method,</b> constant voltage method, fuzzy logic method, neural network etc. A DC/DC converter (boost, buck, Cuk) serves the purpose of transferring maximum power from the solar PV module to the load. In this project we compared perturb and observe <b>method</b> and <b>incremental</b> conductance <b>method</b> with DC-DC Buck converter by implementing hardware using Arduino Duemilanove as a prototype board. Key Words: MPPT, buck converter, solar voltage and current sensing, <b>Incremental</b> conductance <b>method</b> (INC) ...|$|R
50|$|Notably, the {{procedures}} for firing and demoting {{a member of}} the competitive service are considerable {{in order to protect the}} employment rights of the member, yet to provide the employer (the US government) a fair and <b>incremental</b> <b>method</b> to manage employees. A written notice of thirty days, a statement of reasons for dismissal, and a right to a hearing must be granted.|$|E
50|$|It {{is local}} in that each {{clustering}} {{decision is made}} without scanning all data points and currently existing clusters.It exploits the observation that data space is not usually uniformly occupied and not every data point is equally important.It makes full use of available memory to derive the finest possible sub-clusters while minimizing I/O costs.It is also an <b>incremental</b> <b>method</b> that {{does not require the}} whole data set in advance.|$|E
50|$|At first sight, policy {{experimentation}} displays commonalities with what Lindblom characterizes as the <b>incremental</b> <b>method</b> of successive limited comparisons in making public policy: the exploratory, reversible character of policymaking and the prior reduction of political antagonisms by avoiding drastic {{change at the}} outset. Yet, under certain conditions, experimentation can transcend incrementalist tinkering with existing practices and lead to drastic policy departures and transformative change marked {{by the emergence of}} new configurations of actors, interests, institutions, ideologies, and goals.|$|E
5000|$|... {{may use the}} {{information}} in the samples better, while <b>incremental</b> <b>methods</b> are the only choice when batch methods are infeasible due to their high computational or memory complexity. In addition, some methods try to combine the two approaches. Methods based on temporal differences also overcome the fourth issue.|$|R
40|$|A {{linear model}} tree is a {{decision}} tree with a linear functional model in each leaf. Previous model tree induction algorithms have operated on the entire training set, however there are many situations when an incremental learner is advantageous. In this paper we demonstrate that model trees can be induced incrementally using an algorithm that scales linearly {{with the number of}} examples. An incremental node splitting rule is presented, together with <b>incremental</b> <b>methods</b> for stopping the growth of the tree and pruning. Empirical testing in three domains, where the emphasis is on learning a dynamic model of the environment, shows that the algorithm can learn a more accurate approximation from fewer examples than other <b>incremental</b> <b>methods.</b> In addition the induced models are smaller, and the learner requires less prior knowledge about the domain. 1...|$|R
40|$|In {{longitudinal}} clinical trials, {{missing data}} are mostly related to dropouts. Some dropouts appear completely at random. The source for other dropouts is withdrawal from trials {{due to lack}} of efficacy. For the latter case, the analyses of the actual observed data and completers can produce bias. One of the approaches to comply with the intent-to-treat principle is the imputation of incomplete data. This paper deals with the <b>incremental</b> <b>methods</b> of imputation applied to incomplete longitudinal data sets with MAR drop-outs. Comparison is done between the <b>incremental</b> <b>methods</b> and some other imputation methods (including the last observation carriedforward method and linear mixed-models method) on simulated longitudinal data. The data sets are simulated to resemble time behavior of the HbA 1 c and fasting plasma glucose in diabetes clinical trials...|$|R
5000|$|... 1956-57 - Just outside Amboasary Sud, bestriding the Mandrare {{river at}} a 15m height, Paindavoine Sarl launch, by the <b>incremental</b> <b>method,</b> a 414 m long, design-improved and appropriate, {{licensed}} Callender-Hamilton bridge. Holding up the steel girders - six 69 m long spans - the massive reinforced concrete 5 piles and 2 abuttals (some of them, on compressed air-caisson foundations) were erected by Anciens Ets Eiffel, {{who designed the}} work. The Direction Générale des Travaux Publics de Madagascar was the Owner and the Construction Supervisor. It was financed by FIDES credits (public investments' fund of the French Union Overseas Ministry) for 400 million fCFA (around US$2 million). The Pont du Mandrare provides the first all-year-long road link between the Anosy and Androy regions (RIG 13).|$|E
50|$|Agile Construction {{is a way}} {{of doing}} {{business}} adapted to construction jobsites and overall project delivery, born from agile manufacturing and project management, mostly used in manufacturing production, automotive and software developing teams. It is the application of the Toyota Production System to construction, with two parallel paths: measuring (ASTM E2691) and improving productivity, and segregating and externalizing work through prefabrication and supply chain management. Like the Toyota Production System, Agile construction is a system that relies on input from the source of the work information, both up front for planning the project, as well as throughout the life of a project for real-time feedback. The real-time input produces real-time measurements of productivity. It is an iterative and <b>incremental</b> <b>method</b> of managing the design and build activities. This means that each time the process is repeated some changes are made to make the process better. Changes for the better are kept and for the worse are discarded.|$|E
5000|$|The {{mutually}} consistent field (MCF) method [...] {{had introduced}} {{the idea of}} self-consistent fragment calculations in their embedding potential, which was later used with some modifications in various methods including FMO. There had been other methods related to FMO including the incremental correlation method by H. Stoll (1992). Also FMO bears some similarity to the method by J. Gao (1997), the applicability of which for condensed phase systems was subsequently demonstrated by carrying out a statistical mechanical Monte Carlo simulation of liquid water in 1998; this method was later renamed as the explicit polarization (X-Pol) theory. The <b>incremental</b> <b>method</b> uses formally the same many-body expansion of properties as FMO, although the exact meaning of terms is different. The difference between X-Pol and FMO is in the approximation for estimating the pair interactions between fragments. X-Pol {{is closely related to}} the one-body expansion used in FMO (FMO1) in terms of the electrostatics, but other interactions are treated differently.|$|E
40|$|<b>Incremental</b> <b>methods</b> are {{successfully}} appliedtodeal with successive veri#cations {{of slightly}} modi#ed switchlevel networks. That is, only those parts a#ected by {{the changes are}} symbolically traversed for veri#cation. In this paper, we present an incremental technique for symbolic simulators which is inspired in both existing incremental techniques for non-symbolic simulators and a token-passing mechanisms in Petri nets...|$|R
40|$|Optimizing Incremental View Maintenance Expressions in Relational Databases Dimitra Vista Doctor of Philosophy Graduate Department of Computer Science University of Toronto 1996 In {{the last}} few years, there has been {{significant}} interest {{in the design of}} <b>incremental</b> <b>methods</b> to improve the performance of view maintenance. Despite that, very little analysis or experimentation supports the predominant view that <b>incremental</b> <b>methods</b> are more efficient than their non-incremental counterparts. We argue that the performance of incremental view maintenance depends on system aspects of the database, such as the availability of indices, the sizes of the relations involved, and the sizes of the database updates. We also argue that the database query optimizer is a reasonable component of the database system to decide, at the time of view maintenance, whether a view is to be maintained incrementally or not, because the query optimizer has knowledge of, and access to, all of the parameters that [...] ...|$|R
40|$|Image {{reconstruction}} in X-ray transmission tomography {{has been}} an important research field for decades. In light of data volume increasing faster than processor speeds, one needs accelerated iterative algorithms to solve the optimization problem in the X-ray CT application. <b>Incremental</b> <b>methods,</b> in which a subset of data is being used at each iteration to accelerate the computations, have been getting more popular lately in the machine learning and mathematical optimization fields. The most popular member of this family of algorithms in the X-ray CT field is ordered-subsets. Even though it performs well in earlier iterations, the lack of convergence in later iterations is a known phenomenon. In this paper, we propose two <b>incremental</b> <b>methods</b> that use Jensen surrogates for the X-ray CT application, one stochastic and one ordered-subsets type. Using measured data, we show that the stochastic variant we propose outperforms other algorithms, including the gradient descent counterparts...|$|R
5000|$|In the {{milieu of}} levering methods, {{there are those}} that lift the block incrementally, as in {{repeatedly}} prying up alternating sides of the block and inserting a wooden or stone shims to gradually move the stone up one course; {{and there are other}} methods that use a larger lever to move the block up one course in one lifting procedure. Since the discussion of construction techniques to lift the blocks attempts to resolve a gap in the archaeological and historical record with a plausible functional explanation, the following examples by Isler, Keable, and Hussey-Pailos [...] list experimentally tested methods. Isler's method (1985, 1987) is an <b>incremental</b> <b>method</b> and, in the Nova experiment (1992), used wooden shims or cribbing. Isler [...] was able to lift a block up one tier in approximately one hour and 30 minutes. Peter Hodges’s and Julian Keable’s method is similar to Isler's method and instead used small manufactured concrete blocks as shims, wooden pallets, and a pit where their experimental tests were performed. Keable was able to perform his method in approximately 2 minutes. Scott Hussey-Pailos's (2005) method [...] uses a simple levering device to lift a block up a course in one movement. This method was tested with materials of less strength than historical analogs (tested with materials weaker than those available in ancient Egypt), a factor of safety of 2, and lifted a 2500-pound block up one course in under a minute. This method is presented as a levering device to work complementary with Mark Lehner's idea of a combined ramp and levering techniques.|$|E
50|$|The Maxwell-Cremona {{correspondence}} {{has been}} used to obtain polyhedral realizations of polyhedral graphs by combining it with a planar graph drawing method of W. T. Tutte, the Tutte embedding. Tutte's method begins by fixing one face of a polyhedral graph into convex position in the plane. This face will become the outer face of a drawing of a graph. The method continues by setting up a system of linear equations in the vertex coordinates, according to which each remaining vertex should be placed at the average of its neighbors. Then as Tutte showed, this system of equations will have a unique solution in which each face of the graph is drawn as a convex polygon. The result is almost an equilibrium stress: if one assigns weight one to each interior edge, then each interior vertex of the drawing is in equilibrium. However, it is not always possible to assign negative numbers to the exterior edges so that they, too, are in equilibrium.Such an assignment is always possible when the outer face is a triangle, and so this method can be used to realize any polyhedral graph that has a triangular face.If a polyhedral graph does not contain a triangular face, its dual graph does contain a triangle and is also polyhedral, so one can realize the dual in this way and then realize the original graph as the polar polyhedron of the dual realization. It is also possible to realize any polyhedral graph directly by choosing the outer face to be any face with at most five vertices (something that exists in all polyhedral graphs) and choosing more carefully the fixed shape of this face {{in such a way that}} the Tutte embedding can be lifted, or by using an <b>incremental</b> <b>method</b> instead of Tutte's method to find a liftable planar drawing that does not have equal weights for all the interior edges.|$|E
30|$|The {{extended}} <b>incremental</b> <b>method</b> is {{used for}} the linearization of the gas physics [11]. This linearization method builds on the simple <b>incremental</b> <b>method,</b> exhibiting enhanced features and advantages as compared to standard piecewise linear approximation methods.|$|E
40|$|In {{longitudinal}} clinical trials, {{missing data}} are mostly related to dropouts. Some dropouts appear completely at random. The source for other dropouts is withdrawal from trials {{due to lack}} of efficacy. One of the approaches to comply with the intent-to-treat principle is the imputation of incomplete data. When the dropout process is related to the outcome process (informative dropouts), it creates tremendous challenges in analyzing such data. No commercial software currently considers the dropout mechanisms in dealing with informative or non-random dropout. Consequently, the results can be biased and misleading. This paper deals with the <b>incremental</b> <b>methods</b> of imputation applied to incomplete longitudinal data sets with informative dropouts. It is shown by simulation that the <b>incremental</b> <b>methods</b> are more precise than some other imputation methods (including the last observation carried forward method, the multiple imputation method, mixed models). The drop-out mechanism depends on individual previously and currently observed values of a secondary endpoint correlated with the primary endpoint...|$|R
40|$|We {{propose the}} notion of {{rewriting}} modules {{in order to provide}} a structural and hierarchical approach of TRS. We define then relative dependency pairs built upon these modules which allow us to perform termination proofs incrementally. Important results can be expressed in that new framework (regarding CE -termination for instance), and with help of extendable orderings, we give effective new <b>incremental</b> <b>methods</b> for proving termination particularly suited for automation. ...|$|R
40|$|New {{supercomputers}} {{depend upon}} parallel architectures {{to achieve their}} high rate of computation. In order {{to take advantage of}} the power of such a machine, programs must be executed in parallel, that is, parts of the program must execute on different processors. When a program is executed in parallel it is impossible to guarantee the execution order of the parts of the program being executed by different processors. Dependence analysis identifies the statements whose execution order must be preserved in order for the program to be correct. Making available the results of dependence analysis in an interactive programming environment can aid a programmer in writing programs which will execute more efficiently on a parallel machine. In order to provide the results of dependence analysis to the programmer in as timely a manner as possible, <b>incremental</b> <b>methods</b> of dependence analysis have been developed. The performance of these algorithms has been estimated based on static measurements of F scORTRAN programs. This dissertation presents the <b>incremental</b> <b>methods</b> and the results of estimates of their performance...|$|R
30|$|First of all, {{it should}} be {{mentioned}} that the <b>incremental</b> <b>method</b> as basis of the extended <b>incremental</b> <b>method</b> {{is just one of}} various methods to linearize nonlinear functions. MIP-relaxations may be formulated with alternative methods, for instance with a convex combination model that introduces only a number of extra binary variables and constraints that is logarithmic in the number of breakpoints [18]. However, the <b>incremental</b> <b>method</b> is used in this paper, since it performs best for gas transport problems [5, 17, 19].|$|E
40|$|This {{technical}} report describes an <b>incremental</b> <b>method</b> that allows to add security mechanisms to an existing, but insecure system, {{such as a}} prototype or a legacy system. The <b>incremental</b> <b>method</b> is presented and as a showcase its application is demonstrated at {{the example of a}} Webbased information system...|$|E
40|$|This paper {{reports on}} an <b>incremental</b> <b>method</b> that allows adding {{security}} mechanisms to an existing, but insecure system, {{such as a}} prototype or a legacy system. The <b>incremental</b> <b>method</b> is presented and as a showcase its application is demonstrated at {{the example of a}} Web-based information system. Comment: 5 pages, 0 figure...|$|E
40|$|Enabling the {{execution}} of Java applications on personal embedded devices could bring great benefits to their users. For example, you could exchange your calendar application with your neighbor, or send your favorite telephone game to your friends without thinking {{if they have a}} compatible phone. Moreover, these devices will have to provide a reliable execution environment as soon as they will be implied in critical or distributed applications. Checkpoints capture/rollback recovery solves a part of this problem. This paper presents the integration of a checkpoint mech­anism in our own embedded Java Virtual Machine named Scratchy. Our mechanism, is transparent for the user and has a low overhead on the applications. We propose one global and two <b>incremental</b> <b>methods</b> which are evaluated and compared each other. This mechanism can be used with the midlets which are the standard Java applications for cell phones and PDAs. We present two series of evaluations, the first is done with a benchmark and the second with real applications. We show that the <b>incremental</b> <b>methods</b> give shorter capture times than the global method, under certain conditions...|$|R
30|$|According to the {{differences}} of basic data learning <b>method,</b> <b>incremental</b> learning <b>method</b> can be sorted as there categories: incremental decision tree, incremental Bayesian and incremental SVM. According {{to the number}} of new instances to be added in a model at a time, it can be sorted as instance-by-instance learning and block-by-block learning.|$|R
40|$|<b>Incremental</b> {{subspace}} <b>methods</b> {{have proven}} to enable efficient training if large amounts of training data have to be processed or if not all data is available in advance. In this paper we focus on incremental LDA learning which provides good classification results while it assures a compact data representation. In contrast to existing <b>incremental</b> LDA <b>methods</b> we additionally consider reconstructive information when incrementally building the LDA subspace. Hence, we get a more flexible representation that is capable to adapt to new data. Moreover, this allows to add new instances to existing classes {{as well as to}} add new classes. The experimental results show that the proposed approach outperforms other <b>incremental</b> LDA <b>methods</b> even approaching classification results obtained by batch learning. ...|$|R
