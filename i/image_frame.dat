537|2143|Public
25|$|A literal {{term for}} SSTV is {{narrowband}} television. Analog broadcast television requires at least 6MHz wide channels, because it transmits 25 or 30 picture {{frames per second}} (in the NTSC, PAL or SECAM color systems), but SSTV usually only takes up {{to a maximum of}} 3kHz of bandwidth. It is a much slower method of still picture transmission, usually taking from about eight seconds to a couple of minutes, depending on the mode used, to transmit one <b>image</b> <b>frame.</b>|$|E
25|$|An {{advanced}} {{application of}} DSA is road mapping. From the acquired DSA sequence, the <b>image</b> <b>frame</b> with maximum vessel opification is identified and assigned {{to be the}} so-called road-map mask. This mask is continuously subtracted from live fluoroscopy images to produce real-time subtracted fluoroscopic images overlaid on a static image of the vasculature. The clinical benefit is better visualization of small and complex vascular structures without distracting underlying tissue to support the placement of catheters and wires.|$|E
5000|$|GIF: Support for {{decoding}} and rendering compressed Graphics Interchange Format (GIF) images, in its single-frame variants only. Loading a multi-frame GIF will display {{only the}} first <b>image</b> <b>frame.</b>|$|E
3000|$|...,[*]α) {{represents}} transition algorithm. It can {{be found}} that the complex <b>image</b> <b>frames</b> are proportional to the degree and feature matching. This shows that more space, time, and computation must be paid {{in order to get}} more features to match the <b>image</b> <b>frames.</b>|$|R
30|$|A few <b>image</b> <b>frames</b> {{with minimal}} camera motion is {{selected}} from the image sequence. By doing this, image redundancy is addressed as <b>image</b> <b>frames</b> having large camera motion between them have less amount of overlapping object regions. So, adding two frames with large camera motion does not give many corresponding points.|$|R
30|$|The {{characteristics}} of real-time target <b>image</b> <b>frames</b> would be extracted.|$|R
5000|$|Third, analog video {{signals are}} {{interlaced}} - each <b>image</b> (<b>frame)</b> is sent as two [...] "fields", each {{with half the}} lines. Thus pixels are either twice as tall as they would be without interlacing, or the image is deinterlaced.|$|E
50|$|Pillarboxing (reversed letterboxing) is {{the display}} of an image within a wider <b>image</b> <b>frame</b> by adding lateral mattes (vertical bars at the sides); for example, a 1.33:1 image has lateral mattes when {{displayed}} on a 16:9 aspect ratio television screen.|$|E
5000|$|By convention, {{in still}} photography, the normal lens for a {{particular}} format has a focal length approximately equal {{to the length of}} the diagonal of the <b>image</b> <b>frame</b> or digital photosensor. In cinematography, a lens of roughly twice the diagonal is considered [...] "normal".|$|E
3000|$|The {{input to}} the system is a {{sequence}} of grey scale <b>image</b> <b>frames</b> from a video of a maritime scene. The output {{of the system is}} ideally the same set of <b>image</b> <b>frames</b> with various maritime objects of interest highlighted by a level set contour. An overview of how the system functions is as follows: [...]...|$|R
40|$|A {{vision system}} has been {{developed}} that recognizes and tracks multiple vehicles from sequences of gray-scale images taken from a moving car in hard real time. Recognition is accomplished by combining the analysis of single <b>image</b> <b>frames</b> with {{the analysis of the}} motion information provided by multiple consecutive <b>image</b> <b>frames.</b> In single <b>image</b> <b>frames,</b> cars are recognized by matching deformable gray-scale templates, by detecting image features, such as corners, and by evaluating how these features relate to each other. Cars are also recognized by differencing consecutive <b>image</b> <b>frames</b> and by tracking motion parameters that are typical for cars. The vision system utilizes the hard real-time operating system Maruti which guarantees that the timing constraints on the various vision processes are satisfied. The dynamic creation and termination of tracking processes optimizes the amount of computational resources spent and allows fast detection and tracking of multiple cars. Experimental results [...] ...|$|R
40|$|This paper {{introduces}} a spatio-temporal technique for selecting or filtering out lower quality digital <b>image</b> <b>frames.</b> The technique is demonstrated on Electro-Optical/Infrared image sequences which suggests it {{is a candidate}} for exploiting reconnaissance (recce) imagery or can be part of a recce subsystem. For human vision exploitation, a few poor quality <b>image</b> <b>frames</b> out of hundreds in a digital image sequence may be only a minor irritation when the sequence runs at the typical 30 frames per second. Of course, if that human needs to examine each frame, a system that automatically removes or enhances lower quality <b>image</b> <b>frames</b> could be beneficial. For machine vision subsystems, a few poor quality <b>image</b> <b>frames</b> could cause lower probability of recognition. The filtering technique introduced in this paper can improve input into machine vision algorithms. Another application for this technique is digital transmission to filter out unwanted images prior to transmission or to selectively enha [...] ...|$|R
5000|$|In lossy {{predictive}} codecs, previous and/or subsequent decoded data is used {{to predict}} the current sound sample or <b>image</b> <b>frame.</b> The error between the predicted data and the real data, together with any extra information needed to reproduce the prediction, is then quantized and coded.|$|E
50|$|Super 35 (originally {{known as}} Superscope 235) is a motion picture film format that uses {{exactly the same}} film stock as {{standard}} 35 mm film, but puts a larger <b>image</b> <b>frame</b> on that stock by using the negative space normally reserved for the optical analog sound track.|$|E
50|$|Whereas {{the image}} circle of a {{standard}} lens usually just covers the image frame,a lens that provides tilt or shift must allow for displacement of the lens axis {{from the center of}} the <b>image</b> <b>frame,</b> and consequently requires a larger image circle than a standard lens of the same focal length.|$|E
40|$|A video based {{method to}} detect {{volatile}} organic compounds (VOC) leaking out of process equipments used in petrochemical refineries is developed. Leaking VOC plume from a damaged component causes edges present in <b>image</b> <b>frames</b> loose their sharpness. This leads to {{a decrease in the}} high frequency content of the image. The background of the scene is estimated and decrease of high frequency energy of the scene is monitored using the spatial wavelet transforms of the current and the background images. Plume regions in <b>image</b> <b>frames</b> are analyzed in low-band sub-images, as well. <b>Image</b> <b>frames</b> are compared with their corresponding low-band images. A maximum likelihood estimator (MLE) for adaptive threshold estimation is also developed in this paper. © 2008 IEEE...|$|R
3000|$|A {{digital input}} filter, RTSP, that captures <b>image</b> <b>frames</b> from an IP camera using RTSP/RTP for transmission; [...]...|$|R
40|$|We {{address the}} problem of {{restoring}} a high-quality image from an observed image sequence strongly distorted by atmospheric turbulence. A novel algorithm is proposed in this paper to reduce geometric distortion as well as space-and-time-varying blur due to strong turbulence. By considering a suitable energy functional, our algorithm first obtains a sharp reference image and a subsampled image sequence containing sharp and mildly distorted <b>image</b> <b>frames</b> with respect to the reference image. The subsampled image sequence is then stabilized by applying the Robust Principal Component Analysis (RPCA) on the deformation fields between <b>image</b> <b>frames</b> and warping the <b>image</b> <b>frames</b> by a quasiconformal map associated with the low-rank part of the deformation matrix. After <b>image</b> <b>frames</b> are registered to the reference image, the low-rank part of them are deblurred via a blind deconvolution, and the deblurred frames are then fused with the enhanced sparse part. Experiments have been carried out on both synthetic and real turbulence-distorted video. Results demonstrate that our method is effective in alleviating distortions and blur, restoring image details and enhancing visual quality. Comment: 21 pages, 24 figure...|$|R
50|$|In HTML, longdesc is an {{attribute}} used within the image element, frame element, or iframe element. It {{is supposed to}} be a URL to a document that provides a long description for the <b>image,</b> <b>frame,</b> or iframe in question. Note that this attribute should contain a URL, and not as is commonly mistaken, the text of the description itself.|$|E
50|$|The dot {{that was}} green on negatives was red on slide film and so stereo hobbyists could tell which chip was the left frame aftercutting the film {{by looking for}} the red dot. Because many slide mounts were {{designed}} for an <b>image</b> <b>frame</b> taller than the Nimslo frame this red dot was sometimes visible in the picture.|$|E
50|$|Each 2D <b>image</b> <b>frame</b> is {{supplemented}} with a greyscale depth map which indicates if a specific pixel in the 2D image {{needs to be}} shown {{in front of the}} display (white) or behind the screen plane (black). The 256 greyscales can build a smooth gradient of depth within the image. Processing within the monitor used this input to render the multiview images.|$|E
2500|$|Teletext {{information}} is broadcast in the {{vertical blanking interval}} between <b>image</b> <b>frames</b> in a broadcast television signal, in numbered [...] "pages." ...|$|R
50|$|A DynaScan 360 is a {{cylindrical}} LED display device, {{designed to}} minimize the number of light-emitting diodes used to display <b>image</b> <b>frames.</b>|$|R
40|$|Fitting {{an image}} block with {{ordinary}} discrete orthogonal polynomials results in large errors at {{and around the}} block center. However, using discrete orthogonal polynomials gen-eralized with a normal weight, we have smaller errors at and around the center. In this paper, we show a technique estimating block motion in two successive <b>image</b> <b>frames</b> rising thegeneralized polynomials. The technique fits blocks of two <b>image</b> <b>frames</b> with the polynomi-als and derives constraints from which translational motion components can be determined...|$|R
50|$|Initiatied in 2007, the sound:frame festival {{has been}} staged {{annually}} in Vienna, Austria. The festival activities {{focus on the}} link between auditive and visual media {{in the context of}} art and culture (interdisciplinarity). The name sound:frame stands for the combination and the equal importance of music (sound = the smallest component of music) and moving <b>image</b> (<b>frame</b> = single film frame).|$|E
50|$|For LCD {{monitors}} the pixel brightness changes are much slower than CRT or plasma phosphors. Typically LCD pixel brightness changes are faster when voltage is applied than when voltage is removed, {{resulting in an}} asymmetric pixel response time. With 3D shutter glasses this {{can result in a}} blurry smearing of the display and poor depth perception, due to the previous <b>image</b> <b>frame</b> not fading to black fast enough as the next frame is drawn.|$|E
50|$|A literal {{term for}} SSTV is {{narrowband}} television. Analog broadcast television requires at least 6 MHz wide channels, because it transmits 25 or 30 picture {{frames per second}} (in the NTSC, PAL or SECAM color systems), but SSTV usually only takes up {{to a maximum of}} 3 kHz of bandwidth. It is a much slower method of still picture transmission, usually taking from about eight seconds to a couple of minutes, depending on the mode used, to transmit one <b>image</b> <b>frame.</b>|$|E
3000|$|... [18], {{which is}} used to {{describe}} the regional structure of an image that is used to model the regional change in the <b>image</b> <b>frames</b> over time.|$|R
5000|$|... 85 mm: Portrait — A short {{telephoto}} lens {{that allows a}} longer subject to camera distance, to produce pleasing perspective effects, while maintaining useful <b>image</b> <b>framing.</b>|$|R
40|$|Abstract [...] A medical {{workstation}} {{has been}} developed for the efficient display and analysis of large sets of digital cineradiographic images. Various features aid the clinician in quickly identifying and extracting the image information relevant for diagnosis: animated viewing of <b>image</b> <b>frames,</b> a digital magnifying glass for local image enlargement and enhancement, a special review queue for critical <b>image</b> <b>frames,</b> and task-oriented <b>image</b> processing. Double <b>frame</b> buffering and direct memory addressing ensure fast, artifact-free image display and transfer. Much freedom is provided for adapting the system to one’s own preferences. A statistical analysis of extensive tests conducted by eight clinical expert reviewers is given...|$|R
5000|$|AFR {{belongs to}} a class of {{parallel}} rendering methods, which subdivide a four-dimensional <b>image</b> <b>frame</b> sequence (x,y,z and time) into smaller regions, {{each of which is}} then assigned to a different physical processor within a multi-processor array. Note that the regional boundaries may be defined in space or in time. Also, the multiple processors can be implemented within a single video card or separate video graphics cards can be combined, subject to the motherboard and I/O slot limitations. When separate video cards are used, they must be specifically designed to allow a [...] "cross-link" [...] between them.|$|E
5000|$|The {{scanning}} system: progressive scanning (p) or {{interlaced scanning}} (i). Progressive scanning (p) redraws an <b>image</b> <b>frame</b> (all of its lines) when refreshing each image, for example 720p/1080p. Interlaced scanning (i) draws the image field every other line or [...] "odd numbered" [...] lines {{during the first}} image refresh operation, and then draws the remaining [...] "even numbered" [...] lines during a second refreshing, for example 1080i. Interlaced scanning yields greater image resolution if subject is not moving, but loses {{up to half of}} the resolution and suffers [...] "combing" [...] artifacts when subject is moving.|$|E
50|$|Conventional, widefield {{microscopy}} {{is generally}} unsuitable for imaging thick tissue because {{the images are}} corrupted by a blurred, out-of-focus background signal. Endomicroscopes achieve optical sectioning (removal of the background intensity) using the confocal principle - each <b>image</b> <b>frame</b> is assembled in a point-by-point fashion by scanning a laser spot rapidly over the tissue. In table-top confocal microscopes the scanning is usually performed using bulky galvanometer or resonant scanning mirrors. Endomicroscopes either have a miniaturised scanning head at the distal tip of the imaging probe, or perform the scanning outside of the patient and use an imaging fibre bundle to transfer the scan pattern to the tissue.|$|E
50|$|C-HTML {{does not}} support tables, image maps, {{multiple}} fonts and styling of fonts, background colors and <b>images,</b> <b>frames,</b> or style sheets, and {{is limited to a}} monochromatic display.|$|R
40|$|Efficient {{representation}} of the background texture in video <b>image</b> <b>frames,</b> motivates com-pression strategies based on good perceptual reconstruction quality, instead of just bit-accurate reconstruction. This {{is especially true for}} video <b>image</b> <b>frames</b> in applications such as videos with structural patterns, and Bi-Directional Reflectance Distribution Func-tion (BRDF) <b>image</b> <b>frames</b> of an object, where different images of an object in a single pose are taken in different illumination conditions. This paper investigates a new approach for an efficient {{representation of}} a class of images from textured videos and different BRDF images of an object, using sparse {{representation of the}} Directional Empirical Mode Decom-position (DEMD) residue of the frame. The efficient representation of the DEMD residue is achieved as a sparse coding solution based on a Discrete Wavelet Transform (DWT) -based sparsification. Experimental results demonstrate the effectiveness of the algorithm showing higher compression as compared to standard wavelet-based image compression schemes in a Compressive Sensing (CS) framework and JPEG 2000, at similar perceptual reconstruction quality...|$|R
3000|$|At each user-click of the tip-electrode, {{automatic}} tracking commences between the diastolic and systolic <b>image</b> <b>frames</b> determined in Section 2.1. Two cropped window sizes are first defined: (i) a [...]...|$|R
