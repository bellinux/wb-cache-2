2|6|Public
40|$|In this paper, {{we present}} RegNet, the first deep {{convolutional}} neural network (CNN) to infer a 6 degrees of freedom (DOF) extrinsic calibration between multimodal sensors, exemplified using a scanning LiDAR and a monocular camera. Compared to existing approaches, RegNet casts all three conventional calibration steps (feature extraction, feature matching and global regression) into a single real-time capable CNN. Our method does not require any human interaction and bridges the gap between classical offline and target-less online calibration approaches as it provides both a stable initial estimation as well as a continuous online correction of the extrinsic parameters. During training we randomly <b>decalibrate</b> our system in order to train RegNet to infer the correspondence between projected depth measurements and RGB image and finally regress the extrinsic calibration. Additionally, with an iterative execution of multiple CNNs, that are trained on different magnitudes of decalibration, our approach compares favorably to state-of-the-art methods in terms of a mean calibration error of 0. 28 degrees for the rotational and 6 cm for the translation components even for large decalibrations up to 1. 5 m and 20 degrees. Comment: published in IEEE Intelligent Vehicles Symposium, 201...|$|E
40|$|Today digital sources supply an {{unprecedented}} component of human sensorimotor data, {{the consumption of}} which is correlated with poorly understood maladies such as Internet Addiction Disorder and Internet Gaming Disorder. This paper offers a mathematical understanding of human sensorimotor processing as multiscale, continuous-time vibratory interaction. We quantify human informational needs using the signal processing metrics of entropy, noise, dimensionality, continuity, latency, and bandwidth. Using these metrics, we define the trust humans experience as a primitive statistical algorithm processing finely grained sensorimotor data from neuromechanical interaction. This definition of neuromechanical trust implies that artificial sensorimotor inputs and interactions that attract low-level attention through frequent discontinuities and enhanced coherence will <b>decalibrate</b> a brain's representation of its world {{over the long term}} by violating the implicit statistical contract for which self-calibration evolved. This approach allows us to model addiction in general as the result of homeostatic regulation gone awry in novel environments and digital dependency as a sub-case in which the decalibration caused by digital sensorimotor data spurs yet more consumption of them. We predict that institutions can use these sensorimotor metrics to quantify media richness to improve employee well-being; that dyads and family-size groups will bond and heal best through low-latency, high-resolution multisensory interaction such as shared meals and reciprocated touch; and that individuals can improve sensory and sociosensory resolution through deliberate sensory reintegration practices. We conclude that we humans are the victims of our own success, our hands so skilled they fill the world with captivating things, our eyes so innocent they follow eagerly. Comment: 59 pages, 14 figure...|$|E
40|$|Abstract â€” This paper {{describes}} our {{stereo vision}} method which is combining an omnidirectional and a perspective camera. It {{was developed for}} our robot soccer team 1. RFC Stuttgart, which attends RoboCup competitions every year. The common approach to stereovision leads to high deviations from the real positions {{when it is not}} possible to synchronize the cameras for tracking moving objects and when the orientations of the cameras of a soccer playing robot can be <b>decalibrated</b> during a game. Therefore we introduce an object localization for the RoboCup scenario combining the most accurate position information from each camera system. Our method for a reliable three-dimensional position estimation can be used to track a flying ball after being kicked by a robot. I...|$|R
40|$|Planetary imaging from {{unmanned}} spacecraft, {{almost exclusively}} done by digital systems, is examined. The Mars Mariner 9 television camera, representative of such systems, is considered. Each image consists of 700 lines, each containing 832 picture elements, or pixels. Each pixel contains nine binary {{bits of information}} capable of displaying 512 discrete brightness levels. Several problems inherent in television systems are discussed. These include nonuniform target response, residual images, noise, and blemishes. These defects can be removed to some extent by decalibration of the image. The final product is geometrically corrected for camera distortion and photometrically corrected. Several versions of the <b>decalibrated</b> images are available. The most generally useful are the geometrically corrected images with enhanced contrast. The Mariner 10 imaging of Mercury is briefly discussed...|$|R
40|$|Surface {{temperatures}} and ice evaporation rates are calculated for Ganymede and Callisto as functions of latitude, time of day, and albedo, {{according to a}} model that uses surface thermal properties determined by eclipse radiometry and albedos determined from photometrically <b>decalibrated</b> Voyager images. The difference in temperature between Ganymede and Callisto is not great enough {{to account for the}} lack of bright polar caps on Callisto, which seems instead to reflect a real deficiency in the amount of available water frost relative to Ganymede. The temperature difference between Ganymede's grooved and cratered terrains also cannot account for the high concentration of bright ray craters in the former, suggesting that an internal geologic process has enriched the grooved terrain in ice content relative to the cratered terrain...|$|R
40|$|The ground data {{processing}} system for the HRSC and WAOSS stereo scanner systems on board the Russian Mars 94 / 96 missions is currently being developed by DLR. The system involves software to generate decompressed, <b>decalibrated,</b> and geometrically corrected standard photo products for expected 200 GB of image data, and in addition DEMs, orthoimages and various topographic and thematic image maps for selected imagery. Other software is being developed {{for the analysis of}} compositional properties of the surface and for studies of the Martian atmosphere. all software will be based on the VICAR/SPICE environment and will be designed to operate on the hardware platforms DEC AXP, SUN, and SG. Data will be archived on CD-ROMs in PDS formats to facilitate data exchange among an international team of experiment Co-Investigators...|$|R
40|$|The {{ubiquity of}} {{approximately}} sparse data has led {{a variety of}} com- munities to great interest in compressed sensing algorithms. Although these are very successful and well understood for linear measurements with additive noise, applying them on real data can be problematic if imperfect sensing devices introduce deviations from this ideal signal ac- quisition process, caused by sensor decalibration or failure. We propose a message passing algorithm called calibration approximate message passing (Cal-AMP) that can treat a variety of such sensor-induced imperfections. In addition to deriving the general form of the algorithm, we numerically investigate two particular settings. In the first, {{a fraction of the}} sensors is faulty, giving readings unrelated to the signal. In the second, sensors are <b>decalibrated</b> and each one introduces a different multiplicative gain to the measures. Cal-AMP shares the scalability of approximate message passing, allowing to treat big sized instances of these problems, and ex- perimentally exhibits a phase transition between domains of success and failure. Comment: 27 pages, 9 figure...|$|R
40|$|Visual SLAM is, {{in recent}} years, {{a very active}} {{research}} area, the result of activities in the convergence of the robotics and computer vision communities. We present an overview of techniques, from classical filtering to bundle adjustment solutions, for both monocular and stereo (or multicamera) systems, and emphasize that classical SLAM solutions have been discarding precious sensory information. In particular, the ability of vision to sense objects at infinity should be exploited at its maximum because it is precisely these remote objects that will provide long-term, stable angular references (in the way a compass would do). Monocular SLAM systems have already solved this issue, but stereo and multicamera systems have not. We propose in these cases to use monocular SLAM algorithms using fusion to incorporate all the information. Numerous advantages like desynchronization of the sensors firing, {{the possibility of using}} several unequal cameras, or selfcalibration, will naturally arise. We develop a particular method for extrinsically <b>decalibrated</b> stereo systems to illustrate the proposed ideas. We evaluate the method with a real indoor experiment, and highlight and discuss both its assets and drawbacks...|$|R

