141|743|Public
25|$|A high {{proportional}} gain {{results in}} a large change in the output for a given change in the error. If the proportional gain is too high, the system can become unstable (see the section on loop tuning). In contrast, a small gain {{results in a}} small output response to a large <b>input</b> <b>error,</b> and a less responsive or less sensitive controller. If the proportional gain is too low, the control action may be too small when responding to system disturbances. Tuning theory and industrial practice indicate that the proportional term should contribute {{the bulk of the}} output change.|$|E
2500|$|A {{fuzzy set}} is defined for the <b>input</b> <b>error</b> {{variable}} [...] "e", and the derived change in error, [...] "delta", {{as well as}} the [...] "output", as follows: ...|$|E
50|$|Three {{sources of}} error can cause weak {{correlation}} during calibration: <b>input</b> <b>error,</b> model error, and parameter error. In general, <b>input</b> <b>error</b> and parameter error {{can be adjusted}} easily by the user. Model error however {{is caused by the}} methodology used in the model and may not be as easy to fix. Simulation models are typically built using several different modeling theories that can produce conflicting results. Some models are more generalized while others are more detailed. If model error occurs as a result, in may be necessary to adjust the model methodology to make results more consistent.|$|E
40|$|The diploma {{thesis is}} focused on two {{localization}} algorithms, iterative algorithm, and a linked algorithm simulated in MATLAB. Further, {{the investigation of the}} influence of <b>input</b> <b>errors</b> on the errors in localization of sensor nodes examined algorithms and explore possible relationships between the <b>input</b> <b>errors</b> and localization errors. Subsequently are submitted possible ways to optimize and their results...|$|R
5000|$|Correction of <b>input</b> <b>errors</b> via a [...] "Did {{you mean}} ...?" [...] function.|$|R
30|$|Our {{system must}} provide {{intuitive}} revisions and modification functions {{to correct the}} <b>input</b> <b>errors.</b>|$|R
50|$|A fat-finger {{error is}} a {{keyboard}} <b>input</b> <b>error</b> {{in the financial}} markets such as the stock market or foreign exchange market whereby an order to buy or sell is placed of far greater size than intended, for the wrong stock or contract, at the wrong price, or with any number of other input errors.|$|E
50|$|OpenDatcom is an {{open-source}} GUI for the Digital DATCOM {{created and}} {{hosted by the}} OpenAE http://openae.org/software community. OpenDatcom incorporates all the basic (non-experimental) functionality supported by the Digital DATCOM while providing real-time <b>input</b> <b>error</b> and bounds checking. An alpha version {{of the program was}} released November 1, 2009 to the general public. The OpenAE.org web site is no longer active.|$|E
50|$|The use of OMR is {{not limited}} to schools or data {{collection}} agencies; many businesses and health care agencies use OMR to streamline their data input processes and reduce <b>input</b> <b>error.</b> OMR, OCR, and ICR technologies all provide a means of data collection from paper forms. OMR may also be done using an OMR (discrete read head) scanner or an imaging scanner.|$|E
5000|$|Acknowledgement of {{the order}} by {{electronic}} means without undue delay, and information of how to amend any <b>input</b> <b>errors</b> made.|$|R
3000|$|... <b>input</b> <b>errors,</b> e.g. with {{files that}} do not respect the schema. These are common in practice, and can {{influence}} the validation process [24, 30].|$|R
3000|$|Note that, as the {{interleaving}} {{operation is}} mainly integrated to disperse the <b>input</b> <b>errors</b> that are contiguous, other configurations to an interleaving depth (i.e., k [...]...|$|R
50|$|Precise {{control of}} the system is essential. If the line speed of web is reduced, the amount of lateral {{displacement}} error that can be controlled by the steering guide system also decreases. If the <b>input</b> <b>error</b> decreases, the lateral displacement error also becomes smaller. Lateral displacement occurs on the transport web by the air blow from the dryer and the increase of blowing frequency can reduce the lateral displacement.|$|E
5000|$|... eBanking: an aid {{to reduce}} {{administration}} costs and manual <b>input</b> <b>error</b> as well as improve productivity and cash management in a security-enhanced environment. Routine accounting tasks are moved online and bank transactions are electronically enabled and reconciled. Transactions are applied to accounts when they occur rather than days or weeks later, such as BACS payments or payment collections via Direct Debits or credit cards. Special feature verifies that sort codes and bank account numbers entered for suppliers and customers make sense.|$|E
50|$|Burke-Fisher repair {{attempts}} to continue parsing by 'backing up' to 'k' parse tokens before the error point, {{and attempting to}} substitute all possible tokens into all positions from that point {{to the point where}} the error was detected. This procedure is adopted because the point at which an error is detected may not be the point of the actual <b>input</b> <b>error.</b> For instance, the string 'Look up below' might be detected as invalid when 'below' is encountered, but the true error might be that 'up' has been written where 'down' was intended.|$|E
50|$|User data {{inconsistencies}} {{can also}} occur due to simple manual <b>input</b> <b>errors,</b> non-standard nomenclature, or name changes {{that might not}} be identically updated across all systems.|$|R
40|$|The {{problem of}} variational data {{assimilation}} for a nonlinear evolution model {{is considered to}} identify the initial condition. An equation for the error of the optimal solution through the statistical <b>errors</b> of <b>input</b> data is derived, based on the Hessian of the misfit functional and second-order adjoint techniques. The covariance operator of the optimal solution error is expressed through the covariance operators of <b>input</b> <b>errors.</b> Numerical algorithms are developed for constructing the covariance operator of the optimal solution error using the covariance operators of <b>input</b> <b>errors...</b>|$|R
30|$|Chen, T., Y. Yesilada, and S. Harper, What <b>input</b> <b>errors</b> do you experience? Typing and {{pointing}} errors of mobile Web users. Int. J. Hum.-Comput. Stud., 2010. 68 (3): p. 138 – 157.|$|R
50|$|A high {{proportional}} gain {{results in}} a large change in the output for a given change in the error. If the proportional gain is too high, the system can become unstable (see the section on loop tuning). In contrast, a small gain {{results in a}} small output response to a large <b>input</b> <b>error,</b> and a less responsive or less sensitive controller. If the proportional gain is too low, the control action may be too small when responding to system disturbances. Tuning theory and industrial practice indicate that the proportional term should contribute {{the bulk of the}} output change.|$|E
5000|$|Molpro was {{designed}} and maintained by Wilfried Meyer and Peter Pulay in the late 1960s. At that moment, Pulay developed the first analytical gradient code called Hartree-Fock (HF), and Meyer researched his PNO-CEPA (pseudo-natural orbital coupled-electron pair approximation) methods. In 1980, Werner and Meyer developed a new state-averaged, quadratically convergent (MC-SCF) method, which provided geometry optimization for multireference cases. [...] By the same year, the first internally contracted multireference configuration interaction (IC-MRCI) program was developed by Werner and Reinsch. About four years later (1984), Werner and Knowles developed on a new generation program called CASSCF (complete active space SCF). This new CASSCF program combined fast orbital optimization algorithms with determinant-based full CI codes, and additional, more general, unitary group configuration interaction (CI) codes. This resulted in the quadratically convergent MCSCF/CASSCF code called MULTI, [...] which allowed modals to be optimized a weighted energy average of several states, and is capable of treating both completely general configuration expansions. In fact, this method is still available today. In addition to these organizational developments, Knowles and Werner started to cooperate on a new, more efficient, IC-MRCI method. Extensions for accurate treatments of excited states became possible through a new IC-MRCI method. In brief, the present IC-MRCI will be described as MRCI. These recently developed MCSCF and MRCI methods resulted in {{the basis of the}} modern Molpro. In the following years, a number of new programs were added. Analytic energy gradients can be evaluated with coupled-cluster calculations, density functional theory (DFT), as well as many other programs. These structural changes make the code more modular and easier to use and maintain, and also reduces the probability of <b>input</b> <b>error.</b>|$|E
40|$|Algorithms for model {{reference}} {{adaptive control}} {{were developed in}} recent years, and their stability and convergence properties have been investigated. Typical algorithms in continuous time involve strictly positive real conditions on the reference model, while similar discrete time algorithms do not require such conditions. It is shown how algorithms differ {{by the use of}} an <b>input</b> <b>error</b> versus an output error, and present a continuous time <b>input</b> <b>error</b> adaptive control algorithm which does not involve SPR conditions. The connections with other schemes are discussed. The <b>input</b> <b>error</b> scheme has general stability and ocnvergence properties that are similar to the output error scheme. However, analysis using averaging methods reveals some preferable convergence properties of the <b>input</b> <b>error</b> scheme. Several other advantages are also discussed...|$|E
40|$|International audienceIt {{is widely}} claimed that {{parallel}} robots are intrinsically {{more accurate than}} serial robots be-cause their errors are averaged instead of added cumulatively, an assertion {{which has not been}} properly addressed in the literature. This paper addresses this void by comparing the kinematic accuracy of two pairs of serial-parallel 2 -DOF planar robots. Only <b>input</b> <b>errors</b> are considered and all robots are optimized for accuracy, the only constraint being that they cover a given de-sired workspace. The results of this comparison seem to confirm that parallel robots are less sen-sitive to <b>input</b> <b>errors</b> than serial robots...|$|R
40|$|In this article, {{we report}} users’ {{perceptions}} of query <b>input</b> <b>errors</b> and query reformulation strategies in voice search using data collected through a laboratory user study. Our results reveal that: 1) users’ perceived obstacles during a voice search {{can be related}} to speech recognition errors and topic complexity; 2) users naturally develop different strategies to deal with various types of words (e. g., acronyms, single-worded queries, non-English words) with high error rates in speech recognition; and 3) users can have various emotional reactions when encounter voice <b>input</b> <b>errors</b> and they develop preferred usage occasions for voice search...|$|R
40|$|Human {{error is}} {{embedded}} in every human endeavour. Given that research is conducted by humans, it is therefore prone to human error. This paper focuses on the errors that derive from transcribing data across formats. These 'inputs' errors arise largely from the monotony of the data entry process and may mean that an otherwise thoroughly designed research can potentially produce misleading conclusions. The paper reports {{the results of a}} quality checking process developed to monitor the transcription of data from paper-based questionnaires, collected as part of current PhD research, into the computer. Following the same entry method, the data from all questionnaires received were input twice by the PhD Candidate, then twice again by another participant. The 28, 140 entries were matched and any differences analysed in order to quantify the occurrence of <b>input</b> <b>errors</b> were committed and identify the nature of these errors. The results suggest that where the <b>input</b> <b>errors</b> were committed had more impact on the findings revealed from each question than the total number of <b>input</b> <b>errors</b> committed...|$|R
30|$|In this paper, for a {{class of}} linear {{networked}} iterative learning control (ILC) systems, methods to compensate dropped input data in time or iteration domain are compared. Specifically, the transition matrices of <b>input</b> <b>error</b> at the controller side with the two methods are derived first, respectively. After that, the varieties of eigenvalues and elements in the lower triangular of the transition matrices are analyzed. Through analyzing the varieties, it can be easily found that the two methods guarantee the convergence of <b>input</b> <b>error</b> at the controller side, while only the compensation in iteration domain guarantees the convergence of <b>input</b> <b>error</b> at the actuator side. Due {{to the introduction of}} networks, the convergence of output error is determined by the <b>input</b> <b>error</b> at the actuator side. Hence, a conclusion could be made naturally that the output error converges to zero with compensation in iteration domain, while compensation in time domain cannot guarantee that. Finally, numerical experiments are given to corroborate the theoretical analysis.|$|E
40|$|Uncertainty in any {{hydrological}} modeling can {{be quantified}} either implicitly by lumping all sources of errors or explicitly by addressing different sources of errors individually. This dissertation has evaluated some implicit and explicit methods of uncertainty analysis for a physically based distributed hydrological model called Soil and Water Assessment Tool (SWAT). A multiplicative <b>input</b> <b>error</b> model has been developed considering season-dependent precipitation multipliers for quantifying precipitation uncertainty explicitly in the distributed hydrological modeling. The high-dimensional and computational problems of the existing explicit methods have {{lead to the development}} of the seasonal <b>input</b> <b>error</b> model. The model is implemented in the calibration process of SWAT for simulating streamflow in two watersheds of Southwestern Ontario, Canada. The calibration method is based on the Bayesian approach and the Markov Chain Monte Carlo (MCMC) simulations are performed by the Shuffled Complex Evolution Metropolis (SCEM-UA) algorithm to analyze the posterior probability distribution of model parameters. By keeping the number of precipitation multipliers equal to the number of distinct seasons, the seasonal <b>input</b> <b>error</b> model has reduced the number of latent variables in the Bayesian modeling and has reduced the dimension of posterior probability distribution. The study reveals that streamflow prediction uncertainty due to parameter uncertainty is reduced when the autoregressive models are used in the implicit methods to represent the residual errors. However, the model parameters are biased when the Box-Cox transformation of data is used in the calibration process for addressing non-homogeneity and non-normality of the residual errors. The parameter and prediction uncertainties estimated by the seasonal <b>input</b> <b>error</b> model based calibration method are consistent with that of implicit methods. Model structural uncertainty is observed to be dominating over the input and parameter uncertainties in modeling the study area with SWAT. Hence, the autoregressive models as well as the <b>input</b> <b>error</b> models could not provide global optimum values in the parameter space. The seasonal <b>input</b> <b>error</b> model quantifies that the true precipitation is lower than the measured precipitation and the precipitation uncertainty estimated by the model is comparable to that of existing <b>input</b> <b>error</b> models. The effects of seasonal precipitation multipliers on parameter estimation and model prediction are explained by the correlation of estimated model parameters and by the reliability of model prediction uncertainty...|$|E
30|$|Localization {{using the}} Seaweb server {{consists}} of basically five steps namely, server input, data <b>input,</b> <b>error</b> correction, levelling of the network, mesh grids and finally, determination of location of nodes. The pseudocode of our localization algorithm is shown as Algorithm 1.|$|E
50|$|Each L-WIN {{refers to}} the wine itself (i.e. the {{producer}} and brand, grape or vineyard). The first six numbers of the code represent each wine’s unique identifier, while the seventh number is a “check digit” that minimises <b>input</b> <b>errors.</b>|$|R
40|$|LLM (Import and Export Law), North-West University, Potchefstroom Campus, 2014 The central task in {{this study}} is to {{discover}} and analyse the legal framework applicable to <b>input</b> <b>errors</b> in electronic contracts. The study analyses the law of South Africa, the Electronic Communications and Transactions Act 25 of 2002 (hereinafter referred to as the ECT Act) to be more specific, and the United Nations Convention on the Use of Electronic Communications in International Contracts (2005) (hereinafter referred to as the UNECIC). The ECT Act is the statute regulating electronic communications and transactions in South Africa. It was passed by the South African parliament in 2002. Almost all provisions of the ECT Act are based on the United Nations Model Law on Electronic Commerce (1996). However, section 20 thereof, which deals with <b>input</b> <b>errors,</b> was not based on the Model law, but on provisions from statutes of leading jurisdictions. 1 The UNECIC is a new international convention by the United Nations Commission on International Trade Law (hereinafter referred to as UNCITRAL). The Convention came into operation on the 1 st of March 2013, 2 and is the first United Nations convention that deals with electronic communications. Article 12 thereof deals with automated transactions, and section 14 with <b>input</b> <b>errors.</b> These are the two provisions that shall be analysed in relation to the UNECIC in this work. With the UNECIC having come into full operation, there is a real need to harmonise domestic laws with it. In various jurisdictions, including Singapore 3 and Australia, 4 the statutes governing electronic communications have been amended with some provisions of the UNECIC. Article 14 is one of the provisions of the UNECIC which have been domesticated in both jurisdictions. Judged against the UNECIC, a number of issues relating to <b>input</b> <b>errors</b> in the ECT Act are inconsistent with the new international standards embodied in the UNECIC. This work recommends that South Africa must adopt the UNECIC, and secondly that some of the provisions dealing with <b>input</b> <b>errors</b> in the ECT Act must be aligned with the UNECIC by amendment. Master...|$|R
40|$|A user's manual is {{presented}} for MacPASCO, {{which is an}} interactive, graphic, preprocessor for panel design. MacPASCO creates input for PASCO, an existing computer code for structural analysis and sizing of longitudinally stiffened composite panels. MacPASCO provides a graphical user interface which simplifies the specification of panel geometry and reduces user <b>input</b> <b>errors.</b> The user draws the initial structural geometry and reduces user <b>input</b> <b>errors.</b> The user draws the initial structural geometry on the computer screen, then uses a combination of graphic and text inputs to: refine the structural geometry; specify information required for analysis such as panel load and boundary conditions; and define design variables and constraints for minimum mass optimization. Only the use of MacPASCO is described, since the use of PASCO has been documented elsewhere...|$|R
30|$|In the {{login page}} that we consider, {{responses}} to valid requests include welcome messages and invalid <b>input</b> <b>error</b> messages. Responses to invalid requests include PHP or SQL error messages. The essential {{point is the}} existence of differences between execution pages and rejection pages, and, more precisely, between welcome messages and invalid <b>input</b> <b>error</b> messages, and between PHP and SQL error messages. Our approach focuses on the analysis of these differences. The objective is to identify, among several responses, those which correspond to execution pages generated through syntactically valid requests. In other words, we learn {{the behavior of the}} application based on the clustering of Web server response pages that are similar enough.|$|E
40|$|Active power filters as {{solutions}} to power quality problems {{have become more}} and more important nowadays. A nonlinear repetitive controller for current control of active power filters is proposed. The proposed method is composed of a repetitive controller and a deadband relay. Whenever the <b>input</b> <b>error</b> is above the threshold, the current control loop is driven dominantly by the deadband relay to obtain fast dynamic response. After the <b>input</b> <b>error</b> is below the threshold, the deadband relay automatically turns off and the repetitive control alone governs the current control to eliminate the steady-state error. Discussions on the design of the current and voltage control loops are also given. Simulation and experimental results verified the feasibility of the proposed method. Department of Electrical Engineerin...|$|E
40|$|Rainfall input {{errors are}} one of the most {{important}} sources of uncertainty in hydrological. models. They have been analysed for the watershed-averaged rainfall used as input in lumped conceptual models for watershed hydrology. The total rainfall <b>input</b> <b>error</b> is described in a stochastic framework on the basis of the different error-sources (e. g. point rainfall measurement errors and spatially-averaged rainfall estimation errors). They are related to the storm volumes, the distance between the rain gauges and the watershed centre and the configuration of the rain gauge network. The error description is applicable in probabilistic water management and efficient model calibration. It is also shown that, under certain circumstances, small storm volumes are underestimated and large volumes overestimated, and this bias can be corrected using the rainfall <b>input</b> <b>error</b> description. status: publishe...|$|E
40|$|MacPASCO, an interactive, graphic {{preprocessor}} for panel {{design is}} described. MacPASCO creates input for PASCO, an existing computer code for structural analysis and optimization of longitudinal stiffened composite panels. By using a graphical user interface, MacPASCO simplifies the specification of panel geometry and reduces user <b>input</b> <b>errors,</b> thus making the modeling {{and analysis of}} panel designs more efficient. The user draws the initial structural geometry on the computer screen, then uses a combination of graphic and text inputs to: refine the structural geometry, specify information required for analysis such as panel load conditions, and define design variables and constraints for minimum-mass optimization. Composite panel design is an ideal application because the graphical user interface can: serve as a visual aid, eliminate the tedious aspects of text-based input, and eliminate many sources of <b>input</b> <b>errors...</b>|$|R
40|$|It {{is widely}} claimed that {{parallel}} robots are intrinsically {{more accurate than}} serial robots because their errors are averaged instead of added cumulatively, an assertion {{which has not been}} properly addressed in the literature. This paper addresses this void by comparing the kinematic accuracy of two pairs of serialparallel 2 -DOF planar robots. Only <b>input</b> <b>errors</b> are considered and all robots are optimized for accuracy, the only constraint being that they cover a given desired workspace. The results of this comparison seem to confirm that parallel robots are less sensitive to <b>input</b> <b>errors</b> than serial robots. However, this comparison is too limited to draw any general conclusions. Besides, {{it is virtually impossible to}} make a meaningful comparison between other pairs of serial and parallel robot. Therefore, there is no simple answer to this question of superiority...|$|R
40|$|Three-degree-of-freedom planar {{parallel}} robots {{are increasingly}} being used in applications where precision is of the utmost importance. Clearly, methods for evaluating the accuracy of these robots are therefore needed. The accuracy of well designed, manufactured, and calibrated parallel robots depends mostly on the <b>input</b> <b>errors</b> (sensor and control errors). Dexterity and other similar performance indices have often been used to evaluate indirectly the influence of <b>input</b> <b>errors.</b> However, industry needs a precise knowledge of the maximum orientation and position output errors at a given nominal configuration. An interval analysis method that can be adapted for this purpose has been proposed in the literature, but gives no kinematic insight into the problem of optimal design. In this paper, a simpler method is proposed based on a detailed error analysis of 3 -DOF planar parallel robots that brings valuable understanding {{of the problem of}} error amplification...|$|R
