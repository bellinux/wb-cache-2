0|1008|Public
30|$|In {{setting the}} higher-level <b>interpretation</b> <b>rules,</b> the analyst {{creates a new}} <b>interpretation</b> <b>rule</b> name in the text area of (a) and can use the combo-boxes to set and select the {{conditional}} part of the function described in “Notation for <b>interpretation</b> <b>rule</b> definition” section, {{as well as the}} label for the lower-level/higher-level interpretation results that will become the argument. Here, as a function relying on Eye-Sizhi, when the target argument is a statement, the Sizhi-tag can be specified to identify the statement. If necessary, the analyst also specifies the type of Sizhi-tag of the evidence statements and statement ID as optional settings. It is also possible to confirm and add <b>interpretation</b> <b>rules</b> in area (c); <b>interpretation</b> <b>rules</b> added in this way will be displayed in the <b>interpretation</b> <b>rule</b> display area of (d). A list that includes the lower-level <b>interpretation</b> <b>rules</b> applied in (1) is displayed in this area and can be used as an argument of the function established in (b). Pushing the “apply” button after setting a series of <b>interpretation</b> <b>rules</b> divides each applied interpretation result and displays it on the timeline visualization screen (Fig.  8 (detailed in “Applied results of interpretation rules” section)). Detailed information on the results is shown in (e).|$|R
40|$|Abstract. We {{present an}} {{approach}} to semantic interpretation of syntactically parsed Japanese sentences that works largely parser-independent. The approach relies on a standardized parse tree format that restricts the number of syntactic con gurations that the semantic <b>interpretation</b> <b>rules</b> have toanticipate. All parse trees are converted to this format prior to semantic interpretation. This setup allows us not only to apply {{the same set of}} semantic <b>interpretation</b> <b>rules</b> to output from di erent parsers, but also to independently develop parsers and semantic <b>interpretation</b> <b>rules.</b> ...|$|R
50|$|There {{is no such}} <b>interpretation</b> <b>rule</b> for {{vertical}} coordinates.|$|R
30|$|Prostate MRI {{technical}} standard and <b>interpretation</b> <b>rules</b> are still evolving.|$|R
30|$|This process {{involves}} interpreting each data series classified via preprocessing. Interpretation processing {{consists of}} two steps: application of a lower-level <b>interpretation</b> <b>rule</b> that provides a lower-level interpretation (lower-level interpretation); and for sections given an interpretation in this stage of processing, application of a higher-level <b>interpretation</b> <b>rule</b> (higher-level <b>interpretation)</b> that gives interpretations including meta-level thinking processes.|$|R
30|$|In Fig.  8, the {{application}} results of each <b>interpretation</b> <b>rule</b> are classified and visualized. Row (i) represents a section {{in which the}} corrector compares A’s-thought and B’s-thought due to {{the application}} of higher-level <b>interpretation</b> <b>rule</b> hr 1. More specifically, in the conditions of hr 1, sections of thinking activity about A’s-thought and B’s-thought, which are consecutive within 5000  ms are extracted from the application results of lower-level <b>interpretation</b> <b>rule</b> lr 1, and it is interpreted that the two thoughts, which are sources of conflict (A’s-thought, B’s-thought), are compared (metacognitive monitoring) by a corrector (Compare_A’s-Thought_and_B’s-thought). These results indicate that this corrector performed metacognitive monitoring to compare A’s-thought and B’s-thought {{in the first and}} second halves of the correction activity (Fig.  8, in the blue frame). Higher-level <b>interpretation</b> <b>rules</b> hr 2 and hr 3 extract a section of the understanding process of a policy statement that forms a belief conflict (hr 2) and a correction section of a policy statement (hr 3), respectively.|$|R
5000|$|All {{remaining}} ambiguous constructs {{are interpreted}} deterministically {{on the basis}} of a small number of <b>interpretation</b> <b>rules</b> ...|$|R
5000|$|Metaphrase modifies the <b>interpretation</b> <b>rules</b> {{used for}} {{pre-existing}} expressions. It {{corresponds to the}} modern notion of reflection.|$|R
30|$|Applications {{and other}} {{specific}} examples of lower- and higher-level <b>interpretation</b> <b>rules</b> {{are described in}} “Applied results of interpretation rules” section.|$|R
30|$|Therefore, by {{constructing}} a thinking externalization application {{on the basis}} of the base-level thinking representation ontology for a given thinking task, <b>interpretation</b> <b>rules</b> can be applied to gaze behaviors and thought operation actions on thinking representation objects. This supports the possibility that one part of the metacognitive thinking process can be grasped from this example. Although the validity of the extracted interpretation section is dependent on the <b>interpretation</b> <b>rules</b> defined by the analyst, the analyst clarifies the premises for analysis to target highly implicit, latent thoughts and sets <b>interpretation</b> <b>rules</b> to enhance agreement about the types of metacognitive thinking processes from the types of semi-metacognitive monitoring and control activities under consideration. We believe our framework-based thinking analysis will contribute to the formation and accumulation of knowledge for thinking analysis methods.|$|R
30|$|Primitive- and collective-BL-thinking {{are defined}} as invisible-activity that cannot be {{observed}} from the outside world. In the meta-level thinking which targets those base level thinking processes, thoughts are performed such as “to think about the premise of a given judgment,” “to compare policies leading to a belief conflict,” “to examine whether an assumption is valid,” and “to check and adopt different judgment policies.” Additionally, the framework provides the notation to define <b>interpretation</b> <b>rules</b> (“Notation for <b>interpretation</b> <b>rule</b> definition” section) for capturing such kinds of meta-level thinking dependent on these thinking tasks.|$|R
30|$|Higher-level {{interpretation}} processing area: This area is used {{to display}} interpretation results {{that have been raised}} to the metacognition level by applying higher-level <b>interpretation</b> <b>rules</b> to lower-level <b>interpretation</b> results from (1).|$|R
40|$|Abstract:-Shewhart X chart usually {{supplemented}} by <b>interpretation</b> <b>rules</b> {{is common in}} practice. These rules are designed to show an earlier detection of un-natural patterns in the process mean. Although these rules are valuable in detecting the “true ” problems, they also increase the probability of false alarm. In this paper the false alarm rates of most used seven <b>interpretation</b> <b>rules</b> were obtained through by developing a spread sheet for normal and non-normal distributions. The {{results show that the}} number of false alarm can be fairly high for particular rules when the underlying data from a gamma distribution rather than normal distribution...|$|R
30|$|We {{explain the}} {{base-level}} thinking representation ontology {{defined in the}} framework in “Base-level thinking representation ontology” section, and the notation to specify <b>interpretation</b> <b>rules</b> in “Interpretation of thinking processes based on interpretation rules” section.|$|R
5000|$|Not all ambiguities can {{be safely}} removed from ACE without {{rendering}} it artificial. To deterministically interpret otherwise syntactically correct ACE sentences we use a small set of <b>interpretation</b> <b>rules.</b> For example, if we write: ...|$|R
40|$|The {{development}} of larger scale natural language systems has been {{hampered by the}} need to manually create mappings from syntactic structures into meaning representations. A new approach to semantic interpretation is proposed, which uses partial syntactic structures as the main unit of abstraction for <b>interpretation</b> <b>rules.</b> This approach can work for a variety of syntactic representations corresponding to directed acyclic graphs. It is designed to map into meaning representations based on frame hierarchies with inheritance. We define semantic <b>interpretation</b> <b>rules</b> in a compact format. The format is suitable for automatic rule extension or rule generalization, when existing hand-coded rules do not cover the current input. Furthermore, automati...|$|R
40|$|It {{is common}} in {{practice}} that the Shewhart chart usually supplemented with <b>interpretation</b> <b>rules</b> in order to detect the small shifts in the process mean. In this study the effect of scale parameters {{in the performance of}} the Shewhart control chart of the most used seven <b>interpretation</b> <b>rules</b> were obtained through by developing a spread sheet for normal and gamma distributions when process remains in control. The results show that the in-control performance can be fairly high for particular rules when the underlying data from a gamma distribution rather than normal distribution considering scale parameters. It was also observed that the in-control performance of gamma distribution grows larger when the scale parameter increases...|$|R
30|$|Development phase (C): A {{thinking}} analysis {{support system}} is developed that can extract {{the subjects of}} analysis from gaze behaviors and thought operation actions measured in (B) and where <b>interpretation</b> <b>rules</b> (“Interpretation of thinking processes based on interpretation rules” section) can be defined.|$|R
40|$|Abstract. In {{this paper}} we {{describe}} a semi-automated approach for ontology learning. Exploiting an ontology-based multimodal information extraction system, the ontology learning subsystem accumulates documents that are insufficiently analysed and through clustering proposes new concepts, relations and <b>interpretation</b> <b>rules</b> {{to be added}} to the ontology...|$|R
40|$|We discuss from a {{philosophical}} perspective {{the way in}} which the normal concept of time might be said to `emerge' in a quantum theory of gravity. After an introduction, we briefly discuss the notion of emergence, without regard to time (Section 2). We then introduce the search for a quantum theory of gravity (Section 3); and review some <b>general</b> <b>interpretative</b> issues about space, time and matter (Section 4). We then discuss the emergence of time in simple quantum geometrodynamics, and in the Euclidean approach (Section 5). Section 6 conclude...|$|R
30|$|Analysis phase (E): <b>Interpretation</b> <b>rules</b> are {{specified}} and deployed on {{the thinking}} analysis support system developed in (C) {{and applied to}} the thinker’s gaze behaviors and thought operation actions measured in (D), and through iterative analysis, a verifiable hypothesis on the thinker’s metacognitive processes is captured.|$|R
40|$|To {{evaluate}} whether fuzzy operators can be usefully {{applied to the}} interpretation of genotypic HIV- 1 drug resistance by experts, and to improve the prediction of salvage therapy outcome by adapting <b>interpretation</b> <b>rules</b> of genotypic resistance {{on the basis of their}} association with virological response data...|$|R
40|$|A {{syntax tree}} or {{standard}} semantic representation {{can be represented}} {{as a set of}} indexed constraints. This paper describes how this idea can be used in task oriented dialogue systems to provide <b>interpretation</b> <b>rules</b> which incorporate structural and contextual constraints where available, and degrade gracefully on ungrammatical input...|$|R
30|$|The {{structure}} of the thinking task influences the way that metacognition monitors and controls base-level thinking. For example, if a teacher evaluates learners’ written documents/reports in terms of learners’ bug detection/correction, the teacher is asked to engage in thinking activities such as understanding (metacognitive monitoring) and modifying (metacognitive control) the described base-level thought of others (learners). To cope with the diversity of interpretations of metacognition influenced by the {{structure of}} the thinking task, we introduce “interpretation rules” (Fig.  1 (vi)). <b>Interpretation</b> <b>rules</b> are formally represented rules that extract sections of base-level and meta-level thinking from the gaze behaviors and thought operation actions, including the activities of semi-metacognitive monitoring/control, and interpret them. These <b>interpretation</b> <b>rules</b> are assumed to be defined and applied by an analyst through the thinking analysis support system.|$|R
40|$|We give derivations of two formal {{models of}} Gricean Quantity 1 implicature and strong exhaustivity (Van Rooij and Schulz, 2004; Schulz and Van Rooij, 2006), in {{bidirectional}} optimality theory {{and in a}} signalling games framework. We show that, under a unifying model based on signalling games, these interpretative strategies are game-theoretic equilibria when the speaker {{is known to be}} respectively minimally and maximally expert in the matter at hand. That is, in this framework the optimal strategy for communication depends on the degree of knowledge the speaker is known to have concerning the question she is answering. In addition, and most importantly, we give a game-theoretic characterisation of the <b>interpretation</b> <b>rule</b> Grice (formalising Quantity 1 implicature), showing that under natural conditions this <b>interpretation</b> <b>rule</b> occurs in the unique equilibrium play of the signalling game. ...|$|R
50|$|Attempto Controlled English (ACE) is a {{controlled}} natural language, i.e. {{a subset of}} standard English with a restricted syntax and restricted semantics described by a small set of construction and <b>interpretation</b> <b>rules.</b> It has been under development at the University of Zurich since 1995. In 2013, ACE version 6.7 was announced.|$|R
40|$|Chevron, {{the most}} famous rule of {{administrative}} law, is also a central doctrine of statutory interpretation. But Chevron is understood and operates quite differently {{from most of the}} other statutory <b>interpretation</b> <b>rules.</b> This Essay explores six such divergences and how they illuminate of some the most important, unanswered questions of the statutory era...|$|R
50|$|The {{grammar of}} ACE defines and {{constrains}} {{the form and}} the meaning of ACE sentences and texts. ACE's grammar is expressed as a set of construction rules. The meaning of sentences is described as a small set of <b>interpretation</b> <b>rules.</b> A Troubleshooting Guide describes how to use ACE and how to avoid pitfalls.|$|R
40|$|Trust is a {{construct}} studied {{by a growing}} number of disciplines that, in time, following a natural process of convergence, have increasingly featured the multidisciplinarity of studies. To fully appreciate the increasing multidisciplinarity of trust literature, a review of the major research areas from the different disciplines has been done. This in order to understand two elements: (1) the major relational contexts studied by each discipline as well as their analytical goals; (2) the contribution that they can offer to define a <b>general</b> <b>interpretative</b> model of trust in market relations discussed in {{the last part of the}} paper...|$|R
40|$|This article {{introduces}} to {{the thematic}} scope and {{the articles of}} this special issue and it explains some important terminological distinctions of the intercultural research field. The overall aim of this issue is to explore the manifold ways to apply and to reflect upon qualitative research methods {{in the context of}} intercultural communication. This implies both a discussion of genuine characteristics of intercultural qualitative research as well as attempts to identify common features and linkages of this special area with more <b>general</b> <b>interpretative</b> research traditions under the "umbrella" of qualitative social research. URN: urn:nbn:de: 0114 -fqs 090134...|$|R
40|$|Recent {{experiments}} {{have shown that}} naive speakers find borderline contradictions involving vague predicates acceptable. In Cobreros et al. (Journal of Philosophical Logic, 41, 347 – 385, 2012 a) we proposed a pragmatic explanation of the acceptability of borderline contradictions, building on a three-valued semantics. In a reply, Alxatib et al. (Journal of Philosophical Logic, 42, 619 – 634, 2013) show, however, that the pragmatic account predicts the wrong interpretations for some examples involving disjunction, and propose as a remedy a semantic analysis instead, based on fuzzy logic. In this paper we provide an explicit global pragmatic <b>interpretation</b> <b>rule,</b> based on a somewhat richer semantics, and show that with its help the problem can be overcome in pragmatics after all. Furthermore, we use this pragmatic <b>interpretation</b> <b>rule</b> to define a new (nonmonotonic) consequence-relation and discuss some of its properties...|$|R
50|$|<b>Interpretation</b> <b>rules</b> {{resolve the}} anaphoric {{references}} in (3): the tie and it {{of the second}} sentence refer to a new tie of the first sentence, while his and {{the man of the}} second sentence refer to a man of the first sentence. Thus an ACE text is a coherent entity of anaphorically linked sentences.|$|R
5000|$|ACE {{construction}} rules {{require that}} each noun be introduced by a determiner (a, every, no, some, at least 5, ...). ACE <b>interpretation</b> <b>rules</b> decide that (1) is interpreted as universally quantified, while (2) is interpreted as existentially quantified. Sentences like [...] "Women are human" [...] {{do not follow}} ACE syntax and are consequently not valid.|$|R
3000|$|We propose an “interpretation framework” for {{metacognition}} {{that could}} serve as the design principles for developing a system that makes it possible to provide metacognitive interpretations on the basis of gaze behaviors and thought operation actions (“Metacognitive interpretation framework for understanding metacognitive processes”, “Base-level thinking representation ontology”, and “Notation for <b>interpretation</b> <b>rule</b> definition” sections); and [...]...|$|R
5000|$|... {{then with}} a code {{attaches}} to the verb inserts, but not to a card. However, this is probably not what we meant to say. To express that the code {{is associated with the}} card we can employ the <b>interpretation</b> <b>rule</b> that a relative sentence always modifies the immediately preceding noun phrase, and rephrase the input as: ...|$|R
40|$|The schema {{method is}} a {{framework}} for correcting grammatically ill-formed input. In a natural language processing system ill-formed input cannot be overlooked. A computer assisted instruction (CAI) system, in particular, needs to show the user's errors. This framework diagnoses ill-formed input, corrects it and explains the error, if an input is ill-?ormed. The framework recognizes a sentonce at two steps: first parses weak grammar, and then strongly filters the parsed sentence. When it is known what sentences are passed by the filter, {{it can be used}} even if it is imperfect. As the strong filter, a new method is used: an interpretation schema and an <b>interpretation</b> <b>rule.</b> An <b>interpretation</b> schema collects input information schemata and then an <b>interpretation</b> <b>rule</b> judges whether the collected scbemata are correct or incorrect. This approach overcomes the problem of relaxation control, the major drawback of the previous syntacticallyworiented methods, and is also more efficient...|$|R
