17|166|Public
50|$|In {{a further}} {{analysis}} {{of the age of}} the break-up of Greater India (India plus Seychelles) and Madagascar it has been inferred to have occurred in the Upper Cretaceous at 88 Ma. The strength of this inference is based on the approach that the Felsic volcanics (rhyolites and Rhyodacites) of the St. Mary's Islands (SMI), Southern India, were originally interpreted as a distant outlier of the 66 Ma Deccan volcanic province of west-central India, comprising dominantly flood basalts. Later studies had dated it at 93 Ma by the K-Ar dating technique. Since the technique used was a simple use of an average of five out of six widely varying dates and arbitrary <b>data</b> <b>selectivity</b> chosen, the results were not considered reliable. A method of 40Ar-39Ar (argon-argon dating) of the SMI volcanic yields is reportedly more reliable of the plateau and isochron ages. The weighted mean isochron age is reported to be 85.6±0.9 Ma (2σ). The K-Ar (potassium-argon dating) technique adopted for the southern Indian Precambrian terrain, intruded by numerous mafic-doleritic dyke swarms, the age from Proterozoic to the latest Cretaceous is reported as 69-66 Ma (Deccan-related). The two regional dykes (a leucograbbro and a felsite) from the Kerala region of southwestern India, which were also dated earlier, indicate the age as 85 Ma. Madagascar flood basalt province's 40Ar-39Ar ages of 89-85 Ma tallies with the SMI volcanic age. The conclusion drawn by the study is that the Madagascar flood basalt province, the SMI volcanics, and possibly the Kerala dykes may well represent volcanic activity associated with the break-up of Greater India and Madagascar, in the Upper Cretaceous at 88 Ma.|$|E
40|$|The {{validation}} of an analytical procedure must be certified through {{the determination of}} parameters known as figures of merit. For first order data, the acuracy, precision, robustness and bias {{is similar to the}} methods of univariate calibration. Linearity, sensitivity, signal to noise ratio, adjustment, selectivity and confidence intervals need different approaches, specific for multivariate <b>data.</b> <b>Selectivity</b> and signal to noise ratio are more critical and they only can be estimated by means of the calculation of the net analyte signal. In second order calibration, some differentes approaches are necessary due to data structure...|$|E
40|$|Vapor-Liquid equilibria of palm {{fatty acids}} distillates/carbon dioxide {{system has been}} {{investigated}} experimentally at temperatures of 333, 353, and 373 K and pressures of 20, 23, 26, and 29 MPa using the static method. Experimental data for the quasi-binary system palm fatty acids distillates/carbon dioxide has been correlated with Redlich-Kwong-Aspen equation of state. Modeling shows good agreement with experimental <b>data.</b> <b>Selectivity</b> obtained indicates that supercritical carbon dioxide is a reasonable solvent for separating saturated (palmitic acid) and unsaturated (oleic+linoleic acids) fatty acids from palm fatty acids distillates in a continuous multistage countercurrent column...|$|E
40|$|Discusses several {{tests to}} check for the {{presence}} of selectivity bias in estimators based on panel <b>data.</b> Introduction; <b>Selectivity</b> bias in the fixed and random effects estimators; Simple tests for selectivity bias; Specification of the response mechanism and the LM test for selectivity bias; Numerical results on the pseudo true values of the RE and FE estimators; More...|$|R
30|$|Quench signal has a {{major impact}} on superregenerative receiver’s <b>data</b> rate, <b>selectivity,</b> and gain. It {{essentially}} defines the sampling rate of a superregenerative receiver. A sample is taken from the received signal after the quench signal allows oscillations to start. Then the amplitude of oscillations starts to increase exponentially (in the logarithmic mode) until the next quench signal resets them. This procedure is repeated continuously. Application requirements for data rate define the sufficient quench frequency.|$|R
5000|$|Biblical scholar Thomas L. Thompson {{contends that}} the methods of [...] "biblical archaeology" [...] have also become outmoded: [...] "and Albright's {{historical}} interpretation can make no claim to be objective, proceeding as it does from a methodology which distorts its <b>data</b> by <b>selectivity</b> which is hardly representative, which ignores the enormous lack of data {{for the history of}} the early second millennium, and which wilfully establishes hypotheses on the basis of unexamined biblical texts, to be proven by such (for this period) meaningless mathematical criteria as the 'balance of probability' ..." ...|$|R
40|$|An {{investigation}} has compiled {{a very large}} amount of data on central or near central solar eclipses as recorded in four principal ancient sources (Greek and Roman classics, medieval European chronicles, Chinese annals and astronomical treatises, and Late Babylonian astronomical texts) and applied careful <b>data</b> <b>selectivity</b> criteria and statistical methods to obtain reliable dates, magnitudes, and places of observation of the events, and thereby made estimates of the earth acceleration and lunar acceleration. The basic conclusion is that the lunar acceleration and both tidal and nontidal earth accelerations have been essentially constant {{during the period from}} 1375 B. C. to the present...|$|E
40|$|The nonfarm work {{participation}} {{decisions of}} married {{men and women}} in rural Northern Ghana were jointly and separately estimated for married couples through a bivariate probit, using recent survey <b>data.</b> <b>Selectivity</b> bias was corrected for in estimating wage offer and labor supply equations, using Heckman's procedure. Education, experience, infrastructure, distance to the capital, and population density, as well as interactions between education and infrastructure and between education and distance to the city, were found to be significantly related to the probability of nonfarm labor market participation, wages, and the amount of nonfarm labor performed, with significant differences by gender. Copyright 1999, Oxford University Press. ...|$|E
40|$|Spatial {{data base}} systems (SDBSs) deal with {{data that are}} special in nature and size. Thus, the {{technologies}} developed for conventional data base systems such as physical design, access methods, query optimizers and languages, have to be modified {{in order to satisfy}} the needs of a SDBS. These modifications, embedded in several SDBSs, or being proposed by research projects, need to be evaluated. Our research focuses specifically multidimensional access methods (MAMs), which are very important structures used to diminish the execution time of search operations in a SDBS. In this paper, we discuss two important factors that affect the performance of MAMs: degree of overlap between non-zero size data objects and <b>data</b> <b>selectivity.</b> Pages: 112 - 11...|$|E
40|$|The use of {{literature}} data to identify catalysts for a novel transformation is a commonly used approach. Herein, we have evaluated {{if this is}} a viable strategy in enzyme catalysis, using asymmetric reduction of 1 -aryl- 2 -alkanoates as a model system. The study, which includes data from 24 ketone substrates and 108 enzymes, clearly identifies pitfalls with this approach, but anyhow shows that literature data is highly useful for identification of enantioselective catalysts. By combining <b>data</b> for <b>selectivity</b> and rate useful catalyst for converting different substrates to their corresponding (R) - and (S) -enantiomers are highlighted...|$|R
40|$|Length {{frequency}} data of Scomberomorus commerson {{collected from}} April 1984 to March 1987 from artisanal fisheries using {{three types of}} gill nets, hook and line, shore seine and shrimp trawls are analysed. Assuming that the length frequencies of combined gears will give distributions unaffected by <b>selectivity</b> <b>data</b> were pooled and analysed by the Bhattacharya method...|$|R
40|$|In {{this paper}} {{we present a}} scheme for accumulating local visual {{information}} in 3 D, under known motion. Information about the object’s 3 D shape is provided by reconstructing local contour descriptors. This shape information is accumulated over time in three ways: 1) disambiguation: erroneous stereo correspondences that are unsuccessfully tracked are discarded. We make use of aspect cues to increase the <b>data</b> association <b>selectivity.</b> 2) correction: the full pose of the reconstructed features is corrected over time using an Kalman Filter approach. 3) completeness: multiple 2 1 / 2 D representations become merged, constructing a full 3 D representation of the object. The described system is evaluated quantitatively on three different scenarios...|$|R
40|$|This study {{examined}} the incidence and determinants of quantity price discounts and quantity price surcharges in the German food sector through a bivariate probit, using recent consumer scanner survey <b>data.</b> <b>Selectivity</b> bias was corrected for in estimating the degree of quantity price surcharge and quantity price discount, using Heckman’s procedure. The findings reveal that almost 10 % of the investigated products attract higher unit prices for larger package sizes, although the extent of price surcharges varied among product categories. The number of package sizes, the average package size, packaging form, storage form, {{as well as the}} price image of a product, were found to be significantly related to the probability and degree of quantity price surcharges and quantity price discounts. JEL classification...|$|E
40|$|A {{technology}} development plan {{designed to reduce}} the data load and data-management problems associated with global study and monitoring missions is described with a heavy emphasis placed on developing mission capabilities to eliminate the collection of unnecessary data. Improved <b>data</b> <b>selectivity</b> can be achieved through sensor automation correlated with the real-time needs of data users. The {{first phase of the}} plan includes the Feature Identification and Location Experiment (FILE) which is scheduled for the 1980 Shuttle flight. The FILE experiment is described with attention given to technology needs, development plan, feature recognition and classification, and cloud-snow detection/discrimination. Pointing, tracking and navigation received particular consideration, and it is concluded that this technology plan is viewed as an alternative to approaches to real-time acquisition that are based on extensive onboard format and inventory processing and reliance upon global-satellite-system navigation data...|$|E
40|$|Police road crash data {{comprise}} a non-random {{sample of the}} true population of road crashes, the bias being due {{to the existence of}} crashes that are not notified to the Police. Heckman viewed similar problems as ‘omitted variables’ problems in that the exclusion of some observations in a systematic manner (so-called selectivity bias) has inadvertently introduced the need for an additional regressor in least squares procedures. In the case of Police road crash <b>data,</b> <b>selectivity</b> bias arises from factors affecting the notification of crashes to the Police, such as the number of vehicles in the crash and the type and location of the crash. Using Heckman's methodology for correcting for this selectivity bias, Police road crash data for Western Australia are reconciled with total road crash data in the estimation of the property damage costs of road crashes. ...|$|E
40|$|Abstract. Given {{a set of}} N multi-dimensional points, {{we study}} the {{computation}} of φ-quantiles according to a ranking function F, which {{is provided by the}} user at runtime. Specifically, F computes a score based on the coordinates of each point; our objective is to report the object whose score is the φN-th smallest in the dataset. φ-quantiles provide a succinct summary about the F-distribution of the underlying data, which is useful for online decision support, <b>data</b> mining, <b>selectivity</b> estimation, query optimization, etc. Assuming that the dataset is indexed by a spatial access method, we propose several algorithms for retrieving a quantile efficiently. Analytical and experimental results demonstrate that a branch-and-bound method is highly effective in practice, outperforming alternative approaches by a significant factor. ...|$|R
40|$|We {{present a}} {{generalization}} of frequent itemsets {{allowing for the}} notion of errors in the itemset definition. We motivate the problem and present an efficient algorithm that identifies errortolerant frequent clusters of items in transactional data (customerpurchase data, web browsing data, text, etc.). The algorithm exploits sparseness of the underlying data to find large groups of items that are correlated over database records (rows). The notion of transaction coverage allows us to extend the algorithm and {{view it as a}} fast clustering algorithm for discovering segments of similar transactions in binary sparse data. We evaluate the new algorithm on three real-world applications: clustering highdimensional <b>data,</b> query <b>selectivity</b> estimation and collaborative filtering. Results show that the algorithm consistently uncovers structure in large sparse databases that other traditional clustering algorithms fail to find...|$|R
40|$|Given {{a set of}} N multi-dimensional points, {{we study}} the {{computation}} of phi;-quantiles according to a ranking function F, which {{is provided by the}} user at runtime. Specifically, F computes a score based on the coordinates of each point; our objective is to report the object whose score is the φN-th smallest in the dataset. φ-quantiles provide a succinct summary about the F-distribution of the underlying data, which is useful for online decision support, <b>data</b> mining, <b>selectivity</b> estimation, query optimization, etc. Assuming that the dataset is indexed by a spatial access method, we propose several algorithms for retrieving a quantile efficiently. Analytical and experimental results demonstrate that a branch-and-bound method is highly effective in practice, outperforming alternative approaches by a significant factor. © Springer-Verlag Berlin Heidelberg 2006. link_to_subscribed_fulltex...|$|R
40|$|We study smoking {{persistence}} in ten countries {{using data from}} the European Community Household Panel. Such persistence may be due to true state dependence but may also reflect individual unobserved heterogeneity. We distinguish between the two by using semi-parametric dynamic panel data methods applied to both the decision to smoke or not and to the decision on the number of cigarettes smoked. Our model allows for correlation of the two time-varying error terms, i. e. for selectivity. We find that for both smoking decisions true state dependence is in general much smaller when unobserved individual heterogeneity is taken into account, and we also uncover large differences in true state dependence across countries. Finally, we find that taking into account heaping in the reported number of cigarettes smoked considerably improves the fit of our model. smoking, panel <b>data,</b> <b>selectivity...</b>|$|E
40|$|The KDB-tree and its {{variants}} {{have been}} reported to have good performance by us-ing them as the index structures for retrieving multidimensional data. However, many literatures still frequently address the low storage utilization and insufficient retrieval performance as two bottlenecks for this family of structures. The excessive amount of frequent splits caused by improper data sequences and data skewness is the fatal reason for these two bottlenecks. Partition shifting (PS-method) and skewness handling (SH-method) proposed in this paper are proposed to conquer these problems. Without loss the quantity of <b>data</b> <b>selectivity,</b> a better dynamic partitioning scheme can accommodate data entries to leaves as many as possible. In addition, system performance degradation caused by skewed data is carefully investigated and our SH-method can prevent the well-classified pages from frequent splits. Analytical and experimental results show that both time and space efficiencies are significantly improved by the proposed compressed KDB-trees...|$|E
40|$|A bivariate probit {{model was}} {{employed}} to jointly and separately estimate banana market participation decisions of buying and selling households in Rwanda and Burundi using household survey <b>data.</b> <b>Selectivity</b> bias was corrected for estimating the transacted volumes using Heckman’s procedure. The results showed that transaction cost-related factors such as geographical location of households, market information sources, and travel time to the nearest urban center influence market participation. Non-price-related factors such as security of land tenure, labor availability, off-farm income, gender of the household head, and years of farming experience had a significant influence on the transacted volumes. Output prices had a significant correlation with sales volume, indicating price incentives increased supply by sellers. Generally, {{the findings suggest that}} policies aimed at investments in rural road infrastructure, market information systems, collective marketing, and value addition of banana products may provide a potential avenue for mitigating transaction costs and enhancing market participation and production of marketed surplus by rural households. Funding was provided by the Belgian Development Cooperation...|$|E
40|$|Hydrogenative {{ring-opening}} {{reactions of}} methyloxirane (MOX) were performed over reduced and preoxidized silica-supported Pt, Pd, Ph, Ni and Cu catalysts {{in order to}} study reactions at metal-metal oxide interfaces. A comparison of the activity, as well as ring-opening <b>selectivity</b> <b>data</b> over the reduced and preoxidized surfaces, revealed that MOX adsorbed through the ring oxygen and itself oxidized the metal surfaces. This means that the active sites for its catalytic transformations are ionic species formed in situ at the metal-metal oxide interface...|$|R
40|$|Compact, {{portable}} systems {{capable of}} quickly identifying contaminants {{in the field}} are of great importance when monitoring the environment. In this paper, we examine the effectiveness of using artificial neural networks for real-time data analysis of a sensor array. Analyzing the sensor data in parallel may allow for rapid identification of contaminants in the field without requiring highly selective individual sensors. We use a prototype sensor array which consists of nine tin-oxide Taguchi-type sensors, a temperature sensor, and a humidity sensor. We illustrate that by using neural network based analysis of the sensor <b>data,</b> the <b>selectivity</b> of the sensor array may be significantly improved, especially when some (or all) the sensors are not highly selective. Keywords: neural network, sensor array, environmental monitoring, sensor selectivity. 1 INTRODUCTION One of the missions of the Pacific Northwest Laboratory is to examine and develop new technologies for environmental restoration [...] ...|$|R
40|$|Consider {{a setting}} where a {{treatment}} that starts {{at some point}} during a spell (e. g. in unemployment) may impact on the hazard rate of the spell duration, and where the impact may be heterogeneous across subjects. We provide Monte Carlo evidence on the feasibility of estimating the distribution of treatment effects from duration <b>data</b> with <b>selectivity,</b> by means of a nonparametric maximum likelihood estimator with unrestricted numbers of mass points for the heterogeneity distribution. We find that specifying the treatment effect as homogenous may yield misleading average results if the true effects are heterogeneous, even when the sorting into treatment is appropriately accounted for. Specifying the treatment effect as a random coefficient allows for precise estimation of informative average treatment effects including the program’s overall impact on the mean duration. duration analysis, unobserved heterogeneity, program evaluation, nonparametric estimation, Monte Carlo simulation, timing of events, random effects...|$|R
40|$|In this study, {{the authors}} {{examined}} the incidence and determinants of quantity price discounts and quantity price surcharges in the German food sector through a bivariate probit model, using recent consumer scanner survey <b>data.</b> <b>Selectivity</b> bias was corrected for in estimating {{the magnitude of}} quantity price surcharges and quantity price discounts, using Heckman's procedure. The findings reveal that almost 10 % of the investigated products attract higher unit prices for larger package sizes, although the extent of price surcharges varied among product categories. Quantity price discounts were found to dominate in the firms' pricing strategies. The econometric {{results showed that the}} number of package sizes, the average package size, the packaging and storage forms, as well as the price image of a product are all significant determinants of the decision to impose both quantity price surcharges and quantity price discounts. [JEL classification: D 40, L 11 ] © 2009 Wiley Periodicals, Inc. ...|$|E
40|$|In {{the present}} study a hybrid molecularly {{imprinted}} poly(methaaylic acid-trimethylolpropane trimethacrylate) silica (MIP) was synthesized and modified with (3 -glycidyloxypropyl) trimethoxysilane (GPTMS) with posterior opening of epoxy ring to provide hydrophilic properties of material in the extraction of folic acid from aqueous medium. The chemical and structural aggregates of hybrid material were characterized by means of Fourier Transform Infrared (FT-ER), Transmission Electron Microscopy (TEM), Scanning Electron Microscopy (SEM), Thermogravimetric analysis (TGA) and textural <b>data.</b> <b>Selectivity</b> data of MIP were compared to non-imprinted polymer (NIP) through competitive sorption studies {{in the presence of}} caffeine, paracetamol or 4 -aminobenzamide yielding relative selectivity coefficients (k') higher than one unit, thus confirming the selective character of MIP even in the presence of structurally smaller compounds than the folic acid. The lower hydrophobic sorption by bovine serum albumin (BSA) in the MIP as compared to unmodified MIP proves the hydrophilicity of polymer surface by using GPTMS with opening ring. Under acid medium (pH 1. 5) the sorption of folic acid onto MIP from batch experiments was higher than the one achieved for NIP. Equilibrium sorption of folic acid was reached at 120 min for MIP, NIP and MIP without GPTMS and kinetic sorption data were well described by pseudo-second-order, Elovich and intraparticle diffusion models. Thus, these results indicate the existence of different binding energy sites in the polymers and a complex mechanism consisting of both surface sorption and intraparticle transport of folic add within the pores of polymers. (C) 2015 Elsevier B. V. All rights reserved...|$|E
40|$|The felsic volcanics (rhyolites and rhyodacites) of the St. Mary’s Islands (SMI), {{southern}} India (V 13 ‡N), {{were originally}} {{interpreted as a}} distant outlier of the V 65 Ma Deccan volcanic province of west^central India, comprising dominantly flood basalts. Later the SMI volcanics were dated atV 93 Ma by the K^Ar technique. However, this K^Ar ‘age ’ was dubious, being merely an average of five out of six widely varying dates and arbitrary <b>data</b> <b>selectivity</b> being involved in this averaging. Our first 40 Ar^ 39 Ar dating of the SMI volcanics yields excellent plateau and isochron ages, and their weighted mean isochron age is 85. 6 þ 0. 9 Ma (2 c). Interestingly, the southern Indian Precambrian terrain is intruded by numerous mafic^doleritic dyke swarms {{ranging in age from}} Proterozoic to the latest Cretaceous (69 ^ 65 Ma, Deccan-related), and indeed, two regional dykes (a leucograbbro and a felsite) from the Kerala region of southwestern India remain previously dated atV 85 Ma, but again with the K^Ar technique. However, this age for the SMI volcanics also corresponds excellently with 40 Ar^ 39 Ar ages of V 89 ^ 85 Ma (weighted mean isochron age 87. 6 þ 1. 2 Ma, 2 c: equivalent to 88. 1 þ 1. 2 Ma corresponding to MMhb- 1 age of 523. 1 þ 2. 6 Ma) for the Madagascar flood basalt province. Together, therefore, the Madagascar flood basalt province, the SMI volcanics, and possibly the Kerala dykes could represent volcanic activity associated with the break-up of Greater India (India plus Seychelles) and Madagascar...|$|E
40|$|A {{simple method}} is {{reported}} for the epoxidation of hydroxyl-terminated polybutadiene (HTPB) by using in-situ generated dimethyl dioxirane (DMD) as an oxidant and Cloisite 15 Aº nanoclay as a phase-transfer catalyst (PTC). In order to find the optimum reaction conditions, real time analyses of the products as well as epoxidation progress, followed by ¹HNMR and FTIR techniques at various reaction times and different PTC concentrations, were done. Obtained <b>data</b> revealed the <b>selectivity</b> of DMD/ Cloisite 15 Aº in predominant cis double bonds epoxidation in comparison with trans and pendant vinyl functional groups...|$|R
40|$|There {{was a clear}} {{difference}} in affinity (257 -fold) for methoctramine between the muscarinic receptors involved in the methacholine-induced contraction of isolated pig coronary and basilar arteries, whereas atropine did not discriminate between the muscarinic receptors in these arterial smooth muscle preparations. Comparison of this finding with recent <b>data</b> on the <b>selectivity</b> of methoctramine suggests that the basilar artery contains M 2 receptors whereas those in the coronary artery belong to the muscarinic receptor subtype which is present in exocrine glands (M 3) and/or in ileal smooth muscl...|$|R
30|$|The ceramic matrix {{is formed}} mainly with {{particles}} of micron size, which are distorted due to annealing and pressure. The ion exchanger consists of nanosized particles, the radius {{of which is}} 3 to 5  nm. The nanoparticles form aggregates (rp[*]=[*] 20 to 23  nm). The larger particles form pores, which are responsible for charge selectivity. Radii of narrowing of these pores have been estimated as 4 to 8  nm; this is in agreement with porosimetry <b>data.</b> Charge <b>selectivity</b> is also due to ion exchange ability of HZD, which is retained under thermal treatment of the membranes. The materials {{can be used for}} electromembrane separation; the modified membranes demonstrate higher desalination degree and current efficiency in comparison with the pristine separator. Mechanical stability of the active layer is provided by its location inside pores of ceramics. As expected, the membranes can be used in aggressive media as well as for treatment of solutions containing organic substances.|$|R
40|$|In {{this study}} the Canadian Cordilleran {{displacements}} inferred from paleomagnetic {{results have been}} reevaluated by reviewing the existing data base {{with the addition of}} new data. Results from the Eocene Ootsa Lake Group yield a pole position which is statistically indistinguishable from published 50 Ma reference poles for North America. This is consistent with paleomagnetic results from Stikinia, Quesnellia, southern Wrangellia, and the Coast Belt indicating that much of the allochthonous CC had docked with the craton by 50 Ma.;Paleomagnetic directions from the Early Jurassic Telkwa Formation from this study confirm, with improved precision, the data obtained by Monger and Irving (1980). The reanalysis of the tectonic displacements indicated by all the CC Early Jurassic paleomagnetic data indicates that Terrane I, from the Permian to Early Jurassic, was in its present latitudinal position relative to the craton. Similar latitudinal concordance of southern Wrangellia with Terrane I and North America is suggested by the reanalysis of the Bonanza Group result.;The significant implication which has not been considered by previous large-scale northward displacement models is that the pre-Cretaceous data requires first large-scale southward displacement after the Early Jurassic. Paleomagnetic constraints from rocks with reasonable paleohorizontal control were provided by the Kasalka Group of this study and several other recent studies which support moderate (dollar≈dollar 1000 km) northward translation consistent with geologic estimates of maximum strike-slip along major CC transcurrent faults. Thus, the Cretaceous CC data is best explained by a CC displacement model in which moderate (dollar≈dollar 1000 km) northward translation has taken place, combined with local tilting of the Coast Belt intrusives and local block rotations principally in the Intermontane Belt. The solution to the 2 ̆ 2 tilt vs. translation 2 ̆ 2 controversy appears to be {{a combination of the two}} models. This interpretation has the desirable attribute of not requiring <b>data</b> <b>selectivity</b> as a prerequisite to the model as all the CC Cretaceous paleomagnetic results can be accommodated by this model. In addition, it is consistent with moderate post mid-Cretaceous northward displacements originally proposed by Monger and Irving (1980) and later reconfirmed by Armstrong et al. (1985) ...|$|E
40|$|Effectively using heterogeneous, {{distributed}} {{information has}} attracted much research in recent years. Current web services technologies {{have been used}} suc- cessfully in some non data intensive distributed systems. However, {{we still need to}} investigate the performance of web services applied on data intensive distributed systems. To take a step further, compositing several distributed services together normally needs web service composition technique. Obviously different compo- sition plans would end up with different performances at the end. Especially in a data intensive environment, choosing an optimal plan becomes even more critical. For example, Environment Protection agency, Queensland (EPA) needs an effective and optimal solution of providing spatial information services from several organizations. The data volumes need to be transferred and processed of are extremely high. A bad composition plan may end up running for days. In the contrast, a good plan may only take a couple of minutes. Therefore, our work here is to provide EPA a system prototype that is smart enough to effectively provide spatial information services by using web services over the Internet. To make our system clever enough to know what the best plan is, we propose a cost model to predict and estimate the cost of each plan. This cost model requires <b>data</b> <b>selectivity</b> estimation as a key parameter. In another words, the more precise the selectivity estimation on underlying dataset is, the more accurate our system is to pick up an optimal plan. Therefore, to make more accurate estimation and suite web services dynamic feature, we propose a query execution feedback learn- ing based histogram and parametric technique to estimate range query selectivity. Actually histograms have been studied extensively in the context of selectivity es- timation and approximate query processing. Comparing to static histograms that require periodical histogram reconstruction to reflect changes of the underlying data distribution, workload-aware dynamic histograms can self-tune itself based on user query feedback. Without scanning or sampling the underlying datasets in a systematic and comprehensive way, dynamic histograms allocate more buckets not only for the areas with most skewed data distribution but also according to users 2 ̆ 7 interests. A major limitation of such an approach, however, is that it takes long time to warm-up (i. e., a large number of queries need to be processed before the histogram can provide a satisfactory coverage and accuracy), and it is less effective to adapt to workload changes. To sum up, in this thesis, we investigate performance issues of applying web services in data intensive environment. To optimize dynamic web service com- positions strategies, we propose a cost model to measure different composition plans. And we develop a self-tuning histogram and parametric technique to esti- mate key parameters of our proposed cost model. This is the core contribution of our work as it has a direct impact on our system 2 ̆ 7 s performance...|$|E
40|$|A polymer-based, Cytop planar {{photonic}} crystal waveguide (PPCW) {{was designed for}} guiding terahertz radiation. Results indicate that the propagation and coupling losses in the 0. 2 - 1. 1 THz range are relatively small for a sheetlike thickness design. Spectral analysis of the transmission <b>data</b> reveals frequency <b>selectivity</b> of the PPCW. Calculations of the spatial distribution of the terahertz electric field through the waveguide show evidence of single-mode propagation at a 0. 45 THz central frequency. The highly transparent nature of Cytop from deep ultraviolet to the far infrared region indicates its potential use as an integral component in hybrid optics...|$|R
40|$|Protein kinase inhibitors are a {{well-established}} class of clinically useful drugs, {{particularly for the}} treatment of cancer. Achieving inhibitor selectivity for particular protein kinases often remains a significant challenge in the development of new small molecules as drugs or as tools for chemical biology research. This review summarises the methodologies available for measuring kinase inhibitor selectivity, both in vitro and in cells. The interpretation of kinase inhibitor <b>selectivity</b> <b>data</b> is discussed, particularly with reference to the structural biology of the protein targets. Measurement and prediction of kinase inhibitor selectivity will be important for the development of new multi-targeted kinase inhibitors...|$|R
40|$|We study smoking persistence, {{which can}} be due to both true state {{dependence}} and individual unobserved heterogeneity, in ten European countries. We distinguish between the two sources of persistence by using semi-parametric dynamic panel selection methods, applied to both smoking participation and cigarette consumption. We find that for both smoking decisions true state dependence is generally much smaller when unobserved individual heterogeneity is taken into account, and we also uncover large differences in true state dependence across countries. Finally, allowing for heaping in the reported number of cigarettes smoked considerably improves the fit of our model. smoking, panel <b>data,</b> state dependence, <b>selectivity...</b>|$|R
40|$|Adsorption of {{quinoline}} (pKa 5 4. 92) {{and background}} electrolyte (CaCl 2) onto specimen kaolinite and montmorillonite were measured {{as a function}} of pH (3 – 7. 5) and ionic strength (1 – 10 mM), and as a func-tion of quinoline concentration (0. 2 – 1. 55 mM) at fixed pH values of maximum adsorption. Maximum sorption of quinoline occurred at pH 3. 5 – 4. 0 for kaolinite, and pH 3. 0 – 5. 0 for montmorillonite. At their respective pH values of maximum adsorption, the sorption capacity for quinoline was 100 times greater with montmorillonite than kaolinite on a mass basis. Selectivity coefficients, which were calculated from pH edge <b>data,</b> indicated <b>selectivity</b> for cationic quinoline (QH 1) over Ca 21 was greater with montmoril-lonite (Kexc 5 27 at pH 4) compared to kaolinite (Kexc 5 1. 6 at pH 4), and Kexc was not affected by ionic strength for either clay. The results indicate the important role of charged siloxane sites in the adsorption of this N-heterocyclic contaminant. Key words: quinoline; adsorption; kaolinite; montmorillonite; selectivity coefficients; heterocyclic aro-matic...|$|R
