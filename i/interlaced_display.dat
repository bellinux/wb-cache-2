10|37|Public
50|$|The {{technique}} {{does not}} in fact achieve a true <b>interlaced</b> <b>display,</b> as the Spectrum lacks the ability to synchronise with the display hardware at such a low level. Rather, the effect is more akin to anti-aliasing, with certain pixels appearing at half intensity.|$|E
50|$|The {{progressive}} {{output of}} a DVD player {{can be considered}} the baseline for EDTV. Movies shot at 24 frames-per-second (fps) are often encoded onto a DVD at 24 fps progressive, and most DVD players do the 2:2 or 3:2 pulldown conversion internally, before feeding the output to (usually) an <b>interlaced</b> <b>display,</b> or here, a progressive 576p or 480p.|$|E
50|$|Elements of some sprite-based {{games that}} were {{originally}} designed for <b>interlaced</b> <b>display</b> may appear less detailed when displayed in progressive mode {{due to the}} lack of scanlines softening the image. However, these games are officially considered compatible with the VGA Box because they can be played normally in VGA mode, and were thus branded as compatible on packaging and marketing materials.|$|E
2500|$|The {{use of an}} <b>interlace</b> <b>display</b> script {{in which}} each letter is joined to one another by means of brontosaurus-like beast heads; and ...|$|R
50|$|Early high-definition (HD) plasma {{displays}} had {{a resolution}} of 1024x1024 and were alternate lighting of surfaces (ALiS) panels made by Fujitsu/Hitachi. These were <b>interlaced</b> <b>displays,</b> with non-square pixels.|$|R
5000|$|... 2:2 {{pulldown}} {{is widely}} used in 50 Hz interlaced television systems to broadcast progressive material recorded at 25 frame/s, but is rarely used in 60 Hz systems. The 2:2 pulldown scheme had originally been designed for <b>interlaced</b> <b>displays,</b> so fine vertical details are usually filtered out to minimize interline twitter. PsF has been designed for transporting progressive content and therefore does not employ such filtering.|$|R
5000|$|Sony adapted HDV, {{originally}} {{conceived as}} progressive-scan format by JVC, to interlaced video. Interlaced video {{has been a}} useful compromise for decades due to its ability to display motion smoothly while reducing recording and transmission bandwidth. Interlaced video is still being used in acquisition and broadcast, but <b>interlaced</b> <b>display</b> devices are being phased out. Modern flat-panel television sets that utilize plasma and LCD technology are inherently progressive. All modern computer monitors use progressive scanning as well.|$|E
5000|$|The above {{method is}} a [...] "classic" [...] 2:3, {{which was used}} before frame buffers allowed for holding more than one frame. The {{preferred}} method for doing a 2:3 creates only one dirty frame in every five (i.e. 3:3:2:2 or 2:3:3:2 or 2:2:3:3); while this method has slightly more judder, it allows for easier upconversion (the dirty frame can be dropped without losing information) and a better overall compression when encoding. The 2:3:3:2 pattern {{is supported by the}} Panasonic DVX-100B video camera under the name [...] "Advanced Pulldown". Note that just fields are displayed—no frames hence no dirty frames—in <b>interlaced</b> <b>display</b> such as on a CRT. Dirty frames may appear in other methods of displaying the interlaced video.|$|E
5000|$|In {{the case}} of most media, such as DVD movies and video games, the video is blurred during the {{authoring}} process itself to subdue interline twitter when played back on interlace displays. As a consequence, recovering the sharpness of the original video is impossible when the video is viewed progressively. A user-intuitive solution to this is when display hardware and video games come equipped with options to blur the video at will, or to keep it at its original sharpness. This allows the viewer to achieve the desired image sharpness with both interlaced and progressive displays. An example of a video game with this feature is Super Smash Bros. Brawl, where a [...] "Deflicker" [...] option exists. Ideally, [...] "Deflicker" [...] would be turned on when played on an <b>interlaced</b> <b>display</b> to reduce interline twitter, and off when played on a progressive display for maximum image clarity.|$|E
5000|$|... 512×512 virtual (320×480 <b>display,</b> <b>interlaced)</b> @ 32,768 colors - overlay not {{supported}} ...|$|R
50|$|According to Neil Schneider, {{executive}} director of the S-3D Gaming Alliance, NVIDIA has developed a proprietary method for NVIDIA's GeForce 3D Vision that allows left and right images to be passed directly from the game engine to the PC display, in the form of quad buffers. Up until Avatar, this was a limitation criticized by the gaming industry because they were forced to use NVIDIA's stereoscopic 3D driver when they would prefer to have full control of the S-3D gaming experience. Alternate solutions like iZ3D monitors, <b>interlaced</b> <b>displays,</b> dual output projectors and 3D Checkerboard DLP do not require this enhancement because game developers have full output control.|$|R
5000|$|... 256×512 virtual (256×240 <b>display,</b> <b>interlaced)</b> @ 32,768 colors - overlay {{support with}} mode 9 ...|$|R
50|$|By the mid-1980s, {{computers}} had outgrown these video {{systems and}} needed better displays. The Apple IIgs {{suffered from the}} use of the old scanning method, with the highest display resolution being 640x200, resulting in a severely distorted tall narrow pixel shape, making the display of realistic proportioned images difficult. Solutions from various companies varied widely. Because PC monitor signals {{did not need to be}} broadcast, they could consume far more than the 6, 7 and 8 MHz of bandwidth that NTSC and PAL signals were confined to. IBM's Monochrome Display Adapter and Enhanced Graphics Adapter as well as the Hercules Graphics Card and the original Macintosh computer generated a video signal close to 350p. The Commodore Amiga created a true interlaced NTSC signal (as well as RGB variations). This ability resulted in the Amiga dominating the video production field until the mid-1990s, but the <b>interlaced</b> <b>display</b> mode caused flicker problems for more traditional PC applications where single-pixel detail is required. 1987 saw the introduction of VGA, on which PCs soon standardized, Apple only followed suit some years later with the Mac when the VGA standard was improved to match Apple's proprietary 24 bit color video standard also introduced in 1987.|$|E
5000|$|There are two {{horizontal}} graphics resolutions, [...] "lowres" [...] with 140 ns pixels and [...] "hires" [...] with 70 ns pixels, with a default of 320 or 640 horizontal pixels wide {{without using}} overscan. As the pixel output is {{regulated by the}} main system clock, which is based directly on the NTSC colorburst clock, these sizes very nearly fill {{the width of a}} standard television with only a thin [...] "underscan" [...] border between the graphics and the screen border when compared to many other contemporary home computers, for an appearance closer to a games console but with finer detail. On top of this, Denise supports reasonably extensive overscan; technically modes with enough data for upto 400 or 800 pixels (+25%) may be specified, although this is only actually useful for scrolling and special effects that involve partial display of large graphics, as a separate hardware limit is met at 368 (or 736) pixels, which is the maximum that will fit between the end of one blanking period and the start of the next - although it is unlikely that even this many pixels will be visible on any display other than a dedicated monitor that allows adjustment of horizontal scan width, as much of the image will, by design, disappear seamlessly behind the screen bezel (or, on LCDs, be cropped off {{at the edge of the}} panel). Because of the highly regular structure of the Amiga's timing in relation to scanlines and allocation of DMA resources to various uses besides normal [...] "playfield" [...] graphics, increased horizontal resolution is also a tradeoff between number of pixels and how many hardware sprites are available, as increasing the DMA slots dedicated to playfield video ends up stealing some (from 1 to 7 of the total 8) the sprite engine.http://amigadev.elowar.com/read/ADCD_2.1/Hardware_Manual_guide/node02D4.html. Vertical resolution, without overscan, is 200 pixels for an 60 Hz NTSC Amiga or 256 for a 50 Hz PAL Amiga. This can be doubled using an <b>interlaced</b> <b>display,</b> and, as with horizontal resolution, increased using overscan, to a maximum of 241 (or 483) for NTSC, and 283 (567) for PAL (interlaced modes gaining one extra line as the maximum is determined by how many lines are taken from the available total by blanking and sync, and the total scanlines in non-interlaced modes are half the original, broadcast-spec odd-numbered interlaced counts, rounded down).|$|E
40|$|Aims: To compare {{monoscopic}} and stereoscopic {{assessment of}} the optic disc using novel software for the digital stereoscopic analysis of optic disc stereopairs. Methods: Software was developed for the stereoscopic display of digital optic disc images using an <b>interlaced</b> <b>display</b> method. Neuroretinal rim width was determined at 10 degree intervals around the optic disc using a custom (stereoscopic) cursor whose depth was adjusted to that of Elschnigâ€™s rim. Measurements were taken, first viewing the disc monoscopically and at a separate sitting, stereoscopically. Results: Measurements were made in 35 eyes from 35 patients (1260 estimates for each observer) using three observers. The mean cup to disc ratio (CDR) ranged from 0. 57 to 0. 66 (SD 0. 13 â€“ 0. 14) for monoscopic viewing compared with 0. 64 to 0. 69 (SD 0. 12 â€“ 0. 14) for stereoscopic viewing. Stereoscopic assessments gave higher CDRs in temporal, superior, nasal, and inferior aspects of the optic disc (p< 0. 001, Mann-Whitney U test). Agreement between observers in estimating CDR was high for monoscopic assessment (intraclass correlation coefficient 0. 74 (CI 0. 72 to 0. 76) increasing to 0. 80 (0. 78 to 0. 82) for stereoscopic assessment. Conclusion: Digital stereoscopic optic disc assessment provides lower estimates of neuroretinal rim width {{and higher levels of}} interobserver agreement compared with monoscopic assessments...|$|E
5000|$|... 256×512 virtual (256×256 <b>display,</b> <b>interlaced)</b> @ 32,768 colors - overlay {{support with}} modes 3 or 10 ...|$|R
5000|$|Full-screen {{resolution}} {{generated by}} the SAA5050 was 480&times;500 pixels, corresponding to 40&times;25 characters. Each character position therefore corresponded to a 12&times;20 pixel space. Internally each character shape was defined on a 5&times;9 pixel grid. This was then interpolated by smoothing diagonals to give a 10&times;18 pixel character, with a characteristically angular shape, surrounded {{to the top and}} to the left by two pixels of blank space. This gave a particularly stable and flicker-free arrangement on <b>interlaced</b> <b>displays.</b> The alternate set of 2&times;3 block graphic characters were created on the same 12&times;20 pixel grid, so that the top two blocks were each 6&times;6 pixels, the middle two blocks each 6&times;8 pixels, and the bottom two blocks again 6&times;6 pixels (or two fewer in each direction, if the [...] "separated graphics" [...] control character had been sent).|$|R
50|$|ALiS plasma {{panels and}} the old CRTs can <b>display</b> <b>interlaced</b> video directly, but modern {{computer}} video displays and TV sets are mostly based on LCD technology, which mostly use progressive scanning.|$|R
50|$|Each desktop or 'screen' {{could have}} its own colour depth (number of {{available}} colours) and resolution, including use of <b>interlacing.</b> The <b>display</b> chipset ('graphics card' on a PC) could switch between these desktop modes on the fly, and during the drawing of a single screen, usually with three pixel deep line between each desktop shown on the screen. However, if one interlaced (flickering) desktop was displayed, all desktops onscreen would be similarly affected.|$|R
50|$|Note: Because the {{refresh rate}} has been slowed {{down by a}} factor of three, and the {{resolution}} is less than half a resolution of a typical interlaced video, the flicker in the simulated interlaced portions and also the visibility of the black lines in these examples are exaggerated. Also, the images above are based on what it would look like on a monitor that does not support interlaced scan, such as a PC monitor or an LCD or plasma-based television set, with the <b>interlaced</b> images <b>displayed</b> using the same mode as the progressive images.|$|R
50|$|Analog display devices {{reproduce}} each {{frame in}} the same way, effectively doubling the frame rate as far as perceptible overall flicker is concerned. When the image capture device acquires the fields one at a time, rather than dividing up a complete frame after it is captured, the frame rate for motion is effectively doubled as well, resulting in smoother, more lifelike reproduction (although with halved detail) of rapidly moving parts of the image when viewed on an <b>interlaced</b> CRT <b>display,</b> but the display of such a signal on a progressive scan device is problematic.|$|R
50|$|This {{effectively}} doubles {{the time}} resolution (also called temporal resolution) {{as compared to}} non-interlaced footage (for frame rates equal to field rates). Interlaced signals require a display that is natively capable of showing the individual fields in a sequential order. CRT displays and ALiS plasma displays are made for <b>displaying</b> <b>interlaced</b> signals.|$|R
50|$|Before <b>interlaced</b> {{video is}} <b>displayed</b> on a progressive-scan device {{it must be}} {{converted}} to progressive using the process known as deinterlacing. Progressive-scan television sets employ built-in deinterlacing circuits to cope with interlaced broadcast signal, but computer video players rarely have this capability. As such, interlaced video may exhibit ghosting or combing artifacts when watched on a computer.|$|R
5000|$|Standard-definition {{television}} {{standards and}} practices were developed as broadcast technologies and intended for terrestrial broadcasting, and were therefore {{not designed for}} digital video presentation. Such standards define an image as an array of well-defined horizontal [...] "Lines", well-defined vertical [...] "Line Duration" [...] and a well-defined picture center. However, {{there is not a}} standard-definition television standard that properly defines image edges or explicitly demands a certain number of picture elements per line. Furthermore, analog video systems such as NTSC 480i and PAL 576i, instead of employing progressively displayed frames, employ fields or <b>interlaced</b> half-frames <b>displayed</b> in an interwoven manner to reduce flicker and double the image rate for smoother motion.|$|R
50|$|It {{also offers}} clearer and faster results for scaling to higher resolutions than its {{equivalent}} interlaced video, such as upconverting 480p to display on a 1080p HDTV. HDTVs {{not based on}} CRT technology cannot natively <b>display</b> <b>interlaced</b> video, therefore interlaced video must be deinterlaced before it is scaled and displayed. Deinterlacing can result in noticeable visual artifacts and/or input lag between the video source and the display device.|$|R
50|$|To <b>display</b> <b>interlaced</b> {{video on}} a {{progressive}} scan display requires {{a process called}} deinterlacing. This is an imperfect technique, and generally lowers resolution and causes various artifacts—particularly in areas with objects in motion. Providing the best picture quality for interlaced video signals requires expensive and complex devices and algorithms. For television displays, deinterlacing systems are integrated into progressive scan TV sets that accept interlaced signal, such as broadcast SDTV signal.|$|R
50|$|A Phase Alternating Line (PAL)-based {{television}} set display, for example, scans 50 fields every second (25 odd and 25 even). The {{two sets of}} 25 fields work {{together to create a}} full frame every 1/25 of a second (or 25 frames per second), but with interlacing create a new half frame every 1/50 of a second (or 50 fields per second). To <b>display</b> <b>interlaced</b> video on progressive scan displays, playback applies deinterlacing to the video signal (which adds input lag).|$|R
50|$|Interlaced {{video is}} {{designed}} to be captured, stored, transmitted, and displayed in the same interlaced format. Because each interlaced video frame is two fields captured at different moments in time, interlaced video frames can exhibit motion artifacts known as interlacing effects, or combing, if recorded objects move fast enough to be in different positions when each individual field is captured. These artifacts may be more visible when <b>interlaced</b> video is <b>displayed</b> at a slower speed than it was captured, or in still frames.|$|R
50|$|Software {{emulation}} would copy {{from the}} CGA video memory location to the Hercules memory location. It would reformat the CGA data (320 or 640 × 200 pixels) {{to the higher}} resolution (720 × 348) Hercules. Because of the reformatting of data while copying to completely fill the 720×348 graphics space, and the speed penalty introduced via that method, this introduced an <b>interlacing</b> type of <b>display</b> artifact since the copying could not complete {{before the beginning of}} the next display cycle.|$|R
50|$|RCA, then a {{world leader}} in {{television}} technology, had been experimenting with military television systems for some time at this point. As part of this they had developed a miniaturized iconoscope, the 1846, suitable for use in aircraft. In 1941 these were experimentally used to fly drone aircraft and in April 1942 one of these was flown into a ship about 50 km away. The US Army Air Force ordered a version of their GB-1 glide bomb to be equipped with this system, which became the GB-4. It {{was similar to the}} Hs 293D in almost every way. The Army's Signal Corps used the 1846 with their own transmitter and receiver system to produce an <b>interlaced</b> video <b>display</b> with 650 lines of resolution at 20 frames a second (40 fields a second). A film recorder was developed to allow post-launch critique.|$|R
50|$|Another {{innovation}} (for its time) is the VIDEL video controller. The possibilities {{offered by}} the graphics processor are limited only by its frequency (25/32 MHz core, adjustable to 50 MHz with a hardware accelerator) and the slowness of the RAM, as the graphics memory is shared with system memory which can degrade performance significantly when using high resolutions or video modes requiring many bit planes. The parameters are numerous; each timing of a video line (start, end, number of pixels, etc.) is adjustable, the image may be interlaced or not, and the vertical frequency can go down to 50 Hz <b>interlaced</b> to <b>display</b> on a television. The number of colors is also adjustable when VIDEL operates in bit plane mode. This mode is available for compatibility with the previous generation, but is quite complex to manage. There is also a true color 16-bit mode in which bits defining each pixel are grouped together to display 65,536 colors simultaneously, though CPU performance is degraded while displaying this mode.|$|R
50|$|Since the {{interlaced}} signal {{contains the}} two fields {{of a video}} frame shot at two different times, it enhances motion perception to the viewer and reduces flicker {{by taking advantage of}} the persistence of vision effect. This results in an effective doubling of time resolution as compared with non-interlaced footage (for frame rates equal to field rates). However, interlaced signal requires a display that is natively capable to show the individual fields in a sequential order, and only traditional CRT-based TV sets are capable of <b>displaying</b> <b>interlaced</b> signal, due to the electronic scanning and lack of apparent fixed resolution.|$|R
50|$|An {{interlaced}} {{video frame}} {{consists of two}} sub-fields taken in sequence, each sequentially scanned at odd, and then even, lines of the image sensor. Analog television employed this technique because it allowed for less transmission bandwidth and further eliminated the perceived flicker that a similar frame rate would give using progressive scan. CRT-based displays were able to <b>display</b> <b>interlaced</b> video correctly due to their complete analogue nature. Newer displays are inherently digital, in that the display comprises discrete pixels. Consequently, the two fields need to be combined into a single frame, which leads to various visual defects. The deinterlacing process should try to minimize these.|$|R
25|$|There {{is thus a}} filesize {{trade-off}} {{between high}} color depth, maximal metadata (including color space information, together with information that does not affect <b>display),</b> <b>interlacing,</b> and speed of compression, which all yield large files, with lower color depth, fewer or no ancillary chunks, no interlacing, and tuned but computationally intensive filtering and compression. For different purposes, different trade-offs are chosen: a maximal file may be best for archiving and editing, while a stripped down file may be best for use on a website, and similarly fast but poor compression is preferred when repeatedly editing and saving a file, while slow but high compression is preferred when a file is stable: when archiving or posting.|$|R
50|$|Wobulation {{works by}} {{overlapping}} pixels. It does so by generating multiple sub-frames of data while an optical image shifting mechanism (e.g. {{the mirror of}} a digital micromirror device) then displaces the projected image of each sub-frame by {{a fraction of a}} pixel (e.g. one-half or one-third). The sub-frames are then projected in rapid succession, and appear to the human eye as if they are being projected simultaneously and superimposed. For example, a high-resolution HDTV video frame is divided into two sub-frames, A and B. Sub-frame A is projected, and then the miniature mirror on a digital micromirror device switches and displaces sub-frame B one half pixel length as it is projected. When projected in rapid succession, the sub-frames superimpose, and create to the human eye a complete and seamless image. If the video sub-frames are aligned so that the corners of the pixels in the second sub-frame are projected at the centers of the first, the illusion of double the resolution is achieved, like in an <b>interlaced</b> CRT <b>display.</b> Thus a lower resolution fixed pixel device using wobulation can emulate the picture of higher resolution fixed device, at a reduced cost.|$|R
30|$|There are {{two basic}} types of de-interlacing algorithms: field {{combination}} and field extension [15]. In the field extension type, there is a de-interlacing method called vertical half-sizing. In this method, each <b>interlaced</b> field is <b>displayed</b> separately, resulting in a video with half the vertical resolution of the original one, this alleviates the problem of combing artifacts. This method is implemented by deleting all the even or odd lines of the interlaced frame. It can eliminate most combing artifacts but it severely degrades the video quality and breaks the aspect ratio, and hence, it is not widely used for de-interlacing. We focused on the powerful de-interlacing ability of vertical half-sizing and used it {{as the basis of}} our scheme to separate the screenshots and nonscreenshots.|$|R
