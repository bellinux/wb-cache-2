16|7|Public
50|$|Il présageait bien les séquelles tristes et pénibles de cet exil: la séparation de ses ouailles, de ses parents et amis, et de sa patrie bien-aimée, l'incertitude d'un pays étranger, le problème de survie dans un pays où l'exercice du sacerdoce catholique et en langue étrangère était peu prometteur, et quoi encore. Bien que ce pays ait été à {{plusieurs}} reprises l'antagoniste obstiné de la France en temps de guerre, il témoigne pourtant d'une hospitalité remarquable envers ces malheureux émigrés. Il fait preuve d'autant de commisération humanitaire qu'il lui était possible dans les circonstances, allant même jusqu'à payer une obole de deux à quatre guinées aux exilés dans le besoin. Dans l'ensemble cela était, cependant, grandement <b>insuffisant</b> pour faire vivre cette masse de réfugiés français qui ne pouvait réellement pas vivre de leur sacerdoce en un pays étranger de religion protestante. En résumé, Sigogne a vécu sept ans en Angleterre d'où il est parti le 16 avril 1799 dans l'espoir de reprendre la pratique de son ministère sacerdotal, cette fois en Acadie (Nouvelle-Écosse). Durant son exil {{en terre}} britannique, il s'est adonné à des besognes journalières, à des oeuvres de charité et d'éducation dans la mesure où le lui permettaient les circonstances de l'époque.|$|E
40|$|Enzo Traverso, Totalitarianism : History and Contradictions of a Concept The {{concept of}} {{totalitarianism}} seems both inevitable and unusable because it concerns only a typology of power relations. The {{problem is that}} it cannot explicate either the genesis or the history of these structural relationships. If historians and sociologists cannot ignor the notion, they also cannot accept its limitations. Now that the ideological and political connotations of the concept can be disregarded, it is nevertheless probable that it remains <b>insuffisant</b> in explaining the phenomena specific to the twentieth century. Traverso Enzo. Le totalitarisme. Histoire et apories d'un concept. In: L'Homme et la société, N. 129, 1998. Regards sur l'humanitaire. pp. 97 - 111...|$|E
40|$|En {{conditions}} chaudes et sèches, les résultats d’un essai en pots sur la lignée de maïs « F 7 » indiquent que l’envahissement des tiges par le complexe Fusarium moniliforme Sheld. + Macrophomina phaseoli Maubl. a lieu lorsque sont réalisées trois conditions : - présence de ces champignons, - tige appauvrie en glucides par la présence d’un épi bien garni, - arrosage <b>insuffisant.</b> Three factors seem to {{be necessary}} for stalk rot apparition in maize : - presence at the crown of the plant of semi-parasitic fungi like Fusarium moniliforme and Macrophomina phaseoli in mediterranean and subtropical areas, - carbohydrate depletion of the stalk by the metabolic sink of a fully garnished ear, - a physiological stress endured by the maize plant, which was drought at temperatures superior to 20 °C in the situation studied here. The necessity of these three factors was demonstrated in an experiment with plants of the inbred line « F 7 » growing in plastic containers in the open, with four treatments combining optimal and restricted irrigation, and inoculation (or not) {{with a mixture of}} F. moniliforme + M. phaseoli...|$|E
5000|$|Auzière-Jourdan {{practices}} {{high risk}} cardiology and vascular diseases in Vincennes and Nogent-sur-Marne. She practices with cardiologists Didier Catuli and Pierre Sablon. She has published research in cardiology, including [...] "Facteurs échographiques associés à un niveau de BNP élevé chez les <b>insuffisants</b> cardiaques: interaction systole diastole. (2004)" ...|$|R
40|$|National audienceObjectives: In 2015, a {{formative}} assessment about relevance of parenteral nutrition (PN) prescriptions {{was performed in}} a French Cancer Center following the survey proposed by the French speaking Society for Clinical Nutrition and Metabolism (SFNEP). Methods: All patients hospitalized in acute care wards from January 1 st to December 31, 2014 and receiving PN were retrospectively studied. Were analyzed the criteria for PN indication relevance: previous nutritional assessment and non-functional gastrointestinal tract; PN prescription relevance: micronutrients administration, amount of energy prescribed, PN duration, and relevance of clinical and biological monitoring. Results: Forty-six patients (49 PN prescriptions) were studied. The indication was relevant in only 53 % of cases. Enteral nutrition was tested or proposed but refused in 2 % of cases. Nutritional screening was performed in 65 % of cases. In 39 % of cases, energy intake was not adequate: > 35 kcal/kg/day in 6 % or 35 kcal/kg/jour dans 6 % ou < 20 kcal/kg/jour dans 33 % des cas. L’adjonction de micronutriments était manquante dans 14 % des prescriptions. La durée moyenne de la NP était de 10, 9 ± 8, 8 jours. La surveillance du poids était réalisée dans 31 % des cas et la surveillance biologique était incomplète dans 96 % des cas. Conclusion: La plupart des prescriptions de NP ne respectait pas les recommandations de la SFNEP, notamment parce que le recours à la nutrition entérale et le dépistage de la dénutrition étaient <b>insuffisants...</b>|$|R
40|$|Le cancer du sein est {{le cancer}} le plus fréquent chez les femmes. Il y a une {{multitude}} de solutions proposées concernant une éventuelle intervention médicale pour le cancer du sein une en particulier est la chirurgie mammaire conservatrice (tumoréctomie). Le but de la tumoréctomie est de parvenir à un contrôle local du cancer, ainsi que de préserver une forme du sein qui satisfait les besoins esthétiques de la femme. Bien que ces objectifs sont généralement atteint, il reste encore parfois des résultats inattendus,tels qu'une tumeur récurrence locale, ou des résultats cosmétiques <b>insuffisants.</b> L'objectif de cette thèse est de proposer une plateforme de calcul, qui contribue à la tumoréctomie. Cela comprend: 1) Une étude de la dynamique de croissance des tumeurs du sein. 2) Une étude sur la prédiction du contour du sein grâce a la chirurgie virtuelle. 3) Un modèle de calcul de la forme finale du sein après cicatrisation. Breast {{cancer is the}} most common cancer among women in the developed as well as the developing countries. There are a plethora of proposed solutions regarding possible medical interventions for breast cancer one in particular is Breast Conserving Therapy (BCT). BCT comprises of complete surgical excision of the tumor (partialmastectomy), and post-operative radiotherapy for the remaining breast tissue. This is a feasible treatment for most women with breast cancer. The goal of BCT is toachieve local control of the cancer, as well as to preserve breast shape that appeases awoman s cosmetic concerns. Although these goals are usually achieved, there are still occasional unexpected results, such as reexcision of the tumor due to a positive margin assessment, tumor local recurrence, unsatisfactory cosmetic results, and breastpain. Other than surgical experience and judgment, there are currently no toolswhich can predict the outcome of partial mastectomy on the contour and deformity of the treated breast. The objective of this dissertation is to propose computational framework, which contributes to BCT operations, this was achieve by exploring two areas. On the one hand we developed a multiscale model adapted for breast cancer tumor growth, ductal carcinoma in situ (DCIS). The model features included: nutrients growth limitation, wall degradation enzyme and HER 2 chemical expression tumor phenotype. Our model successfully simulate some pattern of DCIS carcinoma. Among the interesting result we showed that the enzyme contributed to a greater tumor size and that when HER 2 was over expressed, the growth limiting factor wasthe EGFR. On the other hand, we developed a virtual surgery box to simulate BCT surgery. The box will input MRI patient data and will output cosmetic and functional indicator to rate the impact of the surgery. It appears that stiffness of the tissue, resection radius as well as the lump quadrant location are the most sensitive parameters to the indicators. A healing model was also embedded to simulate the wound closure after resection, this model was stress dependent and illustrate anasymmetric wound closure progression. The tools developed in this research allows a new type of field convergence between the surgery and computation field. At the local level it will allow surgeons and patient to be able to communicate on the pertinence and necessity of performing alumpectomy surgery, enabling to anticipate the possible outcome of the operation. On the global aspect this type of tool gives birth to a new type of field: computational surgery, where computer scientist and surgeons work hand in hand to provide the best and the most reliable service to the patients. BORDEAUX 1 -Bib. electronique (335229901) / SudocSudocFranceF...|$|R
40|$|Cet article vise à dégager les {{implications}} ontologiques du projet Ricoeurien d’une herméneutique du soi tel que formulé dans Soi-même comme un autre. L’auteur retrace d’abord la double approche de Ricoeur proposant de penser l’attestation du soi suivant la notion aristotélicienne de l’être-vrai et l’homme capable selon les catégories de l’acte et de la puissance. Soulignant le caractère fragmentaire et <b>insuffisant</b> des analyses de Ricoeur, il explore ensuite une troisième façon de nommer l’être du soi selon la catégorie de la relation, développant ainsi l’idée d’une “ontologie de la relation” sous-jacente à cette herméneutique du soi.   This article aims to make explicit {{the ontological}} {{implications of the}} Ricœurian project of a hermeneutics of self as formulated in Oneself as Another. The author first redraws Ricœur’s double approach proposing to think the attestation of the self following the Aristotelian notion of being-true and the capable man following the categories of actuality and potentiality. Underlining the fragmentary nature and the incompleteness of Ricœur’s analysis, he then explores a third way {{to speak about the}} being of the self following the category of relation, thus developing the idea of an underlying “ontology of the relation” implied by this hermeneutics of the self.    </p...|$|E
40|$|Separated {{from the}} rest of the country by the slopes of the Boutières and badly {{connected}} to the Rhône valley, the little town of Le Cheylard (4 500 inhabitants) has nevertheless succeeded in becoming a well known center of industrial activities one does not expect to find in the same place such as : textile industries, jewellery and bottling machines making. Yet, all these efforts have not been enough to acheive neither the restarting of a dying agriculture nor the revival of the upper valley of the Dorne which seems to the bound to lose its population. As of Le Cheylard it is however a small industrial town the clerical workers of which remains inadequate in number and quality. Will the growth of tourism create a new an more propitious situation ?Isolée par les pentes des Boutières et mal reliée à la vallée du Rhône, la petite ville du Cheylard (4 500 habitants) n'en a pas moins réussi à devenir un centre industriel réputé dans les secteurs les plus inattendus : verre industriel, bijouterie, machines d'embouteillage. Tout cet effort n'a pourtant permis ni la relance d'une agriculture moribonde, ni la réanimation de la haute vallée de la Dorne dont le dépeuplement semble inéluctable. De son côté, Le Cheylard reste une bourgade industrielle dont le secteur tertiaire demeure <b>insuffisant</b> par son étendue et sa qualité. Le développement du tourisme engendrera-t-il un équilibre plus favorable ?Coustaury Alain. Déclin et vitalité en Ardèche : la région du Cheylard. In: Revue de géographie de Lyon, vol. 49, n° 3, 1974. pp. 211 - 239...|$|E
40|$|NOTRE TRAVAIL PART DE L'HYPOTHESE QUE L'INEFFICACITE DE LA REPONSE IMMUNITAIRE HUMORALE AU COURS DE L'INFECTION PAR LE HIV- 1 S'EXPLIQUE PAR SA NATURE CLONALE, QUI S'ACCOMPAGNE D'UN REPERTOIRE B <b>INSUFFISANT,</b> ET QUI PEUT ETRE LIEE A L'EXISTENCE DE CERTAINS DETERMINANTS ANTIGENIQUES VIRAUX IMMUNODOMINANTS, ET PAR LE FAIT QU'ELLE PEUT COMPORTER UNE COMPOSANTE FACILITANT LA REPLICATION VIRALE. DANS UNE PERSPECTIVE D'UTILISATION VACCINALE, NOUS AVONS DONC MODIFIE PAR MUTAGENESE UN DES EPITOPES IMMUNODOMINANTS ET CONSERVES DE L'ENVELOPPE DU HIV- 1, LE DIP, DOMAINE IMMUNODOMINANT PRINCIPAL. NOUS AVONS PROCEDE A UNE MUTAGENESE ALEATOIRE DANS UNE ENVELOPPE M-TROPIQUE AU SEIN DE LA SEQUENCE LIMITEE PAR DEUX CYSTEINES DU DIP, ET A UNE MUTAGENESE DIRIGEE DE LA MEME SEQUENCE D'UNE ENVELOPPE T-TROPIQUE. NOTRE TRAVAIL NOUS A EN FAIT AMENE A UNE ANALYSE PLUS LARGE DES RELATIONS STRUCTURE/FONCTION DES GLYCOPROTEINES D'ENVELOPPE DU HIV- 1, CETTE MUTAGENESE DU DIP ETANT A L'ORIGINE D'UNE DESTABILISATION DU COMPLEXE FORME PAR LES DEUX SOUS-UNITES DE L'ENVELOPPE SU ET TM. NOUS AVONS ENSUITE COMPARE LES CONSEQUENCES DE CETTE DESTABILISATION DANS LES DEUX TYPES D'ENVELOPPES MUTEES. NOS RESULTATS MONTRENT QUE LA MUTAGENESE DANS L'ENVELOPPE M-TROPIQUE ABOUTIT A UNE PERTE DE CAPACITE INFECTIEUSE, ET A UNE CAPACITE FUSIOGENE DIMINUEE, ALORS QUE DANS UNE ENVELOPPE T-TROPIQUE ELLE A PEU OU PAS DE CONSEQUENCES FONCTIONNELLES. LES CONSEQUENCES BIOCHIMIQUES DE CETTE MUTAGENESE SONT DONC D'UNE PART L'INDUCTION D'UNE DESTABILISATION DU COMPLEXE SU/TM DANS LES DEUX TYPES D'ENVELOPPES, ET D'AUTRE PART, UNE ALTERATION DE LA MATURATION DES ENVELOPPES MUTEES M-TROPIQUES. NOUS SOUTENONS QUE CES PROPRIETES DE MATURATION DIFFERENTES SONT LIEES A DES CONTRAINTES DE REPLIEMENT DIFFERENTES ET A UNE CAPACITE DIFFERENTE A TOLERER LA DESTABILISATION INDUITE DANS LE COMPLEXE SU/TM. PAR AILLEURS, NOS RESULTATS MONTRENT QUE LA CONSERVATION DE LA SEQUENCE DU DIP EST AU MOINS EN PARTIE LIEE A DES CONTRAINTES DE STRUCTURE ET DE REPLIEMENT DE L'ENVELOPPE. NOS HYPOTHESES IMMUNOLOGIQUES INITIALES POURRONT ETRE VERIFIEES DANS LE MODELE FIV, NOUS AVONS A CE TITRE CONTRIBUE A CARACTERISER CE MODELE EN PARTICIPANT A UN TRAVAIL QUI A PERMIS DE MONTRER QUE CERTAINS ISOLATS PRIMAIRES DU FIV UTILISAIENT, COMME CERTAINS ISOLATS ADAPTES, LE CXCR 4 COMME CORECEPTEUR D'ENTREE. PARIS 7 -Bibliothèque {{centrale}} (751132105) / SudocSudocFranceF...|$|E
40|$|L'industrie textile utilise des {{colorants}} de synthèse toxiques qui polluent ses eaux résiduaires avec, parfois, des flux importants. Les procédés traditionnels les éliminent mal : ils sont peu iodégradables et la seule floculation, {{par exemple}} par des sels de fer, donne des résultats <b>insuffisants.</b> Or, en Algérie, la réutilisation agricole des eaux usées même industrielles est devenue une impérieuse nécessité. Le procédé proposé repose sur l'utilisation de sels d'aluminium ou, mieux encore, un polyhydroxyaluminium, associés à une bentonite de forage très fine présentant l'avantage d'être localement disponible et peu coûteuse. Quatre colorants ont été testés. Ils appartiennent à deux grandes familles : les colorants acides d'une part, Jaune Supranol 4 GL et Vert Nylomine C 8 B et les colorants dispersifs d'autre part, Rouge Foron RDGL et Violet Foron S 3 RL. Les essais montrent que, si la bentonite seule ou les sels d'aluminium seuls présentent des efficacités insuffisantes, ces derniers du fait d'une mauvaise décantabilité des microflocs formés, l'association bentonite-aluminium permet d'éliminer les colorants en quasi totalité avec une excellente décantabilité. Les concentrations optimales à mettre en oeuvre sont relativement basses, de l'ordre de 13 mg/l de Al 3 + et 250 mg/l de bentonite. Les coûts d'exploitation sont donc très raisonnables. Sur un effluent industriel réel, le procédé permet de passer d'une DCO de 770 mg/l à moins de 30 mg/l. The textile industry uses synthetic dyes, {{most of them}} being toxic. In Algeria, the agricultural reuse of treated wastewater, even of industrial origin, is becoming commonplace. It is therefore compulsory to drastically reduce pollutant fluxes. The presently operated conventional processes cannot meet the water quality requirements: bioelimination of dyes is negligible and flocculation with iron salts, as currently {{carried out in the}} SOITEX plant located in Tlemcen, Algeria, is not effective enough. The use of aluminum salts in the flocculation of such wastewaters is well known (FIESSINGER AND BERSILLON, 1977; LAHAV et al., 1978) but the resulting microflocs are not easily settleable. Bentonite, locally available at a low cost, can also eliminate micropollutants (LAHAV et al., 1978). Associated with polyhydroxyaluminum, it can reduce such compounds as benzene or toluene, favoring simultaneously the liquid-solids separation. This paper evaluates the treatability of dyes by bentonite associated with aluminum salts. All the runs were carried out in a 200 cm 3 batch reactor, mechanically stirred and thermoregulated at 20 ·C. The main physico-chemical characteristics of the bentonite are given in Table 1. The flocculant was aluminum chloride, previously neutralized with sodium hydroxide (mass ratio OH-/Al= 1. 85). The solutions were used immediately or left to polymerize during 6 days leading to polyhydroxyaluminum PHAl (LAHAV et al., 1978). When the reactor was operated with bentonite and aluminum, the mass ratio Al/bentonite was maintained at 53. 10 - 3 (KACHA, 1994). Four dyes belonging to two main families were tested: Supranol Yellow 4 GL and Nylomine Green (acid dyes) and Foron Red RDGL and Foron Violet S 3 RL (dispersive dyes). Their concentrations were obtained by spectrophotometry. Bentonite alone does not induce a significant abatement excepted for low pH values around 4 (Figs. 1 and 2). Dye elimination appears to require a previous protonation step followed by cation exchange. The equilibrium can be modeled by a Freundlich equation (Fig. 3 and Table 2). The dyes can also be eliminated by aluminum salts alone (Fig. 4). The efficiency is then better with polyhydroxyaluminum, i. e. more than 90 % of the initial concentration is removed. Nevertheless, the dyes abatement probably results from an adsorption or chemical reaction on microflocs which are not easily settleable. By assuming that all the aluminum ions are precipitated as aluminum hydroxide, the equilibrium is modeled by the Langmuir equation which would indicate a monolayer adsorption (Fig. 5). When the reactor is operated with bentonite and aluminum salts, dye abatement is nearly complete and the liquid-solids separation is particularly efficient (Figs. 6 and 7). The best results are obtained with PHAl but the use of the monomer can be sufficient. The required concentrations are relatively low and the process is then economically feasible (Table 3). However, the experimental data can no longer be modeled by the Freundlich equation nor by the Langmuir equation. When the aluminum salts react alone with the dyes, the conductance displayed against the aluminum concentration shows two straight lines of different slopes (Fig. 8). The abscissa of the points where the slopes change are proportional to the initial dye concentration, suggesting a chemical reaction between the dye and the aluminum salts (Fig. 9). However, the final pH value lies at the limit value of aluminum hydroxide precipitation; an adsorption on aluminum hydroxide or an aluminum salt precipitation cannot then be assumed. In presence of bentonite, such changes of slope are not observed and, moreover, the final pH value does not correspond either to a precipitation value (Figs. 11 and 12). At this stage, a comprehensive mechanism cannot thus be proposed. However, the process using bentonite/PHAl is particularly efficient and easy to operate (Fig. 13 and Table 3). The results were confirmed with a true industrial effluent, the Chemical Oxygen Demand (COD) of which was reduced from 770 mg/l to less than 30 mg/l (Fig. 14). As a matter of comparison, the actual process, which includes an activated sludge treatment followed by an iron sulfate/lime flocculation, leads to an effluent containing only 140 mgCOD/l...|$|R
40|$|L'essai dit de leak-offconsiste à {{augmenter}} la pression dans un puits, au droit d'une formation, jusqu'à la limite de rupture de la roche. Cette opération sert principalement à évaluer la pression de boue maximale admissible. Depuis une décennie on essaie d'utiliser la pression en leak-off dans les puits verticaux pour évaluer les deux contraintes horizontales en place. Une variante de l'opération précédente consiste à aller jusqu'à rompre la roche et propager la rupture : c'est la micro fracturation. L'interprétation des pressions obtenues reste basée principalement sur la mécanique linéaire de la rupture : paramètres élastiques et ténacité de la roche sont constants. On montre comment quatre facteurs - rapport des contraintes recherchées, existence ou non de fissure(s) préexistante(s) en paroi, pénétration du fluide dans ces fissures, filtration du fluide - peuvent conduire à des niveaux et des évolutions de pression très variés. Ils sont cependant <b>insuffisants</b> pour expliquer quelques observations courantes : la partie non-linéaire de la courbe pression-temps, la valeur du maximum de pression, sa variation avec le débit injecté en fracture. On montre comment la prise en compte d'effets poroélastiques en bout de fracture et d'un endommagement mécanique en paroi de puits pourrait permettre de faire mieux. Deux grandeurs apparaissent comme essentielles à l'interprétation : la limite supérieure de linéarité en pression, la pression de fermeture de la fracture. L'application à trois cas concrets montre que, dans les couvertures, il faudrait probablement évaluer la pénétration du fluide dans la fracture à l'initiation de celle-ci et modéliser l'initiation de fracture en tenant compte d'un endommagement mécanique de la paroi rocheuse. La deuxième partie de ce programme est en cours. This summary contains formulas (***) {{which can}} not be displayed on this screen. The leak-off test technique is used in wells during drilling and/or completion operations. It consists in increasing the fluid pressure in the well in front of a rock formation up to a limit corresponding to the initiation of a rupture in this rock. The main purpose is to estimate the maximum admissible mud pressure during drilling. However through theoretical analyses laboratory experiments and field work, ways have beeen proposed to extract from the leak-off tests performed in vertical wells the values of the horizontal principal stresses. If fluid injection is carried on up to propagation of a fracture in the rock, the operation is then called micro fracturing. Usually a leak-off test or a micro fracturing operation are performed under a low and constantfluid injection rate. The corresponding pressure increase is first linear, then non-linear above a pressure p index (nl). It reaches a maximum p index (b) (break-down pressure) and then a lower and quasi constant level p index (e) (extension pressure, i. e. pressure needed to extend the fracture). If fluid injection is stopped and if the fluid mobility is low enough, the pressure lowers to p index f, the closure pressure. The problem is to derive relations between these characteristic pressures and in-situ stresses. For fractures of limited extent this problem can be limited to two-dimensional analyses. Most analyses are based on linear fracture mechanics : the elastic parameters and the critical stress intensity factors of the rock are considered as constants. The minimum principal stress is taken horizontal and consequently the mode I fracture is vertical. A basic parameter is the ratio of the fracture radius to the well radius (alpha / a). Explicit solutions are available for very short fractures (alpha/a = 1 + epsilon) and for largefractures (alpha / a > 5). Recent work suggests that the pressure corresponding to a very short fracture, or initiation pressure, coincide with the pressure p index (nl). Given the maximum horizontal stress sigma index h and the minimum horizontal stress sigma index (h), this pressure still depends on four parameters : tensile strength of the rock T, penetration of the fluid into the fracture s, mobility of the fluid towards the fracture faces, pore pressure p index (p). The tensile strength T is essentially unknown. A method in use to bypass this difficulty is to carry out several fluid injection/bleed-off phases : then T can be (as least theoretically) set to zero. When the fluid filtration time is short compared to the fracture propagation time, the initiation pressure can be written (Haimson and Fairhurst) :(***) ß is a poroelastic constant which depends on the Biot coefficient and the Poisson's ratio of the drained rock. When the fluid filtration time is large compared to the fracture propagation time (impermeable rock) the fracture initiation pressure is supposed to be (adapted by Detournay) :(***) Interpretation of fracture initiation pressure in overburden formations can be based on this last formula. Depending on s, which characterizes the access of the fluid to the fracture, this pressure is bounded by a maximum (no fluid penetration) and a minimum (complete fluid penetration) value:(***) For large fractures the best practical data available from micro fracturing operations is the closure pressure p index (f). Indeed under most actual conditions, p index (f) can be considered as equal to sigma index (h). Although a rather large number of parameters is involved in the interpretation of the leak-off pressure the interpretation of the nonlinear part of the pressure-time curve (from p index (nl) to p index (b)) is still matter of controversy. Indeed under the assumptions of linear fracture mechanics there should not be a non linear part in the pressure curve and the breakdown pressure p index (b) should not depend on the injection rate. However, in addition to non-linearity, laboratory experiments and field tests show that p index (b) increases with the injection flow rate up to values which are far over the theoretical prediction. Various ways have been explored to explain this behavior. The first one consists in substituting a non linear fracture mechanics to the linear one : the tensile strength of the rock in the plane of the fracture is not set to zero at the rock rupture but still exists after creation of the fracture. Then it decreases progressively when the fracture thickness increases and, for example, reaches the zero value for a ten microns fracture thickness. Another interpretation of the p index (b) value keeps the linear fracture mechanics assumptions and adds to the problem poroelastic considerations. According to this theory the pore pressure field around the fracture is inhomogeneous and in particular there is a depression zone ahead of the fracture tip. The progression of the fracture is controlled by the progression rate of this depression zone, which itself depends mainly on matrix properties (mobility of the fluid, elastic properties and porcelastic coupling). When this fracture progression rate no more keeps up with the fluid injection rate the pressure exceeds the values predicted by a more classical (non poroelastic) theory. A third way of interpretation has been modeled at Institut Français du Pétrole (IFP). In this model a mechanical damage phase comes before the creation of a single fracture plane. The non linear pressure growth takes place during the damaging phase. The results of three micro fracturing field tests (two tests in overburden layers, the third one in a reservoir) are used to extract from the p index (nl) and p index (f) pressure values the maximum horizontal stress sigma index (h), the interpretation being based on linear fracture mechanics. The exercise is convincing when applied to the reservoir example. It is not satisfactory when applied to the other examples since the fluid penetration parameter needs to be tailored to each case. The measurement of this parameter is recommended in parallel with the development of the above mentioned damage/localization modeling approach...|$|R
40|$|Dans la région de Marrakech, les eaux usées sont utilisées pour l'irrigation sans aucun traitement. Par {{ailleurs}} ces eaux usées ruissellent dans des canaux à ciel ouvert sur des distances supérieures à 2 km. Nous avons étudié le devenir des kystes de protozoaires et des oeufs d'helminthes sur le parcours d'un canal alimenté par un émissaire d'eau usée (E 2). L'analyse parasitologique des eaux usées a montré que ces eaux contiennent plusieurs types de parasites. En effet, nous avons observé la présence des kystes de protozoaires (Entamoeba histolytica, Entamoebacoli, Giardiasp.) et des oeufs d'helminthes pathogènes (Ascaris,Trichuris, Enterobius, Hymenolepis [...] .). L'étude de la charge parasitaire le long du cours d'eau usée montre une diminution du nombre de parasites dans l'eau usée en allant de l'embouchure S 0 vers l'aval de l'émissaire E 2. Avec des concentrations moyennes de 1, 6. 105 kystes/L et 145 oeufs/L à S 0, alors qu'à 2 km de S 0 (SV) il n'est plus retrouvé que 2, 7. 104 kystes/L et 33, 4 oeufs/L. La charge parasitaire dans le sédiment du cours d'eau, contrairement à l'eau, augmente en s'éloignant de l'embouchure S 0. Ainsi, les concentrations moyennes de kystes de protozoaires et les oeufs d'helminthes sont respectivement de 1, 7. 104 kystes/g et de 9, 6 oeufs/g à 80 m de S 0 et atteignent, 1, 4. 105 kystes/g et 78, 1 oeufs/g à 2 km de S 0. Le ruissellement des eaux usées sur un parcours de 2 Km, à ciel ouvert, montre des taux d'abattement importants des parasites. En effet, plus de 83 % des kystes de protozoaires et plus de 77 % des oeufs d'helminthes sont éliminés de l'effluent. Mais ces abattements restent <b>insuffisants</b> pour satisfaire les directives de l'OMS (1989) en matière de réutilisation des eaux usées en agriculture. The use of wastewater {{in agriculture}} {{in what is}} called "sewage farming" is becoming more widespread, particularly in countries with a severe shortage of water resources. Wastewater {{from the city of}} Marrakech is used for irrigation without any treatment. Nevertheless, the wastewater runs into an open channel of 2 km before being used. Thus, the fate of helminth eggs and protozoan cysts in this channel is of great importance for public health. The effluent studied carries wastewater from highly populated residential areas (Sidi Youssef Ben Ali, la Médina [...] .). The primary channel originating from this effluent runs for 2 km with a variable width of 0. 7 to 5. 5 m in a clay soil. Secondary ramifications on the channel are used for irrigation. Water and sediment samples were collected at different locations on the channel twice monthly for five months (April-August). One litre wastewater samples and 10 g sediment samples were collected, at all stations on the channel. The samples were analysed using the concentration method of Teleman-Rivas as modified by Bailenger (1962) because of its reliability and low cost. Helminth eggs were then counted on MacMaster cells after addition of saturated saccharose solution to the samples. Protozoan cysts were quantified using a Thoma cell after addition of Lugol solution to the samples. Results of water analyses are expressed as the number of cysts or eggs per liter of wastewater and results for sediments are expressed as the number of cysts or eggs per gram of dry matter. - Wastewater samples from the effluent contained helminths as well as protozoa. All wastewater samples contained protozoan cysts. Among three species of protozoa identified, two were pathogenic: Entamoebahistolytica, Giardiasp. and one saprophytic Entamoebacoli. All water samples contained helminth eggs. Analyses for helminth egg revealed the presence of Nematodes (Ascaris, Trichuris, Enterobius) and Cestodes (Hymenolepis, Moniezia). This results mainly from Ascaris eggs that were encountered in all water samples. The concentration of helminth eggs in the sewage was much less than the protozoan cysts. In terms of densities, protozoan cysts were in the range 6. 9 x 10 [exp] 4 to 2. 0 x 10 [exp] 5 cysts /L with an average of 1. 6 x 10 [exp] 5 cysts/L. Pathogenic protozoa represent 49 % of total cysts. The wastewater {{at the beginning of the}} channel contained from 102 to 238 helminth eggs/L with an average of 145 helminth eggs/L. Nematode eggs represented 72 % of total helminth eggs. Ascaris eggs dominated in the water samples with 75. 6 eggs/L representing 52 % of total helminth eggs. The densities of protozoan cysts as well as helminth eggs in wastewater samples decreased dramatically along the open channel. Protozoan cysts dropped from 1. 6 x 10 [exp] 5 cysts/L at the beginning of the channel to 2. 7 x 10 [exp] 4 cysts/L at a distance 2 km in the open channel. Pathogenic protozoa decreased from 8. 1 x 10 [exp] 4 cysts/L to 1. 0 x 10 [exp] 4 cysts/L for the same distance. The average of helminth eggs also dropped from 145 eggs/L to 33 eggs/L. Ascaris eggs showed the highest decrease from 76 eggs/L to 12 eggs/L. The genus Trichuris showed the lowest decrease from 11 eggs/L to 6. 8 eggs/L. - Analyses of sediment samples revealed the presence of all protozoan cysts and helminth eggs. Contrary to water samples, sediments samples showed an increase of all egg and cyst concentrations along the open channel. Protozoan cysts progressively increased from 1. 7 x 10 [exp] 4 cysts/g at 80 m in the open channel to 1. 4 x 10 [exp] 5 cysts/g at 2 km distance in the channel. Helminth parasites also increased from 9. 6 eggs/g to 78 eggs/g for the same distance. This increase of helminth eggs and protozoan cysts resulted from the decrease of water flow velocity which caused their sedimentation. Parasites settle out of the water column because of their own weight and because they adsorb to particles accelerating their settling. Among all parasites Ascaris eggs settle out first before all other nematode eggs. Ascaris eggs were detected at 80 m in the open channel while Enterobius eggs were not observed until 560 m in the channel. Trichuris eggs were not observed in any sediment sample. Trichuris eggs are more easily carried by the water flow because of their hydrodynamic fusiform shape which may explain their absence in sediment samples. In conclusion, the parasitic quality of a domestic wastewater in Marrakech showed significant improvement after 2 km in an open channel. Both helminth eggs and protozoan cysts showed significant removal percentage of 77 % and 83 % after 2 km running in the open channel. The best percent removal of protozoan cysts was observed for pathogenic protozoa with 88 % for Entamoeba histolytica and 87 % for Giardia sp. For helminth eggs, Ascaris eggs showed the highest removal percentage with 85 % while Trichuris showed the lowest with 37 %. However, the concentration of helminth eggs and protozoan cysts, after the sewage flows over a distance of 2 km in the open channel, are still higher than the guidelines of the W. H. O. (1989) for the use of wastewater in agriculture (less than one nematode egg per litre). These wastewaters require further treatment before they can be used for irrigation...|$|R
40|$|LE CONTROLE DE L'ANCRAGE EST FONDAMENTAL EN ORTHODONTIE, IL EST L'UN DES F ACTEURS ASSURANT LE SUCCES DU TRAITEMENT. LE DEFI EST DE MAITRISER LA TROISIEME LOI DE NEWTON QUI ASSOCIE UNE REACTION A TOUTE ACTION. L'ANCRAGE BIOLOGIQUE PEUT ALORS S'AVERER <b>INSUFFISANT.</b> CECI EST D'AUTANT PLUS VRAI CHEZ L'ADULTE QUI EST SOUVENT AFFECTE PAR DES PERTES DENTAIRES ET/OU UN SUPPORT PARODONTAL DEFICIENT. L'ANCRAGE SQUELETTIQUE A L'AIDE DE MINIVIS PREND ALORS TOUTE SA DIMENSION. APRES UN RAPPEL SUR PLUSIEURS NOTIONS FONDAMENTALES TELLES QUE LA MECANIQUE ET LA BIOMECANIQUE,. LES MOUVE 1 vOENTS ORTHODONTIQUES ET L'ANCRAGE CONVENTIONNEL, NOUS EVOQUERONS LES PARTICULARITES DU PATIENT ADULTE ET LEURS REPERCUSSIONS AU NIVEAU DE LA THERAPEUTIQUE ORTHODONTIQUE. LA TROISIEME PARTIE DE CE TRAVAIL SERA CONSACREE AUX MINIVIS D'ANCRAGE ORTHODONTIQUE. LE MATERIEL ET LES PROTOCOLES DE MISE EN PLACE Y SERONT ETUDIES. NOUS DETAILLERONS LES CRITERES DE REUSSITE, QU'ILS SOIENT LIES DIRECTEMENT A LA MINIVIS, A DES CONSIDERATIONS BIOMECANIQUES OU BIOLOGIQUES. APRES AVOIR EVOQUE LES INDICATIONS ET CONTRE-INDICATIONS DE L'UTILISATION DES MINIVIS DANS LE TRAITEMENT ORTHODONTIQUE DE L'ADULTE, NOUS NOUS DEMANDERONS CE QUE PEUT APPORTER LEUR UTILISATION, NOTAMMENT FACE AUX AUTRES SYSTEMES. ENFIN, NOUS ILLUSTRERONS LES POSSIBILITES THERAPEUTIQUES OFFERTES PAR CE SYSTEME D'ANCRAGE SQUELETTIQUE A L'AIDE DE CAS CLINIQUES TIRES, POUR LA PLUPART, DE LA LITTERATURE. ANCHORAGE CONTROL IN ORTHODONTICS IS FUNDAMENTAL, IT IS ONE OF THE FACTORS INSURING THE SUCCESS OF TREATMENT. THE CHALLENGE IS TO CONTROL THE NEWTON'S THIRD LAW, WHICH COMBINES A REACTION TO ANY ACTION. THE BIOLOGICAL ANCHORING CAN THEN TURN OUT INSUFFICIENT. THIS IS ESPECIALL Y TRUE FOR ADUL T PATIENTS WHO ARE OFTEN AFFECTED BY DENTAL LOSS AND/OR BY DEFICIENT PERIODONTAL SUPPORT. THE SKELETAL ANCHORAGE WITH MINISCREWS TAKES THEN ALL ITS MEANING. AFTER A REVIEW OF SEVERAL BASIC CONCEPTS SUCH AS MECHANICS AND BIOMECHANICS, ORTHODONTICS MOVEMENTS AND CONVENTIONAL ANCHORING, WE WILL DISCUSS THE SPECIFICITIES OF ADULT PATIENT AND THEIR CONSEQUENCES ON ORTHODONTIC THERAPY. THE THIRD PART WILL BE DEDICATED TO THE ORTHODONTIC MINISCREWS. EQUIPMENT AND PLACEMENT'S PROTOCOLS WILL BE STUDIED. WE WILL DETAIL CRITERIA OF SUCCESS, WHETHER THEY ARE DlRECTL Y RELATED TO MINISCREW OR DEPENDENT ON BIOMECHANICAL OR BIOLOGICAL CONSIDERATIONS. AFTER MENTIONING THE INDICATIONS AND CONTRAINDICATIONS (?) FOR USE OF MINISCRE...|$|E
40|$|DANS LES MODIFICATIONS DU PHENOTYPE CELLULAIRE SURVENANT AU COURS DE L'HYPERTENSION ARTERIELLE, CELLES INTERESSANT LES CML DES ARTERIOLES RESISTIVES SONT AU PREMIER PLAN, EN PARTICULIER AU SEIN DE LA MICROCIRCULATION RENALE, CE QUI JUSTIFIE QUE DES TRAVAUX LEUR SOIENT CONSACRES. TOUT D'ABORD, NOUS AVONS MONTRE QUE L'EXPRESSION DE L'ENDOPEPTIDASE NEUTRE, UNE ECTOENZYME RESPONSABLE DU CATABOLISME DES PEPTIDES NATRIURETIQUES ET VASODILATATEURS, EST INFLUENCEE PAR LES FACTEURS DE CROISSANCES EGF ET TGF-. EN RETOUR, LA PROLIFERATION CELLULAIRE INDUITE PAR L'EGF NECESSITE L'ACTIVITE DE L'ENDOPEPTIDASE NEUTRE, CE QUI CONFERE UNE NOUVELLE FONCTION POUR CETTE ENZYME VASCULAIRE DANS LE REIN. NOUS AVONS ETUDIE LE ROLE DU MONOXYDE D'AZOTE (NO) SUR LA SYNTHESE DE RENINE IN VIVO ET NOUS AVONS ALORS OBSERVE QUE LE NO ENDOGENE EXERCE UN EFFET PERMISSIF POUR L'ACTIVATION PHYSIOLOGIQUE DE CE PHENOMENE. EN L'ABSENCE DE NO ENDOGENE EN EFFET, LA SYNTHESE ET LA SECRETION DE RENINE PAR LES ARTERIOLES AFFERENTES SONT BLOQUEES PAR L'ACTIVATION DES CANAUX CALCIQUES DE TYPE L SOUS LE CONTROLE DES RECEPTEURS DE L'ENDOTHELINE DE CE FAIT ACTIVES. AINSI, L'EQUILIBRE DES ACTIONS DU NO ET DE L'ENDOTHELINE, OUTRE LA REGULATION DU TONUS ARTERIOLAIRE, AFFECTE LA FONCTION ENDOCRINE DES CMLV SPECIALISEES. EN PHYSIOPATHOLOGIE, L'INHIBITION CHRONIQUE DES NO SYNTHASES CHEZ LE RAT A DEMASQUE L'ACTION FIBROGENE RENALE DE L'ENDOTHELINE. LA SYNTHESE PAR LES ARTERIOLES PREGLOMERULAIRE DE COLLAGENE DE TYPE I EST ACTIVEE DE PAIR AVEC LA SYNTHESE D'ENDOTHELINE- 1. LA SYNTHESE VASCULAIRE DE COLLAGENE I COMME LA NEPHROANGIOSCLEROSE ONT PU ETRE PREVENUES PAR LE BLOCAGE PHARMACOLOGIQUE DES RECEPTEURS DE L'ENDOTHELINE. CE RESULTAT A ETE OBTENU SANS MODIFIER L'HYPERTENSION ARTERIELLE SYSTOLIQUE CE QUI SUGGERE QUE CE CRITERE D'EFFICACITE CLINIQUE HABITUELLE EST <b>INSUFFISANT</b> POUR JUGER DES EFFETS D'UN AGENT PHARMACOLOGIQUE SUR LE PHENOTYPE VASCULAIRE RESISTIF RENAL. A CONTRARIO, CETTE ETUDE OUVRE DES PERSPECTIVES D'ACTION THERAPEUTIQUES ANTIFIBROSANTES SPECIFIQUES DES MALADIES RENALES CHRONIQUES. LA PART DU ROLE DE L'HEMODYNAMIQUE RENALE DANS CE PHENOMENE N'EST CEPENDANT PAS EXCLUE COMME LE SUGGERE LA GRANDE AUTONOMIE DE CETTE CIRCULATION AUTOREGULEE VIS A VIS DE LA PRESSION ARTERIELLE SYSTEMIQUE. NOUS AVONS ENFIN COMPARE LES VOIES CELLULAIRES D'ACTIVATION TRANSCRIPTIONNELLE DU GENE DE LA CHAINE ALPHA 2 DU COLLAGENE DE TYPE I (PROCOL 2 (I)) RESPECTIVEMENT PAR L'ANGIOTENSINE II (ANG II) ET PAR LE TGF-. LES RESULTATS INDIQUENT QUE L'ACTIVITE BIOLOGIQUE DU TGF- EST NECESSAIRE A L'ACTION FIBROGENE AIGUE DE L'ANGIOTENSINE II. PARMI LES VOIES ETUDIEES, CELLE DES MAPK/ERK EST EGALEMENT INDISPENSABLE A LA STIMULATION DE PROCOL 2 (I) PAR L'ANG II MAIS NON A CELLE INDUITE PAR LE TGF- DANS LES AORTES ET LE CORTEX RENAL DE SOURIS. PARIS-BIUSJ-Thèses (751052125) / SudocCentre Technique Livre Ens. Sup. (774682301) / SudocPARIS-BIUSJ-Physique {{recherche}} (751052113) / SudocSudocFranceF...|$|E
40|$|L'EXPERIENCE COMPASS VISE PRINCIPALEMENT A MESURER LA POLARISATION DES GLUONS PAR L'ASYMETRIE DE SPIN DANS LA DIFFUSION D'UN FAISCEAU DE MUONS POLARISES SUR UNE CIBLE DE NUCLEONS POLARISES. LE PROCESSUS SENSIBLE A LA DISTRIBUTION DES GLUONS EST LA FUSION PHOTON-GLUON, LAQUELLE PEUT ETRE IDENTIFIEE PAR LA PRODUCTION DE MESONS CHARMES. CE PROCESSUS RESTE TOUTEFOIS RARE ET DIFFICILE A IDENTIFIER DANS UN BRUIT DE FOND IMPORTANT. LA DETERMINATION DE L'EFFICACITE ET DE LA RESOLUTION SPATIALE DES TROIS STATIONS DE CHAMBRES A DERIVE DU SPECTROMETRE PERMET DE S'ASSURER DES BONNES PERFORMANCES DE LA RECONSTRUCTION DES TRAJECTOIRES DES PARTICULES. L'IDENTIFICATION DES HADRONS, ESSENTIELLE DANS LA RECONSTRUCTION DE LA DECROISSANCE DES MESONS CHARMES, EST ASSUREE PAR UN DETECTEUR RICH. EN VUE D'AMELIORER LES PERFORMANCES DE CE DERNIER, UNE METHODE DE TRAITEMENT PROBABILISTE DU SIGNAL ET DU BRUIT A ETE DEVELOPPEE, DE MEME QU'UN PROJET DE REMPLACEMENT DE L'ELECTRONIQUE DE LECTURE. LA DEUXIEME PARTIE DES TRAVAUX EST CONSACREE A LA MESURE DE L'ASYMETRIE D'HELICITE POUR L'EXTRACTION DE LA POLARISATION DES GLUONS. CELA NECESSITE LE DEVELOPPEMENT DE CRITERES DE SELECTION POUR MINIMISER LE RAPPORT BRUIT SUR SIGNAL, ET DE TECHNIQUES DE PONDERATION DES EVENEMENTS PERMETTANT DE REDUIRE L'ERREUR STATISTIQUE. CETTE THESE PRESENTE UN RESULTAT PRELIMINAIRE, BASE SUR LA STATISTIQUE ACCUMULEE PAR COMPASS ENTRE 2002 ET 2004. CECI MET EN EVIDENCE UNE POLARISATION DES GLUONS COMPATIBLE AVEC ZERO, LA BARRE D'ERREUR STATISTIQUE RESTANT NEAMOINS ENCORE ASSEZ IMPORTANTE. LE RESULTAT, QUOIQU'EN ACCORD AVEC LES MESURES EXISTANTES, DEMEURE ENCORE <b>INSUFFISANT</b> POUR TRANCHER ENTRE LES DIFFERENTS MODELES THEORIQUES. THE MAIN AIM OF THE COMPASS EXPERIMENT IS THE MEASUREMENT OF THE GLUON POLARIZATION IN THE NUCLEON, WHICH CAN BE ACCESSED BY THE SPIN ASYMETRY IN THE SCATTERING OF A POLARIZED MUON BEAM ON A POLARIZED NUCLEON TARGET. THE PROCESS SENSITIVE TO THE GLUON DISTRIBUTION IS THE PHOTON-GLUON FUSION, WHICH CAN BE TAGGED BY LOOKING AT THE PRODUCTION OF CHARMED MESONS, HOWEVER IT IS A RARE PROCESS, DOMINATED BY A LARGE BACKGROUND. THE MEASUREMENT OF THE EFFICIENCY AND THE SPACE RESOLUTION OF THE THREE DRIFT CHAMBER STATIONS OF THE SPECTROMETER IS A NECESSARY STEP IN UNDERSTANDING THE PERFORMANCES OF THE RECONSTRUCTION OF PARTICLE TRAJECTORIES. THE HADRON IDENTIFICATION, WHICH IS FUNDAMENTAL IN THE RECONSTRUCTION OF CHARMED MESON DECAY, IS PERFORMED BY A RICH. A STATISTICAL TREATEMENT OF SIGNAL AND BAKGROUND, TOGETHER WITH AN UPGRADE PROJECT TO REPLACE THE PRESENT FRONT END ELECTRONICS, HAVE BEEN DEVELOPPED IN ORDER TO INCREASE THE IDENTIFICATION PERFORMANCES. THE SECOND PART OF THIS WORK CONCERNS THE SPIN ASYMMETRY MEASUREMENT, WHICH REQUIRES THE APPLICATION OF SELECTION CRITERIA IN ORDER TO MINIMIZE THE NOISE OVER SIGNAL RATIO, AND THE DEVELOPMENT OF EVENT-WEIGHTING METHODS TO REDUCE THE STATISTICAL ERROR. ALTHOUGH THE ERROR BARS ARE STILL LARGE, THIS WORK PRESENTS A PRELIMINARY RESULT, BASED ON 2002 - 2004 STATISTICS, LEADING TO A GLUON POLARIZATION COMPATIBLE WITH ZERO. THE COMPARISON WITH NLO-QCD FITS AND WITH OTHER DIRECT MEASUREMENTS SHOWS THAT THIS RESULT IS COMPATIBLE WITH THE EXISTING MEASUREMENTS BUT, GIVEN THE PRESENT ACCURACY, IT DOES NOT ALLOW TO DISTINGUISH BETWEEN DIFFERENT MODELS. ORSAY-PARIS 11 -BU Sciences (914712101) / SudocSudocFranceF...|$|E
40|$|This {{thesis is}} about {{immigrants}} in self-employment in Germany. More specifically, {{it is about}} immigrants who make a culturally-endowed practice or knowledge economically available in their new home. These immigrant business owners are generally referred to as ethnic entrepreneurs. Yet, according to research and widely-held public opinions in Germany, a problem that hampers {{the success of these}} businesses is the owner's lack of proficiency in the German language, which apparently impedes them from accessing institutional support and from offering their services to the majority population. However, the ways that language competence actually affects the entry of immigrants into self-employment and the execution of their daily work as business owners has received only insufficient attention, including from a sociolinguistic perspective. 	Hence, this thesis aspires to examine the pathways of immigrants into self-employment and how these pathways are shaped by the owners' language knowledge. Secondly, by analysing the workplace practices in close empirical detail, it aims to understand how the owners' language knowledge impacts the execution of their work and whether these practices constitute sites of language learning for the owners. Thirdly, it intends to document the challenges that the business owners face at their workplaces, in order to understand to what extent they are due to insufficient levels of language knowledge. 	In order to answer these research questions, this study focuses on three businesses owned and operated by first-generation female immigrants from Thailand in the federal state of Saarland in southwest Germany. Businesses by Thai immigrants are particularly interesting {{for the purposes of this}} investigation, because they have flourished in recent years and because they offer their services in markets that target the majority, primarily German-speaking population. 	The ventures are typical examples of ethnic small businesses created by Thai immigrants in Germany: Thai massage salons and food retails stores. The first is a large Thai massage salon run by Kanita, the second a small Thai massage salon managed by Patcharin, and the third business is a food retail store owned and operated by Wipa. The three owners (and their staff) differ in terms of their competence in German. Kanita has only minimal competence in German, Patcharin has partial competence, while Wipa has maximum competence in the language. 	The analysis of the pathways into self-employment of these three owners exhibits a number of similarities. In all three cases, their migration to Germany was triggered by marriage to a German national. Previously, they all had professional careers which were directly connected to their appropriation of English, a language that later enabled communication with their German husbands. While their move to Germany was generally motivated by prospects of a better future, they were unable to find work due to a lack of German proficiency. German was primarily learned informally. Informal learning was fostered by their prior experience of language learning, their individual engagement in the form of self-study and reflexivity, a deliberate exposure to German through media, and their engagement with native speakers in practices towards which that they had developed an affinity. Interestingly, these practices were either their previous professional practices or activities that they took up after migration and later on developed into their own businesses. 	Realising the demand for their services in the open market and among the majority population kindled Kanita's, Patcharin's and Wipa's flame to enter self-employment. They deliberately adapted their services to the requirements of their customers, but also in reaction to prejudices about their professions. The support of their husbands and other associates was also significant, as they handled tasks that were difficult to perform linguistically, as, for example, the registration of the businesses and the preparation of administrative paperwork. In sum, these findings suggest that an advanced standard level of German was no prerequisite for these owners to enter self-employment, but that the prospects of engaging in self-employed work acted as an incentive to improve their German language skills. 	A detailed analysis of the workplace practices at Kanita's Massage Salon shows that working with minimal competence in German is possible, but that its success depends on several factors. To complete their workplace actions, Kanita and her staff draw on both resources in their linguistic repertoires, Thai and German. In addition, all workplace actions are designed as routine actions with discursive routines that all staff members are able to master quickly. Their successful accomplishment also depends on the customers' familiarity with these actions. Therefore, formal inconsistencies in German do generally not impede the performance of work, but problems are primarily due to the staff's or the customer's inexperience with the routines. If problems occur, they tend to be solved in cooperation with colleagues or by drawing on the material resources available to the staff members. 	In comparison to Kanita, Patcharin and her staff have partial competence in German, which is instrumental for the performance of the key practices at their workplace. The analysis shows that their restricted competence in German is important for their work, as it provides the tools for Patcharin and her staff to perform discursive practices during the massage treatment, such as finding out about their clients' health problems, building rapport with clients, giving instructions or clarifications about the treatment, or providing assessments of their customers' health issues. Talk is an important part of the massage treatment at Patcharin's salon and it aids to construct the professional identity that Patcharin claims for herself, namely to provide a high-quality and personalised service to her customers. Thai is less relevant, but in interactions between Patcharin and her staff it serves to exchange information and coordinate work. 	Wipa has maximum competence in German and Thai, which allows her to manage her store and serve her customers independently and competently in line with her professional aspirations. The key practices at her store of explaining and ordering stock illustrate how Wipa relies on both the use of Thai and German to effectively perform these actions. Her maximum competence in German and in Thai permits her to make 'rational' choices about the suitability of her suppliers and to provide her customers with advice that is tuned to their linguistic and cultural background. 	The conclusions drawn from these findings are that an advanced competence in German in not a prerequisite for immigrant entrepreneurs to start their businesses. The owners attune their workplace actions to the level of competence in their linguistic repertoires and operate effectively. Moreover, self-employed work provides the owners with the necessary motivation and the need to appropriate German. On the other hand, the data suggest that a greater proficiency in German becomes important, if the immigrant entrepreneur wants to differentiate her business from direct competitors, as it allows them to move beyond the concrete performance of routine actions. Cette thèse a pour sujet les immigrés établis professionnellement à leur compte en Allemagne. Elle concerne plus précisément les immigrés qui rendent une pratique ou un savoir chargé culturellement abordable dans leur nouveau foyer. On qualifie généralement ces immigrés chefs d’entreprises d’entrepreneurs ethniques. Cependant, selon les recherches et selon l’opinion publique largement répandue en Allemagne, le manque de maîtrise de l’allemand de ces entrepreneurs serait une entrave sérieuse à leur succès. Cela les empêcherait visiblement d’avoir accès aux appuis institutionnels et de proposer leurs services à une large part de la population. Toutefois, la façon dont les compétences langagières affectent effectivement l’accès des immigrés à l’entrepreneuriat ainsi que l’exécution de leur travail quotidien en tant que chefs d’entreprise n’a reçu que peu d’attention, y compris du point de vue de la sociolinguistique. 	Par conséquent, nous souhaitons tout d’abord étudier l’accès à l’entrepreneuriat des immigrés ainsi que la façon dont cet entrepreneuriat est façonné par leurs compétences linguistiques. Dans un deuxième temps, nous analyserons empiriquement et dans le détail les pratiques professionnelles afin de comprendre non seulement dans quelle mesure les compétences linguistiques des entrepreneurs impactent la réalisation de leurs tâches professionnelles mais aussi si ces tâches professionnelles sont une manière d’acquérir des compétences linguistiques. Dans un troisième temps, il s’agira d’analyser les défis auxquels sont confrontés les entrepreneurs sur leurs lieux de travail, afin de comprendre dans quelle mesure ces obstacles sont dus à des niveaux de langue <b>insuffisants.</b> 	Pour répondre à ces questions de recherche, nous allons orienter essentiellement notre étude sur l’analyse de trois entreprises tenues et exploitées par trois femmes issues de la première génération d’ immigrés thaïlandais dans l’état fédéral de la Sarre. Ces entreprises tenues par des immigrés thaïlandais sont particulièrement intéressants pour notre étude non seulement car elles sont devenues plus nombreuses ces dernières années mais aussi parce qu’elles proposent leurs services sur un marché qui cible prioritairement et majoritairement la population germanophone. 	Ces entreprises sont des exemples typiques de petits commerces créés par des immigrés thaïlandais en Allemagne : les salons de massages thaïlandais et les magasins d’alimentation. Le premier commerce est un grand salon de massage thaïlandais tenu par Kanita, le deuxième est un petit salon de massage thaïlandais|$|R
40|$|La quantité de matière sèche et d’éléments minéraux exportée au cours de l’exploitation forestière est estimée pour 3 taillis d’espèces mélangées dans les Ardennes françaises. Des tarifs, régression linéaire, sont construits à partir d’échantillons. Nous montrons dans cet article la nécessité d’établir des tarifs de biomasse ou de mininéralomasse en {{fonction}} de chacun des facteurs étudiés. L’analyse de variance permet de classer, {{en fonction}} de la valeur du test F, les effets des facteurs ou de leur interaction soit : Espèce » Compartiment »> Station > Espèce-Station ≥ Espèce-Compartiment > Station-Compartiment. La nécessité d’utiliser les tarifs spécifiques à chaque espèce, à chaque station et pour chacun des compartiments pose le problème de l’optimisation de l’échantillonnage. Nous admettons que la variance générale estimée à partir de nos échantillons est le meilleur estimateur de la variance générale. Nous calculons ainsi le nombre minimum d’individus (arbres) à la probabilité de 5 p. 100 pour satisfaire à une erreur de 10 p. 100 sur la moyenne. Le nombre de 20 arbres échantillonnés par station et par espèce, se révèle <b>insuffisant</b> dans 17 p. 100 des cas. The intensification of forestry (including whole tree harvesting) {{raises the question}} of its consequences on site fertility. We evaluate the removal of mineral elements related to the degree of intensification by applying tariffs established by stratified sampling. Here we summarise the limitations to the application of these tariffs due to the variability of other factors : species, site, tree and its components. - Three coppices in the Primary Ardennes were sampled by : 1. Species : Oak (Quercus sessiliflora, birch (Betula verrucosa), and mountain ash (Sorbus aucuparia). 2. Site : « sol brun acide » with greater (80 cm) or lesser (40 cm) depths of loess over shales. 3. Tree component : leaves, branches, and three parts of the trunk cut at 7 cm, 4 cm and 1 cm diameters. - The dry weight of the material at 65 °C and major elements, N, P, K, Ca, Mg were determined. We used the following tariff model : Log (biomass) = a + b Log (circumference) and applied the correction for bias as used by Baskerville (1972). - The analyses of variance with one or more factors were measured {{to examine the effects of}} the factors. We used analysis of co-variance to compare the tariffs. Results : The qualitative examination of the variation in the chemical composition of the different components, showed that each is partly a function of site, but is primarly due to species (table 2). The interaction between species and site is low. We can classify the effects of, and interactions between, factors as a function of their F test value in the following order of decreasing magnitude : Species » tree component »> site > species X site ≥ species X component > station X component. The quantitative results (table 3) confirm that species is the most discriminating factor. There are also significant differences between the tariffs. These must be specific to species, site and tree component. The cost of these studies is high, so it was not possible to regroup the samples. Therefore, is it possible to increase the efficiency of the sampling strategy ? As no general law exists for the relationship between the parameter measured (circumference at 1. 30 m or C 130) and the mineral content of tree tissue, we calculated the minimum number of individuals, N, necessary by using the formula :(formule document ci-joint) at 5 p. 100 where L is the confidence limit at 10 p. 100 of the mean. The value of ơ is the value of the variance, and we admit that the best estimate is the variance estimated from our samples. Table 4 shows the results calculated for the different tree components. The variability is greater for mountain ash than for birch or oak. In our study, the choice ot 60 trees per species is theoretically insufficient in 17 p. 100 of the cases. At each site, for each species, we propose to sample 30 branches to estimate the mean at 10 p. 100, and 15 trees for the mean at 15 p. 100...|$|E
40|$|L'une des difficultés rencontrées couramment dans la {{conception}} des réseaux de mesure - au moins {{en ce qui concerne}} les micropolluants - porte sur la sélection des paramètres à mesurer. C'est notamment le cas pour les pesticides, dont plusieurs centaines sont utilisées en agriculture, mais qu'il est impossible de surveiller dans les eaux en totalité pour des raisons à la fois techniques et économiques. C'est la raison pour laquelle les autorités françaises ont fait procéder à la mise au point d'une méthode de sélection des matières actives utilisées en agriculture basée sur l'évaluation du risque. Dans cette méthode, l'exposition est figurée par un rang combinant les données relatives aux usages des matières actives (superficie, dose par ha) et leurs caractéristiques physico-chimiques. Le danger est représenté par la toxicité, soit pour l'homme, soit pour les espèces aquatiques. Cette approche a été appliquée à l'échelle nationale et dans un certain nombre de régions françaises, dont l'Alsace et la Lorraine. Les résultats des mesures de pesticides réalisées ensuite pendant un an ont été confrontés aux indices d'exposition obtenus. Les substances détectées le plus fréquemment correspondent effectivement à celles dotées des rangs d'exposition les plus élevés (ajustement exponentiel, r 2 ≈ 0. 82); cependant, le diuron apparaît à une fréquence plus élevée que celle attendue, {{en raison de}} ses usages non agricoles. La corrélation est moins bonne pour les substances dont les rangs d'exposition sont proches de la valeur considérée comme significative pour les eaux superficielles, ce qui peut provenir soit de l'utilisation de données erronées lors de la sélection, soit d'un poids <b>insuffisant</b> attribué à certains facteurs dans la méthode de sélection, soit enfin d'aléas météorologiques. Monitoring of micropollutants is {{a rather}} recent activity (10 - 15 years), at least in surface waters; because of the need for sophisticated analytical methods and of the potential number of analytes, this type of activity is confronted with important economic constraints, which require that one make a selection among the range of substances to monitor. Among organic micropollutants, pesticides constitute a well-identified category, since they are used mainly in agriculture; this use on broad surfaces may have important impacts on the quality of surface water. Various methods have been used to select those pesticides likely to have the greatest impacts on water quality; some of these methods might be considered to be "hazard assessment", whereas others correspond to simplified "risk assessment" methods (this appears particularly true for pesticides, of which several hundreds are used in agriculture). Recently, a French panel of experts mandated by different Ministries designed a selection method called SIRIS, which allows one to define three different lists of pesticides according to the media to be monitored (surface or ground-water) and to the monitoring objectives (ecosystem protection, drinking water production). This paper deals with the application of the SIRIS method at a regional level, {{in the context of a}} permanent survey of river quality. As a simplified risk assessment method, SIRIS combines data on hazard and exposure; hazard is estimated by a single parameter, either toxicity for aquatic species or acceptable daily intake (ADI). Exposure represents the probability that a transfer to water bodies may occur; for surface water, this probability is influenced by the crop acreage, the applied dose (kg/ha), the solubility, the pesticide half-life, the hydrolysis and the distribution coefficient between water and organic matter (Koc). These factors are considered in this hierarchical order, and for each substance a score is assigned to each of these factors among three possible values ("o"=slight, "m"=medium, "d"=high, according to the relative influence on transfer); finally exposure is estimated by a relative rank obtained by a combination of these values following a "penalisation" principle. Two tables are available for applying this approach at a regional level: the first contains the values (o,m,d) assigned to more than 300 substances by the expert panel for solubility, half-life, etc., and should be completed with crop acreage and dose. The second table provides the ranks corresponding to the different combinations of o,m,d values. A final rank of 35 was considered by consensus to be a pragmatic threshold for the transfer to surface water. This method was applied in 1996 in two regions in France (Alsace and Lorraine) separately; most of the selected chemicals (but unfortunately not all, due to technical constraints) were then analysed monthly in surface waters (24 sampling points, yielding 144 samples in Alsace and 169 in Lorraine). Occurrences fell between 0 % and 60 % in Alsace, and between 0 % and 90 % in Lorraine; in both regions, the most frequently detected chemicals were atrazine and diuron. The relevance of the selection method may be discussed under several aspects: the choice of the factors, their order, the position of thresholds corresponding to o,m,d values, the value of the overall threshold, and the availability of the data. Some pesticides are not ranked only because no data were available concerning their solubility, hydrolysis rate or Koc, but the relative importance of such gaps cannot be appreciated with the current set of data. Other items may be assessed through the comparison of the exposure rank versus the occurrence. This relationship takes an exponential shape, with some anomalies: for example, the occurrence of diuron in Alsace is higher than expected, based on its exposure rank. This situation can be explained by the fact that there are non-agricultural uses of this substance, such that the exposure rank appears to be underestimated. For other substances, like aldicarb and chlorpyrifos-ethyl, discrepancies are observed between the exposure rank and occurrences, when comparing with substances with higher exposure ranks. This anomaly may be due to poor data quality. For carbendazime, the occurrence in Lorraine appears underestimated, probably because of a dry period deficit after the application. Finally, chlortoluron received the same rank in the 2 regions, but is more frequently detected in Lorraine; crop acreage may have been overestimated in Alsace. However, the dataset is still limited to one year of sampling; some discrepancies may appear less important when more data are available. For chemicals with ranks > 50, there is a good exponential fit between ranks and occurrences (y= 0. 0235 *e 0. 0739 x; r 2 = 0. 82). This observation means that pesticides with ranks > 50 are systematically encountered in surface waters; however, the current threshold (35) should be maintained, because some substances with ranks < 50 are also detected. Thus, the SIRIS method appears to be a good tool for selecting agricultural pesticides for monitoring purposes at a regional level...|$|E
40|$|Increasing milk {{production}} {{is a key}} issue for Vietnam. Improving {{milk production}} involves controlling direct or indirect factors responsible for this. These factors are genetics, feed, environment, and reproductive performance. The identification and control of individual or collective factors responsible for reproductive performance is therefore {{an important step in}} improving milk production. The general objective of our study is to describe the milk and reproductive performances of dairy smallholding in Vietnam and to analyze the effects of risk factors on reproductive performance. The specific objectives are:(1) to describe the physiological and pathological characteristics of genital tract of culled dairy cows in dairy smallholding; (2) to specify the fecundity and fertility of heifers and dairy cows of small dairy farms; (3) to identify the postpartum (PP) reproductive disorders of cows in dairy smallholders (4) to analyze the effects of individual and environmental risk factors on the reproductive performance of heifers and cows; and (5) to analyze the risk factors for the postpartum (PP) reproductive disorders of cows. The first work of our study was conducted from February to August 2012 on 507 culled crossbred Holstein Friesian (HF) x Lai Sind (LS) dairy cows at two slaughterhouses in HCMC. Age and body condition score (BCS) of cows were determined prior to slaughter. A visual examination of vulva region was also performed to identify the presence of eventual discharges. Then, vaginoscopic examination was performed to determine the presence of discharges and pneumovagina or even urovagina. After slaughter, the uterus was incised to examine the contents. Oviducts were observed to identify abnormalities. The ovaries were collected to evaluate eventual structures (number and diameter of follicles, corpus luteum - CL and cysts) using an ultrasound (KX 5200, 6. 5 MHz linear probe). The results of this study revealed some important pathological characteristics of examined cows. Nearly half (44. 4 %) of examined cows had a BCS lower than 2. 5. The prevalence of pneumovagina and urovagina was 33. 1 % and 14. 7 %, respectively; age and BCS have had a significant effect on the prevalence of these pathologies. The frequencies of vaginal discharges and abnormal uterine contents were 12. 1 % and 5. 4 %, respectively. 226 out of 507 examined cows (44. 6 %) were in anœstrus. The frequencies of functional pathological anœstrus, cystic, pyometral and gestation were 37. 3 %, 2. 0 %, 0. 4 % and 4. 9 %, respectively. Type 0 and I anœstrus have been more often observed in cows with low BCS and in cows aged less than 6 years. The results of the first work reinforced us in the need to set up specific monitoring of small dairy farms at HCMC. The total of 232 heifers and 244 cows (261 lactations) of 35 small farms in Cu Chi district, HCMC were observed during the years 2013 and 2014. The animals are kept permanently indoors. Their diet consists of fodder (Pennisetum purpureum or natural grass and rice straw), concentrates and by-products (spent grain and cassava waste). Each farm was monitored monthly for reproduction of heifers and cows by transrectal palpation, ultrasound (KX 5200, 6. 5 MHz linear probe) and vaginoscopy. Reproductive data (dates and type of calving, calf sex, complications, results of clinical examinations, date of heat, date of insemination), milk production (daily average milk yield per cow), BCS and weight of heifers were updated at each visit. The reproductive performance was assessed by fecundity and fertility parameters. The fecundity of heifers and cows was calculated by (1) birth to conception interval (heifers) (or age at conception – AC) or calving to conception interval (cows) (or days open - DO), (2) birth to first service (heifers) (or age at first service – AFS) or calving to first service (cows) (or waiting period - WP) and (3) days between first and last service (DFLS). The fertility of heifers and cows was determined by (1) number of services per conception (NSC), (2) conception rate at first service (CRFS) and (3) overall conception rate (CR). The prevalence of PP disorders (dystocia, retained placenta or RP, clinical endometritis, urovagina, cysts and anœstrus) was also determined. The monthly temperature and humidity index (THI) for the years 2013 - 2014 has been calculated. The body weight and average daily gain of heifer at 6, 12 and 16 months of age were 159, 280 and 351 kg and 690, 646 and 705 g/day respectively. The average daily milk yield per cow was 11. 6 (± 0. 5) kg. The average duration of lactation was 368 (± 100) days. The overall mean of AFS, DFLS and AC of heifers was 479 (± 80), 38 (± 80) and 517 (± 114) days, respectively. The NSC, CR and CRFS was 1. 8 (± 1. 4), 55 % and 58 %, respectively. A significant decrease in AFS and AC according to the year of birth and a significant increase in AFS with a heavier weight (> 320 kg) at first AI were observed. CRFS of heifers inseminated in 2013 was higher than that of heifers inseminated in 2014 (64 % vs 50 %, P 320 kg) lors de la première insémination ont été observées. Le PGAIA 1 des génisses inséminées en 2013 est plus élevé que celui des génisses inséminées en 2014 (64 % vs 50 %; P < 0, 05). Le TGA des génisses a été corrélé négativement à l’ITH mensuel au cours de la période observée. La PA, la PR et l’intervalle VIF des vaches ont été respectivement de 109 (± 52), 133 (± 114) et 242 (± 129) jours. L’IFA, le TGA et le PGAIA 1 ont été respectivement de 4, 3 (± 2, 7), 23 % et 14 %. La PA, la PR, l’intervalle VIF et l’IFA ont diminué significativement en fonction de l’année de vêlage. Les vêlages observés en saison des pluies se sont accompagnés d’une augmentation significative de la PA. La manifestation d’une pathologie du PP (endométrite clinique, et pneumo/urovagin) s’est accompagnée d’une augmentation de la PA (108 vs 98 jours), de l’intervalle VIF (249 vs 216 jours) et de l’IFA (4, 7 vs 3, 9). Une diminution du SC entre le vêlage et le 60 e jour de lactation (V 60) et ainsi qu’entre le 60 e jour et 120 e jour de lactation a augmenté significativement les durées de la PA et de l’intervalle VIF. La diminution du SC entre V 60 s’est également traduite par une réduction significative très importante du PGAIA 1 des vaches (8 vs 18 %, P < 0, 05). L’année et la saison d’IA, et le SC au moment d’IA ont exercé un effet significatif sur l’IFA et le TGA des vaches. Le TGA des vaches a été corrélé négativement à l’ITH mensuel. Au total, 353 vêlages et périodes du PP de 302 vaches ont été observés. La fréquence des dystocies, des RP, d’endométrite clinique, d’urovagin, d’anœstrus du PP et de kystes ovariens a été respectivement de 24, 4 %, 16, 4 %, 19, 2 %, 5, 6 %, 49, 9 % et 6, 3 %. Les primipares ont eu plus 1, 7 fois de risque de dystocie que les pluripares (29, 9 % vs 20, 4 %; P < 0, 05). Les vaches vêlées en 2014 ou en saison des pluies ont eu respectivement plus 6 et 2, 1 fois de risque de dystocie que les vaches vêlées en 2013 (P < 0, 001) ou en saison sèche (P < 0, 01). La fréquence de RP a été plus élevée en 2014 qu’en 2013 (21, 8 % vs 11, 7 %; P < 0, 01). Les vaches vêlées en 2014 ou en saison des pluies ont présenté plus fréquemment une endométrite clinique que les vaches vêlées en 2013 (OR= 3, 03; P= 0, 001) ou en saison sèche (OR= 3, 78; P< 0, 001). La dystocie et la RP ont multiplié respectivement par 2, 8 (P= 0, 003) et 4, 7 (P= 0, 001) le risque d’endométrite clinique. Le vêlage difficile, l’endométrite clinique et le SC <b>insuffisant</b> au vêlage (< 3) ou au 30 e jour du PP se sont accompagnés d’une augmentation de risque d’anœstrus de type I. En conclusion, l’infécondité observée caractérise davantage les vaches que les génisses. L’infertilité et les anœstrus du PP constituent les facteurs majeurs responsables de cette situation. Le stress thermique et la sous-nutrition sont les causes majeures de l’infertilité et des anœstrus du PP de vaches observées. Par ailleurs, la fréquence des pathologies de reproduction (dystocie, RP, endométrite clinque et anœstrus du PP) est également importante dans cette étude. La dystocie et la RP sont les facteurs de risque de l’endométrite clinique et la dernière a également exercé un effet négatif sur la fertilité et la reprise d’activité ovarienne de vaches...|$|E
40|$|While Jhumpa Lahiri’s work {{might be}} thought of {{as one of the most}} emblematic {{instances}} of the popularity of today’s Indian-American diasporic literature, it remains that its hyper-visibility coincides with an odd form of critical invisibility. This is not to say that critical interventions on Lahiri’s three books have been nonexistent, nor could they have been in view of the fact that the author won the Pulitzer Prize in 2000 for her first collection of short-stories, Interpreter of Maladies. But the vast majority of these readings takes as its premise that view that cultural assimilation and hybridity are still valid notions to investigate narratives focusing on members of the second generation, even as these descendants of migrants consider themselves Indian simply by virtue of their parents, so that they can only claim a second-hand knowledge of migration. Ignoring the difference between first and second-generation Indian-American diasporic experiences – and, what is more, overlooking the fact that the offspring of migrants, unlike their parents, “[do] not really have any other place [than the U. S. ] to call home” (Lahiri) – such critical consensus ignores important aspects of Gogol’s complex trajectory in The Namesake. Worse, it proves highly unsatisfactory when it comes to discussing Lahiri’s recent collection of short stories, Unaccustomed Earth, in which the second generation’s accession to early middle age calls into question various preconceptions on heritage and transmission. Can it be then that what is passed on from one generation to the next organizes itself less around positive, than negative entities, that is, around categories such as the gap, the absent, and the unsaid?	 	Taking its cue from Vijay Mishra’s understanding of the diasporic subjectivity in terms of an impossible mourning, my dissertation examines the ways in which Lahiri redefines the notions of belonging and arrival as regards the Indian-American second generation not in terms of cultural assimilation – which would hardly make sense for characters who were born in the U. S. in the first place – but in terms of a re-symbolization of the gaps in the parents’ migrant narratives, more particularly in terms of the “phantom loss” haunting transgenerational relationships between migrants and their offspring. While investigating the figures of emptiness, spectrality, and the message, my dissertation takes various psychoanalytic theories by Sigmund Freud, Julia Kristeva, Nicolas Abraham, Maria Torok and Jean Laplanche, among others, as its major methodological tools. As against a critical consensus that overemphasizes matters of culture, such theoretical framework aims to revaluate the power of the literary in Lahiri’s work. 	Although this dissertation extends, at times, to Lahiri’s three books, its four chapters boil down to a close reading of the three texts constituting the “Hema and Kaushik” trilogy, which also form part 2 of Lahiri’s 2008 collection of short stories, Unaccustomed Earth. Through these three narratives, which all traffic with the dead-mother metaphor, Lahiri can be seen to inscribe the dimension of mourning at the heart of her approach to “generational arrival. ” The three short stories of “Hema and Kaushik” indeed bring to the fore some unacknowledged facets of the much-idealized diasporic experience, which forces us to revise the cultural scenarios through which today’s contemporary world constructs, even essentializes, the figure of the migrant as an emblem of ultimate freedom. My close reading of “Hema and Kaushik” falls into four parts. Part 1 looks at “Once in a Lifetime,” the first text of Lahiri’s trilogy, with a view to showing how the apostrophic form of the text opens up a space of mourning which might blur the boundaries between absence and presence, return and arrival, self and other, but also positions Kaushik, for Hema, as a transitionary figure whose absence might well prove crucial in letting Hema-as-narrator acquire her own generational voice. Part 2 is devoted to “Year’s End,” and investigates the ways in which Lahiri employs the Gothic to represent the second generation as being haunted by its own belatedness in relation to the first generation’s experiences. The psychoanalytic theories of Nicolas Abraham and Maria Torok, among others, will help me clarify how the dead-mother metaphor, in “Hema and Kaushik,” proves tightly interweaved with notions of transgenerational transmission, connection, and infiltration. Calling into question the possible unity of the “I” in the second text of the trilogy, Part 3 tracks the mole, so to speak, and bears witness to aspects of Lahiri’s work that are not all “in the words,” but “among the words,” to borrow Marcel Proust’s suggestive phrase, notably by revisiting aspects of “Once in a Lifetime” and “Years’ End” that are given a new significance through the interplay of the three texts of the trilogy. Relying on André Green’s concept of the “dead mother,” I will then propose an alternative reading of Lahiri’s trilogy in which Hema’s and Kaushik’s romance is only a surface-plot, enlisted to give representability to “the great unspeakable” of Hema’s life. In Part 4, Jean Laplanche’s description of the formation of the ego and the unconscious in relation to “early messages of the m/other” will allow me to look behind the curtain of transgenerational forms of melancholia, to that place where infinite longing is shown to organize itself not around any “real thing” but around a phantom entity whose idealization covers up the necessity to grapple with one’s involvement in a history of loss, which is also a history of guilt. L’œuvre de Jhumpa Lahiri a beau être citée comme une des plus représentatives du grand succès de la littérature diasporique indienne nord américaine aujourd’hui, il n’en reste pas moins que son hypervisibilité médiatique coïncide avec une troublante invisibilité critique. Non pas que la littérature secondaire sur les trois livres de Lahiri soit inexistante, surtout depuis que l’auteur a remporté le prix Pulitzer en 2000 pour son premier recueil de nouvelles, Interpreter of Maladies. Mais ces lectures critiques s’appuient dans leur grande majorité sur l’hypothèse que les notions d’assimilation et d’hybridité culturelles sont toujours d’actualité pour analyser des récits ayant trait à la seconde génération, celle qui se considère « indienne » principalement en rapport aux parents, et qui n’a jamais accès à l’expérience migratoire qu’indirectement. Faisant fi de la différence entre les différentes générations de la diaspora indienne aux Etats-Unis – notamment du fait que, contrairement à leurs aînés, les membres de la seconde génération n’ont d’autre choix que de se référer aux Etats-Unis comme espace identitaire – ce consensus critique masque des aspects importants de la complexité du parcours de Gogol dans le roman de Lahiri, The Namesake, et s’avère tout à fait <b>insuffisant</b> pour envisager le dernier recueil de nouvelles de l’auteur, Unaccustomed Earth, qui aborde l’installation de la seconde génération dans l’âge adulte en interrogeant les notions stéréotypées de transmission et d’héritage. Et si ce qui était transmis d’une génération à l’autre avait davantage à voir avec le négatif, qu’avec le positif, c'est-à-dire, avec les catégories du creux, de l’absence, et du non-dit ? Prenant appui sur le travail critique de Vijay Mishra qui place la thématique du deuil impossible au cœur de la subjectivité diasporique, ma dissertation s’intéresse à la façon dont Lahiri redéfinit la notion d’appartenance et d’arrivée quant à la seconde génération indo-américaine non pas en termes d’assimilation culturelle – ce qui ne fait plus vraiment sens pour des personnages nés aux Etats-Unis – mais en termes d’une resymbolisation des creux de l’histoire migratoire parentale, plus particulièrement d’une resymbolisation de la « perte fantôme » hantant les rapports intergénérationnels. Investiguant les figures du creux, du spectral et du message, ma recherche s’inspire principalement de la psychanalyse (Sigmund Freud, Julia Kristeva, Nicolas Abraham et Maria Torok, André Green, Jean Laplanche). Cette approche méthodologique est motivée par le souci de dégager la valeur éminemment « littéraire » de l’œuvre de Lahiri, dont la portée a été significativement réduite par un consensus critique privilégiant à outrance le champ du culturel. Même si j’aborde à certains moments l’ensemble de l’œuvre de l’auteur, la lecture rapprochée de trois textes que je considère exemplaires, les trois nouvelles entrelacées de « Hema and Kaushik » ou la seconde partie de Unaccustomed Earth, constitue la partie centrale de mon travail. C’est à travers ces trois nouvelles, en effet, et plus particulièrement à travers la métaphore de la mère morte, que Lahiri inscrit la problématique du deuil au cœur d’une nouvelle « arrivée » générationnelle. C’est aussi au travers d’ « Hema and Kaushik » que Lahiri révèle une facette plus sombre et moins idéalisante de l’expérience diasporique, qui induit une relecture des scénarios ayant construit la figures du migrant comme emblème d’un monde hypermobile, où le brouillage des relations entre corps, espace, et temps, est essentialisé comme gage ultime de liberté. Ma dissertation comporte quatre chapitres. Le premier analyse « Once in a Lifetime », la première nouvelle de la trilogie de Lahiri, avec pour objectif de montrer comment la figure de l’apostrophe ouvre ici un espace de deuil qui confond les frontières entre absence et présence, retour et arrivée, le « je » et le « tu », tout en positionnant Kaushik, pour Hema, comme une figure transitionnelle dont l’absence pourrait bien permettre l’émergence d’une nouvelle voix (voie ?) générationnelle. Le deuxième chapitre est consacré à « Year’s End », et s’intéresse à la façon dont Lahiri s’empare du gothique afin de mettre en lumière l’importance de la temporalité de l’« après-coup » (afterwardsness) dans sa représentation de la seconde génération indo-américaine. Les théories psychanalytiques de Nicolas Abraham et de Maria Torok, entre autres, m’aideront à montrer comment, dans la trilogie de Lahiri, la métaphore de la mère morte entremêle les notions d’héritage, de transmission et d’infiltration. Mettant en question l’unité du « je » dans le deuxième texte de « Hema and Kaushik », le troisième chapitre de ma dissertation investit les souterrains de la trilogie, pour ainsi dire, et s’attache non pas à tout ce qui est « dans les mots », mais « entre les mots », pour reprendre l’expression consacrée de Marcel Proust. Il sera notamment question de revisiter des aspects de « Once in a Lifetime » et de « Year’s End » qui prennent un sens nouveau en regard de l’interaction des trois nouvelles. Prenant appui sur le concept de « la mère morte » d’André Green, je proposerai alors une lecture alternative de la trilogie de Lahiri, en vertu de laquelle la romance entre Hema et Kaushik n’est qu’une intrigue de surface servant à donner corps au cœur d’indicible et d’impensable dans l’existence d’Hema. Dans le dernier chapitre, les théories de Jean Laplanche sur la formation du moi et de l’inconscient en rapport au « message de l’autre » me permettront de pénétrer l’envers du décor de la mélancolie intergénérationnelle, cet espace où la nostalgie sans fin est révélée en tant qu’elle s’organise moins autour d’une quelconque chose réelle qu’autour d’une entité fantôme dont l’idéalisation sert à masquer la nécessité d’en découdre avec une histoire de perte, qui comporte aussi sa part de culpabilité...|$|E
40|$|The façade of the Clunisian abbey {{church of}} Saint-Gilles-du-Gard {{is one of}} the mostcomplex and {{elaborate}} examples of the profound influence of antique architectureand architectural sculpture on the late Romanesque style in Southern France. Sincethe 19 th century, several generations of scholars have studied this famous monument,trying to establish the history of its construction, explaining the stylistic diversity ofits sculptural program and commenting on its architectural and artistic concept. Oneof the major aspects consistent with nearly all previous theories is that the design ofthe façade, considered as incoherent in its actual state, had been subjected to majorchanges during the building process. Attempts to reconstruct the originalhypothetical design, by various authors such as Marcel Gouron, Victor Lassalle andWhitney S. Stoddard, were based on the tacit assumption that the Romanesqueproject was founded on a logical concept similar to those found in the laterRenaissance and classical period. Idealistic visions of what the "original" façadewould, could or should have looked like led either to a selective perception ofauthentic archaeological evidence, or to misleading interpretations of thearchitectural structure. Since the late 1970 ’s no major study of the façade of Saint-Gilles has addedsubstantially new or convincing arguments to this futile discussion, from anarchaeological point of view, and both Willibald Sauerländer and Dorothea Diemer,author of the latest architectural analysis of the monument, have noted the necessityof authentic fundamental research before resuming the debate. The evidence that nofurther progress could be achieved without a profound and systematic archaeologicalsurvey of the entire façade became the starting point of our thesis. From 1999 to 2002, three whole years were spent on a complete and exact stone-by stone scaledrawing of the façade and its foundations, {{as well as of the}} aisle walls of theadjacent crypt and nave, consisting in all the exterior and interior elevations andhorizontal and vertical cross-sections. The combination of measurements takenmanually from a mobile scaffolding and a precise survey assisted by computer andlaser technology (theodolite, laser level) resulted in a highly reliable type of drawingwhich benefits from both a thorough macroscopic examination of all the visiblesurfaces of the monument and a dense network of precise topographical threedimensionalreferences. An archaeological survey alongside the foundation walls,undertaken in 2004, added substantial evidence to the results of the stone-by-stoneanalysis. The survey revealed that the Romanesque foundation was built upon earlierstructures, some of which were either removed or incorporated into the centralprojection of the western wall of the crypt on which the façade rests. Resistant to theweight and pressure of the new structure, the remaining masonry caused severedamage to the ashlar masonry when parts of the façade started to move downwardsduring the building process. The deformations, hardly perceptible to the eye butmeasurable, must have become obvious almost immediately, as the masons tried tolevel the courses with thicker joints and with angles bent back into a verticalposition, which soon began inclining again due to the slow but continuousmovement of the façade. The huge crack in the middle of the foundation wouldactually have begun to open before work had started on the upper level of the façadeitself. As a major threat to the stability of the planned structure, the crack seems tohave been responsible for the first major change of the project which included aprotruding protiro inspired by North Italian prototypes, the pedestals of which werenever executed as such but were instead replaced by blocks of a considerably lessersize, and their lion figures put to a different use. By the time the structure hadreached the level of the main lintel the protiro was definitely abandoned, theprotruding pairs of columns were subsequently shortened and fitted with corniceblocks at a lower level, and the main blind arch on the inside was downsized to thesame level as the secondary arches of the south and north portals. At that time thecentre of the façade must have been left open, with the decision of building a nonprotrudingarchivolt being taken at a later date. The orphaned corbels for the protirogable were finally inserted above the major frieze, and the façade was completed. Our analysis of the façade has established that the sculpture was entirely prepared inadvance. The evidence of reused antique stone material, which the sculptors chosefor their excellent quality, could explain some of the irregularities and the incoherentassembly of the superior registers of the façade; the size of the three lintel blocksbeing obviously insufficient to match the adjacent blocks of the figured frieze. Onthe other hand, no proof could be found for any of the major modificationssuggested in the former studies of the façade, the sculptured blocks having beenassembled in a regular process without obvious interruption, with the exception ofthe main archivolt, the corbels and the retro-fitted parts of the underlying cornice. Our study contradicts former opinion that the building of the façade was delayedafter the western wall of the crypt which the façade is based upon had beencompleted. Both levels are, in fact, inseparable and closely related. Incompatiblewith this technical evidence is the early inscription in the south wall of the crypt,which commemorates the foundation of the church in 1116, and which should notnecessarily refer to the including masonry. The same conclusion applies to theepitaphs in the western wall dated 1129 and 1142 : the archaeological survey hasproven in at least two cases the absence of any contemporary tomb underneath thefunerary inscriptions, which could have been cenotaphs for older tombs removed forthe foundations of the church. Comparisons with Saint-Trophime at Arles and otherrelated monuments in Italy tend to confirm that the sculpture cannot be earlier thanthe late 1170 s or early 1180 s. The very similar crypt of Saint-Trophime, which waspossibly completed for the translation of the relics of Saint Trophimus in 1153,should hint at a close date for the crypt of Saint-Gilles. The focus of our study of the façade of Saint-Gilles excludes the making of thesculpture itself, nor do we discuss the formerly and much debated problem of theartists, seriously questioned by Dorothea Diemer, Willibald Sauerländer andanalyzed by Andreas Hartmann-Virnich in his studies on the sculpture of Saint-Trophime at Arles. Instead, our archaeological approach reveals in great detail thetechniques, and the strategies which the builders developed and used in order tointegrate the earlier structures, and in order to counterbalance the negative effectsthat resulted of their insufficient knowledge or carelessness during the buildingprocess. The history of the building of the façade of Saint-Gilles, told through themasonry itself, offers a fascinating insight into the world of the builders of one of thechief masterpieces of Romanesque architecture in the Mediterranean. La façade de l'église abbatiale clunisienne de Saint-Gilles-du-Gard est l'un des plus complexes exemples de l'influence profonde de l'architecture antique et de sa sculpture architecturale sur le style roman tardif dans le sud de la France. Depuis le 19 ème siècle, plusieurs générations de chercheurs ont étudié ce célèbre monument, en essayant d'établir l'histoire de sa construction, pour expliquer la diversité stylistique de son programme sculptural et de commenter son concept architectural et artistique. Un des aspects majeurs de presque toutes les théories précédentes est une supposée incohérence de la conception de la façade dans son état actuel, qui aurait subit de grands changements au cours du processus de sa construction. Les tentatives de reconstruire une conception originale hypothétique, par divers auteurs tels que Marcel Gouron, Victor Lassalle et Whitney S. Stoddard, étaient fondées sur l'hypothèse tacite que le projet initial a été fondé sur un concept logique, similaire des constructions de la Renaissance et de la période classique, des visions idéalistes à ce que la façade « originale » serait, pourrait ou devrait avoir ressemblé, ont conduit soit à une perception sélective de l’évidence archéologique, ou à induire en erreur les interprétations de la structure architecturale. Depuis la fin des années 1970, aucune étude majeure de la façade de Saint-Gilles n’a fourni des arguments sensiblement nouveaux ou convaincants à cette discussion futile au point de vue archéologique, et Willibald Sauerländer et Dorothea Diemer, auteur de la dernière analyse architecturale du monument, ont noté la nécessité d’une recherche fondamentale de la construction avant de reprendre le débat. En conséquence une étude archéologique profonde et systématique sur l'ensemble de la façade est devenue le point de départ de notre thèse. De 1999 à 2002, trois années successives ont été consacrés au relevé exhaustif pierre à pierre des élévations de la façade et de ses fondations, ainsi qu’aux murs conjoints de la crypte des côtés extérieurs et intérieurs et aux plans et coupes transversales du massif occidental. La combinaison des relevés effectués manuellement à partir d'un échafaudage mobile et des relevés tachéométriques au laser assistés par ordinateur ont donné lieu à une documentation fiable de toutes les faces visibles de la façade. Une étude archéologique au pied du mur ouest, entreprise en 2004, a ajouté des évidences substantielles aux résultats de l’étude en archéologie du bâti. L’analyse des relevés a révélé que la fondation romane a été construite au dessus de structures plus anciennes et hétérogènes dont certaines ont été détruits partiellement ou incorporés dans la partie centrale du mur sur laquelle repose le portail principal de la façade. Ces irrégularités ont causé de graves dommages à la maçonnerie lorsqu’une partie de la façade a commencé à s’affaisser au cours du processus de construction. Les déformations furent corrigées par les maçons en renivelant l’affaissement, entre autre avec des joints plus épais et avec des angles verticaux repliés. L'énorme fissure au milieu de la fondation apparaissait sans doute au cours du chantier de la construction de la façade au dessus de son socle. Comme une menace majeure pour la stabilité de la structure prévue, la grande fissure au centre du mur semble responsable de la première modification importante du projet initial d’un protiro en saillie, à l’instar des exemples d’Italie du Nord, une construction prévue au dessus des piédestales très massifs toujours en places, qui n’était jamais exécutée, remplacée par une structure réduite en taille et moins fragile. Au niveau du linteau principal le protiro fut définitivement abandonné, les doubles colonnettes furent raccourcies et munies d'une corniche déterminante horizontale à un niveau inférieur. Et l’arc de décharge principal à l'intérieur du mur fut réduit au même niveau que les arcs secondaires des portails sud et nord. A ce stade de la construction la partie haute du portail central au dessus du linteau était laissée ouverte, avec la décision de construire une archivolte non saillante à une date ultérieure. Les encorbellements orphelins pour le protiro furent finalement insérés au niveau de la grande frise, et la façade a été achevée. Notre analyse de la façade a établi que la sculpture a été entièrement préparée en avance. L’existence de pierres antique remployées, que les sculpteurs ont choisi pour leur excellente qualité, pourrait expliquer certaines des irrégularités et l'incohérence de l’assemblage des registres supérieurs de la façade; la taille des trois blocs de linteaux étant manifestement <b>insuffisant</b> pour correspondre aux blocs adjacents de la frise figurée. D'autre part, aucune preuve n’a été trouvée pour l'une des principales modifications suggérées dans les études antérieures, les blocs sculptés ayant été assemblé dans un processus régulier sans interruption évidente, à l'exception de l'archivolte principale et la corniche en encorbellement mis en place postérieurement dans une maçonnerie déjà en place. Notre étude contredit l’ancienne opinion que le montage de la façade a été retardé après la construction du socle sur lequel elle repose. Les deux niveaux sont inséparables et étroitement liées. En revanche cette évidence est incompatible avec l'inscription dans le contrefort sud-ouest de la crypte, qui commémore la fondation de l'église en 1116, élément de remploie d’un monument antérieur, abandonné pour la nouvelle construction dont la façade occidentale fait partie. La même conclusion vaut pour les épitaphes dans le socle du mur occidental des années 1129 et 1142 : l'étude archéologique a en effet montré dans au moins deux cas l'absence de tombes contemporaines en dessous des inscriptions funéraires, probablement des cénotaphes pour des tombes enlevées pour les fondations de cette église. Les comparaisons avec Saint-Trophime à Arles et d'autres monuments en Italie tendent à confirmer que la sculpture ne peut pas être antérieure à 1170 ou au début des années 1180. La crypte très similaire de Saint-Trophime, éventuellement complétée pour la translation des reliques de Saint Trophime en 1153, devrait faire allusion à une date proche de la crypte de Saint-Gilles. L'objectif de notre étude de la façade de Saint-Gilles exclut l’étude de la réalisation de la sculpture elle-même et les questions artistes et d’histoire de l’art, sérieusement interrogées par Dorothea Diemer, Willibald Sauerländer et analysées par Andreas Hartmann-Virnich dans ses études sur la sculpture de Saint-Trophime à Arles. En revanche notre approche archéologique révèle en détail les techniques et les stratégies que les bâtisseurs développaient et utilisaient dans le but d’intégrer les structures antérieures, et de contrebalancer les effets négatifs qui résultent de leurs manques de connaissances ou de la négligence lors du processus de construction. L'histoire de la construction de la façade de Saint-Gilles, lisible à travers la maçonnerie elle-même, offre un aperçu fascinant du chantier d’un chefs-d'œuvre de l'architecture romane en Méditerranée...|$|E
40|$|Strontium Bismuth Titanate {{is a very}} {{promising}} material for high temperature piezoelectric applications, its elevated ferroelectric phase transition (530 °C), linear piezoelectric properties under low field and relatively low room temperature conductivity (compared to others Bismuth Titanates) make it very attractive for precision sensors. However, under severe conditions (low frequency, high field, high temperature or low oxygen partial pressure) some of those advantages disappear. Piezoelectric response is dominated by charge drift in general becomes unstable. Above all, at high temperature and low oxygen partial pressure, a large conductivity increase reduces the piezoelectric efficiency of the material, in this work, electrical conductivity, piezoelectric properties and dielectric permittivity of SrBIT ceramic have been investigated in conditions of high temperature, low oxygen partial pressure, low to moderate driving field and frequency. As {{a result of this}} research, a better understanding of SrBIT properties was achieved. Thanks to a careful study of SrBIT processing as a bulk ceramic, a reproducible route was established. Many basic mechanisms leading to both SrBIT crystallization and sintering have been identified. It was demonstrated that a detailed knowledge of the exact processing conditions is required in order to achieve high quality material. DC conductivity measurements were carried out as a function of temperature, oxygen partial pressure and dopant concentration. It was found that the apparent activation energy for conduction for undoped SrBIT was 1 eV between 140 and 220 °C and 1. 5 eV between 450 and 700 °C. Decrease of the activation energy in the lower temperature range has been discussed considering grain boundary conductivity, as a transition from electronic to ionic conduction or as consequence of small polarons conduction. It was shown that lower activation energy resulted from Manganese doping (0. 5 eV), this was interpreted as either growing influence of grain boundary conductivity as dopant concentration increases or as shallow hole trap formation. DC conductivity measurements and acceptor/donor doping experiments demonstrated p-type conductivity in the low temperature range (up to 220 °C) as donor doping decreases conductivity, while oxygen partial pressure controlled measurements indicated n-type conductivity at higher temperature (above 700 °C). An electrical impedance analysis was performed with several equivalent circuits. The aim of these models was to simulate the impedance of SrBIT. The best approximation was found with a distributed element of Havriliak-Negami type. However, as the physical justification for this circuit was not clear, the investigation of the grain, grain boundary and electrode impedances was performed with multiple discrete parallel RC elements. With temperature, grain size and oxygen activity variations, the identification of three separate contributions as grain, grain boundary and electrode was realized. The anisotropy of conductivity and permittivity was demonstrated with textured material and both DC and AC analysis. With the master curves built for the electrical modulus, {{it was found that the}} impedance probably related to Bismuth oxide layers produces an additional high frequency are. From this finding and by comparing characteristic relaxation frequencies of undoped, 2 mol. % Mn and 4 mol. % Nb SrBIT, it was determined that conductivity is higher in the ab plane direction than in the c direction within both perovskite units and Bismuth oxide layers. With conductivity measurements under controlled oxygen partial pressure, it was found that an acceptor-based (intrinsic or extrinsic) model could be used to describe the electrical conductivity under controlled oxygen partial pressure of both undoped and 2 mol. % Mn doped SrBIT. However, as neither a pO 2 - 1 / 6 region (intrinsic oxygen vacancies compensated by electrons) for undoped SrBIT nor a pO 2 - 1 / 4 region (oxygen vacancies compensated by singly ionized acceptors) for Mn doped SrBIT were seen, it was concluded that the acceptorcontrolled model is not sufficient for a complete description of SrBIT. For this reason and in order to include the low oxygen partial pressure behavior of undoped SrBIT, a donor-based (intrinsic) model was also considered. The source of intrinsic donors would be in that case Bi 3 + cations sitting on Sr 2 + sites in the perovskite sublattice. Considering Bismuth vacancies as the negative compensating species, both pO 2 - 1 / 4 and pO 2 -independent regions could be predicted with the model. However, even if the donor-controlled model seems to better match conductivity measurements in the full PO 2) range, rejecting the acceptor-based model would be an error. It is actually not demonstrated that in SrBIT the concentration of exchanged Bismuth cations is always (all temperature, pressure) larger than the natural acceptor impurity concentration. It is very likely that the cation exchange is dependent of the oxygen partial pressure. It is also not proved as suggested in the literature that direct compensation between exchanged Strontium and Bismuth exists, reducing the net donor-excess. With the acceptor-controlled model, the mass-action constants for reduction and for ionization of intrinsic carriers across the band gap were determined. The band gap of SrBIT was estimated to be 3. 5 eV. The ionic conductivity of SrBIT was determined at high temperature with measurements under controlled oxygen partial pressure. It was found that the electrical conductivity of SrBIT is probably mixed (electronic and ionic) as the estimation of the transference number provided quite large values (t= 0. 8 at 800 °C). From electronic and ionic conductivity data, mixed conduction can actually be predicted in a large temperature range (above room temperature). The piezoelectric measurements using direct effect demonstrated that it is actually possible to unlock piezoelectrically active ferroelectric domain walls and create non-linear piezoelectric properties in undoped SrBIT. This occurs above a threshold elastic field, which is thermally activated. With a piezoelectric composite, it was demonstrated that the electromechanical coupling between two different phases creates a piezoelectric relaxation. This one could be positive or negative depending on the respective properties of each composite's component. It was shown experimentally that a small temperature change is sufficient to transform a positive relaxation into a negative one. While these experiments did not provide a detailed microstructural explanation for the piezoelectric relaxation observed in 2 mol. % Mn doped SrBIT, they gave a first insight into an original phenomenological approach. Microstructure and piezoelectric properties were related with the calculation of a piezoelectric relaxation composite made of two textured samples. This demonstrated that a piezoelectric relaxation may occur just because of anisotropy. Microstructural reproduction of this coupling is actually an important feature of Aurivillius phases. Le Titanate de Strontium Bismuth (abrégé SrBIT) est un matériau très prometteur pour des applications piézo-électriques à haute température. Grâce à une température de transition de phase ferro-électrique élevée (530 °C), à des propriétés piézo-électriques très stables sous faible champ et à une conductivité électrique relativement basse à température ambiante (comparée à d'autres Titanates de Bismuth), ce matériau est très intéressant pour réaliser des capteurs de précision. Cependant, sous conditions extrêmes (basse fréquence, champ élevé, haute température ou basse pression d'oxygène), ces avantages disparaissent et la réponse piézo-électrique, dominée par les dérives de charge, devient instable. Mais avant tout, à haute température et basse pression d'oxygène, l'accroissement très fort de la conductivité réduit considérablement l'effet piézo-électrique de SrBIT. Dans ce travail, la conductivité électrique, les propriétés piézo-électriques et la permittivité diélectrique de SrBIT ont été étudiées à haute température, basse pression partielle d'oxygène, faible champ et fréquence. Cette recherche a permis une meilleure compréhension des propriétés de SrBIT. Par une étude détaillée de la préparation de SrBIT sous forme de céramique massive, une méthode de préparation reproductible a été établie. Différents mécanismes élémentaires qui interviennent lors de la cristallisation ou du frittage ont été identifiés. Mais, il a été démontré également qu'une connaissance pointue des paramètres du procédé est requise pour garantir la préparation de matériaux de bonne qualité. Des mesures de conductivité électrique de type DC ont été effectuées en variant la température, la pression partielle d'oxygène et la teneur en dopant. L'énergie d'activation pour la conductivité déterminée lors de ce travail de thèse est de 1 eV entre 140 et 220 °C et de 1. 5 eV entre 450 et 700 °C. La diminution de l'énergie d'activation dans la gamme inférieure de température a été interprétée comme la conséquence d'une conductivité aux joints de grain prépondérante à basse température. Les hypothèses de la transition d'un régime électronique à un régime ionique ou la conduction par polarons ont également été considérées. La diminution de l'énergie d'activation (0. 5 eV) par le dopage de type accepteur de SrBIT a été interprétée comme soit l'influence grandissante de la conductivité des joints de grains soit le piégeage des trous dans des niveaux peu profonds. Les mesures de conductivité DC et les dopages de type donneur et accepteur ont démontré une conductivité de type p dans la gamme inférieure de température (jusqu'à 220 °C), car l'ajout d'une certaine quantité de Niobium (donneur) diminue la conductivité de SrBIT. Par contre, les mesures effectuées à plus haute température sous pression partielle d'oxygène contrôlée indiquent une conductivité de type n. L'analyse dc l'impédance électrique de SrBIT a été réalisée à l'aide de différents circuits équivalents. A l'aide de ces modèles, l'impédance de SrBIT a pu être simulées. La meilleure approximation a été trouvée avec un élément distribué de type Havriliak-Negami. Cependant, comme la justification physique de ce circuit n'est pas claire l'étude de l'impédance des grains, des joints de grains et de l'interface céramique-électrode a été effectuée avec plusieurs circuits équivalents de type discret. À l'aide de l'influence de la température, de la taille de grain et de la pression partielle d'oxygène, l'identification de l'impédance des grains, des joints de grains et de l'électrode a pu être établie. L'anisotropie de la conductivité et de la permittivité a été démontrée par l'analyse AC et DC de matériau texturé. Grâce à des courbes maîtresses construites pour le module électrique, l'impédance probablement liée aux couches d'oxyde de Bismuth a été observée à haute fréquence. Avec ce résultat et en comparant les fréquences de relaxation de SrBIT non-dopé, dopé accepteur (2 % mol Mn) et dopé donneur (4 % mol.), il a pu être démontré que la conductivité est plus grande dans la direction dite "plan ab" que dans la direction "c" pour les unités de structure pérovskite et pour les couches d'oxyde de Bismuth. Avec des mesures de conductivité DC à haute température (> 700 °C) sous pression partielle d'oxygène contrôlée, il a pu être démontré qu'un modèle basé sur un excès d'accepteurs pouvait être avantageusement utilisé pour décrire la conductivité de SrBIT non-dopé et dopé accepteur. Cependant, comme aucune région en pO 2 - 1 / 6 (compensation des lacunes d'oxygènes intrinsèques par des électrons) pour SrBIT non-dopé ou en O 2 - 1 / 4 (compensation des lacunes d'oxygènes par des accepteurs simplement ionisés) pour SrBIT dopé Mn n'ont été observée, il a été conclu qu'un modèle basé uniquement sur un excès d'accepteurs était <b>insuffisant.</b> C'est pourquoi, afin aussi d'inclure le comportement de SrBIT à très basse pression d'oxygène, un autre modèle, basé sur un excès intrinsèque de donneurs a également été considéré. Dans ce modèle, la source intrinsèque de donneur proviendrait d'un échange de site entre Bi 3 + des couches d'oxydes de Bismuth et Sr 2 + des unités pérovskite. En assumant la compensation des défauts positifs par des lacunes de Bismuth, une région de conductivité en pO 2 - 1 / 4 et une autre indépendante de la pression peuvent être prédites. Cependant, même si ce modèle semble mieux correspondre aux mesures de conductivité, rejeter le modèle accepteur serait une erreur. En effet, il n'est pas prouvé que la concentration de donneurs intrinsèque soit toujours supérieure (à n'importe quelle température ou pression) que la concentration d'impuretés. Il est par exemple très probable que l'échange de cations soit dépendant de la pression partielle d'oxygène. De plus, la compensation directe des deux cations échangés ne peut pas être exclue, ce qui réduirait l'excès net de donneur. Avec le modèle accepteur, les constantes d'équilibre pour la création de lacunes d'oxygène et pour l'ionisation de porteurs au travers de la bande interdite ont été déterminées. L'énergie de la bande interdite de SrBIT a été estimée à 3. 5 eV. Avec les mesures de conductivité sous pression partielle d'oxygène contrôlée, la conductivité ionique de SrBIT a été estimée à haute température. Ainsi, il est proposé que la conductivité de SrBIT est de type mixte (électronique et ionique), par exemple le nombre de transférence à 800 °C est de 0. 8. A partir des mesures de conductivité ionique et électronique, une conduction mixte sur une large gamme de température peut être prédite. Des mesures piézo-électriques ont démontré que le désancrage de parois de domaines ferroélectriques actives pour la piézo-électricité de SrBIT était possible, ce qui induit des propriétés piézo-électriques non linéaires. Ceci se produit au-dessus d'un seuil de champ élastique qui est activé thermiquement. Avec un composite piézo-électrique, la création d'une relaxation piézoélectrique par le couplage électro-mécanique de deux différentes phases a été démontré. Cette relaxation peut être positive ou négative selon les propriétés des matériaux constituant le composite. Par exemple, un petit écart de température transforme une relaxation positive en relaxation négative. Bien que ces expériences ne permettent pas d'expliquer les relaxations piézo-électriques observées pour SrBIT dopé Manganèse, elles donnent un premier aperçu d'une approche phénoménologique originale. Le lien entre la microstructure et la relaxation piézoélectrique a été établi par le calcul du coefficient piézo-électrique d'un composite constitué de deux échantillons texturés. Il a ainsi été démontré que les différences de propriétés dues à l'anisotropie de SrBIT suffisent à créer une relaxation. La reproduction interne à la microstructure de ce couplage est certainement une caractéristique importante des phases d'AuriviIlius...|$|E
40|$|Growth and {{employment}} {{the scope of}} an European initiative Jacques Drèze, Edmond Malinvaud et Alii Executive Summary 1. Since almost twenty years now, European unemployment is a major social problem and the sign of significant underutilisation of resources {{at a time of}} substantial unfilled needs. Whereas employment increased by nearly 6 % between 1987 and 1990 in EC 12, the rate of employment is now again exceeding 10 % and rising. Even under reasonably optimistic forecasts (a growth rate of 2. 5 to 3 %), the unemployment rate will remain above 10 % for at least four or five years. This position paper reviews the short-, medium- and long-run policies best susceptible of promoting growth {{and employment}} in Europe. 2. We argue that fiscal policy is not, at this time, a suitable instrument of short-run stabilisation. Attention should rather be focussed on medium-term structural budget consolidation, which was neglected during the expansion of the late eighties. On the other hand, we argue for monetary stimulation through a strong decrease of short-term interest rates, and propose the reference level of zero short-term real interest rates. 3. Turning to medium-run policies, we advocate two sets of measures, concerning respectively labour costs and investment. 3. a We note that high unemployment is heavily concentrated among unskilled workers. Moreover, we find evidence of a trend in the skilll composition of labour demand, which contains a declining proportion of unskilled jobs. These considerations justify investment in training and education. We believe that they also justify immediate measures aimed at reducing the cost of unskilled labour relative to the cost of skilled labour and of capital. An important element of labour costs consists in taxes and social insurance contributions, which drive a substantial wedge — 30 to 50 % in the EC member countries — between the cost of labour to employers on the one hand, take-home pay or the social opportunity cost of unskilled labour on the other hand. We argue {{that the time has come}} to reduce that wedge, and we propose exempting minimum wages from employers' contributions to social security. This may be done either by collecting such contributions only on that part of all wages that exceeds minimum wages; or by introducing an exemption amounting to 100 % of these contributions at the minimum wage level but decreasing linearly to zero at twice that level. The first measure is very costly — of the order of 3. 2 % of GDP on average in EC 12, with substantial country differences. The second measure is much less costly, rather like 1. 2 % of GDP. In either case, substitute resources should be allocated to the social security. The CO 2 tax currently under consideration by EC countries (with estimated receipts of the order of 1 to 1. 3 % of GDP) is a natural source. Raising the ceiling on VAT rates is another source. There is room for country- specific measures. Econometric simulations of labour tax exemptions in France and Belgium must be regarded as imprecise. Generally, they confirm our belief that no miracle should be hoped for, but that appreciable medium-term gains in employment are in sight, at no budgetary cost, if our proposal is implemented on a bold scale. 3. b With regard to investment, we recognise that unused capacities limit the immediate prospects for business investment. But we argue that idle resources could be mobilised towards labour-intensive investments with adequate social returns — contributing in addition to sustain aggregate demand. This is also the logic of the Edinburgh initiative, where Trans-European Neworks receive priority, together with small firms. We argue however that the Edinburgh package falls short of what is needed. An investment program matching the structural budget consolidations to come would place no strain on capital markets, while making up the shortfall in public investments of the past decade. We advance a figure of 250 Bilion ECU'S (or roughly 8 times the Edinburgh objective) as a realistic medium-term target, and propose to privilege in addition areas like low-income housing, urban renewal and urban transportation. In order to stimulate such targeted investments, we suggest to rely mainly on employment subsidies, proportional to the labour content of approved projects. This would reinforce, or possibly anticipate, our previous suggestion for reducing labour costs — while enlarging the set of investments attractive to private investors and local authorities [...] . Improved access to capital markets should in addition be sought through collaboration with institutional intermediaries, through an extension of the mission of the European Investment Bank and through an extension or replication of the European Investment Fund. 4. Our discussion of structural problems is foccused on basic principles. We first stress the detrimental incidence of the prevailing uncertainty about some inflation, interest and exchange rates, but also about institutional developments in the monetary area — including the recurring temptations of competitive devaluations. We do not opt for a specific political program. But we stress that reducing institutional monetary uncertainties is an important goal in its own rights. It should be pursued actively, to put monetary Europe on a track more promising for employment than a return to floating exchange rates between the currencies of relatively small economies closely integrated through trade. We next turn to public finance and the Welfare State, recognising the need in several countries for structural budget consolidation, and the elements of disenchantment with respect to the performance of the Welfare State. Reviewing its economic logic, we conclude that the agenda should be to make the Welfare State leaner and more efficient, not to dismantle it. This calls for reviewing in depth the operating and distributive efficiency of existing programs, with the conflicting aims of reducing the share of social transfers in GDP by several percentage points, while strengthening the protection of the least endowed. Economists should intensify their participation in this important research challenge. Finally, we draw the implication for wages of an European Growth Initiative aimed at a period of sustained growth, with priority given to employment relative to real wages. We feel that a realistic pattern combines output growth in excess of 3 % with employment growth above 1 %. This leaves a margin of at most 2 % for real wages. Given the presence of wage drift, this seems to call for negotiated settlements at roughly constant real wages. Is such a pattern realistic ? We bring out the controversial issue of the significance for wage developments of the relative tax burdens on capital and labour. And we recognise that the decline of the labour share in the eighties has been accompanied by a rise in the share of interest income, which in many cases is subject to little taxation, due in particular to capital mobility and intercountry tax competition. A uniform withholding tax on interest income at the European level is the only avenue to correct that imbalance. Whether or not such a tax is desirable in its own rights is a debated issue. That debate should be enlarged to recognise that distributional fairness in the tax treatment of capital and labour could make a significant contribution to wage moderation — even though it may be premature to regard the empirical evidence as conclusive. 5. We hope to have identified a set of measures endowed with overall consistency and with a globality commensurate with the magnitude of the problem confronting us. They have budgetary implications that call for reallocating a few percentage points of GDP, which is more than usually contemplated. And they fall under the responsibility of a whole set of institutions which are not engaged in systematic policy coordination. Serious problems of implementation should thus be tackled. We call on policy makers to exert boldness and determination in tackling these problems. And we call on academic economists to participate actively in the definition and promotion of an ambitious European initiative — starting perhaps with a criticism and elaboration of our own views. Depuis bientôt vingt ans, le chômage européen est un problème social majeur et le signe d'une importante sous-utilisation des ressources à une époque où existent bien des besoins insatisfaits. Alors que l'emploi a crû de près de 6 % entre 1987 et 1990 dans la Communauté Européenne des douze, le taux de chômage dépasse à nouveau 10 % et s'élève. Même selon des prévisions raisonnablement optimistes (un taux de croissance de 2, 5 à 3 %) le taux de chômage dépassera 10 % durant au moins quatre ou cinq ans. Cette note prend position sur les politiques de court, moyen et long terme que nous considérons comme les mieux aptes à promouvoir la croissance et l'emploi en Europe Occidentale. Nous prétendons qu'actuellement une politique budgétaire active ne paraît pas constituer un instrument adéquat pour la stabilisation économique à court terme. L'attention devrait plutôt se concentrer sur la consolidation structurelle à moyen terme des budgets, un objectif négligé durant l'expansion de la fin des années 80. Mais nous plaidons pour une stimulation monétaire, à obtenir par une forte réduction des taux d'intérêt nominaux à court terme; nous proposons le niveau de référence zéro pour les taux d'intérêt réels à court terme, pour aussi longtemps que l'on n'observe pas clairement que la reprise est engagée. S' agissant des politiques de moyen terme, nous recommandons deux ensembles de mesures relatifs respectivement aux coûts du travail et à l'investissement. Nous notons que le chômage élevé se concentre fortement sur les travailleurs non qualifiés. De plus nous trouvons la preuve d'un désaccord croissant entre les structures par qualifications de l'offre et la demande de travail, la composition de celle-ci se modifiant vite au détriment des travailleurs non qualifiés. Cette observation justifie que l'on investisse dans l'enseignement et la formation. Nous considérons qu'elle justifie aussi des mesures visant à réduire le coût du travail non qualifié par rapport aux coûts du travail qualifié et du capital. Un élément important du coût du travail est constitué par des impôts et contributions sociales, qui entraînent un écart, particulièrement substantiel pour le travail non qualifié, entre le coût pour les employeurs et le coût d'opportunité pour la société — de 30 % à 50 % dans les pays de la Communauté. Nous prétendons que le moment est venu de réduire cet écart et nous proposons d'exempter le salaire minimum des contributions sociales à la charge des employeurs. Cela peut se faire soit en percevant de telles contributions, pour tout salaire, sur la part excédant le salaire minimum, soit en introduisant une exonération dégressive s'élevant à 100 % au niveau du salaire minimum et décroissant linéairement jusqu'à zéro au niveau double. La première modalité implique une réforme substantielle des systèmes fiscaux, car son coût direct s'élève à environ 3, 2 % du PIB en moyenne dans la Communauté, avec des différences importantes suivant les pays. En revanche, le coût de la seconde modalité est plutôt de l'ordre de 1, 2 % du PIB. Dans les deux cas, des ressources de remplacement doivent être trouvées pour la sécurité sociale. Une source naturelle serait l'impôt sur les émissions de CO 2 qui est actuellement examiné par les pays de la Communauté (avec un rendement estimé de l'ordre de 1 à 1, 3 % du PIB). Une autre source résiderait dans un relèvement des taux de la TVA. Pour la définition exacte, la mise en œuvre et le financement de cette mesure, il y a évidemment place à des mesures spécifiques aux divers pays. Les simulations économétriques faites en France et en Belgique concernant les exonérations de taxes sur le travail, doivent être considérées comme imprécises. En termes généraux elles confirment nos idées selon lesquelles il ne faut certes pas espérer un miracle, mais des gains appréciables en emploi peuvent être attendus à moyen terme, sans coût budgétaire, si notre proposition est appliquée sans timidité. A propos de l'investissement, nous reconnaissons que des capacités inutilisées limitent les perspectives immédiates d'équipe- ment des entreprises. Mais nous prétendons que des ressources inemployées peuvent être mobilisées pour des investissements riches en travail, qui auraient des rendements sociaux adéquats et contribueraient de plus à soutenir la demande globale. C'est aussi la logique de l'initiative d'Edimbourg, où les réseaux trans-euro- péens ont reçu la priorité, ainsi que les petites entreprises. Nous prétendons cependant que l'ensemble convenu à Edimbourg est <b>insuffisant.</b> Un programme d'investissement dont le montant correspondrait aux efforts à venir pour la consolidation structurelle des budgets ne créerait pas de tension sur les marchés du capital, tout en compensant le retard pris par les investissements publics dans la décennie passée. Nous avançons le chiffre de 250 milliards d'Ecus (soit grosso modo huit fois l'objectif d'Edimbourg) comme un but réaliste à moyen terme. Nous proposons de privilégier aussi des domaines tels que le logement pour les ménages à bas revenus, la rénovation urbaine et les transports urbains. Afin de stimuler les investissements ainsi visés, nous suggérons que l'on s'en remettre surtout aux subventions à l'emploi, en proportion du contenu en travail des projets retenus. Une telle disposition renforcerait, voire anticiperait, sur notre proposition précédente destinée à réduire les coûts du travail; elle aurait surtout pour effet d'élargir l'ensemble des projets attractifs pour des investisseurs privés et des autorités locales. De plus un meilleur accès au marché du capital devrait être recherché grâce à la collaboration d'intermédiaires institutionnels, à l'accroissement des missions de la Banque Européenne d'Investissement, à l'extension ou à la duplication du Fonds Européen d'Investissement. Notre discussion des problèmes structurels se concentre sur les principes de base. Nous insistons d'abord sur les effets défavorables des incertitudes actuelles qui touchent non seulement certains taux d'inflation, d'intérêt et de change, mais aussi les évolutions institutionnelles dans le domaine monétaire, y compris la tentation récurrente de dévaluations compétitives. Nous ne choisissons pas un programme politique spécifique. Mais nous proclamons que réduire les incertitudes institutionnelles à propos des monnaies constitue un objectif important en lui-même. Il devrait être poursuivi activement, afin d'engager l'Europe monétaire sur une voie plus prometteuse pour l'emploi qu'un retour à des taux de change flottants libres entre les monnaies d'économies relativement petites et intégrées entre elles par d'étroits liens commerciaux. Nous examinons ensuite les finances publiques et l'Etat-provi- dence, en reconnaissant que plusieurs pays ont besoin d'une consolidation structurelle de leurs budgets et qu'il existe des éléments de déception quant aux effets des régimes sociaux. Etudiant la logique économique de l' Etat-providence, nous concluons que les réformes à réaliser devraient viser à le rendre plus svelte et plus efficace, non à le démanteler. Pour cela il faut revoir à fond l'efficacité opérationnelle et distributive des programmes existants, afin d'atteindre deux objectifs difficilement compatibles : réduire dans la plupart des pays la part des transferts sociaux dans le PIB, renforcer la protection des plus mal dotés. Les économistes devraient intensifier leur participation aux recherches destinées à relever cet important défi. Enfin, nous tirons les conséquences salariales d'une Initiative Européenne de Croissance visant à une période d'expansion soutenue, donnant la priorité à l'emploi par rapport aux salaires réels. Nous estimons qu'un schéma réaliste associe une croissance de la production de plus de 3 % l'an à une augmentation de l'emploi de plus de 1 % l'an. Cela laisse une marge d'au plus 2 % pour les salaires réels. Etant donné la présence du glissement salarial, le calcul semble conduire à des accords négociés avec des taux réels à peu près constants. Ce schéma est-il réaliste ? Nous soulevons alors la question controversée du rôle que peuvent jouer sur les salaires les poids comparés des impôts sur le capital et le travail. Nous reconnaissons que la baisse de la part des salaires au cours des années 80 a été accompagnée d'une augmentation de la part des revenus d'intérêt, qui dans de nombreux cas sont peu taxés, notamment en raison de la mobilité des capitaux et d'une concurrence fiscale entre pays. A défaut de déclarations systématiques, un prélèvement à la source uniforme au niveau européen, est le seul moyen de corriger ce déséquilibre en faveur des revenus d'intérêt. La question de savoir si un tel prélèvement est ou non désirable en lui-même de façon permanente est débattue entre spécialistes de la fiscalité. Le débat devrait être élargi pour tenir compte de ce que l'équité dans le traitement fiscal du capital et du travail pourrait contribuer de façon significative à la modération salariale, bien qu'il soit prématuré de considérer les preuves empiriques comme concluantes à cet égard. Nous espérons avoir identifié un ensemble de mesures formant un tout cohérent et avoir défini une initiative ayant la taille du problème qui nous confronte. Ces mesures ont des implications budgétaires conduisant à réallouer quelques pour cent du PIB, donc davantage qu'on l'envisage habituellement. Et elles relèvent de la responsabilité d'un vaste ensemble d'institutions qui ne sont pas engagées dans une coordination systématique de leurs politiques. De sérieux problèmes devraient ainsi être résolus pour une mise en œuvre. Nous en appelons aux responsables politiques pour qu'ils fassent preuve d'audace et de détermination en affrontant ces problèmes. Et nous en appelons aux économistes des milieux académiques pour qu'ils participent activement à la définition et à la promotion d'une initiative européenne ambitieuse. Drèze Jacques H., Malinvaud Edmond, Grauwe, Gevers Louis, Italianer Alexander, Lefebvre Olivier, Marchand Maurice, Sneessens Henri, Steinherr Alfred, Champsaur Paul, Charpin Jean-Michel, Fitoussi Jean-Paul, Laroque Guy. Croissance et emploi : l'ambition d'une initiative européenne. In: Revue de l'OFCE, n° 49, 1994. pp. 247 - 288...|$|E

