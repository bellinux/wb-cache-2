64|134|Public
50|$|An <b>Inference</b> <b>Attack</b> is a {{data mining}} {{technique}} performed by analyzing data {{in order to}} illegitimately gain knowledge about a subject or database. A subject's sensitive information {{can be considered as}} leaked if an adversary can infer its real value with a high confidence. This is an example of breached information security. An <b>Inference</b> <b>attack</b> occurs when a user is able to infer from trivial information more robust information about a database without directly accessing it. The object of Inference attacks is to piece together information at one security level to determine a fact that should be protected at a higher security level.|$|E
50|$|Data {{fields that}} are less identifying, such as Date of Attendance, are usually not pseudonymized. It is {{important}} to realize that this is because too much statistical utility is lost in doing so, not because the data cannot be identified. For example, given prior knowledge of a few attendance dates it is easy to identify someone's data in a pseudonymized dataset by selecting only those people with that pattern of dates. This is an example of an <b>Inference</b> <b>attack.</b>|$|E
30|$|Target 4 The {{algorithm}} {{has a good}} {{ability to}} defense the side-weight <b>inference</b> <b>attack.</b>|$|E
40|$|Trust-based {{onion routing}} enhances {{anonymity}} protection {{by means of}} constructing onion circuits using trust-based routers. However, attackers who have the knowledge of a priori trust distributions are still capable of largely reducing the anonymity protected by trust-based circuits. The root cause is that these attackers have a high probability to guess the users who initiate trust-based circuits through the routers trusted by few other users (i. e., <b>inference</b> <b>attacks).</b> In this paper, we uncover trust degree, an essential feature of routing anonymity that is effective in defeating <b>inference</b> <b>attacks</b> but has been overlooked {{in the design of}} existing trust-based onion routing. We conduct an isolated model based analysis to understand why the trust degree is effective and how {{it can be used to}} resist <b>inference</b> <b>attacks.</b> Our major contributions are three-fold. First, we present a model to exclusively reason about <b>inference</b> <b>attacks</b> in trust-based onion routing. This model isolates the anonymity compromised by <b>inference</b> <b>attacks</b> from other attacks (e. g., correlation-like attacks), and hence derives an exclusive design space that reveals trust degree as the key feature against <b>inference</b> <b>attacks.</b> Second, to show the usefulness of our model, we design a new routing algorithm by taking into account of trust degree. Our algorithm can protect anonymity against <b>inference</b> <b>attacks</b> without sacrificing the capability against attackers' routers. Third, we compare trust-based routing algorithms with and without considering trust degree using real-world social networking datasets. These comparisons present evidence to confirm the effectiveness of trust degree in defeating <b>inference</b> <b>attacks</b> under real-world settings. Department of Computin...|$|R
40|$|A query {{is said to}} {{be secure}} against <b>inference</b> <b>attacks</b> by a user if there exists no {{database}} instance for which the user can infer the result of the query, using only authorized queries to the user. In this paper, first, the security problem against <b>inference</b> <b>attacks</b> on object-oriented databases is formalized. The definition of <b>inference</b> <b>attacks</b> is based on equational logic. Secondly, the security problem is shown to be undecidable, and a decidable sufficient condition for a given query to be secure under a given schema is proposed. The idea of the sufficient condition is to over-estimate <b>inference</b> <b>attacks</b> using over-estimated results of static type inference. The third contribution is to propose subclasses of schemas and queries for which the security problem becomes decidable. Lastly, the decidability of the security problem is shown to be incomparable with the static type inferability, although the tightness of the over-estimation of the <b>inference</b> <b>attacks</b> is affected in a large degree by that of the static type inference...|$|R
40|$|Abstract—The {{values of}} data {{elements}} stored in biomedical databases often draw from biomedical ontologies. Authorization rules {{can be defined}} on these ontologies to control access to sensitive and private data elements in such databases. Authorization rules may be specified by different authorities at different times for various purposes. Since such policy rules can conflict with each other, access to sensitive information may inadvertently be allowed. Another problem in biomedical data protection is <b>inference</b> <b>attacks,</b> in which a user who has legitimate access to some data elements is able to infer information related to other data elements. We propose and evaluate two strategies; one for detecting policy inconsistencies to avoid potential <b>inference</b> <b>attacks</b> {{and the other for}} detecting policy conflicts. Keywords-Authorization policy, Biomedical ontology, <b>Inference</b> <b>attacks,</b> Policy conflicts...|$|R
3000|$|How to {{guarantee}} that the server can defense the replay attack and side-weight <b>inference</b> <b>attack</b> effectively? [...]...|$|E
30|$|One of {{the best}} {{features}} {{of this approach is}} that it overcomes the possibility of probabilistic <b>inference</b> <b>attack</b> easily. The possibility is compared to the other techniques based on t-closeness [22, 23].|$|E
30|$|Replay {{attack and}} side-weight <b>inference</b> <b>attack</b> {{are the most}} common attack methods to {{location}} privacy and also pose the greatest threat on location privacy. Therefore, the defense abilities against these threats are the main design target of our algorithm.|$|E
40|$|International audienceIn {{spectrum}} sharing, incumbents with sensitive parameters require full {{protection of}} their operations. The incumbent's protection includes {{the protection of}} its privacy (e. g., operational frequency) against <b>inference</b> <b>attacks</b> carried out by malicious authorized secondary users. In this paper, we develop an analytical model to analyze {{the vulnerability of the}} incumbent's frequency to <b>inference</b> <b>attacks</b> and validate it by simulation. Specifically, we study random and ordered channel assignment schemes and compare results for both schemes...|$|R
40|$|On-line social networks, such as Facebook, are {{increasingly}} utilized by many users. These networks {{allow people to}} publish details about themselves and connect to their friends. Some of the information revealed inside these networks is private {{and it is possible}} that corporations could use learning algorithms on the released data to predict undisclosed private information. In this paper, we explore how to launch <b>inference</b> <b>attacks</b> using released social networking data to predict undisclosed private information about individuals. We then explore the effectiveness of possible sanitization techniques {{that can be used to}} combat such <b>inference</b> <b>attacks</b> under different scenarios...|$|R
50|$|The {{weakness}} of pseudonymized data to <b>Inference</b> <b>attacks</b> is commonly overlooked. A famous {{example is the}} AOL search data scandal. This example illustrates {{that there is no}} way to universally protect pseudomymized data whilst allowing general analysis of it.|$|R
40|$|As {{the most}} {{competitive}} solution for next-generation network, software-defined network (SDN) and its dominant implementation OpenFlow, are attracting more and more interests. But besides convenience and flexibility, SDN/OpenFlow also introduces new kinds of limitations and security issues. Of these limitations, the most obvious and maybe the most neglected one, is the flow table capacity of SDN/OpenFlow switches. In this paper, we proposed a novel <b>inference</b> <b>attack</b> targeting at SDN/OpenFlow network, which is motivated by the limited flow table capacities of SDN/OpenFlow switches and the following measurable network performance decrease resulting from frequent interactions between data plane and control plane when the flow table is full. To our best knowledge, {{this is the first}} proposed <b>inference</b> <b>attack</b> model of this kind for SDN/OpenFlow. We also implemented an <b>inference</b> <b>attack</b> framework according to our model and examined its efficiency and accuracy. The simulation results demonstrate that our framework can infer the network parameters(flow table capacity and flow table usage) with an accuracy of 80 % or higher. These findings give us a deeper understanding of SDN/OpenFlow limitations and serve as guidelines to future improvements of SDN/OpenFlow...|$|E
40|$|Social Networking System (SNS) like Facebook and Twitter {{have gained}} more {{popularity}} {{in this new}} era. It allows millions of individuals to create online profiles and share their personal information with vast networks of friend’s. SNS allows third party extensions to access the users’ information through Application Programming Interface (API). Since millions of users are using these sites {{it will lead to}} privacy problems and leakage of private information. This leakage happens without the knowledge of user, which leads to security problems like identity theft and phishing attack. Unknown user taking the information without our knowledge is called <b>inference</b> <b>attack.</b> This paper uses a permission based protection mechanism which limits the direct access of user data. Once an extension is certified by the user to access data from users ’ profile, then there is no more control on how it uses the data. Third party application can be built on trusted or un-trusted server. If it is an un-trusted server it will lead to <b>inference</b> <b>attack</b> and malicious user may use the information for unintended purposes and our data will be at risk. The main objective of this project is to enable the security access control scheme against <b>inference</b> <b>attack...</b>|$|E
40|$|Abstract: An <b>Inference</b> <b>attack</b> {{occurs when}} a user is able to infer some {{information}} about a database without directly accessing them. Data mining techniques help to discover unknown information from a database using known information. This paper discusses how Association Rule mining {{can be used to}} detect unauthorized inferencing from the database...|$|E
40|$|Abstract. The {{problem of}} privacy-preserving record linkage {{is to find}} the {{intersection}} of records from two parties, while not revealing any private records to each other. Recently, group linkage has been introduced to measure the similarity of groups of records [19]. When we extend the traditional privacy-preserving record linkage methods to group linkage measurement, group membership privacy becomes vulnerable – record identity could be discovered from unlinked groups. In this paper, we introduce threshold privacy-preserving group linkage (TPPGL) schemes, in which both parties only learn whether or not the groups are linked. Therefore, our approach is secure under group membership <b>inference</b> <b>attacks.</b> In experiments, we show that using the proposed TPPGL schemes, group membership privacy is well protected against <b>inference</b> <b>attacks</b> with a reasonable overhead...|$|R
30|$|Finally, the {{security}} of a system depends on the correct use of each cipher, considering the characteristics of the data stored in each field. Keeping all data encrypted, it is possible to avoid <b>inference</b> <b>attacks</b> that could cause a big damage to applications using lower computational effort.|$|R
40|$|Abstract—We study <b>inference</b> <b>attacks</b> {{that can}} be {{launched}} via the extension API of Facebook. We explain the threat of these attacks through a reduction to authentication attacks, devise a taxonomy for such attacks, and propose a risk metric to help subscribers of third-party applications refine their privacy expectations. I...|$|R
40|$|Abstract—In database-driven {{cognitive}} radio networks, loca-tion <b>inference</b> <b>attack</b> may cause location privacy leakage of sec-ondary users. Malicious entities could geo-locate secondary users with spectrum utilization information. The efficiency of existing solution largely {{depends on the}} stability of available spectrum. Most solutions are not effective because of the unpredictable return of primary users. To prevent location <b>inference</b> <b>attack,</b> we propose an Agent-based Channel Selection(ACS) scheme in this paper. In this scheme, the database allocates spectrum with self-coexistence mechanism to avoid interference, and each base station registers spectrum information as an agent in the database instead of secondary users (SUs). Thus, the proposed scheme can decrease the probability of being geo-located for SUs effectively. According to the simulation, we analyze the relationship among the factors that impact the probability and {{the efficiency of the}} proposed scheme. Index Terms—Cognitive Radio Networks, spectrum allocation, location privacy, database...|$|E
40|$|Abstract—Data {{privacy in}} {{genome-wide}} association studies (GWAS) {{is a critical}} yet under-exploited research area. In this paper, we first provide a method to construct a two-layered bayesian network explicitly revealing the conditional dependency between SNPs and traits, from the public GWAS catalog. Then we develop efficient algorithms for two attacks: identity <b>inference</b> <b>attack</b> and trait <b>inference</b> <b>attack</b> based on reasoning with the dependency relationship captured in the constructed bayesian network. Different from previously proposed attacks, the possible target of our attacks may be any common people, not limited to GWAS participants. The empirical evaluations show that unprotected statistics released from GWAS can be exploited by attackers to identify individual or derive private information. Thus we show that mining GWAS statistics threatens the privacy of a much wider population and privacy protection mechanisms should be employed. Keywords—Genome-wide association study; privacy; Bayesian network; I...|$|E
30|$|Public {{fields are}} not subject to a {{disclosure}} attack since their contents are already public. However, these fields could provide useful information to an attacker, which could correlate the encrypted tuple contents with a public database and execute an <b>inference</b> <b>attack.</b> Comparable fields also could be used for these attacks since their contents could be inferred.|$|E
40|$|In {{this paper}} we examine {{undesired}} <b>inference</b> <b>attacks</b> from distributed public XML documents. An undesired inference is {{a chain of}} reasoning that leads to protected data of an organization using only publicly available information. We propose a framework, the Ontology guided XML Security Engine (Oxsegin), and algorithms to detect and prevent undesired <b>inference</b> <b>attacks.</b> Oxsegin uses the Correlated Inference Procedure to detect correlated information {{that may lead to}} undesired disclosure. The system operates on the DTD’s of XML documents, and uses an ontological class-hierarchy to identify tags that may contribute to security violations. A security violation pointer is assigned to a set of tags that may contribute to a possible security violation. The likelihood of a detected security violation is measured by a confidence level coefficient attached to the security violation pointers...|$|R
40|$|In {{wireless}} sensor networks, preserving location privacy under successive <b>inference</b> <b>attacks</b> {{is extremely}} critical. Although {{this problem is}} NP-complete in general cases, we propose a dynamic programming based algorithm and prove it is optimal in special cases where the correlation only exists between p immediate adjacent observations. Department of Computin...|$|R
40|$|<b>Inference</b> <b>attacks</b> {{mean that}} a user infers (or tries to infer) {{the result of an}} {{unauthorized}} method execution using only authorized methods to the user. We say that a method ¥ is secure against <b>inference</b> <b>attacks</b> by a user ¦ if there exists no database instance for which ¦ can infer the result of ¥. It is important for database administrators to know which methods are secure and which ones are not. When an administrator finds that a method which retrieves top secret information is not secure against <b>inference</b> <b>attacks</b> by ¦, the administrator can prevent ¦ from attacking the method by changing the authorization for ¦. This paper formalizes the security problem (i. e., to determine whether a given method is secure or not) for method schemas, and presents the following results. First, it is shown that the security problem is undecidable. Next, a decidable sufficient condition for a given method to be secure is proposed. Furthermore, it is shown that the sufficient condition is also a necessary one if a given schema is monadic (i. e., every method has exactly one parameter). The time complexity to decide the condition is also evaluated. For a monadic schema, the condition is decidable (and therefore, the security problem is solvable) in polynomial time {{of the size of the}} schema. ...|$|R
30|$|Reduce the leakage of index {{construction}} in the database: Our proposal leaks both sides of index ciphertexts to enable the index construction. At this moment, an eavesdropper monitoring queries would learn all information required to freely compare the exposed ciphertexts. As discussed in this document, such capability must be restricted, under risk of enabling an <b>inference</b> <b>attack.</b>|$|E
40|$|The Web is {{the largest}} {{repository}} of information. Personal information is usually scattered on various pages of different websites. Search engines have {{made it easier to}} find personal information. An attacker may collect a user’s scattered information together via search engines, and infer some privacy information. We call this kind of privacy attack Privacy <b>Inference</b> <b>Attack</b> via Search Engines. In this paper, we propose a user-side automatic detection service for detecting the privacy leakage before publishing personal information. In the user-side service, we construct a User Information Correlation (UICA) graph to model the association between user information returned by search engines. We map the privacy <b>inference</b> <b>attack</b> into a decision problem of searching a privacy inferring path with the maximal probability in the UICA graph. We propose a Privacy Leakage Detection Probability (PLD-Probability) algorithm to find the privacy inferring path. Extensive experiments indicate that the algorithm is reasonable and effective...|$|E
30|$|In {{this paper}} [20], an anonymization {{algorithm}} established on clustering and resilient to similarity attack and probabilistic <b>inference</b> <b>attack</b> is proposed. The anonymized data are dispersed on hadoop distributed file system. The method attains a better trade-off between privacy and utility. In this work, the data utility {{is measured in}} terms of accuracy and F measure with respect to different classifiers.|$|E
40|$|Abstract—The {{values of}} data {{elements}} stored in biomedical databases often draw from biomedical ontologies. Authorization rules {{can be defined}} on these ontologies to control access to sensitive and private data elements in such databases. Authorization rules may be specified by different authorities at different times for various purposes, and as such policy rules may conflict with each other, inadvertently allowing access to sensitive information. Detecting policy conflicts is nontrivial because it involves identification of applicable rules and detecting conflicts among them dynamically during execution of data access requests. It also requires dynamically verifying conformance with required policies and logging relevant information about decisions for audit. Another problem in biomedical data protection is <b>inference</b> <b>attacks,</b> in which a user who has legitimate access to some data elements is able to infer information related to other data elements. This type of inadvertent data disclosure should be prevented by ensuring policy consistency; that is, data elements {{which can lead to}} inference about other data elements should be protected by the same level of authorization policies as the other data elements. We propose two strategies; one for detecting policy consistencies to avoid potential <b>inference</b> <b>attacks</b> and the other for detecting policy conflicts. We have implemented these algorithms in Java language and evaluated their execution times experimentally. Keywords-Authorization policy, Biomedical ontology, <b>Inference</b> <b>attacks,</b> Policy conflicts...|$|R
40|$|International audienceA geolocated system {{generally}} {{belongs to}} an individual and as such knowing its location reveals the location of its owner, which is a direct threat against his privacy. To protect the privacy of users, a sanitization process, which adds uncertainty to the data and removes some sensible information, can be performed but {{at the cost of}} a decrease of utility due to the quality degradation of the data. In this paper, we introduce GEPETO (for GEoPrivacy-Enhancing TOolkit), a flexible open source software which can be used to visualize, sanitize, perform <b>inference</b> <b>attacks</b> and measure the utility of a particular geolocated dataset. The main objective of GEPETO is to enable a user to design, tune, experiment and evaluate various sanitization algorithms and <b>inference</b> <b>attacks</b> as well as visualizing the following results and evaluating the resulting trade-off between privacy and utility...|$|R
40|$|Covert timing {{channels}} in real-time systems allow adversaries {{to not only}} exfiltrate application secrets but also to mount timing <b>inference</b> based <b>attacks.</b> Much effort has been put into improving real-time system predictability with the additional benefit of reducing the former class of confidentiality attacks. However, the more predictable the system behaves, the easier timing <b>inference</b> based <b>attacks</b> become. Time-triggered scheduling is particularly vulnerable to these types of attacks due to offline constructed tables that are scheduled with clock synchronization and OS-timer predictability. In this paper, we obfuscate timetriggered scheduling to complicate timing <b>inference</b> based <b>attacks</b> while maintaining strong protection against exfiltration attacks...|$|R
40|$|Abstract—With {{the advent}} of GPS-equipped devices, a massive amount of {{location}} data is being collected, raising {{the issue of the}} privacy risks incurred by the individuals whose movements are recorded. In this work, we focus on a specific <b>inference</b> <b>attack</b> called the de-anonymization attack, by which an adversary tries to infer the identity of a particular individual behind a set of mobility traces. More specifically, we propose an implementation of this attack based on a mobility model called Mobility Markov Chain (MMC). A MMC is built out from the mobility traces observed during the training phase and is used to perform the attack during the testing phase. We design two distance metrics quantifying the closeness between two MMCs and combine these distances to build de-anonymizers that can re-identify users in an anonymized geolocated dataset. Experiments conducted on real datasets demonstrate that the attack is both accurate and resilient to sanitization mechanisms such as downsampling. Keywords-Privacy, geolocation, <b>inference</b> <b>attack,</b> deanonymization. I...|$|E
40|$|Abstract: At present most privacy {{preserving}} algorithms {{based on}} l-diversity model are limited only to static data release. It is low efficiency and vulnerable to <b>inference</b> <b>attack</b> if these anonymous algorithms are directly applied to dynamic data publishing. To address this issue, this paper analyzes various inference channels that possibly exist between multiple anonymized datasets and discusses {{how to avoid}} such inferences and provides an effective approach to securely anonymize a dynamic dataset based on incremental clustering: incremental l-diversity algorithm. Theory analysis and experiment {{results show that the}} proposed method is effective and efficient...|$|E
40|$|The {{security}} of smartphone GUI frameworks remains an important yet under-scrutinized topic. In this pa-per, {{we report that}} on the Android system (and likely other OSes), a weaker form of GUI confidentiality can be breached {{in the form of}} UI state (not the pixels) by a background app without requiring any permissions. Our finding leads to a class of attacks which we name UI state <b>inference</b> <b>attack.</b> The underlying problem is that popular GUI frameworks by design can potentially reveal every UI state change through a newly-discovered public side channel — shared memory. In our evaluation, we show that for 6 out of 7 popular Android apps, the UI state in-ference accuracies are 80 – 90 % for the first candidate UI states, and over 93 % for the top 3 candidates. Even though the UI state does not reveal the exact pix-els, we show that it can serve as a powerful building block to enable more serious attacks. To demonstrate this, we design and fully implement several new attacks based on the UI state <b>inference</b> <b>attack,</b> including hijack-ing the UI state to steal sensitive user input (e. g., login credentials) and obtain sensitive camera images shot by the user (e. g., personal check photos for banking apps). We also discuss non-trivial challenges in eliminating the identified side channel, and suggest more secure alterna-tive system designs. ...|$|E
30|$|Interestingly, {{the sensor}} data {{measured}} by smartwatches have been exploited recently to conduct keystroke <b>inference</b> <b>attacks</b> (Liu et al. 2015; Maiti et al. 2016; Wang et al. 2016; Wang et al. 2015). While a user types on a QWERTY keyboard or numeric keypad, he/she moves his/her hand {{to reach the}} keys and this causes distinct motions of the user’s wrist. The motion sensor data collected from the user’s smartwatch {{can be used to}} track the user’s wrist motions and thus infer the user’s inputs such as PINs and passwords. In common, previous studies on keystroke <b>inference</b> <b>attacks</b> show that the motion sensors of smartwatches can be exploited to compromise user security and privacy. From another point of view, the motion sensor data collected from smartwatches contain unique features of users’ typing behaviors, and can thus be exploited to enhance the security of password/PIN-based user authentication.|$|R
30|$|Some sensors, like {{accelerometer}} and gyroscope, {{seem less}} sensitive {{compared to other}} device features like GPS location, device ID, and network access. Mainstream mobile platforms, like Android, set no restrictions on accessing these innocuous sensors. However, when a user uses the device in regular patterns, things become more complicated. For example, when the user touches the screen to enter her screen lock password, the accelerometer may reveal regular patterns [1]. Recent studies [1 – 10] have shown that, by utilizing these innocuous sensors, attackers are able to infer users’ behavior patterns and launch severe privacy <b>inference</b> <b>attacks,</b> such as keylogging [1, 2], inferring user activity [4], profiling [6], and tracking [9]. For example, [4] demonstrates the feasibility for a malicious app to infer the smartphone user’s transportation mode, i.e., whether the user is stationary, walking, running, biking, or in motorized transport, by utilizing the onboard accelerometer. Indeed, privacy <b>inference</b> <b>attacks</b> based on innocuous sensors is an emerging and severe threat on smart devices.|$|R
30|$|Thus, the {{disclosure}} of location information can be dependent on previous location events or accepted pull requests. A usual scenario is {{to limit the number}} of location requests or, alternatively, the request frequency or the cardinality of the set of unique results provided, made by the same person, to a given target. This avoids tracking (as the scenario described previously) among other types of <b>inference</b> <b>attacks.</b>|$|R
