246|10000|Public
5000|$|The Bioinformatics Unit grants {{researchers}} {{services of}} consultation, experiment planning, <b>data</b> <b>processing,</b> <b>software</b> and database development, bioinformatics training, {{and access to}} high-performance computing resources.|$|E
50|$|The company {{develops}} {{and delivers}} report automation solutions and services. The company {{was established in}} 1993 as ISPC {{by one of the}} original founders of Quantime- a specialist <b>Data</b> <b>Processing</b> <b>software.</b> Following a management buyout in 1999 ISPC was rebranded as E-Tabs.|$|E
50|$|Formally, a {{bottleneck}} lies on a system's {{critical path}} {{and provides the}} lowest throughput. Bottlenecks are usually avoided by system designers, also {{a great amount of}} effort is directed at locating and tuning them. Bottleneck may be for example a processor, a communication link, a <b>data</b> <b>processing</b> <b>software,</b> etc.|$|E
30|$|For <b>data</b> <b>processing,</b> the <b>software</b> LabSolutions HPLC-MS/MS (Shimadzu, Kyoto, Japan) was used. Other {{parameters}} were tuned automatically.|$|R
50|$|Contact Telecom is a {{telecommunications}} and IT services company that develops <b>data</b> <b>processing</b> and <b>software</b> {{services for the}} telecommunications industry, established in 1998.|$|R
30|$|The <b>data</b> {{acquisition}} and <b>processing</b> <b>software</b> was SurfaceLab 6.2 (ION-TOF GmbH, Münster, Germany).|$|R
50|$|SBGrid also {{maintains}} the SBGridTV YouTube channel, which houses {{a collection of}} <b>data</b> <b>processing</b> <b>software</b> tutorials, and organizes structural biology workshops, including the 2014 International Workshop on Data Processing in Crystallography. Seventeen workshop lectures are also posted on the YouTube channel. Members also benefit from access to SBGrid-supported high performance computing (HPC) resources and training opportunities.|$|E
50|$|Cwm (pronounced koom) is a {{general-purpose}} <b>data</b> <b>processing</b> <b>software</b> for {{the semantic}} web, similar to sed or awk for text files or XSLT for XML. It is a forward chaining semantic reasoner {{that can be}} used for querying, checking, transforming and filtering information. Its core language is RDF, extended to include rules, it can use RDF/XML or RDF/N3 (see Notation3 Primer) serializations.|$|E
5000|$|The statute expansively defines [...] "public record" [...] {{to include}} all documents, papers, letters, maps, books, tapes, photographs, films, sound recordings, <b>data</b> <b>processing</b> <b>software,</b> or other material, {{regardless}} of physical form, characteristics or means of transmission, made or received pursuant to law or ordinance or {{in connection with the}} transaction of official business by any agency. Fla. Stat. sec. 119.011(1) (1995) ...|$|E
50|$|Electronic <b>Data</b> <b>Processing</b> is a <b>software</b> {{solutions}} corporation {{listed on}} the London Stock Exchange.|$|R
5000|$|Big data is a {{term for}} data sets that are so large or complex that {{traditional}} <b>data</b> <b>processing</b> application <b>software</b> is inadequate to deal with them. Big data challenges include capturing data, data storage, data analysis, search, sharing, transfer, visualization, querying, updating and information privacy.|$|R
40|$|The year 2000 {{is rapidly}} approaching, {{and there is}} a good chance that {{computer}} systems that utilize two digit year dates will experience problems in retrieval of date information. The ISA Thermoluminescent Dosimetry <b>Data</b> <b>Processing</b> (TL-DP) <b>software</b> and computer system has been reviewed for Year 2000 compliance issues...|$|R
50|$|Nanning Huishi UAVs are Chinese UAVs {{developed}} by Nanning Hui-Shi Science and Technology Co., Ltd. (Nanning Huishi, 南宁慧视科技有限责任公司). Originally a developer of UAV subsystems such as aerial survey payload, <b>data</b> <b>processing</b> <b>software,</b> and other software such as {{geographic information system}} utilizing results obtained by aerial survey, Huishi eventually ventured to the final product market of UAV by developing entire UAV system of its own.|$|E
5000|$|Under an {{agreement}} between CNES and [...] EUMETSAT (European Organisation for the Exploitation of Meteorological Satellites), the former was responsible for developing the instrument and <b>data</b> <b>processing</b> <b>software.</b> The latter is responsible for archiving and distributing the data to the users, {{as well as for}} operating IASI itself. [...] Currently, Alcatel Space is the prime contractor of the project and oversees the production of the recurring models.|$|E
50|$|The Geodesy and Geodynamics Lab of ETH Zurich {{holds the}} {{scientific}} leadership and {{is responsible for}} the payload <b>data</b> <b>processing</b> <b>software.</b> EPFL and the Swiss Space Center (SSC) are in charge of project management and the realization of the satellite bus. Lucerne University of Applied Sciences and Arts develops the payload hardware and the ground station. RF and antenna-design is provided by Hochschule für Technik Rapperswil. Further project partners are HES-SO (academic partner), u-blox (industrial partner), RUAG Space (industrial partner) and Saphyrion (industrial partner).|$|E
30|$|Ling Yuan is {{currently}} {{an associate professor}} in the School of Computer Science and Technology, HUST, Wuhan, P.R. China. She received her Ph.D. degree in the Department of Computer Science from National University of Singapore in 2008. She received her B.S degree and M.S. degree in computer science from Wuhan University, Wuhan, China, in 1997 and 2002, respectively. Her research interest includes <b>data</b> <b>processing</b> and <b>software</b> engineering.|$|R
40|$|ASCITOVG {{program for}} IBM PC-series {{computers}} creates files in binary format from columns of numbers in American National Standard Code for Information Interchange (ASCII) format. Files suitable for DEC PDP- 11 / 73 computer under Micro-RSX operating system running the VGS- 5000 Enhanced <b>Data</b> <b>Processing</b> (EDP) <b>software</b> package which analyzes data with color graphics display, speeding up analysis compared with batch job processing. Written in FORTRAN...|$|R
40|$|The {{results of}} an International Conference held on May 18 - 21, 1982, at Michigan State University are presented. The main {{objective}} was to identify critical issues related to <b>data</b> <b>processing,</b> hardware, <b>software,</b> and institutionalization and training for research for agricultural and rural development. food security, food policy, microcomputers, programmable calculators, Research and Development/Tech Change/Emerging Technologies, Downloads December 2008 -June 2009 : 30, Q 18,...|$|R
50|$|Originally {{created during}} a {{collaboration}} between Telecom ParisTech and the R&D division of EDF, the CloudCompare project began in 2003 with the PhD of Daniel Girardeau-Montaut on Change detection on 3D geometric data. At that time, its main purpose was to quickly detect changes in 3D high density point clouds acquired with laser scanners in industrial facilities (such as power plants) or building sites. Afterwards it evolved towards a more general and advanced 3D <b>data</b> <b>processing</b> <b>software.</b> It is now an independent open source project and a free software.|$|E
50|$|Systematics {{was founded}} in 1968 by University of Arkansas {{graduate}} Walter Smiley, who learned of the high software costs and other difficulties faced by small banks in trying to use <b>data</b> <b>processing</b> <b>software</b> from his experiences working with IBM and in the banking industry. Smiley recognized a niche that could be filled for medium-sized banks in this space, and sought funding {{to start his own}} company. Through Jon Jacoby, Smiley was introduced to the Stephens family, who agreed to invest $400,000 in Walter and Systematics in return for 80% equity stake.|$|E
50|$|CHS has {{migrated}} from single-beam sonar {{to becoming a}} major user of multibeam echo sounder sonar systems coupled with GPS to achieve improved survey accuracies. CHS {{was also one of}} the first organizations in the world to develop airborne LiDAR technology, with the LARSEN-500 sensor being used for remote Arctic surveys. Survey <b>data</b> <b>processing</b> <b>software</b> provided by companies such as CARIS and Helical Systems, as well as the development of Oracle Spatial database storage, are spin-offs from research developments at CHS, and are now used throughout the world by other Hydrographic Offices and in the geo-spatial technology industry. CHS demonstrates international leadership in Crowd-Source Bathymetry, Satellite-Derived Bathymetry and Marine Spatial Data Infrastructurce.|$|E
40|$|Abstract. Software {{agents are}} {{often seen as}} “intelligent, {{autonomous}} software components. ” Interestingly, the question of efficient implemen-tation of “intelligence ” remains open. In this paper we discuss, in some details, the process of implementing software agents with “brains. ” In {{the context of an}} agent system supporting decisions of glider pilots, we consider native implementation of “intelligent ” behaviors, rule based en-gines, and semantic <b>data</b> <b>processing.</b> Based on the analysis of the state-of-the-art in these areas, we present a novel approach combining rule based engines, semantic <b>data</b> <b>processing</b> and <b>software</b> agents. ...|$|R
40|$|The {{objective}} of diploma thesis is composition of operational {{geographic information system}} of Moravian Wine Trails. This paper includes description of data collection process, <b>data</b> <b>processing</b> in ArcGIS <b>software</b> and map server Marushka. Data presentation was performed by demonstration of most popular export opportunities...|$|R
40|$|Mariner 9 TV {{data from}} the 1971 - 1972 {{encounter}} with Mars, which contain good synoptic coverage of of the planet {{as well as the}} highest-resolution images thus far obtained for the south polar region, can lead to more accurate photometric analysis if subjected to improved processing methods. While calibration errors are rather greater than those of the Viking Orbiter cameras, both calibration <b>data</b> and <b>processing</b> <b>software</b> applicable to an improvement program have become available through the USGS's Planetary Image Cartography System...|$|R
5000|$|Science data {{telemetry}} {{collected during}} mission operations at LASP is sent for processing to the Kepler Data Management Center (DMC) {{which is located}} at the Space Telescope Science Institute on the campus of Johns Hopkins University in Baltimore, Maryland. The science data telemetry is decoded and processed into uncalibrated FITS-format science data products by the DMC, which are then passed along to the Science Operations Center (SOC) at NASA Ames Research Center, for calibration and final processing. The SOC at NASA Ames Research Center (ARC) develops and operates the tools needed to process scientific data for use by the Kepler Science Office (SO). Accordingly, the SOC develops the pipeline <b>data</b> <b>processing</b> <b>software</b> based on scientific algorithms developed by the SO. During operations, the SOC: ...|$|E
40|$|Abstract. Radar <b>data</b> <b>processing</b> <b>software</b> is {{a complex}} system, which has been {{implemented}} with mixed language programming using Visual Studio. Net and Visual C++ 6. 0. COM-based software architecture for radar data processing system is proposed in this paper. It provides modular design framework, and integrates modules developed with different programming language and ready-made modules. Firstly, introduce COM technology in brief, then design radar <b>data</b> <b>processing</b> <b>software</b> system framework, finally show the programming examples to explain how to define and refer the COM interfaces. The results show that using COM-based modular mixed language programming is an effective method to realize the radar <b>data</b> <b>processing</b> <b>software</b> system...|$|E
40|$|There are {{two types}} of GPS <b>data</b> <b>processing</b> <b>software,</b> first is {{scientific}} GPS <b>data</b> <b>processing</b> <b>software</b> and the other is commercial GPS <b>data</b> <b>processing</b> <b>software.</b> It is usually believed that scientific GPS <b>data</b> <b>processing</b> <b>software</b> is better than commercial software, in terms of accuracy and precision of coordinate results especially in large areas. However, continual improvements in commercial GPS <b>data</b> <b>processing</b> <b>software</b> may enable people to achieve the same result as the scientific software. This paper describes the performance of the GPS commercial software in processing GPS baseline data in large areas. For that instance, Trimble Geomatics Office, one of GPS commercial software is used to reprocess STATEFIX GPS data. STATEFIX is GPS geodetic network in Western Australia, which is processed by using in-house software developed by Geodesy Group Laboratory, Curtin University. The coordinate results will be compared with STATEFIX coordinates. The results found that the quality indicator of GPS data processing such as RMS and precision can achieve centimeter level. The mean RMS of GPS baseline processing is 0. 0117 m for 205 km mean baseline length. Point absolute error is around 1. 5 cm in horizontal and 4. 3 cm in vertical. However, the differences between coordinate results and STATEFIX coordinates are quite big, around 3 cm in horizontal and 15 cm in vertical...|$|E
40|$|IPEX is a 1 u Cubesat {{sponsored}} by NASA Earth Science Technology Office (ESTO), the goals or which are: (1) Flight validate high performance flight computing, (2) Flight validate onboard instrument <b>data</b> <b>processing</b> product generation <b>software,</b> (3) flight validate autonomous operations for instrument processing, (4) enhance NASA outreach and university ties...|$|R
50|$|Peter Tertzakian {{began his}} career as a {{geophysicist}} with the Chevron Corporation in 1982 where he spent eight years working in field operations, seismic <b>data</b> <b>processing</b> and geophysical <b>software</b> development. He moved from the oil & gas to the financial sector in 1990 and has since been analyzing technology and energy-related businesses.|$|R
40|$|Enhanced Publication Information Systems (EPISs) are {{information}} systems devised {{for the management}} of enhanced publications (EP), i. e. digital publications enriched with (links to) other research outcomes such as <b>data,</b> <b>processing</b> workflows, <b>software.</b> Today, EPISs are typically realised with a "from scratch" approach that entails non-negligible implementation and maintenance costs. This work argues for a more systemic approach to narrow those costs and presents the notion of Enhanced Publication Management Systems, software frameworks that support the realisation of EPISs by providing developers with EP-oriented tools and functionalities...|$|R
30|$|Like {{the control}} software, the <b>data</b> <b>processing</b> <b>software</b> is custom written and forms {{part of the}} esaProject code (© 2006 - 2014 EVA Surface Analysis) [28].|$|E
3000|$|... max. The <b>data</b> <b>processing</b> <b>software</b> {{automatically}} subtracts 2 π {{from these}} values to shift them inside the “allowed” phase range {{so that the}} adjusted phase values become close to Ψ [...]...|$|E
40|$|LIDAR data {{filtering}} and classification are {{the most}} important steps of the LIDAR data processing, which requires efficient <b>data</b> <b>processing</b> <b>software.</b> This paper introduces a new LIDAR <b>data</b> <b>processing</b> <b>software</b> named TopLidar. TopLidar was developed to be used on MicroStation. It makes full use of the excellent secondary development capability and efficient large amount of data management, interactive editing and dynamic 3 D display of MicroStation system. In data classification, the software provides extended mathematical morphology algorithm and robust estimation algorithm and has some adaptive capability. Our testing shows that the software could be efficiently used in different terrain condition...|$|E
40|$|Astronauts {{on board}} the International Space Station (ISS) have taken {{thousands}} of high-resolution colour photographs of the aurora, which could be made useful for research if their pointing information could be reconstructed. We describe a method to do this using the star field in the images, and how the reconstructed pointing can then be used to georeference the images to a similar level of accuracy in existing all-sky camera images. We have used this method to make georeferenced auroral images taken from the ISS available and here describe the resulting <b>data</b> set, <b>processing</b> <b>software,</b> and how to access them...|$|R
40|$|Imaging {{techniques}} have been revolutionized by advancements in both microscope instrumentation and <b>data</b> collection <b>processing</b> <b>software.</b> Immunologists and microbiologists now {{have access to}} a large panel of powerful technologies that are characterized by different spatial and time resolutions. In this review, we discuss recent studies in which emerging imaging technologies have been used to decipher the complexity of the interactions between pathogens and their mammalian hosts. By focusing on two very different pathogens, Plasmodium and Salmonella, we emphasize the critical role of imaging studies in the understanding of the host's immune system response to a pathogen...|$|R
30|$|In {{the aspect}} of <b>data</b> <b>processing,</b> <b>data</b> {{analysis}} <b>software</b> system was used to analysis data. The noise analysis was removed using undecimated discrete wavelet transform (UDWT) analysis (Aiazzi et al. 2002; Fowler 2005). The model was established by SVM method. SVM were used to align and integrate hundreds of mass data points from large numbers of samples, and {{could be used to}} process many samples in parallel. This approach is sensitive and fast, these were features essential for clinical use. SVM exhibited many unique advantages in solving small sample, nonlinear and high dimensional pattern recognition problems and achieve the statistical theory of structural risk minimization principle. The application of these techniques obtained serum protein diagnostic model with high credibility.|$|R
