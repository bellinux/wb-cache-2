1362|763|Public
5|$|It {{raised an}} {{additional}} $18 million in funding in September 2015. It also {{began working with}} Cisco to jointly develop the Cisco <b>Data</b> <b>Preparation</b> suite of software and services.|$|E
5|$|Paxata is {{a privately}} owned {{software}} company headquartered in Redwood City, California. It develops self-service <b>data</b> <b>preparation</b> software that gets data ready for data analytics software. Paxata's software {{is intended for}} business analysts, as opposed to technical staff. It is used to combine data from different sources, then check it for data quality issues, such as duplicates and outliers. Algorithms and machine learning automate certain aspects of <b>data</b> <b>preparation</b> and users work with the software through a user-interface similar to Excel spreadsheets.|$|E
25|$|Tapeout and mask generation: {{the design}} data is turned into photomasks in mask <b>data</b> <b>preparation.</b>|$|E
5000|$|... {{reflects}} {{the complexity of}} the deterministic structure in the system. However, this entropy depends sensitively on the bin number and, thus, may differ for different realisations of the same process, as well as for different <b>data</b> <b>preparations.</b>|$|R
40|$|This {{research}} {{explores the}} effects of various training settings on a Polish to English Statistical Machine Translation system for spoken language. Various elements of the TED, Europarl, and OPUS parallel text corpora were {{used as the basis}} for training of language models, for development, tuning and testing of the translation system. The BLEU, NIST, METEOR and TER metrics were used to evaluate {{the effects of}} the <b>data</b> <b>preparations</b> on the translation results. Comment: arXiv admin note: substantial text overlap with arXiv: 1509. 09097, arXiv: 1509. 08909, arXiv: 1509. 0887...|$|R
30|$|MK is {{responsible}} for the <b>data</b> collection, <b>preparation</b> of manuscript, text corrections, coordinating work; SzJ {{is responsible}} for the initial <b>preparation,</b> <b>data</b> collection, text corrections; KU {{is responsible for}} the proposal and performance of statistical analysis and contribution to interpretation of results; JU {{is responsible for the}} description and performance of statistical analysis and correction of manuscript; PP is responsible for the data collection, text corrections. All authors read and approved the final manuscript.|$|R
25|$|Typical {{duties of}} {{physicists}} with master's and doctoral degrees working in their domain involves research, observation and analysis, <b>data</b> <b>preparation,</b> instrumentation, design {{and development of}} industrial or medical equipment, computing and software development, etc.|$|E
25|$|Data mining {{requires}} <b>data</b> <b>preparation</b> {{which can}} uncover information or patterns which may compromise confidentiality and privacy obligations. A common way {{for this to}} occur is through data aggregation. Data aggregation involves combining data together (possibly from various sources) {{in a way that}} facilitates analysis (but that also might make identification of private, individual-level data deducible or otherwise apparent). This is not data mining per se, but a result of the preparation of data before – and for the purposes of – the analysis. The threat to an individual's privacy comes into play when the data, once compiled, cause the data miner, or anyone who has access to the newly compiled data set, to be able to identify specific individuals, especially when the data were originally anonymous.|$|E
25|$|The {{actual data}} mining task is the {{semi-automatic}} or automatic analysis of {{large quantities of}} data to extract previously unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection), and dependencies (association rule mining, sequential pattern mining). This usually involves using database techniques such as spatial indices. These patterns can then {{be seen as a}} kind of summary of the input data, and may be used in further analysis or, for example, in machine learning and predictive analytics. For example, the data mining step might identify multiple groups in the data, which can then be used to obtain more accurate prediction results by a decision support system. Neither the data collection, <b>data</b> <b>preparation,</b> nor result interpretation and reporting is part of the data mining step, but do belong to the overall KDD process as additional steps.|$|E
3000|$|Details on <b>data</b> format, <b>preparation</b> etc. are {{provided}} in Section  1 of Additional file 1. Data {{used in this study}} is provided as [...].csv files for download (see Additional file 2).|$|R
40|$|This paper {{reports on}} the {{processing}} of time series of MODIS NDVI/EVI and LST satellite data in a Geographical Information System (GIS). The required <b>data</b> <b>preparations</b> for the integration of MODIS data in GIS is described with focus on the reprojection from MODIS/Sinusoidal projection to national coordinate systems. To remove low quality pixels, the MODIS quality maps are utilized. We explain subsequent filtering of Land Surface Temperature maps with an outlier detector to eliminate originally undetected cloud pixels. Further analysis of time series is briefly discussed as well as related landscape epidemiological applications {{in the field of}} tick-borne diseases. 1...|$|R
30|$|KI {{performed}} the study design, <b>data</b> collection, manuscript <b>preparation,</b> and literature search. SH and TY {{performed the}} patient care, study design, <b>data</b> collection, manuscript <b>preparation,</b> and literature search. TS, HS, and HK performed the patient care and data collection. NT and ET collected the data. AT critically revised the manuscript. All authors {{read and approved}} the final manuscript.|$|R
500|$|Paxata {{refers to}} its suite of {{cloud-based}} data quality, integration, enrichment and governance products as [...] "Adaptive Data Preparation." [...] The software {{is intended for}} business analysts, who need to combine data {{from a variety of}} sources, then check the data for duplicates, empty fields, outliers, trends and integrity issues before conducting analysis or visualization in a third-party software tool. It uses algorithms and machine-learning to automate certain aspects of <b>data</b> <b>preparation.</b> For example, it may automatically detect records belonging to the same person or address, even if the information is formatted differently in each record in different data sets.|$|E
2500|$|On January 10, 2000 Numerical Technologies {{acquired}} Transcription Enterprises, Inc. primarily {{known for}} its CATS software for mask <b>data</b> <b>preparation,</b> ...|$|E
50|$|Mica {{was listed}} in the Gartner Market Guide for Self-Service <b>Data</b> <b>Preparation</b> (August 25, 2016), showing very robust {{capabilities}} among products from over 36 products in self-service <b>data</b> <b>preparation.</b>|$|E
5000|$|... high {{demands for}} input <b>data</b> and the <b>preparation</b> of {{assumptions}} {{for the model}} ...|$|R
5000|$|To {{develop a}} {{feedback}} loop to share teacher performance <b>data</b> with teacher <b>preparation</b> programs.|$|R
40|$|This manual {{explains}} {{how to use}} an Euler based computational method for predicting the airframe/propulsion integration effects for an aft-mounted turboprop transport. The propeller power effects are simulated by the actuator disk concept. This method consists of global flow field analysis and the embedded flow solution for predicting the detailed flow characteristics in the local vicinity of an aft-mounted propfan engine. The computational procedure includes the use of several computer programs performing four main functions: grid generation, Euler solution, grid embedding, and streamline tracing. This user's guide provides information for these programs, including input <b>data</b> <b>preparations</b> with sample input decks, output descriptions, and sample Unix scripts for program execution in the UNICOS environment...|$|R
5000|$|Given {{the variety}} of data sources (e.g. , [...] ) that provide data and formats that data can arrive in, <b>data</b> <b>preparation</b> can be quite {{involved}} and complex. There are many tools and technologies that are used for <b>data</b> <b>preparation.</b>|$|E
5000|$|Personnel {{time for}} <b>data</b> <b>preparation,</b> management, documentation, and {{preservation}} ...|$|E
5000|$|Clean: Process {{to filter}} and {{transform}} <b>data,</b> <b>preparation</b> for visualization ...|$|E
30|$|Stability {{data for}} {{establishing}} expiry dates of compounded products {{are derived from}} published <b>data,</b> where <b>preparation</b> methods likely vary from local methods, or are simply default expiry periods defined by regional pharmacy regulations and “best practices” or applicable USP Chapters 795, 797 and 1191.|$|R
30|$|The present paper {{developed}} a new boundary element formulation that account for the effect of pre-stressing cables in flat slabs. The equivalent load method is used to simulate the effect of pre-stressing cables. The formulation is automated and tested against simple cases and practical problems. The present formulation has many advantages over the existing finite element based codes in terms of <b>data</b> <b>preparations,</b> computer time and storage requirements. Analysis of pre-stressed foundation plates, punching calculations and pre-stressing losses could be easily considered using the proposed model. However, they will be considered as future research. The present method could also {{be regarded as a}} fast checking tool for results obtained from existing FEM-based software packages. It is also a promising tool for value engineering.|$|R
40|$|This {{research}} {{explores the}} effects of various training settings from Polish to English Statistical Machine Translation system for spoken language. Various elements of the TED parallel text corpora for the IWSLT 2013 evaluation campaign were {{used as the basis}} for training of language models, and for development, tuning and testing of the translation system. The BLEU, NIST, METEOR and TER metrics were used to evaluate {{the effects of}} <b>data</b> <b>preparations</b> on translation results. Our experiments included systems, which use stems and morphological information on Polish words. We also conducted a deep analysis of provided Polish data as preparatory work for the automatic data correction and cleaning phase. Comment: statistical machine translation. arXiv admin note: substantial text overlap with arXiv: 1509. 08874, arXiv: 1509. 0890...|$|R
5000|$|November 2016: Recognized by IDC Innovator for Self-Service <b>Data</b> <b>Preparation</b> ...|$|E
5000|$|<b>Data</b> <b>Preparation</b> is a necessary, {{but often}} tedious, {{activity}} that is a critical first step in data analytics projects for Data wrangling. <b>Data</b> <b>Preparation</b> can include many discrete tasks such as loading data or data ingestion, data fusion, data cleansing, data augmentation and data delivery (writing out the prepared data to databases, file systems or applications).|$|E
50|$|In October 2015, {{the company}} {{released}} Mica, their first self-service <b>data</b> <b>preparation</b> platform.|$|E
40|$|International audienceI {{will present}} {{the current status of}} the Gaia project, both from the {{viewpoint}} of the spacecraft manufacturing and the <b>data</b> analysis <b>preparation.</b> I'll put special emphasis on the acquisition peculiarities for the solar system alert system impacting on the quick availability of the data...|$|R
40|$|Funding: {{this study}} was {{supported}} by Pharmacia Ltd., Erlangen, Germany and the Leukämie-Initiative Bonn e. V. The sponsors had no influence on the evaluation of <b>data,</b> the <b>preparation</b> of the manuscript or the decision to submit it for publication. Assistance with documentation was provided by Megapharm Ltd. ...|$|R
40|$|We thank Ellen Bobe for {{assistance}} with <b>data</b> collection. <b>Preparation</b> {{of this manuscript}} {{was supported in part}} by funding of the Deutsche Forschungsgemeinschaft (DFG) awarded to MK. Correspondence concerning this article should be addressed to Katharina Schnitzspahn, Faculté de psychologie et des sciences de l'éducation, Université de Genève...|$|R
5000|$|... 1981 - <b>Data</b> <b>Preparation</b> and Data Tabulation Departments {{were added}} in April 1981.|$|E
50|$|After RET, {{the next}} step in an EDA flow is usually mask <b>data</b> <b>preparation.</b>|$|E
50|$|Data Preparation: The <b>data</b> <b>preparation</b> phase {{covers all}} {{activities}} {{to construct the}} final dataset (data that will be fed into the modeling tool(s)) from the initial raw data. <b>Data</b> <b>preparation</b> tasks {{are likely to be}} performed multiple times, and not in any prescribed order. Tasks include table, record, and attribute selection as well as transformation and cleaning of data for modeling tools.|$|E
5000|$|PMO's mission {{includes}} a strong public education aspect. Programs for high-school students {{have not only}} include observation, but also analysis of <b>data</b> and <b>preparation</b> of a paper for publication. [...] PMO has developed software that enables K-12 teachers to perform observations remotely and process the data for classroom use ...|$|R
40|$|Abstract. The {{aim of the}} {{research}} in progress is to enhance continuously cast billets images software analyzer (based on sulfur prints and template photos) <b>data</b> aquisition and <b>preparation</b> methods. Aquired sulfur prints images and templates photographs were evaluated according to statistical criteria. Raw <b>data</b> aquisition and <b>preparation</b> methods for continuously cast billets analysis software based on sulfur prints and templates photographs were developed in course of work. Conditions of aquiring templates sulfur prints and photographs were also evaluate...|$|R
30|$|<b>Data</b> input <b>preparation</b> in SimStadt {{is reduced}} to {{preparing}} the CityGML file with information regarding building age and building usage; in case of TRNSYS, all data inputs must be put manually in detail which is time consuming. In an application over several buildings or whole districts, SimStadt performs much faster.|$|R
