3|10000|Public
40|$|AbstractIn {{order to}} solve {{problems}} existing in household travel survey, such as tedious designing work of survey forms, single survey method, single function, poor pertinence of existing data statistical analysis software, and the difficulty to examine data validation, a survey data statistical analysis software named OD Star had been developed for engineering. The OD Star sets a series functions of independent designing and generating of the questionnaire, data <b>entry,</b> <b>data</b> <b>validation,</b> statistical analysis, graphic charts generation and engineering management. The main improved points of the software lie in highly integrated function, key technologies of statistical analysis, examination of data validation and so on...|$|E
40|$|Error {{messages}} may {{be displayed}} during any activity that may update the NWIS database. There are two sources of error messages: GWSI software may issue errors {{based on data}} validation using reference list checks and logical checks of entered data during Screen Entry, Query Entry, Edit, and Update. Status errors may be returned by the RETR routines that, in most cases, indicate database problems. These generally occur during the Update procedure. The following {{is a list of}} the error messages that may occur during data entry using Screen Entry, Query <b>Entry,</b> <b>Data</b> <b>Validation,</b> and the Edit and Update procedures. Negative numbered error messages represent non-fatal warning messages. Error messages are displayed in specific formats, depending on the activity being performed, and convey information about the error beyond the textual description: (1) Screen and Query Entry, and Sitefile/GWSI Data validation (gwcheck) programs display error message surrounded by either dashes or asterisks to indicate whether the reported error is a warning (dashes) or fatal (asterisks), for example: Warning error message...|$|E
40|$|Data {{management}} has {{significant impact on}} the quality control of clinical studies. Every clinical study should have a data management plan to provide overall work instructions and ensure that all of these tasks are completed according to the Good Clinical Data Management Practice (GCDMP). Meanwhile, the data management plan (DMP) is an auditable document requested by regulatory inspectors and must be written {{in a manner that is}} realistic and of high quality. The significance of DMP, the minimum standards and the best practices provided by GCDMP, the main contents of DMP based on electronic data capture (EDC) and some key factors of DMP influencing the quality of clinical study were elaborated in this paper. Specifically, DMP generally consists of 15 parts, namely, the approval page, the protocol summary, role and training, timelines, database design, creation, maintenance and security, data <b>entry,</b> <b>data</b> <b>validation,</b> quality control and quality assurance, the management of external data, serious adverse event data reconciliation, coding, database lock, data management reports, the communication plan and the abbreviated terms. Among them, the following three parts are regarded as the key factors: designing a standardized database of the clinical study, entering data in time and cleansing data efficiently. In the last part of this article, the authors also analyzed the problems in clinical research of traditional Chinese medicine using the EDC system and put forward some suggestions for improvement...|$|E
50|$|Oracle Clinical or OC is a {{database}} management system designed by Oracle to provide <b>data</b> management, <b>data</b> <b>entry</b> and <b>data</b> <b>validation</b> functionalities to support Clinical Trial operations.|$|R
40|$|The Mars Pathfinder {{heatshield}} contained several thermocouples {{and resistance}} thermometers. A {{description of the}} experiment, the <b>entry</b> <b>data,</b> {{and analysis of the}} entry environment and material response is presented. In particular, the analysis addresses uncertainties of the data and the fluid dynamics and material response models. The calculations use the latest trajectory and atmosphere reconstructions for the Pathfinder entry. A modified version of the GIANTS code is used for CFD (computational fluid dynamics) analyses, and FIAT is used for material response. The material response and flowfield are coupled appropriately. Three different material response models are considered. The analysis of Pathfinder <b>entry</b> <b>data</b> for <b>validation</b> of aerothermal heating and material response models is complicated by model uncertainties and unanticipated data-acquisition and processing problems. We will discuss these issues as well as ramifications of the data and analysis for future Mars missions...|$|R
25|$|Most {{people do}} not keep record of minute details of their {{healthcare}} experiences and therefore {{find it difficult to}} make use of web-based PHRs. Overall, the sites selected for evaluation offered limited functionality to the general public. Low adoption of web-based PHRs can be a direct result of limitations in these applications’ <b>data</b> <b>entry,</b> <b>validation</b> and information display methods. PHR development should be guided by ample patient-oriented research in future.|$|R
30|$|The 2012 ELMPS was {{implemented}} by 39 {{teams in the}} field, each consisting of one supervisor, one reviewer, and four enumerators. Additionally, there were two teams undertaking quality control. All interviewers were trained for 10  days by the technical director and CAPMAS prior to fielding the survey. The fielding of the full 2012 survey took place from March 1, 2012 to June 10, 2012, with more than 90 % of households and individuals surveyed during March and April. Desk review, coding, and <b>data</b> <b>entry</b> and <b>validation</b> at CAPMAS occurred after fielding.|$|R
40|$|Many {{end users}} still take {{advantage}} of the immediacy and simplicity of spreadsheets as a medium for storing simple data. It is not always clear which {{is the best way to}} arrange the data in a spreadsheet. We have identified a number of arrangements that can be used for storing multi-valued data. In particular we look at the ease of <b>data</b> <b>entry</b> and <b>validation,</b> querying the <b>data,</b> and producing summaries and reports for each of the arrangements. Understanding these issues will allow users to decide on the most appropriate arrangement for their multi-valued data...|$|R
50|$|Many {{computer}} systems implement <b>data</b> <b>entry</b> forms, but <b>data</b> collection systems {{tend to be}} more complex, with possibly many related forms containing detailed user input fields, <b>data</b> <b>validations,</b> and navigation links among the forms.|$|R
40|$|An {{indicator}} {{analysis was}} performed on the fish production chain by assessing the indicators which may be of importance for the detection of emerging risks. The indicators were embedded in a “risk pathway”, in which the relations between different indicators could be illustrated. The risk pathways illustrate the main characteristics of the salmon production chain. However further research is required in order to develop further interaction with other sectors, and production chains to bring emerging risk detection to the next level. In relation to the assigned indicators, a selection of (electronic) data sources were identified {{in order to be able}} to combine data flows with indicators and risk pathways. The indicators were analyzed for availability, sources of <b>data</b> <b>entry,</b> <b>validation</b> of <b>data</b> sources, update frequency and delay in input. The combination of risk pathways, indicators and data sources, will be one of the key information sources for the further development of an Emerging Risk Detection Support System (ERDSS) ...|$|R
40|$|This is {{a report}} on {{national}} data on Perinatal events in 2013. Information on every birth in the Republic of Ireland is submitted to the National Perinatal Reporting System (NPRS). All births are notified and registered on a standard four part birth notification form (BNF 01) which is completed where the birth takes place. Part 3 of this form {{is sent to the}} HPO for <b>data</b> <b>entry</b> and <b>validation.</b> The information collected includes data on pregnancy outcomes (with particular reference to perinatal mortality and important aspects of perinatal care), as well as descriptive social and biological characteristics of mothers giving birth. The time frame to which the information relates is from 22 weeks gestation to the first week of life...|$|R
40|$|Abstract: One of {{the most}} {{overlooked}} but critical component of telemetry studies is database management. Database management is the cornerstone to providing accurate and creditable data for analysis. In the last decade {{it has become a}} necessary element in fisheries research as different telemetry technologies and study designs require different database needs. Researchers can quickly become overwhelmed by the sheer volume and/or complexity of data without an appropriate system of management to organize, store and make vital data accessible in real-time. Some of the tools available for data management include the Microsoft SQL Server with front-end data access through Microsoft Access or WebFOCUS. These programs offer many important functions including the ability to query specific components of data sets, generate reports by pushbutton, run repeatable programming processes and validate data in an accurate and expeditious way. They also reduce the potential for human error by the organization and automation of the process and allows for robust quality control and assurance of data sets. Microsoft Access databases can be easily utilized in the field for <b>data</b> <b>entry</b> and pushbutton <b>data</b> <b>validation</b> and reporting. Microsoft SQL Server is a more complex system typically used for larger data sets and requires a more skilled manager for proper usage...|$|R
5000|$|Many {{organizations}} {{develop their}} own [...] "baseline" [...] security standards and designs detailing basic security control measures for their database systems. These may reflect general information security requirements or obligations imposed by corporate information security policies and applicable laws and regulations (e.g. concerning privacy, financial management and reporting systems), along with generally accepted good database security practices (such as appropriate hardening of the underlying systems) and perhaps security recommendations from the relevant database system and software vendors. The security designs for specific database systems typically specify further security administration and management functions (such as administration and reporting of user access rights, log management and analysis, database replication/synchronization and backups) along with various business-driven information security controls within the database programs and functions (e.g. <b>data</b> <b>entry</b> <b>validation</b> and audit trails). Furthermore, various security-related activities (manual controls) are normally incorporated into the procedures, guidelines etc. relating to the design, development, configuration, use, management and maintenance of databases.|$|R
40|$|Comprehensive {{geriatric}} assessment (CGA), {{supported by}} e-health, {{was provided to}} 89 frail veterans aged 70 years or older who were admitted to medical, surgical or orthopaedic units at two private hospitals in rural Queensland. Patients were screened and assessed by trained nurses using the interRAI-Acute Care tools. <b>Data</b> <b>entry,</b> <b>validation,</b> reporting and geriatrician comment were facilitated by an online, secure database and reporting system. The process was evaluated based on its utilization and staff satisfaction. The response to the project was generally very positive, {{but there were also}} some problems: (1) lack of staff, staff time and resources to successfully complete the assessments; (2) limited referrals from general practitioners (GPs) and difficulty with developing a sustainable communication and referral system between GPs and the hospital; (3) significant variations in caseloads between the study sites; and (4) the unfamiliarity of sufficient staff at the trial sites with the CGA process. Despite these challenges, the use of e-health-supported strategies in geriatric medicine certainly appears achievable and deserve further study. No Full Tex...|$|R
40|$|CDS/ISIS, an {{information}} storage and retrieval package produced and distributed by UNESCO, {{is widely used}} in Europe and many developing countries. It supports most of the requirements for designing bibliographic / textual databases. The CDS/ISlS Pascal programming facility can be used to create end-user interfaces for any specific additional requirements. The standard CDS/ISIS package does not provide for <b>data</b> <b>validation</b> with respect to subfielded fields and to check whether any mandatory fields have been missed (left blank) during <b>data</b> <b>entry.</b> This paper discusses the need for <b>data</b> <b>validation</b> and ope-ration of a CDS/ISIS Pascal interface designed for <b>data</b> <b>validation</b> of CDS/ISIS databases. The programmes enable specification of mandatory fields, validation of such fields and inadvertant omission of subfield delimiters in the master records, and obtaining online help about the use of the interface programmes...|$|R
40|$|Increasing {{dependability}} {{in collaboration}} work among health professionals will directly improve patient outcomes, and reduce healthcare costs. Our research examines {{the development of}} a shared visual display to facilitate <b>data</b> <b>entry</b> and <b>validation</b> of an electronic record during multidisciplinary team meeting discussion, where specialists discuss patient symptoms, test results, and image findings. The problem of gen- erating an electronic record for patient files that will serve as a record of collaboration, communication and a guide for later tasks is addressed through use of the shared visual display. Shortcomings in user-informed designed, structured data-entry screens became evident when in actual use. Time constraints prompt the synopsis of discussion in acronyms, free text, abbreviations, and the use of inferences. We demonstrate how common ground, team cohesiveness and the use of a shared visual display can improve dependability, but these factors can also provide {{a false sense of security}} and increase vulnerability in the patient management system...|$|R
5000|$|... 1. A <b>Data</b> <b>Validation</b> Certificate (DVC), {{delivering}} {{the results of}} <b>data</b> <b>validation</b> operations, performed by the DVCS.|$|R
40|$|Clinical {{research}} often generates vast {{arrays of}} complex, interrelated demographic, patient exam, and laboratory measurement data. Researchers have long contended with the costly, fatiguing and inefficient processes of entering this {{data on a}} database and verifying its accuracy prior to report generation and statistical analysis. We have examined several new systems in which <b>data</b> <b>entry</b> forms are scanned, interpreted through Optical Character Recognition technology, and the research data automatically stored on a database. The Berkeley Contact Lens Extended Wear Study (CLEWS), a large, randomized controlled clinical trial conducted at the University of California at Berkeley School of Optometry, {{was used as a}} testing ground for an automated <b>data</b> <b>entry</b> and <b>validation</b> system based on the Teleform software and an Epson scanner. The system allowed design of <b>data</b> <b>entry</b> forms that satisfied the needs of our clinicians, biostatisticians, and administrative staff. The system drastically reduced the time required to enter patient exam, demographic, and laboratory measurement data onto the study database, and provided tools for verifying that the data were scanned accurately. The system improved both the quality of patient care and the integrity of clinical patient data, allowing clinicians to quickly and easily retrieve patient records, and permitted our biostatisticians to generate periodic recruitment monitoring, patient safety, protocol adherence, and data quality assurance reports in a timely fashion...|$|R
40|$|Abstract. There {{are many}} tools {{suitable}} to model systems and to generate software code from system models, but these tools {{do not support}} <b>data</b> <b>validation.</b> Available <b>data</b> <b>validation</b> tools are domain specific and require manual definition of <b>data</b> <b>validation</b> rules. Thus, the lack of the tool supporting both system modelling and automated generation of <b>data</b> <b>validation</b> rules from system models is obvious. The paper discusses the use of system models represented by UML in automation of <b>data</b> <b>validation.</b> The method to derive rules from UML models is presented. A fragment of UML model and derivation of rules represented in the model is demonstrated. The tool supporting proposed method is introduced {{and the process of}} automated <b>data</b> <b>validation</b> rules generation from UML models is presented. 1...|$|R
5000|$|Advanced <b>data</b> <b>validation</b> and {{reconciliation}} (DVR) is an integrated approach of combining data reconciliation and <b>data</b> <b>validation</b> techniques, which {{is characterized by}} ...|$|R
5000|$|... 6. {{check the}} {{validity}} of its own signing key and certificate before delivering <b>data</b> <b>validation</b> certificates and MUST not deliver <b>data</b> <b>validation</b> certificate in case of failure.|$|R
40|$|Background and purpose: EpiData and Epi Info {{are often}} used {{together}} by public health agencies around the world, particularly in developing countries, {{to meet their needs}} of low-cost public health data management; however, the current open source data management technology lacks a mobile component {{to meet the needs of}} mobile public health data collectors. The goal of this project is to explore the opportunity of filling this gap through developing and trial of a personal digital assistant (PDA) based data collection/entry system. It evaluated whether such a system could increase efficiency and reduce data transcription errors for public surveillance data collection in developing countries represented by Fiji. Methods: A generic PDA-based data collection software eSTEPS was developed. The software and the data collected using it directly interfaces with EpiData. A field trial was conducted to test the viability of public health surveillance data collection using eSTEPS. The design was a randomised, controlled trial with cross-over design. 120 participants recruited from the Fiji School of Medicine were randomly assigned to be interviewed by one of six interviewers in one of the two ways: (1) paper-based survey followed by PDA survey and (2) PDA survey followed by paper-based survey. Data quality was measured by error rates (logical range errors/inconsistencies, skip errors, missing values, date or time field errors and incorrect data type). Work flow and cost were evaluated in three stages of the survey process: (1) preparation of data collection instrument, (2) data collection and (3) <b>data</b> <b>entry,</b> <b>validation</b> and cleaning. User acceptance was also evaluated in the two groups of participants: (1) data collectors and (2) survey participants. Results: None of the errors presented in 20. 8 % of the paper questionnaires was found in the data set collected using PDA. Sixty two percent of the participants perceived that the PDA-based questionnaire took less time to complete. <b>Data</b> <b>entry,</b> <b>validation</b> and cleaning for the PDA-based data collection from 120 participants took a total of 1. 5 hours, a 93. 26 % reduction of time from 20. 5 hours required using paper and pen. The cost is also significantly reduced with PDA-based protocol. Both data collectors and participants prefer to use PDA instead of paper for data collection. The trial results prove that eSTEPS is a feasible solution for public health surveillance data collection in the field. Several deficiencies of the software were also identified and would be addressed in the next version. Conclusion: eSTEPS offers the potential to meet the need for an effective mobile public health data collection tool for use in the field. The eSTEPS field trial proves that PDA was more efficient than paper for public health survey data collection. It also significantly reduced errors in <b>data</b> <b>entry.</b> The later benefit was derived from the software providing its users with the flexibility of building their own constraints to control the data type, range and logic of <b>data</b> <b>entry...</b>|$|R
50|$|Failures or {{omissions}} in <b>data</b> <b>validation</b> {{can lead}} to data corruption or a security vulnerability. <b>Data</b> <b>validation</b> checks that <b>data</b> are valid, sensible, reasonable, and secure before they are processed.|$|R
50|$|A <b>Data</b> <b>Validation</b> and Certification Server (DVCS) is a Trusted Third Party (TTP) {{providing}} <b>data</b> <b>validation</b> services, asserting correctness of digitally signed documents, {{validity of}} public key certificates, and possession or existence of data.|$|R
50|$|<b>Data</b> <b>Validation</b> and Certification Server (DVCS) is {{a public}} key {{infrastructure}} or PKI service providing <b>data</b> <b>validation</b> services, asserting correctness of digitally signed documents, validity of public key certificates and possession or existence of data.|$|R
40|$|Online <b>data</b> <b>validation</b> is a performance-enhancing {{component}} of modern control and health management systems. It {{is essential that}} performance of the <b>data</b> <b>validation</b> system be verified prior to its use in a control and health management system. A new <b>Data</b> Qualification and <b>Validation</b> (DQV) Test-bed application was developed to provide a systematic test environment for this performance verification. The DQV Test-bed {{was used to evaluate}} a model-based <b>data</b> <b>validation</b> package known as the <b>Data</b> Quality <b>Validation</b> Studio (DQVS). DQVS was employed as the primary <b>data</b> <b>validation</b> {{component of}} a rocket engine health management (EHM) system developed under NASA's NGLT (Next Generation Launch Technology) program. In this paper, the DQVS and DQV Test-bed software applications are described, and the DQV Test-bed verification procedure for this EHM system application is presented. Test-bed results are summarized and implications for EHM system performance improvements are discussed...|$|R
50|$|If {{the request}} is valid, the DVCS {{performs}} all necessary verification steps, and generates a <b>Data</b> <b>Validation</b> Certificate(DVC), and sends a response message containing the DVC {{back to the}} requestor. The <b>Data</b> <b>Validation</b> Certificate {{is formed as a}} signed document (CMS Signed Data).|$|R
40|$|Abstract—To {{reduce the}} {{deficiency}} {{of the traditional}} methods of <b>data</b> <b>validation</b> in web applications, research and analysis of Struts framework and AJAX technology are carried out, and a dynamic, real time and interactive web <b>data</b> <b>validation</b> model based on asynchronous communication is proposed. This model combines {{the functions of the}} flexible and dynamic presentation in AJAX and the controller in Struts. The architecture and implementation method of this model are elaborated in detail. Index Terms—Struts, AJAX, asynchronous communication, Web <b>data</b> <b>validation</b> mode...|$|R
40|$|A {{fundamental}} Software-as-a-Service (SaaS) characteristic in Cloud Computing {{is to be}} application-specific; {{depending on}} the application, Cloud Providers (CPs) restrict data formats and attributes allowed into their servers via a <b>data</b> <b>validation</b> process. An ill-defined <b>data</b> <b>validation</b> process may directly impact both security (e. g. application failure, legal issues) and accounting and charging (e. g. trusting metadata in file headers). Therefore, this paper investigates, evaluates (by means of tests), and discusses <b>data</b> <b>validation</b> processes of popular CPs. A proof of concept system was thus built, implementing encoders carefully crafted to circumvent <b>data</b> <b>validation</b> processes, ultimately demonstrating how large amounts of unaccounted, arbitrary data can be stored into CPs. Comment: 8 pages, ISBN 978 - 1 - 4673 - 5229 -...|$|R
5000|$|... #Subtitle level 2: Advanced <b>data</b> <b>validation</b> and {{reconciliation}} ...|$|R
5000|$|... #Subtitle level 2: <b>Data</b> <b>Validation</b> and Certification Requests ...|$|R
40|$|Visual Basic is {{a popular}} {{programming}} package because of its user-friendly interface and data access features. Two popular data access mechanisms are data bound controls with data access objects, and remote data controls with remote data objects. The main difference between these methods are that data bound controls are usually used to connect to desktop databases, and remote data objects are used to connect to client/server data (for client database manipulation of a remote database). Using Microsoft's FlexGrid control (MSFLXGRD. OCX) you can create utilities to display, filter, edit, validate and update your data. For example, such utilities could include: 1. <b>data</b> <b>entry</b> & <b>validation</b> 2. high level reports 3. ported spreadsheet macro applications retaining cell layout & format Also, users do not require any addition software or tools for it to connect it accurately {{in order to provide}} authentication. This technique is helpful for connect with database programming system and it save the extra time which is wasted for connect with different Sheets i. e. Excel Sheet and other Style Sheets and we connect the database with this programming tool and access the data...|$|R
50|$|<b>Data</b> <b>validation</b> is {{intended}} to provide certain well-defined guarantees for fitness, accuracy, and consistency for any of various kinds of user input into an application or automated system. <b>Data</b> <b>validation</b> rules can be defined and designed using any of various methodologies, and be deployed in any of various contexts.|$|R
50|$|A DVCS MUST {{support at}} least a subset of these services. A DVCS may support a {{restricted}} vsd service allowing to validate <b>data</b> <b>validation</b> certificates.On completion of each service, the DVCS produces a <b>data</b> <b>validation</b> certificate - a signed document containing the validation results and trustworthy time information.|$|R
40|$|This paper {{describes}} a universal framework for online <b>data</b> <b>validation</b> process management developed {{as part of}} the activities performed for the construction and test of the CMS (Technical Proposal, CERN/LHCC 94 - 38, 1994.) crystal calorimeter. Our framework allows the parallel development of language-independent <b>data</b> <b>validation</b> tasks automatically taking care of the synchronization of the activities and avoiding any complex user interface. The only requirement for the <b>data</b> <b>validation</b> tasks consists in the fact that their output must be available as HTML-formatted text files. (C) 2004 Elsevier B. V. All rights reserved...|$|R
40|$|<b>Data</b> <b>validation</b> rules {{constitute}} the constraints that data input and processing must adhere to {{in addition to}} the structural constraints imposed by a data model. Web modeling tools do not make all types of <b>data</b> <b>validation</b> explicit in their models, hampering full code generation and model expressivity. Web application frameworks do not offer a consistent interface for <b>data</b> <b>validation.</b> In this paper, we present a solution for the integration of declarative <b>data</b> <b>validation</b> rules with user interface models in the domain of web applications, unifying syntax, mechanisms for error handling, and semantics of validation checks, and covering value well-formedness, data invariants, input assertions, and action assertions. We have implemented the approach in WebDSL, a domain-specific language for the definition of web applications. Software TechnologyElectrical Engineering, Mathematics and Computer Scienc...|$|R
