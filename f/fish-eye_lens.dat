121|47|Public
500|$|A music video, co-directed by Neil Pollock and Jonathan Bekemeier, {{to promote}} the single shows the band playing its {{instruments}} through a distorted <b>fish-eye</b> <b>lens,</b> the camera variously panning horizontally across the performance space and vertically over the individual band members. Keeping {{in the spirit of}} the mimed performance, Francis and bassist Kim Deal open and shut their mouths in time with their prerecorded vocals, yet make no attempt to articulate their lips in synch with the words that they are supposed to be singing. Instead, they simply keep their mouths wide open with blank expressions for the duration of each verse. Francis stated that [...] "Water on the brain" [...] was the theme of the clip.|$|E
5000|$|... #Caption: The Curves of ESO’s Headquarters {{through a}} <b>fish-eye</b> <b>lens.</b>|$|E
5000|$|... #Caption: <b>Fish-eye</b> <b>lens</b> {{view of the}} {{interior}} of Cupola with shutters closed ...|$|E
5000|$|Door viewers — small <b>fish-eye</b> <b>lenses</b> {{that allow}} {{residents}} to view outside without opening the door.|$|R
40|$|<b>Fish-eye</b> <b>lenses</b> are {{convenient}} in such {{computer vision}} applications where {{a very wide}} angle of view is needed. However, their use for measurement purposes {{is limited by the}} lack of an accurate, generic, and easy-to-use calibra-tion procedure. We hence propose a generic camera model for cameras equipped with <b>fish-eye</b> <b>lenses</b> and a method for calibration of such cameras. The calibration is possible by using only one view of a planar calibration object but more views should be used for better results. The proposed cali-bration method was evaluated with real images and the ob-tained results are promising. The calibration software will become commonly available at the author’s Web page. 1...|$|R
40|$|We {{present an}} {{autonomous}} mobile robot navigation system using stereo <b>fish-eye</b> <b>lenses</b> for navigation in an indoor structured environment, and for generating {{a model of the}} imaged scene. The system estimates the three-dimensional (3 D) position of significant features in the scene, and by estimating its relative position, navigates through narrow passages and makes turns at corridor ends. <b>Fish-eye</b> <b>lenses</b> are used to provide a large field of view, which helps in imaging objects close to the robot and in making smooth transitions in the direction of motion. Calibration is performed for the lens-camera setup and the distortion is corrected to obtain accurate quantitative measurements. A vision based algorithm that uses the vanishing points of extracted segments from a scene in a few 3 D orientations provides an accurate estimate of the robot orientation. This is used, in addition to 3 D recovery via stereo correspondence, to maintain the robot motion in a purely translational path as well as to r [...] ...|$|R
5000|$|... #Caption: Cross-section of Maxwell's <b>fish-eye</b> <b>lens,</b> {{with blue}} shading {{representing}} increasing refractive index ...|$|E
50|$|Panoramic {{cameras are}} fixed-lens digital action cameras. They {{usually have a}} single <b>fish-eye</b> <b>lens</b> or {{multiple}} lenses, to cover the entire 180° up to 360° in their field of view.|$|E
5000|$|Maxwell's <b>fish-eye</b> <b>lens</b> is also {{an example}} of the {{generalized}} Luneburg lens. The fish-eye, which was first fully described by Maxwell in 1854 (and therefore pre-dates Luneburg's solution), has a refractive index varying according to ...|$|E
40|$|We {{present a}} {{complete}} step-by-step approach to calibration of ultra wide angle <b>fish-eye</b> <b>lenses</b> with {{the angle of}} view larger than 180 #. Such a large field of view is necessary for some applications such as the 360 x 360 mosaicing. Recently, a Nikon FC-E 8 fish eye lens converter with {{the field of view}} equal 183 # become available. In this paper, we propose its model, suggest a calibration procedure, and demonstrate its use in a mosaicing application...|$|R
40|$|In {{this article}} {{a method for}} reconstructing {{atmospheric}} cloud surfaces using a stereo camera system is presented. The proposed camera system utilizes <b>fish-eye</b> <b>lenses</b> in a flexible wide baseline camera setup. The entire workflow from the camera calibration {{to the creation of}} the 3 D point set is discussed, but the focus is mainly on cloud segmentation and on the image processing steps of stereo reconstruction. Speed requirements, geometric limitations, and possible extensions of the presented method are also covered. After evaluating the proposed method on artificial cloud images, this paper concludes with results and discussion of possible applications for such systems...|$|R
40|$|The paper {{presents}} {{the design of}} a real-time and low-cost embedded system for image acquisition and processing in Advanced Driver Assisted Systems (ADAS). The system adopts a multi-camera architecture to provide a panoramic view of the objects surrounding the vehicle. <b>Fish-eye</b> <b>lenses</b> are used to achieve a large Field of View (FOV). Since they introduce radial distortion of the images projected on the sensors, a real-time algorithm for their correction is also implemented in a pre-processor. An FPGA-based hardware implementation, re-using IP macrocells for several ADAS algorithms, allows for real-time processing of input streams from VGA automotive CMOS cameras...|$|R
50|$|The Nusselt analog has on {{occasion}} {{been used to}} actually measure form factors for complicated surfaces, by photographing them through a suitable <b>fish-eye</b> <b>lens.</b> (see also Hemispherical photography). But its main value now is essentially in building intuition.|$|E
5000|$|... #Caption: As {{a highly}} perfected {{rectilinear}} lens, straight lines are rendered perfectly straight (while a similar focal length <b>Fish-Eye</b> <b>lens</b> will distort such lines). This photograph was {{taken at the}} Getty Villa in Pacific Palisades, CA with the 13mm Nikkor.|$|E
50|$|The {{less obvious}} digital {{contributions}} into an analog scene include lens effects {{such as the}} <b>fish-eye</b> <b>lens,</b> motion blur to more vividly portray movement, instability in {{the focus of the}} camera, unstable light exposure, lighting effects such as shadows, and gun muzzle flashes.|$|E
5000|$|At {{this point}} Rollei still lagged behind the large Japanese {{companies}} who already offered <b>fish-eye</b> <b>lenses,</b> super-telephoto lenses and zoom lenses. Although few amateur photographers purchased lenses {{such as these}} in the early 1970s, from a marketing perspective, statements published in camera reviews like [...] "lenses available with focal lengths from 7.5 mm to 800 mm" [...] sounded more impressive than [...] "... from 25 to 200 mm". Consequently, Rollei soon expanded their range; by 1973 a total of 16 lenses (all with fixed focal-lengths) were available for the Rolleiflex SL35: 13 from Carl Zeiss (Oberkochen), and 3 from Schneider-Kreuznach.|$|R
40|$|It is commonplace to use {{digital video}} cameras in robotic applications. These cameras have {{built-in}} exposure control {{but they do}} not have any knowledge of the environment, the lens being used, the important areas of the image and do not always produce optimal image exposure. Therefore, it is desirable and often necessary to control the exposure off the camera. In this paper we present a scheme for exposure control which enables the user application to determine the area of interest. The proposed scheme introduces an intermediate transparent layer between the camera and the user application which combines the information from these for optimal exposure production. We present results from indoor and outdoor scenarios using directional and <b>fish-eye</b> <b>lenses</b> showing the performance and advantages of this framework. ...|$|R
40|$|This paper {{covers the}} whole process of {{developing}} an Augmented Reality Stereoscopig Render Engine for the Oculus Rift. To capture the real world in form of a camera stream, two cameras with <b>fish-eye</b> <b>lenses</b> had to be installed on the Oculus Rift DK 1 hardware. The idea was inspired by Steptoe steptoe 2014 presence. After the introduction, a theoretical part covers all the most neccessary elements to achieve an AR System for the Oculus Rift, following the implementation part where the code from the AR Stereo Engine is explained in more detail. A short conclusion section shows some results, reflects some experiences and in the final chapter some future works will be discussed. The project can be accessed via the git repository [URL]...|$|R
50|$|The smc Pentax-DA 10-17mm f/3.5-4.5 ED (IF) <b>Fish-Eye</b> <b>lens</b> is a fisheye {{zoom lens}} for the Pentax K-mount. It offers an up to 180 degree view, and allows quick shift focus (Pentax's term for giving the {{photographer}} {{the ability to}} manually focus the lens even when the camera is in autofocus mode without damaging the lens or camera).|$|E
50|$|Named after a Japanese god of thunder, Raiko is a 2 kg spacecraft, {{which will}} be used for {{technology}} demonstration. It carries a camera with a <b>fish-eye</b> <b>lens</b> for Earth imaging, a prototype star tracker, a deployable membrane to slow the satellite, lowering its orbit, a photographic system to measure the satellite's movement relative to the International Space Station, and a Ku-band antenna for communications and Doppler ranging experiments.|$|E
50|$|The fisheye and {{spherical mirror}} {{distortion}} features allow Stellarium to be projected onto domes. Spherical mirror distortion {{is used in}} projection systems that utilize a digital video projector and a first surface convex spherical mirror to project images onto a dome. Such systems are generally cheaper than traditional planetarium projectors and <b>fish-eye</b> <b>lens</b> projectors {{and for that reason}} are used in budget and home planetarium setups where projection quality is less important.|$|E
40|$|The {{design and}} the {{implementation}} of a flexible and low-cost embedded system for real-time car's surrounding vision is presented. The target of the proposed multi-camera vision system is to provide the driver a better view of the objects that surround the vehicle. <b>Fish-eye</b> <b>lenses</b> are used to achieve a larger Field of View (FOV) but, on the other hand, introduce radial distortion of the images projected on the sensors. Using low-cost cameras there could be also some alignment issues. Since these complications are noticeable and dangerous, a real-time algorithm for their correction is presented. Then another real-time algorithm, used for merging 4 camera video streams together in a single view, is described. Real-time image processing is achieved through a hardware-software platform...|$|R
40|$|Omnidirectional {{optoelectronic}} systems {{find their}} application {{in areas where}} a wide viewing angle is critical. However, omnidirectional optoelectronic systems have a large distortion that makes their application more difficult. The paper compares the projection functions of traditional perspective lenses and omnidirectional wide angle <b>fish-eye</b> <b>lenses</b> with a viewing angle not less than 180 °. This comparison proves that distortion models of omnidirectional cameras cannot {{be described as a}} deviation from the classic model of pinhole camera. To solve this problem, an algorithm for transforming omnidirectional images has been developed. The paper provides a brief comparison of the four calibration methods available in open source toolkits for omnidirectional optoelectronic systems. Geometrical projection model is given used for calibration of omnidirectional optical system. The algorithm consists of three basic steps. At the first step, we calculate he field of view of a virtual pinhole PTZ camera. This field of view is characterized by an array of 3 D points in the object space. At the second step the array of corresponding pixels for these three-dimensional points is calculated. Then we make a calculation of the projection function that expresses the relation between a given 3 D point in the object space and a corresponding pixel point. In this paper we use calibration procedure providing the projection function for calibrated instance of the camera. At the last step final image is formed pixel-by-pixel from the original omnidirectional image using calculated array of 3 D points and projection function. The developed algorithm gives the possibility for obtaining an image for a part of the field of view of an omnidirectional optoelectronic system with the corrected distortion from the original omnidirectional image. The algorithm is designed for operation with the omnidirectional optoelectronic systems with both catadioptric and <b>fish-eye</b> <b>lenses.</b> Experimental results are presented...|$|R
40|$|Abstract — The {{majority}} of computer vision applications {{assume that the}} camera adheres to the pin-hole camera model. However, most real optical systems will introduce some undesirable effects, rendering the assumption of the pin-hole camera model invalid. By far the most evident of these effects is radial distortion, particularly in fish-eye camera systems where the level of this distortion is relatively extreme. The aim of fish-eye distortion correction is, therefore, to transform the distorted view of fish-eye cameras to the desired rectilinear pin-hole perspective view. To perform this distortion correction, several authors have developed models of fish-eye distortion. It is {{the aim of this}} paper to examine the accuracy of several of the polynomial-based models against the equidistance mapping function, which is the most common mapping function that <b>fish-eye</b> <b>lenses</b> are designed to follow. __________________________________________________________________________________________...|$|R
5000|$|... "Limelight" [...] {{is another}} {{perennial}} radio favourite. The lyrics are autobiographical, based on Peart's own dissatisfaction with fame and its intrusion into personal life. The song contains two self-references: the first, the line [...] "living in a <b>fish-eye</b> <b>lens,</b> {{caught in the}} camera eye" [...] references the next track, [...] "The Camera Eye", while the line [...] "all the world's indeed a stage, and we are merely players", references {{the title of the}} live album All the World's a Stage, itself taken from William Shakespeare's As You Like It.|$|E
5000|$|Sumberg's early {{paintings}} were figurative and somewhat indebted to pop {{art and the}} milieu she was part of, with areas of bold, flat colour and schematic, heavily out-lined drawing, done in enamel on Masonite. Australian artist and critic Robert Rooney wrote of these works: [...] "…The best are boldly painted and ambitiously constructed, often {{with the aid of}} <b>fish-eye</b> <b>lens</b> distortion…. Surfaces are smooth, with an occasional drip on a tuxedo in ‘Dijon Waiter’ or a wrinkled skin in ‘Model Lisa No. 6.’ Flat areas and images are outlined in black." ...|$|E
50|$|A mini planetarium, with {{seating for}} a dozen people, is used for {{initiating}} the general public into celestial mechanics : explanations as to the motion of stars and planets, the location of constellations, etc. are readily visualized. Since March 2006, a new digital planetarium system has been installed: the Digitarium Alpha. This equipment comprises a computer on which an adapted version of the Stellarium open source software runs, and a beamer equipped with a <b>fish-eye</b> <b>lens.</b> A simultaneous projection of the skies together with a drawing of the constellations and astronomical pictures or movies is made possible thanks to the incorporated DVD drive.|$|E
40|$|Although an {{immersive}} {{projection display}} provides {{a high quality}} of presence, it requires a large space and a high cost to equip the facility. This paper proposes a room-sized immersive projection display system named CC Room. In this system, the rounded corner of an ordinary room {{was used for the}} screen, and the projectors equipped with the <b>fish-eye</b> <b>lenses</b> were used to project wide angle images. By using this system, an immersive virtual environment that covers the user’s view can be generated using one PC and one projector system. This system was connected to the JGN 2 network and it was applied to the tele-immersive communication using video avatar. This paper describes the system construction of the CC Room, the distortion correction method, the evaluation experiments and the tele-immersion applications...|$|R
40|$|The {{majority}} of computer vision applications {{assumes that the}} camera adheres to the pinhole camera model. However, most optical systems will introduce undesirable effects. By far, the most evident of these effects is radial lensing, which is particularly noticeable in fish-eye camera systems, where the effect is relatively extreme. Several authors have developed models of <b>fish-eye</b> <b>lenses</b> {{that can be used}} to describe the fish-eye displacement. Our aim is to evaluate the accuracy of several of these models. Thus, we present a method by which the lens curve of a fish-eye camera can be extracted using well-founded assumptions and perspective methods. Several of the models from the literature are examined against this empirically derived curve. © 2010 Optical Society of America OCIS codes: 100. 2980, 100. 4994, 110. 6980, 150. 1488...|$|R
5000|$|Photographically, Bolster {{was among}} the first to use <b>fish-eye</b> <b>lenses,</b> motor-drive {{sequences}} and strobes while documenting California's skateboarding culture. For example, Ty Page's multi-faceted, rapid-fire technique and footwork were nothing short of incredible. After trying many times to photograph his footwork, Bolster was forced to purchase a new $3,000 high-speed camera to catch him on film to publish in the August and September 1977 issues of Skateboarder Magazine. Superstar professional skateboarder Tony Hawk said the magazine was the only one worth reading at the time. [...] "The pictures were always dreamy and left me full of disbelief…. If it weren't for SkateBoarder, I would have never realized what was really possible on my four-wheeled plank," [...] Hawk said in the book The Legacy of Warren Bolster: Master of Skateboard Photography.|$|R
50|$|Displaying a {{hyperbolic}} tree commonly utilizes the Poincaré disk {{model of}} hyperbolic geometry, though the Klein-Beltrami model {{can also be}} used. Both display the entire hyperbolic plane within a unit disk, making the entire tree visible at once. The unit disk gives a <b>fish-eye</b> <b>lens</b> view of the plane, giving more emphasis to nodes which are in focus and displaying nodes further out of focus closer to the boundary of the disk. Traversing the hyperbolic tree requires Möbius transformations of the space, bringing new nodes into focus and moving higher levels of the hierarchy out of view.|$|E
5000|$|Peripheral vision - At {{the outer}} {{extremes}} {{of the visual}} field, parallel lines become curved, as in a photo taken through a <b>fish-eye</b> <b>lens.</b> This effect, although usually eliminated from both art and photos by the cropping or framing of a picture, greatly enhances the viewer's sense of being positioned within a real, three-dimensional space. (Classical perspective has no use for this [...] "distortion", although in fact the [...] "distortions" [...] strictly obey optical laws and provide perfectly valid visual information, just as classical perspective does for {{the part of the}} field of vision that falls within its frame.) ...|$|E
5000|$|A music video, co-directed by Neil Pollock and Jonathan Bekemeier, {{to promote}} the single shows the band playing its {{instruments}} through a distorted <b>fish-eye</b> <b>lens,</b> the camera variously panning horizontally across the performance space and vertically over the individual band members. Keeping {{in the spirit of}} the mimed performance, Francis and bassist Kim Deal open and shut their mouths in time with their prerecorded vocals, yet make no attempt to articulate their lips in synch with the words that they are supposed to be singing. Instead, they simply keep their mouths wide open with blank expressions for the duration of each verse. Francis stated that [...] "Water on the brain" [...] was the theme of the clip.|$|E
40|$|Abstract—Wide-angle or <b>fish-eye</b> <b>lenses</b> are popularly {{used for}} the {{surveillance}} system due to their large field of view (FOV). However, images obtained by wide-angle cameras tend to be nonlinearly distorted owing to lens optics. In this paper, we propose a novel framework to correct the wide-angle lens distortion for surveillance systems. Our approach {{is based on the}} FOV model, which is an efficient and simple correction method. The FOV model works well for typical wide-angle lens, whose FOV is usually smaller than 150 °. However, it begins to reveal problems as the FOV increases. First, we address two main problems of the FOV model and then improve the FOV model by refining the distortion curve. The proposed method is tested on images and videos with different FOV. Experimental results show the efficiency of our algorithm. I...|$|R
40|$|We {{show that}} it is {{possible}} to obtain a very complete 3 D metric reconstruction of the surrounding scene from two or more uncalibrated omnidirectional images. In particular, we demonstrate that omnidirectional images with angle of view above 180 # can be reliably autocalibrated. We also show that wide angle images provide reliable information about their camera positions and orientations. We link together a method for simultaneous omnidirectional camera model and epipolar geometry estimation and a method for factorization-based 3 D reconstruction in order to obtain metric reconstruction of unknown scene observed by uncalibrated omnidirectional images. The 3 D reconstruction is done from automatically established image correspondences only. We demonstrate our method in experiments with Nikon FC [...] E 8 and Sigma 8 mm-f 4 -EX <b>fish-eye</b> <b>lenses.</b> Nevertheless, the proposed method can be used for a large class of non-perspective central omnidirectional cameras...|$|R
40|$|We {{propose a}} method of {{simultaneously}} calibrating the radialdistortion functionof a camera alongwith the otherinternal calibration parameters. The method relies {{on the use of}} a planar (or alternatively non-planar) calibration grid, which is captured in several images. In this way, the determination of the radial distortion is an easy add-on to the popular calibration method proposed by Zhang [17]. The method is entirely non-iterative, and hence is extremely rapid and immune from the problem of local minima. Our method determines the radial distortion in a parameter-free way, not relying on any particular radial distortion model. This makes it applicable to a large range of cameras from narrow-angle to <b>fish-eye</b> <b>lenses.</b> The method also computes the centre of radial distortion, which we argue is important in obtaining optimal results. Experiments show that this point may be significantly displaced from the centre of the image, or the principal point of the camera. ...|$|R
