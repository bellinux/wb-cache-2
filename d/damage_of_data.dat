0|10000|Public
40|$|To {{verify the}} results of seismic microzoning and to improve techniques, the <b>damage</b> <b>data</b> <b>of</b> past {{destructive}} earthquakes is an important key reference. The <b>damage</b> <b>data</b> <b>of</b> the 1923 Kanto, Japan, earthquake in the epicentral region are collected and compiled to produce the most reliable and detailed damage map. The damage map is compared with {{the results from the}} existing damage assessment and is used to discuss revision of the site amplification evaluation...|$|R
40|$|Analysis <b>of</b> {{radiation}} <b>damage</b> <b>of</b> MOSFET <b>data</b> from Explorer 34 (IMP-F), {{and radiation}} <b>damage</b> characteristics <b>of</b> MOSFET with boron diffused between a silicon semiconductor and silicon oxide are considered. The first subject is {{an interpretation of}} the discrepancy between the space data and the laboratory data. The second subject is an attempt to analyze the radiation <b>damage</b> characteristic <b>of</b> MOSFET when there is modification of electrical properties in the gate oxide region...|$|R
50|$|Additionally, if {{the archive}} becomes even {{slightly}} <b>damaged,</b> some <b>of</b> the <b>data</b> (sometimes even all data) after the damaged part can be unusable (depending on the compression and archiving format), whereas in a non-solid archive format, usually only one file is unusable {{and the subsequent}} files can usually still be extracted.|$|R
25|$|On May 9, 2008, it was {{reported}} that data from a disk drive on board Columbia had survived the shuttle accident, and while part of the 340MB drive was <b>damaged,</b> 99% <b>of</b> the <b>data</b> was recovered. The drive was used to store data from an experiment on the properties of shear thinning.|$|R
50|$|As any code can {{potentially}} <b>damage</b> the <b>data</b> <b>of</b> another task (except in larger systems using an MMU) programs {{must be carefully}} designed and tested, and access to shared data must be controlled by some synchronization strategy, such as message queues, semaphores or a non-blocking synchronization scheme.|$|R
40|$|This {{research}} aim {{to know and}} analyse influence between control quality to level <b>damage</b> <b>of</b> product Especial PT. FILMA Soap Surabaya. In this research there are 4 free variable that is Routing, Loading, Dispatching and of Follow up and also variable tied that is Level <b>Damage</b> <b>of</b> Product <b>Data</b> collecting obtained to through documentation data and observation and also spreading of passed to quisioner is responder Method analyse data the utilized is quantitative analysis of empirical analysis with statistic. For solution in this research is utilized analysis of regression the following variable multi : Result of analysis of regression analyse and furthermore examination, by partial (test significance partial) with analysis of r 2 test and of t, and by simultaneous (test significance simultaneous) using analysis of R 2 and test of F. Result of research can be concluded that Routing, Loading, Dispatching and of Follow up as free variable have influence which is significance to level <b>damage</b> <b>of</b> product as variable tied Keyword : Routing, Loading, Dispatching dan Follow up and level <b>damage</b> <b>of</b> produc...|$|R
40|$|International audienceThis paper {{presents}} {{the design of}} a P 2 P data persistent platform. Durable access and integrity <b>of</b> the <b>data</b> are ensured despite massive attacks. This platform, named DataCube, exploits the properties of cluster-based peer-to-peer substrates to implement a compound of full replication and rateless erasure codes. DataCube guarantees durable access and integrity <b>of</b> <b>data</b> despite adversarial attacks. In particular, the recovery <b>of</b> <b>damaged</b> <b>data</b> is achieved through the retrieval of coded blocks whose integrity is checked on the fly...|$|R
50|$|Measurement {{of small}} {{differences}} in the refractive index between the two data states. This method usually employs a phase contrast microscope or confocal reflection microscope. No absorption of light is necessary, {{so there is no}} risk <b>of</b> <b>damaging</b> <b>data</b> while reading, but the required refractive index mismatch in the disc may limit the thickness (i.e. number <b>of</b> <b>data</b> layers) that the media can reach due to the accumulated random wavefront errors that destroy the focused spot quality.|$|R
40|$|Abstract — Authorization in Grid {{computing}} environment involves primarily {{the technique of}} providing the access control to the users for the resources. Lack of proper authorization process leads towards great loss and <b>damage</b> <b>of</b> vital <b>data</b> and information. The matter is more complicated in Grid environment because of the interior concept of virtual organization (VO). Role Based Access Control (RBAC) has gained significance for authorization and for providing RBAC, some sets of policies are to be created for the Grid {{computing environment}} with the corresponding virtual organizations. In this paper we have developed a novel architecture and cross-domain policy mechanism for authorization in Grid {{which is based on}} RBAC, where access control is attained through global-local role of users and resources providers. Keywords—Grid authorization, Security, RBAC, Crossdomain framework...|$|R
40|$|The current paper {{presents}} a new digital watermarking method through bit replacement technology, which stores mul-tiple copies <b>of</b> the same <b>data</b> {{that is to}} be hidden in a scrambled form in the cover image. In this paper an indigenous approach is described for recovering the data from the <b>damaged</b> copies <b>of</b> the <b>data</b> under attack by applying a majority algorithm to find the closest twin of the embedded information. A new type of non-oblivious detection method is also proposed. The improvement in performance is supported through experimental results which show much enhancement in the visual and statistical invisibility <b>of</b> hidden <b>data...</b>|$|R
40|$|Key words：Lushan {{earthquake}},macroscopic epicenter, earthquake <b>damage</b> <b>of</b> engineering Abstract：Damage <b>data</b> <b>of</b> 52 masonry structures inYuxiVillage {{which is}} the macroscopic epicenter of Ms 7. 0 LuShan strong earthquake were summarized and analyzed to study basic seismic capacity of the rural residence in Southwest China, and the following conclusions were obtained: summarized structural features of the main rural residence structure in Southwest China that exemplified by YuxiVillage; summarized <b>damage</b> characteristics <b>of</b> masonry structure inYuxiVillage, given brief analysis <b>of</b> its <b>damage</b> causes and provided reinforcement and improvement suggestions according to the corresponding damage characteristics; analyzed general <b>damage</b> characteristics <b>of</b> the village houses in the macroscopic level based on statistically analyze seismic site survey data. The basic seismic capacity of rural residential status in Southwest China is initially grasped, and it has important reference value to understand <b>of</b> the <b>damage</b> characteristics <b>of</b> various types of structure, the development of earthquake disaster mitigation planning and revision of seismic design code...|$|R
40|$|ABSTRACT: The {{development}} <b>of</b> storm <b>damage</b> functions is <b>of</b> {{importance for}} <b>damage</b> and risk assessment of extreme storm events. Building <b>damage</b> <b>data</b> <b>of</b> four winter storms in the German state of Baden-Württemberg are analyzed {{in order to}} quantify the relationship between gust speed and amount and number <b>of</b> <b>damages.</b> It {{was found that the}} incorporation of the local wind climate is necessary to describe storm damage rather than solely dealing with the absolute gust speed. A new damage model is described and calibrated to the available data. In contrast to em-pirical functions, the new function are based on logical and physical assumptions. Finally, the application in storm damage scenarios and storm risk maps is demonstrated...|$|R
40|$|The {{increase}} in the adoption of database systems by the Corporates in key data management technology for their day-to-day operations. So, decision-making becomes crucial for the security <b>of</b> <b>data</b> that is managed by these systems. The <b>damage</b> and misuse <b>of</b> <b>data</b> affects not only the single user or application, but it may have disastrous consequences for the entire organization as well. Accessing more secured information through client’s mobile device is an important issue. In this paper, a framework for Secure Mobile Database Transactions using the Cryptographic Co-processor (CCP) is proposed. A dedicated coprocessor for encryption and decryption process enables high level security when compared to software based encrypting/decrypting process in corporate environment...|$|R
40|$|We {{have used}} ion-irradiation {{to damage the}} (001) {{surfaces}} of SmB_ 6 single crystals to varying depths, and have measured the resistivity {{as a function of}} temperature for each depth <b>of</b> <b>damage.</b> We observe a reduction in the residual resistivity with increasing depth <b>of</b> <b>damage.</b> Our <b>data</b> are consistent with a model in which the surface state is not destroyed by the ion-irradiation, but instead the damaged layer is poorly conducting and the initial surface state is reconstructed below the damage. This behavior is consistent with a surface state that is topologically protected. Comment: 5 pages, 3 figure...|$|R
40|$|This paper {{presents}} a wavelet-based {{method of identification}} modal parameter and damage detection in a free vibration response. An algorithm for modal parameter identification and damage detection is purposed and complex Morlet wavelet is chosen as an analysis wavelet function. This paper only focuses on identification of natural frequencies of the structural system. The method utilizes both undamaged and <b>damage</b> experiment <b>data</b> <b>of</b> free vibration response of the truss structure system. Wavelet scalogram is utilizes for damage detection. The change of energy components for undamaged and damage structure is investigated from the plot of wavelet scalogram which corresponded to the detection <b>of</b> <b>damage...</b>|$|R
5000|$|In some cases, {{data on a}} {{hard disk}} drive can be {{unreadable}} due to damage to the partition table or file system, or to (intermittent) media errors. In {{the majority of these}} cases, at least a portion <b>of</b> the original <b>data</b> can be recovered by repairing the damaged partition table or file system using specialized data recovery software such as Testdisk; software like dd rescue can image media despite intermittent errors, and image raw data when there is partition table or file system <b>damage.</b> This type <b>of</b> <b>data</b> recovery can be performed by people without expertise in drive hardware as it requires no special physical equipment or access to platters.|$|R
40|$|The Natural Hazards Research Centre makes exten-sive use of GIS in {{determining}} {{the relationship between a}} hazard event and the damage caused by the event. With the assistance of the Australian Insurance Industry we have compiled extensive databases detailing the type, extent and location <b>of</b> <b>damage</b> claims for damage to domestic buildings. Some of the research to date is based on overseas experience and may not truly represent the Australian experience. One of our research aims is to produce loss curves for building damage relevant to the Australian experience. This requires intensive analysis <b>of</b> <b>damage</b> <b>data,</b> which would not be possible without GIS to provide the spatial framework for damage assessment...|$|R
40|$|<b>Damage</b> <b>data</b> <b>of</b> Hanshin-Awaji {{earthquake}} {{is collected}} in a 3 dimensional spatial and temporal Geographic Information System (4 D-GIS) to analyzed features of disaster. It become clear after experimental apply of GIS in local government (Nagata-ku Cobe city) that under confused condition of destructed area, address information is not useful enough to determine positions. Coordinate expression of spatial positions are necessary. GIS for disaster management which is able to use ordinary task in local government and methods to make spatial database and update through daily work is also mentioned...|$|R
40|$|The key {{material}} of high-speed train gearbox shells is high-strength aluminum alloy. Material damage is inevitable {{in the process}} of servicing. It is of great importance to study material damage for in-service gearboxes of high-speed train. Structural health monitoring methods have been widely used to study material damage in recent years. This study focuses on the application of an acoustic emission (AE) method to quantify tensile <b>damage</b> evolution <b>of</b> high-strength aluminum alloy. First, a characteristic parameter was developed to connect AE signals with tensile damage. Second, a tensile damage quantification model was presented based on the relationship between AE counts and tensile behavior to study elastic deformation <b>of</b> tensile <b>damage.</b> Then tensile tests with AE monitoring were employed to collect AE signals and tensile <b>damage</b> <b>data</b> <b>of</b> nine samples. The experimental data were used to quantify tensile <b>damage</b> <b>of</b> high-strength aluminum alloy A 356 to demonstrate the effectiveness of the proposed method...|$|R
40|$|This paper {{presents}} {{the design of}} DataCube, a P 2 P data persistent platform. This platform exploits the properties of cluster-based peer-to-peer structured overlays altogether with a hybrid redundancy schema (a compound of light replication and rateless erasure coding) to guarantee durable access and integrity <b>of</b> <b>data</b> despite adversarial attacks. In particular, the recovery <b>of</b> <b>damaged</b> <b>data</b> is achieved through the retrieval of the minimum number of coded blocks: coded blocks are selectively retrieved and their integrity is checked on the y. An analysis validates DataCube principles design. Specically, the triptych "availability - storage overhead - bandwidth usage" is evaluated, and results show that despite massive attacks and high churn, DataCube performs remarkably well...|$|R
40|$|Abstract Cloud {{computing}} {{has gained}} significant traction for recent years. It {{is a form}} of distributed computing whereby resources and application platform are shared over the internet through on demand and pay on utilization basis. Several companies have already built Internet consumer services such as search engine, use of some websites to communicate with other user in websites, E-mail services, and services to purchase items online that use cloud computing infrastructure. However this technology suffers from threats and vulnerabilities that prevent the users from trusting it. The occurrence of these threats may result into <b>damaging</b> <b>of</b> confidential <b>data</b> in cloud environment. This survey paper aims to analyze the various unresolved security threats in cloud computing which are affecting the various stake-holders linked to it. It also describes {{the pros and cons of}} the existing security strategy and also introduces the existing issues in cloud computing such as data integrity, data segregation, and security and so on. Keywords:- Cloud computing, data integrity, segregation and security, PaaS, IaaS, SaaS, and Denial of service attack. 1...|$|R
2500|$|Self-healing NTFS: In {{previous}} Windows versions, NTFS {{marked the}} volume [...] "dirty" [...] upon detecting file-system corruption and CHKDSK {{was required to}} be run by taking the volume [...] "offline". With self-healing NTFS, an NTFS worker thread is spawned in the background which performs a localized fix-up <b>of</b> <b>damaged</b> <b>data</b> structures, with only the corrupted files/folders remaining unavailable without locking out the entire volume. The self-healing behavior can be turned on for a volume with the fsutil repair set C: 1 command where C presents the volume letter.|$|R
40|$|The paper {{describes}} <b>damage</b> assessment <b>of</b> structural components such as {{wall and}} column in a masonry infilled house {{due to a}} tsunami, assessing the <b>damage</b> <b>data</b> <b>of</b> structures in the south coast of Java due to the 2006 Giant Earthquake and Tsunami. The effect of wave loads with failure mode of subject structural components was verified, inversely computing the dominant parameter 2 ̆ 7 α 2 ̆ 7 representing the amplification of tsunami wave pressure against a structural component. It was found that its crack mode might occur when parameter α takes the value ranging from 4 to 5, and that major failure mode such as collapse or shear crack might occur although parameter a takes more than 3 dependent upon tsunami affection...|$|R
40|$|Abstract. This paper {{presents}} a wavelet-based {{method of identification}} modal parameter and damage detection in a free vibration response. An algorithm for modal parameter identification and damage detection is purposed and complex Morlet wavelet is chosen as an analysis wavelet function. This paper only focuses on identification of natural frequencies of the structural system. The method utilizes both undamaged and <b>damage</b> experiment <b>data</b> <b>of</b> free vibration response of the truss structure system. Wavelet scalogram is utilizes for damage detection. The change of energy components for undamaged and damage structure is investigated from the plot of wavelet scalogram which corresponded to the detection <b>of</b> <b>damage...</b>|$|R
30|$|In this work, we have {{considered}} normalized displacement <b>data</b> <b>of</b> the first mode of a cantilever beam for training ε-SVM in regression problem. This approach needs only <b>damaged</b> state <b>data</b> <b>of</b> the structure (beam). Finite element (FE) {{analysis of the}} beam is {{carried out in the}} FE package ABAQUS® (ABAQUS Inc., Providence, RI, USA). The damages are simulated at 12 different damage locations, and 12 damage intensities at each location are considered in this study. The efficiency of SVM is examined by adding noise levels of 30 to 80 dB in steps of 10 dB to the original data.|$|R
40|$|This paper {{describes}} a methodology for the documentation {{and analysis of}} historical buildings. Techniques of digital image processing give the possibility to detect damages, such as moisture or biological changes, on surfaces <b>of</b> monuments. Intensity <b>data</b> obtained from laser scanner equipment and colour information gathered with a digital camera were evaluated for damage identification that affects the materials used in several historical buildings, such as granitic rock. Then, digital image processing was used to identify damages over granitic rock in a nondestructive way; in particular, classification methods were applied. Several unsupervised classification algorithms were analyzed. The output data were classified images showing the different kind <b>of</b> <b>damages</b> that affect the granitic rock. Post-analysis <b>of</b> these <b>data</b> allow obtaining thematic maps with the size and position <b>of</b> <b>damages.</b> The <b>data</b> and first results that were obtained to date are described below. 1...|$|R
40|$|Achievement of {{an optimal}} {{improvement}} in signal-to-noise ratio from image averaging techniques depends crucially {{on the assumption}} that all members of the set of images to be averaged are fundamentally alike. In HREM of biological macromolecules, this assumption may be invalid for such reasons as variations in viewing geometry, non-uniformity of staining, or structural perturbations caused by specimen preparation procedures or radiation <b>damage.</b> Inclusion <b>of</b> <b>data</b> that are compromized by these or other factors will degrade the information content of the averaged image. Here we present an algorithm which provides an objective quantitative method for the identification and elimination of anomalous members of a set of pre-aligned images. Based on a statistical criterion of mutual consistency, the algorithm forms an ordered list in which the individual images are ranked from most to least reliable. On specification of the noise statistics- in the formulation given here, of stationary white noise- an acceptability threshold in this ordered list is imposed. The derivation and implementation of this algorithm are presented, its properties discussed, and its application illustrated using both real and model electron micrograph data. 1...|$|R
40|$|Agriculture (DoA) {{undertook}} {{to identify and}} pro secute {{those responsible for the}} physical <b>damage</b> and loss <b>of</b> <b>data</b> and the abuse of officials. The DoA said “[We have] always {{been at the forefront of}} pro moting agricultural development and growth in the Bicol region. We support conventional, modern and organic farming as means of achieving food sufficiency and sustainability. We are committed to providing Filipinos 1 ”Efforts to lift completely the shadow of death cast by vitamin A deficiency [...] . in some places still entail a struggle against intractable opposition. The victims who continue to suffer under the shadow are mainly the children. 1 ” Golden Rice: a long-running story at the watershed of the GM debat...|$|R
40|$|Phase clocks are {{synchronization}} {{tools that}} implement {{a form of}} logical time in distributed systems. For systems tolerating transient faults by self-repair <b>of</b> <b>damaged</b> <b>data,</b> phase clocks can enable reasoning about the progress of distributed repair procedures. This paper presents a phase clock algorithm suited to the model of transient memory faults in asynchronous systems with read/write registers. The algorithm is self-stabilizing and guarantees accuracy of phase clocks within O(k) time following an initial state that is k-faulty. Composition theorems show how the algorithm {{can be used for}} the timing of distributed procedures that repair system outputs. Comment: 22 pages, LaTe...|$|R
5000|$|In Windows {{versions}} {{prior to}} Windows Vista, if {{the operating system}} detected corruption in the file system of an NTFS volume, it marked the volume [...] "dirty"; to correct errors on the volume, {{it had to be}} taken offline. With self-healing NTFS, an NTFS worker thread is spawned in the background which performs a localized fix-up <b>of</b> <b>damaged</b> <b>data</b> structures, with only the corrupted files/folders remaining unavailable without locking out the entire volume and needing the server to be taken down. The operating system now features S.M.A.R.T. detection techniques to help determine when a hard disk may fail.|$|R
40|$|RAID {{architectures}} {{have been}} used {{for more than two decades}} to recover data upon disk failures. Disk failure is just one of the many causes <b>of</b> <b>damaged</b> <b>data.</b> Data can be damaged by virus attacks, user errors, defective software/firmware, hardware faults, and site failures. The risk of these types <b>of</b> <b>data</b> <b>damage</b> is far greater than disk failure with today’s mature disk technology and networked information services. It has therefore become increasingly important for today’s disk array to be able to recover data to any point in time when such a failure occurs. This paper presents a new disk array architecture that provides Timely Recovery to Any Point-in-time, referred to as TRAP-Array. TRAP-Array stores not only the data stripe upon a write to the array, but also the time-stamped Exclusive-ORs of successiv...|$|R
40|$|Forensic {{clinical}} anatomy {{is a new}} {{practical application}} of the discipline of Clinical Anatomy for ascertaining and evaluating medicolegal questions. In particular, individual anatomy (normal anatomy, anatomical variations, age-, disease-, or surgery-related modifications) can acquire significant relevance in various fields of legal medicine such as child abuse, sudden death, medical responsibility and/or liability, personal injury and <b>damage.</b> Anatomical <b>data</b> <b>of</b> forensic interest frequently arise from the correct application of methods of ascertainment; anatomical methods may then be required for further comprehensive analysis. The rigorous interpretation <b>of</b> anatomical <b>data,</b> derived from the ascertainment phase and analyzed {{on the basis of}} pertinent literature, can be pivotal for the correct application of evaluation criteria in various forensic contexts. Clin. Anat., 2016. © 2016 Wiley Periodicals, Inc...|$|R
40|$|For {{the first}} time, the {{communities}} of birds of the anthropogenous inhabitation places of Subarctic have been studied; the summer population of birds of the destructed territories have been studied, the laws of formation have been revealed. The obtained data are necessary {{for the evaluation of}} the populations and communities of birds of Subarctic state under the conditions of the economic run in of the region, its protection. The recommendations on protection of species and communities of the birds, the methodological bases <b>of</b> evaluation <b>of</b> <b>damage,</b> the <b>data</b> base have been developedAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|This paper {{researches}} and {{summarizes the}} state of the art concerning the reliability analysis of hull structures under the influence of corrosion and fatigue damage. It is found through a literature survey that the objects of hull structure reliability analyses have gradually transferred from the design phase to the in-service phase of hull structures. Furthermore, the research focus develops from the single influence of corrosion and fatigue damage to its interaction effect. In the future, the key points of hull structure reliability studies will focus on the following four aspects: 1) research into the influence <b>of</b> pitting corrosion <b>damage</b> on hull structure failure mechanisms and corresponding evaluation methods; 2) research into hull structure failure mechanisms under the interaction of corrosion and fatigue damage; 3) presenting a reliability evaluation method that can overcome excessive reliance on sample data, and establishing a hull structure reliability analysis model based on the <b>damage</b> testing <b>data</b> <b>of</b> real ships; and 4) establishing a database on the corrosion and fatigue <b>damage</b> <b>of</b> real ships under different service environments and periods...|$|R
5000|$|Problems {{involving}} metadata {{in litigation}} in the United States are becoming widespread. Courts {{have looked at}} various questions involving metadata, including the discoverability of metadata by parties. Although the Federal Rules of Civil Procedure have only specified rules about electronic documents, subsequent case law has elaborated on the requirement of parties to reveal metadata. In October 2009, the Arizona Supreme Court has ruled that metadata records are public record. Document metadata have proven particularly important in legal environments in which litigation has requested metadata, which can include sensitive information detrimental to a certain party in court. Using metadata removal tools to [...] "clean" [...] or redact documents can mitigate the risks of unwittingly sending sensitive data. This process partially (see data remanence) protects law firms from potentially <b>damaging</b> leaking <b>of</b> sensitive <b>data</b> through electronic discovery.|$|R
40|$|As {{organizations}} {{increase their}} adoption of database systems as one <b>of</b> their key <b>data</b> management technologies {{for the daily}} operations and decision makings, the security <b>of</b> <b>data</b> managed by these systems becomes crucial. <b>Damage</b> and misuse <b>of</b> <b>data</b> affect not only a single user or application, but may have effect the entire organization. The recent rapid proliferations of web-based applications with database at its backend have further increased the risk of database exposure to the outside world. There are many recent reports on intrusion from external hackers which compromised the database system. However, there are also insiders who abuse their privileges and access the database system for many intentions. For that reason, it is imperative for us to secure database system from both external and internal attacks. This paper describes on database security threats and the existing works {{that had been done}} to mitigate these problems. One of possible solutions is by using Intrusion Detection System (IDS). For that reason, this study proposed a novel SQL Injections and Insider Misuse Detection System (SIIMDS) to provide higher level of security for database system...|$|R
