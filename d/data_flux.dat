27|1805|Public
40|$|A novel device able {{to perform}} a {{real-time}} recognition of a temporal stream of optical bits at the communication wavelength of 1550 nm is presented. First experimentation with byte streams at 2. 5 Gbit/s coming from a standard transmission line shows the capability of the device to produce the recognition optical signal in a PRBS continuous <b>data</b> <b>flux...</b>|$|E
40|$|This note {{describes}} {{a proposal for}} the Level- 0 Decision Unit (L 0 DU) of LHCb. The aim of this unit is to collect information from all the Level- 0 subtriggers (calorimeter, muon and pile-up systems) and to combine it to take a decision every 25 ns {{in order to allow}} to reduce the <b>data</b> <b>flux</b> up to 1 MHz for the next trigger level...|$|E
30|$|The {{resolution}} method {{proposed for}} this kind of problem is an algorithm of inverse modeling whose objective is reservoir characterization by the integration of dynamic data in stochastic modeling using direct sequential simulation (DSS) and co-simulation as a convergent process of global and regional perturbation of the permeability images. This algorithm allows obtaining a spatial distribution of the reservoir permeability which respects both static data (variogram and histogram of permeability distribution in the stochastic model) and dynamic <b>data</b> (<b>flux</b> in the observations boreholes).|$|E
40|$|Scientific {{workflow}} {{systems have}} become a necessary tool for many applications, enabling the composition and execution of complex analysis. CO(2) <b>flux</b> <b>data</b> observed by eddy covariance technique is large in quantity and the procedure of <b>flux</b> <b>data</b> is complex, scientific workflow technique plays {{a very important role}} in the sharing, reusing and automatic calculation of <b>flux</b> <b>data</b> processing method. In this paper, we discuss the feasibility and validity of applying scientific workflow technique to <b>flux</b> <b>data</b> processing and make a tentative approach to construct a scientific workflow system for CO(2) <b>flux</b> <b>data</b> processing by taking Kepler scientific workflow system as the development platform. CO(2) <b>flux</b> <b>data</b> of Changbai Mountain in 2003 is used to verify the scientific workflow system. The results show that scientific workflow system for CO(2) <b>flux</b> <b>data</b> processing can solve many problems of too much multifarious calculation, inconsistent development platform and complicated procedure in <b>flux</b> <b>data</b> processing. This approach indicates that the scientific workflow system applied to CO(2) <b>flux</b> <b>data</b> processing can provide an automatic calculation platform for <b>flux</b> <b>data</b> processing and prompt the communication and sharing of international <b>flux</b> <b>data</b> processing method, which make it easier for scientists to focus on their research and not computation management...|$|R
50|$|New {{observation}} techniques using satellites has necessitated the recording, {{processing and}} accessible storage of high <b>data</b> <b>fluxes</b> {{over long periods}} of time. This demanding task is performed by a data processing group, which has grown quickly in the last decade. Special data centers were established for the large satellite projects.|$|R
40|$|The {{energy balance}} of eddy {{covariance}} (EC) <b>flux</b> <b>data</b> is normally not closed. Therefore, {{at least if}} used for modelling, EC <b>flux</b> <b>data</b> are usually post-closed, i. e. the measured turbulent fluxes are adjusted so as to close the energy balance. At {{the current state of}} knowledge, however, {{it is not clear how}} to partition the missing energy in the right way. Eddy <b>flux</b> <b>data</b> therefore contain some uncertainty due to the unknown nature of the energy balance gap, which should be considered in model evaluation and the interpretation of simulation results. We propose to construct the post-closure methods uncertainty band (PUB), which essentially designates the differences between non-adjusted <b>flux</b> <b>data</b> and <b>flux</b> <b>data</b> adjusted with the three post-closure methods (Bowen ratio, latent heat flux (LE) and sensible heat flux (H) method). To demonstrate this approach, simulations with the NOAH-MP land surface model were evaluated based on EC measurements conducted at a winter wheat stand in southwest Germany in 2011, and the performance of the Jarvis and Ball–Berry stomatal resistance scheme was compared. The width of the PUB of the LE was up to 110 W m − 2 (21 % of net radiation). Our study shows that it is crucial to account for the uncertainty in EC <b>flux</b> <b>data</b> originating from lacking energy balance closure. Working with only a single post-closing method might result in severe misinterpretations in model–data comparisons...|$|R
40|$|Gaia is {{the most}} ambitious space {{astrometry}} mission currently envisaged and is a technological challenge in all its aspects. We describe a proposal for the payload data handling system of Gaia, {{as an example of}} a high-performance, real-time, concurrent, and pipelined data system. This proposal includes the front-end systems for the instrumentation, the data acquisition and management modules, the star data processing modules, and the payload data handling unit. We also review other payload and service module elements and we illustrate a <b>data</b> <b>flux</b> proposal...|$|E
40|$|This paper {{presents}} a new control model, ideal for teleoperation, which {{takes into account}} the problems arising with heavily delayed communicating systems. This is done {{with the help of a}} general purpose neural network and a specific dedicated training structure which is able to train the network and to minimize the network errors due to convergence problems. The principal aim of this model is to give more stability to the <b>data</b> <b>flux</b> reducing the uncertainties due to a variable delay present in the communication suppor...|$|E
40|$|Plasma and {{magnetic}} field data from ISEE 1 and 2 are examined for 5 passes of the magnetopause region at 20 and 40 deg northern latitudes, and {{are presented in}} terms of moments of the distribution function, calculated from two-dimensional or three-dimensional <b>data.</b> <b>Flux</b> transfer events are characterized by a mixture of magnetosheath and magnetospheric particles, which supports the hypothesis that flux transfer events represent encounters of reconnected flux tubes. An excess pressure appears to be balanced by the tension of the ambient magnetic field lines as they are draped around the reconnected flux tube, and the different observed magnetic field signatures are consistent with expectations for encounters of the flux tubes at different relative locations. It is suggested that increased flow speeds are caused by continued reconnection at the low-latitude boundaries of the flux tubes...|$|E
40|$|Japanese Ocean <b>Flux</b> <b>data</b> sets with Use of Remote sensing Observations (J-OFURO) {{includes}} {{various kinds}} of satellite data sets related to ocean surface flux and is provided for research people {{on the web site}} ([URL]) and anonymous ftp site. Recently we extended the data period for several kinds of data included in J-OFURO. We introduce the new J-OFURO latent heat <b>flux</b> <b>data</b> and some results using new J-OFURO turbulent heat <b>flux</b> <b>data</b> in this pape...|$|R
30|$|This is {{the domain}} of systems biology [12]. Systems biology {{provides}} in silico models that incorporate biological <b>data,</b> metabolic <b>flux</b> <b>data</b> and different physico-chemical constraints such as the conservation of mass and energy, thermodynamics, redox balance, etc. [12] and thus provides an opportunity to identify the bottlenecks hidden in a complex network of interactions and cellular compartmentation [13].|$|R
40|$|We review {{uncertainty}} quantification (UQ) for hyperbolic {{systems of}} conservation (balance) laws. The input uncertainty {{could be in}} the initial <b>data,</b> <b>fluxes,</b> coefficients, source terms or boundary conditions. We focus on forward UQ or uncertainty propagation and review deterministic methods such as stochastic Galerkin and stochastic collocation finite volume methods for approximating random (field) entropy solutions. Statistical sampling methods of the Monte Carlo and multilevel Monte Carlo (MLMC) type are also described. We present alternative UQ frameworks such as measure-valued solutions and statistical solutions. © 2017 Elsevier B. V...|$|R
40|$|ABSTRACT {{the best}} {{simulation}} {{of the data}} giving the desired param-Because they are objective and reproducible, inverse modeling eter set. The best-fit condition is reached by minimizing procedures are increasingly used to identify model parameters that an objective function, which expresses the discrepancy cannot be easily measured. This study investigated the feasibility of between the experimental data and the simulation. Inusing inverse methods to estimate parameters describing macropore verse modeling procedures are thus objective, reproducflow, transport, and transformation processes in the dual-permeability model MACRO. MACRO {{was linked to the}} inverse modeling package SUFI, and we used numerically generated data representing transient leaching experiments for tracers and reactive solutes in microlysime-ters (21 -cm height). Attention was focused on parameter sensitivity, availability of experimental <b>data</b> (<b>flux</b> and resident concentrations), the degree of macropore flow in the system, and the significance of experimental errors. Reliable results were obtained in the case of ible, and unambiguous, providing the problem is well posed (i. e., the solution exists, is unique, and depend...|$|E
40|$|In {{the present}} work several optical network {{functionalities}} based on Semiconduc-tor Optical Amplifiers (SOA) are investigated {{by means of}} numerical simulations. An optical network has the function of connecting two or more optical links through a network node. Although in the transmission paths the <b>data</b> <b>flux</b> is all-optical, in the network nodes much of the signal switching/processing has been implemented through electronic circuits whose speed is {{much lower than the}} speed of optics. One of the challenges of the present work was to propose novel all-optical network func-tions to substitute electronic signal processing in order to avoid a bottleneck in the network nodes. In this context, several network functionalities have been proposed and theoreti-cally investigated in the present work. In the beginning of the work, Optical Time-Division Multiplexing (OTDM) technology was considered to be a potential solution to future-generation optical networks. Therefore, the simulation environment devel-oped was first envisaged to deal with OTDM signals. In this context an existin...|$|E
40|$|This paper {{introduces}} a Maximum Likelihood (ML) approach for estimating the statistical parameters {{required for the}} covariance matrices used in the solution of Bayesian inverse problems aimed at estimating surface fluxes of atmospheric trace gases. The method offers an objective methodology for populating the covariance matrices required in Bayesian inversions, thereby resulting in better estimates of the uncertainty associated with derived fluxes and minimizing the risk of inversions being biased by unrealistic covariance parameters. In addition, a method is presented for estimating the uncertainty associated with these covariance parameters. The ML method is demonstrated using a typical inversion setup with 22 flux regions and 75 observation stations from the National Oceanic and Atmospheric Administration-Climate Monitoring and Diagnostics Laboratory (NOAA-CMDL) Cooperative Air Sampling Network with available monthly averaged carbon dioxide <b>data.</b> <b>Flux</b> regions and observation locations are binned according to various characteristics, and the variances of the model-data mismatch and of the errors associated with the a priori flux distribution are estimated from the available dat...|$|E
40|$|Abstract Background The {{quantification}} of metabolic fluxes {{is gaining}} increasing {{importance in the}} analysis of the metabolic behavior of biological systems such as organisms, tissues or cells. Various methodologies (wetlab or drylab) result in sets of fluxes which require an appropriate visualization for interpretation by scientists. The visualization of flux distributions is a necessary prerequisite for intuitive <b>flux</b> <b>data</b> exploration in the context of metabolic networks. Results We present FluxMap, a tool for the advanced visualization and exploration of <b>flux</b> <b>data</b> in the context of metabolic networks. The template-based <b>flux</b> <b>data</b> import assigns <b>flux</b> values and optional quality parameters (e. g. the confidence interval) to biochemical reactions. It supports the discrimination between mass and substance fluxes, such as C- or N-fluxes. After import, <b>flux</b> <b>data</b> mapping and network-based visualization allow the interactive exploration of the dataset. Various visualization options enable the user to adapt layout and network representation according to individual purposes. Conclusions The Vanted add-on FluxMap comprises a comprehensive set of functionalities for visualization and advanced visual exploration of flux distributions in biological networks. It is available as a Java open source tool from [URL]...|$|R
5000|$|Methods and {{apparatus}} for deriving thermal <b>flux</b> <b>data</b> {{for processing}} a workpiece ...|$|R
40|$|The {{process of}} quality control of micrometeorological {{and carbon dioxide}} (CO 2) <b>flux</b> <b>data</b> can be {{subjective}} and may lack repeatability, which would undermine the results of many studies. Multivariate statistical methods and time series analysis were used together and independently to detect and replace outliers in CO 2 <b>flux</b> <b>data</b> derived from a Bowen ratio energy balance system...|$|R
40|$|Methanosarcina acetivorans strain C 2 A is {{a marine}} methanogenic archaeon notable for its {{substrate}} utilization, genetic tractability, and novel energy conservation mechanisms. To help probe {{the implications of}} this organism’s unique metabolism, we have constructed and manually curated a genome-scale metabolic model, iMB 744, accounting for 744 of the 4540 predicted protein coding genes (16 %) in the M. acetivorans genome. The reconstruction effort has identified key knowledge gaps and differences in the peripheral metabolism and central metabolism between methanogenic species. Using flux balance analysis, the model quantitatively predicts wild type phenotypes and is 96 % accurate in knockout lethality predictions compared to currently available experimental <b>data.</b> <b>Flux</b> balance analysis was used to probe the mechanisms and energetics of byproduct formation and growth on carbon monoxide, {{and the nature of the}} reaction catalyzed by the soluble heterodisulfide reductase HdrABC in M. acetivorans. This work highlights the great utility of constraint-based modeling for identifying feasible solutions to biological questions and provides insights into the workings of the cell at the genome scale...|$|E
40|$|Abstract. Paper {{presents}} a transputerised multi-microprocessor acquisition and processing system, which provides {{the implementation of}} the control algorithm in Carthesian coordinates of the position of contour path robots. This based on real-time digital processing of the Jacobian matrix obtained from direct kinematics model, respectively of the inverse Jacobian matrix for close loop control of the position on six degrees of freedom. There is presented the method of computation in real time of the inverse Jacobian matrix, topology of transputers networks and the <b>data</b> <b>flux</b> corresponding to implementation of the multi-microprocessor system for path control of industrial robots. There are also analysed methods for improving performances of the transputerised multiprocessor system for position control of the robot on six axis of freedom with the goal of reducing the execution time. Key Words: real-time digital processing, position of contour path robots, multi-microprocessor system, transputers networks. Data acquisition system on real time for robot position control it needs flexibility, accuracy, high-speed processing and feed-back control. Flexibility of the robot can be improved if the target generated in the environmen...|$|E
40|$|Approved {{for public}} release; {{distribution}} unlimited. This study {{consists of the}} development of a computer program to numerically solve the space and energy dependent multigroup neutron diffusion equations in a bare homogeneous fast reactor core or reactor material assembly. The resulting program is unique in that it was designed for future use by Naval Postgraduate School students undertaking experimental studies in neutron diffusion with limited time to determine numerical solutions for verification of their results. The equations are solved iteratively in cylindrical geometry using a point successive overrelaxation technique. Convergence between - 6 successive iterations was less than 10 after fifty iterations. The program was tested using ANL three group <b>data.</b> <b>Flux</b> shapes and energy spectra were determined for a typical fast reactor core and for a solid iron cylinder with a source at its center. The program was also used to determine criticality. Computation times were from one to ten minutes with less than 15 OK words of core storage using the IBM 360 / 67. [URL] United States Nav...|$|E
40|$|At present, using Eddy Covariance (EC) {{method to}} {{estimate}} the "true value" of carbon sequestration in terrestrial ecosystem arrests more attention. However, one issue is how to solve the uncertainty of observations (especially the nighttime CO 2 <b>flux</b> <b>data)</b> appearing in post-processing CO 2 <b>flux</b> <b>data.</b> The ratio of effective and reliable nighttime EC CO 2 <b>flux</b> <b>data</b> to all nighttime data is relatively low (commonly, less than 50 %) for all the long-term and continuous observation stations in the world. Thus, the processing method of nighttime CO 2 <b>flux</b> <b>data</b> and its effect analysis on estimating CO 2 flux annual sums are very important. In this paper, the authors analyze and discuss the reasons for underestimating nighttime CO 2 flux using EC method, and introduce the general theory and method for processing nighttime CO 2 <b>flux</b> <b>data.</b> By analyzing the relationship between nighttime CO 2 flux and air fraction velocity u(.), we present an alternate method, Average Values Test (AVT), to determine the thresholds of fraction velocity (u(c) (.)) for screening the effective nighttime CO 2 <b>flux</b> <b>data.</b> Meanwhile, taking the data observed in Yucheng and Changbai Mountains stations for an example, we analyze and discuss the effects of different methods or parameters on nighttime CO 2 flux estimations. Finally, based on the data of part ChinaFLUX stations and related literatures, empirical models of nighttime respiration at different sites in ChinaFLUX are summarized...|$|R
40|$|Standardised, quality-controlled {{and robust}} <b>data</b> from <b>flux</b> {{networks}} underpin {{the understanding of}} ecosystem processes and tools necessary to support the management of natural resources, including water, carbon and nutrients for environmental and production benefits. The Australian regional flux network (OzFlux) currently has 23 active sites and aims to provide a continental-scale national research facility to monitor and assess Australia's terrestrial biosphere and climate for improved predictions. Given the need for standardised and effective <b>data</b> processing of <b>flux</b> <b>data,</b> we have developed a software suite, called the Dynamic INtegrated Gap-filling and partitioning for OzFlux (DINGO), that enables gap-filling and partitioning of the primary fluxes into ecosystem respiration (Fre) and gross primary productivity (GPP) and subsequently provides diagnostics and results. We outline the processing pathways and methodologies that are applied in DINGO (v 13) to OzFlux data, including (1) gap-filling of meteorological and other drivers; (2) gap-filling of fluxes using artificial neural networks; (3) the u * threshold determination; (4) partitioning into ecosystem respiration and gross primary productivity; (5) random, model and u * uncertainties; and (6) diagnostic, footprint calculation, summary and results outputs. DINGO was developed for Australian data, but the framework is applicable to any <b>flux</b> <b>data</b> or regional network. Quality data from robust systems like DINGO ensure the utility and uptake of the <b>flux</b> <b>data</b> and facilitates synergies between flux, remote sensing and modelling...|$|R
40|$|This work aims at obtaining high {{resolution}} NOx and PM 10 emissions from road traffic at hot-spots in Madrid (Spain). For that, 12 1 -hour representative scenarios are simulated with the traffic microsimulation model VISSIM. Measured traffic <b>data</b> (<b>fluxes</b> and fleet composition) {{are used as}} input for the model to obtain speed-time profiles for each vehicle. These profiles are used to predict representative emission factors for different vehicle classes in the VERSIT+micro model through the ENVIVER interface. Emission factors are compared with the ones of COPERT 4, a widely used average-speed model, as a preliminary model assessment. The results are strongly influenced by low average speeds due to saturated traffic situations...|$|R
40|$|A set of {{guidelines}} for evaluation of air-sea heat, freshwater and momentum flux datasets is developed {{in response to a}} recommendation of the CLIVAR Global Synthesis and Observation Panel (GSOP). The panel recognised the need for such guidelines in order to facilitate consistent evaluation and intercomparison of the many new flux datasets currently being developed (particularly those from ocean reanalyses). Our approach is to develop guidelines based on the use of both research quality data from flux buoys and research vessels (local evaluation) and large scale constraints (regional, global evaluation). The different evaluation techniques are discussed with reference to recent examples from the research literature. The document is not intended to be an exhaustive review of all methods for flux evaluation but rather to outline the main techniques that should be employed {{in order to meet the}} CLIVAR GSOP recommendation. CLIVAR GSOP Recommendation 28 (ICPO, 2005) : Ocean Reanalysis fluxes: All future ocean reanalysis fluxes should be evaluated against research quality <b>data</b> (<b>flux</b> buoys, research vessels), in addition to large scale constraints (e. g. heat transport), to determine whether reanalysis has led to improvements (individual reanalysis groups) ...|$|E
40|$|The {{next-generation}} of all-sky EAS detector {{will be able}} {{to lower}} the threshold below the TeV region and will provide a huge <b>data</b> <b>flux,</b> due to the large detecting area and the high duty cycle. In this paper we discuss in detail the possibility of using this detector in order to study the cosmic ray spectrum in the TeV region. The peculiarities of this class of next-generation detectors will make it possible to study the energy profile in the region where direct measurements are available with a large statistical significance. In such a way the measurement obtained by an indirect technique can be fully overlapped with direct measurement data, in order not only to study the cosmic ray spectrum but also to investigate the reliability of the full Monte Carlo simulation process. The sensitivity of such a measurement is also discussed and the data taking time required for a significative measurement is estimated. A standard chi-square fit and a Bayesian unfolding procedure are applied in order to obtain a measurement of the spectral index of the incoming primaries. (C) 2004 Elsevier B. V. All rights reserved...|$|E
40|$|The CCD {{magnitudes}} in Johnson V and Cousins R and I photometric passbands {{are determined}} for GRB 000301 C afterglow starting ~ 1. 5 {{day after the}} gamma-ray burst. In fact we provide the earliest optical observations for this burst. Light curves of the afterglow emissions in U, B, V, R, I, J and K' passbands are obtained by combining the present measurements with the published <b>data.</b> <b>Flux</b> decay shows a very uncommon variation relative to other well observed GRBs. Overall, there is a steepening of the optical and near-infrared flux decay caused by a geometric and sideways expanding jet. This is superimposed by a short term variability especially during early time (Delta t 20 keV indicates, if isotropic,> = 10 ^ 53 ergs of release of energy. The enormous amount of released energy will be reduced, if the radiation is beamed which {{is the case for}} this event. Using a jet break time of 7. 6 days, we infer a jet opening angle of ~ 0. 15 radian. This means the energy released is reduced by a factor of ~ 90 relative to the isotropic value. Comment: LaTeX file, 11 pages including 4 figures, uses psfig. sty, Bull. Astron. Society of India(accepted, Sept, 2000 issue...|$|E
5000|$|Modification of the IEDA EarthChem {{database}} to include volcanic gas composition and gas <b>flux</b> <b>data</b> ...|$|R
40|$|This work aims {{to obtain}} high {{resolution}} NOx and PM 10 emissions related to traffic activity at a hot-spot in Madrid (Spain). For that, twelve representative scenarios for a heavily trafficked roundabout are simulated with the traffic microsimulation model VISSIM. Measured traffic <b>data</b> (<b>fluxes</b> and fleet composition) {{are used as}} input for the model to obtain speed-time profiles for each vehicle. These profiles are used to predict representative emission factors for different vehicle classes in the VERSIT+micro model, through the ENVIVER interface. The emission factors are compared with the ones of COPERT IV, a widely used average-speed model, as a preliminary model assessment. The results are strongly influenced by low average speeds due to saturated traffic situations...|$|R
40|$|The scaling {{behaviours}} of {{the monthly}} solar neutrino <b>flux</b> <b>data</b> from (1) SAGE detector {{during the period from}} 1 st January 1990 to 31 st December 2000; (2) SAGE detector during the period from April 1998 to December 2001; (3) GALLEX detector during the period from May 1991 to January 1997; (4) GNO detector during the period from May 1998 to December 2001; (5) GALLEX-GNO detector (combined data) from May 1991 to December 2001 and (6) average of the data from GNO and SAGE detectors during the period from May 1998 to December 2001 are analysed. In the present analysis the monthly solar neutrino <b>flux</b> <b>data</b> in each case is processed through finite variance scaling method in order to find the corresponding Hurst exponent. The study reveals that the monthly solar neutrino <b>flux</b> <b>data</b> in 1), 3), 4), 5) and 6) exhibit anti-persistent behaviour (or, negative autocorrelation) and has underlying trends while the monthly solar neutrino <b>flux</b> <b>data</b> in 2) shows the nature of a long memory process. Comment: 10 pages including 6 figure...|$|R
40|$|Actinobacillus succinogenes, a gram-negative bacterium, is one {{the most}} {{promising}} natural producers of succinate. This chemical has been well established as a bio-based chemical platform to produce bulk chemicals (e. g. 1, 4 -butanediol) and other biomaterials, but {{the costs associated with}} the bioproduction of succinate are still discouraging. One of the reasons is that succinate is often produced together with other fermentative products like formate, acetate and ethanol under anaerobic conditions, which reduces the cost-effectiveness of this fermentative bioprocess 1. Systems biology approaches may be required to provide valuable insights into the metabolism underlying the homofermentative production of succinate and contribute to new developments in the bio-based production of succinate 2. A genome-scale model of the metabolism of A. succinogenes, accounting for 500 genes, 930 reactions, and 690 metabolites, was reconstructed and validated against published experimental <b>data.</b> <b>Flux</b> Balance Analysis and Flux Variability Analysis were used to investigate flux distributions within the metabolic network. A thorough model-driven analysis was performed to explore the metabolism under hetero- and homo-fermentative conditions. The model provided valuable insights into the metabolism of this bacterium and has the potential to predict the phenotypes of perturbed metabolic networks that promote the homo-fermentative production of succinate. This work was supported by BRIGIT (FP 7 project) and PEM co-funded by the ERDF under the Operational Programme for Competitiveness Factors (COMPETE) ...|$|E
40|$|Darcy’s law {{is applied}} to {{describe}} the steady flow processes in which the flux remains constant with time along the conducting system. Due to the dispersion and migration of colloidal particles and lodging in the soil pores the reduction in hydraulic conductivity occurs with time in particular when the soil and the percolating solution are affected by electrolyte concentration. Hence, {{the aim of this}} study is to find empirical equations that can be used to predict the flux with time. Data for the effluent volume versus time (up to 6 hours) which was collected for three soils (located at Quevedo-Los Rios region) treated by two salt solutions (5 and 50 meq/l) with different SAR values were used to test certain mathematical forms of equations. Only four empirical equations were found to perfectly fit the <b>data</b> (<b>flux</b> vs time) whereas, fitting the calculated and measured data of the hydraulic conductivity for all soils produced regression factors R 2 ? 0. 99. So, these equations can be applied to predict the hydraulic conductivity and to characterize the flow process at saturated conditions of the studied soils with great confidence. The Hoerl function model was the best of all equations for application as the fitting degrees were almost perfect for all studied soils at 5 and 50 meq/l. It was observed for all equations that one of the fitting parameters would always represent the initial hydraulic conductivity (Kos) that was evaluated graphically at zero time by extrapolation. Universidad Técnica Estatal De Quevedo[URL]...|$|E
40|$|We {{present an}} {{analysis}} of the early, rising light curves of 18 Type Ia supernovae (SNe Ia) discovered by the Palomar Transient Factory (PTF) and the La Silla-QUEST variability survey (LSQ). We fit these early <b>data</b> <b>flux</b> using a simple power-law (f(t) = α× t^n) to determine the time of first light (t_ 0), and hence the rise-time (t_rise) from first light to peak luminosity, and the exponent of the power-law rise (n). We find a mean uncorrected rise time of 18. 98 ± 0. 54 days, with individual SN rise-times ranging from 15. 98 to 24. 7 days. The exponent n shows significant departures from the simple 'fireball model' of n = 2 (or f(t) ∝ t^ 2) usually assumed in the literature. With a mean value of n = 2. 44 ± 0. 13, our data also show significant diversity from event to event. This deviation has implications for the distribution of 56 Ni throughout the SN ejecta, with a higher index suggesting a lesser degree of 56 Ni mixing. The range of n found also confirms that the 56 Ni distribution is not standard throughout the population of SNe Ia, in agreement with earlier work measuring such abundances through spectral modelling. We also show that the duration of the very early light curve, before the luminosity has reached half of its maximal value, does not correlate with the light curve shape or stretch used to standardise SNe Ia in cosmological applications. This has implications for the cosmological fitting of SN Ia light curves. Comment: 19 pages, 19 figures, accepted for publication in MNRA...|$|E
40|$|International audienceMany {{research}} {{topics in}} the fields of condensed matter and the life sciences are based on small-angle X-ray and neutron scattering techniques. With the current rapid progress in source brilliance and detector technology, high <b>data</b> <b>fluxes</b> of ever-increasing quality are produced. In order to exploit such a huge quantity of data and richness of information, wider and more sophisticated approaches to data analysis are needed. Presented here is GENFIT, a new software tool able to fit small-angle scattering data of randomly oriented macromolecular or nanosized systems according to a wide list of models, including form and structure factors. Batches of curves can be analysed simultaneously in terms of common fitting parameters or by expressing the model parameters via physical or phenomenological link functions. The models can also be combined, enabling the user to describe complex heterogeneous system...|$|R
40|$|As {{part of the}} Canadian Northern Wetlands Study (NOWES) {{measurements}} of methane flux were made at the Kinosheo Lake tower site for a 1 -month period during the 1990 summer intensive. The measurements were made with a diode-laser-based methane sensor using the eddy correlation technique. Measurements of the methane fluxes were made at two levels, 5 or 18 m. Approximately 900 half-hour average methane flux measurements were obtained. Weak temporal and diurnal trends were observed in the <b>data.</b> <b>Fluxes</b> averaged over the study period showed an overall methane emission of 16 mg CH 4 m(exp - 2) /d with a daytime average of 20 mg CH 4 m(exp - 2) /d and a nighttime average of 9 mg CH 4 m(exp - 2) /d. The effect of emission footprint {{was evident in the}} data. A strong relationship between the daily average methane flux and wet bog temperature at 20 -cm depth was observed...|$|R
40|$|The {{representation}} of subgrid-scale surface heterogeneities in numerical weather and climate models {{has been a}} challenging problem {{for more than a}} decade. The Evaporation at Grid and Pixel Scale (EVA-GRIPS) project adds to the numerous studies on vegetation-atmosphere interaction processes through a comprehensive field campaign and through simulation studies with land surface schemes and mesoscale models. The mixture of surface types in the test area in eastern Germany is typical for larger parts of northern Central Europe. The spatial scale considered corresponds to the grid scale of a regional atmospheric weather prediction or climate model and to the pixel scale of satellite images. Area-averaged fluxes derived from point measurements, scintillometer measurements, and a helicopter-borne turbulence probe were widely consistent with respect to the sensible heat flux. The latent heat flux from the scintillometer measurements is systematically higher than the eddy covariance <b>data.</b> <b>Fluxes</b> derived from numerical simulations proved the so-called mosaic approach to be an appropriate parameterization for subgrid heterogeneity...|$|R
