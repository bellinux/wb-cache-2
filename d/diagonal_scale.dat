17|158|Public
6000|$|... 1506. Similar {{experiments}} {{to those in}} air (1485. 1493.) were made in different gases, the results of which I will describe as briefly as possible. The apparatus is represented fig. 131, consisting of a bell-glass eleven inches in diameter at the widest part, and ten {{and a half inches}} high up {{to the bottom of the}} neck. The balls are lettered, as in fig. 130, and are in the same relation to each other; but A and B were on separate sliding wires, which, however, were generally joined by a cross wire, w, above, and that connected with the brass conductor, which received its positive or negative charge from the machine. The rods of A and B were graduated at the part moving through the stuffing-box, so that the application of a <b>diagonal</b> <b>scale</b> applied there, told what was the distance between these balls and those beneath them. As to the position of the balls in the jar, and their relation to each other, C and D were three and a quarter inches apart, their height above the pump plate five inches, and the distance between any of the balls and the glass of the jar one inch and three quarters at least, and generally more. The balls A and D were two inches in diameter, as before (1493.); the balls B and C only 0.15 of an inch in diameter.|$|E
6000|$|... 1493. These results, though {{indicative}} of very striking and peculiar {{relations of the}} electric force or forces, do not show the relative degrees of charge which the small ball acquires before discharge occurs, i.e. they do not tell whether it acquires a higher condition in the negative, or in the positive state, immediately preceding that discharge. To illustrate this important point I arranged two places of discharge as represented, fig 130. A and D are brass balls 2 inches diameter, B and C are smaller brass balls 0.25 of an inch in diameter; the forks L and R supporting them were of brass wire 0.2 of an inch in diameter; {{the space between the}} large and small ball on the same fork was 5 inches, that the two places of discharge n and o might be sufficiently removed from each other's influence. The fork L was connected with a projecting cylindrical conductor, which could be rendered positive or negative at pleasure, by an electrical machine, and the fork R was attached to another conductor, but thrown into an uninsulated state by connection with a discharging train (292.). The two intervals or places of discharge n and o could be varied at pleasure, their extent being measured by the occasional introduction of a <b>diagonal</b> <b>scale.</b> It is evident, that, as the balls A and B connected with the same conductor are always charged at once, and that discharge may take place to either of the balls connected with the discharging train, the intervals of discharge n and o may be properly compared to each other, as respects the influence of large and small balls when charged positively and negatively in air.|$|E
50|$|<b>Diagonal</b> <b>scale</b> {{is used in}} {{engineering}} to read lengths with higher accuarcy as it represents a unit into three different multiple in metres, centimeters and millimeters. <b>Diagonal</b> <b>scale</b> {{is an important part}} in Engineering drawings.|$|E
3000|$|Preconditioning {{strategies}} are unchanged (Béchet et al. pre-conditioner [21] with X-FEM and <b>diagonal</b> <b>scaling</b> with shifted enrichment), [...]...|$|R
40|$|The Preconditioned Conjugate Gradient method (PCG) is an {{iterative}} method used to solve linear systems of equations Ax=b, were A {{is often a}} large and sparse matrix. In the PCG method, <b>diagonal</b> <b>scaling</b> (Jacobi scaling) {{may be used to}} precondition the Matrix A so that the method converges in fewer iteration steps than the conventional conjugate gradient method. <b>Diagonal</b> <b>scaling</b> is carried out by using the diagonal of A as a preconditioner at each conjugate gradient iteration step. This project proposes a novel approach using an evolutionary algorithm to evolve different diagonal matrices to precondition the Matrix A at each iteration step. The evolutionary algorithm proceeds by applying computational crossover and mutation operators to generate a small population of matrices. The diagonal matrix resulting in the lowest relative residual in the population (higher fitness) is selected to pre-condition the Matrix A for the next iteration. Subsequently, a new generation of diagonal matrices will compete to become the preconditioner for the following iteration. This process continues for the number of iteration steps defined by the PCG Method. Results from conventional <b>diagonal</b> <b>scaled</b> PCG method will be compared with the evolutionary algorithm based <b>diagonal</b> <b>scaled</b> PCG method...|$|R
40|$|This paper {{discusses}} mathematical {{properties of}} preconditioned finite-element matrices based on vector potential formulation (A method) and vector and scalar potential formulation (A-V method) for eddy-current problems. Numerical {{results show that}} A-V method with preconditioning is stable at all frequencies in contrast to A method. In this paper, this property is mathematically discussed by con-sidering the <b>diagonal</b> <b>scaling</b> {{which is one of}} the simple preconditioning methods. In addition, regularization of A method is discussed. Index Terms—A-V method, <b>diagonal</b> <b>scaling,</b> edge elements, finite-element method, preconditioning. I...|$|R
5000|$|... #Caption: This is the {{location}} of the <b>diagonal</b> <b>scale</b> on the square.|$|E
5000|$|... #Caption: The <b>diagonal</b> <b>scale</b> {{gives the}} diagonal, or the hypotenuse, for the {{different}} legs of the triangle for which a brace is to be cut.|$|E
5000|$|<b>Diagonal</b> <b>scale</b> {{follows the}} {{principle}} of similar triangles where a short length is divided into number of parts in which sides are proportional.Divided into required number of equal parts ...|$|E
40|$|Abstract. Constrained stress majorization is a {{promising}} new technique for integrating application specific layout constraints into forcedirected graph layout. We significantly improve {{the speed and}} convergence properties of the constrained stress-majorization technique for graph layout by employing a <b>diagonal</b> <b>scaling</b> of the stress function. <b>Diagonal</b> <b>scaling</b> requires the active-set quadratic programming solver used in the projection step to be extended to handle separation constraints with scaled variables, i. e. of the form siyi + gij ≤ sjyj. The changes, although relatively small, are quite subtle and explained in detail...|$|R
40|$|Abstract. Bounds are {{developed}} for the condition number of the linear system resulting from the finite element discretization of an anisotropic diffusion problem with arbitrary meshes. These bounds are shown to depend on three major factors: a factor representing the base order corresponding to the condition number for a uniform mesh, a factor representing {{the effects of the}} mesh M-nonuniformity (mesh nonuniformity in the metric tensor defined by the diffusion matrix), and a factor representing the effects of the mesh volumenonuniformity. <b>Diagonal</b> <b>scaling</b> for the finite element linear system and its effects on the conditioning are studied. It is shown that a properly chosen <b>diagonal</b> <b>scaling</b> can eliminate the effects of the mesh volume-nonuniformity and reduce the effects of the mesh M-nouniformity on the conditioning of the stiffness matrix. In particular, the bound after a proper <b>diagonal</b> <b>scaling</b> depends only on a volume-weighted average (instead of the maximum for the unscaled case) of a quantity measuring the mesh M-nonuniformity. Bounds on the extreme eigenvalues of the stiffness and mass matrices are also investigated. Numerical examples are presented to verify the theoretical findings. 4...|$|R
40|$|The linear systems {{associated}} with large, sparse, symmetric, positive definite matrices are often solved iteratively using the preconditioned conjugate gradient method. We {{have developed a}} new class of preconditioners, support tree preconditioners, that are based on the connectivity of the graphs corresponding to the matrices and are well-structured for parallel implementation. In this paper, we evaluate the performance of support tree preconditioners by comparing them against two common types of preconditioners: <b>diagonal</b> <b>scaling,</b> and incomplete Cholesky. Support tree preconditioners require less overall storage and less work per iteration than incomplete Cholesky preconditioners. In terms of total execution time, support tree preconditioners outperform both <b>diagonal</b> <b>scaling</b> and incomplete Cholesky preconditioners. ...|$|R
5000|$|<b>Diagonal</b> <b>scale</b> {{is derived}} from the Latin word Diagonalis. The Latin word was {{originally}} coined from the Greek word diagōnios where dia means [...] "through" [...] and gonios denotes [...] "corners".|$|E
50|$|<b>Diagonal</b> <b>scale</b> is an {{engineering}} measuring instrument which {{is composed of}} a set of parallel straight lines which are obliquely crossed by another set of straight lines. Diagonal scales are used to measure small fractions of the unit of measurement.|$|E
50|$|Combinations {{of three}} dimensions, or spatial pulls, become diagonals; {{extremes}} of far reach space that crisscross the body's center from {{one corner of}} an imaginary Cube to the opposite corner. Laban devised the <b>Diagonal</b> <b>Scale</b> to explore these extremes of personal space.|$|E
50|$|The von Kries {{coefficient}} law {{compensates for}} the illumination change using a purely <b>diagonal</b> <b>scaling</b> of the cone absorptions. While {{the law does}} not provide a precise indication of the correction, it typically provides a reasonable approximation.|$|R
30|$|Since matrix W is linear, it {{will not}} be able to {{identify}} the nonlinear blocks. However, we will see that it is able to identify matrix H to within a <b>diagonal</b> <b>scaling</b> matrix if the inputs are Zero-mean and independent.|$|R
40|$|Abstract. Scaling is a {{commonly}} used technique for standard eigenvalue problems {{to improve the}} sensitivity of the eigenvalues. In this paper we investigate scaling for generalized and polynomial eigenvalue problems (PEPs) of arbitrary degree. It is shown that an optimal <b>diagonal</b> <b>scaling</b> of a PEP with respect to an eigenvalue can be described by the ratio of its normwise and componentwise condition number. Furthermore, the effect of linearization on optimally scaled polynomials is investi-gated. We introduce a generalization of the <b>diagonal</b> <b>scaling</b> by Lemonnier and Van Dooren to PEPs that is especially effective if some information about the magnitude of the wanted eigenvalues is available and also discuss variable transformations of the type λ = αµ for PEPs of arbitrary degree...|$|R
50|$|Knee bracing is {{a common}} feature in timber framing to prevent racking under lateral loads. The <b>diagonal</b> <b>scale</b> is useful for {{determining}} {{the length of the}} a knee brace desired for a given distance from the joint between the bost and beam.|$|E
50|$|A and B are entered on the {{horizontal}} and vertical scales, {{and the result is}} read from the <b>diagonal</b> <b>scale.</b> Being proportional to the harmonic mean of A and B, this formula has several applications. For example, it is the parallel-resistance formula in electronics, and the thin-lens equation in optics.|$|E
50|$|The wider arm, {{two inches}} wide, {{is called the}} blade; the {{narrower}} arm, {{one and a half}} inches wide, the tongue. The square has many uses, including laying out common rafters, hip rafters and stairs. It has a <b>diagonal</b> <b>scale,</b> board foot scale and an octagonal scale. On the newer framing squares there are degree conversions for different pitches and fractional equivalents.|$|E
40|$|To improve {{conditioning}} of matrices {{arising from}} the FE solution to Biot's consolidation equations, we investigate a number of scaling algorithms, inclucting simple <b>diagonal</b> <b>scaling,</b> modified scaling by the selection of appropriate non-diagonal factors, and a scaling minimizing {{the sum of the}} squares of the logarithms of the matrix entries. Results from 2 D and 3 D large size examples show that preliminary scaling may play a basic role in accelerating the convergence of projection solvers such as Bi-CGSTAB and TFQMR...|$|R
40|$|Garcia, S. Instituto de Matemáticas y Física, Universidad de Talca, Casilla 721, Talca, ChileAbstract Incremental unknowns are {{efficient}} in the numerical solution of elliptic linear differential equations but no rigorous theoretical justification was available. Hereafter, we establish that the condition {{number of the}} incremental unknowns matrix associated to the Laplace operator is O(1 /h 02) O((log h) 2) where h 0 is the mesh size of the coarsest grid and where h is the mesh size of the finest grid. Furthermore, if block <b>diagonal</b> <b>scaling</b> is used then the condition number of the preconditioned incremental unknowns matrix associated to the Laplace operator comes out to be O((log h) 2); last, we observe that block <b>diagonal</b> <b>scaling</b> by the Laplace operator (scaled by h 02) on the coarsest grid and by 4 I on the fine grids appears as an acceptable alternative...|$|R
3000|$|Then the {{operator}} A is bounded and coercive and {{an application of}} the Lax-Milgram lemma implies {{the existence of the}} unique solution for any f ∈ H^- 1 ([...] 0, 1) [...]. Further, we prove that a diagonally scaled wavelet basis is a Riesz basis when it is scaled with the proposed <b>diagonal</b> <b>scaling.</b>|$|R
5000|$|Coggeshall first {{described}} this apparatus {{in a paper}} he released in London titled, [...] "Timber-measure by a line of more ease, dispatch and exactness, then any other way now in use, by a double scale : after the countrey-measure, by the length and quarter of the circumference in round timber, and by the length and side of the square in squared timber, and square equal in flat timber : as also stone-measure and gauging of vessels by the same near and exact way, likewise a <b>diagonal</b> <b>scale</b> of 100 parts in {{a quarter of an}} inch, very easie both to make and use." ...|$|E
3000|$|Use the {{elements}} of the <b>diagonal</b> <b>scale</b> matrix S in (23). The function for computing the error for the case of a given scale matrix S is the following: [...]...|$|E
3000|$|Based on the {{software}} and the fabricating method, automatic hammering nanolithography was put forward, and an example for generating diamond was represented in the following. The diamond pattern was designed in Figure[*] 3 a; according to the matching program, the tip hammered the film surface after moving 2 μm {{from the center of}} the scan field to create a diamond with a <b>diagonal</b> <b>scale</b> of 4 μm. The matching C program was listed as the following: [...]...|$|E
40|$|We extend two {{fundamental}} properties of positive linear time-invariant (LTI) systems to homogeneous cooperative systems. Specifically, we demonstrate that such systems are D-stable, meaning that global asymptotic stability is preserved under <b>diagonal</b> <b>scaling.</b> We {{also show that}} a delayed homogeneous cooperative system is globally asymptotically stable (GAS) for any non-negative delay {{if and only if}} the system is GAS for zero delay...|$|R
30|$|One {{can show}} that BFGS–GCR always converges for SPD {{matrices}} which are mainly discussed in the present study: First, the residual norm in the flexible GCR always becomes small at each GCR iteration with SPD matrices, and therefore the flexible GCR always converges (Hayami and Sugihara 2004). Second, if the initial Hessian matrix is SPD, the BFGS update always provides SPD Hessian matrices (Nocedal and Wright 1999). Both the <b>diagonal</b> <b>scaling</b> and SSOR provide SPD preconditioning matrices if the original coefficient matrices are SPD (Kushida 2015). Therefore, the Hessian matrices {{in this study are}} also SPD within SPD problems. Finally, precenditioned matrices with SPD preconditioning matrices are also SPD (Kushida 2015). With those points, BFGS–GCR always converges with the <b>diagonal</b> <b>scaling</b> and SSOR within SPD problems although the preconditioning matrices vary at each restart point. In addition, as discussed in this section, the BFGS preconditioning provides a better approximation as the BFGS step continues. Consequently, BFGS–GCR converges faster than the preconditioned GCR.|$|R
40|$|In {{this paper}} we will adapt a known method for <b>diagonal</b> <b>scaling</b> of {{symmetric}} positive definite tridiagonal matrices towards the semiseparable case. Based {{on the fact}} that a symmetric, positive definite tridiagonal matrix T satisfies property A, one can easily construct a diagonal matrix (D) over cap such that (D) over capT (D) over cap has the lowest condition number over all matrices DTD, for any choice of diagonal matrix D. Knowing that semiseparable matrices are the inverses of tridiagonal matrices, one can derive similar properties for semiseparable matrices. Here, we will construct the optimal <b>diagonal</b> <b>scaling</b> of a semiseparable matrix, based on a new inversion formula for semiseparable matrices. Some numerical experiments are performed. In a first experiment we compare the condition numbers of the semiseparable matrices before and after the scaling. In a second numerical experiment we compare the scalability of matrices coming from the reduction to semiseparable form and matrices coming from the reduction to tridiagonal form. status: publishe...|$|R
40|$|Usually direct {{methods are}} {{employed}} for {{the solution of}} linear systems arising {{in the context of}} optimization. However, motivated by the potential of multiscale refinement schemes for large problems of dynamic state estimation, we investigate in this paper the application of iterative solvers based on concepts developed in Ref. 1. Specifically, we explore the effect of different system reductions for various Krylov-space iteration methods as well as three concepts of preconditioning. The first one is the normalization of states and outputs, which also favors error analysis. Secondly, <b>diagonal,</b> <b>scale</b> dependent preconditioners are compared. They all bound the condition numbers independently of the refinement scale, but exhibit significant quantitative differences. Finally, the effect of the regularization parameter on the condition and iteration numbers is analyzed. It turns out that a so called simpli ed Uzawa scheme with Jacobi preconditioning and suitable regularization parameter is most efficient. However, the experiments also reveal that further improvements are necessary...|$|E
40|$|Perturbative QCD {{predictions}} that are truncated at fixed order have an unphysical {{dependence on the}} renormalisation procedure. We investigate two methods of avoiding scale and scheme dependence in QCD predictions of physical observables: the Effective Charges (ECH) method and the Principle of Minimal Sensitivity (PMS). The ECH method is used to avoid the renormalisation scale and scheme dependence of fixed-order predictions of event shape moments. Values of αs(MZ) are extracted from e+e− data using both ECH and the physical scale method in the MS scheme. The ECH method at NLO is found to perform better than standard MS perturbation theory (MS PT) when applied to means of event shapes. However ECH at NNLO functions less well than at NLO, and the ECH method also fails to describe data for higher moments of event shapes. Pad ́e Approximant methods are used to estimate missing higher orders in the perturbative expansions, a technique that works especially well for MS PT applied to the higher moments. We also {{examine the effect of}} adding non-perturbative power corrections to the perturbative approximations. It is found that power corrections are insufficient to counteract the undesirable behaviour of ECH at NNLO. The PMS method is used to provide predictions of the b ̄b and tt ̄total cross-sections at the Tevatron and the LHC. Hadronic cross-sections depend on the factorisation scale as well as the renormalisation scale. PMS is applied by searching for stationary points on the cross-section surface in the space of the two scales. The PMS method predicts substantially larger b ̄b cross-sections than using standard <b>diagonal</b> <b>scale</b> choices. For tt ̄ production, however, there is very little difference observed between the two methods. Both produce {{predictions that}} are in good agreement with the current experimental data. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|This paper studies {{a variant}} of the Additive Average Schwarz {{algorithm}} [1] where the coarse space consists of two subspaces. This approach results in a simpler and more parallel algorithm while we retain the essential convergence properties of the original method. Our theory is confirmed by numerical experiments showing that the new algorithm is often superior to the original variant. 1 Introduction In [1] two additive Schwarz algorithms were described and analyzed. The first, called the Additive <b>Diagonal</b> <b>Scaling</b> method, used a <b>diagonal</b> <b>scaling</b> derived from a coarse space V Γ 1 (see below), combined with the classical coarse space V c 0. This method was not robust when the jumps in the coefficients of the PDE could be arbitrarily distributed across subdomains. The second method, called the Additive Average Schwarz method, was proven robust, but uses a potentially expensive coarse space V avg 0 = Range(IA) with I Au = ae u(x); x 2 @Ω ih ¯ u i; x 2 Ω ih; [...] ...|$|R
30|$|In {{order to}} check the {{feasibility}} of the BFGS preconditioners, we investigate the convergence rate of the GCR with conventional preconditioners and the BFGS preconditoners. In the current studies, the <b>diagonal</b> <b>scaling</b> and the SSOR are employed as conventional preconditioners, and the BFGS and the L-BFGS are newly developed preconditioners. In the cases of BFGS and L-BFGS, the choice of initial Hessian matrices remains an issue. In the current studies, the <b>diagonal</b> <b>scaling</b> preconditioner is employed as an initial Hessian matrix for the BFGS and the L-BFGS, and the SSOR preconditioner is employed for the L-BFGS as well. In addition, {{in the case of}} the L-BFGS, we must determine m, which is the number of previous iterations to be taken into consideration. Unfortunately, with our best knowledge, there is no obvious rule on the choice of m even for the L-BFGS as a nonlinear equation solver. Therefore, we investigate the convergence rate with various m i.e. m = 3, 5, 7, and 10. The algorithms of each preconditioner are given in the “Methods” section in this article.|$|R
40|$|Abstract — The {{class of}} robust {{stability}} problems considered involves structured, repeated, linear time-varying, induced ℓ∞-norm bounded perturbations. A well known sufficient condition for these robust problems {{follows from the}} scaled small gain theorem and is stated {{in the form of}} a scaled ℓ 1 -norm minimization problem with block <b>diagonal</b> <b>scaling</b> matrices. A procedure reducing the domain in the search for an optimal scaling matrix, while preserving global optimality, is presented here. I...|$|R
40|$|AbstractWe give a {{constructive}} {{proof of a}} theorem of Marshall and Olkin that any real symmetric positive definite matrix can be symmetrically scaled by a positive diagonal matrix to have arbitrary positive row sums. We give a slight extension of the result, showing that given a sign pattern, there is a unique <b>diagonal</b> <b>scaling</b> with that sign pattern, and we give {{upper and lower bounds}} on the entries of the scaling matrix...|$|R
