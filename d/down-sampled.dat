263|318|Public
5000|$|... #Caption: 3. Edge points interpolated, then {{anti-aliased}} and <b>down-sampled</b> ...|$|E
50|$|The output image {{should be}} {{nearly to the}} {{original}} image when it is smoothed or <b>down-sampled.</b>|$|E
50|$|Full-scene {{anti-aliasing}} by super-sampling {{usually means}} that each full frame is rendered at double (2x) or quadruple (4x) the display resolution, and then <b>down-sampled</b> {{to match the}} display resolution. Thus, a 2x FSAA would render 4 super-sampled pixels for each single pixel of each frame. Rendering at larger resolutions will produce better results; however, more processor power is needed, which can degrade performance and frame rate. Sometimes FSAA is implemented in hardware {{in such a way}} that a graphical application is unaware the images are being super-sampled and then <b>down-sampled</b> before being displayed.|$|E
40|$|Abstract—Subpixel-based <b>down-sampling</b> is {{a method}} that can {{potentially}} improve apparent resolution of a down-scaled image on LCD by controlling individual subpixels rather than pixels. However, the increased luminance resolution comes at price of chrominance distortion. A major challenge is to suppress color fringing artifacts while maintaining sharpness. We propose a new subpixel-based <b>down-sampling</b> pattern called diagonal direct subpixel-based <b>down-sampling</b> (DDSD) for which we design a 2 -D image reconstruction model. Then, we formulate subpixel-based <b>down-sampling</b> as a MMSE problem and derive the optimal solution called {{minimum mean square error}} for subpixel-based <b>down-sampling</b> (MMSE-SD). Unfortunately, straightfor-ward implementation of MMSE-SD is computational intensive. We thus prove that the solution is equivalent to a 2 -D linear filter followed by DDSD, which is much simpler. We further reduce computational complexity using a small k × k filter to approximate the much larger MMSE-SD filter. To compare the performances of pixel and subpixel-based <b>down-sampling</b> methods, we propose two novel objective measures: normalized l 1 high frequency energy for apparent luminance sharpness and PSNRU(V) for chrominance distortion. Simulation results show that both MMSE-SD and MMSE-SD(k) can give sharper images compared with conventional <b>down-sampling</b> methods, with little color fringing artifacts. Index Terms—Color fringing, image <b>down-sampling,</b> subpixel rendering. I...|$|R
40|$|To {{sustainably}} {{address these}} high computational complexities, this research proposes a low complexity {{and a highly}} transparent watermarking technique for real-time hardware accelerated spatial scalable video streaming. In achieving this goal, two contributions are discussed here. The ﬁrst contribution puts forward a real-time high resolution <b>down-sampling</b> algorithm on many-core processor for spatial scalable video coding. This contribution analyses the principal architecture of a serial <b>down-sampling</b> algorithm in the Joint-Scalable-Video-Model (JSVM) reference software and identify its performance limitations for spatial scalability. Then, a parallel multi-core <b>down-sampling</b> algorithm is studied as benchmark. Experimental results for this algorithm using an 8 -core processor exhibits performance speedup of 5. 25 × in <b>down-sampling</b> a QXGA video resolution into three lower resolution layers (i. e., Full-HD, HD and quarter-HD) ...|$|R
30|$|<b>Down-sample</b> {{the audio}} signal to 10  kHz.|$|R
50|$|In first step, {{learn the}} {{relationship}} between the high resolution image and their smoothed and <b>down-sampled.</b> In second step, model the residue between an original high resolution and the reconstructed high-resolution image after applying learned lineal model by a non-parametric Markov network to capture the high-frequency content of faces.|$|E
50|$|This {{decomposition}} {{is repeated}} to further increase the frequency resolution and the approximation coefficients decomposed with {{high and low}} pass filters and then <b>down-sampled.</b> This is represented as a binary tree with nodes representing a sub-space with a different time-frequency localisation. The tree {{is known as a}} filter bank.|$|E
50|$|In general, super-sampling is a {{technique}} of collecting data points at a greater resolution (usually by a power of two) than the final data resolution. These data points are then combined (<b>down-sampled)</b> to the desired resolution, often just by a simple average. The combined data points have less visible aliasing artifacts (or moiré patterns).|$|E
30|$|It {{cannot be}} {{approximated}} by interpolation or <b>down-sampling.</b>|$|R
30|$|We {{followed}} some preprocessing to {{get better}} simulated image sequences. Firstly, while previously release score database [29] used nearest neighbor interpolation, we used area interpolation implemented in OpenCV [55] for more appropriate <b>down-sampling</b> simulation. As for a silhouette sequence, since the area interpolation induces gray-scale values other than binary values (e.g., background or foreground), we applied thresholding to keep it binary a silhouette image sequence after <b>down-sampling.</b> Moreover, because the boundary of <b>down-sampling</b> by the area interpolation (e.g., pixels whose horizontal or vertical position is a multiple of k for <b>down-sampling</b> with factors of 1 /k) does not necessarily coincide with the bottom of foot or {{the top of the}} head, we randomly shift-up/down the boundary of <b>down-sampling</b> for each subject in order to better simulate the walking position differences among subjects. More specifically, we generated a random number for each subject to shift the silhouette image sequences up or down such that the top of the subject’s head or the bottom parts of their feet are not moved outside the image. The entire silhouette image sequence for each subject was then shifted up/down using the set value, and the same process was applied to each subject.|$|R
40|$|A single sensor {{digital camera}} needs demosaicing to {{reconstruct}} a full color image. To show the high resolution {{image on the}} lower resolution display, it must then be downsampled. Demosaicing and <b>down-sampling</b> are the two steps that influence each other. First is, the color fringing artifacts present in demosaicing may be appear larger in subsequent <b>down-sampling</b> process. On the other hand, the detail removed during the <b>down-sampling</b> cannot be recovered in the demosaicing. So, {{it is very important}} to consider the demosaicing and <b>down-sampling</b> process simultaneously. In this paper, demosaicing and <b>down-sampling</b> are integrated together for single sensor bayer images using bicubic method, due to which the computational complexity is significantly reduced. The bicubic method is directly applied in Bayer domain, without the process of demosaicing. This method uses all its surrounding neighbor pixels to calculate the interpolated value so as to maintain the detail of the image. Simulation results demonstrate that, the proposed method achieves superior performance improvement in terms of computational complexity. As for visual quality, this proposed method is more effective in preserving high frequency details which leads to much sharper and clearer results...|$|R
50|$|Residual-excited linear {{prediction}} (RELP) is an obsolete speech coding algorithm. It {{was originally}} {{proposed in the}} 1970s and {{can be seen as}} an ancestor of code-excited linear prediction (CELP). Unlike CELP however, RELP directly transmits the residual signal. To achieve lower rates, that residual signal is usually <b>down-sampled</b> (e.g. to 1 - 2 kHz). The algorithm is hardly used anymore in audio transmission.|$|E
50|$|For a quick {{demonstration}} {{of how a}} texel can be missing from a filtered texture, here's a list of numbers representing the centers of boxes from an 8-texel-wide texture (in red and black), intermingled with the numbers from the centers of boxes from a 3-texel-wide <b>down-sampled</b> texture (in blue). The red numbers represent texels {{that would not be}} used in calculating the 3-texel texture at all.|$|E
50|$|HDCAM, {{introduced}} in 1997, is a high-definition video digital recording videocassette version of digital Betacam, using an 8-bit discrete cosine transform (DCT) compressed 3:1:1 recording, in 1080i-compatible <b>down-sampled</b> resolution of 1440&times;1080, and adding 24p and 23.976 progressive segmented frame (PsF) modes to later models. The HDCAM codec uses rectangular pixels {{and as such}} the recorded 1440&times;1080 content is upsampled to 1920&times;1080 on playback. The recorded video bit rate is 144 Mbit/s. Audio is also similar, with four channels of AES3 20-bit, 48 kHz digital audio.|$|E
5000|$|... #Caption: 2. Anti-aliased by {{blurring}} and <b>down-sampling</b> by {{a factor}} of five ...|$|R
40|$|A {{vectorized}} rebinning (<b>down-sampling)</b> algorithm, {{applicable to}} N-dimensional data sets, {{has been developed}} that offers {{a significant reduction in}} computer run time when compared to conventional rebinning algorithms. For clarity, a two-dimensional version of the algorithm is discussed to illustrate some specific details of the algorithm content, and using the language of image processing, 2 D data will be referred to as "images," and each value in an image as a "pixel. " The new approach is fully vectorized, i. e., the <b>down-sampling</b> procedure is done as a single step over all image rows, and then as a single step over all image columns. Data rebinning (or <b>down-sampling)</b> is a procedure that uses a discretely sampled N-dimensional data set to create a representation of the same data, but with fewer discrete samples. Such data <b>down-sampling</b> is fundamental to digital signal processing, e. g., for data compression applications...|$|R
5000|$|Pure <b>down-sampling</b> of {{an image}} has the {{following}} effect (viewing at full-scale is recommended): ...|$|R
5000|$|Finally, [...] "Budding Turbines" [...] is so regular that {{systematic}} (Moiré) aliasing {{can clearly}} be seen near the main [...] "turbine axis" [...] {{when it is}} downsized by taking the nearest pixel. The aliasing in the first image appears random because it comes from all levels of detail, below the pixel size. When the lower level aliasing is suppressed, to make the third image and then that is <b>down-sampled</b> once more, without anti-aliasing, to make the fifth image, the order {{on the scale of}} the third image appears as systematic aliasing in the fifth image.|$|E
50|$|Because fractals have {{unlimited}} {{detail and}} no noise other than arithmetic round-off error, they illustrate aliasing {{more clearly than}} do photographs or other measured data. The escape times, which are converted to colours at the exact centres of the pixels, go to infinity at {{the border of the}} set, so colours from centres near borders are unpredictable, due to aliasing. This example has edges in about half of its pixels, so it shows much aliasing. The first image is uploaded at its original sampling rate. (Since most modern software anti-aliases, one may have to download the full-size version to see all of the aliasing.) The second image is calculated at five times the sampling rate and <b>down-sampled</b> with anti-aliasing. Assuming that one would really like something like the average colour over each pixel, this one is getting closer. It is clearly more orderly than the first.|$|E
50|$|Games ported to PAL have {{historically}} been known for having game speed and frame rates inferior to their NTSC counterparts. Since the NTSC standard is 60 fields/30 frames per second but PAL is 50 fields/25 frames per second, games were typically slowed by approximately 16.7% {{in order to avoid}} timing problems or unfeasible code changes. FMV rendered and encoded at 30 frames per second by the Japanese/US (NTSC) developers was often <b>down-sampled</b> to 25 frames per second for PAL release—usually by means of 3:2 pull-down, resulting in motion judder. In addition to this, PAL's increased resolution was not utilised during conversion, creating a pseudo letterbox effect with borders top and bottom, leaving the graphics with a slightly squashed look due to an incorrect aspect ratio caused by the borders. This was especially prevalent during previous generations when 2D graphics were used almost exclusively. The gameplay of many games with an emphasis on speed, such as the original Sonic The Hedgehog for the Mega Drive, suffered in their PAL incarnations.|$|E
40|$|We {{integrate}} the recently proposed spatial transformer network (SPN) [Jaderberg et. al 2015] into a recurrent neural network (RNN) {{to form an}} RNN-SPN model. We use the RNN-SPN to classify digits in cluttered MNIST sequences. The proposed model achieves a single digit error of 1. 5 % compared to 2. 9 % for a convolutional networks and 2. 0 % for convolutional networks with SPN layers. The SPN outputs a zoomed, rotated and skewed version of the input image. We investigate different <b>down-sampling</b> factors (ratio of pixel in input and output) for the SPN and show that the RNN-SPN model is able to <b>down-sample</b> the input images without deteriorating performance. The <b>down-sampling</b> in RNN-SPN {{can be thought of}} as adaptive <b>down-sampling</b> that minimizes the information loss in the regions of interest. We attribute the superior performance of the RNN-SPN to the fact that it can attend to a sequence of regions of interest...|$|R
30|$|Resampling: {{conducting}} <b>down-sampling</b> to 11, 025 Hz {{and then}} upsampling back to 44, 100 Hz.|$|R
30|$|Before {{the second}} time-frequency {{analysis}} is executed, we extracted the centroid curve, which {{is close to}} the speed signal of the human body to a certain extent. <b>Down-sampling</b> is adopted to obtain a sampling frequency down to 10 Hz, which also satisfies the Nyquist sampling theorem. If the sampling frequency of the second time-frequency analysis does not undergo <b>down-sampling,</b> the final time-frequency diagram will exhibit serious distortion.|$|R
30|$|Step 8 : The {{residual}} error is <b>down-sampled</b> by two using cubic spline interpolation technique and three-level discrete wavelet transform using Biorthogonal wavelet (Bior 4.4) {{is applied to}} the <b>down-sampled</b> residual signal.|$|E
30|$|Re-sampling: The {{watermarked}} signal, originally sampled at 44.1  kHz, is <b>down-sampled</b> to 22.05, 11.025, and 6  kHz.|$|E
40|$|Abstract—Current {{image coding}} schemes {{make it hard}} to utilize {{external}} images for compression even if highly correlated images {{can be found in the}} cloud. To solve this problem, we propose a method of cloud-based image coding that is different from current image coding even on the ground. It no longer compresses images pixel by pixel and instead tries to describe images and reconstruct them from a large-scale image database via the descriptions. First, we describe an input image based on its <b>down-sampled</b> version and local feature descriptors. The descriptors are used to retrieve highly correlated images in the cloud and identify corresponding patches. The <b>down-sampled</b> image serves as a target to stitch retrieved image patches together. Second, the <b>down-sampled</b> image is compressed using current image coding. The feature vectors of local descriptors are predicted by the corresponding vectors extracted in the decoded <b>down-sampled</b> image. The predicted residual vectors are compressed by transform, quantization, and entropy coding. The experimental results show that the visual quality of reconstructed images is significantly better than that of intra-frame coding in HEVC and JPEG at thousands to one compression. Index Terms—Image compression, local descriptor, mobile devices, SIFT (scale-invariant feature transform), the cloud. I. ...|$|E
50|$|A CIC filter {{consists}} {{of one or}} more integrator and comb filter pairs. In the case of a decimating CIC, the input signal is fed through one or more cascaded integrators, then a <b>down-sampler,</b> followed by one or more comb sections (equal in number to the number of integrators). An interpolating CIC is simply the reverse of this architecture, with the <b>down-sampler</b> replaced with a zero-stuffer (up-sampler).|$|R
40|$|Nowadays, digital {{pictures}} are usually captured {{at very high}} resolution ranged up to 12 mega-pixels. Limited by low-resolution display, we have to shrink the image. Signal processing theory tells us that optimal decimation requires low-pass filtering with a suitable cut-off frequency followed by <b>down-sampling.</b> In doing so, we need to remove lots of details. Subpixel-based <b>down-sampling,</b> {{taking advantage of the}} fact that each pixel on a color LCD is actually composed of individual red, green, and blue subpixel stripes, can provide apparent higher resolution. In this paper, we use frequency domain analysis to explain what happens in subpixel-based downsampling and why it is possible to achieve a higher apparent resolution. According to our frequency domain analysis and observation, the cut-off frequency of the low-pass filter for subpixel-based decimation can be effectively extended beyond the Nyquist frequency using a novel anti-aliasing filter. Experimental results verify that the proposed subpixel <b>down-sampling</b> scheme based on frequency analysis (SDSFA) can give superior results compared with existing pixel-based <b>down-sampling</b> methods. © 2011 IEEE...|$|R
3000|$|..., and σ[*]=[*]π. After convolving {{an image}} with the {{resulting}} 40 Gabor wavelets, we <b>down-sample</b> the magnitude matrix M [...]...|$|R
3000|$|... (i,j), j = 0,…, 19 is <b>down-sampled</b> to {{the frame}} rate of 50  Hz along the time {{dimension}} to obtain the energy spectrum S [...]...|$|E
40|$|AbstractIn this paper, we give an {{analytical}} {{model of the}} compression error of <b>down-sampled</b> compression based on wavelet transform, which explains why down-sampling before compression can improve coding performance. And we approximate the missing details due to down-sampling and compression by using the linear combination {{of a set of}} basis vectors with L 1 norm. Then we propose a <b>down-sampled</b> and high frequency information approximated coding scheme and apply it to natural images, and achieve gains of both subjective quality and objective quality compared with JPEG 2000...|$|E
40|$|Hierarchical {{image coding}} usually codes a <b>down-sampled</b> {{version of an}} {{original}} image and then {{the difference between the}} original image and a reconstructed version that is interpolated from the <b>down-sampled</b> layer. In this paper, we demonstrate, for the first time, that when the bit-rate used to code the residual layer falls into a critical region (which covers almost all typical bit-rates used in practice), it often happens that all pixels in the <b>down-sampled</b> layer would be deteriorated if the corresponding coded residuals are added into them. To avoid this problem, we first propose a "naive" solution: no coded residuals will be added back into the <b>down-sampled</b> layer; whereas coded residuals will be added only into the interpolated pixels. Then, we propose to apply a constrained quantization technique during the coding of the residual layer so that all residual pixels at the interpolated positions will end up with an improved quality. To verify its effectiveness, we conduct extensive tests to show that the gap between the hierarchical coding scheme and its single-level counterpart (which is typically around 2 - 3 dB in the 2 -level hierarchy) will be filled up by a rather big percentage. (C) 2012 Elsevier Inc. All rights reserved...|$|E
40|$|Embedded smart cameras {{have limited}} {{processing}} power, memory and energy. In this paper, we introduce two methodologies {{to increase the}} energy-efficiency and the battery-life of an embedded smart camera by hardware level operations when performing foreground object detection. We use the CITRIC platform as our embedded smart camera. We first perform <b>down-sampling</b> at hardware level on the micro-controller of the image sensor rather than performing software-level <b>down-sampling</b> at the main microprocessor of the camera board. In addition, we crop an image frame at hardware level by using the HREF and VSYNC signals at the micro-controller of the image sensor to perform foreground object detection only in the cropped search region instead of the whole image. Thus, the amount of data that is moved from the image sensor to the main memory at each frame, is greatly reduced. Thanks to reduced data transfer, better use of the memory resources and not occupying the main microprocessor with image <b>down-sampling</b> and cropping tasks, we obtain significant savings in energy consumption and battery-life. Experimental results show that hardware-level <b>down-sampling</b> and cropping, and performing detection in cropped regions provide 54. 14 % decrease in energy consumption, and 121. 25 % increase in battery-life compared to performing software-level down sampling and processing whole frames...|$|R
40|$|Features for {{automatic}} {{speech recognition}} (ASR) are typically sampled at about 100 Hz (10 ms analysis step). Recent experiments indicate that the most efficient components of the modulation spectrum of speech for ASR are up to about 16 Hz [1]. Consequently, RASTA processing attenuates modulation frequencies higher than 16 Hz and should in principle allow for a subsequent <b>down-sampling</b> of the features. It has been shown earlier that in a Gaussian mixture model based speaker recognition system(which uses single state HMM, thus not requiring any time alignments of the incoming speech) one could <b>down-sample</b> the speech representation after RASTA filtering without any significant loss of performance [2]. However since ASR uses Viterbi time alignment, reduced number of time samples due to <b>down-sampling,</b> although justified by Nyquist criteria after the low-pass filtering, could create problems. In this paper we experimentally show that the downsampling of features after RASTA filtering is fe [...] ...|$|R
40|$|In this paper, {{we present}} a novel design for the {{detection}} of primary synchronization signal in a Long Term Evolution (LTE) system based device at the expense of low cost and low power. This is facilitated by using a matched filter architecture which incorporates parallel processing. The approach of a 1 -bit analog-todigital converter (ADC) with <b>down-sampling</b> is compared with that of a 10 -bit ADC without <b>down-sampling</b> under multi-path fading conditions defined in LTE standard for user equipment (UE) performance test. A high performance primary synchronization signal detection method is derived in this paper...|$|R
