521|227|Public
5000|$|Monitoring {{changes in}} batch {{duration}} to allow alerting of abnormal <b>job</b> <b>execution</b> ...|$|E
50|$|Master Server: Controls all backup {{management}} tasks, catalog, scheduling, <b>job</b> <b>execution,</b> {{and distributed}} processing.|$|E
5000|$|... after {{successful}} JCL validation, job {{is moved}} to input queue, waiting for <b>job</b> <b>execution</b> ...|$|E
5000|$|High {{performance}} (up to 1000 job submissions {{per second}} and 600 <b>job</b> <b>executions</b> per second) ...|$|R
5000|$|Batch {{engine for}} {{controlling}} large file transfers, batch <b>jobs,</b> <b>execution</b> of external scripts and other non-messaging based tasks.|$|R
40|$|Management of complex, distributed, and {{dynamically}} changing <b>job</b> <b>executions</b> {{is a central}} problem in computational Grids. These executions often span multiple heterogeneous resources, cross administrative domains, and need {{to adjust to the}} changing resource availability to leverage opportunities and account for failures or policy induced failures. The executions themselves ar...|$|R
50|$|Hinemos Job map:An {{option to}} add an {{interface}} to see the job configuration and <b>Job</b> <b>execution</b> status graphically.|$|E
50|$|GridWay {{performs}} <b>job</b> <b>execution</b> {{management and}} resource brokering, allowing unattended, reliable, and efficient execution of jobs, array jobs, or complex jobs on heterogeneous, dynamic and loosely coupled Grids. GridWay performs all the job scheduling and submission steps transparently {{to the end}} user and adapts <b>job</b> <b>execution</b> to changing Grid conditions by providing fault recovery mechanisms, dynamic scheduling, migration on-request and opportunistic migration. The GridWay framework is a light component for meta-scheduling in the Grid Ecosystem intended for end users and grid application developers.|$|E
50|$|The jobs {{submitted}} to GRAM are targeted {{at a single}} computation resource, and consist of an optional input file staging phase, <b>job</b> <b>execution,</b> and an optional output file staging and cleanup stage.|$|E
40|$|Time {{independent}} traces from NAS MPI benchmarks (LU,IS,FT) {{that runs}} on Grid' 5000 testbed on the graphene cluster (node 105 to 143) using a dedicated switch (no network contention) and with 1 MPI process per node. These traces are made {{to be used by}} a distributed system simulator to replay the <b>jobs</b> <b>executions...</b>|$|R
40|$|<b>Job</b> {{workflow}} application <b>execution</b> {{over the}} Grid presents significant challenges to current existing <b>job</b> workflow <b>execution</b> models (JWEM). In this paper, we propose executable codes as dynamic services, which acts {{as part of}} Grid resources. Based on service deployment mechanism and where the control thread is, a classification of the JWEMs is presented in this paper. Performance evaluation and comparison studies are carried out on the execution models according to this classification. Our experimental {{studies show that the}} distributed <b>job</b> workflow <b>execution</b> based on dynamic services can achieve better performance than all other models. Department of ComputingRefereed conference pape...|$|R
40|$|The {{concept of}} co-allocation {{provides}} a simple mechanism to request and bind resources in a coordinated fashion in Grids across virtual organization boundaries. We have designed an advanced multistage co-allocation strategy based on resource hierarchies defined through user-specific patterns. The model manages simple flows between resources to perform managed <b>job</b> <b>executions.</b> We demonstrate {{the usefulness of}} our model on several examples and discuss {{advantages and disadvantages of}} the model...|$|R
50|$|Job Profiler -Profiles {{the various}} phases of MapReduce <b>job</b> <b>execution</b> with {{fine-grained}} node level analysis and a cluster level resource consumption view, {{all of which}} can be used for optimizing the job or the cluster.|$|E
50|$|There are n {{machines}} and m jobs. Each job contains exactly n operations. The i-th {{operation of the}} job must be executed on the i-th machine. No machine can perform more than one operation simultaneously. For each operation of each <b>job,</b> <b>execution</b> time is specified.|$|E
50|$|A web-based Administrator User Interface {{provides}} administrators with {{a simplified}} and easy-to-use interface to the Techila Server. The Administrator User Interface allows monitoring system activity, view and control <b>job</b> <b>execution,</b> execution policy, monitor and control Techila Workers and Techila Worker Groups, control security settings, and manage users.|$|E
30|$|Hybrid {{execution}} model [37] is a {{model for}} confidentiality and privacy in cloud computing. It executes public clouds only for operations which are safe while integrating an organization’s private cloud, i.e., it utilizes public clouds only for non-sensitive data and computation of an organization classified as public, whereas for an organization’s sensitive, private, data and computation, the model utilizes their private cloud. It considers data sensitivity before a <b>job’s</b> <b>execution.</b> It provides integration with safety.|$|R
30|$|We {{evaluated}} VMR {{by measuring}} the application turnaround, server network traffic and overhead while running widely used MapReduce applications, which are representative of MapReduce jobs deployed in production environments. Our solution was able to improve the performance of all the MapReduce jobs we tested. The map stage was up to 4 times faster than in an existing VC system. The reduce step also showed an improvement, thus reducing each MapReduce <b>job’s</b> <b>execution</b> time down to less than half.|$|R
5000|$|The Multiple Sequential Scheduler option, {{known as}} Multiprogramming with a Fixed Number of Tasks (MFT) {{provided}} execution of multiple concurrent <b>jobs.</b> <b>Execution</b> was {{governed by a}} priority which had a default for each stream or could be requested separately for each job. MFT version II added subtasks (threads), which executed at a priority based on that of the parent job. Each job stream defined {{the maximum amount of}} memory which could be used by any job in that stream.|$|R
50|$|Figure 2 shows a {{representation}} of a physical Thor processing cluster which functions as a batch <b>job</b> <b>execution</b> engine for scalable data-intensive computing applications. In addition to the Thor master and slave nodes, additional auxiliary and common components are needed to implement a complete HPCC processing environment.|$|E
5000|$|Biased Random Sampling bases its job {{allocation}} on {{the network}} represented by a directed graph. For each execution node in this graph, in-degree means available resources and out-degree means allocated jobs. In-degree will decrease during <b>job</b> <b>execution</b> while out-degree will increase after job allocation.The pseudo-code is following: ...|$|E
5000|$|CBM {{solutions}} typically {{provide input}} into and drive {{all aspects of}} employee career development. This allows organizations to improve productivity in most areas of human capital management human resources. CBM is typically referred to as [...] "strategic" [...] in that it attempts to link organizational planning to <b>job</b> <b>execution.</b>|$|E
40|$|This {{paper is}} {{concerned}} with the design, implementation, and evaluation of algorithms for communication partner identification in mobile agent-based distributed <b>job</b> workflow <b>execution.</b> We first describe a framework for distributed <b>job</b> workflow <b>execution</b> over the Grid: the Mobile Code Collaboration Framework (MCCF). Based on the study of agent communications during a <b>job</b> workflow <b>execution</b> on MCCF, we identify the unnecessary agent communications that degrade the system performance. Then, we design a novel subjob grouping algorithm for preprocessing the job workflow's static specification in MCCF. The obtained information is used in both static and dynamic algorithms to identify partners for agent communication. The mobile agent dynamic location and communication based on this approach is expected to reduce the agent communication overhead by removing unnecessary communication partners during the dynamic <b>job</b> workflow <b>execution.</b> The proof of the dynamic algorithm's correctness and effectiveness are elaborated. Finally, the algorithms are evaluated through a comparison study using simulated job workflows executed on a prototype implementation of the MCCF on a LAN environment and an emulated WAN setup. The results show the scalability and efficiency of the algorithms as well as the advantages of the dynamic algorithm over the static one. Department of Computin...|$|R
40|$|A {{time slot}} {{is defined as}} contention-free {{if the number of}} <b>jobs</b> with {{remaining}} <b>executions</b> in the slot is no larger than the number of processors, or contending, otherwise. Then an important property holds that in any contention-free slot, all <b>jobs</b> with remaining <b>executions</b> are guaranteed to be scheduled as long as the scheduler is work-conserving. This article aims at improving schedulability by utilizing the contention-free slots. To achieve this, this article presents a policy (called CF policy) that moves some <b>job</b> <b>executions</b> from contending slots to contention-free ones. This policy can be employed by any work-conserving, preemptive scheduling algorithm, and we show that any algorithm extended with this policy dominates the original algorithm in terms of schedulability. We also present improved schedulability tests for algorithms that employ this policy, based on the observation that interference from jobs is reduced when their executions are postponed to contention-free slots. Simulation results demonstrate that the CF policy, incorporated into existing algorithms, significantly improves schedulability of those existing algorithms...|$|R
50|$|In lean construction, {{project control}} has the <b>job</b> of <b>execution</b> (Ballard, PhD thesis, 2000); whereas, control in PMI method relies on {{variance}} detection after-the-fact.|$|R
5000|$|Strategy (1) enables to {{estimate}} the job termination time {{and to make it}} easy to allocate nodes for the next batch jobs in advance. Strategy (2) contributes to an efficiency <b>job</b> <b>execution.</b> The job can use the nodes exclusively and the processes in each node can be executed simultaneously. As a result, the large-scale parallel program is able to be executed efficiently.PNs of L-system are prohibited from access to the user disk to ensure enough disk I/O performance. herefore the files used by the batch job are copied from the user disk to the work disk before the <b>job</b> <b>execution.</b> This process is called [...] "stage-in." [...] It is important to hide this staging time for the job scheduling.Main steps of the job scheduling are summarized as follows; ...|$|E
50|$|Now that Sintran {{has mostly}} {{disappeared}} as an operating system {{there are very}} few references to it, however a job control or batch language was available called JEC, believed to be known as <b>Job</b> <b>Execution</b> Controller, this could be used to set up batch jobs to compile COBOL programs etc.|$|E
5000|$|When a new {{batch job}} is submitted, the {{scheduler}} searches available nodes (Step.1). After the nodes and the estimated start time are {{allocated to the}} batch job, stage-in process starts (Step.2). The job waits until the estimated start time after stage-in process is finished. If the scheduler find the earlier start time than the estimated start time, it allocates the new start time to the batch job. This process is called [...] "Job Escalation" [...] (Step.3). When the estimated start time has arrived, the scheduler executes the batch job (Step.4). The scheduler terminates the batch job and starts stage-out process after the <b>job</b> <b>execution</b> is finished or the declared elapsed time is over (Step.5).To execute the batch job, the user logs into the login-server and submits the batch script to ES. And the user waits until the <b>job</b> <b>execution</b> is done. During that time, the user can see {{the state of the}} batch job using the conventional web browser or user commands. The node scheduling, the file staging and other processing are automatically processed by the system according to the batch script.|$|E
40|$|Mobile agent based {{distributed}} <b>job</b> workflow <b>execution</b> is {{a promising}} paradigm for data intensive collaborative scientific computations over the grid. In this paper, a mobile code collaboration framework (MCCF) for distributed <b>job</b> workflow <b>execution</b> over the grid is described and an algorithm to identify partners for agent communication in MCCF is presented. Previous work of mobile agent communication focuses mainly on agent location and communication. Little {{work has been}} done on communication partner identification. In MCCF, a novel subjob grouping algorithm for preprocessing the job workflow's static specification is developed. The obtained information is then used during runtime to identify partners for agent communication. The mobile agent dynamic location and communication based on this approach limits the number of agents required for communication during the dynamic <b>job</b> workflow <b>execution.</b> The algorithm is evaluated through a comparison study using simulated job workflows executed on a prototype implementation of the MCCF. The results show that the algorithm is scalable and efficient. Department of ComputingRefereed conference pape...|$|R
30|$|In {{addition}} to enabling and evaluating horizontal scalability, {{the cost of}} an analysis and the choice of virtual machine flavors are becoming increasingly important for efficient execution of bioinformatics analysis, since pipelines are increasingly deployed and evaluated on commercial clouds [6, 21, 22]. However, even on dedicated clusters {{it is important to understand}} how to scale a pipeline up and out on the available resources to improve the utilization of the resources. However, with the exception of [17], none of the reviewed papers have evaluated multiple pipeline <b>job</b> <b>executions</b> from the cluster provider’s point of view.|$|R
40|$|Big Data {{applications}} {{allow to}} successfully analyze {{large amounts of}} data not necessarily structured, though {{at the same time}} they present new challenges. For example, predicting the performance of frameworks such as Hadoop can be a costly task, hence the necessity to provide models that can be a valuable support for designers and developers. This paper provides a new contribution in studying a novel modeling approach based on fluid Petri nets to predict MapReduce <b>jobs</b> <b>execution</b> time. The experiments we performed at CINECA, the Italian supercomputing center, have shown that the achieved accuracy is within 16...|$|R
5000|$|Operations {{within one}} job must be {{performed}} in the specified order. The first operation gets executed on the first machine, then (as the first operation is finished) the second operation on the second machine, and so until the n-th operation. Jobs can be executed in any order, however. Problem definition implies that this job order {{is exactly the same}} for each machine. The problem is to determine the optimal such arrangement, i.e. the one with the shortest possible total <b>job</b> <b>execution</b> makespan.|$|E
50|$|Specific tools {{may be used}} to {{simulate}} and understand the performance of message passing on computer clusters. For instance, CLUSTERSIM uses a Java-based visual environment for discrete-event simulation. In this approach computed nodes and network topology is visually modeled. Jobs and their duration and complexity are represented with specific probability distributions allowing various parallel job scheduling algorithms to be proposed and experimented with. The communication overhead for MPI message passing can thus be simulated and better understood in the context of large-scale parallel <b>job</b> <b>execution.</b>|$|E
5000|$|The {{semiconductor}} front-end industry {{defined a}} series of standards known as the GEM300 standards that includes SEMI standards E40, E87, E90, E94 and E116 and reference the E39 standard. Each standard provides additional features to the GEM interface yet build upon the features in GEM E30 standard. 300 mm factories worldwide use the underlying GEM standard's data collection features in order to monitor specific equipment activity such as wafer movement and process <b>job</b> <b>execution.</b> The SECS/GEM standard and the additional GEM300 standards are required on nearly each and every 300mm wafer manufacturing tool in order to implement the manufacturing automation. This industry has been the strongest supporter of the GEM and related SEMI standards.|$|E
40|$|Gang {{scheduling}} {{is considered}} to be a highly effective task scheduling policy for distributed systems. In this paper we present a migration scheme which reduces the fragmentation in the schedule caused by gang scheduled jobs which cannot start. Furthermore, the existence of high priority jobs in the workload is addressed by the proposed strategy. High priority jobs need to be started immediately, which can in turn lead to the interruption of a parallel <b>job’s</b> <b>execution.</b> A distributed system consisting of two homogeneous clusters is simulated to evaluate the performance. Our simulation results indicate that the proposed strategy can result in a performance boost...|$|R
30|$|Our {{solution}} {{was able to}} improve the performance of all the MapReduce jobs we tested. The map stage was up to 4 times faster than in an existing VC system. The reduce step also showed an improvement, thus reducing each MapReduce <b>job’s</b> <b>execution</b> time down to less than half. Our experiments regarding the server’s network traffic also gave us some interesting results. We were able to reduce server download traffic by {{an order of magnitude}} on the word count and inverted index applications. Therefore, we were able to witness a decrease in uploaded data to 20  % of the existing VC system server’s value.|$|R
30|$|Hybrid {{execution}} model [55] is a {{model for}} confidentiality and privacy in cloud computing. It utilizes public clouds only for an organization’s non-sensitive data and computation classified as public, i.e., when the organization declares {{that there is no}} privacy and confidentiality risk in exporting the data and performing computation on it using public clouds, whereas for an organization’s sensitive, private data and computation, the model executes their private cloud. Moreover, when an application requires access to both the private and public data, the application itself also gets partitioned and runs in both the private and public clouds. It considers data sensitivity before a <b>job’s</b> <b>execution</b> and provides integration with safety.|$|R
