4|8|Public
50|$|In {{computer}} programming, {{eager evaluation}} or <b>greedy</b> <b>evaluation</b> is the evaluation strategy used by most traditional programming languages. In eager evaluation, an expression is evaluated {{as soon as}} it is bound to a variable. An alternative to eager evaluation is lazy evaluation, where expressions are evaluated only when a dependent expression is evaluated.|$|E
40|$|Wireless ad hoc {{networks}} are usually composed of autonomous nodes, which are powered by batteries only. The energy-efficiency is {{perhaps one of}} the most important factors for each operation in terms of networks. Broadcast, for example, is one of the fundamental operations in modern telecom networks. In this paper a broadcast tree, which is rooted at a source and spans all the destination nodes, has been constructed in a way that the total transmission energy consumption is minimized. This paper describes two polynomial-time heuristics for the energy-efficient broadcasting in static ad hoc wireless networks. Both of the developed approaches are on the basis of a fuzzy <b>greedy</b> <b>evaluation</b> function, which prioritize the network nodes. According to the prioritized order of the nodes, each new node is selected for incorporation in the construction of a solution. Computational experiments indicate that our algorithms improve the well-known Broadcast Link-based Minimum Spanning Tree (BLiMST) and Broadcast Least-Unicast-cost (BLU) heuristics. It will be seen that the BLiMST and the BLU methods are a special case of our more general heuristics...|$|E
40|$|We {{introduce}} {{an electric}} {{vehicle routing problem}} combining conventional, plug-in hybrid, and electric vehicles. Electric vehicles are constrained in their service range by their battery capacity, and may require time-consuming recharging operations at some specific locations. Plug-in hybrid vehicles have two engines, an internal combustion engine and an electric engine using a built-in rechargeable battery. These vehicles can avoid visits to recharging stations by switching to fossil fuel. However, this flexibility comes {{at the price of}} a generally higher consumption rate and utility cost. To solve this complex problem variant, we design a sophisticated metaheuristic which combines a genetic algorithm with local and large neighborhood search. All route evaluations, within the approach, are based on a layered optimization algorithm which combines labeling techniques and <b>greedy</b> <b>evaluation</b> policies to optimally insert recharging stations visits in a fixed trip and to select the fuel types. The metaheuristic is finally hybridized with an integer programming solver, over a set partitioning formulation, so as to recombine high-quality routes from the past search into better solutions. Extensive experimental analyses are conducted, highlighting the good performance of the algorithm and the contribution of each of its main components. Finally, we investigate the impact of fuel and energy cost on fleet composition decisions. Our experiments show that a careful use of a mixed fleet can significantly reduce operational costs in a large variety of price scenarios, in comparison {{with the use of a}} fleet composed of a single vehicle class...|$|E
40|$|Decision {{trees are}} widely disseminated as an {{effective}} solution for classification tasks. Decision tree induction algorithms have some limitations though, due to the typical strategy they implement: recursive top-down partitioning through a <b>greedy</b> split <b>evaluation.</b> This strategy is limiting {{in the sense that}} there is quality loss while the partitioning process occurs, creating statistically insignificant rules. In order to prevent the greedy strategy and to avoid converging to local optima, we present a novel Genetic Algorithm for decision tree induction based on a lexicographic multiobjective approach, and we compare it with the most well-known algorithm for decision tree induction, J 48, over distinct public datasets. The results show the feasibility of using this technique as a means to avoid the previously described problems, reporting not only a comparable accuracy but also, importantly, a significantly simpler classification model in the employed datasets...|$|R
40|$|AbstractA novel {{approach}} is proposed for expressing and computing efficiently a large class of problems, including finding the shortest path in a graph, {{that were previously}} considered impervious to an efficient treatment in the declarative framework of logic-based languages. Our {{approach is}} based on the use of min and max predicates having a first-order semantics defined using rules with negation in their bodies. We show that, under certain monotonicity conditions, (1) there exists a total well-founded model for these programs expressed using negation, (2) this model can be computed efficiently using a procedure called greedy fixpoint, and (3) programs with min/max goals on recursively defined cost predicates can often be rewritten into more efficient ones by pushing min and max predicates into recursion. The <b>greedy</b> fixpoint <b>evaluation</b> of the program expressing the shortest path problem coincides with Dijkstra′s algorithm, once the finite differencing techniques of seminaive fixpoint are applied...|$|R
40|$|Among {{the several}} tasks that {{evolutionary}} algorithms have successfully employed, the induction of classification rules and decision trees {{has been shown}} to be a relevant approach for several application domains. Decision tree induction algorithms represent one of the most popular techniques for dealing with classification problems. However, conventionally used decision trees induction algorithms present limitations due to the strategy they usually implement: recursive top-down data partitioning through a <b>greedy</b> split <b>evaluation.</b> The main problem with this strategy is quality loss during the partitioning process, which can lead to statistically insignificant rules. In this paper, we propose a new GA-based algorithm for decision tree induction. The proposed algorithm aims to prevent the greedy strategy and to avoid converging to local optima. For such, it is based on a lexicographic multi-objective approach. In order to evaluate the proposed algorithm, it is compared with a well-known and frequently used decision tree induction algorithm using different public datasets. According to the experimental results, the proposed algorithm is able to avoid the previously described problems, reporting accuracy gains. Even more important, the proposed algorithm induced models with a significantly reduction in the complexity considering tree sizes...|$|R
30|$|After 2000, {{there are}} {{wide range of}} heuristics, {{meta-heuristics}} and hybrid meta-heuristics developed for flow-shop and permutation flow-shop by researchers. Ruiz et al. (2005) proposed two heuristics for the same problem, and showed that their heuristics outperform previous ones. Ruiz and Stutzle (2008) presented two simple local search-based iterated greedy algorithms, and showed that their algorithms perform better than those of Ruiz et al. (2005). Tseng et al. (2005) developed a penalty-based heuristic algorithm for the same problem and compared their heuristic with an existing index heuristic algorithm. Among all approaches, {{one of the most}} successful meta-heuristics to solve PFSP from last until now is genetic algorithm. Like one worked by Reeves (1995) and Sun and Hwang (2001). Sun and Hwang (2001) addressed a related problem of F 2 /STsd/Cmax where the setup times are present only on the second machine, and the setup time of a job depends on k (k >  1) immediately preceding jobs. They proposed a dynamic programming formulation and a genetic algorithm for the problem. Chaari et al. (2011) considered a scheduling problem under uncertainty. They developed a genetic algorithm for the case of hybrid flow-shop scheduling problem that the processing time of each job for each machine at each stage is the source of uncertainty. They defined a robust bi-objective evaluation function to obtain a robust, effective solution that is only slightly sensitive to data uncertainty. Tseng and Lin (2010) proposed a hybrid genetic algorithm to solve the no-wait flow-shop scheduling problem with the make-span objective. The proposed algorithm hybridized the genetic algorithm and a novel local search scheme. The proposed local search scheme combines two local search methods: the insertion search and a novel local search method called the insertion search with cut-and-repair. Jarboui et al. (2011) proposed a hybrid genetic algorithm to minimize the make-span and the total flow time in the no-wait flow-shop scheduling problem. In their research, the variable neighborhood search was used as an improvement procedure in the last step of the genetic algorithm. Huang and Huang (2010) considered a flow-shop scheduling problem with synchronous material movement in an automated machine center consisting of a loading/unloading (L/U) station, m processing machines, and a rotary table. Furthermore, other useful and strong approaches can be fined to solve PFSP. Li et al. (2004) presented partial enumeration method (PEM) to minimize the make-span performance of large flow-shop scheduling problems. The PEM run in short time and could easily combine with other algorithms or rules to improve performance. In their research, two priority rules, variance method and variance–mean method were developed. Laha and Chakraborty (2007) developed an efficient stochastic hybrid heuristic (H 3) for flow-shop scheduling problem and showed the superiority of their work against other researches. Noori-Darvish and Tavakkoli-Moghaddam (2012) proposed a novel bi-objective mathematical programming for an open-shop scheduling problem with setup and processing times separately such that not only the setup times are dependent on the machines, but also they are dependent on the sequence of jobs that should be processed on a machine. They minimized the total tardiness and the make-span. Maleki-Darounkolaei et al. (2012) considered a three-stage assembly flow-shop scheduling problem with sequence-dependent setup times at the first stage and blocking times between each stage in such a way that the weighted mean completion time and make-span are minimized. Finally, Sheibani (2010) described a polynomial-time heuristic (PH) for the permutation flow-shop scheduling problem with the make-span criterion. His method consists of two phases: arranging the jobs in priority order and then constructing a sequence. He employed a fuzzy <b>greedy</b> <b>evaluation</b> function to prioritize the jobs for incorporating into the construction phase of the heuristic.|$|E
40|$|Robustness {{of complex}} {{networks}} {{has been studied}} for decades, with a particular focus on network attack. Research on network repair, on the other hand, has been conducted only very lately, given the even higher complexity and absence of an effective evaluation metric. A recently proposed network repair strategy is self-healing, which aims to repair networks for larger components at a low cost only with local information. In this paper, we discuss the effectiveness and efficiency of self-healing, which limits network repair to be a multi-objective optimization problem and {{makes it difficult to}} measure its optimality. This leads us to a new network repair evaluation metric. Since the time complexity of the computation is very high, we devise a <b>greedy</b> ranking strategy. <b>Evaluations</b> on both real-world and random networks show the effectiveness of our new metric and repair strategy. Our study contributes to optimal network repair algorithms and provides a gold standard for future studies on network repair...|$|R
40|$|Zero-shot Hashing (ZSH) is {{to learn}} hashing models for novel/target classes without {{training}} data, which is an important and challenging problem. Most existing ZSH approaches exploit transfer learning via an intermediate shared semantic representations between the seen/source classes and novel/target classes. However, due to having disjoint, the hash functions learned from the source dataset are biased when applied directly to the target classes. In this paper, we study the transductive ZSH, i. e., we have unlabeled data for novel classes. We put forward a simple yet efficient joint learning approach via coarse-to-fine similarity mining which transfers knowledges from source data to target data. It mainly consists of two building blocks in the proposed deep architecture: 1) a shared two-streams network, which the first stream operates on the source data and the second stream operates on the unlabeled data, to learn the effective common image representations, and 2) a coarse-to-fine module, which begins with finding the most representative images from target classes and then further detect similarities among these images, to transfer the similarities of the source data to the target data in a <b>greedy</b> fashion. Extensive <b>evaluation</b> results on several benchmark datasets demonstrate that the proposed hashing method achieves significant improvement over the state-of-the-art methods...|$|R
40|$|An {{important}} task for computer-assisted surgical interventions is the alignment of pre- and intra-operative spaces allowing {{the transfer of}} pre-operative information to the current patient situation, known as intra-operative registration. Registration is usually performed by using markers or image-based techniques. Another approach is the intra-operative acquisition of organ surfaces by 3 D range scanners, which are then matched to pre-operatively generated surfaces. However, this approach is not trivial, as methods for intra-operative surface matching {{must be able to}} deal with noise, distortions, deformations, and the availability of only partially overlapping, nearly flat surfaces. For these reasons, surface matching for intra-operative registration has so far only been used to account for displacements that occur in local scales, while the actual alignment is still performed manually. The main contributions of this thesis are two different approaches for automatic surface matching in intra-operative environments. The focus here is the registration of surfaces acquired by different modalities, dealing with the aforementioned issues and without relying on unique landmarks. For the first approach, surfaces are converted to graph representations and correspondences between them are identified by means of graph matching. Graphs are obtained automatically by segmenting the surfaces into regions with similar properties. As the graph matching problem is known to be NP-hard, it was solved by iteratively computing node similarity scores, and converting it to a linear assignment problem. In the second approach, correspondences are identified by the selection of two spatial configurations of landmarks that can be better fitted to each other, according to an error metric. This error metric does not only incorporate a fitting error, but also a new measure for spatial configuration reliability. The optimization problem is solved by means of a <b>greedy</b> algorithm. <b>Evaluation</b> of the two approaches was performed with several experiments, simulating intra-operative conditions. While the graph matching approach proved to be robust for the registration of small partial data, the point-based approach proved to be more reliable for noisy surfaces. Apart from being a significant contribution to the field of feature-less partial surface matching, this work represents a great effort towards the achievement of a fully automatic, marker-less, registration system for computer-assisted surgery guidance...|$|R
40|$|We {{consider}} {{service enhancement}} in a wireless {{environment in which}} clients try to obtain service from a set of servers. Each client desires a minimum overall service success probability, {{which is achieved by}} establishing multiple independent connections with multiple servers. Given the service success probability of each potential client-server connection, our problem is to assign the connections such that the number of satisfied clients (whose overall service success probability is met) is maximized subject to server and client capacity constraints. In this paper, we make minor adaptations to the well-known notion of probabilistic network from the machine learning community and use it as our communication model. We then formally define the above optimization problem as the link assignment for successful service problem (LASS). While LASS can be reduced to the maximum matching problem in the deterministic case (where the success probabilities of each edge is 1), we show that in the probabilistic case it is NP-hard (and MaxSNP-hard). An equivalent integer programming formulation for LASS is obtained so that for small input size, the problem may be efficiently solved by the standard IP solver in practice. To tackle large input size, various heuristics are designed. Furthermore, in the special case where the underlying network graph is a tree (which is common in many real-life settings), we show that LASS can be solved in linear time based on a simple <b>greedy</b> algorithm. Experimental <b>evaluations</b> are performed and the results demonstrate the practicality of the algorithms and the heuristics...|$|R
40|$|Abstract—In-network {{processing}} is {{touted as}} a key technology to eliminate data redundancy and minimize data transmission, which are crucial to saving energy in wireless sensor networks (WSNs). Specifically, operators participating in in-network pro-cessing are mapped to nodes in a sensor network. They receive data from downstream operators, process them and route the output to either the upstream operator or the sink node. The objective of operator tree placement is to minimize the total energy consumed in performing in-network processing. Two types of placement algorithms, centralized and distributed, have been proposed. A problem with the centralized algorithm {{is that it does}} not scale to large WSN’s, because each sensor node is required to know the complete topology of the network. A problem with the distributed algorithm is their high message complexity. In this paper, we propose a heuristic algorithm to place a tree-structured operator graph, and present a distributed implemen-tation to optimize in-network processing cost and reduce the communication overhead. We prove a tight upper bound on the minimum in-network processing cost, and show that the heuristic algorithm has better performance than a canonical <b>greedy</b> algorithm. Simulation-based <b>evaluations</b> demonstrate the superior performance of our heuristic algorithm. We also give an improved distributed implementation of our algorithm that has a message overhead of O(M) per node, which is much less than the O(NM log 2 M) and O(NM) complexities for two previously proposed algorithms, Sync and MCFA, respectively. Here, N is the number of network nodes and M is the size of the operator tree. Index Terms—Sensor networks, operator tree placement, heuristic algorithm. I...|$|R

