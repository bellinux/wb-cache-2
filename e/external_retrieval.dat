5|15|Public
40|$|We {{present a}} new class of {{distributed}} key generation and recovery algorithms suitable for group communication sys-tems where the group membership is either static or slowly time-varying, and must be tightly controlled. The proposed key generation approach allows entities which may have only partial trust in each other to jointly generate a shared key without the aid of an external third party. The shared key is generated using strong one-way function of the group pa-rameter. This scheme also has perfect forward secrecy. The validity of key generation can be checked using verifiable se-cret sharing techniques. The key retrieval method does not require the keys to be stored in an <b>external</b> <b>retrieval</b> cen-ter. We note that many Internet-based applications may have these requirements. Fulfillment of these requirements is realized through the use of fractional keys—a distributed technique recently developed to enhance the security of dis-tributed systems in a non-cryptographic manner...|$|E
40|$|Spatio-temporal data {{ranging from}} 1 -D time series to 4 -D {{measurements}} and simulations have become of central importance {{in terms of}} both data volumes generated and the need for ubiquitous high-level information in a variety of applications. Management of the large variety of data and their combination, however, poses high challenges wrt. structural variety of multi-sensor data, evaluation complexity, and the sheer data volumes on hand. The multidimensional database management system (DBMS) RasDaMan has been developed to provide the same quality of service for the multidimensional raster data category as is available on alphanumeric data since long. Based on a strict separation of <b>external</b> <b>retrieval</b> facilities and internal data management, the client/server system accomplishes storage, retrieval, and manipulation of raster data of any size and dimension. An SQL-based query language allows to phrase queries up to the complexity of the Discrete Fourier Transform. Internally, [...] ...|$|E
40|$|This study {{examined}} age {{differences in the}} accessibility of a single pool of naturally occurring intentions {{both before and after}} completion. Following Maylor, Darby, and Della Sala (2000), accessibility was measured {{in terms of the number}} of activities generated in a 4 -minute activity fluency task. Each participant undertook two such tasks. A prospective task in which they generated activities intended for completion during the following week and a retrospective task, I week later, in which they generated activities carried out over the previous week. In a partial replication of Maylor et al. 's findings, young, but not healthy older, adults generated more to-be-completed intentions than completed ones, demonstrating an intention-superiority effect (ISE) for everyday activities. The absence of an ISE for older adults appeared to reflect the reduced accessibility of intentions prior to completion, rather than the impaired inhibition of fulfilled intentions. Moreover, both groups showed greater inaccessibility of completed than intended activities, thus demonstrating an intentioncompletion effect for naturally occurring intentions that is preserved in healthy ageing (cf. Marsh, Hicks, & Bink, 1998). Despite showing a reduced accessibility of intended activities, older adults reported having completed a greater proportion of their intentions during the week than young adults. Moreover, there was a correlation between the ability to access intentions and the proportion of intentions completed only for young adults. These observations suggest that older adults' everyday prospective memory performance may be relatively less dependent on intention accessibility and more dependent on other factors. While there was no age difference in the reported use and effectiveness of <b>external</b> <b>retrieval</b> aids, older adults demonstrated a greater level of temporal organization in the production of their intentions in the fluency task. This is consistent with the possibility that older adults may have more structured daily lives and may be able to use information about the sequence of ongoing events to support superior everyday prospective remembering...|$|E
5000|$|Technology-supported culture: Finally, the {{cognitive}} ecology dominated by ephemeral face-to-face communication has changed {{for most of}} us {{as a result of the}} external memory-store that reading and writing permit. Computer technology intensifies these changes by offering even more extensive capacities for <b>external</b> storage and <b>retrieval</b> of information.|$|R
40|$|Invenio is a {{comprehensive}} web-based free digital library software suite originally developed at CERN. In order to improve its information retrieval and word similarity ranking capabilities, {{the goal of this}} thesis is to enhance Invenio by bridging it with modern <b>external</b> information <b>retrieval</b> systems. In the first part a comparison of various information retrieval systems such as Solr and Xapian is made. In the second part a system-independent bridge for word similarity ranking is designed and implemented. Subsequently, Solr and Xapian are integrated in Invenio via adapters to the bridge. In the third part scalability tests are performed. Finally, a future outlook is briefly discussed. Comment: 70 pages, 34 figure...|$|R
40|$|Searching the Medline {{database}} {{is almost}} a daily necessity for many biomedical researchers. However, available Medline search solutions are mainly designed for the quick retrieval of a small set of most relevant documents. Because of this search model, they are not suitable for the large-scale exploration of literature and the underlying biomedical conceptual relationships, which are common tasks {{in the age of}} high throughput experimental data analysis and cross-discipline research. We try to develop a new Medline exploration approach by incorporating interactive visualization together with powerful grouping, summary, sorting and active <b>external</b> content <b>retrieval</b> functions. Our solution, PubViz, is based on the FLEX platform designed for interactive web applications and its prototype is publicly available at...|$|R
40|$|Mobile {{information}} technologies are theoretically {{well suited to}} digitally accommodate the informal note taking task wherewith the notes often recorded quickly and under less than ideal circumstances. Unfortunately, user adoption of mobile support for informal note taking has been hindered {{in large part by}} slow text entry techniques. Building on research confirming people's ability to read erroneous text and effectively use incomplete <b>external</b> <b>retrieval</b> cues, this dissertation investigated the effects of two modifications to Graffiti-based text entry with the goal of overcoming the barriers associated with current text entry solutions: disabling text correction and disabling visual feedback. As expected, both modifications improved text entry speed but also resulted in more errors in the resulting text which hindered the users' ability to recognize the words they had recorded. To address this decrease in recognizability, a multi-approach note enhancement mechanism was introduced. When this algorithm was applied to a set of particularly challenging erroneous notes, study participants were able to correctly recognize 56 % more of the words in the notes. In a formal evaluation study with 75 participants, the proposed approach of discouraging user-initiated error correction during note taking, enhancing the resulting erroneous notes, and facilitating recall with enhanced alternative lists, was confirmed to increase the note taking speed by 47 % without any negative impact on the participants' ability to recall important details about the scenarios which prompted the note taking activities. This research highlighted the importance of shifting the focus from accuracy to recallability when examining the overall efficacy of informal notes. With some easily implemented modifications to existing text entry techniques, combined with a note enhancement algorithm which leverages information about the errors users make and the types of errors users are more likely to overcome, a significant improvement in user performance was achieved. These results have important implications for how mobile technologies are designed to support both informal note taking and text entry in general...|$|E
40|$|I Norra Djurgårdsstaden i Stockholm pågår ett stort stadsutvecklingsprojekt där det planerats för ungefär 12 000 nya bostäder, 35 000 arbetsplatser och 600 000 kvadratmeter kommersiell yta. För att koordinera alla {{transporter}} av byggmaterial in till området, samt hantera avfallstransporter ut ur området, har Stockholms stad etablerat ett bygglogistikcenter vars mål bland annat är att reducera antalet transporter. Syftet med detta examensarbete har varit att ta fram en metod för utvärdering av potentiella miljöeffekter med bygglogistikcentret i Norra Djurgårdsstaden. Examensarbetet har tittat på byggtransportlogistik ur ett livscykelperspektiv för jämförelse mellan två olika scenarion, då ett bygglogistikcenter finns (scenario 1) respektive då ett sådant inte finns (scenario 2). De parametrar som ingått är partiklar och energianvändning samt CO 2, NOx och SO 2. Två olika beräkningsverktyg har jämförts och valet föll på ett verktyg från NTM, Nätverket för Transporter och Miljön. En genomgång av vilken information som erfordras för att göra beräkningar har gjorts och för att undersöka tillgången till dessa data har ett antal intervjuer samt en workshop genomförts med olika aktörer, både inom Norra Djurgårdsstaden men också utifrån. Andra saker som diskuterades var aktörernas syn på bygglogistikcentret, vad som kan förbättras med det samt hur själva utfallet av en utvärdering skulle kunna förbättras, exempelvis genom styrning i upphandlingsprocessen. Intervjuer och workshop har också varit viktiga i syfte att förankra den föreslagna utvärderingsmetoden hos aktörerna själva. Under intervjuer och workshop har det bland annat framkommit en del konstateranden och några förslag till förbättringar. Exempelvis sades att logistikfrågor lyfts upp enbart genom att bygglogistikcentret finns och att den största förbättringen med bygglogistikcentret anses vara att framkomligheten är mycket bättre än vad den annars hade varit. En annan sak som de flesta var eniga om var att krav i upphandling bör ställas så tidigt som möjligt för att de ska kunna få så stor effekt som möjligt. För att göra en utvärdering krävs data om alla olika transporter och för varje transporttyp behövs information inom tre olika kategorier: fordonet, lasten samt själva körvägen. Eftersom alla data inte finns tillgängliga idag kommer en del antaganden att behöva göras, hur många beror på när i tiden utvärderingen ska göras och hur noggrann den ska vara. Om en utvärdering ska göras snarast rekommenderas att ett antal manuella mätningar genomförs men för att utvärderingar ska kunna göras kontinuerligt föreslås att en del åtgärder vidtas för att automatisera insamlingen av data. Det rekommenderas också att en känslighetsanalys av erhållna mätvärden görs för bedömning av vilka data som är i störst behov av ökad noggrannhet för att utvärderingens tillförlitlighet ska öka. Beroende på vad en sådan analys visar ges förslag på några olika åtgärder som kan vidtas, såsom att montera kameror vid grindpassager för information om passerande fordon eller att installera datorer i vissa fordon för att få information om körbeteende.  In {{the eastern}} part of Stockholm a major urban development project is taking place. It is called Stockholm Royal Seaport and until the year 2030 approximately 12, 000 new homes, 35, 000 workplaces and 600, 000 square meters of commercial areas will be added to the area. The project has been given a very ambitious environmental action program and as a part of that the City of Stockholm has established a logistics center in the area. The logistics center is supposed to coordinate all transports of building material and handle the waste during the construction phase. One objective with the logistics center is {{to reduce the amount of}} transports and thereby also the generated emissions and the use of energy. The aim of this thesis has been to develop a methodology for evaluating the potential environmental impacts related to the logistics center in the Stockholm Royal Seaport. The evaluation method is able to compare the effect, from a life cycle perspective, from construction transports in two different scenarios, scenario 1 where there is a logistics center and scenario 2 where there is not. The chosen parameters are CO 2, NOx, SO 2, particulate matter and energy usage. Two different tools for computing values for the chosen parameters have been compared and the selected one is developed by NTM, the Network for Transport Measures. After the selection an investigation of input data required to use the tool was performed. A number of interviews were conducted and a workshop was organized with various representatives, mainly people working with construction or transportation in the Stockholm Royal Seaport. The things discussed during the interviews and the workshop were, among other things, the availability of required data, the interviewees opinions about the logistics center and their suggestions for improvements that can be done, both at the center itself, but also for example in the procurement process. Another purpose for the interviews and the workshop was to anchor the methodology with the various representatives. A direct result from the interviews and the workshop has been some proposals for improvement, for example that requirements in the procurement process should be presented at an early stage to be able to be as effective as possible. Some of the interviewees pointed out that logistic issues are highlighted simply by the existence of the logistics center. There are a couple of different transport routes within the area, as some deliveries are allowed directly into the construction sites, whereas some have to pass the logistics center to unload the freight, all depending on the amount of freight to a specific site. Staff at the logistics center will then consolidate the deliveries to the construction sites into one vehicle. They also collect the generated waste, which they handle at the center before it is transported to an <b>external</b> <b>retrieval</b> plant. The logistics center also utilizes a vehicle used for inspections of the traffic and deliveries within the area. All of the above mentioned types of transportations are included in the thesis. An evaluation of the effects of the logistics center requires data about all types of transportation, within three different categories: the vehicle, the load and the actual route. Since all required data is not available today some assumptions have to be made, how many and which depends on the requested accuracy of the evaluation and when it is to be performed. If an evaluation is to be performed given the current conditions it is recommended that a number of manual measurements are carried out to collect data which was not available at the time being, however, if evaluations are to be done continuously it is suggested that the retrieval of data is as automated as possible. It is also recommended to do a sensitivity analysis of the data retrieved from the measurements to assess the impact from certain data on the chosen parameters. The amount of impact helps determine which data to refine in order to increase the accuracy of the evaluation. Depending on what the analysis shows the thesis gives suggestions for actions such as installing cameras at gates to the construction sites and/or the logistics center or to install computers in vehicles to obtain data on driving behavior. ...|$|E
40|$|The PhonePages of Sweden is {{a company}} that {{develops}} software for mobile units, especially cell phones. This thesis treats the development of, and contingencies for, a mobile phone directory, using the limited resources found in a mobile unit. The project was implemented and executed at The PhonePages with the intention of creating a product to sell to a third party. By studying different solutions, their benefits and drawbacks, an abstract picture of the product was constructed. Problems covered include compatibility problems caused by todays platform diversity as well as problems with saving, organizing and presenting data. The main goal was to create a phone directory which does not make <b>external</b> information <b>retrievals.</b> The service should contain both company and personal information, with name and phonenumber. Complete address information should also be available. The application should also manage different priorities and logotypes for the company information. The application, that emerged {{as a result of our}} work at The PhonePages, works independently, without making connections to the Internet and is completely implemented in J 2 ME, all according to the requirement specification. In other words, the analysis of the different solutions led to a working application...|$|R
40|$|In general, {{publication}} of multimedia content such as video, in mass media {{such as the}} Web, it is not complicated for organizations due to the current state-of-art of this technology and, most of all, because of {{the increasing number of}} available websites on the Internet, which in some cases offer this kind of services for free. However, after the experience in designing a website for an autonomic parliament like Cortes de Aragon, it has been observed that the simple {{publication of}} the content might not be enough for a parliament institution; where besides communicating the purpose is to create awareness about the institution. At that time it might be of interest to link the multimedia content through hyperlinks to the rest of available information on the parliament’s website. Two goals can be reached: first of all to improve the parliamentary contents in line with current trends and secondly to facilitate internal and <b>external</b> users the <b>retrieval</b> of legislation-related videos by surfing the web...|$|R
40|$|User {{generated}} {{content is}} characterized by short, noisy documents, with many spelling errors and unexpected language usage. To bridge the vocabulary gap between the user’s information need and documents in a specific user generated content environment, the blogosphere, we apply a form of query expansion, i. e., adding and reweighing query terms. Since the blogosphere is noisy, query expansion on the collection itself is rarely effective but external, edited collections are more suitable. We propose a generative model for expanding queries using external collections in which dependencies between queries, documents, and expansion documents are explicitly modeled. Different instantiations of our model are discussed and make different (in) dependence assumptions. Results using two external collections (news and Wikipedia) show that <b>external</b> expansion for <b>retrieval</b> of user generated content is effective; besides, conditioning the external collection on the query is very beneficial, and making candidate expansion terms dependent on just the document seems sufficient. ...|$|R
5000|$|... "Origins of the Modern Mind {{proposes a}} three-stage {{development}} of human symbolic capacity through culture:Mimetic culture: The watershed adaptation allowing humans {{to function as}} symbolic and cultural beings was a revolutionary improvement in motor control, the [...] "mimetic skill" [...] required to rehearse and refine the body's movements in a voluntary and systematic way, to remember those rehearsals, and to reproduce them on command. Following this development, Homo erectus assimilated and reconceptualized events to create various prelinguistic symbolic traditions such as rituals, dance, and craft.Mythic cultures arose {{as a result of}} the acquisition of speech and the invention of symbols. Mimetic representation serves as a preadaptation to this development.Technology-supported culture: Finally, the cognitive ecology dominated by ephemeral face-to-face communication has changed for most of us {{as a result of the}} external memory-store that reading and writing permit. Computer technology intensifies these changes by offering even more extensive capacities for <b>external</b> storage and <b>retrieval</b> of information." ...|$|R
40|$|The {{rapid growth}} of images and {{photographs}} available on the Web today has created an emerging need for efficient retrieval techniques for visual information. Image searching on the Web today is carried out using text-based search methods. Searching is done by entering keywords describing the images to be retrieved. Not all aspects of an image are easy to describe by text. For instance, is difficult to describe {{the shape of a}} car by words only. Content-based image retrieval is another approach to image searching where the retrieval is based on the visual features found in the images and not on any <b>external</b> description. Content-based <b>retrieval</b> has been a active field of research for several years, but has not been used in any commercial Web search engines so far. This thesis presents techniques and index structures for building an efficient, content-based image search engine for the Web. The thesis presents requirements and issues which must be met, and provides a system design designated from the techniques presented. A prototype has been implemented for a demonstration of the concept. </p...|$|R
5000|$|Consequently, {{this has}} major impacts on bilingual individuals, who can interchangeably encode a memory in English, for instance, and encode another memory in French {{due to their}} diverse {{language}} capabilities. An example of context-dependent memory {{in the case of}} bilingualism is seen in an example by Viorica and Kaushanskaya. They asked participants this question: [...] "name a statue of someone standing with a raised arm while looking into the distance". This inquiry was asked in two separate languages, English and Mandarin. When asked the question in Mandarin, the individuals were more likely to say the [...] "Statue of Mao". However, when asked in English, the participants said the [...] "Statue of Liberty". Furthermore, when a person encodes a memory in English, but is asked about the memory in French, their inner verbalization of the memory, matches that during the encoding (i.e. they are remembering the event in the language that it was encoded with). Thus indicating the importance of reinstating the internal and <b>external</b> context during <b>retrieval</b> to match the context during encoding.|$|R
40|$|Constraint Satisfaction Problems (CSPs) (17)) are an {{effective}} framework for modeling {{a variety of}} real life applications and many techniques have been proposed for solving them efficiently. CSPs {{are based on the}} assumption that all constrained data (values in variable domains) are available at the beginning of the computation. However, many non-toy problems derive their parameters from an <b>external</b> environment. Data <b>retrieval</b> can be a hard task, because data can come from a third-party system that has to convert information encoded with signals (derived from sensors) into symbolic information (exploitable by a CSP solver). Also, data can be provided by the user or have to be queried to a database. For this purpose, we introduce an extension of the widely used CSP model, called Interactive Constraint Satisfaction Problem (ICSP) model. The variable domain values can be acquired when needed during the resolution process by means of Interactive Constraints, which retrieve (possibly consistent) information. A general framework for constraint propagation algorithms is proposed which is parametric in the number of acquisitions performed at each step. Experimental results show the effectiveness of the proposed approach. Some applications which can benefit from the proposed solution are also discussed...|$|R
40|$|Long-term {{surface storage}} of intermediate-level {{radioactive}} waste (ILW) {{has become an}} important issue for regulators and site operators in the UK following deferral of the Nirex deep repository for the disposal of ILW, and the resulting hiatus in Government policy. This paper identifies some key life-cycle issues associated with interim safe storage (ISS) of ILW, and also {{some of the key}} features of existing stores. Important risk management issues include store design and environmental controls, conditioning and packaging, package handling and cranes, operation, monitoring of waste packages, package <b>retrieval,</b> <b>external</b> environmental factors, stakeholder issues and costs. All of these issues will need to be addressed during the design, construction and operation of an ILW store. Given the wide and diverse range of issues requiring consideration, {{it may be difficult to}} choose between alternative design concepts or risk management strategies. We demonstrate a multi-criteria decision analysis approach to ILW storage in which the various attributes of alternative store designs and management strategies are scored and collectively compared using the program OnBalance. By varying the weighting of the different attributes, the sensitivity of the overall score of the various designs to their attributes may be evaluated. Ultimately, the technical issues related to store design, construction and operation will have to be balanced against the non-technical factors that may influence the development of a store, particularly those related to stakeholder interactions and public concerns. Developing a long-term interim storage strategy requires a holistic approach that embraces all of these factors...|$|R
40|$|Quasi-operational {{shipborne}} radiometers {{provide a}} fiducial reference measurement (FRM) for satellite validation of satellite sea surface skin temperature (SSTskin) <b>retrievals.</b> <b>External</b> reference blackbodies {{are required to}} verify the performance and to quantify {{the accuracy of the}} radiometer calibration system. They provide a link in an unbroken chain of comparisons between the shipborne radiometer and a traceable reference standard. A second-generation water bath blackbody reference radiance source has been developed for this purpose. The second generation Concerted Action for the Study of the Ocean Thermal Skin (CASOTS-II) blackbody has a 110 -mm-diameter aperture cylinder-cone geometry coated with NEXTEL suede 3103 paint. Interchangeable aperture stops reduce the cavity aperture diameter and minimize stray radiation. Monte Carlo modeling techniques show the effective emissivity of the cavity to be > 0. 9999 (aperture < 30 mm). The cavity is immersed in a water bath that is vigorously stirred using a pump that slowly heats the water bath at a mean rate of ~ 0. 6 K h? 1. The temperature of the water bath is measured using a thermometer traceable to the International System of Units (SI) standards. The worst-case radiance temperature of the CASOTS-II blackbody system is traceable to the SI with an uncertainty of 58 mK (millikelvin). When operating under typical laboratory conditions using an aperture of 40 mm, the uncertainty is 16 mK. An intercomparison with the U. K. National Physical Laboratory Absolute Measurements of Blackbody Emitted Radiance (AMBER) reference radiometer found no significant differences within 75 mK (110 -mm aperture) or 50 mK (40 -mm aperture), which is the combined uncertainty of the comparison and the reference standard for SI traceability of ISAR radiometer SSTskin records used for satellite SST validation. Applications of the CASOTS-II blackbody to monitor the calibration of shipborne radiometers are described and measurement protocols are proposed...|$|R
40|$|Remote sensing {{measurements}} {{are most important}} to understand the complicated dynamical and chemical processes occurring in the Earth's atmosphere. Only the measurements made by space-borne experiments can give a continuous and global overview of the atmospheric state. Most exact and comprehensive measurements made by such experiments are necessary to validate and improve atmospheric models which combine the knowledge on numerous mechanisms in the atmosphere. Since March 2002 the instrument MIPAS (Michelson Interferometer for Passive Atmospheric Sounding) is operating aboard Envisat, which is the largest and most ambitious satellite ever built by the European Space Agency. MIPAS measures the thermal emissions of atmospheric constituents like trace gases, aerosols and clouds arising from the atmospheric limb. Within the retrieval process geophysical parameters like pressure, temperature, and trace gas concentrations are derived from these measurements. A special feature of MIPAS is its high spectral resolution which allows to gather information on a large number of atmospheric trace species. The analysis of remote sensing measurements made by satellite experiments is an extensive task as time-consuming radiative transfer calculations and substantial amounts of data are typically involved. Envisat MIPAS provides 300 megabyte of measurement data during a single orbit. For future experiments, e. g. the GLORIA instrument (Global Limb Radiance Imager for the Atmosphere) recently proposed by the research centers Juelich and Karlsruhe, the amount of data may even increase by several orders of magnitude. A very important component in the analysis of atmospheric remote sensing measurements is the forward model. It is used to simulate the measurements of an instrument for a given atmospheric state. The rapid and flexible forward model JURASSIC (Juelich Rapid Spectral Simulation Code) was developed as part of this thesis. An innovative retrieval processor was created based on JURASSIC that allows for the analysis of current satellite measurements, as e. g. made by Envisat MIPAS, but is also suited to be a basic module in the analysis of future experiments. The description of structure and possible applications of JURASSIC and the retrieval system are a principal topic of this thesis. The JURASSIC retrieval system has been applied to derive the global distribution of the chlorofluorocarbons CFC- 11 and CFC- 12 from Envisat MIPAS measurements. These trace species {{are not part of the}} ESA operational retrieval at all. Scientific retrievals carried out by other working groups cover only rather limited sets of CFC- 11 and CFC- 12 data. Here, in contrast, the full measurement period from July 2002 to March 2004 is analyzed comprehensively. This could only be done, since the JURASSIC retrieval system allows for a very rapid processing of all these measurements. The derived CFC- 11 and CFC- 12 data are compared to <b>external</b> MIPAS <b>retrievals</b> and successfully validated using independent measurements. Hence, they are suited for further scientific analysis. Being long-lived trace species, CFC- 11 and CFC- 12 are most useful for dynamical studies in the upper troposphere and lower stratosphere region. Zonal means and variances of these species have been analyzed. They are mainly influenced by the residual mean circulation of the stratosphere and the activity of planetary waves. MIPAS {{measurements are}} most useful as they allow to study the seasonal behavior of these processes. In addition, the derived CFC- 11 and CFC- 12 distributions are ideally suited to investigate strongly disturbed dynamical situations. An example is the antarctic major warming in September 2002, which led to a split of the antarctic polar vortex. Such an event has never been observed before. CFC- 11 and CFC- 12 measurements during this period compare well to simulations made by the atmospheric model CLaMS (Chemical Lagrangian Model of the Stratosphere), which allows to study the processes occurring in such events in great detail...|$|R
40|$|The {{information}} {{environment of}} {{the first decade of}} the XXIst century is unprecedented. The physical barriers limiting access to the knowledge are disappearing as traditional methods of accessing information are being replaced or enhanced by computer systems. Digital systems are able to manage much larger sets of documents, confronting information users with the deluge of documents related to their topic of interest. This new situation created an incentive for the rapid development of Data Mining techniques and to the creation of more efficient search engines capable of limiting the search results to a small subset of the most relevant ones. However, most of the up to date search engines operate using the text descriptions of the documents. Those descriptions can either be extracted from the content of the document or be obtained from the <b>external</b> sources. The <b>retrieval</b> based on the non-textual content of documents is a subject of ongoing research. In particular, the retrieval of images and unlocking the information carried by them attracts a lot of attention of the scientific community. Digital libraries hold a special position amongst the systems allowing the access to knowledge. They serve the role of repositories of documents which share some common characteristics (e. g. belonging to the same area of knowledge or produced in the same institution) and as such, contain documents selected as interesting for a particular group of users. In addition, they provide retrieval facilities on top of the managed collections. Typically, scholarly publications are the smallest units of information managed in scientific digital libraries. However, there are different types of artifacts produced and used in the scientific process, among others: figures and datasets. Figures play a particularly important role in the process of scholarly publishing. Representing data in a graphical manner allows showing patterns in large datasets and to make complicated ideas easier to understand. The existing digital library systems enable the access to figures only as part of the files used for the serialisation of the entire publication. The objective of this thesis is to propose a set of methods and techniques in order to transform figures into first-class products within the scientific publication process, allowing researchers to get the maximum benefit from the search and review of bibliography. The proposed methods and techniques are oriented towards the acquisition, semantic annotation and search of figures contained in scholarly publications. Leveraging the completeness of the field and the existing community, we illustrated the described theory with examples from High-Energy Physics (HEP). At every place requiring more focused considerations, we concentrated on the type of figures that appear more frequently in the corpus of HEP publications: the plots. The described prototypes capable of processing figures have been partially integrated with the Invenio digital library software and INSPIRE - one of the largest digital libraries in the world on High-Energy Physics and created by the collaboration of the main laboratories and research centres in this domain (CERN, SLAC, DESY and Fermilab) ...|$|R

