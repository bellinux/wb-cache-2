21|568|Public
50|$|CodePhage: The first {{bug-fixing}} {{tool that}} directly transfer code across programs to generate patch for C program. Note that although it generates C patches, it can <b>extract</b> <b>code</b> from binary programs without source code.|$|E
5000|$|... "Episode 5" [...] is {{the fifth}} episode of the first series of Humans, a show based on Real Humans and co-produced by Channel 4 and AMC. In this episode, Niska {{discusses}} technology and consciousness with Doctor Millican, Leo fails to <b>extract</b> <b>code</b> from Anita and Mattie discovers someone has had sex with Anita. It originally aired in the UK on 12 July 2015, where it was watched live by 3.847 million households. In the United States, the episode aired on 26 July 2015 to a viewership of 1.15 million. The episode received positive reviews.|$|E
5000|$|Sony’s second {{submission}} in the High Court {{was that}} the device fell within {{the terms of the}} definition of [...] "technological protection measure" [...] because it prevented PlayStation users from reproducing copyrighted game code “in material form” in the Ram of the PlayStation console. “Material form” was defined, in section 10 (1) the Act, as including “any form (whether visible or not) of storage from which… a substantial part of the work can be reproduced.” [...] In cross-examination, Mr Nabarro from Sony conceded that the game code could not be reproduced “without developing particular hardware to <b>extract</b> <b>code</b> back from RAM.” ...|$|E
40|$|Abstract. We {{report on}} three {{different}} approaches to implementing hash-consing in Coq programs, using binary decision diagrams (BDD) as running example. The use cases include execution inside Coq, or execution of the <b>extracted</b> OCaml <b>code.</b> There are different trade-offs between faithful use of pristine <b>extracted</b> <b>code,</b> and code that is fine-tuned {{to make use of}} OCaml programming constructs not available in Coq. We discuss the possible consequences in terms of performances and guarantees. ...|$|R
40|$|Extraction is a {{technique}} for producing verified programs. A proof of ∀ chi : T ∃ y : T' F corresponds to a function f of type T → T' that maps every χ of type T to a y of type T' such that F is true. If the proof is constructive, then f is recursive. The semantics of <b>extracted</b> <b>code</b> involves the manipulation of justifications, which are pieces of evidence for the truth of formulas. The raw <b>extracted</b> <b>code</b> for the formula above is actually a function γ that maps χ to a pair (y, γ'), where γ' is a justification that provides evidence for the truth of F. This thesis presents various {{ways to improve the}} efficiency of extracted programs. The first way uses traditional code optimizations. Though very helpful, they are no panacea. The second way involves small changes to its underlying semantics. Certain formulas, called singleton formulas, have no interesting justifications; if F is such a formula, no justification for it needs to be built, which simplifies the <b>extracted</b> <b>code.</b> The third way to improve <b>extracted</b> <b>code</b> is to add call-by-reference parameters to it. As originally defined, <b>extracted</b> <b>code</b> passes arguments by value, which leads to inefficient code for mutable objects like arrays: passing an array by value requires making a copy of it. Adding call-by-reference parameters entails adding a state to the semantics of <b>extracted</b> <b>code,</b> which in turn leads to various semantic and syntactic design issues, like aliasing and side-effects. To account for these changes, the constructive logic used to build proofs is modified. A proof of quicksort illustrates the functional, assignment-free, side-effect-free style of proof promoted by the new logic. To relieve the user of some of the mental overhead involved in using the new logic, an array inferencing algorithm is presented. The algorithm allows users to get code that uses arrays from proofs that reason about and manipulate lists in restricted ways. In this way, users can view the use of arrays as an optimization...|$|R
40|$|We {{report on}} three {{different}} approaches to use hash-consing in programs certified with the Coq system, using binary decision diagrams (BDD) as running example. The use cases include execution inside Coq, or execution of the <b>extracted</b> OCaml <b>code.</b> There are different trade-offs between faithful use of pristine <b>extracted</b> <b>code,</b> and code that is fine-tuned {{to make use of}} OCaml programming constructs not available in Coq. We discuss the possible consequences in terms of performances and guarantees...|$|R
30|$|Agar Cell culture {{media and}} MS medium (Merck, Darmstadt, Germany), Oxoid Yeast <b>Extract</b> (<b>Code</b> L 21) (Unipath LTD, Hampshire, England), (±) Jasmonic acid (Product of Israel, Plant cell culture tested, C 12 H 18 O 3) (Sigma-Aldrich Chemie GmbH, Steinheim, Germany), and other {{materials}} were analytical and plant cell culture tested grades.|$|E
40|$|Abstract. Realizability {{theory can}} produce code {{interfaces}} {{for the data}} structure corresponding to a mathematical theory. Our tool, called RZ, serves as a bridge between constructive mathematics and programming by translating specifications in constructive logic into annotated interface code in Objective Caml. The system supports a rich input language allowing descriptions of complex mathematical structures. RZ does not <b>extract</b> <b>code</b> from proofs, but allows any implementation method, from handwritten code to code extracted from proofs by other tools. ...|$|E
40|$|Abstract. In this paper, an {{approach}} to synthesize correct programs from specifications is presented. The idea is to <b>extract</b> <b>code</b> from definitions appearing in statements which have been mechanically proved {{with the help of}} a proof assistant. This approach has been found when proving the correctness of certain Computer Algebra programs (for Algebraic Topology) by using the Isabelle proof assistant. To ease the understanding of our techniques, they are illustrated by means of examples in elementary arithmetic. ...|$|E
40|$|We {{report on}} four {{different}} approaches to implementing hash-consing in Coq programs. The use cases include execution inside Coq, or execution of the <b>extracted</b> OCaml <b>code.</b> We explore the different trade-offs between faithful use of pristine <b>extracted</b> <b>code,</b> and code that is fine-tuned {{to make use of}} OCaml programming constructs not available in Coq. We discuss the possible consequences in terms of performances and guarantees. We use the running example of binary decision diagrams and then demonstrate the generality of our solutions by applying them to other examples of hash-consed data structures...|$|R
3000|$|... {{only has}} the {{positive}} values, by introducing the bias ΔT on the <b>extracted</b> <b>code</b> index pair, the disturbance due to timing offset can be spread out around the original code index point t [...]...|$|R
40|$|In this paper, {{we propose}} a {{verification}} method {{to check the}} behavioral consistency of two given C descriptions. The main idea of the method {{is to reduce the}} verification effort by verifying only the program codes where the behavioral consistency must be checked. For this purpose, textual differences between the descriptions are identified at first. Then, based on these differences, the codes relevant to these differences are extracted by using the technique of program slicing. Then, the behavioral consistency between the de-scriptions is verified by applying symbolic simulation for the <b>extracted</b> <b>codes.</b> Our proposed method was tested on several examples. Because the verification effort was restricted to only the <b>extracted</b> <b>codes,</b> the behavioral consistency of the descriptions was efficiently verified. ...|$|R
40|$|In {{order to}} {{evaluate}} the impact that code review coverage and participation have on software quality, the authors <b>extract</b> <b>code</b> review data from the Gerrit review databases of the studied systems, and link the review data to the integrated patches recorded in the corresponding VCSs. The data extraction approach is broken down into three steps: (1) extract review data from the Gerrit review database, (2) extract Gerrit change IDs from the VCS commits, and (3) calculate version control metrics...|$|E
30|$|Although {{numerous}} {{techniques and}} tools {{have been proposed}} for code clone detection (Kamiya et al. [2002]), only little has been known about, which detected code clones are appropriate for refactoring and how to <b>extract</b> <b>code</b> clones for refactoring. A technique that helps to process the code clones is called Refactoring. Refactoring is defined as “restructuring an existing body of code, altering its internal structure without changing its external behaviour” (Fowler [1999]). By refactoring the clones detected, one can potentially improve understandability, maintainability and extensibility and reduce {{the complexity of the}} system (Fowler [1999]).|$|E
40|$|This paper {{describes}} work in progress. It {{summarizes the}} methodology for analyzing building codes and isolating generic building characteristics. These characteristics {{can be used}} by building code experts to markup code documents and subsequently by building code users to <b>extract</b> <b>code</b> provisions that apply to their projects. Although this methodology has been developed for the National Building Code of Canada, it can be applied to any model code and implemented on most computer platforms using off-the-shelf software. The paper outlines the scope of the research, the historical development, the problems encountered, and paradigms for markup and extraction of code provisions...|$|E
30|$|From this equation, several {{observations}} can be <b>extracted.</b> <b>Code</b> diversity performance {{shifts to}} the right on SNR {{with the increase in}} the number of sub-carriers and/or number of users following a logarithmic decay. Besides, the diversity due to the different transmit antennas vanishes because the number of transmit antennas is much smaller than N×Nu.|$|R
30|$|ESTScan ([URL] (Iseli et al. 1999) was {{performed}} to detect and <b>extract</b> <b>coding</b> regions from low-quality sequences with high selectivity and sensitivity, which is also able to accurately correct frameshift errors. In the framework of genome sequencing projects, ESTScan could become a very useful tool for gene discovery, for quality control, and for the assembly of consigns representing the coding regions of genes.|$|R
40|$|Legacy code {{can often}} be made more {{understandable}} and maintainable by extracting out selected sets of statements to form procedures and replacing the <b>extracted</b> <b>code</b> with procedure calls. Sets of statements that are noncontiguous and/or include non-local jumps (caused by gotos, breaks, continues, etc.) {{can be difficult to}} extract, and usually cause previous automatic-extraction algorithms to fail or to produce poor results...|$|R
30|$|To <b>extract</b> <b>code</b> from malware that applied Bangcle and DexProtector, we experimented in the {{environment}} described as follows. Because an app using Bangcle only needs to be repackaged to be executed, we ran the app on an Android version 4.4. 4 device {{that had not been}} rooted. We determined that the Bangcle version information was given by the numbers assigned with the VERSION_NAME variables in the Util class. Because a debugger needs to be used for apps that have applied DexProtector, we used a rooted device to obtain higher privileges than the app process. For the debugger, we used a GDB built for ARM use. Finally, for decompiling and repackaging, we used apktool version 2.0. 3.|$|E
40|$|Realizability {{theory is}} not just a {{fundamental}} tool in logic and computability. It also has direct application to the design and implementation of programs, since it can produce code interfaces for the data structure corresponding to a mathematical theory. Our tool, called RZ, serves as a bridge between the worlds of constructive mathematics and programming. By using the realizability interpretation of constructive mathematics, RZ translates specifications in constructive logic into annotated interface code in Objective Caml. The system supports a rich input language allowing descriptions of complex mathematical structures. RZ does not <b>extract</b> <b>code</b> from proofs, but allows any implementation method, from handwritten code to code extracted from proofs by other tools. ...|$|E
40|$|Abstract. In this paper, {{we present}} CodeXt—a novel malware code ex-traction {{framework}} built upon selective symbolic execution (S 2 E). Upon real-time detection of the attack, CodeXt {{is able to}} automatically and ac-curately pinpoint the exact start and boundaries of the attack code {{even if it is}} mingled with random bytes in the memory dump. CodeXt has a generic way of handling self-modifying code and multiple layers of encod-ing, and it can automatically extract the complete hidden and transient code protected by multiple layers of sophisticated encoders without using any signature or pattern of the decoder. To the best of our knowledge, CodeXt is the first tool that can automatically <b>extract</b> <b>code</b> protected by Metasploit’s polymorphic xor additive feedback encoder Shikata-Ga-Nai, as well as transient code protected by multi-layer incremental encoding...|$|E
40|$|We {{developed}} a rule-based {{natural language processing}} (NLP) system for <b>extracting</b> and <b>coding</b> clinical data from free text reports. We studied the systems ability to accurately <b>extract</b> and <b>code</b> family history data from hospital admission notes. The system searches the family history for 12 diseases (and relative degree). It achieved a sensitivity of. 96 and a PPV of. 97 for disease extraction, and. 96 and. 93 respectively for relative categorization...|$|R
40|$|Extract Method {{has been}} {{recognized}} as one of the most important refactorings, since it decomposes large methods and can be used in combination with other refactorings for fixing a variety of design problems. However, existing tools and methodologies support extraction of methods based on a set of statements selected by the user in the original method. The goal of the proposed methodology is to automatically identify Extract Method refactoring opportunities and present them as suggestions to the designer of an object-oriented system. The suggested refactorings adhere to three principles: the <b>extracted</b> <b>code</b> should contain the complete computation of a given variable declared in the original method, the behavior of the program should be preserved after the application of the refactoring, and the <b>extracted</b> <b>code</b> should not be excessively duplicated in the original method. The proposed approach is based on the union of static slices that result from the application of a block-based slicing technique. The soundness of the identified refactoring opportunities has been evaluated by an independent designer on the system that he developed. 1...|$|R
30|$|The tool {{automatically}} <b>extracts</b> source <b>code</b> {{models of}} a target system from its version control platform in predefined time intervals.|$|R
40|$|We {{present in}} this paper a new type system which allows to <b>extract</b> <b>code</b> for an {{abstract}} machine instead of lambda-terms. Thus, we get a framework to compile correctly programs extracted from proof by translating their proof in our system and then extracting the code. Moreover, we will see that we can associate programs to classical proofs. 1 Introduction. The proof as program paradigm, using the Curry-Howard isomorphism [4], gives a way to associate a program to an intuitionistic proof. This program is almost always a functional program (in general a lambda-term [1]) which has to be compiled before being executed [11]. This ensures some correctness about the functional program extracted from the proof. But the correctness of the compiled code is relative to the proof of the compiler. The usual way to ensure this kind of correctness is to define a semantics for the functional language, and to verify that the compiler preserves this semantics. We study {{in this paper}} a type system for th [...] ...|$|E
40|$|Realizability is an {{interpretation}} of intuitionistic logic which subsumes the Curry-Howard interpretation of propositions as types, because it allows the realizers to use computational effects such as non-termination, store and exceptions. Therefore, we can use realizability {{as a framework for}} program development and extraction which allows any style of programming, not just the purely functional one that is supported by the Curry-Howard correspondence. In joint work with Christopher A. Stone we developed RZ, a tool which uses realizability to translate specifications written in constructive logic into interface code annotated with logical assertions. RZ does not <b>extract</b> <b>code</b> from proofs, but allows any implementation method, from handwritten code to code extracted from proofs by other tools. In our experience, RZ is useful for specification of non-trivial theories. While the use of computational effects does improve efficiency it also makes it difficult to reason about programs and prove their correctness. We demonstrate this fact by considering non-purely functional realizers for a Brouwerian continuity principle...|$|E
40|$|Code clone {{detection}} tools may {{report a}} large number of code clones, while software developers are interested in only a subset of code clones that are relevant to software development tasks such as refactoring. Our research group has supported many software developers with the code clone detection tool CCFinder and its GUI front-end Gemini. Gemini shows clone sets (i. e., a set of code clones identical or similar to each other) with several clone metrics including their length and the number of code clones; however, {{it is not clear how}} to use those metrics to extract interesting code clones for developers. In this paper, we propose a method combining clone metrics to <b>extract</b> <b>code</b> clones for refactoring activity. We have conducted an empirical study on a web application developed by a Japanese software company. The result indicates that combinations of simple clone metric is more effective to extract refactoring candidates in detected code clones than individual clone metric...|$|E
30|$|The {{analyzed}} apps {{were applied}} with various versions of Bangcle, from 1.0 to 8.5. 12. However, {{all of the}} versions were able to <b>extract</b> the original <b>codes.</b> Likewise, {{it was possible to}} <b>extract</b> the original <b>codes</b> from DexProtector.|$|R
50|$|Ready Identification: A coder {{must be able}} to {{identify}} the exact record being coded in order to effectively <b>extract</b> diagnoses <b>codes.</b>|$|R
50|$|Jad (Java Decompiler) is, , an unmaintained {{decompiler}} for the Java programming language.Jad {{provides a}} command-line user interface to <b>extract</b> source <b>code</b> from class files.|$|R
40|$|In {{embedded}} systems, achieving good performances for {{signal processing}} applications {{is crucial for}} power management. Good compilation is required to have maximal use of the available processing capabilities. Compiling for communication-exposed architectures such as ADRES, TRIPS and Wavescalar is however a complex task. Dataflow graphs are mapped on execution unit grids {{in order to increase}} the instruction-level parallelism while minimizing communication. Complex algorithms and the large number of code optimizations make debugging hard for the developer. Moreover, iterative approaches are used to optimize the compiled code quality. This paper proposes to embed functional simulators in compilers in order to enable debugging and profiling-driven iterative compilation. Debugging of optimization passes is achieved by means of functional simulators, running the original code and the transformed code. Intermediate and output values results comparison allows to verify the correctness of the optimization pass. Using embedded simulators also allows to <b>extract</b> <b>code</b> and execution characteristics convenient for iterative compilation. We present the mechanisms required to control those simulators. A case study based on the TRIPS processor demonstrates the usefulness of our approach...|$|E
40|$|The {{increasing}} number of repeated malware penetrations into official mobile app markets poses a high security threat to the confidentiality and privacy of end users' personal and sensitive information. Protecting end user devices from falling victims to adversarial apps presents a technical and research challenge for security researchers/engineers in academia and industry. Despite the security practices and analysis checks deployed at app markets, malware sneak through the defenses and infect user devices. The evolution of malware has seen it become sophisticated and dynamically changing software usually disguised as legitimate apps. Use of highly advanced evasive techniques, such as encrypted code, obfuscation and dynamic code updates, etc., are common practices found in novel malware. With evasive usage of dynamic code updates, a malware pretending as benign app bypasses analysis checks and reveals its malicious functionality only when installed on a user's device. This dissertation provides a thorough study on the use and the usage manner of dynamic code updates in Android apps. Moreover, we propose a hybrid analysis approach, StaDART, that interleaves static and dynamic analysis to cover the inherent shortcomings of static analysis techniques to analyze apps {{in the presence of}} dynamic code updates. Our evaluation results on real world apps demonstrate the effectiveness of StaDART. However, typically dynamic analysis, and hybrid analysis too for that matter, brings the problem of stimulating the app's behavior which is a non-trivial challenge for automated analysis tools. To this end, we propose a backward slicing based targeted inter component code paths execution technique, TeICC. TeICC leverages a backward slicing mechanism to <b>extract</b> <b>code</b> paths starting from a target point in the app. It makes use of a system dependency graph to <b>extract</b> <b>code</b> paths that involve inter component communication. The extracted code paths are then instrumented and executed inside the app context to capture sensitive dynamic behavior, resolve dynamic code updates and obfuscation. Our evaluation of TeICC shows that it can be effectively used for targeted execution of inter component code paths in obfuscated Android apps. Also, still not ruling out the possibility of adversaries reaching the user devices, we propose an on-phone API hooking based app introspection mechanism, AppIntrospector, {{that can be used to}} analyze, detect and prevent runtime exploitation of app vulnerabilities that involve dynamic code updates...|$|E
40|$|Coverage {{analysis}} {{is critical in}} pre-silicon verification of hardware designs for assessing the completeness of verification and identifying inadequately exercised areas of the design. It is widely integrated in the simulation based verification flow in the hardware industry. In this thesis, we provide solutions to enable effective coverage analysis in assertion based and emulation based verification. We introduce two practical and effective code coverage metrics for assertions: one inspired by the test suite code coverage reported by Register Transfer Level (RTL) simulators and the other by assertion correctness {{in the context of}} formal verification. We present efficient algorithms to compute coverage with respect to the proposed metrics by analyzing the Control Flow Graph (CFG) constructed from the RTL source code. We apply our technique to a USB 2. 0 design and an OpenRISC processor design and show that our coverage evaluation is efficient and scalable. We also present a technique to evaluate and rank automatically generated assertions based on fault coverage. We present a novel technique to <b>extract</b> <b>code</b> coverage from emulation platforms. Using our CFG framework, we identify conditions or decision nodes and map them to other statements in the code. Triggering of decision nodes is recorded using additional trigger logic during emulation and mapped back to the source code to obtain coverage information. We apply our technique to an industrial design and show that it can efficiently provide fairly accurate code coverage statistics with minimal overheads during emulation...|$|E
5000|$|Tamper {{resistance}} finds {{application in}} smart cards, set-top boxes {{and other devices}} that use digital rights management (DRM). In this case, {{the issue is not}} about stopping the user from breaking the equipment or hurting themselves, but about either stopping them from <b>extracting</b> <b>codes,</b> or acquiring and saving the decoded bitstream. This is usually done by having many subsystem features buried within each chip (so that internal signals and states are inaccessible) and by making sure the buses between chips are encrypted.|$|R
50|$|After Heart of the Alien became {{unsupported}} and unavailable, a fan took up {{the effort}} of <b>extracting</b> a source <b>code</b> variant from the binary game by reverse engineering to make the game runnable again on modern platforms. This <b>extracted</b> source <b>code</b> was made open-source and is hosted freely available on Sourceforge. An Amiga version has since been released that uses {{the assets of the}} SegaCD original.|$|R
40|$|S-Check is a {{software}} tool for identifying performance bottlenecks in parallel and networked programs. The system uses and incorporates sophisticated statistical techniques and synthetic perturbation for <b>extracting</b> <b>code</b> sensitivities. The methodology demands extensive setup and execution procedures. S-Check automates {{much of this}} process. Even still, using S-Check at first glance can be formidable because of its unfamiliar scheme for performance analysis. To alleviate the initial learning curve we present a simple walk through example of {{how to set up}} and conduct an S-Check performance analysis...|$|R
