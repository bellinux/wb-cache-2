38|74|Public
50|$|The Muwallads, or Muslims of Iberian descent, {{were far}} more {{numerous}} than those of purely Arabic descent. They were composed of those descended from the marriages of the original invading Arabs to the native women of Iberia along with those who converted to Islam by choice since the invasions. The muwallads adopted Arabic genealogies and thus became <b>further</b> <b>fused</b> to the Arabs ethnically over time. By the 10th century, no clear distinction existed between the muwallads and the Arab Muslims and by the 10th century, Muslims represented about 80% {{of the total population}} of Al-Andalus, including Christian converts and the Berber Muslims.|$|E
3000|$|... [...]. The size of LBP {{feature vector}} is 1 [*]×[*] 59 that are <b>further</b> <b>fused</b> with HOG and GLCM {{features}} {{based on their}} vector size.|$|E
30|$|The butterfly-shape (Figure  8 a,b,c,d,e,f,g,h,i,j,k,l,m,n): {{exclusive}} of two {{closely related species}} - T. galaga and T. rorschachi. In this pattern, the horns of each side are fused with the corresponding arm, filling the space between them, and resulting in a much thicker body. Also arms and feet of each side are partially fused, giving a more rounded aspect. T. rorschachi (Figure  8 h,i,j,k,l,m,n) may be distinguished from T. galaga by the feet squared and the horns <b>further</b> <b>fused</b> to each other, filling the central concavity. There are also small posterior fragments.|$|E
5000|$|Magic of Incarnum {{describes}} Incarnum, which, in its pure form, {{looks like}} a [...] "radiant mist, deep blue in color." [...] With the supplemental rules provided within, characters can use incarnum to create Soulmelds using Essentia. The Soulmelds function like magically-sustained items that are applied to {{different parts of the}} body, and Essentia is invested into said Soulmelds to make them more effective. In addition to investing Essentia, characters can bind Soulmelds to different Chakras, which <b>further</b> <b>fuses</b> Soulmelds to their corresponding body parts, providing characters with bonus effects.|$|R
30|$|One {{can suggest}} {{the use of}} other speech sensors to create {{stronger}} modality combinations that can <b>further</b> be <b>fused</b> using the proposed method to boost the overall performance of an SV system.|$|R
3000|$|Iris: Kalka et al.[8] evaluates defocus (DF), {{motion blur}} (MB), {{occlusion}} (O), illumination (I), specular reflectance (SR), and pixel count (PC). <b>Further,</b> a <b>fused</b> metric (Q) is obtained using DS-theory. The technique {{is discussed in}} Section 3.|$|R
40|$|We {{propose a}} fully {{automatic}} spliced image detection method based on consistency checking of camera characteristics among different areas in an image. A test image is first segmented into distinct areas. One camera response function (CRF) is estimated from each area using geometric invariants from locally planar irradiance points (LPIPs). To classify a boundary segment between two areas as authentic or spliced, CRF cross fitting scores and area intensity features are computed and fed to SVM-based classifiers. Such segment-level scores are <b>further</b> <b>fused</b> {{to form the}} image-level decision. Tests on both the benchmark data set and an unseen high-quality spliced data set reach promising performance levels with 70 % precision and 70 % recall. 1...|$|E
30|$|In addition, machine learning, {{especially}} deep learning, {{is increasingly}} used to extract high-level features from neuroimaging data. The advantage of learning-based features {{is they do}} not depend on prior knowledge of the disorder or imaging characteristics as the hand-engineered features. They are also essentially suitable for multimodal feature learning, and could expect better performance with larger datasets. However, learning-based features heavily depend on the training datasets [141]. Recently, Suk et al. [142] proposed a feature representation learning framework for multimodal neuroimaging data. One stacked auto-encoder (SAE) was trained for each modality, then the learnt high-level features were <b>further</b> <b>fused</b> with a multi-kernel support vector machine (MK-SVM). They further proposed another deep learning framework based on the deep Boltzmann machine (DBM) and trained it using the 3 D patches extracted from the multimodal data [143].|$|E
40|$|In {{this paper}} we have studied two {{information}} fusion approaches, namely feature vector concatenation and decision fusion, {{for the task}} of reducing error rates in a speaker verification system used in mismatched conditions. Three types of features are fused: Mel Frequency Cepstral Coefficients (MFCC), MFCC with Cepstral Mean Subtraction (CMS) and Maximum Auto-Correlation Values (MACV). We have used the mismatch sensitivity of Linear Prediction Cepstral Coefficients (LPCC) as a speech quality measure for selecting {{the weight of the}} contribution of the MFCC modality in the adaptive decision fusion approach. We show that in most cases concatenation fusion is superior to decision fusion. The results lead us to propose a hybrid fusion approach in which two combinations of concatenation fusion are <b>further</b> <b>fused</b> using adaptive decision fusion. The hybrid system is shown to have the lowest error rates on both clean and noisy speech...|$|E
40|$|International audienceThis paper {{presents}} an upper-body detection algorithm that extends classical shape-based detectors {{through the use}} of additional semantic colour segmentation cues. More precisely, candidate upper-body image patches produced by a base detector are soft-segmented using a multi-class probabilistic colour segmentation algorithm that leverages spatial as well as colour prior distributions for different semantic object regions (skin, hair, clothing, background). These multi-class soft segmentation maps are then classified as true or false upper-bodies. By <b>further</b> <b>fusing</b> the score of this latter classifier with the base detection score, the method shows a performance improvement on three different public datasets and using two different upper-body base detectors, demonstrating the complementarity of the contextual semantic colour segmentation and the base detector...|$|R
40|$|Digital {{books can}} {{significantly}} enhance the reading experience, providing many functions {{not available in}} printed books. In this paper we study a particular augmentation of digital books that provides readers with customized recommendations. We systematically explore the application of spreading activation over text and citation data to generate useful recommendations. Our findings reveal that for the tasks performed in our corpus, spreading activation over text is more useful than citation data. <b>Further,</b> <b>fusing</b> text and citation data via spreading activation results in the most useful recommendations. The fused spreading activation techniques outperform traditional text-based retrieval methods. Finally, we introduce a preliminary user interface for the display of recommendations from these algorithms. Keywords Spreading activation, bibliometrics, recommendations, information visualization, 3 D book, degree of interest INTRODUCTION The digital nature of online books enables various [...] ...|$|R
40|$|In {{this paper}} we {{introduce}} a fully end-to-end approach for multi-spectral image registration and fusion. Our method for fusion combines images from different spectral channels {{into a single}} fused image by different approaches for low and high frequency signals. A prerequisite of fusion is a stage of geometric alignment between the spectral bands, {{commonly referred to as}} registration. Unfortunately, common methods for image registration of a single spectral channel do not yield reasonable results on images from different modalities. For that end, we introduce a new algorithm for multi-spectral image registration, based on a novel edge descriptor of feature points. Our method achieves an accurate alignment of a level that allows us to <b>further</b> <b>fuse</b> the images. As our experiments show, we produce a high quality of multi-spectral image registration and fusion under many challenging scenarios...|$|R
40|$|Cellulose fibers {{were used}} as {{substrates}} to induce the formation of nano-Ti 0 (2) via heterogeneous titanium oxysulfate hydrolysis under microwave irradiation. The microwave provided fast heating for the one-pot reaction at 90 degrees C {{and contributed to the}} generation of 10 nm anatase TiO 2 nanoparticles. These spherical particles <b>further</b> <b>fused</b> into 100 nm raspberry-like mesoporous TiO 2 agglomerates uniformly distributed on the cellulose surface. The composite material was able to adsorb Pb 2 + very rapidly from simulated wastewater with a maximum capacity of 42. 5 mg/g. The adsorption, characterized by pseudo-second order kinetics and Freundlich isotherm, was attributed to the reaction between the hydroxyl groups of TiO 2 and Pb 2 + to form Pb- 0 bond, as indicated by XPS analysis. The adsorbent can be easily regenerated for a number of times without significant reduction in adsorption performances. (C) 2016 Elsevier B. V. All rights reserved...|$|E
30|$|Figure  2 e,f {{shows the}} top-view SEM {{images of the}} CdS(3)/Ag 2 S/TiO 2 /ITO film. As shown in Figure  2 e, after {{introduction}} of three cycles of CdS deposition, {{a large amount of}} CdS nanocrystals are deposited {{on the surface of the}} CdS(3)/Ag 2 S/TiO 2 /ITO film, and these deposited CdS nanocrystals are <b>further</b> <b>fused</b> together, which causes a large reduction in the number of pinholes. In addition, some lumps appear on the surface of the CdS(3)/Ag 2 S/TiO 2 /ITO film. Obviously, these lumps should be CdS that resulted from the residual CdS precursor solution on the surface of the film after the calcinations at 250 °C. The corresponding high-magnification SEM image of the CdS(3)/Ag 2 S/TiO 2 /ITO film shown in Figure  2 f further reveals that the CdS nanocrystals become fused together, which is similar to the case of Ag 2 S nanocrystals in the Ag 2 S/TiO 2 /ITO film.|$|E
40|$|Mass {{segmentation}} is {{an important}} task in mammogram analysis, providing effective morphological features and regions of interest (ROI) for mass detection and classification. Inspired {{by the success of}} using deep convolutional features for natural image analysis and conditional random fields (CRF) for structural learning, we propose an end-to-end network for mammographic mass segmentation. The network employs a fully convolutional network (FCN) to model potential function, followed by a CRF to perform structural learning. Because the mass distribution varies greatly with pixel position, the FCN is combined with position priori for the task. Due to the small size of mammogram datasets, we use adversarial training to control over-fitting. Four models with different convolutional kernels are <b>further</b> <b>fused</b> to improve the segmentation results. Experimental results on two public datasets, INbreast and DDSM-BCRP, show that our end-to-end network combined with adversarial training achieves the-state-of-the-art results. Comment: First version on arXiv 2016, MICCAI 2017 Deep Learning in Medical Image Analysis (DLMIA) worksho...|$|E
50|$|The {{radio signal}} logs of unit 250/3 contain two <b>further</b> {{proximity}} <b>fuse</b> activation pings beyond the F-117 and F-16 shootdown events, indicating that either extra NATO aircraft were hit or ALE-50 towed jammer devices {{were destroyed by}} the missiles, {{as opposed to the}} SAM missiles simply missing due to radar jamming or chaff dispersal.|$|R
50|$|In {{an attempt}} to <b>further</b> allow <b>Fuse</b> viewers to get inside his head, Steven began to carry a camera on {{location}} when Steven's Untitled Rock Show traveled abroad. The web-exclusive program, Destination Untitled, captured Steven’s exploits and misadventures in preparing for, going to, and hanging out at concerts, festivals, and performances with the bands and their fans.|$|R
40|$|Despite recent {{advances}} in 3 D pose estimation of human hands, especially thanks to the advent of CNNs and depth cameras, this task is still far from being solved. This is mainly due to the highly non-linear dynamics of fingers, which makes hand model training a challenging task. In this paper, we exploit a novel hierarchical tree-like structured CNN, in which branches are trained to become specialized in predefined subsets of hand joints, called local poses. We <b>further</b> <b>fuse</b> local pose features, extracted from hierarchical CNN branches, to learn higher order dependencies among joints in the final pose by end-to-end training. Lastly, the loss function used is also defined to incorporate appearance and physical constraints about doable hand motion and deformation. Experimental results suggest that feeding a tree-shaped CNN, specialized in local poses, into a fusion network for modeling joints correlations, helps to increase the precision of final estimations, outperforming state-of-the-art results on NYU and MSRA datasets...|$|R
40|$|Rapid {{growth of}} machine {{learning}} methodologies and their applications offer new opportunity for improved transformer asset management. Accordingly, power system operators are currently looking for data-driven methods to make better-informed decisions {{in terms of}} network management. In this paper, machine learning and data fusion techniques are integrated to estimate transformer loss of life. Using IEEE Std. C 57. 91 - 2011, a data synthesis process is proposed based on hourly transformer loading and ambient temperature values. This synthesized data is employed to estimate transformer loss of life by using Adaptive Network-Based Fuzzy Inference System (ANFIS) and Radial Basis Function (RBF) network, which are <b>further</b> <b>fused</b> together {{with the objective of}} improving the estimation accuracy. Among various data fusion techniques, Ordered Weighted Averaging (OWA) and sequential Kalman filter are selected to fuse the output results of the estimated ANFIS and RBF. Simulation results demonstrate the merit and the effectiveness of the proposed method...|$|E
3000|$|... micROS {{adopts a}} role-based {{distributed}} collective perception model for different tasks. When the robots perform collective perception, the role task tree is constructed {{according to the}} perception capabilities of the collective robots and the relevance between the capabilities and the given collective perception task. Meanwhile, the role of each robot is assigned. In order to achieve maximal collective efficiency, this role assignment method {{takes into account the}} actual perception capabilities of the collective robots at the beginning of producing the role task tree. Thus, it is different from traditional methods, such as those in [18, 19], which directly decompose cooperative tasks to achieve role task trees. The perception task of each node of the role task tree is fulfilled by fusing sensing data of each corresponding robot. Then, perception results of all nodes are <b>further</b> <b>fused</b> for collective perception task. Moreover, in order to achieve globally optimized role assignment strategy and collective perception capability, {{the quantity and quality of}} the fulfillment of the collective perception task are evaluated in micROS, based on which the role task tree is dynamically adjusted.|$|E
40|$|We {{present a}} method for fusion of {{information}} derived from different airborne synthetic aperture radar (SAR) measurement processes and from different observations of the same scene. The different measurement processes are the measurements of received backscatter and measurements of received phases correlation (coherence) in interferometric SAR (InSAR) imaging. Dempster [...] Shafer Theory of Evidence (DSTE) {{will be used to}} fuse radar backscatter and coherence measurements. Basic mass assignments in DSTE are derived from neural network modelling of the considered terrain classes. The result of DSTE, i. e. assigned evidence and conflict measurements, will be <b>further</b> <b>fused</b> in an Expert System (ES), i. e. rule [...] based, fusion framework. The ES fusion system combines the information acquired by the same airborne radar instrument imaging the scene from a different flight track. The second observation is chosen so as to eliminate the harmful influence of radar ambiguities, i. e. shadow and foreshortening effects, on classification accuracy. Results of the fusion system are presented for a test site in Bavaria, Germany, where remarkable improvement compared to a single observation was achieved...|$|E
40|$|Electrical analogues of fracture, such as {{the fuse}} network model, are widely studied. However, the "analogy" between the {{electrical}} problem and the elastic problem is rarely established explicitly. <b>Further,</b> the <b>fuse</b> network is a discrete approximation to the continuous problem of fracture. It is rarely, if ever, shown that the discrete approximation indeed approaches its continuum limit. We establish both of these correspondences directly...|$|R
40|$|Autophagy is an {{intracellular}} {{catabolic pathway}} {{essential for the}} recycling of proteins and larger substrates such as aggregates, apoptotic corpses, or long-lived and superfluous organelles whose accumulation could be toxic for cells. Because of its unique feature to engulf part of cytoplasm in double-membrane cup-shaped structures, which <b>further</b> <b>fuses</b> with lysosomes, autophagy is also involved in the elimination of host cell invaders and takes an active part of the innate and adaptive immune response. Its pivotal role in maintenance of the inflammatory balance makes dysfunctions of the autophagy process having important pathological consequences. Indeed, defects in autophagy {{are associated with a}} wide range of human diseases including metabolic disorders (diabetes and obesity), inflammatory bowel disease (IBD), and cancer. In this review, we will focus on interrelations that exist between inflammation and autophagy. We will discuss in particular how mediators of inflammation can regulate autophagy activity and, conversely, how autophagy shapes the inflammatory response. Impact of genetic polymorphisms in autophagy-related gene on inflammatory bowel disease will be also discussed...|$|R
40|$|As a major type of {{transportation}} equipments, bicycles, including electrical bicycles, are distributed almost everywhere in China. The accidents caused by bicycles {{have become a}} serious threat to the public safety. So bicycle detection is one major task of traffic video surveillance systems in China. In this paper, a method based on multi-feature and multi-frame fusion is presented for bicycle detection in low-resolution traffic videos. It first extracts some geometric features of objects from each frame image, then concatenate multiple features into a feature vector and use linear support vector machine (SVM) to learn a classifier, or put these features into a cascade classifier, to yield a preliminary detection result regarding whether an object is a bicycle. It <b>further</b> <b>fuses</b> these preliminary detection results from multiple frames to provide a more reliable detection decision, together with a confidence level of that decision. Experimental results show that this method based on multi-feature and multi-frame fusion can identify bicycles with high accuracy and low computational complexity. It is, therefore, applicable for real-time traffic video surveillance systems...|$|R
40|$|Abstract–The most {{important}} {{application of the}} dual-modality PET/CT {{is the ability to}} efficiently display the fused data. However, in PET/CT fusion, the amount of information displayed is often impaired as the CT data occupies greater range of contrast than that is possible to display without enhancements. A common approach to improving the CT information in the PET/CT fusion is by enhancing the contrast range of the CT data which can improve on the accuracy of structure localization and PET/CT interpretation. In this study, we present an interactive multi-image fusion which optimizes the display of the information from dual-modality PET/CT data. By interactively selecting a specific CT contrast range and assigning the resultant image as a layer, the multi-layers can be constructed and then fused using the multi-image pixel compositing. The enhanced CT data is <b>further</b> <b>fused</b> with the PET data for PET/CT diagnosis. The proposed algorithm is able to simultaneously display greater amount of information from the fused PET/CT data and reveal substantial details of the CT data {{that would not have been}} possible with standard PET/CT fusion. The preliminary results are encouraging and show potential in the PET/CT diagnosis and interpretation. I...|$|E
40|$|Abstract—We {{present a}} fully {{automatic}} method to detect doctored digital images. Our method {{is based on}} a rigorous consistency checking principle of physical characteristics among different arbitrarily shaped image regions. In this paper, we specifically study the camera response function (CRF), a fundamental property in cameras mapping input irradiance to output image intensity. A test image is first automatically segmented into distinct arbitrarily shaped regions. One CRF is estimated from each region using geometric invariants from locally planar irradiance points (LPIPs). To classify a boundary segment between two regions as authentic or spliced, CRF-based cross fitting and local image features are computed and fed to statistical classifiers. Such segment level scores are <b>further</b> <b>fused</b> to infer the image level authenticity. Tests on two data sets reach performance levels of 70 % precision and 70 % recall, showing promising potential for real-world applications. Moreover, we examine individual features and discover the key factor in splicing detection. Our experiments show that the anomaly introduced around splicing boundaries plays the major role in detecting splicing. Such finding is important for designing effective and efficient solutions to image splicing detection. Index Terms—Camera response function (CRF), image forensics, splicing detection, tampering detection. I...|$|E
40|$|A {{high-performance}} differential {{global positioning}} system (GPS)   receiver with real time kinematics provides absolute localization for driverless cars. However, it is not only susceptible to multipath effect but also unable to effectively fulfill precise error correction {{in a wide range of}} driving areas. This paper proposes an accurate GPS–inertial measurement unit (IMU) /dead reckoning (DR) data fusion method based on a set of predictive models and occupancy grid constraints. First, we employ a set of autoregressive and moving average (ARMA) equations that have different structural parameters to build maximum likelihood models of raw navigation. Second, both grid constraints and spatial consensus checks on all predictive results and current measurements are required to have removal of outliers. Navigation data that satisfy stationary stochastic process are <b>further</b> <b>fused</b> to achieve accurate localization results. Third, the standard deviation of multimodal data fusion can be pre-specified by grid size. Finally, we perform a lot of field tests on a diversity of real urban scenarios. The experimental results demonstrate that the method can significantly smooth small jumps in bias and considerably reduce accumulated position errors due to DR. With low computational complexity, the position accuracy of our method surpasses existing state-of-the-arts on the same dataset and the new data fusion method is practically applied in our driverless car...|$|E
40|$|Background: {{the last}} few decades have seen a {{progressive}} shift in paradigm, replacing the notion of body implants as inert biomaterials for that of immune-modulating interactions with the host. Purpose: this text represents an attempt at understanding the current knowledge on the healing mechanisms controlling implant-host interactions, thus interpreting osseointegration and the peri-implant bone loss phenomena also from an immunological point of view. Materials and Methods: a Narrative Review approach was taken in the development of this article. Results: Osseointegration, actually representing a foreign body reaction (FBR) to biomaterials, is an immune-modulated, multifactorial and complex healing process where a number of cells and mediators are involved. The build-up of osseointegration seems to be an immunologically and inflammatory driven process, with the ultimate end to shield off the foreign material placed in the body, triggered by surface protein adsorption, complement activation and build-up of a fibrin matrix, followed by recruitment of granulocytes, mesenchymal stem cells (MSCs) and monocytes/macrophages, with the latter largely controlling the longer term response, <b>further</b> <b>fusing</b> into foreign body giant cells (FBGC), while bone cells make and remodel hydroxyl apatite. The above sequence results in the FBR that we call osseointegration and use for clinical purposes. However, the long term clinical function is dependent on a foreign body equilibrium, that if disturbed may lead to impaired clinical function of the implant, through a breakdown process where macrophages are again activated and may <b>further</b> <b>fuse</b> into FBGCs, now seen in much greater numbers, resulting in the start of bone resorption- due to cells such as osteoclasts with different origins and possibly even macrophages degrading more bone than what is formed via osteoblastic activity- and rupture of mucosal seals, through complex mechanisms in need of further understanding. Infection may follow as a secondary event, further complicating the clinical scenario. Implant failure may ensue. Conclusions: dentistry is still to embrace the concept of the biomaterials healing- and immune-modulating effect when in contact with body tissues. The presented knowledge has the potential to open the door for a different interpretation of past, current and future observations in dental implant science. From a clinical standpoint it seems recommendable to react as rapidly as possible when facing peri-implant bone loss, trying to re-establish a foreign body equilibrium if with some bone resorption...|$|R
30|$|In {{three cases}} the {{superficial}} intermediate layer {{separated from the}} deep intermediate layer more proximal. The former again <b>fused</b> <b>further</b> distally with the deep gliding aponeurosis of the vastus medialis and the tendon of the rectus femoris.|$|R
25|$|While {{dialogue}} {{can involve}} {{two or more}} people having conversations about opposing view points, it is not dialectical {{because there is no}} thesis or antithesis. In dialetical debates, all parties engaged are trying to prove the other wrong (which is what modern day psychotherapy boils down to). Rather, dialogue is more of a fusion of horizons, to use Gadamer’s term. When Dasein engages in dialogue with others, his horizon effectively fuses with the horizons of others. These horizons are polyphonic (multi-voiced) and fuse {{for the sole purpose of}} achieving higher truth and understanding. Put differently, the horizons of two polyphonic individuals are fused together during dialogue in such a way that both horizons are influenced and edified as opposed to one winning out over the other, and as opposed to one horizon remaining the same while the other that is judged to be wrong, or could be, is changed. Hermeneutics states that fusing horizons with others involves memory and imagination. It is through dialogue that memory and imagination enables therapists to empathically envision (intropathy) the horizon of their clients and <b>further</b> <b>fuse</b> it with their own.|$|R
40|$|International {{audience}} 3 D Face recognition {{has emerged}} {{in the recent years}} as a major solution to deal with the unsolved issues for reliable 2 D face recognition, namely lighting condition and viewpoint variations. However, the 3 D approach is currently limited by its cost of registration and computational complexity. In this paper, we propose to investigate an asymmetric face recognition solution, i. e. enrolling people in 3 -D but performing authentication in 2 -D. The goal is to limit the use of 3 -D data to where it really helps to improve recognition performances. In our approach, Local Binary Patterns (LBP) are used as an efficient facial representation both for 2 D texture and 3 D range facial images. A weighted Chi square distance is computed as the matching score between 2 D LBP facial texture images Canonical Correlation Analysis (CCA) is introduced to learn the mapping between LBP-based range facial image (3 D) andLBP facial texture image (2 D). Both matching scores are <b>further</b> <b>fused</b> to obtain the final result. Compared with the traditional 2 D- 2 D algorithms, our LBP and CCA-based asymmetric face recognition solution scheme achieves better performance while avoiding the registration cost and computational complexity in 3 D- 3 D approaches...|$|E
40|$|Classification is a {{significant}} subject in hyperspectral remote sensing image processing. This study proposes a spectral-spatial feature fusion algorithm for the classification of hyperspectral images (HSI). Unlike existing spectral-spatial classification methods, the influences and interactions of the surroundings on each measured pixel were taken into consideration in this paper. Data field theory was employed as the mathematical realization of the field theory concept in physics, and both the spectral and spatial domains of HSI were considered as data fields. Therefore, the inherent dependency of interacting pixels was modeled. Using data field modeling, spatial and spectral features were transformed into a unified radiation form and <b>further</b> <b>fused</b> into a new feature by using a linear model. In contrast to the current spectral-spatial classification methods, which usually simply stack spectral and spatial features together, the proposed method builds the inner connection between the spectral and spatial features, and explores the hidden information that contributed to classification. Therefore, new information is included for classification. The final classification result was obtained using a random forest (RF) classifier. The proposed method was tested with the University of Pavia and Indian Pines, two well-known standard hyperspectral datasets. The experimental results demonstrate that the proposed method has higher classification accuracies than those obtained by the traditional approaches...|$|E
40|$|The most {{important}} {{application of the}} dual-modality PET/CT {{is the ability to}} efficiently display the fused data. However, in PET/CT fusion, the amount of information displayed is often impaired as the CT data occupies greater range of contrast than that is possible to display without enhancements. A common approach to improving the CT information in the PET/CT fusion is by enhancing the contrast range of the CT data which can improve on the accuracy of structure localization and PET/CT interpretation. In this study, we present an interactive multi-image fusion which optimizes the display of the information from dual-modality PET/CT data. By interactively selecting a specific CT contrast range and assigning the resultant image as a layer, the multi-layers can be constructed and then fused using the multi-image pixel compositing. The enhanced CT data is <b>further</b> <b>fused</b> with the PET data for PET/CT diagnosis. The proposed algorithm is able to simultaneously display greater amount of information from the fused PET/CT data and reveal substantial details of the CT data {{that would not have been}} possible with standard PET/CT fusion. The preliminary results are encouraging and show potential in the PET/CT diagnosis and interpretation. Department of Electronic and Information EngineeringAuthor name used in this publication: Dagan FengCentre for Multimedia Signal Processing, Department of Electronic and Information Engineerin...|$|E
40|$|License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. Autophagy is an intracellular catabolic pathway {{essential for the}} recycling of proteins and larger substrates such as aggregates, apoptotic corpses, or long-lived and superfluous organelles whose accumulation could be toxic for cells. Because of its unique feature to engulf part of cytoplasm in double-membrane cup-shaped structures, which <b>further</b> <b>fuses</b> with lysosomes, autophagy is also involved in the elimination of host cell invaders and takes an active part of the innate and adaptive immune response. Its pivotal role in maintenance of the inflammatory balance makes dysfunctions of the autophagy process having important pathological consequences. Indeed, defects in autophagy {{are associated with a}} wide range of human diseases including metabolic disorders (diabetes and obesity), inflammatory bowel disease (IBD), and cancer. In this review, we will focus on interrelations that exist between inflammation and autophagy. Wewill discuss in particular howmediators of inflammation can regulate autophagy activity and, conversely, how autophagy shapes the inflammatory response. Impact of genetic polymorphisms in autophagy-related gene on inflammatory bowel disease will be also discussed. 1...|$|R
40|$|In this paper, {{we present}} a novel {{approach}} to recognizing human actions from different views by view knowledge transfer. An action is originally modelled as a bag of visual-words (BoVW), which is sensitive to view changes. We argue that, as opposed to visual words, there exist some higher level features which can be shared across views and enable the connection of action models for different views. To discover these features, we use a bipartite graph to model two view-dependent vocabularies, then apply bipartite graph partitioning to co-cluster two vocabularies into visual-word clusters called bilingual-words (i. e., high-level features), which can bridge the semantic gap across viewdependent vocabularies. Consequently, we can transfer a BoVW action model into a bag-of-bilingual-words (BoBW) model, which is more discriminative {{in the presence of}} view changes. We tested our approach on the IXMAS data set and obtained very promising results. Moreover, to <b>further</b> <b>fuse</b> view knowledge from multiple views, we apply a Locally Weighted Ensemble scheme to dynamically weight transferred models based on the local distribution structure around each test example. This process can further improve the average recognition rate by about 7 %. 1...|$|R
50|$|While {{dialogue}} {{can involve}} {{two or more}} people having conversations about opposing view points, it is not dialectical {{because there is no}} thesis or antithesis. In dialetical debates, all parties engaged are trying to prove the other wrong (which is what modern day psychotherapy boils down to). Rather, dialogue is more of a fusion of horizons, to use Gadamer’s term. When Dasein engages in dialogue with others, his horizon effectively fuses with the horizons of others. These horizons are polyphonic (multi-voiced) and fuse {{for the sole purpose of}} achieving higher truth and understanding. Put differently, the horizons of two polyphonic individuals are fused together during dialogue in such a way that both horizons are influenced and edified as opposed to one winning out over the other, and as opposed to one horizon remaining the same while the other that is judged to be wrong, or could be, is changed. Hermeneutics states that fusing horizons with others involves memory and imagination. It is through dialogue that memory and imagination enables therapists to empathically envision (intropathy) the horizon of their clients and <b>further</b> <b>fuse</b> it with their own.|$|R
