4|3037|Public
40|$|Abstract Pair {{formation}} in the bushcricket Gampsocleis gratiosa is achieved through acoustic signalling by the male and phonotactic approaches of the female towards the calling song. On a walking belt in the <b>free</b> <b>sound</b> <b>field,</b> females tracked {{the position of the}} speaker broadcasting the male calling song with a remarkable precision, deviating by no more than 10 cm in either direction from the ideal course. Starting with stimulus angles of 6 – 10 the females significantly turned to the correct side, and with stimulus angles greater than 25 no incorrect turns were made. Using neurophysiological data on the directionality of the ear we calculated that with such stimulus angles the available binaural intensity difference is in the order of 1 – 2 dB. We developed a dichotic ear stimulation device for freely moving females with a cross-talk barrier of about 50 dB, which allowed to precisely apply small binaural intensity differences. In such a dichotic stimulation paradigm, females on aver-age turned to the tronger stimulated side starting with a 1 dB difference between both ears. The significance of such a reliable lateralization behaviour with small in-teraural intensity differences for phonotactic behaviour under natural conditions is discussed...|$|E
40|$|The {{features}} that separate an opera house from a concert hall are the semi-closed performance area, orchestra pit, and the compart-mental audience areas, or boxes. The sound propagated from the orchestra pit reaches listeners through barriers and diffraction effects. As well, the sound arriving to listeners {{seated in the}} boxes is further limited because it must cross the box openings. In this study, to assess the sound fields of opera houses, the maximum sound pressure of direct sound coming from an impulse response measured in the Teatro Nuovo di Spoleto is investigated using G re (relative strength), which is {{the ratio of the}} sound pressure measured in a hall to an equivalent sound pressure that would be measured at the same distance from the same source to the receiver in a <b>free</b> <b>sound</b> <b>field.</b> Impulse response analyses show that G re is predicted mainly by the elevation angle from the source to the edges (pit rail and box rails), and that the values of G re also have high correlations with the interaural cross-correlation coefficient (IACC). G re is suggested as a useful parameter for quantifying the barrier effect of a pit and for evaluating the architectural design of opera house boxes...|$|E
40|$|The {{auditory}} tympana in the quail, Coturnix coturnix japonica (L.) are in-ternally {{coupled by}} an interaural air space. Unilaterally applied sound causing vibration of the ipsilateral tympanum is conducted through the interaural cavity {{to the inside}} surface of the contralateral tympanum. In a <b>free</b> <b>sound</b> <b>field</b> at frequencies up to 3150 Hz, sound pressure at the external surface of the tympanum contralateral to the source is within about 3 dB of the pressure exterior to the ipsilateral tympanum. Sound pressures developed at the inner surfaces of the tympana are of similar amplitude to the external pressures at several frequencies in the range 800 - 6300 Hz. In addition, pressure at {{each side of the}} tympanum ipsilateral to the source are generally out of phase, whereas pressures at each side of the contralateral tympanum are relatively close to the same phase. From measurements of amplitude and phase of the interacting pressures at the tympanum, the calculated driving pressure at the ipsilateral tympanum exceeds that at the contralateral tympanum by 10 - 20 dB over a range of frequencies. The auditory tympana in quail have considerable inherent directionality, therefore, due to their function as pressure-gradient receivers. Anatomical analogies with anurans and reptiles indicate that they derive directional hearing from the same acoustic mechan-ism that operates in the quail...|$|E
40|$|In a <b>sound</b> <b>field</b> {{disturbance}} of pressure, particle velocity, density, temperature, and energy occur. In this paper acoustic disturbances in air are considered. In {{the majority of}} papers on acoustics only changes in the sound pressure are reported while in this paper results on the particle velocity are reported. Since particle velocity is a vector, while the pressure is a scalar, more information can be obtained when using a particle velocity sensor instead of a pressure sensor (microphone). Four particle velocity sensors are combined to one (small) device. In a reverberant room the four autospectra and the six cross spectra are determined. Interpretation of the measured results gives information of the <b>free</b> <b>field</b> (<b>sound</b> <b>field</b> without a contribution of reflections) {{as well as of the}} reverberant fiel...|$|R
40|$|Feedback active {{noise control}} (FB-ANC) systems need no {{reference}} signal sensors and their implementation cost is therefore attractive due to the relatively simple configuration. This paper reports the design of an FB-ANC system for <b>free</b> <b>sound</b> <b>fields</b> by H ∞ control theory based on a lower-order infinite impulse response (IIR) model of the acoustic plant. The acoustic plant, which is an acoustic transmission system from a loudspeaker (i. e. the actuator) to an error microphone (i. e. the sensor), is first devised by using the physical modeling method {{in conjunction with a}} system identification result. The feedback controller is next designed to attenuate the noise level {{in the vicinity of the}} error sensor by reducing the sensitivity function over the frequency range of interest. H ∞ control theory is applied to achieve the control objective, because it can formulate the control specifications in terms of the frequency weighting functions in the frequency domain. Finally, the effectiveness of the proposed design procedure is demonstrated by experimental tests...|$|R
5000|$|Assuming <b>free</b> <b>field</b> <b>sound</b> propagation, it {{has been}} shown that the <b>sound</b> <b>field</b> {{presented}} by these two transducers can deliver an appropriate phase difference between the positions of listener’s ears at low frequencies, where the relation between the position of phantom image and the corresponding amplitude ratio may be summarized by the so-called ‘sine law’ [...] (similarly, the tangent law).|$|R
40|$|Vibratory mode of {{the infant}} skull was {{observed}} and analysed by holography to elucidate the mechanism of bone-conduction hearing in the childhood. Three dried human infant skulls, one of six months, two of eight months postnatal age, were used. As the cranial suture was incomplete with the wide fonticulus remaining and the composition was not so dense or strong {{as that of the}} adult, very careful manipulation was needed in the experiment with the infant skull. Consequently, an acoustic loud-speaker was utilized to make the infant skull vibrate in the <b>free</b> <b>sound</b> <b>field,</b> instead of using direct vibrator conventionally attached to the adult skull for the measurement of vibration. An area around the foramen occipitale magnum was fixed by means of bolts, and the skull was stood on a table. Attempts were made to change the frequency and intensity of the test sounds during the experiment. The sound pressure level of the sound field was measured with a noise meter. The value measured {{at the site of the}} skull closest to the loud-speaker was regarded as the intensity of the test sound. The resulting pattern of vibration was recorded and reconstructed by holographic interferometry. As the light source for holography helium-neon laser was used. Interference fringes were observed at 110 phon or more of the intensities of the test sounds. When frequency of the test tone was low such that 500 Hz or less, interference fringes of parallel lines were observed in the hologram. This meant the skull was found to vibrate as a whole, and the sound signal seemed to be transmitted by "inertia bone-conduction" in the mechanism of hearing when the frequency of the test sound was 500 Hz or less. on the other hand, at 1 kHz and more of the test frequency, the vibratory pattern changed into concentric fringes with multiple maximum points of amplitude. Then, it was clarified that when the frequency was 1 KHz or more, "compression bone-conduction" was added up in the hearing mechanism. At about 3 KHz of test sound, the vibratory amplitude was larger than any other frequencies used, suggesting that 3 KHz was the closest to the resonance frequency {{of the infant}} skull...|$|E
40|$|An {{analogy between}} {{electromagnetism}} and acoustics {{is presented in}} 2 D. The propagation of sound in presence of absorbing material is modeled using an open boundary microwave package. Validation is performed through analytical and experimental results. Application to local impedance active control for <b>free</b> <b>field</b> <b>sound</b> absorption is finally described...|$|R
40|$|<b>Sound</b> <b>field</b> {{reconstruction}} technologies, that is, {{models of}} the <b>sound</b> <b>field</b> radiated by some physical sources in different environments, often constitute the key technical component of various acoustics-related engineering applications, such as: sound radiation visualization, sound source identification, audio product evaluation, etc. A new approach was proposed and implemented here to predict the sound radiation of a loudspeaker or other similar audio devices into a room (i. e., reverberant) environment specifically {{for the purpose of}} virtual evaluation of a designed product. In the first step of the proposed simulation approach, a free-space <b>sound</b> <b>field</b> model of the physical device is constructed based on anechoic <b>sound</b> <b>field</b> information at a number of locations, either measured or simulated. In the next and final step, the results of the previously generated free-space model are input into a room acoustics model which describes the effect of the room on the <b>sound</b> <b>field,</b> and which allows the sound pressure signals at certain locations in the room to be used for subjective sound quality evaluation. A new model, named the Simple Source Model (SSM), was developed for the <b>free</b> space <b>sound</b> <b>field</b> reconstruction process. Exact definitions of simple sources of different orders were clarified from a mathematical point-of-view, based on which the analytical <b>sound</b> <b>field</b> expressions for simple sources were derived. The method of simple source <b>sound</b> <b>field</b> decomposition was formulated to simplify the form of the model parameter estimation process. Appropriate algorithms were chosen to solve the parameter estimation problem based on research in optimization techniques. For the purpose of room acoustics modeling, an image source model was chosen for its simplicity and because actual listening test rooms are usually of a relatively simple geometry like a rectangular cuboid. Both simulation and experimental results have validated the use of each of the two models involved. A software package was built to perform the whole simulation process and to generate audible signals for product evaluation under different room environments. ...|$|R
40|$|Objectives] In {{order to}} study the {{underwater}} jet noise characteristics, [Methods] the Lighthill acoustic analogy is carried out to compute the underwater <b>free</b> jet flow <b>sound</b> <b>field</b> characteristic of axisymmetric nozzle, with applying of FLUENT simulation software and large eddy simulation, the real flow field of submerged axisymmetric nozzle is simulated, and the jet noise {{is measured by the}} reverberation method. [Results] The results show that the core length of steady flow field is independent of flow rate, and the length is about 8 times the diameter of the nozzle. The radiation power of jet noise is proportional to the velocity of eight times. The power spectrum of jet noise is different with the flow velocity in the low frequency. In the high frequency, the difference is significantly reduced. The radiated noise energy is mainly concentrated in the low frequency. With the increase of flow velocity, the main contribution of jet noise moves to high frequency. [Conclusions] In terms of computing simulation of jet noise, the large eddy simulation and Lighthill acoustic analogy combined analysis is an effective means...|$|R
50|$|In the <b>free</b> <b>field,</b> <b>sound</b> {{which has}} its origin at a point (a point source) will be {{propagated}} equally in all directions as a sphere. Since the surface area of a sphere = 4π r² where r is the radius, every doubling of the radius results in a four-fold increase in the sphere's surface area. The result {{of this is that}} the sound intensity quarters for every doubling of distance from the point source. Sound intensity is the acoustic power per unit area, and it decreases as the surface area increases since the acoustic power is spread over a greater area. The ratio between two acoustic pressures in deciBels is expressed by the equation dB = 20log(p1/p2), so for every doubling of distance from the point source p1 = 1 and p2 = 2, thus there is a sound pressure decrease of approximately 6 dB.|$|R
40|$|In {{order to}} deal with the {{acoustic}} radiation from rotating sources, this paper describes a frequency-domain numerical method for predicting sound radiation. The method is based on the analytical Green’s function of rotating monopole and dipole source in <b>free</b> space. <b>Sound</b> radiation model is established and characteristics of <b>sound</b> <b>field</b> are discussed by numerical simulation and the relationship between radiated sound frequencies and acoustic nature frequency of source, angular frequency and its harmonics can be revealed. The radiated <b>sound</b> <b>field</b> has a strong directivity, fundamental frequency transmitting in the rotary shaft direction and harmonics spreading along radial direction and frequency shift phenomena appearing clearly in higher rotating speed of source. The method has a theoretical significance for exploring the low-noise rotating machinery. </p...|$|R
40|$|Results of a {{national}} survey on <b>sound</b> <b>field</b> usage and <b>sound</b> <b>field</b> calibration are presented. The {{purposes of this study}} are: (1) to describe and analyze <b>sound</b> <b>field</b> stimuli, <b>sound</b> <b>field</b> test conditions, and <b>sound</b> <b>field</b> calibration procedures currently employed by audiologists nationwide, and (2) to investigate the extent of agreement between current practice and suggested practice from the current literature. Respondents to the survey were 418 ASHA certified audiologists, who answered questions on demographic variables, <b>sound</b> <b>field</b> testing conditions, and <b>sound</b> <b>field</b> calibration procedures. Eighty-one percent of the respondents use <b>sound</b> <b>field</b> audiometry as part of their audiological practice. Demographic characteristics of the respondents indicate that they were representative of the population of ASHA certified audiologists. Most respondents use two loudspeakers for <b>sound</b> <b>field</b> testing and use warbled pure tones for the stimuli. Forty-two different models of audiometers are in use, although three models account for over one-half of the responses. Electroacoustic calibration of the <b>sound</b> <b>field</b> stimuli is done most often by an equipment technician, and {{only a small percentage of}} the respondents knew how the calibration was done. No pattern of significant interactions was found among the calibration methods, <b>sound</b> <b>field</b> test conditions, and demographic variables of the subjects. Results show a lack of standardization among <b>sound</b> <b>field</b> test rooms, great diversity in the stimuli used for <b>sound</b> <b>field</b> testing, and inconsistent calibration methods. Results therefore indicate the need for national standards and improved pre-service and in-service training in <b>sound</b> <b>field</b> testing and <b>sound</b> <b>field</b> calibration techniques. Recommendations for clinical practice in <b>sound</b> <b>field</b> testing and <b>sound</b> <b>field</b> calibration are proposed...|$|R
40|$|Frogs {{rely upon}} vocal {{communication}} to advertise for potential mates, to defend territory and to alarm neighbors of danger. Cells in the auditory midbrain of an awake frog display tuning to the spectral energy present in calls based upon discharge rate and encode the temporal properties of {{calls in the}} timing of their discharges. This laboratory experiment is designed to allow students to explore the relationship between stimulus amplitude or frequency and response rate, and how the timing of responses {{can also be used}} to encode behaviorally relevant features of the stimulus. Action potentials in the midbrain auditory nucleus, the torus semicularis, are evoked by delivery of <b>free</b> <b>field</b> <b>sounds</b> and recorded. Most cells are broadly tuned to frequency, yet some can be fairly precise in preserving periodic structure. The use of a comparative model of study should help students understand principles common among all sensory systems, and an appreciation that the architecture of each system is adaptively matched to the ethological task at hand. Key words: Rana, sensory coding, comparative model...|$|R
50|$|In {{near-field}} acoustical holography, light refraction {{is measured}} in a two-dimensional area in the medium (this two-dimensional <b>sound</b> <b>field</b> is {{a cross section of}} the three-dimensional <b>sound</b> <b>field)</b> to produce a hologram. Then the wave number of the medium is estimated through analysis of the water temperature. Multiple two-dimensional <b>sound</b> <b>fields</b> are calculated, and the three-dimensional <b>sound</b> <b>field</b> can be reconstructed as well.|$|R
40|$|An {{application}} of current interest in sound reproduction systems {{is the creation}} of multizone <b>sound</b> <b>fields</b> which produce multiple independent <b>sound</b> <b>fields</b> for multiple listeners. The challenge in producing such <b>sound</b> <b>fields</b> is the avoidance of interference between sound zones, which is dependent on the geometry of the zone and the direction of arrival of the desired <b>sound</b> <b>fields.</b> This paper provides a theoretical basis for the generation of two zones based on the creation of <b>sound</b> <b>fields</b> with nulls and the positioning of those nulls at arbitrary positions. The nulls are created by suppressing low-order mode terms in the <b>sound</b> <b>field</b> expansion. Simulations are presented for the two-dimensional case which shows that suppression of interference is possible across a broad frequency audio range...|$|R
40|$|The {{ability to}} {{replicate}} a plane wave represents {{an essential element}} of spatial <b>sound</b> <b>field</b> reproduction. In <b>sound</b> <b>field</b> synthesis, the desired field is often formulated as a plane wave and the error minimized; for other <b>sound</b> <b>field</b> control methods, the energy density or energy ratio is maximized. In all cases and further to the reproduction error, it is informative to characterize how planar the resultant <b>sound</b> <b>field</b> is. This paper presents a method for quantifying a region's acoustic planarity by superdirective beamforming with an array of microphones, which analyzes the azimuthal distribution of impinging waves and hence derives the planarity. Estimates are obtained for a variety of simulated <b>sound</b> <b>field</b> types, tested with respect to array orientation, wavenumber, and number of microphones. A range of microphone configurations is examined. Results are compared with delay-and-sum beamforming, which is equivalent to spatial Fourier decomposition. The superdirective beamformer provides better characterization of <b>sound</b> <b>fields</b> and is effective with a moderate number of omni-directional microphones over a broad frequency range. Practical investigation of planarity estimation in real <b>sound</b> <b>fields</b> is needed to demonstrate its validity as a physical <b>sound</b> <b>field</b> evaluation measure...|$|R
40|$|In this paper, {{we study}} the spatialization of the <b>sound</b> <b>field</b> in rooms, in {{particular}} {{the evolution of the}} room impulse responses in function of their spatial positions. Thanks to this study, we are now able to predict the <b>sound</b> <b>field</b> in any position knowing the <b>sound</b> <b>field</b> in a certain number of positions in the room. If enough measurements are taken, we are able to completely characterize the <b>sound</b> <b>field</b> of the room at any arbitrary location. Further, we determine the number and the spacing between the microphones needed to reconstruct the <b>sound</b> <b>field</b> in a room up to a certain temporal frequency...|$|R
40|$|Numerous {{innovative}} controllers {{and collaborative}} tactile interfaces {{have been developed}} for social interaction with <b>sound.</b> This evolutionary <b>field</b> of interaction design has led {{to a wide range of}} compositional models that increasingly mirror the open source methodologies developed by the creators of such systems. The authors consider the software integration of such systems and propose a potential model for <b>free</b> <b>sound</b> composition. We speculate on how these integrative approaches are leading to new compositional frameworks for distributed composition, providing an overview of how an open source development approach influences the structure, interaction design and compositional output of such systems. The range of related works in this field is considerable, selected examples are considered in terms of interaction models & compositional approaches that offer a <b>free</b> <b>sound</b> or open source model for social collaboration with the potential for distributed composition. 1...|$|R
40|$|We {{study the}} spatialization of the <b>sound</b> <b>field</b> in a room, in {{particular}} the evolution of room impulse responses as function of their spatial positions. The presented technique allows us to completely characterize the <b>sound</b> <b>field</b> in any arbitrary location if the <b>sound</b> <b>field</b> is known in a certain finite number of positions. In this paper, we include an analytical solution of the problem for any rectangular room. Further results on reconstruction of the <b>sound</b> <b>field</b> by interpolation of the Plenacoustic function are discussed...|$|R
40|$|In this paper, {{we study}} the spatialization of the <b>sound</b> <b>field</b> in rooms, in {{particular}} {{the evolution of the}} room impulse responses in function of their spatial positions. Thanks to this study, we are now able to predict the <b>sound</b> <b>field</b> in any position knowing the <b>sound</b> <b>field</b> in a certain number of positions in the room. If enough measurements are taken, we are able to completely characterize the <b>sound</b> <b>field</b> of the room at any arbitrary location. The existing techniques usually make use of models of the room in order to recreate the <b>sound</b> <b>field</b> present {{at some point in the}} room. The models take in consideration the different walls materials, obstacles present in the room, etc. Our technique simply starts from the measurements of the room impulse response in a finite number of positions and starting from this information the total <b>sound</b> <b>field</b> is then recreated. Further, we determine the number and the spacing between the microphones needed to reconstruct the <b>sound</b> <b>field</b> in a room up to a certain temporal frequency. We give a link between the temporal frequency of the sound and the spatial frequency of the sensors (microphones) in order to reconstruct the <b>sound</b> <b>field...</b>|$|R
40|$|The {{object of}} this study is to clarify what kind of <b>sound</b> <b>field</b> is {{desirable}} for musical players on the stage in auditoria and to propose a method to evaluate stage acoustics. In this paper, three psycho-acoustical experiments on stage <b>sound</b> <b>field</b> by clarinetists and horn players are performed. In the experiments, professional clarinetists and horn players are asked to evaluate which <b>sound</b> <b>field</b> is good for their musical performance among the <b>sound</b> <b>fields</b> whose directional reflections are varied. As a result, it is shown that clarinetists evaluate the <b>sound</b> <b>field</b> in which refiections coming from back are prominent as good for musical performance. On the other hand, horn players evaluate the <b>sound</b> <b>field</b> in which reflections coming from below are prominent as good for musical performance. This suggests that reflections coming from different direction from directivity of musical instruments clue musical players about their performance...|$|R
40|$|An {{acoustical}} {{model for}} the <b>sound</b> <b>field</b> generated by hemi-cylindrical loudspeaker arrays is presented and a method for beamforming with said arrays is derived. The <b>sound</b> <b>field</b> model is obtained by introducing two independent boundary conditions for the <b>sound</b> <b>field</b> of a single impinging plane wave. The {{model for the}} radiation from a single loudspeaker in the array is then obtained from the reciprocity principle. Various beam patterns are presented and the theoretically predicted <b>sound</b> <b>field</b> is evaluated {{as a function of}} frequency. The results are discussed and an experimental array prototype is presented...|$|R
40|$|In {{the present}} paper, we study the spatialization of the <b>sound</b> <b>field</b> in a room, in {{particular}} the evolution of room impulse responses as function of their spatial positions. The presented technique allows us to completely characterize the <b>sound</b> <b>field</b> in any arbitrary location if the <b>sound</b> <b>field</b> is known in a certain finite number of positions. The existing techniques usually make use of room models to recreate the <b>sound</b> <b>field</b> present {{at some point in}} the space. Our technique simply starts from the measurements of impulse responses in a finite number of positions and with this information the total <b>sound</b> <b>field</b> can be recreated. An analytical solution of the problem is given for different cases of spaces. Further, we determine the number and the spacing between the microphones needed to perfectly reconstruct the <b>sound</b> <b>field</b> up to a certain temporal frequency. The optimal sampling pattern for the microphone positions is given. Applications are also discussed. 1...|$|R
40|$|For the {{complexity}} of the sound generated mechanism of rotating body source, this paper describes a frequency-domain numerical method for predicting sound radiation of rotating body sources based on the Kirchhoff integral equation with analytical Green’s function of rotating monopole and dipole source in <b>free</b> space. The <b>sound</b> radiation model is established in free space and the relationship between characteristics of <b>sound</b> <b>field</b> and acoustic nature frequency of source, angular frequency and its harmonics can be revealed by the mathematical solution. Numerical simulation shows that <b>sound</b> <b>field</b> has a strong directivity, fundamental frequency transmitting in the rotary shaft direction and harmonics spreading along radial direction and frequency shift phenomena appearing clearly in higher rotating speed of source. The method has a theoretical significance for exploring the low-noise rotating machinery. </p...|$|R
40|$|Comparison {{between the}} <b>sound</b> <b>field</b> {{generated}} by an open rotor and the <b>sound</b> <b>field</b> {{generated by the}} same rotor placed inside a semi-infinite duct. The <b>sound</b> <b>field</b> associated with an open rotor and that associated with the same rotor placed inside a semi-infinite duct can be extremely different. A good understanding of the differences is important in fan noise work. We will use nondimensional variables...|$|R
40|$|This work {{presents}} {{a method for}} estimation of the acoustic intensity, the energy density and the associated <b>sound</b> <b>field</b> diffuseness around the origin, when the <b>sound</b> <b>field</b> is weighted with a spatial filter. The method permits energetic DOA estimation and <b>sound</b> <b>field</b> characterization focused in a specific angular region determined by the beam pattern of the spatial filter. The formulation of the estimators is presented and their behavior is analyzed for the fundamental cases useful in parametric <b>sound</b> <b>field</b> models of a single plane wave, a uniform diffuse field and a mixture of the two. Comment: 7 page...|$|R
40|$|<b>Sound</b> <b>field</b> {{reconstruction}} {{techniques for}} recreating immersive audio in entertainment applications are well established. However, these techniques and their underlying principles do no readily upscale to cover larger listening areas with a sizable number of either static or ambulant listeners. In this work, we review {{the theory and}} considerations of <b>sound</b> <b>field</b> control and contrast that to the requirements for creating a consistent experience across a large audience. An argument is made that precise <b>sound</b> <b>field</b> control is neither necessary or sufficient, and we propose key challenges and hybrid approaches for further research and development beyond <b>sound</b> <b>field</b> control...|$|R
40|$|Bone {{conduction}} (BC) {{relative to}} air conduction (AC) <b>sound</b> <b>field</b> sensitivity is here {{defined as the}} perceived difference between a <b>sound</b> <b>field</b> transmitted to the ear by BC and by AC. Previous investigations of BC-AC <b>sound</b> <b>field</b> sensitivity have used different estimation methods and report estimates that vary by up to 20 dB at some frequencies. In this study, the BC-AC <b>sound</b> <b>field</b> sensitivity was investigated by hearing threshold shifts, ear canal sound pressure measurements, and skull bone vibrations measured with an accelerometer. The vibration measurement produced valid estimates at 400 Hz and below, the threshold shifts produced valid estimates at 500 Hz and above, while the ear canal sound pressure measurements were found erroneous for estimating the BC-AC <b>sound</b> <b>field</b> sensitivity. The BC-AC <b>sound</b> <b>field</b> sensitivity is proposed, by combining the present result with others, as frequency independent at 50 to 60 dB at frequencies up to 900 Hz. At higher frequencies, it is frequency dependent with minima of 40 to 50 dB; at 2 and 8 kHz, and a maximum of 50 to 60 dB at 4 kHz. The BC-AC <b>sound</b> <b>field</b> sensitivity is the theoretical limit of maximum attenuation achievable with ordinary hearing protection devices. (c) 2007 Acoustical Society of America...|$|R
40|$|The Spatial Transformation of <b>Sound</b> <b>Fields</b> (STSF) {{technique}} {{permits a}} 3 D <b>sound</b> <b>field</b> mapping {{based on a}} 2 D scan measurement in the near field of a source. By measurement of the cross spectra between a set of references and the cross spectra from each scan position {{to each of the}} references, a principal component representation of the <b>sound</b> <b>field</b> is extracted which can be applied for near field holography and Helmholtz' integral equation calculations. Basically, this <b>sound</b> <b>field</b> representation includes only the part of the <b>sound</b> <b>field,</b> which is coherent with the reference signals. More precisely, only "views" of the independent parts of the <b>sound</b> <b>field</b> seen by the references are included. Therefore, provided the references do not pick up the background noise, the background noise will not be part of the <b>sound</b> <b>field</b> model processed by STSF. However, if the background noise is picked up by the reference transducers, it will become part of the model and cause errors in the calculations. In order to overcome this problem, the possibility of using a set of "exclude references" has been implemented in the STSF system. These references should pick up only the uncorrelated background noise to be suppressed in the model...|$|R
40|$|The spatial {{correlation}} {{has previously}} been investigated for tonal and narrow-band <b>sound</b> <b>fields.</b> This letter presents an experimental investigation of the spatial correlation coefficients in a reverberation chamber driven by broadband signals. The main objective is to verify recent theoretical results for broadband spatial correlation in diffuse <b>sound</b> <b>fields.</b> Experimental results show good agreement with theoretical predictions when the frequency band of the <b>sound</b> <b>field</b> is entirely above the Schroeder frequency...|$|R
40|$|Active sound {{reduction}} {{is the use}} of active sources of sound, that is devices which are potentially sources of sound energy, to modify a preexisting <b>sound</b> <b>field</b> {{in such a way that}} the overall effect is a reduction in sound. Until recently the most common approach in active sound control was to attempt to achieve complete cancellation of the sound. This is possible at single points but is practically impossible over an appreciable region. A more modest and practical aim is to try to reduce the <b>sound</b> <b>field</b> by as much as possible by minimizing some overall measure of the amplitude of the <b>sound</b> <b>field.</b> This thesis examines the technique of <b>sound</b> <b>field</b> minimization. Candidate <b>sound</b> <b>field</b> measures which are suitable for minimization are presented and discussed. The quantities include acoustic energy, intensity and power flow as well as a practical measure, the sum of the squares of the signals from a number of sensors. Theoretical simulations and experimental implementations are used to evaluate <b>sound</b> <b>field</b> minimization techniques. The discussion and experiments are extended to the active reduction of structural vibrations...|$|R
40|$|To {{clarify the}} {{relationship}} of the <b>sound</b> <b>fields</b> between the pit and the stage, we conducted acoustical measurements in a typical historical opera house, the “Teatro Comunale” in Ferrara, Italy. Based on the theory of subjective preference in the <b>sound</b> <b>field,</b> orthogonal factors and other related factors were analysed. First, the <b>sound</b> <b>fields</b> for a singer on the stage in relation to the musicians in the pit were analysed. Second, the <b>sound</b> <b>fields</b> for performers in the orchestra pit in relation to the singers on the stage were considered. Finally, the <b>sound</b> <b>fields</b> for the conductor in the orchestra pit in relation to the musicians in the orchestra pit and the singers on the stage were investigated. Because physical factors vary depending on the location of the sound source, performers can move on the stage or in the pit to find the preferred <b>sound</b> <b>field.</b> Also the conductor can rearrange musicians for the performance. Our results provide valuable information for designing the stage and orchestra pit inside opera house...|$|R
40|$|The {{active control}} of <b>sound</b> <b>fields</b> {{has been widely}} applied in both active noise control and <b>sound</b> <b>field</b> reproduction, however, {{relatively}} few {{studies have focused on}} active acoustic cloaking. In order to build upon the knowledge and understanding in the areas of active noise control and <b>sound</b> <b>field</b> reproduction, this paper investigates their physical limitations and compares them to the active cloaking problem when the three strategies are employed in the presence of an acoustic scatterer. The three <b>sound</b> <b>field</b> control strategies have been formulated within a consistent framework, and this has enabled insight into the physical control mechanisms. Two different three-dimensional scattering problems have then been simulated and used to investigate the performance limitations of the three strategies. The influence of the number of control sources and their proximity to the scattering object have been investigated, and {{it has been shown that}} the requirements for active cloaking differ from those for active noise control and <b>sound</b> <b>field</b> reproduction. Specifically, it has been shown that there is a clear distinction between controlling the internal and external <b>sound</b> <b>fields</b> in the three cases...|$|R
40|$|A {{method is}} {{presented}} for generating a <b>sound</b> <b>field</b> that is significantly attenuated {{over half of}} the reproduction region, which has application to the generation of two independent <b>sound</b> <b>fields</b> for two listeners. The half-space <b>sound</b> <b>field</b> is produced by attenuating the negative or positive modes in the cylindrical or spherical expansion of a plane wave or point source <b>sound</b> <b>field.</b> It is shown that this is equivalent to adding to the original <b>sound</b> <b>field,</b> in quadrature, a second field which is the Hilbert transform of the original field. The resulting analytic field has a small magnitude in one half of the plane. Methods are presented for controlling the attenuation in the unwanted half-space. Finally, a simulation is presented showing the generation of a wideband pulse that propagates across half of the area within a circular array of sources...|$|R
40|$|<b>Sound</b> <b>field</b> {{synthesis}} techniques like Wave Field Synthesis and Higher-Order Ambisonics aim at {{the physical}} synthesis of a desired <b>sound</b> <b>field</b> over an extended listening area. However, for practical setups the accuracy up to which the desired <b>sound</b> <b>field</b> can be synthesized over an extended area is limited. For certain applications it is desirable to limit the spatial extent of the listening area {{in order to increase}} the accuracy within this limited region for a given loudspeaker arrangement. Local <b>sound</b> <b>field</b> synthesis aims at a higher accuracy within a local listening area. An approach to local <b>sound</b> <b>field</b> synthesis is presented that is based on the concept of using virtual loudspeakers that are placed more densely around the local listening area than the existing loudspeakers. The approach is illustrated using Wave Field Synthesis as an example. 1...|$|R
