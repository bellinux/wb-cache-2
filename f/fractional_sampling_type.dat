0|5157|Public
40|$|<b>Fractional</b> <b>sampling</b> has {{received}} considerable interest {{recently as a}} means of developing blind equalization techniques without resorting to higher order statistics. Instead, cyclostationarity introduced at the receiver by <b>fractional</b> <b>sampling</b> is exploited. In this paper, we show that simpler solutions are possible if cyclostationarity is introduced at the transmitter instead of the receiver. We propose specific coding and interleaving strategies at the transmitter that induce cyclostationarity and facilitate the equalization task. Novel batch and adaptive equalization algorithms are derived that make no assumptions on the channel zeros locations. Subspace methods are also proposed and, in the absence of noise, guarantee perfect estimation from finite data. Synchronization issues and bandwidth considerations are briefly discussed, and simulation examples are presented...|$|R
40|$|Motion {{compensation}} {{is a fundamental}} technology in video coding to remove the temporal redundancy between video frames. To further improve the coding efficiency, sub-pel motion compensation has been utilized, which requires interpolation of <b>fractional</b> <b>samples.</b> The video coding standards usually adopt fixed interpolation filters that are derived from the signal processing theory. However, as video signal is not stationary, the fixed interpolation filters may turn out less efficient. Inspired by the great success of convolutional neural network (CNN) in computer vision, we propose to design a CNN-based interpolation filter (CNNIF) for video coding. Different from previous studies, one difficulty for training CNNIF {{is the lack of}} ground-truth since the <b>fractional</b> <b>samples</b> are actually not available. Our solution for this problem is to derive the "ground-truth" of <b>fractional</b> <b>samples</b> by smoothing high-resolution images, which is verified to be effective by the conducted experiments. Compared to the fixed half-pel interpolation filter for luma in High Efficiency Video Coding (HEVC), our proposed CNNIF achieves up to 3. 2 % and on average 0. 9 % BD-rate reduction under low-delay P configuration. Comment: International Symposium on Circuits and Systems (ISCAS) 201...|$|R
40|$|It {{is shown}} that for {{rounding}} <b>fractional</b> <b>sampling</b> allocations to integers, the rounding method of Jefferson maximizes an efficiency coefficient that {{is motivated by}} variance minimization. Adams rounding method Efficient design apportionment Efficient sampling apportionment Jefferson rounding method Neyman-Tschuprow allocation Proportional allocation...|$|R
40|$|Abstract — We {{present and}} {{evaluate}} a novel robust image transmission system for frequency selective fading channels. The system combines a wavelet image coder and space-time block codes (STBC) {{in conjunction with}} <b>Fractional</b> <b>Sampling</b> OFDM (FS-OFDM). Specifically, we employ an image coder based on channel optimized trellis coded quantization (COTCQ), {{which has not been}} previously studied for frequency selective fading channels. We demonstrate that our COTCQ coder based system both with (i) (2, 2) STBC OFDM without <b>fractional</b> <b>sampling,</b> and (ii) (2, 1) STBC with <b>fractional</b> <b>sampling</b> significantly outperforms a system employing trellis coded quantization (TCQ) and set partitioning in hierarchical trees (SPIHT) image coding in conjunction with (2, 2) STBC OFDM at low channel signal-tonoise ratios (SNR). The usage of STBC over FS-OFDM systems improves the capacity and diversity achievable over the frequency selective fading channels. For a channel SNR of 9 dB, for instance, the peak signal-to-noise ratio (PSNR) of the Lenna image is over 2 – 4 dB higher with our system. Importantly, the results demonstrate that the diversity gain obtained with a (2, 1) STBC FS-OFDM system with low-complexity maximum ratio combining at the receiver can be translated into significant quality gains (in PSNR) in received images. I...|$|R
40|$|The H. 265 /MPEG-H High Efficiency Video Coding (HEVC) {{compliant}} encoding process {{faces the}} challenge of high computational complexity. Particularly, in case of inter-picture prediction, most of the computational resources are allocated for the motion estimation (ME) process. In turn, ME and motion compensation (MC) enable improving coding efficiency by addressing blocks of video frames as corresponding displacements from one or more reference blocks. These displacements do not necessarily have {{to be limited to}} integer sample positions, but may have an accuracy of half sample or quarter sample positions, which are identified during <b>fractional</b> <b>sample</b> refinement. In this work, a context-based scheme for <b>fractional</b> <b>sample</b> refinement is proposed. The scheme takes advantage of already obtained information in prior ME steps and provides significant flexibility in terms of parametrization. This way, it adaptively achieves a desired trade-off between computational complexity and coding efficiency. According to experimental results obtained for an example algorithm utilizing the proposed framework, a significant {{decrease in the number of}} search points can be achieved. For instance, considering only 6 instead of 16 <b>fractional</b> <b>sample</b> positions results in a trade-off of only 0. 4 % Bjøntegaard-Delta (BD) -rate loss for High Definition video sequences compared to the conventional interpolation-and-search method...|$|R
3000|$|... aNote that a SIMO system {{employing}} either multiple receive antennas or <b>fractional</b> <b>sampling</b> can perfectly sparsen {{the channel}} {{under certain conditions}} on subchannel roots [18]. bWhile {{it is possible that}} the noise observed at the receiver front-end is not white to begin with, we make the standard AWGN assumption throughout.|$|R
40|$|We extend {{previous}} work on linear MMSE (minimum mean square error) SISO (soft-in/soft-out) equalizers for turbo equalization {{to the case}} of <b>fractional</b> <b>sampling</b> of the received signal. We present a time-recursive algorithm also for this case. Special attention is paid to the influence of the receiver filter preceeding the sampler. 1...|$|R
40|$|A blind {{equalization}} method {{based on}} the theory of independent component analysis is presented. The blind equalization of an unknown FIR channel with possibly non-minimum phase is formulated as a blind separation problem. The inputs to the equalizer are formed by stacking the <b>fractional</b> <b>samples</b> of the channel outputs. New on-line blind equalization algorithms are developed from on-line blind separation algorithms, thus they inherit the equivariant property from the equivariant blind separation algorithms. Due to this property, {{the performance of the}} new algorithms is independent of the channel parameters. Therefore, they are useful for equalizing some ill-conditioned channels. It is shown by simulations that the proposed algorithm works well when the input sequence has some degree of correlation. Keywords: blind equalization, blind separation, on-line algorithm, <b>fractional</b> <b>sample,</b> equivariant property, condition number Running head: Blind Equalization via Blind Separation I. Introdu [...] ...|$|R
50|$|Each {{of these}} <b>sample</b> <b>types</b> can be collected, {{prepared}} and PCR tested {{within a short}} time for many <b>sample</b> <b>types.</b> Some <b>sample</b> <b>types</b> may require <b>sample</b> enrichment via shortened culture growth periods prior to PCR testing.|$|R
40|$|A {{recently}} proposed block-processing {{approach to}} polyphase implementation of <b>fractional</b> <b>sample</b> rate conversion (FSRC) [1 - 4] is revisited and extended to rational factors L=M with arbitrary L, M 2 N. For a z-domain derivation {{of this type}} of FSRC a novel multirate identity is introduced. Potential applications include parallelization of digital systems to any desired degree for minimum power consumption. 1...|$|R
5000|$|The {{relation}} {{between the number of}} <b>fractional</b> frequency <b>samples</b> and time error series is fixed in the relationship ...|$|R
40|$|Abstract — Signal-flow-graph (SFG) transforma-tions {{by means}} of identities are {{frequently}} used to obtain efficient structures. In contrast to time-domain approaches these transformations are graph-ical and therefore easier to handle. In this paper well-known noble identities [2] for multirate signal processing are revisited and extended. To this end up- and downsamplers with arbitrary integer phase shifts are introduced. As an application, a novel z-domain approach to efficient <b>fractional</b> <b>sample</b> rate conversion is given. ...|$|R
40|$|An {{improved}} technique with a <b>fractional</b> <b>sampling</b> {{based on}} two samples per chip, according to the Nyquist criterion, has been employed by the authors to enhance the performance in the code synchronization of UMTS (or W-CDMA) systems. In this paper, we investigate on the theoretical rationale of such a promising behavior. The performance is analyzed for several wireless channels, {{in the presence of}} typical pedestrian and vehicular scenarios of the IMT 2000 /UMTS cellular systems...|$|R
40|$|The {{derivation}} of block-processing {{structures for}} <b>fractional</b> <b>sample</b> rate conversion (FSRC) is revisited. In the past, sev-eral time- or frequency-domain approaches [1 - 6] have been proposed. However, the resulting structures differ concern-ing their group delay and, {{as a consequence}} thereof, in the arrangement of coefficients. In this paper it is shown that a minimum extra delay of z(MLLM+ 1) is sufficient to ensure causality. This outcome is demonstrated both in fre-quency- and time-domain. 1...|$|R
5000|$|For average <b>fractional</b> {{frequency}} <b>sample</b> series, [...] {{denotes the}} ith {{sample of the}} average continuous fractional frequency function y(t) as given by ...|$|R
40|$|Blind Source Separation (BSS) is {{the process}} of {{recovering}} a set of independent signals when only mixtures with unknown mixing coefficients are observed. Many important theories and applications have been investigated in BSS and snore generally in Independent Component Analysis (ICA). Blind equalization (BE) refers to the problem of determining the impulse response of the system or the input signal when the system is unknown and its input is inaccessible. ^ In digital communications, multiple independent sources may produce received signals from dispersive channels. Due to the presence of inter-symbol interference (ISI) in each channel and inter-user interference from adjacent channels, the received signals will be convolutive mixtures of source symbol sequences. Therefore, channel equalization is required to remove ISI, and source separation is necessary to separate each individual source signal from their mixtures. Blind equalization and blind source separation assume no training sequences, and little is assumed about the source signals and channel conditions. A novel technique for multichannel blind source separation and blind equalization using <b>fractional</b> <b>sampling</b> is proposed in this dissertation. Our method is also applicable to a single-input-single-output (SISO) channel. ^ Different BSS algorithms call be used to equalize a SISO channel. In this dissertation, we include performance comparisons between different BSS algorithms and other BE algorithms based on second-order cyclostationary statistics (SOCS). Mean-squared-error (MSE) of recovered signal is used as the performance measure of each algorithm. Our simulation results show that in general BSS combined with <b>fractional</b> <b>sampling</b> gives better performance at high SNR. It is also shown that the performance of the method using BSS and <b>fractional</b> <b>sampling</b> depends on the specific BSS algorithm chosen. ^ As an interesting application of BSS, we consider linear blind equalization for the global system for mobile communications (GSM) systems using source separation. The Gaussian minimum shift keying (GMSK) modulation employed in GSM systems is a nonlinear modulation technique, which necessitates the use of linear approximation models for the GMSK signal. In this dissertation, we consider two linear approximation models for the GMSK signal. The denotation technique and the denotation combined with <b>fractional</b> <b>sampling</b> method are discussed based on the two linear models. We introduce a novel equalizer structure that exploits both derotation and oversampling. ^ Robustness against deviations from nominal source probability density function (pdf) assumptions is very desirable in BSS algorithms. Little has bee done in the past on robustness issues in BSS. In this dissertation a new approach using ranks is proposed for robust BSS. Two different methods for evaluation of ranks are also introduced. ...|$|R
5000|$|The average <b>fractional</b> {{frequency}} <b>sample</b> series lets M {{denote the}} number of samples (...) in the series. The traditional convention uses index 1 through M.|$|R
40|$|This paper {{addresses}} {{the problem of}} subsample or <b>fractional</b> <b>sample</b> time delay estimation of narrowband signals of known centre frequency, in order to synchronise the signals. The Lagrange interpolator filter is incorporated into the explicit time delay estimator (ETDE) method. In order to achieve this, {{a new form of}} the Lagrange interpolator is presented in this paper. Further modifications are made to the ETDE algorithm. Simulations show delay estimation bias using the new algorithm is orders of magnitude smaller than conventional "sinc"-based ETDE...|$|R
40|$|In this paper, a new {{comb filter}} design method using <b>fractional</b> <b>sample</b> delay is presented. First, the specifica-tion of the comb filter design is {{transformed}} into that of fractional delay filter design. Then, conventional FIR and allpass filter design techniques are directly applied to design fractional delay filter with transformed specification. Nex-t, we develop a constrained fractional delay filter design approach t o improve {{the performance of the}} direct design method. Finally, several design examples are demonstrated to illustrate the effectiveness of this new design approach. 1...|$|R
40|$|The {{detection}} of avian viruses in wild populations has considerable conservation implications. For DNA-based studies, feathers {{may be a}} convenient <b>sample</b> <b>type</b> for virus screening and are, therefore, an increasingly common technique. This is despite recent concerns about DNA quality, ethics, and a paucity of data comparing the reliability and sensitivity of feather sampling to other common <b>sample</b> <b>types</b> such as blood. Alternatively, skeletal muscle tissue may offer a convenient sample to collect from dead birds, which may reveal viraemia. Here, we describe a probe-based quantitative real-time PCR for the relative quantification of beak and feather disease virus (BFDV), a pathogen of serious conservation concern for parrots globally. We used this method to test for BFDV in wild crimson rosellas (Platycercus elegans), and compared three different <b>sample</b> <b>types.</b> We detected BFDV in samples from 29 out of 84 individuals (34. 5 %). However, feather samples provided discordant results concerning virus presence when compared with muscle tissue and blood, and estimates of viral load varied somewhat between different <b>sample</b> <b>types.</b> This study provides evidence for widespread infection of BFDV in wild crimson rosellas, but {{highlights the importance of}} <b>sample</b> <b>type</b> when generating and interpreting qualitative and quantitative avian virus data...|$|R
40|$|When <b>fractional</b> <b>samples</b> are {{available}} at the receiver, blind channel estimation methods can be developed exploiting the cyclostatlonaxy nature of the received signal. In this paper, we show that different solutions are possible if cyclostationaxity is introduced at the transmitter instead of the receiver. We propose specific coding and interleaving strategies at the transmitter which induce cyclostationaxity and facilitate the equalization task. Novel subspace equalization algorithms are derived which make no assumptions whatsoever on the channel zeros locations. Synchronization issues axe briefly discussed and some simulation examples are presented...|$|R
40|$|In {{the past}} various FIR block-processing {{structures}} (e. g. for <b>fractional</b> <b>sample</b> rate conversion) have been published. However, the timing interval of all proposed structures is constrained to integer multiples of Ts=MTi (Ti: timing interval of input signal). Increasing Ts by p∈ concurrently raises {{the number of}} multipliers by the same factor p. In this paper, two novel structures are proposed that enable {{a higher degree of}} freedom for the optimal choice of the timing interval. As a result, a refined trade-off between timing interval (system clock) and hardware expenditure (chip area) is possible...|$|R
40|$|A {{research}} {{review of}} 46 peer-reviewed articles with bisexuals {{as a target}} group was conducted with the objective to investigate methods of finding bisexual participants in empirical Social Sciences studies. The aim was to examine occurring definitions of “bisexual”, <b>sample</b> <b>types,</b> and sources of data. Results indicated that a self-identification definition was most frequently used, that <b>sample</b> <b>type</b> was seldom reported with an even distribution between probability and non-probability <b>sample</b> <b>types</b> when occurring, and that sources of data varied with media as most frequent. Some of the conclusions drawn were that bisexuals often occur in the same studies as lesbians and gay men, and that bisexual women have a poor representation in studies...|$|R
40|$|<b>Fractional</b> <b>sample</b> delay (FD) {{filters are}} useful and {{necessary}} in many applications, {{such as the}} accurate steering of acoustic arrays [1], [2], delay lines for physical models of musical instruments [3] [4], and time delay estimation[5]. This paper addresses the design of finite impulse response (FIR) FD filters. The problem will be posed as a convex optimization problem in which the maximum modulus of the complex error will be minized. Several design examples will be presented, along with an empirical formula for the filter order required to meet a given worst case group delay error specification. 1...|$|R
40|$|Several {{explicit}} identifiability {{results are}} derived for deterministic blind beamforming in incoherent multipath with small delay spread. For example, it is shown {{that if the}} sum of spatial and <b>fractional</b> <b>sampling</b> diversities exceeds two times {{the total number of}} paths, then identifiability can be guaranteed even for one symbol snapshot. The tools come from the theory of low-rank three-way array decomposition (commonly referred to as parallel factor analysis (PARAFAC) and data smoothing in one and two dimensions. New results regarding the Kruskal-rank of certain structured matrices are also included, and they are of interest in their own right...|$|R
40|$|Sampling {{methods for}} graph signals in the graph {{spectral}} domain are proposed. Conventional sampling of graph signals {{can be regarded}} as sampling in the graph vertex domain, but it does not have desired characteristics in regard to the graph spectral domain. Down- and upsampled graph signals by using our methods inherit the frequency domain characteristics of sampled signals defined in the time/spatial domain. Properties of the sampling effects are studied theoretically and experimentally in comparison with the conventional sampling method in the vertex domain. <b>Fractional</b> <b>sampling</b> and Laplacian pyramid of graph signals are also shown as possible applications...|$|R
40|$|Eight DNA {{extraction}} {{products or}} methods (Applied Biosystems PrepFiler Forensic DNA Extraction Kit; Bio-Rad Instagene Only, Bio-Rad Instagene & Spin Column Purification; EpiCentre MasterPure DNA & RNA Kit; FujiFilm QuickGene Mini 80; Idaho Technologies 1 - 2 - 3 Q-Flow Kit; MoBio UltraClean Microbial DNA Isolation Kit; Sigma Extract-N-Amp Plant and Seed Kit) were adapted to facilitate extraction of DNA under BSL 3 containment conditions. DNA was extracted from 12 common interferents or <b>sample</b> <b>types,</b> spiked with spores of Bacillus atropheaus. Resulting extracts were tested by real-time PCR. No one method was the best, {{in terms of}} DNA extraction, across all <b>sample</b> <b>types.</b> Statistical analysis indicated that the PrepFiler method was the best method from six dry powders (baking, biological washing, milk, plain flour, filler and talcum) and one solid (Underarm deodorant), the UltraClean method was the best from four liquids (aftershave, cola, nutrient broth, vinegar), and the MasterPure method was the best from the swab <b>sample</b> <b>type.</b> The best overall method, in terms of DNA extraction, across all <b>sample</b> <b>types</b> evaluated was the UltraClean method...|$|R
40|$|The {{composition}} of the gut microbiota is associated with various disease states, most notably inflammatory bowel disease, obesity and malnutrition. This underlines that analysis of intestinal microbiota is potentially an interesting target for clinical diagnostics. Currently, {{the most commonly used}} <b>sample</b> <b>types</b> are feces and mucosal biopsy specimens. Because sampling method, storage and processing of samples impact microbiota analysis, each <b>sample</b> <b>type</b> has its own limitations. An ideal <b>sample</b> <b>type</b> for use in routine diagnostics should be easy to obtain in a standardized fashion without perturbation of the microbiota. Rectal swabs may satisfy these criteria, but little is known about microbiota analysis on these <b>sample</b> <b>types.</b> In this study we investigated the characteristics and applicability of rectal swabs for gut microbiota profiling in a clinical routine setting in patients presenting with various gastro-intestinal disorders. We found that rectal swabs appeared to be a convenient means of sampling the human gut microbiota. Swabs can be performed on demand, whenever a patient presents; swab-derived microbiota profiles are reproducible, whether they are gathered at home by patients or by medica...|$|R
40|$|Background: As {{a part of}} the {{longitudinal}} Chronic Obstructive Pulmonary Disease (COPD) study, Subpopulations and Intermediate Outcome Measures in COPD study (SPIROMICS), blood samples are being collected from 3200 subjects with the goal of identifying blood biomarkers for sub-phenotyping patients and predicting disease progression. To determine the most reliable <b>sample</b> <b>type</b> for measuring specific blood analytes in the cohort, a pilot study was performed from a subset of 24 subjects comparing serum, Ethylenediaminetetraacetic acid (EDTA) plasma, and EDTA plasma with proteinase inhibitors (P 100 ™). Methods: 105 analytes, chosen for potential relevance to COPD, arranged in 12 multiplex and one simplex platform (Myriad-RBM) were evaluated in duplicate from the three <b>sample</b> <b>types</b> from 24 subjects. The reliability coefficient and the coefficient of variation (CV) were calculated. The performance of each analyte and mean analyte levels were evaluated across <b>sample</b> <b>types.</b> Results: 20 % of analytes were not consistently detectable in any <b>sample</b> <b>type.</b> Higher reliability and/or smaller CV were determined for 12 analytes in EDTA plasma compared to serum, and for 11 analytes in serum compared to EDTA plasma. While reliability measures were similar for EDTA plasma and P 100 plasma for a majority of analytes, CV was modestly increased in P 100 plasma for eight analytes. Each analyte within a multiplex produced independent measurement characteristics, complicating selection of <b>sample</b> <b>type</b> for individual multiplexes. Conclusions: There were notable detectability and measurability differences between serum and plasma. Multiplexing may not be ideal if large reliability differences exist across analytes measured within the multiplex, especially if values differ based on <b>sample</b> <b>type.</b> For some analytes, the large CV should be considered during experimental design, and the use of duplicate and/or triplicate samples may be necessary. These results should prove useful for studies evaluating selection of samples for evaluation of potential blood biomarkers...|$|R
60|$|Such is a <b>fractional</b> <b>sample</b> of the {{evidence}} which was laid before the Commission, corroborated by every detail of name, place and date which could enforce conviction. There {{is no doubt that}} it did enforce thorough conviction. The judges travelled down the river sadder and wiser men. When they reached Boma, they had an interview with Governor-General Constermann. What passed at that interview has not been published, but the Governor-General went forth from it and cut his own throat. The fact may, perhaps, give some indication of how the judges felt when the stories were still fresh in their minds, and their nerves wincing under the horror of {{the evidence}}.|$|R
40|$|Transmitter-induced cyclostationarity {{has been}} {{explored}} recently {{as an alternative}} to <b>fractional</b> <b>sampling</b> and antenna array methods for blind identification of FIR communication channels. An interesting application of these ideas is in OFDM systems, which induce cyclostationarity due to the cyclic prefix. In this correspondence, we develop a novel subspace approach for blind channel identification using cyclic correlations at the OFDM receiver. Even channels with equispaced unit circle zeros are identifiable in the presence of any nonzero length cyclic prefix with adequate block length. Simulations of the proposed channel estimator along with its performance in OFDM systems combined with impulse response shortening and Reed [...] Solomon coding are presented...|$|R
5000|$|Historically, {{the severe}} “nugget effect” {{produced}} by the extreme variability in gold size and distribution within the Goldboro mineralized belts forced companies to implement a number of sampling and grade determination programs. The nugget effect is so extreme that collecting and processing samples of a size adequate enough to overcome the nugget effect is problematic using conventional analytical methods. The programs {{have resulted in a}} wide variety of <b>sample</b> <b>types</b> tested by several different processing protocols on the initial and sub-split <b>sample</b> sizes. <b>Sample</b> <b>types</b> have included: ...|$|R
40|$|Background: Settled {{airborne}} dust {{is used as}} a surrogate for airborne exposure in studies that explore indoor microbes. In order to determine whether detecting differences in dust environments would depend on the <b>sampler</b> <b>type,</b> we compared different passive, settled dust sampling approaches with respect to displaying qualitative and quantitative aspects of the bacterial and fungal indoor microbiota. Results: Settled dust sampling approaches—utilizing plastic petri dishes, TefTex material, and electrostatic dustfall collectors (EDCs) —were evaluated in indoor spaces in the USA and Finland and in an experimental chamber study. The microbial content was analyzed with quantitative PCR (qPCR) to quantify total bacterial and fungal biomass and through high-throughput sequencing to examine bacterial community composition. Bacterial composition and diversity were similar within a sampling environment regardless of the <b>sampler</b> <b>type.</b> The <b>sampling</b> environment was the single largest predictor of microbial community composition within a study, while <b>sampler</b> <b>type</b> was found to have much less predictive power. Quantitative analyses in indoor spaces indicated highest yields using a petri dish approach, followed by sampling with EDCs and TefTex. The highest correlations between duplicate samples were observed for EDC and petri dish approaches, indicating greater experimental repeatability for these <b>sampler</b> <b>types.</b> For the EDC samples, it became apparent that, due to the fibrous nature of the material, a rigorous extractio...|$|R
50|$|In FTIR, three <b>types</b> of <b>samples</b> can be analyzed: {{solution}} (KBr), powder, or film. A {{solid film}} {{is the easiest}} and most straight forward <b>sample</b> <b>type</b> to test.|$|R
40|$|New {{potential}} tumor markers such as matrix metalloproteinases {{and their}} inhibitors have been extensively studied {{during the last}} decades. The aim is to find prognostic markers that are measurable in easily available samples, such as serum or plasma. The proper <b>sample</b> <b>type</b> to use when measuring the levels of gelatinases and their inhibitors from blood samples is currently under critical evaluation. In this study, the effect of <b>sample</b> <b>type</b> is studied in 26 healthy controls, {{and the result is}} confirmed in a series of 80 breast carcinoma patients...|$|R
40|$|The 6 Apollo {{missions}} that {{landed on the}} lunar surface returned 2196 samples comprised of 382 kg. The 58 samples weighing 21. 5 kg collected on Apollo 11 expanded to 741 samples weighing 110. 5 kg {{by the time of}} Apollo 17. The main goal on Apollo 11 was to obtain some material and return it safely to Earth. As we gained experience, the sampling tools and a more specific sampling strategy evolved. A summary of the <b>sample</b> <b>types</b> returned is shown in Table 1. By year 1989, some statistics on allocation by <b>sample</b> <b>type</b> were compiled [2]. The "scientific interest index" {{is based on the assumption}} that the more allocations per gram of sample, the higher the scientific interest. It is basically a reflection of the amount of diversity within a given <b>sample</b> <b>type.</b> <b>Samples</b> were also set aside for biohazard testing. The samples set aside and used for biohazard testing were represen-tative, as opposed to diverse. They tended to be larger and be comprised of less scientifically valuable mate-rial, such as dust and debris in the bottom of sample containers...|$|R
