688|334|Public
25|$|In the southeastern, central, and southwestern {{part of the}} United States, {{the adult}} C. rufifacies {{is one of the}} first insects to arrive on a fresh corpse. The adults {{normally}} arrive within the first 10 minutes after death. The larvae also have a shorter developmental time than other species, but because of their predatory nature, they can also alter entomological-based post mortem <b>interval</b> <b>estimation.</b> In Texas and Florida, the species emerges from corpses that are in an advanced stage of decomposition.|$|E
25|$|Further {{research}} is being conducted on Cynomya cadaverina {{to gain more}} information on its lifecycle {{as well as its}} behavior in order to better pinpoint time of death with postmortem <b>interval</b> <b>estimation.</b> This information will further aid forensic entomologists as well as investigators in solving medicocriminal investigations. Also, continued research on mitochondrial DNA analysis will be able to provide more identifications in cases where identification may have seemed impossible. Although Cynomya cadaverina is not as forensically or medically important as some of the other species of fly, it can still be a powerful tool in investigations as well as aid in maggot therapy.|$|E
25|$|To {{estimate}} insect age, forensic entomologists {{must determine}} {{the amount of}} time a particular insect spends in each stage of development and apply this information to temperature data at a crime scene to determine a post-mortem <b>interval</b> <b>estimation.</b> Timing of various insect stages is determined in a laboratory at standardized temperatures so that ranges may be applied to the different temperature conditions encountered in the field. Post-mortem intervals are estimated by determining the accumulated degree days (ADD) or accumulated degree hours (ADH) acquired by each insect stage on the remains; this information is then used to calculate the overall degree days or degree hours accumulated during the insect’s entire life cycle and association with the carcass, representing the minimal amount of time the body has been available for colonization by insects. This estimation does not claim to represent an accurate time of death, but rather a minimal time of colonization. This is an important distinction that must be considered with the use of forensic evidence in courts of law.|$|E
40|$|Linear {{polarization}} measurements {{provide access}} to two quantities, the degree (DOP) and the angle of polarization (AOP). The aim of this work is to give a complete and concise overview of how to analyze polarimetric measurements. We review <b>interval</b> <b>estimations</b> for the DOP with a frequentist and a Bayesian approach. Point estimations for the DOP and <b>interval</b> <b>estimations</b> for the AOP are further investigated with a Bayesian approach to match observational needs. Point and <b>interval</b> <b>estimations</b> are calculated numerically for frequentist and Bayesian statistics. Monte Carlo simulations are performed to clarify {{the meaning of the}} calculations. Under observational conditions, the true DOP and AOP are unknown, so that classical statistical considerations - based on true values - are not directly usable. In contrast, Bayesian statistics handles unknown true values very well and produces point and <b>interval</b> <b>estimations</b> for DOP and AOP, directly. Using a Bayesian approach, we show how to choose DOP point estimations based on the measured signal-to-noise ratio. <b>Interval</b> <b>estimations</b> for the DOP show great differences in the limit of low signal-to-noise ratios between the classical and Bayesian approach. AOP <b>interval</b> <b>estimations</b> that are based on observational data are presented for the first time. All results are directly usable via plots and parametric fits. Comment: 11 pages, 14 figures, 3 table...|$|R
50|$|<b>Interval</b> <b>estimations</b> (for example at a plan on paper) to 3-5%.|$|R
40|$|Abstract. Authors {{extend the}} multi-parameter attacktree model to include {{inaccurate}} or estimated parameter values, which are modelled as probabilistic <b>interval</b> <b>estimations.</b> The paper develops mathematical tools {{to extend the}} computation rules of the attacktree model to work with <b>interval</b> <b>estimations</b> instead of point estimates. We present a sample computation routine and discuss how to interpret the analysis results and how to choose the optimal or an economically justified security level. ...|$|R
50|$|In statistics, <b>interval</b> <b>estimation</b> {{is the use}} {{of sample}} data to {{calculate}} an interval of possible (or probable) values of an unknown population parameter, in contrast to point estimation, which is a single number. Jerzy Neyman (1937) identified <b>interval</b> <b>estimation</b> ("estimation by interval") as distinct from point estimation ("estimation by unique estimate"). In doing so, he recognised that then-recent work quoting results {{in the form of an}} estimate plus-or-minus a standard deviation indicated that <b>interval</b> <b>estimation</b> was actually the problem statisticians really had in mind.|$|E
5000|$|The {{scientific}} {{problems associated}} with <b>interval</b> <b>estimation</b> may be summarised as follows: ...|$|E
50|$|Confidence {{intervals}} are {{one method}} of <b>interval</b> <b>estimation,</b> {{and the most}} widely used in frequentist statistics.An analogous concept in Bayesian statistics is credible intervals, while an alternative frequentist method is that of prediction intervals which, rather than estimating parameters, estimate the outcome of future samples. For other approaches to expressing uncertainty using intervals, see <b>interval</b> <b>estimation.</b>|$|E
40|$|In this study, {{first we}} derived {{classical}} estimators for the shape parameter of the minimax distribution using un-grouped data and also consider relationship between them. We compare the classical estimators {{based on their}} mean squared errors (MSE's). Then, we obtain classical estimators of the shape parameter of this distribution under grouped data. In all cases, we considered both point and <b>interval</b> <b>estimations.</b> These the point and <b>interval</b> <b>estimations</b> are compared empirically using monte-carlo simulation...|$|R
25|$|As {{members of}} Sarcophaga bullata are found {{from coast to}} coast in the United States and in parts of Canada, these flesh flies have been the focus of many forensically related studies. Most of these studies deal with the {{immature}} stages, as maggots are a helpful tool in the forensic world for determining post-mortem <b>interval</b> <b>estimations.</b> One such study concerning S. bullata determined that when evaluating a post-mortem interval, temperature {{plays a major role in}} maturation of the maggots and the decomposition of the surrounding tissue. This is an important consideration for forensic entomologists, as the ambient temperature at the crime scene before and during the colonization of human remains by arthropods must be accounted for to ensure that post-mortem <b>interval</b> <b>estimations</b> are accurate.|$|R
30|$|The {{important}} {{fact from}} {{a view of}} the calcium score is a confidence interval of the median for the individual analyzed groups of patients. In this context it is important, so that these <b>interval</b> <b>estimations</b> would correspond with estimated range of values proposed by physicians from clinical practice. The individual <b>interval</b> <b>estimations</b> lay inside of expected intervals of the CS. Interesting fact is a comparison of individual interval lengths. Calcified blood vessels have the narrowest interval of calcium score. The next important fact is also comparison between length of the estimated intervals and the average value estimation. These parameters are directly proportional. Gastwirth median exhibits minimal differences in a comparison with the median estimation. In a case of the CBV group, the Gastwirth median is identical to median estimation; in the other cases, observed differences are not perceived as statistically significant.|$|R
5000|$|Other common {{approaches}} to <b>interval</b> <b>estimation,</b> which are encompassed by statistical theory, are: ...|$|E
5000|$|Smoothing bias complicates <b>interval</b> <b>estimation</b> {{for these}} models, and the {{simplest}} approach {{turns out to}} involve a Bayesian approach ...|$|E
50|$|There {{is another}} {{approach}} to statistical inference, namely fiducial inference, that also considers <b>interval</b> <b>estimation.</b> Non-statistical methods {{that can lead}} to interval estimates include fuzzy logic.|$|E
40|$|Discrete event {{simulation}} modelling {{has been}} extensively used in modelling complex systems. Although it offers great conceptual-modelling flexibility, it is both computationally expensive and data intensive. There are several examples of simulation models that generate millions of observations to achieve satisfactory point and confidence <b>interval</b> <b>estimations</b> for the model variables. In these cases, it is exceptionally cumbersome to conduct the required output and sensitivity analysis in a spreadsheet or statistical package. In this paper, we highlight the advantages of employing data warehousing techniques for storing and analyzing simulation output data. The proposed data warehouse environment is capable of providing the means for automating the necessary algorithms and procedures for estimating different parameters of the simulation. These include initial transient in steady-state simulations and point and confidence <b>interval</b> <b>estimations.</b> Previously developed models for evaluating patient flow through hospital departments are used to demonstrate the problem and the proposed solutions. ...|$|R
40|$|The aim of {{this study}} is finding {{classical}} and Bayesian estimators for the shape parameter of the Kumaraswamy distribution using un-grouped data and also considers relationship between them. We show how the classical estimators can be derived from various choices made within a Bayesian framework. We compare the classical estimators based on their Mean Squared Errors (MSE's). Then, we obtain Bayesian and non-Bayesian estimators of the shape parameter of this distribution under Grouped data. In Bayesian estimation, we consider three types of loss functions; the Squared error, Precautionary and General entropy loss functions which are symmetric and asymmetric, respectively. In all cases, we considered both point and <b>interval</b> <b>estimations.</b> These the point and <b>interval</b> <b>estimations</b> are compared empirically using Monte-Carlo simulation. Bayes approach under Precautionary loss function is best estimator for estimating the parameter of Kumaraswamy distribution and this is true for both un-grouped and grouped data...|$|R
40|$|We {{consider}} the parameter inference for a two-parameter life distribution with bathtub-shaped or increasing failure rate function. We present {{the point and}} <b>interval</b> <b>estimations</b> for the parameter of interest based on type-II censored samples. Through intensive Monte-Carlo simulations, we assess {{the performance of the}} proposed estimation methods by a comparison of precision. Example applications are demonstrated for the efficiency of the methods...|$|R
50|$|The {{concept of}} {{fiducial}} inference can be outlined by comparing {{its treatment of}} the problem of <b>interval</b> <b>estimation</b> in relation to other modes of statistical inference.|$|E
50|$|Sperling, F., Anderson, G., & Hickey, D. (1994). A dna-based {{approach}} to the identification of insect species used for postmortem <b>interval</b> <b>estimation.</b> Journal of Forensic Sciences, 39(2), 418-427.|$|E
5000|$|Vexler, A., Liu, S., Kang, L. and Hutson, A. D. (2009)**. Modifications of the Empirical Likelihood <b>Interval</b> <b>Estimation</b> with Improved Coverage Probabilities. Communications in Statistics (Simulation and Computation). 38, 2171-2183. many {{citations}} and incited {{several other}} related works: http://www.tandf.co.uk/journals/pdf/lssp-lsta-virtual-issue.pdf ...|$|E
50|$|The {{development}} of C. livida is very useful in determining post-mortem <b>interval</b> <b>estimations</b> {{because it is}} possible to determine relatively precise estimations based on a specific instar. Temperature, heat generated by the maggot mass, the type of food source, contaminants and toxins, and obstructions that thwart the oviposition of adults are all factors that can affect the rate of {{development of}} larvae, thereby effecting the estimation.|$|R
25|$|The {{secondary}} screwworm (Cochliomyia macellaria) {{has become}} one of the principal species on which to base post-mortem <b>interval</b> <b>estimations</b> because its succession and occurrence on decomposing remains has been well defined. The secondary screwworm is found throughout the United States, the American tropics, and in southern Canada during summer months. This species is one of the most common species found on decomposing remains in the southern United States.|$|R
40|$|Abstract: Scope of {{the work}} is the {{decision}} of a high accuracy experimental data reception problem in medical, ecological and chemical data processing software. Using complex schemes of filtering improves reception of experimental data with high reliability. Approach of data acquisition about random parameter with a required degree of reliability is investigated. The approach is used for control of experimental stochastic parameter {{on the basis of the}} found <b>interval</b> <b>estimations</b> regression dependences [1, 2]...|$|R
5000|$|Calliphora livida is {{a member}} of the family Calliphoridae, the blow flies. This large family {{includes}} the genus Calliphora, the [...] "blue bottle flies". This genus is important in the field of forensic entomology because of its value in post-mortem <b>interval</b> <b>estimation.</b>|$|E
50|$|In statistics, the Behrens-Fisher problem, {{named after}} Walter Behrens and Ronald Fisher, {{is the problem}} of <b>interval</b> <b>estimation</b> and {{hypothesis}} testing concerning the difference between the means of two normally distributed populations when the variances of the two populations are not assumed to be equal, based on two independent samples.|$|E
50|$|The {{problem of}} density {{estimation}} arises in two applications. Firstly, in estimating the probability density functions of random variables and secondly in estimating the spectral density {{function of a}} time series. In these problems the estimates are functions that {{can be thought of}} as point estimates in an infinite dimensional space, and there are corresponding <b>interval</b> <b>estimation</b> problems.|$|E
40|$|In {{this paper}} we study some {{properties}} of the density function which may {{be obtained from the}} distribution of the last order statistic from a reduced logistic population. Its truncated variant is also discussed. The point and <b>interval</b> <b>estimations</b> for are provided also. The so-called - type statistical tolerances are constructed and a comment on the hazard rate is done also. The last paragraph is devoted to testing procedures on the parameter involved...|$|R
40|$|The main {{contribution}} of this thesis {{is the introduction}} of Bayesian quantile regression for hidden Markov models, especially {{when we have to}} deal with extreme quantile regression analysis, as there is a limited research to inference conditional quantiles for hidden Markov models, under a Bayesian approach. The first objective is to compare Bayesian extreme quantile regression and the classical extreme quantile regression, with the help of simulated data generated by three specific models, which only differ in the error term’s distribution. It is also investigated if and how the error term’s distribution affects Bayesian extreme quantile regression, in terms of parameter and confidence <b>intervals</b> <b>estimation.</b> Bayesian extreme quantile regression is performed by implementing a Metropolis-Hastings algorithm to update our parameters, while the classical extreme quantile regression is performed by using linear programming. Moreover, the same analysis and comparison is performed on a real data set. The results provide strong evidence that our method can be improved, by combining MCMC algorithms and linear programming, in order to obtain better parameter and confidence <b>intervals</b> <b>estimation.</b> After improving our method for Bayesian extreme quantile regression, we extend it by includin...|$|R
40|$|Statistical {{inference}} of an {{exponential distribution}} model, using progressively Type-II censored data with random scheme, {{is discussed in}} this paper. Maximum likelihood and Bayes procedures are used to derive both point and interval estimates of the parameters included in the model. Monte Carlo simulation method is used to generate a progressive Type-II censored data from exponential distribution, then these data is used to compute the point and <b>interval</b> <b>estimations</b> of the parameter and compare both the methods used when different random schemes...|$|R
50|$|The chi-squared {{distribution}} {{is used in}} the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence <b>interval</b> <b>estimation</b> for a population standard deviation of a normal distribution from a sample standard deviation. Many other statistical tests also use this distribution, such as Friedmans analysis of variance by ranks.|$|E
50|$|A {{stochastic}} investment model {{tries to}} forecast how returns and prices on different assets or asset classes, (e. g. equities or bonds) vary over time. Stochastic models are not applied for making point estimation rather <b>interval</b> <b>estimation</b> {{and they use}} different stochastic processes. Investment models can be classified into single-asset and multi-asset models. They are often used for actuarial work and financial planning to allow optimization in asset allocation or asset-liability-management (ALM).|$|E
50|$|Instead of, or in {{addition}} to, point estimation, <b>interval</b> <b>estimation</b> {{can be carried}} out, such as confidence intervals.These are easily computed, based on the observation that the probability that k samples will fall in an interval covering p of the range (0 ≤ p ≤ 1) is pk (assuming in this section that draws are with replacement, to simplify computations; if draws are without replacement, this overstates the likelihood, and intervals will be overly conservative).|$|E
5000|$|The fresh {{stage of}} {{decomposition}} is generally {{described as the}} period between the moment of death and when {{the first signs of}} bloat are apparent. [...] There are no outward signs of physical change, though internal bacteria have begun to digest organ tissues. [...] No odor is associated with the carcass. [...] Early post-mortem changes, used by pathologists as medical markers for early post-mortem <b>interval</b> <b>estimations,</b> have been described by Goff and include livor mortis, rigor mortis and algor mortis.|$|R
5000|$|Necrophagous blowfly {{species are}} often {{the first to arrive}} and colonize at a site of decomposing remains. [...] These species develop from eggs laid {{directly}} on the carcass and complete their life cycle on or near the remains. Because of this, necrophagous species are considered {{to be the most important}} for post-mortem <b>interval</b> <b>estimations.</b> [...] The initial colonizers of greatest importance are those of the family Calliphoridae, Sarcophagidae and Muscidae (house flies), as these are typically the first insects to lay eggs at remains.|$|R
3000|$|... in {{a certain}} finite <b>interval.</b> These <b>estimations</b> will play an {{important}} role in investigating convergence or divergence of higher-order Hermite-Fejér interpolation polynomials (see [3, 5 – 17]).|$|R
