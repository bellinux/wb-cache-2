5|121|Public
5000|$|Format bugs {{were first}} noted in 1989 by the fuzz testing work {{done at the}} University of Wisconsin, which {{discovered}} an [...] "interaction effect" [...] in the C shell (csh) between its command history mechanism and an <b>error</b> <b>routine</b> that assumed safe string input.|$|E
5000|$|The {{number of}} {{instructions}} {{to perform the}} above basic [...] "loop" [...] (Fetch/Execute/calculate new address) depends on hardware {{but it could be}} accomplished on IBM S/360/370/390/ES9000 range of machines in around 12 or 13 instructions for many instruction types. Checking for valid memory locations or for conditional [...] "pause"s add considerably to the overhead but optimization techniques can reduce this to acceptable levels. For testing purposes this is normally quite acceptable as powerful debugging capabilities are provided including instruction step, trace and deliberate jump to test <b>error</b> <b>routine</b> (when no actual error). In addition, a full instruction trace can be used to test actual (executed) code coverage.|$|E
40|$|A new {{recursive}} prediction <b>error</b> <b>routine</b> {{is compared}} with the backpropagation method of training neural networks. Results based on simulated systems, the prediction of Canadian Lynx data and the modelling of an automotive diesel engine indicate that the recursive prediction error algorithm is far superior to backpropagation...|$|E
5000|$|... int yyerror(SExpression **expression, yyscan_t scanner, const char *msg) { // Add <b>error</b> {{handling}} <b>routine</b> as needed} %} ...|$|R
5000|$|The entire [...]se domain was {{unavailable}} for 58 minutes on 12 October 2009, when an <b>error</b> during <b>routine</b> maintenance by [...]SE corrupted all {{names in the}} domain name registry.|$|R
3000|$|... 2 Valentin A, Schiffinger M, Steyrer J et al. Safety climate reduces {{medication}} and dislodgement <b>errors</b> in <b>routine</b> intensive care practice. Intensive Care Medicine 2013; 39 : 391 - 398.|$|R
40|$|ERROR is {{a routine}} {{to provide a}} common {{location}} for all routines. Its celling sequence is: SXD SERROR, 4 TSX SERROR+ 1, 4 The above is normally followed immediately by up to 20 registers of BCD remarks terminated by a word of 1 's. This may be left out, however. ERROR prints out the remark, if any, {{the location of the}} TSX that entered error, restores the console except for the AC overflow, and transfers to the user's <b>error</b> <b>routine</b> specified by the calling sequence of SETUP...|$|E
40|$|Sudoku, {{also known}} as Number Place, is a logic-based {{placement}} puzzle. The aim of the puzzle is to enter a numerical digit from 1 through 9 in each cell of a 9 x 9 grid made up of 3 x 3 subgrids (called ''regions''), starting with various digits given in some cells (the ''givens''). Each row, column, and region must contain only one instance of each numeral. Completing the puzzle requires patience and logical ability. Although first published in a U. S. puzzle magazine in 1979, Sudoku initially caught on in Japan in 1986 and attained international popularity in 2005. Last fall, after noticing Sudoku puzzles in some newspapers and magazines, I attempted a few {{just to see how}} hard they were. Of course, the difficulties varied considerably. ''Obviously'' one could use Trial and Error but all the advice was to ''Use Logic''. Thinking to flex, and strengthen, those powers, I began to tackle the puzzles systematically. That is, when I discovered a new tactical rule, I would write it down, eventually generating a list of ten or so, with some having overlap. They served pretty well except for the more difficult puzzles, but even then I managed to develop an additional three rules that covered all of them until I hit the Oregonian puzzle shown. With all of my rules, I could not seem to solve that puzzle. Initially putting my failure down to rapid mental fatigue (being unable to hold a sufficient quantity of information in my mind at one time), I decided to write a program to implement my rules and see what I had failed to notice earlier. The solver, too, failed. That is, my rules were insufficient to solve that particular puzzle. I happened across a book written by a fellow who constructs such puzzles and who claimed that, sometimes, the only tactic left was trial and error. With a trial and <b>error</b> <b>routine</b> implemented, my solver successfully completed the Oregonian puzzle, and has successfully solved every puzzle submitted to it since...|$|E
40|$|ABSTRACT: A sun {{tracking}} <b>error</b> correcting <b>routine,</b> {{following the}} principles of classical controllers, is presented for integration in hybrid sun tracking strategies working on an open loop sun ephemeris basis, {{which is to be}} subsequently adjusted. Space scanning routines for feedback acquisition and tabulation of error estimates are introduced to complete the strategy. First analysis of the behavior of this strategy is obtained through custom-developed simulation software. In this context EUCLIDES concentrator <b>error</b> correcting <b>routine</b> is reviewed, and its comparison with the PI strategy gives way for extrapolation to a more general framework for hybrid strategies, which opens a range of different possibilities...|$|R
40|$|In vivo dosimetry, {{recommended}} by various {{national and international}} organizations is a Quality Assurance tool to measure radiation dose delivered to patients dur-ing radiotherapy [1 - 5]. These measurements {{can be compared to}} the planned doses specified by the oncologist and calculated by the Treatment Planning System (TPS) for the target and critical organs (e. g. rec-tum or spinal cord). In this way set-up, calculation, mo-tion or transcription errors, that may have gone unnoticed during pre-treatment check, can be recovered. In the absence of <b>errors,</b> <b>routine</b> in vivo dose measure-ments document that the treatment was delivered correctly. Detectors commonly used for in vivo measurements are thermoluminescence dosimeters (TLDs), semicon...|$|R
30|$|One of {{the primary}} tools to assess air-pollution {{patterns}} is through continuous monitoring of pollutants ambient levels. To accomplish this, numerous physicochemical methods have been developed and Air quality monitoring (AQM) station networks have been deployed all around the world. However, any longitudinal data acquisitioning system suffers from economical constraints, measurement <b>errors,</b> <b>routine</b> downtime due to maintenance and technical malfunctions, which result in missing data points. Data can be missing in long chunks due to a critical failure or in short intervals due to, for example, calibration or a temporary power outage. To cope with this inherent problem, many imputation methods have been proposed. The length of the missing interval {{and the kind of}} study conducted, are important in determining the best method for interpolation.|$|R
40|$|This work {{extends the}} error {{reduction}} properties of frames to an <b>error</b> correcting <b>routine.</b> It leads to complete noise removal for sparse noise {{for a class}} of frames. The results for images using Laplacian pyramids show an additional 10 dB improvement over the previously demonstrated noise reduction for frames...|$|R
40|$|With {{existence}} of computerized sales system, then the expected {{improvements in the}} sales field because in this system can facilitate in providing necessary information on matters relating to the sale, helping to reduce <b>errors</b> in <b>routine</b> work and easy to provide reports in complete and correct at any time the report was required...|$|R
40|$|The role of {{computers}} on the computerized sales {{system with the}} use of cigarettes in stores Garuda FoxPro application has many advantages compared with the previous manual system. Can easily provide the necessary information on matters relating to the sale of Morocco, reduce <b>errors</b> in <b>routine</b> work and time efficiency of very bergarga for the progress of the company...|$|R
50|$|In January 2010, Horyn {{was widely}} criticized when she insinuated {{in an article}} that actress Christina Hendricks was large. The photo of Hendricks {{included}} in Horyn's article was distorted by being widened, possibly to falsely illustrate Horyn's point. The New York Times replaced the image, claiming {{that it had been}} only slightly distorted inadvertently due to an <b>error</b> during <b>routine</b> processing.|$|R
50|$|In late 1983 {{the funding}} cost for {{continued}} development of Oric caused external funding to be sought, and {{eventually led to}} a sale to Edenspring Investments PLC. The Edenspring money enabled Oric International to release the Oric Atmos, which added a true keyboard and an updated V1.1 ROM to the Oric-1. The faulty tape <b>error</b> checking <b>routine</b> was still there.|$|R
2500|$|Thu Minh {{declared}} that she considers dancesport as [...] "lovers, {{still in love}} but could not see it again because of a fear for love blossoming". After Dancing With the Stars in 2011, Thu Minh had been [...] "feeling the miss of its abrupt ending for a long time". It is said that Thu Minh led many of her fans and colleagues to respect and feel an empathy for her artistic performance and drastic efforts in each of her artistic fields, the Northern-originated singer has always been committed into a challenge and attempting to play her best in any role. Judge Khanh Thi mentioned Thu Minh as a hard-working candidate who was the only contestant not showing many [...] "trifling skill" [...] to put a cover on <b>error</b> <b>routines</b> like other candidates but attempting to show skillful techniques of dancesport. She mainly focused and boldly tried to imitate routines and style of a 'real' professional dancer throughout the competition.|$|R
50|$|In telecommunications, {{asynchronous}} operation or asynchronous working {{is where a}} sequence of operations is executed such that the operations are executed out of time coincidence with any event. It can also be an operation that occurs without a regular or predictable time relationship to a specified event; e.g., the calling of an <b>error</b> diagnostic <b>routine</b> that may receive control {{at any time during}} the execution of a computer program.|$|R
25|$|Hardware {{exception}} {{mechanisms are}} processed by the CPU. It {{is intended to}} support error detection and redirects the program flow to <b>error</b> handling service <b>routines.</b> The state before the exception is saved on the stack.|$|R
50|$|Endurance {{was laid}} up in Portsmouth from 2008 to 2016, {{following}} serious {{damage caused by}} flooding following an <b>error</b> during <b>routine</b> maintenance on a sea suction strainer. In October 2013 {{it was reported that}} she would be scrapped; in July 2015 the vessel was offered for sale for further use or recycling and left Portsmouth under tow to the Leyal ship recycling Ltd. (LEYAL Gemi Söküm) facility in Turkey on 1 June 2016.|$|R
5000|$|This BIOS {{interrupt}} call {{is used by}} {{the running}} OS to get the memory size for 64MB+ configurations. It is supported by AMI BIOSses dated August 23, 1994 or later. The operating system just sets AX to 0xE801 then calls int 0x15. If some error has happened, the routine returns with CF (Carry Flag) set to 1. If no <b>error,</b> the <b>routine</b> returns with CF clear and the state of registers is described as following: ...|$|R
50|$|In October 1990, {{operator}} <b>error</b> {{during a}} <b>routine</b> test caused a shutdown of unit 2. In September 1991, twenty reactor operators failed required licensing examinations. The shortfall of licensed operators necessitated a shutdown of unit 1 until March 1992.|$|R
30|$|Shedid (2001) {{developed}} another J-function {{suitable for}} shaly reservoirs. It {{is based on}} using in situ conventional well logging data, which is more representative to wettability condition and also have less <b>error</b> chance than <b>routine</b> core measurements of porosity and permeability.|$|R
30|$|Some of {{the known}} attacks {{exploited}} known vulnerabilities, such as (1) buffer overflow, which allows an attacker to obtain unauthorised access to the system and execution of arbitrary code, (2) inproper handling of input values, e.g., one attack exploited vulnerable <b>error</b> handling <b>routine</b> that would crash on invalid DNS transaction identifier values, (3) improper check of memory copy, e.g., would crashed the server allowing an attacker to gain root privileges on name server, and many others.|$|R
50|$|Digital {{fragility}} can {{be reduced}} by designing a digital system for robustness. For example, a parity bit or other error management method can be inserted into the signal path. These schemes help the system detect errors, and then either correct the errors, or at least ask for a new copy of the data. In a state-machine, the state transition logic can be designed to catch unused states and trigger a reset sequence or other <b>error</b> recovery <b>routine.</b>|$|R
40|$|We {{present a}} {{probabilistic}} error correction technique {{to be used}} with an average magnitude difference function (AMDF) based pitch detector. This <b>error</b> correction <b>routine</b> provides a very simple method to correct errors in pitch period estimation. Used in conjunction with the computationally efficient AMDF, the result is a fast and accurate pitch detector. In performance tests on the CSTR (Center for Speech Technology Research) database, probabilistic error correction reduced the gross error rate from 6. 07 % to 3. 29 %...|$|R
40|$|Problem statement: The present {{work offers}} {{equations}} of Newton-Cotes Integration until twenty segments. Approach: It shows Newton-Cotes closed and open integration formulas. The new type Newton-Cotes semi-closed or semi-open was proposed. Results: An analysis of {{error in the}} technique was made. To estimate the error of integration in discrete data, we propose apply different rules or mix several rules. Conclusion/Recommendations: The difference in the result of each formula provides an approximation of the <b>error.</b> Computational <b>routines</b> to generate Newton-Cotes integration rules were presented...|$|R
5000|$|The buffer in {{an audio}} {{controller}} is a ring buffer. If an underrun occurs and the audio controller is not stopped, it will either keep repeating the sound {{contained in the}} buffer, which may hold {{a quarter of a}} second, or replace by silence depending on the implementation. Such effect is commonly referred to as [...] "machinegun" [...] or Max Headroom stuttering effect. This happens if the operating system hangs during audio playback. An <b>error</b> handling <b>routine</b> (e.g. blue screen of death) may eventually stop the audio controller.|$|R
40|$|Cloning is {{extremely}} {{likely to occur}} in web sites, much more so than in other software. While some clones exist for valid reasons, or are too small to eliminate, cloning percentages of 30 % or higher [...] -not uncommon in web sites [...] - suggest that some improvements can be made. Finding and resolving the clones in web documents is rather challenging, however: syntax <b>errors</b> and <b>routine</b> use of multiple languages complicate parsing the documents and finding clones, while lack of native code reuse tools forces the analyst to rely on other technologies for resolution. Here w...|$|R
40|$|Summary: We {{extended}} the original easyLINKAGE program by enabling linkage analyses for large-scale SNP data {{in addition to}} those of microsatellites. We implemented new modules for Allegro, Merlin, SimWalk, GeneHunter Imprinting, GeneHunter TwoLocus, SuperLink and extended FastSLink by automatic loop breaking and new out-puts. We added conditional linkage analyses as well as multipoint simulation studies, and extended <b>error</b> test <b>routines</b> by checking for Mendelian/non-Mendelian genotyping errors and for deviations from Hardy–Weinberg equilibrium. Data can be analyzed in sets of markers, in defined centimorgan intervals and by using different allele frequency algorithms. The outputs consist of genome-wide as well as chromo-somal postscript plots of LOD scores, NPL scores, P-values and other parameters...|$|R
5000|$|The current agent {{mechanism}} {{leaves a}} possibility of run-time type <b>error</b> (if a <b>routine</b> with n arguments is passed to an agent expecting m arguments with m < n). This can be avoided by a run-time check through the precondition [...] of [...] Several proposals for a purely static correction of this problem are available, including a language change proposal by Ribet et al.|$|R
40|$|Motivation: Current DNA {{sequencing}} technology produces reads of about 500 - 750 base pairs (bp) with typical coverage under 10 X. New sequencing technologies are emerging that produce shorter reads (length 80 - 200 bp) but allow one to generate significantly higher coverage (30 X and higher) at low cost. Modern assembly programs and <b>error</b> correction <b>routines</b> have been tuned {{to work well}} with current read technology, but were not designed for assembly of short reads. Results: We analyze the limitations of assembling reads generated by these new technologies, and present a routine for basecalling in reads prior to their assembly. We demonstrate that while it is feasible to assemble such short reads, the resulting contigs will require significant (if not prohibitive) finishing efforts. Contact...|$|R
40|$|Approved {{for public}} release; {{distribution}} in unlimited. Compiler writers continue {{to search for}} a reliable method of syntactic error recovery. Spurious error reports and confusing diagnostics are common problems confronting the programmer. Innumerable error possibilities have made recovery design a frustrating task. This thesis implements a method of syntactic error recovery using recursive calls on the <b>error</b> recovery <b>routine.</b> Parsing is accomplished by traversing transition diagrams which are created from syntax charts. Key language symbols and dynamically generated recovery positions are used in restoring the parse. High-quality error diagnostics give a clear, accurate, and thorough description of each error, providing an excellent instructional software tool. Approach and implementation issues are discussed, and sample output listings are included. [URL] Commander, United States Nav...|$|R
40|$|Total {{error is}} often {{calculated}} {{as a combination}} of random error and fixed bias. However, the specific protocols used to estimate random error and fixed bias are themselves variable factors that can affect the estimate of total error. We refer to biases such as assay drift, sample-to-sample carryover, and reagent carryover as examples of fixed biases that are protocol-specific and distinguish them from other fixed biases. Failing to account for protocol-specific biases that are present will lead to incorrect estimates of total <b>error</b> when <b>routine</b> use of the assay involves a protocol different from that used to estimate total error. Multi-factor protocols are recommended to determine protocol-specific biases, which, if present, {{should be included in}} the estimate of total error. AdditionalKeyphrases:quality control multi-factor protocol...|$|R
40|$|Systematic <b>errors</b> in <b>routine</b> {{procedural}} tasks {{present an}} important problem for psychologists who study interactions {{between humans and}} technological systems. This paper details an experiment designed to examine systematic error patterns and evaluate error predictions made by a notable psychological theory and industry-standard usability tools when performing multiple routine procedural tasks on a single highly visual interface. Participants completed three dynamic, computer-based routine procedural tasks involving execution of multiple steps. Differences were found in error frequencies at particular steps between the three tasks, a result {{that is consistent with}} predictions derived from Altmann and Trafton's (2002) activation-based model of memory for goals, but contrary to those of usability guidelines. Error patterns were reminiscent of several familiar types of systematic error. History and Motivatio...|$|R
5000|$|The {{original}} BinHex was {{a fairly}} simple format, one that was not very efficient because it expanded every byte of input into two, {{as required by the}} hexadecimal representation—an 8-to-4 bit encoding. For BinHex 2.0, Lempereur used a new 8-to-6 encoding that improved file size by 50% and took the opportunity to add a new CRC <b>error</b> checking <b>routine</b> in place of the earlier checksum. This new encoding used the first 64 ASCII printing characters, including the space, to represent the data, similarly to uuencode. Even though the new encoding was no longer hexadecimal in nature, the established name of the program was retained. The smaller files were incompatible with the older ones, so the extension became [...]hcx, c for compact.|$|R
