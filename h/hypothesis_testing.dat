8871|10000|Public
5|$|The {{problem of}} {{induction}} discussed above {{is seen in}} another form in debates over the foundations of statistics. The standard approach to statistical <b>hypothesis</b> <b>testing</b> avoids claims about whether evidence supports a hypothesis or makes it more probable. Instead, the typical test yields a p-value, which is the probability of the evidence being such as it is, {{under the assumption that}} the hypothesis being tested is true. If the p-value is too low, the hypothesis is rejected, in a way analogous to falsification. In contrast, Bayesian inference seeks to assign probabilities to hypotheses. Related topics in philosophy of statistics include probability interpretations, overfitting, and the difference between correlation and causation.|$|E
5|$|The {{software}} {{can be purchased}} in any of five capability configurations: JMP, JMP Pro, JMP Clinical, JMP Genomics and the JMP Graph Builder App for the iPad. JMP can be automated with its proprietary scripting language, JSL. The software is focused on exploratory visual analytics, where users investigate and explore data. These explorations can also be verified by <b>hypothesis</b> <b>testing,</b> data mining, or other analytic methods. In addition, discoveries made through graphical exploration can inspire a designed experiment that can be both designed and analyzed with JMP.|$|E
25|$|Fisher {{thought that}} <b>hypothesis</b> <b>testing</b> was a useful {{strategy}} for performing industrial quality control, however, he strongly disagreed that <b>hypothesis</b> <b>testing</b> {{could be useful}} for scientists.|$|E
3000|$|... [...]. Generally, {{a multivariate}} <b>hypothesis</b> <b>test</b> {{may also be}} {{regarded}} as an integration of multiple univariate <b>hypothesis</b> <b>tests.</b>|$|R
40|$|Virtually all {{business}} and economics statistics texts start their discussion of <b>hypothesis</b> <b>tests</b> with some more-or-less detailed reference to criminal trials. Apparently, these authors believe {{that students are}} better able to understand the relevance and usefulness of <b>hypothesis</b> <b>test</b> procedures by introducing them first via the dramatic analogy of the criminal justice system. In this paper, we argue that using the criminal trial analogy to motivate and introduce <b>hypothesis</b> <b>test</b> procedures represents bad statistics and bad pedagogy. First, we show that statistical <b>hypothesis</b> <b>test</b> procedures can not be applied to criminal trials. Thus, the criminal trial analogy is invalid. Second, we propose that students can better understand the simplicity and validity of statistical <b>hypothesis</b> <b>test</b> procedures if these procedures are carefully contrasted with the difficulties of decisionmaking in the context of criminal trials. The criminal trial discussion provides a bad analogy but an excellent counter-example for teaching statistical hypothesis procedures and the nature of statistical decision-making. <b>hypothesis</b> <b>tests,</b> criminal trials, Neyman-Pearson <b>hypothesis</b> <b>test</b> procedure...|$|R
30|$|More precisely, in this article, the MSRL for {{multiple}} parameters of interest per signal using a <b>hypothesis</b> <b>test</b> is derived. This choice {{is motivated by}} the following arguments: (i) the <b>hypothesis</b> <b>test</b> approach is not specific to a certain high-resolution algorithm (unlike the mean null spectrum approach), (ii) in this article, we link the asymptotic MSRL based on the <b>hypothesis</b> <b>test</b> approach to a new extension of the MSRL based on the CRB approach. Furthermore, we show that the MSRL based on the CRB approach {{is equivalent to the}} MSRL based on the <b>hypothesis</b> <b>test</b> approach for a fixed couple (Pfa, Pd), and (iii) the <b>hypothesis</b> <b>test</b> is shown to be asymptotically an uniformly most powerful test which is the strongest statement of optimality that one could expect to obtain [28].|$|R
25|$|The {{terminology}} is inconsistent. <b>Hypothesis</b> <b>testing</b> {{can mean}} any mixture of two formulations that both changed with time. Any discussion of significance testing vs <b>hypothesis</b> <b>testing</b> is doubly vulnerable to confusion.|$|E
25|$|Statistics is {{increasingly}} {{being taught in}} schools with <b>hypothesis</b> <b>testing</b> {{being one of the}} elements taught. Many conclusions reported in the popular press (political opinion polls to medical studies) are based on statistics. An informed public should understand the limitations of statistical conclusions and many college fields of study require a course in statistics for the same reason. An introductory college statistics class places much emphasis on <b>hypothesis</b> <b>testing</b> – perhaps half of the course. Such fields as literature and divinity now include findings based on statistical analysis (see the Bible Analyzer). An introductory statistics class teaches <b>hypothesis</b> <b>testing</b> as a cookbook process. <b>Hypothesis</b> <b>testing</b> is also taught at the postgraduate level. Statisticians learn how to create good statistical test procedures (like z, Student's t, F and chi-squared). Statistical <b>hypothesis</b> <b>testing</b> is considered a mature area within statistics, but a limited amount of development continues.|$|E
25|$|The p-value {{is used in}} {{the context}} of null <b>hypothesis</b> <b>testing</b> in order to {{quantify}} the idea of statistical significance of evidence. Null <b>hypothesis</b> <b>testing</b> is a reductio ad absurdum argument adapted to statistics. In essence, a claim is assumed valid if its counter-claim is improbable.|$|E
3000|$|The {{respective}} statistical <b>hypothesis</b> <b>test</b> {{to answer}} the primary hypothesis above is a one-sided <b>hypothesis</b> <b>test</b> on the population standard deviation of the paired differences between measurements (σ) against a predefined benchmark (σ [...]...|$|R
40|$|This paper adapts {{an already}} {{existing}} nonparametric <b>hypothesis</b> <b>test</b> to the bootstrap framework. The test utilizes the nonparametric kernel regression method to estimate {{a measure of}} distance between the models stated under the null hypothesis. The bootstraped version of the test allows to approximate errors involved in the asymptotic <b>hypothesis</b> <b>test.</b> <b>Hypothesis</b> <b>test,</b> the bootstrap, nonparametric regression, omitted variables, Research Methods/ Statistical Methods, C 12, C 14, C 15,...|$|R
25|$|<b>Testing</b> <b>hypothesis</b> in the field, modifying {{and setting}} up new <b>hypotheses,</b> <b>testing</b> them, and so on.|$|R
25|$|<b>Hypothesis</b> <b>testing</b> is of {{continuing}} interest to philosophers.|$|E
25|$|For {{statistical}} <b>hypothesis</b> <b>testing</b> {{this function}} {{is used to}} construct the p-value.|$|E
25|$|The {{cookbook}} {{method of}} teaching introductory statistics leaves {{no time for}} history, philosophy or controversy. <b>Hypothesis</b> <b>testing</b> has been taught as received unified method. Surveys showed that graduates of the class were filled with philosophical misconceptions (on all aspects of statistical inference) that persisted among instructors. While the problem was addressed {{more than a decade}} ago, and calls for educational reform continue, students still graduate from statistics classes holding fundamental misconceptions about <b>hypothesis</b> <b>testing.</b> Ideas for improving the teaching of <b>hypothesis</b> <b>testing</b> include encouraging students to search for statistical errors in published papers, teaching the history of statistics and emphasizing the controversy in a generally dry subject.|$|E
30|$|The <b>hypothesis</b> <b>test</b> method {{using the}} {{statistics}} of {{the arrangement of}} circular traces can improve {{the performance of the}} <b>hypothesis</b> <b>test</b> using the variance to some extent. Therefore, we propose the combination of these two methods for NLOS identification and mitigation.|$|R
40|$|While the {{combination}} of several or more models is often found to improve forecasts (Brandt and Bessler, Min and Zellner, Norwood and Schroeder), <b>hypothesis</b> <b>tests</b> are typically conducted using a single model approach 1. <b>Hypothesis</b> <b>tests</b> and forecasts have similar goals; they seek to define a range over which a parameter should lie within a degree of confidence. If it is true that, on average, composite forecasts are more accurate than a single model's forecast, {{it might also be}} true that <b>hypothesis</b> <b>tests</b> using information from numerous models are, on average, more accurate in the sense of lower Type I and Type II errors than <b>hypothesis</b> <b>tests</b> using a single model. Research Methods/ Statistical Methods,...|$|R
40|$|The {{ability to}} conduct <b>hypothesis</b> <b>tests</b> {{is among the}} most {{important}} statistical skills that our students can learn. Unfortunately, {{it is also one of}} the most difficult skills for them to learn. In our survey of 44 introductory business and economics statistics textbooks, we find that textbook authors differ over the better way to explain one-tailed <b>hypothesis</b> <b>tests.</b> Approximately half of these books use the simple null hypothesis approach, while the remaining textbooks use the composite null hypothesis approach. In this article, we show that the majority of textbooks that use the composite null hypothesis approach contain methodological shortcomings that potentially, at least, make it more difficult for students to learn how to use <b>hypothesis</b> <b>tests</b> for business decisions. Keywords: One-tailed <b>hypothesis</b> <b>tests.</b> JEL codes: A 22 and C 12. XX 0 H 0 : X 9 X 0 H a : XX 0 1 A CRITIQUE OF ONE-TAILED <b>HYPOTHESIS</b> <b>TEST</b> PROCEDURES IN BUSINESS AND ECONOMICS STAT [...] ...|$|R
25|$|Some {{people find}} it helpful {{to think of the}} <b>hypothesis</b> <b>testing</b> {{framework}} as analogous to a mathematical proof by contradiction.|$|E
25|$|One naïve Bayesian {{approach}} to <b>hypothesis</b> <b>testing</b> is to base {{decisions on the}} posterior probability, but this fails when comparing point and continuous hypotheses. Other approaches to decision making, such as Bayesian decision theory, attempt to balance the consequences of incorrect decisions across all possibilities, rather than concentrating on a single null hypothesis. A number of other approaches to reaching a decision based on data are available via decision theory and optimal decisions, {{some of which have}} desirable properties. <b>Hypothesis</b> <b>testing,</b> though, is a dominant {{approach to}} data analysis in many fields of science. Extensions to the theory of <b>hypothesis</b> <b>testing</b> include the study of the power of tests, i.e. the probability of correctly rejecting the null hypothesis given that it is false. Such considerations can be used for the purpose of sample size determination prior to the collection of data.|$|E
25|$|Many of the {{philosophical}} criticisms of <b>hypothesis</b> <b>testing</b> are discussed by statisticians in other contexts, particularly correlation does not imply causation and the design of experiments.|$|E
3000|$|A <b>hypothesis</b> <b>test</b> can be deduced {{from the}} idea {{described}} above. This <b>hypothesis</b> <b>test</b> determines if NLOS nodes exist or not by comparing the MSE of the range estimates with the variance of the LOS range estimates. The two hypotheses are [...]...|$|R
40|$|In this article, {{a global}} <b>hypothesis</b> <b>test</b> is studied to {{simultaneously}} compare the likelihood ratios of multiple binary diagnostic tests {{when in the}} presence of partial disease verification the missing data mechanism is ignorable. The <b>hypothesis</b> <b>test</b> is based on the chi-squared distribution. Simulation experiments were carried out to study the type I error {{and the power of the}} global <b>hypothesis</b> <b>test</b> when comparing the likelihood ratios of two and three diagnostic tests respectively. The results obtained were applied to the diagnosis of coronary stenosis. Peer Reviewe...|$|R
30|$|Discriminative {{analyses}} and integrative <b>hypothesis</b> <b>tests</b> (IHT).|$|R
25|$|Mathematica {{supports}} the univariate Poisson distribution as PoissonDistribution, and the bivariate Poisson distribution as MultivariatePoissonDistribution, including computation of probabilities and expectation, sampling, parameter estimation and <b>hypothesis</b> <b>testing.</b>|$|E
25|$|Rigidly {{requiring}} {{statistical significance}} {{as a criterion}} for publication, resulting in publication bias. Most of the criticism is indirect. Rather than being wrong, statistical <b>hypothesis</b> <b>testing</b> is misunderstood, overused and misused.|$|E
25|$|Over-reliance on testimonial, anecdotal evidence, or {{personal}} experience: This evidence {{may be useful}} for the context of discovery (i.e. hypothesis generation), but {{should not be used}} in the context of justification (e.g. Statistical <b>hypothesis</b> <b>testing).</b>|$|E
30|$|If we {{have found}} a {{globally}} optimum solution to Eq. (12) in the <b>hypothesis</b> <b>tests</b> of one bottleneck user, obviously {{there is no need}} to check the rest of <b>hypothesis</b> <b>tests,</b> and the PASA routine terminates. Otherwise, we turn to check the case of two bottleneck users.|$|R
5000|$|... #Subtitle level 3: Classification of {{multiple}} <b>hypothesis</b> <b>tests</b> ...|$|R
40|$|The {{problem is}} how to compare the quality of {{different}} <b>hypothesis</b> <b>tests</b> in a Bayesian framework without introducing a loss function. Three different linear orders {{on the set of}} all possible <b>hypothesis</b> <b>tests</b> are studied. The most natural order estimates the Fisher information between indicators of event and decision...|$|R
25|$|GSEA uses a Kolmogorov Smirnov style {{statistic}} to {{see whether}} any previously defined gene sets exhibited unusual behavior in the current expression profile. This leads to a multiple <b>hypothesis</b> <b>testing</b> challenge, but reasonable methods exist to address it.|$|E
25|$|The new methodological {{approaches}} of the processual research paradigm include logical positivism (the idea that {{all aspects of}} culture are accessible through the material record), the use of quantitative data, and the hypothetico-deductive model (scientific method of observation and <b>hypothesis</b> <b>testing).</b>|$|E
25|$|Fisher was an {{agricultural}} statistician who emphasized rigorous experimental design and methods to extract a result from few samples assuming Gaussian distributions. Neyman (who teamed {{with the younger}} Pearson) emphasized mathematical rigor and methods to obtain more results from many samples and {{a wider range of}} distributions. Modern <b>hypothesis</b> <b>testing</b> is an inconsistent hybrid of the Fisher vs Neyman/Pearson formulation, methods and terminology developed in the early 20th century. While <b>hypothesis</b> <b>testing</b> was popularized early in the 20th century, evidence of its use can be found much earlier. In the 1770s Laplace considered the statistics of almost half a million births. The statistics showed an excess of boys compared to girls. He concluded by calculation of a p-value that the excess was a real, but unexplained, effect.|$|E
30|$|We {{compare the}} {{performance}} of the proposed method, the combination of <b>hypothesis</b> <b>test</b> methods (HC), with a number of other methods. One is the <b>hypothesis</b> <b>test</b> method using the variance (HT) described in Section 3.1. The second is the <b>hypothesis</b> <b>test</b> method using circular traces (CT) in Section 3.2. The third is the Residual weighting method (RW) described in [16]. In addition, the AML method [11], which is the best performing algorithm among some typical location estimation algorithms compared in [12] but without NLOS identification, is also included.|$|R
40|$|Abstract – In {{remote sensing}} and other disciplines, {{clustering}} is frequently used in classification to assign labels to data. In particular, the iterative guided spectral class rejection (IGSCR) classification algorithm uses labeled data and a statistical <b>hypothesis</b> <b>test</b> {{to determine which}} clusters {{should be used in}} classification. Rejected clusters (based on this evaluation method) are then refined. The <b>hypothesis</b> <b>test</b> used in IGSCR is based on the binomial distribution, which effectively models hard cluster and class memberships. This work proposes an analogous <b>hypothesis</b> <b>test</b> for soft cluster evaluation...|$|R
40|$|Multiple <b>hypothesis</b> <b>tests</b> {{have been}} widely studied in the recent {{literature}} of statistics, however, {{most of the studies}} focus on how to control the false discovery rate for a given set of test scores or, equivalently, test p-values. Given the vast data involved in a multiple <b>hypothesis</b> <b>test,</b> it is natural to think about how to make use of population information of samples to improve the power of the test for each individual subject and thus to improve the power of the multiple <b>hypothesis</b> <b>test.</b> In this paper, we propose a nonparametric method for evaluation of test scores for each individual subject involved in a multiple <b>hypothesis</b> <b>test.</b> The method consists of two key steps, smoothing over neighboring subjects and density estimation over control samples, both of which allow for the use of population information of the subjects. The new method is tested on both the microarray data and the ChIP-chip data. The numerical results indicate that use of population information can significantly improve the power of multiple <b>hypothesis</b> <b>tests...</b>|$|R
