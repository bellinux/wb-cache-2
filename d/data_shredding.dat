2|20|Public
50|$|Provides encryption, WORM and <b>data</b> <b>shredding</b> services, data {{resilience}} and business continuity services and content management services.|$|E
40|$|Abstract: This paper {{presents}} a performance analysis of strategies for storing XML data sets in relational databases, focusing on XML datasets {{that are a}} combination of structured and semi-structured data. The analysis demonstrates advantages of a hybrid approach combining structure mapping and XML data type instances. However problems remain with current technology with regards to scaling of the approach for large data sets. Also, anomalous results are identified and a threshold at which the cost of <b>data</b> <b>shredding</b> out weighs the advantages of structure mapping. ...|$|E
50|$|<b>Data</b> <b>Shredder</b> (also {{known as}} CBL <b>Data</b> <b>Shredder)</b> is a <b>data</b> {{destruction}} utility designed to securely erase a hard disk or digital storage device, completely removing {{the data and}} making it unrecoverable. The software utilizes an overwrite method of destroying data rather than other means of data destruction (such as: ATA secure erase, crypto-shredding, degaussing, physical destruction).|$|R
5000|$|Avast Premier - Includes all the {{features}} of Internet Security, {{with the addition of}} a <b>data</b> <b>shredder,</b> an [...] "AccessAnywhere" [...] service, and automatic software updater (for programs such as Google Chrome). Does not require registration, but does require a license or activation code.|$|R
5000|$|Widespread {{need for}} secure data {{destruction}} meant that language-variants {{of the program}} needed to be developed to support demand. Coverage of the product in countries like Germany and Singapore lead to excessive downloading and general popularity. PC Magazine included <b>Data</b> <b>Shredder</b> {{as one of its}} must-have security tools. [...] A large increase in electronic waste due to high quanitites of old computers being thrown out as garbage in dumps and landfills made security of data stored on hard drives a bigger concern of the general public. [...] Data destruction became a part of regular service offerings from the company as press coverage highlighted the step in the data recovery process.|$|R
40|$|Abstract — By {{imposing}} a single hierarchy on data, XML makes queries brittle {{in the sense}} that a query might fail to produce the desired result if it is executed on the same data organized in a different hierarchy, or if the hierarchy evolves during the life-time of an application. This paper presents a new transformation language, called XMorph, which supports more flexible querying. XMorph is a shape polymorphic language, that is, a single XMorph query can extract and transform data from differently-shaped hierarchies. The XMorph <b>data</b> <b>shredder</b> distills XML <b>data</b> into a graph of closest relationships, which are exploited by the query evaluation engine to produce a result in the shape specified by an XMorph query. I...|$|R
50|$|PCKeeper Live offers 13 {{different}} PC {{services in}} 4 categories: Human Assistance (Find & Fix, Geek on Demand, Live Support), Security (Anti-Theft, <b>Data</b> Hider, <b>Shredder,</b> Files Recovery), Cleaning (Disk Cleaner, Disk Explorer, Duplicates Finder, Uninstaller) and Optimization (Context Menu Manager, Startup Manager).|$|R
40|$|As XML usage grows {{for both}} {{data-centric}} and document-centric applications, introducing native support for XML data in relational databases brings significant benefits. It {{provides a more}} mature platform for the XML data model and serves {{as the basis for}} interoperability between relational and XML data. Whereas query processing on XML <b>data</b> <b>shredded</b> into one or more relational tables is well understood, it provides limited support for the XML data model. XML data can be persisted as a byte sequence (BLOB) in columns of tables to support the XML model more faithfully. This introduces new challenges for query processing such as the ability to index the XML blob for good query performance. This paper reports novel techniques for indexing XML data in the upcoming version of Microsoft ® SQL Server™, and how it ties into the relational framework for query processing. 1...|$|R
50|$|As {{optical media}} are not magnetic, {{they are not}} erased by {{conventional}} degaussing. Write-once optical media (CD-R, DVD-R, etc.) also cannot be purged by overwriting. Read/write optical media, such as CD-RW and DVD-RW, may be receptive to overwriting. Methods for successfully sanitizing optical discs include delaminating or abrading the metallic <b>data</b> layer, <b>shredding,</b> incinerating, destructive electrical arcing (as by exposure to microwave energy), and submersion in a polycarbonate solvent (e.g., acetone).|$|R
5000|$|Cyber Shredder - A program {{created by}} Utrom Shredder {{as a backup}} {{identity}} in case he was defeated. Viral's attempt to gain the <b>data</b> of <b>Shredder</b> causes her to merge with the data of the Utrom Shredder resulting {{in the creation of}} the Cyber Shredder. He would subsequently attempt to escape to the real world, assisted by the reformed Foot Clan under Master Khan. After facing the Turtles on several occasions, he absorbed a powerful energy source and attacked during April and Casey's wedding. This ability made him more than a match for the Turtles and even the Justice Force, but the Turtles found a way to make him digital again and delete him using Serling's Decompiler weapon.|$|R
50|$|In {{some cases}} {{everything}} is encrypted (eg. harddisk, computer file, database, etc.) {{but in other}} cases only specific data (eg. passport number, social security number, bank account number, person name, record in a database, etc.) is encrypted. In addition the same specific data in one system can be encrypted with another key in another system.The more specific data is encrypted (with different keys) the more specific <b>data</b> can be <b>shredded.</b>|$|R
40|$|HST WFPC 2 {{images are}} {{presented}} that span the inner 19 kpc {{diameter of the}} edge-on spiral galaxy NGC 3079; they are combined with ground-based Halpha+[N II] Fabry-Perot spectra and VLA images of radio polarization vectors and rotation measures. Ionized gas filaments within 9 kpc diameter project ~ 3 kpc above the disk, with the brightest forming the 1 kpc diameter superbubble. They are often resolved into strands ~ 0. " 3 (25 pc) wide which emerge from the nuclear CO ring as five distinct gas streams with velocity gradients and dispersions of hundreds of km/s. One stream flows for 250 pc and aligns with the VLBI-scale radio jet, the other four are not connected to the jet, instead curving to the vertical 0. 6 kpc above the galaxy disk, then dispersing in a spray of droplets each with ionized mass ~ 1000 sqrt(f) Msun (volume filling factor f > 0. 003 from our <b>data).</b> <b>Shredded</b> clumps of disk gas form a similar structure in hydro models of a galaxy-scale wind. The pattern of magnetic fields and the gas kinematics also suggest a wind of mechanical luminosity 10 ^ 43 erg/s that has stagnated in the galaxy disk at radius ~ 800 pc, flared to larger radii with increasing height as the balancing ISM pressure reduces above the disk, and entrained dense clouds into a vortex. Total KE and momentum of the filaments are (0. 4 - 5) x 10 ^ 55 sqrt(f) ergs and (1. 6 - 6) x 10 ^ 47 sqrt(f) dyne s. A star-forming complex elsewhere in the galaxy shows a striking spray of linear filaments that extend for hundreds of parsecs. Comment: Accepted to ApJ, 31 pages, 15 figures (some color). High-fidelity figs at [URL]...|$|R
40|$|XML {{has emerged}} as the {{standard}} data format for Internet-based business ap-plications. In many bussiness settings, a relational database management sys-tem(RDBMS) will serve as the storage manager for data from XML documents. In such a system, once the XML <b>data</b> is <b>shredded</b> and loaded into the storage sys-tem, XML queries posed against these (now virtual) XML documents are processed by translating them as much as possible into SQL queries against the underlying re-lational storage. Clearly, in order to support full database functionalities over XML data, we must allow users not only to query but also to specify updates on XML documents. Today while the XML query language XQuery is being standardized by W 3 C, no syntax for updating XML documents is included in this language proposal as of now. In this thesis, we have developed techniques for supporting translation of XML updates on XML views of relational data into SQL updates on the underlying re-lations. These techniques are based on techniques for supporting translation o...|$|R
40|$|Much of {{business}} XML data has accompanying XSD specifications. In many scenarios, "shredding" such XML data into a relational storage {{is a popular}} paradigm. Optimizing evaluation of XPath queries over such XML data requires paying careful attention to both logical and physical design of the relational database where XML <b>data</b> is <b>shredded.</b> None of the existing solutions has taken into account physical design of the generated relational database. In this paper, we study the interplay of logical and physical design and conclude that (1) solving them independently leads to suboptimal performance; (2) there is substantial overlap between logical and physical design: some well-known logical design transformations generate the same mappings as physical design. Furthermore, existing search algorithms are inefficient to search the extremely large space of logical and physical design combinations. We propose a search algorithm that carefully avoids searching duplicated mappings and utilizes the workload information to further prune the search space. Experimental results confirm the effectiveness of our approach...|$|R
40|$|Abstract—Much of {{business}} XML data has accompanying XSD specifications. In many scenarios, “shredding ” such XML data into a relational storage {{is a popular}} paradigm. Optimizing evaluation of XPath queries over such XML data requires paying careful attention to both the logical and physical designs of the relational database where XML <b>data</b> is <b>shredded.</b> None of the existing solutions has taken into account physical design of the generated relational database. In this paper, we study the interplay of logical and physical design and conclude that 1) solving them independently leads to suboptimal performance and 2) there is substantial overlap between logical and physical designs: some well-known logical design transformations generate the same mappings as physical design. Furthermore, existing search algorithms are inefficient to search the extremely large space of logical and physical design combinations. We propose a search algorithm that carefully avoids searching duplicated mappings and utilizes the workload information to further prune the search space. Experimental results confirm the effectiveness of our approach. Index Terms—XML, physical design, relational databases. ...|$|R
40|$|The {{performance}} of XML query processing in persistent XML databases crucially {{depends on the}} chosen data access paths, and on {{the efficiency of the}} remaining query processing steps, notably navigation (path) query processing, and result construction (or re-construction, if the <b>data</b> has been <b>shredded).</b> In this context, we demonstrate that XML path summaries are useful tools for access path selection, and establish efficient algo-rithms for building and exploiting them. This leads to very efficient processing when used in conjunction with a path-partitioned store, in particular much better than if tag partitioning is used. Further-more, we devise an efficient method for complex tree reconstruc-tion, with much lower memory needs than existing alternatives. Our algorithms are implemented in the XSum Java library [6]. 2. PATH SUMMARIES AND PATH PARTI-TIONIN...|$|R
40|$|Analytical {{processing}} on XML repositories {{is usually}} enabled by designing complex <b>data</b> transformations that <b>shred</b> the documents into a common data warehousing schema. This {{can be very}} timeconsuming and costly, especially if the underlying XML data {{has a lot of}} variety in structure, and only a subset of attributes constitutes meaningful dimensions and facts. Today, there is no tool to explore an XML data set, discover interesting attributes, dimensions and facts, and rapidly prototype an OLAP solution. In this paper, we propose a system, called SEDA 1, that enables users to start with simple keyword-style querying, and interactively refine the query based on result summaries. SEDA then maps query results onto a set of known, or newly created, facts and dimensions, and derives a star schema and its instantiation to be fed into an offthe-shelf OLAP tool, for further analysis. 1...|$|R
40|$|Abstract — Spurred by {{financial}} scandals and privacy concerns, governments worldwide {{have moved to}} ensure confidence in digital records by regulating their retention and deletion. These requirements {{have led to a}} huge market for compliance storage servers, which ensure that <b>data</b> are not <b>shredded</b> or altered before the end of their mandatory retention period. These servers preserve unstructured and semi-structured data at a file-level granularity: email, spreadsheets, reports, instant messages. In this paper, we extend this level of protection to structured data residing in relational databases. We propose a compliant DBMS architecture and two refinements that illustrate the additional security that one can gain with only a slight performance penalty, with almost no modifications to the DBMS kernel. We evaluate our proposed architecture through experiments with TPC-C on a high-performance DBMS, and show that the runtime overhead for transaction processing is approximately 10 % in typical configurations. I...|$|R
40|$|In a cloud {{environment}} where Storage is {{offered as a}} service, a client stores his data with a provider and pays as per the usage. Once the contract ends, the client, as the data owner, may like to see, due to privacy reasons and otherwise that the <b>data</b> is properly <b>shredded</b> in the provider storage. In this {{paper we propose a}} scheme for Zero Data Remnance Proof (ZDRP) – a comprehensive proof given by the cloud data storage provider as regards to zero data remnance post the SLA period. In absence of such shredding the provider can consume the data to his benefit without coming in legal framework. The proof of data destruction can be achieved together by clauses in the SLA and a comprehensive destruction-verifier algorithm. The implementation of this can be achieved by appropriate modification of the data updation mechanisms provided by open source cloud providers...|$|R
5000|$|Distributing {{very long}} {{one-time}} pad keys is inconvenient and usually poses a significant security risk. The pad {{is essentially the}} encryption key, but unlike keys for modern ciphers, it must be extremely long and is much too difficult for humans to remember. Storage media such as thumb drives, DVD-Rs or personal digital audio players {{can be used to}} carry a very large one-time-pad from place to place in a non-suspicious way, but even so the need to transport the pad physically is a burden compared to the key negotiation protocols of a modern public-key cryptosystem, and such media cannot reliably be erased securely by any means short of physical destruction (e.g., incineration). A 4.7 GB DVD-R full of one-time-pad <b>data,</b> if <b>shredded</b> into particles 1 mm² in size, leaves over 4 megabits of (admittedly hard to recover, but not impossibly so) data on each particle. [...] In addition, the risk of compromise during transit (for example, a pickpocket swiping, copying and replacing the pad) is likely to be much greater in practice than the likelihood of compromise for a cipher such as AES. Finally, the effort needed to manage one-time pad key material scales very badly for large networks of communicants—the number of pads required goes up as the square of the number of users freely exchanging messages. For communication between only two persons, or a star network topology, this is less of a problem.|$|R
50|$|A {{limitation}} of shred when invoked on ordinary files {{is that it}} only overwrites the data in place without overwriting other copies of the file. Copies can manifest themselves {{in a variety of}} ways, such as through manual and automatic backups, file system snapshots, copy-on-write filesystems, wear leveling on flash drives, caching such as NFS caching, and journaling. All limitations imposed by the file system can be overcome by shredding every device on which the data resides instead of specific files. However, since wear leveled devices do not guarantee a fixed relationship between logical blocks addressable through the interface and the physical locations in which the <b>data</b> is stored, <b>shredding</b> may not provide adequate security. If available, the SATA secure erase command, issued through hdparm or a similar utility, may be helpful in this situation. Even for magnetic devices, SATA secure erase will be faster and more reliable than shredding. Physical destruction may be necessary to securely erase devices such as memory cards and unusable hard disks.|$|R
40|$|A 2. 91 -billion {{base pair}} (bp) {{consensus}} {{sequence of the}} euchromatic portion {{of the human genome}} was generated by the whole-genome shotgun sequencing method. The 14. 8 -billion bp DNA sequence was generated over 9 months from 27, 271, 853 high-quality sequence reads (5. 11 -fold coverage of the genome) from both ends of plasmid clones made from the DNA of five individuals. Two assembly strategies—a whole-genome assembly and a regional chromosome assembly—were used, each combining sequence data from Celera and the publicly funded genome effort. The public <b>data</b> were <b>shredded</b> into 550 -bp segments to create a 2. 9 -fold coverage of those genome regions that had been sequenced, without including biases inherent in the cloning and assembly procedure used by the publicly funded group. This brought the effective coverage in the assemblies to eightfold, reducing the number and size of gaps in the final assembly over what would be obtained with 5. 11 -fold coverage. The two assembly strategies yielded very similar results that largely agree with independent mapping data. The assemblies effectively cover the euchromatic regions of the human chromosomes. More than 90 % of the genome is in scaffold assemblies of 100, 000 bp or more, and 25 % of the genome is in scaffolds of 10 million bp or larger. Analysis of the genome sequence revealed 26, 588 protein-encoding transcripts for which there was strong corroborating evidence and an additional ∼ 12, 000 computationally derived genes with mouse matches or other weak supporting evidence. Although gene-dense clusters are obvious, almost half the genes are dispersed in low G+C sequence separated by large tracts of apparently noncoding sequence. Only 1. 1 % of the genome is spanned by exons, whereas 24 % is in introns, with 75 % of the genome being intergenic DNA. Duplications of segmental blocks, ranging in size up to chromosomal lengths, are abundant throughout the genome and reveal a complex evolutionary history. Comparative genomic analysis indicates vertebrate expansions of genes associated with neuronal function, with tissue-specific developmental regulation, and with the hemostasis and immune systems. DNA sequence comparisons between the consensus sequence and publicly funded genome data provided locations of 2. 1 million single-nucleotide polymorphisms (SNPs). A random pair of human haploid genomes differed at a rate of 1 bp per 1250 on average, but there was marked heterogeneity in the level of polymorphism across the genome. Less than 1 % of all SNPs resulted in variation in proteins, but the task of determining which SNPs have functional consequences remains an open challenge...|$|R

