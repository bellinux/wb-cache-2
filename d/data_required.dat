3698|10000|Public
5|$|The {{report writer}} is a {{declarative}} facility for creating reports. The programmer need only specify the report layout and the <b>data</b> <b>required</b> to produce it, freeing them {{from having to}} write code to handle things like page breaks, data formatting, and headings and footings.|$|E
25|$|Just as {{absolute}} entropy {{serves as}} theoretical background for data compression, relative entropy serves as theoretical background for data differencing – the absolute entropy {{of a set}} of data in this sense being the <b>data</b> <b>required</b> to reconstruct it (minimum compressed size), while the relative entropy of a target set of data, given a source set of data, is the <b>data</b> <b>required</b> to reconstruct the target given the source (minimum size of a patch).|$|E
25|$|JSON Schema {{specifies}} a JSON-based {{format to}} define the structure of JSON data for validation, documentation, and interaction control. It provides a contract for the JSON <b>data</b> <b>required</b> by a given application, and how that data can be modified.|$|E
5000|$|... "Use of <b>data</b> <b>requires</b> {{knowledge}} about the different sources of uncertainty.Measurement is a process. Is the system of measurement stable or unstable? Useof <b>data</b> <b>requires</b> also understanding {{of the distinction between}} enumerative studies and analytic problems." ...|$|R
30|$|Usage of multivariate {{and noisy}} <b>data</b> <b>requires</b> a robust algorithm.|$|R
5000|$|Health Insurance Portability and Accountability Act (HIPAA) (Moving {{confidential}} <b>data</b> <b>requires</b> encryption.) ...|$|R
25|$|Telkom SA has {{upgraded}} {{many of its}} exchanges {{to support}} ADSL2+ up to a maximum downstream speed of 20Mbit/s and 1Mbit/s upload. As of August 2012 there are close to 200,000 subscribers upgraded onto this service. Availability {{is determined by the}} proliferation of higher bandwidth backhaul in order to support the larger amount of <b>data</b> <b>required.</b>|$|E
25|$|While solar {{photovoltaic}} (PV) cells are promising for clean energy production, their deployment is hindered by production costs, material availability, and toxicity. <b>Data</b> <b>required</b> to investigate their impact are sometimes {{affected by a}} rather large amount of uncertainty. The values of human labor and water consumption, for example, are not precisely assessed {{due to the lack}} of systematic and accurate analyses in the scientific literature.|$|E
25|$|Flux balance {{analysis}} (FBA) is {{a mathematical}} method for simulating metabolism in genome-scale reconstructions of metabolic networks. In comparison to {{traditional methods of}} modeling, FBA is less intensive {{in terms of the}} input <b>data</b> <b>required</b> for constructing the model. Simulations performed using FBA are computationally inexpensive and can calculate steady-state metabolic fluxes for large models (over 2000 reactions) in a few seconds on modern personal computers.|$|E
2500|$|Therefore, 80 minutes (4,800 seconds) of CD-DA <b>data</b> <b>requires</b> 846,720,000 bytes of storage: ...|$|R
2500|$|... improve {{compression}} {{in compression}} algorithms {{where a small}} area of <b>data</b> <b>requires</b> n-grams of greater length ...|$|R
2500|$|For example, {{assessment}} of [...] from surveillance <b>data</b> <b>requires</b> careful {{control of the}} variation of the reporting rate {{and the intensity of}} surveillance.|$|R
25|$|Another ICTS International {{product is}} Integrated Passenger Processing Solutions or IP@SS, {{a system that}} accelerates {{passenger}} flow while enhancing security. Automated TravelDoc is a system which performs automatic scans of travel documents to verify their authenticity and ensure they {{meet the requirements of}} the destination country. Another product is APIS Solution, a scanner that extracts <b>data</b> <b>required</b> by U.S. Customs automatically. ICTS International also produces a computer-based training system for X-ray operators that simulates potential workday situations.|$|E
25|$|Non-tomographic {{variants}} on this method, {{referred to}} as single particle analysis, use images of multiple (hopefully) identical objects at different orientations to produce the image <b>data</b> <b>required</b> for three-dimensional reconstruction. If the objects do not have significant preferred orientations, this method does not suffer from the missing data wedge (or cone) which accompany tomographic methods nor does it incur excessive radiation dosage, however it assumes that the different objects imaged can be treated as if the 3D data generated from them arose from a single stable object.|$|E
25|$|While the <b>data</b> <b>required</b> {{are easily}} {{identified}} {{in the case of}} humans, the computation of life expectancy of industrial products and wild animals involves more indirect techniques. The life expectancy and demography of wild animals are often estimated by capturing, marking, and recapturing them. The life of a product, more often termed shelf life, is also computed using similar methods. In the case of long-lived components, such as those used in critical applications: in aircraft, methods like accelerated aging are used to model the life expectancy of a component.|$|E
50|$|For comparison, CCM mode {{offering}} similar functionality requires {{twice as}} many block cipher operations per message block (associated <b>data</b> <b>requires</b> one, as in OCB).|$|R
50|$|Not much data is {{available}} regarding {{the safety of}} hitchhiking. Compiling good safety <b>data</b> <b>requires</b> counting hitchhikers, counting rides, and counting problems: a difficult task.|$|R
40|$|The {{theoretical}} {{nature of}} risk premiums in foreign currency futures markets is derived and studied empirically. Estimation problems encountered in using futures data are discussed. Since forward rates and futures prices are demonstrated to be approximately equal, and because risk premiums in forward markets are highly variable, {{consistency of the}} <b>data</b> <b>requires</b> time variation in daily risk premiums in the futures market. Unbiasedness of daily futures prices as predictors of the following day's futures price is rejected for all currencies. Reconciliation of daily and monthly <b>data</b> <b>requires</b> positive serial correlation in daily risk premiums...|$|R
25|$|The U.S. Food and Drug Administration (FDA) {{appears to}} be very {{invested}} in the science of pharmacogenomics as is demonstrated through the 120 and more FDA-approved drugs that include pharmacogenomic biomarkers in their labels. On May 22, 2005, the FDA issued its first Guidance for Industry: Pharmacogenomic Data Submissions, which clarified the type of pharmacogenomic <b>data</b> <b>required</b> to be submitted to the FDA and when. Experts {{recognized the importance of}} the FDA’s acknowledgement that pharmacogenomics experiments will not bring negative regulatory consequences. The FDA had released its latest guide Clinical Pharmacogenomics (PGx): Premarket Evaluation in Early-Phase Clinical Studies and Recommendations for Labeling in January, 2013. The guide is intended to address the use of genomic information during drug development and regulatory review processes.|$|E
25|$|In 1654, Ferdinando II de Medici {{established}} the first weather observing network, {{that consisted of}} meteorological stations in Florence, Cutigliano, Vallombrosa, Bologna, Parma, Milan, Innsbruck, Osnabrück, Paris and Warsaw. The collected data were sent to Florence at regular time intervals. In 1832, an electromagnetic telegraph was created by Baron Schilling. The arrival of the electrical telegraph in 1837 afforded, for the first time, a practical method for quickly gathering surface weather observations from a wide area. This data {{could be used to}} produce maps {{of the state of the}} atmosphere for a region near the Earth's surface and to study how these states evolved through time. To make frequent weather forecasts based on these <b>data</b> <b>required</b> a reliable network of observations, but it was not until 1849 that the Smithsonian Institution began to establish an observation network across the United States under the leadership of Joseph Henry. Similar observation networks were established in Europe at this time. The Reverend William Clement Ley was key in understanding of cirrus clouds and early understandings of Jet Streams. Later after this Charles Kenneth Mackinnon Douglas known as 'CKM' Douglas read Ley's papers after his death and carried on the early study of weather systems.|$|E
500|$|In {{the lead}} up to Churchill's next meeting with Eisenhower in June 1954, the President's {{assistant}} for atomic energy, Major General Howard G. Bunker, discussed carriage of American atomic bombs in British aircraft with the BJSM. A detailed list of the equipment and technical <b>data</b> <b>required</b> was drawn up, and the USAF undertook to provide training and technical assistance. It would also establish facilities to store, assemble and assist with loading the bombs. The McMahon act was amended in August 1954, and while it did not go nearly {{as far as the}} British government wanted—the transfer of information regarding the design and manufacture of nuclear weapons was still prohibited—it did now allow for the interchange of information on their use. This {{paved the way for the}} Agreement for Cooperation Regarding Atomic Information for Mutual Defence Purposes with Britain, which was signed on 12 June 1955. A colonel and two majors from the USAF and the Armed Forces Special Weapons Project were given briefings on RAF aircraft [...] to determine which American bombs could be carried. The Americans then wanted to know how many bombs would be required. The Minister of Defence, Harold Macmillan, determined that the V-bomber force would reach a strength of 240 aircraft during 1958.|$|E
50|$|Sailing Directions {{are updated}} when new <b>data</b> <b>requires</b> {{extensive}} revision {{of an existing}} text. These data are obtained from several sources, including pilots and Sailing Directions from other countries.|$|R
5000|$|A <b>data</b> {{definition}} specification <b>requires</b> <b>data</b> definitions to be: ...|$|R
30|$|Conclusion: For basic CCE use, {{next-generation}} micro-digital broadband beamformer appears providing {{reliable information}} with good-to-excellent diagnostic capability, accurate two-dimensional measurements, and adapted therapeutic suggestions. These preliminary <b>data</b> <b>require</b> further confirmation.|$|R
500|$|The Soviets {{never did}} get the {{detailed}} <b>data</b> <b>required</b> to redesign the ship's barbettes and magazines, but they did know that the 380-mm barbettes was bigger in diameter {{than that of the}} 305mm turret as well as taller than the Russian turrets. So the barbette of turret number two had to be raised to clear turret number one and the height of the conning tower had to be raised to clear turret number two. Similarly the [...] anti-aircraft guns behind turret number three had to be raised as well. The new turrets required more electrical power which meant that the output of the turbo generators had to be increased to 1,300 kilowatts. All of these changes added over [...] to the ships' displacement and the sketch design was completed by 16 October 1940, as Project 69-I (Importnyi—Imported), even though they still lacked data for the turrets and their barbettes. This was presented to the State Defense Committee on 11 February 1941, but the design was not approved until 10 April when it ordered that the first two ships be completed with German guns while the others would continue to use the 305mm guns. The detailed design was supposed to be completed by 15 October 1941, but it was rendered pointless when the Germans invaded the Soviet Union in June.|$|E
2500|$|A full brain map {{has been}} {{estimated}} to occupy less than 2 x 1016 bytes (20,000 TB) and would store the addresses of the connected neurons, the synapse type and the synapse [...] "weight" [...] {{for each of the}} brains' 1015 synapses. [...] However, the biological complexities of true brain function (e.g. the epigenetic states of neurons, protein components with multiple functional states, etc.) may preclude an accurate prediction of the volume of binary <b>data</b> <b>required</b> to faithfully represent a functioning human mind.|$|E
2500|$|The {{computation}} method Saltmod {{is based}} on seasonal water balances of agricultural lands. Four seasons in one year can be distinguished, e.g. dry, wet, cold, hot, irrigation or fallow seasons. The number of seasons (Ns) can be chosen between a minimum of one and a maximum of four. The larger the number of seasons becomes, the larger {{is the number of}} input <b>data</b> <b>required.</b> The duration of each season (Ts) is given in number of months (0 < Ts < 12). Day to day water balances are not considered for several reasons: ...|$|E
50|$|Bromcom {{systems for}} {{accessing}} student's <b>data</b> <b>require</b> substantial interoperability {{directly with the}} schools Management Information Systems (MIS). Since the 1990s {{the most widely used}} MIS in the UK has been Capita's SIMS.|$|R
3000|$|... 1. While {{quantification}} of the MS data {{is completely}} straightforward and mathematically simple, quantification of the ASL <b>data</b> <b>requires</b> selection among {{quite a number}} of different modeling approaches [21 – 24, 36 – 38].|$|R
50|$|Collection {{of mobile}} web {{analytics}} <b>data</b> <b>requires</b> {{a different approach}} from collecting traditional web analytics data. A number of solutions are available and the best results are obtained {{through the use of}} more than one technology.|$|R
2500|$|In each simplex iteration, {{the only}} <b>data</b> <b>required</b> {{are the first}} row of the tableau, the (pivotal) column of the tableau {{corresponding}} to the entering variable and the right-hand-side. The latter can be updated using the pivotal column and the first row of the tableau can be updated using the (pivotal) row corresponding to the leaving variable. Both the pivotal column and pivotal row may be computed directly using the solutions of linear systems of equations involving the matrix B and a matrix-vector product using A. These observations motivate the [...] "revised simplex algorithm", for which implementations are distinguished by their invertible representation ofB.|$|E
2500|$|It {{approaches}} the experimental problem by asking; is additional <b>data</b> <b>required?</b> If so, how much {{needs to be}} collected and by what means and finally, how does the decision maker revise his prior judgment {{in light of the}} results of the new experimental evidence? In this example the advertising manager can use the Bayesian approach to deal with his dilemma and update his prior judgments in light of new information he gains. [...] He needs to take into account the profit (utility) attached to the alternative acts under different events and the value versus cost of information in order to make his optimal decision on how to proceed.|$|E
2500|$|There are two layouts to the PDF files: {{non-linear}} (not [...] "optimized") and linear ("optimized"). Non-linear PDF files consume less {{disk space}} than their linear counterparts, {{though they are}} slower to access because portions of the <b>data</b> <b>required</b> to assemble pages of the document are scattered throughout the PDF file. Linear PDF files (also called [...] "optimized" [...] or [...] "web optimized" [...] PDF files) are constructed {{in a manner that}} enables them to be read in a Web browser plugin without waiting for the entire file to download, since they are written to disk in a linear (as in page order) fashion. PDF files may be optimized using Adobe Acrobat software or QPDF.|$|E
50|$|A Geospatial Information Officer (GIO) is {{the head}} of {{geospatial}} information technology within a civilian, business, government and/or military organization. The high demand for efficient geospatial <b>data</b> <b>requires</b> dedicated leadership in data collection, production and analysis.|$|R
40|$|The 1 heoretical na 1 ure of risk {{premiums}} in roreign currency futures markets is derived and s 1 udied empirically. Eslimation problems encountered in using futures da 1 a are discussed. Since forward rates and fu 1 ures {{prices have been}} found to be approximately equal, and because {{risk premiums}} in forward markets are highly variable, consistency of the <b>data</b> <b>requires</b> time variation in daily risk premiums in the futures marke 1. Unbiasedness of daily futures prices as predictors of the following day’s futures price is rejected for all currencies. Reconciliation of daily and monthly <b>data</b> <b>requires</b> positive serial correlation in daily risk premiums. 1...|$|R
50|$|A client can be {{any system}} within the cell. Clients {{that are to be}} backed up require the {{installation}} of a Disk Agent. Clients that control the backup and restore <b>data</b> <b>require</b> the installation of a Media Agent.|$|R
