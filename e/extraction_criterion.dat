19|56|Public
30|$|The <b>extraction</b> <b>criterion</b> of {{the true}} BIMFs based on the {{correlation}} coefficient is a reliable technique which successfully identifies and estimates the spurious components. It reserves the main frequency bands which are of great import to the extraction of the actual vibration mode and corresponding features of the time-frequency domain.|$|E
40|$|Abstract: The paper {{deals with}} the {{extraction}} of features for statistical pattern recognition. In particular, the case of recognition with learning is considered. Bayes probability of correct classification is adopted as the <b>extraction</b> <b>criterion.</b> The problem with incomplete probabilistic information is discussed and Bayes-optimal feature extraction procedure is presented in detail. As method of solution of optimal feature extraction a genetic algorithm is proposed. A numerical example demonstrating quality of proposed algorithm to solve feature extraction problem is presented. ...|$|E
40|$|Abstract. In this paper, a novel approach, namely local {{variation}} projection (LVP), {{is presented}} for face recognition. LVP defines an adjacency graph {{to model the}} variation among nearby face images, which includes the within-class variation and between-class variation, also called margin. In order to better detect the discriminant structure, we assign a small weight to the variation among nearby face images from the same class. Based on this content, a concise feature <b>extraction</b> <b>criterion</b> is built for dimensionality reduction. Experiments indicate the effectiveness of our proposed approach...|$|E
40|$|The present study, {{utilizing}} {{a sample of}} inpatients with schizophrenia or schizoaffective disorder (n 167), examined {{the factor structure of}} the Repeatable Battery for the Assessment of Neuropsychological Status (RBANS). Principal axis exploratory factor analysis, multiple factor <b>extraction</b> <b>criteria,</b> and higher-order factor analysis were used. Results were inconsistent with the five-factor structure of the RBANS purported in the test manual. Factor <b>extraction</b> <b>criteria</b> recommended <b>extraction</b> of one or two factors. Extraction of two factors resulted in a memory dimension and a less homogeneous visual perception and processing speed dimension. Higher-order analysis found that a second-order factor, representing general neurocognitive functioning, accounted for over three times the total and common variance than the two first-order factors combined. It was concluded that although the RBANS appears to be a useful measure of general neurocognitive functioning for inpatients with schizophrenia or schizoaffective disorder, clinical interpretation beyond a general factor (i. e., Total Scale score) should be done with caution in this population. Limitations of the present study and directions for future research are discussed...|$|R
40|$|Objective To {{develop a}} {{semantic}} representation for clinical research eligibility criteria to automate semistructured information <b>extraction</b> from eligibility <b>criteria</b> text. Materials and Methods An analysis pipeline called eligibility <b>criteria</b> <b>extraction</b> and representation (EliXR) was developed that integrates syntactic parsing and tree pattern mining to discover common semantic patterns in 1000 eligibility criteria randomly selected fro...|$|R
40|$|In this study, {{based on}} DCCM (Differential Capability Control Machine), the new feature-extraction {{criterion}} NFEC is developed using the first-order differential {{information and a}} new feature-extraction algorithm DCCFE is accordingly proposed for binary classification problems. NFEC and DCCFE are then extended to their multi-classification versions, i. e., m_NFEC and m_DCCFE, respectively. Present experimental results demonstrate that the new feature <b>extraction</b> <b>criteria</b> and algorithms outperform or have comparable performance with the current methods for cancer gene expression datasets. Furthermore, since the new algorithms here admit more general first-order differential functions as the basis functions instead of kernel functions in SVM-based method, they perhaps have more potential applications in bioinformatics in the future...|$|R
40|$|Blind {{extraction}} of quaternion-valued latent sources is addressed {{based on their}} local temporal properties. The <b>extraction</b> <b>criterion</b> {{is based on the}} minimum mean square widely linear prediction error, thus allowing for the {{extraction of}} both proper and improper quaternion sources. The use of the widely linear adaptive predictor is justified by the relationship between the mean square prediction error and the crosscorrelation and cross-pseudocorrelations of the source signals. Simulations on benchmark improper quaternion sources together with a real-world example of EEG artifact removal illustrate the usefulness of the proposed methodology. © 2011 IEEE...|$|E
40|$|A {{new feature}} <b>extraction</b> <b>{{criterion}},</b> maximum margin criterion (MMC), is proposed in this paper. This new criterion is {{general in the}} sense that, when combined with a suitable constraint, it can actually give rise to the most popular feature extractor in the literature, linear discriminate analysis (LDA). We derive a new feature extractor based on MMC using a different constraint that {{does not depend on}} the nonsingularity of the within-class scatter matrix Sw. Such a dependence is a major drawback of LDA especially when the sample size is small. The kernelized (nonlinear) counterpart of this linear feature extractor is also established in this paper. Our preliminary experimental results on face images demonstrate that the new feature extractors are efficient and stable. ...|$|E
40|$|In pattern recognition, feature {{extraction}} techniques {{have been widely}} employed to reduce the dimensionality of high-dimensional data. In this paper, we propose a novel {{feature extraction}} algorithm called membership-degree preserving discriminant analysis (MPDA) based on the fisher criterion and fuzzy set theory for face recognition. In the proposed algorithm, the membership degree of each sample to particular classes is firstly calculated by the fuzzy k-nearest neighbor (FKNN) algorithm to characterize the similarity between each sample and class centers, and then the membership degree is incorporated into {{the definition of the}} between-class scatter and the within-class scatter. The feature <b>extraction</b> <b>criterion</b> via maximizing the ratio of the between-class scatter to the within-class scatter is applied. Experimental results on the ORL, Yale, and FERET face databases demonstrate the effectiveness of the proposed algorithm...|$|E
40|$|This paper {{presents}} a text/graphic labelling for ancient printed documents. Our approach {{is based on}} the extraction and the quantification of the various orientations that are present in ancient printed document images. The documents are initially cut into normalized square windows in which we analyze significant orientations with a directional rose. Each kind of information (textual or graphical) is typically identified and marked by its orientation distribution. This choice of characterization allows us to separate textual regions from graphics by minimizing the a priori knowledge. The evaluation of our proposition lies on a page classification using layout <b>extraction</b> <b>criteria.</b> The system has been tested over several ancient printed books of the Renaissance...|$|R
40|$|Abstract. Ensemble methods improve {{accuracy}} {{by combining}} the predictions {{of a set of}} different hypotheses. However, there is an important shortcoming associated with ensemble methods. Huge amounts of memory are required to store a set of multiple hypotheses. In this work we devise an ensemble method that partially solves this drawbacks. The key point is that components share their common parts. For this goal, we employ a multi-tree, a structure that can simultaneously contain an ensemble of decision trees, but with the advantage that decision trees share some conditions. To construct this multi-tree we define an algorithm based on a beam search with several <b>extraction</b> <b>criteria</b> and with several forgetting policies for the suspended nodes. Finally, we compare the behaviour of this ensemble method with some well-known methods for generating hypothesis ensembles...|$|R
40|$|The {{present study}} {{examined}} {{the factor structure of}} the Wechsler Adult Intelligence Scale—Fourth Edition (WAIS–IV; D. Wechsler, 2008 a) standardization sample using exploratory factor analysis, multiple factor <b>extraction</b> <b>criteria,</b> and higher order exploratory factor analysis (J. Schmid & J. M. Leiman, 1957) not included in the WAIS–IV Technical and Interpretation Manual (D. Wechsler, 2008 b). Results indicated that the WAIS–IV subtests were properly associated with the theoretically proposed first-order factors, but all but one factor-extraction <b>criterion</b> recommended <b>extraction</b> of one or two factors. Hierarchical exploratory analyses with the Schmid and Leiman procedure found that the second-order g factor accounted for large portions of total and common variance, whereas the four first-order factors accounted for small portions of total and common variance. It was concluded that the WAIS–IV provides strong measurement of general intelligence, and clinical interpretation should be primarily at that level...|$|R
30|$|The {{advantages}} of BEMD and LSSVM are combined {{in this paper}} for detecting and identifying grinding chatter. Section two gives {{a brief review of}} BEMD and LSSVM, as well as the <b>extraction</b> <b>criterion</b> of true BIMFs. Moreover, the peak to peak, real-time standard deviation and instantaneous energy are presented as feature vectors for the grinding chatter. In section three, a simulation chatter signal is constructed and then processed by BEMD. Afterwards, peak to peak, real-time standard deviation and instantaneous energy are extracted from BIMFs. In section four, the benefits of the proposed method are further validated experimentally by processing grinding signals which are derived from the grinder KD 4020 X 16, and then a LSSVM model is established to predict the grinding state. Finally, conclusions are presented in section five, which also gives new directions for future work.|$|E
40|$|Transfer of a glycosylphosphatidylinositol (GPI) anchor to {{proteins}} {{carrying a}} C-terminal GPI-directing signal sequence occurs after protein translocation across the endoplasmic reticulum (ER). We describe the translocation and GPI modification {{of a model}} protein, preprominiPLAP, in ER microsomes depleted of lumenal content by high pH washing. In untreated microsomes preprominiPLAP was processed to prominiPLAP and GPI-anchored miniPLAP. Both products were fully translocated, since they resisted proteinase K treatment of the microsomes, and both behaved as membrane proteins by the carbonate <b>extraction</b> <b>criterion.</b> Microsomes depleted of lumenal content were able to translocate and process preprominiPLAP to give protease-protected prominiPLAP, but were unable to convert prominiPLAP to miniPLAP. Loss of GPI anchoring capacity occurred with a wash of pH > 9. 5. If the alkaline wash was performed after formation of prominiPLAP conversion to miniPLAP was relatively unimpaired. The results indicate that constituents of the ER lumen, possibly chaperones interacting with the proprotein and/or the GPI anchor precursor, are required in the initial steps of GPI anchoring...|$|E
40|$|Abstract—A {{class of}} second-order complex domain blind source {{extraction}} algorithms is introduced to cater for signals with noncircular probability distributions, {{which is a}} typical case in real-world scenarios. This is achieved by employing the so-called augmented complex statistics {{and based on the}} temporal structures of the sources, thus permitting widely linear (WL) predictability to be the <b>extraction</b> <b>criterion.</b> For rigor, the analysis of the existence and uniqueness of the solution is provided based on both the covariance and the pseudocovariance and for both noise-free and noisy cases, and serves as a platform for the deriva-tion of the algorithms. Both direct solutions and those requiring prewhitening are provided based on a WL predictor, thus making the methodology suitable for the generality of complex signals (both circular and noncircular). Simulations on synthetic non-circular sources support the uniqueness and convergence study, followed by a real-world example of electrooculogram artifact removal from electroencephalogram recordings in real time. Index Terms—Augmented complex least mean square (ACLMS), blind source extraction (BSE), complex noncircularity, complex pseudocovariance, electroencephalogram (EEG) artifact removal, noisy mixtures, widely linear (WL) model. I...|$|E
40|$|We {{present an}} {{information}} theoretic approach to multi-modal signal processing, and validate the framework with illustrative examples from {{medical image processing}} and multi-media signal processing. The approach tries to adaptively identify that pair of feature space representations {{of a pair of}} multi-modal signals which carries maximal redundancy. Analogously, we can say that the framework extracts simultaneously the features of both signals of a multi-modal signal pair where the <b>extraction</b> <b>criteria</b> is maximum redundancy between the resulting feature space representations. The framework is based on stochastic processes, Markov chains, and error probabilities. Extracting such feature pairs of multi-modal signals has a wide range of potential applications, some of which will be used to illustrate the framework with practical results. In particular, we will show how our approach can efficiently be used for multi-modal medical image processing and for joint analysis of multi-media sequences (audio and video) ...|$|R
40|$|Many {{inferential}} statistical tests {{require that}} the observed variables have a normal distribution. Monte Carlo simulations are used to investigate the effect of violating this assumption and require an algorithm that generates samples from non-normal distributions, thereby controlling correlations among random variables, the marginal distributions, and the multivariate distribution. Most previously used algorithms only allow control over the correlations and the marginals, but recent {{results show that the}} robustness of certain methods depends on the multivariate distribution as well. In my thesis, I suggest a new method to generate samples from non-normal distributions that allows manipulations of all three parameters simultaneously. The algorithm jointly controls the correlation matrix, central moments of the marginals, and the multivariate distribution. Additionally, I also show that the multivariate distribution has a distinct impact on the robustness of a structural equation model, whereas <b>extraction</b> <b>criteria</b> for exploratory factor analysis are unaffected by the underlying distribution...|$|R
40|$|Use of a {{three-dimensional}} geoscientific modelling system in offshore sand resources analysis is described. The benefits of {{a three-dimensional}} approach to geological modelling are that geologists can concentrate on geological interpretation without the constraints embodied in a two-dimensional approach and geological models can be used directly for aggregate volume assessment, in terms of global and local estimates 1 with no need to construct isopachytes. An algorithm has been developed which, {{on the basis of}} the geological model and variable <b>extraction</b> <b>criteria.</b> yields parameters required for detailed extraction design: depth of dredging, volume of aggregate and ratio of aggregate to waste in the total extracted volume. In addition, the algorithm also accepts as input a three-dimen­ sional geostatistfoal model of aggregate resource. Data from an offshore site investigated in relation to land reclamation for the Chek Lap Kok Airport, Hong Kong, are modelled, and results are presented for demonstration...|$|R
40|$|Analysis of {{networks}} {{and in particular}} discovering communities within networks has been a focus of recent work in several fields and has diverse applications. Most community detection methods focus on partitioning the entire network into communities, with the expectation of many ties within communities and few ties between. However, many networks contain nodes that do not fit in {{with any of the}} communities, and forcing every node into a community can distort results. Here we propose a new framework that extracts one community at a time, allowing for arbitrary structure in the remainder of the network, which can include weakly connected nodes. The main idea is that the strength of a community should depend on ties between its members and ties to the outside world, but not on ties between nonmembers. The proposed <b>extraction</b> <b>criterion</b> has a natural probabilistic interpretation in a wide class of models and performs well on simulated and real networks. For the case of the block model, we establish asymptotic consistency of estimated node labels and propose a hypothesis test for determining the number of communities...|$|E
40|$|Analysis of {{networks}} {{and in particular}} discovering communities within networks has been a focus of recent work in several fields, with applications ranging from citation and friendship networks to food webs and gene regulatory networks. Most of the existing community detection methods focus on partitioning the entire network into communities, with the expectation of many ties within communities and few ties between. However, many networks contain nodes that do not fit in {{with any of the}} communities, and forcing every node into a community can distort results. Here we propose a new framework that focuses on community extraction instead of partition, extracting one community at a time. The main idea behind extraction is that the strength of a community should not depend on ties between members of other communities, but only on ties within that community and its ties to the outside world. We show that the new <b>extraction</b> <b>criterion</b> performs well on simulated and real networks, and establish asymptotic consistency of our method under the block model assumption...|$|E
40|$|Copyright © 2013 Zhangjing Yang et al. This is an {{open access}} article {{distributed}} under the Creative CommonsAttribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. In pattern recognition, feature extraction techniques have been widely employed to reduce the dimensionality of high-dimensional data. In this paper, we propose a novel feature extraction algorithm called membership-degree preserving discriminant analysis (MPDA) based on the fisher criterion and fuzzy set theory for face recognition. In the proposed algorithm, the membership degree of each sample to particular classes is firstly calculated by the fuzzy k-nearest neighbor (FKNN) algorithm to characterize the similarity between each sample and class centers, and then the membership degree is incorporated into {{the definition of the}} between-class scatter and the within-class scatter. The feature <b>extraction</b> <b>criterion</b> via maximizing the ratio of the between-class scatter to the within-class scatter is applied. Experimental results on the ORL, Yale, and FERET face databases demonstrate the effectiveness of the proposed algorithm. 1...|$|E
40|$|Abstract. Based on {{the study}} of the {{specificity}} of historical printed books and on the main error sources of classical methods of page layout analysis, this paper presents a new way to achieve an indexation of ancient printed documents. We have developed an approach based on the extraction and the quantification of the various orientations that are present in printed document images. The documents are initially splitted into homogenous areas in which we analyze significant orientations with a directional rose. Each kind of information (textual or graphical) is typically identified and labelled according to its orientation distribution. This choice of characterization allows us to separate textual regions from graphical ones by minimizing the a priori knowledge. The evaluation of our proposition lies on a document image retrieval using layout <b>extraction</b> <b>criteria</b> and {{can also be used to}} precisely localize graphical parts in various types of documents. The system has been tested with success over several ancient printed books of the Renaissance. ...|$|R
40|$|Feature-based flow {{visualization}} {{is naturally}} dependent on feature extraction. To extract flow features, often higher-order {{properties of the}} flow data are used such as the Jacobian or curvature properties, implicitly describing the flow features {{in terms of their}} inherent flow characteristics (e. g., collinear flow and vorticity vectors). In this paper we present recent research which leads to the (not really surprising) conclusion that feature extraction algorithms need to be extended to a time-dependent analysis framework (in terms of time derivatives) when dealing with unsteady flow data. Accordingly, we present two extensions of the parallel vectors based vortex <b>extraction</b> <b>criteria</b> to the time-dependent domain and show the improvements of feature-based flow visualization in comparison to the steady versions of this extraction algorithm both {{in the context of a}} high-resolution dataset, i. e., a simulation specifically designed to evaluate our new approach, as well as for a real-world dataset from a concrete application...|$|R
40|$|A {{classical}} {{application of}} biosignal analysis {{has been the}} psychophysiological detection of deception, {{also known as the}} polygraph test, which is currently a part of standard practices of law enforcement agencies and several other institutions worldwide. Although its validity is far from gathering consensus, the underlying psychophysiological principles are still an interesting add-on for more informal applications. In this paper we present an experimental off-the-person hardware setup, propose a set of feature <b>extraction</b> <b>criteria</b> and provide a comparison of two classification approaches, targeting the detection of deception {{in the context of a}} role-playing interactive multimedia environment. Our work is primarily targeted at recreational use in the context of a science exhibition, where the main goal is to present basic concepts related with knowledge discovery, biosignal analysis and psychophysiology in an educational way, using techniques that are simple enough to be understood by children of different ages. Nonetheless, this setting will also allow us to build a significant data corpus, annotated with ground-truth information, and collected with non-intrusive sensors, enabling more advanced research on the topic. Experimental results have shown interesting findings and provided useful guidelines for future work. Pattern Recognitio...|$|R
30|$|Grinding chatter is a {{self-induced}} vibration which is unfavorable to precision machining processes. This paper proposes a forecasting method for grinding state identification based on bivarition empirical mode decomposition (BEMD) and least squares {{support vector machine}} (LSSVM), which allows the monitoring of grinding chatter over time. BEMD is a promising technique in signal processing research which involves the decomposition of two-dimensional signals {{into a series of}} bivarition intrinsic mode functions (BIMFs). BEMD and the <b>extraction</b> <b>criterion</b> of its true BIMFs are investigated by processing a complex-value simulation chatter signal. Then the feature vectors which are employed as an amplification for the chatter premonition are discussed. Furthermore, the methodology is tested and validated by experimental data collected from a CNC guideway grinder KD 4020 X 16 in Hangzhou Hangji Machine Tool Co., Ltd. The results illustrate that the BEMD is a superior method in terms of processing non-stationary and nonlinear signals. Meanwhile, the peak to peak, real-time standard deviation and instantaneous energy are proven to be effective feature vectors which reflect the different grinding states. Finally, a LSSVM model is established for grinding status classification based on feature vectors, giving a prediction accuracy rate of 96 %.|$|E
40|$|Grinding chatter {{reduces the}} {{long-term}} reliability of grinding machines. Detecting {{the negative effects}} of chatter requires improved chatter detection techniques. The vibration signals collected from grinders are mainly nonstationary, nonlinear and multidimensional. Hence, bivariate empirical mode decomposition (BEMD) has been investigated as a multiple signal processing method. In this paper, a feature vector extraction method based on BEMD and Hilbert transform was applied to the problem of grinding chatter. The effectiveness of this method was tested and validated with a simulated chatter signal produced by a vibration signal generator. The <b>extraction</b> <b>criterion</b> of true intrinsic mode functions (IMFs) was also investigated, as well as a method for selecting the most ideal number of projection directions using the BEMD algorithm. Moreover, real-time variance and instantaneous energy were employed as chatter feature vectors for improving the prediction of chatter. Furthermore, the combination of BEMD and Hilbert transform was validated by experimental data collected from a computer numerical control (CNC) guideway grinder. The results reveal the good behavior of BEMD in terms of processing nonstationary and nonlinear signals, and indicating the synchronous characteristics of multiple signals. Extracted chatter feature vectors were demonstrated to be reliable predictors of early grinding chatter...|$|E
40|$|In this paper, a wavelet-based {{multiscale}} linear minimum mean square-error estimation (LMMSE) {{scheme for}} image denoising is proposed, and {{the determination of}} the optimal wavelet basis with respect to the proposed scheme is also discussed. The overcomplete wavelet expansion (OWE), which is more effective than the orthogonal wavelet transform (OWT) in noise reduction, is used. To explore the strong interscale dependencies of OWE, we combine the pixels at the same spatial location across scales as a vector and apply LMMSE to the vector. Compared with the LMMSE within each scale, the interscale model exploits the dependency information distributed at adjacent scales. The performance of the proposed scheme is dependent on the selection of the wavelet bases. Two criteria, the signal information <b>extraction</b> <b>criterion</b> and the distribution error criterion, are proposed to measure the denoising performance. The optimal wavelet that achieves the best tradeoff between the two criteria can be determined from a library of wavelet bases. To estimate the wavelet coefficient statistics precisely and adaptively, we classify the wavelet coefficients into different clusters by context modeling, which exploits the wavelet intrascale dependency and yields a local discrimination of images. Experiments show that the proposed scheme outperforms some existing denoising methods. Department of Computin...|$|E
40|$|The Repeatable Battery for the Assessment of Neuropsychological Status (RBANS: Randolph, 1998, 2012) {{is a brief}} neurocognitive {{instrument}} used to evaluate cognitive functioning in clinical settings. While this test is used regularly, investigation of the factor structure has resulted in inconsistent findings across samples. It was hypothesized that inconsistent RBANS dimensional structures {{are the result of}} methodological differences and not solely due to unique sample characteristics. The present study utilized empirically supported <b>extraction</b> <b>criteria</b> (Parallel Analysis; Minimum Average Partial Procedure) and uniformly investigated five samples. RBANS data from four samples were previously published (Carlozzi, Horner, Yang, 2 ̆ 6 Tilley, 2008; Duff, Hobson, Beglinger, O 2 ̆ 7 Bryant, 2010; Duff et al., 2006; Wilde, 2006) and a new clinical sample was obtained from the Gundersen Health System, Memory Center. The congruence of factor structures was investigated by conducting orthogonal vector matrix comparisons (Barrett, 2005), and a robust two factor structure reliably emerged across samples. The invariant RBANS two factor structure primarily emphasized memory and visuospatial functioning. This finding definitively clarifies the RBANS factor structure and the relationships between subtests and indices. Due to the expansive use of the RBANS, this psychometric knowledge has significant clinical implications...|$|R
40|$|The {{solution}} {{described in}} this paper is a web tool to access and manage patients’ data in Ophthalmology. Clinical data are collected in a database through a system {{that can be easily}} utilized by physicians and internal information can be extracted for statistical purposes. The platform is also available for simultaneous Multicenter Clinical Trials. A specific algorithm and extraction tool were developed to allow physicians to extract data for research purposes. Users can simply add and manage patients, records, follow-up visits, treatments, diagnosis, clinical history; all the information can be modified and reused whenever required. Physicians can also enter specific <b>extraction</b> <b>criteria,</b> in order to exploit the full potential of the available information. Once the extraction of data is completed, it is possible to view and save data in an Excel format. The Ophthalmology Clinic of the San Martino Hospital in Genoa has been working with this web tool since April 2013. By the end of November 2013, 568 patients and 2668 visits had been registered. The web-platform allows effective management, sharing and reuse of information within primary care and clinical research. In the near future, there is a plan to share the system with other Italian centers...|$|R
40|$|International audienceA {{methodology}} {{to detect}} sleep apnea/hypopnea {{events in the}} respiratory signals of polysomnographic recordings is presented. It applies advanced signal processing tools, such as empirical mode decomposition (EMD), Hilbert- Huang transform (HHT), fuzzy logic, feature <b>extraction,</b> expert <b>criteria</b> and context analysis. EMD, HHT and fuzzy logic are used for preliminary detection of respiration signal zones with significant variations in the amplitude of the signal; feature <b>extraction,</b> expert <b>criteria</b> and context analysis are used to characterize and validate the respiratory events. The system parameters were adjusted using the training set and fine-tuned applying the validation set; the testing data set {{was used to measure}} the final performance of the system. An annotated database of 30 all-night polysomnographic recordings, acquired from 30 healthy ten-year-old children at the Sleep Laboratory of the INTA-Universidad de Chile, was divided in a training set of 15 recordings (485 sleep apnea/hypopnea events), a validation set of five recordings (109 sleep apnea/hypopnea events), and a testing set of ten recordings (281 sleep apnea/hypopnea events). The overall detection performance on the testing data set of continuous all-night recordings was 89. 7 % sensitivity and 16. 3 % false-positive rate. The next step is to include discrimination among apneas, hypopneas and respiratory pauses...|$|R
40|$|CONTEXT AND OBJECTIVES 					The Beliefs about Medicines Questionnaire (BMQ-Specific) {{has proven}} useful for {{measuring}} patients' beliefs and associating them with non-adherence to treatment in several illness groups. The {{aim was to}} cross-culturally adapt the BMQ-Specific into Portuguese for {{the general population of}} medicine users. 				 				 					DESIGN AND SETTING 					Cross-sectional study conducted among users of public hospitals and outpatient clinics in Guarda and Covilh&# 227;, Portugal. 				 				 					METHODS 					The BMQ-Specific was translated using international recommendations for performing cross-cultural adaptation and was administered to 300 patients. An initial principal component analysis (PCA) was conducted with the <b>extraction</b> <b>criterion</b> of eigenvalue > 1. 0, followed by a second PCA with restriction to two components. Reliability was assessed by calculating Cronbach's alpha coefficient. 				 				 					RESULTS 					The mean scores obtained for the Necessity and Concerns subscales of the Portuguese BMQ-Specific were 19. 9 (standard deviation, SD = 2. 8) (range 10 to 25) and 17. 7 (SD = 3. 9) (range 6 to 30), respectively. The first PCA produced an unstable three-component structure for the Portuguese BMQ-Specific. The final PCA solution yielded a two-component structure identical to the original English version (a five-item Necessity and a six-item Concerns subscale), and explained 44 % of the variance. Cronbach's alpha for the complete Portuguese BMQ-Specific was 0. 70, and 0. 76 and 0. 67 for the Necessity and Concerns subscales, respectively. 				 				 					CONCLUSION 					A cross-culturally adapted Portuguese version of the BMQ-Specific questionnaire for use among the general population of medicine users was obtained, presenting good internal consistency and component structure identical to the original English version...|$|E
40|$|CONTEXT AND OBJECTIVES The Beliefs about Medicines Questionnaire (BMQ-Specific) {{has proven}} useful for {{measuring}} patients' beliefs and associating them with non-adherence to treatment in several illness groups. The {{aim was to}} cross-culturally adapt the BMQ-Specific into Portuguese for {{the general population of}} medicine users. DESIGN AND SETTING Cross-sectional study conducted among users of public hospitals and outpatient clinics in Guarda and Covilhã, Portugal. METHODS The BMQ-Specific was translated using international recommendations for performing cross-cultural adaptation and was administered to 300 patients. An initial principal component analysis (PCA) was conducted with the <b>extraction</b> <b>criterion</b> of eigenvalue > 1. 0, followed by a second PCA with restriction to two components. Reliability was assessed by calculating Cronbach's alpha coefficient. RESULTS The mean scores obtained for the Necessity and Concerns subscales of the Portuguese BMQ-Specific were 19. 9 (standard deviation, SD = 2. 8) (range 10 to 25) and 17. 7 (SD = 3. 9) (range 6 to 30), respectively. The first PCA produced an unstable three-component structure for the Portuguese BMQ-Specific. The final PCA solution yielded a two-component structure identical to the original English version (a five-item Necessity and a six-item Concerns subscale), and explained 44 % of the variance. Cronbach's alpha for the complete Portuguese BMQ-Specific was 0. 70, and 0. 76 and 0. 67 for the Necessity and Concerns subscales, respectively. CONCLUSION A cross-culturally adapted Portuguese version of the BMQ-Specific questionnaire for use among the general population of medicine users was obtained, presenting good internal consistency and component structure identical to the original English version...|$|E
40|$|Public {{hospitals}} and outpatient clinics in Guarda and Covilhã, Portugal CONTEXT AND OBJECTIVES: The Beliefs about Medicines Questionnaire (BMQ-Specific) has proven use-ful for measuring patients ’ beliefs and associating them with non-adherence to treatment in several illness groups. The {{aim was to}} cross-culturally adapt the BMQ-Specific into Portuguese for {{the general population of}} medicine users. DESIGN AND SETTING: Cross-sectional study conducted among users of public {{hospitals and}} outpatient clinics in Guarda and Covilhã, Portugal. METHODS: The BMQ-Specific was translated using international recommendations for performing cross-cultural adaptation and was administered to 300 patients. An initial principal component analysis (PCA) was conducted with the <b>extraction</b> <b>criterion</b> of eigenvalue> 1. 0, followed by a second PCA with restriction to two components. Reliability was assessed by calculating Cronbach’s alpha coefficient. RESULTS: The mean scores obtained for the Necessity and Concerns subscales of the Portuguese BMQ-Specific were 19. 9 (standard deviation, SD = 2. 8) (range 10 to 25) and 17. 7 (SD = 3. 9) (range 6 to 30), respec-tively. The first PCA produced an unstable three-component structure for the Portuguese BMQ-Specific. The final PCA solution yielded a two-component structure identical to the original English version (a five-item Necessity and a six-item Concerns subscale), and explained 44 % of the variance. Cronbach’s alpha for the complete Portuguese BMQ-Specific was 0. 70, and 0. 76 and 0. 67 for the Necessity and Concerns subscales, respectively. CONCLUSION: A cross-culturally adapted Portuguese version of the BMQ-Specific questionnaire for use among the general population of medicine users was obtained, presenting good internal consistency and component structure identical to the original English version. RESUMO CONTEXTO E OBJETIVO: O Beliefs about Medicines Questionnaire (BMQ-Específico) tem se mostrado úti...|$|E
30|$|After {{initial data}} <b>extraction,</b> the {{exclusion}} <b>criteria</b> were reassessed. It {{became clear that}} most studies had different inclusion criteria and outcome measures, thus prohibiting a proper meta-analysis and comparison between the different studies. Only the union rate and number of complications were compared between the different treatments.|$|R
30|$|We also chose a {{systematic}} {{approach to the}} data <b>extraction</b> using predefined <b>criteria</b> to minimise bias in reporting of the qualities of each identified indicator set. Content analysis methodology has been criticised for being too reductive and consequently we may have missed identifying important indicator qualities (Dixon-Woods et al. 2005).|$|R
40|$|Vacuum {{extraction}} {{dates back}} to the 18 th Century [1], MALMSTRÖM first introduced a fully practicable vacuum extractor äs an operative method of delivery about 20 years ago [2], Vacuum extraction has since found increasing application and is considered in many countries to be äs useful äs forceps. Numerous articles have been published concerning tech-nique and clinical application of vacuum extraction. To date, however, there has been no direct research, äs far äs wc know, about the extent of the effective tractive forces and the length of application during the extraction. Be-cause of this lack criteria based upon subjective judgments were used to characterize a vacuum <b>extraction.</b> Such <b>criteria</b> are insufficient for objective analysis of tractiv...|$|R
