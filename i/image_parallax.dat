4|59|Public
50|$|Even after gain {{compensation}} some image {{edges are}} still visible {{due to a}} number of unmodelledeffects, such as vignetting (intensity decreases towards the edge of the <b>image),</b> <b>parallax</b> effects due to unwanted motion of the optical centre, mis-registration errors due to mismodellingof the camera, radial distortion and so on. Due to these reasons they propose a blending strategy called multi band blending.|$|E
30|$|The {{determination}} of an <b>image</b> <b>parallax</b> range is obtained through an associated depth map. There {{are several ways}} to obtain a depth map from a stereo image, depending on the computation complexity and accuracy restrictions. As a rule of thumb, it can be stated that complexity is proportional to accuracy, thus, low complexity algorithms such as sum of absolute differences (SAD) can perform well under certain circumstances, as stated in [25, 26]. Scharstein and Szeliski [27] described the procedures to define the Middlebury Database [28], which offers the most complete stereoscopic algorithms benchmark to date, and software to evaluate new algorithms to predict <b>image</b> <b>parallax.</b> SAD-based algorithms are among the least complex and more often used. Census-based algorithms [29 – 32], first introduced in [33], are common in real-time hardware-based systems [34 – 38] and may work better in the homogeneous zones of the image. Its complexity increases when used in software-based systems because of its bit-based nature. Some systems mix both algorithms in order to obtain the best results from each one of them, such as [39], ranked in second place in the Scharstein and Szeliski list, or [40] based on dense stereo matching.|$|E
30|$|Overlapping {{sections}} of the aerial photographs were carefully trimmed out in order to minimise <b>image</b> <b>parallax,</b> using image subsetting procedures within ERDAS. In order to optimise {{the contrast between the}} light and dark tones, contrast on each trimmed image was enhanced by spreading the digital number (DN) values on the full grey level scale range using a linear stretch. After separately mapping the woody cover on the respective aerial photographs from a given analysis year and study site, using image classification, the photographs were joined into thematic layer mosaics. All the images were carefully examined for presence of burn scars whose dark tone could have introduced error in mapping woody cover. Consequently the 1940 photographs of the Nhlowa site were excluded from the analysis due to extensive burn scars.|$|E
50|$|Founded by Peter Kang and Gene Na in 1999, one of Kioken’s early {{websites}} {{was for the}} R & B singer Brandy, and {{a string}} of entertainment clients followed, most notably including Jennifer Lopez, Motown, and Bad Boy Records. Criticized by some for a lack of usability, contrary to popular opinion, Kioken was resolute in its belief that audiences raised in the video game era were practiced in deciphering interfaces — in fact, they took pleasure in the experience. Taking their cue from TV and video games, Kioken’s websites had a depth and emotional quality absent from their counterparts. Full-bleed <b>images,</b> <b>parallax</b> movement, and floating palettes were used with great effect, all coming together beautifully on Barneys.com. According to Na, it's simple: “You have to think beyond the limits of a page.” Built in Flash 4.|$|R
50|$|The {{apparent}} stereo effect {{results from}} syncing {{the timing of}} the wiggle and the amount of parallax to the processing done by the visual cortex. Three or five <b>images</b> with good <b>parallax</b> may produce a better effect than simple left and right images.|$|R
5000|$|Shadow Stereopsis : A. Medina Puerta {{demonstrated}} that retinal <b>images</b> with no <b>parallax</b> disparity but with different shadows are fused stereoscopically, imparting depth perception to the imaged scene. He named the phenomenon [...] "shadow stereopsis". Shadows are therefore an important, stereoscopic cue for depth perception.|$|R
40|$|Crack {{detection}} for bridge {{bottom surfaces}} via remote sensing techniques {{is undergoing a}} revolution in the last few years. For such applications, a large amount of images, acquired with high-resolution industrial cameras close to the bottom surfaces with some mobile platform, are required to be stitched into a wide-view single composite image. The conventional idea of stitching a panorama with the affine model or the homographic model always suffers a series of serious problems due to poor texture and out-of-focus blurring introduced by depth of field. In this paper, we present a novel method to seamlessly stitch these images aided by 3 D structure lines of bridge bottom surfaces, which are extracted from 3 D camera data. First, we propose to initially align each image in geometry based on its rough position and orientation acquired with both a laser range finder (LRF) and a high-precision incremental encoder, and these images are divided into several groups with the rough position and orientation data. Secondly, the 3 D structure lines of bridge bottom surfaces are extracted from the 3 D cloud points acquired with 3 D cameras, which impose additional strong constraints on geometrical alignment of structure lines in adjacent images to perform a position and orientation optimization in each group to increase the local consistency. Thirdly, a homographic refinement between groups is applied to increase the global consistency. Finally, we apply a multi-band blending algorithm to generate a large-view single composite image as seamlessly as possible, which greatly eliminates both the luminance differences and the color deviations between images and further conceals <b>image</b> <b>parallax.</b> Experimental results on a set of representative images acquired from real bridge bottom surfaces illustrate the superiority of our proposed approaches...|$|E
5000|$|In October 2010, Toshiba {{unveiled}} the Toshiba Regza GL1 21" [...] LED backlit LCD TV glasses-free 3D prototype at CEATEC 2010. This system supports 3D capability without glasses (utilising an integral imaging system of 9 <b>parallax</b> <b>images</b> with vertical lenticular sheet). The retail product {{was released in}} December 2010.|$|R
40|$|We {{present an}} {{electro-optical}} apparatus capable of displaying a computer generated hologram (CGH) in real time. The CGH is calculated by a supercomputer, read from a fast frame buffer, and transmitted to a high-bandwidth acousto-optic modulator (AOM). Coherent light is modulated by the AOM and optically processed {{to produce a}} three-dimensional <b>image</b> with horizontal <b>parallax.</b> 1...|$|R
40|$|Stereoscopic {{scenes of}} the mankind is {{naturally}} caused by synthesizing two images produced by the parallax of the two eyes of human. Such being the case, mankind can distinguish the relative position of the objects. In the study of related stereovision, some persons aim at the framework of taking simulated images with two eyes using one or two cameras from front and back or simultaneously {{at the same time}} to obtain a pair of parallax mages; someone pay more attention to the theoretical analysis of the relative positions of the <b>parallax</b> <b>images,</b> and some others do the work of using <b>parallax</b> <b>images</b> as material to carry out the job of image classification, comparison and analysis. The purpose of this paper is to estimate the distance between the objects and the camera in an outdoor environment using commercial digital camera. Key words: computer vision, machine vision, stereoscopic, object depth, binocular disparity, depth perception. 1...|$|R
40|$|This paper {{describes}} {{the evolution of}} classic stereo-radargrammetric techniques to the bistatic spaceborne geometry. When a monostatic image and a bistatic one are adopted to form the stereoscopic pair, new relations are needed to define parallax {{as a function of}} the peculiar parameters of bistatic surveying geometry. Two models are analyzed to extract parallax difference from radar data: parallax difference estimation from SAR <b>images</b> and <b>parallax</b> difference calculation by exploiting slant-range equations. An error budget of elevation measurement accuracy has been performed, showing that bistatic radargrammetric techniques applied to a spaceborne scenario mission can achieve an error in height measurement adequate for several applications and lower than the one obtained by previous monostatic experiments...|$|R
40|$|An {{integral}} {{imaging system}} is employed {{as part of}} a three dimensional imaging system, allowing display of full colour <b>images</b> with continuous <b>parallax</b> within a wide viewing zone. A novel approach to the problem of compressing the significant quantity of data required to represent integral 3 D video is presented and it is shown that the reduction in bit cost achieved makes possible transmission via conventional broadcast channels...|$|R
50|$|Since {{the advent}} of the Internet, a variant {{technique}} has developed where the images are specially processed to minimize visible mis-registration of the two layers. This technique is known by various names, the most common, associated with diopter glasses, and warmer skin tones, is Anachrome. The technique allows most images to be used as large thumbnails, while the 3D information is encoded into the <b>image</b> with less <b>parallax</b> than conventional anaglyphs.|$|R
40|$|The visual {{function}} of lens accommodation was measured while subjects used stereoscopic vision {{with a head}} mounted display (HMD). Eyesight while viewing stereoscopic Landolt ring images displayed on HMD was also studied. Accommodation to virtual objects was seen when subjects viewed stereoscopic images of 3 D computer graphics, but not when the images were displayed without appropriate binocular parallax. This suggests that stereoscopic moving images on HMD induced visual accommodation. Accommodation should be adjusted {{to the position of}} virtual stereoscopic <b>images</b> induced by <b>parallax.</b> A difference in the distances of the focused display and stereoscopic image may cause visual load. However, an experiment showed that Landolt rings of almost the same size were distinguished regardless of virtual distance of 3 D <b>images</b> if the <b>parallax</b> was not larger than the fusional upper limit. The {{results of this study suggest}} that stereoscopic moving images on HMD induced visual accommodation by expansion and contraction of the ciliary muscle, which was synchronized with convergence. Appropriate parallax of stereoscopic vision should not reduce the visibility of stereoscopic virtual objects...|$|R
50|$|Some {{viewers of}} 3D movies {{complain}} of headaches or nausea {{during or after}} viewing. These problems {{can be caused by}} the viewer tilting his or her head, making it harder for the brain to fuse the two <b>images</b> (due to <b>parallax</b> mismatch between the eyes and the cameras). It can also be caused by rapid transitions in the movie between scenes of very different depth. Consequently, directors and editors of 3D movies should avoid such transitions.|$|R
50|$|Integral imaging is an autostereoscopic or multiscopic 3D display, {{meaning that}} it {{displays}} a 3D image {{without the use of}} special glasses {{on the part of the}} viewer. It achieves this by placing an array of microlenses (similar to a lenticular lens) in front of the image, where each lens looks different depending on viewing angle. Thus rather than displaying a 2D image that looks the same from every direction, it reproduces a 4D light field, creating stereo <b>images</b> that exhibit <b>parallax</b> when the viewer moves.|$|R
5000|$|In 1989 Antonio Medina Puerta {{demonstrated}} {{with photographs}} that retinal <b>images</b> with no <b>parallax</b> disparity but with different shadows are fused stereoscopically, imparting depth perception to the imaged scene. He named the phenomenon [...] "shadow stereopsis". Shadows are therefore an important, stereoscopic cue for depth perception. He showed how effective {{the phenomenon is}} by taking two photographs of the Moon at different times, and therefore with different shadows, making the Moon to appear in 3D stereoscopically, {{despite the absence of}} any other stereoscopic cue.|$|R
40|$|The step barrier {{technology}} with multiple <b>parallax</b> <b>images</b> has overcome {{the problem of}} conventional parallax barrier system that the image quality of each image deteriorates only in the horizontal direction. The step barrier distributes the resolution problem both to the horizontal and the vertical directions. The system has a simple structure, which consists of a flat-panel display and a step barrier. The apertures of the step barrier are not stripes but tiny rectangles that are arranged {{in the shape of}} stairs, and the sub-pixels of each image have the same arrangement. And three image processes for the system applicable to computer graphics and real image have been proposed. Then, two types of 3 -D displays were developed, 22 -inch model and 50 -inch model. The 22 -inch model employs a very high-definition liquid crystal display of 3840 x 2400 pixels. The number of <b>parallax</b> <b>images</b> is seven and the resolution of one image is 1646 x 800. The 50 -inch model has four viewing points on the plasma display panel of 1280 x 768 pixels. It can provide stereoscopic animations and the resolution of one image is 960 x 256 pixels. Moreover, the structural or electric 2 -D 3 -D compatible system was developed...|$|R
40|$|Abstract: Distance {{measurement}} {{technology of}} binocular stereo vision has {{the advantages of}} wide-range detection, simplicity and reliability. The method is widely applied to robot obstacle avoidance and path planning. Binocular stereo vision can only measure the distance of images feature points generally. However, more information about distance of non-feature points is also needed to acquire in practical applications. This paper proposes a stereo distance measurement method, which can measure distance of points {{whether it is a}} feature point or not based on a dense matching method. A dense parallax map is obtained by the graph-cuts algorithm. On the basis of the calibration parameters of binocular camera and the left and right <b>image</b> dense <b>parallax</b> map, the three-dimensional coordinates of the any points and their distance will be gotten. The true image experiment has proved the feasibility of this algorithm with high accuracy and maneuverability...|$|R
40|$|Two {{well-known}} {{problems of}} stereoscopic displays are the accommodation-convergence {{conflict and the}} lack of natural blur for defocused objects. We present a new technique that we name Super Stereoscopy (SS 3 D) to provide a convenient solution to these problems. Regular stereoscopic glasses are replaced by SS 3 D glasses which deliver at least two <b>parallax</b> <b>images</b> per eye through pinholes equipped with light selective filters. The pinholes generate blur-free retinal images so as to enable correct accommodation, while the delivery of multiple <b>parallax</b> <b>images</b> per eye creates an approximate blur effect for defocused objects. Experiments performed with cameras and human viewers indicate that the technique works as desired. In case two, pinholes equipped with color filters per eye are used; the technique can be used on a regular stereoscopic display by only uploading a new content, without requiring any change in display hardware, driver, or frame rate. Apart from some tolerable loss in display brightness and decrease in natural spatial resolution limit of the eye because of pinholes, the technique is quite promising for comfortable and realistic 3 D vision, especially enabling the display of close objects that are not possible to display and comfortably view on regular 3 DTV and cinema. © 2014 Optical Society of America OCIS codes: (330. 1400) Vision- binocular and stereopsis; (330. 7322) Visual optics, accommodation; (120. 2040...|$|R
40|$|International audienceThe human {{vision system}} has visual {{functions}} for viewing 3 D images with a correct depth. These functions are called accommodation, vergence and binocular stereopsis. Most 3 D display system utilizes binocular stereopsis. We {{have developed a}} monocular 3 D vision system with accommodation mechanism, which is useful function for perceiving depth. This vision unit needs an image shift optics for generating monocular <b>parallax</b> <b>images.</b> But conventional image shift mechanism is heavy because of its linear actuator. To improve this problem, we developed a light-weight 3 D vision unit for presenting monocular stereoscopic images using a polypyrrole linear actuator...|$|R
40|$|We {{address the}} problem of fusing sparse and noisy depth data {{obtained}} from a range finder with features obtained from intensity images to estimate ego-motion and refine 3 D structure of a scene using a Rao-Blackwellized particle filter. For scenes with low depth variability, the algorithm shows an alternate way of performing Structure from Motion (SfM) starting with a flat depth map. Instead of using 3 D depths, we formulate the problem using 2 D <b>image</b> domain <b>parallax</b> and show that conditioned on non-linear motion parameters, the parallax magnitude with respect to the projection of the vanishing point forms a linear subsystem independent of camera motion and their distributions can be analytically integrated. Thus, the structure is obtained by estimating parallax with respect to the given depths using a Kalman filter and only the ego-motion is estimated using a particle filter. Hence, the required number of particles becomes independent of the number of feature points which is an improvement over previous algorithms. Experimental results on both synthetic and real data show the e#ectiveness of our approach. ...|$|R
50|$|In this method, {{parallax}} in {{the vertical}} plane is sacrificed {{to allow a}} bright, well-defined, gradiently colored reconstructed image to be obtained using white light. The rainbow holography recording process usually begins with a standard transmission hologram and copies it using a horizontal slit to eliminate vertical parallax in the output image. The viewer is therefore effectively viewing the holographic image through a narrow horizontal slit, but the slit has been expanded into a window by the same dispersion that would otherwise smear the entire <b>image.</b> Horizontal <b>parallax</b> information is preserved but movement in the vertical direction results in a color shift rather than altered vertical perspective. Because perspective effects are reproduced along one axis only, the subject will appear variously stretched or squashed when the hologram is not viewed at an optimum distance; this distortion may go unnoticed when {{there is not much}} depth, but can be severe when the distance of the subject from the plane of the hologram is very substantial. Stereopsis and horizontal motion parallax, two relatively powerful cues to depth, are preserved.|$|R
40|$|We {{describe}} an electro-optic apparatus capable of displaying a computer-generated hologram in real time. The computer-generated hologram is calculated by a supercomputer, read from a fast frame buffer, and transmitted to a wide-bandwidth acousto-optic modulator. Coherent light is modulated by the acousto-optic modulator and optically processed {{to produce a}} three-dimensional <b>image</b> with horizontal <b>parallax.</b> We evaluate different dis-play geometries and their effect on the optical parameters of the system. We then show how the display resolu-tion can be increased by simultaneously writing three acoustic columns on a single crystal and optically multiplexing the resulting holograms. We finally describe some improvements that follow from the analysis. 1...|$|R
40|$|Abstract — The human {{vision system}} has visual {{functions}} for viewing 3 D images with a correct depth. These functions are called accommodation, vergence and binocular stereopsis. Most 3 D display system utilizes binocular stereopsis. The authors {{have developed a}} monocular 3 D vision system with accommodation mechanism, which is useful function for perceiving depth. This vision unit needs an image shift optics for generating monocular <b>parallax</b> <b>images.</b> But conventional image shift mechanism is heavy because of its linear actuator system. To improve this problem, we developed a light-weight 3 D vision unit for presenting monocular stereoscopic images using a polypyrrole linear actuator. Index Terms—head mounted display, monocular stereoscopic display, real-time stereogram, 3 -D display I...|$|R
40|$|We {{present an}} {{approach}} to update and refine coarse 3 D models of urban environments from a sequence of intensity <b>images</b> using surface <b>parallax.</b> This generalizes the plane-parallax recovery methods to surface-parallax using arbitrary surfaces. A coarse and potentially incomplete depth map of the scene obtained from a Digital Elevation Map (DEM) {{is used as a}} reference surface which is refined and updated using this approach. The reference depth map is used to estimate the camera motion and the motion of the 3 D points on the reference surface is compensated. The resulting parallax, which is an epipolar field, is estimated using an adaptive windowing technique and used to obtain the refined depth map...|$|R
40|$|The paper {{gives an}} {{overview}} of our multimodal 3 D display technology. Enabling technologies such as head tracking, shifting and scaling for content adaptation are briefly described using {{the example of a}} single-user display. These new solutions can be applied to multiview and lightfield 3 D displays as they {{can be found in the}} market independent of the used technology for <b>image</b> separation like <b>parallax</b> barrier, lenticular or holographic optical element. Beyond that dual view or integral imaging displays can be manipulated with similar results by slightly different means. In general, the new algorithms enable the use of content originally produced for glasses type 3 D displays without the need of additional calculation of interpolated views...|$|R
50|$|Segmented panoramas, {{also called}} {{stitched}} panoramas, {{are made by}} joining multiple photographs with slightly overlapping fields of view to create a panoramic image. Stitching software is used to combine multiple images. Ideally, in order to correctly stitch <b>images</b> together without <b>parallax</b> error, the camera must be rotated about the center of its lens entrance pupil. Stitching software can correct some parallax errors and different programs seem to vary {{in their ability to}} correct parallax errors. In general specific panorama software seems better at this than some of the built in stitching in general photomanipulation software. Some digital cameras can do the stitching internally, either as a standard feature or by installing a smartphone app.|$|R
40|$|A {{fundamental}} {{element of}} stereoscopic image production is to geometrically analyze the conversion from real space to stereoscopic <b>images</b> by binocular <b>parallax</b> under various shooting and viewing conditions. This paper reports on this analysis, {{particularly on the}} setting of the optical axes of 3 D cameras, which has received little attention in the past. The parallel camera configuration maintains linearity during the conversion from real space to stereoscopic images. But the toed-in camera configuration often can not maintain linearity during the conversion from real space to stereoscopic images. 3 D cameras (see Fig. 1) [7]. As the demand for efficient program production increases, {{it is very important to}} precisely understand the characteristics of these two ways of placing optical axes and to use them flexibly depending on the situation. 1...|$|R
40|$|This thesis {{presents}} an image based falling snow rendering method {{which is based}} on spectral synthesis technique. By incorporating the natural falling snow motion property, that is, the image speed and size of the snowflakes are related to the depth, we develop a tent-like surface in frequency domain. We synthesize the power spectrum along the tent-like surface and use IFFT to bring the data function back to space-time domain, thus attain a motion <b>parallax</b> <b>image</b> sequence. Treating the motion parallax as an opacity function, we can composite it with an existing video sequence {{and turn it into a}} snowing scene. Treating the motion parallax as a stimulus for the psychophysical study, it could serve as a complex yet natural scene-like stimulus, and therefore being expected to give a new perspective to the psychophysical study...|$|R
40|$|Attitude jitter is {{a common}} {{phenomenon}} {{in the application of}} high resolution satellites, which may result in large errors of geo-positioning and mapping accuracy. Therefore, it is critical to detect and compensate attitude jitter to explore the full geometric potential of high resolution satellites. In this paper, a framework of jitter detection and compensation for high resolution satellites is proposed and some preliminary investigation is performed. Three methods for jitter detection are presented as follows. (1) The first one is based on multispectral <b>images</b> using <b>parallax</b> between two different bands in the image; (2) The second is based on stereo images using rational polynomial coefficients (RPCs); (3) The third is based on panchromatic images employing orthorectification processing. Based on the calculated parallax maps, the frequency and amplitude of the detected jitter are obtained. Subsequently, two approaches for jitter compensation are conducted. (1) The first one is to conduct the compensation on image, which uses the derived parallax observations for resampling; (2) The second is to conduct the compensation on attitude data, which treats the influence of jitter on attitude as correction of charge-coupled device (CCD) viewing angles. Experiments with images from several satellites, such as ASTER (Advanced Spaceborne Thermal Emission and Reflection Radiaometer), LRO (Lunar Reconnaissance Orbiter) and ZY- 3 (ZiYuan- 3) demonstrate the promising performance and feasibility of the proposed framework...|$|R
40|$|We {{present an}} {{electro-optical}} apparatus capable of displaying a computer generated hologram (CGH) in real time. The CGH is calculated by a supercomputer, read from a fast frame buffer, and transmitted to a high-bandwidth acousto-optic modulator (AOM). Coherent light is modulated by the AOM and optically processed {{to produce a}} three-dimensional <b>image</b> with horizontal <b>parallax.</b> 1. INTRODUCTION The display of three-dimensional information is central to progress in many fields, such as medical imaging, computer-aided design, and navigation. Typically, such information can {{be transformed into a}} holographic image, which facilitates rapid and accurate perception of complex structures in depth using the natural depth cues of stereopsis, motion parallax, and ocular accommodation. Although conventional display holograms can produce bright, full-color images of high resolution and a large range of depths, they are static, and cannot be altered electronically as can a typical two-dimensional displa [...] ...|$|R
40|$|Integral imaging is a {{technique}} capable of displaying 3 –D <b>images</b> with continuous <b>parallax</b> in full natural color. It {{is one of the}} most promising methods for producing smooth 3 –D images. Extracting depth information from integral image has various applications ranging from remote inspection, robotic vision, medical imaging, virtual reality, to content-based image coding and manipulation for integral imaging based 3 –D TV. This paper presents a method of generating a depth map from unidirectional integral images through viewpoint image extraction and using a hybrid disparity analysis algorithm combining multi-baseline, neighborhood constraint and relaxation strategies. It is shown that a depth map having few areas of uncertainty can be obtained from both computer and photographically generated integral images using this approach. The acceptable depth maps can be achieved from photographic captured integral images containing complicated object scene...|$|R
40|$|Holoscopic 3 D imaging {{also known}} as Integral imaging is a {{promising}} technique for creating full color 3 D optical models that exist in space independently of the viewer. The <b>images</b> exhibit continuous <b>parallax</b> throughout the viewing zone. In order to achieve depth control, robust and real-time, a single aperture holoscopic 3 D imaging camera is used for recording holoscopic 3 D image using a regularly spaced array of small lenslets, which view the scene at a slightly different angle to its neighbour. However, the main problem the holoscopic 3 D camera aperture faces {{is that it is}} not big enough for recording larger scene with existing 2 D camera sensors. This paper proposes a novel reference based holoscopic 3 D camera aperture stitching method that enlarges overall viewing angle of the holoscopic 3 D camera in post-production after the capture...|$|R
40|$|In this study, {{we propose}} a VR system for {{allowing}} {{various types of}} interaction with virtual objects using an autostereoscopic mobile display and an accelerometer. The system obtains the orientation and motion information from the accelerometer attached to the mobile display and reflects them to the motion of virtual objects. It can present 3 D <b>images</b> with motion <b>parallax</b> by estimating {{the position of the}} user’s viewpoint and by displaying properly projected images. Furthermore, our method enables to connect the real space and the virtual space seamlessly through the mobile display by determining the coordinate system so that one of the horizontal surfaces in the virtual space coincides with the display surface. To show the effectiveness of this concept, we implemented an application to simulate food cooking by regarding the mobile display as a frying pan...|$|R
40|$|A unique {{integral}} {{imaging system}} is employed {{as part of}} a three dimensional television system, allowing display of full colour 3 D <b>images</b> with continuous <b>parallax</b> within a wide viewing zone. A significant quantity of data is required to represent captured integral 3 D images with adequate resolution. A lossy compression scheme has been developed, based on the use of a three dimensional discrete cosine transform (3 D-DCT), which makes possible efficient storage and transmission of such images while maintaining all information necessary to produce a high quality 3 D display. In this paper we present the results of investigations into the design of quantisation strategies to maximise rate-distortion performance, including the use of image-orientated optimization. Performance is vastly improved compared with that achieved using baseline JPEG for compression of full parallax integral 3 D image data. INTRODUCTION A number of potential applications exist for fully threedimensional image and video [...] ...|$|R
