103|1283|Public
25|$|In 1995, Andrew Roos {{experimentally}} {{observed that}} the first byte of the keystream is correlated to the first three bytes of the key and the first few bytes of the permutation after the KSA are correlated to some linear combination of the key bytes. These biases remained unexplained until 2007, when Goutam Paul, Siddheshwar Rathi and Subhamoy Maitra proved the keystream-key correlation and in another work Goutam Paul and Subhamoy Maitra proved the permutation-key correlations. The latter work also used the permutation-key correlations to design the first algorithm for complete key reconstruction from the final permutation after the KSA, without any assumption on the key or initialization vector. This algorithm has a constant probability of success in a time which is the square root of the <b>exhaustive</b> <b>key</b> <b>search</b> complexity. Subsequently, many other works have been performed on key reconstruction from RC4 internal states. Subhamoy Maitra and Goutam Paul also showed that the Roos type biases still persist even when one considers nested permutation indices, like S or S. These types of biases are used {{in some of the}} later key reconstruction methods for increasing the success probability.|$|E
5000|$|KTANTAN32, the {{computational}} {{complexity of}} the above attack is , compared to [...] with an <b>exhaustive</b> <b>key</b> <b>search.</b> The data complexity is 3 plain-/ciphertext pairs.|$|E
50|$|The key size is 80 {{bits and}} the IV size is {{specified}} to be 64 bits. The authors {{claim that the}} cipher is designed such that no attack faster than <b>exhaustive</b> <b>key</b> <b>search</b> should be possible, hence the best attack should require a computational complexity not significantly lower than 280.|$|E
40|$|Steganalysis in {{the wide}} sense {{consists}} of first identifying suspicious objects and then further analysis during which we try to identify the steganographic scheme used for embedding, recover the stego key, and finally extract the hidden message. In this paper, we present a methodology for identifying the stego key in key-dependent steganographic schemes. Previous approaches for stego <b>key</b> <b>search</b> were <b>exhaustive</b> searches looking for some recognizable structure (e. g., header) in the extracted bit-stream. However, if the message is encrypted, the search will become much more expensive because for each stego key, all possible encryption keys {{would have to be}} tested. In this paper, we show that for a very wide range of steganographic schemes, the complexity of the stego <b>key</b> <b>search</b> is determined only {{by the size of the}} stego key space and is independent of the encryption algorithm. The correct stego key can be determined through an <b>exhaustive</b> stego <b>key</b> <b>search</b> by quantifying statistical properties of samples along portions of the embedding path. The correct stego key is then identified by an outlier sample distribution. Although the search methodology is applicable to virtually all steganographic schemes, in this paper we focus on JPEG steganography. Search techniques for spatial steganographic techniques are treated in our upcoming paper...|$|R
40|$|Abstract. PRESENT is a hardware-oriented {{block cipher}} {{suitable}} for resource constrained environment. In this paper we analyze PRESENT by the multidimensional linear cryptanalysis method. We claim that our attack can recover the 80 -bit secret key of PRESENT up to 25 rounds out of 31 rounds with around 2 62. 4 data complexity. Furthermore, {{we showed that}} the 26 -round version of PRESENT can be attacked faster than <b>key</b> <b>exhaustive</b> <b>search</b> with the 2 64 data complexity by an advanced <b>key</b> <b>search</b> technique. Our results are superior to all the previous attacks. We demonstrate our result by performing the linear attacks on reduced variants of PRESENT. Our results exemplify that {{the performance of the}} multidimensional linear attack is superior compared to the classical linear attack...|$|R
40|$|Abstract: Classification trees {{based on}} {{exhaustive}} search algorithms {{tend to be}} biased towards selecting variables that afford more splits. As a result, such trees should be interpreted with caution. This article presents an algorithm called QUEST that has negligible bias. Its split selection strategy shares similarities with the FACT method, but it yields binary splits and the final tree can be selected by a direct stopping rule or by pruning. Real and simulated data are used to compare QUEST with the exhaustive search approach. QUEST is shown to be substantially faster and the size and classification accuracy of its trees are typically {{comparable to those of}} <b>exhaustive</b> <b>search.</b> <b>Key</b> words and phrases: Decision trees, discriminant analysis, machine learning. 1...|$|R
5000|$|In cryptography, a brute-force attack {{consists}} of an attacker trying many passwords or passphrases {{with the hope of}} eventually guessing correctly. The attacker systematically checks all possible passwords and passphrases until the correct one is found. Alternatively, the attacker can attempt to guess the key which is typically created from the password using a key derivation function. This is known as an <b>exhaustive</b> <b>key</b> <b>search.</b>|$|E
50|$|Brute force {{attack or}} <b>exhaustive</b> <b>key</b> <b>search</b> - in this attack every {{possible}} key is tried until the correct one is found. Every cipher except the unbreakable Information-theoretically secure methods {{like the one}} time pad is vulnerable to this method, and as its difficulty {{does not depend on}} the cipher but only on the key length - it's not considered a real cryptanalysis of the cipher. If the key has N bits, there are 2N possible keys to try, so a brute-force attack can recover the cipher in a worst-case time proportional to 2N and an average time of 2N-1. This is often used as a standard of comparison for other attacks. Brute-force can be applied in ciphertext-only settings, but the cryptanalyst must have enough information about the plaintext (at least N bits) to allow the identification of the correct key once it is tried.|$|E
5000|$|In 1995, Andrew Roos {{experimentally}} {{observed that}} the first byte of the keystream is correlated to the first three bytes of the key and the first few bytes of the permutation after the KSA are correlated to some linear combination of the key bytes. These biases remained unexplained until 2007, when Goutam Paul, Siddheshwar Rathi and Subhamoy Maitra proved the keystream-key correlation and in another work Goutam Paul and Subhamoy Maitra proved the permutation-key correlations. The latter work also used the permutation-key correlations to design the first algorithm for complete key reconstruction from the final permutation after the KSA, without any assumption on the key or initialization vector. This algorithm has a constant probability of success in a time which is the square root of the <b>exhaustive</b> <b>key</b> <b>search</b> complexity. Subsequently, many other works have been performed on key reconstruction from RC4 internal states. Subhamoy Maitra and Goutam Paul also showed that the Roos type biases still persist even when one considers nested permutation indices, like [...] or [...] These types of biases are used {{in some of the}} later key reconstruction methods for increasing the success probability.|$|E
40|$|Crypton is a 12 -round blockcipher {{proposed}} as an AES candidate by C. H. Lim in 1998. In this paper, we present two bottleneck attacks on reduced round version of Crypton v 0. 5 and Crypton v 1. 0. Those cryptanalyses are built upon a four-round distinguisher {{based on a}} three-round property due to a restricted dependency of the one byte to one byte permutation transformation as made for the AES in [GM 00]. We present {{an attack on a}} six round version of Crypton. We also present a marginal speed up of the 128 -bits <b>key</b> <b>exhaustive</b> <b>search</b> for a seven-round version of Crypton. This attack does not endanger the practical security offered by Crypton but shows an other example where the bottleneck property could be used with an S-box level composed of at least two S-boxes...|$|R
40|$|Two main {{approaches}} {{are used for}} increasing the quality of systems: in model checking, one checks properties of a known design of a system; in testing, one usually checks whether a given implementation, whose internal structure is often unknown, conforms with an abstract design. We {{are interested in the}} combination of these techniques. Namely, we {{would like to be able}} to test whether an implementation with unknown structure satisfies some given properties. We propose and formalize this problem of black box checking and suggest several algorithms. Since the input to black box checking is not given initially, as is the case in the classical model of computation, but is learned through experiments, we propose a computational model based on games with incomplete information. We use this model to analyze the complexity of the problem. We also address the more practical question of finding an approach that can detect errors in the implementation before completing an <b>exhaustive</b> <b>search.</b> <b>Key</b> [...] ...|$|R
40|$|In this paper, {{we propose}} an {{expanded}} set of design {{criteria for the}} generation of DES-like Sboxes which enable DES being immunized against three known robust cryptanalysis, i. e., differential, Improved Davies' and linear cryptanalysis and we also suggest a set of new 8 DES-like S-boxes generated by our proposed design criteria in order to replace with the current 8 DES S-boxes. The computer simulation leads us {{to conclude that the}} breaking complexity of the strengthened DES (we call s 5 DES) by three powerful cryptanalysis is no more efficient than the key-exhaustive search. 1 Introduction Until now, three powerful cryptanalysis have been published to break DES (Data Encryption Standard) [1] more efficiently than the 56 -bit <b>key</b> <b>exhaustive</b> <b>search.</b> One is the DC (Differential Cryptanalysis) proposed by Biham and Shamir [2],[4] in 1990. The DC is a kind of chosen plaintext attack in a sense that an attacker has to choose 2 47 plaintexts and their corresponding ciphertexts to find an [...] ...|$|R
40|$|Among {{methods of}} {{breaking}} a cipher, <b>exhaustive</b> <b>key</b> <b>search</b> {{stands out as}} the most successful (albeit the least efficient) method. We demonstrate that various algorithmic implementations of <b>exhaustive</b> <b>key</b> <b>search</b> are not equally effective, and cryptosystems can be devised which make some implementations of <b>exhaustive</b> <b>key</b> <b>search</b> unsuccessful (in {{the sense that the}} problem these algorithms try to solve turns out to be incomputable). We observe that there are implementations of <b>exhaustive</b> <b>key</b> <b>search</b> that are always successful (i. e. they terminate and generate a correct result irrespective of the cryptosystem they are used against). As to those implementations of <b>exhaustive</b> <b>key</b> <b>search</b> that are not always successful, we describe them and those cryptosystems that can make them unsuccessful. 1...|$|E
40|$|LILI- 128 is {{a stream}} cipher that was {{submitted}} to NESSIE. Strangely, the designers {{do not really}} seem to have tried to ensure that cryptanalysis is no easier than by <b>exhaustive</b> <b>key</b> <b>search.</b> We show that there are indeed attacks faster than <b>exhaustive</b> <b>key</b> <b>search.</b> We also demonstrate a related key attack which has very low complexity, and which could be of practical significance if the cipher were used in a certain rather natural way...|$|E
40|$|<b>Exhaustive</b> <b>key</b> <b>search</b> is the {{simplest}} attack against a cryptosystem, {{but it is}} sometimes the most realistic. This is specially true for carefully designed block ciphers for which advanced cryptanalysis (e. g. : linear, differential) is not applicable. In this paper, we dirst update {{the cost of an}} <b>exhaustive</b> <b>key</b> <b>search</b> of the Data Encryption Standard (DES) using Field Programmable Gate Arrays (FPGAs). Then we illus- trate how a time-memory tradeoff attack can be mounted for a similar cost, with much more dramatic consequences...|$|E
40|$|This paper {{presents}} an effective {{field-programmable gate array}} (FPGA) -based hardware implementation of a parallel <b>key</b> <b>searching</b> system for the brute-force attack on RC 4 encryption. The design employs several novel key scheduling techniques to minimize {{the total number of}} cycles for each <b>key</b> <b>search</b> and uses on-chip memories of the FPGA to maximize the number of <b>key</b> <b>searching</b> units per chip. Based on the design, a total of 176 RC 4 <b>key</b> <b>searching</b> units can be implemented in a single Xilinx XC 2 VP 20 - 5 FPGA chip, which currently costs only a few hundred U. S. dollars. Operating at a 47 -MHz clock rate, the design can achieve a <b>key</b> <b>searching</b> speed of 1. 07 × 10 7 keys per second. Breaking a 40 -bit RC 4 encryption only requires around 28. 5 h. © 2008 IEEE. link_to_subscribed_fulltex...|$|R
5000|$|This adversary (call it A1) {{will attempt}} to cryptanalyze its input by brute force. It has its own DES implementation. It gives a single query to its oracle, asking for the 64-bit string of all zeroes to be encrypted. Call the {{resulting}} ciphertext E0. It then runs an <b>exhaustive</b> <b>key</b> search.The algorithm looks like this: ...|$|R
30|$|The <b>key</b> <b>search</b> terms included: “arsenic AND water AND suicide”.|$|R
40|$|Armed with super {{computational}} ability, {{the most}} efficient attack on symmetric-key systems is an <b>exhaustive</b> <b>key</b> <b>search.</b> A novel encryption method with infinite key space is presented by modifying traditional book cipher. Infinite key space means the unbounded entropy of the key space, which can frustrate any <b>exhaustive</b> <b>key</b> <b>search.</b> Moreover, this book cipher is immune from frequency analysis. Experimental results show that both encryptionand decryption have very high rates of data throughput while compared with DES. High efficiency makes it suitable for some computing power limited environments...|$|E
40|$|In {{cryptanalysis}} of block ciphers, {{there are}} several attacks that are always feasible and for which the success probability and complexity only depend on key length and/or block size. <b>Exhaustive</b> <b>key</b> <b>search</b> and table precomputation are two of such attacks. In [Hel 80] an attack was introduced which provides a tradeoff between the processing complexity of <b>exhaustive</b> <b>key</b> <b>search</b> and the memory complexity of table precomputation. We introduce a variant on the Hellman time-memory tradeoff, which decreases the expected number of memory accesses by a large factor and we demonstrate its advantages in a distributed key search. 1 Introduction In this paper we study an attack on block ciphers that combines the following two attacks. One is <b>exhaustive</b> <b>key</b> <b>search</b> in which an attacker tries all possible keys to encrypt a known plaintext for which he has the corresponding ciphertext. The other is table precomputation in which the attacker precomputes and stores encryptions of a chosen plaintext and co [...] ...|$|E
40|$|The Data Encryption Standard (DES) {{is among}} the most popular {{encryption}} method that has become the de facto standard to protect confidential information ranging from Automatic Teller Machines (ATMs) and smart cards to emails and online websites. Although recently a successor - the Advanced Encryption Standard (AES) has emerged, DES and its variants remain being used in various applications as the complete roll out of the AES will take some years to materialize. To date, the only practical attack on the DES is the <b>exhaustive</b> <b>key</b> <b>search.</b> In this paper, we exploit a recently presented sliding property of the DES key schedule to show that the <b>exhaustive</b> <b>key</b> <b>search</b> of the DES can be further reduced from previous known results...|$|E
40|$|Encryption <b>Key</b> <b>Search</b> is a compute-intensive {{operation}} {{that consists of}} a brute-force search of a particular key in a given key space. Sequential execution time for a 56 -bit encryption <b>key</b> <b>search</b> is approximately 200, 000 years and therefore it is ideal to execute such operation in a grid environment. ALiCE (Adaptive and scaLable internet-based Computing Engine) is a grid middleware that offers a portable software technology for developing and deploying grid applications and systems. This paper discusses {{the development of the}} Encryption <b>Key</b> <b>Search</b> application on ALiCE and also presents the performance evaluation of ALiCE using this application. Singapore-MIT Alliance (SMA...|$|R
40|$|Background: Executive {{function}} deficits {{are commonly}} observed in many clinical populations, highlighting {{the importance of}} appropriate diagnostic tools to screen for these deficits. Most neuropsychological tests of executive function, however, are time-consuming and difficult to administer {{in the case of}} moderate to severe cognitive decline. The aim {{of the present study was}} to examine whether the <b>Key</b> <b>Search</b> Test, a short and easy to administer test, is a useful indicator of executive function deficits in a study sample with a diagnosis of cognitive impairment. Methods: Participants consisted of elderly people visiting the memory clinic at the department of geriatrics of a university medical center (n = 140) and of elderly controls (n = 37). Next to the <b>Key</b> <b>Search</b> Test, other executive function tests and a memory test were administered. Results: Low to moderate correlations were found between the <b>Key</b> <b>Search</b> Test and other executive function tests. Furthermore, although the <b>Key</b> <b>Search</b> Test discriminated significantly between intact and impaired executive function (AUC = 0. 677, P < 0. 001), sensitivity and specificity were low and no optimal cut-off point could be determined. Conclusion: The <b>Key</b> <b>Search</b> test might not be an appropriate measure of executive functions in cognitively impaired individuals...|$|R
40|$|A massively {{parallel}} single instruction multiple data stream (SIMD) processor {{designed specifically for}} cryptographic <b>key</b> <b>search</b> applications is presented. This design aims to exploit fine grain parallelism and the high memory bandwidth available in an FPGA by integrating 95 simple processors and memory on a single FPGA chip. Performance is compared with a previously reported hardwired design on a RC 4 <b>key</b> <b>search</b> application. ...|$|R
40|$|Many searching {{problems}} allow time-memory tradeoffs. That is, {{if there}} are K possible solutions to search over, the time-memory tradeoff allows the solution to be found with high probability, in T operations (time) with M words of memory, provided the time-memory product T ×M is larger than K. Cryptanalytic attacks based on <b>exhaustive</b> <b>key</b> <b>search</b> are the typical context where time-memory tradeoffs are applicable. Due to large key sizes, <b>exhaustive</b> <b>key</b> <b>search</b> usually needs unrealistic computing pow-ers and corresponds to a situation where T = K and M = 1. However, if the same attack has {{to be carried out}} numerous times, {{it may be possible to}} execute the exhaus-tive search in advance and store all the results in a memory. Once this precomputation is done, the attack could be performed almost instantaneously, although in practice, the method is not realistic because of the huge amount of memory needed: T = 1, M = K. The aim of a time-memory tradeoff is to mount an attack that has a lower online processing complexity than <b>exhaustive</b> <b>key</b> <b>search</b> and lower memory complexity than a table lookup, neglecting the precomputations (hence, it only makes sense if the attack has to be performed multiple times). The method can be used to invert an...|$|E
40|$|In {{order to}} achieve {{computational}} workload equivalent to the <b>exhaustive</b> <b>key</b> <b>search</b> of an n-bit key for inversion of RSA or Diffie-Hellman one-way candidate functions the length of their arguments have to have from 10 n to 60 n bits. One-way functions based on Elliptic Curves in this moment are holding the record, demanding only 2 n bits for their arguments. In this {{paper we propose a}} definition and construction of a new family of one-way candidate functions {cal R}_N:Q^N ightarrow Q^N, where Q={ 0, 1,ldots,s- 1 } is an alphabet with s elements. Special instances of these functions can be permutations (i. e. one-way permutations). These one-way functions have the property that for achieving the security level equivalent of <b>exhaustive</b> <b>key</b> <b>search</b> of n-bit key, only n bits of input are needed...|$|E
40|$|A {{computationally}} secure noised based {{cipher system}} is proposed. The {{advantage of this}} cipher system is that it operates above noise level. Therefore computationally secure communication can be done when error correction code fails. Another feature of this system is that minimum number of <b>exhaustive</b> <b>key</b> <b>search</b> can be made fixed. Comment: Revised, Latex, 4 page...|$|E
50|$|By using Grover's {{algorithm}} on {{a quantum}} computer, brute-force <b>key</b> <b>search</b> {{can be made}} quadratically faster. However, this could be countered by doubling the key length.|$|R
40|$|This {{paper is}} an {{extension}} of our work 1 on stego <b>key</b> <b>search</b> for JPEG images published at EI SPIE in 2004. We provide a more general theoretical description of the methodology, apply our approach to the spatial domain, and add a method that determines the stego key from multiple images. We show that in the spatial domain the stego <b>key</b> <b>search</b> can be made significantly more efficient by working with the noise component of the image obtained using a denoising filter. The technique is tested on the LSB embedding paradigm and on a special case of embedding by noise adding (the ± 1 embedding). The stego <b>key</b> <b>search</b> can be performed for a wide class of steganographic techniques even for sizes of secret message well below those detectable using known methods. The proposed strategy may prove useful to forensic analysts and law enforcement. 1...|$|R
40|$|Abstract—This paper {{proposes a}} novel fault-propagation pattern based {{differential}} fault analysis method- FPP-DFA, and proves its feasibility on SPN structure block ciphers using bitwise permutation, such as PRESENT and PRINTcipher. Simulated experiments demonstrate that, with the fault model of injecting one nibble fault into the r- 2 th round substitution layer, on average 8 and 16 faulty samples {{can reduce the}} master <b>key</b> <b>search</b> space of PRESENT- 80 / 128 to 2 14. 7 and 2 21. 1 respectively, and 12 and 24 effective faulty samples can reduce the master <b>key</b> <b>search</b> space of PRINTcipher- 48 / 96 to 2 13. 7 and 2 22. 8 respectively; with the fault model of injecting one nibble fault into the r- 3 th round substitution layer, 8 samples can reduce the master <b>key</b> <b>search</b> space of PRINTCipher- 96 to 2 18. 7. Fault-propagation pattern; fault-propagation path; differential fault analysis; bitwise permutation; SPN block cipher; PRESENT; PRINTcipher (key words) I...|$|R
40|$|This paper {{describes}} {{an investigation of}} a potential weakness in DES {{which leads to a}} statistical property observable in plaintextciphertext pairs and dependent on the key. However, the number of encryptions of known plaintext needed to exploit this property is comparable to the number of encryptions of an <b>exhaustive</b> <b>key</b> <b>search,</b> so the &quot; is mainly of theoretical interest...|$|E
40|$|Abstract in Undetermined This report {{presents}} a security {{evaluation of the}} Enocoro- 128 v 2 stream cipher. Enocoro- 128 v 2 was proposed in 2010 {{and is a member}} of the Enocoro family of stream ciphers. This evaluation examines several different attacks applied to the Enocoro- 128 v 2 design. No attack better than <b>exhaustive</b> <b>key</b> <b>search</b> has been found...|$|E
40|$|Abstract. Sober-t 16 and Sober-t 32 are two {{synchronous}} stream ci-phers {{developed by}} G. Rose and P. Hawkes and {{submitted to the}} NESSIE competition. In this paper we show how a probabilistic factor in the de-sign can be exploited. A Guess and Determine attack is mounted against Sober-tw. For unstuttered Sober-t 32, this attack is more e±cient than <b>exhaustive</b> <b>key</b> <b>search...</b>|$|E
3000|$|... {{correctly}} {{is already}} difficult to satisfy. Considering this fact and the phenomenon that the iterative <b>key</b> <b>search</b> procedure has even problems to achieve convergence with {{all but one}} correct [...]...|$|R
30|$|A DFA on PRESENT- 80 key {{schedule}} {{has been}} proposed by Wang et al.[24]. They assumed that the key schedule was corrupted by the fault injection and tried to recover the key. They have reduced the master <b>key</b> <b>search</b> space of PRESENT- 80 to 229 with 64 pairs of correct and faulty cipher texts on average. In addition, Zhao et al.[25] proposed a fault propagation pattern-based DFA on PRESENT- 80 / 128. They reduce the master <b>key</b> <b>search</b> space of PRESENT- 80 / 128 to 214.7 and 221.1, respectively, with 8 and 16 pairs of correct and faulty cipher texts on average.|$|R
5000|$|For Full <b>key</b> <b>Search</b> on Indexed Fields, TACE16 {{performed}} better than Unicode Tamil {{by up to}} 24.07%. In the case of non-indexed fields also TACE16 {{performed better}} than Unicode Tamil by up to 20.9%.|$|R
