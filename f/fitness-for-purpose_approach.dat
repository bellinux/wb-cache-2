3|0|Public
40|$|A new {{methodology}} {{to assess}} source apportionment model performance in intercomparison exercises, encompassing {{the preparation of}} real-world and synthetic datasets and {{the evaluation of the}} source apportionment results reported by participants, is described. The evaluation consists of three types of tests: complementary tests, preliminary tests, and performance tests. The complementary tests provide summary information about the source apportionment results as a whole. The preliminary tests check whether source/factors belong to a given source category. Three types of indicators: Pearson Correlation (Pearson), Standardized Identity Distance (SID), and Weighted Difference (WD) are used to test factor/source chemical profiles, while factor/source time series and contribution-to-species values are tested only using the Pearson. The performance tests, based on international standards for proficiency testing, are targeted at evaluating whether the reported biases in the quantification of the factor/source contribution estimates (SCEs) and uncertainties are consistent with previously established quality standards in a <b>fitness-for-purpose</b> <b>approach.</b> Moreover, the consistency of the SCE time series is evaluated using a variant of the RMSE normalised by the reference standard uncertainty. The described methodology facilitates a thorough evaluation of the source apportionment output. The new indicator to compare source or factor profiles presented in this study (SID) is more robust and provides additional information compared to the existing ones. JRC. H. 2 -Air and Climat...|$|E
40|$|ABSTRACT: BACKGROUND: An {{assessment}} programme, a purposeful mix {{of assessment}} activities, {{is necessary to}} achieve a complete picture of assessee competence. High quality assessment programmes exist, however, design requirements for such programmes are still unclear. We developed guidelines for design based on an earlier developed framework which identified areas to be covered. A <b>fitness-for-purpose</b> <b>approach</b> defining quality was adopted to develop and validate guidelines. METHODS: First, in a brainstorm, ideas were generated, followed by structured interviews with 9 international assessment experts. Then, guidelines were fine-tuned through analysis of the interviews. Finally, validation was based on expert consensus via member checking. RESULTS: In total 72 guidelines were developed and in this paper the most salient guidelines are discussed. The guidelines are related and grouped per layer of the framework. Some guidelines were so generic that these are applicable in any design consideration. These are: the principle of proportionality, rationales should underpin each decisions, and requirement of expertise. Logically, many guidelines focus on practical aspects of assessment. Some guidelines {{were found to be}} clear and concrete, others were less straightforward and were phrased more as issues for contemplation. CONCLUSIONS: The set of guidelines is comprehensive and not bound to a specific context or educational approach. From the fitness-for-purpose principle, guidelines are eclectic, requiring expertise judgement to use them appropriately in different contexts. Further validation studies to test practicality are required...|$|E

