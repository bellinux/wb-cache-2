185|16|Public
25|$|No {{power of}} Introspection. All {{knowledge}} of the internal world comes by <b>hypothetical</b> <b>reasoning</b> from known external facts.|$|E
25|$|Our propositional {{calculus}} has ten inference rules. These rules {{allow us to}} derive other true formulas given a set of formulas that {{are assumed to be}} true. The first nine simply state that we can infer certain well-formed formulas from other well-formed formulas. The last rule however uses <b>hypothetical</b> <b>reasoning</b> in the sense that in the premise of the rule we temporarily assume an (unproven) hypothesis {{to be part of the}} set of inferred formulas to see if we can infer a certain other formula. Since the first nine rules don't do this they are usually described as non-hypothetical rules, and the last one as a hypothetical rule.|$|E
2500|$|Non-monotonic {{reasoning}}. Non-monotonic reasoning allows {{various kinds}} of <b>hypothetical</b> <b>reasoning.</b> The system associates facts asserted with the rules and facts used to justify them and as those facts change updates the dependent knowledge as well. In rule based systems this capability {{is known as a}} truth maintenance system.|$|E
5000|$|Establishment (of the thesis) and {{refutation}} (of the counter-thesis) {{should be}} based upon adequate evidence or means for knowledge (pramana) as well as upon (proper) <b>hypothetical</b> or indirect <b>reasoning</b> (tarka).|$|R
40|$|One of the {{problems}} of the recent approaches to problem solving based on deep knowledge is the lack of a formal treatment of incomplete knowledge. However, dealing with incomplete models is fundamental to many realworld domains. In this paper we propose a formal theory of causal diagnostic reasoning, dealing with different forms of incompleteness both in the general causal knowledge (missing or abstracted knowledge) and in the data describing a specific case under examination. Different forms of nonmonotonic <b>reasoning</b> (<b>hypothetical</b> and circumscriptive <b>reasoning)</b> are used in order to draw and confirm conclusions from incomplete knowledge. Multiple fault solutions are treated in a natural way and parsimony criteria arc used to rank alternative solutions. 1...|$|R
5000|$|The {{final stage}} {{is known as}} the formal {{operational}} stage (adolescence and into adulthood, roughly ages 11 to approximately 15-20): Intelligence is demonstrated through the logical use of symbols related to abstract concepts. This form of thought includes [...] "assumptions that have no necessary relation to reality." [...] At this point, the person is capable of <b>hypothetical</b> and deductive <b>reasoning.</b> During this time, people develop the ability to think about abstract concepts.|$|R
5000|$|Abductive Cognition. The Epistemological and Eco-Cognitive Dimensions of <b>Hypothetical</b> <b>Reasoning</b> (Springer Science+Business Media, Heidelberg/Berlin, 2009); ...|$|E
5000|$|No {{power of}} Introspection. All {{knowledge}} of the internal world comes by <b>hypothetical</b> <b>reasoning</b> from known external facts.|$|E
5000|$|Non-monotonic {{reasoning}}. Non-monotonic reasoning allows {{various kinds}} of <b>hypothetical</b> <b>reasoning.</b> The system associates facts asserted with the rules and facts used to justify them and as those facts change updates the dependent knowledge as well. In rule based systems this capability {{is known as a}} truth maintenance system.|$|E
40|$|It was {{of concern}} to the {{researcher}} that students were successfully completing introductory tertiary statistics units (if success is measured by grades received), without having the ability to explain the principles behind statistical inference. In other words, students were applying procedural knowledge (surface learning) without concurrent conceptual knowledge. This study had the aim of investigating if alternative teaching strategies could assist students in gaining the ability to explain the principles behind two tools of statistical inference: P-values and confidence intervals for the population mean. Computer simulations were used to introduce students to statistical concepts. Students were also introduced to alternative representations of hypothesis tests, and were encouraged to give written explanations of their reasoning. Time for reflection, writing and discussion was also introduced into the lectures. It was the contention of the researcher that students are unfamiliar with the <b>hypothetical,</b> probabilistic <b>reasoning</b> that statistical inference requires. Therefore students were introduced to this form of reasoning gradually throughout the teaching semester, starting with simple examples that the students could understand. It was hoped that {{by the use of}} these examples students could make connections that would form the basis of further understanding. It was found that in general, students‟ understanding of P-values, as demonstrated by the reasoning used in their written explanations, did improve over the four semesters of the study. Students‟ understanding of confidence intervals also improved over the time of the study. However for confidence intervals, where simple examples were more difficult to find, student understanding did not improve {{to the extent that it}} did for P-values. It is recommended that statistics instructors need to appreciate that tertiary students, even those with pre-tertiary mathematics, may not have a good appreciation of probabilistic processes. Students will also be unfamiliar with <b>hypothetical,</b> probabilistic <b>reasoning,</b> and will find this difficult. Statistics instructors, therefore, need to find connections that students can make to more familiar contexts, use alternative representations of statistical processes, and give students time to reflect and write on their work...|$|R
60|$|But, say the abettors of our penal laws, {{this old}} possessed superstition is such in its principles, that society, on its general principles, cannot subsist along with it. Could a man think such an {{objection}} possible, {{if he had}} not actually heard it made,--an objection contradicted, not by <b>hypothetical</b> <b>reasonings,</b> but the clear evidence of the most decisive facts? Society not only exists, but flourishes at this hour, with this superstition, in many countries, under every form of government,--in some established, in some tolerated, in others upon an equal footing. And was there no civil society at all in these kingdoms before the Reformation? To say it was not as well constituted as it ought to be is saying nothing at all to the purpose; for that assertion evidently regards improvement, not existence. It certainly did then exist; and it as certainly then was at least as much to the advantage of a very great part of society as what we have brought in the place of it: which is, indeed, a great blessing to those who have profited of the change; but to all the rest, as we have wrought, that is, by blending general persecution with partial reformation, it is the very reverse. We found the people heretics and idolaters; we have, by way of improving their condition, rendered them slaves and beggars: they remain in all the misfortune of their old errors, and all the superadded misery of their recent punishment. They were happy enough, in their opinion at least, before the change; what benefits society then had, they partook of them all. They are now excluded from those benefits; and, so far as civil society comprehends them, and as we have managed the matter, our persecutions are so far from being necessary to its existence, that our very reformation is made in a degree noxious. If this be improvement, truly I know not what can be called a depravation of society.|$|R
50|$|Elkind {{introduced}} {{the idea of}} an adolescent egocentrism, which according to him emerges {{in the midst of the}} transition to Piaget’s formal operational stage of cognition(the final stage in which the individual is capable of abstract thinking: <b>hypothetical</b> and deductive <b>reasoning).</b> Although the construct itself remains widely used in research today, there has been no supporting evidence to suggest that adolescent egocentrism follows any age related pattern (as would be suggested by the assumption that it disappears when adolescents enter the formal operational stage, which in fact some individuals never reach).|$|R
5000|$|<b>Hypothetical</b> <b>reasoning.</b> In this, the {{knowledge}} base can be divided up into many possible views, a.k.a. worlds. This allows the inference engine to explore multiple possibilities in parallel. For example, the system may want to explore the consequences of both assertions, what will be true if Socrates is a Man and what will be true if he is not? ...|$|E
50|$|The Nyaya metaphysics recognizes sixteen padarthas or {{categories}} and includes all six (or seven) {{categories of the}} Vaisheshika in the second one of them, called prameya. These sixteen categories are pramāṇa (valid means of knowledge), prameya (objects of valid knowledge), saṁśaya (doubt), prayojana (aim), dṛṣṭānta (example), siddhānta (conclusion), avayava (members of syllogism), tarka (<b>hypothetical</b> <b>reasoning),</b> nirṇaya (settlement), vāda (discussion), jalpa (wrangling), vitaṇḍā (cavilling), hetvābhāsa (fallacy), chala (quibbling), jāti (sophisticated refutation) and nigrahasthāna (point of defeat).|$|E
50|$|Our propositional {{calculus}} has ten inference rules. These rules {{allow us to}} derive other true formulas given a set of formulas that {{are assumed to be}} true. The first nine simply state that we can infer certain well-formed formulas from other well-formed formulas. The last rule however uses <b>hypothetical</b> <b>reasoning</b> in the sense that in the premise of the rule we temporarily assume an (unproven) hypothesis {{to be part of the}} set of inferred formulas to see if we can infer a certain other formula. Since the first nine rules don't do this they are usually described as non-hypothetical rules, and the last one as a hypothetical rule.|$|E
40|$|In {{this paper}} we study the {{differences}} between two logic theories for temporal reasoning, the Situation Calculus and the Event Calculus, {{and the implications of}} these differences. We construct a new formalism that combines the advantages of both Situation and Event Calculus and avoids the problems of either. The new formalism is useful for general temporal reasoning in worlds with discrete and continuous change, and enables representation {{of a wide range of}} <b>hypothetical</b> temporal <b>reasoning</b> problems. We show that both Situation and Event Calculus are instances of this new formalism. 1 Introduction The Situation Calculus ([15]) and the Event Calculus ([14]) are two well-known formalisms for temporal reasoning. Although the original versions of both formalisms were created with clearly different goals in mind and did not look alike at all, later simplified versions of both started to show more and more similarities. In [18] an Event Calculus-like time line has been incorporated [...] ...|$|R
40|$|AbstractWe {{introduce}} a logic programming language which supports <b>hypothetical</b> and counterfactual <b>reasoning.</b> The language {{is based on}} a conditional logic which enables to formalize conditional updates of the knowledge base. Due to the presence of integrity constraints, alternative revisions of the knowledge base may result from an update. We develop an abductive semantics which captures different evolutions of the knowledge base. Furthermore, we provide a goal-directed abductive proof procedure to compute the alternative solutions for a goal. We finally analyze our conditional programming language in the context of belief revision theory, and we establish a connection with Nebel's prioritized base revision...|$|R
40|$|The {{diagnosis}} of acute neuroborreliosis {{may be difficult}} if it's regarded as a "classical" infectious disease. Through a clinical case, we illustrate the difficulties met and we suggest two ways of reflexion {{to assist in the}} diagnosis: [...] firstly, we explain how the comprehension of the behavior of the pathogen agent, which is similar to a parasitic behavior, can help to choose and interpret the results of additional tests; [...] secondly, we develop practically the clinical form of Bayes's theorem to demonstrate the interest of a rational Bayesian and abductive approach which should be preferred to the classical <b>hypothetical</b> and deductive <b>reasoning.</b> info:eu-repo/semantics/publishe...|$|R
5000|$|... "There are, you say, no exceptions, in the New Testament, to your rule; that is, I suppose, unless these {{particular}} texts be such; which you think utterly improbable. You would argue, then, {{that if these}} texts were exceptions, there would be more. I do not perceive any great weight in this <b>hypothetical</b> <b>reasoning.</b> But, however plausible it may appear, the reply is at hand. There are no other words so likely to yield exceptions; {{because there are no}} other words, between which the insertion of the copulative, would effect so remarkable a deviation from the established form of constructing them to express one person; and of course, would so pointedly suggest a difference of signification." ...|$|E
50|$|An early {{example of}} the first {{approach}} was the Simkit tool developed by Intellicorp in the 1980s. Simkit was developed on top of Intellicorp's Knowledge Engineering Environment (KEE). KEE was a very powerful knowledge-based systems development environment. KEE started on Lisp and added frames, objects, and rules, as well as powerful additional tools, such as <b>hypothetical</b> <b>reasoning</b> and truth maintenance. Simkit added stochastic simulation capabilities to the KEE environment. These capabilities included an event model, random distribution generators, simulation visualization, and more. The Simkit tool was an early example of KBE. It could define a simulation in terms of class models and rules and then run the simulation as a conventional simulation would. Along the way, the simulation could continue to invoke rules, demons, and object methods, providing the potential for much richer simulation as well as analysis than conventional simulation tools.|$|E
5000|$|The Nyaya {{school of}} Gautama speaks of five-membered {{inference}} or [...] "pararthanumana". Knowledge of vyapti {{is considered by}} this school to {{be the cause of}} successful inference because inference depends upon the unconditional universal concomitance between the middle term and the major term, the middle term indicating the existence of the major term, and {{is to be found in}} the minor term or [...] "paksa", the subject of inference. It is not possible to perceive all instances of the middle term and the major term nor can vyapti be known by internal perception. In order for the inference to be sound the major and the minor premises have to be true, the former should be secure because the latter’s truth is given by perception. They hold the view that vyapti is the unconditional uniform relation of the reason to the predicate and that a condition pervades the predicate. Faulty reasons such as inconclusive ("savyabhicara"), contradictory ("viruddha"), counterbalanced ("prakaranasama"), unproved ("sadhyasama"), and mistimed ("atitkala") or contradicted ("badhita) hinder the production of a valid inference when they are known. Vyapti is known by the joint method of agreement in presence and agreement in absence based on repeated observation aided by favourable <b>hypothetical</b> <b>reasoning.</b> Doubt about vyapti and certainty of the absence of vyapti act as hindrances to inferential knowledge; the certainty about vyapti is the cause of inferential knowledge.|$|E
40|$|We {{present a}} logic {{programming}} language, GCLA (Generalized horn Clause LAnguage), {{that is based}} on a generalization of Prolog. This generalization is unusual in that it takes a quite different view of the meaning of a logic program [...] a "definitional" view rather than the traditional logical view. GCLA has a number of noteworthy properties, for instance <b>hypothetical</b> and non-monotonic <b>reasoning.</b> This makes implementation of reasoning in knowledge-based systems more direct in GCLA than in Prolog. GCLA is also general enough to incorporate functional programming as a special case. GCLA and its syntax and semantics are described. The use of various language constructs are illustrated with several examples. Revised version of R 89005. Original report number R 89005 B. </p...|$|R
40|$|The primary {{objective}} {{of this paper is}} to revisit and make a case for the merits of R. A. Fisher's objections to the decision-theoretic framing of frequentist inference. It is argued that this framing is congruent with the Bayesian but incongruent with the frequentist inference. It provides the Bayesian approach with a theory of optimal inference, but it misrepresents the theory of optimal frequentist inference by framing inferences solely in terms of the universal quantifier `for all values of theta in the parameter space'. This framing is at odds with the {{primary objective}} of model-based frequentist inference, which is to learn from data about the true value of theta (unknown parameter(s)); the one that gave rise to the particular data. The frequentist approach relies on factual (estimation, prediction), as well as <b>hypothetical</b> (testing) <b>reasoning</b> whose primary aim is to learn from data about the true theta. The paper calls into question the appropriateness of admissibility and reassesses Stein's paradox as it relates to the capacity of frequentist estimators to pinpoint the true theta. The paper also compares and contrasts loss-based errors with traditional frequentist errors, such as coverage, type I and II; the former are attached to θ, but the latter to the inference procedure itself...|$|R
40|$|A unified {{framework}} is developed for representation of, and reasoning about dynamic games. A game {{is described by}} the subjective knowledge of players at hypothetical situations—the epistemic game form. Subjective knowledge—termed confidence—allows us to replace objective <b>reasoning</b> about <b>hypothetical</b> events with <b>reasoning</b> about the confidence of hypothetical identities, i. e., the subjective reasoning of players in hypothetical situations. This leads to an endogenous definition for players’ action sets. Applying subjective reasoning to games such as the “Beer–Quiche ” signaling game, provides a characterization of the dynamic reasoning by players {{that leads to the}} suggested solutions for these games. For perfect information games we find that rationality and common confidence of future rationality imply backward induction, although common confidence of rationality can logically contradict the definition of the game...|$|R
40|$|A gesture {{towards the}} gist Adopting a {{particular}} perspective on ellipsis pushes us toward Transformational analyses of linguistic phenomena, {{but in addition}} to ‘movement’, we need <b>Hypothetical</b> <b>reasoning,</b> which is, derivationally speaking, the ‘mirror image ’ of movement. Can <b>hypothetical</b> <b>reasoning</b> be linked up with some linguistic phenomenon, or is it just a technical tool? Here we explore the possibility that <b>Hypothetical</b> <b>reasoning</b> [...] is association with focu...|$|E
40|$|Abstract. <b>Hypothetical</b> <b>reasoning</b> is an {{important}} framework for knowledge-based systems because it is theoretically founded and useful for many practical problems. Since the inference time of <b>hypothetical</b> <b>reasoning</b> grows exponentially with respect to problem size, its ineciency becomes the most crucial problem when applied to practical problems. In this paper, we develop a new framework for <b>hypothetical</b> <b>reasoning</b> that uses paral-lel software processors. Our earlier SL method, which can nd a near-optimal solution for cost-based <b>hypothetical</b> <b>reasoning</b> in polynomial time (with respect to problem size), uses both linear programming and nonlinear programming techniques. In the new method, these techniques are realized as the interaction of parallel processors. Taking this approach, we may generalize related methods such as the breakout method or Gu's nonlinear optimization method for SAT problems, and introduce two superior algorithms. One algorithm {{is similar to the}} breakout method, and the other achieves good-quality solutions by adding new processors during search iterations...|$|E
40|$|<b>Hypothetical</b> <b>{{reasoning}}</b> or reasoning under assumptions {{is a key}} {{concept of}} logic, philosophy of science and mathematics. The Conference on <b>Hypothetical</b> <b>Reasoning</b> focussed on its logical aspects, such as assumption-based calculi and their proof theory, logical consequence from a proof-theoretic or model-theoretic point of view, logics of conditionals, proof systems, structure of assumption-based proofs, hypotheses in proof-theoretic semantics, notions of implication, substructural logics, hypotheses in categorial logic, logical aspects of scientific explanation, <b>hypothetical</b> <b>reasoning</b> in mathematics and reasoning from definitions and axioms. The conference took place 23 – 24 August, 2014 in Tübingen at the Department of Philosophy, in conjunction with ESSLLI 2014. The proceedings collect abstracts, slides and papers of the presentations given...|$|E
40|$|This paper {{describes}} an {{implementation of a}} small knowledge-based system in GCLA II. GCLA II is perhaps best described as a logical programming language, with some properties usually found among functional languages, and it includes <b>hypothetical</b> and non-monotonic <b>reasoning</b> as integral parts, which {{makes it easy to}} handle hypothetical queries, negation and AI-techniques like simulation and planning in a natural way. It also makes implementation of reasoning in knowledge-based systems (KBS) more direct than in Prolog. The application is an already existing KBS that guides a service technician in the task of diagnosing a specific device which is a measuring instrument for testing telecommunications equipment. The method used in the application is a problem solving method called TDFL. The TDFL method is a task specific problem solving method for technical diagnosis that gives strong support for knowledge acquisition. The method is adapted to cope with some features of the appl [...] ...|$|R
40|$|The {{teaching}} and learning of quantum mechanics is very frequently postponed until relatively late in a student’s academic career. In U. S. universities students typically receive a quick introduction to some aspects of one-dimensional quantum mechanics {{from the end of}} the second or beginning of the third year of their university studies and then do not study quantum mechanics in any depth until the fourth year. Thus, the major concepts which have driven much of the development of physics and of modern technology during the 20 th century are delayed until the end of a physicist’s academic career and are frequently not studied by other students at any time during their careers. One reason for this delay is the rather abstract nature of quantum mechanics itself. We can easily argue that, for the way in which quantum mechanics is traditionally taught, students need to have generally developed their formal reasoning skills. For example, formal operations, in the Piagetian sense, include <b>hypothetical</b> and deductive <b>reasoning,</b> abstract thought, use of symbolic representation, and the use of transformations. Quantum mechanics is a hypothetical system for understanding very small objects. It relies heavily on the use of symbolic representations and deduction to apply quantum mechanics to a variety of situations. Symmetry arguments, and therefore transformations, are a significant part of many presentations of quantum mechanics. Therefore overall, we can assume that the traditional mod...|$|R
40|$|Objective: Contemporary {{healthcare}} requires {{physicians to}} have well developed ethical judgment skills {{in addition to}} excellent clinical skills. However, no consensus has been reached on how to best teach ethical judgment skills during medical training. Previous studies revealed inconclusive results and applied varying theoretical frameworks. To date, the students’ perspectives on their development in ethical judgment has received less attention. Better insights in the learners’ experiences can help to improve educational interventions in medical ethics. Methods: A vignette featuring a challenging case with opposing views between a patient’s parents and a physician followed by a questionnaire was presented to a cohort of medical students at a German medical school at three points in time during their medical training (Year 1, 2 and 5). The questionnaire included closed and open-ended questions addressing the participant’s preferred, <b>hypothetical</b> actions, their <b>reasoning</b> {{as well as the}} resources informing their reasoning. Content analysis was used for qualitative data; frequencies and percentages were used to describe quantitative findings. Results: The response rate remained stable (28 %) over the study period. Participants’ responses changed overtime. Accepting parents’ autonomy in the decision-making process was the majority standpoint of students in year 1 and 2 and became less often cited in year 5 (Year 1 / 2 / 5 : 68 / 67 / 48 %). On the contrary, not readily following the parents’ decision for medical reasons was a minority standpoint in year 1 and became more prevalent over time (year 1 / 2 / 5 : 12 / 17 / 42 %). Judgments were only partly based on ethics training. Instead, participants drew on experiences from their clinical clerkships and their personal lives. Throughout the study, participants did not feel well-prepared to make a judgment in the case (Average 2. 7 on a Likert-Scale; 1 =very well prepared, 4 =very poor). Conclusions: Over the course of their medical training, the participants seemed to increasingly frame the presented vignette as a medical problem. To optimize the development of ethical judgment teaching of ethics should be more integrated in clinical teaching. In addition to the analysis of rare and extreme cases, teaching ethics should also expand on challenges students and junior doctors commonly encounter themselves to promote ethical sensitivity and confidence in students...|$|R
40|$|<b>Hypothetical</b> <b>reasoning</b> is {{a useful}} knowledge-processing {{framework}} applicable to many problems including system diagnosis, design, etc. However, due to its non-monotonic inference nature, it takes exponential computation-time {{to find a solution}} hypotheses-set to prove a given goal. This is also true for cost-based <b>hypothetical</b> <b>reasoning</b> to find an optimal solution with minimal cost. As for the <b>hypothetical</b> <b>reasoning</b> expressed in propositional logic, since it is easily transformed into 0 - 1 integer programming problem, a polynomial-time method finding a near-optimal solution has been developed so far by employing an approximate solution method of 0 - 1 integer programming called the Pivot and Complement method. Also, by reforming this method, a network-based inference mechanism called Networked Bubble Propagation (NBP) has been invented by the authors, which allows even faster inference. More importantly, a network-based approach is meaningful, for its potential of being developed extending to a broader framework of knowledge processing. In this paper, we extend the NBP method to dealing with the <b>hypothetical</b> <b>reasoning</b> expressed with predicate logic. By constructing a series of knowledge networks, to which the NBP method is applied, in a stepwise manner according to a top-down control, we avoid the excessive expansion of the network size. As a result, we can achieve a polynomial time inference for computing a near-optimal solution for the cost-based <b>hypothetical</b> <b>reasoning</b> in predicate-logic knowledge...|$|E
40|$|In this paper, it is {{discussed}} to which extent <b>hypothetical</b> <b>reasoning</b> can be modeled by formal logics. The paper starts by exploring this idea in general (Section 1 and 2), {{which leads to}} the conclusion that in order to model this kind of reasoning formally, a more ne-grained classica- tion of reasoning patterns is in order. After such a classication is provided in Section 3, a formal framework that has proven successful to capture some of these patterns is described (Sections 4 and 6) and some of the specic problems for this procedure are discussed (Section 5). The paper concludes by presenting two logics for <b>hypothetical</b> <b>reasoning</b> in an informal way (Sections 7 and 8) such that the non-technically skilled reader can get a flavour how formal methods can be used to describe <b>hypothetical</b> <b>reasoning...</b>|$|E
40|$|For propositional-level <b>hypothetical</b> <b>reasoning</b> (or abduction), {{particularly}} for its cost-based variant, some efficient {{methods have been}} developed which achieve polynomial-time reasoning (with respect to problem size) to compute a near-optimal solution. However, for predicate-logic version <b>hypothetical</b> <b>reasoning,</b> which allows rich and compact knowledge representation, it seems {{difficult to find a}} method with polynomial-order efficiency, as long as we stick to symbolic manipulation. As a result, there exists no efficient method in the predicate logic domain so far. A naive approach for efficient predicate-logic version <b>hypothetical</b> <b>reasoning</b> might work as follows: knowledge expressed by predicate logic is first transformed into propositional knowledge, and then an efficient method is applied to the propositional knowledge base. If the knowledge base is function-free, this can be accomplished by instantiating variables to elements of the Herbrand universe (in this case simply a finite se [...] ...|$|E
40|$|This thesis {{concerns}} with intelligent autonomous software agents that populate open computational environments, {{in which they}} interact for various purposes, e. g. competitively {{in the case of}} auctions or resource allocation problems, collaboratively in the case of distributed problem solving or parallel processing, joint planning, etc. We use the term open to characterize a computational environment in Hewitt’s sense, that is to describe an environment that is dynamic, continuous, unobservable (or, at best, partially observable) and non-deterministic. Agents in such environments possess, unavoidably, information that is incomplete, imprecise, maybe even incorrect, due to the very fact that the environment is open and, at the very least, agents join and leave it as they please. The information exchanged between agents may be delayed, or distorted by noise during its communication, and in any case, as the environment evolves, it is bound to change. The interactions among agents in any multi-agent system are typically governed by norms. These may refer to restrictions on communication means among agents, or to particular coordination mechanisms, liveness and safety properties of the system etc. In some application areas, such as ecommerce, additional norms may regulate the agents’ behaviours, resulting from agreements into which the agents enter willingly, and possibly from the protocol that governs the e-market. Norms prescribe what each agent is obliged, permitted, prohibited, empowered and so on, to do during its life in the particular environment. Autonomous agents decide for themselves which norms to subject itself to and whether to comply with the norms of their environment. This decision-making is all the more challenging when an agent has to perform it in circumstances where its available knowledge is incomplete/imprecise/incorrect. This thesis addresses the need and requirement for common-sense reasoning agents in open computational environments. We discuss and illustrate our proposals with reference to an e-commerce example. First, based on the example scenario, we identify the requirements for the representation of the norms that govern the environment and the specifications for the environment itself. Nevertheless, our proposals are generally applicable to any case where multiple agents interact and their interaction is governed by some contract as a coordination or collaboration mechanism. Primarily, this thesis examines and motivates the need of agents to fill in information gaps by resorting to assumptions. Agents {{need to be able to}} identify and use assumptions dynamically, in any open computational environment, as well as in the particular application context of an e-commerce example. We present a novel approach to dynamic assumption identification and <b>hypothetical</b> nonmonotonic <b>reasoning</b> inspired by the syntax and semantics of Default Logic, without however resorting to proof, which is notably computationally hard. We discuss in detail what distinguishes our approach from other work on dynamic assumption based reasoning, namely i. e., we do not resort to a prespecified pool of assumptions, nor to goal-orientation as a means to identify candidate assumptions. In this way, we claim, an agent is autonomous in deciding which assumptions are appropriate, given its knowledge-hypotheses requirements at any given time. We propose symbolic and schematic representations to characterize formally the possible knowledge-hypotheses status of an agent, and we use their properties to characterize their dynamics. From these formal characterizations we derive and present the algorithms that support our approach, which we have implemented in a prototype. ...|$|R
40|$|This paper {{presents}} {{a language of}} update programs that integrates logical queries, bulk updates and <b>hypothetical</b> <b>reasoning</b> in a seamless manner. There is no syntactic or semantic distinction between queries and updates. Update programs extend logic programs with negation in both syntax and semantics. Users can specify bulk updates in which an arbitrary update is applied simultaneously for all answers of an arbitrary query. <b>Hypothetical</b> <b>reasoning</b> is naturally supported by testing {{the success or failure}} of an update. We describe an alternating fixpoint semantics of update programs and show that it can express all nondeterministic database transformations. Current techniques of logical query evaluation can be generalized for effective execution of updates. Keywords: bulk updates, <b>hypothetical</b> <b>reasoning,</b> logical queries, alternating fixpoint semantics, database languages. 1 Introduction Updates play an important role in modeling dynamic behaviors in database systems [1, 24]. Various lang [...] ...|$|E
40|$|AbstractThe aim of {{this paper}} is to build the {{relationship}} between deductive databases with incomplete information and <b>hypothetical</b> <b>reasoning</b> using embedded implications. We first consider the semantics of deductive databases with incomplete information in the form of null values. We motivate query answering against a deductive database with nulls as the problem of extracting the maximal information from a (deductive) database in response to queries, and formalize this in the form of conditional answers in a (syntactic) higher-order logic. We give a fixpoint semantics to deductive databases with nulls, and examine the relationship between existing recursive query processing techniques and the proof procedure for deductive databases with nulls. We then examine <b>hypothetical</b> <b>reasoning</b> using embedded implications and develop an intuitionistic model semantics for embedded implications with integrity constraints. Finally, we illustrate by example a method for transforming embedded implications into deductive databases with nulls. This result shows that the important functionality of <b>hypothetical</b> <b>reasoning</b> can be implemented within the framework of deductive databases with null values...|$|E
