1692|6425|Public
5000|$|<b>Data</b> <b>evaluation,</b> {{interpretation}} and formulation of recommendations ...|$|E
50|$|He was {{involved}} in the <b>data</b> <b>evaluation</b> of the Giotto, Stardust, and Solar and Heliospheric Observatory missions.|$|E
50|$|This {{type of data}} usually brings complex {{procedures}} of <b>data</b> <b>evaluation</b> and migration between the storage tiers.|$|E
40|$|<b>Data</b> quality <b>evaluation</b> {{is one of}} {{the most}} {{critical}} steps during the data mining processes. Data with poor quality often leads to poor performance in data mining, low efficiency in data analysis, wrong decision which bring great economic loss to users and organizations further. Although many researches have been carried out from various aspects of the extracting, transforming, and loading processes in data mining, most researches pay more attention to analysis automation than to <b>data</b> quality <b>evaluation.</b> To address the <b>data</b> quality <b>evaluation</b> issues, we propose an approach to combine human beings' powerful cognitive abilities in <b>data</b> quality <b>evaluation</b> with the high efficiency ability of computer, and develop a visual analysis method for <b>data</b> quality <b>evaluation</b> based on visual morphology. © 2012 IEEE. IEEE Visualization and Graphics Technical Committee (VGTC) <b>Data</b> quality <b>evaluation</b> {{is one of the}} most critical steps during the data mining processes. Data with poor quality often leads to poor performance in data mining, low efficiency in data analysis, wrong decision which bring great economic loss to users and organizations further. Although many researches have been carried out from various aspects of the extracting, transforming, and loading processes in data mining, most researches pay more attention to analysis automation than to <b>data</b> quality <b>evaluation.</b> To address the <b>data</b> quality <b>evaluation</b> issues, we propose an approach to combine human beings' powerful cognitive abilities in <b>data</b> quality <b>evaluation</b> with the high efficiency ability of computer, and develop a visual analysis method for <b>data</b> quality <b>evaluation</b> based on visual morphology. © 2012 IEEE...|$|R
30|$|EA Pritts: protocol/project development, <b>data</b> {{collection}} and <b>evaluation,</b> <b>data</b> analysis, and manuscript writing/editing.|$|R
40|$|Neutron {{scattering}} {{measurements are}} made using {{an array of}} proton recoil detectors surrounding a scattering sample, which is struck by a beam of neutrons. Detector signals are analyzed using {{a state of the}} art digital data acquisition system, and these measurements are compared with the expected detector response based on Monte Carlo simulation of the scattering experiment using existing nuclear <b>data</b> <b>evaluations.</b> In this way, high accuracy neutron scattering experimental benchmarks, combined with high accuracy Monte Carlo simulations, can be used to assess differences among nuclear <b>data</b> <b>evaluations.</b> Experiments were done with C, Be and Mo samples. There is excellent agreement for C, while Be and Mo show differences between the experiments and calculations using ENDF/B-VII. ...|$|R
50|$|He {{is author}} or co-athor of around 50 {{international}} publications. The topics cover field of chemistry which {{are related to}} computer simulations or mathematics, e.g. modelling of condensed matter, molecular dynamics and Monte Carlo simulations, Reverse Monte Carlo simulations, <b>data</b> <b>evaluation,</b> chemometrics and numerical methods.|$|E
50|$|The Therapist Multiple-Choice Examination {{consists}} of 160 multiple-choice questions (140 scored items and 20 pretest items) distributed among three major content areas: Patient <b>Data</b> <b>Evaluation</b> and Recommendations, Troubleshooting and Quality Control of Equipment and Infection Control, and Initiation and Modification of Interventions. Candidates are given {{three hours to}} complete the TMC Examination.|$|E
50|$|For a decade, the SHSC, {{offered a}} {{dedicated}} insurance program for social housing providers, bulk gas purchasing and an innovative energy efficiency retrofit program which coordinated energy audits, expertise, funding, bulk purchasing of energy-efficient goods, training and education, and <b>data</b> <b>evaluation</b> through its three subsidiaries—SOHO Tenant Insurance, SHSC Financial Inc. and GLOBE (Green Light on a Better Environment).|$|E
3000|$|... aPlease {{note that}} for all {{long-term}} ASM <b>data</b> <b>evaluations,</b> no ASM <b>data</b> {{is available on the}} Swarm Charlie satellite since 5 November 2014 when an ASM instrument anomaly occurred. This event is currently under investigation and prevents any new ASM data delivery on Swarm Charlie.|$|R
40|$|The Hauser-Feshbach codes, EMPIRE, TALYS, CCONE, and CoH 3, {{which are}} widely {{utilized}} in nuclear <b>data</b> <b>evaluations,</b> are compared, {{with a particular}} focus on neutron-induced reactions on major actinides. We report the results of Hauser-Feshbach calculations using well-defined input parameters, and discuss the differences among these codes...|$|R
40|$|Abstract—We {{consider}} {{the problem of}} gathering <b>data</b> for <b>evaluation</b> of given hypotheses, and describe a method for analyzing tradeoffs between the expected utility {{and the cost of}} data collection. Keywords—Uncertainty, hypothesis <b>evaluation,</b> <b>data</b> gathering, Bayesian reasoning, artificial intelligence. W I...|$|R
50|$|ISO 14698-2 became {{available}} to the public in October 2003. ISO 14698-2 gives guidance on basic principles and methodological requirements for all microbiological <b>data</b> <b>evaluation,</b> and the estimation of biocontamination data obtained from sampling for viable particles in zones at risk, as specified by the system selected. This is not intended for testing the performance of microbiological counting techniques of determining viable units.|$|E
50|$|The Goddard Center's <b>Data</b> <b>Evaluation</b> Laboratory has {{the only}} known {{surviving}} piece of equipment which can read the missing tapes and was set to be closed in October 2006, causing some fear that, even if the tapes were later found, {{there would be no}} ready way to read and copy them. However, equipment that could read the tapes was maintained.|$|E
50|$|The Weihenstephan Standards (WS) are {{communication}} interfaces for machine data acquisition. Currently libraries have been realised for connecting bottling and packaging plants (WS Pack) and machines for food processing (WS Food) with higher-level systems, such as data acquisition systems (SCADA) or Manufacturing Execution Systems (MES). In the Weihenstephan Standards, the physical interface specification, specification of the interface content, recommendations for <b>data</b> <b>evaluation</b> and reporting are defined.|$|E
40|$|Computational {{methods and}} data used for {{sensitivity}} and uncertainty analysis within the SCALE nuclear analysis code system are presented. The methodology used to calculate sensitivity coefficients and similarity coefficients and to perform nuclear data adjustment is discussed. A description is provided of the SCALE- 6 covariance library based on ENDF/B-VII and other nuclear <b>data</b> <b>evaluations,</b> supplemented by “low-fidelity ” approximate covariances. I...|$|R
40|$|This {{document}} {{is the second}} part of a comprehensive study designed to review child development <b>data</b> and program <b>evaluation</b> <b>data</b> so that proposals for Federal program planning can be made. This section (Volume 2) consists of rive chapters that review project <b>evaluation</b> <b>data</b> in the five major modes of child intervention. Chapter 1 looks at <b>evaluation</b> <b>data</b> of Federally sponsored early childhood education programs, including Follow Through, the national network of Research and Development Centers, and Performance Contracts experiments. Chapter 2 focuses on preschool intervention of the sort now implemented under Head Start. chapter 3 reviews current knowledge about the influence of day care on child development, when intervention occurs with children between 0 - 3 years. Chapter 4 is concerned with family intervention, based on <b>evaluation</b> <b>data</b> of programs involved in parent education, parent training, family therapy, and provision of social services. The final chapter reviews <b>data</b> arising from <b>evaluation</b> of health care projects. (DP) fgt, [...] . v.,. h,'e.,. r- 4 FEDERAL PROGRAMS te...|$|R
40|$|X-ray-absorption near-edge {{structure}} <b>data</b> <b>evaluations,</b> {{based on}} a simple approach to determine bond lengths directly from features of the spectra, have frequently {{been reported in the}} literature. This approach is discussed critically taking into account multiple-scattering calculations as well as previously published experimental and theoretical data. All results together demonstrate that this approach can be used for simple molecules, but becomes questionable for condensed-matter analysis...|$|R
5000|$|His main {{scientific}} {{contributions are}} {{in the field of}} molecular spectroscopy applied to the Earth's atmosphere: laboratory measurements of unstable and reactive molecules and radicals, <b>data</b> <b>evaluation</b> for international databases e.g. HITRAN, preparation and use of remote-sensing satellite missions (GOME, SCIAMACHY, MIPAS, MetOp, MTG ...) to observe stratospheric chemistry, tropospheric air quality and processes of relevance for climate, as well as the development of sensitive in-situ measurements techniques like IBBCEAS.|$|E
50|$|JACDEC {{stands for}} Jet Airliner Crash <b>Data</b> <b>Evaluation</b> Centre, {{providing}} global safety analysis about commercial aviation since 1989. The German founders Jan-Arwed Richter and Christian Wolf {{have written a}} number of books about aviation accidents Jacdec books. Since 2002 JACDEC developed under that term social research a global as a service, detailed information about an airline are with costs. The JACDEC Safety Index was developed from their own database. The Centre also monitors current safety occurrences and provides updates on airline safety issues in social networks.|$|E
50|$|In January 2013, the Jet Airliner Crash <b>Data</b> <b>Evaluation</b> Centre (JACDEC) {{determined}} that TAM Airlines had the second worst safety {{record in the}} world. The ratings {{take into account the}} number and deadliness of the hull losses (destroyed airplanes) they have suffered in the past 30 years, how they have fared more recently, and how many flights they have flown without incident. The results do {{not take into account the}} cause of the hull losses, or whether the airline is at fault, so they are not a perfect measure of how safely an airline behaves.|$|E
30|$|As {{provenance}} is a {{key factor}} for <b>data</b> trustworthiness <b>evaluation</b> in WSNs, {{it needs to be}} protected.|$|R
40|$|Within the ENIFAIR {{research}} program high speed tests {{were carried out}} in the ONERA S 1 wind tunnel. The main objective of these tests was to determine the installation drag level of three different engine simulators installed on the DLR ALVAST model. In the report <b>data</b> <b>evaluations</b> will be described, which are necessary to explain the unusual jet effects on the drag behaviour, detected in the experimental results...|$|R
40|$|The {{branching}} of the 2 + to 0 + {{transition in}} 92 Sr has been measured to 0. 032 (4) per 92 Rb decay. It confirms an earlier measurement however discarded in nuclear <b>data</b> <b>evaluations</b> since in contradiction with accepted lower logft limits. The conflict could be solved assuming {{that close to}} half of the decay intensity, mostly as high-energy ground-state transitions, is missing in th edecay scheme...|$|R
50|$|Mark Norell is {{the direct}} {{discoverer}} of the enigmatic theropod Shuvuuia, co-led {{the group that}} discovered Ukhaa Tolgod, the richest Cretaceous terrestrial vertebrate fossil locality in the world, discovered the first embryo of a theropod dinosaur, described a series of dinosaurs with feathers, and discovered the first direct evidence of dinosaur brooding. Norell's theoretical work has a focus of <b>data</b> <b>evaluation</b> in large cladistic sets, as well as fossil pattern estimation through phylogeny, {{in order to see}} trends in diversity and extinction. He has authored several papers that discuss the relationship between stratigraphic position and phylogenetic topology.|$|E
50|$|With {{an annual}} budget of $4.5 million, SHSC and its two subsidiaries, SOHO and SHSC Financial Inc. offers a {{dedicated}} insurance program for social housing providers, bulk gas purchasing and an innovative energy efficiency retrofit program that coordinates energy audits, expertise, funding, bulk purchasing of energy-efficient goods, training and education, and <b>data</b> <b>evaluation.</b> SHSC manages and provides investment advice to housing providers on capital reserves valued at more than $390 million. Working closely with other housing sector organizations and non-governmental organizations, SHSC also supports and develops independent housing-related research, including a new Housing Internship program for graduate-level researchers.|$|E
50|$|On 23 January 2013, the Jet Airliner Crash <b>Data</b> <b>Evaluation</b> Centre (JACDEC) {{announced}} that Gol Airlines had the fourth worst safety {{record in the}} world. The ratings {{take into account the}} number and deadliness of the hull losses (destroyed airplanes) they have suffered in the past 30 years, how they have fared more recently, and how many flights they have flown without incident. The results do {{not take into account the}} cause of the hull losses, or whether the airline is at fault, so they are not a perfect measure of how safely an airline behaves. It should be noted that since Gol is a relatively young airline with only one hull loss, but with a large number of casualties (Flight 1907), that single fatal accident significantly affects the calculation.|$|E
40|$|The European {{approach}} {{for the development}} of nuclear data for fusion technology applications is presented. Related R&D activities are conducted by the Consortium on Nuclear Data Development and Analysis for Fusion to satisfy the nuclear data needs of the major projects including ITER, the Early Neutron Source (ENS) and DEMO. Recent achievements are presented in the area of nuclear <b>data</b> <b>evaluations,</b> benchmarking and validation, nuclear model improvements, and uncertainty assessments...|$|R
40|$|<b>Evaluation</b> {{of nuclear}} <b>data</b> {{typically}} includes {{validation of the}} data through computation of k{sub eff}for critical assemblies. The sensitivity of the computed k{sub eff} values to the nuclear data is used as an indicator in determining the adequacy of an evaluation. Subcritical measurements offer an alternative to critical experiments {{as a means to}} evaluate nuclear data through direct computation of subcritical measurement quantities. In some instances, the subcritical measurement quantities are more sensitive to nuclear data changes than the computed k{sub eff} values. Simulations of subcritical source-driven noise measurements were performed for highly enriched uranium metal cylinders and highly enriched uranyl nitrate solutions to demonstrate the sensitivity of the computed subcritical quantities to nuclear data. A particular ratio of spectral quantities from the source-driven noise measurements is of interest because of its independence of detection efficiency and source intensity. These simulations indicate that the spectral ratio is more sensitive to nuclear <b>data</b> <b>evaluations</b> than the computed k{sub eff} values for these systems. Direct simulation of subcritical measurements offers additional means to validate nuclear <b>data</b> <b>evaluations...</b>|$|R
40|$|The SAMINT {{methodology}} allows coupling {{of differential}} and integral <b>data</b> <b>evaluations</b> in a continuous-energy framework. Prior to {{development of the}} SAMINT code, integral experimental data {{such as in the}} International Criticality Safety Benchmark Experiments Project remained a tool for validation of completed nuclear <b>data</b> <b>evaluations.</b> Now, SAMINT extracts information from integral benchmarks in the form of calculated sensitivity coefficients by Monte Carlo codes such as CE TSUNAMI- 3 D or MCNP 6 and combines it with the results of experimental cross section measurements to produce an updated cross section evaluation utilizing information from both sets of data. The use of the generalized linear least squares methodology ensures that proper weight is given to both the differential and integral data. SAMINT is not intended to bias nuclear data toward specific integral experiments, but it should be used to supplement evaluation of differential experimental data. This work demonstrates the application of the SAMINT methodology to the new Oak Ridge National Laboratory (ORNL) evaluations of the resonance parameters for two isotopes of copper: 63 Cu and 65 Cu...|$|R
50|$|Other NAVFACs {{were located}} in the Pacific at Naval Air Station Barbers Point, Hawaii; Naval Air Facility Midway; and Naval Base Guam, while {{additional}} Atlantic locations expanded to include Naval Air Station Keflavik, Iceland; CFS Shelburne, Nova Scotia and Naval Station Argentia, Newfoundland (both later remoted to CFB Halifax, Nova Scotia); Naval Facility Brawdy, Wales; Joint Maritime Facility St. Mawgan, Cornwall; Antigua; Maritime Data Centre Gibraltar, UK; Naval Facility Barbados; Naval Facility Eleuthera, Bahamas; Naval Facility San Salvador, Bahamas; Naval Facility Bermuda; and Naval Facility Grand Turk. Evaluation Centers were also set up at Naval Air Station Whidbey Island, Washington and Naval Air Station Oceana, Virginia in the early 1980s. The <b>Data</b> <b>Evaluation</b> Center at Dam Neck was named after Commander Will James whose entire Navy career was spent in the system.|$|E
5000|$|Randomness tests (or {{tests for}} randomness), in <b>data</b> <b>evaluation,</b> {{are used to}} analyze the {{distribution}} of a set of data to see if it is random (patternless). In stochastic modeling, as in some computer simulations, the hoped-for randomness of potential input data can be verified, by a formal test for randomness, to show that the data are valid for use in simulation runs. In some cases, data reveals an obvious non-random pattern, as with so-called [...] "runs in the data" [...] (such as expecting random 0-9 but finding [...] "4 3 2 1 0 4 3 2 1..." [...] and rarely going above 4). If a selected set of data fails the tests, then parameters can be changed or other randomized data can be used which does pass the tests for randomness.|$|E
40|$|We {{developed}} a <b>data</b> <b>evaluation</b> technique that allows to evaluate dynamically {{a kind of}} reliability of data from sensors by the redundancy among process variables. In this paper, we extend the <b>data</b> <b>evaluation</b> {{so that it can}} diagnose not only sensor faults but also process faults, taking reliability of the constraints (such as balance equations) into account. Further, the extended <b>data</b> <b>evaluation</b> is combined with data reconciliation technique to handle the situation when both measurement error and gross error may exist. On one hand, when gross error exist, <b>data</b> <b>evaluation</b> is used to filter out inadequate constraints used in data reconciliation. On the other hand, when measurement error exist, data reconciliation is used to filter out noise, hence provides <b>data</b> <b>evaluation</b> with clean relation among data. It is demonstrated by simulations that the combined method greatly enhance diagnostic performance than both methods are applied independently. ...|$|E
30|$|To further {{examine the}} {{contributions}} of these two criteria, session-to-session transfers are performed using the training session which has the best classification result in the cross-validation for each subject. As the independent <b>evaluation</b> <b>data</b> are recorded on a different day than the training sessions, EEG signals of the subjects may change significantly from the training <b>data</b> to the <b>evaluation</b> <b>data.</b> This test aims at evaluating the robustness of the methods to non-stationary signals.|$|R
40|$|Good <b>data</b> {{sets for}} <b>evaluation</b> of {{computer}} vi-sion algorithms {{are important for}} the continued progress of the field. There exist good evaluation sets for many applications, {{but there are others}} for which good evaluation sets are harder to come by. One such example is feature tracking, where there is an obvious difficulty in the collection of <b>data.</b> Good <b>evaluation</b> <b>data</b> is important both for comparisons of different algorithms, and to detect weaknesses in a specific method. All image data is a result of light interacting with its environment. These interactions are so well modelled in rendering software that sometimes not even the sharpest human eye can tell the dif-ference between reality and simulation. In this pa-per we thus propose to use a high quality rendering system to create <b>evaluation</b> <b>data</b> for sparse point correspondence trackers. ...|$|R
40|$|The {{aim of this}} master {{thesis is}} to analyze the social media {{engagement}} of the FMCGs (Fast Moving Consumer Goods) in Austria. The used methodologies are literature studies, Internet searches as well as internal <b>data</b> <b>evaluations</b> of the FMCG clients of a marketing agency. The thesis analyses selected key success factors on Social Media focusing on facebook, evaluates their development in the monitored period, and recommends main possibilities of future measures aiming on reaching an improvement of key indicators...|$|R
