6|13|Public
40|$|In {{order to}} {{overcome}} the limitation of traditional nonnegative factorization algorithms, the paper presents a generalized discriminant orthogonal non-negative tensor factorization algorithm. At first, the algorithm takes the orthogonal constraint into account to ensure the nonnegativity of the low-dimensional features. Furthermore, the <b>discriminant</b> <b>constraint</b> is imposed on low-dimensional weights to strengthen the discriminant capability of the low-dimensional features. The experiments on facial expression recognition have demonstrated that the algorithm is superior to other non-negative factorization algorithms...|$|E
40|$|License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. In order {{to overcome the}} limitation of traditional nonnegative factorization algorithms, the paper presents a generalized discriminant orthogonal non-negative tensor factorization algorithm. At first, the algorithm takes the orthogonal constraint into account to ensure the nonnegativity of the low-dimensional features. Furthermore, the <b>discriminant</b> <b>constraint</b> is imposed on low-dimensional weights to strengthen the discriminant capability of the low-dimensional features. The experiments on facial expression recognition have demonstrated that the algorithm is superior to other non-negative factorization algorithms. 1...|$|E
40|$|Speech {{recognition}} {{is a special}} field of pattern recognition. In order to improve the performances of the systems, one can opt for sev-eral ways and among them {{the design of a}} feature extractor. This paper presents a new nonlinear feature extraction method based on the Learning Vector Quantization (LVQ) and the Neural Predictive Coding (NPC). The key idea of this work is to design a feature ex-tractor, the NPC, by the introduction of <b>discriminant</b> <b>constraint</b> pro-vided by the LVQ classifier. The performances are estimated on a phoneme classification task by several methods: GMM, MLP, LVQ. The phonemes are extracted from the NTIMIT database. We make comparisons with linear and nonlinear feature transformation meth...|$|E
40|$|Abstract. The paper {{proposes a}} novel {{discriminant}} non-negative matrix factorization algorithm and applies it to facial expression recognition. Unlike traditional non-negative matrix factorization algorithms, the algorithm adds <b>discriminant</b> <b>constraints</b> in low-dimensional weights. The experiments on facial expression recognition {{indicate that the}} algorithm enhances the discrimination capability of low-dimensional features and achieves better performance than other non-negative matrix factorization algorithms...|$|R
40|$|Abstract. In this paper, a {{supervised}} {{feature extraction}} method having both nonnegative bases and weights is proposed. The {{idea is to}} extend the Non-negative Matrix Factorization (NMF) algorithm in order to extract features that enforce not only the spatial locality, but also the separability between classes in a discriminant manner. The proposed method incorporates <b>discriminant</b> <b>constraints</b> inside the NMF decomposition in a class specific manner. Thus, a decomposition of a face to its discriminant parts is obtained and new update rules for both the weights and the basis images are derived. The introduced methods have been applied {{to the problem of}} frontal face verification using the well known XM 2 VTS database. The proposed algorithm greatly enhance the performance of NMF for frontal face verification. ...|$|R
40|$|Non-negative Matrix Factorization (NMF) {{is among}} the most popular {{subspace}} methods widely used in a variety of image processing problems. Recently, a discriminant NMF method that incorporates Linear Discriminant Analysis criteria and achieves an efficient decomposition of the provided data to its discriminant parts has been proposed. However, this ap-proach poses several limitations since it assumes that the un-derline data distribution forms compact sets which is often un-realistic. To remedy this limitation we regard that data inside each class form various number of clusters and apply a Clus-tering based Discriminant Analysis. The proposed method combines appropriate <b>discriminant</b> <b>constraints</b> in the NMF decomposition cost function in order {{to address the problem of}} finding discriminant projections that enhance class separa-bility in the reduced dimensional projection space. Experi-mental results performed on the Cohn-Kanade database ver-ified the effectiveness of the proposed method in the facial expression recognition task. Index Terms — Non-negative matrix factorization, sub-space methods, clustering discriminant analysis, facial ex-pression recognition 1...|$|R
40|$|A novel facial {{expression}} recognition algorithm based on discriminant neighborhood preserving nonnegative tensor factorization (DNPNTF) and extreme learning machine (ELM) is proposed. A <b>discriminant</b> <b>constraint</b> is adopted {{according to the}} manifold learning and graph embedding theory. The constraint is useful to exploit the spatial neighborhood structure and the prior defined discriminant properties. The obtained parts-based representations by our algorithm vary smoothly along the geodesics of the data manifold and have good discriminant property. To guarantee the convergence, the project gradient method is used for optimization. Then features extracted by DNPNTF are fed into ELM which is a training method for the single hidden layer feed-forward networks (SLFNs). Experimental results on JAFFE database and Cohn-Kanade database demonstrate that our proposed algorithm could extract effective features and have good performance in {{facial expression}} recognition...|$|E
40|$|Abstract. We {{propose a}} novel hybrid metric {{learning}} approach to com-bine multiple heterogenous statistics for robust image set classification. Specifically, we represent each set with multiple statistics – mean, covari-ance matrix and Gaussian distribution, which generally {{complement each other}} for set modeling. However, it is not trivial to fuse them since the mean vector with d-dimension often lies in Euclidean space Rd, whereas the covariance matrix typically resides on Riemannian manifold Sym+d. Besides, according to information geometry, the space of Gaussian dis-tribution can be embedded into another Riemannian manifold Sym+d+ 1. To fuse these statistics from heterogeneous spaces, we propose a Hy-brid Euclidean-and-Riemannian Metric Learning (HERML) method to exploit both Euclidean and Riemannian metrics for embedding their original spaces into high dimensional Hilbert spaces and then jointly learn hybrid metrics with <b>discriminant</b> <b>constraint.</b> The proposed method is evaluated on two tasks: set-based object categorization and video-based face recognition. Extensive experimental results demonstrate that our method has a clear superiority over the state-of-the-art methods. ...|$|E
40|$|The distinguishment {{between the}} object {{appearance}} and {{the background is}} the useful cues available for visual tracking in which the discriminant analysis is widely applied However due to {{the diversity of the}} background observation there are not adequate negative samples from the background which usually lead the discriminant method to tracking failure Thus a natural solution is to construct an object-background pair constrained by the spatial structure which could not only reduce the neg-sample number but also make full use of the background information surrounding the object However this Idea is threatened by the variant of both the object appearance and the spatial-constrained background observation especially when the background shifts as the moving of the object Thus an Incremental pairwise discriminant subspace is constructed in this paper to delineate the variant of the distinguishment In order to maintain the correct the ability of correctly describing the subspace we enforce two novel constraints for the optimal adaptation (1) pairwise data <b>discriminant</b> <b>constraint</b> and (2) subspace smoothness The experimental results demonstrate that the proposed approach can alleviate adaptation drift and achieve better visual tracking results for a large variety of nonstationary scenes (C) 2010 Elsevier B V All rights reserve...|$|E
40|$|Abstract—Nonnegative matrix {{factorization}} (NMF) {{has proven}} to be very successful for image analysis, especially for object rep-resentation and recognition. NMF requires the object tensor (with valence more than one) to be vectorized. This procedure may result in information loss since the local object structure is lost due to vec-torization. Recently, in order to remedy this disadvantage of NMF methods, nonnegative tensor factorizations (NTF) algorithms that can be applied directly to the tensor representation of object col-lections have been introduced. In this paper, we propose a series of unsupervised and supervised NTF methods. That is, we extend several NMF methods using arbitrary valence tensors. Moreover, by incorporating <b>discriminant</b> <b>constraints</b> inside the NTF decom-positions, we present a series of discriminant NTF methods. The proposed approaches are tested for face verification and facial ex-pression recognition, where it is shown that they outperform other popular subspace approaches. Index Terms—Face verification, facial expression recognition, linear discriminant analysis, nonnegative matrix factorization (NMF), nonnegative tensor factorization (NTF), subspace tech-niques. I...|$|R
40|$|In this paper, two {{supervised}} {{methods for}} enhancing the classification {{accuracy of the}} Non-negative Matrix Factorization (NMF) algorithm are presented. The idea is to extend the NMF algorithm in order to extract features that enforce not only the spatial locality, but also the separability between classes in a discriminant manner. The first method employs discriminant analysis in the features derived from NMF. In this way, a two phase discriminant feature extraction procedure is implemented, namely NMF plus Linear Discriminant Analysis (LDA). The second method incorpo-rates the <b>discriminant</b> <b>constraints</b> inside the NMF decomposition. Thus, a decomposition of a face to its discriminant parts is obtained and new update rules for both the weights and the basis images are derived. The introduced methods have been applied {{to the problem of}} frontal face verification using the well known XM 2 VTS database. Both methods greatly enhance the performance of NMF for frontal face verification. Index Terms Subspace techniques, non-negative matrix factorization, linear discriminant analysis, frontal face verification. I...|$|R
30|$|Recently, many FER {{algorithms}} {{have adopted}} NMF. Buciu and Pitas employed NMF for FER by enforcing local constraints {{to create a}} local NMF (LMF) model [22]. Nikitidis et al. incorporated <b>discriminant</b> <b>constraints</b> to build the supervised NMF learning method [23, 24]. Based on clustering-based discriminant analysis (CDA), the algorithm in [25] efficiently decomposes the provided data to discriminant parts and successfully extended the well-known NMF to subclass discriminant NMF (SDNMF). R. Zhi et al. [26] provided another extended NMF which imposed both sparse constraints on the basis matrix and graph-preserving criterions to improve the classification performance. Interpreting expressive images into two subspaces including the identity subspace and the expression subspace was a new model investigated in dual subspace nonnegative matrix factorization (DSNMF) [27] and dual subspace nonnegative graph embedding [28]. It can be seen that, in order to extract representative expression facial features, most existing algorithms tried to integrate label information via different constraints to derive supervised NMF. Therefore, the overall performance highly depends on the expression label which is insufficient to characterize data by the variations of pose, illumination, etc.|$|R
40|$|Analysis of high {{dimensional}} data in modern applications, such as neuroscience, text mining, spectral analysis or chemometrices naturally requires tensor decomposition methods. The Tucker decompositions {{allow us to}} extract hidden factors (component matrices) with a different dimension in each mode and investigate interactions among various modes. The Alternating Least Squares (ALS) algorithms have been confirmed effective and efficient in most of tensor decompositions, especially, Tucker with orthogonality constraints. However, for nonnegative Tucker decomposition (NTD), standard ALS algorithms suffer from unstable convergence properties, demand high computational cost for large scale problems due to matrix inversion and often return suboptimal solutions. Moreover, they are quite sensitive with respect to noise, and can be relatively slow in the special case when the data are nearly collinear. In this paper, we propose a new algorithm for nonnegative Tucker decomposition based on constrained minimization {{of a set of}} local cost functions and Hierarchical Alternating Least Squares (HALS). The developed HALS NTD algorithm sequentially updates components, hence avoids matrix inversion, and is suitable for large-scale problems. The proposed algorithm is also regularized with additional constraint terms such as sparseness, orthogonality, smoothness, and especially <b>discriminant</b> <b>constraints</b> for classification problems. Extensive experiments confirm the validity and higher performance of the developed algorithm in comparison with other existing algorithms...|$|R
40|$|Abstract-Non-negative Matrix Factorization (NMF) {{is among}} the most popular {{subspace}} methods widely used in a variety of pattern recognition applications. Recently, a discriminant NMF method that incorporates Linear Discriminant Analysis criteria and achieves an efficient decomposition of the provided data to its salient parts has been proposed. An extension of this work specialized for classification, optimized using projected gradients in order to ensure converge to a stationary limit point, resulted in a more efficient method of the latter approach. Assuming multimodality of the underlying data samples distribution and incorporating clustering <b>discriminant</b> inspired <b>constraints</b> into the NMF decomposition cost function, resulted in the Subclass Discriminant NMF algorithm which found to outperform both approaches under real life settings. In this work we review all these methods in the context of various pattern recognition problems using facial images. I...|$|R
40|$|AbstractUnder normality, Flury and Schmid [Quadratic <b>discriminant</b> {{functions}} with <b>constraints</b> on the covariances matrices: some asymptotic results, J. Multivariate Anal. 40 (1992) 244 – 261] {{investigated the}} asymptotic {{properties of the}} quadratic discrimination procedure under hierarchical models for the scatter matrices, that is: (i) arbitrary scatter matrices, (ii) common principal components, (iii) proportional scatter matrices and (iv) identical matrices. In this paper, we study the properties of robust quadratic discrimination rules based on robust estimates of the involved parameters. Our analysis {{is based on the}} partial influence functions of the functionals related to these parameters and allows to derive the asymptotic variances of the estimated coefficients under models (i) –(iv). From them, we conclude that the asymptotic variances verify the same order relations as those obtained by Flury and Schmid [Quadratic <b>discriminant</b> functions with <b>constraints</b> on the covariances matrices: some asymptotic results, J. Multivariate Anal. 40 (1992) 244 – 261] for the classical estimators. We also perform a Monte Carlo study for different sample sizes and different hierarchies which shows the advantage of using robust procedures over classical ones, when anomalous data are present. It also confirms that better rates of misclassification can be achieved if a more parsimonious model among all the correct ones is used instead of the standard quadratic discrimination...|$|R
40|$|Under normality, Flury and Schmid [Quadratic <b>discriminant</b> {{functions}} with <b>constraints</b> on the covariances matrices: some asymptotic results, J. Multivariate Anal. 40 (1992) 244 - 261] {{investigated the}} asymptotic {{properties of the}} quadratic discrimination procedure under hierarchical models for the scatter matrices, that is: (i) arbitrary scatter matrices, (ii) common principal components, (iii) proportional scatter matrices and (iv) identical matrices. In this paper, we study the properties of robust quadratic discrimination rules based on robust estimates of the involved parameters. Our analysis {{is based on the}} partial influence functions of the functionals related to these parameters and allows to derive the asymptotic variances of the estimated coefficients under models (i) -(iv). From them, we conclude that the asymptotic variances verify the same order relations as those obtained by Flury and Schmid [Quadratic <b>discriminant</b> functions with <b>constraints</b> on the covariances matrices: some asymptotic results, J. Multivariate Anal. 40 (1992) 244 - 261] for the classical estimators. We also perform a Monte Carlo study for different sample sizes and different hierarchies which shows the advantage of using robust procedures over classical ones, when anomalous data are present. It also confirms that better rates of misclassification can be achieved if a more parsimonious model among all the correct ones is used instead of the standard quadratic discrimination. Common principal components Outliers Partial influence functions Plug-in methods Proportional scatter matrices Quadratic discrimination Robust estimation...|$|R
40|$|Non-negative Matrix Factorization (NMF) {{is among}} the most popular {{subspace}} methods, widely used in a variety of image processing problems. To achieve an efficient decomposition of the provided data to its discriminant parts, thus enhancing classification performance, we regard that data inside each class form clusters and use criteria inspired by Clustering based Discriminant Analysis. The proposed method com-bines these <b>discriminant</b> criteria as <b>constraints</b> in the NMF decomposition cost function in order {{to address the problem of}} finding discriminant projections that enhance class sepa-rability in the reduced dimensional projection space. The de-veloped algorithm has been applied to the facial expression recognition problem and experimental results verified that it successfully identified discriminant facial parts, thus enhanc-ing recognition performance. 1...|$|R
40|$|Relationship between morphometric {{variables}} {{extracted from}} SRTM (Shuttle Radar Topography Mission) data and vegetation in Brasilia National Park). This paper aims {{to study the}} relationship between the distribution of vegetation in Brasilia National Park and topographic variables, to evaluate the potential of SRTM data alone, in addition to data traditionally used in remote sensing of vegetation. A map of vegetation of the area was used as a reference and the morphometric variables (elevation, slope, aspect and profile and plane curvatures) were compared to the mapped units. Analyses indicated vegetation types easily discriminated depending on topographic position. The variables elevation, slope and aspect were shown {{to be the most important}} for their high discrimination power of the vegetation types. Although morphometric data are recognized as having strong potential for characterizing vegetation, this was not shown in the results, due to the mismatching of variability scales between the two sources of data, where large units tend to exhibit similar distribution patterns of morphometry, and comprise classes with different responses for morphometric <b>constraints.</b> <b>Discriminant</b> analyses of morphometric variables allowed vegetation mapping up to sub-physiognomy levels. Pages: 96 - 10...|$|R
40|$|A novel {{approach}} to semi-supervised learning for classical Fisher {{linear discriminant analysis}} is presented. It formulates the problem {{in terms of a}} constrained log-likelihood approach, where the semi-supervision comes in through the constraints. These constraints encode that the parameters in linear discriminant analysis fulfill particular relations involving label-dependent and label-independent quantities. In this way, the latter type of parameters, which can be estimated based on unlabeled data, impose constraints on the former. The former parameters are the class-conditional means and the average within-class covariance matrix, which are the parameters of interest in linear <b>discriminant</b> analysis. The <b>constraints</b> lead to a reduction in variability of the label-dependent estimates, resulting in a potential improvement of the semi-supervised linear discriminant over that of its regular supervised counterpart. We state upfront that some of the key insights in this contribution have been published previously in a workshop paper by the first author. The major contribution in this work is the basic observation that a semi-supervised linear discriminant analysis can be formulated in terms of a principled log-likelihood approach, where the previous solution employed an ad hoc procedure. With the current contribution, we move yet another step closer to a proper formulation of a semi-supervised version of this classical techniqu...|$|R

