39|0|Public
40|$|Software {{reliability}} {{is one of}} {{the most}} important characteristics of software quality. Its measurement and management technologies employed during the software life-cycle are essential for producing and maintaining quality/reliable software systems. Herein, we discuss a modified approach to calculating the delivery cost of a software product, when warranty is to be provided, with an <b>imperfect</b> <b>debugging</b> phenomenon. Unlike existing cost models, here the strategy was to consider maintenance support given to the customer with an <b>imperfect</b> <b>debugging</b> phenomenon. The optimal release time can be calculated for various reliability levels by minimizing the cost. The delivery cost, reliability of the software system, and the optimal release time were calculated by using an <b>imperfect</b> <b>debugging</b> software reliability growth model. Numerical illustration supports the optimal release policies. 1...|$|E
30|$|The {{debugging}} {{process may}} introduce new errors into the software. This is an <b>imperfect</b> <b>debugging</b> process, but the maximum faults {{contained in the}} software is L.|$|E
40|$|A new {{approach}} called RESID is proposed {{in this paper}} for estimating reliability of a software allowing for <b>imperfect</b> <b>debugging.</b> Unlike earlier approaches based on counting number of bugs or modelling inter-failure time gaps, RESID focuses on the probability of "bugginess" of different parts of a program buggy. This perspective allows {{an easy way to}} incorporate the structure of the software under test, as well as <b>imperfect</b> <b>debugging.</b> One main design objective behind RESID is ease of implementation in practical scenarios. Comment: 13 pages, 4 figure...|$|E
40|$|Software {{testing is}} {{essential}} for software reliability improvement and assurance. However, software testing is subject to <b>imperfect</b> <b>debugging</b> {{in the sense that}} new defects may be introduced into the software under test while detected defects are removed. The quantitative effects of software testing on software reliability improvement are obscure. In this paper we propose a Markov usage model to explore the quantitative relationships between software testing and software reliability in the presence of <b>imperfect</b> <b>debugging.</b> Several interesting quantities for software reliability assessment are derived and the corresponding upper and lower bounds are obtained. (C) 2012 Elsevier Inc. All rights reserved. National Natural Science Foundation of China 70731003, 70971125, 10721101, 10928103, 11071008, 60973006; 973 Project 2010 CB 731400, 2011 CB 808000; Beijing Natural Science Foundation 4112033 Software testing {{is essential for}} software reliability improvement and assurance. However, software testing is subject to <b>imperfect</b> <b>debugging</b> in the sense that new defects may be introduced into the software under test while detected defects are removed. The quantitative effects of software testing on software reliability improvement are obscure. In this paper we propose a Markov usage model to explore the quantitative relationships between software testing and software reliability in the presence of <b>imperfect</b> <b>debugging.</b> Several interesting quantities for software reliability assessment are derived and the corresponding upper and lower bounds are obtained. (C) 2012 Elsevier Inc. All rights reserved...|$|E
40|$|Software Reliability {{is defined}} as the {{probability}} of free-failure operation for a specified period of time in a specified environment. Software Reliability Growth models (SRGM) have been developed to estimate software reliability measures such as number of remaining faults, software failure rate and Software Reliability. <b>Imperfect</b> <b>debugging</b> models are considered in these models. However, most SRGM assume that faults will eventually be removed. Fault removal efficiency in the existing models is limited. This paper aims to incorporate the fault removal efficiency in software reliability growth modeling. In this paper <b>imperfect</b> <b>debugging</b> is considered in the sense that new faults can be introduced into the software during debugging and the detected faults may not be removed completely...|$|E
40|$|Reliability of {{software}} has been analyzed using some existing mathematical models often termed as software reliability growth models(SRGM). We have considered Yamada Delayed S shaped model and incorporated the fault dependency, debugging time lag and <b>imperfect</b> <b>debugging.</b> Results shows that reliability {{of software}} gets improved under imperfect debuggin...|$|E
40|$|In {{allusion to}} the flaws in {{software}} cost model and optimal release policy, inadequate consideration for real debugging, a cost model and optimal release policy for SRGM (Software Reliability Growth Model) incorporating <b>imperfect</b> <b>debugging</b> is proposed. A SRGM is presented, based on incomplete debugging, introduction of new faults and TE (Testing Effort). It is verified to describe real testing process well by actual failure data set and has better performance as compared to other models. Based on the proposed SRGM, a formulation of cost function is also established especially considering the impact of <b>imperfect</b> <b>debugging</b> on cost. Furthermore, the optimal release policies given limited reliability objective and the uncertainty in actual total cost exceeding expected one are developed and elaborated. Finally, a numerical example and related data analyses are illustrated and parameter sensitivity analysis is performed...|$|E
40|$|Most Software Reliability Growth Models (SRGMs) {{based on}} the Nonhomogeneous Poisson Process (NHPP) {{generally}} assume perfect or <b>imperfect</b> <b>debugging.</b> However, environmental factors introduce great uncertainty for SRGMs {{in the development and}} testing phase. We propose a novel NHPP model based on partial differential equation (PDE), to quantify the uncertainties associated with perfect or <b>imperfect</b> <b>debugging</b> process. We represent the environmental uncertainties collectively as a noise of arbitrary correlation. Under the new stochastic framework, one could compute the full statistical information of the debugging process, for example, its probabilistic density function (PDF). Through a number of comparisons with historical data and existing methods, such as the classic NHPP model, the proposed model exhibits a closer fitting to observation. In addition to conventional focus on the mean value of fault detection, the newly derived full statistical information could further help software developers make decisions on system maintenance and risk assessment...|$|E
40|$|Software {{testing is}} an {{important}} phase of softwaredevelopment life cycle. It controls the quality of softwareproduct. Due {{to the complexity of}} software system andincomplete understanding of software, the testing team maynot be able to remove/correct the fault perfectly onobservation/detection of a failure and the original fault mayremain resulting in a phenomenon known as imperfectdebugging, or get replaced by another fault causing faultgeneration. In case of <b>imperfect</b> <b>debugging,</b> the fault contentof the software remains same while in case of faultgeneration, the fault content increases as the testingprogresses and removal/correction results in introduction ofnew faults while removing/correcting old ones. Duringsoftware testing fault detection /correction rate may not besame throughout the whole testing process, but it maychange at any time moment. In the literature varioussoftware reliability models have been proposedincorporating change-point concept. In this paper wepropose a distribution based change-point problem with twotypes of <b>imperfect</b> <b>debugging</b> in software reliability. Themodels developed have been validated and verified usingreal data sets. Estimated Parameters and comparisoncriteria results have also been presente...|$|E
40|$|In this paper, we have {{modified}} the Jelinski-Moranda (J-M) model of software reliability using <b>imperfect</b> <b>debugging</b> process in fault removal activity. The J-M model was developed assuming the debugging process {{to be perfect}} which implies that there is one-to-one correspondence {{between the number of}} failures observed and faults removed. But in reality, {{it is possible that the}} fault which is supposed to have been removed may cause a new failure. In the proposed modified J-M model, we consider that whenever a failure occurs, the detected fault is not perfectly removed and there is a chance of raising new fault/faults due to wrong diagnosis or incorrect modifications in the software. In this paper, we develop a modified J-M model which can describe the <b>imperfect</b> <b>debugging</b> process. The parameters of our modified J-M model are estimated by using maximum-likelihood estimation method. Applicability of the model has been shown on the failure data set of Musa...|$|E
40|$|Resource {{control and}} {{resource}} maintenance during the software testing {{is one of}} the finest optimization problems. During the software testing many of the resources like time, effort and budget were consumed. The main aim of the manager is allocate the resources in a constrained manner such that the effort can be optimally allocated and overall budget is minimized. In this paper we proposed a <b>imperfect</b> <b>debugging</b> SRGM during testing and resource allocation is done based on optimizing the effort and reliability. An experimental result shows the proposed model well fitted for software testing...|$|E
40|$|AbstractIn this paper, {{we propose}} a {{software}} availability model considering {{the number of}} restoration actions. We correlate the failure and restoration characteristics of the software system with the cumulative number of corrected faults. Furthermore, we consider an <b>imperfect</b> <b>debugging</b> environment where the detected faults are not always corrected and removed from the system. The time-dependent behavior of the system alternating between up and down states is described by a Markov process. From this model, we can derive quantitative measures for software availability assessment {{based on the number}} of restoration actions. Finally, we show numerical examples of software availability analysis...|$|E
40|$|Computer {{software}} has progressively {{turned out}} to be anessential component in modern technologies. Penalty costs resulting fromsoftware failures are often more considerable than software developing costs. Debugging decreases the error content but expands the software developmentcosts. To improve the software quality, software reliability engineering playsan important role in many aspects throughout the software life cycle. In thispaper, we incorporate both <b>imperfect</b> <b>debugging</b> and change-point problem intothe software reliability growth model(SRGM) based on the well-knownexponential distribution the parameter estimation is studied and the proposedmodel is compared with the some existing models in the literature and is find tobe better...|$|E
40|$|In Classicy. The {{procedure}} adopted {{for this}} is, Sequential Probabilital Hypothesis testing volumes of data {{is to be}} collected and then the conclusions are drawn which may take more time. But, Sequential Analysis of statistical science could be adopted in order to decide upon the reliable / unreliable of the developed software very quickly Ratio Test (SPRT). In the present paper, we have proposed the performance of SPRT on Time domain data using exponential <b>imperfect</b> <b>debugging</b> model and analyzed the results by applying on 5 data sets. The parameters are estimated by using Maximum Likelihood Estimation...|$|E
30|$|Software {{reliability}} is {{a significant}} measurement to characterize software quality and determine when to stop testing and release software upon the predetermined objectives [3]. A great number of software reliability models also have been proposed {{in the past few}} decades to predict software failures and determine the release time based on a non-homogeneous Poisson process (NHPP). Some software reliability models consider perfect debugging, such as [4, 5, 6, 7]; some assume <b>imperfect</b> <b>debugging</b> [6, 7, 8, 9, 10]. The fault detection rate, described by a constant [4, 6, 11] or by learning phenomenon of developers [3, 8, 12, 13, 14, 15, 16], is also studied in literature. However, lots of difficulties are also generated from model assumptions when applying software reliability models on real testing environment. These non-significant assumptions have limited their usefulness in the real-world application [17]. For most software reliability models in literature, software faults are assumed to be removed immediately and perfectly upon detection [9, 17, 18]. Additionally, software faults are assumed to be independent for simplicity reason. Several studies including [3, 19, 20] incorporate fault removal efficiency and <b>imperfect</b> <b>debugging</b> into the modeling consideration. Also, Kapur et al. [21] consider that the delay of the fault removal efficiency depends on their criticality and urgency in the software reliability modeling in the operation phase. However, we have not seen any research incorporate fault-dependent detection and imperfect fault removal based on our knowledge.|$|E
40|$|Bugs are {{inevitable}} in any software development life cycle. Most bugs are detected and removed in the testing phase. In software, we can classify bugs into two categories: (1) bugs of different severity (2) bugs of different complexity. Prior knowledge of bug distribution of different complexity in software can help project managers in allocating testing resources and tools. Various researchers have proposed models {{for determining the}} proportion of bugs present in software of different complexity {{but none of these}} models have been applied to object oriented software. Software reliability growth models have been used during later stages of testing to predict the number of latent bugs dormant in the software. Once a bug is found in the software, efforts have been made by the development team to debug it. It is found in practice that debugging may not be perfect and during removal of bugs, some new bugs may be generated and this phenomenon is called <b>imperfect</b> <b>debugging.</b> In this paper, we have developed a software reliability growth model for object oriented software system for perfect debugging in which new bugs are not generated during removal process and also by incorporating <b>imperfect</b> <b>debugging,</b> where new bugs are generated during removal process in a proportion removed bugs. Here, the proposed paper is used to assess the reliability growth of object oriented software developed under concurrent distributed development environment. We have collected bug reported data of MySQL for python. Numerical illustration has been also presented in the paper...|$|E
40|$|Software {{reliability}} is {{one important}} factor for software quality. Measuring the software quality and its reliability is one complex task. Many papers are {{published in the}} history of reliability which answers the software reliability and related problems. Determining the cost of the software is another issue. In this paper we have determined the total cost of the software under given warranty period. During the warranty period the company will give the maintenance support. The optimal release time is determined for software under reliability, cost and given warranty period with two types of <b>imperfect</b> <b>debugging</b> software reliability growth models. Numeric calculations were done to support our phenomenon. 1...|$|E
40|$|Software {{reliability}} {{process can}} be monitored efficiently by using Statistical Process Control (SPC). It assists the software development team to identify failures and {{actions to be taken}} during software failure process and hence, assures better software reliability. In this paper, we consider a software reliability growth model of Non-Homogenous Poisson Process (NHPP) based, that incorporates <b>imperfect</b> <b>debugging</b> problem. The proposed model utilizes the failure data collected from software development projects to analyze the software reliability. The maximum likelihood approach is derived to estimate the unknown point estimators of the model. We investigate the model and demonstrate its applicability in the software reliability engineering field...|$|E
40|$|Abstract. In this paper, we will {{investigate}} {{how to perform}} he log-logistic testing-effort function (TEF) into different software reliability growth models based on non-homogeneous Poisson process (NHPP). The models parameters are estimated by least square estimation (LSE) and maximum likelihood estimation (MLE) methods. The methods of data analysis and comparison criteria are presented and the experimental results from actual data applications are analyzed. Results are compared with the other existing models {{to show that the}} proposed models can give fairly better predictions. It is shown that the log-logistic TEF is suitable for incorporating into inflection S-shaped NHPP growth models. In addition, the proposed models are also discussed under <b>imperfect</b> <b>debugging</b> environment...|$|E
40|$|Purpose – The {{purpose of}} this paper is to {{investigate}} how to incorporate the exponentiated Weibull (EW) testing-effort function (TEF) into inflection S-shaped software reliability growth models (SRGMs) based on non-homogeneous Poisson process (NHPP). The aim is also to present a more flexible SRGM with <b>imperfect</b> <b>debugging.</b> Design/methodology/approach – This paper reviews the EW TEFs and discusses inflection S-shaped SRGM with EW testing-effort to get a better description of the software fault detection phenomenon. The SRGM parameters are estimated by weighted least square estimation (WLSE) and maximum-likelihood estimation (MLE) methods. Furthermore, the proposed models are also discussed under <b>imperfect</b> <b>debugging</b> environment. Findings – Experimental results from three actual data applications are analyzed and compared with the other existing models. The findings reveal that the proposed SRGM has better performance and prediction capability. Results also confirm that the EW TEF is suitable for incorporating into inflection S-shaped NHPP growth models. Research limitations/implications – This paper presents the WLSE results with equal weight. Future research may be carried out for unequal weights. Practical implications – Software reliability modeling and estimation are a major concern in the software development process, particularly during the software testing phase, as unreliable software can cause a failure in the computer system that can be hazardous. The results obtained in this paper may facilitate the software engineers, scientists, and managers in improving the software testing process. Originality/value – The proposed SRGM has a flexible structure and may capture features of both exponential and S-shaped NHPP growth models for failure phenomenon. ...|$|E
40|$|In this paper, {{we propose}} a {{software}} reliability model that considers not only error generation but also fault removal efficiency combined with testing coverage information {{based on a}} nonhomogeneous Poisson process (NHPP). During the past four decades, many software reliability growth models (SRGMs) based on NHPP have been proposed to estimate the software reliability measures, most of which have the same following agreements: 1) {{it is a common}} phenomenon that during the testing phase, the fault detection rate always changes; 2) as a result of <b>imperfect</b> <b>debugging,</b> fault removal has been related to a fault re-introduction rate. But there are few SRGMs in the literature that differentiate between fault detection and fault removal, i. e. they seldom consider the imperfect fault removal efficiency. But in practical software developing process, fault removal efficiency cannot always be perfect, i. e. the failures detected might not be removed completely and the original faults might still exist and new faults might be introduced meanwhile, which is referred to as <b>imperfect</b> <b>debugging</b> phenomenon. In this study, a model aiming to incorporate fault introduction rate, fault removal efficiency and testing coverage into software reliability evaluation is developed, using testing coverage to express the fault detection rate and using fault removal efficiency to consider the fault repair. We compare the performance of the proposed model with several existing NHPP SRGMs using three sets of real failure data based on five criteria. The results exhibit that the model can give a better fitting and predictive performance...|$|E
40|$|In this paper, {{we first}} {{show that the}} {{logistic}} testing-effort function is practically acceptable/helpful for modeling software reliability growth and providing a reasonable description of resource consumption. Therefore, {{in addition to the}} exponential-shaped models, we will integrate the logistic testing-effort function into S-shaped model for further analysis. The model is designated as the Yamada Delayed S-shaped model. A realistic failure data set is used in the experiments to demonstrate the estimation procedures and results. Furthermore, the analysis of the proposed model under <b>imperfect</b> <b>debugging</b> environment is investigated. In fact, from these experimental results and discussions, it is apparent that the logistic testing-effort function is well suitable for making estimations of resource consumption during th...|$|E
40|$|Abstract — In {{literature}} we {{have several}} software reliability growth models developed to monitor the reliability growth during the testing phase of the software development. These models typically use the calendar / execution time and hence are known as continuous time SRGM. However, very little {{seems to have been}} done in the literature to develop discrete SRGM. Discrete SRGM uses test cases in computer test runs as a unit of testing. Debugging process is usually imperfect because during testing all software faults are not completely removed as they are difficult to locate or new faults might be introduced. In real software development environment, the number of failures observed need not be same as the number of errors removed. If the number of failures observed is more than the number of faults removed then we have the case of <b>imperfect</b> <b>debugging...</b>|$|E
40|$|We {{propose the}} {{performance}} evaluation method for the multi-task system with software reliability growth process. The software fault-detection {{phenomenon in the}} dynamic environment is described by the Markovian software reliability model with <b>imperfect</b> <b>debugging.</b> We assume that the cumulative number of tasks arriving at the system follows the homogeneous Poisson process. Then we can formulate {{the distribution of the}} number of tasks whose processes can be complete within a prespecified processing time limit with the infinite-server queueing model. From the model, several quantities for software performance measurement considering the real-time property can be derived and given as the functions of time and the number of debuggings. Finally, we present several numerical examples of the quantities to analyze the relationship between the software reliability characteristics and the system performance measurement. Performance evaluation, multi-task system, software reliability growth, Markov process, infinite-server queueing model...|$|E
40|$|Software Reliability Growth Models (SRGM) {{have been}} {{developed}} to estimate software reliability measures such as software failure rate, number of remaining faults and software reliability. In this paper, the software analyzers tool proposed for deriving several software reliability growth models based on Enhanced Non-homogeneous Poisson Process (ENHPP) in the presence of <b>imperfect</b> <b>debugging</b> and error generation. The proposed models are initially formulated for the case when there is no differentiation between failure observation and fault removal testing processes and then this extended for the case when there is a clear differentiation between failure observation and fault removal testing processes. Many Software Reliability Growth Models (SRGM) {{have been developed}} to describe software failures as a random process and can be used to measure the development status during testing. With SRGM software consultants can easily measure (or evaluate) the software reliability (or quality) and plot software reliability growth charts...|$|E
40|$|Abstract — Software {{reliability}} is {{an important}} aspect of software quality. And achieving reliability is the need of today’s global competition. Estimation and prediction are the ways to analyze software reliability. Software reliability growth model is used to estimate the reliability through mathematical expression and it also used to interpret software failures as a random process. This paper describes a novel software reliability growth model based on non homogeneous Poisson process with allowing for <b>imperfect</b> <b>debugging.</b> Maintaining and improving quality of the software is a very difficult task due to many factors like ambiguous requirement specification, lack of required resources etc. Many reliability growth models have been proposed until now according to different context and hence there is no globally accepted model. Software quality metric highlights the quality aspects of product, process, and project. As there is proportional relationship between quality and reliability, analyzing quality metrics is also a way to estimate reliability. So, we analyze quality metrics along with maintaining the defect database...|$|E
40|$|One of {{the most}} {{important}} decisions related to the efficient management of testing phase of software development life cycle is to determine when to stop testing and release the software in the market. Most of the testing processes are imperfect once. In this paper first we have discussed an optimal release time problem for an imperfect faultdebugging model due to Kapur et al considering effect of perfect and <b>imperfect</b> <b>debugging</b> separately on the total expected software cost. Next, we proposed a SRGM incorporating the effect of imperfect fault debugging and error generation. The proposed model is validated on a data set cited in literature and a release time problem is formulated minimizing the expected cost subject to a minimum reliability level to be achieved by the release time using the proposed model. Solution method is discussed to solve such class of problem. A numerical illustration is given for both type of release problem and finally a sensitivity analysis is performed...|$|E
40|$|AbstractThis paper {{studies the}} fault {{detection}} process (FDP) and fault correction process (FCP) with {{the incorporation of}} testing effort function and <b>imperfect</b> <b>debugging.</b> In order to ensure high reliability, {{it is essential for}} software to undergo a testing phase, during which faults can be detected and corrected by debuggers. The testing resource allocation during this phase, which is usually depicted by the testing effort function, considerably influences not only the fault detection rate but also the time to correct a detected fault. In addition, testing is usually far from perfect such that new faults may be introduced. In this paper, we first show how to incorporate testing effort function and fault introduction into FDP and then develop FCP as delayed FDP with a correction effort. Various specific paired FDP and FCP models are obtained based on different assumptions of fault introduction and correction effort. An illustrative example is presented. The optimal release policy under different criteria is also discussed...|$|E
40|$|Gokhale and Trivedi (1998) have {{proposed}} the Log-logistic software reliability growth model that can capture the increasing/decreasing {{nature of the}} failure occurrence rate per fault. In this paper, we will first show that a Log-logistic testing-effort function (TEF) can be expressed as a software development/testing-effort expenditure curve. We investigate how to incorporate the Log-logistic TEF into inflection S-shaped software reliability growth models based on non-homogeneous Poisson process (NHPP). The models parameters are estimated by least square estimation (LSE) and maximum likelihood estimation (MLE) methods. The methods of data analysis and comparison criteria are presented. The experimental results from actual data applications show good fit. A comparative analysis {{to evaluate the effectiveness}} for the proposed model and other existing models are also performed. Results show that the proposed models can give fairly better predictions. Therefore, the Log-logistic TEF is suitable for incorporating into inflection S-shaped NHPP growth models. In addition, the proposed models are discussed under <b>imperfect</b> <b>debugging</b> environment...|$|E
40|$|Considering testing {{effort and}} <b>imperfect</b> <b>debugging</b> in {{reliability}} modeling process may further improve the fitting and prediction results of software reliability growth models (SRGMs). For describing the S-shaped varying {{trend of the}} testing-effort increasing rate more accurately, this paper first proposes a inflected S-shaped testing effort function (IS-TEF). Then this new TEF is incorporated into the inflected S-shaped NHPP SRGMs for obtaining a new NHPP SRGMs which consider S-shaped TEF (IS-TEFM-IS). We further discuss this new NHPP SRGM with two imperfect-debugging assumptions to propose two new NHPP SRGMs, i. e. IS-TEFM-IS-ID 1 and IS-TEFM-IS-ID 2. Finally these three new NHPP SRGMs and several comparison NHPP SRGMs are applied into two real failure data-sets respectively for investigating the fitting power of the IS-TEFM-IS, IS-TEFM-IS-ID 1 and IS-TEFM-IS-ID 2. The experimental {{results show that the}} inflected S-shaped NHPP SRGMs considering IS-TEF and imperfect indeed can yield the best accurate estimation results than the other comparison SRGMs.  </p...|$|E
40|$|This paper {{studies the}} fault {{detection}} process (FDP) and fault correction process (FCP) with {{the incorporation of}} testing effort function and <b>imperfect</b> <b>debugging.</b> In order to ensure high reliability, {{it is essential for}} software to undergo a testing phase, during which faults can be detected and corrected by debuggers. The testing resource allocation during this phase, which is usually depicted by the testing effort function, considerably influences not only the fault detection rate but also the time to correct a detected fault. In addition, testing is usually far from perfect such that new faults may be introduced. In this paper, we first show how to incorporate testing effort function and fault introduction into FDP and then develop FCP as delayed FDP with a correction effort. Various specific paired FDP and FCP models are obtained based on different assumptions of fault introduction and correction effort. An illustrative example is presented. The optimal release policy under different criteria is also discussed...|$|E
40|$|AbstractSoftware {{reliability}} {{testing is}} concerned with the quantitative relationship between software testing and software reliability. Our previous work develops a mathematically rigorous modeling framework for software reliability testing. However the modeling framework is confined to the case of perfect debugging, where detected defects are removed without introducing new defects. In this paper the modeling framework is extended to the case of <b>imperfect</b> <b>debugging</b> and two models are proposed. In the first model it is assumed that debugging is imperfect and may make the number of remaining defects reduce by one, remain intact, or increase by one. In the second model it is assumed that when the number of remaining defects reaches the upper bound, the probability that the number of remaining defects is increased by one by debugging is zero. The expected behaviors of the cumulative number of observed failures and the number of remaining defects in the first model show that the software testing process may induce a linear or nonlinear dynamic system, depending on the relationship between the probability of debugging introducing a new defect and that of debugging removing a detected defect. The second-order behaviors of the first model also show {{that in the case of}} <b>imperfect</b> <b>debugging,</b> although there may be unbiased estimator for the initial number of defects remaining in the software under test, the cumulative number of observed failures and the current number of remaining defects are not sufficient for precisely estimating the initial number of remaining defects. This is because the variance of the unbiased estimator approaches a non-zero constant as the software testing process proceeds. This may be treated as an intrinsic principle of uncertainty for software testing. The expected behaviors of the cumulative number of observed failures and the number of remaining defects in the second model show that the software testing process may induce a nonlinear dynamic system. However theoretical analysis and simulation results show that, if defects are more often removed from than introduced into the software under test, the expected behaviors of the two models tend to coincide with each other as the upper bound of the number of remaining defects approaches infinity...|$|E
40|$|Software {{reliability}} growth {{models were}} used since {{long time to}} access {{the quality of the}} software which was developed. Past few decades several papers describes reliability growth phenomenon. As the time progress, the number of errors detection and correction also increases. A Large effort is required in testing to increases the rate of detection and correction of error to increase the reliability of the software. Generally a Testing-effort is better described by number of persons involved; number of test cases used and calendar time. When the software is lagging by schedule time then there is need of automated testing tools to cop up with lagging. Use of automated tools can increase the testing efficiency to a greater extent. This paper we proposed a software reliability growth model which incorporates the Gompertz testing-effort function and an analysis is made on optimal release. Experiments are performed on two real datasets. Parameters are estimated. The results show our model is better fit than other. KEYWORDS: Delayed S-shaped models, <b>imperfect</b> <b>debugging</b> model, non homogeneous Poisson process, Software reliability growth model, and testing-effort...|$|E
40|$|A {{simple and}} {{effective}} method of assessing {{the reliability of}} a piece of software is to plot the cumulative number of failures observed during testing, N(x), against time x. Since no software is ever completely free of errors, be it careless minor oversights or the results of serious design problems, it is therefore expected that with prolonged and systematic testing, N(x) will increase with x. Since the 1970 s, there have been many models, aptly named Software Reliability Growth Models (SRGMs) which have been proposed to fit software failure data to the curve m(x) =E(N(x)). Unfortunately, due to the complexity of the software development processes, which include the possibility of <b>imperfect</b> <b>debugging</b> and introduction of new faults into the system, many of these SRGMs are very complex and standard estimation procedures such as Maximum Likelihood estimation (MLE) fails to estimate correctly, if at all, the parameters of these models. In this paper, we investigate the potential benefits of using Nonparametric Regression (NPR) methods to fit SRGMs. In addition, we will also develop methods based on Stein two-stage and modified two-stage sequential procedures to find a fixed-width confidence interval for the estimator of m(x). Finally, numerical examples based on real software failure data will be presented to illustrate the techniques developed and compare the results with some parametric SRGMs...|$|E
40|$|Abstract—This paper {{presents}} a general software reliability growth model (SRGM) based on nonhomogeneous Poisson process (NHPP). Although many research have {{been devoted to}} unify some NHPP models, most of them either only consider <b>imperfect</b> <b>debugging,</b> learning phenomenon, or take fault removal efficiency as a constant. Consideration of the variation of fault removal efficiency during debugging period in the exiting models is limited. The general model in this paper is the first unified scheme of some NHPP models which take fault removal efficiency {{as a function of}} debugging time. Fault detection rate (FDR) is usually used to measure the effectiveness of fault detection of test techniques and test cases. Most researchers assume a constant FDR in deriving their SRGMs. Because of learning process of testers, some researchers take FDR as increasing functions over testing period. Some literature take FDR as decreasing functions because failures removed first have higher detected rate. A bell-shaped FDR function is proposed which integrates both learning phenomenon and inherent FDR. As a special case of the general SRGM, a NHPP SRGM called PBbell-SRGM is put forward which integrates the proposed FDR function and fault removal efficiency. PBbell-SRGM is evaluated using a set of software failure data. The results show that PBbell-SRGM fits the given failure data better than some selected NHPP models. Index Terms—Imperfect debugging, learning phenomenon, nonhomogeneous Poisson process, software reliability growth model...|$|E
40|$|Abstract: Nonhomogeneous {{poisson process}} based {{software}} reliability growth models are generally classified into two groups. The first group contains models, which use the machine execution time or calendar {{time as a}} unit of fault detection/removal period. Such models are called continuous time models. The second group contains models, which use the number of test occasions/cases as a unit of fault detection period. Such models are called discrete time models, since the unit of software fault detection period is countable. A large number of models have been developed in the first group while there are fewer in the second group. Discrete time models in software reliability are important and a little effort {{has been made in}} this direction. In this paper, we develop two discrete time SRGMs using probability generating function for the software failure occurrence / fault detection phenomenon based on a NHPP namely, basic and extended models. The basic model exploits the fault detection/removal rate during the initial and final test cases. Whereas, the extended model incorporates fault generation and <b>imperfect</b> <b>debugging</b> with learning. Actual software reliability data have been used to demonstrate the proposed models. The results are fairly encouraging in terms of goodness-of-fit and predictive validity criteria due to applicability and flexibility of the proposed models as they can capture a wide class of reliability growth curves ranging from purely exponential to highly S-shaped...|$|E
