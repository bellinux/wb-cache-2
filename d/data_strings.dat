69|513|Public
2500|$|The Kolmogorov {{structure}} {{function of}} an individual data string expresses {{the relation between the}} complexity level constraint on a model class and the least log-cardinality of a model in the class containing the data. The structure function determines all stochastic properties of the individual data string: for every constrained model class it determines the individual best-fitting model in the class irrespective of whether the true model is in the model class considered or not. In the classical case we talk about a set of data with a probability distribution, and the properties are those of the expectations. In contrast, here we deal with individual <b>data</b> <b>strings</b> and the properties of the individual string focussed on. In this setting, a property holds with certainty rather than with high probability as [...] in the classical case. The Kolmogorov structure function precisely quantify the goodness-of-fit {{of an individual}} model with respect to individual data.|$|E
5000|$|In {{the above}} [...] "compare" [...] code, the {{original}} (KDP10?) instruction set compared {{from right to}} left, requiring the whole length of the <b>data</b> <b>strings</b> to be compared, a character at a time. KDP8 was enhanced to compare from left to right, so the comparison could stop {{as soon as the}} relative values were clear, speeding up processing of such instructions considerably.|$|E
5000|$|... 4+ bytes {{optional}} extra <b>data</b> <b>strings</b> = short integer type + short unsigned string length (types are Extended Info End = -1; Directory Name = 0; Directory IDs = 1; Absolute Path = 2; AppleShare Zone Name = 3; AppleShare Server Name = 4; AppleShare User Name = 5; Driver Name = 6; Revised AppleShare info = 9; AppleRemoteAccess dialup info = 10) ...|$|E
40|$|Each <b>data</b> <b>string</b> over {{a finite}} {{alphabet}} of length {{a power of}} two is represented via a binary tree called a bisection tree. The nodes of the bisection tree correspond {{to the members of}} the smallest class of substrings of the <b>data</b> <b>string</b> which contains the <b>data</b> <b>string</b> and is closed with respect to bisection. A <b>data</b> <b>string</b> can be perfectly reconstructed from its bisection tree. A lossless data compression algorithm is presented which compresses the <b>data</b> <b>string</b> by compressing its bisection tree. This algorithm is shown to be a universal algorithm in the sense that it yields a compression performance at least as good as the compression performance provided by any finite-state sequential lossless data compression algorithm, asymptotically as the length of the <b>data</b> <b>string</b> goes to infinity. Index Terms: lossless data compression, arithmetic coding, entropy, universal algorithms I Introduction Throughout this paper, let A be a generic symbol denoting a finite alphabet containing at least tw [...] ...|$|R
40|$|Till now {{communication}} is possible of 7 bit information <b>data</b> <b>string</b> by transmitting 11 bit <b>data</b> <b>string</b> in single frame {{due to this}} speed of communication system is very slow. And we can transmit very minimum number of configuration of <b>data</b> <b>string.</b> To increase the speed of communication system and increase the numbers of configuration <b>data</b> <b>string</b> author design some communication system by different methodologies of Hamming code. About all these communication systems all methodologies are discuss here. First, author design communication system to make communication by even parity check method for 25 bit information <b>data</b> <b>string.</b> In second paper, author design communication system to make communication by odd parity check method for 25 bit information data. In third paper, author again design communication system for 25 bit information <b>data</b> <b>string</b> by even parity and odd parity check method by using VHDL by single system. Till now, for 25 bit information <b>data</b> <b>string</b> {{communication is}} possible only in simplex mode. So that now author, design 25 bit hamming code transceiver to make communication possible in full duplex mode. Key word Hamming code, VHDL code, Xilinx ISE 10. 1 simulator, even parity check, odd parity check, transmitter, receiver, transceiver...|$|R
40|$|Mechanisms for {{operating}} a prover device and a verifier device {{so that the}} verifier device can verify {{the authenticity of the}} prover device. The prover device generates a <b>data</b> <b>string</b> by: (a) submitting a challenge to a physical unclonable function (PUF) to obtain a response string, (b) selecting a substring from the response string, (c) injecting the selected substring into the <b>data</b> <b>string,</b> and (d) injecting random bits into bit positions of the <b>data</b> <b>string</b> not assigned to the selected substring. The verifier: (e) generates an estimated response string by evaluating a computational model of the PUF based on the challenge; (f) performs a search process to identify the selected substring within the <b>data</b> <b>string</b> using the estimated response string; and (g) determines whether the prover device is authentic based on a measure of similarity between the identified substring and a corresponding substring of the estimated response string...|$|R
5000|$|Complex strings {{are harder}} to {{compress}}. While intuition tells us that this may depend on the codec used to compress a string (a codec could be theoretically created in any arbitrary language, including {{one in which the}} very small command [...] "X" [...] could cause the computer to output a very complicated string like [...] "18995316"), any two Turing-complete languages can be implemented in each other, meaning that the length of two encodings in different languages will vary by at most the length of the [...] "translation" [...] language - which will end up being negligible for sufficiently large <b>data</b> <b>strings.</b>|$|E
5000|$|Synchronous CDMA {{exploits}} mathematical {{properties of}} orthogonality between vectors representing the <b>data</b> <b>strings.</b> For example, binary string 1011 {{is represented by}} the vector (1, 0, 1, 1). Vectors can be multiplied by taking their dot product, by summing the products of their respective components (for example, if u = (a, b) and v = (c, d), then their dot product u·v = ac + bd). If the dot product is zero, the two vectors are said to be orthogonal to each other. Some properties of the dot product aid understanding of how W-CDMA works. If vectors a and b are orthogonal, then [...] and: ...|$|E
50|$|In 1973 Kolmogorov {{proposed}} a non-probabilistic approach to statistics and model selection. Let each datum be a finite binary string {{and a model}} be finite sets of binary strings. Consider model classes consisting of models of given maximal Kolmogorov complexity.The Kolmogorov structure function of an individual data string expresses {{the relation between the}} complexity level constraint on a model class and the least log-cardinality of a model in the class containing the data. The structure function determines all stochastic properties of the individual data string: for every constrained model class it determines the individual best-fitting model in the class irrespective of whether the true model is in the model class considered or not. In the classical case we talk about a set of data with a probability distribution, and the properties are those of the expectations. In contrast, here we deal with individual <b>data</b> <b>strings</b> and the properties of the individual string focussed on. In this setting, a property holds with certainty rather than with high probability as in the classical case. The Kolmogorov structure function precisely quantify the goodness-of-fit of an individual model with respect to individual data.|$|E
5000|$|... resource: Resource <b>data</b> <b>string</b> being transmitted, e.g., an IP address or email address.|$|R
50|$|If, on {{the other}} hand, the symbol in the string was a 1, the rule {{separator}} changes into a new structure which admits the incoming production rule. Although the new structure is again destroyed when it encounters the next rule separator, it first allows a series of structures to pass through towards the left. These structures are then made to append themselves {{to the end of}} the cyclic tag system's <b>data</b> <b>string.</b> This final transformation is accomplished by means of a series of infinitely repeating, right-moving clock pulses, in the right-moving pattern shown above. The clock pulses transform incoming left-moving 1 symbols from a production rule into stationary 1 symbols of the <b>data</b> <b>string,</b> and incoming 0 symbols from a production rule into stationary 0 symbols of the <b>data</b> <b>string.</b>|$|R
25|$|Another {{possibility}} to access <b>data</b> <b>STRING</b> {{is to use}} the application programming interface (API) by constructing a URL that contain the request.|$|R
40|$|A {{method used}} preferably with LZSS-based {{compression}} methods for compressing {{a stream of}} digital data. The method uses a run-length encoding scheme especially suited for <b>data</b> <b>strings</b> of identical data bytes having large run-lengths, such as data representing scanned images. The method reads an input data stream to determine {{the length of the}} <b>data</b> <b>strings.</b> Longer <b>data</b> <b>strings</b> are then encoded {{in one of two ways}} depending on the length of the string. For <b>data</b> <b>strings</b> having run-lengths less than 18 bytes, a cleared offset and the actual run-length are written to an output buffer and then a run byte is written to the output buffer. For <b>data</b> <b>strings</b> of 18 bytes or longer, a set offset and an encoded run-length are written to the output buffer and then a run byte is written to the output buffer. The encoded run-length is written in two parts obtained by dividing the run length by a factor of 255. The first of two parts of the encoded run-length is the quotient; the second part is the remainder. Data bytes that are not part of <b>data</b> <b>strings</b> of sufficient length are written directly to the output buffer...|$|E
40|$|We {{introduce}} {{streaming data}} string transducers that map input <b>data</b> <b>strings</b> to output <b>data</b> <b>strings</b> {{in a single}} left-to-right pass in linear time. <b>Data</b> <b>strings</b> are (unbounded) sequences of data values, tagged with symbols from a finite set, over a potentially infinite data domain that supports only the operations of equality and ordering. The transducer uses a finite set of states, a finite set of variables ranging over the data domain, and a finite set of variables ranging over <b>data</b> <b>strings.</b> At every step, it can {{make decisions based on}} the next input symbol, updating its state, remembering the input data value in its data variables, and updating data-string variables by concatenating data-string variables and new symbols formed from data variables, while avoiding duplication. We establish that the problems of checking functional equivalence of two streaming transducers, and of checking whether a streaming transducer satisfies pre/pos...|$|E
40|$|We {{introduce}} {{streaming data}} string transducers that map input <b>data</b> <b>strings</b> to output <b>data</b> <b>strings</b> {{in a single}} left-to-right pass in linear time. <b>Data</b> <b>strings</b> are (unbounded) sequences of data values, tagged with symbols from a finite set, over a potentially infinite data domain that supports only the operations of equality and ordering. The transducer uses a finite set of states, a finite set of variables ranging over the data domain, and a finite set of variables ranging over <b>data</b> <b>strings.</b> At every step, it can {{make decisions based on}} the next input symbol, updating its state, remembering the input data value in its data variables, and updating data-string variables by concatenating data-string variables and new symbols formed from data variables, while avoiding duplication. We establish that the problems of checking functional equivalence of two streaming transducers, and of checking whether a streaming transducer satisfies pre/post verification conditions specified by streaming acceptors over input/output data-strings, are in PSPACE. We identify a class of imperative and a class of functional programs, manipulating lists of data items, which can be effectively translated to streaming data-string transducers. The imperative programs dynamically modify a singly-linked heap by changing next-pointers of heap-nodes and by adding new nodes. The main restriction specifies how the next-pointers can be used for traversal. We also identify an expressively equivalent fragment of functional programs that traverse a list using syntactically restricted recursive calls. Our results lead to algorithms for assertion checking and for checking functional equivalence of two programs, written possibly in different programming styles, for commonly used routines such as insert, delete, and reverse...|$|E
50|$|The differing memory {{layout and}} storage {{requirements}} of strings {{can affect the}} security of the program accessing the <b>string</b> <b>data.</b> <b>String</b> representations requiring a terminating character are commonly susceptible to buffer overflow problems if the terminating character is not present, caused by a coding error or an attacker deliberately altering the <b>data.</b> <b>String</b> representations adopting a separate length field are also susceptible if the length can be manipulated. In such cases, program code accessing the <b>string</b> <b>data</b> requires bounds checking to ensure that it does not inadvertently access or change data outside of the string memory limits.|$|R
40|$|A {{universal}} lossless {{data compression}} code called the multilevel pattern matching code (MPM code) is introduced. In processing a finite alphabet <b>data</b> <b>string</b> of length n, the MPM code operates at O(log log n) levels sequentially. At each level, the MPM code detects matching {{patterns in the}} input <b>data</b> <b>string</b> (substrings of the data appearing in two or more nonoverlapping positions). The matching patterns detected at each level are of a fixed length which decreases by a constant factor from level to level, until this fixed length becomes one at the final level. The MPM code represents information about the matching patterns at each level as a string of tokens, with each token string encoded by an arithmetic encoder. From the concatenated encoded token strings, the decoder can reconstruct the <b>data</b> <b>string</b> via several rounds of parallel substitutions. A O(1 = log n) maximal redundancy/sample upper bound is established for the MPM code with respect to any class of finite state sources of unifo [...] ...|$|R
40|$|Ordered labeled {{trees are}} trees {{in which the}} sibling order matters. This paper {{presents}} algorithms for three problems {{having to do with}} approximate matching for such trees with variable-length don't cares (VLDC's). In strings, a VLDC symbol in the pattern may substitute for zero or more symbols in the <b>data</b> <b>string.</b> For example, if "comer" is the pattern, then the "" would substitute for the substring "put" when matching the <b>data</b> <b>string</b> "computer". Approximate VLDC matching in strings means that after the best possible substitution, the pattern still need not be the same as the <b>data</b> <b>string</b> for a match to be allowed. For example, "comer" matches "counter" within distance 1 (representing the cost of removing the "m" from "comer" and having the "" substitute for "unt"). We generalize approximate VLDC string matching to three algorithms for approximate VLDC matching on trees. The time complexity of our algorithms is O(jP j Θ jDj Θ min(depth(P); leaves(P)) Θ min(de [...] ...|$|R
40|$|Spatial encoded {{video is}} used for {{a large number of}} mapping {{projects}} for various applications (McCarthy T., 1999). GPS data can be encoded onto the video or audio track using different techniques. One encoding/decoding hardware system, designed by Navtech (NavTech, 2007), enables 1 Hz GPS ASCII <b>data</b> <b>strings</b> to be encoded onto...|$|E
40|$|Software package {{consists}} of FORTRAN subroutines that perform universal noiseless coding and decoding of integer and binary <b>data</b> <b>strings.</b> Purpose {{of this type}} of coding to achieve data compression in sense that coded data represents original data perfectly (noiselessly) while taking fewer bits to do so. Routines universal because they apply to virtually any "real-world" data source...|$|E
40|$|A {{system and}} method is {{described}} for converting an analog signal into a digital signal. The gain and offset of an ADC is dynamically adjusted {{so that the}} N-bits of input data are assigned to a narrower channel instead of the entire input range of the ADC. This provides greater resolution {{in the range of}} interest without generating longer digital <b>data</b> <b>strings...</b>|$|E
40|$|Data Transmission {{utilizes}} {{maximum power}} (almost 80 %) of the sensor node. • The power consumed for sending a single bit of data {{is equivalent to}} power used to execute some 100 - 1000 instructions, {{depending on the type}} of transmission media. • Hence, the power consumed by compressing “a” bits <b>data</b> <b>string</b> into “b ” bits <b>data</b> <b>string,</b> where “a>b ” has to be smaller than the power consumed by transmitting “a-b ” bit of <b>data</b> <b>string.</b> • It is also crucial to select a data compression scheme which requires less memory access during the execution. • All in all, efficient energy consumption for long life of the sensor node is what is aimed for data compression. Coding by Ordering[1] • Idea here is to code the data of some packets according to the ordering of other packets. • It is assumed that in a network there are Sink nodes and there are certain data nodes. • This scheme is a part of Data Funneling Routing algorithm, which is an algorithm for data aggregation...|$|R
5000|$|The {{firmware}} of D-Link {{products such}} as routers are notorious for containing the following hidden <b>data</b> <b>string</b> (probably as a joke from the programmers): [...] "Hey Moe, it don't woik. Nyuk nyuk nyuk nyuk *bop* Owww!" ...|$|R
50|$|A TDSC {{detector}} digitises {{the original}} calls and derives a two dimensional <b>data</b> <b>string</b> by analysing {{the parameters of}} each call with respect to time. This is analysed by a neural network to provide pattern recognition for each species.|$|R
30|$|An {{efficient}} {{solution to}} this direction, without adding new requirements like the use of dedicated hardware (i.e., smart cards), would be a password authentication mechanism. A simple approach of a password-based authentication scheme could be the use of sufficiently large and randomly generated <b>data</b> <b>strings</b> employed as passwords. In such a scheme, all nodes could agree on a password and achieve mutual authentication supported by a trivial authentication protocol.|$|E
40|$|Gene {{expression}} profiles obtained through microarray or data mining analyses often exist as vast <b>data</b> <b>strings.</b> To interpret {{the biology of}} these genetic profiles, investigators must analyze this data {{in the context of}} other information such as the biological, biochemical, or molecular function of the translated proteins. This is particularly challenging for a human analyst because large quantities of less than relevant data often bury such information. To address this need we implemented an automated routine, called Onto-Expres...|$|E
40|$|Query autocompletion is an {{important}} feature saving users many keystrokes from typing the entire query. In this paper we studytheproblemofqueryautocompletion thattolerates errors in users ’ input using edit distance constraints. Previous approaches index <b>data</b> <b>strings</b> in a trie, and continuously maintain all the prefixes of <b>data</b> <b>strings</b> whose edit distance from the query are within the threshold. The major inherent {{problem is that the}} number of such prefixes is huge for the first few characters of the query and is exponential in the alphabet size. This results in slow query response even if the entire query approximately matches only few prefixes. Inthispaper, weproposeanovelneighborhoodgenerationbased algorithm, IncNGTrie, which can achieve up to two orders of magnitude speedup over existing methods for the error-tolerant queryautocompletion problem. Ourproposed algorithm only maintains a small set of active nodes, thus saving both space and time to process the query. We also study efficient duplicate removal which is a core problem in fetching query answers. In addition, we propose optimization techniques to reduce our index size, as well as discussions on several extensions to our method. The efficiency of our method is demonstrated against existing methods through extensive experiments on real datasets. 1...|$|E
50|$|Additionally, if {{the total}} number of data bits {{available}} in the symbol is not a multiple of the codeword size, the <b>data</b> <b>string</b> is prefixed with an appropriate number of 0 bits to occupy the extra space. These bits are not included in the check word computation.|$|R
40|$|An {{embedded}} Global Positioning System (GPS) auto time synchronizing {{system is}} designed and proposed. It is fully embedded microcontroller device that extract <b>data</b> <b>string</b> from GPS receiver module and parse it into a useful data for time synchronizing purpose in a unique dock using self-developed processing software...|$|R
5000|$|Null-terminated {{arrays of}} 8 bit encoded <b>data</b> (C-style <b>strings)</b> ...|$|R
40|$|Motivated by {{considerations}} in XML database theory and model checking, <b>data</b> <b>strings</b> {{have been introduced}} {{as an extension of}} finite alphabet strings which carry, at each position, a symbol and a data value from an infinite domain. Previous work has shown {{that it is difficult to}} come up with an expressive yet decidable automaton model for data languages. Recently, such a model, data automata, was introduced. This paper introduces a simpler but equivalent model and investigates its expressive power, algorithmic and closure properties, and some extensions. ...|$|E
40|$|Adaptive codes {{have been}} {{introduced}} in [5] as {{a new class of}} non-standard variablelength codes. These codes associate variable-length codewords to symbols being encoded depending on the previous symbols in the input data string. A new data compression algorithm, called EAH, has been introduced in [7], where we have behaviorally shown that for a large class of input <b>data</b> <b>strings,</b> this algorithm substantially outperforms the well-known Lempel-Ziv universal data compression algorithm. In this paper, we translate the EAH encoder into automata theory. Key words: algorithms, coding theory, data compression, formal languages...|$|E
40|$|Abstract. Motivated by {{considerations}} in XML theory and model checking, <b>data</b> <b>strings</b> {{have been introduced}} {{as an extension of}} finite alphabet strings which carry, at each position, a symbol and a data value from an infinite domain. Previous work has shown that {{it is not easy to}} come up with an expressive yet decidable automata model for data languages. Recently, such an automata model, data automata has been introduced. This paper introduces a simpler but equivalent model and investigates its expressive power, algorithmic and closure properties and some extensions. ...|$|E
30|$|The system {{continues}} {{to go into}} the stage of data recognition. The <b>data</b> <b>string</b> is after the mode section or the status section. Because the mode has determined the data's components, then the pulse pattern of every parameter will be easily extracted and the pattern number will be known accordingly.|$|R
40|$|The Rivest-Shamir-Adleman (RSA) {{encryption}} {{method and}} the binary encoding method are assembled {{to form a}} hybrid hiding method to hide a covert digital image into a dot-matrix holographic image. First, the RSA encryption method is used to transform the covert image to form a RSA encryption <b>data</b> <b>string.</b> Then, {{all the elements of}} the RSA encryption <b>data</b> <b>string</b> are transferred into binary data. Finally, the binary data are encoded into the dot-matrix holographic image. The pixels of the dot-matrix holographic image contain seven groups of codes used for reconstructing the covert image. The seven groups of codes are identification codes, covert-image dimension codes, covert-image graylevel codes, pre-RSA bit number codes, RSA key codes, post-RSA bit number codes, and information codes. The reconstructed covert image derived from the dot-matrix holographic image and the original covert image are exactly the same...|$|R
40|$|To produce {{accurate}} {{estimates of}} the line-profile parameters of a model used to represent the spectral features in a solar oscillation power spectrum, {{it is necessary to}} (1) select the appropriate probability density function when deriving the maximum-likelihood function to be employed for the parameter estimation and (2) allow for the redistribution of spectral power caused by gaps in the <b>data</b> <b>string.</b> This paper describes a maximum-likelihood method for estimating the model parameters (based on the observed power spectrum statistics) that accounts for redistribution of spectral power caused by gaps in the <b>data</b> <b>string,</b> by convolving the model with the power spectrum of the observed window function. The accuracy and reliability of the method were tested using both artificial and authentic solar oscillation power spectrum data. A comparison of this method with various least-squares techniques is also presented...|$|R
