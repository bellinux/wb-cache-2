190|0|Public
5|$|Not all {{software}} {{states are}} vulnerable to rowhammer attacks. An attacker thus needs to find right target states in order to utilize rowhammer errors. In practice, {{one of the main}} challenges is in identifying target states. Such typically have been done by domain experts. The mainstream fault tolerance community responded to rowhammer attacks with a systematic methodology which can be used to identify, validate, and evaluate rowhammer attack target states and their <b>exploitability.</b> That work is based on the well-established fault injection-based experimental methodology, and generalized attack target states and found a few practical target states that were previously unknown.|$|E
50|$|The <b>exploitability</b> (E) metric {{describes}} {{the current state}} of exploitation techniques or automated exploitation code.|$|E
5000|$|Functionality - Capability (Size & Generality of Feature Set), Reusability (Compatibility, Interoperability, Portability), Security (Safety & <b>Exploitability)</b> ...|$|E
50|$|These six metrics {{are used}} to {{calculate}} the <b>exploitability</b> and impact sub-scores of the vulnerability. These sub-scores {{are used to}} calculate the overall base score.|$|E
50|$|The {{temporal}} metrics {{denote the}} mutable {{nature of a}} vulnerability for example the credibility of an <b>exploitability,</b> {{the current state of}} a system violation and the development of any workarounds that could be applied.|$|E
50|$|This {{would give}} an <b>exploitability</b> sub-score of 10, and an impact sub-score of 8.5, giving an overall base score of 9.0.The vector for the base score {{in this case}} would be AV:N/AC:L/Au:N/C:P/I:P/A:C. The score and vector are {{normally}} presented together to allow the recipient to fully {{understand the nature of}} the vulnerability and to calculate their own environmental score if necessary.|$|E
50|$|Metasploit's {{emerging}} {{position as}} the de facto exploit development framework led {{to the release of}} software vulnerability advisories often accompanied by a third party Metasploit exploit module that highlights the <b>exploitability,</b> risk and remediation of that particular bug. Metasploit 3.0 began to include fuzzing tools, used to discover software vulnerabilities, rather than just exploits for known bugs. This avenue can be seen with the integration of the lorcon wireless (802.11) toolset into Metasploit 3.0 in November 2006. Metasploit 4.0 was released in August 2011.|$|E
5000|$|Article 1 of the {{convention}} defined the term shelf in terms of <b>exploitability</b> rather than relying upon the geological definition. It defined a shelf [...] "to the seabed and subsoil of the submarine areas adjacent to the coast but outside {{the area of the}} territorial sea, to a depth of 200 meters or, beyond that limit, to where the depth of the superjacent waters admits of the exploitation of the natural resources of the said areas" [...] or [...] "to the seabed and subsoil of similar submarine areas adjacent to the coasts of islands".|$|E
50|$|Not all {{software}} {{states are}} vulnerable to rowhammer attacks. An attacker thus needs to find right target states in order to utilize rowhammer errors. In practice, {{one of the main}} challenges is in identifying target states. Such typically have been done by domain experts. The mainstream fault tolerance community responded to rowhammer attacks with a systematic methodology which can be used to identify, validate, and evaluate rowhammer attack target states and their <b>exploitability.</b> That work is based on the well-established fault injection-based experimental methodology, and generalized attack target states and found a few practical target states that were previously unknown.|$|E
50|$|The Geothermal Exploratory Drilling Project (GEDP) is a {{new project}} {{consisting}} of two independent stages, which aim to confirm the suitability of the geothermal resource at the Karkar field for electric power generation. If confirmed, future steps will include involvement {{of the private sector}} {{in the development of a}} geothermal power plant. Geothermal resources differ from other renewable energy sources, such as wind, solar and hydro in that the commercial <b>exploitability</b> of a geothermal field largely depends on its meeting of certain specific parameters of temperature and pressure. These parameters may be considered with sufficient confidence only upon viable assessment of the results of exploratory drillings.|$|E
5000|$|Automated bug triage is used {{to group}} {{a large number of}} failure-inducing inputs by root cause and to {{prioritize}} each individual bug by severity. A fuzzer produces a large number of inputs, and many of the failure-inducing ones may effectively expose the same software bug. Only some of these bugs are security-critical and should be patched with higher priority. For instance the CERT Coordination Center provides the Linux triage tools which group crashing inputs by the produced stack trace and lists each group according to their probability to be exploitable. The Microsoft Security Research Centre (MSEC) developed the !exploitable tool which first creates a hash for a crashing input to determine its uniqueness and then assigns an <b>exploitability</b> rating: ...|$|E
50|$|By observing past discoveries and {{production}} levels, and predicting future discovery trends, the geoscientist M. King Hubbert used statistical modelling in 1956 to accurately predict that United States oil production would peak between 1965 and 1971. Hubbert used a semi-logistical curved model (sometimes incorrectly {{compared to a}} normal distribution). He assumed the production rate of a limited resource would follow a roughly symmetrical distribution. Depending on the limits of <b>exploitability</b> and market pressures, the rise or decline of resource production over time might be sharper or more stable, appear more linear or curved. That model and its variants are now called Hubbert peak theory; they {{have been used to}} describe and predict the peak and decline of production from regions, countries, and multinational areas. The same theory has also been applied to other limited-resource production.|$|E
5000|$|In May 2017, Rio Tinto {{announced}} that the Jadar area {{has one of the}} largest lithium deposits in the world, lifting Lower Jadar's deposits to 136 million tons. The company stated that the ore deposit's mineral resource estimation confirmed the quality of the mineral. Extraction is scheduled to begin in 2023, with a projected underground <b>exploitability</b> of 50 years. , construction of a mine has not begun. A jadarite processing plant next to the mines, which will process the ore into lithium carbonate and boric acid, is also planned. The prototype facility has been constructed by the scientists from Serbia, Australia and USA and is being tested in Melbourne. Testing includes the processing of the jadarite concentrate. On 25 July 2017 a memorandum was signed by the company and the Government of Serbia, represented by the prime minister Ana Brnabić, which confirmed the year 2023 as the starting year, but also revealed that only now the working groups will be formed, studies will be conducted and the process of issuing the permits will begin. The entire enterprise was named [...] "Project Jadar".|$|E
40|$|Abstract Two studies {{examined}} women’s {{perception of}} the relationship between sexual <b>exploitability</b> and sexual attrac-tiveness and women’s use of cues to sexual <b>exploitability</b> to signal sexual accessibility. Study 1 (N = 77) found that women accurately assessed other women displaying cues to sexual ex-ploitability both as sexually exploitable and sexually attractive to men. Study 2 (N = 74) tested the predictions that women who were dispositionally inclined toward short-term mating, who were not in a committed relationship, and who perceived themselves to be low in mate value {{would be more likely to}} display cues to sexual <b>exploitability</b> as a mate attraction tactic. Results supported the first prediction. These results suggest that asubsetofwomen, thosedispositionally inclinedtowardashort-term mating strategy, employ the risky strategy of signaling sexual accessibility using cues to <b>exploitability</b> to advance their mating goals...|$|E
40|$|Although antiexploitation adaptations, such as cheater-detection mechanisms, {{have been}} well explored, {{comparatively}} little {{research has focused on}} identifying adaptations for exploitation. The present study had two purposes: (1) to identify observable cues that afford information about which women are sexually exploitable and (2) to test the hypothesis that men find cues to sexual <b>exploitability</b> sexually attractive, an adaptation that functions to motivate pursuit of accessible women. Male participants rated photographs of women who displayed varying levels of hypothesized cues to <b>exploitability.</b> We identified 22 cues indicative of sexual <b>exploitability.</b> Nineteen of these cues were correlated significantly with sexual attractiveness, supporting the central hypothesis. Results suggest that sexual attraction to <b>exploitability</b> cues functions to motivate men to employ exploitative strategies towards accessible targets, and contribute foundational knowledge to the diverse classes of cues that afford information about which women are and are not sexually exploitable...|$|E
40|$|The {{aim of this}} {{research}} was to determine the variables that characterize slate <b>exploitability</b> and to model spatial distribution. A generalized linear spatial model (GLSMs) was fitted in order to explore relationship between <b>exploitability</b> and different explanatory variables that characterize slate quality. Modelling the influence of these variables and analysing the spatial distribution of the model residuals yielded a GLSM that allows slate <b>exploitability</b> to be predicted more effectively than when using generalized linear models (GLM), which do not take spatial dependence into account. Studying the residuals and comparing the prediction capacities of the two models lead us to conclude that the GLSM is more appropriate when the response variable presents spatial distribution...|$|E
40|$|Abstract — Most of {{the attacks}} on {{computer}} systems are due {{to the presence of}} vulnerabilities in software. Recent trends show that number of newly discovered vulnerabilities still continue to be significant. Studies have also shown that the time gap between the vulnerability public disclosure and the release of an automated exploit is getting smaller. Therefore, assessing vulnerabilities <b>exploitability</b> risk is critical as it aids decision-makers prioritize among vulnerabilities, allocate resources, and choose between alternatives. Several methods have recently been proposed in the literature to deal with this challenge. However, these methods are either subjective, requires human involvement in assessing <b>exploitability,</b> or do not scale. In this research, our aim is to first identify vulnerability exploitation risk problem. Then, we introduce a novel vulnerability <b>exploitability</b> metric based on software structure properties viz. : attack entry points, vulnerability location, presence of dangerous system calls, and reachability. Based on our preliminary results, reachability and the presence of dangerous system calls appear to be a good indicator of <b>exploitability.</b> Next, we propose using the suggested metric as feature to construct a model using machine learning techniques for automatically predicting the risk of vulnerability exploitation. To build a vulnerability exploitation model, we propose using Support Vector Machines (SVMs). Once the predictor is built, given unseen vulnerable function and their <b>exploitability</b> features the model can predict whether the given function is exploitable or not...|$|E
40|$|Abstract — An unpatched {{vulnerability}} {{can lead}} to security breaches. When a new vulnerability is discovered, {{it needs to be}} assessed {{so that it can be}} prioritized. A major challenge in software security is the assessment of the potential risk due to vulnerability <b>exploitability.</b> CVSS metrics have become a de facto standard that is commonly used to assess the severity of a vulnerability. The CVSS Base Score measures severity based on <b>exploitability</b> and impact measures. CVSS <b>exploitability</b> is measured based on three metrics: Access Vector, Authentication, and Access Complexity. However, CVSS <b>exploitability</b> measures assign subjective numbers based on the views of experts. Two of its factors, Access Vector and Authentication, are the same for almost all vulnerabilities. CVSS does not specify how the third factor, Access Complexity, is measured, and hence we do not know if it considers software properties as a factor. In this paper, we propose an approach that assesses the risk of vulnerability <b>exploitability</b> based on two software properties – attack surface entry points and reachability analysis. A vulnerability is reachable if it is located in one of the entry points or is located in a function that is called either directly or indirectly by the entry points. The likelihood of an entry point being used in an attack can be assessed by using damage potential-effort ratio in the attack surface metric and the presence of system calls deemed dangerous. To illustrate the proposed method, five reported vulnerabilities of Apache HTTP server 1. 3. 0 have been examined at the source code level. The results show that the proposed approach, which uses more detailed information, can yield a risk assessment that can be different from the CVSS Base Score...|$|E
40|$|Abstract The fractal {{protein is}} a new concept for {{improving}} evolvability, scalability, <b>exploitability</b> and providing a rich medium for evolution. Here the idea of fractal proteins is introduced, {{and a series of}} experiments showing how evolution can design and exploit them within gene regulatory networks is described. ...|$|E
40|$|File {{download}} vulnerability, which exposes {{web servers}} ’ local filesystem to the public, {{is among the}} most serious security threats in the web. Exploiting this vulnerability will cause disastrous conse-quences such as, but not limited to, system intrusion, database intrusion and even the leakage of massive confidential documents. Although the file download vulnerability has been known in the literature for a long time, a comprehensive study of its <b>exploitability</b> in the wild is still lacked. In this paper, we survey the landscape of file download vulnerabilities across different countries and domains, and more importantly, examines their <b>exploitability</b> from a hacker’s perspective. We have successfully revealed the weak protection of this vulnerability in today’s web, as well as confirmed its wide <b>exploitability.</b> To demonstrate the serious consequences, we present two real-world intru-sion case studies. One is a system intrusion against a Chinese government website, and the other is a database intrusion targeted to a Chinese industrial service. Our intrusion cases have been confirmed as severe security events by CNCERT (an official security agency in China). At the end, we explore the root cause of this weak protection by analyzing the perils and pitfalls of existing defending solu-tions, and thereby propose a new enhancement. The basic idea is to deploy a mandatory access control mechanism in the server-side script engine kernel, so as to isolate the files managed by the web serve...|$|E
40|$|According to Dimson (1998), modem {{financial}} {{theory is}} founded {{on the assumption that}} markets are highly efficient. The presence of anomalous stock market behaviour has therefore attracted a great amount of research internationally. This thesis investigates the presence and <b>exploitability</b> of style anomalies on the London Stock Exchange (LSE) and is divided into three main branches of research...|$|E
40|$|Uneven spatial {{distribution}} of groundwater resources in the East Slovakia is unfavourable to their economical <b>exploitability.</b> Hitherto, the assessment of groundwater resources in particular regions expresses only the groundwater amount and quality without {{taking into account the}} dispersal of catchworks. The authors suggest to express the spatial concentration of groundwater exploitation points by several quantitative indices for complementing the resources assessment...|$|E
40|$|When solving extensive-form {{games with}} large action spaces, {{typically}} significant abstraction {{is needed to}} make the problem manageable from a modeling or computational perspective. When this occurs, a procedure is needed to interpret actions of the opponent that fall outside of our abstraction (by mapping them to actions in our abstraction). This is called an action translation mapping. Prior action translation mappings have been based on heuristics without theoretical justification. We show that the prior mappings are highly exploitable and that most of them violate certain natural desiderata. We present a new mapping that satisfies these desiderata and has significantly lower <b>exploitability</b> than the prior mappings. Furthermore, we observe that the cost of this worst-case performance benefit (low <b>exploitability)</b> is not high in practice; our mapping performs competitively with the prior mappings against no-limit Texas Hold’em agents submitted to the 2012 Annual Computer Poker Competition. We also observe several paradoxes that can arise when performing action abstraction and translation; for example, we show {{that it is possible to}} improve performance by including suboptimal actions in our abstraction and excluding optimal actions. ...|$|E
40|$|Extensive-form {{games are}} a {{powerful}} tool for represent-ing complex multi-agent interactions. Nash equilibrium strategies are commonly used as a solution concept for extensive-form games, but many games are too large for the computation of Nash equilibria to be tractable. In these large games, <b>exploitability</b> has traditionally been used to measure deviation from Nash equilibrium, and thus strategies are aimed to achieve minimal exploitabil-ity. However, while <b>exploitability</b> measures a strategy’s worst-case performance, it fails to capture how likely that worst-case is to be observed in practice. In fact, em-pirical evidence has shown that a less exploitable strat-egy can perform worse than a more exploitable strat-egy in one-on-one play against a variety of opponents. In this work, we propose a class of response functions {{that can be used to}} measure the strength of a strat-egy. We prove that standard no-regret algorithms can be used to learn optimal strategies for a scenario where the opponent uses one of these response functions. We demonstrate the effectiveness of this technique in Leduc Hold’em against opponents that use the UCT Monte Carlo tree search algorithm...|$|E
30|$|Data isolation. Researchers have {{proposed}} numerous solutions {{to enforce the}} integrity of security-critical data. Data flow integrity {{can be achieved by}} restricting all memory write operations within their bounds so that no memory error exploit can be launched (Akritidis et al. 2008; Castro et al. 2006; Oleksenko et al. 2017; Erlingsson et al. 2006; Koning et al. 2017). The high overhead of instrumenting all memory writes regardless of the <b>exploitability</b> makes these solutions far from practical.|$|E
40|$|With the {{advancement}} of fabrication processes, single domain nanomagnets devices are being exploited to design digital logic circuits. In this work we evaluate the <b>exploitability</b> of nanomagnetic technologies to design cryptographic devices, such as True Random Number Generators and Physical Unclonable Functions. To quantify the source randomness we use the tests defined in NIST SP 800 - 22 [1] while for simulate the electronic devices we use micromagnetic simulations and Digital Signal Processing to reproduce circuit binary response...|$|E
40|$|My {{research}} interests {{focus on the}} evolution of human mating strategies with an emphasis on short-term low commitment relationships, women’s sexual strategies, and long-term relationship maintenance. Recent empirical work includes changes in women’s mating strategies across the lifespan, willingness to engage in short-term low commitment relationships {{as a function of the}} potential costs and benefits of such a relationship, sex differences in detecting sexual <b>exploitability</b> in women, and individual differences in men’s feelings of jealousy and relationshi...|$|E
40|$|International audienceThe Lexicon-Grammar of French is a {{dictionary}} with structured syntactic-semantic information. In {{order to assess}} its <b>exploitability</b> in language processing, we survey four criteria: readability, degree of formalisation, degree of validity of information content, and richness in information. We contribute concrete examples to inform this discussion. We compare {{the significance of the}} criteria, in order to evaluate the validity of the priorities retained and of the compromises adopted {{in the course of the}} construction of the Lexicon-Grammar...|$|E
40|$|This thesis aims at {{studying}} the Asymmetric Multi-Processing architecture on the i. MX 6 SoloX SABRE board, featuring an ARM Cortex-A 9 core and an ARM Cortex-M 4 core. As a tangible {{application of the}} <b>exploitability</b> of this heterogeneous architecture, the prospect of using the board as a quadcopter's on-board flight control system is illustrated. A demo implementing IMU polling and data fusing algorithms is developed for the board running MQX RTOS on the Cortex-M 4 core and Linux on the Cortex-A...|$|E
40|$|Abstract — New {{advances}} in reconfigurable optical interconnect technologies {{will allow the}} fabrication of cheap, fast and run-time adaptable networks for connecting processors and memory modules in large shared-memory multiprocessor machines. Since the switching times of these components are typically high compared to the memory access time, reconfiguration can only take place on a time scale significantly above individual memory accesses. In this paper, we present preliminary results of our investigation into the <b>exploitability</b> of the space and time locality of address streams by a reconfigurable network...|$|E
40|$|The aim of {{this paper}} is to provide an {{overview}} of the papers which appear in this special issue of Accounting Forum. The paper sets out the background and rationale for this special issue, introduces the papers contained within it and discusses their contributions to the literature on social and environmental accounting and accountability in emerging and less developed economies. This discussion is informed by the notions of vulnerability and <b>exploitability.</b> The final section of the paper provides conclusions and directions for future research in this under-researched area...|$|E
40|$|This paper {{analyzes}} the actual cost of attacking TLS im-plementations that use NIST’s Dual EC pseudorandom number generator, {{assuming that the}} attacker generated the constants used in Dual EC. It {{has been known for}} several years that an attacker generating these constants and seeing a long enough stretch of Dual EC output bits can predict all future outputs; but TLS does not natu-rally provide a long enough stretch of output bits, and the cost of an attack turns out to depend heavily on choices made in implementing the RNG and on choices made in implementing other parts of TLS. Specifically, this paper investigates OpenSSL-FIPS, Windows ’ SChannel, and the C/C++ and Java versions of the RSA BSAFE library. This paper shows that Dual EC <b>exploitability</b> is fragile, and in particular is stopped by an outright bug in the certified Dual EC implementation in OpenSSL. On the other hand, this paper also shows that Dual EC <b>exploitability</b> benefits from a modification made to the Dual EC standard in 2007; from several attack op-timizations introduced here; and from various proposed TLS extensions, one of which is implemented in BSAFE, though disabled in the version we obtained and stud-ied. The paper’s attacks are implemented; benchmarked; tested against libraries modified to use new Dual EC con-stants; and verified to successfully recover TLS plaintext...|$|E
40|$|Abstract: We {{describe}} a first experiment on whether product complexity affects competition and consumers in retail markets. We {{are unable to}} detect a significant effect of product complexity on prices, except insofar as the demand elasticity for complex products is higher. However, there is qualified evidence that complex products {{have the potential to}} induce consumers to buy more than they would otherwise. In this sense, consumer <b>exploitability</b> in quantities cannot be ruled out. We also find evidence for shaping effects: consumers ’ preferences are shaped by past experience with prices, and firms may in principle exploit this to sell more...|$|E
40|$|This paper {{presents}} a semantic setup for Dutch {{on the basis}} of deep processing. The parser and generator Delilah computes a system of logical forms that is both semantically adequate, and instrumental in processing tasks like disambiguation and inference. The logical forms are derivationally related but differ as to the level of specification and <b>exploitability.</b> The semantic setup is new, and {{is likely to be the}} first computed, fully specified semantics for Dutch. One of the logical forms introduces a new way of compiling out semantic dependencies. The resulting system is discussed at the crossroad of logical semantics and computational linguistics...|$|E
40|$|This {{summary of}} {{exploitation}} {{and assessment of}} its effects has been derived from consideration of (a) historical factors, (b) prcsent distribution and population levels, and (c) relevant features of the life history and ecology of the vertebrates concerned {{as far as this}} has a bearing on the exploitation results. In marshalling the known facts w~ end up with a summary which is about twothirds history and one-third natural historv, an imbalance that brings out how little is yet known about the full life cycle and ecology of most marine vertebrates, at least in sufficient critical detail to allow an accurato estimation of <b>exploitability...</b>|$|E
30|$|The {{effects of}} drying {{parameters}} (drying temperature and time) on some physicochemical characteristics of mango seed kernels were studied. Drying temperature was impacting {{more than the}} drying time. The interaction was only significant for antioxidant activity, meaning {{that there was no}} synergetic action of drying temperature and time for water, oil, and total polyphenol content. The study showed that satisfactory properties could be achieved when acting on drying parameters. Optimization of physicochemical properties of mango seed kernels showed that compromise could permit to obtain physicochemical characteristics of importance in order to assess the <b>exploitability</b> of the results for the valorization of mango seed kernels.|$|E
