2|10|Public
40|$|In {{this short}} paper, the Responsive Systems Comparison (RSC) method is introduced. RSC is a {{structured}} method for collecting information and conducting analysis to characterize {{a wide variety}} of possible futures in order to enable the comparison of the performance of proposed systems in those futures. A case study uses the RSC to analyze a satellite radar system. The needs and expectations of a user community for such a system, the context it will operate in, and its technical basis are determined both at the present time, and with possible changes over the next 15 years. This information is used to set up an analysis that should be able to highlight systems that will deliver value under {{a wide variety of}} future situations. The case study illustrates the practicality of the method, and provides lessons for improvement and <b>implementation.</b> <b>Nomenclature</b> Nepoch 1 = Number of possible configurations of Epoch 1 Nepoch(total) = Number of possible configurations of all Epochs Nneeds = Number of possible need sets in a given Epoch Ncontexts = Number of possible context sets in a given Epoch Neras = Number of possible Era...|$|E
40|$|Gradient based {{trajectory}} optimization {{relies on}} accurate sensitivity information to robustly move a solution towards an optimum. Computational complexity of sen-sitivity calculations increases exponentially for higher problem dimensions and orders. Hence, the computation of these sensitivities is traditionally a major speed bottleneck in trajectory optimization and targeting algorithms. We propose to use Nvidia’s GPU (Graphics Processing Unit) to rapidly calculate the derivatives in a multilayer, parallel, and heterogeneous way while the CPU (Central Processing Unit) sequentially computes the less expensive state equations. The proposed tool computes both {{the first and}} second order analytic sensitivities on the GPU with double precision accuracy. For an example trajectory propagation, we demon-strate overlapped computations such that sensitivities are calculated almost for free compared to the conventional CPU <b>implementation.</b> <b>NOMENCLATURE</b> t Time vector y State vector f Equations of motion for the state g Inequality constraint vector c Equality constraint vector X Nominal state vector I Identity matrix J Performance index or cost n Dimension of state vector x, y, z Position vector u, v, w Velocity vector G Standard gravitational parameter M Mass of the body φ 1 First order state transition matrix φ 2 Second order state transition tensor Ns Number of sub-trajectories Nt Total number of integration steps SP Single precisio...|$|E
5|$|One of {{the most}} visible Hispanic {{legacies}} is the prevalence of Spanish names and surnames among Filipinos; a Spanish name and surname, however, does not necessarily denote Spanish ancestry. This peculiarity, unique among the people of Asia, came {{as a result of}} a colonial edict by Governor-General Narciso Clavería y Zaldua, which ordered the systematic distribution of family names and <b>implementation</b> of Hispanic <b>nomenclature</b> on the population.|$|R
40|$|A {{generalized}} model characterizing most remotely sensed data pixel-level fusion techniques is {{very important}} for theoretical analysis and applications. This paper focuses on the establishment of a generalized model for most data fusion methods, which is helpful to quantitatively analyze and quickly implement different data fusion techniques. As an example, the PCA fusion method is selected to demonstrate the availability of the generalized model through the generalized model based <b>implementation.</b> 1. <b>NOMENCLATURE</b> xs k th: the k band of the lower resolution multispectral image; pan: the higher resolution panchromatic band; L pan: the degraded panchromatic band; n pan A: approximation coefficients after n level GLP (Generalized Laplacian Pyramid) or a trous wavelet decomposition; n pan D: detail coefficients after n level GLP or a trous wavelet decomposition; L xsk: the k th band of multispectral image resampled or relatively processed to have same size as the panchromatic band; H xs k th: the k band of the higher resolution multispectral image after fusion; L xs k, i, j) : the pixel value of location (i,j) of the ban...|$|R
40|$|The article {{describes}} the dependence of steady operation of computer network on a deliberate change of operation modes of software and hardware. The authors consider the technologies ensuring computer network security {{with the use of}} the means variable in time and {{with the use of the}} means variable in nomenclature. Structure of the technology ensuring protection of computer networks using the softwares compatible in nomenclature has been worked through.   To verify the practical <b>implementation</b> of the <b>nomenclature</b> method using two programs BitLocker and TrueCrypt was used the virtualization program VMware Workstation 11 with the operating system Microsoft Windows 7 Enterprise without a TPM.   </div...|$|R
40|$|With recent rapid {{advances}} in genomic technologies, precise delineation of structural chromosome rearrangements at the nucleotide level {{is becoming increasingly}} feasible. In this era of “next-generation cytogenetics” (i. e., an integration of traditional cytogenetic techniques and next-generation sequencing), a consensus nomenclature is essential for accurate communication and data sharing. Currently, nomenclature for describing the sequencing data of these aberrations is lacking. Herein, we present a system called Next-Gen Cytogenetic Nomenclature, which is concordant with the International System for Human Cytogenetic Nomenclature (2013). This system starts with the alignment of rearrangement sequences by BLAT or BLAST (alignment tools) and arrives at a concise and detailed description of chromosomal changes. To facilitate usage and <b>implementation</b> of this <b>nomenclature,</b> we are developing a program designated BLA(S) T Output Sequence Tool of Nomenclature (BOSToN), a demonstrative version of which is accessible online. A standardized characterization of structural chromosomal rearrangements is essential both for research analyses and for application in the clinical setting...|$|R
50|$|One of {{the most}} visible Hispanic {{legacies}} is the prevalence of Spanish names and surnames among Filipinos; a Spanish name and surname, however, does not necessarily denote Spanish ancestry. This peculiarity, unique among the people of Asia, came {{as a result of}} a colonial edict by Governor-General Narciso Clavería y Zaldua, which ordered the systematic distribution of family names and <b>implementation</b> of Hispanic <b>nomenclature</b> on the population.The names of many streets, towns, and provinces are also in Spanish. Spanish architecture has left an imprint in the Philippines in the way many towns were designed around a central square or plaza mayor, but many of the buildings bearing its influence were demolished during World War II. Some examples remain, mainly among the country's churches, government buildings, and universities. Four Philippine baroque churches are included in the list of UNESCO World Heritage Sites: the San Agustín Church in Manila, the Paoay Church in Ilocos Norte, the Nuestra Señora de la Asunción (Santa María) Church in Ilocos Sur, and the Santo Tomás de Villanueva Church in Iloilo.|$|R
40|$|Evolutionary {{studies are}} {{generating}} {{increasing numbers of}} phylogenies which, in turn, sometimes result in changes to hierarchical organization and therefore changes in taxonomic nomenclature. A three-layered data model for a nomenclature database has been developed in order to elucidate the information structure in nomenclature and {{as a means to}} organize and manage a large, dynamic knowledge-base. In contrast to most other taxonomic databases, the model is publication-oriented rather than taxon-oriented and dynamic rather than static, in order to mimic the processes that taxonomists use naturally. The three-layered structure requires data integrity localized to each publication, instead of global data integrity, which relaxes constraints common to taxonomic databases and permits multiple taxonomic opinions: taxon names are made available as metadata within the model. Its prototype implementation, written in C++, has an autonomous self-identification mechanism to avoid spurious data-inflation in a publication-oriented data model. Self-identification is also desirable for distributed <b>implementations</b> of the <b>nomenclature</b> database. Publication-oriented design also will make maintenance easier than for taxon-oriented databases, much of the maintenance workload being amenable to automation. The three-layered data model was designed for use by taxonomists, but is also able to provide concise, reduced expression for non-experts required in biodiversity research, for example...|$|R
40|$|Sea anemone toxins are {{predominantly}} peptide and proteins that act mainly on sodium and potassium channels, {{as well as}} in a variety of target cells causing lysis. Over recent years, the number of sea anemone peptide toxins as well as cytolytic pore-forming proteins and phospholipase A(2) sequences submitted to databases has been rapidly increasing due to the developments in DNA sequencing technology and proteomic approaches. However, the lack of a systematic nomenclature has resulted in multiple names being assigned to the same toxins, toxins from unrelated species being designated by the same name, and ambiguous name designations. Therefore, in this work we propose a systematic nomenclature in which we adopted specific criteria, based on order of discovery and phylogenetic analysis, in order to avoid redundant sea anemone toxin names. <b>Implementation</b> of the <b>nomenclature</b> proposed here not only allowed us to rename the already published 191 anemone toxins without ambiguities, but {{it can be used to}} unambiguously name newly discovered toxins whether or not they are related to previously published sea anemone sequences. In the new nomenclature each toxin name contains information about the toxin 2 ̆ 7 s biological activity, origin and relationship to known isoforms. Ongoing increases in the speed of DNA sequencing will raise significantly the number of sea anemone toxin sequences in the literature. This will represent a constant challenge in their clear identification and logical classification, which could be solved using the proposed nomenclature. (c) 2012 Elsevier Ltd. All rights reserved...|$|R
40|$|The {{power of}} {{microsatellite}} markers lies {{in their ability}} to identify. Whether it is the identification of genes and associating them with known phenotypes or identifying and discerning individuals from one another, the role they play in the genetic field has been immense. Parentage testing of horses today is done via molecular means as opposed to serology. Microsatellite marker panels are decided upon by bodies such as the International Society for Animal Genetics (ISAG) in order to uphold international genotyping standards. The current horse microsatellite marker panel is not fully characterized and many markers are amplified by primers originally designed for linkage studies and were never intended for multiplex PCR analysis. The aim {{of this study was to}} refine and validate the current marker panel used for horses through sequencing of the repeat elements and flanking regions as well as the design of new primers for the setup of a marker panel incorporating more microsatellites and better primers. Sequencing of microsatellite flanking regions revealed that much variation lies within the regions flanking a microsatellite repeat element. Sequencing of the repeat element showed that not all markers are simple repeats, as was previously thought. The primers used to amplify microsatellite markers for horses were re-designed in the course of this study, utilizing knowledge gained from flanking region variation and repeat element length. New primers and known allele sizes allowed for the <b>implementation</b> of a <b>nomenclature</b> system in horses based on repeat element length as opposed to alphabet letters. By incorporating more markers into the panel it was hoped that a greater discriminatory power would be achieved. Measures of genetic diversity such as Observed Heterozygosity and Polymorphism Information Content showed negligible differences between the two panels however genotyping data from the old ISAG panel of nine markers showed that the probability of excluding an individual in a parentage test was better when using more markers. Dissertation (MSc) [...] University of Pretoria, 2011. Production Animal Studiesunrestricte...|$|R
40|$|Research Doctorate - Doctor of Philosophy (PhD) Throughout his Sprawl and Bridge trilogies, each {{of which}} portray visions of a future {{evolving}} from his postmodern present, William Gibson expresses concerns regarding postmodernization {{and its impact on}} individuals and society alike. I argue that in these trilogies in particular, Gibson asserts the view that the various dilemmas faced by postmodern culture arise from its passive submission to commodification and technologization. By adopting a Jamesonian approach to the postmodern and combining it with Guy Debord’s theory of spectacular societies and Jean Baudrillard’s hypotheses on postmodern consumerism, I analyze the way Gibson’s fiction details the possible consequences of spectacularization on cultural discourses, the human body, and historical perspective. In Fredric Jameson’s view, postmodernism is imbricated in “the cultural logic of late capitalism. ” For Gibson, this logic, and its relationship to the development of multinational corporate powers, is {{the driving force behind the}} cultural constitution of his fictional worlds. The Sprawl and Bridge trilogies both articulate perspectives on consumer culture, its evolution within late capitalist societies, and the remodelling of discursive practices it initiates. Through his <b>implementation</b> of technological <b>nomenclature</b> in the Sprawl trilogy and his demonstration of consumer excess in the Bridge trilogy, Gibson expresses anxieties about the spectacle and its relationship to postmodern culture. He further develops these anxieties by way of his approach to posthuman forms and their existential boundaries, and by his profound commentary on postmodernism’s influence on both cultural history and personal memory. These three issues, emerging from Gibson’s observations of the 1980 s and 1990 s, form the basis of the discussion undertaken in this thesis. Essentially, postmodern culture does not just embrace new technologies or accept the logic of late capitalism with which consumer desires correspond. It also submits entirely to spectacularization, which, as Gibson puts forth in his work, challenges the very nature of humanity as well as our ability to fully understand, or respond to, the world in which we live...|$|R
40|$|Abstract Background Autocoding (or {{automatic}} concept indexing) {{occurs when}} a software program extracts terms contained within text and maps them to a standard list of concepts contained in a nomenclature. The purpose of autocoding {{is to provide a}} way of organizing large documents by the concepts represented in the text. Because textual data accumulates rapidly in biomedical institutions, the computational methods used to autocode text must be very fast. The {{purpose of this paper is}} to describe the doublet method, a new algorithm for very fast autocoding. Methods An autocoder was written that transforms plain-text into intercalated word doublets (e. g. "The ciliary body produces aqueous humor" becomes "The ciliary, ciliary body, body produces, produces aqueous, aqueous humor"). Each doublet is checked against an index of doublets extracted from a standard nomenclature. Matching doublets are assigned a numeric code specific for each doublet found in the nomenclature. Text doublets that do not match the index of doublets extracted from the nomenclature are not part of valid nomenclature terms. Runs of matching doublets from text are concatenated and matched against nomenclature terms (also represented as runs of doublets). Results The doublet autocoder was compared for speed and performance against a previously published phrase autocoder. Both autocoders are Perl scripts, and both autocoders used an identical text (a 170 + Megabyte collection of abstracts collected through a PubMed search) and the same nomenclature (neocl. xml, containing over 102, 271 unique names of neoplasms). In side-by-side comparison on the same computer, the doublet method autocoder was 8. 4 times faster than the phrase autocoder (211 seconds versus 1, 776 seconds). The doublet method codes 0. 8 Megabytes of text per second on a desktop computer with a 1. 6 GHz processor. In addition, the doublet autocoder successfully matched terms that were missed by the phrase autocoder, while the phrase autocoder found no terms that were missed by the doublet autocoder. Conclusions The doublet method of autocoding is a novel algorithm for rapid text autocoding. The method will work with any nomenclature and will parse any ascii plain-text. An implementation of the algorithm in Perl is provided with this article. The algorithm, the Perl <b>implementation,</b> the neoplasm <b>nomenclature,</b> and Perl itself, are all open source materials. </p...|$|R

