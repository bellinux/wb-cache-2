20|10000|Public
40|$|The authors model trades-through, <b>i.</b> <b>e.</b> <b>transactions</b> {{that reach}} {{at least the}} second level of limit orders in an order book. Using tick-by-tick data on Euronext-traded stocks, they show that a simple bivariate Hawkes process fits nicely their {{empirical}} observations of tradesthrough. The authors show that the cross-influence of bid and ask trades-through is weak...|$|E
40|$|International audienceThe authors model trades-through, <b>i.</b> <b>e.</b> <b>transactions</b> {{that reach}} {{at least the}} second level of limit orders in an order book. Using tick-by-tick data on Euronext-traded stocks, they show that a simple bivariate Hawkes process fits nicely their {{empirical}} observations of tradesthrough. The authors show that the cross-influence of bid and ask trades-through is weak...|$|E
40|$|We {{show that}} it is {{impossible}} to design a transactional mem-ory system which ensures parallelism, <b>i.</b> <b>e.</b> <b>transactions</b> do not need to synchronize unless they access the same appli-cation objects, while ensuring very little consistency, i. e. a consistency condition, called weak adaptive consistency, in-troduced here and which is weaker than snapshot isolation, processor consistency, and any other consistency condition stronger than them (such as opacity, serializability, causal serializability, etc.), and very little liveness, i. e. that trans-actions eventually commit if they run solo. Categories and Subject Descriptor...|$|E
40|$|This paper {{seeks to}} address the stock price {{adjustment}} toward fundamentals. Using the class of Switching Transition Error Correction Models (STECMs), we show that two regimes describe the dynamics of stock price deviations from fundamentals in the G 7 countries over the period 1969 - 2005. Deviations appear to follow a quasi random walk in the central regime when prices are near fundamentals (<b>i.</b> <b>e.</b> <b>transaction</b> costs being greater than expected gains, the mean reversion mechanism is inactive), while they approach a white noise in the outer regimes (<b>i.</b> <b>e.</b> <b>transaction</b> costs being lower than expected gains, the mean reversion works). As expected when transaction costs are heterogeneous, the STECM shows that stock price adjustments are smooth, implying that the convergence speed is time-varying according {{to the size of}} the deviation. Finally, using appropriate indicators, both the magnitudes of under- and overvaluation of stock price and the speed of the mean reversion are exhibited per date in the G 7 countries, showing that the dynamics of stock price adjustment is highly dependent on the date and on the country under consideration. Price, heterogeneous transaction costs, STECMs...|$|R
40|$|In {{this paper}} we {{consider}} privacy problems with anonymized <b>transaction</b> databases, <b>i.</b> <b>e.,</b> <b>transaction</b> databases where the items are renamed {{in order to}} hide sensitive information. In particular, we show how an anonymized transaction database can be deanonymized using non-anonymized frequent itemsets. We describe how the problem can be formulated as an integer programming task, study the computational complexity of the problem, discuss how the computations could be done more e#ciently in practice and experimentally examine the feasibility of the proposed approach...|$|R
40|$|The work {{presented}} {{focuses on}} scheduling for transaction-intensive cost-constrained cloud workflows, which are workflows {{with a large}} number of workflow instances (<b>i.</b> <b>e.</b> <b>transaction</b> intensive) bounded by a certain budget for execution (<b>i.</b> <b>e.</b> cost constrained) on a cloud computing platform (<b>i.</b> <b>e.</b> cloud workflows). First, the scheduling algorithms should take execution cost of pay for use as one key factor. Second, as an important criterion of transaction-intensive workflows, mean execution time will be taken as another key factor. Third, the algorithms should facilitate multiple strategies for compromising execution time and cost with user input enabled on the fly. Finally, they should conform to the nature of cloud computing...|$|R
40|$|M. Friedman (1956) {{suggests}} that the demand for money should be analyzed in terms of consumer demand theory, although often the interpretation of empirical results from studies using aggregate data {{appears to be in}} terms of the "motives approach" (<b>i.</b> <b>e.,</b> <b>transactions,</b> precautionary, and speculative motives). The authors develop Friedman's ideas within an explicit model of consumer theory and find that they provide a consistent framework for analyzing portfolio choice and offer greater insights into results from aggregate studies of the demand for money than the motives approach. In particular, the authors provide a new interpretation of the role of nominal interest rates, inflation, and a Hicksian measure of wealth in the demand for money function. Copyright 1991 by Royal Economic Society. ...|$|E
40|$|Computational {{models of}} trust have been {{proposed}} for use in ubicomp environments for deciding whether to allow customers to pay with an e-purse or not. In order to build trust in a customer, a means to link transactions using the same e-purse is required. Roughly, trust {{is a result of}} knowledge. As the number of transactions increases, the resulting increase in knowledge about the user of the e-purse threatens privacy due to global profiling. We present a scheme (and its prototype) that mitigates this loss of privacy without forbidding the use of trust for smoothing payment by giving the opportunity to the user to divide trust (<b>i.</b> <b>e.</b> <b>transactions)</b> according to context (e. g. location, user’s current activity or subset of shops) ...|$|E
40|$|On November 19, 2015, Treasury {{released}} Notice 2015 - 79 (the “Notice”). The Notice represents Treasury’s {{most recent}} {{response to the}} second wave of inversions, <b>i.</b> <b>e.,</b> <b>transactions</b> in which US corporations become subsidiaries of foreign corporations without a meaningful change in their underlying business or in the location of their corporate headquarters. It follows {{on the heels of}} the announcement that Pfizer Inc. is considering a merger with Allergan PLC, an inverted Irish company, and supplements Notice 2014 - 52 from September 2014. Unfortunately, just like Notice 2014 - 52, the Notice is unlikely to stem the tide, and is even unlikely to stop Pfizer/Allergan. For that, stronger executive and legislative action is needed. To understand the issues, it is important to know about the history of inversions and the three reasons that drive them...|$|E
40|$|This article classifies common Internet banking {{authentication}} methods regarding potential {{threats and}} {{their level of}} security against common credential stealing and channel breaking attacks, respectively. We present two challenge/response Internet banking authentication solutions, one based on short-time passwords and one certificate-based, and relate them to the taxonomy above. We further outline how these solutions can be easily extended for non-repudiation (<b>i.</b> <b>e.,</b> <b>transaction</b> signing), should more sophisticated content manipulation attacks become a real problem. Finally, we summarize our view on future requirements for secure Internet banking authentication and conclude by referencing real-live implementations...|$|R
40|$|Knowledge {{management}} {{has emerged as}} a very successful organization practice and has been extensively treated in a large body of academic work. Surprisingly, however, organizational economics (<b>i.</b> <b>e.,</b> <b>transaction</b> cost economics, agency theory, team theory and property rights theory) has played no {{role in the development of}} knowledge management. We argue that organizational economics insights can further the theory and practice of knowledge management in several ways. Specifically, we apply notions of contracting, team production, complementaries, hold-up, etc. to knowledge management issues (<b>i.</b> <b>e.,</b> creating and integration knowledge, rewarding knowledge workers, etc.), and derive refutable implications that are novel to the knowledge management field from our discussion. Transaction costs, organizational economics...|$|R
40|$|The article {{analyses}} how enlargements {{affect the}} speed of European Union (EU) decision-making. In line with rationalist theories of group choice, we argue that enlargements increase the costs of organizing decisions, <b>i.</b> <b>e.</b> <b>transaction</b> costs. Increasing transaction costs, in turn, slow down EU law-making. We test this theory by estimating Cox regression models that incorporate time-varying covariates on all directives, regulations and decisions submitted by the European Commission between 1976 and 2006. In contrast to previous analyses, we show that an increase in group size indeed slows down EU law-making. decision-making, enlargement, European Union, event history analysis...|$|R
40|$|An {{extended}} transaction model, {{called the}} Adaptive Transaction Model, is proposed for Real-Time Database Management System (RTDBMS) applications where partial and/or approximate results are utilized. The Adaptive Transaction Model is a nested transaction model with optional and required subtransactions. Adaptive Transactions (ATs) have time constraints to support real-time database applications. Optional subtransactions can be eliminated during execution if time (or the scheduling policy) {{does not permit}} for completion, thereby reporting partial results. A risk-based transaction load control mechanism determines each transaction's probability of completion within its deadline {{as well as the}} overall system load. 1 Introduction Recent research in real-time systems and databases has focused on the idea of utilizing partial results so that jobs (<b>i.</b> <b>e.,</b> <b>transactions)</b> meet their deadlines. In other words, transactions report estimate or approximate results when they cannot complete within t [...] ...|$|E
40|$|In {{this chapter}} we present the {{analysis}} of the Wikipedia collection by means of the ELiDa framework with the aim of enriching linked data. ELiDa is based on association rule mining, an exploratory technique to discover relevant correlations hidden in the analyzed data. To compactly store the large volume of extracted knowledge and efficiently retrieve it for further analysis, a persistent structure has been exploited. The domain expert is in charge of selecting the relevant knowledge by setting filtering parameters, assessing the quality of the extracted knowledge, and enriching the knowledge with the semantic expressiveness which cannot be automatically inferred. We consider, as representative document collections, seven datasets extracted from the Wikipedia collection. Each dataset has been analyzed from two point of views (<b>i.</b> <b>e.,</b> <b>transactions</b> by documents, transactions by sentences) to highlight relevant knowledge at different levels of abstraction...|$|E
40|$|International audienceThis paper studies {{foundational}} {{issues in}} securities markets models with fixed costs of trading, <b>i.</b> <b>e.</b> <b>transactions</b> costs that are bounded {{regardless of the}} transaction size, such as fixed brokerage fees, investment taxes, operational, and processing costs or opportunity costs. We show {{that the absence of}} free lunches in such models is equivalent to the existence of a family of absolutely continuous probability measures for which the normalized securities price processes are martingales. This is a weaker condition than the absence of free lunch in frictionless models, which is equivalent to the existence of an equivalent martingale measure. We also show that the only arbitrage-free pricing rules on the set of attainable contingent claims are those that are equal to the sum of an expected value with respect to any absolutely continuous martingale measure and of a bounded fixed cost functional. Moreover, these pricing rules are the only ones to be viable as models of economic equilibrium...|$|E
40|$|The {{concept of}} cloud {{computing}} has been wide spreading very recently. Cloud computing has many unique advantages {{which can be}} utilised to facilitate (cloud) workflow execution. Transaction-intensive cost-constrained cloud workflows are workflows {{with a large number}} of workflow instances (<b>i.</b> <b>e.</b> <b>transaction</b> intensive) bounded by a certain budget for execution (<b>i.</b> <b>e.</b> cost constrained) in a cloud computing environment (<b>i.</b> <b>e.</b> cloud workflows). However, there are not any specific scheduling algorithms so far for transaction-intensive cost-constrained cloud workflows. This paper presents a novel scheduling algorithm which considers the characteristics of cloud computing to accommodate transaction-intensive cost-constrained workflows by compromising execution time and cost with user input enabled on the fly. The simulation performed demonstrates that the algorithm can reduce the mean execution cost while meeting the user-requested deadline...|$|R
40|$|This paper compares two {{approaches}} to the measurement of the resources devoted to the organisational task in the economy, <b>i.</b> <b>e.</b> Porat and Rubin’s ‘Information Economy’ and Wallis and North’s ‘Transaction Sector’. While {{there have been a}} number of studies using the information economy approach, it seems to have made way for a narrower focus on the information technology economy in recent years. The quantitative measurement of the transaction sector, on the other hand, again focuses on the wider issues involved in information activities, e. g. organisational and institutional questions. However, it is only in its infancy. Being based on a well-known theory, <b>i.</b> <b>e.</b> <b>transaction</b> cost economics, it might attract attention from a larger number of economists than does the information economy approach. The paper points out similarities and shortcomings of both approaches and indicates areas for further research...|$|R
40|$|In a broad sense, {{corporate}} governance {{is about how}} firms should be governed {{so that they are}} run effectively and efficiently. This paper takes a broad perspective on {{corporate governance}} mechanisms and considers possible synergies between corporate governance and international business (IB) research. We summarize the papers included in this Focused Issue, and draw out their main contributions to the literature. In so doing, we compare and contrast the four theoretical perspectives concerning corporate governance and IB adopted in the five papers: <b>i.</b> <b>e.</b> <b>transaction</b> cost economics, the resource-based view, agency theory, and institutional theory. Finally, we highlight five research themes (international diversification, business groups, entry modes, subsidiary mandates, and new international ownership structures) where future work explicitly addressing governance issues may prove fruitful...|$|R
40|$|The {{fusion of}} gift giving and market {{exchange}} elements in economic transactions creates practical difficulties. How can {{the parties involved}} agree {{about the meaning of}} their engagement and the value of the exchanged objects? This article tackles the topic—an important one in economic sociology—by looking at moral transactions (<b>i.</b> <b>e.,</b> <b>transactions</b> that combine pecuniary and ethical considerations). Through an empirical study of the issuance of Irish and Israeli diaspora bonds during the 1920 s and 1950 s, respectively, I identify practices that help actors overcome the difficulties inherent in moral transactions. Clarification practices allow actors to treat the exchange as either gift giving or market exchange. Blurring practices allow actors to complete a transaction without agreeing on its meaning. Blurring practices require creating a zone of indeterminacy, that is, a context in which the parties can cooperate without agreeing on their relationships. The broader implications of these practices are then discussed. Keywords gift giving, market exchange, credit and loans, zone of indeterminacy, morals and market...|$|E
40|$|In {{order to}} cope with consistency-preserving {{operations}} (<b>i.</b> <b>e.</b> <b>transactions)</b> over distributed and heterogeneous database systems, all database systems involved must support a certain transaction protocol. Unfortunately, the ECMA-PCTE standard does not contain a protocol of this kind. The common protocol for distributed transactions is the two-phase commit. An increasingly accepted industrial standard for distributed transactions covering the two-phase commit is the XA specification by the X/Open group which is supported {{by most of the}} UNIX-database vendors. In this paper we propose a concept for an interface that fulfils the XA specification and can be implemented on top of a system conforming to the ECMA-PCTE standard. Recently, more and more (distributed) applications have been based on (transactions on) database systems, e. g. CAD/CAM systems or software engineering environments which are typical PCTE applications. The two-phase commit protocol is not always adequate for all these oft en long-lived kinds of transactions. A great number of non-standard transactions have been suggested to overcome problems like inefficient blocking of data or lack of cooperation between complex activities. However, currently available transaction managers just support the two-phase commit. In {{the second part of the}} paper we present a concept for a transaction system whichallows the processing of both standard and non-standard transactions (including nested transactions, SAGAS, split-and-joint transactions, and S-transactions) over different and distributed database systems...|$|E
40|$|The profit rate {{represents}} a central concept in economics and is commonly {{seen as one}} of the most accurate indicators of economic vitality of firms, industries, and regions. The profit rate is expected to influence a number of economic processes, such as capital flows, technological change, and long-term shifts in economic activities. In regional economics, spatial variations in profitability are supposed to guide investment over space which affects the speed of regional accumulation and regional economic structures. Thus, differences in regional profit rates may be a major source for differences in regional economic development. An analysis of factors determining the regional level of profitability might deepen the understanding of regional development processes. Despite the theoretical attention which is paid to the rate of profit in regional economics there is a significant lack in empirical studies. A major reason might be the poor quality or even absence of adequate data. In this paper, an attempt is made to measure profit rates for Austrian regions on a highly disaggregated regional level (97 districts) and a 21 -year period (1972 - 1992). An explanatory conceptual model is employed in order to identify variables which affect regional profit rate variations. Three groups of determinants are distinguished: structural characteristics of a regional economy (production technology, market structures, capital-labour-relations), spatial characteristics of a regional economy (<b>i.</b> <b>e.</b> <b>transactions</b> costs and spatial externalities) and firm- and location-specific efficiencies (in terms of production process...|$|E
40|$|Industrial firms {{increasingly}} {{attempt to}} license their technologies apart from applying {{them in their}} own products. Because of the imperfections in technology markets, an active approach towards technology licensing does not automatically result in licensing transactions. To balance prior research, which has focused on licensing transactions as the outcome of licensing intentions, we take a contingency view to analyze how characteristics of a firm's innovation ecosystem determine different strategic types of licensing. Specifically, we distinguish proactive licensing, which refers to identifying recipients for technology transactions, and reactive licensing, which relates to offering licenses to infringers of a firm's intellectual property. Survey data show that environmental antecedents concerning appropriability, <b>i.</b> <b>e.,</b> patent protection and technological turbulence, and determinants regarding technology markets, <b>i.</b> <b>e.,</b> <b>transaction</b> frequency and competitive intensity, have different effects on proactive and reactive licensing. On this basis, the article has major implications for research into technology licensing, markets for technology, and open innovation. Technology licensing Technology exploitation Markets for technology Appropriability Open innovation...|$|R
40|$|From the publisher: 2 ̆ 2 This book {{addresses}} {{the provisions of}} the Internal Revenue Code that govern the U. S. operations of foreign persons (<b>i.</b> <b>e.,</b> inbound <b>transactions)</b> and the foreign operations of U. S. persons (<b>i.</b> <b>e.,</b> outbound <b>transactions).</b> Part <b>I</b> provides a general introduction and introduces the impact of tax treaties; Part II focuses on the taxation of inbound transactions and addresses such issues as the U. S. taxation of a branch or U. S. subsidiary owned by a foreign corporation. Part III considers outbound transactions and deals with the U. S. taxation of foreign corporations controlled by U. S. persons. This part also {{addresses the}} rules regarding transfer pricing between commonly controlled entities, such as a U. S. parent corporation and its foreign subsidiary. Part IV focuses on cross-border mergers and acquisitions. Particular attention is given to the role of Section 367 on cross border reorganizations. 2 ̆ 2 [URL]...|$|R
40|$|This paper {{investigates the}} time-complexity of the {{non-blocking}} atomic commit (NBAC) {{problem in a}} synchronous distributed model where t out of n processes may fail by crashing. We exhibit for t � 3 an inherent trade-off between the fast abort property of NBAC, <b>i.</b> <b>e.,</b> aborting a <b>transaction</b> {{as soon as possible}} if some process votes “no”, and the fast commit property, <b>i.</b> <b>e.,</b> committing a <b>transaction</b> as soon as possible when all processes vote “yes ” and no process crashes. We also give two algorithms: the first satisfies fast commit and a weak variant of fast abort, whereas the second satisfies fast abort and a weak variant of fast commit. © 2004 Elsevier B. V. All rights reserved...|$|R
40|$|Purpose – The {{purpose of}} this paper is to {{evaluate}} how markets in financial instruments directive (MiFID) and regulation national market system (Reg NMS) affect the competition for order flow among trading venues in, respectively, Europe and the USA. Design/methodology/approach – The paper examines the differences between MiFID and Reg NMS and provides, based on market microstructure principles, insights as to their likely impact on European and the US securities markets. Findings – Although MiFID and Reg NMS share the common objective of enhancing competition in securities markets, they adopt different provisions with respect to three issues that strongly influence the competition for order flow among trading venues. Specifically, some of the provisions set forth by the US regulation with respect to the best execution duty, the consolidation of market data and the disclosure of execution quality information appear to be more effective, compared to the European Union ones, in strengthening competition for order flow among trading venues. Research limitations/implications – Regulatory factors can only partly explain the current structure of the European and US securities markets. Technology and heterogeneity in traders' demand are other important factors that concur in shaping the European and US markets. Practical implications – The degree of competition for order flow among trading venues depends on how regulations define the best execution duty, the availability of updated and consolidated pre-trade (i. e. quotations) and post-trade (<b>i.</b> <b>e.</b> <b>transactions)</b> information and the efficiency of post-trading infrastructures. Originality/value – The paper addresses issues not yet investigated and provides valuable insights for financial intermediaries, incumbent and prospective exchanges as to the competition in the securities industry, and to regulators as to the likely impact of the new regulations. Europe, European directives, International trade, Regulation, United States of America...|$|E
40|$|Cache-oblivious B-trees {{for data}} sets stored in {{external}} memory represent an application that {{can benefit from}} the use of transactional memory (TM), yet pose several challenges for existing TM implementations. Using TM, a programmer can modify a serial, in-memory cache-oblivious B-tree (CO B-tree) to support concurrent operations in a straightforward manner, by performing queries and updates as individual transactions. In this paper, we describe three obstacles that must be overcome, however, before one can implement an efficient external-memory concurrent CO B-tree. First, CO B-trees must perform input/output (I/O) inside a transaction if the underlying data set is too large to fit in main memory. Many TM implementations, however, prohibit such transaction I/O. Second, a CO B-tree that operates on persistent data requires a TM system that supports durable transactions if the programmer wishes to be able to restore the data to a consistent state after a program crash. Finally, CO B-trees operations generate megalithic transactions, <b>i.</b> <b>e.,</b> <b>transactions</b> that modify the entire data structure, because performance guarantees on CO B-trees are only amortized bounds. In most TM implementations, these transactions create a serial bottleneck because they conflict with all other concurrent transactions operating on the CO B-tree. Of these three issues, we argue that a solution for the first two issues of transaction I/O and durability is to use a TM system that supports transactions on memory-mapped data. We demonstrate the feasibility of this approach by using LibXac, a library that supports memory-mapped transactions, to convert an existing serial implementation of a CO B-tree into a concurrent version with only a few hours of work. We believe this approach can be generalized, that memory-mapped transactions can be used for other applications that concurrently access data stored in external memory...|$|E
40|$|Numerous {{types of}} Information Systems are broadly used in various fields. With the fast {{development}} of computer network, Information System users {{care more about}} data sharing in networks. Sharing of information and changes made by dissimilar user at different permission level is controlled by super user, but the read/write operation is performed in a reliable manner. In conventional relational database, data reliability was controlled by consistency control mechanism when a data object is locked in a sharing mode, other transactions can only read it, but cannot update it. If the conventional consistency control method has been used yet, the system’s concurrency will be inadequately influenced. So there are many new necessities for the consistency control {{in the field of}} Information system (MDRTS). In present era not only the information grows enormously it also brings together in different nature of data like text, image, and picture, graphic and sound. The problem not limited only to type of data (e. g. databases) it has used in different environment of database like Mobile Database, Distributed, Real Time Database, and Database and Multimedia database. There are many aspects of data reliability problems in mobile distributed real time system (MDRTS), such as inconsistency between attribute and type of data; the inconsistency of topological relations after objects has been modified. In this paper, many cases of data reliability are discussed for Information System. As the mobile computing becomes well-liked and the database grows with information sharing security is a big issue for researchers. Reliability and Security of data is a big confront for researchers because whenever the data is not reliable and secure no maneuver on the data (e. g. transaction) is useful. It becomes more and more crucial when the data changes from one form to another (<b>i.</b> <b>e.</b> <b>transactions)</b> that are used in non-traditional environment like Mobile, Distributed, Real Time and Multimedia databases. In this paper we raise the different aspects and analyze the available solution for reliability and security of databases. Conventional Database Security has focused primarily on creating user accounts and managing user privileges level to database objects. In this paper we also talk about an impression of the present and past database security challenges...|$|E
40|$|This paper studies {{foundational}} {{issues in}} securities markets models with fixed costs of trading, <b>i.</b> <b>e.</b> <b>transaction</b> costs that are bounded {{regardless of the}} transaction size, such as : fixed brokerage fees, investment taxes, operational and processing costs, or opportunity costs. We show {{that the absence of}} free lunches in such models is equivalent to the existence of a family of absolutely continuous probability measures for which the normalized price processes are martingales, conditional to any possible future event. This is a weaker condition than the absence of free lunches in frictionless models, which is equivalent to the existence of an equivalent martingale measure. We also show that the only arbitrage free pricing rules on the set of attainable contingent claims are those that are equal to the sum of an expected value with respect to any absolutely continuous martingale measure and of a bounded fixed cost functional. Moreover, these pricing rules are the only ones to be viable as models of economic equilibrium. ...|$|R
40|$|The saga of {{strategic}} sourcing, {{due to the}} fact that globalization is inevitable and today’s manufacturers are competing in highly competitive environment, has pooled many business practices into two competing school of thoughts related to sourcing strategies, <b>i.</b> <b>e.</b> <b>Transaction</b> Cost Economics (TCE) Theory and Resource Based View (RBV). This paper investigated sourcing strategies and sourcing supplying countries of firms in Malaysia in responding to the intensified competition and put these strategies as an integral parts of firms’ distinctive competencies. Specifically, the results indicated sourcing strategies have significant effects to both financial and non-financial performance. However, both models indicated the ‘self-produce’ and ‘outsourcing’ strategies affect non-financial performance more than financial performance. The results also indicated the most popular supplying countries for both sourcing strategies (self-produce and outsourcing) are Malaysia, China and Singapore and majority of them received supply from one country. These findings provide new insights of sourcing practices among Malaysia based manufacturing firms and how those companies perceive and react to the competition environment surrounding them...|$|R
40|$|This paper {{develops}} a property rights-based view of strategy (the “PRV”). A property right (or economic right) is an individual’s net valuation, in expected terms, {{of the ability}} to directly consume the services of an asset (including, e. g., a monopoly position) or consume it indirectly through exchange. Resources expended on exchanging, protecting and capturing such rights are transaction costs, so that we directly link property rights, transaction costs, and economic value. We assume that all relevant exchange is costly and that all agents maximize their property rights. We argue that economizing with transaction costs become a distinct source of value, and potentially of sustained competitive advantage in such a setting. Strategizing revolves around influencing impediments (<b>i.</b> <b>e.,</b> <b>transaction</b> costs) to value creation. Expectations and contracting also become crucial parts of processes of creating, protecting and capturing value. We use these insights to derive a number of refutable propositions, and argue that key insights from both industrial organization economics and the resource-based view are consistent with the PRV. ...|$|R
40|$|The Markets in Financial Instruments Directive (MiFID), which {{entered into}} force on 1 November 2007, implies the {{abolition}} of the concentration rule regarding equity transactions so far in force in France. This rule, which was applied to varying degrees across Europe, resulted {{in the vast majority of}} order flow being concentrated in regulated markets, and notably in Euronext Paris for shares listed on the French stock exchange. Over the coming years, order flow will become fragmented de facto as a result of being able to execute client orders on regulated markets as well as on multilateral trading facilities (MTFs), and by use of systematic internalisers (SIs), which act as counterparties for transactions in the same way as market makers on price-driven markets such as the London Stock Exchange (LSE) or Nasdaq. The competition between trading venues, which will be enhanced at the European level, has steadily been increasing since the 1970 s. Since then, alternating series of regulations and technological progress have gradually weakened the monopolistic position of national regulated markets. The impact of this phenomenon has been a continuous fall in transaction costs, benefi ting investors and issuers of securities through a drop in the cost of capital. However, the fragmentation of order fl ow stemming from a proliferation of trading venues may raise concern about a reduction in market liquidity and a slowdown in the decline in transaction costs, which would run counter to the competitive effect between systems sought by the European regulatory authorities. Although the most conservative medium-term scenarios point to continued dominance by regulated markets, we estimate that in the case of France, a very signifi cant share of order fl ow may rapidly be executed on alternative trading systems. Here, we focus on the impact on “wholesale” transactions, <b>i.</b> <b>e.</b> <b>transactions</b> of at least EUR 50, 000, which we attribute to institutional investors. In particular, we identify the portion of these trades currently executed outside the order book. According to our estimates, these transactions constitute roughly 10 % of the traded volume on CAC 40 shares and that may be lost to the regulated market each year. This volume, which would more or less equally be distributed between SIs and MTFs operating crossing systems, only constitutes a fraction of the total volume of the wholesale market. ...|$|E
40|$|Discovering {{amino acid}} (AA) {{patterns}} on protein binding sites has recently become popular. We propose {{a method to}} discover the association relationship among AAs on binding sites. Such knowledge of binding sites is very helpful in predicting protein-protein interactions. In this paper, we focus on protein complexes which have protein-protein recognition. The association rule mining technique is used to discover geographically adjacent amino acids on a binding site of a protein complex. When mining, instead of treating all AAs of binding sites as a transaction, we geographically partition AAs of binding sites in a protein complex. AAs in a partition are treated as a transaction. For the partition process, AAs on a binding site are projected from three-dimensional to two-dimensional. And then, assisted with a circular grid, AAs on the binding site are placed into grid cells. A circular grid has ten rings: a central ring, the second ring with 6 sectors, the third ring with 12 sectors, and later rings are added to four sectors in order. As for the radius of each ring, we examined the complexes and found that 10 Å is a suitable range, which can be set by the user. After placing these recognition complexes on the circular grid, we obtain mining records (<b>i.</b> <b>e.</b> <b>transactions)</b> from each sector. A sector {{is regarded as a}} record. Finally, we use the association rule to mine these records for frequent AA patterns. If the support of an AA pattern is larger than the predetermined minimum support (i. e. threshold), it is called a frequent pattern. With these discovered patterns, we offer the biologists a novel point of view, which will improve the prediction accuracy of protein-protein recognition. In our experiments, we produced the AA patterns by data mining. As a result, we found that arginine (arg) most frequently appears on the binding sites of two proteins in the recognition protein complexes, while cysteine (cys) appears the fewest. In addition, if we discriminate the shape of binding sites between concave and convex further, we discover that patterns {arg, glu, asp} and {arg, ser, asp} on the concave shape of binding sites in a protein more frequently (i. e. higher probability) make contact with {lys} or {arg} on the convex shape of binding sites in another protein. Thus, we can confidently achieve a rate of at least 78 %. On the other hand {val, gly, lys} on the convex surface of binding sites in proteins is more frequently in contact with {asp} on the concave site of another protein, and the confidence achieved is over 81 %. Applying data mining in biology can reveal more facts that may otherwise be ignored or not easily discovered by the naked eye. Furthermore, we can discover more relationships among AAs on binding sites by appropriately rotating these residues on binding sites from a three-dimension to two-dimension perspective. We designed a circular grid to deposit the data, which total to 463 records consisting of AAs. Then we used the association rules to mine these records for discovering relationships. The proposed method in this paper provides an insight into the characteristics of binding sites for recognition complexes...|$|E
40|$|The authors {{scrutinize the}} {{conceptual}} framework commonly used in the incomplete contract literature. This literature usually assumes that contractual incompleteness {{is due to the}} transaction costs of describing [...] or of even foreseeing [...] the possible states of nature in advance. They argue, however, that such transaction costs need not interfere with optimal contracting (<b>i.</b> <b>e.,</b> <b>transaction</b> costs need not be relevant), provided that agents can probabilistically forecast their possible future payoffs (even if other aspects {{of the state of the}} nature cannot be forecast). In other words, all that is required for optimality is that agents be able to perform dynamic programming, an assumption always invoked by the incomplete contract literature. The foregoing optimality result holds very generally provided that parties can commit themselves not to renegotiate. Moreover, the authors point out that renegotiation may be hard to reconcile with a framework that otherwise presumes perfect rationality. However, even if renegotiation is allowed, the result still remains valid provided that parties are risk averse. Copyright 1999 by The Review of Economic Studies Limited. ...|$|R
40|$|The Euro {{is the new}} single European {{currency}} {{for participating}} European Union (EU) member countries. The participating countries have adopted the new single currency to simplify cross-border trade, employment and travel. Through the single currency, most European travelers (or businesses), for example, will {{no longer have to}} pay the currency exchange rate fee (<b>i.</b> <b>e.,</b> <b>transaction</b> costs). In addition, there will be no need for speculation on the value of European currencies against one another as risk related to such valuation changes. The intent {{of this paper is to}} briefly discuss the historical reasons for the creation of the European Union. The current state of the European Union will be presented by stating the economic significance of this pact for the European Community. This paper will culminate with a weak-form hypothesis concerning what will happen to the European Community and the Euro in the future. A Brief European History Lesson European countries have a long history of war from the times of the Roman Empire invading, controlling and influencing much of Europe before 400 AD. Aroun...|$|R
40|$|This {{syllabus}} {{was submitted}} to the Rhodes College Office of Academic Affairs by the course instructor. Marketing Management I is organized around the study of marketing as an exchange process; <b>i.</b> <b>e.,</b> how <b>transactions</b> are initiated, motivated, facilitated and consummated. You have studied demand in economics. In this course, you will examine theories, principles and practices aimed at explaining and managing demand. Moreover, you will examine the environment within which demand arises and is managed. I hope upon completion of this course you will have sufficient theoretical understanding of marketing principles to understand and explain marketing phenomena in a logically consistent manner...|$|R
40|$|In {{planning}} an audit, auditors {{are required to}} develop a sufficient understanding of their clients' internal control systems This study examines which task structure (<b>i.</b> <b>e</b> <b>transaction</b> flow or control objective) is more effective for auditors in developing an under standing of internal control systems and in identifying internal control issues. In auditing, if a mismatch between audit task structure and the auditor's category knowledge occurs, the auditor's ability to draw on prior experiences can be impaired and consequently decision performance may be undermined Therefore, {{it is important to}} provide auditors with internal control information in an appropriate form to assist in internal control decision making. The aim {{of this paper is to}} contribute to the internal control literature in two ways: First, by examining the interaction between auditors' category knowledge and task structure using two distinct groups: group one comprising experienced practicing auditors with category knowledge developed by experience and training (with well developed knowledge structures); and group two comprising students (with less developed knowledge structures). Second, by examining these two groups, we can identify their individual task structure preferences That is, we can investigate whether an auditor exhibits enhanced decision making when task structure is compatible with their knowledge structure. 42 page(s...|$|R
