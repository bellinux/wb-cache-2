276|42|Public
5|$|Although Itanium did attain {{limited success}} in the niche market of <b>high-end</b> <b>computing,</b> Intel had {{originally}} hoped it would find broader acceptance {{as a replacement for}} the original x86 architecture.|$|E
5|$|The Itanium 2 {{processor}} {{was released}} in 2002, and was marketed for enterprise servers rather than for the whole gamut of <b>high-end</b> <b>computing.</b> The first Itanium2, code-named McKinley, was jointly developed by HP and Intel. It relieved many of the performance problems of the original Itanium processor, which were mostly caused by an inefficient memory subsystem. McKinley contains 221 million transistors (of which 25 million are for logic), measured 19.5mm by 21.6mm (421mm2) and was fabricated in a 180nm, bulk CMOS process with six layers of aluminium metallization.|$|E
25|$|The {{university}} also collaborates {{with the}} Centre for Telecommunications Value-Chain-Driven Research (CTVR) and with Bell Labs Research Ireland (BLRI). The National Centre for Sensor Research also collaborates with the National Botanic Gardens on the Eco-Sensor Network project. DCU {{is also a}} participant in the Irish Centre for <b>High-End</b> <b>Computing.</b>|$|E
5000|$|Engine is {{responsible}} for the bulk of the data processing and input/output and is typically run on a remote machine where the data is located. This eliminates the need move the data and makes <b>high-end</b> <b>compute</b> and I/O resources available to it. The engine can be run serially on a single processor or in parallel on thousands of processors.|$|R
40|$|The present review {{provides}} an overview of the role of cardiac positron emission tomography in the diagnosis and management of cardiovascular disease. It expands on the relative advantages and disadvantages over other imaging modalities as well as the available evidence supporting its value in the diagnosis and management of patients with coronary artery disease, the assessment of myocardial viability, and evaluation of the cardiac sympathetic nervous system. Furthermore, the recent developments, such as the implementation of <b>high-end</b> <b>computed</b> tomography devices to form hybrid systems, and the advances of molecular imaging probes in experimental applications are briefly discussed...|$|R
40|$|The {{ability to}} query and process very large, terabytescale {{datasets}} {{has become a}} key step in many scientific and engineering applications. In this paper, we describe the application of two middleware frameworks in an integrated fashion to provide a scalable and efficient system for execution of seismic data analysis on large datasets in a distributed environment. We investigate different strategies for efficient querying of large datasets and parallel implementations of a seismic image reconstruction algorithm. Our results on a state-of-the-art mass storage system coupled with a <b>high-end</b> <b>compute</b> cluster show that our implementation is scalable and can achieve about 2. 9 Gigabytes per second data processing rate – about 70 % of the maximum 4. 2 GB/s application-level raw I/O bandwidth of the storage platform...|$|R
5000|$|<b>High-end</b> <b>computing</b> {{infrastructure}} and applications. Further development includes {{the advancement of}} <b>high-end</b> <b>computing</b> applications, development of leading-edge cyber infrastructure, providing access to facilities and resources, enhancing infrastructure for computational and data-enabled science, and share best management practices.|$|E
5000|$|Federal Plan for <b>High-End</b> <b>Computing</b> (Second Printing - July 2004) ...|$|E
50|$|The Center is {{equipped}} with appropriate equipments and instrumentation, including <b>high-end</b> <b>computing</b> facilities.|$|E
50|$|The Computer Centre {{is one of}} the {{advanced}} computing service centre among academic institution in India. IT hosts IIT Kanpur website and provides personal web space for students and faculties. It also provides a spam filtered email server and high speed fibre optic Internet to all the hostels and the academics. Users have multiple options to choose among various interfaces to access mail service. It has Linux and windows laboratories equipped with dozens of high-end software like MATLAB, Autocad, Ansys, Abaqus etc. for use of students. Apart from departmental computer labs, computer centre hosts more than 300 Linux terminals and more than 100 Windows terminals and is continuously available to the students for academic work and recreation. Computer centre has recently adopted an open source software policy for its infrastructure and <b>computing.</b> Various <b>high-end</b> <b>compute</b> and GPU servers are remotely available from data centre for user computation.|$|R
40|$|Abstract- High-speed {{network and}} grid {{computing}} have been actively investigated, and their capabilities are being demonstrated. However, their application to <b>high-end</b> scientific <b>computing</b> and modeling {{is still to}} be explored. In this paper we discuss the related issues and present our prototype work on applying XCAT 3 framework technology to geomagnetic data assimilation development with distributed computers, connected through an up to 10 Gigabit Ethernet network. I...|$|R
50|$|The Department of Visualization prepares {{students}} for careers as professional artists and engineers in fields using computing to create visual imagery such as computer animation, simulation, visual effects, electronic games, web design, graphic design, and contemporary arts. The department's {{undergraduate and graduate}} degree programs combine the study of both the science and art of image making while exposing students to hardware, software, tools, and languages of <b>high-end</b> visual <b>computing</b> in the Visualization Laboratory.|$|R
50|$|The American Super Computing Leadership Act would {{amend the}} Department of Energy <b>High-End</b> <b>Computing</b> Revitalization Act of 2004 with respect to: (1) {{exascale}} computing (computing system performance {{at or near}} 10 to the 18th power floating point operations per second); and (2) a <b>high-end</b> <b>computing</b> system with performance substantially exceeding that of systems commonly available for advanced scientific and engineering applications.|$|E
50|$|System G has 324 Mac Pros (2592 {{processor}} cores) with QDR InfiniBand in Virginia Tech's Center for <b>High-End</b> <b>Computing</b> Systems.|$|E
5000|$|<b>High-end</b> <b>computing</b> {{research}} and development. Rapid increase in <b>high-end</b> <b>computing</b> capabilities are expected, which creates challenges for developing applications and system architectures that effectively utilize billion-fold concurrency, reducing the energy per computation by orders of magnitude, achieving system resilience at extreme scales, and enabling future revolutions in simulation and big-data-enabled science and technology. Some 2013 priorities were improving extreme-scale computation devising new directions in HEC hardware, software and system architectures, and developing architectures and prototypes to take computing power and communications “beyond Moore’s Law” and enhancing productivity of dispersed collaborative teams.|$|E
50|$|Alibaba Cloud aims {{to build}} a cloud {{computing}} service platform, including e-commerce data mining, e-commerce data processing, and data customisation. It was established in September 2009 {{in conjunction with the}} 10th anniversary of Alibaba Group. It has R&D centres and operators in Hangzhou, Beijing, Hong Kong, Singapore, Silicon Valley and Dubai. In July 2014, Alibaba Cloud entered into a partnership deal with Inspur. Alibaba Cloud is the largest <b>high-end</b> cloud <b>computing</b> company in China. In 2009, Alibaba acquired HiChina, the largest domain registration service and web hosting service company in China, and built it into Alibaba Cloud.|$|R
40|$|We {{report on}} the {{progress}} made {{during the first year}} of the project. Most of the progress at this point has been on the theoretical and computational side. Here are the highlights: (1) A new code, tailored for <b>high-end</b> desktop <b>computing,</b> now combines modern Accelerated Dynamics (AD) with the well-tested Embedded Atom Method (EAM); (2) The new Accelerated Dynamics allows the study of relatively slow, thermally-activated processes, such as diffusion, which are much too slow for traditional Molecular Dynamics; (3) We have benchmarked the new AD code on a rather simple and well-known process: vacancy diffusion in copper; and (4) We have begun application of the AD code to the diffusion of vacancies in ordered intermetallics...|$|R
40|$|Intel {{recently}} began shipping its Xeon 1 5100 series processors, formerly known by their “Woodcrest ” code name. To evaluate {{the suitability of}} the Woodcrest processor for <b>high-end</b> scientific <b>computing,</b> we obtained access to a Woodcrest-based system at Intel and measured its performance first using computation and memory microbenchmarks, followed by full applications from the areas of climate modeling and molecular dynamics. In most cases, the Woodcrest showed excellent performance compared to a test system managed by our research group that uses Opteron processors from Advanced Micro Devices, even when taking differences in clock speed into account. Our evaluation suggests the Woodcrest to be a compelling foundation for future leadership class systems for scientific computing. ...|$|R
50|$|The Irish Centre for <b>High-End</b> <b>Computing</b> (ICHEC) is the {{national}} high-performance computing centre in Ireland. It was established in 2005 and provides supercomputing resources, support, training and related services.|$|E
50|$|Although Itanium did attain {{limited success}} in the niche market of <b>high-end</b> <b>computing,</b> Intel had {{originally}} hoped it would find broader acceptance {{as a replacement for}} the original x86 architecture.|$|E
50|$|Lenovo ThinkStations are {{workstations}} {{designed for}} <b>high-end</b> <b>computing.</b> In 2008, Lenovo expanded {{the focus of}} its THINK brand to include workstations, with the ThinkStation S10 being the first model released.|$|E
40|$|Abstract—The growing {{popularity}} of the <b>high-end</b> mobile <b>computing</b> devices – smartphones, tablets, notebooks and more – equipped with high-speed network access, enables the mobile user to watch multimedia content from any source on any screen, at any time, {{while on the move}} or stationary. In this context, the network operators must ensure smooth video streaming with the lowest service delay, jitter, and packet loss. This paper proposes a resource efficient Device-Oriented Adaptive Multimedia Scheme (DOAS) built on top of the downlink scheduler in LTE-Advanced systems. DOAS bases its adaptation decision on the end-user device display resolution information and Quality of Service (QoS). DOAS is implemented on top of the Proportional Fair (PF) and th...|$|R
5000|$|Therefore, in a subproject {{within a}} {{medically}} oriented, multi-disciplinary collaborative research center {{the development of}} a new software system was started in early 1994. The initial development was performed by Detlev Stalling, who later became the chief software architect. The software system was called “HyperPlan”, highlighting its initial target application - a planning system for hyperthermia cancer treatment. The system was being developed on [...] Silicon Graphics (SGI) computers, which at the time were the standard workstations used for <b>high-end</b> graphics <b>computing.</b> Software development was based on libraries such as OpenGL, SGI Open Inventor, and the graphical user interface libraries X11, Motif (software), and ViewKit. In 1998, X11/Motif/Viewkit were replaced by the Qt toolkit.|$|R
40|$|Abstract—Mobile {{computing}} platforms like laptops, palmtops {{and smart}} phones are increasingly replacing conventional desktop computers. Exponentially increasing transistor densities and cheap wireless connectivity {{are the key}} driving forces behind this mobile revolution. Battery technologies and cooling solutions however, are becoming the key bottlenecks in developing more powerful mobile devices. <b>High-end</b> <b>compute</b> servers and workstations also face energy problems due to cooling costs and exorbitant electricity bills. Energy-management is therefore of paramount importance in commercial computing platforms. In this work, we explore the complex architecture-dependent relationship between processor frequency, number of active cores, application performance and energy consumption. We experimentally show that conventionally studied metrics in literature like IPC, are not good indicators on all architectural platforms. We therefore proceed to develop application-aware approaches to reducing the energy consumption in modern multi-core processors without sacrificing performance. We employ Dynamic Voltage and Frequency Scaling (DVFS) and Core-Throttling techniques to control the energy consumed by the processor. First, we present a static algorithm that relies on off-line characterization of the frequency-dependence of applications. We then present a dynamic algorithm that estimates the frequency-dependence online and performs energy management. As a case study to understand the impact of parallelization on application performance, we evaluate two commonly used applications make and gunzip, which exhibit very different energy-performance characteristics. We also present an implementation of our techniques for the Intel Core 2 Duo processor using the cpufreq, powersave and ACPI drivers, on the Linux 2. 6. 22 kernel. We also evaluate our approaches along the dimensions of energy and performance, and compare the results with the powersave, conservative, ondemand and performance cpufreq governors currently employed by Linux...|$|R
5000|$|Richard D. Rinehart, an {{employee}} of DB Consulting Group Inc., for outstanding efforts in advancing the center's <b>high-end</b> <b>computing</b> and visualization capabilities, fostering multicenter collaborations, and promoting the agency and center.|$|E
50|$|EPCC {{manages a}} {{collection}} of HPC systems including ARCHER (the UK’s national <b>high-end</b> <b>computing</b> system) {{and a variety of}} smaller HPC systems. These systems are all available for industry use on a pay-per-use basis.|$|E
50|$|The University has {{supported}} high-performance computing (HPC) services since 1982. , through EPCC, it supports the UK’s national <b>high-end</b> <b>computing</b> system, ARCHER (Advanced Research Computing High End Resource), and the UK Research Data Facility (UK-RDF).|$|E
40|$|Linux {{has emerged}} as the system-of-choice in {{academic}} and production scientific computing settings. A key limitation to the use of Linux for <b>high-end</b> cluster <b>computing</b> however is its potential performance impact on application execution, since Linux dictate general policies that do not promote the performance of high-end scientific applications. In this abstract, we are presenting our Application Specific Linux (ASL), a customized Linux image that enhances the performance of the scientific applications. Our Research end-goal is a software system that automatically enables high performance scientific computing on commodity systems through application-specific customization and dynamic adaptation of the Linux OS. Our research is novel in that it combines the research done in OS specialization, extensibility and minimization as well as virtual machine monitors (VMMs) into a system that automatically customizes the kernel imag...|$|R
40|$|To {{enable the}} quick {{applications}} and services of new-born innovative optical network service (INS) in largescale <b>high-end</b> grid <b>computing,</b> we propose an overlay approach to integrate grid and emerging INS resources establishing the value-added optical grid network flexibly cross over multi-domain WSONs. In particular, we introduce an edge-mode approach which flexibly leverages new multifunction wavelength selective multicasting (WSM) {{at a special}} edge close to the core node. To integrate grid and innovative optical network technologies efficiently, we propose a unified platform - optical grid/INS network infrastructure (OGINI). Through field trial experiments over a developed metropolitan-scale wavelength switched optical network (WSON) test-bed, the feasibility of the proposed WSM scheme in the optical transmission systems and the totally automated value-added OGN constructions supported by the proposed OGINI have been verified successfully...|$|R
40|$|There {{is today}} {{consensus}} {{on the fact that}} optical interconnects can relieve bandwidth density concerns at integrated circuit boundaries. However, {{when it comes to the}} extension of this emerging interconnect technology to on-chip communication as well, such consensus seems to fall apart. The main reason consists of a fundamental lack of compelling cases proving the superior performance and/or energy properties yielded by devices of practical interest, when re-architected around a photonically-integrated communication fabric. This paper takes its steps from the consideration that manycore computing platforms are gaining momentum in the <b>high-end</b> embedded <b>computing</b> domain in the form of general-purpose programmable accelerators. Hence, the performance and energy implications when augmenting these devices with optical interconnect technology are derived by means of an accurate benchmarking framework against an aggressively optimized electrical counterpart...|$|R
5000|$|Since 2008 Genomatix has {{strongly}} {{focused on}} Next Generation Sequencing data analysis. Because {{of the large}} amount of data and the need for <b>high-end</b> <b>computing</b> power, Genomatix deploys its solutions as in-house installations (hardware software bundle) ...|$|E
50|$|The ThinkStation {{products}} from Lenovo are professional workstations designed for <b>high-end</b> <b>computing.</b> In 2008, Lenovo expanded {{the focus of}} its “THINK” brand to include workstations, with the ThinkStation S10 being the first model released. In 2014, Lenovo introduced the P Series workstations.|$|E
50|$|While {{hardware}} RAID controllers {{were available}} for a long time, they always required expensive SCSI hard drives and aimed at the server and <b>high-end</b> <b>computing</b> market. SCSI technology advantages include allowing up to 15 devices on one bus, independent data transfers, hot-swapping, much higher MTBF.|$|E
50|$|Rajendra's multi-element antenna {{arrangement}} folds flat {{when the}} vehicle is in motion. The Radar consists of a surveillance antenna array with 4000 phase control modules (PCM's) operating in the G/H-Band (4-8 GHz), engagement antenna array with 1000 PCM's operating in the I/J-Band (8-20 GHz), a 16-element IFF array and steering units. A powerful <b>high-end</b> computer <b>computes</b> phases for {{all the elements of}} the array. Rajendra controls the beam positioning sequence through beam requests for each track at adaptive data rates and performs multifunctional roles like search -confirm -track -interrogate targets, assign and lock on launchers, and launch/acquire/ track/guide missiles. The RDP supplies track data to remote group control centre. Rajendra features a Dual channel radar receiver and a C band transmitter, although the complete transmitting and receiving features and bands are unknown.|$|R
40|$|A new, radical CNN design {{approach}} {{is presented in}} this paper, considering {{the reduction of the}} total computational load during inference. This is achieved by a new holistic intervention on both the CNN architecture and the training procedure, which targets to the parsimonious inference by learning to exploit or remove the redundant capacity of a CNN architecture. This is accomplished, by the introduction of a new structural element that can be inserted as an add-on to any contemporary CNN architecture, whilst preserving or even improving its recognition accuracy. Our approach formulates a systematic and data-driven method for developing CNNs that are trained to eventually change size and form in real-time during inference, targeting to the smaller possible computational footprint. Results are provided for the optimal implementation on a few modern, <b>high-end</b> mobile <b>computing</b> platforms indicating a significant speed-up of up to x 3 times. Comment: 17 pages, 10 figures, 5 table...|$|R
40|$|An {{emerging}} technology for solutions in <b>high-end</b> applications in <b>computing</b> and telecommunication is Superconductor Electronics. A system-level {{study has been}} carried out to verify the feasibility of DfT in superconductor electronics. In this paper, we present how this can be realized to monitor so-called single-flux quantum pulses. As a part of our research, test structures have been developed to detect structural defects in this technology. We also show detailed test results of those structures. It proves {{that it is possible to}} detect possible random defects and provide defect statistics for the Niobium-based fabrication process. 1...|$|R
