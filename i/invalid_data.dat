165|94|Public
5|$|The TRIM command {{also needs}} {{the support of}} the SSD. If the {{firmware}} in the SSD does not have support for the TRIM command, the LBAs received with the TRIM command will not be marked as invalid and the drive will continue to garbage collect the data assuming it is still valid. Only when the OS saves new data into those LBAs will the SSD know to mark the original LBA as invalid. SSD Manufacturers that did not originally build TRIM support into their drives can either offer a firmware upgrade to the user, or provide a separate utility that extracts the information on the <b>invalid</b> <b>data</b> from the OS and separately TRIMs the SSD. The benefit would be realized only after each run of that utility by the user. The user could set up that utility to run periodically in the background as an automatically scheduled task.|$|E
2500|$|On December 19, 2006, GoDaddy {{received}} {{a third party}} complaint of invalid domain contact information in the WHOIS database for the domain FamilyAlbum.com. GoDaddy {{wrote a letter to}} the owner of FamilyAlbum.com saying, [...] "Whenever we receive a complaint, we are required by ICANN regulations to initiate an investigation as to whether the contact data displaying in the WHOIS database is valid data or not... On 12/19/2006 we sent a notice to you at the admin/tech contact email address and the account email address informing you of <b>invalid</b> <b>data</b> in breach of the domain registration agreement and advising you to update the information or risk cancellation of the domain. The contact information was not updated within the specified period of time and we canceled the domain." [...] The editor of [...] "Domain Name Wire" [...] said that since domain names are valuable it was reasonable to expect that the registrar would try to contact the domain owner by phone or postal mail. On February 28, 2007, GoDaddy offered to get the domain name back for the previous owner if he would indemnify GoDaddy from legal action by the new registrant. GoDaddy stated that the new owner paid $18.99 for the domain, the price of a backorder, not a regular registration. On November 2, 2007, Domain Name Wire reported that it appears that GoDaddy no longer cancels domains for invalid WHOIS. The editor on Domain Name Wire {{received a}} message from a reader who is trying to acquire a domain with obviously false WHOIS information. The message from GoDaddy said, [...] "The domain has been suspended due to invalid WHOIS. The domain will remain in suspension through expiration, including the registry's redemption period, unless the owner updates the contact information before that time." ...|$|E
50|$|Check {{constraints}} {{are used}} to ensure the validity of data in a database and to provide data integrity. If they are used at the database level, applications that use the database {{will not be able}} to add <b>invalid</b> <b>data</b> or modify valid data so the data becomes invalid, even if the application itself accepts <b>invalid</b> <b>data.</b>|$|E
40|$|We firstly suggest new cache policy {{applying}} {{the duty to}} delete <b>invalid</b> cache <b>data</b> on Non-volatile Memory (NVM). This cache policy includes generating random data and overwriting the random <b>data</b> into <b>invalid</b> cache <b>data.</b> Proposed cache policy is more economical and effective regarding perfect deletion of data. It is ensure that the <b>invalid</b> cache <b>data</b> in NVM is secure against malicious hackers. Comment: 3 pages, 8 figure...|$|R
5000|$|Negative testing {{together}} with positive testing {{allows you to}} test your application with any (valid or <b>invalid)</b> input <b>data.</b>|$|R
40|$|Model-based {{testing is}} a {{recognized}} method for testing the functionality {{of a system}} under test. However, {{it is not only}} the functionality of a system that has to be assessed. Also the security aspect has to be tested, especially for systems that provide interfaces to the Internet. In order to find vulnerabilities that could be exploited to break into or to crash a system, fuzzing is an established technique in industry. Model-based fuzzing complements model-based testing of functionality in order to find vulnerabilities by injecting <b>invalid</b> input <b>data</b> into the system. While it focuses on <b>invalid</b> input <b>data,</b> we present a complementary approach called behavioral fuzzing. Behavioral fuzzing does not inject <b>invalid</b> input <b>data</b> but sends an invalid sequence of messages to the system under test. We start with existing UML sequence diagrams - e. g. functional test cases - and modify them by applying fuzzing operators in order to generate invalid sequences of messages. We present the identified fuzzing operators and propose a classification for them. A description of a case study from the ITEA- 2 research project DIAMONDS as well as preliminary results are presented...|$|R
5000|$|There is no data {{standardization}} verification done at {{the central}} repository thus <b>invalid</b> <b>data</b> is possible.|$|E
5000|$|A data exceptionPoOps is {{recognized}} when a decimal instruction specifies invalid operands, e.g., <b>invalid</b> <b>data,</b> invalid overlap.|$|E
5000|$|Data {{cleansing}} includes {{identification and}} removal (or update) of <b>invalid</b> <b>data</b> {{from the source}} systems. The ETL process utilizing the staging area {{can be used to}} implement business logic to identify and handle [...] "invalid" [...] data. <b>Invalid</b> <b>data</b> is often defined through a combination of business rules and technical limitations. Technical constraints may additionally be placed on staging area structures (such as table constraints in a relational database) to enforce data validity rules.|$|E
50|$|Based {{on a set}} {{questionnaire}} {{the committee}} judge each item from various dimensions including {{the nature of the}} item, item difficulty, item conformity to the content controls, item bias, and item quality. Justifications have to be provided if an item is deemed <b>invalid.</b> All <b>data</b> is entered into the Center's computer.|$|R
40|$|This article {{concerns}} {{the problems of}} a defective depth map and limited field of view of Kinect-style RGB-D sensors. An anisotropic diffusion based hole-filling method is proposed to recover <b>invalid</b> depth <b>data</b> in the depth map. The field {{of view of the}} Kinect-style RGB-D sensor is extended by stitching depth and color images from several RGB-D sensors. By aligning the depth map with the color image, the registration data calculated by registering color images can be used to stitch depth and color images into a depth and color panoramic image concurrently in real time. Experiments show that the proposed stitching method can generate a RGB-D panorama with no <b>invalid</b> depth <b>data</b> and little distortion in real time and can be extended to incorporate more RGB-D sensors to construct even a 360 ° field of view panoramic RGB-D image...|$|R
40|$|Bug reports {{provide insight}} {{about the quality}} of an {{evolving}} software and about its development process. Such data, however, is often incomplete and inaccurate, and thus should be cleaned before analysis. In this paper, we present patterns that help both novice and experienced data scientists to discard <b>invalid</b> bug <b>data</b> that could lead to wrong conclusions...|$|R
5000|$|Data {{corruption}} and/or loss {{caused by}} the entry of <b>invalid</b> <b>data</b> or commands, mistakes in database or system administration processes, sabotage/criminal damage etc.|$|E
50|$|In {{the case}} of an input failure, an {{electromechanical}} instrument adds yet another indicator—typically, a bar drops across the erroneous data. EFIS, on the other hand, removes <b>invalid</b> <b>data</b> from the display and substitutes an appropriate warning.|$|E
5000|$|Due to {{the nature}} of NIDS systems, and the need for them to analyse {{protocols}} as they are captured, NIDS systems can be susceptible to same protocol based attacks that network hosts may be vulnerable. <b>Invalid</b> <b>data</b> and TCP/IP stack attacks may cause an NIDS to crash.|$|E
50|$|The NSS {{software}} crypto module {{has been}} validated five times (1997, 1999, 2002, 2007, and 2010) for conformance to FIPS 140 at Security Levels 1 and 2. NSS {{was the first}} open source cryptographic library to receive FIPS 140 validation. The NSS libraries passed the NISCC TLS/SSL and S/MIME test suites (1.6 million test cases of <b>invalid</b> input <b>data).</b>|$|R
40|$|This Bachelor's thesis {{practical}} part's {{main goal}} is transformation of <b>invalid</b> pseudoXML <b>data</b> into valid XML and use Schematron for advance validation. Teoretical part is about XML markup language. Next part ilustrates and describes data storing in OLIF, ISLE/MILE etc. standards {{and differences between}} them. Part, where the thesis concentrates on implementation, describes problems and work progress. Last part is about statistic evaluation...|$|R
40|$|Abstract—Fuzz testing or fuzzing is {{interface}} robustness testing {{by stressing}} the interface {{of a system}} under test (SUT) with <b>invalid</b> input <b>data.</b> It aims at finding security-relevant weaknesses in the implementation that {{may result in a}} crash of the system-under-test or anomalous behavior. Fuzzing means sending <b>invalid</b> input <b>data</b> to the SUT, the input space is usually huge. This is also true for behavioral fuzzing where invalid message sequences are submitted to the SUT. Because systems getting more and more complex, testing a single invalid message sequence becomes more and more time consuming due to startup and initialization of the SUT. We present an approach to make the test execution for behavioral fuzz testing more efficient by generating test cases at runtime instead of before execution, focusing on interesting regions of a message sequence based on a previously conducted risk analysis and reducing the test space by integrating already retrieved test results in the test generation process...|$|R
50|$|Business logic {{could be}} {{anywhere}} in a program. For example, given a certain format for an address, a database table could be created which has columns that correspond exactly to the fields specified in the business logic, and type checks added {{to make sure that}} no <b>invalid</b> <b>data</b> is added.|$|E
5000|$|Most fixed-size integer formats do {{not have}} any way of {{explicitly}} indicating <b>invalid</b> <b>data.</b> Converting NaN to an integer type, or performing an integer operation whose floating-point equivalent would produce NaN, usually throws an exception. In Java, such operations throw instances of [...] In C, they lead to undefined behavior.|$|E
5000|$|Code {{injection}} is {{the exploitation}} of a computer bug that is caused by processing <b>invalid</b> <b>data.</b> Injection is used by an attacker to introduce (or [...] "inject") code into a vulnerable computer program and {{change the course of}} execution. The result of successful code injection can be disastrous, for example by allowing computer worms to propagate.|$|E
50|$|In the Internet Protocol Version 4, {{the address}} 0.0.0.0 is a non-routable meta-address used to {{designate}} an invalid, unknown or non-applicable target.To give a special meaning to an otherwise <b>invalid</b> piece of <b>data</b> is {{an application of}} in-band signaling.|$|R
50|$|Cache {{coherence}} {{is provided}} by the memory controllers. Each memory controller has a cache coherence engine. The Alpha 21364 uses a directory cache coherence scheme where part of the memory is used to store Modified, Exclusive, Shared, <b>Invalid</b> (MESI) coherency <b>data.</b>|$|R
50|$|Data input {{required}} intermediate processing via punched {{paper tape}} or punched card and separate input to a repetitive, labor-intensive task, removed from user control and error-prone. <b>Invalid</b> or incorrect <b>data</b> needed correction and resubmission with consequences for data and account reconciliation.|$|R
5000|$|We {{do wrong}} things {{and see if}} the DUT can detect and behave accordingly.In this case, we must modify the PDU {{sequence}} sent to the DUT to some extent (e.g., change CmdSN of a command, set an <b>invalid</b> <b>data</b> digest...), and verify the DUT can react according to the protocol (e.g., send a Reject PDU, close the connection...).|$|E
5000|$|Because {{the value}} {{returned}} from a cache miss cannot be known ahead of time, {{it is possible for}} pre-processed instructions to be dependent upon <b>invalid</b> <b>data.</b> These are denoted by adding an [...] "invalid" [...] or INV bit to every register in the register file. If runahead was initiated by a load instruction, the load's destination register is marked INV.|$|E
50|$|Non-ECRS {{processes}} typically import valid transactions {{only and}} generate an exception {{list of the}} invalid transactions. The exception list is then printed and distributed to users who correct the <b>invalid</b> <b>data</b> elements by annotating the report. When the annotated reports are completed {{and returned to the}} billing or accounting department, the entire transaction must be manually input into the billing system. Using an ECRS eliminates this costly and time-consuming procedure.|$|E
5000|$|Servers that accept all {{e-mail address}} at RCPT TO stage but reject <b>invalid</b> ones at <b>DATA</b> stage. This is {{commonly}} done {{in order to}} prevent directory harvest attacks and will, by design, give no information about whether an e-mail address is valid and thus prevent callback verification from working.|$|R
30|$|To {{eliminate}} the seasonal factors and day factors, the matched case–control method was utilized to avoid possible bias resulting from dissimilar traffic patterns on different {{days of the}} month and the week. A 4 : 1 control-case ratio was recommended by some existing study [24]. For each specific crash case, four non-crash samples were selected. The four control samples were selected by the crash recorded time, respectively, 14  days before, 7  days before, 7  days after and 14  days after. The control samples with <b>invalid</b> traffic <b>data</b> would also {{be removed from the}} control dataset.|$|R
5000|$|It {{frequently}} {{refers to}} an error which is not detected {{at the time it}} occurs but shows up later in data errors or incorrect human decisions. Situations which are frequently called computer glitches are incorrectly written software (software bugs), incorrect instructions given by the operator (operator errors, and a failure to account for this possibility might also be considered a software bug), undetected <b>invalid</b> input <b>data</b> (this might also be considered a software bug), undetected communications errors, computer viruses, Trojan attacks and computer exploiting (sometimes called [...] "hacking").|$|R
5000|$|The same {{technique}} {{can be used}} to map two-letter {{country codes}} like [...] "us" [...] or [...] "za" [...] to country names (262 = 676 table entries), 5-digit zip codes like 13083 to city names ( [...] entries), etc. <b>Invalid</b> <b>data</b> values (such as the country code [...] "xx" [...] or the zip code 00000) may be left undefined in the table or mapped to some appropriate [...] "null" [...] value.|$|E
5000|$|A TPS {{may fail}} {{for many reasons}} such as system failure, human errors, {{hardware}} failure, incorrect or <b>invalid</b> <b>data,</b> computer viruses, software application errors or natural or man-made disasters. As it's not possible to prevent all failures, a TPS {{must be able to}} detect and correct errors when they occur and cope with failures. A TPS will go through a recovery of the database which may involve the backup, journal, checkpoint, and recovery manager: ...|$|E
50|$|Negative testing {{ensures that}} {{the plot of the}} {{application}} is according to the requirements and can handle the unwanted input and user behavior. In this testing we put <b>invalid</b> <b>data</b> and see the output against the given input.We determine that application is not doing anything that it isn't supposed to do. Negative testing is also known as failure testing or error path testing. When performing negative testing exceptions are expected. This shows that your application is able to handle improper user behavior.|$|E
40|$|An {{analysis}} {{is modified to}} incorporate the actual structure of the command signal system of the very large array (VLA). In particular, {{in addition to the}} 1 -ms command signal there is a <b>data</b> <b>invalid</b> signal that is generated. The command signals are transmitted to the antennas during the period in which the <b>data</b> <b>invalid</b> signal is on. This means that the gaps in the received data are really 1. 6 ms long rather than 1 ms long. Simulation results with this taken into account show that the VLA will not support (7, 1 / 2) convolutionally encoded telemetry at acceptable error rates at any of the Voyager telemetry data rates. VLA will support Voyager encounters provided that either concatenated coding is implemented, VLA is arrayed with another receiving site (such as Goldstone), or VLA is reconfigured so that the gaps are rotated...|$|R
5000|$|... but the {{transaction}} started before the object's read timestamp {{it means that}} something has had {{a look at the}} object, and we assume it took a copy of the object's data. So we can't write to the object as that would make any copied <b>data</b> <b>invalid,</b> so {{the transaction}} is aborted and must be restarted.|$|R
40|$|Abstract. To {{improve the}} speed and {{accuracy}} of cerebral vessel extraction, a fast and robust method is proposed in this paper. First, volume data are divided into sub-volumes by using octree, {{and at the same}} time <b>invalid</b> volume <b>data</b> are eliminated. Second, fuzzy connectedness is introduced to achieve fast cerebral vessel segmentation from 3 D MRA Images. The values of gradient and Laplacian transformation are then calculated to improve the accuracy of the distance field. Last, the center of gravity is utilized to refine the initial centerline to make it closer to the actual centerline of the vessel cavity. The experiment demonstrates that the proposed method can effectively improve {{the speed and}} precision of centerline extraction...|$|R
