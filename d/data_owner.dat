692|4765|Public
2500|$|In a pre-Feist case, West's {{citation}} copyright claim {{had been}} affirmed by the U.S. Court of Appeals for the Eighth Circuit {{in a preliminary}} injunction case in 1986 brought by West against Mead <b>Data,</b> <b>owner</b> of Lexis. West v. Mead (1986); however, in a case commenced in 1994 in the U.S. District Court for the Southern District of New York, the U.S. Court of Appeals for the Second Circuit found Feist to have undermined the reasoning in West v. Mead. [...] West's citation claims were challenged in 1994 by legal publisher, Matthew Bender & Company and by a small CD-Rom publisher HyperLaw, Inc. HyperLaw intervened, joining Matthew Bender in the citation challenge and separately challenging West's text copyright claims. [...] West was found by the Second Circuit in 1998 {{not to have a}} protectable copyright interest in its citations; neither to the first page citations nor to its internal pagination citations. [...] See Matthew Bender [...] v. West, [...] Citation Appeal. [...] The Second Circuit thereby rejected the 1996 determination of a Minnesota district court in Oasis Publishing Co. v. West Publishing Co., 924 F.Supp. 918 (D. Minn. 1996), that the outcome of West is not changed by Feist.|$|E
50|$|A {{report by}} ENISA (the European Union Agency for Network and Information Security) elaborates on {{what needs to}} be done to achieve privacy and data {{protection}} by default. It specifies that encryption and decryption operations must be carried out locally, not by remote service, because both keys and data must remain in the power of the <b>data</b> <b>owner</b> if any privacy is to be achieved. The report specifies that outsourced data storage on remote clouds is practical and relatively safe, as long as only the <b>data</b> <b>owner,</b> not the cloud service, holds the decryption keys.|$|E
5000|$|A Direct {{client is}} defined {{where there is}} a direct {{relationship}} between the <b>data</b> <b>owner</b> and the decision maker, this is further defined that there is no commission payable in these circumstances, market research agencies can be classified as direct only where the results of a campaign are shared but not the data, call centres are defined as a direct client, although the data is being used on behalf of client(s), or the call centre owner, {{as long as there is}} no commission due, and the relationship is direct between them and the <b>data</b> <b>owner.</b>|$|E
30|$|Our {{dissemination}} activities mainly targeted {{developers and}} <b>data</b> <b>owners.</b> Tourists were not our target audience, {{as they were}} a much wider audience, requiring a larger budget and greater men-power, even though user driven demand could be a motivation for <b>data</b> <b>owners</b> to publish.|$|R
40|$|Storing data on remote {{cloud storage}} makes the {{maintenance}} affordable by <b>data</b> <b>owners.</b> The reliability and trustworthiness of these remote storage locations {{is the main}} concern for <b>data</b> <b>owners</b> and cloud service providers. When multiple <b>data</b> <b>owners</b> are involved, the aspects of membership and data sharing need to be addressed. In this paper the author proposed efficient multi <b>owner</b> <b>data</b> sharing technique over cloud storage. The proposed scheme provides privacy and complexity while handling the data sharing over cloud. The proposed technique works with improved Shamir’s secret sharing group key mechanism. In this technique data can be uploaded in to the server after the encryption of the content by the secret group key. When new member joined in the group, new granted users can directly decrypt data files uploaded without contacting with <b>data</b> <b>owners.</b> Keywords...|$|R
5000|$|... {{comprehensive}} {{integration of}} geodata e.g. from different <b>data</b> <b>owners.</b>|$|R
5000|$|Discretionary Access Control (DAC)In DAC, the <b>data</b> <b>owner</b> determines who {{can access}} {{specific}} resources. For example, a system administrator may create {{a hierarchy of}} files to be accessed based on certain permissions.|$|E
50|$|The {{conditional}} ‘tag’ of the IBCPRE {{facilitates the}} fine-grained access of encrypted messages. By setting different tag values onto different encrypted messages, the <b>data</b> <b>owner</b> Alice {{can control the}} exact set of encrypted messages {{that she wants to}} share with any particular friends of her with great flexibility.|$|E
50|$|MAP is {{committed}} to the free and open dissemination of this data (where permission has been granted by the <b>data</b> <b>owner</b> to release it). Dissemination of data is facilitated via the main MAP webpage and the Explorer tool. The latter allows users to download tabular data on malaria by countries.|$|E
40|$|Cloud {{storage is}} an {{important}} service of cloud computing, which offers service for <b>data</b> <b>owners</b> to host their data in the cloud. This new paradigm of data hosting and data access services introduces two major security concerns. The first is the protection of <b>data</b> integrity. <b>Data</b> <b>owners</b> may not fully trust the cloud server and worry that data stored in the cloud could be corrupted or even removed. The second is data access control. <b>Data</b> <b>owners</b> may worry that some dishonest servers provide data access to users that are not permitted for profit gain and thus {{they can no longer}} rely on the server...|$|R
50|$|With {{their own}} tenant keys, <b>data</b> <b>owners</b> {{get a sense}} of {{ownership}} over their data. Formally, the responsibility for the data lies only with the owner, and government agencies {{may not be able to}} obtain information from Cloud computing providers (CCP) directly. Even if the providers do pass the data to government agencies, <b>data</b> <b>owners</b> assume <b>data</b> will still be in its encrypted form, hence the provider may not be deemed of evading the <b>data</b> <b>owner's</b> privacy. Anyone who wants the encrypted data may request access directly from the <b>owner</b> of the <b>data,</b> allowing the <b>owner</b> of the <b>data</b> time and space to hire lawyers for the negotiation process of what is to be handed over to the requesting party.|$|R
30|$|The {{data for}} this study were {{obtained}} with different data policies and can be made available only with consent of the respective <b>data</b> <b>owners.</b> <b>Data</b> requests can be send to the corresponding author.|$|R
50|$|By definition, BYOE secret {{keys are}} brought to the Cloud {{computing}} provider, hence actual security of BYOE is far from its perceived security. Secret keys are copied over to the Cloud environment, and providers may leak them or hand them over to government agencies at their own discretion, sometimes even without notifying the <b>data</b> <b>owner.</b>|$|E
50|$|BYOE {{was born}} as a {{reformulation}} of traditional key management {{solutions for the}} Cloud era. Explicitly named to resemble successful trends like Bring Your Own Device, BYOE branding hints that responsibility for key management translates to exclusive ownership of keys and data. In reality however, BYOE burdens the <b>data</b> <b>owner</b> with the responsibility for key management, while the owned secret keys are always handed over (read: brought) to the Cloud provider.|$|E
50|$|Access {{controllability}} {{means that}} a <b>data</b> <b>owner</b> can perform the selective restriction of access to his data outsourced to cloud. Legal users can be authorized by the owner to access the data, while others can not access it without permissions. Further, it is desirable to enforce fine-grained access control to the outsourced data, i.e., different users should be granted different access privileges with regard to different data pieces. The access authorization must be controlled only by the owner in untrusted cloud environments.|$|E
40|$|Cloud {{computing}} is {{the long}} dreamed vision of computing as a utility, where <b>data</b> <b>owners</b> can remotely store their {{data in the}} cloud to enjoy on-demand high-quality applications and services from a shared pool of configurable computing resources. While data outsourcing relieves {{the owners of the}} burden of local data storage and maintenance, it also eliminates their physical control of storage dependability and security, which traditionally has been expected by both enterprises and individuals with high service-level requirements. In order to facilitate rapid deployment of cloud data storage service and regain security assurances with outsourced data dependability, efficient methods that enable ondemand data correctness verification on behalf of cloud <b>data</b> <b>owners</b> have to be designed. In this article we propose that publicly auditable cloud data storage is able to help this nascent cloud economy become fully established. With public audit ability, a trusted entity with expertise and capabilities <b>data</b> <b>owners</b> do not possess can be delegated as an external audit party to assess the risk of outsourced data when needed. Such an auditing service not only helps save <b>data</b> <b>owners</b> computation resources but also provides a transparent yet cost-effective method for <b>data</b> <b>owners</b> to gain trust in the cloud. We describe approaches and system requirements that should be brought into consideration, and outline challenges that need to be resolved for such a publicly auditable secure cloud storage service to become a reality...|$|R
40|$|Abstract: In {{cloud service}} {{providers}} the <b>data</b> <b>owners</b> outsource their <b>data</b> in cloud databases. There are many users access their data. In this {{there are some}} security issues to provide security to outsourced data. So we introduced the secure method to provide security for data in cloud and frequent verification of multiple clouds using signature verification and symmetric cryptographic techniques. This method provides maximum security to outsourced data and secure authentication to all <b>data</b> <b>owners</b> in cloud service. I...|$|R
3000|$|We use {{an access}} tree T̃ {{to express the}} access policy {{specified}} by <b>data</b> <b>owners.</b> We introduce a hash function H: 0,[*] 1 *[*]→[*]G [...]...|$|R
50|$|One {{of the key}} {{features}} of IBCPRE is that when Alice as a <b>data</b> <b>owner</b> encrypts messages, the encryption is done for herself and only Alice herself can decrypt the encrypted messages using her secret key. There {{is no need for}} Alice to know in advance about who that she would like to share the encrypted messages with. In other words, picking the friends to share with by Alice can be done after she encrypts the messages and uploads to the Server.|$|E
50|$|Data {{integrity}} demands {{maintaining and}} assuring the accuracy and completeness of data. A <b>data</b> <b>owner</b> always expects that his {{data in a}} cloud can be stored correctly and trustworthily. It means that the data should not be illegally tampered, improperly modified, deliberately deleted, or maliciously fabricated. If any undesirable operations corrupt or delete the data, the owner {{should be able to}} detect the corruption or loss. Further, when a portion of the outsourced data is corrupted or lost, it can still be retrieved by the data users.|$|E
50|$|Specifically {{related to}} web-based search, the {{challenge}} of interoperability {{stems from the fact}} designers of web resources typically have little or no need to concern themselves with exchanging information with other web resources. Federated Search technology, which does not place format requirements on the <b>data</b> <b>owner,</b> has emerged as one solution to search interoperability challenges. In addition, standards, such as OAI-PMH, RDF, and SPARQL, have emerged recently that also help address the issue of search interoperability related to web resources. Such standards also address broader topics of interoperability, such as allowing data mining.|$|E
40|$|Abstract—With the {{prevalence}} of cloud computing, more and more data are outsourced to the untrusted cloud servers, which raises a security issue that how can <b>data</b> <b>owners</b> ensure {{the privacy of their}} data in cloud. A straightforward way is to encrypt the data before uploading, but it will face new challenge when <b>data</b> <b>owners</b> need to search on their encrypted data. Searchable encryption will help to solve this problem by enabling the cloud servers to perform searching for the <b>data</b> <b>owners</b> while not learning any information about the data and the searching criteria. Range query on large encrypted data set {{is one of the most}} difficult parts of searchable encryption. In this paper, we proposed a novel scheme which improves the security and avoids any false positive. And the evaluation shows that our scheme reduces client storage and remain efficiency compared with the existing schemes...|$|R
40|$|Today, mobile <b>data</b> <b>owners</b> lack {{consent and}} control over the release and {{utilization}} of their location data. Third party applications continuously process and access location <b>data</b> without <b>data</b> <b>owners</b> granular control and without knowledge of how location data is being used. The proliferation of IoT devices will lead to larger scale abuses of trust. In this paper we present the first design and implementation of a privacy module built into the GPSD daemon. The GPSD daemon is a low-level GPS interface that runs on GPS enabled devices. The integration of the privacy module ensures that <b>data</b> <b>owners</b> have granular control over the release of their GPS location. We describe the design of our privacy module and then evaluate the performance of private GPS release and demonstrate that strong privacy guarantees can be built into the GPSD daemon itself with minimal to no overhead. Comment: arXiv admin note: text overlap with arXiv: 1604. 0489...|$|R
40|$|The rising {{popularity}} of various social networking websites {{has created a}} huge problem on Internet privacy. Although {{it is easy to}} post photos, Comments, opinions on some events, etc. on the Web, some of these data (such as a person's location at a particular time, criticisms of a politician, etc.) are private and should not be accessed by unauthorized users. Although social networks facilitate sharing, the fear of sending sensitive data to a third party without knowledge or permission of the <b>data</b> <b>owners</b> discourages people from taking full advantage of some social networking applications. We exploit the existing relationships on social networks and build a "trust network" with transitive relationship to allow controlled data sharing so that the privacy and preferences of <b>data</b> <b>owners</b> are respected. The trust network linking private <b>data</b> <b>owners,</b> private <b>data</b> requesters, and intermediary users is a directed weighted graph. The permission value for each private data requester can be automatically assigned in this network based on the transitive relationship. Experiments were conducted to confirm the feasibility of constructing the trust network from existing social networks, and to assess the validity of permission value assignments in the query process. Since the <b>data</b> <b>owners</b> only need to define the access rights of their closest contacts once, this privacy scheme can make private data sharing easily manageable by social network participants...|$|R
5000|$|Referential {{integrity}} {{concerns the}} concept of a foreign key. The referential integrity rule states that any foreign-key value can only be in one of two states. The usual state of affairs is that the foreign-key value refers to a primary key value of some table in the database. Occasionally, and this will depend on the rules of the <b>data</b> <b>owner,</b> a foreign-key value can be null. In this case we are explicitly saying that either there is no relationship between the objects represented in the database or that this relationship is unknown.|$|E
50|$|Privacy {{notice is}} a text that will {{explain to the}} <b>data</b> <b>owner</b> how the data will be used, and is {{generated}} in print or electronic (appears as a link on a Web page). The law and its regulations mentioned in several articles that will shape this privacy notice. Additionally, on January 17, 2013 the Ministry of Economy published in the Official Journal in August Federation guidelines for generating the Privacy Notice, {{in order to minimize}} the need for them to have recourse to private companies for advice in its creation. The publication of three forms differ Privacy Notice: Integral, Simplified and Short, depending on your application.|$|E
50|$|IBCPRE {{supports}} one-to-many encryption. The <b>data</b> <b>owner</b> Alice {{can choose}} multiple friends {{to share her}} data with. For multiple friends to share the encrypted messages with, Alice simply needs to generate a re-encryption key for each of her friends and sends all the re-encryption keys to the server for carrying out the re-encryption. The number of re-encryption keys that Alice needs to generate depends {{on the number of}} friends that Alice wants to share the encrypted messages with. It does not depend on the number of encrypted messages. One re-encryption key will allow the Server to convert all the encrypted messages provided the tag of the encrypted messages and the tag of the re-encryption key matches.|$|E
40|$|Since the {{technology}} of mobile cloud computing has {{brought a lot of}} benefits to information world, many applications in mobile devices based on cloud have emerged and boomed in the last years. According to the storage limitation, <b>data</b> <b>owners</b> would like to upload and further share the data through the cloud. Due to the safety requirements, mobile <b>data</b> <b>owners</b> are requested to provide credentials such as authentication tags along with the data. However, it is impossible to require mobile <b>data</b> <b>owners</b> to provide every authenticated computational results. The solution that signers’ privilege is outsourced to the cloud would be a promising way. To solve this problem, we propose three secure multi-entities delegated authentication protocols (MEDAPs) in mobile cloud computing, which enables the multiple mobile <b>data</b> <b>owners</b> to authorize a group designated cloud servers with the signing rights. The security of MEDAPs is constructed on three cryptographic primitive identity-based multi-proxy signature (IBMPS), identity-based proxy multi-signature (IBPMS), and identity-based multi-proxy multi-signature (IBMPMS), relied on the cubic residues, equaling to the integer factorization assumption. We also give the formal security proof under adaptively chosen message attacks and chosen identity/warrant attacks. Furthermore,compared with the pairing based protocol, MEDAPs are quite efficient and the communication overhead is nearly not a linear growth with the number of cloud servers. Copyright⃝c 2015 John Wiley & Sons, Ltd...|$|R
30|$|In this chapter, some {{harmonization}} {{guidelines and}} best practices are defined for city officials and other <b>data</b> <b>owners</b> {{who are interested}} in providing and working with different spatial and non-spatial data sources.|$|R
40|$|Abstract:-In cloud {{computing}} <b>data</b> <b>owners</b> store or host their information and users access that information from cloud. Some traditional integrity verifying methods and then cannot {{be applied to}} the auditing service until the data in the cloud service can be dynamically updated. Therefore an efficient and secure dynamic multi- owner auditing protocol is designed to serve <b>data</b> <b>owners</b> that the <b>data</b> are correctly stored in the cloud. We designed a framework that provides privacy preserving and secure storage and secure verifying protocol. This framework is designed for auditing multi-owner data storage in cloud service by using cryptographic methods. I...|$|R
50|$|Very often, {{the service}} of backing up data is done by one person (or persons) in {{the service of}} others, the Owners of the data. Becoming more {{prevalent}} today also is the charging for those services back to the data Owner(s). A simple fee per backup might be agreed upon, or, as is more often the case, a complex charge based on success rates, speed, size, frequency and retention (how long the copy is kept) is put into place. Usually some form of service level agreement (SLA) is in place between the backup service provider and the <b>data</b> <b>owner</b> in which it is agreed {{what is to be done}} and how the service is to be charged for.|$|E
50|$|A {{differential}} backup {{is a type}} of data backup that preserves data, saving only the difference in the data since the last full backup. The rationale in this is that, since changes to data are generally few compared to the entire amount of data in the data repository, the amount of time required to complete the backup will be smaller than if a full backup was performed every time that the organization or <b>data</b> <b>owner</b> wishes to back up changes since the last full backup. Another advantage, at least as compared to the incremental backup method of data backup, is that at data restoration time, at most two backup media are ever needed to restore all the data. This simplifies data restores as well as increases the likelihood of shortening data restoration time.|$|E
50|$|Metadata {{repositories}} should store metadata in four classifications: ownership, descriptive characteristics, {{rules and}} policies, and physical characteristics. Ownership, showing the <b>data</b> <b>owner</b> {{and the application}} owner. The descriptive characteristics, define the names, types and lengths, and definitions describing business data or business processes. Rules and policies, will define security, data cleanliness, timelines for data, and relationships. Physical characteristics define the origin or source, and physical location. Like building a logical data model for creating a database, a logical meta model can help identify the metadata requirements for business data. The metadata repository will be centralized, decentralized, or distributed. A centralized design {{means that there is}} one database for the metadata repository that stores metadata for all applications business wide. A centralized metadata repository has the same advantages and disadvantages of a centralized database. Easier to manage because all the data is in one database, but the disadvantage is that bottlenecks may occur.|$|E
40|$|Cloud {{computing}} is {{an emerging}} {{model in which}} computing infrastructure resources are provided as a service over the Internet. <b>Data</b> <b>owners</b> can outsource their data by remotely storing them in the cloud and enjoy on-demand high quality applications and services from a shared pool of configurable computing resources. However, since <b>data</b> <b>owners</b> and cloud servers {{are not in the}} same trusted domain, the outsourced data may be at risk as the cloud server may no longer be fully trusted. Therefore, data integrity is of critical importance in such a scenario. Cloud should let either the owners or a trusted third party to audit their data storage without demanding a local copy of the <b>data</b> from <b>owners.</b> Replicating <b>data</b> on cloud servers across multiple data centers provides a higher level of scalability, availability, and durability. When the <b>data</b> <b>owners</b> ask the Cloud Service Provider (CSP) to replicate data at different servers, they are charged a higher fee by the CSP. Therefore, the <b>data</b> <b>owners</b> need to be strongly convinced that the CSP is storing all the data copies that are agreed upon in the service level contract, and the data-update requests issued by the customers have been correctly executed on all the remotely stored copies. To deal with such problems, previous multi copy verification schemes either focused on static files or incurred huge update costs in a dynamic file scenario. In this paper, we propose some ideas under a Dynamic Multi-Replica Provable Data Possession scheme (DMR-PDP) that prevents the CSP from cheating; for example, by maintaining fewer copies than paid for. DMR-PDP also supports efficient dynamic operations like block modification, insertion and deletion on data replicas over cloud servers. ...|$|R
30|$|Explanatory {{variables}} are available via internet at the locations specified. A package of NetCDF files containing all variables {{is available on}} request from the authors. Tree data are obtained from NFIs with different data policies and can be made available only with consent of the respective <b>data</b> <b>owners.</b> <b>Data</b> requests {{can be sent to}} the corresponding author.|$|R
40|$|Abstract—Data {{outsourcing}} offers cost-effective {{computing power}} to manage massive data streams and reliable access to data. For example, <b>data</b> <b>owners</b> can forward their data to clouds, {{and the clouds}} provide data mirroring, backup, and online access services to end users. However, outsourcing data to untrusted clouds requires data authentication and query integrity {{to remain in the}} control of the <b>data</b> <b>owners</b> and users. In this paper, we address this problem specifically for multi-version key-value data that is subject to continuous updates under the constraints of data integrity, data authenticity, and “freshness ” (i. e., ensuring that the value returned for a key is the latest version). We detail this problem and propose INCBM-TREE, a novel construct delivering freshness and authenticity. Compared to existing work, we provide a solution that offers (i) lightweight signing and verification on massive data update streams for <b>data</b> <b>owners</b> and users (e. g., allowing for small memory footprint and CPU usage on mobile user devices), (ii) integrity of both real-time and historic data, and (iii) support for both real-time and periodic data publication. Extensive benchmark evaluations demonstrate that INCBM-TREE achieves more throughput (in an order of magnitude) for data stream authentication than existing work. For <b>data</b> <b>owners</b> and end users that have limited computing power, INCBM-TREE can be a practical solution to authenticate the freshness of outsourced data while reaping the benefits of broadly available cloud services. I...|$|R
