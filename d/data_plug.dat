5|58|Public
40|$|We {{report the}} {{development}} of an open-sourced data warehouse builder, InterBase Data Warehouse Builder (IB-DWB), based on Borland InterBase 6 Open Edition Database Server. InterBase 6 is used for its low maintenance and small footprint. IB-DWB is designed modularly and consists of 5 main components, <b>Data</b> <b>Plug</b> Platform, Discoverer Platform, Multi-Dimensional Cube Builder, and Query Supporter, bounded together by a Kernel. It is also an extensible system, made possible by the <b>Data</b> <b>Plug</b> Platform and the Discoverer Platform. Currently, extensions are only possible via dynamic linked-libraries (DLLs). Multi-Dimensional Cube Builder represents a basal mean of data aggregation. The architectural philosophy of IB-DWB centers around providing a base platform that is extensible, which is functionally supported by expansion modules. IB-DWB is currently being hosted by sourceforge. net (Project Unix Name: ib-dwb), licensed under GNU General Public License, Version 2...|$|E
40|$|Copyright {{confirmation}} in progress. Any queries to UMER-enquiries @unimelb. edu. auWe {{report the}} development of an open-sourced data warehouse builder, InterBase Data Warehouse Builder (IB-DWB), based on Borland InterBase 6 Open Edition Database Server. InterBase 6 is used for its low maintenance and small footprint. IB-DWB is designed modularly and consists of 5 main components, <b>Data</b> <b>Plug</b> Platform, Discoverer Platform, Multi-Dimensional Cube Builder, and Query Supporter, bounded together by a Kernel. It is also an extensible system, made possible by the <b>Data</b> <b>Plug</b> Platform and the Discoverer Platform. Currently, extensions are only possible via dynamic linked-libraries (DLLs). Multi-Dimensional Cube Builder represents a basal mean of data aggregation. The architectural philosophy of IB-DWB centers around providing a base platform that is extensible, which is functionally supported by expansion modules. IB-DWB is currently being hosted by sourceforge. net (Project Unix Name: ib-dwb), licensed under GNU General Public License, Version 2. Sept. 24 - 26, 2003 Restricted Access: This resource is not available from the Digital Repository for copyright reasons. This is a citation and abstract only record...|$|E
40|$|Big data tsunami has hit Malaysia {{recently}} that has awakening {{the industry and}} academy communities to aggressively address the insight, hindsight and foresight challenges ensuring Malaysia {{to be among the}} top world players in big data information economy for the next decade. Rapid development of Information and Communication Technology (ICT) in this era is very significant due to increasing number of users accessing data keeps growing by the time. This phenomenon has been coined as big data. What is Big data??? We address big data as assets that needs unique platform to deal with bizarre behavior of datasets whose size is beyond the ability of typical data storage to manage, mine and analyze accordingly. This bizarre behavior requires three main personalities: volume, velocity, and variety that basically need new architecture, techniques, algorithms, and analytics to uncover the golden and hidden knowledge from information obesity. From these perspectives, we demonstrate our experiences in setting up our Data Science/Big Data platform, algorithms and tool to align with big <b>data</b> <b>plug</b> and play within the academic environment as well as our services to the community and industries...|$|E
30|$|Numerical experiments, in this research, {{are carried}} out using simple {{database}} that are successfully applied by Ben-Akiva and Lermans [5] for model parameter estimation of a given model specification. The reason behind this is, that a proven data base provides guarantee for successful convergence of the experimental model run. Additionally, the value of parameter estimates generated through experimental runs {{can be compared to}} true values and hence it may be concluded that all experimental runs are conducted on the right estimation track. <b>Data</b> <b>plugged</b> in model specification within tailored computing environments allow research to keep track of computational efforts: such as log-likelihood values generated for each observation until model convergence is achieved.|$|R
40|$|Markowitz's celebrated mean [...] {{variance}} portfolio optimization theory {{assumes that}} the means and covariances of the underlying asset returns are known. In practice, they are unknown {{and have to be}} estimated from historical <b>data.</b> <b>Plugging</b> the estimates into the efficient frontier that assumes known parameters has led to portfolios that may perform poorly and have counter-intuitive asset allocation weights; this has been referred to as the "Markowitz optimization enigma. " After reviewing different approaches in the literature to address these difficulties, we explain the root cause of the enigma and propose a new approach to resolve it. Not only is the new approach shown to provide substantial improvements over previous methods, but it also allows flexible modeling to incorporate dynamic features and fundamental analysis of the training sample of historical data, as illustrated in simulation and empirical studies. ...|$|R
40|$|Graduation date: 1998 A {{gas phase}} kinetic {{model for the}} CF₄/O₂ {{microwave}} discharge plasma and afterglow of our laboratory has been developed. A reaction pathway identifying the major chemical reactions is proposed. The rate coefficients of the electron impact dissociation reactions are determined at three different plasma powers using both published electron molecule collision cross section <b>data</b> and <b>plug</b> flow analysis of data collected in our system. Agreement between calculated and experimental rate coefficients is better than 20...|$|R
40|$|OBJECTIVE: To {{review the}} {{published}} literature assessing the efficacy {{and safety of}} lacrimal drainage system plug insertion for dry eye in adults. METHODS: Literature searches of the PubMed and Cochrane Library databases were last conducted on March 9, 2015, without date restrictions and were limited to English language abstracts. The searches retrieved 309 unique citations. The primary authors reviewed the titles and abstracts. Inclusion criteria specified reports that provided original data on plugs {{for the treatment of}} dry eyes in at least 25 patients. Fifty-three studies of potential relevance were assigned to full-text review. The 27 studies that met the inclusion criteria underwent data abstraction by the panels. Abstracted data included study characteristics, patient characteristics, plug type, insertion technique, treatment response, and safety information. All studies were observational and rated by a methodologist as level II or III evidence. RESULTS: The plugs included punctal, intracanalicular, and dissolving types. Fifteen studies reported metrics of improvement in dry eye symptoms, ocular-surface status, artificial tear use, contact lens comfort, and tear break-up time. Twenty-five studies included safety <b>data.</b> <b>Plug</b> placement resulted in ≥ 50 % improvement of symptoms, improvement in ocular-surface health, reduction in artificial tear use, and improved contact lens comfort in patients with dry eye. Serious complications from plugs were infrequent. Plug loss was the most commonly reported problem with punctal plugs, occurring on average in 40 % of patients. Overall, among all plug types, approximately 9 % of patients experienced epiphora and 10 % required removal because of irritation from the plugs. Canaliculitis was the most commonly reported problem for intracanalicular plugs and occurred in approximately 8 % of patients. Other complications were reported in less than 4 % of patients on average and included tearing, discomfort, pyogenic granuloma, and dacryocystitis. CONCLUSIONS: On the basis of level II and III evidence in these studies, plugs improve the signs and symptoms of moderate dry eye that are not improved with topical lubrication, and they are well tolerated. There are no level I studies that describe the efficacy or safety of lacrimal drainage system plugs...|$|E
40|$|Examination of {{embryonic}} myogenesis of two distinct, but functionally related, skeletal muscle dystrophy mutants (mdx and cav- 3 −/−) establishes {{for the first}} time that key elements of the pathology of Duchenne muscular dystrophy (DMD) and limb-girdle muscular dystrophy type 1 C (LGMD- 1 c) originate in the disruption of the embryonic cardiac and skeletal muscle patterning processes. Disruption of myogenesis occurs earlier in mdx mutants, which lack a functional form of dystrophin, than in cav- 3 −/− mutants, which lack the Cav 3 gene that encodes the protein caveolin- 3; this finding is consistent with the milder phenotype of LGMD- 1 c, a condition caused by mutations in Cav 3, and the earlier [embryonic day (E) 9. 5] expression of dystrophin. Myogenesis is severely disrupted in mdx embryos, which display developmental delays; myotube morphology and displacement defects; and aberrant stem cell behaviour. In addition, the caveolin- 3 protein is elevated in mdx embryos. Both cav- 3 −/− and mdx mutants (from E 15. 5 and E 11. 5, respectively) exhibit hyperproliferation and apoptosis of Myf 5 -positive embryonic myoblasts; attrition of Pax 7 -positive myoblasts in situ; and depletion of total Pax 7 protein in late gestation. Furthermore, both cav- 3 −/− and mdx mutants have cardiac defects. In cav- 3 −/− mutants, there is a more restricted phenotype comprising hypaxial muscle defects, an excess of malformed hypertrophic myotubes, a twofold increase in myonuclei, and reduced fast myosin heavy chain (FMyHC) content. Several mdx mutant embryo pathologies, including myotube hypotrophy, reduced myotube numbers and increased FMyHC, have reciprocity with cav- 3 −/− mutants. In double mutant (mdxcav- 3 +/−) embryos that are deficient in dystrophin (mdx) and heterozygous for caveolin- 3 (cav- 3 +/−), whereby caveolin- 3 is reduced to 50 % of wild-type (WT) levels, these phenotypes are severely exacerbated: intercostal muscle fibre density is reduced by 71 %, and Pax 7 -positive cells are depleted entirely from the lower limbs and severely attenuated elsewhere; these data suggest a compensatory rather than a contributory role for the elevated caveolin- 3 levels that are found in mdx embryos. These data establish a key role for dystrophin in early muscle formation and demonstrate that caveolin- 3 and dystrophin are essential for correct fibre-type specification and emergent stem cell function. These <b>data</b> <b>plug</b> a significant gap in the natural history of muscular dystrophy and will be invaluable in establishing an earlier diagnosis for DMD/LGMD and in designing earlier treatment protocols, leading to better clinical outcome for these patients...|$|E
40|$|Abstract. An {{evaluation}} {{model was}} established in this paper according to the mutual mapping relationships among material and energy consumption in the scrap recycling process of automotive parts. The model provides a new computing method for evaluating the energy consumption quantity in this process. Then this model was applied to a power seat for empirical research, whose <b>data</b> was <b>plugged</b> into the model to conduct the analysis, which verifies the feasibility of the model and the valuable evaluation results were obtained. ...|$|R
5000|$|EPROM (Erasable {{programmable}} read-only memory) In {{this type}} {{the data in}} it can be rewritten by removing the chip from the circuit board, exposing it to an ultraviolet light to erase the existing <b>data,</b> and <b>plugging</b> it into a PROM programmer. The IC package has a small transparent [...] "window" [...] in the top to admit the UV light. It is often used for prototypes and small production run devices, where the program in it {{may have to be}} changed at the factory.|$|R
50|$|Pod {{slurping}} is the act {{of using}} a portable data storage device such as an iPod digital audio player to illicitly download large quantities of confidential <b>data</b> by directly <b>plugging</b> it into a computer where the data are held, and which {{may be on the}} inside of a firewall.|$|R
50|$|Very stable clocks make {{comparable}} {{the readings}} from many far-flung seismometers. (Without reliable time-stamps, data from different machines would be unusable.) Development of these clocks {{was a crucial}} advance for seismologists studying the Earth's interior. After recovering an ocean-bottom seismometer, scientists can offload the instrument's <b>data</b> by <b>plugging</b> in a <b>data</b> cable. This feature saves the task of gingerly disassembling the instrument's protective casing while aboard a rolling ship. The ability to connect a seismometer to a mooring or observatory makes the instrument's data instantly available. This is a huge advantage for geologists scrambling {{to respond to a}} major earthquake.|$|R
40|$|Simulation {{of heavy}} oil thermal {{cracking}} process {{is very important}} but few researches have been published now. In this paper, a simulation framework based on the carbon number-based approach(CNCA) has been established. A systematic division rule is put forward for dividing cracked products into 59 carbon number components. Then the cracking reaction network has been structured and the corresponding reaction rate equations have been obtained. The reaction rate constants were fitted with the experimental <b>data.</b> A <b>plug</b> fluid model is used to model the cracking reactor and the simulation procedure for heavy-oil thermal-cracking process has been developed. The calculated results are compared with the plant data...|$|R
5000|$|In automobiles, all {{diagnostic}} trouble codes (DTCs) are {{logged in}} engine control units (ECUs) so {{that at the time}} of service of a vehicle, a service engineer will read all the DTCs using Tech-2 or similar tools connected to the on-board diagnostics port, and will come to know problems occurred in the vehicle. Sometimes a small OBD <b>data</b> logger is <b>plugged</b> into the same port to continuously record vehicle data.|$|R
40|$|We {{investigate}} eruptive {{activity by}} analysis of thermal-alert {{data from the}} MODIS (Moderate Resolution Imaging Spectrometer) thermal infrared satellite instrument, detected by the MODVOLC (MODIS Volcano alert) algorithm. These data are openly available on a website, and easy to use. We show how such <b>data</b> can <b>plug</b> major gaps in the conventional monitoring record of volcanoes in an otherwise generally poorly-documented region (Melanesia), including: characterising the mechanism of lava effusion at Pago; demonstrating an earlier-than-realised onset of lava effusion at Lopevi; extending the known period of lava lake activity at Ambrym; and confirming on-going activity at Bagana, Langila and Tinakula. We also add to the record of activity even at some generally better-monitored volcanoes in Indonesia, but point out that {{care must be taken}} to recognise and exclude fires...|$|R
40|$|The present paper {{reports on}} a novel way of {{increasing}} the modularity and pluggability of text-to-speech (TTS) architectures. In a proof-of-concept study, two current TTS systems, both using XML-based languages for internal <b>data</b> representation, are <b>plugged</b> together using XSLT transforms {{as a means of}} translating from one system 's internal representation to the other's. This method allows one system to use modules from the other system. The potential and the limitations of the approach are discussed...|$|R
50|$|There is {{currently}} a collaboration between NRG Energy, Inc. and AT&T to implement Street Charge units throughout New York City, which will each offer six USB ports in total. This project will cost around $300,000-500,000. As of 2013 there was a controversy surrounding Street Charge appliances in {{that there were no}} plans implemented to protect appliances and users utilizing the device. The concern was that the wiring might be modified by malicious users to steal or wipe <b>data</b> from devices <b>plugged</b> into the device.|$|R
40|$|This report {{documents}} {{the development of}} a system capable of gathering energy consumption data from multiple different brands of smart energy plugs. The problem today is that firstly the manufacturers’ software is not general and provides a limited set of functions. For example, one brand’s software may provide forecasting of energy consumption while another does not. Secondly, {{it is not possible to}} use different brands of plugs together. The system presented in this report consists of a <b>plug</b> <b>data</b> parser, a message broker and a data processing engine. The <b>plug</b> <b>data</b> parser can gather data from one or multiple different brands of energy plugs at once. Using a message broker opens the possibility to gather data from a large number of plugs at the same time and in real-time. A data processing engine enables processing of the data through which use cases are implemented. It provides functions such as calculation of a moving average for the energy consumption, the total power consumption for all plugs and provides alerts for the energy consumption. Lastly, it provides a foundation to forecast future consumption. The resulting system is capable of processing more than 500 plug readings per second in real time, from two different plug brands...|$|R
40|$|Abstract – Web {{pages are}} usually {{generated}} for visualization not for data exchange. Each page may contain several groups of structured data. Web pages are generated by <b>plugging</b> <b>data</b> values to predefined templates. Manual data extraction from semi supervised web pages {{is a difficult}} task. This paper focuses on study of various automatic web data extraction techniques. There are mainly two types of techniques one is based on wrapper induction another is automatic extraction. In wrapper induction set of extraction rules are used, which are learnt from multiple pages containing similar data records...|$|R
40|$|We {{present a}} method for {{non-linear}} data projection that offers non-linear versions of Principal Component Analysis and Canonical Correlation Analysis. The data is accessed through a probabilistic mixture model only, therefore any mixture model for any type of <b>data</b> can be <b>plugged</b> in. Gaussian mixtures are one example, but mixtures of Bernoulli's to model discrete data might be used as well. The algorithm minimizes an objective function that exhibits one global optimum {{that can be found}} by finding the eigenvectors of some matrix. Experimental results on toy data and real data are provided...|$|R
40|$|Web {{pages are}} usually {{generated}} for visualization not for data exchange. Each page may contain several groups of structured data. Web pages are generated by <b>plugging</b> <b>data</b> values to predefined templates. Manual data extraction from semi supervised web pages {{is a difficult}} task. This paper focuseson study of various automatic web data extraction techniques. There are mainly two types of techniques one is based on wrapper induction another is automatic extraction. In wrapper induction set of extraction rules are used, which are learnt from multiple pages containing similar data records...|$|R
50|$|A switch is {{a device}} in a {{computer}} network that electrically and logically connects together other devices. Multiple <b>data</b> cables are <b>plugged</b> into a switch to enable communication between different networked devices. Switches manage the flow of data across a network by transmitting a received network packet only to {{the one or more}} devices for which the packet is intended. Each networked device connected to a switch can be identified by its network address, allowing the switch to regulate the flow of traffic. This maximizes the security and efficiency of the network.|$|R
40|$|National audienceWe {{present a}} method for {{non-linear}} data projection that offers non-linear versions of Principal Component Analysis and Canonical Correlation Analysis. The data is accessed through a probabilistic mixture model only, therefore any mixture model for any type of <b>data</b> can be <b>plugged</b> in. Gaussian mixtures are one example, but mixtures of Bernoulli's to model discrete data might be used as well. The algorithm minimizes an objective function that exhibits one global optimum {{that can be found}} by finding the eigenvectors of some matrix. Experimental results on toy data and real data are provided...|$|R
40|$|The central pore of the SecYEG preprotein-conducting {{channel is}} closed at the periplasmic {{face of the}} {{membrane}} by a plug domain. To study its conformational dynamics, the plug was labeled site-specifically with an environment-sensitive fluorophore. In {{the presence of a}} stable preprotein translocation intermediate, the SecY plug showed an enhanced solvent exposure consistent with a displacement from the hydrophobic central pore region. In contrast, binding and insertion of a ribosome-bound nascent membrane protein did not alter the <b>plug</b> conformation. These <b>data</b> indicate different <b>plug</b> dynamics depending on the ligand bound state of the SecYEG channel. ...|$|R
40|$|The {{objective}} {{of this study is}} to provide an experimental performance assessment of cement borehole plugs subjected to dynamic loadings. This includes the study of dried-out plugs as well as of plugs that have remained wet throughout the testing period. Literature review indicates lack of quantitative <b>data</b> on <b>plug</b> performance under dynamic loading. Nevertheless, it shows that deep underground structures in competent rocks are safer than surface structures, openings at shallow depth, and openings in fractured rocks, when subjected to earthquakes and subsurface blasts. Flow test results indicate that wet cement seals are less permeable than Charcoal granite. Sealing performance is severely degraded when cement seals are allowed to dry. Dye injection tests show that the flow penetrates uniformly through the wet plugs, but occurs only along the plug/rock interface of the dried-out plugs. The permeability of wet and dried-out cement seals does not change significantly after the application of dynamic loads...|$|R
40|$|An {{accurate}} analytical {{interpretation method}} {{to determine the}} Leverett-function (fw) and its derivative (fw') from immiscible displacement <b>data</b> in core <b>plugs</b> is presented. Linear equations are developed to describe the displacement processes occurring before and after breakthrough. A quadratic function is introduced to represent the saturation distribution along the cores. The relationships derived in this study {{can be used for}} analysis of core tests involving constant injection rates and constant pressure differences. The applicability, practicality, and accuracy of the new analytical method are verified by means of the experimental data obtained in the present study and by those reported in the literature...|$|R
40|$|AbstractA {{building}} energy simulation {{relies on}} accurate parameterisation of occupant-related internal loads to simulate a realistic energy balance within a building. The internal loads are {{inextricably linked to}} occupant behaviour, both directly through the contribution of occupant heat output to thermal energy balance and indirectly via the interactions between occupants, appliances and building services. While occupancy itself is difficult to measure directly, most buildings possess a wealth of data {{in the form of}} monitored electricity consumption in varying degrees of resolution. These <b>data,</b> particularly <b>plug</b> loads, may be used to inform the model of occupant-related internal loads. Different approaches to parameterisation of plug loads have been investigated, with the purpose of exploring the conditions that might lead to preference of one approach over another. The models have been tested through a case study and simulation results have been compared against a range of response variables. Conclusions have been drawn as to the most important features of plug load parameterisation for a model to be used for forecasting future demand...|$|R
40|$|Porous {{media and}} narrow ducts of simple shape at zero net mass flow (ZNMF) {{are used to}} {{investigate}} the influence of pore size on the entropy/heat convection rate at ZNMF. The study is relevant {{to the development of}} specific types of phase separators. Previous work on heat transport by convection is extended to porous media without mass loss. The experimental results show the influence of pore size on heat flux for permeabilities between 10 to the - 8 th and 10 to the - 6 th sq cm. ZNMF <b>plug</b> <b>data</b> are found to be similar to results obtained for vapor liquid phase separation...|$|R
40|$|This work {{discusses}} three {{tactile sensor}} systems {{developed by the}} authors to capture interaction patterns of humans and anthropomorphic robots. The rst, tacTiles, is a exible blanket with embedded force sensors, facilitating rapid augmentation of the environment {{with a sense of}} touch and is targeted towards cognitive rooms and ambient intelligence. The second, Myrmex, is a modular 2 D high-speed tactile pattern camera with USB-Video-Class interface, allowing computer vision algorithms to work on tactile <b>data</b> in a <b>plug</b> and-play fashion. Finally, intelligent Object (iObject), is a wireless instrumented tool equipped with tactile and motion capture sensors for evaluating human or robotic grasping and manipulation. ...|$|R
40|$|The rate of {{production}} of oil and turpentine in the effluent from the plug screw feeder {{at the exit from}} the presteamer of a fibreboard pilot plant was determined after a steady state of operation had been reached. From these data, the recovery of turpentine from the plug screw feeder effluent, as a proportion of that available in the wood chips, was shown to be 27 %. Turpentine levels in wood of Pinus radiata D. Don were determined and compared with previous data, along with causes of variations in these <b>data.</b> The presteamer <b>plug</b> screw feeder effluent from a medium-density fibreboard production line appears to be a useful source of turpentine...|$|R
40|$|Title from PDF {{of title}} page, viewed on June 1, 2012 Thesis advisor: Jejung LeeVitaIncludes bibliographic {{references}} (p. 106 - 110) Thesis (M. S.) [...] Dept. of Geosciences. University of Missouri [...] Kansas City, 2012 Analyzing data derived from well logging and core plugs {{to understand the}} heterogeneity of porosity in geologic formations is paramount in petrological studies. The well-log data and core-plug data are integrated in order to generate an accurate model describing the porosity distribution; however these data exist at different scales and resolution. This difference necessitates scaling of one or both sets of the data to aid in integration. The present study established a geostatistical scaling (GS) model combining mean, variance, skewness, kurtosis and standard deviation with a misfit algorithm and sequential Gaussian simulation to integrate porosity data in conjunction with correlating the depth of core-plug data within the well-log data through a scaling process. The GS model examined well-log porosity data from a Permian-age formation in the Hugoton Embayment in Kansas and well log data from a Cretaceous-age formation in the GyeongSang Basin in The Republic of Korea. Synthetic core-plug porosity data was generated from well-log data with random number generation. The GS model requires basic histograms and variogram models for scaling the computerized tomography (CT) <b>plug</b> <b>data</b> to well log scale as well as integrating the data in a sequential Gaussian simulation. Variance-based statistics were calculated within specific intervals, based on the CT plug size, then a best fit for depth correlation determined. A new correlation algorithm, named the multiplicative inverse misfit correlation method (MIMC), was formulated for accurate depth correlation. This associated depth then constrained the well log porosity data at reservoir- or field-scale to interpolate higher-resolution porosity distributions. Results for all the wells showed the MIMC method accurately identified the depth from which the CT <b>plug</b> <b>data</b> originated. The porosity from the CT <b>plug</b> <b>data</b> was applied in a sequential Gaussian co-simulation, after kriging the well log data. This culminated in a greater refinement in determining the higher porosities distributions than the interpolation of solely the well log data. These results validate the proposed high-resolution model for integrating data and correlating depths in reservoir characterization. Introduction [...] Geostatistical framework [...] Formulation of the geostatistical scaling model [...] Applications of the model: case studies [...] Discussion of results [...] Conclusion [...] Appendi...|$|R
40|$|State {{of the art}} {{security}} {{research in}} the field of wireless sensor networks has focused on providing security in a coarse-grained, full-fledged and static fashion. This implies providing confidentiality, data authentication, data integrity and freshness to the entire spectrum of communication between the participating nodes in a network. In this paper however we advocate {{that as a result of}} a number of factors relating wireless sensor networks, providing security in similar fashion for the entire communication set isn't a pragmatic approach and does not precisely reflect the application level security requirements. We therefore propose DiFiSec, a dynamic, fine-grained and adaptable security framework that supports various levels of plug gable security for distinct data communication sets depending on the context, environment and criticality of the <b>data.</b> These <b>plug</b> gable security levels can be enacted at the levels of component wirings and receptacles, hence empowering application users to select only the most appropriate security respecting the resource-constrained nature of WSNs. Furthermore, to support system evolution and changing application requirements DiFiSec offers runtime adaptability. A prototype of this system has been implemented on SunSPOT sensor nodes where we have evaluated our approach in comparison with other network security variations...|$|R
40|$|AbstractThis study {{presents}} an investigation and {{discussion on the}} energy performance of three tertiary institutional buildings in Singapore. Building information, energy consumption data of the air-conditioning system, and energy consumption <b>data</b> of the <b>plug</b> loads were collected separately. MATLAB identification models are developed to simulate the real daily energy consumption data:. Three functions are introduced to represent the function of daily occupancy, function of additional occupancy due to visitors and the function of outdoor air temperature. The {{results show that the}} predicted value follows the trend of real energy consumption value very well and can predict the daily variations. The newly developed methodology is able to simulate the daily variations of energy consumption. R 2 of 0. 54, 0. 66 and 0. 63 can be achieved for the three buildings respectivel...|$|R
40|$|International audienceThe {{effect of}} {{modification}} with cobalt via aqueous impregnation {{on the structure}} of MCM- 41 and SBA- 15 materials was studied using X-ray diffraction (XRD) at low scattering angles and low-temperature nitrogen adsorption. It was shown that the introduction of small amounts of cobalt resulted in dramatic changes in the structure of MCM- 41 silica. The low angle XRD peaks characteristic of long-range ordering disappeared while the BET surface area and the total pore volume decreased considerably. Only micropores smaller than 20 Å were detected in the cobalt containing MCM- 41 materials. A much smaller impact of impregnation with cobalt on the hexagonal structure and porosity was observed for SBA- 15 materials. The periodic structure, surface area and total pore volume of SBA- 15 mesoporous silica remained almost unchanged on impregnation with cobalt nitrate, catalyst drying and calcination. Low angle XRD patterns typical of hexagonal structure were still well resolved and intense in the SBA- 15 materials containing up to 20 wt. % of cobalt. Analysis of XRD intensities suggested that after aqueous impregnation and drying a considerable amount of cobalt ions was located in the SBA- 15 mesopores. Nitrogen adsorption-desorption <b>data</b> indicated <b>plugging</b> a part of SBA- 15 mesopores in cobalt containing samples. Due to the high stability, SBA- 15 silica appears to have a good potential for its use as a support for metal and oxide catalysts...|$|R
40|$|International audienceTo {{maintain}} an energy footprint {{as low as}} possible, data centres manage their VMs according to conventional and established rules. Each data centre is however made unique due to its hardware and workload specificities. This prevents the ad hoc design of current VM managers from taking these particularities into account to provide additional energy savings. In this paper, we present Plug 4 Green, an energy-aware VM placement algorithm {{that can be easily}} specialized and extended to fit the specificities of the <b>data</b> centres. <b>Plug</b> 4 Green computes the placement of the VMs and state of the servers depending on a large number of constraints, extracted automatically from SLAs. The flexibility of Plug 4 Green is achieved by allowing the constraints to be formulated independently from each other but also from the power models. This flexibility is validated through the implementation of 23 SLA constraints and 2 objectives aiming at reducing either the power consumption or the greenhouse gas emissions. On a heterogeneous test bed, Plug 4 Green specialization to fit the hardware and the workload specificities allowed to reduce the energy consumption and the gas emission by up to 33 % and 34 %, respectively. Finally, simulations showed that Plug 4 Green is capable of computing an improved placement for 7500 VMs running on 1500 servers within a minute...|$|R
40|$|This paper {{proposes a}} new {{architecture}} called Pipelined LookUp Grid (PLUG) that can perform data structure lookups in network processing. PLUGs are programmable and through simplicity achieve power efficiency. We {{draw upon the}} insights that data structure lookups have natural structure that can be statically determined and exploited. The PLUG execution model transforms data-structure lookups into pipelined stages of computation and associates small code-blocks with <b>data.</b> The <b>PLUG</b> architecture is a tiled architecture with each tile consisting predominantly of SRAMs, a lightweight no-buffering router, {{and an array of}} lightweight computation cores. Using a principle of fixed delays in the execution model, the architecture is contention-free and completely statically scheduled thus achieving high energy efficiency. The architecture enables rapid deployment of new network protocols and generalizes as a data-structure accelerator. This paper describes the PLUG architecture, the compiler, and evaluates our RTL prototype PLUG chip synthesized on a 55 nm technology library. We evaluate six diverse high-end network processing workloads including IPv 4, IPv 6, and Ethernet forwarding. We show that at a 55 nm technology, a 16 -tile PLUG occupies 58 mm 2, provides 4 MB on-chip storage, and sustains a clock frequency of 1 GHz. This translates to 1 billion lookups per second, a latency of 18 ns to 219 ns, and average power less than 1 watt...|$|R
