736|134|Public
5|$|In {{the domain}} of humanities, arts, and social sciences, MIT economists have been awarded five Nobel Prizes and nine John Bates Clark Medals. Linguists Noam Chomsky and Morris Halle {{authored}} seminal texts on <b>generative</b> <b>grammar</b> and phonology. The MIT Media Lab, founded in 1985 within the School of Architecture and Planning and known for its unconventional research, has been home to influential researchers such as constructivist educator and Logo creator Seymour Papert.|$|E
25|$|Harrocks, G. 1987. <b>Generative</b> <b>Grammar.</b> London: Longman.|$|E
25|$|Ray S. Jackendoff's model {{deviates}} {{from the}} traditional <b>generative</b> <b>grammar</b> in {{that it does not}} treat syntax as the main generative component from which meaning and phonology is developed unlike Chomsky. According to him, a <b>generative</b> <b>grammar</b> consists of five major components: the lexicon, the base component, the transformational component, the phonological component and the semantic component.|$|E
50|$|First {{introduced}} in 1985 as <b>Generative</b> <b>Grammars</b> and later more elaborated upon, Christiansen grammars (apparently dubbed so by Shutt, possibly due to conflict with Chomsky <b>generative</b> <b>grammars)</b> are an adaptive extension of attribute grammars. Christiansen grammars were classified by Shutt as declarative.|$|R
50|$|The {{operators}} {{are used in}} rewrite rules for <b>generative</b> <b>grammars.</b>|$|R
5000|$|Tree-adjoining grammars {{increase}} the expressiveness of conventional <b>generative</b> <b>grammars</b> by allowing rewrite rules {{to operate on}} parse trees instead of just strings.|$|R
25|$|The {{concept of}} grammaticality is {{closely tied to}} <b>generative</b> <b>grammar,</b> which has the goal of {{generating}} all and only the well-formed sentences in a given language.|$|E
25|$|Construction grammar was {{developed}} in the 1980s by linguists such as Charles Fillmore, Paul Kay, and George Lakoff. Construction grammar {{was developed}} in order to handle cases that intrinsically went beyond the capacity of <b>generative</b> <b>grammar.</b>|$|E
25|$|By the 1980s, {{a number}} of Chomsky's {{students}} had become leading linguistic specialists in their own right, expanding, revising, and expanding on Chomsky's ideas of <b>generative</b> <b>grammar.</b> By {{the end of the}} 1980s, Chomsky had established himself as a globally recognized figure.|$|E
2500|$|In {{the classic}} {{formalization}} of <b>generative</b> <b>grammars</b> first proposed by Noam Chomsky in the 1950s, a grammar G {{consists of the}} following components: ...|$|R
40|$|Abstract — L-systems are {{parallel}} <b>generative</b> <b>grammars</b> that can model branching structures. Taking a graphical object {{and attempting to}} derive an L-system describing it is a hard problem. Grammatical Evolution (GE) is an evolutionary technique aimed at creating grammars describing the legal structures an object can take. We use GE to evolve L-systems, and investigate the effect of elitism, and {{the form of the}} underlying grammar. I. INTRODUCTION AND BACKGROUND L-systems {{are parallel}} <b>generative</b> <b>grammars</b> [1] used to model plant development, branching tree structures, and other iteratively-defined and fractal artefacts. Starting from an axiom string, or seed, the grammar rules are applied in parallel t...|$|R
40|$|This paper {{discusses}} some student projects involving <b>generative</b> <b>grammars.</b> While grammars {{are usually}} associated with linguisitics, their usefuleness goes far beyond just "language" to make different domains. Their application is general enough to make grammars a sort of programming language in their own right...|$|R
25|$|Universal grammar {{takes into}} account general formal {{structures}} and features that are common to all dialects and languages, and the template of which pre-exists {{in the mind of}} an infant child. This idea is based on the theory of <b>generative</b> <b>grammar</b> and the formal school of linguistics, whose proponents include Noam Chomsky and those who follow his theory and work.|$|E
25|$|Bloomfield's {{approach}} to linguistics {{was characterized by}} its emphasis on the scientific basis of linguistics, adherence to behaviorism especially in his later work, and emphasis on formal procedures {{for the analysis of}} linguistic data. The influence of Bloomfieldian structural linguistics declined in the late 1950s and 1960s as the theory of <b>generative</b> <b>grammar</b> developed by Noam Chomsky came to predominate.|$|E
25|$|Linguistic {{competence}} {{is the system}} of linguistic knowledge possessed by native speakers of a language. It is distinguished from linguistic performance, {{which is the way}} a language system is used in communication. Noam Chomsky introduced this concept in his elaboration of <b>generative</b> <b>grammar,</b> where it has been widely adopted and {{competence is}} the only level of language that is studied.|$|E
40|$|It {{is shown}} that the. {{assumption}} t?at language is non-finite {{involves the use}} of a constructive logic which leafs to some restrictions on language theory an {{to the fact that the}} only possible definition of language is that propose by <b>generative</b> <b>grammars.</b> Generatire grammars can be formu]. atef aa normal /. arkov/ algorithms thus their study can be reduce to the stufy of such algorithms of a special tye. A new type of ffenerative grammar is efine, called matrix grs. mmar. It is shown that a language generated by a context-restricted grammar can be also generate by a matrix grammar. Some properties of matrix grammars are shown to be eciable. The problem of the explieative power of <b>generative</b> <b>grammars</b> is iseusse...|$|R
40|$|This {{dissertation}} {{examines the}} connections between music and mathematics with particular reference to Markov chains and <b>generative</b> <b>grammars.</b> The main {{purpose of this study}} is to investigate how mathematical concepts can help to control, create and analyse music material. The core part of this study is software that allows one to compose music with Markov Chains and <b>generative</b> <b>grammars.</b> The study will explore the on-going influence of such tools on composers and their relationship to musical sources and inspirations. An in-depth analysis of existing literature, music material and composition tools was conducted. Using comparative case studies, this research explored the significant role of mathematics in music in the twentieth and twenty-first centuries. The evolving role of stochastic concepts in music was presented. The next step was to develop a useful tool that would allow composers to apply Markov chains and <b>generative</b> <b>grammars</b> in their compositions. The web application that resulted was called Stochastic Composer. To evaluate this application five composers were invited to test it. The results include over one hundred samples of music material that were later analysed and used to improve the software. This dissertation offers insight into applications of various mathematical concepts in music. The Stochastic Composer software, available online, proved to be a useful tool in a compositional process...|$|R
40|$|Abstract—This paper investigates {{strategies}} to generate levels for action-adventure games. For this genre, level design is more critical than for rule-driven genres such as simulation or rogue-like role-playing games, for which procedural level generation {{has been successful}} in the past. The approach outlined by this article dis-tinguishes between missions and spaces as two separate structures that need to be generated in two individual steps. It discusses the merits of different types of <b>generative</b> <b>grammars</b> for each indi-vidual step in the process. Notably, the approach acknowledges that the online generation of levels needs to be tailored strictly to the actual experience of a player. Therefore, the approach incor-porates techniques to establish and exploit player models in actual play. Index Terms—Game AI, game design, <b>generative</b> <b>grammars,</b> real-time generated game environments. I...|$|R
25|$|The {{formalism}} of context-free grammars {{was developed}} in the mid-1950s by Noam Chomsky, and also their classification as a special type of formal grammar (which he called phrase-structure grammars). What Chomsky called a phrase structure grammar is also known now as a constituency grammar, whereby constituency grammars stand in contrast to dependency grammars. In Chomsky's <b>generative</b> <b>grammar</b> framework, the syntax of natural language was described by context-free rules combined with transformation rules.|$|E
25|$|Such {{rules are}} another {{standard}} device in traditional linguistics; e.g. passivization in English. Much of <b>generative</b> <b>grammar</b> {{has been devoted}} to finding ways of refining the descriptive mechanisms of phrase-structure grammar and transformation rules such that exactly the kinds of things can be expressed that natural language actually allows. Allowing arbitrary transformations doesn't meet that goal: they are much too powerful, being Turing complete unless significant restrictions are added (e.g. no transformations that introduce and then rewrite symbols in a context-free fashion).|$|E
25|$|In {{contemporary}} <b>generative</b> <b>grammar</b> (from {{the late}} 1970s to the present), {{the principles and}} parameters framework has been the dominant formulation of UG. In this framework, a principle is a grammatical requirement that applies to all languages, and a parameter is a tightly constrained point of variation across languages. In the early 1980s parameters were often conceptualized as switches in a switchbox (an idea attributed to James Higginbotham). In more recent research on syntax, parameters are often conceptualized as options for the formal features of functional heads.|$|E
50|$|Music {{composed}} from analytic {{theories that}} are so explicit as {{to be able to}} generate structurally coherent material (Loy and Abbott 1985; Cope 1991). This perspective {{has its roots in the}} <b>generative</b> <b>grammars</b> of language (Chomsky 1956) and music (Lerdahl and Jackendoff 1983), which generate material with a recursive tree structure.|$|R
50|$|The piece {{consists}} of four movements, corresponding to four experiments: the first is about the generation of cantus firmi, the second generates four-voice segments with various rules, the third deals with rhythm, dynamics and playing instructions, and the fourth with various models and probabilities for <b>generative</b> <b>grammars</b> or Markov chains (see stochastic music).|$|R
40|$|Two new {{classes of}} <b>generative</b> <b>grammars</b> are defined. The first class, the {{compound}} grammars, consists of grammars {{in which the}} initial symbol is replaced by the language generated by another grammar. The other class, the serial grammars, consists of sequences of compound <b>grammars.</b> The <b>generative</b> power of compound and serial grammars consisting of finite-state grammars is investigated...|$|R
25|$|Chomsky's theory {{posits that}} {{language}} consists of both deep structures and surface structures. Surface structure 'faces out' and {{is represented by}} spoken utterances, while deep structure 'faces inward' and expresses the underlying relations between words and conceptual meaning. Transformational grammar is a <b>generative</b> <b>grammar</b> (which dictates that the syntax, or word order, of surface structures adheres to certain principles and parameters) that consists of a limited series of rules, expressed in mathematical notation, which transform deep structures into well-formed surface structures. The transformational grammar thus relates meaning and sound.|$|E
25|$|Theories that posit {{movement}} have a {{long and}} established tradition that reaches back to early <b>Generative</b> <b>Grammar</b> (1960s and 1970s). They assume that the displaced constituent (e.g. the wh-expression) is first generated in its canonical position at some level or point in the structure generating process below the surface. This expression is then moved or copied out of this base position and placed in its surface position where it actually appears in speech. Movement is indicated in tree structures using one {{of a variety of}} means (e.g. a trace t, movement arrows, strikeouts, lighter font shade, etc.).|$|E
25|$|A {{hypothesis}} that all creole languages derive their grammar from the medieval Mediterranean Lingua Franca was widely {{held at the}} end of the 1950s and the beginning of the 1960s before it fell out of favour. It was later argued that, for example, the grammar of Haitian Creole is a substratum, created when Fon-speaking African slaves relexified their language with French vocabulary, because of underlying similarities between Haitian and Fon. However, the role of relexification in creole genesis is disputed by adherents of <b>generative</b> <b>grammar.</b> , , , and , for example, have argued that the similarities in syntax reflect a hypothetical Universal Grammar, not the workings of relexification processes.|$|E
40|$|Generative design offers new {{modes of}} {{aesthetic}} experience {{based on the}} incorporation of system dynamics into the production of artifact and experience. In this paper, we review a number of processes that can be explored by designers and suggest how design as a discipline can benefit from this research. These processes include self-organization, swarm systems and ant colonies, evolution, and <b>generative</b> <b>grammars.</b> We give example applications of these processes to creativity and design. 1...|$|R
40|$|This thesis {{deals with}} {{procedural}} building generation. The method which {{was chosen for}} implementation of the tool created during this study is based on <b>generative</b> <b>grammars.</b> In this document are introduced some of the advisable methods for solving given problem. It deals with predesign, implementation and {{evaluation of the results}} of the application for procedural building generation created in this work. The final tool also allows export of the generated models to Wavefront. obj format...|$|R
5000|$|<b>Generative</b> <b>grammars</b> can be {{described}} and compared, {{with the aid of}} the Chomsky hierarchy (proposed by Chomsky) in the 1950s. This sets out a series of types of formal grammars with increasing expressive power. Among the simplest types are the regular grammars (type 3); Chomsky claims that these are not adequate as models for human language, because of the allowance of the [...] center-embedding of strings within strings, in all natural human languages.|$|R
25|$|Linguistics is the {{scientific}} study of language. Chomskyan linguistics (an inclusive, though perhaps informal, label for the theories and methodologies of linguistic study spearheaded by Noam Chomsky, meant to encompass his extensive work and influence in the field) includes everything from Chomsky's earliest work in transformational grammar to more recent work in the Minimalist Program. More exactly, it is the study of the structure of language, or grammar. Chomskyan linguistics is defined by a particular theoretical foundation and methodological approach that sets it apart from other linguistic perspectives, such as those described by functional grammar or structuralism (per Leonard Bloomfield) for example. This particular approach to the study of language is also often referred to as Generative linguistics, which is attributed to Chomsky and his early <b>generative</b> <b>grammar</b> work.|$|E
25|$|Born to middle-class Ashkenazi Jewish {{immigrants}} in Philadelphia, Chomsky developed an early interest in anarchism from alternative bookstores in New York City. At {{the age of}} 16 he began studies at the University of Pennsylvania, taking courses in linguistics, mathematics, and philosophy. From 1951 to 1955 he was appointed to Harvard University's Society of Fellows, where he developed the theory of transformational grammar {{for which he was}} awarded his doctorate in 1955. That year he began teaching at MIT, in 1957 emerging as a significant figure in the field of linguistics for his landmark work Syntactic Structures, which remodeled the scientific study of language, while from 1958 to 1959 he was a National Science Foundation fellow at the Institute for Advanced Study. He is credited as the creator or co-creator of the universal grammar theory, the <b>generative</b> <b>grammar</b> theory, the Chomsky hierarchy, and the minimalist program. Chomsky also played a pivotal role in the decline of behaviorism, being particularly critical of the work of B. F. Skinner.|$|E
2500|$|The 1984 Nobel Prize laureate in Medicine and Physiology, Niels Kaj Jerne, used Chomsky's {{generative}} {{model to}} explain the human immune system, equating [...] "components of a <b>generative</b> <b>grammar...</b> with various features of protein structures". The title of Jerne's Stockholm Nobel Lecture was [...] "The <b>Generative</b> <b>Grammar</b> of the Immune System". His theory of <b>generative</b> <b>grammar</b> has also carried over into music theory and analysis.|$|E
5000|$|Early <b>generative</b> <b>grammars</b> {{dealt with}} {{language}} from a syntactic perspective, i.e. {{as the problem}} presented by the task of creating rules able to combine words into well-formed (i.e., grammatical) sentences. The rules used by these grammars were referred to as phrase-structure rules (P-rules). It was soon apparent, however, that a generative component composed solely of P-rules could not generate {{a wide variety of}} commonly occurring sentence types. In response to this dilemma, we find Harris proposing an explanation: ...|$|R
40|$|This paper investigates <b>generative</b> <b>grammars</b> {{with only}} one type of symbol: no {{distinction}} is made between terminals and nonterminals. This means that all intermediate words in a derivation are necessarily in the language generated and, consequently, such languages differ considerably from languages generated by grammars, where nonterminals {{can be used to}} exclude words from the language. We investigate in this paper basic question concerning language hierarchies, ambiguity and decidability. Also some more general models of pure grammars will be considered...|$|R
40|$|Multi-Level Multi-Decision Models for Automatic Speech Recognition is discussed. It is hierarchically organized. Here {{there are}} not used the <b>generative</b> <b>grammars</b> for model speech signal {{synthesis}} as a feedback in speech recognition process. Instead of the latter significant decisions, but under simplified conditions, {{at all levels of}} a speech signal processing hierarchy are introduced. The 3 -level model with phoneme recognizer, word recognizer and continuous speech interpreter is proposed. Experimental results for the 3 -level model are given and problems to be solved are discussed. 1...|$|R
