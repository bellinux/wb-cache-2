3403|116|Public
25|$|DirectX Media Objects: {{support for}} {{streaming}} {{objects such as}} <b>encoders,</b> decoders, and effects.|$|E
25|$|Nero's AAC encoder {{has been}} very {{competitive}} when tested against other <b>encoders</b> in scientific listening tests, for a time, second only to Apple's AAC encoder.|$|E
25|$|Compression {{efficiency}} of <b>encoders</b> is typically {{defined by the}} bit rate, because compression ratio depends on the bit depth and sampling rate of the input signal. Nevertheless, compression ratios are often published. They may use the Compact Disc (CD) parameters as references (44.1 kHz, 2 channels at 16 bits per channel or 2×16 bit), or sometimes the Digital Audio Tape (DAT) SP parameters (48kHz, 2×16 bit). Compression ratios with this latter reference are higher, which demonstrates the problem with {{use of the term}} compression ratio for lossy <b>encoders.</b>|$|E
3000|$|... of Theorem 1 {{can also}} be {{obtained}} by time-sharing between two successive decoding schemes, that is, decoding one <b>encoder's</b> message first and using the decoded codeword and the channel output to decode the other <b>encoder's</b> message. On one hand, consider first decoding {{the message of the}} informed encoder. Following [16], if [...]...|$|R
5000|$|A {{convolutional}} encoder is called so because it performs a convolution of the input stream with the <b>encoder's</b> impulse responses: ...|$|R
50|$|In the <b>encoder's</b> {{current form}} an image pixel dynamic range {{of up to}} 16 bits is supported, whereas ICER and JPEG2000 support 24 and 32 bitplanes.|$|R
25|$|It is {{important}} to note that both MP3 and WMA <b>encoders</b> have undergone active development and improvement for many years, so their relative quality may change over time.|$|E
25|$|Even though PNG {{has been}} {{designed}} as a lossless format, PNG <b>encoders</b> can pre-process image data in a lossy fashion (so as to reduce colors used) to improve PNG compression.|$|E
25|$|Besides the {{bit rate}} of an encoded piece of audio, {{the quality of}} MP3 encoded sound also depends {{on the quality of}} the encoder {{algorithm}} as well as the complexity of the signal being encoded. As the MP3 standard allows quite a bit of freedom with encoding algorithms, different <b>encoders</b> do feature quite different quality, even with identical bit rates. As an example, in a public listening test featuring two early MP3 <b>encoders</b> set at about 128kbit/s, one scored 3.66 on a 1–5 scale, while the other scored only 2.22. Quality is dependent on the choice of encoder and encoding parameters.|$|E
30|$|Rigid {{allocation}} of functionality PVC enforces rigid {{allocation of}} functionality between encoder (complex) and decoder (simple), with the complex motion search operation dominating the overall <b>encoder’s</b> complexity.|$|R
3000|$|... ‘Preserving’ the {{constraint}} length (binary equivalent) {{requires that}} between M’ (SB and MB encoders' memory) and M (MNB <b>encoder's</b> memory) there be the formula: M’ = Q × M.|$|R
40|$|Abstract — We {{address the}} problem of {{stabilizing}} a continuous-time linear time-invariant process under commu-nication constraints. We assume that the sensor that measures the state is connected to the actuator through a finite capacity communication channel over which an encoder at the sensor sends symbols from a finite alphabet to a decoder at the actuator. We consider a situation where one symbol from the alphabet consumes no communication resources, whereas each of the others consumes one unit of communication resources to transmit. This paper explores how the imposition of limits on an <b>encoder’s</b> bit-rate and average resource consumption affect the encoder/decoder/controller’s ability to keep the process bounded. The main result is a necessary and sufficient condition for a bounding encoder/decoder/controller which depends on the <b>encoder’s</b> average bit rate, its average resource consump-tion, and the unstable eigenvalues of the process. I...|$|R
25|$|The ARRL has a {{readability}} {{standard for}} robot <b>encoders</b> called ARRL Farnsworth Spacing {{that is supposed}} to have higher readability for both robot and human decoders. Some programs like WinMorse have implemented the standard.|$|E
25|$|Within the entropy-coded data, after any 0xFF byte, a 0x00 byte is {{inserted}} by the encoder {{before the next}} byte, so that there {{does not appear to}} be a marker where none is intended, preventing framing errors. Decoders must skip this 0x00 byte. This technique, called byte stuffing (see JPEG specification section F.1.2.3), is only applied to the entropy-coded data, not to marker payload data. Note however that entropy-coded data has a few markers of its own; specifically the Reset markers (0xD0 through 0xD7), which are used to isolate independent chunks of entropy-coded data to allow parallel decoding, and <b>encoders</b> are free to insert these Reset markers at regular intervals (although not all <b>encoders</b> do this).|$|E
25|$|QuickTime 6 added limited {{support for}} MPEG-4; {{specifically}} encoding and decoding using Simple Profile (SP). Advanced Simple Profile (ASP) features, like B-frames, were unsupported (in contrast with, for example, <b>encoders</b> such as XviD or 3ivx). QuickTime 7 supports the H.264 encoder and decoder.|$|E
3000|$|... to the {{corresponding}} code string {{in order to}} synchronize with each other. As soon as the forbidden symbol is decoded, the occurrence of error in the received sequence is detected. However, this method of decoding is not capable of correcting the errors. But, the redundancy of the <b>encoder's</b> output can be used for correcting errors.|$|R
3000|$|... where d 4 is {{the minimum}} weight of error paths {{in the fourth}} error event. This error {{probability}} is caused by both finite truncation depth and {{the uncertainty of the}} <b>encoder's</b> initial state. The bit error probability of the k th decoded bit is upper bounded by the sum of four upper bounds in (2), (7), (8), and (9).|$|R
30|$|A {{distortion}} {{control algorithm}} {{is presented in}} (Roca et al. 2007) to overcome the coding distortions in PDWZ codec. The algorithm helps in choosing the optimal steps size for quantization levels associated with certain target quality. However, the experimental {{results showed that the}} accuracy in prediction of distortion function is primarily dependent on the <b>encoder’s</b> computational power.|$|R
25|$|In 1984 {{was formed}} the Committee on Mechanisation in the Banking Industry (1984) whose {{chairman}} was Dr. C Rangarajan, Deputy Governor, Reserve Bank of India. The major recommendations of this committee were introducing MICR technology {{in all the}} banks in the metropolises in India. This provided {{for the use of}} standardised cheque forms and <b>encoders.</b>|$|E
25|$|Due to the {{densities of}} color- and brightness-sensitive receptors {{in the human}} eye, humans can see {{considerably}} more fine detail in the brightness of an image (the Y' component) than in the hue and color saturation of an image (the Cb and Cr components). Using this knowledge, <b>encoders</b> can be designed to compress images more efficiently.|$|E
25|$|MPEG-2 doubles {{the number}} of {{sampling}} rates which are supported and MPEG-2.5 adds 3 more. When this was written, the suggested implementations were quite dated. Implementers of the standard were supposed to devise their own algorithms suitable for removing parts of {{the information from the}} audio input. As a result, many different MP3 <b>encoders</b> became available, each producing files of differing quality. Comparisons were widely available, so it was easy for a prospective user of an encoder to research the best choice. Some <b>encoders</b> that were proficient at encoding at higher bit rates (such as LAME) were not necessarily as good at lower bit rates. Over time, LAME evolved on the SourceForge website until it became the de facto CBR MP3 encoder. Later an ABR mode was added. Work progressed on true variable bit rate using a quality goal between 0 and 10. Eventually numbers (such as -V 9.600) could generate excellent quality low bit rate voice encoding at only 41kbit/s using the MPEG-2.5 extensions.|$|E
3000|$|In {{order to}} achieve the {{objective}} of encoder player's evaluation, the payoff should get a balanced function value between the intensity of embedded watermark and the perceptual translucence for watermark. Therefore, the payoff function f 1 is defined as a normalized operation from four quality assessment metrics (MSSIM, VIF, PSNR-HVS-M, and WSNR) and correlation where the <b>encoder's</b> best strategy is [...]...|$|R
50|$|The optical <b>encoder's</b> disc is made {{of glass}} or plastic with {{transparent}} and opaque areas. A light source and photo detector array reads the optical pattern that results from the disc's position at any one time.The Gray code is often used.This code can be read by a controlling device, such as a microprocessor or microcontroller to determine {{the angle of the}} shaft.|$|R
50|$|The H-ternary code {{has three}} levels for signal representation; these are {{positive}} (+), zero (0), and negative (−). These three levels {{are represented by}} three states. The state of the line code could be {{in any one of}} these three states. A transition takes place to the next state {{as a result of a}} binary input 1 or 0 and the <b>encoder's</b> present output state. The encoding procedure is as follows.|$|R
25|$|During {{the final}} NASA Sample Return Robot Centennial Challenge in 2016, a rover, named Cataglyphis, {{successfully}} demonstrated fully autonomous navigation, decision-making, and sample detection, retrieval, and return capabilities. The rover {{relied on a}} fusion of measurements from inertial sensors, wheel <b>encoders,</b> Lidar, and camera for navigation and mapping, instead of using GPS or magnetometers. During the 2 hour challenge, Cataglyphis traversed over 2.6km and returned five different samples to its starting position.|$|E
25|$|A more {{sophisticated}} MP3 encoder can produce variable bitrate audio. MPEG audio may use bitrate switching on a per-frame basis, but only layer III decoders must support it. VBR is used when {{the goal is}} to achieve a fixed level of quality. The final file size of a VBR encoding is less predictable than with constant bitrate. Average bitrate is a type of VBR implemented as a compromise between the two: the bitrate is allowed to vary for more consistent quality, but is controlled to remain near an average value chosen by the user, for predictable file sizes. Although an MP3 decoder must support VBR to be standards compliant, historically some decoders have bugs with VBR decoding, particularly before VBR <b>encoders</b> became widespread. The most evolved LAME MP3 encoder supports the generation of VBR, ABR, and even the ancient CBR MP3 formats.|$|E
25|$|A {{reference}} {{simulation software}} implementation, {{written in the}} C language and later known as ISO 11172-5, was developed (in 1991–1996) {{by the members of}} the ISO MPEG Audio committee in order to produce bit compliant MPEG Audio files (Layer 1, Layer 2, Layer 3). It was approved as a committee draft of ISO/IEC technical report in March 1994 and printed as document CD 11172-5 in April 1994. It was approved as a draft technical report (DTR/DIS) in November 1994, finalized in 1996 and published as international standard ISO/IEC TR 11172-5:1998 in 1998. The reference software in C language was later published as a freely available ISO standard. Working in non-real time on a number of operating systems, it was able to demonstrate the first real time hardware decoding (DSP based) of compressed audio. Some other real time implementation of MPEG Audio <b>encoders</b> and decoders were available for the purpose of digital broadcasting (radio DAB, television DVB) towards consumer receivers and set top boxes.|$|E
40|$|For many {{real-time}} {{visual communication}} {{applications such as}} video telephony, the transmission channel in used is typically constant bit rate (e. g. PSTN). Under this circumstance, the <b>encoder’s</b> output bit-rate must be regulated to meet the transmission bandwidth in order to guarantee a constant frame rate and delay. In this work, we propose a new predictive rate control scheme based on {{the activity of the}} scene to be coded for H. 263 encoder 1...|$|R
5000|$|Introduced {{with the}} second-{{generation}} Maxwell architecture, third generation NVENC implements the video compression algorithm High Efficiency Video Coding (a.k.a. HEVC, H.265) and also increases the H.264 <b>encoder's</b> throughput to cover 4K-resolution at 60fps (2160p60). However, {{it does not}} support B-frames for HEVC encoding (just I and P frames). The maximum NVENC HEVC coding tree unit (CU) size is 32 (the HEVC standard allows a maximum of 64), and its minimum CU size is 8.|$|R
50|$|On the EV3 AM1808 platform, it is {{possible}} with a small hack to double the <b>encoder's</b> resolution. By enabling edge triggered interrupts on the encoder B line (called direction line by Lego), it {{is possible}} to have 720 increments per turn instead of 360. This enhancement allows for smoother rotation at low speed and better position control. This hack was not possible on the NXT due to a hardware limitation. The modified firmware implementing this modification is called EV3.14.|$|R
25|$|Suppose a {{listener}} cannot hear a given acoustical signal under silent condition. When a signal is playing while another sound {{is being played}} (a masker) the signal has to be stronger for the listener to hear it. The masker {{does not need to}} have the frequency components of the original signal for masking to happen. A masked signal can be heard even though it is weaker than the masker. Masking happens when a signal and a masker are played together. It also happens when a masker starts after a signal stops playing. The effects of backward masking is weaker than forward masking. The masking effect has been widely used in psychoacoustical research. With masking you can change the levels of the masker and measure the threshold, then create a diagram of a psychophysical tuning curve that will reveal similar features. Masking effects are also used for audio encoding. The masking effect is used in lossy <b>encoders.</b> It can eliminate some of the weaker sounds, so the listener can not hear the difference. This technique has been used in MP3's.|$|E
500|$|Many of the {{parameter}} knobs {{are simple}} potentiometers, however {{there are several}} 360-degree lighted rotary <b>encoders.</b> These rotary <b>encoders</b> control parameters that can be [...] "morphed". Morph Grouping is Clavia's technology that allows users to assign multiple parameters to one control, such as the mod wheel, a control pedal, or aftertouch.|$|E
500|$|At a minimum, all digital {{television}} broadcasters in Australia provide a 576i [...] standard-definition service, {{in addition to}} high definition. The 576p50 format is also considered a HDTV format, as it has higher vertical resolution {{through the use of}} progressive scanning. When Australia started DVB-T in 2001 several networks broadcast high-definition in a 576p format as this could give better quality on 50Hz scanning CRT TVs and was not as demanding on MPEG-2-bit-rate. Since many modern television sets have an interlace to progressive scan conversion there is little difference in picture quality. MPEG-2 <b>encoders</b> have also improved so the more conventional 720p and 1080i formats are now used.|$|E
40|$|The Mecanum {{automated}} guided vehicle (AGV), {{which can}} move in any direction by using a special wheel structure with a LIM-wheel and a diagonally positioned roller, holds considerable promise for the field of industrial electronics. A conventional method for Mecanum AGV localization has certain limitations, such as slip phenomena, because there are variations in {{the surface of the}} road and ground friction. Therefore, precise localization is a very important issue for the inevitable slip phenomenon situation. So a sensor fusion technique is developed to cope with this drawback by using the Kalman filter. <b>ENCODER</b> and StarGazer were used for sensor fusion. StarGazer is a position sensor for an image recognition device and always generates some errors due to the limitations of the image recognition device. <b>ENCODER</b> has also errors accumulating over time. On the other hand, there are no moving errors. In this study, we developed a Mecanum AGV prototype system and showed by simulation that we can eliminate the disadvantages of each sensor. We obtained the precise localization of the Mecanum AGV in a slip phenomenon situation via sensor fusion using a Kalman filter...|$|R
30|$|All {{simulations}} {{are performed}} under this controlled {{environment and the}} <b>encoder’s</b> elapsed time is recorded using Intel Parallel Studio’s 2011 Vtune Amplifier and AMD code analyst. The memory leaks are analyzed using Intel Parallel Inspector 2011. The parallel programming is implemented using OpenMP technique. The resolutions of the video sequences used in the simulation are QCIF, CIF, SD, and HD resolutions. The scalability is tested by {{increasing the number of}} processing cores and applying homogeneous software optimization techniques to each core.|$|R
40|$|Covert {{channels}} are of two types: (a) timing channel and (b) storage channel. Most previous works have studied these channels from the <b>encoder’s</b> perspective, namely, information theoretic capacity, algorithms and protocols for hiding information etc. This paper investigates the covert channel problem from an passive adversary’s perspective. A sequential distinguisher for storage channel identification by an adversary is proposed and its properties are derived analytically. The impact of correlation in the observations {{received by the}} adversary is studied analytically as well as numerically...|$|R
