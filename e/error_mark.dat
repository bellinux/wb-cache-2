3|196|Public
5000|$|In 1973 Barbels weapons {{division}} set a SUBPAC {{record for}} successfully shooting 118 torpedoes that year. This included successful salvo firing two Mark 16-8 exercise torpedoes, and a successful MK 16-8 warshot operational test. In addition the boat performed a zero <b>error</b> <b>Mark</b> 45 torpedo Technical Standardization Inspection conducted by DoD, a Navy Technical Proficiency Inspection, and the torpedomen identified {{the source of}} the MK 45 torpedo [...] "flex hose eater problem." [...] For this record, Barbel was awarded the 1973 Battle Efficiency [...] "E". Barbel record for firing torpedoes was around 1978. She also succeeded in a simulated [...] "sinking" [...] of the aircraft carrier [...] during Exercise RIMPAC during that same period.|$|E
40|$|The {{effectiveness}} of shape information alone, without size, for recognizing stored 3 D models is considered. The geometric constraint filtering method of Grimson and Lozano-Pérez {{is used to}} curb the potentially combinatorial expansion of the model search space. Results, typical of those from several models experimented with, are given for the task of recognizing a plug from uncertain surface normal data. They show that, at least for an 'interesting' view, shape data is highly effective, even when the sensed surface normals are uncertain in direction to, say, ± 10 °. The loss of size information does, however, result in a drop in search efficiency, but this appears relatively small: u factor of ≈ 5 for {{the example of a}} plug at the 10 ° <b>error</b> <b>mark.</b> © 1987...|$|E
40|$|The lack of {{a robust}} {{framework}} for quantifying the parametric and predictive uncertainty of conceptual rainfall‐runoff (CRR) models remains a key challenge in hydrology. The Bayesian total error analysis (BATEA) methodology provides a comprehensive framework to hypothesize, infer, and evaluate probability models describing input, output, and model structural error. This paper assesses the ability of BATEA and standard calibration approaches (standard least squares (SLS) and weighted least squares (WLS)) to address two key requirements of uncertainty assessment: (1) reliable quantification of predictive uncertainty and (2) reliable estimation of parameter uncertainty. The case study presents a challenging calibration of the lumped GR 4 J model to a catchment with ephemeral responses and large rainfall gradients. Postcalibration diagnostics, including checks of predictive distributions using quantile‐quantile analysis, suggest that while still far from perfect, BATEA satisfied its assumed probability models better than SLS and WLS. In addition, WLS/SLS parameter estimates were highly dependent on the selected rain gauge and calibration period. This will obscure potential relationships between CRR parameters and catchment attributes and prevent the development of meaningful regional relationships. Conversely, BATEA provided consistent, albeit more uncertain, parameter estimates and thus overcomes one of the obstacles to parameter regionalization. However, significant departures from the calibration assumptions remained even in BATEA, e. g., systematic overestimation of predictive uncertainty, especially in validation. This is likely due to the inferred rainfall errors compensating for simplified treatment of model structural <b>error.</b> <b>Mark</b> Thyer, Benjamin Renard, Dmitri Kavetski, George Kuczera, Stewart William Franks and Sri Srikantha...|$|E
5000|$|In Norway, {{the vehicle}} {{inspection}} is called [...] "Periodisk Kjøretøykontroll", which translates to [...] "Periodic vehicle inspection", {{although it is}} {{commonly referred to as}} [...] "EU kontroll", for its origin from the European Union.When a car is 4 years old it must undergo its first inspection. After this, inspections will be required every second year.Buses, taxicabs and ambulances are inspected every year.The inspection focuses on safety and emission. After the inspection is completed, the owner will be given a check list with errors that must be repaired before the vehicle can pass. If the car only have <b>errors</b> <b>marked</b> with 1, or none errors at all, the car will pass immediately. The errors are rated depending on how dangerous they are, with the grades of 1, 2 and 3. <b>Errors</b> <b>marked</b> with 1 will not require a re-inspection. <b>Errors</b> <b>marked</b> with 2 will require a re-inspection, but the owner can use the car until the inspection deadline. <b>Errors</b> <b>marked</b> with 3 are very rare, and prohibits the user from using the car until those errors are repaired.|$|R
30|$|To {{summarize}} our {{answer to}} RQ 5 : Tool support {{was available to}} about 60 % of respondents. The functionality most available was highlighting (41 %), followed by renaming, navigation, and finally <b>error</b> <b>marking</b> (25 %).|$|R
30|$|Tool {{support for}} cross-language linking was {{available}} to about 60 % of our respondents, with automated error detection available to only 25 %. Respondents universally agree {{on the benefits of}} tool support, especially for <b>error</b> <b>marking.</b>|$|R
50|$|Marks {{claims in}} his book that the real issue was {{internal}} rivalry between the SOE and the SIS; the former {{did not want to}} admit <b>error.</b> <b>Marks</b> says he was ordered to withhold important cryptographic information from people investigating the Dutch operation at the time.|$|R
3000|$|... 55 (nearly 40 %) of {{participants}} indicated that no tool support at all {{was used in}} their last completed project. Thus, tool support was in fact in use, but less so than we expected. In particular, the <b>error</b> <b>marking</b> functionality, which is the one directly relevant to problems — was selected by the lowest amount of recipients (35 recipients, 25 %), which mirrors the result in question 12 (where 27 respondents (20 %) reported using dedicated tools for error detection).|$|R
40|$|We {{investigate}} the sink bit error probability (BEP) performance of an intermediate node encoding network (coded network). The network consists of statistically independent binary noisy channels. We observe three {{situations in which}} network coding can affect the sink BEP. An <b>error</b> <b>marking</b> algorithm {{is used to calculate}} the number of erroneous bits (error weight) in the sinks. Then we can calculate the sink BEP from the channel BEPs. Finally, we {{investigate the}} optimal transmitted energy allocation within a BEP constraint network...|$|R
5000|$|Embedding {{a secret}} {{message in the}} pattern of {{deliberate}} <b>errors</b> and <b>marked</b> corrections in a word processing document, using the word processor's change tracking feature.|$|R
30|$|There {{are just}} two {{questions}} in this section. The first (13) is, as usual, related to the last project and asks whether the tools used by participants offered {{one of the four}} typical functions (highlighting, <b>error</b> <b>marking,</b> navigation, and refactoring) that are commonly mentioned in the literature; additionally, a free text field was provided. Respondents were instructed to select a function even if it was only present for some of the languages used. It was also possible to state that no functions were available at all.|$|R
30|$|First, we {{have seen}} that most {{respondents}} indicated having problems with cross-language links, mostly related to link changeability and understanding software during the programming phase of a software project, and that tool support seems both in short supply and perceived as beneficial. Thus, creating tool support in particular for <b>error</b> <b>marking</b> in cross-language links might offer developers a better safety net than they currently have. For program understanding, accountability of cross-language links through advanced querying mechanisms or visualization might be beneficial to avoid the tendency to not change code for fear of breaking the system.|$|R
40|$|In {{this paper}} {{we present a}} Prolog plugin for Eclipse based upon BE 4, and {{providing}} many features such as semantic-aware syntax highlighting, outline view, <b>error</b> <b>marking,</b> content assist, hover information, documentation generation, and quick fixes. The plugin makes use of a Java parser for full Prolog with an integrated Prolog engine, and can be extended with further semantic analyses, e. g., based on abstract interpretation. Comment: Paper presented at the 18 th Workshop on Logic-based Methods in Programming Environments (WLPE 2008) (Report-No: WLPE/ 2008). Paper submitted by a co-editor of the Workshop proceeding...|$|R
50|$|A {{generally}} nonsensical {{genre of}} play, farces are often overacted and often involve slapstick humor. An {{example of a}} farce includes William Shakespeare's play The Comedy of <b>Errors,</b> or <b>Mark</b> Twain's play Is He Dead?.|$|R
3000|$|In {{this final}} question, {{recipients}} agreed that having more tool support would be beneficial. A total of 82 % of recipients {{indicated that they}} see tool support in general as [...] "very" [...] or [...] "rather" [...] important. Thus, {{it seems clear that}} there is a need for further support. There is little difference between the individual functions in rating. The most important functionality to recipients is, as expected, support for <b>error</b> <b>marking</b> (87 %). The least important was support for highlighting (67 %), although it should be noted here that highlighting was the functionality most available to developers and thus may have received less votes.|$|R
40|$|In modern Integrated Development Environments (IDEs), textual editors are {{interactive}} and {{can handle}} intermediate, incomplete, or otherwise erroneous texts while still providing editor {{services such as}} syntax highlighting, <b>error</b> <b>marking,</b> outline views, and hover help. In this paper, we present an approach for the robust synchronization of interactive textual and graphical editors. The approach recovers from errors during parsing and text-to-model synchronization, preserves textual and graphical layout {{in the presence of}} erroneous texts and models, and provides synchronized editor services such as selection sharing and navigation between editors. It was implemented for synchronizing textual editors generated by the Spoofax language workbench and graphical editors generated by the Graphical Modeling Framework...|$|R
30|$|Software {{development}} {{in general is}} supported by a myriad of tools, ranging from command-line compilers to fully integrated development environments. Tools exist that specifically support different functions for dealing with cross-language links, such as highlighting, <b>error</b> <b>marking,</b> or even automated rename refactoring. Dedicated tools for cross-language linking become important since the usual infrastructure of compilers and editors is mostly focused on supporting individual languages. Often, there is support for using multiple languages within a development environment — for example through plugins — but support for interaction points (cross-language links) between the languages is another issue. Existing work on theexistence and usefulness of cross-language tool support to developers is available (e.g. Pfeiffer and Wasowski (2015); Pfeiffer and Wasowski (2012 a)).|$|R
40|$|This paper {{presents}} a robust and computationally low-cost tech-nique for tracking facial markers which exploits an adaptive marker collocation model {{to recover from}} tracking <b>errors.</b> <b>Marker</b> collo-cation statistics are estimated during periods where the markers are successfully tracked, and employed to estimate the position of missing markers during periods where the tracker fails to locate the full set. Evaluation experiments have been conducted on a small audio-visual corpus of connected digits in which the speaker was recorded with small white markers affixed to easily locatable points on the chin, lips, and nose. It is demonstrated that use of the marker collocation model makes the tracker robust {{in the face of}} marker occlusion. 1...|$|R
5|$|There {{are many}} <b>errors</b> by homoioteleuton (<b>Mark</b> 2:18; 4:24; 12:26; 14:70; 15:14; Luke 12:22.47; 13:28.29; John 4:14).|$|R
5000|$|Nicole was {{the first}} to read the map, and made several <b>errors.</b> <b>Mark</b> {{attempted}} to correct them, but the team was running out of time. Having noticed that the bomb had several colored wires, and a pair of wire cutters were provided, Mark reasoned that the clue would tell them which wire(s) to cut. On that assumption, the team deduced that the only two colors that could be made from the letters they found were [...] "red" [...] and [...] "blue". However, they did not have the correct letters for the word [...] "wire", so were unsure if they should cut two wires, red and blue, or cut the purple wire. In the end, the team cut the purple wire, which was correct, and added the money to the pot with 21 seconds to spare.|$|R
40|$|We {{investigate}} the calculation {{approach of the}} sink bit error probability (BEP) for a network with intermediate node encoding. The network consists of statistically independent noisy channels. The main contributions are, for binary network codes, an <b>error</b> <b>marking</b> algorithm is given to collect the error weight (the number of erroneous bits). Thus, we can calculate the exact sink BEP from the channel BEPs. Then we generalize the approach to nonbinary codes. The coding scheme works on the Galois field 2, where m is a positive integer. To reduce computational complexity, a subgraph decomposition approach is proposed. In general, it can significantly reduce computational complexity, and the numerical result is also exact. For approximate results, we discuss the approach of only considering error events in a single channel. The results well approximate the exact results in low BEP regions with much lower complexity...|$|R
40|$|Abstract: This paper {{describes}} {{the first step}} of a research in developing an <b>error</b> analysis <b>marking</b> tool for ESL (English as a Second Language) learners at Malaysian institutions of higher learning. The writing in ESL comprises 400 essays written by 112 undergraduates. Subject-matter experts use an error classification scheme to identify the errors. Markin 3. 1 software is used to speed up the process of classifying these errors. In this way, the statistical analysis of errors are made accurately. The results of the study show that common errors in these essays in decreasing order are tenses, prepositions, articles, word choice, mechanics, and verb to be. The findings from this phase of the study will lend to the next phase of the research that is developing techniques and algorithms for <b>error</b> analysis <b>marking</b> tool for ESL learners...|$|R
40|$|Outputs {{of three}} English-Slovak machine {{translation}} systems for 50 sentences {{randomly selected from}} WMT 2011 test set. The translations were manually processed and the <b>errors</b> were <b>marked</b> and classified according to the scheme by Vilar et al. (David Vilar, Jia Xu, Luis Fernando D’Haro, Hermann Ney: Error Analysis of Statistical Machine Translation Output, Proceedings of LREC- 2006, 2006...|$|R
40|$|A {{number of}} color image {{fidelity}} metrics {{were evaluated by}} looking at how well they predict visibility of image reproduction errors on perceptual image distortion maps. The image distortion maps are obtained empirically. Subjects examined image pairs consisting of an original and a reproduction. They marked locations on the reproduction that differed detectably from the original. We refer to the distribution of <b>error</b> <b>marks</b> by the subjects as image distortion maps. The empirically obtained image distortion maps are compared to the visible difference calculated using (1) the widely used {{root mean square error}} (point-by-point RMS) computed in uncalibrated RGB values, (2) the point-by-point CIELAB 94 values (CIE, 1994), and (3) S-CIELAB 94, a spatial extension of CIELAB metric. The uncalibrated RMS metric did not predict the perceptual image distortion data very well. The CIELAB 94 metric is a calibrated color fidelity metric, and gave better predictions [...] ...|$|R
40|$|The report {{describes}} improved algorithms {{within a}} computer program for identifying spelling and word order errors in student responses. A "markup analysis " compares a student's response string to an author-specified model string and generates a graphical error markup that indicates spelling, capitalization, and accent errors, extra or missing words, and out-of-order words. The algorithm determines whether the response was acceptable or not, and computes a string of graphical <b>error</b> <b>marks</b> to be displayed below the student response. Synonyms and ignorable words can be specified and spelling errors, extra words, and word order errors can be accepted at the author's discretion. Spelling analysis is done using a dynamic programming algorithm that produces a least-cost edit trace; word order analysis is implemented using recursive branch and bound search. Improvements on earlier versions of the algorithm give more intuitive markup values. The algorithm is implemented as a HyperTal...|$|R
40|$|Subjects {{examined}} image pairs {{consisting of}} an original and a reproduction created using either JPEG compression or digital halftoning. Subjects marked locations on the reproduction that differed detectably from the original. We {{refer to the}} distribution of <b>error</b> <b>marks</b> by the subjects as image distortion maps. The empirically obtained image distortion maps are compared to the visible difference calculated using three color difference metrics. These are color distortions predicted by the widely used mean square error (point-bypoint MSE) computed in RGB values, the point-by-point CIELAB #E color difference formula (CIE, 1971), and SCIELAB, a spatial extension of CIELAB that incorporates spatial filtering in an opponent colors representation prior to the CIELAB calculation (Zhang & Wandell, 1996). For halftoned reproductions the RMS, CIELAB, and SCIELAB error sizes correlated with the locations marked by subjects reasonably well, given the freedom to select a threshold level separately [...] ...|$|R
5|$|Spencer {{ended the}} inning by {{throwing}} Snider out {{at home to}} keep the score 2–0. Eddie Stanky reached base after a Dodgers <b>error,</b> <b>marking</b> the second <b>error</b> for both teams; after another hit, the inning ended with a strikeout by Thomson. In the fourth inning, three players hit singles but did not score. Snider doubled in the fifth inning with one out, and a Jackie Robinson single made the score 3–0 for the Dodgers. The inning ended for the Dodgers on a double play, and Don Mueller hit a single {{in the bottom of}} the fifth before the Giants recorded three straight outs. The Dodgers opened up the game in the sixth inning, as Hodges led off with a home run. Billy Cox then reached base on an error and scored on a second error to make the game 5–0. After Labine walked to get on base, there was a rain delay, and play did not resume until that night.|$|R
40|$|PELAB at Linköping University is {{developing}} a complete environment for developing software in the Modelica language. Modelica is a computer language for modelling and simulating complex systems that can be described by using mathematical equations. The language is currently being extended by PELAB to also support language modeling and meta-modeling. The environment that PELAB {{is developing}} is called OpenModelica. An {{important part of this}} project is a textual environment for creating and editing Modelica models. The Modelica Development Tooling is a collection of integrated tools for working with Modelica projects. It is developed as a series of plugins to the Eclipse environment. One of the requirements of an integrated development environment (IDE) is to provide the user with extra information that is helpful for developing and understanding software. Some of the information provided by MDT is package browsing and <b>error</b> <b>marking.</b> Modelica packages can be browsed {{in much the same way}} as Java packages can be browsed in JDT, the Jav...|$|R
40|$|Anumber {{of color}} image #delity metrics were {{evaluated}} by looking at howwell they predict visibility of image reproduction errors on perceptual image distortion maps. The image distortion maps are obtained empirically. Subjects examined image pairs consisting of an original and a reproduction. They marked locations on the reproduction that di#ered detectably from the original. We refer to the distribution of <b>error</b> <b>marks</b> by the subjects as image distortion maps. The empirically obtained image distortion maps are compared to the visible difference calculated using # 1 # the widely used {{root mean square error}} #point-by-point RMS# computed in uncalibrated RGB values, # 2 # the point-by-point CIELAB #E 94 values #CIE, 1994 #, and # 3 # S-CIELAB #E 94, a spatial extension of CIELAB #E metric. The uncalibrated RMS metric did not predict the perceptual image distortion data very well. The CIELAB #E 94 metric is a calibrated color #delity metric, and gave better predictions. The S-CIELAB metric, whi [...] ...|$|R
40|$|Spoofax is a {{language}} workbench for efficient, agile development of textual domain-specific languages with state-of-the-art IDE support. Spoofax integrates language processing techniques for parser generation, meta-programming, and IDE development {{into a single}} environment. It uses concise, declarative specifications for languages and IDE services. In this paper we describe the architecture of Spoofax and introduce idioms for high-level specifications of language semantics using rewrite rules, showing how analyses can be reused for transformations, code generation, and editor services such as <b>error</b> <b>marking,</b> reference resolving, and content completion. The implementation of these services is supported by language-parametric editor service classes that can be dynamically loaded by the Eclipse IDE, allowing new languages to be developed and used side-by-side in the same Eclipse environment. Preprint accepted for publication in Proceedings of the 25 th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA 2010), Portland (USA), 20 - 24 Oct. 2010. Software TechnologyElectrical Engineering, Mathematics and Computer Scienc...|$|R
50|$|Spencer {{ended the}} inning by {{throwing}} Snider out {{at home to}} keep the score 2-0. Eddie Stanky reached base after a Dodgers <b>error,</b> <b>marking</b> the second <b>error</b> for both teams; after another hit, the inning ended with a strikeout by Thomson. In the fourth inning, three players hit singles but did not score. Snider doubled in the fifth inning with one out, and a Jackie Robinson single made the score 3-0 for the Dodgers. The inning ended for the Dodgers on a double play, and Don Mueller hit a single {{in the bottom of}} the fifth before the Giants recorded three straight outs. The Dodgers opened up the game in the sixth inning, as Hodges led off with a home run. Billy Cox then reached base on an error and scored on a second error to make the game 5-0. After Labine walked to get on base, there was a rain delay, and play did not resume until that night.|$|R
50|$|Truck Twelve {{took place}} on the weekend of 25-26 July 2009 The Saturday headliners were Ash, while local music stalwarts Supergrass closed {{proceedings}} on the Sunday night. Other acts included Red Light Company, Yacht, <b>Errors,</b> <b>Mark</b> Olson & Gary Louris, And So I Watch You from Afar, Broken Records, Sportsday Megaphone, Data.select.party, Pete Molinari, Pulled Apart by Horses, Chew Lips, Joe Allen Band, Calories, Mike Heron, The Candyskins, Disasteradio, Detroit Social Club, Panama Kings, KTB, Danny and the Champions of the World, Gabriel Minnikin, Holton's Opulent Oog, Nervous Test Pilot, Jali Fily Cissokho, Andrew Ferris and Ruth Minnikin & Her Bandwagon. Dial F for Frankenstein (an unsigned Oxford band) were the opening act in the Cow-Shed on the Saturday and were met by a huge turn out, the On the Sunday Rock Sound magazine and Bob Harris hosted the barn-stage and the solar-powered market stage respectively. A secret set was played by Frank Turner on the Sunday night, under the name Funk Tanker.|$|R
40|$|Outputs of five Czech-Slovak machine {{translation}} systems (Česílko, Česílko 2, Google Translate and Moses with different settings) for first 50 sentences of WMT 2010 testing set. The translations were manually processed and the <b>errors</b> were <b>marked</b> and classified {{according to the}} scheme by Vilar et al. (David Vilar, Jia Xu, Luis Fernando D’Haro, Hermann Ney: Error Analysis of Statistical Machine Translation Output, Proceedings of LREC- 2006, 2006...|$|R
40|$|This {{article was}} republished on April 11, 2014, to correct an <b>error</b> that <b>marked</b> {{coauthor}} Tim D. Smith as deceased. The publisher apologizes for this error. Please download this article again {{to view the}} correct version. The originally published, uncorrected article and the republished, corrected article are provided here for reference. Supporting Information File S 1. Originally published, uncorrected article. File S 2. Republished corrected article...|$|R
40|$|Micro-editing {{procedures}} {{have a number}} of problems: often there are many checks with narrow tolerances resulting in too many mistakes that need to be resolved manually by analysts. The analysts cannot assess the relative importance of these <b>errors.</b> Each <b>marked</b> item has the same weight and needs {{the same amount of time}} for correction. However, many errors have a neglible impact on the final estimates: either they are small or the...|$|R
40|$|This {{paper is}} a pre-print of: Oskar van Rest, Guido Wachsmuth, Jim Steel, Jörn Guy Süß, Eelco Visser. Robust Real-Time Synchronization between Textual and Graphical Editors. In Keith Duddy, Gerti Kappel, editors, Theory and Practice of Model Transformations, Sixth International Conference, ICMT 2013, Budapest, Hungary, June 18 - 19, 2013. Proceedings. Lecture Notes in Computer Science, Springer Verlag 2013. In modern Integrated Development Environments (IDEs), textual editors are {{interactive}} and can handle intermediate, incomplete, or otherwise erroneous texts while still providing editor {{services such as}} syntax highlighting, <b>error</b> <b>marking,</b> outline views, and hover help. In this paper, we present an approach for the robust synchronization of interactive textual and graphical editors. The approach recovers from errors during parsing and text-to-model synchronization, preserves textual and graphical layout {{in the presence of}} erroneous texts and models, and provides synchronized editor services such as selection sharing and navigation between editors. It was implemented for synchronizing textual editors generated by the Spoofax language workbench and graphical editors generated by the Graphical Modeling Framework. Software Computer TechnologyElectrical Engineering, Mathematics and Computer Scienc...|$|R
