239|30|Public
5|$|Simultaneous {{multithreading}} (of which Intel's <b>Hyper-Threading</b> is {{the best}} known) was an early form of pseudo-multi-coreism. A processor capable of simultaneous multithreading includes multiple execution units in the same processing unit—that is it has a superscalar architecture—and can issue multiple instructions per clock cycle from multiple threads. Temporal multithreading {{on the other hand}} includes a single execution unit in the same processing unit and can issue one instruction at a time from multiple threads.|$|E
5|$|Development for {{multiple}} platforms is profitable, but difficult. Optimizations needed for one platform architecture {{do not necessarily}} translate to others. Individual platforms such as the Sega Genesis and PlayStation 3 are seen as difficult to develop for compared to their competitors, and developers are not yet fully accustomed to new technologies such as multi-core processors and <b>hyper-threading.</b> Multi-platform releases are increasingly common, but not all differences between editions on multiple platforms can be fully explained by hardware alone, and there remain franchise stalwarts that exist solely on one system. Developers for new platforms such as handheld and mobile systems {{do not have to}} operate under the pressure of $20 million budgets and the scrutiny of publishers' marketing experts.|$|E
5|$|The device uses a 65nm process, {{includes}} {{two to four}} cores, up to 24MB on-die caches, <b>Hyper-Threading</b> technology and integrated memory controllers. It implements double-device data correction, which helps to fix memory errors. Tukwila also implements Intel QuickPath Interconnect (QPI) to replace the Itanium bus-based architecture. It has a peak interprocessor bandwidth of 96GB/s and a peak memory bandwidth of 34GB/s. With QuickPath, the processor has integrated memory controllers and interfaces the memory directly, using QPI interfaces to directly connect to other processors and I/O hubs. QuickPath is also used on Intel processors using the Nehalem microarchitecture, making it probable that Tukwila and Nehalem {{will be able to}} use the same chipsets.|$|E
5000|$|Current version {{supports}} systems {{running up}} to 64 CPU cores; logical or in <b>Hyper-Threaded</b> mode.|$|R
50|$|The mobile Core i5-2xxxM {{processors}} are all dual-core and <b>hyper-threaded</b> chips {{like the}} previous Core i5-5xxM series, and share {{most of the}} features with that product line.|$|R
40|$|Intel's <b>Hyper-Thread</b> ng Technology {{brings the}} concept of {{simultaneous}} multi-thread ng to the Intel Architecture. <b>Hyper-Thread</b> ng Technology makes a single physical processor appear as two logical processors; the physical execution resources are shared and the architecture state isdzR icated for the two logical processors. From a software or architecture perspective, this means operating systems and user programs can sched(e processes or thread to logical processors as they would on multiple physical processors. From a microarchitecture perspective, this means that instructions from both logical processors will persist and execute simultaneously on shared execution resources...|$|R
25|$|Like {{the last}} NetBurst CPUs, Core based {{processors}} feature multiple cores and hardware virtualization support (marketed as Intel VT-x), {{as well as}} Intel 64 and SSSE3. However, Core-based processors {{do not have the}} <b>Hyper-Threading</b> Technology found in Pentium 4 processors. This is because the Core microarchitecture is a descendant of the P6 microarchitecture used by Pentium Pro, Pentium II, Pentium III, and Pentium M.|$|E
25|$|The L1 {{cache size}} was {{enlarged}} in the Core microarchitecture, from 32KB on Pentium II/III (16KB L1 Data + 16KB L1 Instruction) to 64KB L1 cache/core (32KB L1 Data + 32KB L1 Instruction) on Pentium M and Core/Core 2. It also lacks an L3 Cache {{found in the}} Gallatin core of the Pentium 4 Extreme Edition, although an L3 Cache is present in high-end versions of Core-based Xeons. Both an L3 cache and <b>Hyper-threading</b> were reintroduced in the Nehalem microarchitecture.|$|E
2500|$|Windows 9x has no native {{support for}} [...] <b>hyper-threading,</b> Data Execution Prevention, {{symmetric}} multiprocessing or multi-core processors.|$|E
40|$|International audienceModular {{multiplication}} is {{the most}} costly and common operation in hyper-elliptic curve cryptography. Over prime fields, it uses dependent partial products and reduction steps. These dependencies make FPGA implementations with fully pipelined DSP blocks difficult to optimize. We propose a new multiplier architecture with <b>hyper-threaded</b> capabilities. Several independent multiplications are handled in parallel for efficiently filling the pipeline and overlapping internal latencies by independent computations. It increases the silicon efficiency and leads to a better area / computation time trade-off than {{current state of the}} art. We use this <b>hyper-threaded</b> multiplier into small accelerators for hyper-elliptic curve cryptography in embedded systems...|$|R
50|$|Google compute {{engine unit}} (GCEU), which is {{pronounced}} as GQ, is an abstraction of compute resources. According to Google, 2.75 GCEUs represent the minimum power of one logical core (a hardware <b>hyper-thread)</b> {{based on the}} Sandy Bridge platform.|$|R
50|$|Processor {{affinity}} {{can effectively}} reduce cache problems, {{but it does}} not reduce the persistent load-balancing problem. Also note that processor affinity becomes more complicated in systems with non-uniform architectures. For example, a system with two dual-core <b>hyper-threaded</b> CPUs presents a challenge to a scheduling algorithm.|$|R
2500|$|... whereas Windows 7 Starter, Home Basic, and Home Premium editions support only 1. Physical {{processors}} {{with either}} multiple cores, or <b>hyper-threading,</b> or both, implement {{more than one}} logical processor per physical processor. The x86 editions of Windows 7 support up to 32 logical processors; x64 editions support up to 256 (4 x 64).|$|E
2500|$|Zen {{is a new}} {{architecture}} for x86-64 based Ryzen series CPUs and APUs, {{introduced in}} 2017 by AMD and built {{from the ground up}} by a team led by Jim Keller, beginning with his arrival in 2012, and taping out before his departure in September 2015. One of AMD's primary goals with Zen was an IPC increase of at least 40%, however in February 2017 AMD announced that they had actually achieved a 52% increase. Processors made on the Zen architecture are built on the 14nm FinFET node and have a renewed focus on single-core performance and HSA compatibility. Previous processors from AMD were either built in the 32nm process ("Bulldozer" [...] and [...] "Piledriver" [...] CPUs) or the 28nm process ("Steamroller" [...] and [...] "Excavator" [...] APUs). Because of this, Zen is much more energy efficient. The Zen architecture is the first to encompass CPUs and APUs from AMD built for a single socket (Socket AM4). Also new for this architecture is the implementation of simultaneous multithreading (SMT) technology, something Intel has had for years on some of their processors with their proprietary <b>Hyper-Threading</b> implementation of SMT. This is a departure from the [...] "Clustered MultiThreading" [...] design introduced with the Bulldozer architecture. Zen also has support for DDR4 memory. AMD released the Zen-based high-end Ryzen 7 [...] "Summit Ridge" [...] series CPUs on March 2, 2017, mid-range Ryzen 5 series CPUs on April 11, 2017, and entry level Ryzen 3 series CPUs on July 27, 2017. AMD later released the Epyc line of Zen derived server processors for 1P and 2P systems. In October 2017, AMD released Zen based APUs as Ryzen Mobile, incorporating Vega graphics cores.|$|E
5000|$|Intel {{released}} the Nehalem (Core i7) in November 2008 in which <b>hyper-threading</b> made a return. The first generation Nehalem contained four cores and effectively scaled eight threads. Since then, both two- and six-core {{models have been}} released, scaling four and twelve threads respectively. [...] Earlier Intel Atom cores were in-order processors, sometimes with <b>hyper-threading</b> ability, for low power mobile PCs and low-price desktop PCs. [...] The Itanium 9300 launched with eight threads per processor (two threads per core) through enhanced <b>hyper-threading</b> technology. The next model, the Itanium 9500 (Poulson), features a 12-wide issue architecture, with eight CPU cores with support for eight more virtual cores via <b>hyper-threading.</b> The Intel Xeon 5500 server chips also utilize two-way <b>hyper-threading.</b>|$|E
50|$|Unlike a {{traditional}} dual-processor configuration that uses two separate physical processors, the logical processors in a <b>hyper-threaded</b> core share the execution resources. These resources include the execution engine, caches, and system bus interface; {{the sharing of}} resources allows two logical processors to work with each other more efficiently, and allows a logical processor to borrow resources from a stalled logical core (assuming both logical cores {{are associated with the}} same physical core). A processor stalls when it is waiting for data it has sent for so it can finish processing the present thread. The degree of benefit seen when using a <b>hyper-threaded</b> or multi core processor depends on the needs of the software, and how well it and the operating system are written to manage the processor efficiently.|$|R
50|$|The ZenFone 5 is the {{mid range}} of the series and {{includes}} a 5-inch 1280×720 HD IPS display protected with Corning Gorilla Glass 3. This Zenfone features either a dual-core <b>hyper-threaded</b> (dubbed Multicore) Intel Atom or a quad-core Qualcomm Snapdragon processor, an 8 MP rear and 2 MP front camera.|$|R
50|$|Rather {{than being}} a {{successor}} of any previous W-series model, the Lenovo W550s is a thinner Ultrabook variant of the W-series. While a capable Ultrabook, {{when compared to the}} W541 and its predecessors, it offers less capability with only dual-core <b>hyper-threaded</b> Intel Broadwell Processors vs. the true quad-core processors of other models and has only two RAM slots.|$|R
5000|$|According to a November 2009 {{analysis}} by Intel, performance impacts of <b>hyper-threading</b> result in increased overall latency {{in case the}} execution of threads does not result in significant overall throughput gains, which vary by the application. In other words, overall processing latency is significantly increased due to <b>hyper-threading,</b> with the negative effects becoming smaller as there are more simultaneous threads that can effectively use the additional hardware resource utilization provided by <b>hyper-threading.</b> [...] A similar performance analysis is available {{for the effects of}} <b>hyper-threading</b> when used to handle tasks related to managing network traffic, such as for processing interrupt requests generated by network interface controllers (NICs). [...] Another paper claims no performance improvements when <b>hyper-threading</b> is used for interrupt handling.|$|E
5000|$|There {{has been}} some {{marketing}} confusion {{between the use of}} HT referring to HyperTransport and the later use of HT to refer to Intel's <b>Hyper-Threading</b> feature on some Pentium 4-based and the newer Nehalem and Westmere-based Intel Core microprocessors. <b>Hyper-Threading</b> is officially known as <b>Hyper-Threading</b> Technology (HTT) or HT Technology. Because of this potential for confusion, the HyperTransport Consortium always uses the written-out form: [...] "HyperTransport." ...|$|E
50|$|Originally, Intel {{released}} two Prescott lines: the E-series, with an 800 MT/s FSB and <b>Hyper-Threading</b> support, and the low-end A-series, with a 533 MT/s FSB and <b>Hyper-Threading</b> disabled. Intel eventually added XD Bit (eXecute Disable) and Intel 64 functionality to Prescott.|$|E
40|$|This paperd escribes the <b>Hyper-Thread</b> ng Technology architecture, and d scusses the {{microarchitecture}} de ails of Intel's first implementation on the Intel processor family. <b>Hyper-Thread</b> ing Technology is {{an important}} adz tion to Intel's enterprise prodqq line and will be integratedz nto a wid e variety of prodFq s. Intel is a registere d trad) ark of Intel Corporation or its subsid iaries in the Unitedz tates andRF subsid iaries in the Unitedz tates and) F INTRO 1 K, IOK The amazing growth of the Internet and telecommunications is powered by ever-faster systems dF and ng increasingly higher levels of processor performance. To keep up with this and we cannot rely entirely on trad tional approaches to processor d)) gn. Microarchitecture techniques used to achieve past processor performance improvement [...] superpipelining, branch pr ed ction, super-scalar execution, out-of-or dF execution, caches [...] have mad [...] microprocessors increasingly more complex, have more transistors, and consume more power. In fact, transistor counts and power are increasing at rates greater than processor performance. Processor architects are therefore {{looking for ways to}} improve performance at a greater rate than transistor counts and power d ssipation. Intel's <b>Hyper-Thread</b> ng Technology is one solution. Processor Microarchitecture Trad tional approaches to processor d(j gn have focused on higher clock speedzO instruction-level parallelism (ILP), and caches. Techniques to achieve higher clock speed s involve pipelining the microarchitecture to finer granularities, also called super-pipelining. Higher clock frequencies can greatly improve performance by increasing the number of instructions that can be executed each secondz Because there will be far more ins [...] ...|$|R
5000|$|The INtime [...] Real Time Operation System (RTOS) {{family is}} based on a 32 bit RTOS {{conceived}} to run time-critical operations cycle-times as low as 50μs. INtime RTOS runs on single-core, <b>hyper-threaded</b> and multi-core x86 PC platform from Intel and AMD and supports two binary compatible usage configurations; INtime for Windows where the INtime RTOS runs alongside Microsoft® Windows® and INtime Distributed RTOS where INtime runs as a stand-alone RTOS.|$|R
40|$|We {{present a}} {{comparative}} {{analysis of the}} maximum performance achieved by the Linpack benchmark on compute intensive hardware publicly available from multiple cloud providers. We study both performance within a single compute node, and speedup for distributed memory calculations with up to 32 nodes or at least 512 computing cores. We distinguish between <b>hyper-threaded</b> and non-hyper-threaded scenarios and estimate the performance per single computing core. We also compare results with a traditional supercomputing system for reference. Our findings provide a way to rank the cloud providers and demonstrate {{the viability of the}} cloud for high performance computing applications...|$|R
5000|$|<b>Hyper-threading</b> {{works by}} {{duplicating}} certain {{sections of the}} processor—those that store the architectural state—but not duplicating the main execution resources. This allows a <b>hyper-threading</b> processor to appear as the usual [...] "physical" [...] processor and an extra [...] "logical" [...] processor to the host operating system (HTT-unaware operating systems see two [...] "physical" [...] processors), allowing the operating system to schedule two threads or processes simultaneously and appropriately. When execution resources would not {{be used by the}} current task in a processor without <b>hyper-threading,</b> and especially when the processor is stalled, a <b>hyper-threading</b> equipped processor can use those execution resources to execute another scheduled task. (The processor may stall due to a cache miss, branch misprediction, or data dependency.) ...|$|E
5000|$|A CPU package means {{physical}} CPU {{which can}} have multiple cores (single core for one, dual core for two, quad core for four).This allows {{a distinction between}} <b>hyper-threading</b> and dual-core, i.e. the number of hyper-threads per CPU package can be calculated by siblings / CPU cores. If both values for a CPU package are the same, then <b>hyper-threading</b> is not supported. [...] For instance, a CPU package with siblings=2 and [...] "cpu cores"=2 is a dual-core CPU but does not support <b>hyper-threading.</b>|$|E
5000|$|Simultaneous {{multithreading}} {{by multiple}} cores and <b>hyper-threading</b> (2× per core).|$|E
40|$|Today’s {{general-purpose}} processors {{are increasingly}} using multithreading {{in order to}} better leverage the additional on-chip real estate available with each technology generation. Simultaneous Multi-Threading (SMT) was originally proposed as a large dynamic superscalar processor with monolithic hardware structures shared among all threads. Intel’s <b>Hyper-Threaded</b> Pentium 4 processor partitions the queue structures among two threads, demonstrating more balanced performance by reducing the hoarding of structures by a single thread. IBM’s Power 5 processor is a 2 -way Chip Multiprocessor (CMP) of SMT processors, each supporting 2 threads, which significantly reduces design complexity and can improve power efficiency. This paper examines processor partitioning options fo...|$|R
40|$|Accelerators, such as field {{programmable}} gate arrays (FPGAs) {{and graphics}} processing units (GPUs), are special purpose processors designed {{to speed up}} compute-intensive sections of applications. FPGAs are highly customizable, while GPUs provide massive parallel execution resources and high memory bandwidth. In this paper, we compare the performance of these architectures, presenting a performance study of SEAL, a fast, software-oriented encryption algorithm on a Virtex- 6 FPGA, a Graphics Processor Unit (GPU), and Intel Core i 7, a 2 -way <b>hyper-threaded,</b> 4 -core processor. We show that each platform has relative competitive advantages in encrypting an input plaintext using SEAL. © 2011 IEEE...|$|R
40|$|Modern {{multimedia}} workloads provide {{increased levels}} of quality and compression efficiency {{at the expense of}} substantially increased computational complexity. It is important to leverage the off-the-shelf emerging multi-core processor architectures and exploit all levels of parallelism of such workloads in order to achieve real time functionality at a reasonable cost. This paper presents the implementation, optimization and characterization of the AVS video decoder on Intel Core i 7, a quad-core, <b>hyper-threaded,</b> chip multiprocessor (CMP). AVS (Audio Video Standard), a new compression standard from China, is competing with H. 264 to potentially replace MPEG- 2, mainly in the Chinese market. We show {{that it is necessary to}} perform a. © 2010 IEEE...|$|R
5000|$|Up {{to eight}} {{physical}} cores or 16 logical cores through <b>Hyper-threading</b> ...|$|E
5000|$|MONITOR, MWAIT - These {{optimize}} multi-threaded applications, giving processors with <b>Hyper-threading</b> better performance.|$|E
50|$|Diamondville, Pineview are current Intel cores with <b>Hyper-Threading</b> {{sold under}} the Intel Atom brand.|$|E
40|$|Helper {{threading}} is {{a technology}} to accelerate a program by exploiting a processor’s multithreading capability to run “assist ” threads. Previous experiments on <b>hyper-threaded</b> processors have demonstrated significant speedups by using helper threads to prefetch hard-to-predict delinquent data accesses. In order to apply this technique to processors {{that do not}} have built-in hardware support for multithreading, we introduce virtual multithreading (VMT), a novel form of switch-on-event user-level multithreading, capable of fly-weight multiplexing of event-driven thread executions on a single processor without additional operating system support. The compiler {{plays a key role in}} minimizing synchronization cost by judiciously partitioning register usage among the user-level threads. The VMT approach make...|$|R
40|$|So far, {{the privileged}} {{instructions}} MONITOR and MWAIT introduced with Intel Prescott core, {{have been used}} mostly for inter-thread synchronization in operating systems code. In a <b>hyper-threaded</b> processor, these instructions offer a ""performance-optimized"" way for threads involved in synchronization events to wait on a condition. In this work, we explore the potential of using these instructions for synchronizing application threads that execute on <b>hyper-threaded</b> processors, and are characterized by workload asymmetry. Initially, we propose a framework through which one can use MONITOR/MWAIT to build condition wait and notification primitives, with minimal kernel involvement. Then, we evaluate the efficiency of these primitives in a bottom-up manner: at first, we quantify certain performance aspects of the primitives that reflect the execution model under consideration, such as resource consumption and responsiveness, and we compare them against other commonly used implementations. As a further step, we use our primitives to build synchronization barriers. Again, we examine the same performance issues as before, and using a pseudo-benchmark we evaluate the efficiency of our implementation for fine-grained inter-thread synchronization. In terms of throughput, our barriers yielded 12 % better performance on average compared to Pthreads, and 26 % compared to a spin-loops-based implementation, for varying levels of threads asymmetry. Finally, we test our barriers in a real-world scenario, and specifically, in applying thread-level Speculative Precomputation on four applications. For this multithreaded execution scheme, our implementation provided up to 7 % better performance compared to Pthreads, and up to 40 % compared to spin-loops-based barriers. © 2008 IEEE...|$|R
40|$|Simulation of {{large-scale}} networks {{remains to be}} a challenge, although various network simulators are in place. In this paper, we identify fundamental issues for large-scale network simulation, and propose new techniques that address them. First, we exploit optimistic parallel simulation techniques to enable fast execution on inexpensive <b>hyper-threaded,</b> multiprocessor systems. Second, we provide a compact, light-weight implementation framework that greatly reduces the amount of state required to simulate large-scale network models. Based on the proposed techniques, we provide sample simulation models for two networking protocols: TCP and OSPF. We implement these models in a simulation environment ROSSNet, which is an extension to the previously developed optimistic simulator ROSS. We perform validation experiments for TCP and OSPF and present performance results of our technique...|$|R
