3|33|Public
50|$|UNI was {{the result}} of the merger of four organisations: FIET (International Federation of Employees, {{technicians}} and managers), MEI (Media and Entertainment International), IGF (<b>International</b> <b>Graphical</b> <b>Federation)</b> and CI (Communications International, formally PTTI).|$|E
50|$|Verdi is {{a member}} of many {{international}} union federations such as the UNI Global Union, the International Transport Workers' Federation, the <b>International</b> <b>Graphical</b> <b>Federation,</b> the European and the International Federation of Journalists and the Public Services International. It {{is also a member of}} the European Movement Germany (EBD) and a partner of the Tax Justice Network.|$|E
50|$|Bonfield {{grew up in}} Hitchin in Hertfordshire before {{becoming}} a printer. He joined the Typographical Association, becoming its National Assistant Secretary in 1948, then General President in 1955 and General Secretary in 1957. That year, he was also elected to the executive of the <b>International</b> <b>Graphical</b> <b>Federation,</b> becoming President in 1967. In 1961, he was also elected as President of the Printing and Kindred Trades Federation.|$|E
5000|$|After {{the coup}} of 1976 {{he moved to}} Buenos Aires, working in the {{printing}} industry and was elected the first delegate of the Editorial Atlantida and then, in 1984, deputy {{general secretary of the}} <b>Graphical</b> <b>Federation</b> [...]|$|R
40|$|This article {{discusses}} basic transcripition {{approaches of}} foreign and borrowed words in Ukrainian, Russian, and Belarusian; Ukrainian words in Latin script. It {{is argued that}} the adopted and foreign words should be rendered on different bases, namely by invariant transcription and transliteration. Also, the current problems of implementation of the Ukrainian Latinics as an <b>international</b> <b>graphical</b> presentation of Ukrainian, are analyzed. The scholarly grounded simple-correspondent transliteration system for Belarusian, Russian, and Ukrainian, is given in the paper...|$|R
5000|$|There {{are several}} {{national}} and <b>international</b> standards for <b>graphical</b> symbols in circuit diagrams, in particular: ...|$|R
40|$|<b>International</b> audienceAncient <b>graphical</b> {{documents}} are invaluable heritages {{which have been}} handed down since generations. They possess both intellectual and spiritual worth for humanity. In this context, many digitization processes have been started, producing very large warehouse of images. These huge amount of data raise the problem of indexing the information {{in order to make}} easier navigation in the databases. In the context of a French research program, called MADONNE, this paper proposes a set of complementary contributions concerning ancient graphic images indexing...|$|R
40|$|In French) <b>International</b> audienceThe Gaspard (<b>Graphical</b> Array Specification for PARallel and Distributed computing) {{project is}} a visual {{specification}} environment for data-parallelism. We describe here the specification model used in Gaspard. This model inherits from the Array-OL one. We then define an SQL inspired approach to intensive data treatment that proposes a language to describe irregular components...|$|R
40|$|<b>International</b> audienceProbabilistic <b>graphical</b> {{models have}} been widely {{recognized}} as a powerful formalism in the bioinformatics field, especially in gene expression studies and linkage analysis. Although less well known in association genetics, many successful methods have recently emerged to dissect the genetic architecture of complex diseases. In this review paper, we cover the applications of these models to the population association studies' context, such as linkage disequilibrium modeling, fine mapping and candidate-gene studies, and genome-scale association studies. Significant breakthroughs of the corresponding methods are highlighted, but emphasis is also given to their current limitations, in particular, {{to the issue of}} scalability. Finally, we give promising directions for future research in this field...|$|R
40|$|II!I J) u! Preface Over {{the last}} 18 months, {{the staff of}} the Graphics Project has been working to convert the NCAR Graphics Package to conform to the <b>international</b> <b>Graphical</b> Kernel System (GKS) stan-dard, as adopted by the International Standards Organization (ISO) and the American National Standards Institute (ANSI). CKS {{includes}} a FORTRAN binding that specifies the names and arguments of the library of routines that comprise a standard system. The work done by Graphics Project staff inclltdes: converting all graphics code to FORTRAN 77; converting utili-ties to call GKS-based rout ies; creating the System Plot Package Simulator (SPPS) to replace the old NCAR System Plot Package (NSPP); and implementing GKS library routines to allow software design and testing. This is the first release of documentation for NCAR's GKS-based Graphics Package. Both the software and the documentation included in this package have been completely revised. If you are new to the NCAR Graphics Package, you may wish to skip over the sections dealing with differences in the new software versus the old software, conversion instructions, and the like. These sections have been provided to aid users of the old NCAR Graphics Package in their conversions to the new software. Cover Diagram The diagram shown on the cover of this text displays the components of the old and new pack-ages side-by-side. The applications layer, shown at the upper level of the top boxes, is the software supplied by a scientist or programmer. Applications programs at NCAR typically display experimental data or the output of model runs. Applications software is not part of th...|$|R
40|$|<b>International</b> audienceTrace {{analysis}} <b>graphical</b> user environments have {{to provide}} different views on trace data, {{in order to be}} effective in helping the comprehension of the traced application behavior. In this article we propose an open and modular software architecture, the FrameSoC workbench, which defines clear principles for view engineering and for view consistency management. The FrameSoC workbench has been successfully applied in real trace analysis use cases...|$|R
40|$|<b>International</b> audienceExisting <b>graphical</b> {{authentication}} methods {{take into}} account the fact that users are more capable of remembering pictures instead of text. Graphical authentication schemes are expected to be less vulnerable to specific hacker attack techniques that have greatly improved in recent years. The usability aspect of a graphical authentication product refers to the extent that a product can be used by users to achieve goals with effectiveness, efficiency and satisfaction in a specified context of use. This paper describes a prototype system providing graphical authentication of mobile devices over the Internet, covering both usability and security aspects. Color images are assigned to the mobile users and authentication is achieved by modifying the Red-Green Blue (RGB) color intensity values of the assigned image...|$|R
40|$|<b>International</b> audienceGaussian <b>Graphical</b> Models {{provide a}} {{convenient}} framework for representing dependencies between variables. Recently, this tool {{has received a}} high interest for the discovery of biological networks. The literature focuses on the case where a single network is inferred from a set of measurements, but, as wetlab data is typically scarce, several assays, where the experimental conditions affect interactions, are usually merged to infer a single network. In this paper, we propose two approaches for estimating multiple related graphs, by rendering the closeness assumption into an empirical prior or group penalties. We provide quantitative results demonstrating {{the benefits of the}} proposed approaches. The methods presented in this paper are embeded in the R package simone from version 1. 0 - 0 and later...|$|R
40|$|<b>International</b> audienceProbabilistic <b>Graphical</b> Models (PGMs) offer {{a popular}} {{framework}} including {{a variety of}} statistical formalisms, such as Bayesian networks (BNs). These latter are able to depict real-world situations with high degree of uncertainty. Due to their power and flexibility, several extensions were proposed, ensuring thereby the suitability of their use. Probabilistic Relational Models (PRMs) extend BNs to work with relational databases rather than propositional data. Their construction represents an active area since it remains the most complicated issue. Only few works have been proposed in this direction, {{and most of them}} don’t guarantee an optimal identification of their dependency structure. In this paper we intend to propose an approach that ensures returning an optimal PRM structure. It is inspired from a BN method whose performance was already proven...|$|R
40|$|<b>International</b> audienceProbabilistic <b>graphical</b> {{models for}} {{continuous}} variables {{can be built}} out of either parametric or nonparametric conditional density estimators. While several research efforts have been focusing on parametric approaches (such as Gaussian models), kernel-based estimators are still the only viable and well-understood option for nonparametric density estimation. This paper develops a semiparametric estimator of probability density functions based on the nonparanormal transformation, which has been recently proposed for mapping arbitrarily distributed data samples onto normally distributed datasets. Pointwise and uniform consistency properties are established for the developed method. The resulting density model is then applied to pseudo-likelihood estimation in Markov random fields. An experimental evaluation on data distributed according {{to a variety of}} density functions indicates that such semiparametric Markov random field models significantly outperform both their Gaussian and kernel-based alternatives in terms of prediction accuracy...|$|R
40|$|<b>International</b> audienceIn the <b>graphical</b> user {{interface}} of a P 300 -BCI, {{the location and}} {{the moment of the}} flashes can be considered as relevant parameters for increasing the accuracy. The inter stimuli interval has been largely discussed but the location of the flashes, i. e., row/column, has not been investigated so much. We propose a formal description that allows any P 300 -BCI designer to quickly go beyond the row/column flashes while keeping the exact same number of flashes of the classical row/column method i. e., without losing speed...|$|R
40|$|<b>International</b> audienceThe recent <b>graphical</b> {{rendering}} {{models of}} desktop computers {{can be used}} to explore new window management techniques. In order to evaluate these new techniques, we should have tools that help us better understand how users manipulate their windows. We present a log and visualization tool of the Human-Window interaction for the X Window system. The tool allows to replay a session (without the windows contents) as a video. A filtering system allows to select and easily access high level actions. We give some examples of application of this system...|$|R
40|$|International audienceThis volume {{constitutes}} the thoroughly refereed post-conference {{proceedings of the}} Second <b>International</b> Workshop on <b>Graphical</b> Models for Security, GraMSec 2015, held in Verona, Italy, in July 2015. The 5 revised full papers presented together with one short tool paper and one invited article were carefully reviewed and selected from 13 submissions. The GraMSec workshop contributes {{to the development of}} well-founded graphical security models, efficient algorithms for their analysis, as well as methodologies for their practical usage, thus providing an intuitive but systematic methodology to analyze security weaknesses of systems and to evaluate potential protection measures...|$|R
40|$|Published in Lecture Notes on Computer Science, vol 7520, pp. 206 - 218, 2012 <b>International</b> audienceDirected evidential <b>graphical</b> {{models are}} {{important}} tools for handling uncertain {{information in the}} framework of evidence theory. They obtain their efficiency by compactly representing (in) dependencies between variables in the network and efficiently reasoning under uncertainty. This paper presents a new dynamic evidential network for representing uncertainty and managing temporal changes in data. This proposed model offers an alternative framework for dynamic probabilistic and dynamic possibilistic networks. A complexity study of representation and reasoning in the proposed model is also presented in this paper...|$|R
40|$|<b>International</b> audienceThe <b>graphical</b> {{characterisation}} ofmany important structural properties, such as controllability, observability, diagnosability of {{many kinds}} of structured systems, uses mainly four types of elementary graphical conditions: connectivity, complete matching, linking and distance conditions. Since structural properties depend on different associations of elementary conditions, {{it is interesting to}} study elementary conditions. This paper is {{the first part of this}} global approach based on elementary graphical conditions and we choose to study the so-called connectivity and complete matching conditions. Starting from the graphical representation associated with a system, the paper provides Boolean expressions of the connectivity and complete matching conditions based on the edges validity, which can be linked to the physical components operating state. These expressions can then be used to define and compute the reliability of a structural property knowing the reliability of the system physical components. This knowledge can be important during both conception and exploitation stages. The proposed methods are quite intuitive and simple to implement and have basically polynomial complexity orders. This makes our approach well suited to analyse large-scale systems...|$|R
40|$|<b>International</b> audienceProbabilistic <b>graphical</b> {{models are}} very {{efficient}} modeling and reasoning tools. In this paper, we propose an efficient and novel Bayesian network {{model for a}} major problem in alert correlation which plays a crucial role in nowadays computer security. Indeed, the use of multiple intrusion detection systems (IDSs) and complementary approaches is fundamental to improve the overall detection rates. This however inevitably rises huge amounts of alerts most of which are redundant and false alarms making the manual analysis of all the amounts of triggered alerts intractable. In this paper, we first propose a Bayesian network-based model allowing to handle the reliability of IDSs when predicting severe attacks by correlating the alerts reported by the IDSs monitoring the network. Then we propose a flexible and efficient approach especially designed to limit the false alarm rates by controlling the confidence of the prediction model. Finally, we provide experimental studies carried out on a real and representative alert corpus showing significant improvements regarding the tradeoffs between the prediction rates and the corresponding false alarm ones...|$|R
40|$|<b>International</b> audienceProbabilistic <b>graphical</b> {{models are}} very {{powerful}} modeling and reasoning tools. In this paper, we propose efficient Bayesian network-based approaches for two major problems in alert correlation which {{plays an important}} role in nowadays computer security infrastructures. While the use of multiple intrusion detection systems (IDSs) and complementary approaches is highly recommended to improve the overall detection rates, this inevitably rises huge amounts of alerts most of which are redundant and false alarms. The aim of this work is twofold: Firstly, we propose an approach based on Bayesian multi-nets which allow to take advantage of local influence relationships in order to improve the prediction of severe attacks. Secondly, we propose to handle the reliability of IDSs by considering the uncertainty relative to the triggered alerts. Experimental studies carried out on real and recent IDMEF alerts produced by the de facto network-based IDS Snort shows significant improvements with respect to standard Bayesian approaches. More particularly, the handling of IDSs' reliability significantly reduces the false alarm rate which represents a crucial issue for intrusion detection development...|$|R
40|$|<b>International</b> audienceIn <b>graphical</b> user interfaces, direct {{manipulation}} {{consists in}} incremental actions {{that should be}} reversible. Typical examples include manipulating geometrical shapes in a vector graphics editor, navigating a document using a scrollbar, or moving and resizing windows on the desktop. As in many such cases, {{there will not be}} any mechanism to undo them, requiring users to manually revert to the previous state using a similar sequence of direct manipulation actions. The associated motor and cognitive costs can be high. We argue that proper and consistent mechanisms to support undo in this context are lacking, and present Dwell-and-Spring, an interaction technique that uses the metaphor of springs to enable users to undo direct manipulations. A spring widget pops up whenever the user dwells during a press-drag-release interaction, giving her the opportunity to either cancel the current manipulation or undo the last one. The technique is generic and can easily be implemented on top of existing applications to complement the traditional undo command. Empirical evaluation shows that users quickly adopt it as soon as they discover it...|$|R
40|$|<b>International</b> audienceWhile <b>Graphical</b> User Interfaces (GUI) still {{represent}} {{the most common}} way of operating modern computing technology, Spoken Dialog Systems (SDS) {{have the potential to}} offer a more natural and intuitive mode of interaction. Even though some may say that existing speech recognition is neither reliable nor practical, the success of recent product releases such as Apple's Siri or Nuance's Dragon Drive suggests that language-based interaction is increasingly gaining acceptance. Yet, unlike applications for building GUIs, tools and frameworks that support the design, construction and maintenance of dialog systems are rare. A particular challenge of SDS design is the often complex integration of technologies. Systems usually consist of several components (e. g. speech recognition, language understanding, output generation, etc.), all of which require expertise to deploy them in a given application domain. This paper presents work in progress that aims at supporting this integration process. We propose a framework of components and describe how it maybe used to prototype and gradually implement a spoken dialog system without requiring extensive domain expertise...|$|R
40|$|Part 1 : Long and Short Papers (Continued) <b>International</b> audienceRecognition-based <b>graphical</b> {{authentication}} systems (RBGSs) using {{images as}} passwords {{have been proposed}} as one potential solution {{to the need for}} more usable authentication. The rapid increase in the technologies requiring user authentication has increased the number of passwords that users have to remember. But nearly all prior work with RBGSs has studied the usability of a single password. In this paper, we present the first published comparison of the usability of multiple graphical passwords with four different image types: Mikon, doodle, art and everyday objects (food, buildings, sports etc.). A longitudinal experiment was performed with 100 participants over a period of 8 weeks, to examine the usability performance of each of the image types. The results of the study demonstrate that object images are most usable in the sense of being more memorable and less time-consuming to employ, Mikon images are close behind but doodle and art images are significantly inferior. The results of our study complement cognitive literature on the picture superiority effect, visual search process and nameability of visually complex images...|$|R
40|$|Using the ARFIMA-FIGARCH model, {{this paper}} studies the {{efficiency}} of the Japanese equity market by examining the statistical properties of the return and volatility of the Nikkei 225. It shows that both follow a long range dependence, which stands against the efficient market hypothesis (EMH). The result is valid for all sample periods, suggesting that the recent equity market reform has not produced major efficiency gains. Stock markets;Economic models;equity market, stock market, random walk, martingale, time series, equation, autocorrelation, econometrics, financial market, stock returns, equations, financial markets, survey, stock exchange, statistics, financial institutions, time series analysis, financial economics, maximum likelihood method, financial reform, covariance, stock price, statistical methods, gamma function, bonds, heteroscedasticity, stock market prices, financial assets, asymptotic distribution, warrant bonds, stationary process, international financial markets, random walk process, futures trading, domestic capital, stochastic process, stock price index, hedge, index futures, statistical model, stock futures, standard deviations, statistic, money markets, operations research, gamma functions, equity markets, financial services, stock prices, <b>international</b> standards, <b>graphical</b> analysis, financial deregulation, stock market volatility, fractals, hedging, stock market index, financial reforms, foreign stock, standard deviation, foreign equity, domestic capital markets, skewness, stock holdings, international finance, stock market cycles, financial corporations, bond...|$|R
40|$|<b>International</b> audienceAs <b>graphical</b> {{summaries}} for topological {{spaces and}} maps, Reeb graphs are common {{objects in the}} computer graphics or topological data analysis literature. Defining good metrics between these objects has become an important question for applications, where it matters to quantify {{the extent by which}} two given Reeb graphs differ. Recent contributions emphasize this aspect, proposing novel distances such as functional distortion or interleaving that are provably more discriminative than the so-called bottleneck distance, being true metrics whereas the latter is only a pseudo-metric. Their main drawback compared to the bottleneck distance is to be comparatively hard (if at all possible) to evaluate. Here we take the opposite view on the problem and show that the bottleneck distance is in fact good enough locally, {{in the sense that it}} is able to discriminate a Reeb graph from any other Reeb graph in a small enough neighborhood, as efficiently as the other metrics do. This suggests considering the intrinsic metrics induced by these distances, which turn out to be all globally equivalent. This novel viewpoint on the study of Reeb graphs has a potential impact on applications, where one may not only be interested in discriminating between data but also in interpolating between them...|$|R
40|$|<b>International</b> audienceThe <b>graphical</b> {{approaches}} {{often have}} different backgrounds and view a system or an algebraic model from different perspectives {{in order to}} facilitate the communication and the understanding. These graphical approaches satisfy the modeling needs and give a clear and easily understandable overview of the behavioral and functional models and make easier to see what the process is, which vulnerabilities and asset that are involved and how the system works. The main goal {{of this paper is to}} develop and implement a methodology which combines the functional analysis and the bond graph (BG) tool for intelligent and autonomous systems. As a result, a supervisory interface is obtained, given under a ﬁnite automaton, displaying to the operators the possibilities the system has to achieve or not, its objectives. Each operating mode, corresponding to a vertex of the automaton, is associated with a set of services from a functional point-of-view and is deﬁned accurately by a behavioral BG model. Furthermore, the service availability (associated to the BG elements) and the conditions for switching from one mode to another one are analyzed by fault detection and isolation algorithms generated on the basis of the structural and causal properties of the BG tool. Moreover, when a fault is not completely isolable some results can nevertheless be expressed in terms of available or unavailable services...|$|R
50|$|With the game's {{initial release}} hitting Japan on December 21, 1997, the {{international}} release was slightly delayed. With mixed reviews from the press, {{the game was}} noted to be too easy and little rewarding. Nintendo of America would thus demand the difficulty bar of the game to be raised. With extra time to polish the title, several changes {{were made to the}} <b>international</b> release, including <b>graphical</b> cleanup; the addition of white fences on cardboard courses; Egg Blocks with colors matching the Yoshi in play; new locations for some items; a slightly different ending when the player finishes a course with only melons; and additional secrets, including hidden coin formations that spell out letters. Furthermore, the updated version also added a save feature to Story Mode, allowing the player to continue the game from the last page reached.|$|R
40|$|A {{simulation}} {{was developed}} to investigate the utilization of computer assisted decision making for the task of sequencing and scheduling aircraft in a high density terminal area. The simulation incorporates a decision methodology termed Constrained Position Shifting. This methodology accounts for aircraft velocity profiles, routes, and weight classes in dynamically sequencing and scheduling arriving aircraft. A sample demonstration of Constrained Position Shifting is presented where six aircraft types (including both light and heavy aircraft) are sequenced to land at Denver's Stapleton <b>International</b> Airport. A <b>graphical</b> display is utilized and Constrained Position Shifting with a maximum shift of four positions (rearward or forward) is compared to first come, first serve with respect to arrival at the runway. The implementation of computer assisted sequencing and scheduling methodologies is investigated. A time based control concept will be required and design considerations for such a system are discussed...|$|R
40|$|Part 1 : Long and Short Papers (Continued) <b>International</b> audienceIn <b>graphical</b> user interfaces, every {{application}} usually {{asks for}} the user’s full attention during interaction with it. Even marginal side activities often force {{the user to}} switch windows, which results in attention shifts and increased cognitive load. Peripheral interaction addresses this problem by providing input facilities in {{the periphery of the}} user’s attention by relying on divided attention and human capabilities such as proprioception and spatial memory. Recent work shows promising results by shifting tasks to the periphery for parallel task execution. Up to now, most of these interfaces rely on tag-based objects, tokens or wearable devices, which need to be grasped and manipulated, e. g., by turning, moving or pressing the device. To explore this design space further, we implemented three modalities for peripheral interaction with a desktop audio player application – graspable interaction, touch and freehand gestures. In an eight-week in-situ deployment, we compared the three modalities {{to each other and to}} media keys (as the state-of-the-art approach). We found that all modalities can be successfully used in the (visual and attentional) periphery and reduce the amount of cognitive load when interacting with an audio player. With this work we intend to (1) illustrate the variety of possible modalities beyond graspable interfaces, (2) give insights on manual peripheral interaction in general and the respective modalities in particular and (3) elaborate on paper based prototypes for the evaluation of peripheral interaction...|$|R
40|$|The present volume {{contains}} {{the proceedings of}} the First <b>International</b> Workshop on <b>Graphical</b> Models for Security (GraMSec' 14). The workshop was held in Grenoble, France, on April 12, 2014, as one of the satellite events of the European Joint Conferences on Theory and Practice of Software 2014 (ETAPS' 14). Graphical security models provide an intuitive but systematic methodology to analyze security weaknesses of systems and to evaluate potential protection measures. Such models have been subject of academic research and they have also been widely accepted by the industrial sector, as a means to support and facilitate threat analysis and risk management processes. The objective of GraMSec is to {{contribute to the development of}} well-founded graphical security models, efficient algorithms for their analysis, as well as methodologies for their practical usage. The workshop brings together academic researchers and industry practitioners designing and employing visual models for security in order to provide a platform for discussion, knowledge exchange and collaborations...|$|R
40|$|<b>International</b> audienceMotivation: <b>Graphical</b> {{models are}} often {{employed}} to interpret patterns of correlations observed in data through {{a network of}} interactions between the variables. Recently, Ising/Potts models, also known as Markov random fields, have been productively applied to diverse problems in biology, including the prediction of structural contacts from protein sequence data and the description of neural activity patterns. However, inference of such models is a challenging computational problem that cannot be solved exactly. Here, we describe the adaptive cluster expansion (ACE) method to quickly and accurately infer Ising or Potts models based on correlation data. ACE avoids overfitting by constructing a sparse network of interactions sufficient to reproduce the observed correlation data within the statistical error expected due to finite sampling. When convergence of the ACE algorithm is slow, we combine it with a Boltzmann Machine Learning algorithm (BML). We illustrate this method {{on a variety of}} biological and artificial datasets and compare it to state-of-the-art approximate methods such as Gaussian and pseudo-likelihood inference. Results: We show that ACE accurately reproduces the true parameters of the underlying model when they are known, and yields accurate statistical descriptions of both biological and artificial data. Models inferred by ACE more accurately describe the statistics of the data, including both the constrained low-order correlations and unconstrained higher-order correlations, compared to those obtained by faster Gaussian and pseudo-likelihood methods. These alternative approaches can recover the structure of the interaction network but typically not the correct strength of interactions, resulting in less accurate generative models...|$|R
40|$|<b>International</b> audienceRulings are <b>graphical</b> {{primitives}} {{that are}} essential for document structure recognition. However {{in the case of}} ancient documents, bad printing techniques or bad conditions of conservation induce problems for their recognition. Consequently, usual line segment extractors are not powerful enough to properly extract all the rulings of a heterogeneous document. In this paper, we propose a new method for ruling recognition, based on perceptive vision: we show that combining several levels of vision improves ruling recognition. Thus, it is possible to put forward hypothesis {{on the nature of the}} rulings at a given resolution, and to confirm or infirm their presence and find their exact position at higher resolutions. We propose an original strategy of cooperation between resolutions and present tools to set up a correspondence between the elements extracted at each resolution. We validate this approach on images of ancient newspaper pages (dated between 1848 and 1944). At last, we propose to use the extracted rulings for the structure analysis of newspaper pages. We show that using more reliable extracted rulings simplifies and improves document structure recognition...|$|R
40|$|<b>International</b> audienceMost {{interactive}} <b>graphical</b> {{applications that}} use direct manip- ulation are built with low-level libraries such as Xlib because the graphic and interaction models of higher-level toolkits such as Motif are not extensible. This results in high de- sign, development and maintenance costs and encourages {{the development of}} stereotyped applications based on buttons, menus and dialogue boxes instead of direct manipulation of the applications objects. There have been several attempts to provide high level tools for building such applications, including popular toolkits such as Garnet [26], Unidraw [33], Fresco [21, 32] and Open- Inventor [28]. Unfortunately, these tools are not adapted {{to the development of}} sophisticated graphical editors because of their lack of extensibility: In this article we argue that these drawbacks come from the fact that high-level toolkits rely on a visualization model to manage interaction. We introduce a model that uses several graphical layers to separate the graphic entities involved in visualization from those involved in feedback and interaction management. We describe the implementation of this Multi- Layer Model and we show how it can take advantage of soft- ware and hardware graphic extensions to provide good per- formance. We also show how it supports multiple input de- vices and simplifies the description {{of a wide variety of}} in- teraction styles. Finally, we describe our experience in using this model to implement a set of editors for a professional an- imation system...|$|R
40|$|<b>International</b> audienceVPloop, the <b>graphical</b> {{representation}} of pressure versus velocity, and its characteristic angles, GALA and β, {{can be used}} to monitor cardiac afterload during anesthesia. Ideally VPloop should be measured from pressure and velocity obtained at the same arterial location but standard of care usually provide either radial or femoral pressure waveforms. The {{purpose of this study was}} to look at the influence of arterial sites and the use of a transfer function (TF) on VPloop and its related angles. Invasive pressure signals were recorded in 25 patients undergoing neuroradiology intervention under general anesthesia with transesophageal flow velocity monitoring. Pressures were recorded in the descending thoracic aorta, abdominal aorta, femoral and radial arteries. We compared GALA and β from VPloops generated from each location and in high and low risk patients. GALA was similar in the central locations (55 °[49 – 63], 52 °[47 – 61] and 54 °[45 – 62] from descending thoracic to femoral artery, median[interquartile], p[*]=[*] 0. 10), while there was a difference in β angle (16 °[4 – 27] to 8 °[3 – 15], p[*]<[*] 0. 0001). GALA and β obtained from radial waveforms were different (39 °[31 – 47] compared to 46 °[36 – 54] and 6 °[2 – 14] compared to 16 °[4 – 27] for GALA and β angles respectively, p[*]<[*] 0. 001) which was corrected by the use of a TF (45 °[32 – 55] and 17 °[5 – 28], p[*]=[*]ns). GALA and β are underestimated when measured with a radial catheter. Using pressure waveforms from femoral locations alters VPloops, GALA and β in a smaller extend. The use of a TF on radial pressure allows to correctly plot VPloops and their characteristic angles for routine clinical use...|$|R
