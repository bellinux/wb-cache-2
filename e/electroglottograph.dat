40|2|Public
5000|$|... #Caption: <b>Electroglottograph,</b> Glottal Enterprises model EG2-PCX shown here.|$|E
5000|$|... #Caption: Photograph of an EGG {{signal from}} a Glottal Enterprises EG2-PC (top) and a Laryngograph/Kay <b>electroglottograph</b> (bottom).|$|E
50|$|<b>Electroglottograph</b> signals {{have also}} been used in {{stroboscope}} synchronization, voice fundamental frequency tracking, tracking vocal fold abductory movements {{and the study of}} the singing voice.|$|E
5000|$|... #Caption: Showing the {{contacts}} on the electrodes from a Glottal Enterprises EG2-PCX. Electrodes for other <b>electroglottographs</b> are typically very similar {{in size and}} shape. This set of electrodes is from a Glottal Enterprises EG2-PCX, which is a dual-channel EGG, so it has 2 sets of contacts. Electrode jelly is used to help conduct the signal from {{the contacts}} to the neck.|$|R
40|$|There are {{numerous}} models of varying complexities which seek to efficiently represent the voice source signal. These models are typi-cally {{based on data}} and observations which can come from air-flow masks, <b>electroglottographs,</b> mechanical systems, and the inverse-filtering of speech signals. The {{first part of this}} study examines ob-servations from the high-speed imaging of the larynx and proposes a new source model, which is shown to provide a better fit for the ob-served data than existing models. The proposed source model is then used in an automatic source estimation application, based on meth-ods introduced in an earlier study [1]. Results, on average, show that the proposed model provides a more accurate estimation of the source signal compared with the Liljencrants-Fant model. Index Terms — source estimation, voice source, speech analysis 1...|$|R
50|$|The <b>electroglottograph,</b> or EGG, (also {{referred}} to as a laryngograph) is a device used for the noninvasive measurement of the degree of contact between the vibrating vocal folds during voice production. Though it is difficult to verify the assumption precisely, the aspect of contact being measured by a typical EGG unit is considered to be the vocal fold contact area (VFCA). To measure VFCA, an electrodes are applied {{on the surface of the}} neck so that the EGG records variations in the transverse electrical impedance of the larynx and nearby tissues by means of a small A/C electric current (in megaHertz). This electrical impedance will vary slightly with the area of contact between the moist vocal folds during the setment of the glottal vibratory cycle in which the folds are in contact. However, because the percentage variation in the neck impedance caused by vocal fold contact can be extremely small and varies considerably between subjects, no absolute measure of contact area is obtained, only the pattern of variation for a given subject.|$|E
40|$|The study {{presents}} experimental {{investigations of}} non-linear vibration effects, particularly bifurcation phenomena in the vibrations of human vocal folds. The vocal fold vibrations were excited by airflow and the microphone, the pressure transducers, an <b>electroglottograph</b> and the laser vibrometer registered the phonation and vibration of the vocal folds. Furthermore the vocal fold oscillations were observed optically by strobovideoscopy and videokymography. Bifurcations in the vocal fold vibrations were observed when smoothly changing {{the tension of}} the vocal folds. 1...|$|E
40|$|It has {{previously}} shown {{that there is}} a clear duration difference between the long and short stop series in Bininj Gun-Wok, a language spoken in Northern Australia. Previously these have been phonologically labeled lenis and fortis. This investigation looks at some non-durational phonetic correlates of the contrast between lenis and fortis consonants. H 1 -H 2, H 1 -A 2 and H 1 -A 3 measurements were made using acoustic recordings and the closed quotient (CQ) was measured using an <b>electroglottograph.</b> Voice quality was not found to be a consistent cue to a contrast...|$|E
40|$|The highest ''register'' of {{the female}} singing voice, often called the ''flageolet register'' (also called ''flute register,'' ''bell register,'' etc., {{as well as the}} {{misleading}} term ''whistle register''), is broadly recognized by voice pedagogues, but not generally defined in terms that are adequate for objective description. This article presents a description of characteristic patterns of vocal fold movement and of vocal tract formants that are specific for the register. Measurements are made by <b>electroglottograph,</b> pharyngeally placed wide-band pressure transducers, and an external microphone in professional soprano subjects who are adept in using this register...|$|E
40|$|<b>Electroglottograph</b> and {{microphone}} {{signals are}} examined of scale passages crossing {{the boundary between}} chest and middle registers in the female singing voice. From a protocol executed by professional classical singers, the examples are selected to illustrate differing approaches to the chest-middle transition, {{as well as to}} illuminate varying theories on the female middle register, specifically the question of 'mixing' the primary registers, chest and falsetto. The results suggest that the skillful tuning of the resonances of the vocal tract contributes more toward the pedagogical goal of smoothing the register transition than does a presumed mixing of the registers at the glottal source...|$|E
30|$|To achieve robust speaker verification, {{we propose}} a {{multimodal}} method which includes additional nonaudio features and glottal activity detector. As a nonaudio sensor an <b>electroglottograph</b> (EGG) is applied. Parameters of EGG signal {{are used to}} augment conventional audio feature vector. Algorithm for EGG parameterization {{is based on the}} shape of the idealized waveform and glottal activity detector. We compare our algorithm with conventional one in the term of verification accuracy in high noise environment. All experiments are performed using Gaussian Mixture Model recognition system. Obtained results show a significant improvement of the text-independent speaker verification in high noise environment and opportunity for further improvements in this area.|$|E
40|$|Two {{studies are}} presented, in which {{emotional}} vocal recordings were made {{using a computer}} emotion induction task and an imagination technique. Concurrent recordings were made {{of a variety of}} physiological parameters, including <b>electroglottograph,</b> respiration, electrocardiogram, and surface electromyogram (muscle tension). Acoustic parameters pertaining to voice quality, including F 0 floor, F 0 range, jitter and spectral energy distribution were analysed and compared to the physiological parameters. The range of parameters was also statistically compared across different emotions. Although methodological problems still hamper such research, the combined analysis of physiological and acoustic parameters across emotional speaker states promises a clearer interpretation of the effects of emotion on voice quality. 1...|$|E
40|$|Speech pitch {{detection}} {{remains a}} fundamental problem due to importance in numerous aspects of speech processing. Current pitch detectors focus on determining the Glottal Closure Instant (GCI). Accurate GCI measures {{can be obtained}} from the Differentiated <b>Electroglottograph</b> (DEGG) signal. Unfortunately, DEGG signals are not available in most practical applications. A novel method of pitch detection is proposed here based on the nonlinear estimation of DEGG signals from the acoustic speech waveform. This method requires the DEGG signals only during optimization. In operation, the proposed pitch detector marks glottal closures based strictly on the acoustical speech waveform. In addition to the algorithm development, performance comparison results are presented...|$|E
40|$|A {{portable}} helmet based {{system has}} been developed to capture motor behavior during singing and other oral-motor functions in a non-laboratory experimental environment. The system, based on vocal tract sensing methods developed for speech production and recognition, consists of a lightweight “hyper-helmet” containing an ultrasonic (US) transducer to capture tongue movement, a video camera for the lips, and a microphone, coupled with a further sensor suite including an <b>electroglottograph</b> (EGG), nose-mounted accelerometer, and respiration sensor. The {{system has been}} tested on two rare, endangered singing musical styles, Corsican “Cantu in Paghjella”, and Byzantine hymns from Mount Athos, Greece. The versatility of the approach is furthermore demonstrated by capturing a contemporary singing style known as “Human Beat Box. ...|$|E
40|$|An {{examination}} of the historical treatises of Manuel Garcia II and Giambattista Mancini, scientific studies pertaining to glottal closure, and Vocal Function Exercises used in clinical speech pathology led to an exploratory study that attempted to increase the glottal closure in an untrained university male chorus using only choral voice building exercises. The exploratory study used a single group, pre-test post-test design, and data was recorded using audio recordings of the entire chorus as well as <b>electroglottograph</b> measurements of individual subjects. The data show an increase in glottal closure as measured by closed quotient values, {{and an increase in}} energy in the upper partials of the recorded acoustic signal from the chorus...|$|E
40|$|International audienceA {{portable}} helmet based {{system has}} been developed to capture motor behavior during singing and other oral-motor functions in a non-laboratory experimental environment. The system, based on vocal tract sensing methods developed for speech production and recognition, consists of a lightweight " hyper-helmet " containing an ultrasonic (US) transducer to capture tongue movement, a video camera for the lips, and a microphone, coupled with a further sensor suite including an <b>electroglottograph</b> (EGG), nose-mounted accelerometer, and respiration sensor. The {{system has been}} tested on two rare, endangered singing musical styles, Corsican " Cantu in Paghjella ", and Byzantine hymns from Mount Athos, Greece. The versatility of the approach is furthermore demonstrated by capturing a contemporary singing style known as " Human Beat Box. ...|$|E
30|$|It is {{possible}} to accomplish robustness by the utilization of other sensing modalities to complement the audio signal of speech. As a matter of fact, in almost every context, carefully designed multimodal interfaces {{turned out to be}} more beneficial than any single-modality interface [1, 22]. Some multimodal approaches are based on sensors where a speaker is not connected to a recording device, like GEMS, ultrasonic or video signal [23 – 25]. Other researches use sensors physically connected to the speaker's head, face or throat, like <b>electroglottograph</b> (EGG), P-microphone, bone-conducting microphone [22, 24, 26]. The practical application of physically connected sensors is in specific environment (military approach, battle field environment, etc.) as well as in situations where the user is willing to cooperate meaning amenable to attach the sensor on herself/himself.|$|E
40|$|Many nonacoustic sensors are now {{available}} to augment user authentication. Devices such as the GEMS (glottal electromagnetic micro-power sensor), the EGG (<b>electroglottograph),</b> and the P-mic (physiological mic) all have distinct methods of measuring physical processes associated with speech production. A potential exciting aspect of the application of these sensors {{is that they are}} less influenced by acoustic noise than a microphone. A drawback of having many sensors available is the need to develop features and classification technologies appropriate to each sensor. We therefore learn feature extraction based on data. State of the art classification with Gaussian Mixture Models and Support Vector Machines is then applied for multimodal authentication. We apply our techniques to two databases—the Lawrence Livermore GEMS corpus and the DARPA Advanced Speech Encoding Pilot corpus. We show the potential of nonacoustic sensors to increase authentication accuracy in realistic situations. 1...|$|E
40|$|In pitch {{synchronous}} {{speech synthesis}} the analysis/synthesis {{of the speech}} is done at each glottal closure instant (GCI). The errors in estimation of GCI's {{affect the quality of}} the synthesized speech. The effect of random perturbations in the GCI's, obtained from the speech and from glottal signal from an impedance <b>electroglottograph</b> using Childers and Hu's algorithm on the quality of speech synthesized using harmonic plus noise model (HNM), is investigated in this paper. Investigations show that the speech quality is very sensitive to positions of the GCI's. A small perturbation with maximum of 4 % of the local fundamental frequency considerably degrades the synthesized speech. Perturbations above 8 % severely affect quality of the out put speech. GCI's obtained from the glottal signal can afford slightly more perturbation as compared to the GCI's calculated from the speech signal...|$|E
40|$|The {{computational}} model uses temporal decomposition to approximate multi-channel trajectories and yield {{a set of}} target functions and vectors. Temporal decomposition constructs multiple-channel trajectories from data-derived target functions using a form of adaptive Gauss-Seidel iteration. The resultant target functions, {{in conjunction with the}} weights for each basis function, are then used to derive the articulatory-phonetic representation [...] gestural scores for the CVC syllables embedded in the frame sentences. The voicing information is derived from the simultaneously recorded <b>electroglottograph</b> data. This method is applied to the task of estimating the gestural score for various CVC syllables in a stimulus set. To evaluate the adequacy of the derived gestural scores two evaluations were performed: a perception test, and a classification test using an automatic recognizer based on a neural network model. High recognition rates from both the perceptual experiments and the automatic...|$|E
40|$|International audienceThis paper {{deals with}} new {{capturing}} technologies to safeguard and transmit endangered {{intangible cultural heritage}} including Corsican multipart singing technique. The described work, part of the European FP 7 i-Treasures project, aims at increasing our knowledge on rare singing techniques. This paper includes (i) a presentation of our light hyper-helmet with 5 non-invasive sensors (microphone, camera, ultrasound sensor, piezoelectric sensor, <b>electroglottograph),</b> (ii) the data acquisition process and software modules for visualization and data analysis, (iii) a case study on acoustic analysis of voice quality for the UNESCO labelled traditional Cantu in Paghjella. We could identify specific features for this singing style, such as changes in vocal quality, especially concerning the energy in the speaking and singing formant frequency region, a nasal vibration that seems to occur during singing, as well as laryngeal mechanism characteristics. These capturing and analysis technologies will contribute to define relevant features for a future educational platform...|$|E
40|$|Pitch {{perturbation}} is {{a measure}} of the cycle-to-cycle variation in vocal fold vibration. Perturbation can be assessed by means of electroglottographic or acoustic signals. The purpose of this study was to determine if these two analysis techniques are equiv-alent measures. TheLaryngograph, an <b>electroglottograph,</b> and the Visi-Pltch, an acous-tic analyzer, were used to measure pitch perturbation in 80 dysphonic SUbjects. Both instruments use Koike's formula to calculate relative average perturbation. While intra-subject variability appeared erratic, statistical analysis of Intersubject data indicated that the two instruments provided an equivalent measure of pitch perturbation. (OTO-LARYNGOL HEAD NECK SURG 1992; 107 : 617.) Pitch perturbation is an objective measure of vocal hoarseness and refers to fluctuations in the period of each cycle of vocal fold vibration. I Vocal folds in a healthy larynx vibrate in a periodic manner and produce minimal pitch perturbation; alterations in vocal fold mass or tension may produce increased aperiodicity o...|$|E
40|$|Copyright © 2010 Zoran Ćirović et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. To achieve robust speaker verification, we propose a multimodal method which includes additional nonaudio features and glottal activity detector. As a nonaudio sensor an <b>electroglottograph</b> (EGG) is applied. Parameters of EGG signal are used to augment conventional audio feature vector. Algorithm for EGG parameterization {{is based on the}} shape of the idealized waveform and glottal activity detector. We compare our algorithm with conventional one in the term of verification accuracy in high noise environment. All experiments are performed using Gaussian Mixture Model recognition system. Obtained results show a significant improvement of the text-independent speaker verification in high noise environment and opportunity for further improvements in this area. 1...|$|E
40|$|Sustained high notes, {{diminishing}} gradually {{from the}} loudest to the softest phonation within a maneuver called messa di voce, are examined in two contrasting professional tenor voices. Signals {{of the sound}} pressure level, <b>electroglottograph,</b> and mean esophageal pressure are recorded, and similar maneuvers by the same subjects are examined stroboscopically. The lyric voice is found to make a gradual diminuendo while maintaining nearly constant posture of the vocal tract together with a phase of complete closure in the glottal cycle. The robust voice, by contrast, passes abruptly from a production of high subglottal pressure and a high closed quotient to one of low pressure and incomplete closure, and the transition {{is marked by a}} sudden opening of the previously constricted laryngeal collar. It is proposed that the mode of soft voice production demonstrated by the robust voice be recognized as a distinct register of the singing voice...|$|E
40|$|Nonacoustic sensors such as {{the general}} {{electromagnetic}} motion sensor (GEMS), the physiological microphone (P-mic), and the <b>electroglottograph</b> (EGG) offer multimodal approaches to speech processing and speaker and speech recognition. These sensors provide measurements of functions of the glottal excitation and, more generally, of the vocal tract articulator movements that are relatively immune to acoustic disturbances and can supplement the acoustic speech waveform. This paper describes an approach to speech enhancement that exploits these nonacoustic sensors according to their capability in representing specific speech characteristics in different frequency bands. Frequency-domain sensor phase, as well as magnitude, is found to contribute to signal enhancement. Preliminary testing involves the time-synchronous multi-sensor DARPA Advanced Speech Encoding Pilot Speech Corpus collected {{in a variety of}} harsh acoustic noise environments. The enhancement approach is illustrated with examples that indicate its applicability as a pre-processor to low-rate vocoding and speaker authentication, and for enhanced listening from degraded speech. 1...|$|E
40|$|There {{has been}} {{consistent}} interest among speech signal processing {{researchers in the}} accurate estimation of the fundamental frequency (F(0)) of speech signals. This study examines ten F(0) estimation algorithms (some well-established and some proposed more recently) to determine which of these algorithms is, on average, better able to estimate F(0) in the sustained vowel /a/. Moreover, a robust method for adaptively weighting the estimates of individual F(0) estimation algorithms based on quality and performance measures is proposed, using an adaptive Kalman filter (KF) framework. The accuracy of the algorithms is validated using (a) a database of 117 synthetic realistic phonations obtained using a sophisticated physiological model of speech production and (b) a database of 65 recordings of human phonations where the glottal cycles are calculated from <b>electroglottograph</b> signals. On average, the sawtooth waveform inspired pitch estimator and the nearly defect-free algorithms provided the best individual F(0) estimates, and the proposed KF approach resulted in a ∼ 16 % improvement in accuracy over the best single F(0) estimation algorithm. These findings {{may be useful in}} speech signal processing applications where sustained vowels are used to assess vocal quality, when very accurate F(0) estimation is required...|$|E
40|$|Phonation {{threshold}} pressure (PTP) {{is frequently}} used for characterizing vocal fold vibration properties. However, {{because of the}} very low pressures, {{it is often difficult}} to measure PTP with acceptable accuracy. This investigation analyses an alternative pressure, the collision threshold pressure (CTP), defined as the lowest pressure required to initiate vocal fold collision. Fourteen amateur singers – six female and eight male – served as subjects. They were recorded while repeating the syllable /pa: / with a gradually decreasing degree of vocal loudness. Several pitches were recorded before and after vocal warm-up by means of an audio microphone, an <b>electroglottograph</b> (EGG) and a pressure transducer, which the subjects held in the corner of their mouths and which hence reflected oral pressure. The amplitude of an EGG signal increases substantially when the vocal folds make contact, i. e., collide, thus allowing simple measurement of the CTP. The oral pressure during the p-occlusion was used as for estimating subglottal pressure. CTP and PTP tended to be higher before than after the warm-up, although the differences varied greatly both between given subject’s pitches and between subjects. Repeated measurements on two subjects showed lower standard deviations for CTP than for PTP. The results support the conclusion that CTP is a promising parameter in investigations of vocal fold characteristics...|$|E
40|$|Phonation {{threshold}} pressures (PTP) {{have been}} commonly used for obtaining a quantitative measure of vocal fold motility. However, as {{these measures are}} quite low, it is typically difficult to obtain reliable data. As the amplitude of an <b>electroglottograph</b> (EGG) signal decreases substantially {{at the loss of}} vocal fold contact, it is mostly easy to determine the collision threshold pressure (CTP) from an EGG signal. In an earlier investigation (Enflo & Sundberg, forthcoming) we measured CTP and compared it with PTP in singer subjects. Results showed that in these subjects CTP was on average about 4 cm H 2 O higher than PTP. The PTP has been found to increase during vocal fatigue. In the present study we compare PTP and CTP before and after vocal loading in singer and non-singer voices, applying a loading procedure previously used by co-author FP. Seven subjects repeated the vowel sequence /a,e,i,o,u / at an SPL of at least 80 dB @ 0. 3 m for 20 min. Before and after the loading the subjects ’ voices were recorded while they produced a diminuendo repeating the syllable /pa/. Oral pressure during the /p / occlusion was used as a measure of subglottal pressure. Both CTP and PTP increased significantly after the vocal loading...|$|E
40|$|Résumé long de la {{communication}} visible au lien suivant: [URL] audienceThe i-Treasures project, which officially began on 1 February 2013, is a 12 -partner FP 7 project that proposes to use multi- sensor technology to capture, preserve, and transmit {{four types of}} intangible cultural heritage, referred to as 'use cases': rare traditional songs, rare dance interactions, traditional craftsmanship and contemporary music composition. Methodologies used will include body and gesture recognition, vocal tract modeling, speech processing and electroencephalography (EEG). The "Rare traditional songs" use case, {{which will be the}} focus of our work, targets Corsican "cantu in Paghjella", Sardinian "Canto a tenore", Mt. Athos Greek byzantine hymns and the recent "Human beat box" styles. The final objective of the "Rare traditional songs" use case is to capture vocal tract movements with sufficient accuracy to drive a real-time 2 D or 3 D avatar of the vocal tract, which will in turn {{play a crucial role in}} the transmitting of captured invisible cultural heritage to future generations. The acquisition sensors are: multi-sensor helmet, nose-mounted accelerometer, camera, ultrasound probe, <b>Electroglottograph,</b> Microphone and breathing belt. This system is described in this study, and also the vocal tract modeling, the preliminary data processing, and the extracting tongue contour method...|$|E
40|$|The {{purpose of}} this study was to examine the phonatory {{characteristics}} of pig, sheep, and cow excised larynges and to find out which of these animal species is the best model for human phonation. Excised pig, sheep, and cow larynges were prepared and mounted over a tapered tube on the excised bench that supplied pressurized, heated, and humidified air in a manner similar to that for excised canine models. Each excised larynx was subjected to a series of pressure-flow experiments with adduction as major control parameter. The subglottal pressure, <b>electroglottograph</b> (EGG), mean flow rate, audio signal, and sound pressure level were recorded during each experiment. EGG signal was used to extract the fundamental frequency. It was found that pressure-frequency relations were nonlinear for these species with large rate of frequency changes for the pig. The average oscillation frequencies for these species were 220 ± 57 Hz for the pig, 102 ± 33 Hz for the sheep, and 73 ± 10 Hz for the cow. The average phonation threshold pressure for the pig was 7. 4 ± 2. 0 cm H 2 O, 6. 9 ± 2. 9 cm H 2 O for the sheep, and 4. 4 ± 2. 3 cm H 2 O for the cow...|$|E
40|$|Glottal-synchronous speech {{processing}} {{is a field}} of speech science where the pseudoperiodicity of voiced speech is exploited. Traditionally, {{speech processing}} involves segmenting and processing short speech frames of predefined length; this may fail to exploit the inherent periodic structure of voiced speech which glottal-synchronous speech frames {{have the potential to}} harness. Glottal-synchronous frames are often derived from the glottal closure instants (GCIs) and glottal opening instants (GOIs). The SIGMA algorithm was developed for the detection of GCIs and GOIs from the <b>Electroglottograph</b> signal with a measured accuracy of up to 99. 59 %. For GCI and GOI detection from speech signals, the YAGA algorithm provides a measured accuracy of up to 99. 84 %. Multichannel speech-based approaches are shown to be more robust to reverberation than single-channel algorithms. The GCIs are applied to real-world applications including speech dereverberation, where SNR is improved by up to 5 dB, and to prosodic manipulation where the importance of voicing detection in glottal-synchronous algorithms is demonstrated by subjective testing. The GCIs are further exploited in a new area of data-driven speech modelling, providing new insights into speech production and a set of tools to aid deployment into real-world applications. The technique is shown to be applicable in areas of speech coding, identification and artificial bandwidth extension of telephone speechEThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|Abstract—Accurate {{estimation}} of glottal closing instants (GCIs) and opening instants (GOIs) {{is important for}} speech processing applications that benefit from glottal-synchronous processing including pitch tracking, prosodic speech modification, speech dereverberation, synthesis and study of pathological voice. We propose the YAGA algorithm to detect GCIs from speech signals by employing multiscale analysis, the group delay function and N-best dynamic programming. A novel GOI detector based upon {{the consistency of the}} candidates ’ closed quotients relative to the estimated GCIs is also presented. Particular attention is paid to the precise definition of the glottal closed phase, which we define as the analysis interval that produces minimum deviation from an all-pole model of the speech signal with closed-phase linear prediction (LP). A reference algorithm analyzing both EGG and speech signals is described for evaluation of the proposed speech-based algorithm. In addition {{to the development of a}} GCI/GOI detector, an important outcome of this work is in demonstrating that GOIs derived from the EGG signal are not necessarily well-suited to closed-phase LP analysis. Evaluation of YAGA against the APLAWD and SAM databases show that GCI identification rates of up to 99. 3 % can be achieved with an accuracy of 0. 3 ms and GOI detection can be achieved equally reliably with an accuracy of 0. 5 ms. Index Terms—Speech processing, glottal closing instants, glot-tal opening instants, <b>electroglottograph,</b> group delay function, multiscale analysis, dynamic programming. I...|$|E
40|$|Accurate {{estimation}} of glottal closure instants (GCIs) in voiced speech {{is important for}} speech analysis applications which benefit from glottal-synchronous processing. <b>Electroglottograph</b> (EGG) recordings give {{a measure of the}} electrical conductance of the glottis, providing a signal which is proportional to its contact area. EGG signals contain little noise or distortion, providing a good reference from which GCIs can be extracted to evaluate GCI estimation from speech recordings. Many approaches impose a threshold on the differentiated EGG signal which provide accurate results during voiced speech but are prone to errors at the onset and end of voicing; modern algorithms use a similar approach across multiple dyadic scales using the stationary wavelet transform. This paper describes a new method for EGG-based GCI estimation named SIGMA, which is based upon the stationary wavelet transform, peak detection with a group delay function and Gaussian Mixture Modelling for discrimination between true and false GCI candidates. In most real-world environments, it is necessary to estimate GCIs from a speech signal recorded with a microphone placed at some distance from the talker. The presence of reverberation, noise and filtering by the vocal tract render GCI detection from real speech signals relatively difficult to achieve compared with the EGG, so EGG-based references have often been used to evaluate GCI detection from speech signals. Evaluation against 500 handlabelled sentences has shown an accuracy of 99. 35 %, a 4. 7 % improvement over a popular existing method. 1...|$|E
40|$|SummaryObjectiveElectroglottography (EGG) is {{a widely}} used noninvasive method that purports to measure changes in {{relative}} vocal fold contact area (VFCA) during phonation. Despite its broad application, the putative direct relation between the EGG waveform and VFCA has to date only been formally tested in a single study, suggesting an approximately linear relationship. However, in that study, flow-induced vocal fold (VF) vibration was not investigated. A rigorous empirical evaluation of EGG {{as a measure of}} VFCA under proper physiological conditions is therefore still needed. Methods/designThree red deer larynges were phonated in an excised hemilarynx preparation using a conducting glass plate. The time-varying contact between the VF and the glass plate was assessed by high-speed video recordings at 6000 fps, synchronized to the EGG signal. ResultsThe average differences between the normalized [0, 1] VFCA and EGG waveforms for the three larynges were 0. 180 (± 0. 156), 0. 075 (± 0. 115), and 0. 168 (± 0. 184) in the contacting phase and 0. 159 (± 0. 112), − 0. 003 (± 0. 029), and 0. 004 (± 0. 032) in the decontacting phase. Discussions and conclusionsOverall, there was a better agreement between VFCA and the EGG waveform in the decontacting phase than in the contacting phase. Disagreements may be caused by nonuniform tissue conductance properties, electrode placement, and <b>electroglottograph</b> hardware circuitry. Pending further research, the EGG waveform may be a reasonable first approximation to change in medial contact area between the VFs during phonation. However, any quantitative and statistical data derived from EGG should be interpreted cautiously, allowing for potential deviations from true VFCA...|$|E
40|$|Physical {{modeling}} using digital waveguide mesh (DWM) {{models is}} an audio synthesis method {{that has been}} shown to produce an acoustic output in music synthesis applications that is often described as being “organic,” “warm,” or “intimate. ” This paper describes work that takes its inspiration from physical modeling music synthesis and applies it to speech synthesis through a physical modeling mesh model of the human oral tract. Oral tract shapes are found using a computational technique based on the principles of biological evolution. Essential to successful speech synthesis using this method is accurate measurements of the cross-sectional area of the human oral tract, and these are usually derived from magnetic resonance imaging (MRI). However, such images are nonideal, because of the lengthy exposure time (relative to the time of articulation of speech sounds) required, the local ambient acoustic noise associated with the MRI machine itself and the required supine position for the subject. An alternative method is described where a bio-inspired computing technique that simulates the process of evolution is used to evolve oral tract shapes. This technique is able to produce appropriate oral tract shapes for open vowels using acoustic and excitation data from two adult males and two adult females, but shapes for close vowels that are less appropriate. This technique has none of the drawbacks associated with MRI, because all it requires from the subject is an acoustic and electrolaryngograph (or <b>electroglottograph)</b> recording. Appropriate oral tract shapes do enable the model to produce excellent quality synthetic speech for vowel sounds, and sounds that involve dynamic oral tract shape changes, such as diphthongs, can also be synthesized using an impedance mapped technique. Efforts to improve performance by reducing mesh quantization for close vowels had little effect, and further work is required...|$|E
40|$|Abstract—In this paper, {{we present}} a time domain aperiodicity, periodicity, and pitch (APP) {{detector}} that estimates 1) the proportion of periodic and aperiodic energy in a speech signal and 2) the pitch period of the periodic component. The APP system is particularly useful in situations where the speech signal contains simultaneous periodic and aperiodic energy, {{as in the case}} of breathy vowels and some voiced obstruents. The performance of the APP system was evaluated on synthetic speech-like signals corrupted with noise at various levels of signal-to-noise ratio (SNR) and on three different natural speech databases that consist of simultaneously recorded <b>electroglottograph</b> (EGG) and acoustic data. When compared on a frame basis (at a frame rate of 2. 5 ms) the results show excellent agreement between the periodic/aperiodic decisions made by the APP system and the estimates obtained from the EGG data (94. 43 % for periodicity and 96. 32 % for aperiodicity). The results also support previous studies that show that voiced obstruents are frequently manifested with either little or no aperiodic energy, or with strong periodic and aperiodic components. The EGG data were used as a reference for evaluating the pitch detection algorithm. The ground truth was not manually checked to rectify or exclude incorrect estimates. The overall gross error rate in pitch prediction across the three speech databases was 5. 67 %. In the case of synthetic speech-like data, the estimated SNR was found to be in close proportion to the actual SNR, and the pitch was always accurately found regardless of the presence of any shimmer or jitter. Index Terms—Aperiodic and periodic energy, average magnitude difference function (AMDF), pitch detection, speech preprocessing, voiced obstruents, voice quality. I...|$|E
