242|1746|Public
60|$|It is {{well enough}} known, {{that the best}} {{productions}} of the best human intellects, are generally regarded by those intellects as mere immature freshman exercises, wholly worthless in themselves, except as initiatives for entering the great University of God after death. Certain it is, that if any inferences {{can be drawn from}} observations of the familiar lives of men of the greatest mark, their finest things, those which become the foolish glory of the world, are not only very poor and inconsiderable to themselves, but often positively distasteful; they would rather not have the book in the room. In minds comparatively inferior as compared with the above, these surmising considerations so sadden and unfit, that they become careless of what they write; go to their desks with discontent, and only remain there--victims to headache, and pain in the back--by the <b>hard</b> <b>constraint</b> of some social necessity. Equally paltry and despicable to them, are the works thus composed; born of unwillingness and the bill of the baker; the rickety offspring of a parent, careless of life herself, and reckless of the germ-life she contains. Let not the short-sighted world for a moment imagine, that any vanity lurks in such minds; only hired to appear on the stage, not voluntarily claiming the public attention; their utmost life-redness and glow is but rouge, washed off in private with bitterest tears; their laugh only rings because it is hollow; and the answering laugh is no laughter to them.|$|E
50|$|Hard {{constraints}} typically {{include a}} specification of shifts (e.g. morning, afternoon, and night), that each nurse should work {{no more than}} one shift per day, and that all patients should have nursing coverage. Differences in qualifications between nurses also create hard constraints. Soft constraints may include minimum and maximum numbers of shifts assigned to a given nurse in a given week, of hours worked per week, of days worked consecutively, of days off consecutively, and so on. The shift preferences of individual nurses may be treated as a soft constraint, or as a <b>hard</b> <b>constraint.</b>|$|E
30|$|The {{first thing}} to notice is that the relaxed {{constraint}} Tr[YQ] <Tr[X] imposes the same restriction in (1.26) as does the <b>hard</b> <b>constraint</b> Tr[YQ] = Tr[X] since, if Tr[YQ] < Tr[X], we may replace Q by (Tr[X]/Tr[YQ])Q so that the <b>hard</b> <b>constraint</b> is satisfied. Thus we may replace the relaxed constraint in (1.26) by the <b>hard</b> <b>constraint</b> without affecting the function D_D(X||Y). This will be convenient in the lemma, though elsewhere the relaxed constraint will be essential.|$|E
30|$|The {{soft and}} <b>hard</b> <b>constraints</b> {{can then be}} pooled in {{different}} matrices, splitting the original matrix M into separate matrices. Let M_soft only contain soft constraints and M_hard only contain <b>hard</b> <b>constraints.</b> The vector c is split into c_soft and c_hard accordingly.|$|R
40|$|The {{university}} course timetabling {{is the problem}} of assigning a set of lectures to rooms and timeslots (periods) satisfying a number of constraints. The set of constraints are usually divided in two groups: <b>hard</b> <b>constraints</b> and soft <b>constraints.</b> Violations of <b>hard</b> <b>constraints</b> make the assignment infeasible while violations of sof...|$|R
40|$|Wireless sensor {{networks}} {{have emerged as}} a promising way to develop high security systems. This paper presents the optimizations of a space-based reconfigurable sensor network under <b>hard</b> <b>constraints</b> by employing an efficient multi-objective evolutionary algorithm (MOEA). First, a system model is proposed for cluster-based space wireless sensor networks. Second, the statement of multi-objective optimization problems is mathematically formulated under <b>hard</b> <b>constraints.</b> Third, the MOEA is used to find multi-criteria solutions {{in the sense of}} Pareto optimality. Finally, simulation results are provided to illustrate the effectiveness of applying the MOEA to the multi-objective evolutionary optimizations of a space-based reconfigurable sensor network under <b>hard</b> <b>constraints...</b>|$|R
40|$|In this paper, {{we propose}} a new {{combined}} message passing algorithm which allows belief propagation (BP) and mean filed (MF) applied on a same factor node, so that MF {{can be applied}} to <b>hard</b> <b>constraint</b> factors. Based on the proposed message passing algorithm, a iterative receiver is designed for MIMO-OFDM systems. Both BP and MF are exploited to deal with the <b>hard</b> <b>constraint</b> factor nodes involving the multiplication of channel coefficients and data symbols to reduce the complexity of the only BP used. The numerical results show that the BER performance of the proposed low complexity receiver closely approach that of the state-of-the-art receiver, where only BP is used to handled the <b>hard</b> <b>constraint</b> factors, in the high SNRs...|$|E
40|$|The {{curvature}} potential {{arising from}} confining a particle initially in three-dimensional space onto a curved surface is normally derived in the <b>hard</b> <b>constraint</b> q → 0 limit, with q {{the degree of}} freedom normal to the surface. In this work the <b>hard</b> <b>constraint</b> is relaxed, and eigenvalues and wave functions are numerically determined for a particle confined to a thin layer {{in the neighborhood of}} a toroidal surface. The <b>hard</b> <b>constraint</b> and finite layer (or soft constraint) quantities are comparable, but both differ markedly from those of the corresponding two dimensional system, indicating that the curvature potential continues to influence the dynamics when the particle is confined to a finite layer. This effect is potentially of consequence to the modelling of curved nanostructures. Comment: 4 pages, no fig...|$|E
30|$|Properties of {{the input}} {{data can be}} a <b>hard</b> <b>constraint</b> on U and V. For example, the product of two non-negative {{matrices}} will always be positive.|$|E
40|$|Abstract. Many {{real world}} {{problems}} can be modeled {{using a combination of}} <b>hard</b> and soft <b>constraints.</b> Markov Logic is a highly expressive language which represents the underlying constraints by attaching realvalued weights to formulas in first order logic. The weight of a formula represents the strength of the corresponding <b>constraint.</b> <b>Hard</b> <b>constraints</b> are represented as formulas with infinite weight. The theory is compiled into a ground Markov network over which probabilistic inference can be done. For many problems, <b>hard</b> <b>constraints</b> pose a significant challenge to the probabilistic inference engine. However, solving the <b>hard</b> <b>constraints</b> (partially or fully) before hand outside of the probabilistic engine can hugely simplify the ground Markov network and speed probabilistic inference. In this work, we propose a generalized arc consistency algorithm that prunes the domains of predicates by propagating <b>hard</b> <b>constraints.</b> Our algorithm effectively performs unit propagation at a lifted level, avoiding the need to explicitly ground the <b>hard</b> <b>constraints</b> during the pre-processing phase, yielding a potentially exponential savings in space and time. Our approach results in much simplified domains, thereby, making the inference significantly more efficient both in terms of time and memory. Experimental evaluation over one artificial and two real-world datasets show the benefit of our approach. ...|$|R
40|$|We {{conducted}} {{a study on the}} performance of genetic algorithm in designing institutional lecture time table, using empirical data of a college in a University. The study was focused on assessing the effectiveness of the algorithm given a number of <b>hard</b> <b>constraints</b> and a limited number of resources. The algorithm was implemented in C++. Several tests representing different scenarios were run and we found that genetic algorithm would always search for an optimum lecture allocation that satisfies the <b>hard</b> <b>constraints</b> in generating Institutional lecture time table. The algorithm can only reach the fitness of 1 when all the <b>hard</b> <b>constraints</b> have been satisfied. The fitness of the algorithm can be improved upon by the provision of adequate number and sufficient capacity of resources to carter for the <b>hard</b> <b>constraints.</b> We therefore, conclude that genetic algorithm works best in an environment where resources capacity and availability do not constitute some bottleneck...|$|R
40|$|Abstract. Motivated by the {{connection}} between strong and soft type systems we explore flow analyses with <b>hard</b> <b>constraints</b> on the admissible solutions. We show how to use observation predicates and formula rearrangements to map flow analyses with <b>hard</b> <b>constraints</b> into more traditional flow analyses {{in such a way}} that the <b>hard</b> <b>constraints</b> are satisfied exactly when the observation predicates report no violations. The development is carried out in a large fragment of a first order logic with negation and also takes care of the transformations necessary in order to adhere to the stratification restrictions inherent in Alternation-free Least Fixed Point Logic and similar formalisms such as Datalog. ...|$|R
30|$|Typically, a WSC {{problem is}} a Satisfiability (SAT) problem, such that the {{composition}} of Web services is considered as a process that creates new logic formula which can satisfy the target formula, known as goal. Verifying the satisfaction of composition with the constraints becomes a theoretical verification problem. Since the <b>hard</b> <b>constraint</b> is typically represented by a traditional form of logic, often as First-Order Logic [3], the verification of whether a WSC satisfies <b>hard</b> <b>constraint</b> or not can adopt a traditional approach, such as SAT solver, in the classic AI planning approach [4].|$|E
3000|$|... (t) as {{the true}} idle {{probability}} of channel n. Then, we apply the scheduling strategy in Prop. 1 (for the soft constraint case) or in Prop. 2 (for the <b>hard</b> <b>constraint</b> case).|$|E
40|$|We {{address the}} problem of energy {{efficient}} scheduling for the loss tolerant applications by exploiting the multiuser diversity. The proposed scheduling scheme allows dropping of a certain predefined proportion of data packets on the transmitter side. However, there is a <b>hard</b> <b>constraint</b> on the maximum number of successively dropped packets. The scheduler exploits average data loss tolerance to reduce the average system energy expenditure while fulfills the <b>hard</b> <b>constraint</b> on successively dropped packets. We analyze the scheme using asymptotically large user limit. The numerical results illustrate the energy efficiency of the scheme {{as a function of the}} average packet drop probability and the maximum permitted successively dropped packets parameters...|$|E
40|$|Abstract. We {{present a}} novel {{approach}} to deal with preferences expressed as a mixture of <b>hard</b> <b>constraints,</b> soft constraints, and CP nets. We construct a set of <b>hard</b> <b>constraints</b> whose solutions are the optimal solutions of the set of preferences. This allows us to avoid dominance testing (is one outcome better than another?) {{which is a very}} expensive operation often used when finding optimal solutions or testing optimality. We also show how <b>hard</b> <b>constraints</b> can eliminate cycles in the preference ordering. Finally, we extend this approach to deal with the preferences of multiple agents. This simple and elegant technique permits conventional constraint and SAT solvers to solve problems involving both preferences and constraints. ...|$|R
5000|$|... where [...] and [...] are {{constraints}} {{that are required}} to be satisfied; these are called <b>hard</b> <b>constraints.</b>|$|R
40|$|In this study, a multi {{objective}} programming {{model for}} nurse scheduling is developed. In this paper, {{we present a}} goal programming (GP) model that accommodates both <b>hard</b> and soft <b>constraints</b> for a monthly planning horizon. The <b>hard</b> <b>constraints</b> should be adhered to strictly, whereas the soft constraints can be violated when necessary. The relative importance values of the soft constraints have been computed by the analytical hierarchy process (AHP), which are used as coefficients of the deviations from the soft constraints in the objective function. goal programming, analytical hierarchy process, AHP, nurse scheduling, emergency departments, A&am, E, accident and emergency, <b>hard</b> <b>constraints,</b> soft constraints, healthcare management,...|$|R
3000|$|... where a is the set {{of input}} {{distributions}} which includes the sub-channel selection policy {{and the distribution of}} explicit symbols in X if the corresponding sub-channel is idle. We discuss the optimal input policy with soft constraint and <b>hard</b> <b>constraint</b> separately.|$|E
30|$|Characteristics of {{the data}} will either be a <b>hard</b> <b>{{constraint}}</b> or a soft constraint imposed as a regularization. In practice, hard constraints are computationally expensive, and regularization provides good interpretability. Sometimes, for very large matrices enforcing <b>hard</b> <b>constraint</b> might take days to weeks and would require running on distributed supercomputing clusters [24]. The importance of the regularization is always defined through positive regularization constants—the higher the value, the higher the importance. The preference among the conflicting soft constraints is expressed through {{the values of the}} corresponding regularization constant. There are scientific libraries such as mlrmbo [57] and hyperopt [58] that help domain scientists determine the values of these regularization constants based on a grid search, line search, random search, or Bayesian optimization techniques.|$|E
40|$|In {{this paper}} we {{investigate}} {{the advantages of}} using Case-Based Reasoning (CBR) to solve personnel rostering problems. Constraints for personnel rostering problems are commonly categorised as either `hard' or `soft'. Hard constraints are those which must be satisfied and a roster which violates none of these constraints {{is considered to be}} `feasible'. Soft constraints are more flexible and are often used to measure roster quality in terms of sta# satisfaction. We introduce a method for repairing <b>hard</b> <b>constraint</b> violations using CBR. CBR is an artificial intelligence paradigm whereby new problems are solved by considering the solutions to previous similar problems. We store a history of <b>hard</b> <b>constraint</b> violations and their corresponding repairs, which is captured from human rostering experts, and use this to solve similar violations in new rosters. The soft constraints are not defined explicitly. Their treatment is captured implicitly during the repair of <b>hard</b> <b>constraint</b> violations. The knowledge in the case-base is combined with tabu search concepts in a hybrid meta-heuristic algorithm. Experiments on real world data from a UK hospital are presented. The results show that CBR can guide a meta-heuristic algorithm towards feasible solutions with high sta# satisfaction, without the need to explicitly define soft constraint objectives...|$|E
40|$|Nowadays many real {{problems}} can be modeled as Constraint Satisfaction Problems (CSPs). In many situations, it is desirable {{to be able to}} state both <b>hard</b> <b>constraints</b> and soft <b>constraints.</b> <b>Hard</b> <b>constraints</b> must hold while soft constraints may be violated but as many as possible should be satisfied. Although the problem constraints can be divided into two groups, the order in which these constraints are studied can improve e#ciency, particulary in problems with non-binary constraints...|$|R
40|$|The Gibbs entropy of a microcanonical network {{ensemble}} is the logarithm of {{the number}} of network configurations compatible with a set of <b>hard</b> <b>constraints.</b> This quantity characterizes the level of order and randomness encoded in features of a given real network. Here we show how to relate this entropy to large deviations of conjugated canonical ensembles. We derive exact expression for this correspondence using the cavity methods for some <b>hard</b> <b>constraints.</b> Comment: 8 page...|$|R
40|$|The linear {{programme}} and its constraints are {{split into two}} parts. The first consists of the traditional structure, the second being akin to goal programming. SOFT constraints are weighted relative {{to each other and}} then approximately weighted relative to the <b>HARD</b> <b>constraints.</b> The LP is run four times giving different emphasis to the SOFT and <b>HARD</b> <b>constraints.</b> The manager requesting the LP has then to decide which gives the most appropriate solution. ...|$|R
40|$|International audienceIn many applications, such as Eddy-Current Testing (ECT), we {{are often}} {{interested}} in the joint model choice and parameter estimation. Nested Sampling (NS) {{is one of the}} possible methods. The key step that reflects the efficiency of the NS algorithm is how to get samples with <b>hard</b> <b>constraint</b> on the likelihood value. This contribution is based on the classical idea where the new sample is drawn within a hyper-ellipsoid, the latter being located from Gaussian approximation. This sampling strategy can automatically guarantee the <b>hard</b> <b>constraint</b> on the likelihood. Meanwhile, it shows the best sampling efficiency for models which have Gaussian-like likelihood distributions. We apply this method in ECT. The simulation results show that this method has high model choice ability and good parameter estimation accuracy, and low computational cost meanwhile...|$|E
40|$|Latent {{variable}} methods, such as PLCA (Probabilistic Latent Component Analysis) {{have been}} successfully used for analysis of non-negative signal representations. In this paper, we formulate PLCS (Probabilistic Latent Component Segmentation), which models each time frame of a spectrogram as a spectral distribution. Given the signal spectrogram, the segmentation boundaries are estimated using a maximum-likelihood approach. For an efficient solution, the algorithm imposes a <b>hard</b> <b>constraint</b> that each segment is modelled by a single latent component. The <b>hard</b> <b>constraint</b> facilitates the solution of ML boundary estimation using dynamic programming. The PLCS framework does not impose a parametric assumption unlike earlier ML segmentation techniques. PLCS can be naturally extended to model coarticulation between successive phones. Experiments on the TIMIT corpus show that the proposed technique is promising compared to most {{state of the art}} speech segmentation algorithms...|$|E
40|$|Classical meta-heuristic {{methods for}} solving {{rostering}} problems focus on defining measures of roster quality. Here {{we present a}} new case-based reasoning approach to generating repairs of <b>hard</b> <b>constraint</b> violations using expert-human experience. This approach is used to guide heuristic constraint satisfaction algorithms, eliminating the need to explicitly define search objectives...|$|E
40|$|<b>Hard</b> <b>{{constraints}}</b> {{must always}} hold. Violations of soft constraints may be tolerable. Inconsistency-tolerant in-tegrity checking serves to flexibly check both <b>hard</b> and soft <b>constraints</b> {{in a uniform}} manner. With an extended exam-ple for risk management, we illustrate that inconsistency-tolerant integrity checking methods are more efficient and more reliable for checking <b>hard</b> and soft <b>constraints</b> than traditional approaches. ...|$|R
5000|$|... 2008: ILEWG International Lunar Exploration “Technology Award”, for the {{development}} of advanced technologies within <b>hard</b> <b>constraints</b> of short time and cost ...|$|R
40|$|We {{present an}} integer {{programming}} {{approach to the}} university course timetabling problem, in which weekly lectures have to be scheduled and assigned to rooms. Students’ curricula impose restrictions as to which courses may be scheduled in parallel. Besides some <b>hard</b> <b>constraints</b> (no two courses {{in the same room}} at the same time, etc.), there are several soft constraints in practice which give a convenient structure to timetables; these should be met as well as possible. We report on solving benchmark instances from two International Timetabling Competitions which are based on real data from the university of Udine. The first set is solved to proven optimality, for the second set we give solutions which do not violate any <b>hard</b> <b>constraints.</b> We further present solutions to larger instances with more elaborate <b>hard</b> <b>constraints</b> from TU Berlin, Germany...|$|R
40|$|The article {{discusses}} {{essential for}} systems adaptation issues. The investigation objectives are to analyse and compare abilities for self-regulation and adaptation of heuristic algorithm called Free Search. It {{is evaluated with}} <b>hard</b> <b>constraint</b> test problem. Experimental results are compared with collection of published in the literature solutions achieved by other methods...|$|E
30|$|The {{difference}} between the soft constraint and <b>hard</b> <b>constraint</b> cases is in the latter case, no sensing probability can be 1; in contrast, a sensing probability could be 1. The common {{point is that the}} sensing probability for every sub-channel should be non-zero. Moreover, the constraint for the sum of sensing probabilities could be an inequality for both cases.|$|E
3000|$|... {{pertaining}} to different road types j {{to reflect the}} different levels of smoothness of the daily variation patterns shown in Fig.  1. Finally, a rank constraint could {{be added to the}} estimation of Γ to obtain an even better bias/variance trade-off. Therein, the appropriate rank may either be enforced as a <b>hard</b> <b>constraint</b> or estimated by penalization as in [17].|$|E
40|$|In {{universities}} scheduling curriculum {{activity is}} an essential job. Primarily, scheduling is a distribution of limited resources under interrelated constraints. The set of <b>hard</b> <b>constraints</b> demand the highest priority and should not to be violated at any cost, while the maximum soft constraints satisfaction mounts the quality scale of solution. In this research paper, a novel bisected approach is introduced that is comprisesd of GA (Genetic Algorithm) as well as Backtracking Recursive Search. The employed technique deals with both <b>hard</b> and soft <b>constraints</b> successively. The first phase decisively is focused over elimination of all the <b>hard</b> <b>constraints</b> bounded violations and eventually produces partial solution for subsequent step. The second phase is supposed to draw the best possible solution on the search space. Promising results are obtained by implementation on the real dataset. The key points of the research approach are to get assurance of <b>hard</b> <b>constraints</b> removal from the dataset and minimizing computational time for GA by initializing pre-processed set of chromosomes...|$|R
40|$|Model Predictive Control {{algorithms}} minimize on-line and {{at every}} sampling point an appropriate objective function, {{subject to the}} satisfaction of possible <b>hard</b> <b>constraints</b> on the process outputs, inputs or other state variables. The presence of the <b>hard</b> <b>constraints</b> in the on-line optimization problem results in a nonlinear closed-loop system, even though the process dynamics are assumed linear. This paper describes a procedure for analyzing the nominal and robust stability properties of such control laws, by utilizing the Operator Control Theory framework...|$|R
30|$|The {{crossover}} 2 {{is applied}} to part 2 of a chromosome. As many <b>hard</b> <b>constraints</b> involved, the following steps are proposed to implement the crossover 2.|$|R
