123|10000|Public
5000|$|There is no [...] "best" [...] {{number of}} bins, and {{different}} bin sizes can reveal different {{features of the}} <b>data.</b> <b>Grouping</b> data {{is at least as}} old as Graunt's work in the 17th century, but no systematic guidelines were given until Sturges's work in 1926.|$|E
5000|$|Bailey {{outlined}} {{five different}} methods for identifying ecosystems: gestalt ("a whole {{that is not}} derived through considerable of its parts"), in which regions are recognized and boundaries drawn intuitively; a map overlay system where different layers like geology, landforms and soil types are overlain to identify ecosystems; multivariate clustering of site attributes; digital image processing of remotely sensed <b>data</b> <b>grouping</b> areas based on their appearance or other spectral properties; or by a [...] "controlling factors method" [...] where a subset of factors (like soils, climate, vegetation physiognomy or the distribution of plant or animal species) are selected from a large array of possible ones are used to delineate ecosystems. In contrast with Bailey's methodology, Puerto Rico ecologist Ariel Lugo and coauthors identified ten characteristics of an effective classification system: that it be based on georeferenced, quantitative data; that it should minimize subjectivity and explicitly identify criteria and assumptions; {{that it should be}} structured around the factors that drive ecosystem processes; that it should reflect the hierarchical nature of ecosystems; that it should be flexible enough to conform to the various scales at which ecosystem management operates; that it should be tied to reliable measures of climate so that it can [...] "anticipate global climate change; that it be applicable worldwide; that it should be validated against independent data; that it take into account the sometimes complex relationship between climate, vegetation and ecosystem functioning; and that it should be able to adapt and improve as new data become available".|$|E
40|$|This paper {{explains}} the simulator of dynamic {{behavior of a}} Fed Batch bioreactor modeled with anfis networks. The simulator was built from the proposed model to observe the oscillatory behavior of the Zymomonas mobilis (Z. m). The model uses the anfis networks created in Matlab to simulate the system response. The commands genfis 1 and genfis 2 were used to generate {{the structure of the}} fuzzy inference system without using <b>data</b> <b>grouping</b> and with <b>data</b> <b>grouping</b> respectively. The predictions of the Anfis network are shown in the results for the output system variables: the biomass concentration, the substract concentration, the product concentration and the biomass growth speed...|$|E
50|$|OKI <b>Data</b> <b>Group,</b> which markets its {{products}} under the OKI brand, {{is focused on}} creating professional printed communications products, applications and services. The OKI <b>Data</b> <b>Group</b> provides {{a wide range of}} devices, from printers, faxes and multi-functional products to business applications and consultancy services.|$|R
50|$|All data is {{from the}} Particle <b>Data</b> <b>Group.</b>|$|R
40|$|Abstract: Extended {{introduction}} in {{data compression}} problems {{is given in}} the paper. Two classes of compression methods are outlined: element-by-element compression and <b>data</b> <b>group</b> compression. A systematization of <b>data</b> <b>group</b> compression methods is given. The class of basic compression methods and modifications is described in detail. Note: Publication language:russia...|$|R
40|$|Abstract. Ubiquitous {{computing}} {{has been}} identied {{as one of}} the next major directions in computing. This paper identies several require-ments to support data access in ubiquitous computing environments and presents a design to meet the requirements. The impetus for the design lies in three areas; 1) content adaptation, 2) <b>data</b> <b>grouping,</b> and 3) loca-tion awareness. The system is composed of data access building blocks, which allows devices to customize {{the way in which they}} retrieve data. All data in the system is indexed and typed, which facilitates <b>data</b> <b>grouping,</b> automatic content conversions, random access, and higher level services, such as streaming. The personal storage of a user is implicitly linked to a user and can be automatically incorporated into an environment conditioned on their physical presence. ...|$|E
30|$|Identifying {{the units}} which have an {{important}} role in flow transmissivity and storage can be helpful in secondary recovery and more production of reservoir. According to acquired flow units from different methods, the question which types of <b>data</b> <b>grouping</b> are more precise in defining transmissive and storage hydraulic units are posed.|$|E
40|$|In this work, {{we present}} several {{compiler}} optimizations {{to reduce the}} overhead due to software protection. We first propose an aggressive rematerialization algorithm which attempts to maximally realize non-trusted values from other trusted values thereby avoiding the security cost for those non-trusted values. We further propose a compiler technique to utilize the secure storage in our machine model efficiently. To optimize the security cost on data {{that has to be}} stored in non-trusted storage, we propose a <b>data</b> <b>grouping</b> technique. Security operations can be performed over the group of data instead of over each piece separately. We show an interesting application of the <b>data</b> <b>grouping</b> technique to reduce the security cost. We test the effectiveness of our optimizations on a recently proposed software protection scheme that involves large overhead. Our results show that the above optimizations are effective and reduce the security overhead significantly. 1...|$|E
50|$|The first 256 bytes of the <b>data</b> <b>group</b> must be zero. They will be {{populated}} by CP/M-86 with the zero page (comparable to the Program Segment Prefix in DOS). If {{there is no}} <b>data</b> <b>group,</b> then the first 256 bytes of the code group will be used instead.|$|R
5000|$|... 2008: International <b>Data</b> <b>Group</b> CIO Pakistan Pioneer in Innovation Award ...|$|R
5000|$|In 2016, the {{corporation}} retained Goldman Sachs {{to explore a}} possible sale. On January 19, 2017, the Wall Street Journal reported that China Oceanwide Holdings Group was, {{as part of a}} Chinese consortium, acquiring International <b>Data</b> <b>Group</b> Inc., at the time known for IDG Ventures. Also at the time, International <b>Data</b> <b>Group</b> published publications such as Computerworld magazine, and according to the Journal, was [...] "one of the first global venture capital investors in China." [...] On March 29, 2017, China Oceanwide Holdings Group announced the close of the acquisition of International <b>Data</b> <b>Group,</b> Inc. (“IDG”).|$|R
30|$|The {{agents for}} {{aggregation}} modes creation and edition {{is needed to}} support the technology of work with and database in the aggregation mode for selection and visualization of data mart in the hypertable. When the aggregation mode is setup the hypertable view is given, and values of visible columns, the number and nature of <b>data</b> <b>grouping</b> levels, as well as color coding are determined.|$|E
40|$|Deep {{learning}} {{has been successfully}} applied to various tasks, but its underlying mechanism remains unclear. Neural networks map input data to hidden states in deep layers. As deeper layers have fewer degrees of freedom, subsets of data are transformed into identical states in the deep layers. In this sense, deep learning {{can be considered as}} a hierarchical <b>data</b> <b>grouping</b> process. In this Letter, we discover that deep learning forces the size distributions of the data clusters to follow power laws with a different power exponent within each layer. In particular, we identify a critical layer where the cluster size distribution obeys a reciprocal relationship between rank and frequency, also known as Zipf's law. Deep learning ensures balanced <b>data</b> <b>grouping</b> by extracting similarities and differences between data. Furthermore, we verify that the data structure in the critical layer is most informative to reliably generate patterns of training data. Therefore, the criticality can explain the operational excellence of deep learning and provide a useful concept for probing optimal network architectures. Comment: 3 figure...|$|E
40|$|Based on {{the typical}} {{biological}} responses of an organism to allelochemicals (hormesis), concepts of whole-range assessment and inhibition index were developed for improved analysis of allelopathic data. Examples of their application are presented using data {{drawn from the}} literature. The method is concise and comprehensive, and makes <b>data</b> <b>grouping</b> and multiple comparisons simple, logical, and possible. It improves data interpretation, enhances research outcomes, and is a statistically efficient summary of the plant response profiles...|$|E
5000|$|Neil Fantom, Manager of the Development <b>Data</b> <b>Group,</b> The World Bank ...|$|R
5000|$|... a duplex Digital <b>Data</b> <b>Group</b> for timing {{signals in}} the {{electronic}} equipment ...|$|R
25|$|PivotDiagrams, {{which are}} used to {{visualize}} <b>data,</b> show <b>data</b> <b>groups</b> and hierarchical relationships.|$|R
40|$|Abstract: Clustering or <b>data</b> <b>grouping</b> {{is a key}} initial {{procedure}} in image processing. This paper deals with the application of standard and genetic k-means clustering algorithms {{in the area of}} image segmentation. In order to assess and compare both versions of kmeans algorithm and its variants, appropriate procedures and software have been designed and implemented. Experimental results point that genetically optimized k-means algorithms proved their usefulness in the area of image analysis, yielding comparable and even better segmentation results. ...|$|E
40|$|A {{forecasting}} model {{about the}} daily gas load based on {{support vector machine}} theory is developed in this paper. The {{ways to improve the}} forecasting accuracy is discussed, including the normalization method, the <b>data</b> <b>grouping</b> method and the effect of different history data period. It is proved that the proper normalization method is to map the input gas load data from the small and narrow range to the big and wide one. The <b>data</b> <b>grouping</b> method is important because it relates to the gas consumer composition. It is better to obtain the period of history load data by experiment investigation than by theory analysis. As it relates to both the number of training samples and the characteristic of the nonlinear regression. For this study, the period of 5 days is better than 7 days, although the latter one is the number of a week. The high performance of the model is proved as the average error is 0. 94 % for 5 days forecasting in heating period. Moreover, the research about the ways to improve the forecasting accuracy is helpful to solve the similar problems...|$|E
40|$|International audienceRecommending {{appropriate}} {{content and}} users {{is a critical}} feature of on-line social networks. Computing accurate recommendations on very large datasets can however be particularly costly in terms of resources, even on modern parallel and distributed infrastructures. As a result, modern recommenders must generally trade-off quality and computational cost to reach a practical solution. This trade-off has however so far been largely left unexplored by the research community, {{making it difficult for}} practitioners to reach informed design decisions. In this paper, we investigate to which extent the additional computing costs of advanced recommendation techniques based on supervised classifiers can be balanced by the gains they bring in terms of quality. In particular, we compare these recommenders against their unsupervised counterparts, which offer lightweight and highly scalable alternatives. We propose a thorough evaluation comparing 11 classifiers against 7 lightweight recommenders on a real Twitter dataset. Additionally, we explore <b>data</b> <b>grouping</b> as a method to reduce computational costs in a distributed setting while improving recommendation quality. We demonstrate how classifiers trained using <b>data</b> <b>grouping</b> can reduce their computing time by 6 while improving recommendations up to 22 % when compared with lightweight solutions...|$|E
50|$|The Particle <b>Data</b> <b>Group</b> has renamed Y(4140) {{to follow}} naming {{conventions}} to X(4140).|$|R
5000|$|The {{following}} <b>data,</b> <b>grouped</b> {{by first}} language, {{is from the}} 1921 population census: ...|$|R
5000|$|PivotDiagrams, {{which are}} used to {{visualize}} <b>data,</b> show <b>data</b> <b>groups</b> and hierarchical relationships.|$|R
40|$|We {{present a}} graph {{partitioning}} method to integrate prior knowl-edge in <b>data</b> <b>grouping.</b> We consider priors represented by {{three types of}} constraints: unitary constraints on labelling of groups, partial a priori grouping information, external in uence on binary constraints. They are modelled as biases in the grouping process. We incorporate these biases into graph partitioning criteria. Com-putationally this formulation leads to a constrained eigenproblem. We demonstrate the eectiveness of this algorithm on image seg-mentation with priors and object detection with spatial attention. ...|$|E
40|$|Tyt. z nagłówka. Bibliografia s. 590. Dostępny również w formie drukowanej. ABSTRACT: The Miocene {{formation}} {{in the area of}} Księżpol gas field is built of very thin sandy-shaly layers. Log data from wells Księżpol 11 and Księżpol 17 were processed with statistical methods. Principal Component Analysis was used for grouping and specifying well log data. Clustering, discrimination and classification are statistical tools facilitating data arrangement and preliminary <b>data</b> <b>grouping</b> according to natural petrophysical features of analysed rocks. KEYWORDS: Carpathian Foredeep, gas deposits, statistical methods. SŁOWA KLUCZOWE: zapadlisko przedkarpackie, złoże gazu ziemnego, metody statystyczne...|$|E
40|$|K-anonymisation is an {{approach}} to protecting private information contained within a dataset. Many k-anonymisation methods have been proposed recently and one class of such methods are clustering-based. These methods are able to achieve high quality anonymisations and thus have a great application potential. However, existing clustering-based techniques use different quality measures and employ different <b>data</b> <b>grouping</b> strategies, and their comparative quality and performance are unclear. In this paper, we present and experimentally evaluate a family of clustering-based k-anonymisation algorithms in terms of data utility, privacy protection and processing efficiency...|$|E
50|$|This {{table is}} {{based in part on}} data {{gathered}} by the Particle <b>Data</b> <b>Group.</b>|$|R
50|$|The new chip based {{passports}} {{contain an}} RFID chip with 16 <b>data</b> <b>groups</b> (DGs).|$|R
5000|$|Patrick Joseph McGovern, Jr. - the {{chairman}} and founder of International <b>Data</b> <b>Group</b> (IDG) ...|$|R
40|$|AbstractThe {{determination}} of structural dynamic stress spectrum distribution {{is of great}} significance in the structural fatigue strength evaluation as well as reliability design. In previous empirical data processing methods, the <b>data</b> <b>grouping</b> and distribution fitting were excessively coarse and contained distinctive defects. This paper proposed an effective approach to statistically group actual measured dynamic stress data and validly extrapolate the combined distribution to fit the dynamic stress spectrum distribution. This approach has been verified its effectiveness through chi-square test, stress spectrum extrapolation and damage calculation in dynamic stress study...|$|E
40|$|Abstract. The stereological {{problem of}} {{unfolding}} spheres size distribution from linear sec-tions is formulated {{as a problem}} of inverse estimation of a Poisson process intensity function. A singular value expansion of the corresponding integral operator is given. The theory of recently proposed B-spline sieved quasi-maximum likelihood estimators is modied to make it applicable to the current problem. Strong L 2 -consistency is proved and convergence rates are given. The estimators are implemented with the recently proposed EMDS algorithm. Promising performance of this new methodology in nite samples is illustrated with a nu-merical example. <b>Data</b> <b>grouping</b> eects are also discussed...|$|E
40|$|Sign-based {{spectral}} clustering performs <b>data</b> <b>grouping</b> {{based on}} signs of {{components in the}} eigenvectors of the input. This paper introduces the concept of sign-based clustering, proves some of its basic properties and describes its use in applications. It is shown that for certain applications where {{a relatively small number}} of clusters are sought the sign-based approach can greatly simplify clustering by just examining the signs of components in the eigenvectors, while improving the speed and robustness of the clustering process. For other such applications, it can provide useful initial approximations in improving the performance of cluster searching heuristics such as k-means. 1...|$|E
30|$|In the {{previous}} section, we demonstrated that music familiarity affects EEG signals using both analysis at the single-electrode {{level and the}} functional connectivity level. In this section, we present the results of EEG-based emotion recognition assessment that takes music familiarity into account. To measure this, we separated EEG signals into two groups in accordance with familiarity level (low and high). In our dataset, we separated the data from songs into a high familiarity <b>data</b> <b>group</b> (4 – 6 familiarity scores) and a low familiarity <b>data</b> <b>group</b> (1 – 3 familiarity scores). For the DEAP dataset, we used the same separation approach as in {{the previous}} section. Features were then separately extracted from the EEG signals of each <b>data</b> <b>group</b> and used to train emotion recognition models. As a comparison with the traditional approach that overlooks the familiarity effect, we also trained a model to use features extracted from all <b>data</b> <b>groups</b> (i.e., the original data before separation).|$|R
50|$|Following the buyout, AccessKenya {{merged with}} Internet Solutions Kenya Limited, a Dimension <b>Data</b> <b>Group</b> subsidiary.|$|R
5000|$|Comprehensive {{tables for}} {{radiation}} lengths and other {{properties of materials}} {{are available from the}} Particle <b>Data</b> <b>Group</b> ...|$|R
