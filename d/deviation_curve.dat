16|147|Public
50|$|A <b>deviation</b> <b>curve</b> {{is simply}} a {{combination}} of two reverse curves. It is used when {{it is necessary to}} deviate from given straight path to avoid intervening obstructions such as a building, and place of worship, or river.|$|E
50|$|The maximum {{permitted}} {{width of}} the handle (51 mm) is illustrated in the diagram by {{the distance between the}} dotted lines A-A and A1-A1. A hockey stick handle will rarely be of the maximum permitted width: most are between 46 mm and 48 mm at the widest point. The maximum permitted 'deviation' is shown by the lines B-B and B1-B1 respectively. The line B-B is 20 mm further along the X- axis than the line A-A and the line B1-B1 is 20 mm further along the X+ axis than the line A1-A1. There is no limit to the length of a protrusion along the y-axis specified, so the <b>deviation</b> <b>curve</b> or curves may be of any length {{along the length of the}} stick-handle. Some goalkeeping sticks have an outward curve on the toe side (within the line B-B) that extends for almost half the total length of the stick.|$|E
3000|$|... f is {{no longer}} to be chosen during {{measurements}} by continuously computing the slope regression on MW and by checking a stability criterion. In effect, the standard <b>deviation</b> <b>curve</b> (the blue one in Figure  8) can be drawn by knowing just the variogram model, because σ [...]...|$|E
3000|$|Figure 9 shows {{local time}} {{variation}} of the percent relative deviations, ΔM 3000 F 2 between model results and data. The plot in the top left, top right, bottom left and bottom right panel indicates March, June, September and December deviations, respectively. Figure 9 indicates that there are substantial hour-to-hour and month-to-month variations of <b>deviation</b> <b>curves</b> compared to variation observed in h [...]...|$|R
30|$|Eventually, {{a look at}} the {{standard}} <b>deviation</b> <b>curves</b> in Fig.  4 suggests that the measurements are quite noisy, hence non-trivial to exploit with a limited amount of observations. This will be confirmed in our following PDF estimation phase and therefore motivates the dimensionality reduction in the next section (intuitively because using more dimensions can possibly lead to better signal extraction, which can mitigate the effect of a large noise level).|$|R
40|$|Properness {{has been}} {{introduced}} in the expected utility framework and it recently has been transfered to mean-variance utility functions. Here, we show that properness implies {{the slope of the}} mean-standard <b>deviation</b> indifference <b>curve</b> being convex in the standard <b>deviation.</b> This indifference <b>curve</b> property allows us to characterize the comparative static effects of changing the background risk and dependency structure in a simple portfolio choice model. Copyright Springer-Verlag Berlin/Heidelberg 2005 Properness, Mean-standard deviation, Comparativestatics.,...|$|R
40|$|The maximum <b>deviation</b> <b>curve</b> of an {{estimator}} {{describes how}} an estimate can change (in the worst case) when you replace m out of n "good" observations to arbitrary positions. This function will be computed for some robust univariate location estimators. A lower bound for this curve is derived, {{and it is}} shown that this bound can be attained. Trimmed means will always be close to this lower bound. When more than {{one third of the}} observations is contaminated, the median also gets to the lower bound. Finally, it is shown that a high breakdown point leads to a relatively large maximum deviation in the presence of small amounts of contaminants. The maximum <b>deviation</b> <b>curve</b> approach is based on the finite sample behavior of the estimators and makes no distributional assumptions. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|E
30|$|F 2, {{although}} the magnitudes of the {{deviations from the}} observations are smaller. The largest amplitude of deviation occurs in June with a value greater than 10 %. The amplitude of the <b>deviation</b> <b>curve</b> varies from about − 10 to 7 % (March), − 10 to 12 % (June), − 9 to 4 % (September), and − 8 to 4 % (December), implying that IRI model seems to be largely underpredicts M 3000 F 2 more than overpredicting propagation factor. On average, absolute percent disparity varies between about 0 – 10 %.|$|E
40|$|A recent {{modification}} of the methodology of profile analysis, which allows the testing for differences between two functions as a whole with a single test, rather than point by point with multiple tests is discussed. The modification {{is applied to the}} examination of the issue of motion/no motion conditions as shown by the lateral <b>deviation</b> <b>curve</b> as a function of engine cut speed of a piloted 737 - 100 simulator. The results of this application are presented along with those of more conventional statistical test procedures on the same simulator data...|$|E
40|$|This paper {{focuses on}} the design and {{implementation}} of on-line optimal control strategies of crystal properties for non-isothermal antisolvent crystallization processes. The one-dimensional Fokker-Planck equation (FPE) is used to represent the dynamic characteristics of the crystal growth and to generate iso-mean and iso-standard <b>deviation</b> <b>curves.</b> Using controllability tools it is shown {{that the system is}} ill conditioned in the operational range, posing limitations on the achievable control performance. A novel digital image texturing analysis approach is implemented to track crystal's size distribution along the experiment, thus providing the on-line information for further feedback control action. Subsequently, alternative control strategies are implemented and tested to achieve a desired crystal size distribution (CSD) ...|$|R
3000|$|... is minimal, {{under the}} side-conditions of bounded <b>deviation</b> from the <b>curve</b> network and bounded kink angles.|$|R
40|$|This {{class will}} cover basic {{concepts}} {{and methods of}} elementary probability and quantitative reasoning, with practical applications. Topics include: sample average and stan- dard <b>deviation,</b> normal <b>curves,</b> regression, expected value and standard error, confidence intervals and hypothesis tests. You will see that our text will emphasize the underlying ideas rather than memorization of definitions and formulas...|$|R
40|$|The use {{of thermal}} anomaly to monitor or predict {{earthquakes}} has shown little success. Various {{methods have been}} propounded to monitor earthquakes with little emphasis on fundamental soil quantities. This paper propounded a vital factor- soil density ratio {{which can be used}} to monitor earthquakes. The magnitude of earthquakes was discovered to increase when the soil bulk density decreases very low. The dynamics of the heat flow was also discussed with respect to the soil density ratio. The importance of the temperature <b>deviation</b> <b>curve</b> to predict both short term and long term earthquakes were discussed with respect to time. Keywords soil density ratio, temperature deviation, heat frequency, earthquake duration, earthquake magnitude 1...|$|E
40|$|Abstract. A {{new method}} is {{proposed}} {{to estimate the}} parameters of probabilistic fatigue crack growth rate models, including the Paris equation and its ’ improved type. To take the statistical characteristics of whole test data into account, the method inherits the idea from the general maximum likelihood method which is widely used in parameters estimation of fatigue S-N curves, ε-N curves, and da/dN-∆K curves, and extends the conventional correlation coefficient optimization method into parameters evaluation not only for mean curve, but also for standard <b>deviation</b> <b>curve</b> and probabilistic curve. Analysis on the test data of 16 MnR steel indicates that present method is available and feasible. Comparing to the general maximum likelihood method, present method has simpler algorithm, and can avoid constructing and solving the likelihood function, so it is speedier in calculation...|$|E
40|$|A {{theoretical}} {{analysis of}} the effects of the delay-line differential nonlinearity (DNL) on the typical performance parameters of high-resolution time-to-digital converters (TDCs) based on delay-locked-loop (DLL) delay lines has been developed. The theoretical study is based on the knowledge of the delay-line nonlinearity values that can be measured, with the desired precision, by means of a statistical code-density test. In particular, the effects on the TDC time resolution and error standard <b>deviation</b> <b>curve</b> as a function of the measured time interval are investigated. An a posteriors linearization technique, consisting in a proper correction of the TDC readouts, is then analyzed and its advantages are theoretically demonstrated. Finally, the theoretical results are superimposed on experimental data coming from a real TDC. The measured deviations from the ideal behavior are thus justified and can just be ascribed to the delay-line nonlinearity...|$|E
40|$|The issues {{regarding}} {{the design and}} implementation of on-line optimal control strategies of crystal properties in noniso- thermal antisolvent crystallization processes to control particles’ mean size and standard deviation are dealt. The one- dimensional Fokker–Planck equation is used to represent the dynamic characteristics of the crystal growth and generate iso-mean and iso-standard <b>deviation</b> <b>curves.</b> Using controllability tools it is demonstrated {{that the system is}} ill condi- tioned in the whole operational range, posing limitations on the achievable control performance. To circumvent the problem, a control strategy is formulated by pairing crystals’ mean size with antisolvent feed rate and manipulating temperature to control the standard deviation. A novel digital image-texturing analysis approach is discussed and imple- mented to track crystals’ size distribution along the experiment and providing the on-line information for further feed- back control action. Subsequently, alternative control strategies are implemented and tested to achieve a desired crystal size distribution...|$|R
3000|$|... 1 was {{calculated}} {{to obtain the}} minimal value of the standard <b>deviation</b> of approximation <b>curve</b> from experimental data. Then these values were used for calculating A [...]...|$|R
40|$|In this paper, we give a {{treatment}} of the mathematical properties for a new distribution named a Pseudo Lindley distribution (PsLD). The properties stud- ied include: moments,cumulants, characteristic function, failure rate function, mean residual life function, mean <b>deviations,</b> Lorenz <b>curve,</b> stochastic ordering, asymptotic distribution of the extreme order statistics, maximum likelihood es- timation and simulation schemes. An application to waiting time data at a bank is described...|$|R
40|$|Literature {{values of}} the vapor {{pressures}} of H/sub 2 /, HD, D/sub 2 /, N/ sub 2 /, O/sub 2 /, Ne, Ar, Kr, Xe, CO, NO, CH/sub 4 /, N/sub 2 /O, CO/sub 2 /, HCl HBr, HI, SF/sub 6 /, H/sub 2 /S, Cl/sub 2 /, Br/sub 2 /, NH/sub 3 /, C/sub 2 /H/sub 2 /, SO/sub 2 /, SO/sub 3 /, COCl/sub 2 /, HF, HCN, N/sub 2 /O/sub 4 /, CCl/sub 4 /, and SnCl/sub 4 / were compared with the Kirchhoff formula log PK = [...] A/T + B between the normal boiling point and the critical point, where A and B are determined for each liquid. Plots are presented of the deviations computed by the equation: d = PK [...] P b. Based on accurately determined curves for 17 of these substances, empirical hypotheses were developed to allow the prediction of the most probable course of the <b>deviation</b> <b>curve</b> {{in cases where the}} data appeared to be unreliable. In addition, where precise data were available, the possibility of the existence of fine structure curvature was demonstrated. The deviation curves were used to obtain tables of interpolated vapor pressure values which are, in most cases, more accurate by one order of magnitude than any now in the literature, particularly where smoothed regression curves do not discriminate between random experimental errors and systematic deviations of an arbitrarily chosen formula from the real vapor pressure curve. Since the <b>deviation</b> <b>curve</b> is invariably shown to approach the zero ordinate at the critical point with a large negative slope, the correspondence between the critical pressure and temperature is fixed {{with a high degree of}} confidence. A particular result of this work is that the critical pressure of NH/sub 3 / was shown to be about one atmosphere higher than the presently accepted value. The new values for the critical points of CH/sub 4 /, C/sub 2 /N/sub 2 /, HCN, and Br/sub 2 / also resolved differences existing between various authorities in the literature. (auth...|$|E
40|$|Based on an {{extended}} time-space symmetry, a cylindrical model of gravitational geometrical dynamics with two time-like extra-dimensions {{leads to a}} microscopic geodesic description of the curved space-time. Due to interaction of a Higgs-like cosmological potential with individual space-time fluctuations, the original time-space symmetry is spontaneously broken, inducing a strong time-like curvature and a weak space-like <b>deviation</b> <b>curve.</b> As a result, the basic Klein-Gordon-Fock equation of a free massive elementary particle was derived, which implies a duality between the quantum mechanics equation and a microscopic geodesic description {{in the frame of}} general relativity. Consequently, Heisenberg inequalities are determined explicitly by the space-time curvatures. Moreover, extending curvatures to higher time-like dimensional hyper-spherical surfaces than one of the basic common cylindrical configuration, we found reasonable mass ratios of all charged leptons and succeeded to fix the number of their generations to be three. Following to concepts of the standard cosmological model, a possible experimental verification of mass ratio variation is proposed. Comment: 9 pages, presented at the 27 th Rencontres de Blois, France 201...|$|E
40|$|The Deciduous Seasonal Forest of the Northeast {{region of}} the state of Goiás {{is one of the few}} types of forest {{formations}} in the Cerrado biome, which may occur in areas of limestone outcrops. Generally it has a higher biomass of tree species than the contiguous cerrado. This study was carried out in an undisturbed area of forest (Flor Ermo Farm) and in others four areas of disturbed forests: Formosa, Traçadal, Manguinha and Conceição Mocambo Farm. The study aimed to estimate the basal area and the sampling intensity needed to use Bitterlich´s relascope in the deciduous forests. Estimates of basal area of the plots ranged from 23 to 24 m²/ha in the disturbed forests up to a maximum of 29. 3 m²/ha in the undisturbed one. Forests with high disturbance showed very small variation of the standard <b>deviation</b> <b>curve</b> for the sampled points when compared to the area with low disturbance level. For a confidence level of 95 % estimate of the mean, 20 sampling points with the relascope can be enough to sample the basal area in this kind of vegetation. </p...|$|E
30|$|Figure  8 {{shows that}} the {{fluctuation}} cycles of the predicted and measured dynamic cutting force are in good agreement, and only slight <b>deviations</b> in dynamic <b>curve</b> exist. The main reasons are the following.|$|R
40|$|The fluid-dynamic {{characteristics}} of fluidized and vibrofluidized beds of inert particles in liquids are being widely studied by researchers interested in understanding and modeling the paste drying process. In this work characteristic fluid-dynamic curves of pressure drop versus air velocity {{were obtained for}} fluidized and vibrofluidized beds with glycerol. Glycerol {{was used as a}} standard fluid to simulate a paste in the bed, and "ballotini" glass spheres were used as inert particles. The fluid-dynamic behavior as well as the quality of the fluidization regimes was analyzed through pressure drop versus air velocity curves and visual observation of the flow patterns in the beds. The results indicated that standard <b>deviation</b> <b>curves</b> are a useful tool for gaining an understanding of the fluid-dynamic behavior of a vibrofluidized bed. They allow detection of changes in the fluid-dynamic behavior which were not observed by analyzing only the pressure drop versus air velocity curves. For fluidized beds (G= 0. 00), it was also observed that analysis of <b>curves</b> of standard <b>deviations</b> of pressure drop may help in the estimation of more accurate values of minimum fluidization velocities...|$|R
50|$|May {{extended}} {{this theory}} when considering species with different carrying capacities, concluding that coexistence was unlikely if {{the distance between}} the modes of competing resource utilization curves d was less than the standard <b>deviation</b> of the <b>curves</b> w.|$|R
40|$|WOS: 000404657500014 International audienceAn {{experimental}} method {{was developed to}} measure {{the growth rate of}} the capillary instability for free liquid jets. The method uses a standard shadow-graph imaging technique to visualize a jet, produced by extruding a liquid through a circular orifice, and a statistical analysis of the entire jet. The analysis relies on the computation of the standard deviation of a set of jet profiles, obtained in the same experimental conditions. The principle and robustness of the method are illustrated with a set of emulated jet profiles. The method is also applied to free falling jet experiments conducted for various Weber numbers and two low-viscosity solutions: a Newtonian and a viscoelastic one. Growth rate measurements are found in good agreement with linear stability theory in the Rayleigh's regime, as expected from previous studies. In addition, the standard <b>deviation</b> <b>curve</b> is used to obtain an indirect measurement of the initial perturbation amplitude and to identify beads on a string structure on the jet. This last result serves to demonstrate the capability of the present technique to explore in the future the dynamics of viscoelastic liquid jets...|$|E
40|$|In many studies, a {{continuous}} response variable is repeatedly measured over time {{on one or}} more subjects. The subjects might be grouped into different categories, such as cases and controls. The study of resulting observation profiles as functions of time is called functional data analysis. This paper shows how {{you can use the}} SSM procedure in SAS/ETS ® software to model these functional data by using structural state space models (SSMs). A structural SSM decomposes a subject profile into latent components such as the group mean curve, the subject-specific <b>deviation</b> <b>curve,</b> and the covariate effects. The SSM procedure enables you to fit a rich class of structural SSMs, which permit latent components that have a wide variety of patterns. For example, the latent components can be different types of smoothing splines, including polynomial smoothing splines of any order and all L-splines up to order 2. The SSM procedure efficiently computes the restricted maximum likelihood (REML) estimates of the model parameters and the best linear unbiased predictors (BLUPs) of the latent components (and their derivatives). The paper presents several real-life examples that show how you can fit, diagnose, and select structural SSMs; test hypotheses about the latent components in the model; and interpolate and extrapolate these latent components...|$|E
30|$|Figure 8 (b) {{gives the}} local time and {{seasonal}} variations of percent deviations between IRI-URSI foF 2 (solid circle) and IRI-CCIR foF 2 (open circle) and the measured foF 2 during solar maximum of 1990 for low magnetic activity. Figure 8 (b) indicates clearly that both IRI options for critical frequency of F 2 -layer {{appear to be}} less accurate for equatorial region in Africa. Again, in January the <b>deviation</b> <b>curve</b> shows a relatively sharp increase in foF 2 with typical value near 125 % for URSI model, indicating that IRI-URSI option overpredicts foF 2 data by that significant amount at sunrise. The URSI model percent deviation, d foF 2 shows strong seasonal changes with largest value found in December solstice (0 – 124 %), and lowest value occurred in June solstice (3 – 65 %) with equinoxes (April: 0 – 70 %, October: 0 – 67 %) lying between the solstices extreme, whereas CCIR model indicates largest value in June solstice (July: 2 – 76 %), December solstice (January: 9 – 70 %), and March equinox (April: 0 – 71 %), with the smallest value seen in September equinox (October: 0 – 67 %). On average, absolute deviation of modeled foF 2 from observational data ranging from 0 – 80 % and ∼ 3 – 70 % for URSI and CCIR model, respectively for 1990 high solar activity year. Putting Figs. 8 (a) and 8 (b) together, we infer that overall deviations during solar minimum and maximum years are comparable for URSI option, but are marginally difference for CCIR model.|$|E
40|$|Abstract. We show that, for {{mechanical}} system with external forces, the equations of <b>deviations</b> of solution <b>curves</b> of the corresponding Lagrange equations, determine a nonlinear connection {{on the second}} order tangent bundle. In particular, Jacobi equations in Finsler and Riemann spaces determine such a nonlinear connection. 1...|$|R
40|$|The {{worldwide}} {{history and}} {{present state of}} development of rhodium–iron resistance thermometers (RIRTs) is briefly reviewed. A standardized interpolation method using RIRTs with the nominal composition of 0. 5 % Fe (by mole) is presented, with examples using data taken from 60 RIRTs made {{from a variety of}} wire batches and sources worldwide over the last 40 years. The parameterization exploits the favorable characteristics of the Cragoe reduced resistance Z(τ) and a suitably reduced temperature τ. A reference function Zref (τ) which approximates the average characteristics of selected wire is derived for use over the interval 0. 65 K to 24. 5561 K on the ITS- 90. The deviations of real RIRT data from this reference function are examined, and simple four-parameter Fourier-series solutions for the resulting <b>deviation</b> <b>curves</b> are presented. Despite the fact that the wire samples may be of different origins or state-of-anneal, {{it was found that the}} interpolations are successful for most of the samples studied over the 4. 2 K to 24. 5561 K interval, at the level of ≈ 1 mK standard uncertainty or less. This method would allow for calibrations of most RIRTs over this interval using only six calibration points, permitting an efficiency not achievable using the common least-squares curve-fitting calibration methods. The potential of this formalism for a standardized interpolation scheme using RIRTs is discussed...|$|R
40|$|The {{modeling}} {{process of}} settling of concrete top parapet of soil dam reservoir of Khmelnitsky NPP and forecasting movement of individual points is {{considered in the}} article. It is proposed to analyze the results of high-precision geometric leveling in 2 stages: at first is allocated trend component using polynomial approximation and then the remaining <b>deviations</b> from trend <b>curve</b> approximating by partial Fourier series</p...|$|R
40|$|The {{aim of this}} {{investigation}} was the creation of a high precision volume measurement device using the Helmholtz resonator principle, the purpose of which was to measure, without interference, liquids, solids and particulate samples. A previous study by Nishizu et al. (2001) suggested they achieved an accuracy of about + 1 % of full scale, where full scale is 100 % fill of the resonator chamber. Theory suggested that with careful design and measurement accuracy of approximately + 0. 1 % should be achievable. A high precision resonator was designed using acoustic theory and drawn using SolidWorksTM computer aided design software. This was then built using a computerised numerical controlled milling machine. The resulting resonator was coupled to a 16 -bit high-speed data acquisition system driven by purpose-made LabVIEWTM software. Using a resonant hunting method, repeatability was within + 1 mL for a 3 L chamber and the accuracy was better than + 3 mL, which is + 0. 1 % of full scale for liquid and solid samples. Testing of particulate material gave results indicating complex behaviour occurring within the resonator. Accuracy of sub-millimetre granular samples was restricted to approximately + 1 %, and fill factors to about 50 %. This reduction in accuracy was caused by a combination of energy absorption and resonant peak broadening. Medium sized particles, between 1 mm and 15 mm allowed measurement accuracies of approximately + 0. 5 %. Larger samples, greater than 15 mm in diameter, gave results with comparable accuracy to water and solids tested. It was found that most materials required a post measurement curve fit to align predictive volume calculations. All samples were observed to have a predictive <b>deviation</b> <b>curve</b> with coefficients dependent on the material or general shape. This curve appeared to be a function of sample regularity and/or whether the sample has interstitial spaces. To achieve high measurement accuracy temperature compensation was required to negate drifts in sample measurement. Chamber mapping was conducted using a spherical solid moved to precise locations, then making a three-dimensional frequency map of the inside of a dual port resonator. This showed the length extension term for the moving mass of air in the port penetrates roughly three times further than theory suggests. However, the influence of this extra ‘tail’ was found to be negligible when calculating sample volumes. A new method of measuring volume was developed using Q profile shifting and ambient temperature information. Accuracies for this method were comparable to those found using the resonant hunting method. A significant advantage of the new method is a 2 - 3 second measurement time compared to approximately 40 seconds for the resonant hunting method. The Q profile shifting method allowed volume measurements on samples moving through a dual port resonator at speeds of up to 100 mm/s. Free fall measurements proved unsuccessful using existing methods, but variations in signal data for different sample sizes suggest the need for future investigation. Follow-up studies may provide new interpretation models and methods for high-speed acquisition and analysis required to solve freefall measurements. Precise temperature (speed of sound) and flange factor (responsible for port length extension) relationships were evaluated. The correction factor for the speed of sound with temperature was found to be marginally different to established theory using the Helmholtz equation due to temperature secondary effects in the port length extension factor. The flange factor, which determines port length extension, for the configurations used in {{this investigation}} was experimentally found to be approximately 5 % less than theoretical values. It was established that the sample to be measured must be within a certain region of the chamber for accurate volume measurements to be made. If the sample were larger than the bounded region the resonant frequency would no longer obey the Helmholtz relationship. This would thereby reduce the accuracy of the measurement. All samples irrespective of cross sectional area were found to alter the resonant frequency when they were over 85 % of the chamber height. An equalisation method termed environmental normalisation curve was developed to prevent environmental and loudspeaker deficiencies from colouring Q profiles used in Q profile shifting procedures. This was undertaken as Q profile shifting relies on consistency in the Q profile. The environmental normalisation curve was able to equalise external factors to within + 0. 4 dB. The environmental normalisation method could be used to post-process data or applied in real time to frequency generation. The controlled decent Q profile shifting technique was refined further to be used in continuous measurements in a single port resonator. Samples could theoretically be measured up to 15 % of full-scale fill before resonant peak predictability would compromise accuracy. Measurement times were from one to three seconds, depending on environmental temperature stability. An alternative Helmholtz resonator was developed and investigated using an inverted port. This variant has potential applications for a seal-less chamber and port with rapid non-interference chamber access. Q factors for the inverted port resonator were found to be significantly less than tradition [sic] Helmholtz resonators. It is believed this is due to a larger boundary layer acoustic resistance occurring in the inverted port. A variable chamber resonator was designed and built as a further development of the Helmholtz resonator volume measurement system, as the uncertainty of measurement is a function of resonant chamber size. Therefore, using the variable chamber resonator the chamber size could be customised to the sample size. In this way the uncertainty of measurement could be minimised. The variable chamber resonator was used with both the resonant hunting method and the Q profile shifting method. Volume measurements on produce and minerals using the variable chamber resonator yielded results of similar accuracy to measurements on calibration samples. Each sample type displayed characteristics that would make specific calibration necessary. Both techniques were able to detect hidden void spaces, larger than 2 % of the sample volume, and in punctured samples. Therefore, both methods may be viable for rapid sorting of produce and minerals...|$|E
50|$|Subsidence led {{the company}} to build a <b>deviation</b> line which <b>curved</b> round {{the west side of}} the station and the growing settlement, in a similar manner to what it was forced to do at Eskett a few miles to the east. They built a {{passenger}} station on the deviation line which would go on to be called Cleator Moor East.|$|R
2500|$|Queensland Rail's Electric Tilt Train service {{operates}} from Brisbane to Rockhampton, {{while the}} Diesel Tilt Train service runs from Brisbane to Cairns. These routes were partially upgraded in the 1990s {{at a cost}} of $590 million, with the construction of [...] of <b>deviations</b> to straighten <b>curves.</b> Both with a service speed of , the electric train set an Australian rail speed record of [...] in 1999.|$|R
40|$|In {{the present}} work the {{geodesic}} equation represents the {{equations of motion}} of the particles along the geodesics is derived. The <b>deviation</b> of the <b>curved</b> space-time metric tensor {{from that of the}} Minkowski tensor is considered as a perturbation. The quantities is expanded in powers of c- 2 . The equations of motion of the relativistic three body problem in the PN formalism are obtained...|$|R
5000|$|In 1998 Gregor Weihs {{and a team}} at Innsbruck, led by Anton Zeilinger, {{conducted}} an ingenious experiment that closed the [...] "locality" [...] loophole, improving on Aspect's of 1982. The choice of detector was made using a quantum process {{to ensure that it}} was random. This test violated the CHSH inequality by over 30 standard <b>deviations,</b> the coincidence <b>curves</b> agreeing with those predicted by quantum theory.|$|R
5000|$|Queensland Rail's Tilt Trains operate Brisbane to Rockhampton with an {{electric}} train, Brisbane to Cairns with diesel. These routes were partially upgraded in the 1990s {{at a cost of}} $590 million, with the construction of 160 km of <b>deviations</b> to straighten <b>curves.</b> Both with a service speed of 160 km/h, the electric train set an Australian rail speed record of 210 km/h in 1999.|$|R
