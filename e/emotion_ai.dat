4|10|Public
25|$|Sentiment {{analysis}} (sometimes {{known as}} opinion mining or <b>emotion</b> <b>AI)</b> {{refers to the}} use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine.|$|E
40|$|The {{introduction}} of artificial intelligence (AI) on visual images for emotional analysis obliterates the natural subjectivity and contextual dependence of our facial displays. <b>Emotion</b> <b>AI</b> places {{itself as an}} algorithmic lens on our digital artifacts and real-time interactions, creating {{the illusion of a}} new, objective class of data: our emotional and mental states. Building upon a rich network of existing public photographs [...] as well as fresh feeds from surveillance footage or smart phone cameras [...] these emotion algorithms require no additional infrastructure or improvements on image quality. In order to examine the potential policy and legal remedies for <b>emotion</b> <b>AI</b> as an emerging technology, we first establish a framework of actors, collection motivations, time scales, and space considerations that differentiates <b>emotion</b> <b>AI</b> from other algorithmic lenses. Each of these elements influences available policy remedies, and should shape continuing discussions on the antecedent conditions that make emotional AI acceptable or not in particular contexts. Based on our framework of unique elements, we examine potential available policy remedies to prevent or remediate harm. Specifically, our paper looks toward the regulatory role of the Federal Trade Commission in the US, gaps in the EU's General Data Protection Regulation (GDPR) allowing for emotion data collection, and precedent set by polygraph technologies in evidentiary and use restrictions set by law. We also examine the way social norms and adaptations could grow to also modulate broader use. Given the challenges in controlling the flow of these data, we call for further research and attention as <b>emotion</b> <b>AI</b> technology remains poised for adoption...|$|E
40|$|The <b>Emotion</b> <b>AI</b> Engine is a {{software}} “engine ” that can simulate and generate “Artificial Emotion ” and personality. The core {{design of the}} engine {{is based on the}} neural and hormonal systems that form the conceptual basis of emotional behavior and the variations between the structure and functioning of those systems that give rise to personality. It is able to simulate and generate a wide range of gross emotional type behaviors (face, body gestures and actions) that are appropriate to a given age, gender, personality with mood...|$|E
40|$|In this paper, {{we discuss}} the role of <b>emotions</b> in <b>AI</b> and {{possible}} ways to determine their utility {{for the design of}} articial agents. We propose a research methodol-ogy for determining the utility of emotional control and apply it to the study of autonomous agents that com-pete for resources in an articial life environment. The results show that the emotional control can improve performance in some circumstances...|$|R
40|$|Abstract. People listen music, {{than they}} share {{emotions}} writing thinks about music on Twitter, a software analyzes the tweet with music as argument, and report some informations about these spoken emotions. I wrote a patch in Max/MSP that sonify {{in real time}} the global emotion lived by the twitter user music writers, it produce new music and this new music produce emotions also, {{and if you want}} you can write about that in Twitter, in this way the social network produce new emotions from its previous <b>emotions,</b> an <b>AI</b> generated <b>emotion...</b>|$|R
40|$|In {{the fields}} of psychology, AI, and {{philosophy}} there has recently been theoretical activity in the cognitively-based modelling of <b>emotions.</b> Using <b>AI</b> methodology {{it is possible to}} implement and test these complex models, and in this paper we examine an emotion model called ACRES. We propose a set of requirements any such model should satisfy, and compare ACRES against them. Then, analysing its behaviour in detail, we formulate more requirements and criteria that can be applied to future computational models of emotion. In arguing to support the new requirements, we find that they are desirable for autonomous systems in general. We also show how they can explain the psychological concept of regulation. Finally, we use the concepts developed to make a theoretical distinction between emotion and motivation...|$|R
40|$|The {{current work}} {{addresses}} a virtual environment with self-replicating agents whose decisions {{are based on}} a form of "somatic computation" (soma - body) in which basic emotional responses, taken in parallelism to actual living organisms, are introduced as a way to provide the agents with greater reflexive abilities. The work provides a contribution to the field of Artificial Intelligence (AI) and Artificial Life (ALife) in connection to a neurobiology-based cognitive framework for artificial systems and virtual environments' simulations. The performance of the agents capable of emotional responses is compared with that of self-replicating automata, and the implications of research on <b>emotions</b> and <b>AI,</b> in connection to both virtual agents as well as robots, is addressed regarding possible future directions and applications...|$|R
40|$|A crucial {{aspect of}} the "(ri) {{embodiment}} " of mind is cognitive account of subjective xperience, of "feeling something". I analyse the notion of "needs "-a very interesting kind of motivation- {{and the difference between}} needing something or having the need for something (objective need) and "feeling the need for something’. I argue that in order to feel the need for something an embodied cognitive agent is necessary since both self-perception (information from the body) and beliefs and expectations are necessary. After discussing some weaker notions of "feeling " and "need", and characterising also "desires", I criticise the current dominant approach to <b>emotions</b> in <b>AI</b> as correct but insufficient. It is necessary to explain and to model the functional role of "feeling " in emotions. The view of emotion as a reactive response modifying the internal state, cognitive processes, attention, and goals priorities, is not enough: why should we "feel " all these internal and external reactions and the preparation to act?...|$|R
40|$|Abstract]: With {{the recent}} {{resurgence}} of {{investigation into the}} realm of <b>emotion</b> theories from <b>AI</b> researcher's point of view, it is important {{to take a step back}} and evaluate ways in which these new theories and models could enrich the AI domain. Much scientific evidence has come to light that emotions go far beyond their traditional stereotypical affects of irrationality and illogical behaviour in humans to be the foundation of rational thinking, perception, learning and other intelligent cognitive functions. This paper briefly looks at the advantages of affective computing and introduces an emotionally motivated agent architecture capable of synthesizing emotions for given situations...|$|R
40|$|Driven by rapid ongoing {{advances}} in humanoid robot, increasing {{attention has been}} shifted into the issue of <b>emotion</b> intelligence of <b>AI</b> robots to facilitate the communication between man-machines and human beings, especially for the vocal emotion in interactive system of future humanoid robots. This paper explored the brain mechanism of vocal emotion by studying previous researches and developed an experiment to observe the brain response by fMRI, to analyze vocal emotion of human beings. Findings in this paper provided {{a new approach to}} design and evaluate the vocal emotion of humanoid robots based on brain mechanism of human beings...|$|R
40|$|A tecnhical report {{based on}} Mr. Campisi's masters thesis, {{addressing}} {{a new model}} of computer game <b>AI</b> <b>emotions.</b> Modeling human behavior in computer simulations and games is a subject which draws considerable attention. Despite the increased realism of graphics in games, poor modeling of non-player characters’ AI often leads to a shallow and unfulfilling game experience. Recently there has been increased focus on more sophisticated AI routines which have been used in both academic and commercial games. Emotion, however, is often ignored despite being an essential element of human behavior especially under stressful conditions. Research into the use of emotion in agent-based systems seems more concerned with how to convey the emotions of agents to the human player, or how to elicit an emotional response from the human player. Only recently has there been research on modeling emotions in combat simulators. This thesis will describe an emotional model suitable for most computer games which was adapted from the DETT model and significantly expande...|$|R
40|$|The {{discussion}} {{about the importance of}} emotions in the rational behavior of human being is not new. Neither is the {{discussion about}} emotions in artificial beings. The problem is that myth and misconceptions almost ever surround this discussion. It happens due to our difficulty to deal formally with the concepts of emotions. This paper uses the concepts of computational semiotics and others to give this discussion some theoretical background and possibly turn its implementation possible. 1. Introduction Most of the misconceptions and myths that arise from the discussion of <b>emotions</b> in the <b>AI</b> context are due to our difficulty to model it. After all, what is an emotion? Is it a process? Is it an heuristic? Is it a goal? Moreover, {{what is the role of}} emotions? Why do we need emotions? Recently many researchers have been studying those questions and, as we may expect, many different interpretations came up. This paper analyses the emotion in the context of computational semiotics and use [...] ...|$|R
40|$|The term {{emotion is}} {{important}} to AI as the term intelligence itself. Emotions contribute {{a great deal to}} intelligence. Specially in human level <b>AI</b> <b>emotion</b> aspect plays a crucial role. Emotion aspect supports decision making in a sound manner balanced with cognitive aspects, thus making an AI agent believable character different from unconvincing clown. Various attempts have made throughout the history of AI to incorporate emotional support in intelligent systems. Yet still some paths left untraveled. In general previous attempts have identified emotions as static representations. These models are rule based hence the element of uncertainty and evolvability of the system are not given sufficient importance. Although emotions are common to everybody, arousal and responses may be different as driven by a factor of uncertainty. Hence the total outcome is emergent. A strong philosophical basis for these ideas could be found in Buddhist teachings on emotions. This work presents an attempt based on Buddhist philosophical concepts of emotions where mind state can be considered as an emergent phenomena resulting from interactive elementary entities called emotions. These emotion factors are freely interacting autonomous entities. Their interactions are only constrained with boundary conditions imposed by rules for possible combinations of emotion factors as described in Buddhist theory of emotions. Proposed model is realized via MAS where emergence is supported intrinsically. Hence features are supported with MAS features autonomy, emergence, etc together with emotional capabilities. Inputs and outputs to simulated system are simulated sensory inputs and outputs provided in text mode represented by constrained English. Simulated system comprises of three basic modules containing the prescribed MAS for the core accompanied by personality and the world. Implementation of the system is done as a virtual agent application that is comprised of our emotion model within its cognitive architecture. Evaluation of the system suggests that it is capable to behave emotionally supported with features of emotional intelligence, approximately similar to human behavior in closed environment, and behave smoothly compared to conventional emotion models. Hence we are confirmed on the success of the incorporating emergent emotion model. The term emotion {{is important to}} AI as the term intelligence itself. Emotions contribute a great deal to intelligence. Specially in human level <b>AI</b> <b>emotion</b> aspect plays a crucial role. Emotion aspect supports decision making in a sound manner balanced with cognitive aspects, thus making an AI agent believable character different from unconvincing clown. Various attempts have made throughout the history of AI to incorporate emotional support in intelligent systems. Yet still some paths left untraveled. In general previous attempts have identified emotions as static representations. These models are rule based hence the element of uncertainty and evolvability of the system are not given sufficient importance. Although emotions are common to everybody, arousal and responses may be different as driven by a factor of uncertainty. Hence the total outcome is emergent. A strong philosophical basis for these ideas could be found in Buddhist teachings on emotions. This work presents an attempt based on Buddhist philosophical concepts of emotions where mind state can be considered as an emergent phenomena resulting from interactive elementary entities called emotions. These emotion factors are freely interacting autonomous entities. Their interactions are only constrained with boundary conditions imposed by rules for possible combinations of emotion factors as described in Buddhist theory of emotions. Proposed model is realized via MAS where emergence is supported intrinsically. Hence features are supported with MAS features autonomy, emergence, etc together with emotional capabilities. Inputs and outputs to simulated system are simulated sensory inputs and outputs provided in text mode represented by constrained English. Simulated system comprises of three basic modules containing the prescribed MAS for the core accompanied by personality and the world. Implementation of the system is done as a virtual agent application that is comprised of our emotion model within its cognitive architecture. Evaluation of the system suggests that it is capable to behave emotionally supported with features of emotional intelligence, approximately similar to human behavior in closed environment, and behave smoothly compared to conventional emotion models. Hence we are confirmed on the success of the incorporating emergent emotion model...|$|R

