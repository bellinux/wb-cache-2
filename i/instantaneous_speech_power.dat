0|252|Public
40|$|There is {{a variety}} of hearing aid models {{available}} in the marketplace, which vary in terms of size, shape and effectiveness. Due to size constraints, for certain types of hearing aids only a single microphone per hearing aid can be fitted, and only single-channel monaural noise reduction schemes can be integrated in them. In the near future, binaural hearing aids will become available, making use of a wireless link to shape information between the two ears. In this thesis, a binaural diffuse noise power spectral density estimator is first developed. The estimator {{does not require a}} voice activity detection algorithm, it provides an estimate at any time i. e. during speech activity or not, it has no noise tracking latency and it does not assume that the target speaker is in front of the binaural hearing aid user. An <b>instantaneous</b> binaural target <b>speech</b> <b>power</b> spectral density estimator is then developed, for conditions of speech corrupted by lateral interfering noise. The estimator does not require the knowledge of the direction of the noise source, and the noise source can be highly non-stationary or transient. Finally, a complete binaural noise reduction scheme is designed, by incorporating the two binaural estimators mentioned above. The proposed reduction scheme is designed for complex real-life environments composed of time-varying diffuse noise, multiple non-stationary directional noises and reverberant conditions. The proposed scheme also preserves the original interaural cues of both the target speech and the background noises. Simulations using recorded signals provided by a hearing aid manufacturer are performed in the thesis to validate the performance of the proposed estimators and the proposed noise reduction algorithm. The results indicate that the proposed binaural noise reduction scheme proves to be a good candidate for the noise reduction stage of upcoming binaural hearing aids...|$|R
40|$|A noise {{estimation}} {{algorithm is}} proposed for highly nonstationary noise environments. The noise estimate is updated by averaging the noisy <b>speech</b> <b>power</b> spectrum using a time and frequency dependent smoothing factor, which is adjusted based on signal presence probability in subbands. Signal presence is determined by computing {{the ratio of the}} noisy <b>speech</b> <b>power</b> spectrum to its local minimum, which is computed by averaging past values of the noisy <b>speech</b> <b>power</b> spectra with a look-ahead factor. The local minimum estimation algorithm adapts very quickly to highly non-stationary noise environments. This was confirmed with formal listening tests that indicated that our noise estimation algorithm when integrated in speech enhancement was preferred over other noise estimation algorithms. 1...|$|R
40|$|Recently, it {{has been}} shown that MMSE-based noise power estima-tion [1] results in an {{improved}} noise tracking performance with re-spect to minimum statistics-based approaches. The MMSE-based approach employs two estimates of the <b>speech</b> <b>power</b> to estimate the unbiased noise power. In this work, we improve the MMSE-based noise power estimator by employing a more advanced estimator of the <b>speech</b> <b>power</b> based on temporal cepstrum smoothing (TCS). TCS can exploit knowledge about the speech spectral structure. As a result, only one <b>speech</b> <b>power</b> estimate is needed for MMSE-based noise power estimation. Moreover, the presented estimator results in an improved noise tracking performance, especially in babble noise, where SNR improvements of 1 dB over the original MMSE-based approach can be observed. Index Terms — Noise <b>power</b> estimation, <b>speech</b> enhancement. 1...|$|R
40|$|Abstract — This paper {{presents}} a novel mechanism for dynamically adapting {{the quality of}} congestion controlled Voice Over IP (VoIP) applications on the internet in real time. The system uses our proposed variable bit rate speech codec called Speex, which can dynamically adjust the encoding bit rate (and hence the speech quality) based on both the feedback information about the network congestion and the <b>instantaneous</b> <b>speech</b> properties. Our extensive NS 2 simulation results prove that the proposed system indeed provides highest quality speech while maximising the bandwidth utilisation and reducing the network congestion. I...|$|R
40|$|Blind Source Separation {{has been}} an {{extremely}} active area of research {{for the last few}} years. Most of the research has been focused on separation of sources from one-dimensional mixture signals such as speech. More recently, separation of two-dimensional sources (images) has been also examined to a limited extent using second-order statistics, information theoretic models, and neural networks. In this paper, we extend a simple kurtosis maximization algorithm, successfully used in separation of <b>instantaneous</b> <b>speech</b> signals, to images. The higher-order statistics-based algorithm is simple and performs relatively well. ...|$|R
40|$|International audienceUnderdetermined source {{separation}} is often {{carried out by}} modeling time-frequency source coefficients via a fixed sparse prior. This approach fails {{when the number of}} active sources in one time-frequency bin is larger than the number of channels or when active sources lie on both sides of an inactive source. In this article, we partially address these issues by modeling time-frequency source coefficients via Gaussian priors with free variances. We study the resulting maximum likelihood criterion and derive a fast non-iterative optimization algorithm that finds the global minimum. We show that this algorithm outperforms state-of-the- art approaches over stereo <b>instantaneous</b> <b>speech</b> mixtures...|$|R
40|$|Abstract—This paper {{presents}} a novel mechanism for dynamic rate control of prioritised Voice Over IP (VoIP) traffic in real time. The system uses our proposed {{variable bit rate}} speech codec called Speex, which can dynamically adjust the encoding bit rate (and hence the voice quality) based on the feedback information about the network congestion, flow priority, and the <b>instantaneous</b> <b>speech</b> properties. Our extensive NS 2 simulation results along with results from ITU-T standard of speech quality evaluation tool (PESQ) show that the proposed system indeed provides highest quality speech while maximising the bandwidth utilisation and reducing the network congestion. I...|$|R
40|$|Abstract. Underdetermined source {{separation}} is often {{carried out by}} modeling time-frequency source coefficients via a fixed sparse prior. This approach fails {{when the number of}} active sources in one time-frequency bin is larger than the number of channels or when active sources lie on both sides of an inactive source. In this article, we partially address these issues by modeling time-frequency source coefficients via Gaussian priors with free variances. We study the resulting maximum likelihood criterion and derive a fast non-iterative optimization algorithm that finds the global minimum. We show that this algorithm outperforms state-ofthe-art approaches over stereo <b>instantaneous</b> <b>speech</b> mixtures. ...|$|R
40|$|In this paper, {{we present}} a novel speech-rhythm-guided syllablenuclei {{location}} detection algorithm. As a departure from conventional methods, we introduce an <b>instantaneous</b> <b>speech</b> rhythm estimator to predict possible regions where syllable nuclei can appear. Within a possible region, a simple slope based peak counting algorithm is used to get {{the exact location of}} each syllable nucleus. We verify the correctness of our method by investigating the syllable nuclei interval distribution in TIMIT dataset, and evaluate the performance by comparing with a state-of-the-art syllable nuclei based speech rate detection approach. Index Terms — speech rhythm, syllable nuclei detection 1...|$|R
5000|$|The Cato Institute is {{concerned}} that most proposed responses to Citizens United will give [...] "Congress unchecked new power over spending on political <b>speech,</b> <b>power</b> that will be certainly abused." ...|$|R
50|$|The Player is set of APIs (e.g. position2d, bumper, ir, <b>speech,</b> <b>power)</b> {{that can}} be {{implemented}} by a robot chassis (Roomba, Khephera etc.), possibly over serial line or network, or by Stage (2D simulator) or Gazebo (3D simulator).|$|R
5000|$|... 1987 August - the world's first <b>instantaneous</b> {{translation}} of <b>speech</b> by computer was unveiled by BT's research laboratories.|$|R
50|$|Gorfs {{most notable}} feature is its robotic {{synthesised}} <b>speech,</b> <b>powered</b> by the Votrax speech chip. One {{of the first}} games to allow the player to buy additional lives before starting the game, Gorf allows the player to insert extra coins to buy up to seven starting lives.|$|R
5000|$|The [...] "Political Recoreda" [...] in 1987 was {{conducted}} in Iloilo City to drum up support for the Draft Constitution {{and at the same}} time the members distributed copies of the constitution and primers. <b>Speech</b> <b>power</b> of SABAKA members were heard when they spoke in rallies and symposia.|$|R
40|$|Enhancement {{algorithms}} {{are widely}} used to overcome the degra-dation of noisy speech signals. Most enhancement algorithms re-quire {{an estimate of the}} noise and noisy <b>speech</b> <b>power</b> spectra in order to compute the gain function used for the noise suppression. The variance of these power spectral estimates degrades the qual-ity of the enhanced signal and smoothing techniques are therefore often used to decrease the variance. In this paper we present a method to determine the noisy <b>speech</b> <b>power</b> spectrum based on an adaptive time segmentation. More specifically, the proposed al-gorithm determines for each noisy frame which of the surrounding frames should contribute to the corresponding noisy power spec-tral estimate. Objective and subjective experiments show that an adaptive time segmentation leads to significant performance im-provements, particularly in transitional speech regions. 1...|$|R
40|$|Abstract: This paper {{deals with}} the problem of {{checking}} the consistency of the speech corpus during recording in terms of the level of <b>speech</b> <b>power</b> of individual recordings. The question was whether or not setting of the limits of RMS value is useful for checking the volume consistency of recordings destinated for unit selection speech synthesis...|$|R
50|$|On {{the day of}} his 18th birthday, Billy {{attended}} a <b>Speech</b> <b>Power</b> Toastmasters course, and registered his first finance business called the Australian Credit Network. He pursued a career in finance for approximately 15 years, working as a broker, financial planner and corporate banker. In 2011, he was awarded Corporate Solutions Executive of the Year by The Commonwealth Bank.|$|R
40|$|Most {{approaches}} {{to the problem of}} source separation use the assumption of statistical independence. To capture statistical independence higher order statistics are required. In this chapter we will demonstrate how higher order criteria, such as maximum kurtosis, arise naturally from the property of non-stationarity. We will also show that source sepa-ration of non-stationary signals can be based entirely on second order statistics of the signals. Natural signals, be it images or time sequences, are for the most part non-stationary. For natural signals therefore we argue that non-stationarity is the fundamental property, from which speci c second or higher order separation criteria can be derived. We contrast the linear bases obtained using second order non-stationarity and ICA for the cases of natural images and <b>speech</b> <b>powers.</b> Based on these results we argue that <b>speech</b> <b>powers</b> can in fact be understood as a linear superposition of non-stationary spectro-temporal independen...|$|R
30|$|The MS [13] {{approach}} {{has been shown to}} be a reliable estimator of the noise PSD for moderately time-varying noise conditions. This approach relies on the assumption that the minimum of the noisy <b>speech</b> <b>power,</b> P_x̃(k,ℓ), over a short temporal sliding window is not affected by the speech. The noise PSD σ _ṽ^ 2 (k,ℓ) is then estimated by tracking the minimum of P_x̃(k,ℓ) over this sliding window, whose usual length corresponds to 1.5 s according to [13].|$|R
40|$|Abstract—Single-channel {{enhancement}} algorithms {{are widely}} used to overcome the degradation of noisy speech signals. Speech enhancement gain functions are typically computed from two quantities, namely, {{an estimate of the}} noise power spectrum and of the noisy <b>speech</b> <b>power</b> spectrum. The variance of these power spectral estimates degrades the quality of the enhanced signal and smoothing techniques are, therefore, often used to decrease the variance. In this paper, we present a method to determine the noisy <b>speech</b> <b>power</b> spectrum based on an adaptive time segmentation. More specifically, the proposed algorithm determines for each noisy frame which of the surrounding frames should contribute to the corresponding noisy power spectral estimate. Further, we demonstrate the potential of our adaptive segmentation in both maximum likelihood and decision direction-based speech enhancement methods by making a better estimate of the a priori signal-to-noise ratio (SNR). Objective and subjective experi-ments show that an adaptive time segmentation leads to significant performance improvements in comparison to the conventionally used fixed segmentations, particularly in transitional regions, where we observe local SNR improvements in the order of 5 dB. Index Terms—Adaptive time segmentation, a priori signal-to-noise ratio (SNR), decision directed approach, hypothesis test, speech enhancement. I...|$|R
40|$|OFDMA {{is one of}} {{the most}} {{promising}} technologies to support the high speed wireless services. It is a multiple access scheme of current and near future terrestrial and satellite wireless technologies which is used in satellite communication or remote control for space robots or flights for cooperative work. A good resource scheduling scheme for OFDMA can overcome the packet losses due to varying nature of channel fading. In the IEEE 802. 16 standards, the scheduling is left unspecified. However, it has significant impact on system performance and QoS. In this master thesis, we developed the low complexity frequency selective scheduler aware of the current <b>instantaneous</b> <b>speech</b> quality in terms of R-Score particularly combining different metrics like current channel quality and urgency of the packets in scheduling decision for OFDMA system. The schedulers are simulated by using Matlab and the performance of the different schedulers is compared in different overload scenarios ranging from light to severe. The simulative performance evaluation is performed at the example of VoIP transmissions over the IEEE 802. 16 band AMC mode. Validerat; 20101217 (root...|$|R
40|$|Abstract-This paper {{presents}} a new algorithm for Blind Source Separation (BSS) of <b>Instantaneous</b> <b>speech</b> mixtures in under-determined case. A demixing algorithm which exploits the sparsity of speech signals {{in the short}} time Fourier transform (STFT) domain is proposed. This algorithm combines the modified k-means clustering procedure involved in the Line Orientation Separation Technique (LOST) with Smoothed l 0 -norm minimization (SL 0) method. First procedure along with a transformation into a sparse domain tries to estimate the mixing matrix, and the second method tries to extract the sources from the mixtures. Simulation results are presented and compared to the Degenerate Unmixing Estimation Technique (DUET) and LOST algorithms. It is shown in this article that improvements are achieved in two cases. One is the quality of source extraction when the number of mixtures is increased, and second is the speed of source separation when compared to the LOST algorithm. This speed enhancement is about 3 to 10 times comparing to the LOST algorithm. We called the proposed algorithm SL 0 -LOST. I...|$|R
30|$|The {{distances}} from different microphone positions {{to the mouth}} are 20 – 27 cm (Pos. 1), 28 cm (Pos. 2 / 3), and 58 cm (Pos. 4). All microphones are calibrated {{to have the same}} <b>speech</b> <b>power</b> at standstill. This comparison shows that at higher frequencies, the behavior of all microphones is almost similar, whereas at low and medium frequencies, the belt microphone outperforms conventional hands-free microphones. An improvement of up to 6 – 10 dB in SNR can be achieved.|$|R
50|$|It is {{a version}} sold by Orbit Research, {{designed}} {{for people with}} disabilities. It includes <b>speech</b> features. <b>Power</b> source comes from 9V battery instead of solar panel.|$|R
40|$|In this paper, {{we present}} a new {{technique}} for the estimation of short-term linear predictive parameters of speech and noise from noisy data and their subsequent use in waveform enhancement schemes. The method exploits a priori information about speech and noise spectral shapes stored in trained codebooks, parameterized as linear predictive coefficients. The method also uses information about noise statistics estimated from the noisy observation. Maximum-likelihood estimates of the speech and noise short-term predictor parameters are obtained by searching for the combination of codebook entries that optimizes the likelihood. The estimation involves the computation of the excitation variances of the speech and noise auto-regressive models on a frame-by-frame basis, using the a priori information and the noisy observation. The high computational complexity resulting from a full search of the joint speech and noise codebooks is avoided through an iterative optimization procedure. We introduce a classified noise codebook scheme that uses different noise codebooks for different noise types. Experimental {{results show that the}} use of a priori information and the calculation of the <b>instantaneous</b> <b>speech</b> and noise excitation variances on a frame-by-frame basis result in good performance in both stationary and nonstationary noise condition...|$|R
30|$|This paper {{seeks to}} improve CSP {{analysis}} in noisy environments {{with a special}} weighting algorithm. We assume the target sound source is a human speaker and the noise is broadband noise such as a fan, wind, or road noise in an automobile. Denda et al. proposed weighted CSP analysis using average speech spectrums as weights [7]. The assumption is that a subband with more <b>speech</b> <b>power</b> conveys more reliable information for localization. However, it {{did not use the}} harmonic structures of human speech. Because the harmonic bins must contain more <b>speech</b> <b>power</b> than the other bins, they should give us more reliable information in noisy environments. The use of harmonic structures for localization has been investigated in prior art [8, 9], but not for CSP analysis. This work estimated the pitches (F 0) of the target sound and extracted localization cues from the harmonic structures based on those pitches. However, the pitch estimation and the associated voiced-unvoiced classification may be insufficiently accurate in noisy environments. Also, {{it should be noted that}} not all harmonic bins have distinct harmonic structures. Some bins may not be in the speech formants and be dominated by noise. Therefore, we want a special weighting algorithm that puts larger weights on the bins where the harmonic structures are distinct, without requiring explicit pitch detection and voiced-unvoiced classification.|$|R
40|$|In {{this paper}} we propose a new {{framework}} for utilizing frequency information from the short-term <b>power</b> spectrum of <b>speech.</b> Feature extraction is based on the cepstral coefficients derived from the histograms of subband spectral centroids (SSC). Two new feature extraction algorithms are proposed, one based on frequency information alone, and the other which efficiently combines the frequency and amplitude information from the <b>speech</b> <b>power</b> spectrum. Experimental study on an automatic speech recognition task has shown that the proposed methods outperform the conventional speech front-ends in presence of additive white noise, while they perform comparably in the noise-free conditions. 1...|$|R
40|$|In this paper, {{a speech}} signal {{recovery}} algorithm is presented for a personalized voice command automatic recognition system in vehicle and restaurant environments. This novel algorithm {{is able to}} separate a mixed speech source from multiple speakers, detect presence/absence of speakers by tracking the higher magnitude portion of <b>speech</b> <b>power</b> spectrum and adaptively suppress noises. An automatic speech recognition (ASR) process {{to deal with the}} multi-speaker task is designed and implemented. Evaluation tests have been carried out by using the speech da-tabase NOIZEUS and the experimental results show that the proposed algorithm achieves impres-sive performance improvements...|$|R
40|$|A {{practical}} {{speech enhancement}} system {{consists of two}} major components, the estimation of noise power spectrum, and the estimation of speech. In single channel speech enhancement systems, most algorithms require an estimation of average noise spectrum since a secondary channel is not available. This requires a reliable speech/silence detector. Thus the speech/silence detection can be a determining factor {{for the performance of}} the whole speech enhancement system. The speech/silence detection finds out the frames of the noisy speech that contain only noise. If the speech/silence detection is not accurate then speech echoes and residual noise tend to be present in the enhanced speech. The performance of noise estimation algorithm is usually a tradeoff between speech distortion and noise reduction. In existing methods, noise is estimated only during speech pauses and these pauses are identified using Voice Activity Detector (VAD). This paper describes novel noise estimation method to estimate noise in non-stationary environments. This approach uses an algorithm that classifies noisy speech signal into pure speech, quasi speech and non-speech frames based on adaptive thresholds without using of VAD. Speech presence is determined by computing the ratio of the noisy <b>speech</b> <b>power</b> spectrum to its local minimum, which is computed by averaging past values of the noisy <b>speech</b> <b>power</b> spectra with a look-ahead factor. To evaluate proposed method performance, segmental SNR as evaluation criteria and compared with weighted average noise estimation method. The simulation results of the proposed algorithm shows better performance than conventional methods...|$|R
40|$|Two personalised <b>instantaneous</b> <b>speech</b> {{playback}} {{devices were}} designed and developed Both centred upon the memory efficiency advantages of Adaptive Differential Pulse Coded Modulation (ADPCM). One system is handheld and offers 64 seconds of speech. The second system hasdictionary of 230 four second phrases and is PC based. Medical Assessment: The problem of communication for the vocally handicapped is of grave concern. The communication aids currently available {{for this group}} of society include text-to-speech synthesizers and portable LPC coders (ref. 1 & 2). The use of these devices is restrictive due to poor quality speech and the use normally of a mid atlantic accent. Some offer good quality speech although are somewhat restrictive in use (ref. 3). The non-vocal physically handicapped also have few systems available to them for communication. The seventy of their disabilities normally limits their use such systems. Following {{a study conducted by}} the National Medical Rehabilitation Centre it became evident that a syntheziser system would have to preserve quality accent and sex. Also apparent from this study was the fact that full text-to-speech was not required by the majority of potential users but instead short well spoken phrases. Cost also had a bearing on the communication aid prescribed. A...|$|R
40|$|In this paper, {{we propose}} a perceptually-motivated method for modifying the <b>speech</b> <b>power</b> {{spectrum}} {{to obtain a}} set of linear prediction coding (LPC) parameters that possess good noiserobustness properties in network speech recognition. Speech recognition experiments were performed to compare the accuracy obtained from MFCC features extracted from AMR-coded speech that use these modified LPC parameters, {{as well as from}} LPCCs extracted from AMR bitstream parameters. The results show that when using the proposed LP analysis method, the recognition performance was on average 1. 2 % - 6. 1 % better than when using the conventional LP method, depending on the recognition task. Griffith Sciences, Griffith School of EngineeringFull Tex...|$|R
40|$|This {{paper is}} to {{investigate}} the effectiveness of Prontest software to improve English pronunciation and proficiency for Japanese EFL learners. Several parameters such as <b>speech</b> duration, <b>speech</b> <b>power,</b> F 0 (pitch), the ratio of vowel and consonant length and power were introduced {{to find out how}} much students made progress in English pronunciation and overall English proficiency. The study concluded that the average score of CASEC computer test improved from 532 (SD 109. 2) in April to 583 (SD 83. 1) in July after having used this software for six lessons. The differences of parameters between pre and post-recorded readings indicated that this software helped students to improve English pronunciation. 1...|$|R
40|$|There {{has been}} an {{increase}} in use of noninvasive positive-pressure ventilators (NPPV) to provide breathing assistance to people who are limited in their ability to breathe on their own as a result of neuromuscular impairment. To date, essentially nothing is known about how NPPV inspirations are used to <b>power</b> <b>speech,</b> beginning with whether or not individuals actually use their NPPV device for the purposes of speech. This project aimed to quantify inspirations that <b>power</b> <b>speech</b> in users of NPPV, and the amount of speech that followed NPPV <b>powered</b> <b>speech.</b> While participants claimed that NPPV helped them speak, NPPV was found to power only 37...|$|R
40|$|The article {{explores the}} concept of {{censorship}} viewed as an integral attribute of any society. The authors describe censorship as a “social blindfold” intended to eliminate the implications triggered by the information warfare. Analyzing the modern regime of restrictions and constraints, the authors explore such relevant concepts as freedom of <b>speech,</b> <b>power,</b> mass media, stereotypes and manipulative technologies shaping an illusionary reality for the people. Censorship {{is described as a}} factor of information warfare which aims to filter the information through manipulation of individual and mass consciousness. Summing up the results of the study, the authors define the status and goals of censorship in modern society...|$|R
40|$|A {{reliable}} speech presence probability (SPP) estimator {{is important}} to many frequency domain speech enhancement algorithms. It is known that a good estimate of SPP {{can be obtained by}} having a smooth a-posteriori signal to noise ratio (SNR) function, which can be achieved by reducing the noise variance when estimating the <b>speech</b> <b>power</b> spectrum. Recently, the wavelet denoising with multitaper spectrum (MTS) estimation technique was suggested for such purpose. However, traditional approaches directly make use of the wavelet shrinkage denoiser which has not been fully optimized for denoising the MTS of noisy speech signals. In this paper, we firstly propose a two-stage wavelet denoising algorithm for estimating the <b>speech</b> <b>power</b> spectrum. First, we apply the wavelet transform to the periodogram of a noisy speech signal. Using the resulting wavelet coefficients, an oracle is developed to indicate the approximate locations of the noise floor in the periodogram. Second, we make use of the oracle developed in stage 1 to selectively remove the wavelet coefficients of the noise floor in the log MTS of the noisy speech. The wavelet coefficients that remained are then used to reconstruct a denoised MTS and in turn generate a smooth a-posteriori SNR function. To adapt to the enhanced a-posteriori SNR function, we further propose a new method to estimate the generalized likelihood ratio (GLR), which is an essential parameter for SPP estimation. Simulation results show that the new SPP estimator outperforms the traditional approaches and enables an improvement in both the quality and intelligibility of the enhanced speeches. Department of Electronic and Information Engineerin...|$|R
5000|$|... 1961. The Future of Catholic <b>Power</b> <b>Speech</b> to DAR, Am. United Sep. C & S ...|$|R
