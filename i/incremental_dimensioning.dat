0|10|Public
40|$|Suspension {{bridge is}} an {{effective}} and efficient fixed-link to cross rivers or gorges. The advantages of suspension bridge compared with other bridges are: aesthethic performance and longer span where continuous short support along rivers or gorges is not possible. In designing a safe but fairly economical bridge, suitable structure dimensional must be considered. The suspension bridge has several dominan structural elements, such as main cable, hanger rod, main girder, and pylon. This {{research has been done}} by manual calculation and program analysis. The suspension footbridge model has 120 -meters span. Several structure element dimension variation is applied such as diameter of hanger rod, main cable, main girder profile inertia and pylon profile area. Service limit parameters such as: deflection, main girder maximum moment, backstay tensile load, main cable tensile load and pylon compression load have been considered. The influences of <b>incremental</b> <b>dimensions</b> on several service limit parameters have been summarized. An effort of enlarging structural element which provide significant influences on the service parameter is increase the dimension of main cable...|$|R
40|$|Dimension {{reduction}} {{is critical for}} many database and data mining applications, such as e#cient storage and retrieval of high-dimensional data. In the literature, a well-known dimension reduction scheme is Linear Discriminant Analysis (LDA). The common aspect of previously proposed LDA based algorithms {{is the use of}} Singular Value Decomposition (SVD). Due to the di#culty of designing an incremental solution for the eigenvalue problem on the product of scatter matrices in LDA, there is little work on designing incremental LDA algorithms. In this paper, we propose an LDA based <b>incremental</b> <b>dimension</b> reduction algorithm, called IDR/QR, which applies QR Decomposition rather than SVD. Unlike other LDA based algorithms, this algorithm does not require the whole data matrix in main memory. This is desirable for large data sets. More importantly, with the insertion of new data items, the IDR/QR algorithm can constrain the computational cost by applying e#cient QR-updating techniques. Finally, we evaluate the e#ectiveness of the IDR/QR algorithm in terms of classification accuracy on the reduced dimensional space. Our experiments on several real-world data sets reveal that the accuracy achieved by the IDR/QR algorithm is very close to the best possible accuracy achieved by other LDA based algorithms. However, the IDR/QR algorithm has much less computational cost, especially when new data items are dynamically inserted...|$|R
40|$|Abstract—Dimension {{reduction}} {{is a critical}} data preprocessing step for many database and data mining applications, such as efficient storage and retrieval of high-dimensional data. In the literature, a well-known dimension reduction algorithm is Linear Discriminant Analysis (LDA). The common aspect of previously proposed LDA-based algorithms {{is the use of}} Singular Value Decomposition (SVD). Due to the difficulty of designing an incremental solution for the eigenvalue problem on the product of scatter matrices in LDA, there has been little work on designing incremental LDA algorithms that can efficiently incorporate new data items as they become available. In this paper, we propose an LDA-based <b>incremental</b> <b>dimension</b> reduction algorithm, called IDR/QR, which applies QR Decomposition rather than SVD. Unlike other LDA-based algorithms, this algorithm does not require the whole data matrix in main memory. This is desirable for large data sets. More importantly, with the insertion of new data items, the IDR/QR algorithm can constrain the computational cost by applying efficient QR-updating techniques. Finally, we evaluate the effectiveness of the IDR/QR algorithm in terms of classification error rate on the reduced dimensional space. Our experiments on several real-world data sets reveal that the classification error rate achieved by the IDR/QR algorithm is very close to the best possible one achieved by other LDA-based algorithms. However, the IDR/QR algorithm has much less computational cost, especially when new data items are inserted dynamically...|$|R
40|$|This paper {{proposes a}} novel {{algorithm}} called low dimensional space incremental learning (LDSIL) {{to estimate the}} human motion in 3 D from the silhouettes of human motion multiview images. The proposed algorithm takes the advantage of stochastic extremum memory adaptive searching (SEMAS) and <b>incremental</b> probabilistic <b>dimension</b> reduction model (IPDRM) to collect new high dimensional data samples. The high dimensional data samples can be selected to update the mapping from low dimensional space to high dimensional space, so that incremental learning can be achieved to estimate human motion from small amount of samples. Compared with three traditional algorithms, the proposed algorithm can make human motion estimation achieve a good performance in disambiguating silhouettes, overcoming the transient occlusion, and reducing estimation error...|$|R
40|$|The {{emergent}} {{phenomenon of}} social manufacturing is disrupting industries {{all over the}} world. Social manufacturing represents a new collaborative manufacturing paradigm. The shift from the current manufacturing paradigm to social manufacturing is facilitated by rapid development of mobile technologies, new digital manufacturing, and online social networks. There are already successful businesses that build upon the social manufacturing paradigm, e. g., in finance, hospitality, and transportation: new banks are born without physical offices (ING Direct), the world’s greatest hotel chain does not own a single room (AirBnB), and a taxi company neither owns cars nor employs drivers (Uber). The objective {{of this study is}} to construct a model concerning the paradigm shift from current manufacturing to social manufacturing. The model for the paradigm shift incorporates various topics that are central in the transition process, such as 3 D printing, customization, value chains, and social networks. The model is divided into two phases. First, there is an intermediary phase of social manufacturing where customers will co-create with manufacturers. However, here manufacturers still control the manufacturing platform. This phase represents an <b>incremental</b> <b>dimension</b> of social manufacturing. Second, there is the fully-fledged social manufacturing phase that I call it the ultimate phase of social manufacturing. In this phase of social manufacturing, customers can become entrepreneurs, pursuing their ideas throughout the manufacturing value chain by using support from a public manufacturing platform. This phase represents the disruptive dimension of social manufacturing. To demonstrate the practicality of this study, the proposed model is then applied in the apparel industry for creating insights both to the intermediary and ultimate phases of social manufacturing within this field. Finally, opportunities and risks related to social manufacturing are discussed, the limitations of the study are presented, and future avenues of study are outlined...|$|R
40|$|In {{order to}} {{construct}} a reliable IP over WDM network, backup paths as well as primary paths should be embedded within a wavelength-routed topology (or logical topology). However, many conventional approaches assume that the traffic demand is known a priori. In this paper, we propose a new approach, called an <b>incremental</b> capacity <b>dimensioning</b> approach, to build the logical topology. Our incremental approach consists of three steps for designing the logical topology: an initial phase, an incremental phase, and a readjustment phase. By our approach, the logical topology can be adjusted according to the incrementally changing traffic demand. During the incremental phase, the backup lightpaths are reconfigured when the new primary path is set up since the backup lightpaths do not affect the carried traffic on the primary paths. Our proposed algorithm, called MRB (Minimum Reconfiguring for Backup lightpath), assigns the wavelength route {{in such a way}} that the number of backup lightpaths to be reconfigured is minimized. Then, the backup lightpaths are actually reconfigured. For this purpose, we also formulate an optimality problem for reconfiguring the backup lightpaths. Our results show the total traffic volume which the IP over WDM network can accommodate is improved by using our MRB algorithm...|$|R
40|$|Brains and {{computers}} represent and process sensory information in different ways. Bridgingthat gap {{is essential for}} managing and exploiting the deluge of unprocessed andcomplex data in modern information systems. The development of brain-like computersthat learn from experience and process information in a non-numeric cognitive way willopen up new possibilities {{in the design and}} operation of both sensor and informationcommunication systems. This thesis presents a set of simple computational principles with cognitive qualities,which can enable computers to learn interesting relationships in large amounts of datastreaming from complex and changing real-world environments. More specifically, thiswork focuses on the construction of a computational model for analogical mapping andthe development of a method for semantic analysis with high-dimensional arrays. A key function of cognitive systems is the ability to make analogies. A computationalmodel of analogical mapping that learns to generalize from experience is presented in thisthesis. This model is based on high-dimensional random distributed representations anda sparse distributed associative memory. The model has a one-shot learning process andan ability to recall distinct mappings. After learning a few similar mapping examplesthe model generalizes and performs analogical mapping of novel inputs. As a majorimprovement over related models, the proposed model uses associative memory to learnmultiple analogical mappings in a coherent way. Random Indexing (RI) is a brain-inspired dimension reduction method that was developedfor natural language processing to identify semantic relationships in text. Ageneralized mathematical formulation of RI is presented, which enables N-way RandomIndexing (NRI) of multidimensional arrays. NRI is an approximate, <b>incremental,</b> scalable,and lightweight <b>dimension</b> reduction method for large non-sparse arrays. In addition, itprovides low and predictable storage requirements, and also enables the range of arrayindices to be further extended without modification of the data representation. Numericalsimulations of two-way and ordinary one-way RI are presented that illustrate whenthe approach is feasible. In conclusion, it is suggested that NRI {{can be used as a}} tool tomanage and exploit Big Data, for instance in data mining, information retrieval, socialnetwork analysis, and other machine learning applications. Godkänd; 2012; 20120510 (bleemr); LICENTIATSEMINARIUM Ämnesområde: Industriell Elektronik/Industrial Electronics Examinator: Professor Jerker Delsing, Institutionen för rymd- och systemteknik, Luleå tekniska universitet Diskutant: PhD, Senior Lecturer Serge Thill, Humanities and Informatics, University of Skövde Tid: Måndag den 11 juni 2012 kl 10. 30 Plats: D 770, Luleå tekniska universite...|$|R
40|$|Reinforced {{concrete}} (RC) {{structures are}} usually subjected to {{various types of}} loadings, such as permanent, sustained and transient during their lifetime. Reinforced concrete slabs {{are one of the}} most fundamental structural elements in buildings and bridges, which might be exposed to unfavourable conditions such as, impaired quality control, lack of maintenance, adverse environmental effects, and inadequate initial design. Therefore, the resistant capacity of the affected elements would dramatically be reduced which most likely leads to the partial or whole collapse of the structure. Non-destructive testing (NDT) techniques can be used to inspect for defects without further damaging the tested component. Significant research and development have been conducted on the performance of vibration characteristics to identify damage in different types of structures. The vibrations based damage detection methods, particularly modal based methods, are found to be promising in evaluating the health condition of a structure in terms of detection, localisation, classification and quantification of the potential damage in the structure. Damage in composites and the non-homogeneous material is tricky to assess from a surface inspection alone. Although the development of NDTs, especially experimental modal analysis (EMA), has been pushed forward by the aerospace industry where composites materials are employed in many safety critical applications, EMA is not widely employed to diagnose all types of RC structural members. Damage detection in reinforced concrete square slabs is the primary aim of this study. This is achieved experimentally using experimental modal analysis (EMA) and numerically using finite element method (FEM). Artificial neural network (ANN) is also used in this study to classify the void sizes. A whole testing procedure of EMA on freely supported slab was established in this research. It is based on impact hammer technique, as a relevant excitation source for field measurements. After the quality of the measurements had been ensured, the experimental data was collected from four pairs laboratory-scale reinforced concrete slabs modelled with various ranges of parameters. After collecting data, Matlab software was employed to obtain modal parameters, such as natural frequencies, mode shapes and modal damping ratios from two RC square slabs. EMA and FEM studies were undertaken to assess and improve modelling technique for capturing the aim. FEM was used to model the RC slabs using commercial ANSYS software. To balance model simplicity of RC slabs with the ability to reliably predict their dynamic response, both predicted and measured dynamic results were compared to ensure that the analytical model represents the experimental results with reasonable accuracy. ANSYS software was also employed to numerically extract the natural frequencies of the slab. Then, using Matlab software, the extracted natural frequencies were fed as the input to the ANN to classify the void sizes in the slab. The dynamic properties of the slab were investigated for each of four pairs to evaluate modal parameters (natural frequencies, damping ratio and mode shapes) sensitivity to slab's dimensions, degree of damage owing to incremental loading and induced void. The performance of EMA based on impact hammer technique was credibly tested and verified on measurements, which were collected from eight slabs with various parameters. EMA efficiency was conclusively proved on data from modal parameters sensitivity to slab's <b>dimensions,</b> <b>incremental</b> loading and induced void. The results indicated that using a bigger reinforced concrete slabs (1200 x 1200 mm 2) could potentially have further reduced the discrepancy between theoretical (analytical and numerical) and experimental natural frequencies than smaller slabs (600 x 600 mm 2). In general, for the specimens tested slabs, natural frequencies were more sensitive to the damage introduced than the damping ratio because the damping did not consistently increase or decrease as damage increased. The changes in mode shapes tended to increase with increasing damage level. Even small damage induced poised changes to the mode shapes, but it may not be obvious visually. Utilising sophisticated methods for damage identification, which are vital steps in higher level of damage detection in structures, is one of the major contributions to the knowledge. The proposed Modal Assurance Criterion (MAC) and Coordinate Modal Assurance Criterion (COMAC) techniques as advanced statistical classification model were employed in this study. From the vibration mode shapes induced void location can be identified via MAC and COMAC techniques when both intact and damaged data were compared. MAC provided a clear change in the mode shape while the COMAC provided the change in specific a location whereby the location of damage was identified. The outcomes of this two techniques can show the realistic location of the void. Beside the aforementioned contributions in this research, the feasibility of a Feed-Forward Back Propagation Neural Network (FFBPNN) was investigated using ten natural frequencies as input and the void sizes as output. Excellent results were obtained for damage identification of four void sizes, showing that the proposed method was successfully developed for damage detection of slabs. The results proved that the precision of the models was reduced when dealing with small size void. The large size void was detected more accurately than small size void as expected. This is because the natural frequencies of the small void of different location attributed together. Therefore, natural frequencies alone were not considerably good enough to make good identifications for small size void. Moreover, the natural frequencies set of three untrained void specifications were used as FFBPNN inputs to test the performance of the neural networks. The obtained results show that the proposed network can predict the void specifications of the unseen data with high accuracy. Overall, the methodology followed in this work for damage detection in reinforced concrete square slabs is novel when compared to the breadth and depth of all other previous works carried out in the field of reinforced concrete structures...|$|R
40|$|Tez (Yüksek Lisans) [...] İstanbul Teknik Üniversitesi, Fen Bilimleri Enstitüsü, 2012 Thesis (M. Sc.) [...] İstanbul Technical University, Institute of Science and Technology, 2012 Bu tez kapsamında, üç boyutlu düzensiz bir yapı sisteminin doğrusal ve doğrusal olmayan analizleri DOC 3 B yapı analiz programı ile gerçekleştirilmiştir. Analizi için tasarlanmış olan yapıda kat planının sadece üst köşe elemanlarında birer perde eleman bulunmaktadır. Bu tip bir perde yerleşim seçimi ile yapı örneğine burulma düzensizliği kazandırılmıştır. Gerçek yapıyı doğru bir şekilde modellemek, doğru sonuçlar elde edebilmek için oldukça büyük önem taşımaktadır. Bu sebepten ötürü her bir yapı elemanı da hassas bir şekilde modellenmek zorundadır. Modelleme sırasında kirişler ve kolonlar çubuk eleman olarak modellenmektedirler, perdeler ise levha eleman kabul edilirler. Alternatif olarak ise perde elemanlar bazı basitleştirmeler sonucu çeşitli tekniklerle modellenebilmektedirler. Perdelerin modellenmesi için pek çok metot geliştirilmiştir. En bilinen modelleme metodu, geniş orta dikme kolon modelidir. Rijit kirişler ise, perdenin bulunduğu bölüm boyunca devam eder ve orta kolonun üst ucunda birleşirler. Bir diğer model, geniş orta dikme kolon modeline benzeyen gergili çerçeve modeldir. Orta dikme modelde bulunan elemanlara ek olarak yerleştirilmiş, uçlarında dönme serbestliği olduğu kabul edilen iki çapraz eleman perde alanının bir ucundan diğer ucuna kadar devam ederler. Bir başka modelde ise, perdenin her iki ucuna perde rijitliğinin yarısına sahip iki kolon eleman yerleştirilmesi ve perdenin kaldırılmasından ibarettir. Kolon elemanları üst noktalarından birbirine rijit bir kiriş bağlamaktadır. Bu tez kapsamında gerek perdelerin şekil yapısından ötürü, gerekse çerçeve sistemine uygunluğundan ötürü geniş orta dikme kolon modeli kullanılmıştır. Yapının modelleme metoduna karar verdikten sonra DOC 3 B programının sonuçlarının doğruluğu irdelenmiştir. Bunun için, hesap sonuçlarına güvenilen bir paket program, SAP 2000 kullanılmıştır. Doğrulama için her iki programda örnekler oluşturulmuş, hem statik hem de dinamik analiz sonuçları karşılaştırılmıştır. Oluşturulan örnek modellerden ilki tek katlı tek açıklıklı bir yapı, diğeri ise tez sırasında irdelenen düzensiz perdeli betonarme yapıdır. Statik analizler sonucunda kesit tesir değerleri ve deplasman değerleri, dinamik analizler sonucunda ise modlara ait titreşim periyotları yeter derecede yakın sonuçlar vermiştir. Program doğrulaması tamamlandıktan sonra yapı sistemi üç ayrı yapı modeli olarak tasarlanmış ve her bir modele sabit tek modlu itme analizi uygulanmıştır. Oluşturulan yapı modelleri, perdeye komşu olan kiriş ve döşemelerin farklı varyasyonlarından oluşmaktadır. Yapı modelleri hem x hem de y doğrultularında itme analizine tabi tutulmuş, simetrik olmayan doğrultularda her iki yönde itme analizi yapılmıştır. İtme analizleri sonucunda perde çevresinde meydana gelen döşeme boşluklarının, kat planındaki düzensizliklerin ve döşeme boşluğunu çevreleyen kirişlerin tasarımının yapıya olan etkileri incelenmiş, sonuçlar irdelenmiştir. In this M. Sc. thesis, a three {{dimensional}} {{and irregular}} structure analysed in linear and nonlinear manner {{by using a}} developed structural analysing programme DOC 3 B (Nonlinear analysis of orthogonal three dimensional structural systems). An irregular floor plan which includes two shear wall located at the top corners designed for analysis. Location of the shear walls decided which causes buckling irregularity. Creating an accurate structural model has a significant importance due to obtain convergent results with real structure. Therefore every member of structure have to be modelled with high accuracy and versatility. Beams and columns {{can be considered as}} frame sections nonetheless shear walls should be designed as area sections. Alternatively shear walls can be simplified by making some adjustments {{so that they can be}} defined as frame models. There are lots of methods for modelling shear walls. The well - known method is wide column frame model. It is described as a frame model at the middle surface of the shear wall and two rigid horizontal element connect that frame member from the top point. This method can be desired because of adopting it into developed analysing programmes easily and provide saving time by reducing analysing procedure. On the other hand, this acceptance cause much more rolative errors when comparing to other methods. Users always should be aware of this rolative errors cannot be ignored. Second method,the braced frame model, have common properties with wide column frame model. In this method, frame also includes horizontally rigid arms and braces, but the central column of the previous frame is omitted and replaced by a column on one vertical edge and a hinged link on the other. The results compare in accuracy with simple rectangular plane stress finite elements [Stafford Smith, Amal Girgis]. The braced frame model is more efficient than the braced wide column and it is also more consistent and accurate. The real issue of this method rigidity of braces. Third method uses two column which has half of the bending rigidity of shear wall and located at starting and ending points of this element. These two column connected to each other by a beam that has a significant bending rigidity (about infinite). This method uses systems own nodal points. Therefore it can be used easily at the simplified frame analysing programmes. Disadvantage of this method, locating of colums cause moments return into axial forces at columns. Moreover, obtained bending moments values are lower than true values. In this thesis wide column method selected for shear wall solutions due to shape of shear wall (L shape). Therefore central column turns compatible with the system frames. Furthermore, decreasing alaysing steps provide saving important time. These model the fastest method for solving shear wall problems. There dimensional structures only defined by using two dimensional sub - systems in DOC 3 B. DOC 3 B firstly create rigidity and force matrices of two dimensional sub - systems. Then programme combines these matrixes into three dimensional rigidity and force matrices. Because of defining sub - systems, beams horizontal and vertical rigidity values; columns and shear walls every rigidity values at every vertical sub - system defined seperately. Material properties defined at a different file and assigned every member at the sub - systems. These provides user with calculate true capacity behavior during analysis procedure. After selecting solution method, it is have to shown that DOC 3 B gives high accurate results with a programme that analysis results are proved. Because of this reason, a worldwide known programme, SAP 2000 used in this thesis for comparison. Verifications made on two models that one of a simply frame model and other one is main model used in thesis. Besides two new specifications of DOC 3 B tested first time at this step. The first specification is defining uniform distributed load on frame elements. The second is set of equations at the direction of z. Moreover second specification also provide that assign loads at any direction. Firstly, vertical loads assigned frame members of models and a horizontal point load assigned just one point to cause torsion at the simple model. Bending moments, shear and axial forces and nodal points displacements compared after static analysis. These control parameters have nearly same values and displacement values proved occuring of torsion. Free vibration modes compared at the dynamic analysis step. According to analysis results first three mode found as 1. 873, 1. 368 and 0. 502 s by using DOC 3 B and 1. 880, 1. 372 and 0. 505 s by using SAP 2000. These results proved DOC 3 B gives accurate results. After linear analysis and proving DOC 3 B, nonlinear analysis is made for determining performance capacity of structure. Structural performance is defined by damages of structural members. General acceptance in performance based design provide life safety performance level after earthquakes that has a probability of exceedance of 10 %/ 50 years. Nonlinear push-over analysis apllied to the structural model for determining performance level. Turkish Seismic Code 2007 includes several nonlinear analysis procedures. These are incremental equivalant earthquake load method, incremental mode combining method and nonlinear time history analysis. Structural model pushed by using incremental equivalant earthquake load method in this study due to DOC 3 B has not coded for changable modes and nonlinear time history analysis yet. Nonlinear incremental push over analysis can be subjected to structures by using several methods. The simplest push over method is constant single mode push over. Force applied to the structural modal according to dominant mode. Until structure reaches the collapse mode, it is pushed. The other method is flexible single mode push over analysis. This method accepts building modes change after every pushing step. Pushing step increases when a structural member reach its own capacity. Therefore the force vector applied to the structural model has to be calculated at any pushing step. Because of structural model has irregularity, firstly it should be decided that which direction structural model pushed along. Because of that base shear forces and top displacements compared to each other at both directions (x and y). Comparisons showed, although pushig only one direction is enough at the direction of symmetry, structural model should be pushed at any direction at the non-symmetrical direction. Three different structural model created by making some changes in floor plan. First model has no changes in floor plan. The second model has floor gaps next to the shear walls. The third model, capacity of beams, which around the floor gaps, increase by using more wide <b>dimensions.</b> <b>Incremental</b> push over analysis performed on every model. After that performance analysis is made for structural elements chosen randomly. Results showed that floor gaps cause an incremantation at top displacement nevertheless when beam around the gaps changes with much more rigid elements this incrementation can be prevented. Modal capacity diagrams are the proof of this situation. Strains of structural elements have very small values so that when comparing the hazard levels there is no differences between three model. However when comparing the strain values instead of hazard levels, floor gaps cause an incremantation up to 100 %. This situation cause beams around the gaps reaches their capacities much more earlier and make shear walls independent members from whole structure. This situation shows that if there are floor gaps, beams around them should be more rigid to prevent torsion and also reaching structure s capacity. DOC 3 B, the programme used in this whole study, is still in development process. DOC 3 B able to cope with lineer and nonlineer analysis, push over analysis and can calculate strain and stress values at any cross - section. This provide user with making performance analysis easier and faster. The reasons of development of DOC 3 B is produce a programme that has specifications listed below; • Capable with nonlinear analysis much more easily • User friendly • Local producement • Can be rival to the other structural analysis programmes. However DOC 3 B still have some disadvantages like listed below; • it is not possible making time domain analysis • Only three degree of freedom can be defined at nodal points • Data inputting takes important time and it is highly possible making mistakes. Yüksek LisansM. Sc...|$|R

