24|1307|Public
3000|$|... iso the {{normalized}} {{covariance matrix}} of the spatially isotropic (<b>diffuse)</b> <b>noise</b> <b>field</b> [20]. In particular, we assume cylindrically isotropic noise, i.e., sound coming {{from all directions}} in the horizontal plane with equal probability.|$|E
40|$|Cross-correlating ocean {{noise is}} a {{potential}} alternative to using active sources to monitor and study ocean environments. However, directional sources in the medium (usually ships) often introduce a bias in the cross-correlations, making the travel time estimates unreliable. Here, we use recent results in random matrix theory for the eigenvalue density of isotropic noise sample covariance matrices to separate the directional noise from the <b>diffuse</b> <b>noise</b> <b>field.</b> The eigenvalues obtained from ocean data agree well with the theoretical results. Beamforming on the diffuse noise components reveals a fairly spatially isotropic nature for the noise field, which fits the assumption. The cross-correlations using the <b>diffuse</b> <b>noise</b> <b>field</b> alone converge to the expected travel times (i. e., unbiased estimates) and are stable temporally. Index Terms — Passive acoustics, environment monitoring, isotropic noise, sample covariance matrix, eigenvalue densit...|$|E
30|$|When input signals involve interchannel cor{{relation}}, {{the relation}} between input kurtosis and output kurtosis after DS approaches that for only one microphone. If all input signals are identical signals, that is, the signals are completely correlated, the output after DS also becomes {{the same as the}} input signal. In such a case, the effect of DS on the change in kurtosis corresponds to that for only one microphone. However, the interchannel correlation is not equal to one within all frequency subbands for a <b>diffuse</b> <b>noise</b> <b>field</b> that is a typically considered noise field. It is well known that the intensity of the interchannel correlation is strong in lower-frequency subbands and weak in higher-frequency subbands for the <b>diffuse</b> <b>noise</b> <b>field</b> [1]. Therefore, in lower-frequency subbands, it can be expected that DS does not significantly reduce the kurtosis of the signal.|$|E
40|$|In this research, we have {{evaluated}} {{the performance of}} a new hybrid noise reduction system in various real-life <b>noise</b> <b>fields</b> occurring in mobile and vehicular applications. The noise reduction block is composed of a Subband Adaptive Filter (SAF) followed by Wiener filtering. For system evaluation, we have used recordings of real-life noises to contaminate speech materials chosen from the TIMIT database. It is shown that all the recorded noises are samples of <b>diffuse</b> <b>noise</b> <b>fields.</b> As a result, the hybrid system outperforms both the SAF and standard Wiener filtering in all sets of the recordings. The preference of this hybrid system is especially noted in the case of lowpass noise and intense noise conditions. 1...|$|R
40|$|Measurements {{have been}} made of {{coherence}} and phase spectra for the acoustic field in a subsonic wind tunnel. The data are interpreted in terms of simple analytical models for propagating and <b>diffuse</b> <b>noise</b> <b>fields,</b> including the presence of uncorrelated noise signals. It is found that low frequency noise propagates upstream and downstream from the fan, with the noise in the test section arriving in the upstream direction. High frequency sound appears to be generated in the test section and propagates upstream and downstream. In the low frequency range, the ratio of diffuse to propagating energy is about 8 for all locations in the test section, diffuser, and settling chamber; {{the value of the}} ratio increases with frequency. Further analysis is required to describe in better detail the effects of reverberation and incoherent sources in a duct-like environment...|$|R
40|$|This paper {{presents}} a minimum mean-square error spectral phase estimator for speech enhancement in the distributed multiple microphone scenario. The estimator uses Gaussian models {{for both the}} speech and noise priors under the assumption of a <b>diffuse</b> incoherent <b>noise</b> <b>field</b> representing ambient <b>noise</b> in a widely dispersed microphone configuration. Experiments demonstrate significant benefits of using the optimal multichannel phase estimator {{as compared to the}} noisy phase of a reference channel...|$|R
30|$|In this paper, a new noise PSD {{estimator}} for a binaural {{speech enhancement}} {{system that can}} be operated in a fast time-varying <b>diffuse</b> <b>noise</b> <b>field</b> is presented. First, it is established that noise PSD can be estimated from the eigenvalues of the input covariance matrix without dependence on the target speech direction. Then, a method of approximating the obtained noise PSD is presented. The {{result is that the}} smaller eigenvalue is combined with the noise correlation function and the binaural phase difference.|$|E
30|$|As it is {{well known}} that the interchannel {{correlation}} for a <b>diffuse</b> <b>noise</b> <b>field</b> between two measurement locations can be expressed by the sinc function [1], we can state how array signal processing is affected by the interchannel correlation. However, we cannot know exactly how cumulants are changed by the interchannel correlation because (18) only holds when signals are mutually independent. Therefore, we cannot formulate how kurtosis is changed via DS for signals with interchannel correlation. For this reason, we experimentally investigate the effect of interchannel correlation in the following.|$|E
40|$|A blind source {{separation}} {{technique in}} noisy environment is proposed based on spectral masking and minimum variance distortionless response (MVDR) beamformer (BF). Formulating the maximum-likelihood {{of the direction}} of arrivals (DOAs) and solving it using the expectation-maximization, enables the extraction of the masks and the associated MVDR BF as byproducts. The proposed direction of arrival estimator uses an explicit model of the ambient noise, which results in more accurate DOA estimates and good blind source separation. The experimental study demonstrates both the DOA estimation results and the separation capabilities of the proposed method using real room impulse responses in <b>diffuse</b> <b>noise</b> <b>field...</b>|$|E
40|$|Abstract—The minimum {{variance}} distortionless response (MVDR) beamformer, {{also known as}} Capon’s beamformer, is widely studied {{in the area of}} speech enhancement. The MVDR beamformer can be used for both speech dereverberation and noise reduction. This paper provides new insights into the MVDR beamformer. Specifically, the local and global behavior of the MVDR beamformer is analyzed and novel forms of the MVDR filter are derived and discussed. In earlier works it was observed that there is a tradeoff between the amount of speech derever-beration and noise reduction when the MVDR beamformer is used. Here, the tradeoff between speech dereverberation and noise reduction is analyzed thoroughly. The local and global behavior, as well as the tradeoff, is analyzed for different <b>noise</b> <b>fields</b> such as, for example, a mixture of coherent and non-coherent <b>noise</b> <b>fields,</b> entirely non-coherent <b>noise</b> <b>fields</b> and <b>diffuse</b> <b>noise</b> <b>fields.</b> It is shown that maximum noise reduction is achieved when the MVDR beamformer is used for noise reduction only. The amount of noise reduction that is sacrificed when complete dereverber-ation is required depends on the direct-to-reverberation ratio of the acoustic impulse response between the source and the reference microphone. The performance evaluation supports the theoretical analysis and demonstrates the tradeoff between speech dereverberation and noise reduction. When desiring both speech dereverberation and noise reduction, the results also demonstrate that the amount of noise reduction that is sacrificed decreases when the number of microphones increases. Index Terms—Beamforming, microphone arrays, {{minimum variance}} distortionless response (MVDR) filter, noise reduction, Pearson correlation coefficient, speech dereverberation, speech enhancement. I...|$|R
40|$|In this paper, {{we propose}} a novel noise power {{spectral}} density (PSD) estimator which is beneficial for speech enhancement systems with two microphones in <b>diffuse</b> <b>noise</b> environments. The algorithm has a low computational complexity and requires low memory usage. The main advantage is that arbitrary models of the <b>noise</b> <b>field</b> coherence can be employed and a scalable extension of existing single-channel speech enhancement systems to dual channels is also possible. Experiments demonstrate with simulated and measured data that the proposed algorithm outperforms related algorithms in <b>diffuse</b> <b>noise</b> conditions. 1...|$|R
40|$|Recent {{theoretical}} and experimental {{studies have demonstrated}} that an estimate of the Green's function between two hydrophones can be extracted passively from the cross‐correlation of ambient noise recorded at these two points. Hence monitoring the temporal evolution of these estimated Green's functions can provide a means for noise‐based acoustic tomography using a distributed sensor network. However, obtaining unbiased Green's function estimate requires a sufficiently spatially and temporally <b>diffuse</b> ambient <b>noise</b> <b>field.</b> Broadband ambient <b>noise</b> ([200 Hz- 20 kHz]) was recorded continuously for 2 days during the SWAMSI 09 experiment (next to Panama City, FL) using two moored vertical line arrays (VLAs) spanning 7. 5 m of the 20 ‐m water column and separated by 150 m. The feasibility of noise‐based acoustic tomography ([300 - 1000 Hz]) was assessed in this dynamic coastal environment over the whole recording period. Furthermore, coherent array processing of the computed ocean noise cross‐correlations between all pairwise combinations of hydrophones was used to separate acoustic variations between the VLAs caused by genuine environmental fluctuations-such as internal waves-from the apparent variations in the same coherent arrivals caused when the ambient <b>noise</b> <b>field</b> becomes strongly directional, e. g., due to an isolated ship passing {{in the vicinity of the}} VLAs. M. S. Committee Chair: Sabra Karim; Committee Member: Peng Zhigang; Committee Member: Trivett Davi...|$|R
40|$|Most {{previously}} proposed dual-channel coherent-to-diffuse-ratio (CDR) estimators {{are based}} on a free-field model. When used for binaural signals, e. g., for dereverberation in binaural hearing aids, their performance may degrade due to the influence of the head, even when the direction-of-arrival of the desired speaker is exactly known. In this paper, the head shadowing effect is taken into account for CDR estimation by using a simplified model for the frequency-dependent interaural time difference and a model for the binaural coherence of the <b>diffuse</b> <b>noise</b> <b>field.</b> Evaluation of CDR-based dereverberation with measured binaural impulse responses indicates that the proposed binaural CDR estimators can improve PESQ scores. Comment: accepted for EUSIPCO 201...|$|E
30|$|In {{order to}} assess the {{detrimental}} effect that such DOA error could have {{on the performance of}} the MVDR beamformer, one may examine its corresponding beampattern. Figure 4 (bottom) depicts the beampattern of the MVDR beamformer computed using the noise coherence matrix of a theoretically <b>diffuse</b> <b>noise</b> <b>field</b> as in (11), steered towards the zero degrees direction, and using the microphone configuration described in Section 5.1. By observing the width of the main lobe, it appears that the error in DOA is small enough to not introduce distortions in rooms S 1 and S 2. Some cancellation of the target speech signal may occur in room S 3 but should be limited to frequencies higher than 4 kHz.|$|E
40|$|This paper {{discusses}} {{signal processing}} methods for speech extraction in use with voice communication {{applications such as}} personal digital assistants (PDA), mobile telephone terminals and personal computers. The user is distant from the device and thus the speech signal entering the device {{may be subject to}} reverberation and may be disturbed by background noise. The proposed structure consists of a microphone array which allows for techniques of directional processing. Thus it is able to enhance a desired speech source and suppress other speech sources in the background. Three different optimal beamforming methods are considered in a real world car hands-free environment: an optimal near-field array gain optimization procedure, a theoretical <b>diffuse</b> <b>noise</b> <b>field</b> model for a point source and a least squares solutio...|$|E
40|$|This paper {{deals with}} joint {{suppression}} of <b>diffuse</b> <b>noise</b> and rever-beration, to enhance perceived speech quality and speech recogni-tion performance. Although <b>diffuse</b> <b>noise</b> and reverberation are both omnipresent {{in the real}} world, conventional methods have modeled only one while neglecting the other. In contrast, we propose a novel joint suppression method that employs a unified probabilistic model of observed signals affected by both <b>diffuse</b> <b>noise</b> and reverberation. Through likelihood maximization, this unified model enables proper parameter estimation {{that takes into account}} both <b>diffuse</b> <b>noise</b> and reverberation. As a byproduct, we also propose a novel method for <b>diffuse</b> <b>noise</b> suppression. Experimental results demonstrate the ef-fectiveness of the proposed joint suppression method in terms of dereverberation and denoising. Index Terms — Denoising, dereverberation, <b>diffuse</b> <b>noise,</b> expectation-maximization, speech enhancement...|$|R
40|$|International audienceThis paper {{presents}} crystal-MUSIC, {{a method}} for DOA estimation of multiple sources {{in the presence of}} <b>diffuse</b> <b>noise.</b> MUSIC is well known as {{a method for}} the estimation of the DOAs of multiple sources but is not very robust to <b>diffuse</b> <b>noise</b> from many directions, because the covariance structure of such noise is not spherical. Our method makes it possible for MUSIC to accurately estimate the DOAs by removing the contribution of <b>diffuse</b> <b>noise</b> from the spatial covariance matrix. The denoising of the matrix (i. e. removal of the <b>diffuse</b> <b>noise</b> component) consists of two steps: 1) denoising of the off-diagonal entries via a blind noise decorrelation using crystal-shaped arrays, and 2) denoising of the diagonal entries through a low-rank matrix completion technique. The denoising process does not require the spatial covariance matrix of <b>diffuse</b> <b>noise</b> to be known, but relies only on an isotropy feature of <b>diffuse</b> <b>noise.</b> Experimental results with real-world noise show that the DOA estimation accuracy is substantially improved compared to the conventional MUSIC...|$|R
40|$|We propose two {{algorithms}} for jointly {{estimating the}} power spectrogram {{and the room}} transfer functions of a target signal in <b>diffuse</b> <b>noise.</b> These estimates {{can be used to}} design a multichannel Wiener filter, and thereby separate a target signal from an unknown direction from <b>diffuse</b> <b>noise.</b> We express a <b>diffuse</b> <b>noise</b> model as a subspace of a matrix linear space, which consists of Hermitian matrices instead of Euclidean vectors. This general framework enables the design of new general algorithms applicable to all specific noise models, instead of multiple specific algorithms each applicable to a single model. The more general proposed algorithms resulted in superior noise suppression performance to our previous algorithms in terms of an output signal-to-noise ratio (SNR). Index Terms — <b>Diffuse</b> <b>noise,</b> microphone arrays, multichannel Wiener filter, noise suppression, speech enhancement...|$|R
40|$|We {{present a}} new {{adaptive}} microphone array efficiently implemented as a multi-channel FFT-filterbank. The array design {{is based on}} a minimum variance distortionless response (MVDR) optimization criterion. MVDR beamformer weights are updated for each signal frame using an estimated spatio-spectral correlation matrix of the environmental noise field. We avoid matrix inversion by means of an iterative algorithm for weight vector computation. The beamformer performance is superior to designs based on an assumed homogeneous <b>diffuse</b> <b>noise</b> <b>field.</b> The new design also outperforms LMS-adaptive beamformers at the expense of a higher computational load. Additional noise reduction is achieved with the well-known beamformer/postfilter combination of the optimum multi-channel filter. An Ephraim-Malah spectral amplitude modification with minimum statistics noise estimation is employed as a postfilter. Experimental results are presented using sound recordings in a reverberant noisy room. 1...|$|E
40|$|Dereverberation for {{multichannel}} {{hearing aids}} {{is still a}} field of extensive research. If a single desired source is assumed, many binaural spatial filtering techniques such as the minimum variance distortionless response beamformer or the rank-one multichannel Wiener filter (MWF) distort the binaural cues of the residual undesired signal components. A recently proposed spatial filter minimizes the mean squared error plus an additional cost function to preserve the long-term interaural coherence of a <b>diffuse</b> <b>noise</b> <b>field</b> between the hearing aid signals. In this paper, we adapt this approach to binaural dereverberation by modeling the reverberation as a time-varying diffuse sound field. Using this approach, {{a considerable amount of}} reverberation and noise reduction can be achieved. Experimental results show that we can preserve the coherence at the output without significantly impairing the reverberation and noise reduction performance...|$|E
40|$|In this paper, {{a hybrid}} post-filter for {{microphone}} arrays {{with the assumption}} of a <b>diffuse</b> <b>noise</b> <b>field</b> is proposed to suppress correlated as well as uncorrelated noise. In the proposed post-filter, a modified Zelinski post-filter, which is estimated using the signals on the microphone pairs on which noises are uncorrelated by considering the correlation characteristics of noise impinging on different microphone pairs, {{is applied to the}} high frequencies to suppress spatially uncorrelated noise; a single-channel Wiener post-filter is applied to the low frequencies for cancellation of spatially correlated noise. In theory, the proposed post-filter is a Wiener post-filter. In practice, experiments using multi-channel recordings were conducted, and experimental results demonstrate the usefulness and superiority of the proposed post-filter compared to other post-filters using speech quality measures and speech recognition rate...|$|E
3000|$|... {{present in}} the BSS inputs and {{originating}} from the external point sources and from the <b>diffuse</b> <b>noise,</b> respectively. As mentioned in Section 4.1, the BSS algorithm allows to separate point sources, additional <b>diffuse</b> <b>noise</b> having only a limited impact on the separation performance [32]. We therefore concentrate on the first term in (68): [...]...|$|R
40|$|National audienceIn this paper, {{we propose}} {{a method for}} {{estimating}} the azimuths of multiple sound sources accurately even {{in the presence of}} <b>diffuse</b> <b>noise.</b> MUSIC (MUltiple SIgnal Classification) for the estimation of the azimuths of multiple sources is robust against spatially white noise but the estimation performance degrades in the presence of <b>diffuse</b> <b>noise.</b> Based on a low-rank assumption on the covariance matrix of directional signals and the assumption that the covariance matrix of <b>diffuse</b> <b>noise</b> belongs to a subspace in a matrix space, the proposed method estimates the covariance matrix of the directional signals and applies MUSIC to the estimated matrix. The subspace model on the covariance matrix of <b>diffuse</b> <b>noise</b> includes as special cases noise models such as spatially uncorrelated noise, noise with a given coherence matrix, and isotropic noise observed with a crystal array. We showed through experiments with real-world noise recordings that the proposed method estimated the azimuths of multiple sources more accurately than the conventional MUSIC...|$|R
40|$|A multimicrophone speech {{enhancement}} algorithm for binaural hearing aids that preserves interaural time delays was proposed recently. The algorithm {{is based on}} multichannel Wiener filtering and relies on a voice activity detector (VAD) for estimation of second-order statistics. Here, {{the effect of a}} VAD on the {{speech enhancement}} of this algorithm was evaluated using an envelope-based VAD, and the performance was compared to that achieved using an ideal error-free VAD. The performance was considered for stationary directional <b>noise</b> and nonstationary <b>diffuse</b> <b>noise</b> interferers at input SNRs from 10 to + 5 dB. Intelligibility-weighted SNR improvements of about 20 dB and 6 dB were found for the directional and <b>diffuse</b> <b>noise,</b> respectively. No large degradations (< 1 dB) due to the use of envelope-based VAD were found down to an input SNR of 0 dB for the directional noise and 5 dB for the <b>diffuse</b> <b>noise.</b> At lower input SNRs, the improvement decreased gradually to 15 dB for the directional noise and 3 dB for the <b>diffuse</b> <b>noise.</b> 12 page(s...|$|R
40|$|Abstract In this paper, {{a hybrid}} post-filter for {{microphone}} arrays {{with the assumption}} of a <b>diffuse</b> <b>noise</b> <b>field</b> is proposed to suppress correlated as well as uncorrelated noise. In the proposed post-filter, a modified Zelinski post-filter, which is estimated using the signals on the microphone pairs on which noises are uncorrelated by considering the correlation charac-teristics of noise impinging on different microphone pairs, {{is applied to the}} high frequencies to suppress spatially uncorrelated noise; a single-channel Wiener post-filter is applied to the low frequencies for cancellation of spatially correlated noise. In theory, the proposed post-filter is a Wiener post-filter. In practice, experiments using multi-channel recordings were conducted, and experimental results demonstrate the usefulness and superiority of the proposed post-filter compared to other post-filters using speech quality measures and speech recognition rate. Keyword microphone array; diffuse noise filed; coherence function; hybrid post-filter...|$|E
40|$|This paper {{proposes a}} novel {{technique}} for estimating the signal {{power spectral density}} {{to be used in}} the transfer function of a microphone array post-filter. The technique is a modification of the existing Zelinski post-filter, which uses the auto- and crossspectral densities of the array inputs to estimate the signal and noise spectral densities. The Zelinski technique, however, assumes zero cross-correlation between noise on different sensors. This assumption is inaccurate in real conditions, particularly at low frequencies and for arrays with closely spaced sensors. In this paper we replace this with an assumption of a theoretically <b>diffuse</b> <b>noise</b> <b>field,</b> which is more appropriate in a variety of realistic noise environments. In experiments using noise recordings from an office of computer workstations, the modified post-filter results in significant improvement in terms of objective speech quality measures and speech recognition performance...|$|E
30|$|To {{realize the}} MWF, an {{estimate}} of the second-order statistics (SOS) of the noise signals is required. Based on the assumption of a <b>diffuse</b> <b>noise</b> <b>field,</b> several methods are derived for estimating the SOS of the noise components in terms of the auto-power spectral density (PSD) [13 – 15] or the cross PSDs between all channels for both the target source(s) and the noise and interference components [16]. Furthermore, it was recently proposed to exploit the direct-to-diffuse ratio (DDR) to realize the MWF for stationary noise and babble noise conditions [17]. It was also suggested to exploit the position information to estimate the cross PSDs of directional speech interferences [18]. For unsupervised algorithms, prior spatial information such as information about the source positions or the sensor constellation is often incorporated to improve the robustness. Model-based multichannel approaches [6, 7] can incorporate the directional information by initialization of a part of the spatial model. Parra and Alvino [19] proposed to combine an ICA algorithm with geometric constraints in order to improve the separation performance, where BSS was regarded as a set of beamformers whose response is constrained to a set of DoAs for recovering all sources from the mixture. Inspired by [19], Directional BSS [20] was proposed to serve as a blocking matrix (BM) when using a different constraint for the opposite purpose: this constraint forces essentially a spatial null towards a certain direction in order to suppress the target source and to preserve the interfering and noise components. The precondition not only for Directional BSS but also for Parra’s method is that the DoA information on the target source(s) must be given. Furthermore, based on the noise estimate produced by Directional BSS, a two-unit source extraction/noise reduction scheme combining a BM and a noise reduction unit was proposed in [21], where the spectral weights in the noise reduction stage are designed based on a <b>diffuse</b> <b>noise</b> <b>field</b> assumption. In this paper, we focus on the discussion of Directional BSS operating as a BM.|$|E
40|$|International audienceWe propose two {{algorithms}} for jointly {{estimating the}} power spectrogram {{and the room}} transfer functions of a target signal in <b>diffuse</b> <b>noise.</b> These estimates {{can be used to}} design a multichannel Wiener filter, and thereby separate a target signal from an unknown direction from <b>diffuse</b> <b>noise.</b> We express a <b>diffuse</b> <b>noise</b> model as a subspace of a matrix linear space, which consists of Hermitian matrices instead of Euclidean vectors. This general framework enables the design of new general algorithms applicable to all specific noise models, instead of multiple specific algorithms each applicable to a single model. The more general proposed algorithms resulted in superior noise suppression performance to our previous algorithms in terms of an output signal-to-noise ratio (SNR) ...|$|R
3000|$|Since a two-channel ICA-based BSS {{algorithm}} {{can only}} separate two point sources (Section 4.1), no <b>diffuse</b> <b>noise</b> {{has been added}} to the sensor signal mixture (i.e., [...]...|$|R
40|$|ICASPP 2010 : IEEE International Conference on Acoustics, Speech, and Signal Processing, March 14 - 19, 2010, Dallas, Texas, USA. Several recent {{methods for}} speech {{enhancement}} in presence of <b>diffuse</b> background <b>noise</b> use frequency domain blind signal separation {{to estimate the}} <b>diffuse</b> <b>noise</b> and a nonlinear post filter to suppress this estimated noise. This paper presents a frequency domain blind signal extraction method for estimating the <b>diffuse</b> <b>noise</b> {{in place of the}} frequency domain blind signal separation. The method is based on the minimization by means of a complex Newton algorithm of a cost function depending of the modulus of the extracted component. The proposed complex Newton method is compared to the gradient descent on the same cost function and to the blind signal separation approach...|$|R
40|$|Abstract—This paper {{addresses}} {{application of}} missing data recovery via matrix completion for audio sensor network. We propose a method based on Euclidean distance matrix completion for ad-hoc microphone array location calibration. This method can calibrate a full network from partial connectivity information. The pairwise distances of microphones {{in close proximity}} are estimated using the coherence model of the <b>diffuse</b> <b>noise</b> <b>field.</b> The distance matrix of the ad-hoc network is constructed where the distances of the microphones above a threshold are missing. We exploit the low-rank property of the squared distance matrix and apply a matrix completion method to recover the missing entries. In order to constrain the Euclidean space geometry, we propose the additional use of the Cadzow algorithm for matrix completion. The applicability of the proposed method is evaluated on real data recordings where a significant improvement over the state-of-the-art is achieved. Index Terms—Ad-hoc microphone calibration, Diffuse noise coherence, Matrix completion, Cadzow algorithm I...|$|E
40|$|In {{this paper}} we present an {{analysis}} of the generalized sidelobe canceller (GSC). It can be shown that the theoretical limits of the noise reduction performance depend only on the auto- and crossspectral densities of the input signals. Furthermore, we compute the limits of the noise reduction performance for the theoretically determined <b>diffuse</b> <b>noise</b> <b>field,</b> which is an approximation for reverberant rooms. Our results will show that the GSC cannot reduce noise further than 1 dB. These results were verified by simulation of reverberant environments. Only in sound-proof rooms with a reverberation time less than 100 ms the GSC performs well. 1. INTRODUCTION Noise reduction in speech communication is still an unsolved problem in the signal processing society. The problem is that the desired speech signal and the environmental noise overlap in the time- and in the frequency domain. One way of separating the signals is to use different spatial characteristics, but to get spatial information we [...] ...|$|E
40|$|To {{harvest the}} {{potential}} of multi-channel noise reduction methods, {{it is crucial to}} have an accurate estimate of the noise correlation ma-trix. Existing algorithms either assume speech absence and exploit a voice activity detector (VAD), or make use of additional assump-tions like a <b>diffuse</b> <b>noise</b> <b>field.</b> Therefore, these algorithms are lim-ited with respect to their tracking speed and the type of noise fields for which they can estimate the correlation matrix. In this paper we present a new method for noise correlation ma-trix estimation that makes no assumptions about the type of noise field, nor uses a VAD. The presented method exploits the existence of accurate single-channel noise PSD estimators, as well as the avail-ability of one noise reference per microphone pair. For spatially and temporally non-stationary noise fields, the proposed method leads to improved performance compared to widely used state-of-the-art reference methods in terms of both segmental SNR and beamformer response error. Index Terms — Speech enhancement, noise correlation matrix, multi-microphone 1...|$|E
30|$|Many {{practical}} noise situations, however, have to {{be modeled}} as <b>diffuse</b> <b>noise</b> [22], with high correlation in the low frequencies. Therefore, the noise PSD is underestimated especially at low frequencies.|$|R
30|$|To {{evaluate}} the performance for different reverberation, simulated data was used. RIRs were computed using the simulator in [37]. <b>Diffuse</b> <b>noise</b> was simulated {{as described in}} [34] and the microphone signals were obtained by adding the speech signals convolved with the RIRs, the <b>diffuse</b> <b>noise</b> signal, and spatially and temporally uncorrelated noise signal. The processing was done at a sampling rate of 16 kHz, with an STFT frame length of 64 ms with 50 % overlap, windowed by a Hamming window. Unless stated otherwise, the DOA estimator with instantaneous phase differences, described in Section 3.1 was employed.|$|R
40|$|Abstract—Linear {{microphone}} arrays {{combined with}} the min-imum variance distortionless response (MVDR) beamformer have been widely studied in various applications to acquire desired sig-nals and reduce the unwanted noise. Most of the existing array sys-tems assume that the desired sources are in the broadside direc-tion. In this paper, we study and analyze {{the performance of the}} MVDR beamformer {{as a function of the}} source incidence angle. Using the signal-to-noise ratio (SNR) and beampattern as the cri-teria, we investigate its performance in four different scenarios: spatially white <b>noise,</b> <b>diffuse</b> <b>noise,</b> diffuse-plus-white noise, and point-source-plus-white noise. The results demonstrate that the op-timal performance of the MVDR beamformer occurs when the source is in the endfire directions for <b>diffuse</b> <b>noise</b> and point-source noise while its SNR gain does not depend on the signal incidence angle in spatially white noise. This indicates that most current sys-tems may not fully exploit the potential of theMVDR beamformer. This analysis does not only help us better understand this algo-rithm, but also helps us design better array systems for practical applications. Index Terms—Beamforming, <b>diffuse</b> <b>noise,</b> microphone arrays, minimum variance distortionless response (MVDR) beamformer, noise reduction, spatially white noise, speech enhancement. I...|$|R
