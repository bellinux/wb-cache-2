197|10000|Public
25|$|Yang, J. and Honavar, V. (1999). DistAl: An Inter-Pattern Distance Based Constructive Neural Network Learning Algorithm.. <b>Intelligent</b> <b>Data</b> <b>Analysis.</b> Vol. 3. pp.55–73.|$|E
2500|$|Quafafou M. and Boussouf M. (2000). Generalized rough sets based feature selection. Journal <b>Intelligent</b> <b>Data</b> <b>Analysis,</b> 4:1 pp3 – 17 ...|$|E
5000|$|Yang, J. and Honavar, V. (1999). DistAl: An Inter-Pattern Distance Based Constructive Neural Network Learning Algorithm.. <b>Intelligent</b> <b>Data</b> <b>Analysis.</b> Vol. 3. pp. 55-73.|$|E
50|$|Infocomm {{will make}} Singapore a premier wealth {{management}} centre, with <b>intelligent</b> <b>data</b> management and <b>analysis</b> and efficient back- office processes and the assurance of authentication, privacy, information systems and security.|$|R
40|$|NASA is {{focusing}} on grand challenge problems in Earth and space sciences. Within these areas of science, new instrumentation will be providing scientists with unprecedented amounts of unprocessed data. Our goal is to design and implement a system that takes raw data as input and efficiently discovers interesting concepts that can target areas for further investigation {{and can be used}} to compress the data. Our approach will provide an <b>intelligent</b> parallel <b>data</b> <b>analysis</b> system...|$|R
40|$|Abstract — Because {{of using}} {{relational}} database, there exists difficulty in real-time data processing and <b>data</b> <b>analysis</b> in traditional transformer substation hotspot monitoring system. And even some important functions are not implemented, such as real-time alarm and real-time statistics. In this regard, this paper introduces real-time database {{to transform the}} traditional system. The use of real-time database achieves fast and real-time storage of temperature data, as well as <b>intelligent</b> <b>data</b> processing and <b>analysis.</b> And external display and real-time alarm functions are also achieved, which strengthens the safety management of substation...|$|R
50|$|Klaus-Robert Müller {{received}} his Diplom in mathematical physics and Ph.D. in theoretical computer science from the University of Karlsruhe. Following his Ph.D. {{he went to}} Berlin as a postdoctoral fellow at Fraunhofer FIRST (now part of Fraunhofer Institute for Open Communication Systems), where he started building up the <b>Intelligent</b> <b>Data</b> <b>Analysis</b> (IDA) group.|$|E
50|$|Fraud that {{involves}} cell phones, insurance claims, tax return claims, credit card transactions etc. represent significant problems for governments and businesses, but yet detecting and preventing fraud {{is not a}} simple task. Fraud is an adaptive crime, so it needs special methods of <b>intelligent</b> <b>data</b> <b>analysis</b> to detect and prevent it. These methods exist in the areas of Knowledge Discovery in Databases (KDD), Data Mining, Machine Learning and Statistics. They offer applicable and successful solutions in different areas of fraud crimes.|$|E
50|$|Starting in 1985, Bratt led {{research}} initiatives at Science Applications International Corporation {{and later}} {{served as the}} program manager at Defense Advanced Research Projects Agency developing advanced concepts for real-time global sensor monitoring, <b>intelligent</b> <b>data</b> <b>analysis,</b> and international telecommunications. By 1993, Bratt was integrating Web technologies into monitoring systems {{as a means of}} data sharing and collaboration. Bratt was a scientific advisor to the U.S. delegation to the Comprehensive Nuclear Test Ban Treaty negotiations in Geneva, Switzerland from their start in 1993 through their conclusion in 1996. In 1997, he was named the first Coordinator of the International Data Centre in Vienna, Austria of the preparatory commission for the Comprehensive Nuclear-Test-Ban Treaty Organization.|$|E
40|$|Association rules, {{introduced}} by Agrawal, Imielinski and Swami, {{is one of}} data mining technique to discover interesting rules or relationships among attributes in databases. It has attracted great attention in database research communities in recent years. In this paper, we propose a Mining Association Rules (MAR) model which integrate <b>intelligent</b> and <b>data</b> <b>analysis</b> techniques. MAR model has been implemented and tested using Jakarta Stock Exchange (JSA) databases. Our study conclude that MAR model can improve the performance ability of generated rules. In this paper, we explain the proposed MAR model, testing and experimental results in looking into {{the performance of the}} model and conclusion...|$|R
40|$|This paper {{describes}} a tool called Isaac (intelligent sensor analysis and actuator controller) that autonomously explores {{the behavior of}} a dynamical system and uses the resulting knowledge to help build and test mathematical models of that system. Isaac is a unified knowledge representation and reasoning framework for input/output modeling that can be incorporated into any automated tool that reasons about dynamical models. It is based on two modeling paradigms, <b>intelligent</b> sensor <b>data</b> <b>analysis</b> and qualitative bifurcation analysis, which capture essential parts of an engineer's reasoning about modeling problems. We demonstrate Isaac's power and adaptability by incorporating it into the Pret automated system identification tool and showing how input/output modeling expands Pret's repertoire...|$|R
40|$|NEREUS is {{a compact}} {{self-contained}} low-power submersible membrane-inlet mass spectrometer, {{designed to measure}} dissolved volatile gasses in the water column. It is capable of <b>intelligent</b> <b>data</b> collection, <b>analysis</b> and state-based mission control while operating as a stand-alone instrument or onboard the Kemonaut autonomous underwater vehicle (AUV). Kemonaut is an Odyssey class AUV with increased payload carrying capacity and dynamic stability, and is intended for freshwater and coastal marine applications to depths of 300 meters. The NEREUS-Kemonaut system characteristics allow for greatly improved dissolved gas data collection rates, accuracy and mapping resolution over presently available technologies. Applications particularly well suited for the NEREUS-Kemonaut system include identification and mapping of pollution sources such as chemical spills, investigation of enigmatic freshwater and marine ecosystems, assessment of subsurface natural resources and estimation of marine-related greenhous...|$|R
40|$|Abstract. A {{broad range}} of {{mathematical}} techniques, ranging from statistics to fuzzy logic, {{have been used to}} great advantage in <b>intelligent</b> <b>data</b> <b>analysis.</b> Topology—the fundamental mathematics of shape—has to date been conspicuously absent from this repertoire. This paper shows how topology, properly reformulated for a finite-precision world, can be useful in <b>intelligent</b> <b>data</b> <b>analysis</b> tasks. ...|$|E
40|$|Extensive {{amounts of}} {{knowledge}} and data stored in medical databases require the development of specialized tools for storing and accessing of data, data analysis, and effective use of stored knowledge and data. This paper focuses on methods and tools for <b>intelligent</b> <b>data</b> <b>analysis,</b> aimed at narrowing the increasing gap between data gathering and data comprehension. The paper sketches the history of research {{that led to the}} development of current <b>intelligent</b> <b>data</b> <b>analysis</b> techniques, discusses the need for <b>intelligent</b> <b>data</b> <b>analysis</b> in medicine, and proposes a classification of <b>intelligent</b> <b>data</b> <b>analysis</b> methods. The scope of the paper covers temporal data abstraction methods and data mining methods. A selection of methods is presented and illustrated in medical problem domains. Presently data abstraction and data mining are attracting considerable research interest. However the two technologies, in spite of the fact that they share their central objective, namely the intelligen [...] ...|$|E
40|$|Each time we hold an IDA conference, a {{distinguished}} conference committee thinks hard about a theme and {{a distinguished}} researcher writes a keynote lecture about what <b>Intelligent</b> <b>Data</b> <b>Analysis</b> is or might be. We suspect {{that all this}} hard thinking does not influence the kinds of papers we receive. Every conference season we review and accept roughly {{the same kinds of}} papers as appear at the data mining and machine learning conferences. The subject of the conference should not be a fifteen year old vision of <b>intelligent</b> <b>data</b> <b>analysis,</b> nor should the subject default to a sample of current work in data mining and machine learning. The conference should provide a venue for future interpretations of <b>intelligent</b> <b>data</b> <b>analysis.</b> We should start publishing in areas that are developing now and will reach full bloom in five years. At the same time, we should stay true to the traditional goals of the IDA conference. The first symposium on <b>Intelligent</b> <b>Data</b> <b>Analysis</b> was organized b...|$|E
40|$|Abstract: With {{the wide}} {{application}} of electronic device and network, plenty of data {{is added to}} multimedia database. In this paper, our work will expand application area and improve mining efficiency based on the improved data mining algorithm. A better humanization of evaluation (mining) process and results is obtained {{with the help of}} D-M strategy. The technique, which is concluded from plenty of data, is mainly divided into 3 steps: data arrangement, regulation searching and regulation presentation. This method reduces the affection of human factors on each evaluation links and saves the human task of management. It makes great sense to the theory research and algorithm improvement by applying digital manipulation to improvement of <b>intelligent</b> teaching-management <b>data</b> <b>analysis</b> evaluation and management tactics...|$|R
40|$|Urgency of {{application}} {{and development of}} cognitive graphic tools for usage in <b>intelligent</b> systems of <b>data</b> <b>analysis,</b> decision making and its justifications is given. Cognitive graphic tool " 2 -simplex prism" and examples of its usage are presented. Specificity of program realization of cognitive graphics tools invariant to problem areas is described. Most significant results are given and discussed. Future investigations are connected with usage of new approach to rendering, cross-platform realization, cognitive features improving and expanding of n-simplex family. Comment: 14 pages, 6 figures, conferenc...|$|R
40|$|About the book: This edited {{volume is}} {{dedicated}} to the theory and applications of Computational Intelligence techniques for <b>Intelligent</b> Image Processing, <b>Data</b> <b>Analysis</b> and Information Retrieval. It consists of 52 accepted research papers from the 1999 International Conference on Computational Intelligence for Modeling, Control and Automation - CIMCA' 99. The goal of this conference was to provide a medium for the exchange of ideas between theoreticians and practitioners to address the important issues in computational intelligence for modelling, control and automation. The research papers presented in this book cover new techniques and applications in the of Image Processing, Computer Vision, Multimedia Systems, Filtering, Classification, <b>Data</b> <b>Analysis,</b> Prediction, <b>Intelligent</b> Database and Information Retrievals...|$|R
40|$|Abstract — Multiview <b>intelligent</b> <b>data</b> <b>analysis</b> explores {{data from}} {{different}} perspectives to reveal {{various types of}} structures and knowledge embedded in the data. Granular computing provides a general methodology for problem solving and information processing. Its application to data analysis results in hierarchical knowledge structures. In this paper, the fundamental issues of granulations and granular structures for data analysis are discussed based on modal-style data operators. The results {{provide a basis for}} establishing a framework of multiview <b>intelligent</b> <b>data</b> <b>analysis.</b> I...|$|E
40|$|Data {{analysis}} is an interdisciplinary science. Traditionally its {{development has been}} driven by the areas of application, but nowadays its development is also stimulated by the ever-changing possibilities promised by progress in computer technology. Huge data sets and non-numerical data, such as text data, image data, and metadata, present both challenges and opportunities for modern data analysts. These in turn lead to new types of problems and require the development of new types of models. <b>Intelligent</b> <b>data</b> <b>analysis</b> also requires that one take proper advantage of the largely complementary abilities of humans and computers. Interactive graphics, an important tool for modern <b>intelligent</b> <b>data</b> <b>analysis,</b> nicely illustrates this: the production of such graphics, and the ability to manipulate them in real time, requires advanced computational facilities; but the ability to interpret them requires the capacity to synthesise possessed only by the human eye and mind. <b>Intelligent</b> <b>data</b> <b>analysis</b> [...] ...|$|E
40|$|In e-business, {{knowledge}} can be extracted from the recorded information by <b>intelligent</b> <b>data</b> <b>analysis</b> and then utilised in the business transaction. E-knowledge is a foundation for e-business. E-business can be supported by an intelligent in-formation system that provides intelligent business process support and advanced support of the e-knowledge manage-ment cycle. Knowledge is stored as knowledge models that can be updated in the e-knowledge management cycle. As illustrated in examples, the e-knowledge cycle aids in the business decision taking, production management, and costs management. Keywords e-business, <b>intelligent</b> <b>data</b> <b>analysis,</b> intelligent information systems, knowledge management...|$|E
40|$|Abstract State-of-the-art <b>data</b> <b>analysis</b> in {{production}} allows engineers to characterize reservoirs using production data. This saves companies large sums that should otherwise be spend on well testing and reservoir simulation and modeling. There are two shortcomings with today’s production data analysis: It needs bottom-hole or well-head pressure data {{in addition to}} data for rating reservoirs’ characterization. Analysis remains at the individual well level. It does not offer integration of results from individual wells to create a field-wide analysis. A new technique called <b>Intelligent</b> Production <b>Data</b> <b>Analysis,</b> IPDA, addresses both of these short-comings. Through an iterative technique, IPDA integrates Decline Curve Analysis, Type Curve Matching, and Numerical Reservoir Simulation (History Matching) in order to converge {{to a set of}} reservoir characteristics, compatible with all three techniques. Furthermore, once reservoir characteristics for individual wells in the field are identified through above process, and by using a unique Fuzzy Pattern Recognition technology the results are mapped on the entire field in order to evaluate reserve estimates, pin-point optimum infill drilling locations, track fluid flow and depletion, remaining reserves and finally identify under-performe...|$|R
40|$|Abstract: One of {{the most}} {{important}} challenges of the emerging Information Age is to effectively utilize the immense wealth of data and information acquired, computed and stored by modern information systems. On the one hand, the intelligent use of available data volumes and information extracted thereof offers large potential to realize technological progress and business success. On the other hand, there exists the severe danger that users and analysts get lost in irrelevant, or inappropriately processed or presented information, a problem, which is generally called the information overload problem. Visual Analytics is an emerging research discipline developing technology to make the best possible use of huge information loads {{in a wide variety of}} applications. The basic idea is to appropriately combine the strengths of <b>intelligent</b> automatic <b>data</b> <b>analysis</b> with the visual perception and analysis capabilities of the human user. In this paper, we will outline the most important challenges of the young research field. 1...|$|R
40|$|AbstractVisual {{analytics}} is {{an emerging}} research discipline aiming at {{making the best}} possible use of huge information loads {{in a wide variety}} of applications by appropriately combining the strengths of <b>intelligent</b> automatic <b>data</b> <b>analysis</b> with the visual perception and analysis capabilities of the human user. The major goal of visual analytics is the integration of these disciplines into visual analytics to acquire well-established and agreed upon concepts and theories, combining scientific breakthroughs in a single discipline to have a potential impact on visual analytics and vice versa. In a session at FET’ 11, the leaders of the thematic working groups of the recently finalised FET Open coordination action VisMaster CA presented the scientific challenges that were identified in the visual analytics research roadmap, and the connection between the various disciplines and the broader vision of visual analytics. This article contains excerpts from this research roadmap to motivate further research in this direction within FET...|$|R
40|$|Excessive {{amounts of}} {{knowledge}} and data stored in medical databases request the development of specialized tools for storing and accessing of data, data analysis, and effective use of stored knowledge and data. This paper first sketches the history of research {{that led to the}} development of current <b>intelligent</b> <b>data</b> <b>analysis</b> techniques, aimed at narrowing the increasing gap between data gathering and data comprehension. Next, we present our view on the relation of <b>Intelligent</b> <b>data</b> <b>analysis</b> to Knowledge discovery in databases and Data mining. Finally, we discuss the need for <b>intelligent</b> <b>data</b> <b>analysis</b> in medicine and present the aims of research in this area. 1 Introduction "Now that we have gathered so much data, what do we do with it?" This is the opening statement of the editorial by Usama Fayyad and Ramasamy Uthurusamy in the Communications of the ACM, Special issue on Data Mining [12]. Recently, many statements of this kind appeared in journals, conference proceedings, and other [...] ...|$|E
40|$|Objective: To {{introduce}} the focus theme of Methods of Information in Medicine on <b>Intelligent</b> <b>Data</b> <b>Analysis</b> for Knowledge Discovery, Patient Monitoring and Quality Assessment. Methods: Based on two workshops on <b>Intelligent</b> <b>Data</b> <b>Analysis</b> in bioMedicine (IDAMAP) held in Washington, DC, USA (2010) and Bled, Slovenia (2011), six authors {{were invited to}} write full papers for the focus theme. Each paper was throughly reviewed by anonymous referees and revised one or more times by the authors. Results: The selected papers cover four ongoing and emerging topics in <b>Intelligent</b> <b>Data</b> <b>Analysis</b> (IDA), being i) systems biology and metabolic pathway modelling; ii) gene expression data modelling; iii) signal processing from in-home monitoring systems; and iv) quality of care assessment. Each of these topics is discussed in detail to {{introduce the}} papers to the reader. Conclusion: The development and application of IDA methods in biomedicine is an active area of research which continues to blend with other subfields of medical informatics. As data become increasingly ubiquitous in the biomedical domain, the demand for fast, smart and flexible data analysis methods is undiminishe...|$|E
40|$|This book gathers papers {{presented}} at the ECC 2016, the Third Euro-China Conference on <b>Intelligent</b> <b>Data</b> <b>Analysis</b> and Applications, which was held in Fuzhou City, China from November 7 to 9, 2016. The aim of the ECC is to provide an internationally respected forum for scientific research in the broad areas of <b>intelligent</b> <b>data</b> <b>analysis,</b> computational intelligence, signal processing, and all associated applications of artificial intelligence (AI). The third installment of the ECC was jointly organized by Fujian University of Technology, China, and VSB-Technical University of Ostrava, Czech Republic. The conference was co-sponsored by Taiwan Association for Web Intelligence Consortium, and Immersion Co., Ltd...|$|E
40|$|International audienceA {{monitoring}} {{system based on}} wireless sensor network is established, aiming at the difficulty of information acquisition in the orchard on the hill at present. The temperature and humidity sensors are deployed around fruit trees to gather the real-time environmental parameters, and the wireless communication modules with self-organized form, which transmit the data to a remote central server, can realize the function of monitoring. By setting the parameters of <b>data</b> <b>intelligent</b> <b>analysis</b> judgment, the information on remote diagnosis and decision support can be timely and effectively feed back to users...|$|R
40|$|Current video {{surveillance}} systems still lack of <b>intelligent</b> video and <b>data</b> <b>analysis</b> modules for supporting situation awareness of decision makers. Especially in mass gatherings like large public events, {{the decision maker}} would benefit from different views of the area, especially from crowd density estimations. This article describes a multi-camera system called NEST and its application for crowd density analysis. First, the overall system design is presented. Based on this, the crowd density estimation method is explained. The graphical user interface consists of two components: a georeferenced dynamic heat-map visualization and an interactive video stream visualization. Both components allow a direct camera control. In addition, the system is equipped with an adaptive privacy masking for privacy protection...|$|R
40|$|Visual {{analytics}} is {{an emerging}} research discipline aiming at {{making the best}} possible use of huge information loads {{in a wide variety}} of applications by appropriately combining the strengths of <b>intelligent</b> automatic <b>data</b> <b>analysis</b> with the visual perception and analysis capabilities of the human user. The major goal of visual analytics is the integration of these disciplines into visual analytics to acquire well-established and agreed upon concepts and theories, combining scientific breakthroughs in a single discipline to have a potential impact on visual analytics and vice versa. In a session at FET' 11, the leaders of the thematic working groups of the recently finalised FET Open coordination action VisMaster CA presented the scientific challenges that were identified in the visual analytics research roadmap, and the connection between the various disciplines and the broader vision of visual analytics. This article contains excerpts from this research roadmap to motivate further research in this direction within FET. (C) Selection and peer-review under responsibility of FET 11 conference organizers and published by Elsevier B. V...|$|R
40|$|<b>Intelligent</b> <b>data</b> <b>analysis</b> (IDA) is an {{interdisciplinary}} study {{concerned with the}} effective analysis of data. The paper briefly looks {{at some of the}} key issues in <b>intelligent</b> <b>data</b> <b>analysis,</b> discusses the opportunities for soft computing in this context, and presents several IDA case studies in which soft computing has played key roles. These studies are all concerned with complex real-world problem solving, including consistency checking between mass spectral data with proposed chemical structures, screening for glaucoma and other eye diseases, forecasting of visual field deterioration, and diagnosis in an oil refinery involving multivariate time series. Bayesian networks, evolutionary computation, neural networks, and machine learning in general are some of those soft computing techniques effectively used in these studies...|$|E
40|$|<b>Intelligent</b> <b>data</b> <b>analysis</b> {{extracts}} symbolic {{information and}} relations between objects from quantitative or qualitative data. A prominent class of methods are clustering or grouping principles which {{are designed to}} discover and extract structures hidden in data sets [Jain and Dubes, 1988]. The parameters whic...|$|E
40|$|This {{volume of}} Advances in Intelligent Systems and Computing {{contains}} accepted papers {{presented in the}} main track of ECC 2015, the Second Euro-China Conference on <b>Intelligent</b> <b>Data</b> <b>Analysis</b> and Applications. The aim of ECC is to provide an internationally respected forum for scientific research in the broad area of <b>intelligent</b> <b>data</b> <b>analysis,</b> computational intelligence, signal processing, and all associated applications of AIs. The second edition of ECC was organized jointly by VSB - Technical University of Ostrava, Czech Republic, and Fujian University of Technology, Fuzhou, China. The conference, organized under the patronage of Mr. Miroslav Novak, President of the Moravian-Silesian Region, took place in late June and early July 2015 in the Campus of the VSB - Technical University of Ostrava, Czech Republic...|$|E
5000|$|Data Science and Machine Intelligence Center: Research {{on basic}} {{mathematics}} and statistical theory of high dimensional <b>data</b> <b>analysis,</b> efficient and extensible machine learning algorithms, <b>intelligent</b> <b>data</b> acquisition devices and equipment, parallel distributed computer systems and software development platforms, and applications of image, video, text, speech, bioinformatics and other aspects.|$|R
40|$|The {{proposed}} election system lies {{in ensuring}} that it is transparent and impartial. Thus while the electoral system may vary from country to country, It has {{to take into account}} the peculiarities of every society while at the same time incorporating remedies to problems prevailing in the system. The Electoral process expressed serious concerns regarding the independence of the Election Commission of Pakistan, the restrictions on political parties and their candidates, the misuse of state resources, some unbalanced coverage in the state media, deficiencies in the compilation of the voting register and significant problems relating to the provision of ID cards. The holding of a general election does not in itself guarantee the restoration of democracy. The unjustified interference with electoral arrangements, as detailed above, irrespective of the alleged motivation, resulted in serious flaws being inflicted on the electoral process. Additionally, questions remain as to whether or not there will be a full transfer of power from a military to civilian administration. The Independent study research has following modules: Login/Subscription Module Candidate Subscription Module Vote casting Module Administration Module <b>Intelligent</b> decision <b>data</b> <b>analysis</b> ModuleComment: 6 page...|$|R
40|$|This paper {{presents}} {{an overview of}} support vector machines (SVM) {{as one of the}} most promising <b>intelligent</b> techniques for <b>data</b> <b>analysis</b> found in the published literature, as theoretical approaches and sophisticated applications developed for various research areas and problem domains. This work is an attempt to provide a survey of the applications of SVM for oil and gas exploration to professionals, researchers and academics involved with the hydrocarbons industry. The applications of SVM have been grouped and summarized in the different areas of the exploration phase, which can be used as a guide to assess the effectiveness of SVM over other data mining algorithms. It also provides a better understanding of the various applications that have been developed for an area that offers a glimpse of innovative applications in other domains of the industry. </span...|$|R
