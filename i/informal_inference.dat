46|31|Public
2500|$|Logic {{has been}} defined as [...] "the study of {{arguments}} correct in virtue of their form". [...] This has not been the definition taken in this article, but the idea that logic treats special forms of argument, deductive argument, rather than argument in general, has a history in logic that dates back at least to logicism in mathematics (19th and 20th centuries) and the advent of the influence of mathematical logic on philosophy. [...] A consequence of taking logic to treat special kinds of argument is that it leads to identification of special kinds of truth, the logical truths (with logic equivalently being the study of logical truth), and excludes many of the original objects of study of logic that are treated as informal logic. [...] Robert Brandom has argued against the idea that logic is the study of a special kind of logical truth, arguing that instead one can talk of the logic of material inference (in the terminology of Wilfred Sellars), with logic making explicit the commitments that were originally implicit in <b>informal</b> <b>inference.</b>|$|E
5000|$|According to Statistical Reasoning, Thinking and Literacy forum, three {{essential}} {{principles to}} <b>informal</b> <b>inference</b> are : ...|$|E
50|$|<b>Informal</b> <b>inference</b> {{is akin to}} calculus. In <b>informal</b> <b>inference</b> one {{reaches a}} {{conclusion}} by considering the accumulation of converging antecedent probabilities. Natural inference is when the individual, in a simple and whole process, grasps the antecedent conditions and conclusions instantaneously. For instance, if one sees smoke, one may instantly infer the presence of fire. Natural inference, in Newman's view, is related to experience or innate ability.|$|E
40|$|<b>Informal</b> {{statistical}} <b>inference</b> has {{now been}} researched {{at all levels of}} schooling and initial tertiary study. Work in <b>informal</b> statistical <b>inference</b> is least understood in the early years, where children have had little if any exposure to data handling. A qualitative study in Australia was carried out through a series of teaching experiments with a class of five- to six-year-old children in two phases over sixmonths. The aim of the exploratory study was to understand and support the emergence of <b>informal</b> statistical <b>inference</b> {{in the early years of}} schooling. Through activities that initially built on children 2 ̆ 7 s experiences with prediction and key characteristics of <b>informal</b> statistical <b>inference,</b> the children 2 ̆ 7 s actions were observed in a data-based inquiry involving prediction to identify critical relationships that then supported children in making <b>informal</b> statistical <b>inferences.</b> Implications are discussed...|$|R
40|$|Inference, or {{decision}} making, is seen {{in curriculum}} documents as the final step in a statistical investigation (Australian Education Council, 1991). For a formal statistical enquiry this {{may be associated with}} sophisticated tests involving probability distributions. For young students without the mathematical background to perform such tests, it is still possible to draw <b>informal</b> <b>inferences</b> based on data of various sorts, for example by comparing two graphical representations (e. g., Watson & Moritz, 1999). In doing so {{it is important to be}} able to state the assumptions that are the foundation for the decision made (Whitin, 2006). This article considers a straightforward context where students are asked to make predictions. These predictions are <b>informal</b> <b>inferences</b> that can be based on aspects of the scenario, the students’ appreciation of the context, and their cognisance of the data presented...|$|R
40|$|<b>Informal</b> {{statistical}} <b>inference</b> (ISI) {{has been}} a frequent focus of recent research in statistics education. Considering the role that context plays in developing ISI {{calls into question the}} need to be more explicit about the reasoning that underpins ISI. This paper uses educational literature on <b>informal</b> statistical <b>inference</b> and philosophical literature on inference to argue that in order for students to generate <b>informal</b> statistical <b>inferences,</b> {{there are a number of}} interrelated key elements that are needed to support their informal inferential reasoning. In particular, we claim that ISI is nurtured by statistical knowledge, knowledge about the problem context, and useful norms and habits developed over time, and is supported by an inquiry-based environment (tasks, tools, scaffolds). We adopt Peirce 2 ̆ 7 s and Dewey 2 ̆ 7 s view that inquiry is a sense-making process driven by doubt and belief, leading to inferences and explanations. To illustrate the roles that these elements play in supporting students to generate <b>informal</b> statistical <b>inferences,</b> we provide an analysis of three sixth-graders 2 ̆ 7 (aged 12) informal inferential reasoning-the reasoning processes leading to their <b>informal</b> statistical <b>inferences.</b> © Taylor & Francis Group, LLC...|$|R
50|$|Rubin, A., Hammerman, J., & Konold, C. (2006). Exploring <b>informal</b> <b>inference</b> with {{interactive}} visualization software. In A. Rossman & B. Chance (Eds.) Proceedings of the 7th International Conference on Teaching Statistics (ICOTS) CD-ROM. Salvador, Bahai, Brazil, July 2-7, 2006.|$|E
50|$|In {{statistics}} education, informal inferential reasoning (also called <b>informal</b> <b>inference)</b> {{refers to}} the process of making a generalization based on data (samples) about a wider universe (population/process) while taking into account uncertainty without using the formal statistical procedure or methods (e.g. P-values, t-test, hypothesis testing, significance test).|$|E
50|$|Scientific {{progress}} in archaeology, {{as in any}} other discipline, requires building abstract, generalized and transferable knowledge about the processes that underlie past human actions and their manifestations. Quantification provides the ultimate known way of abstracting and extending our scientific abilities past the limits of intuitive cognition. Quantitative approaches to archaeological information handling and inference constitute a critical body of scientific methods in archaeological research. They provide the tools, algebra, statistics and computer algorithms, to process information too voluminous or complex for purely cognitive, <b>informal</b> <b>inference.</b> They also build a bridge between archaeology and numerous quantitative sciences such as geophysics, geoinformation sciences and applied statistics. And they allow archaeological scientists to design and carry out research in a formal, transparent and comprehensible way.|$|E
40|$|Teaching from an <b>informal</b> {{statistical}} <b>inference</b> perspective {{can address}} {{the challenge of}} teaching statistics in a coherent way. We argue that activities that promote model-based reasoning address two additional challenges: providing a coherent sequence of topics and promoting the application of knowledge to novel situations. We take a models and modeling perspective {{as a framework for}} designing and implementing an instructional sequence of model development tasks focused on developing primary students 2 ̆ 7 generalized models for drawing <b>informal</b> <b>inferences</b> when comparing two sets of data. This study was conducted with 26 Year 5 students (ages 10 - 11). Our study provides empirical evidence for how a modeling perspective can bring together lines of research that hold potential for the teaching and learning of inferential reasoning...|$|R
5000|$|Makar, K., & Rubin, A. (2009). A {{framework}} {{for thinking about}} <b>informal</b> statistical <b>inference.</b> Statistical Education Research Journal, 8(1), 82-105.|$|R
40|$|Research on <b>informal</b> {{statistical}} <b>inference</b> {{has so far}} attended {{little to}} developing students 2 ̆ 7 reasoning about samples and sampling. This SRTL- 7 pre-paper will prepare the ground for analyzing children’s reasoning about sampling when making <b>informal</b> statistical <b>inferences</b> in a collaborative, project- and inquirybased learning environment. Using data from a design experiment in Israeli Grade 5 (age 11) classrooms, {{we focus on the}} emergent reasoning of two boys working with TinkerPlots on investigations with growing sample size...|$|R
5000|$|Logic {{has been}} defined as [...] "the study of {{arguments}} correct in virtue of their form". This has not been the definition taken in this article, but the idea that logic treats special forms of argument, deductive argument, rather than argument in general, has a history in logic that dates back at least to logicism in mathematics (19th and 20th centuries) and the advent of the influence of mathematical logic on philosophy. A consequence of taking logic to treat special kinds of argument is that it leads to identification of special kinds of truth, the logical truths (with logic equivalently being the study of logical truth), and excludes many of the original objects of study of logic that are treated as informal logic. Robert Brandom has argued against the idea that logic is the study of a special kind of logical truth, arguing that instead one can talk of the logic of material inference (in the terminology of Wilfred Sellars), with logic making explicit the commitments that were originally implicit in <b>informal</b> <b>inference.</b>|$|E
30|$|Since the {{introduction}} of statistics into school mathematics curricula about 25  years ago (e.g. Australian Education Council 1991; National Council of Teachers of Mathematics, 1989), {{there has been a}} growing awareness of the inadequacy of focusing solely on a procedural ability to calculate statistics. In particular, <b>informal</b> <b>inference,</b> a precursor to formal inference, has been highlighted as a foundational component that has not received the required attention especially in the elementary grades (Makar, in press). As described by Makar and Rubin (2009), <b>informal</b> <b>inference</b> is the process of using the evidence provided by data to answer questions beyond the data, acknowledging the uncertainty associated with the conclusion reached. Variation is the key to accepting a conclusion with some degree of certainty (Franklin et al., 2007, p. 18).|$|E
40|$|Abstract. Inference {{is one of}} human’s {{high-level}} functionalities and it is {{not easy}} to implement in machine. It is believed that inference is not results of single neuron’s activity. Instead, it is a complex activity generated by multiple neural networks. Unlike computer, it is more flexible and concludes differently even for the similar situations in case of human. In this paper, these characteristics are defined as “informality. ” Informality in inference can be implemented using the interaction of multiple neural networks with the inclusion of internal or subjective properties. Simple inference tasks such as pattern recognition and robot control are solved based on the <b>informal</b> <b>inference</b> ideas. Especially, fuzzy integral and behavior network methods are adopted to realize that. Experimental results show that the <b>informal</b> <b>inference</b> can perform better with more flexibility compared to the previous static approaches...|$|E
40|$|Research on <b>informal</b> {{statistical}} <b>inference</b> {{has so far}} attended {{little to}} sampling. This paper analyzes children‘s reasoning about sampling when making <b>informal</b> statistical <b>inferences</b> in an inquiry-based environment. Using data from a design experiment in Israeli Grade 5 (age 11) classrooms, {{we focus on the}} emergent reasoning of two boys working with TinkerPlots on investigations with growing sample size. They turn out to have useful ideas about whether inferences can be made from samples of different sizes. Initially, they oscillate between deterministic and relativistic conclusions, but they come to reason in more sophisticated ways with increasing awareness of what is at stake when making inferences from samples...|$|R
40|$|Our {{world is}} {{increasingly}} data-rich and data-dependent. Every day, 2. 5 quintillion bytes of new data are created — {{so much that}} 90 % of the data {{in the world today}} has been created {{in the last two years}} alone. Data visualization allows us to explore and effectively communicate relevant information about this voluminous data through graphic representations. This includes visualisation of all kinds of information, not just data, and is closely associated with research by computer scientists. From the perspective of statistical pedagogy, data visualisation can be viewed as computer-assisted exploratory data analysis of voluminous complex data sets. Data visualisation has blossomed into a multidisciplinary research area, and a wide range of visualisation tools have been developed at an accelerated pace. Admittedly, statistical data analysis necessitates data visualisation to form the basis for decision-making. There is a greater need for people to make good inferences from visualisations. The flexible nature of current computing tools can potentially have a major impact on the discipline of statistics and allow easier use of visualisations in the educational process. There is evidence that a wholly visual approach can help students learn statistics, especially the <b>informal</b> <b>inferences,</b> and the abilities used by students to make <b>informal</b> <b>inferences</b> based on a wholly visual approach are the same abilities needed to make inferences from and judgements about the statistical graphs that are so common. This paper proposes a framework for considering the way that youth might employ data visualisation when working with data in a pedagogical context...|$|R
40|$|Year 11 (15 -year-old) {{students}} are not exposed to formal statistical inferential methods. When drawing conclusions from data, their reasoning must be based mainly on looking at graph representations. Therefore, a challenge for research is {{to understand the nature}} and type of informal inferential reasoning used by students. In this paper two studies are reported. The first study reports on the development of a model for a teacher’s reasoning when drawing <b>informal</b> <b>inferences</b> from the comparison of box plots. Using this model, the second study investigates the type of reasoning her students displayed in response to an assessment task. The resultant analysis produced a conjectured hierarchical model for students’ reasoning. The implications of the findings for instruction are discussed...|$|R
40|$|Most {{statistics}} educators {{would agree}} that statistical inference is both the central objective of statistical reasoning {{and one of the}} most difficult ideas for students to understand. In traditional approaches, statistical inference is introduced as a quantitative problem, usually of figuring out the probability of obtaining an observed result on the assumption that the null hypothesis is true. In this article, we lay out an alternative approach towards teaching statistical inference that we are calling “informal inference. ” We begin by describing <b>informal</b> <b>inference</b> and then illustrate ways we have been trying to develop the component ideas of <b>informal</b> <b>inference</b> in a recent data analysis seminar with teachers; our particular emphasis in this article is on the ways in which teachers used TinkerPlots, a statistical visualization tool. After describing teachers ’ approaches to an inferential task, we offer some preliminary hypotheses about the conceptual issues that arose for them...|$|E
40|$|This {{experiment}} investigated {{how different}} methods of data visualisation can influence <b>informal</b> <b>inference.</b> Two hundred and five student participants with an introductory statistics background completed an online randomised survey. Participants {{were presented with}} a scenario that required them to make inferences {{about the difference between}} the life of two battery brands, based on a plot visualising the data. The plot type and the dataset visualised were manipulated based on {{the degree to which a}} plot depicted variability in the data (bar, box and dot) and whether or not the plot depicted data sampled from populations where each brands&# 039; battery life was equal or unequal. Both manipulations were found to significantly impact the informal inferences drawn by participants. The experiment also discovered an interaction between plot type and brands&# 039; battery life equality. Plots that depicted variability (box and dot) led to more correct inferences when the plots depicted data sampled from unequal populations, but fewer correct inferences when they displayed data sampled from identical populations. The findings build upon previous research by demonstrating that different methods of data visualisation can affect <b>informal</b> <b>inference.</b> These findings have important implications for statistics education and data visualisation...|$|E
40|$|International audienceThis paper {{reports on}} {{preliminary}} {{results of a}} study aiming to identify <b>informal</b> <b>inference</b> aspects that emerge when grade 8 students explore a statistical investigation using the software TinkerPlots for data handling. Examples from students' work on one task in a sequence, designed to engage students in posing statistical questions about meaningful phenomena, in collecting and representing data and finally in making data-based inferences, illustrate how informal statistical inferences emerge. The results provide suggestions for further research and some educational implications are drawn...|$|E
40|$|This paper {{addresses}} {{research from}} a three-year longitudinal study that engaged children in data modeling experiences {{from the beginning}} school year through to third year (6 - 8 years). A data modeling approach to statistical development differs in several ways from what is typically done in early classroom experiences with data. In particular, data modeling immerses children in problems that evolve from their own questions and reasoning, with core statistical foundations established early. These foundations include a focus on posing and refining statistical questions within and across contexts, structuring and representing data, making <b>informal</b> <b>inferences,</b> and developing conceptual, representational, and metarepresentational competence. Examples are presented of how young learners developed and sustained informal inferential reasoning and metarepresentational competence across the study to become “sophisticated statisticians”...|$|R
40|$|In {{order to}} better {{understand}} the thinking of students' learning to make <b>informal</b> statistical <b>inferences,</b> this research examined the thinking of senior secondary school students (age 17) engaged in the task of using observed data to make point estimates of a population parameter within a computer-based simulation. Following the ``Growing Samples" instructional model, the point estimation activity involved sampling and estimating across three tasks with different sample sizes. This research study aimed to trace the evolution of the students' thinking, with particular attention to use of the statistical concepts in making <b>informal</b> <b>inferences</b> from sampling.   The students in this study were observed to rely primarily on mathematical thinking, which, perhaps, inhibited their ability to construct meanings about the basic statistical concepts underpinning sampling when performing point estimates. At times in the process students were seen to shift between mathematical thinking, statistical thinking, and thinking about the context, but the mathematical thinking seemed to dominate their attempts to create estimates. These research findings are useful for informing the teaching of point estimation of a population parameter to school-aged students. The research findings also stress the need for teachers to rethink the relationship between statistical thinking and mathematical thinking in order to promote statistical thinking in relevant learning situations for their students...|$|R
40|$|<b>Informal</b> {{statistical}} <b>inference</b> {{has gained}} increasing recognition {{as an effective}} approach to teaching statistics. Distinct from descriptive statistics, inference provides learners {{with access to the}} power of statistics by giving them tools to make predictions beyond their data. International research in this area has focused on students from primary school through university. A series of teaching experiments introduced <b>informal</b> statistical <b>inference</b> to very young children (aged 5 - 6). Although making predictions was familiar as an everyday task, initial attempts revealed challenges to teaching informal inferential reasoning to young learners. Prior to conducting a statistical inquiry involving inference, activities were designed to generate a need for recording and organising data, the language of uncertainty and using data as evidence. Results suggest that the activities prior to inquiry likely supported students in their emerging inferential practices...|$|R
40|$|The {{adoption}} of advertising and product differentiation strategies normally associated with monopolistically competitive industry structures {{calls into question}} the competitive assumption generally utilized in agricultural econometrics. The scale of large corporate, and sole proprietor, farms has also expanded during the past century and a half. As a means for examining the competitive hypothesis, a univariate time series methodology is proposed that involves both formal statistical testing and <b>informal</b> <b>inference</b> regarding individual model characteristics. Empirical analysis utilizes data for seven vegetable producing regions of the United States...|$|E
40|$|Informal {{inferential}} reasoning {{has shown}} some promise in developing students’ {{deeper understanding of}} statistical processes. This paper presents a framework to think about three key principles of <b>informal</b> <b>inference</b> – eneralizations ‘beyond the data,’ probabilistic language, and data as evidence. The authors use primary school classroom episodes and excerpts of interviews with the teachers to illustrate the framework and reiterate the importance of embedding statistical learning {{within the context of}} statistical inquiry. Implications for the teaching of more powerful satistical concepts at the primary school level are discussed...|$|E
40|$|A {{range of}} monthly series are {{currently}} available giving indications of short-term movements in output in the UK. The main {{aim of this}} paper is to suggest a formal and coherent procedure for grossing these monthly data up to represent the whole of GDP. Although the resultant estimates of GDP would be worse than those obtained by direct measurement, they should be more satisfactory than simply making an <b>informal</b> <b>inference</b> from whatever monthly data are available. Our examination of the efficacy of the method for estimation of the state of economic activity indicates a rather satisfactory outcome. Copyright 2005 Royal Economic Society. ...|$|E
40|$|This article explores 6 th- grade students’ {{modelling}} {{with data}} in generating models for selecting an Australian swimming {{team for the}} (then) forthcoming 2016 Olympics, using data on swimmers’ times at various previous events. We propose a modelling framework comprising four components: working in shared problem spaces between mathematics and statistics; interpreting and reinterpreting problem contexts and questions; interpreting, organising and operating on data in model construction; and drawing <b>informal</b> <b>inferences.</b> In studying students’ model generation, consideration is given to how they interpreted, organised, and operated on the problem data in constructing and documenting their models, and how they engaged in informal inferential reasoning. Students’ responses included applying mathematical and statistical operations and reasoning to selected variables, identifying how variation and trends in swimmers’ performances inform model construction, recognising limitations in using only one performance variable, and acknowledging inform model construction, recognising limitations in using only one performance variable, and acknowledging uncertainty in model creation and model application due to chance variation...|$|R
50|$|Algorithmic {{probability}} is {{the main}} ingredient of Solomonoff's theory of inductive inference, the theory of prediction based on observations; it was invented {{with the goal of}} using it for machine learning; given a sequence of symbols, which one will come next? Solomonoff's theory provides an answer that is optimal in a certain sense, although it is incomputable. Unlike, for example, Karl Popper's <b>informal</b> inductive <b>inference</b> theory, Solomonoff's is mathematically rigorous.|$|R
40|$|This {{document}} is the Accepted Manuscript {{version of the}} following article: Brendan Larvor, ???How to think about informal proofs???, Synthese, Vol. 187 (2) : 715 - 730, first published online 9 September 2011. The final publication is available at Springer via doi: 10. 1007 /s 11229 - 011 - 0007 - 5 It is argued {{in this study that}} (i) progress in the philosophy of mathematical practice requires a general positive account of informal proof; (ii) the best candidate is to think of informal proofs as arguments that depend on their matter as well as their logical form; (iii) articulating the dependency of <b>informal</b> <b>inferences</b> on their content requires a redefinition of logic as the general study of inferential actions; (iv) it is a decisive advantage of this conception of logic that it accommodates the many mathematical proofs that include actions on objects other than propositions; (v) this conception of logic permits the articulation of project-sized tasks for the philosophy of mathematical practice, thereby supplying a partial characterisation of normal research in the fiel...|$|R
40|$|AbstractPost-graduate {{students}} in statistics courses {{are expected to}} use their reasoning when making <b>informal</b> <b>inference</b> from comparison of two box plots. A framework based on the SOLO Taxonomy {{that can be used}} to assess students’ informal inferential reasoning as they compare two box plots had been developed. It consists of a set of descriptors of the levels of reasoning and interview tasks {{that can be used to}} collect evidence of students’ informal inferential reasoning. An example of a student's response to one of the tasks and how the descriptors are used to determine the levels of students’ informal inferential reasoning will be presented...|$|E
40|$|This study {{reports on}} {{the second phase of}} a design {{experiment}} involving classroom implementation of a sequence of four lessons introducing <b>informal</b> <b>inference</b> supported by TinkerPlots software to a grade 7 class. A Beginning Inference Framework was used as an implicit foundation for the teachers and as an explicit rubric for assessing students ’ observed outcomes. Outcomes were judged in relation to saved TinkerPlots files annotated with student-completed text boxes and to individual interviews with 12 of the students. In 2006, {{as part of a larger}} professional learning research project, Jenny (pseudonym), a grade 7 teacher in a rural district school (K- 10), undertook a case study related to introducing her class to TinkerPlots graphing software for middle schools (Konold & Miller, 2005). The case study evolved into a design experiment adapting lessons to cover elements of a Beginning Inference Framework, derived from a model suggested by Pfannkuch (2006). Data collected in the form of TinkerPlots files from four sessions were analysed in relation to the Beginning Inference Framework to document students ’ observed progress in taking up the elements of <b>informal</b> <b>inference</b> (Watson, 2007). The key aspects of the initial intervention included the evaluation of the extent to which the elements of the framework were observed in student output. The 2006 case study and the subsequent 2007 case study described in this report arose from the desire of the statistics education research community to provide a meaningful bridge to formal inference, which man...|$|E
30|$|In summary, {{this study}} {{addresses}} three underrepresented components of statistical {{development in the}} elementary grades. First, in integrating the strands of statistics and measurement in the curriculum, the study targets the neglected factor of variation in linear measurement. Second, the study {{highlights the importance of}} students' awareness, creation and understanding of variation in data representations, in contrast to traditional approaches where ‘information’ is simply read from a graph without being interpreted, analysed and questioned. Third, it focuses on an understanding and appreciation of <b>informal</b> <b>inference,</b> in this instance related to predicting a student's arm span length from data exhibiting variation, which is critical in interpreting data and distributions and making informed decisions.|$|E
40|$|We {{examine the}} use of the {{likelihood}} ratio (LR) statistic to test for unobserved heterogeneity in duration models, based on mixtures of exponential or Weibull distributions. We consider both the uncensored and censored duration cases. The asymptotic null distribution of the LR test statistic is not the standard chi-square, as the standard regularity conditions do not hold. Instead, there is a nuisance parameter identified only under the alternative, and a null parameter value on the boundary of the parameter space, as in Cho and White (2007 a). We accommodate these and provide methods delivering consistent asymptotic critical values. We conduct a number of Monte Carlo simulations, comparing the level and power of the LR test statistic to an information matrix (IM) test due to Chesher (1984) and Lagrange multiplier (LM) tests of Kiefer (1985) and Sharma (1987). Our simulations show that the LR test statistic generally outperforms the IM and LM tests. We also revisit the work of van den Berg and Ridder (1998) on unemployment durations and of Ghysels etÂ al. (2004) on interarrival times between stock trades, and, as it turns out, affirm their original <b>informal</b> <b>inferences.</b> Unobserved heterogeneity Mixture models Likelihood ratio test Search theory Interarrival times...|$|R
5000|$|Many <b>informal</b> Bayesian <b>inferences</b> {{are based}} on [...] "intuitively reasonable" [...] {{summaries}} of the posterior. For example, the posterior mean, median and mode, highest posterior density intervals, and Bayes Factors can all be motivated in this way. While a user's utility function need not be stated {{for this sort of}} inference, these summaries do all depend (to some extent) on stated prior beliefs, and are generally viewed as subjective conclusions. (Methods of prior construction which do not require external input have been proposed but not yet fully developed.) ...|$|R
40|$|A {{common goal}} of neuroimaging {{research}} is to use imaging data to identify the mental processes that are engaged when a subject performs a mental task. The use of reasoning from activation to mental functions, known as “reverse inference,” has been previously criticized {{on the basis that}} it {{does not take into account}} how selectively the area is activated by the mental process in question. In this Perspective, I outline the critique of <b>informal</b> reverse <b>inference</b> and describe a number of new developments that provide the ability to more formally test the predictive power of neuroimaging data...|$|R
