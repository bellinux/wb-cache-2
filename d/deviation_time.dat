31|889|Public
5000|$|In {{statistical}} mechanics, {{the mean}} squared displacement (MSD, also mean square displacement, average squared displacement, or mean square fluctuation) {{is a measure}} of the <b>deviation</b> <b>time</b> between the position of a particle and some reference position. It is the most common measure of the spatial extent of random motion, and can be thought of as measuring the portion of the system [...] "explored" [...] by the random walker. In the realm of biophysics and environmental engineering, the Mean Squared Displacement is measured over time to determine if a particle is spreading solely due to diffusion, or if an advective force is also contributing. Another relevant concept, the Variance-Related Diameter (VRD, which is twice the square root of MSD), is also used in studying the transportation and mixing phenomena in the realm of environmental engineering. It prominently appears in the Debye-Waller factor (describing vibrations within the solid state) and in the Langevin equation (describing diffusion of a Brownian particle). The MSD is defined as ...|$|E
40|$|The {{quantitative}} evaluation of unmanned ground vehicles is difficult. For this problem, we propose a {{quantitative evaluation}} method based on chaos theory. First, the ideal trajectory of an unmanned ground vehicle was designed applying the quintic polynomial method, and the <b>deviation</b> <b>time</b> series {{were obtained by}} calculating the deviation of the actual trajectory from the ideal trajectory. Then, the phase space of the <b>deviation</b> <b>time</b> series was reconstructed based on the improved algorithm using correlation integral method. Finally, the Lyapunov exponent of the <b>deviation</b> <b>time</b> series was calculated, which was the quantitative presentation of the unmanned ground vehicle’s trajectory. The quantitative presentation of the unmanned ground vehicle’s trajectory for lane keeping, obstacle avoidance, and overtaking lane changing was achieved. The Lyapunov exponent of lane keeping was the least, so the maximum predicted time was the longest. Lane keeping was done the best of all. Experimental {{results show that the}} quantitative evaluation method based on chaos theory for unmanned ground vehicle trajectory is feasible and effective...|$|E
40|$|This paper {{describes}} application SCADA {{to monitoring}} and control arm robot. Arm robot always used on modern industry to moving some goods, but it sometimes is not effective if the distance is far away from control room, so it is needed SCADA system to control and monitoring the plant. In this research, the arm robot prototipe is controled with PLC and monitored by HMI/SCADA. Base on test result that <b>deviation</b> <b>time</b> was 0, 487...|$|E
50|$|For {{the context}} of time and {{frequency}} and qualification of oscillators and amplifiers the technical terms <b>time</b> <b>deviation</b> and <b>time</b> variance is defined.|$|R
50|$|Once the {{barriers}} {{of aging and}} environmental effects are removed the only theoretical limitation to holdover performance in such a GPSDO is irregularity or noise in the drift rate, which is quantified using a metric like Allan <b>deviation</b> or <b>Time</b> <b>deviation.</b>|$|R
5000|$|For {{rotational}} diffusion about {{a single}} axis, the mean-square angular <b>deviation</b> in <b>time</b> [...] is ...|$|R
40|$|Good track {{geometry}} state {{ensures the}} safe {{operation of the}} railway passenger service and freight service. Railway transportation {{plays an important role}} in the Chinese economic and social development. This paper studies track irregularity standard <b>deviation</b> <b>time</b> series data and focuses on the characteristics and trend changes of track state by applying clustering analysis. Linear recursive model and linear-ARMA model based on wavelet decomposition reconstruction are proposed, and all they offer supports for the safe management of railway transportation...|$|E
40|$|Power system {{performance}} {{is affected by}} dynamic characteristics of hydraulic governor-turbines during and following any disturbance, such as occurrence of a fault, loss of a transmission line or a rapid change of load. Accurate modelling of hydraulic governor-turbines is essential to characterise and diagnose the system response during an emergency. In this article, both detailed and simplified hydraulic systems governed by proportional-integral-derivative and proportional-integral controllers are modelled. This article examines their transient responses to disturbances through simulation in Matlab/Simulink. The article also investigates the dynamic performance of an isolated hydraulic system through evaluating stability margins, eigenvalues, root loci and frequency <b>deviation</b> <b>time</b> responses of the system. The results obtained provide an insight into {{the stability of the}} power system governed by different governor settings...|$|E
40|$|Highly {{efficient}} and position sensitive photon detection {{is essential in}} a variety of applications from particle identification in fundamental nuclear and particle physics research, to radionuclide imaging in healthcare. Due to their position sensitivity and high packing fraction, the Hamamatsu H 8500 and H 9500 multianode photomultiplier tubes (MAPMTs) are promising candidates for such applications and have thus been studied through precision laser scans at several light intensities. This has revealed signal and crosstalk dependencies upon constructional features of the MAPMTs. Both MAPMTs feature a common last dynode output signal, which can be used for self-triggering. The strength and timing of this signal have been investigated for the H 8500 MAPMT, yielding similar dependencies upon MAPMT construction and standard <b>deviation</b> <b>time</b> resolutions of 67. 5  ps and 154. 4  ps for 20 and single photoelectron signals respectively...|$|E
5000|$|... {{standard}} <b>deviation</b> of <b>time</b> : {{the variability}} of the time for accomplishing an activity (σte) or a path (σTE) ...|$|R
3000|$|... is the {{standard}} <b>deviation</b> at <b>time</b> t, and the following three distances are defined to describe the similarity degree among the monitoring values of the temperature measuring points.|$|R
40|$|The {{muscles and}} tendons in the forearm and {{hand of a}} young man, amputated after an accident, have been weighed and measured. The {{physiological}} cross-sectional areas of those muscles that had long tendons were 35 +/- 9 (mean and standard <b>deviation)</b> <b>times</b> the cross-sectional areas of the tendons. The mean {{is very close to}} the optimum calculated from the theory of Ker, Alexander & Bennett (1988). It implies that the tendons experience stresses of about 11 MPa and strains of about 1. 3 %, when the muscles exert their maximum isometric forces. Very much larger forces would be needed to break the tendons...|$|R
40|$|I {{study the}} {{implications}} of productivity shocks in a model where agents observe the aggregate level of productivity but not its permanent and transitory components separately. The model''s predictions under learning differ substantially from those under full information and {{are in line with}} several empirical findings: (i) the response of investment to a permanent shock is sluggish and peaks with delay; (ii) permanent shocks generate positive rather than negative savings on impact; and (iii) saving and investment are highly correlated despite the assumption of capital mobility. Unlike other standard explanations of the Feldstein-Horioka puzzle, learning induces high correlations irrespective of the assumed persistence of shocks. Productivity;Savings;Economic models;current account, correlations, equation, correlation, random walk, current account dynamics, current account response, forecasting, separability, standard <b>deviation,</b> <b>time</b> series, observable variable, polynomial, current account deficits, predictions, probabilities, calibration, statistics, confidence interval, current account deficit, normal distributions, predictability, current account responses, current account adjustment, survey...|$|E
40|$|Macroeconomic policy {{decisions}} in real-time are based {{the assessment of}} current and future economic conditions. These assessments are made difficult {{by the presence of}} incomplete and noisy data. The problem is more acute for emerging market economies, where most economic data are released infrequently with a (sometimes substantial) lag. This paper evaluates "nowcasts" and forecasts of real GDP growth using five alternative models for ten Latin American countries. The results indicate that the flow of monthly data helps to improve forecast accuracy, and the dynamic factor model consistently produces more accurate nowcasts and forecasts relative to other model specifications, across most of the countries we consider. Data quality assessment framework;Economic forecasting;Economic growth;Forecasting models;gdp growth, forecasting, real gdp, equation, equations, surveys, missing observations, covariance, survey, samples, forecasting techniques, standard deviations, random walk, outliers, data transformation, econometrics, growth rate, standard <b>deviation,</b> <b>time</b> series, outlier, diagonal matrix, gdp per capita, sample sizes, gdp growth rates, constant term, maximum likelihood estimator, growth rates, gdp growth rate, computation, statistics, correlation...|$|E
40|$|This paper {{examines}} how the informational {{efficiency of the}} Japanese stock markets changed {{with the introduction of}} ETFs(Exchange-Traded Funds) by looking at the arbitrage relationships between cash and futures of the Nikkei 225. This paper is unique in that it uses tick data, which enable me to measure the degree of arbitrage by four indexes: 1) the frequency and 2) the size of the deviations from non-arbitrage condition, which reflects the magnitude of arbitrage opportunities, 3) the frequency of arbitrage transactions as a measures of the intensity of arbitrage activities and 4) the time during a deviation from non-arbitrage condition for an indicator of the achieved informational efficiency. I found that the frequency {{and the size of the}} deviations as well as the frequency of arbitrage transactions increased significantly. However, the <b>deviation</b> <b>time</b> did not change. These results suggest that while arbitrage opportunities increased, the intensified arbitrage activities balanced out it, resulting in the invariant time of deviation. ETF(Exchange-Traded Funds), Arbitrage Relationship, Arbitrage Activity...|$|E
3000|$|Table 5 {{shows that}} in all three control charts, the {{variation}} of the Bayesian estimates for time tends to reduce when the magnitude of slope increases. The mean of posterior standard <b>deviation</b> for <b>time,</b> [...]...|$|R
30|$|Based on the {{stability}} analysis of WTS, the <b>deviation</b> of <b>time</b> domain response between WTS and WT resulted from the one-step time delay of acceleration observation is further discussed and mitigated by the improved inertia compensation scheme.|$|R
40|$|This paper {{presents}} a multivariate (MV) methodology for obtaining measures of excess demand that can facilitate discussion of monetary policy issues and improve policy decisions. Using {{data for the}} Czech Republic, a growing economy undergoing major structural change, it shows how the use of more information to condition the paths of potential output and the non accelerating inflation rate of unemployment (NAIRU) improves on univariate methods as the Hodrick-Prescott (HP) filter. Unemployment;Production;Economic models;nairu, equation, equations, covariance, random walk, unemployment rate, forecasting, standard <b>deviations,</b> <b>time</b> series, constant term, rate of change, rate of unemployment, econometrics, random variables, correlation, time series analysis, samples, prediction, structural unemployment, survey...|$|R
40|$|Let α ([0, 1]^p) {{denote the}} {{intersection}} local time of p independent d-dimensional Brownian motions {{running up to}} the time 1. Under the conditions p(d- 2) 2, we prove lim_t→∞t^- 1 Pα([0, 1]^p) > t^(d(p- 1)) / 2 =-γ_α(d,p) with the right-hand side being identified {{in terms of the}} the best constant of the Gagliardo-Nirenberg inequality. Within the scale of moderate deviations, we also establish the precise tail asymptotics for the intersection local time I_n=#(k_ 1, [...] .,k_p) ∈ [1,n]^p;S_ 1 (k_ 1) = [...] . =S_p(k_p) run by the independent, symmetric, Z^d-valued random walks S_ 1 (n), [...] .,S_p(n). Our results apply to the law of the iterated logarithm. Our approach is based on Feynman-Kac type large <b>deviation,</b> <b>time</b> exponentiation, moment computation and some technologies along the lines of probability in Banach space. As an interesting coproduct, we obtain the inequality (EI_n_ 1 + [...] . +n_a^m) ^ 1 /p 0 m!/k_ 1 ! [...] . k_a!(EI_n_ 1 ^k_ 1) ^ 1 /p [...] . (EI_n_a^k_a) ^ 1 /p in the case of random walks. Comment: Published at [URL] in the Annals of Probability ([URL] by the Institute of Mathematical Statistics ([URL]...|$|E
40|$|Let α([0, 1] p) {{denote the}} {{intersection}} local time of p independent d-dimensional Brownian motions {{running up to}} the time 1. Under the conditions p(d − 2) < d and d ≥ 2, we prove lim t→ ∞ t− 1 log P{α([0, 1] p) ≥ t (d(p− 1)) / 2 } = −γα(d,p) with the right-hand side being identified {{in terms of the}} the best constant of the Gagliardo–Nirenberg inequality. Within the scale of moderate deviations, we also establish the precise tail asymptotics for the intersection local time In = #{(k 1, [...] .,kp) ∈ [1,n] p;S 1 (k 1) = · · · = Sp(kp) } run by the independent, symmetric, Z d-valued random walks S 1 (n), [...] .,Sp(n). Our results apply to the law of the iterated logarithm. Our approach is based on Feynman–Kac type large <b>deviation,</b> <b>time</b> exponentiation, moment computation and some technologies along the lines of probability in Banach space. As an interesting coproduct, we obtain the inequality (EI m n 1 +···+na) 1 /p ∑ m! n 1) 1 /p · · ·(EI ka na) 1 /p k 1 +···+ka=m k 1, [...] .,ka≥ 0 in the case of random walks. k 1 ! · · ·ka! (EIk 1 1. Introduction. Let {S 1 (n) }, [...] .,{Sp(n...|$|E
40|$|Background: Implant {{fractures}} {{are rare}} but offer a challenging clinical situation. Purpose: To determine {{the prevalence of}} implant fracture and the possible risk factors predisposing an implant to a higher fracture risk. Materials and Methods: This retrospective study is based on 2670 patients consecutively treated with implant-supported prostheses. Anatomical-, patient-, and implant-related factors were collected. Descriptive statistics and survival analyses were performed. Generalized estimating equations (GEE) evaluated the effect of explanatory variables on implant fracture. Results: Forty-four implants (out of 10 099; 0. 44 %) fractured. The mean[*]±[*]standard <b>deviation</b> <b>time</b> for fracture to occur was 95. 1 [*]±[*] 58. 5 months (min-max, 3. 8 - 294. 7). Half of the occurrences of fracture happened between 2 and 8 years after implantation. Five factors had a statistically significant influence on the fracture of implants (increase/decrease in fracture probability) : use of higher grades of titanium (decrease 72. 9 %), bruxism (increase 1819. 5 %), direct adjacency to cantilever (increase 247. 6 %), every 1 mm increase in implant length (increase 22. 3 %), every 1 mm increase in implant diameter (decrease 96. 9 %). Conclusions: It is suggested that 5 factors could influence the incidence of implant fractures: grade of titanium, implant diameter and length, cantilever, bruxism...|$|E
40|$|Mobile {{messaging}} applications, such as WhatsApp, {{provide a}} free alternative for mobile texting on smartphones. Mobile messengers typically also share presence information about users to indicate when a user is online. We investigated the privacy implications of such presence updates, using WhatsApp as an example. We conducted a user study with two independent groups (19 participants in total), {{in which we}} collected and analyzed their presence information over four weeks of regular WhatsApp use and conducted follow-up interviews. Our results show that presence information alone is sufficient to accurately identify, for example, daily routines, <b>deviations,</b> <b>times</b> of inappropriate mobile messaging, or conversation partners. We discuss resulting privacy implications of presence information and potential solutions to mitigate these issues...|$|R
40|$|Abstract – In {{this paper}} the methods {{enabling}} real-time calculation of two commonly used parameters of timing signals – Allan <b>deviation</b> (ADEV) and <b>time</b> <b>deviation</b> – are presented. The idea of real-time computation of both parameters is described. The results of experimental {{tests of the}} methods enabling separate as well as joint real-time ADEV and TDEV computation are presented and discussed. Index Terms – timing signal, <b>time</b> error, Allan <b>deviation...</b>|$|R
50|$|<b>Time</b> <b>deviation</b> (TDEV), {{also known}} as , is the time {{stability}} of phase x versus observation interval τ of the measured clock source. The <b>time</b> <b>deviation</b> thus forms a standard deviation type of measurement to indicate the time instability of the signal source. This is a scaled variant of frequency stability of Allan deviation. It is commonly defined from the modified Allan deviation, but other estimators may be used.|$|R
40|$|This study assesses spatio-temporal {{changes in}} inter-annual {{variability}} of temperature, precipitation and runoff for 1962 - 2014 at sub-basin scale in Finland. The analysis {{is based on}} 1) interpolated areal average temperature and total precipitation based on corrected observations, and 2) modelled runoff based on the areal averages, both prepared by the Finnish Environmental Institute (SYKE). Temporal changes in variability were analyzed by constructing moving window median absolute <b>deviation</b> <b>time</b> series at annual and seasonal scales. Sub-basins with similar patterns of temporal variability were identified using principal component analysis and agglomerative hierarchical clustering. Presence of monotonic trends in variability was tested. Distinct areas with similar patterns of statistically significant changes in variability were found. Decreases in temperature variability were found annually, in winter and in summer, respectively {{in many parts of}} Finland, the south and the north. Precipitation variability increased in autumn in northern Finland, and decreased annually as well as in winter and spring in northern and central parts of Finland. Runoff variability increased in winter in most parts of Finland and in summer in the central parts, as well as decreased in spring in southern Finland. Findings of this study describes hydro-climatic variability in Nordic conditions and hence potentially improves the possibility to adapt and predict the changes in hydro-climatic conditions, including weather extremes...|$|E
40|$|This paper aims at clarifying, {{with the}} help of a simple formal model and {{numerical}} examples, several aspects of the relationship between international investment position (IIP) and balance of payments (BOP) statistics. Exact and approximated relations are compared to analyze the estimation accuracy of the most popular data model used to reconcile BOP transaction statistics with IIP and external debt stock statistics, and discuss (a) how such accuracy is affected by volatile asset prices and transactions and (b) how net errors and omissions are related to the model in question. Numerical examples based on equity prices and exchange rates actually observed in the 1990 s suggest that the bias might have been especially large for estimates based on less detailed financial information. Serious consideration should be therefore given by national compilers to make use of more detailed financial information in compiling BOP and IIP statistics. Balance of payments statistics;External debt;Capital outflows;exchange rates, statistics, equation, exchange rate, equations, estimation bias, correlation, survey, measurement errors, exchange rate indices, arithmetic, standard <b>deviation,</b> <b>time</b> series, constant exchange rates, exchange rate adjustments, estimation period, foreign exchange, confidence intervals, statistical information, foreign exchange rates, independent variables, exchange rate valuation, statistical terms, prediction, currency exchange rate, exchange rate movements, financial statistics, national currency exchange rate, surveys, exchange rate changes, computations, samples, floating exchange rate...|$|E
40|$|We {{provide an}} {{empirical}} and theoretical {{assessment of the}} value of information sharing in a two-stage supply chain. The value of downstream sales information to the upstream firm stems from improving upstream order fulfillment forecast accuracy. Such an improvement can lead to lower safety stock and better service. Based on the data collected from a CPG company, we empirically show that, if the company includes the downstream sales data to forecast orders, the improvement in the mean squared forecast error ranges from 7. 1 % to 81. 1 % across all studied products. Theoretical models in the literature, however, suggest that the value of informa-tion sharing should be zero for over half of our studied products. To reconcile the gap between the literature and the empirical observations, we develop a new theoretical model. While the literature assumes that the decision maker strictly adheres to a given inventory policy, our model allows him to deviate, accounting for private information held by the decision maker, yet unobservable to the econometrician. This turns out to reconcile our empirical findings with the literature. These “decision deviations ” lead to information losses in the order process, resulting in a strictly positive value of downstream information sharing. Furthermore, we empirically quantify and show the significance {{of the value of}} knowing the downstream replenishment policy. Key words: supply chain, information sharing, signal propagation, decision <b>deviation,</b> <b>time</b> series, empirical forecasting, ARIMA process...|$|E
40|$|We {{investigate}} a single machine rescheduling problem that arises from an unexpected machine unavailability, after the given set of jobs {{has already been}} scheduled to minimize the total weighted completion time. Such a disruption is represented as an unavailable time interval and is revealed to the production planner before any job is processed; the production planner wishes to reschedule the jobs to minimize the alteration to the originally planned schedule, which is measured as the maximum <b>time</b> <b>deviation</b> between the original and the new schedules for all the jobs. The objective function in this rescheduling problem is to minimize {{the sum of the}} total weighted completion time and the weighted maximum <b>time</b> <b>deviation,</b> under the constraint that the maximum <b>time</b> <b>deviation</b> is bounded above by a given value. That is, the maximum <b>time</b> <b>deviation</b> is taken both as a constraint and as part of the objective function. We present a pseudo-polynomial time exact algorithm and a fully polynomial time approximation scheme, the latter of which is the best possible given that the general problem is NP-hard. Comment: 17 page...|$|R
5000|$|<b>Time</b> <b>deviation</b> (TDEV) is a {{statistical}} analysis of the phase stability of a signal over a given period of time.|$|R
50|$|There {{are also}} {{different}} adaptations or alterations of Allan variance, notably the modified Allan variance MAVAR or MVAR, the total variance, and the Hadamard variance. There also exist time stability variants such as <b>time</b> <b>deviation</b> TDEV or <b>time</b> variance TVAR. Allan variance and its variants have proven useful outside {{the scope of}} timekeeping and are a set of improved statistical tools to use whenever the noise processes are not unconditionally stable, thus a derivative exists.|$|R
40|$|Active {{database}} systems (ADSs) react automatically to {{the occurrence}} of predefined events by defining a set of active rules. One of the main modules of an ADS is the rule scheduler, which has {{a significant impact on}} the effectiveness and efficiency of ADSs. During the rule scheduling process, the rule scheduler is responsible for choosing one of the activated or ready-to-be-executed rules to evaluate its condition section or execute its action section, respectively. This process continues until there is no rule to be evaluated or executed. In this research, we evaluate and compare existing rule scheduling approaches in a laboratory environment based on a three-tier architecture. There are criteria used for the evaluation and comparison of rule scheduling approaches: Average Response Time, Throughput, Response Time Standard <b>Deviation,</b> <b>Time</b> Overhead per Transaction, and CPU Utilization. The three first criteria are used to evaluate the effectiveness, and the latter two criteria are used to evaluate the efficiency of rule scheduling approaches. In this paper, a new approach, referred to as EX-SJFEsTLA, is proposed to improve the rule scheduling process, using a learning automaton. In our laboratory environment, EX-SJFEsTLA is compared with those rule scheduling approaches that are unconstrained as EX-SJFEsTLA is. Unconstrained scheduling approaches serially schedule the rules that do not have any priorities or deadlines The results of experiments revealed that the proposed approach improved the rule scheduling process according to the evaluation criteria...|$|E
40|$|A {{critical}} {{discussion of}} a comparative growth analysis about Central and Eastern European (CEE) countries is performed. The main conclusion {{is that there was}} economic convergence for most CEE accession candidates, but not between them and Western Europe. Results do justify a separation into first and second-wave accession countries, but also undermine differences in Central and Eastern Europe between accession and non-accession countries. This paper critically examines theories and empirical studies for three types of convergence, namely β,σ and club convergence. Each can be in absolute terms or conditional to the long-term equilibrium (steady state) for each country. Empirical results are provided for all types of convergence from 1996 to 2000, both with population-weighted and non-weighted data. The analysis is performed for differently framed country subgroups considering even Western Europe for better comparability. Once absolute convergence is found through a unit root test about a standard <b>deviation</b> <b>time</b> series of cross-sectional income per capita, the regression coefficient for initial income per capita with the average growth over the sample period as dependent variable (β convergence) establishes the speed of this process. The same method applies to the conditional version by using the distance of the income from the corresponding steady state instead of the level of GDP. Then Markov chain probability matrixes (club convergence) provide information about the past behaviour of the whole cross-sectional income distribution over time, but also about intra-mobility of single countries. Copyright Kluwer Academic Publishers 2003 β and σ convergence, Central and Eastern Europe, club convergence, comparative growth analysis, Eastern Enlargement of the EU, economic convergence,...|$|E
40|$|Active rule {{scheduling}} Learning automata a b s t r a c t Active database systems (ADSs) react automatically to {{the occurrence}} of predefined events by defining a set of active rules. One of the main modules of an ADS is the rule scheduler, which has {{a significant impact on}} the effectiveness and efficiency of ADSs. During the rule scheduling process, the rule scheduler is responsible for choosing one of the activated or ready-to-be-executed rules to evaluate its condition section or execute its action section, respectively. This process continues until there is no rule to be evaluated or executed. In this research, we evaluate and compare existing rule scheduling approaches in a laboratory environment based on a three-tier architecture. There are criteria used for the evaluation and comparison of rule scheduling approaches: Average Response Time, Throughput, Response Time Standard <b>Deviation,</b> <b>Time</b> Overhead per Transaction, and CPU Utilization. The three first criteria are used to evaluate the effectiveness, and the latter two criteria are used to evaluate the efficiency of rule scheduling approaches. In this paper, a new approach, referred to as EX-SJFEsTLA, is proposed to improve the rule scheduling process, using a learning automaton. In our laboratory environment, EX-SJFEsTLA is compared with those rule scheduling approaches that are unconstrained as EX-SJFEsTLA is. Unconstrained scheduling approaches serially schedule the rules that do not have any priorities or deadlines. The results of experiments revealed that the proposed approach improved the rule scheduling process according to the evaluation criteria. & 2014 Elsevier Ltd. All rights reserved. 1...|$|E
5000|$|Shifting {{of the end}} of {{the stop}} pulse is a <b>deviation</b> in {{character}} <b>time</b> and rate rather than an end distortion.|$|R
40|$|System <b>time</b> <b>deviation</b> and {{inadvertent}} interchange {{energy of}} an area are considered as a vector with two coordinates. For any one control area, {{the rest of the}} interconnection is considered as one equivalent area. The two-dimensional vector which represents system <b>time</b> <b>deviation</b> (epsilon) and inadvertent interchange energy I can be decomposed into two vector components: a component caused by the area itself, and a component caused {{by the rest of the}} interconnection. The former vector component represents the area component of the system <b>time</b> <b>deviation</b> and the primary component of inadvertent interchange energy as defined by Nathan Cohn. The latter vector component represents the area component of system <b>time</b> <b>deviation</b> and the secondary component of inadvertent interchange energy caused by the rest of the interconnection as defined by Cohn;The concept of vector decomposition can be illustrated on the two-dimensional Cartesian plane. This plane is called the ((epsilon),I) plane. Some properties of the effect of the control actions on system <b>time</b> <b>deviation</b> and inadvertent interchange energy are discussed. Control actions investigated are the automatic generation control actions and/or corrective control actions in and/or outside an area. Various corrective control schemes are investigated and illustrated. These corrective control schemes are compared in terms of energy (MWH) required for the control action;The causes of excessive accumulation of inadvertent interchanges encountered in the Western System Coordinating Council are investigated. The possible situations that can lead to excessive accumulation of inadvertent interchanges in the area of interest are investigated using an Automatic Generation Control (AGC) simulation program. Selective participation in the continuous, automatic time error correction scheme is also investigated;The validity of the decomposed vector components {{of an area}} itself and of the rest of the interconnection is checked using the AGC computer program. These results confirm the validity of the concept of vector decomposition;Finally, three examples of debit/credit computation, based on area components of system <b>time</b> <b>deviation,</b> are presented. With the help of the debit/credit system, the inadvertent interchange energy accounts of control areas can be adjusted properly in order to correct the system <b>time</b> <b>deviation</b> to zero with a minimum amount of regulation (MWH) in the whole interconnected power systems...|$|R
50|$|Some {{temperature}} indicators give {{a visual}} signal that a specified temperature has been exceeded. Others, Time temperature indicators, signal when a critical accumulation of temperature <b>deviation</b> over <b>time</b> has been exceeded. When {{the mechanism of}} the indicator is tuned to the mechanism of product degradation, these can provide valuable signals for consumers.|$|R
