45|138|Public
5000|$|The {{film was}} shot over 35 {{days at a}} drive in at Matraville {{starting}} on 9 September 1985. Funding came from the New South Wales Film Corporation. The director said of the film that:The Drive-In is, of course, an allegory for the junk values of the eighties, which our hero sees as a prison. The last 20 minutes of the film - the escape - is the desperate blazing climax, but the whole film has a feeling of high style, of heightened or <b>enhanced</b> <b>reality</b> - a little bit over the top, but retaining a reality that the public will accept.The final stunt by Guy Norris cost around $75,000, more than any single stunt performed in Australia until then, and set a world record for a jump by a truck: 49.378 metres (162 feet.) ...|$|E
50|$|Gradiant is {{currently}} working on several technologies for the implementation of advanced applications, such as cloud technologies and other next generation paradigms, especially in connection with privacy and security, development platforms and analytical systems. In this field, Gradiant cooperates with the key Spanish multi-national companies and has operative demonstrators. Research is also focusing on <b>enhanced</b> <b>reality</b> powered context-dependent information systems for training and technical management in industrial and hospital environments. Regarding the provision of services to network suppliers, Gradiant is working in the integration of heterogeneous services according to international standards. Finally, there is also much work being done in the field ofbusiness intelligence technologies (dashboards, patented algorithms for the in-memory compression of multidimensional databases, big data mining), equally in cooperation with important private firms. Gradiant’s substantial networkingcapacities facilitate the implementation of a multi-layered approach to global projects, guaranteeing optimal results.|$|E
40|$|<b>Enhanced</b> <b>reality</b> {{visualization}} is {{the process}} of enhancing an image by adding to it information which is not present in the original image. A wide variety of information can be added to an image ranging from hidden lines or surfaces to textual or iconic data about a particular part of the image. <b>Enhanced</b> <b>reality</b> visualization is particularly well suited to neurosurgery. By rendering brain structures which are not visible, at the correct location in an image of a patient's head, the surgeon is essentially provided with X-ray vision. He can visualize the spatial relationship between brain structures before he performs a craniotomy and during the surgery he can see what's under the next layer before he cuts through. Given a video image of the patient and a three dimensional model of the patient's brain, the problem <b>enhanced</b> <b>reality</b> visualization faces is to render the model from the correct viewpoint and overlay it on the original image. The relationship between the coordinate frames of t [...] ...|$|E
5000|$|... #Caption: [...] App iWow, {{a mobile}} {{device-based}} augmented <b>reality</b> <b>enhanced</b> world globe ...|$|R
5000|$|... 2014: Mahei {{creates the}} first {{generation}} of augmented <b>reality</b> <b>enhanced</b> educational toys.|$|R
5000|$|Virtual {{brain tumors}} (gliomas) <b>enhance</b> the <b>reality</b> of medical imaging and {{highlight}} inadequacies of current therapy (with K.R. Swanson and E.C. Alvord). British J. Cancer 86: 14-18, 2002. {{for inclusion in}} the 2003 Yearbook of the Institute of Oncology ...|$|R
40|$|The {{problem which}} must be solved to make realtime <b>enhanced</b> <b>reality</b> {{visualization}} possible is basically the camera calibration problem. The relationship between the coordinate frames of the patient, the patient's internal anatomy scans and the image plane of the camera observing the patient must be established. This paper presents {{a new approach to}} finding this relationship and develops a system for performing <b>enhanced</b> <b>reality</b> visualization. Given the locations of a few fiducials our method is fully automatic, runs in nearly real-time, is accurate to a fraction of a pixel, allows both patient and camera motion, automatically corrects for changes to the internal camera parameters (focal length, focus, aperture, etc.) and requires only a single video image. 1 Introduction <b>Enhanced</b> <b>reality</b> visualization is the process process of adding information to a real image. We take a model of the patient obtained from MR or CT data and overlay it on a video image of the patient. The enhanced imag [...] ...|$|E
40|$|<b>Enhanced</b> <b>reality</b> {{visualization}} is {{the process}} of enhancing an image by adding to it information which is not present in the original image. A wide variety of information can be added to an image ranging from hidden lines or surfaces to textual or iconic data about a particular part of the image. <b>Enhanced</b> <b>reality</b> visualization is particularly well suited to neurosurgery. By rendering brain structures which are not visible, at the correct location in an image of a patient's head, the surgeon is essentially provided with X-ray vision. He can visualize the spatial relationship between brain structures before he performs a craniotomy and during the surgery he can see what's under the next layer before he cuts through. Given a video image of the patient and a three dimensional model of the patient's brain the problem <b>enhanced</b> <b>reality</b> visualization faces is to render the model from the correct viewpoint and overlay it on the original image. The relationship between the coordinate frames of the patient, the patient's internal anatomy scans and the image plane of the camera observing the patient must be established. This problem is closely related to the camera calibration problem. This report presents a new approach to finding this relationship and develops a system for performing <b>enhanced</b> <b>reality</b> visualization in a surgical environment. Immediately prior to surgery a few circular fiducials are placed near the surgical site. An initial registration of video and internal data is performed using a laser scanner. Following this, our method is fully automatic, runs in nearly real-time, is accurate to within a pixel, allows both patient and camera motion, automatically corrects for changes to the internal camera parameters (focal length, focus, aperture, etc.) and requires only a single image...|$|E
40|$|Live {{role-playing}} {{is a form}} of improvisational theatre {{played for}} the experience of the performers and without an audience. These games form a challenging application domain for ubiquitous technology. We discuss the design options for <b>enhanced</b> <b>reality</b> live role-playing and the role of technology in live role-playing games...|$|E
40|$|Interactive {{autonomous}} and directable characters require certain architectural {{support such}} as a motor system which moves the character based on decisions made by the behavior system. While previous work has focused on these higher-level systems, {{we focus on the}} infrastructure provided by the graphics system. We describe how a graphics system designed with synthetic characters in mind can be behavior-friendly, simplifying motor and behavior system construction and making new characters easier to create. The system described in this paper was the underlying support for "Swamped!", an interactive 3 -D cartoon demonstrated in the <b>Enhanced</b> <b>Realities</b> section of SIGGRAPH 98 [6, 8]. We describe how our design and implementation allowed us to achieve real-time performance in this Java application...|$|R
40|$|Recently, {{graphics}} hardware {{has increased}} in capability, and is, moreover, now available even on standard PCs. These advances have encouraged researchers to develop hardware-accelerated methods for rendering realistic images. One of the important elements in <b>enhancing</b> <b>reality</b> {{is the effect of}} atmospheric scattering. The scattering of light due to atmospheric particles has {{to be taken into account}} in order to display shafts of light produced by studio spotlights and headlights of automobiles, for example. The purpose of this paper is to develop a method for displaying shafts of light at interactive rates by making use of the graphics hardware. The method makes use of hardware-accelerated volume rendering techniques to display the shafts of light...|$|R
40|$|Article dans revue scientifique avec comité de lecture. Mixing {{video and}} computer-generated images {{is a new}} and {{promising}} area of research for <b>enhancing</b> <b>reality.</b> It {{can be used in}} all the situations when a complete simulation would not be easy to implement. Past work on the subject has relied for a large part on human intervention at key moments of the composition. In this paper, we show that if enough geometric information about the environment are available, then efficient tools developed in the computer vision literature can be used to build a highly automated augmented reality loop. We focus on outdoor urban environments and present an application for the visual assessment of a new lighting project of the bridges of Paris...|$|R
40|$|Computer-assisted {{surgery and}} {{intraoperative}} navigation are novel tools {{used to enhance}} patient treatment and surgical safety. Computer-assisted technologies allow for optimal planning of complex surgeries in a multidisciplinary setting. 3 D models can also be created from pre-chemotherapy MRI and pre-surgery CT-scan data. The surgery can then be performed in an <b>enhanced</b> <b>reality</b> modus where the tumor is visible at its initial size...|$|E
40|$|In this paper, {{a general}} {{framework}} for using Virtual Reality techniques {{in the domain}} of Archaeological Visualisation is presented. It is argued that “visualising” {{is not the same as}} “seeing”, but is an inferential process to understand reality. A definition of <b>Enhanced</b> <b>Reality</b> is also presented, and how visual models can be used in order to obtain additional information about the dynamic nature of historical processes and archaeological data...|$|E
40|$|<b>Enhanced</b> <b>reality</b> is an {{approach}} to support complex situations based on image data by combining real images with spatial, structural, and functional models of the domain in a common scene. Examples are diagnostic medical imaging, computer-supported minimally invasive surgery, and protein analysis in molecular biology. These visual and dynamic applications can hardly be developed using paper-based models. Instead, we recommend to use actual interactive scenes as immediate design representations. Scenes act as mediators between scenarios {{that focus on the}} processes and domain models that later migrate into application objects. The situated view, associating opportunities for action within a situation, is covered by neither scenarios nor domain objects. Using scenes as design representations requires appropriate toolbox support, e. g. by 3 -D graphics libraries. Thanks to the common spatial nature of all parts of an <b>enhanced</b> <b>reality</b> scene, different parts can be developed and prototyped independently. In particular, the integration of functionality can be postponed to the later development, as manual staging of a scene is acceptable during early design phases...|$|E
50|$|Architectural {{animation}} {{is a short}} architectural movie {{created on}} a computer. A computer-generated building is created along with landscaping and sometimes moving people and vehicles. Unlike an architectural rendering, which is a single image from a single point of view, an architectural animation {{is a series of}} hundreds or even thousands of still images. When these images are assembled and played back they produce a movie effect much like a real movie camera except all images are artificially created by computer. It is possible to add a computer-created environment around the building to <b>enhance</b> <b>reality</b> and to better convey its relationship to the surrounding area; this can all be done before the project is built giving designers and stakeholders a realistic view of the completed project. Architectural renderings are often used along with architectural animation.|$|R
40|$|Recent {{development}} in sound technologies has enabled the realistic replay of real-life sounds. Thanks to these tech-nologies, we can experience a virtual real sound environ-ment. However, {{there are other}} types of sound technologies that <b>enhance</b> <b>reality,</b> such as acoustic filters, sound effects, and background music. They are quite effective if carefully prepared, but they also alter the sound itself. Consequently, sound is simultaneously used to reconstruct realistic envi-ronments and to enhance emotions, which are actually in-compatible functions. With this background, we focused on using tactile modality to enhance emotions and propose a method that enhances the sound experience {{by a combination of}} sound and skin sensation to the pinna (earlobe). In this paper, we evaluate the effectiveness of this method. ACM Classification: H 5. 2 [Information interfaces an...|$|R
50|$|The artworks in {{this series}} usually show a {{hand-drawn}} 2D sketch held and photographed by the artist in a specific location. They combine photography and drawing to infuse ordinary scenes with new surreal, visionary, or romanticized narratives. The inclusion of hand-held penciled sketches over {{a portion of the}} original photos allows Heine to <b>enhance</b> <b>reality</b> and open doors to an imaginary world. Heine brought some innovations to the concept in 2012 adding colors and black paper. Between 2010 and 2016, Heine's creations have been seen by the people through the exhibitions and news articles in major media outlets. Heine's first Pencil Vs Camera's images quickly gained popularity online and received positive criticisms from specialized and influential art sites along with news reports and international opportunities for the artist.|$|R
40|$|With {{virtual reality}} systems making heavy demands on many leading edge technologies, {{practical}} applications within real time environments are reliant on advances throughout science and engineering. <b>Enhanced</b> <b>Reality</b> (ER) describes an important set of systems in which technology {{is used to}} create and present information synthesised with the real world. The potential for computer ÔannotatedÕ reality enhancement is diverse and spans not only virtual reality but also machine vision, image processing techniques, auditory landscaping, as well as others. Network centered solutions utilising wearable computing platforms are recognised by the authors as enabling future collaborative working and telecommunications environments...|$|E
30|$|Discussion: Visualization of {{structures}} by fluorescence is emerging technology as used for bladder cancer and blood flow. Similarly algorithms enhancing vascularization {{might be useful}} for diagnosis of endometriosis. What is lacking is real time integration of surgical images, i.e. <b>enhanced</b> <b>reality.</b> Live surgery is important for teaching and learning, although not demonstrated. Video registration is a great tool for teaching and for debriefing. Video registration of entire interventions is claimed to be useful since review of the surgery would facilitate {{diagnosis and treatment of}} complications. Video registration also is claimed to be useful medico legally to demonstrate that surgery was done carefully. Also the usefulness of 3 D remains a claim.|$|E
40|$|The {{practice}} of architecture itself {{has lost the}} ability to draw and imagine. Drawings used to negotiate the dimensions between the human and the cosmic. Today, it has been transmuted into a render factory of sexy images depicting an <b>enhanced</b> <b>reality.</b> ‘Drawing’ in architecture has lost its cultural importance and leads to a misrepresentation of design. Accessibility to visual interpretations of architecture has evoked false realities of the built environment. Do we want architectural understanding to be available to all levels of society but at the expense of truth? Architecture has become a product for the consumption of images; we design permanent structures for an ephemeral society...|$|E
30|$|First of all, {{in order}} to <b>enhance</b> the <b>reality</b> or {{practicality}} of our data model, we collected materials which are actually used at four general tertiary hospitals in Korea. Then, we selected eight types of materials commonly used. Our samples contain four types of images/videos, two types of reports, and two types of examination result reports.|$|R
40|$|A novel {{simulation}} method {{of the brush}} stroke is proposed by applying force feedback technology to the virtual painting process. The relationship between force and the brush deformation is analyzed, and the spring-mass model is applied to construct the brush model, which can realistically simulate the brush morphological changes according to the force exerted on it. According to the deformation of the brush model at a sampling point, the brush footprint between the brush and the paper is calculated in real time. Then, the brush stroke is obtained by superimposing brush footprints along sampling points, and the dynamic painting of the brush stroke is implemented. The proposed method has been successfully applied to the virtual painting system based on the force feedback technology. In this system, users can implement the painting in real time with a Phantom Desktop haptic device, which can effectively <b>enhance</b> <b>reality</b> to users...|$|R
40|$|Why gather? The Luxury of Sharing Time and Space In a world, were {{direct contact}} {{seems to be}} {{replaceable}} by virtual gatherings and digitally <b>enhanced</b> <b>realities,</b> and when we are sceptical about whether the recorded debate we listen to actually happened rather than being cut, pasted and edited, direct contact {{can be seen as}} a rare event of true and life interaction and exchange. But have ‘real-time’ or ‘life’ events indeed become an exclusivity or the ‘true’ luxury of our times? Why do we bother to coordinate busy schedules and travel thousands of miles to meet? Have we understood the importance and irreplaceability of actual events that allow selected groups of people to share a specific space to interact directly and experience something together? This paper wants to interrogate notions of luxury and necessity in sharing time and space through the concept of performativity in current art and design practice...|$|R
40|$|The {{main goal}} of Nano {{technology}} is {{to analyze and}} understand the matter at the atomic and molecular level. While the researchers of Nano technology are lack of an efficient tool which can manipulate the material such as CNT to accomplish the CNT-FET or CNT-sensor. The manipulation robot based on AFM tip can perform the Nano manipulation with the <b>enhanced</b> <b>reality.</b> This paper shows a system view of the Nano manipulation system and the system design of the manipulation system. We can build nano manipulation robot based on the system we design {{with the help of}} haptic device. IEEE Robot & Automat Soc, Shandong Univ, Chinese Univ Hong Kong, Chiba Inst Technol, Robot Soc Japan, Soc Instrument & Control Engn, Japan Soc Mech Engn, ROBIO Fd...|$|E
40|$|International audienceWe {{present the}} use of {{cortical}} sulci, segmented from magnetic resonance imaging, in image guided neurosurgery. Sulcal information was transferred to a surgical microscope with <b>enhanced</b> <b>reality</b> features. This assistance {{was used for the}} resection of supratentorial cavernomas (7 patients). Sulci were semi-automatically segmented from 3 D MRI data sets. Sulci close to the cavernoma were selected and transferred to the neuronavigation system which allows the superimposition of graphics into the right ocular of the microscope. Selected sulci were displayed on the workstation and superimposed into the ocular of the microscope. Cortical sulci proved to be useful for the recognition of the anatomical environment. The superimposed sulci helped to optimize location and size of the skin incision as well as to guide the access to the cavernoma by using the course of a sulcus as indirect trajectory...|$|E
40|$|LOCALITE is a {{frameless}} neuronavigation {{system that}} particularly addresses {{a problem with}} currentinterventional magnetic resonance imaging #iMRI# systems: non-interactive response time in the interactive scan mode and poor image quality with fast scanning sequences. LOCALITE calculates image planes selected via a handheld localizer from pre- or intra-operativevolume data sets. This approach provides a really interactive localizer device with high quality images. The volume data are generated after the patient has been broughtinto the operating room and #xed within the iMRI. Images {{are part of an}} <b>enhanced</b> <b>reality</b> scenario containing only the salient visual information for the intra-operative task rather than letting the surgeon drown in lots of images. First studies show that LOCALITE enables the surgeon to use the iMRI system intuitively and much faster. 1 Introduction With minimally invasiveinterventions, the surgeon's direct view is often extremely restricted. Recent [...] ...|$|E
30|$|When {{a normal}} vector is {{assigned}} to the 3 D model, the image rendered by the rendering engine becomes three-dimensional. However, the model lacks texture and still lacks authenticity. Texture is an important surface attribute in 3 D model. If the real picture is taken as {{the texture of the}} 3 D model, it can greatly <b>enhance</b> the <b>reality</b> of the model.|$|R
40|$|Presented on October 5, 2010, from 5 : 30 pm to 7 : 00 pm at the Student Success Center, Clary Theater on the Georgia Tech campus. The Georgia Tech Honors Program welcomed Dr. Sidney Perkowitz, Professor of Physics at Emory University, who {{presented}} a talk on "Hollywood Science: Good for Hollywood, Bad for Science?"Runtime: 58 : 41 minutesThere’s plenty {{of science in}} Hollywood’s science fiction and superhero films, but {{how much of it}} is real and how much is pure Hollywood? It’s hard to tell because these films often amp up a meaningful scientific premise to <b>enhance</b> <b>reality,</b> improve dramatic impact, or support stunning special effects. Examples include superhuman powers arising from favorable mutations, human clones used for spare body parts, and breakthroughs like intelligent robots, fusion power, and faster-than-light space travel. Dr. Perkowitz will show clips from a variety of science fiction films and examples from his book Hollywood Science to illustrate differences and connections between real science and Hollywood science...|$|R
40|$|This article aims at {{discussing}} the relationship throughout school life. School habits are usually complying rules/contents already {{established by the}} institutional circle. Under this condition, they hide a more careful consideration about how the overthrowing manifestations made by students may be seen from another prism rather than the alienation and disrespect but as a translation of desire/affliction/crisis, which reveal the own society itself, its facets of conflicts, contraditions and inequality. That {{is to say the}} students overthrow might be interpositions and ways of questioning about the adaptation of the very didactic-pedagogical habits and its contents, seen such as unsuitable to reply the wishes of their realities/universes. So, talking over a creative overthrowing it may be a pedagogical exercise in a way to contribute to search path where the students are subjects of the knowledge production. This path may bring a better sizing for concrete life and its problem in a manner that education <b>enhances</b> <b>reality</b> understanding, with the purpose to contribute for an actual humanization...|$|R
40|$|This paper {{introduces}} a novel interface for digitallyaugmented cooperative play. We present {{the concept of}} the "athletic-tangible interface," a new class of interaction which uses tangible objects and full-body motion in physical spaces with digital augmentation. We detail the implementation of PingPongPlus, a "reactive ping-pong table", which features a novel sound-based ball tracking technology. The game is augmented and transformed with dynamic graphics and sound, determined by the position of impact, and the rhythm and style of play. A variety of different modes of play and initial experiences with PingPongPlus are also described. Keywords tangible interface, <b>enhanced</b> <b>reality,</b> augmented reality, interactive surface, athletic interaction, kinesthetic interaction, computer-supported cooperative play. INTRODUCTION When an expert plays ping-pong, a well-used paddle becomes transparent, and allows a player to concentrate on the task [...] playing ping-pong. The good fit of grasp is vit [...] ...|$|E
40|$|This article {{presents}} {{the first version}} of a talking head, called MOTHER (MOrphable Talking Head for <b>Enhanced</b> <b>Reality),</b> based on an articulatory model describing the degrees-of- freedom of visible (lips, cheeks [...] .) but also partially or indirectly visible (jaw, tongue [...] .) speech articulators. Skin details are rendered using texture mapping/blending techniques. We illustrate here the flexibility of such an articulatory control of video-realistic speaking faces by first demonstrating its ability in tracking facial movements by an optical-to-articulatory inversion using an analysis-by-synthesis technique. The stability and reliability of the results allow the automatic inversion of large video sequences. Inversion results are here used to build automatically a coarticulation model for the generation of facial movements from text. It improves the previous Text-ToAudioVisual -Speech (TTAVS) synthesizer developed at the ICP both in terms of the accuracy and realism. 1. INTRODUCTION To date [...] ...|$|E
40|$|International audienceThis article {{presents}} {{the first version}} of a talking head, called MOTHER (MOrphable Talking Head for <b>Enhanced</b> <b>Reality),</b> based on an articulatory model describing the degrees-offreedom of visible (lips, cheeks [...] .) but also partially or indirectly visible (jaw, tongue [...] .) speech articulators. Skin details are rendered using texture mapping/blending techniques. We illustrate here the flexibility of such an articulatory control of video-realistic speaking faces by first demonstrating its ability in tracking facial movements by an optical-to-articulatory inversion using an analysis-by-synthesis technique. The stability and reliability of the results allow the automatic inversion of large video sequences. Inversion results are here used to build automatically a coarticulation model for the generation of facial movements from text. It improves the previous Text-To- AudioVisual-Speech (TTAVS) synthesizer developed at the ICP both in terms of the accuracy and realism...|$|E
50|$|DCS World is in {{the process}} of <b>enhancing</b> its virtual <b>reality</b> {{technology}} support. Platforms it works with currently are TrackIR, Oculus Rift, and HTC Vive. ED plans to continue working on improving support for VR.|$|R
50|$|During the Dark Reign storyline, it is {{revealed}} she survived and comes {{into conflict with}} Mockingbird and Ronin. She also hires Deadpool to retrieve a batch of baby M.O.D.O.C.'s, <b>enhanced</b> to warp <b>reality</b> from H.A.M.M.E.R. headquarters.|$|R
50|$|Virtual walks {{appeal to}} {{those who want to}} {{experience}} {{the sights and sounds of}} particular places in the country or the world, but who may not have the time or the financial or physical resources to actually travel there. They also appeal to treadmill or elliptical trainer users, for whom walking or running while watching these videos <b>enhances</b> the <b>reality</b> of the experience (and, at a minimum, reduce the boredom of the exercise).|$|R
