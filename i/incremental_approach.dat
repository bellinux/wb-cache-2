976|740|Public
5|$|After Palko, the Court {{examined}} Bill of Rights protections one by one. Despite this <b>incremental</b> <b>approach,</b> the Court {{would eventually}} apply most {{rights to the}} states.|$|E
5|$|The Army {{was using}} an <b>incremental</b> <b>approach</b> to combat vehicle modernization, {{centered}} on the Ground Combat Vehicle. The deployment was to be synchronized with upgrades, reset, and divestiture of existing vehicles. Vehicles displaced by the IFV may then replace selected M113 family of vehicles such as command and control, medical evacuation, and mortar carrier, allowing the Army to begin divestiture of the M113 family of vehicles. Upgrades to existing Bradley and Stryker vehicles may have been considered as risk mitigation based on {{the rate at which}} the GCV was introduced. Although upgraded, the Bradley and Stryker would also be replaced in the midterm.|$|E
25|$|These {{complexities}} {{are better}} handled {{with a more}} exploratory or iterative and <b>incremental</b> <b>approach.</b> Several models of iterative and incremental project management have evolved, including agile project management, dynamic systems development method, extreme project management, and Innovation Engineering®.|$|E
40|$|Knowledge {{reduction}} of dynamic covering information systems involves {{with the time}} in practical situations. In this paper, we provide <b>incremental</b> <b>approaches</b> to computing the type- 1 and type- 2 characteristic matrices of dynamic coverings because of varying attribute values. Then we present incremental algorithms of constructing the second and sixth approximations of sets by using characteristic matrices. We employ experimental results to illustrate that the <b>incremental</b> <b>approaches</b> are effective to calculate approximations of sets in dynamic covering information systems. Finally, we perform knowledge {{reduction of}} dynamic covering information systems with the <b>incremental</b> <b>approaches...</b>|$|R
40|$|AbstractSet-valued {{information}} systems are generalized models of single-valued {{information systems}}. The attribute {{set in the}} set-valued information system may evolve over time when new information arrives. Approximations of a concept by rough set theory need updating for knowledge discovery or other related tasks. Based on a matrix representation of rough set approximations, a basic vector H(X) is induced from the relation matrix. Four cut matrices of H(X), denoted by H[μ,ν](X), H(μ,ν](X), H[μ,ν) (X) and H(μ,ν) (X), are derived for the approximations, positive, boundary and negative regions intuitively. The variation of the relation matrix is discussed while the system varies over time. The <b>incremental</b> <b>approaches</b> for updating the relation matrix are proposed to update rough set approximations. The algorithms corresponding to the <b>incremental</b> <b>approaches</b> are presented. Extensive experiments on different data sets from UCI and user-defined data sets show that the proposed <b>incremental</b> <b>approaches</b> effectively reduce the computational time {{in comparison with the}} non-incremental approach...|$|R
40|$|Incremental {{software}} development and delivery {{have been used}} in software projects in many ways for many years. Justifications for <b>incremental</b> <b>approaches</b> include risk amelioration, the management of evolving requirements, and end-user involvement. Incremental development, including iterative, incremental delivery, has become a norm in many sectors. However, there has been little work on modelling the effort in such development and hence a dearth of comparative analyses of cost models for incremental development/delivery. We attempt to rectify this by proposing a COCOMO-style effort model for incremental development/delivery and explore the relationship between effort and the number of increments, thereby providing new insights into the economic impact of <b>incremental</b> <b>approaches</b> to software projects...|$|R
25|$|The first {{proposal}} {{for developing the}} riverfront was given in 1961 by prominent citizens of the city. French architect Bernard Kohn proposed an ecological valley in Sabarmati basin stretched from Dharoi Dam to Gulf of Cambay in 1960s. In 1964, he proposed Integrated Planning & Development of Sabarmati Riverfront by reclaiming 30 hectares of land. The project was considered feasible in 1966 by the Government of Gujarat. Later he distanced himself from the project citing difference between his proposal and the project being implemented. In 1976, the Riverfront Development Group proposed an <b>incremental</b> <b>approach</b> for the construction. In 1992, National River Conservation Plan proposed the construction of sewers and pumping stations to reduce water pollution.|$|E
2500|$|Chen H., Li T., [...] Ruan D., Lin J., Hu C, (2013) A rough-set based <b>incremental</b> <b>approach</b> for {{updating}} approximations under dynamic maintenance environments. IEEE Transactions on Knowledge and Data Engineering, 25(2): 274-284 ...|$|E
2500|$|Page {{responded to}} a {{question}} about corporations, noting that corporations largely get a [...] "bad rap", which he stated was because they were probably doing the same incremental things they were doing [...] "50 or 20 years ago". He went on to juxtapose that kind of <b>incremental</b> <b>approach</b> to his vision of Google counteracting calcification through driving technology innovation at a high rate. Page mentioned Elon Musk and SpaceX: ...|$|E
40|$|Incremental {{software}} development offers many benefits compared with more traditional development <b>approaches.</b> Indeed, <b>incremental</b> <b>approaches</b> have been utilised {{for many years}} due to the involvement of users, the early demonstration of capability {{and the potential for}} risk reduction that they offer. However, there appears to have been little work on modelling, planning and controlling incremental development. The paper attempts to introduce a quantitative analytical framework for evaluating such approaches and their impacts on the development effort. Models that predict development effort as an exponential function of product size are used in the paper to explore some of the relationships between effort and the number of increments, thereby providing new insights into the economic impact of <b>incremental</b> <b>approaches</b> to software project...|$|R
40|$|This paper {{proposes a}} COCOMO-style effort model for {{incremental}} development/delivery of software projects. We explore {{the relationship between}} effort {{and the number of}} increments, thereby providing new insights into the economic impact of <b>incremental</b> <b>approaches</b> to software projects. There has been little work in this important area to date and such a model could prove invaluable to industry...|$|R
50|$|Rain Without Thunder and {{the views}} {{depicted}} within have been criticised by those within the animal movement. One criticism is that Francione depicts a purist ideal {{and does not}} care for <b>incremental</b> <b>approaches</b> to animal welfare, but wants the end of animal use now and {{is not interested in}} discussing the practicality or methodology to make this happen.|$|R
2500|$|The P-8 is {{to replace}} the P-3 Orion. At first, it will be {{equipped}} with legacy P-3 systems, but later upgrades will incorporate more advanced technology. The Government Accountability Office credited the <b>incremental</b> <b>approach</b> with keeping the project on schedule and on budget. The Naval Air Systems Command (NAVAIR) deleted the requirement for the P-8A to be equipped with magnetic anomaly detection (MAD) equipment {{as part of an}} effort to reduce weight by [...] for improved endurance and range. A hydrocarbon sensor detects fuel vapors from diesel-powered submarines and ships.|$|E
2500|$|McCain was an {{advocate}} for strong military measures against {{those responsible for the}} September 11 attacks in 2001 and supported the U.S.-led war in Afghanistan. In a late October 2001 Wall Street Journal op-ed piece he wrote, [...] "America is under attack by a depraved, malevolent force that opposes our every interest and hates every value we hold dear." [...] He advocated an overwhelming, not <b>incremental,</b> <b>approach</b> against the Taliban in Afghanistan, including the use of ground forces, saying, [...] "War is a miserable business. Let's get on with it." ...|$|E
2500|$|An <b>incremental</b> <b>approach</b> {{was adopted}} to {{developing}} the study procedures and technology, using systems designed and {{developed by the}} Clinical Trial Service Unit. [...] This consisted {{of a series of}} pilot [...] studies of increasing complexity and sophistication with interludes for assessment of results and additional scientific input. [...] In-house trials were conducted during 2005, and a fully integrated clinic was run at Altrincham, Greater Manchester throughout Spring 2006 where 3,800 individuals were assessed. [...] On August 22, 2006, it was announced that the main programme would recruit men and women aged between 40 and 69 based from up to 35 regional centres., however recruitment proved more efficient than hoped and only 22 centres had been opened when the recruitment target of 500,000 was reached in 2010.|$|E
40|$|International {{audience}} 2009 {{appears to}} be the launching date for several activities intented to challenge the video compression standard H. 264 /AVC. Improvements upon H. 264 /AVC can be achieved either by breakthrough or <b>incremental</b> <b>approaches.</b> Due to the extreme fine tuning of H. 264 /AVC, the former seems tough. The latter however seems more achievable, even with the announced 50...|$|R
40|$|<b>Incremental</b> {{clustering}} <b>approaches</b> {{have been}} proposed for handling large data when given data set is too large to be stored. The key idea of these approaches is to find representatives to represent each cluster in each data chunk and final data analysis is carried out based on those identified representatives from all the chunks. However, most of the <b>incremental</b> <b>approaches</b> are used for single view data. As large multi-view data generated from multiple sources becomes prevalent nowadays, {{there is a need}} for <b>incremental</b> clustering <b>approaches</b> to handle both large and multi-view data. In this paper we propose a new <b>incremental</b> clustering <b>approach</b> called <b>incremental</b> minimax optimization based fuzzy clustering (IminimaxFCM) to handle large multi-view data. In IminimaxFCM, representatives with multiple views are identified to represent each cluster by integrating multiple complementary views using minimax optimization. The detailed problem formulation, updating rules derivation, and the in-depth analysis of the proposed IminimaxFCM are provided. Experimental studies on several real world multi-view data sets have been conducted. We observed that IminimaxFCM outperforms related incremental fuzzy clustering in terms of clustering accuracy, demonstrating the great potential of IminimaxFCM for large multi-view data analysis. Comment: 32 pages, 1 figures, submitted to Fuzzy Sets and System...|$|R
40|$|Existing {{algorithms}} {{for generating}} referential descriptions to sets of objects have serious deficits: while <b>incremental</b> <b>approaches</b> may produce ambiguous and redundant expressions, exhaustive searches are computationally expensive. Mediating between these extreme control regimes, we propose a best-first searching algorithm for uniquely identifying sets of objects. We incorporate linguistically motivated preferences and several techniques {{to cut down}} the search space. Preliminary results show {{the effectiveness of the}} new algorithm...|$|R
2500|$|Several {{environmental}} protocols {{have been}} established (see List of international environmental agreements) {{as a type of}} international law, [...] "an intergovernmental document intended as legally binding with a primary stated purpose of preventing or managing human impacts on natural resources." [...] International environmental protocols came to feature in environmental governance after trans-boundary environmental problems became widely perceived in the 1960s. [...] Following the Stockholm Intergovernmental Conference in 1972, creation of international environmental agreements proliferated. Due to the barriers already discussed, environmental protocols are not a panacea for global commons issues. [...] Often, they are slow to produce the desired effects, tend to the lowest common denominator, and lack monitoring and enforcement. They also take an <b>incremental</b> <b>approach</b> to solutions where sustainable development principles suggest that environmental concerns should be mainstream political issues.|$|E
2500|$|A January 2005 {{diplomatic}} {{cable that}} {{was released by}} Wikileaks in 2011 includes discussion by U.S. government officials about the best approach to North American integration based on an assessment of Canadian views. The cable suggested a new [...] "North American Initiative" [...] that would address goals {{in the areas of}} [...] "security" [...] and [...] "prosperity" [...] through incremental measures, saying such a proposal would get the most support from Canadian policymakers. It notes many Canadian economists supported [...] "ambitious" [...] goals like a single market, with some supporting a monetary union, but that they believed the <b>incremental</b> <b>approach</b> was more appropriate at the time. Canada's central bank governor is quoted in the cable as having said that a monetary union is [...] "an issue that should be considered once we have made more progress towards establishing a single market." [...] The National Post's Robert Hiltz described the cable in June 2011 as discussing [...] "the obstacles surrounding the merger of the economies of Canada, the United States and Mexico in a fashion similar to the European Union." ...|$|E
2500|$|In 1978, the Fraser {{government}} instigated the Campbell Committee {{to investigate}} financial system reforms. Howard supported the Campbell report, but adopted an <b>incremental</b> <b>approach</b> with Cabinet, {{as there was}} wide opposition to deregulation within {{the government and the}} treasury. The process of reform began before the committee reported 2½ years later, with the introduction of the tender system for the sale of Treasury notes in 1979, and Treasury bonds in 1982. Ian Macfarlane (Governor of the Reserve Bank of Australia, 1996–2006) described these reforms as [...] "second only in importance to the float of the Australian dollar in 1983." [...] In 1981, Howard proposed a broad-based indirect tax with compensatory cuts in personal rates; however, cabinet rejected it citing both inflationary and political reasons. After the free-marketeers or [...] "drys" [...] of the Liberals challenged the protectionist policies of Minister for Industry and Commerce Phillip Lynch, they shifted their loyalties to Howard. Following an unsuccessful leadership challenge by Andrew Peacock to unseat Fraser as prime minister, Howard was elected deputy leader of the Liberal Party in April 1982. His election depended largely on the support of the [...] "drys", and he became the party's champion of the growing free-market lobby.|$|E
40|$|Includes abstract. Includes bibliographical {{references}} (leaves 286 - 299). The aim of {{this research}} was to understand how functionalist <b>approaches</b> and the <b>incremental</b> <b>approaches</b> are manifested in ISRM activities. New insights and meaning to the ISRM activities were presented when the incrementalist approaches to ISRM and the functionalist approaches to ISRM were examined holistically. Improvisation, {{for the purpose of this}} research, was used to explain this holistic understanding...|$|R
30|$|The {{problem of}} dynamic {{community}} detection has received significant {{interest in the}} academic literature (Cazabet and Amblard 2014). Current approaches for dynamic community detection broadly fall under two headings: incremental community detection and global community detection. The approaches in the first category focus on the systematic propagation of communities through time, whereas the approaches in the second category attempt to simultaneously optimize for multiple metrics on several snapshots of data. Stability of computation and accuracy of results are the fundamental limitations of the <b>incremental</b> <b>approaches,</b> while memory (space) and computational requirements are the main limitations of the global approaches (Cazabet and Amblard 2014). <b>Incremental</b> <b>approaches</b> are fundamentally combinatorial in nature (Tantipathananandh and Berger-Wolf 2011; Nguyen et al. 2014) and involve methods to track communities through time. The stochastic nature of these algorithms makes these methods unstable leading to inaccurate results. Mucha et al. (2010) build on the seminal work of Lambiotte et al. (2014) for community detection in dynamic multiplex networks by specializing null models in terms of stability under Laplacian dynamics.|$|R
40|$|Understanding {{decision-making}} processes within dynamic task environments via embodied computational cognitive models {{proves to be}} a challenge for the modeling community (see Gonzalez, Lerch, & Lebiere, 2003 for an example). Decisions made by an agent {{may be the result of}} explicit, strategic moves, or result from implicit, cost-benefit tradeoffs occurring at the level of 1 / 3 of a second. Understanding and properly modeling decisions occurring at these different levels is a challenge for the modeler. This paper proposes a novel <b>incremental</b> modeling <b>approach</b> (see Byrne, 2001 and Gonzalez et al., 2003 for examples of other <b>incremental</b> <b>approaches)</b> that promises to inform decision theory as well as limitations within the chosen modeling architecture. The simulated cyborg (or, simBorg) approach blend...|$|R
5000|$|The FATA Programmes {{adopt an}} <b>incremental</b> <b>approach</b> of first {{building}} trust and then {{coming up with}} human res ...|$|E
50|$|After Palko, the Court {{examined}} Bill of Rights protections one by one. Despite this <b>incremental</b> <b>approach,</b> the Court {{would eventually}} apply most {{rights to the}} states.|$|E
50|$|Last minute {{intervention}} by the UK Treasury delayed the decision, after {{concerns about the}} cost of Meteor, believed to be the preferred solution, compared to the cheaper <b>incremental</b> <b>approach</b> offered by Raytheon.|$|E
40|$|This article informs {{communicative}} action {{theory with}} insights from urban regime theory. The synthesis proposes {{a model of}} planning that is more comprehensive in its treatment of the linkages between planning and governance and helps advance the creation of network power, emancipatory knowledge, empowering subjectivities, and spaces of solidarity. The article then discusses the merits of these insights {{in the context of}} a categorization of planning into traditional, democratic, advocacy, and <b>incremental</b> <b>approaches...</b>|$|R
40|$|Abstract. Recently Support Vector Machines (SVMs) {{have played}} a leading role in pattern classification. SVMs are quite {{effective}} to classify static data in numerous applications. However, the use of SVMs in dynamically data driven application systems (DDDAS) is somewhat limited. This motivates the devel-opment of <b>incremental</b> <b>approaches</b> to handle DDDAS. In an <b>incremental</b> learn-ing <b>approach,</b> it is critical to keep a certain number of support vectors (SVs) without seriously sacrificing the generalization performance of SVMs. In this paper a novel incremental SVM method, called an incremental revised support vector machine with filters (IRSVMF) is proposed to resolve the above limita-tions. Computational experiments with tornado data show that this approach is quite effective {{to reduce the number of}} SVs and computing time and to increase the detection rate of tornados. ...|$|R
40|$|Traditional {{principal}} components analysis (PCA) techniques for face recognition are based on batch-mode training using a pre-available image set. Real world applications require that the training set be dynamic of evolving nature where {{within the framework of}} continuous learning, new training images are continuously added to the original set; this would trigger a costly continuous re-computation of the eigen space representation via repeating an entire batch-based training that includes the old and new images. Incremental PCA methods allow adding new images and updating the PCA representation. In this paper, two <b>incremental</b> PCA <b>approaches,</b> CCIPCA and IPCA, are examined and compared. Besides, different learning and testing strategies are proposed and applied to the two algorithms. The results suggest that batch PCA is inferior to both <b>incremental</b> <b>approaches,</b> and that all CCIPCAs are practically equivalent...|$|R
50|$|The UK {{scheme is}} volume-based because the <b>incremental</b> <b>approach</b> {{provides}} limited or no encouragement to businesses whose R&D spending fluctuates or remains {{at a steady}} level (for instance in times of macro-economic volatility).|$|E
50|$|These {{complexities}} {{are better}} handled {{with a more}} exploratory or iterative and <b>incremental</b> <b>approach.</b> Several models of iterative and incremental project management have evolved, including agile project management, dynamic systems development method, extreme project management, and Innovation Engineering®.|$|E
50|$|In {{order to}} de-risk the {{programme}} ATLAS and the MOD took an <b>incremental</b> <b>approach</b> {{to the development}} and implementation of DII, with a separate contract for each increment. The extended timeline allowed the MOD flexibility in defining its requirements.|$|E
40|$|Classical <b>incremental</b> <b>approaches</b> for the {{identification}} of polynomial NARX/NARMAX models often yield unsatisfactory results in terms of structure selection, which is crucial for model reliability over long-range prediction horizons. This paper embeds the nonlinear identification problem into a probabilistic framework and presents a novel randomized algorithm for structure selection. The approach is validated over different models by means of Monte Carlo simulations, and is shown to outperform competitor probabilistic methods {{in terms of both}} reliability and computational efficiency...|$|R
40|$|In {{practical}} situations, it is {{of interest}} to investigate computing approximations of sets as an important step of knowledge reduction of dynamic covering decision information systems. In this paper, we present <b>incremental</b> <b>approaches</b> to computing the type- 1 and type- 2 characteristic matrices of dynamic coverings whose cardinalities increase with immigration of more objects. We also present the incremental algorithms of computing the second and sixth lower and upper approximations of sets in dynamic covering approximation spaces...|$|R
30|$|Knowledge {{extensibility}} {{is required}} at the agent level to accommodate any new ontological units {{added to the}} system about the domain. The individual agents view of the domain ontology is not necessarily complete. Despite {{the fact that this}} can create inconsistencies, it may be useful for monitoring purposes. However, a structured and understood knowledge representation is required to resolve existing inconsistencies. For example, using <b>incremental</b> <b>approaches</b> based on interactions between an expert and a data stream input can be used [4, 10].|$|R
