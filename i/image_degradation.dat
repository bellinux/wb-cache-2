523|386|Public
50|$|A {{process lens}} with 12 {{elements}} in 8 groups and a fixed aperture, optimized for a 1:1 reproduction ratio. It has {{the capability of}} altering the aspect ratio of the image by up to 8% without any <b>image</b> <b>degradation.</b>|$|E
50|$|These {{monitors}} use touching of {{the screen}} as an input method. Items can be selected or moved with a finger, and finger gestures {{may be used to}} convey commands. The screen will need frequent cleaning due to <b>image</b> <b>degradation</b> from fingerprints.|$|E
50|$|Image {{quality is}} a {{characteristic}} of an image that measures the perceived <b>image</b> <b>degradation</b> (typically, compared to an ideal or perfect image). Imaging systems may introduce some amounts of distortion or artifacts in the signal, so the quality assessment is an important problem.|$|E
3000|$|<b>Image</b> <b>degradations</b> are {{manifested}} by {{the property}} of capture devices and conditions, irrespective of the biometric being captured: [...]...|$|R
40|$|International audienceOne of {{the main}} {{challenges}} facing biometric technologies is system performance decreasingcaused by low quality biometric samples. In fingerprint recognition, the system performance may be negatively affected by fingerprint <b>image</b> <b>degradations,</b> which are introduced by subject characteristic, image acquisition, subject behavior, or environment. Therefore, {{it is necessary to}} investigate how different fingerprint <b>image</b> <b>degradations</b> influence biometric system performance. In this paper, we will first study different fingerprint <b>image</b> <b>degradations</b> that affect system performance. Then review state-of-the-art fingerprint sample quality assessment methods and their evaluation approaches. Based on the survey, we select corresponding degradations and apply them to fingerprint samples. The system performance comparison between original and degraded fingerprints will be conducted in order to illustrated the impact of each degradation on biometric system performance. Finally, we use NFIQ fingerprint image quality metric to investigate its performance on selected degradations...|$|R
3000|$|Face {{quality is}} {{affected}} by pose, illumination, and expression apart from <b>image</b> <b>degradations</b> such as noise and blur. Other covariates such as aging, disguise, and occlusion degrade the performance relative to a reference sample.|$|R
50|$|Modern {{microfilming}} standards {{require that}} a master set of films be produced {{and set aside}} for safe storage, used only to make service copies. When service copies get lost or damaged, another set can be produced from the masters, thus reducing the <b>image</b> <b>degradation</b> that results from making copies of copies.|$|E
50|$|Since {{the middle}} of 2010 PALPlus was dropped in favor of regular 16:9 letterbox, because the system caused {{considerable}} <b>image</b> <b>degradation</b> (with an effective horizontal resolution of only about ~400px compared to 720px of a digital SDTV image) when used on digital transmissions. After that, {{with the end of}} analog broadcasts by 2012, the system became officially obsolete.|$|E
50|$|The SST is {{a vacuum}} telescope, {{meaning that it}} is {{evacuated}} internally to avoid disruption of the image from air inside. This is a particular problem with solar telescopes because of the heating from the large amounts of light collected being passed on to any air causing <b>image</b> <b>degradation.</b> As of 2005 it has produced the highest resolution images on the Sun of any telescope, using its adaptive optics system.|$|E
40|$|In this paper, {{we study}} the {{sensitivity}} of CNN outputs with respect to image transformations and noise {{in the area of}} fine-grained recognition. In particular, we answer the following questions (1) how sensitive are CNNs with respect to image transformations encountered during wild image capture?; (2) how can we predict CNN sensitivity?; and (3) can we increase the robustness of CNNs with respect to <b>image</b> <b>degradations?</b> To answer the first question, we provide an extensive empirical sensitivity analysis of commonly used CNN architectures (AlexNet, VGG 19, GoogleNet) across various types of <b>image</b> <b>degradations.</b> This allows for predicting CNN performance for new domains comprised by images of lower quality or captured from a different viewpoint. We also show how {{the sensitivity of}} CNN outputs can be predicted for single images. Furthermore, we demonstrate that input layer dropout or pre-filtering during test time only reduces CNN sensitivity for high levels of degradation. Experiments for fine-grained recognition tasks reveal that VGG 19 is more robust to severe <b>image</b> <b>degradations</b> than AlexNet and GoogleNet. However, small intensity noise can lead to dramatic changes in CNN performance even for VGG 19. Comment: BMVC 2016 Pape...|$|R
40|$|There is an {{approach}} of annotation extraction from printed documents in which annotations are extracted {{by comparing the}} image of an annotated document and its original document image. In one of the previous methods, {{the image of an}} original document is actually printed and scanned in order to reproduce <b>image</b> <b>degradations</b> of the <b>image</b> of the annotated document. However such a method lacks convenience since users have to use the same printer and scanner to obtain images of an annotated document and its original document. In this paper, we propose an improved annotation extraction method in which the <b>image</b> <b>degradations</b> are compensated by image processing. In the proposed method, the difference between original and annotated document images due to <b>image</b> <b>degradations</b> is reduced by not only removal of the degradations in the annotated document images but also reproduction of the degradation in the original document images. The proposed method consists of three steps of processing which are for dithering, for color change, and for local displacement. We also propose an objective evaluation of extracted annotations to compare the experimental results accurately. Experimental results of the proposed method have shown that the recall of extracted annotations was 80. 94 % and the precision was 85. 59 %. 1...|$|R
40|$|A fast {{process for}} {{two-dimensional}} microwave imaging is presented. The influence of analytical approximations {{as well as}} the effect of range walk can cause severe <b>image</b> <b>degradations.</b> A method for compensation of these effects under the aspect of minimum loss in processing has been developed and will be presented...|$|R
50|$|All gelatin silver {{photographic}} {{materials are}} subject to deterioration. The silver particles that comprise the image are susceptible to oxidation, leading to yellowing and fading of the image. Poor processing can also result in various forms of <b>image</b> <b>degradation,</b> due to residual silver-thiosulfate complexes. Toning increases {{the stability of the}} silver image by coating the silver image with a less easily oxidized metal such as gold, or by converting portions of the silver image particles into more stable compounds, such as silver selenide or silver sulfide.|$|E
5000|$|Because {{regions are}} bound to a {{specific}} orientation, a ninety degree rotation of a region would require both detailed reverse engineering of the structure and extensive coding. A general rotation is impractical when compared to rotating the original source boundary description and simply creating a new region. However, the API includes conversion routines to and from BitMaps. (Bitmaps may also be rotated using well known methods, but with various degrees of <b>image</b> <b>degradation</b> depending upon angle chosen, the storage and processor cycles available to the operation, and {{the complexity of the}} algorithm.) ...|$|E
50|$|A typical American ATSC {{transport}} offers {{three to}} four channels, in most cases {{one of them is}} broadcast in HD (the station's main channel) {{and the rest of the}} channels are broadcast in standard definition, due to the limited 6 MHz 8VSB bandwidth used. In those cases when one physical channel transports more than one HD sub-channel, the data rate drops to the level of standard definition DVD-Video. The corresponding <b>image</b> <b>degradation</b> manifests itself in reduced resolution, increased noise and compression artifacts. For example, KPBS broadcasts four multiplexes on a single physical channel, two of which are HD.|$|E
3000|$|Current {{research}} uses typical {{image processing}} algorithms that evaluate <b>image</b> <b>degradations</b> due to noise, compression, or illumination. However, a quality metric that entails a greater insight of {{the usefulness of}} the biometric sample in consideration can improve the performance of these systems by providing more discernible quality cohorts.|$|R
40|$|Abstract: Stray light {{entering}} the lens system, uncontrolled illumination variations and scattering by participating media are often considered as <b>image</b> <b>degradations.</b> We show that such {{effects can be}} useful, yielding 3 D structure, camera and lighting calibration. OCIS codes: (110. 0110) Imaging systems; (150. 0150) Machine Vision; (280. 0280) Remote sensing and sensors 1...|$|R
40|$|We {{present an}} {{approach}} for still image watermarking {{in which the}} watermark embedding process employs multiresolution fusion techniques and incorporates {{a model of the}} human visual system (HVS). The original unmarked image is required to extract the watermark. Simulation results demonstrate the high robustness of the algorithm to such <b>image</b> <b>degradations</b> as JPEG compression, additive noise and linear filtering. ...|$|R
50|$|Integrated {{sidelobe}} return: ISAR {{image quality}} is degraded by range and azimuth compression side lobes. The sidelobes {{are due to}} data truncation and can be reduced by the application of appropriate window functions. The sidelobes can cause significant <b>image</b> <b>degradation.</b> First, the peaks of the stronger sidelobes may cause a string of progressively weaker targets to appear {{on either side of}} a strong target. Second, the combined power of all sidelobes tends to fog or washout detail in low RCS areas. The integrated sidelobe level can under poor conditions reach a level 10 dB below the peak target return.|$|E
50|$|This live {{conversion}} was crude {{compared to}} early 21st-century electronic digital conversion techniques. <b>Image</b> <b>degradation</b> was unavoidable with this system as the monitor and camera's optical limitations significantly lowered the original SSTV signal's contrast, brightness and resolution. The video seen on home television sets was further degraded {{by the very}} long and noisy analog transmission path. The converted signal was sent by satellite from the receiving ground stations to Houston, Texas. Then the network pool feed was sent by microwave relay to New York, where it was broadcast live to the United States and the world.|$|E
5000|$|Although it was {{possible}} to use existing round phosphor gun technology with Cromaclear, a certain percentage of electron power would have been lost, thereby degrading overall image focus. An effective visual to describe this phenomenon is a [...] "round peg, square hole" [...] analogy: while contact might be taking place, it’s not completely precise. Excess energy transfer could lead to a warped grille or mask, resulting in possible <b>image</b> <b>degradation</b> (color purity and/or brightness uniformity problems). This mismatch tends to occur in aperture grille CRTs (stripe grille/circular electron beam). On the other hand, shadow mask CRTs match a circular beam to a circular shadow mask.|$|E
40|$|The {{effect of}} <b>image</b> quality <b>degradation</b> on the {{verification}} performance of automatic fingerprint recognition is investigated. We study {{the performance of}} two fingerprint matchers based on minutiae and ridge information under varying fingerprint image quality. The ridge-based system {{is found to be}} more robust to <b>image</b> quality <b>degradation</b> than the minutiae-based system for a number of different image quality criteria. © 2005 IEEE...|$|R
40|$|When {{an image}} is highly {{compressed}} {{by using the}} current coding standards, the decompressed image has noticeable <b>image</b> <b>degradations</b> such as blocking artifacts near the block boundaries, corner outliers at cross points of blocks and ringing noise near image edges. These <b>image</b> <b>degradations</b> are caused by quantization process of the 8 x 8 DCT coefficients. In order to restore the decompressed image, a loop-filtering algorithm and a post-filtering algorithm have been developed. The developed methods perform an adaptive filtering on the decompressed image according to blocking and ringing flags that are defined to reduce computation complexity. Performances of both algorithms are compared {{with respect to the}} image quality and the computation complexity. The comparison results show that the post-filtering is slightly better than or similar to the loop filtering with respect to peak signal-to-noise ratio (PSNR), whereas the subjective image qualities of both methods are quite similar. However, the computation complexity of the loop filtering is much less than that of the post-filtering...|$|R
40|$|By the {{application}} of lossy data compression, distortion will occur for media. This media can be image, audio, or video. Compression artifact {{is one of the}} noticeable distortion of media which occur as a result of lossy data compression. At high compression ratios, the visibility of <b>image</b> <b>degradations</b> {{is one of the most}} important drawback of the current video coding standards. Due to the rigid block partitioning of the <b>image,</b> these <b>image</b> <b>degradations</b> leads to blocking artifacts and due to coarse quantization it leads to ringing noise mainlys around edges. Both the blocking and ringing noise are visibly annoying and have a great impact on the received image quality. So, for improving the quality of the reconstructed image we must remove the blocking and ringing noise. In some techniques, blocking noise will be removed from the image, but there will be large amount of blurriness. This paper is a survey on various compression artifact removal techniques...|$|R
50|$|Static (non-moving) {{adapters}} suffer greater <b>image</b> <b>degradation</b> from low-light situations because texture on the {{focusing screen}} becomes more noticeable. The camcorder {{used in conjunction}} with the adapter must focus on the focusing screen inside the adapter which is used as a projection surface. As a result, the camcorder also picks up the pits, dimples and/or specks in the material that give it its translucent properties. The solution to this problem is to shake, rotate or otherwise move the focusing screen so that the texture of the screen is blurred. In a non-static solution such as this, the texture is only a problem at very high shutter speeds, where blurring is reduced.|$|E
5000|$|Paramount's VistaVision was {{a larger}} gauge {{precursor}} to 70mm film. Introduced in 1954, it ran standard 35mm film through the camera horizontally {{to achieve a}} widescreen effect using greater negative area, {{in order to create}} a finer-grained four-perforation 35mm prints in an era where standard monopack stock could not produce finer results. Negative frames were eight perforations wide. Eight-perf photography is sometimes used for shooting special effects in order to produce a finer grained matte that can be used in optical printing without <b>image</b> <b>degradation,</b> and is notable for its use in Lucasfilm's original three Star Wars films, among others. Another similar system with horizontal orientation was MGM's Arnoldscope.|$|E
5000|$|The {{degree of}} image {{blurring}} {{for a given}} amount of focus shift depends inversely on the lens f-number. Low f-numbers, such as [...] to 2.8, {{are very sensitive to}} defocus and have very shallow depths of focus. High f-numbers, in the 16 to 32 range, are highly tolerant of defocus, and consequently have large depths of focus. The limiting case in f-number is the pinhole camera, operating at perhaps 100 to 1000, in which case all objects are in focus almost regardless of their distance from the pinhole aperture. The penalty for achieving this extreme depth of focus is very dim illumination at the imaging film or sensor, limited resolution due to diffraction, and very long exposure time, which introduces the potential for <b>image</b> <b>degradation</b> due to motion blur.|$|E
30|$|Note {{that moment}} invariants take not only image features, such as means and variance, but also <b>image</b> <b>degradations,</b> such as translation, scaling, and rotation, into {{accounts}} to generate some invariants and to properly match images without setting any constant. Therefore, {{in the rest}} of this subsection, we show some discussions of advantage and disadvantage of the use of the SSIM index by comparing with moment invariants.|$|R
40|$|The {{process of}} {{scanning}} inherently introduces <b>degradations</b> to an <b>image.</b> These <b>degradations</b> affect {{the overall quality}} of the scanned image. Models have been derived to characterize the <b>image</b> <b>degradations</b> created by the optical system in a scanner. These models can be used to create the synthetic images. If the models accurately reflect the process of the scanner, the output of the model should match real scans. Through statistical analysis of these images, the models can be validated for accuracy. Experiments are conducted to compare the similarity of the real and synthetic images. These images are compared using several difference metrics: Hamming distance, moment features, and RST-invariant moment features, and several image description features...|$|R
50|$|<b>Image</b> quality <b>degradation,</b> {{caused by}} sharing of {{available}} bandwidth over four multiplexed channels, was noticed by viewers.|$|R
5000|$|The {{difference}} {{with respect to}} other techniques mentioned previously such as MSE or PSNR is that these approaches estimate absolute errors; on the other hand, SSIM is a perception-based model that considers <b>image</b> <b>degradation</b> as perceived change in structural information, while also incorporating important perceptual phenomena, including both luminance masking and contrast masking terms. Structural information {{is the idea that}} the pixels have strong inter-dependencies especially when they are spatially close. These dependencies carry important information about the structure of the objects in the visual scene. Luminance masking is a phenomenon whereby image distortions (in this context) tend to be less visible in bright regions, while contrast masking is a phenomenon whereby distortions become less visible where there is significant activity or [...] "texture" [...] in the image.|$|E
5000|$|Digital {{steganography}} {{can hide}} confidential data (i.e. secret files) very securely by embedding them into some media data called [...] "vessel data." [...] The vessel data is {{also referred to}} as [...] "carrier, cover, or dummy data". In BPCS-Steganography true color images (i.e., 24-bit color images) are mostly used for vessel data. The embedding operation in practice is to replace the [...] "complex areas" [...] on the bit planes of the vessel image with the confidential data. The most important aspect of BPCS-Steganography is that the embedding capacity is very large. In comparison to simple image based steganography which uses solely the least important bit of data, and thus (for a 24-bit color image) can only embed data equivalent to 1/8 of the total size, BPCS-Steganography uses multiple bit-planes, and so can embed a much higher amount of data, though this is dependent on the individual image. For a 'normal' image, roughly 50% of the data might be replaceable with secret data before <b>image</b> <b>degradation</b> becomes apparent.|$|E
50|$|This live {{conversion}} was crude {{compared to}} early-21st century electronic digital conversion techniques. <b>Image</b> <b>degradation</b> was unavoidable with this system as the monitor and camera's optical limitations significantly lowered the original SSTV signal's contrast, brightness and resolution. If the scan converter's settings were incorrectly set, {{as they were}} at the Goldstone station during the first few minutes of Apollo 11's moonwalk, the negative impact on the image could be very obvious. When Armstrong first came down the Lunar Module's ladder, he was barely visible because the contrast and the vertical phase were not set correctly by the scan converter operator. The video seen on home television sets was further degraded by the very long and noisy analog transmission path. The converted signal was sent by satellite from the three receiving ground stations to Houston, Texas. Then the network pool feed was sent by microwave relay to New York, where it was broadcast live to the United States and the world. Because all of these links were analog, each one added additional noise and distortion to the signal.|$|E
30|$|We {{have also}} shown that the {{existence}} of more than two tips at random separations will tend to ameliorate pair-wise destructive beating of signals at a given reciprocal space point, providing additional amplitude at that Fourier point to restore some real-space modulation. Finally, we have recovered textbook knowledge that tip height variations will ameliorate <b>image</b> <b>degradations</b> because of the exponential falloff of the signal with the tip-surface distance.|$|R
40|$|Abstract. Taking a sharp photo {{at several}} {{megapixel}} resolution traditionally relies on high grade lenses. In this paper, we present {{an approach to}} alleviate <b>image</b> <b>degradations</b> caused by imperfect optics. We rely on a calibration step to encode the optical aberrations in a space-variant point spread function and obtain a corrected image by non-stationary deconvolution. By including the Bayer array in our image formation model, we can perform demosaicing {{as part of the}} deconvolution...|$|R
40|$|A {{case study}} on {{appearance}} based feature extraction techniques and their susceptibility to <b>image</b> <b>degradations</b> for the task of face recognition Vitomir ˇStruc and Nikola Paveˇsić, Member, IEEE Abstract—Over the past decades, automatic face recognition has become a highly active research area, mainly due to the countless application possibilities in both the private {{as well as the}} public sector. Numerous algorithms have been proposed in the literature to cope with the problem of face recognition, nevertheless, a group of methods commonly referred to as appearance based have emerged as the dominant solution to the face recognition problem. Many comparative studies concerned with the performance of appearance based methods have already been presented in the literature, not rarely with inconclusive and often with contradictory results. No consent has been reached within the scientific community regarding the relative ranking of the efficiency of appearance based methods for the face recognition task, let alone regarding their susceptibility to appearance changes induced by various environmental factors. To tackle these open issues, this paper assess the performance of the three dominant appearance based methods: principal component analysis, linear discriminant analysis and independent component analysis, and compares them on equal footing (i. e., with the same preprocessing procedure, with optimized parameters for the best possible performance, etc.) in face verification experiments on the publicly available XM 2 VTS database. In addition to the comparative analysis on the XM 2 VTS database, ten degraded versions of the database are also employed in the experiments to evaluate the susceptibility of the appearance based methods on various <b>image</b> <b>degradations</b> which can occur in ”real-life ” operating conditions. Our experimental results suggest that linear discriminant analysis ensures the most consistent verification rates across the tested databases. Keywords—Biometrics, face recognition, appearance based methods, <b>image</b> <b>degradations,</b> the XM 2 VTS database. I...|$|R
