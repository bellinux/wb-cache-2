0|1272|Public
5000|$|The Talking Adventure Team Commander {{featured}} eight new <b>voice</b> <b>commands,</b> {{activated by}} a pull-string through the chest. The <b>voice</b> <b>commands</b> were: ...|$|R
5000|$|Capsela <b>Voice</b> <b>Command</b> systems (3000 and 6000) {{had a small}} {{computer}} {{capable of}} responding {{to a number of}} <b>voice</b> <b>commands.</b> The 6000 system had a rudimentary wireless infrared remote control.|$|R
40|$|Voice Activated Autonomous Quadcopter {{controlled}} by Radio frequency communication. The {{purpose of this}} project to explore the available technologies to control quadcopter by using enhanced <b>voice</b> <b>command.</b> <b>Voice</b> <b>command</b> data are converted into to integer number from 0 to 255 both significantly increase the Human and quadcopter interface. Algorithm written inside flight controller allows to receive <b>voice</b> <b>command</b> and motion sensor data through Radio Receiver and concerted to achieve an aim or deal with respective command. This project is broken in to 2 tasks: Implementation of Voice Recognition and <b>voice</b> <b>command</b> conversion and Design of Autonomous Quadcopter...|$|R
5000|$|As car {{technology}} improves, more features will {{be added}} to cars and these features will most likely distract a driver. <b>Voice</b> <b>commands</b> for cars, according to CNET, should allow a driver to issue commands and not be distracted. CNET states that Nuance is suggesting that in the future they will create a software that resembles Siri, but for cars. [...] Most speech recognition software on the market today only have about 50 to 60 <b>voice</b> <b>commands,</b> but Ford Sync has 10,000. However, CNET suggest that even 10,000 <b>voice</b> <b>commands</b> is not sufficient given the complexity and the variety of tasks a user may want to do while driving. <b>Voice</b> <b>command</b> for cars is different from <b>voice</b> <b>command</b> for mobile phones and for computers because a driver may use the feature to look for nearby restaurants, look for gas, driving directions, road conditions, and the location of the nearest hotel. Currently, technology allows a driver to issue <b>voice</b> <b>commands</b> on both a portable GPS like a Garmin and a car manufacturer navigation system.|$|R
40|$|The {{proposed}} paper {{presents the}} design and implementation of a wireless home automation system with acoustic controlling. In this system, one voice recognition module {{has been added to}} the wireless network. The automation process will be done using recognition of <b>voice</b> <b>commands</b> and the Radio Frequency technology. The <b>voice</b> <b>commands</b> in this system are person independent. The proposed system has transmitting and receiving sections. Initially, the <b>voice</b> <b>command</b> is stored in the memory of voice module using the functions keys arranged. The input voice fed is processed in the voice recognition system where the feature of the <b>voice</b> <b>command</b> is extracted and matched with the pre-loaded <b>voice</b> <b>commands.</b> The module recognizes the voice and sends control messages to the microcontroller. The receiving microcontroller then processes the received data and switches the respective appliances via connected driver circuits...|$|R
40|$|Voice assistants like Siri {{enable us}} to control IoT devices {{conveniently}} with <b>voice</b> <b>commands,</b> however, they also provide new attack opportunities for adversaries. Previous papers attack voice assistants with obfuscated <b>voice</b> <b>commands</b> by leveraging the gap between speech recognition system and human voice perception. The limitation is that these obfuscated commands are audible and thus conspicuous to device owners. In this paper, we propose a novel mechanism to directly attack the microphone used for sensing voice data with inaudible <b>voice</b> <b>commands.</b> We show that the adversary can exploit the microphone's non-linearity and play well-designed inaudible ultrasounds to cause the microphone to record normal <b>voice</b> <b>commands,</b> and thus control the victim device inconspicuously. We demonstrate via end-to-end real-world experiments that our inaudible <b>voice</b> <b>commands</b> can attack an Android phone and an Amazon Echo device with high success rates at a range of 2 - 3 meters...|$|R
40|$|We {{studied with}} {{telephone}} survey the opinions and ideas of 1004 Finns concerning domestic technology and controlling it with <b>voice</b> <b>commands.</b> There is distrust towards commanding your home environment with voice; the users doubt especially its functionality. <b>Voice</b> <b>commands</b> {{are regarded as}} unpleasant. The most positive conceived aspects of <b>voice</b> <b>commands</b> are the speed of control {{and the ability to}} free your hands for something else. Voice feedback, however, is really appreciated. Especially it is welcomed instead of alarm beeps and blinking lights. It is possible that users need first to get accustomed that a device speaks to them. Finally, our studies show major changes in user attitudes when they actually use speech applications. Index Terms: smart home, speech interface, <b>voice</b> <b>command,</b> consumer surve...|$|R
50|$|PowerSecretary - <b>Voice</b> <b>command</b> {{and control}} with {{dictation}} capability.|$|R
5000|$|Microsoft <b>Voice</b> <b>Command</b> for Windows Pocket PC and Windows Mobile ...|$|R
5000|$|<b>Voice</b> <b>commands</b> for menu short cuts, keypad lock, and {{profiles}} ...|$|R
40|$|Paper {{deals with}} the speech {{recognition}} software for controlling computer programs and electric devices by voice. Internet Explorer or any other computer program, which supports special keyboard combinations could be controlled by <b>voice</b> <b>commands.</b> The essential features of the control program are: the possibility to work with any installed in the system speech recognition engine, the possibility to make and to change <b>voice</b> <b>commands</b> and to change reactions to <b>voice</b> <b>commands,</b> the possibility to input the text by spelling. Electric devices could be turned on or turned off by voice with additional USB-based hardware. Speaker dependent projection based recognition algorithm, which was used in Lithuanian speech recognition engine, is described. The accuracy of recognition of ten Lithuanian commands by Lithuanian and English speech recognition engines was checked. Demonstrations of computer and electric devices control by <b>voice</b> <b>commands</b> are prepared...|$|R
50|$|BWV 645: Wachet auf, ruft uns die Stimme the <b>Voice</b> <b>commands.</b>|$|R
5000|$|In 2015, Lab126 {{released}} the Amazon Echo, a <b>voice</b> <b>command</b> device.|$|R
5000|$|Microphones, to take or make phone calls, or take <b>voice</b> <b>commands</b> ...|$|R
5000|$|<b>Voice</b> <b>Command</b> - {{high-level}} {{objects for}} command & control speech recognition ...|$|R
50|$|A deluxe release {{includes}} three extra missions {{and support for}} <b>voice</b> <b>commands.</b>|$|R
40|$|Abstract [...] This paper proposes an {{interaction}} with mechatronic {{system based on}} <b>voice</b> <b>commands.</b> The goal {{of this research is}} to develop a human-machine interface that could be able to control a mechatronic system by using <b>voice</b> <b>commands.</b> With the use of low features extracted from the <b>voice</b> <b>commands,</b> the system will be trained to recognize specific commands. After the training, the commands are recognized and transferred to the controlled system. Intelligent techniques are used with a combination of Hidden Markov Models and Dynamic Time Wrapping for the training and the recognition. The LEGO MINDSTORMS NXT robotics platform controlled by custom software developed under max/msp program is the evaluation tool of the system. The system is tested with different set of commands and the experimental results show that the interaction is efficient with a number of 92 % of accuracy on <b>voice</b> <b>commands.</b> Index Term [...] Human machine Interaction, Voice control...|$|R
25|$|The {{ability to}} use select <b>voice</b> <b>commands</b> to {{remotely}} control the virtual machine.|$|R
5000|$|... 2. Wachet auf, ruft uns die Stimme (Awake, the <b>voice</b> <b>commands),</b> BWV 645 ...|$|R
5000|$|The {{ability to}} use select <b>voice</b> <b>commands</b> to {{remotely}} control the virtual machine.|$|R
40|$|Abstract: In this paper, a <b>voice</b> <b>command</b> {{system for}} {{autonomous}} robots is proposed as a project. The methodology adopted {{is based on}} hybrid techniques used in speech recognition which are zero crossing and extremes with dynamic time warping followed by a decision system based on independent methods test results. To implement the approach on a real time application, a personal computer interface was designed to control the movement {{of a set of}} robots by simple <b>voice</b> <b>commands.</b> The <b>voice</b> <b>command</b> system for four autonomous robots is designed. The main parts of the robots are a microcontroller from Microchip PIC 16 F 84 and a radio frequency receiver module...|$|R
40|$|This paper {{presents}} an experiment of audio-visual <b>voice</b> <b>command</b> recognition from small vocabulary in simulated noisy conditions. Electric and electronics devices should {{be controlled by}} these <b>voice</b> <b>commands</b> mainly in homes of motor-handicapped people and visual part of speech could improve recognition rate if a noise is relatively strong. Therefore the main aims of this experiment were {{to find out how}} visual part of speech can improve resulting recognition rate and if it is possible to use successfully two-stream Hidden Markov Models (HMMs) for audio-visual <b>voice</b> <b>command</b> recognition. Index Terms: audio-visual speech recognition in noisy conditions, voice control of electric and electronics home devices 1...|$|R
25|$|The AIBO {{responded to}} over 100 <b>voice</b> <b>commands</b> and talked in a tonal language.|$|R
50|$|Lansing had craggy good looks, a stentorian <b>voice,</b> <b>commanding</b> presence, and {{characteristic}} bushy eyebrows.|$|R
50|$|The AIBO {{responded to}} over 100 <b>voice</b> <b>commands</b> and talked in a tonal language.|$|R
40|$|This paper {{reports on}} the {{integration}} of a speech recognition component into a small robot, J. Edgar, which {{was developed in the}} AI Vision Lab at the University of Melbourne. While the use of <b>voice</b> <b>commands</b> was fairly easy to implement, the interaction of the <b>voice</b> <b>commands</b> with the existing navigation system of the robot turned out to pose a number of problems...|$|R
5000|$|... #Caption: Seaman {{is played}} using <b>voice</b> <b>commands</b> and came bundled with the {{official}} Dreamcast microphone.|$|R
50|$|The deluxe release {{includes}} three extra missions, support for <b>voice</b> <b>commands,</b> plus some additional game features.|$|R
5000|$|Combines touch IR {{and control}} by <b>voice</b> <b>commands</b> {{and the product}} to give {{customers}} more choice.|$|R
50|$|Any {{mobile device}} running Android OS, Microsoft Windows Phone, iOS 5 or later, or Blackberry OS {{provides}} <b>voice</b> <b>command</b> capabilities. In {{addition to the}} built speech recognition software for each mobile phone's operating system, a user may download third party <b>voice</b> <b>command</b> applications from each operating system's application store: Apple App store, Google Play, Windows Phone Marketplace (initially Windows Marketplace for Mobile), or BlackBerry App World.|$|R
40|$|The {{predominance}} of exclusively manual interaction required when interacting with websites is a restrictive condition. This limitation {{is taken as}} a starting point and shapes the main motivation for the development of web applications driven by <b>voice</b> <b>commands.</b> It is described and provided a process useful to allow the user to interact with web applications invoking <b>voice</b> <b>commands.</b> IX Workshop Innovaci√≥n en Sistemas de Software (WISS) ...|$|R
50|$|Windows Speech Recognition {{allows a}} user {{to control a}} computer, {{including}} the operating system desktop user interface, through <b>voice</b> <b>commands.</b> Applications, including most of those bundled with Windows, can also be controlled through <b>voice</b> <b>commands.</b> By using speech recognition, users can dictate text within documents and e-mail messages, fill out forms, control the operating system user interface, perform keyboard shortcuts, and move the mouse cursor.|$|R
40|$|Research {{was carried}} out on the {{application}} of speech in three areas of man-computer communication: instruction, <b>voice</b> <b>commands</b> for system control and annotation of documents. As to instruction, learning was found to proceed equally fast with speech and written text; a number of subjects preferred speech. Secondly, in speech-to-text conversion, subjects preferred <b>voice</b> <b>commands</b> to manual commands for layout and tygpgraphic control, although text input was slower with <b>voice</b> <b>commands.</b> Thirdly, <b>voice</b> annotations are more readily made than text annotations, but processing times may be longer for voice than for text annotations. In conclusion, speech is a valuable medium for human-computer interaction, provided the applications are carefully chosen and a proper user interface is made...|$|R
5000|$|Apple {{offers a}} wide range of <b>voice</b> <b>commands</b> to {{interact}} with Siri, including, but not limited to: ...|$|R
5000|$|Awake, the <b>voice</b> <b>commands</b> (1947) - Bachs chorale Wachet auf, ruft uns die Stimme, {{transcribed}} for orchestra ...|$|R
40|$|Speech {{recognition}} (SR) {{systems such}} as Siri or Google Now have become an increasingly popular human-computer interaction method, and have turned various systems into voice controllable systems(VCS). Prior work on attacking VCS shows that the hidden <b>voice</b> <b>commands</b> that are incomprehensible to people can control the systems. Hidden <b>voice</b> <b>commands,</b> though hidden, are nonetheless audible. In this work, we design a completely inaudible attack, DolphinAttack, that modulates <b>voice</b> <b>commands</b> on ultrasonic carriers (e. g., f > 20 kHz) to achieve inaudibility. By leveraging the nonlinearity of the microphone circuits, the modulated low frequency audio commands can be successfully demodulated, recovered, and more importantly interpreted by the speech recognition systems. We validate DolphinAttack on popular speech recognition systems, including Siri, Google Now, Samsung S Voice, Huawei HiVoice, Cortana and Alexa. By injecting a sequence of inaudible <b>voice</b> <b>commands,</b> we show a few proof-of-concept attacks, which include activating Siri to initiate a FaceTime call on iPhone, activating Google Now to switch the phone to the airplane mode, and even manipulating the navigation system in an Audi automobile. We propose hardware and software defense solutions. We validate that it is feasible to detect DolphinAttack by classifying the audios using supported vector machine (SVM), and suggest to re-design voice controllable systems to be resilient to inaudible <b>voice</b> <b>command</b> attacks. Comment: 15 pages, 17 figure...|$|R
