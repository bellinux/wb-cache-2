0|10000|Public
40|$|In this work, {{we present}} a nonlocal {{expansion}} scheme to study correlated electron systems aiming at a better description of its spatial fluctuations at all length scales. Taking <b>the</b> nonlocal <b>coupling</b> as a perturbation to the local degrees of freedom, we show that the nonlocality in the self-energy function can be <b>efficiently</b> <b>constructed</b> from <b>the</b> <b>coupling</b> between local fluctuations. It can provide one unified framework to incorporate nonlocality to both ordered and disordered correlated many-body fermion systems. In this application, we prove that the dual-fermion approach {{can be understood as}} a special case of this nonlocal expansion scheme. The scheme presented in this work is constructed without introducing any dual variable, in which the interacting nature and the correlated behaviors of the lattice fermions have a clear physics correspondence. Thus, in this special case, the equivalence of the dual-fermion approach to the nonlocal expansion scheme beautifully reveals the physics origin of the dual variables. We show that the noninteracting dual-fermion Green's function corresponds exactly to a nonlocal <b>coupling</b> of <b>the</b> lattice fermion renormalized by the local single-particle charge fluctuations, and the dual-fermion self-energy behaves as the one-particle fully irreducible components of the lattice Green's function. Not only limited to this specific example, the nonlocal expansion scheme presented in this work can also be applied to other problems depending on the choice of the local degrees of freedom. Comment: 10 pages, 4 figures; minor changes; published versio...|$|R
40|$|A {{synthesis}} {{of natural and}} synthetic members of the meridianin family of kinase inhibitory natural products has been developed. The sequence utilizes {{a variation of the}} Cacchi palladium-catalyzed domino reaction to <b>efficiently</b> <b>construct</b> <b>the</b> heterocyclic framework of the meridianins and meriolins from monocyclic precursors. Scott R. Walker, Milena L. Czyz, and Jonathan C. Morri...|$|R
3000|$|... 2)-sized {{subset of}} samples {{to be removed}} cannot be <b>efficiently</b> <b>constructed</b> from <b>the</b> {{knowledge}} of the best selections of n [...]...|$|R
40|$|Proper Orthogonal Decomposition (POD) is an {{efficient}} model order reduction technique for linear problems in computational sciences, recently gaining popularity in electromagnetics. However, its efficiency {{has been shown}} to considerably degrade for nonlinear problems. In this paper, we propose a reduced order model for nonlinear magnetodynamic problems by combining POD with an interpolation on manifolds, which interpolates the reduced bases to <b>efficiently</b> <b>construct</b> <b>the</b> desired solution. Peer reviewe...|$|R
40|$|The problem {{considered}} involves estimating {{a two-dimensional}} isotropic random field given noisy observations of this field over a disk of finite radius. By expanding {{the field and}} observations in Fourier series, and exploiting the covariance structure of the resulting Fourier coefficient processes, recursions are obtained for <b>efficiently</b> <b>constructing</b> <b>the</b> linear least-squares estimate of the field as the radius of the observa-tion disk increases. These recursions {{are similar to the}} Levinson equations of one-dimensional linear prediction. In the spectral domain they take the form of Schödinger equations, which are used to give an inverse spectral interpretation of our estimation procedure...|$|R
5000|$|In {{quantum field}} theory for example, {{according}} to Crawford (1998), <b>the</b> called <b>coupled</b> cluster diagram is a [...] "simple diagrammatic formalism popularized by Kucharski and Bartlett 1986 by which one may <b>construct</b> <b>the</b> <b>coupled</b> cluster energy and amplitude equations far more quickly than by direct application of Wick's theorem".|$|R
40|$|Abstract. Justification is <b>the</b> {{process of}} <b>constructing</b> {{evidence}}, {{in terms of}} proof, for the truth or falsity of an answer derived by tabled evaluation. The evidence is most easily <b>constructed</b> by post-processing <b>the</b> memo tables created during query evaluation. In this paper we introduce online justification, based on program transformation, to <b>efficiently</b> <b>construct</b> <b>the</b> evidence during query evaluation, while adding little overhead to the evaluation itself. Apart from its efficiency, online justification separates evidence generation from exploration thereby providing flexibility in exploring the evidence either declaratively or procedurally. We present experimental results obtained on examples that construct large evidences which demonstrate the scalability of online justification. ...|$|R
40|$|A dynamic {{decision}} {{model can}} facilitate the complicated decision-making process in medicine, {{in which both}} time and uncertainty are explicitly considered. In this paper, we {{address the problem of}} automatic construction of a dynamic decision model from a large medical database. Within the DynaMoL (a dynamic decision modeling language) framework, a model can be represented in influence view. Thus, our proposed approach first learns the structures of the influence view based on the minimal description length (MDL) principle, and then obtains the conditional probabilities of the model by Bayesian method. The experiment results demonstrate that our system can <b>efficiently</b> <b>construct</b> <b>the</b> influence views from data with high fidelity. Keywords...|$|R
40|$|Mastronardi, Lemmerling, and van Huel {{presented}} an algorithm for solving a total {{least squares problem}} when the matrix and its perturbations are Toeplitz. A Toeplitz matrix is {{a special kind of}} matrix with small displacement rank. Here we generalize the fast algorithm to any matrix with small displacement rank. In particular, we show how to <b>efficiently</b> <b>construct</b> <b>the</b> generators whenever M has small displacement rank and show that in many important cases the Cholesky factorization of the matrix M M can also be determined fast. We further extend this problem to Tikhonov regularization of ill-posed problems and illustrate the use of the algorithm on an image deblurring problem...|$|R
50|$|In Xenopus, XMAP215 and EB1 {{have been}} {{reported}} to interact with each other. While XMAP215 functions to both grow and shrink the microtubule, EB1 is only present during growth. Alone, these proteins have mild effects on microtubule growth. Together, these proteins act in synergy and lengthen microtubules at a much greater rate. Without XMAP215, EB1 does not have a tubulin polymerase that can <b>efficiently</b> <b>construct</b> <b>the</b> microtubule plus-end with free tubulin. Without EB1, XMAP215 continues to add tubulin to the plus-end, but the integrity of the microtubule lattice becomes compromised. This is because EB1 binds to the microtubule lattice as a stabilizer to keep the tubulin straight.|$|R
40|$|In {{this paper}} we show how to <b>construct</b> <b>the</b> <b>coupled</b> (multicomponent) Harry Dym (cHD) {{hierarchy}} from classical Stäckel separable systems. Both nonlocal and purely differential parts of hierarchies are obtained. We also construct various classes of solutions of cHD hierarchy from solutions of corresponding Stäckel systems. Comment: 16 page...|$|R
30|$|An ACO-based method {{including}} its corresponding framework is proposed for solving the project scheduling problem {{in terms of}} minimizing project duration and resource leveling index. An ant representation of activity execution mode, based on which a feasible schedule (including duration and resource allocation for all activities and, in result, project duration and resource leveling index) can be definitely produced, is adopted for the ACO-based approach. The ACO artificial agent seems to provide a powerful alternative to traditional methods in terms of construction scheduling since {{it is able to}} provide an efficient and easy-to-implement alternative to analyze and achieve the project scheduling problem and, in result, <b>efficiently</b> <b>construct</b> <b>the</b> best solutions in acyclic (unidirectional) network topologies.|$|R
40|$|We {{introduce}} {{and analyze}} σ-local graphs, {{based on a}} definition of locality by Erickson [11]. We present two algorithms to construct such graphs, for any real number σ> 1 and any set S of n points. These algorithms run in time O(σ d n + n log n) for sets in R d and O(n log 3 n log log n + k) for sets in the plane, where k {{is the size of}} the output. Algorithms to find the minimum or maximum σ such that the corresponding graph has properties such as connectivity, planarity, and no-isolated vertex are presented, with complexities in n log O(1) n. These algorithms {{can also be used to}} <b>efficiently</b> <b>construct</b> <b>the</b> corresponding graphs. ...|$|R
40|$|Implicit {{techniques}} for construction and {{representation of the}} reachability set of a high-level model have become quite efficient for certain types of models. In particular, previous work developed a “saturation” algorithm that exploits asynchronous behavior to <b>efficiently</b> <b>construct</b> <b>the</b> reachability set using multiway decision diagrams, but requires each model event to be expressible as a Kronecker product. In this paper, we develop {{a new version of}} the saturation algorithm that works for a general class of models: models whose events are not necessarily expressible as Kronecker products, models containing events with complex priority structures, and models whose state variables have unknown bounds. We apply our algorithm to several examples and give detailed experimental results...|$|R
40|$|The {{aim of this}} DPhil {{research}} project is to apply cascade reactions to the total syntheses of gephyrotoxin and morphine. This thesis describes a novel approach towards gephyrotoxin in which the key disconnection is a nucleophilic cascade reaction that <b>constructs</b> <b>the</b> core structure bearing three rings and five stereocentres. This cascade approach enables the total synthesis of gephyrotoxin in nine steps with 14 % overall yield. In addition, a new approach towards morphine, involving an ene-yne-ene cascade ring closing metathesis and 1, 6 -addition to <b>efficiently</b> <b>construct</b> <b>the</b> B/C/D ring systems in a single operation, shortening the synthesis to nine steps with 6. 6 % overall yield is discussed. The cascade shortcuts enable rapid approaches to these natural products, which results in the most concise total syntheses of gephyrotoxin and morphine described to date. </p...|$|R
40|$|AbstractWe {{introduce}} {{and analyze}} σ-local graphs, {{based on a}} definition of locality by Erickson [J. Erickson, Local polyhedra and geometric graphs, Computational Geometry: Theory and Applications 31 (1 – 2) (2005) 101 – 125]. We present two algorithms to construct such graphs, for any real number σ> 1 and any set S of n points. These algorithms run in time O(σdn+nlogn) for sets in Rd and O(nlog 3 nloglogn+k) for sets in the plane, where k {{is the size of}} the output. For sets in the plane, algorithms to find the minimum or maximum σ such that the corresponding graph has properties such as connectivity, planarity, and no-isolated vertex are presented, with complexities in O(nlogO(1) n). These algorithms {{can also be used to}} <b>efficiently</b> <b>construct</b> <b>the</b> corresponding graphs...|$|R
40|$|Feature {{selection}} {{is a fundamental}} process in many classifier design problems. However, it is NP-complete and approximate approaches often require requires extensive exploration and evaluation. This paper describes a novel approach that represents feature selection as a continuous regularization problem which has a single, global minimum, where the modelÕs complexity is measured using a 1 -norm on the parameter vector. A new exploratory design process is also described that allows <b>the</b> designer to <b>efficiently</b> <b>construct</b> <b>the</b> complete locus of sparse, kernel-based classifiers. It allows the designer to investigate the optimal parametersÕ trajectories as the regularization parameter is altered and look for effects, such as SimpsonÕs paradox, that occur in many multivariate data analysis problems. The approach is demonstrated on the well-known Australian Credit data set. Ó 2005 Published by Elsevier B. V...|$|R
40|$|We {{consider}} {{the problem of}} using an inversion algorithm to build inverted files from large document collections. In particular, we focus on applying a hash table to represent the dynamic dictionary data structure. The dictionary is used to store all distinct terms in the document collection during indexing process. It is <b>the</b> challenge to <b>efficiently</b> <b>construct</b> <b>the</b> hash table, since {{we do not know}} in advance the table size. In this paper, we introduce an efficient algorithm for building an inverted file based on the combination of the sortbased inversion algorithm and the cuckoo hashing. Our approach is to exploit the cuckoo hashing scheme that guarantees linear space used and worst case constant look up time. The experimental results show that our algorithm performs well on two large datasets...|$|R
40|$|This account {{describes}} {{an overview of}} the asymmetric syntheses of pyrrolizidines, indolizidines and quinolizidines via a common double reductive cyclisation protocol. The highly diastereoselective conjugate addition of an enantiopure lithium amide to an α,β-unsaturated ester incorporating a terminal C=C bond installed the nitrogen bearing stereogenic centre and was followed by alkenylation of the corresponding enolate to introduce the second olefinic functionality. Alternatively, conjugate addition to the corresponding α-alkenyl α,β-unsaturated ester followed by α-pronation of the intermediate enolate may also be used to access the cyclisation precursor. After oxidation of the two terminal olefinic units to give the corresponding dialdehyde, tandem hydrogenolysis/hydrogenation was employed to <b>efficiently</b> <b>construct</b> <b>the</b> azabicylic core of each target molecule. This double reductive cyclisation strategy was successfully utilized in the syntheses of 13 azabicylic alkaloids or closely related analogues...|$|R
40|$|We {{investigate}} {{for which}} resource states an efficient classical simulation of measurement based quantum computation is possible. We {{show that the}} Schmidt [...] rank width, a measure recently introduced to assess universality of resource states, {{plays a crucial role}} in also this context. We relate Schmidt [...] rank width to the optimal description of states in terms of tree tensor networks and show that an efficient classical simulation of measurement based quantum computation is possible for all states with logarithmically bounded Schmidt [...] rank width (with respect to the system size). For graph states where the Schmidt [...] rank width scales in this way, we <b>efficiently</b> <b>construct</b> <b>the</b> optimal tree tensor network descriptions, and provide several examples. We highlight parallels in the efficient description of complex systems in quantum information theory and graph theory. Comment: 16 pages, 4 figure...|$|R
40|$|Starting from {{steps of}} length h/me and time {{intervals}} h/mc 2, which imply a quasi-local Zitterbewe. quny with velocity steps fc, we employ discrimination be-tween bit-strings of finite length {{to construct a}} necessarily 3 + 1 dimensional eventspace for relativistic quantum mechanics. By using the combinatorial hierarchy to label the strings, we provide a successful start on <b>constructing</b> <b>the</b> <b>coupling</b> constants and mass ratios implied by the scheme. Agreement with experiment is surprisingly accurate...|$|R
40|$|We {{develop a}} {{technique}} to compute scalar potentials in extended supergravities in any dimension on a pure group-theoretical basis. The fermionic supersymmetry variations, which determine the potential, only depend on boosted structure constants of a gauge subgroup K ⊂ G of the isometry group G of the scalar manifold G/H. These variations follow from the Bianchi identities of the underlying gauge superalgebra. We apply this method to <b>construct</b> <b>the</b> <b>coupling</b> of N = 3 matter to supergravity...|$|R
40|$|In {{this paper}} we show how to <b>construct</b> <b>the</b> <b>coupled</b> (multicomponent) Harry Dym (cHD) {{hierarchy}} from classical Stackel separable systems. Both nonlocal and purely differential parts of hierarchies are obtained. We also construct various classes of solutions of cHD hierarchy from solutions of corresponding Stackel systems. Original Publication:Krzysztof Marciniak and Maciej Blaszak, Construction of coupled Harry Dym hierarchy and its solutions from Stackel systems, 2010, NONLINEAR ANALYSIS-THEORY METHODS and APPLICATIONS, (73), 9, 3004 - 3017. [URL] Elsevier Science B. V., Amsterdam. [URL]...|$|R
30|$|In this section, a coupled {{model for}} {{communication}} and rumor spreading under an emergency situation is <b>constructed.</b> Firstly, <b>the</b> <b>coupled</b> mechanism is introduced. Then, a conceptual model is given before the mathematical model is <b>constructed</b> based on <b>the</b> foundation.|$|R
40|$|Standard SU(2) Heavy Baryon Chiral Perturbation Theory is {{extended}} {{in order to}} include the case of light or even vanishing quark condensate. The effective lagrangian is given to O(p 2) in its most general form and to O(p 3) in the scalar sector. A method is developed to <b>efficiently</b> <b>construct</b> <b>the</b> relativistic baryonic effective lagrangian for chiral SU(2) to all orders in the chiral expansion. As a first application, mass- and wavefunction renormalization {{as well as the}} scalar form factor of the nucleon is calculated to O(p 3). The result is compared to a dispersive analysis of the nucleon scalar form factor adopted to the case of a small quark condensate. In this latter analysis, the shift of the scalar form factor between the Cheng-Dashen point and zero momentum transfer is found to be enhanced over the result assuming strong quark condensation by up to a factor of two, with substantial deviations starting to be visible for r = ms / ˆm � 12...|$|R
40|$|Applications {{demanding}} multidimensional index {{structures for}} performing efficient similarity queries often involve {{a large amount}} of data. The conventional tuple-loading approach to building such an index structure for a large data set is inefficient. To overcome the problem, a number of algorithms to bulk-load the index structures, like the R-tree, from scratch for large data sets in continuous data spaces have been proposed. However, many of them cannot be directly applied to a non-ordered discrete data space (NDDS) where data values on each dimension are discrete and have no natural ordering. No bulk-loading algorithm has been developed specifically for an index structure, such as the ND-tree, in an NDDS. In this paper, we present a bulk-loading algorithm, called the NDTBL, for the ND-tree in NDDSs. It adopts a special in-memory structure to <b>efficiently</b> <b>construct</b> <b>the</b> target ND-tree. It utilizes and extends some operations in the original ND-tree tupleloading algorithm to exploit the properties of an NDDS in choosing an...|$|R
40|$|We {{describe}} how to <b>efficiently</b> <b>construct</b> <b>the</b> quantum chemical Hamiltonian operator in matrix product form. We present its implementation as a density matrix renormalization group (DMRG) algorithm for quantum chemical applications in a purely matrix product based framework. Existing implementations of DMRG for quantum chemistry {{are based on}} the traditional formulation of the method, which was developed from a viewpoint of Hilbert space decimation and attained a higher performance compared to straightforward implementations of matrix product based DMRG. The latter variationally optimizes a class of ansatz states known as matrix product states (MPS), where operators are correspondingly represented as matrix product operators (MPO). The MPO construction scheme presented here eliminates the previous performance disadvantages while retaining the additional flexibility provided by a matrix product approach; for example, the specification of expectation values becomes an input parameter. In this way, MPOs for different symmetries - abelian and non-abelian - and different relativistic and non-relativistic models may be solved by an otherwise unmodified program. Comment: 11 pages, 7 figure...|$|R
40|$|A {{coupling}} by {{reflection of}} a time-inhomogeneous diffusion process on a manifold are studied. The condition we assume is a natural time-inhomogeneous extension of lower Ricci curvature bounds. In particular, it includes the case of backward Ricci flow. As in time-homogeneous cases, our coupling provides a gradient estimate of the diffusion semigroup which yields the strong Feller property. To <b>construct</b> <b>the</b> <b>coupling</b> via discrete approximation, we establish the convergence in law of geodesic random walks {{as well as a}} uniform non-explosion type estimate. Comment: 29 page...|$|R
40|$|International audienceData {{structures}} that handle very complex scenes (hundreds {{of thousands of}} objects) {{have in the past}} either been laboriously built by hand, or have required the determination of unintuitive parameter values by the user. It is often the case that an incorrect choice of these parameters can result in greedy memory requirements or severely degraded performance. As a remedy to this problem we propose a new data structure which is fully automatic since it does not require the user to determine any input parameters. The structure is built by first filtering the input objects by size, subsequently applying a clustering step to objects of the same size and finally building a hierarchy of uniform grids (HUG). We then show that this data structure can be <b>efficiently</b> <b>constructed.</b> <b>The</b> implementation of the HUG shows that the new structure is stable since it's memory requirements grow linearly with the size of the scene, and that it presents a satisfactory compromise between memory usage and computational efficiency. A detailed comparison with previous data structures is also presented in the results...|$|R
40|$|Aerodynamic noise {{increases}} with the sixth {{power of the}} running speed. As the speed increases, aerodynamic noise becomes predominant and begins {{to be the main}} noise source at a certain high speed. As a result, aerodynamic noise has to be focused on when designing new high-speed trains. In order to perform the aerodynamic noise optimization, the equivalent continuous sound pressure level (SPL) has been used in the present paper, which could take all of the far field observation probes into consideration. The Non-Linear Acoustics Solver (NLAS) approach has been utilized for acoustic calculation. With the use of Kriging surrogate model, a multi-objective optimization of the streamlined shape of high-speed trains has been performed, which takes the noise level in the far field and the drag of the whole train as <b>the</b> objectives. To <b>efficiently</b> <b>construct</b> <b>the</b> Kriging model, the cross validation approach has been adopted. Optimization results reveal that both the equivalent continuous sound pressure level and the drag of the whole train are reduced in a certain extent...|$|R
40|$|Abstract—Based on IEEE 802. 16 e standard, WiMAX {{proposed}} a relay-based approach, namely, the IEEE 802. 16 j standard, {{to extend the}} service area of Base Stations (BSs) and {{to improve the quality}} of RSS, and then achieved the advantages of low-cost and compatible with existing WiMAX protocol. According to the different features on mobility and relay range, Relay Station (RS) can be classified into three types: Fixed RS (FRS), Nomadic RS (NRS) and Mobile RS (MRS). Since a relay-based WiMAX network includes different types of RSs, how to <b>efficiently</b> <b>construct</b> <b>the</b> relay-based WiMAX and how to determine an optimal routing path between a Mobile Station (MS) and the MR-BS become two important issues. This paper thus {{proposed a}}n IEEE 802. 16 j-conformed relay-based adaptive cost-based routing approach, in which a multihop optimal path is selected in terms of link bandwidth, path length and channel condition. Numerical results demonstrated that the proposed routing approach significantly outperforms other approaches in Fractional Reward Loss, network utilization and average end-to-end path delay...|$|R
40|$|Abstract—In this paper, three generic RAM-based {{architectures}} {{are proposed}} to <b>efficiently</b> <b>construct</b> <b>the</b> corresponding two-dimensional architectures {{by use of}} the line-based method for any given hardware architecture of one-dimensional (1 -D) wavelet filters, including conventional convolution-based and lifting-based architectures. An exhaustive analysis of two-dimensional architectures for discrete wavelet transform in the system view is also given. The first proposed architecture is for 1 -level decomposition, which is presented by introducing the categories of internal line buffers, the strategy of optimizing the line buffer size, and the method of integrating any 1 -D wavelet filter. The other two proposed architectures are for multi-level decomposition. One applies the recursive pyramid algorithm directly to the proposed 1 -level architecture, {{and the other one}} combines the two previously proposed architectures to increase the hardware utilization. According to the comparison results, the proposed architecture outperforms previous architectures in the aspects of line buffer size, hardware cost, hardware utilization, and flexibility. Index Terms—Discrete wavelet transform (DWT), lifting scheme, line-based method, recursive pyramid algorithm, VLSI architecture. I...|$|R
40|$|Data {{structures}} that handle very complex scenes (hundreds {{of thousands of}} objects) {{have in the past}} either been laboriously built by hand, or have required the determination of unintuitive parameter values by the user. It is often the case that an incorrect choice of these parameters can result in greedy memory requirements or severely degraded performance. As a remedy to this problem we propose a new data structure which is fully automatic since it does not require the user to determine any input parameters. The structure is built by first filtering the input objects by size, subsequently applying a clustering step to objects of the same size and finally building a hierarchy of uniform grids (¡£¢¥ ¤). We then show that this data structure can be <b>efficiently</b> <b>constructed.</b> <b>The</b> implementation of the ¡£¢¥¤ shows that the new structure is stable since it’s memory requirements grow linearly with the size of the scene, and that it presents a satisfactory compromise between memory usage and computational efficiency. A detailed comparison with previous data structures is also presented in the results. 1...|$|R
40|$|Recently, RC {{buildings}} with core wall structures have been <b>constructed.</b> <b>The</b> <b>coupling</b> beams connecting core walls are {{possible to be}} failed by bond splitting during an earthquake. Short span beams using SHCC (Strain Hardening Cementitious Composites) with PVA fibers {{have been developed to}} improve brittle behavior. In this study, cantilever-shaped specimens were subjected to bond splitting tests to investigate bond characteristics of SHCC beams. The experimental bond strength shows higher value than calculated strength by conventional formulas for RC beams. The effect of SHCC can be expressed by modifying the term of lateral reinforcement ratio in these formulas...|$|R
40|$|A {{recently}} introduced new SPS resin, possessing a 2 -(ortho-nitrophenyl) ethanal linker, {{was used for}} the regioselective on-resin synthesis of N-mono-hydroxylated and N-mono-methylated polyamine spider toxins of Agelenopsis aperta and Larinioides folium. The polyamine backbones of the target compounds were <b>efficiently</b> <b>constructed</b> from <b>the</b> center by reductive amination of the aldehyde linker, followed by stepwise alkylation and acylation on solid support. Depending on the cleavage conditions, employing either oxidation/Cope elimination or methylation/Hofmann elimination, regioselectively the respective N-hydroxyl or N-methyl products were obtained. Employing this methodology, a number of acylpolyamine spider toxins were synthesized and identified as venom components by UHPLC and ESI-MS/MS...|$|R
40|$|AbstractIn {{previous}} work on artificial social systems, social laws for multi-agent mobilization were handcrafted for particular network structures. In this work, we introduce an algorithm for the automatic synthesis of social laws for multi-agent mobilization in any 2 -connected graph environment. We introduce {{the notion of}} a graph routing and show that the problem of computing a useful social law can be reduced to that of finding a routing in a graph. Then we show that any given 2 -connected graph has a routing which can be <b>efficiently</b> <b>constructed,</b> yielding <b>the</b> desired social law for multi-agent mobilization on the given graph...|$|R
