21|5264|Public
40|$|The {{association}} {{structure of}} a Bayesian network can be known in advance by subject matter knowledge or have {{to be learned from}} a database. In case of <b>data</b> <b>driven</b> <b>learning,</b> one of the most known procedures is the PC algorithm where the structure is inferred carrying out several independence tests under the assumption of independent and identically distributed observations. In practice, sample selection in surveys involves more complex sampling designs. In this paper, {{a modified version of the}} PC algorithm is proposed for inferring casual structure from complex survey data...|$|E
40|$|This chapter {{draws on}} my {{experience}} as a teacher in university translation and English courses and on two research and teaching areas: technology in language learning and the <b>Data</b> <b>Driven</b> <b>Learning</b> approach and its attempt to introduce the analysis of authentic linguistic data in the learning process. It suggests that the two approaches can fruitfully be merged in {{the perspective of a}} new exploitation of the associated methodologies and of the tools and resources offered by the web to create online activities directed at the average foreign language students. This could lead to a new way to foster autonomy, awareness and discovery procedures in our classrooms and in self study settings...|$|E
40|$|The aim of {{this paper}} is to review and analyse {{relevant}} factors related to the implementation of corpus linguistics (CL) in higher education. First we set out to describe underlying principles of CL and its developments in relation to theoretical linguistics and its applications in modern teaching practices. Then we attempt to establish how different types of corpora have contributed to the development of direct and indirect approaches in language teaching. We single out <b>Data</b> <b>Driven</b> <b>Learning</b> (DDL) due to its relevance in applied linguistics literature, and examine in detail advantages and drawbacks. Finally, we outline problems concerning the implementation of CL in the classroom since awareness of the limitations of CL is vital for its future success...|$|E
40|$|This book {{combines}} geostatistics {{and global}} mapping systems {{to present an}} up-to-the-minute study of environmental data. Featuring numerous case studies, the reference covers model dependent (geostatistics) and <b>data</b> <b>driven</b> (machine <b>learning</b> algorithms) analysis techniques such as risk mapping, conditional stochastic simulations, descriptions of spatial uncertainty and variability, artificial neural networks (ANN) for spatial data, Bayesian maximum entropy (BME), and more...|$|R
40|$|Abstract: <b>Data</b> <b>driven</b> {{language}} <b>learning</b> promotes learner {{autonomy and}} discovery learning by providing learners with authentic foreign language data for self-directed or guided exploration. However, the {{effective use of}} corpora data requires {{a certain level of}} linguistic knowledge. We propose an information retrieval augmentation to concordance for adapting to self-directed context of independent learners. The approach involves an expression element model and a retrieving mechanism so as to reduce linguistic threshold and enhance learner empowerment. Simulation results with English proficiency tests and students’ writing samples support the effectiveness of the approach...|$|R
40|$|International audienceThe paper aims {{at making}} online {{forecast}} of electrical load at the MV-LV transformer level. Optimal {{management of the}} Plug-in Electric Vehicles (PEV) charging requires the forecast of the electrical load for future hours. The forecasting module needs to be online (i. e update and make forecast for the future hours, every hour). The inputs to the predictor are historical electrical and weather <b>data.</b> Various <b>data</b> <b>driven</b> machine <b>learning</b> algorithms are compared to derive the most suitable model. The results indicate that an online forecasting method has an error between 2 - 5 % for the future 24 -hour. The decentralized management system works well with the forecasting data...|$|R
40|$|Most of {{the robotic}} arms are {{controlled}} by simple decentralized PD controllers. This control paradigm treats couplings between joints as disturbances {{that are to be}} rejected. Having a realistic model of the manipulator would allows for canceling out nonlinearities due to coupling. Furthermore, model-based controllers are able to achieve lower power consumption and compliance. This is a valuable characteristic for a lightweight robot running on batteries and operating in presence of humans. Standard rigid body dynamics (RBD) model is insufficiently precise due to elasticity of lightweight robotics arms and nonlinearities in motor drives. Recently, <b>data</b> <b>driven</b> <b>learning</b> techniques such as Gaussian Process Regression (GPR) have shown promising results in model learning. These methods are particaulary useful because of theirs flexibility as they learn from input-output data only...|$|E
40|$|In {{many high}} schools, the grammar {{textbook}} {{seems like an}} immovable fixture in English education. This article discusses {{the possibility of using}} <b>Data</b> <b>Driven</b> <b>Learning</b> (DDL) in high school environments which are resistant to change. After considering some of the pragmatic difficulties with using student-based learning while still employing set textbooks, the article proposes using a hybrid of teaching methods to introduce DDL in the classroom. By using both the textbook and information from the British Nation Corpus, students can be taught to explore grammar rules on their own terms while still meeting the requirements of learning the required grammar. Finally, the article discusses changes in implementing such a program and practical steps teachers can take to move forward in using DDL in their classrooms...|$|E
40|$|A {{critical}} {{design decision}} {{in the construction of}} intrusion detection systems is often the selection of features describing the characteristics of the data being learnt. Selecting features often requires a priori or expert knowledge and may lead to the introduction of specific attack biases – intended or otherwise. To this end, summarized network connections from the DARPA 98 Lincoln Labs dataset are employed for training and testing a <b>data</b> <b>driven</b> <b>learning</b> architecture. The learning architecture is composed from a hierarchy of selforganizing feature maps. Such a scheme is entirely unsupervised, thus the quality of the intrusion detection system is directly influenced by the quality of the dataset. Dataset biases are investigated through three different dataset partitions: 10 % KDD (default training dataset); normal connections alone; 50 / 50 mix of attack and normal. The three resulting intrusion detection systems appear to be competitive with the alternative cluster based datamining approaches...|$|E
40|$|Fuzzy Cognitive Maps (FCM) is a {{technique}} to represent models of causal inference networks. <b>Data</b> <b>driven</b> FCM <b>learning</b> approach {{is a good way}} to model FCM. We present a hybrid FCM learning method that combines Nonlinear Hebbian Learning (NHL) and Extended Great Deluge Algorithm (EGDA), which has the efficiency of NHL and global optimization ability of EGDA. We propose using NHL to train FCM at first, in order to get close to optimization, and then using EGDA to make model more accurate. We propose an experiment to test the accuracy and running time of our methods. Fuzzy Cognitive Maps (FCM) (1) is a modeling methodology that represents graph causal relations o...|$|R
40|$|Sentence {{ordering}} is {{a general}} and critical task for natural language generation applications. Previous works have focused on improving its performance in an external, downstream task, such as multi-document summarization. Given its importance, we propose to study it as an isolated task. We collect a large corpus of academic texts, and derive a <b>data</b> <b>driven</b> approach to <b>learn</b> pairwise ordering of sentences, and validate the efficacy with extensive experiments. Source codes and dataset of this paper will be made publicly available...|$|R
40|$|Abstract — Many {{intelligent}} {{transportation systems}} (ITS) applications require accurate prediction of traffic parameters. Previous {{studies have shown}} that <b>data</b> <b>driven</b> machine <b>learning</b> methods like support vector regression (SVR) can effectively and accurately perform this task. However, these studies focus on highways, or a few road segments. We propose a robust and scalable method using ν-SVR to tackle the problem of speed prediction of a large heterogenous road network. The traditional performance measures such as mean absolute percentage error (MAPE) and root mean square error (RMSE) provide little insight into spatial and temporal characteristics of prediction methods for a large network. This inadequacy can be a serious hurdle in effective implementation of prediction models for route guidance, congestion avoidance, dynamic traffic assignment and other ITS applications. We propose unsupervised learning techniques by employing k-means clustering, principal component analysis (PCA), and self organizing maps (SOM) to overcome this insufficiency. We establish the effectiveness of the developed methods by evaluation of spatial and temporal characteristics of prediction performance of the proposed variable window ν-SVR method. I...|$|R
40|$|A <b>data</b> <b>driven</b> <b>learning</b> based {{approach}} has been adopted to classify a video programme into a set of five pre-defined genre including a 7 orts, cartoons, news, commercials and music. The video database studied {{is a collection of}} five-hour non-edited TV broadcast programme of dozens of video clips: one hour long in total for each genre with an even split of training and testing data. This paper reports the classification result for the two media modes - acoustic and visual - used separately, and for a linear fusion of the two modes at the score level. The correaIonding classification accuracy achieved is approximately 74 %, 73 %, and 87 %, reaIectively, given a 30 -second decision window, or for every 30 second non-overlap video segment an answer of its identity is provided Further analysis of the confusion matrices of the classification errors is given. The extension of the approach to the open-set video genre verification and semantic scene segmentation and classification is expected...|$|E
40|$|Abstract — Task-space {{tracking}} control {{is essential for}} robot manipulation. In practice, task-space control of redundant robot systems {{is known to be}} susceptive to modeling errors. Here, <b>data</b> <b>driven</b> <b>learning</b> methods may present an interesting alternative approach. However, learning models for task-space {{tracking control}} from sampled data is an ill-posed problem. In particular, the same input data point can yield many different output values which can form a non-convex solution space. Because the problem is ill-posed, models cannot be learned from such data using common regression methods. While learning of task-space control mappings is globally ill-posed, it has been shown in recent work that it is locally a well-defined problem. In this paper, we use this insight to formulate a local kernelbased learning approach for online model learning for taskspace tracking control. For evaluations, we show in simulation the ability of the method for online model learning for taskspace tracking control of redundant robots. I...|$|E
40|$|We {{present a}} method for {{classifying}} proteins into families based on short subsequences of amino acids using a new probabilistic model called sparse Markov transducers (SMT). We classify a protein by estimating probability distributions over subsequences of amino acids from the protein. Sparse Markov transducers, similar to probabilistic suffix trees, estimate a probability distribution conditioned on an input sequence. SMTs generalize probabilistic suffix trees by allowing for wild-cards in the conditioning sequences. Since substitutions of amino acids are common in protein families, incorporating wild-cards into the model significantly improves classification performance. We present two models for building protein family classifiers using SMTs. As protein databases become larger <b>data</b> <b>driven</b> <b>learning</b> algorithms for probabilistic models such SMTs may require vast amount of memory. We therefore describe efficient data structures to improve the memory usage SMTs and use them in our experiments. We evaluate SMTs by building protein family classifiers using the Pfam and SCOP databases and compare our results to previously published results and state-of-the-art protein homology detection methods. SMTs outperform previous probabilistic suffix tree methods and under certain conditions perform comparably to state-of-the-art protein homology methods...|$|E
40|$|Natural {{languages}} that {{originate from}} a common ancestor are genetically related, words are the core of any language and cognates are words sharing the same ancestor and etymology. Cognate identification, therefore, represents the foundation upon which the evolutionary history of languages may be discovered, while linguistic phylogenetic inference aims to estimate the genetic relationships that exist between them. In this thesis, using several techniques originally developed for biological sequence analysis, we have designed a <b>data</b> <b>driven</b> orthographic <b>learning</b> system for measuring string similarity and we have successfully applied it to the tasks of cognate identification and phylogenetic inference. Our system has outperformed the best comparable phonetic and orthographic cognate identification models previously reported in the literature, with results statistically significant and remarkably stable, regardless of the variation of the training dataset dimension. When applied to phylogenetic inference of the Indo-European language family, whose higher structure does not yet have consensus, our method has estimated phylogenies which are compatible with the benchmark tree and has reproduced correctly all the established major language groups and subgroups present in the dataset...|$|R
40|$|Many {{intelligent}} {{transportation systems}} (ITS) applications require accurate prediction of traffic parameters. Previous {{studies have shown}} that <b>data</b> <b>driven</b> machine <b>learning</b> methods like support vector regression (SVR) can effectively and accurately perform this task. However, these studies focus on highways, or a few road segments. We propose a robust and scalable method using v-SVR to tackle the problem of speed prediction of a large heterogeneous road network. The traditional performance measures such as mean absolute percentage error (MAPE) and root mean square error (RMSE) provide little insight into spatial and temporal characteristics of prediction methods for a large network. This inadequacy can be a serious hurdle in effective implementation of prediction models for route guidance, congestion avoidance, dynamic traffic assignment and other ITS applications. We propose unsupervised learning techniques by employing k-means clustering, principal component analysis (PCA), and self organizing maps (SOM) to overcome this insufficiency. We establish the effectiveness of the developed methods by evaluation of spatial and temporal characteristics of prediction performance of the proposed variable window v-SVR method. Singapore-MIT Alliance for Research and Technology Cente...|$|R
40|$|LTEs uplink (UL) {{efficiency}} critically {{depends on}} how the interference across different cells is controlled. The unique characteristics of LTEs modulation and UL resource assignment poses considerable challenges in achieving this goal because most LTE deployments have 1 : 1 frequency re-use, and the uplink interference can vary considerably across successive time slots. In this work, we propose LeAP, a measurement <b>data</b> <b>driven</b> machine <b>learning</b> paradigm for power control to manage up-link interference in LTE. The <b>data</b> <b>driven</b> approach has the inherent advantage that the solution adapts based on network traffic, propagation and network topology, that is increasingly heterogeneous with multiple cell-overlays. LeAP system design consists of the following components: (i) design of user equipment (UE) measurement statistics that are succinct, yet expressive enough to capture the network dynamics, and (ii) design of two learning based algorithms that use the reported measurements to set the power control parameters and optimize the network performance. LeAP is standards compliant and can be implemented in centralized SON (self organized networking) server resource (cloud). We perform extensive evaluations using radio network plans from real LTE network operational in a major metro area in United States. Our results show that, compared to existing approaches, LeAP provides a 4. 9 x gain in the 20 th percentile of user data rate, and 3. 25 x gain in median data rate. Comment: Submitted to a journa...|$|R
40|$|Data {{quality is}} {{fundamentally}} important {{to ensure the}} reliability of data for stakeholders to make decisions. In real world applications, such as scientific exploration of extreme environments, {{it is unrealistic to}} require raw data collected to be perfect. As data miners, when it is infeasible to physically know the why and the how in order to clean up the data, we propose to seek the intrinsic structure of the signal to identify the common factors of multivariate data. Using our new <b>data</b> <b>driven</b> <b>learning</b> method, the common-factor data cleaning approach, we address an interdisciplinary challenge on multivariate data cleaning when complex external impacts appear to interfere with multiple data measurements. Existing data analyses typically process one signal measurement at a time without considering the associations among all signals. We analyze all signal measurements simultaneously to find the hidden common factors that drive all measurements to vary together, but not {{as a result of the}} true data measurements. We use common factors to reduce the variations in the data without changing the base mean level of the data to avoid altering the physical meaning. Comment: 12 pages, 10 figures, 1 tabl...|$|E
40|$|Abstract—This paper {{proposed}} {{a novel approach}} for the Power Quality (PQ) disturbances classification based on the wavelet transform and self organizing learning array (SOLAR) system. Wavelet transform is utilized to extract feature vectors for various PQ disturbances based on the multiresolution analysis (MRA). These feature vectors then are applied to a SOLAR system for training and testing. SOLAR has three advantageous over a typical neural network: <b>data</b> <b>driven</b> <b>learning,</b> local interconnections and entropy based self-organization. Several typical PQ disturbances are taken into consideration in this paper. Comparison research between the proposed method, the support vector machine (SVM) method and existing literature reports show that the proposed method can provide accurate classification results. By the hypothesis test of the averages, it is shown {{that there is no}} statistically significant difference in performance of the proposed method for PQ classification when different wavelets are chosen. This means one can choose the wavelet with short wavelet filter length to achieve good classification results as well as small computational cost. Gaussian white noise is considered and the Monte Carlo method is used to simulate the performance of the proposed method in different noise conditions. Index Terms—Noise, power quality (PQ), self-organizing learning array (SOLAR), support vector machine (SVM), wavelet transform. I...|$|E
40|$|The aim of {{this study}} is to {{investigate}} the effects of a <b>Data</b> <b>Driven</b> <b>Learning</b> (DDL) approach on Iranian EFL learners' writing skills development and their attitudes towards the approach. A pre-test post-test control group design supplemented by a set of interviews and a questionnaire was employed to collect the required data. The control group received instructions through a conventional method while the experimental group received a certain number of classroom concordance-based handouts in addition to the conventional method. It was found that the DDL group participants can improve their declarative knowledge more than the Non-DDL group. Regarding analytic scoring, the results show that the DDL participants have improved their ‘language use’ features more than the Non-DDL group. This finding has been supported by the results obtained from analysing the ‘Accuracy’ measures. In the CAF analysis, lack of improvement in 'Complexity' features of the learners' performance and slight regression in mean length of T units and mean length of clause was explained as an indication of a trade-off between accuracy and fluency. Results obtained from qualitative data showed the participants’ positive attitudes towards the DDL approach. It was also found that DDL-based materials can help teachers in getting learners involved with learning through 'noticing'...|$|E
40|$|Abstract—Task-space {{control of}} {{redundant}} robot systems based on analytical models {{is known to}} be susceptive to modeling errors. Here, <b>data</b> <b>driven</b> model <b>learning</b> methods may present an interesting alternative approach. However, learning models for task-space tracking control from sampled data is an illposed problem. In particular, the same input data point can yield many different output values, which can form a non-convex solution space. Because the problem is ill-posed, models cannot be learned from such data using common regression methods. While learning of task-space control mappings is globally illposed, it has been shown in recent work that it is locally a well-defined problem. In this paper, we use this insight to formulate a local, kernel-based learning approach for online model learning for task-space tracking control. We propose a parametrization for the local model which makes an application in task-space tracking control of redundant robots possible. The model parametrization further allows us to apply the kerneltrick and, therefore, enables a formulation within the kernel learning framework. For evaluations, we show the ability of the method for online model learning for task-space tracking control of redundant robots. ...|$|R
40|$|Labeled Faces in the Wild (LFW) {{database}} {{has been}} widely utilized as the benchmark of unconstrained face verification and due to big <b>data</b> <b>driven</b> machine <b>learning</b> methods, the performance on the database approaches nearly 100 %. However, we argue that this accuracy may be too optimistic because of some limiting factors. Besides different poses, illuminations, occlusions and expressions, cross-age face is another challenge in face recognition. Different ages of the same person result in large intra-class variations and aging process is unavoidable in real world face verification. However, LFW does not pay much attention on it. Thereby we construct a Cross-Age LFW (CALFW) which deliberately searches and selects 3, 000 positive face pairs with age gaps to add aging process intra-class variance. Negative pairs with same gender and race are also selected to reduce the influence of attribute difference between positive/negative pairs and achieve face verification instead of attributes classification. We evaluate several metric learning and deep learning methods on the new database. Compared to the accuracy on LFW, the accuracy drops about 10 %- 17 % on CALFW. Comment: 10 pages, 9 figure...|$|R
40|$|Task-space {{control of}} {{redundant}} robot systems based on analytical models {{is known to}} be susceptive to modeling errors. Here, <b>data</b> <b>driven</b> model <b>learning</b> methods may present an interesting alternative approach. However, learning models for task-space tracking control from sampled data is an illposed problem. In particular, the same input data point can yield many different output values, which can form a non-convex solution space. Because the problem is ill-posed, models cannot be learned from such data using common regression methods. While learning of task-space control mappings is globally illposed, it has been shown in recent work that it is locally a well-defined problem. In this paper, we use this insight to formulate a local, kernel-based learning approach for online model learning for task-space tracking control. We propose a parametrization for the local model which makes an application in task-space tracking control of redundant robots possible. The model parametrization further allows us to apply the kerneltrick and, therefore, enables a formulation within the kernel learning framework. For evaluations, we show the ability of the method for online model learning for task-space tracking control of redundant robots...|$|R
40|$|Over {{the past}} decades, the {{potential}} for the direct use of corpora known as <b>data</b> <b>driven</b> <b>learning</b> (DDL) has gained great prominence in English language classrooms. A substantial number of empirical studies demonstrated that DDL instruction positively affects students’ learning. As learning outcomes can be affected by individual differences, some researchers have investigated the efficiency of DDL in the light of learners’ different characteristics to determine the type of learners who were more responsive to DDL. The DDL literature has indicated the need for more research addressing for whom DDL best suits. Therefore, the aim of the current study was to examine whether or not learners’ predominant intelligences were significant predictors of DDL learning outcomes. The sample for this study included 30 female EFL Yemeni students at Sana’a University. The study used three primary instruments:  a multiple intelligence questionnaire, a posttest and a delayed test on the vocabulary that was taught using DDL. The result of the correlation analyses between the participants’ three identified predominant intelligences and their performances in the posttest and delayed test showed an insignificant relationship between the variables. The regression analyses results also revealed that the predominant intelligences insignificantly predicted the participants’ posttest and delayed test performances.  Based on these findings, learners’ needs and preferences should be activated and addressed by classroom instructions for creating a diverse and motivating learning environment...|$|E
40|$|In {{this paper}} we {{describe}} how the advances in corpus usage in second language learning {{have implications for}} the education of health professionals. The growing understanding that practitioners in the health care disciplines must also be effective communicators means that education for these practitioners is ripe for innovation in educational practice. To illustrate what may be learned in this way, we describe some of our own investigations into the idiomatic use of a particular term which occurred frequently in one of our corpora, concerned with health enquiries directed at an online agony aunt. Those inquiring were frequently concerned with whether the issue they described was ‘normal’ yet idiomatically this was loaded with considerably more meaning than would be disclosed from a mere dictionary definition of the term. Inspection of the contexts in which it occurred suggest that ‘normal’ is a term drawn upon to mark major life transitions and to aid the identification of aspects of physical or mental health where medical intervention is merited. Normalising practices may be enabling, and part of what {{has been described as a}} process of ‘civilizing’ the body. It is through corpora such as ours that practitioners can understand the concepts employed by actual and potential clients, the medical terms used and what they likely mean, in a fruitful convergence of <b>data</b> <b>driven</b> <b>learning</b> and education for health care practitioners...|$|E
40|$|The {{use of the}} Web as a corpus and Google as a concordancer, {{has been}} {{regarded}} as one of the promising areas that has a potential for revolutionizing language pedagogy in general, and second language (L 2) writing, in particular. More specifically, it is believed that the functions of Google-Informed Pattern-Hunting (GIPH) and Google-Informed Pattern-Defining (GIPD) can promote natural L 2 writing through Discovery Learning (DL) and <b>Data</b> <b>Driven</b> <b>Learning</b> (DDL), however, these advantages have mostly been given lip services than tested with first hand empirical studies, and only more recently some studies have been undertaken in this vein. Focusing on L 2, this article explored how and to what extent this great potential of GIPH and GIPD has been recognized by reviewing the related studies, thereby some factors and themes (such as Learning Style, Training, Naturalness, Tidiness, Speed, Number of Retrieval, and Proficiency) have been extracted and elaborated on. However, due to the novelty of the area, the themes are mostly the outcome of researchers’ descriptions and interpretations than empirical studies. The inclusion criteria for the present review were studies that focus on the application of the Web as a corpus and Google as a concordance for language learning and L 2 writing based on researchers’ and learners’ evaluation of it. Seven studies included in the present review show that learners’ use of GIPH and GIPD champions the promotion of their language learning and L 2 writing, providing that proper training and scaffolding are provided. Future studies are also recommended based on the gaps and deficiencies identified in the reviewed researches...|$|E
40|$|We {{describe}} a fully <b>data</b> <b>driven</b> model that <b>learns</b> {{to perform a}} retrosynthetic reaction prediction task, which is treated as a sequence-to-sequence mapping problem. The end-to-end trained model has an encoder-decoder architecture that consists of two recurrent neural networks, which has previously shown great success in solving other sequence-to-sequence prediction tasks such as machine translation. The model is trained on 50, 000 experimental reaction examples from the United States patent literature, which span 10 broad reaction types that are commonly used by medicinal chemists. We find that our model performs comparably with a rule-based expert system baseline model, and also overcomes certain limitations associated with rule-based expert systems and with any machine learning approach that contains a rule-based expert system component. Our model provides {{an important first step}} towards solving the challenging problem of computational retrosynthetic analysis...|$|R
40|$|We study {{nonlinear}} regression of real valued data {{in an individual}} sequence manner, where we provide results that are guaranteed to hold without any statistical assumptions. We address the convergence and undertraining issues of conventional {{nonlinear regression}} methods and introduce an algorithm that elegantly mitigates these issues via an incremental hierarchical structure, (i. e., via an incremental decision tree). Particularly, we present a piecewise linear (or nonlinear) regression algorithm that partitions the regressor space in a <b>data</b> <b>driven</b> manner and <b>learns</b> a linear model at each region. Unlike the conventional approaches, our algorithm gradually increases the number of disjoint partitions on the regressor space in a sequential manner according to the observed data. Through this <b>data</b> <b>driven</b> approach, our algorithm sequentially and asymptotically achieves {{the performance of the}} optimal twice differentiable regression function for any data sequence with an unknown and arbitrary length. The computational complexity of the introduced algorithm is only logarithmic in the data length under certain regularity conditions. We provide the explicit description of the algorithm and demonstrate the significant gains for the well-known benchmark real data sets and chaotic signals...|$|R
40|$|Inserting a {{patterned}} occluder at {{the aperture}} {{of a camera}} lens {{has been shown to}} improve the recovery of depth map and all-focus image compared to a fully open aperture. However, design of the aperture pattern plays a very critical role. Previous approaches for designing aperture codes make simple assumptions on image distributions to obtain metrics for evaluating aperture codes. However, real images may not follow those assumptions and hence the designed code may not be optimal for them. To address this drawback we propose a <b>data</b> <b>driven</b> approach for <b>learning</b> the optimal aperture pattern to recover depth map from a single coded image. We propose a two stage architecture where, in the first stage we simulate coded aperture images from a training dataset of all-focus images and depth maps and in the second stage we recover the depth map using a deep neural network. We demonstrate that our learned aperture code performs better than previously designed codes even on code design metrics proposed by previous approaches. Comment: 5 pages, 4 figures. Accepted at IEEE ICIP 2017, Beijing, Chin...|$|R
40|$|Corpora in the {{translation}} classroom? No, please, we are students! Using online resources and corpora in the classroom. Corpora, {{as we all}} know, can be extremely useful in the classroom. Teachers can use concordances, keyness and frequencies to create exciting activities. Students can develop awareness and self confidence, autonomy and accuracy in L 2. I entirely agree. But most of my students do not. Introducing corpora {{in the classroom is}} not an easy task: most of the experiences described by research articles, books and online publications illustrate either advanced and highly motivated students who collect and sometimes annotate their own corpus, or presentations to the classroom of the results of research previously conducted by the teacher. Teachers do not have many chances to include the basics of corpus linguistics in the syllabus of the average L 2 classroom And if they do the students’ reaction may not be enthusiastic. The result is that most students are unlikely to acquire the indispensable methodological background and technical skills. The aim of the paper - which draws on my personal experience in teaching university translation courses and on studies in corpus linguistics (J. Sinclair, M. Hoey, A. Partington), <b>data</b> <b>driven</b> <b>learning</b> (Johns and King) {{and the use of the}} web both as a corpus (M. Baroni & S. Bernardini, A. Kilgarriff,) and as a resource - is to suggest an approach leading to an inductive discovery of language patterns and usage through activities based on selected online resources which are more familiar to students but can nonetheless gradually develop autonomy and methodological soundness. The presentation will illustrate examples of activities accessible through a Moodle website and used by students with a limited L 2 competence to analyse, unravel and translate unfamiliar words, complex linguistic features, ‘exotic’ expressions and texts aiming at using corpora as a means and not as an end...|$|E
40|$|Abstract {{copyright}} {{data collection}} owner. This data collection consists of two. csv files containing lists of sentences with individual and mean sentence ratings (crowd sourced judgements) on three modes of presentation. This research {{holds out the}} prospect of important impact in two areas. First, it can {{shed light on the}} relationship between the representation and acquisition of linguistic knowledge on one hand, and learning and the encoding of knowledge in other cognitive domains. This work can, in turn, help to clarify the respective roles of biologically conditioned learning biases and <b>data</b> <b>driven</b> <b>learning</b> in human cognition. Second, this work can {{contribute to the development of}} more effective language technology by providing insight, from a computational perspective, into the way in which humans represent the syntactic properties of sentences in their language. To the extent that natural language processing systems take account of this class of representations they will provide more efficient tools for parsing and interpreting text and speech. Project description: In the past twenty-five years work in natural language technology has made impressive progress across a wide range of tasks, which include, among others, information retrieval and extraction, text interpretation and summarization, speech recognition, morphological analysis, syntactic parsing, word sense identification, and machine translation. Much of this progress has been due to the successful application of powerful techniques for probabilistic modeling and statistical analysis to large corpora of linguistic data. These methods have given rise to a set of engineering tools that are rapidly shaping the digital environment in which we access and process most of the information that we use. In recent work (Lappin and Shieber (2007), Clark and Lappin (2011 a), Clark and Lappin (2011 b)) my co-authors and I have argued that the machine learning methods that are driving the expansion of natural language technology are also directly relevant to understanding central features of human language acquisition. When these methods are used to construct carefully specified formal models and implementations of the grammar induction task, they yield striking insights into the limits and possibility of human learning on the basis of the primary linguistic data to which children are exposed. These models indicate that language learning can be achieved without the sorts of strong innate learning biases that have been posited by traditional theories of universal grammar. Weak biases, some derivable from non-linguistic cognitive domains, and domain general learning procedures are sufficient to support efficient <b>data</b> <b>driven</b> <b>learning</b> of plausible systems of grammatical representation. In the current research I am focussing on the problem of how to specify the class of representations that encode human knowledge of the syntax of natural languages. I am pursuing the hypothesis that a representation in this class is best expressed as an enriched statistical language model that assigns probability values to the sentences of a language. A central part of the enrichment of the model consists of a procedure for determining the acceptability (grammaticality) of a sentence as a graded value, relative to the properties of that sentence and the language of which it is a part. This procedure avoids the simple reduction of the grammaticality of a string to its estimated probability of occurrence, while still characterizing grammaticality in probabilistic terms. An enriched model of this kind will provide a straightforward explanation for the fact that individual native speakers generally judge the well formedness of sentences along a continuum, rather than through the imposition of a sharp boundary between acceptable and unacceptable sentences. The pervasiveness of gradedness in the linguistic knowledge of individual speakers poses a serious problem for classical theories of syntax, which partition strings of words into the grammatical sentences of a language and ill formed strings of words...|$|E
40|$|The {{topic of}} this book is {{business}} English in Slovenian tertiary education. If the most important findings are summarised, the following is needed in Slovenian tertiary education with regard to business English teaching: (a) student-centred and learning-centred approach, (b) communicative task-based approach, (c) development of language skills and strategies needed for successful learning, (d) {{a wide variety of}} teaching methods, (e) encouraging creativity (of both students and teachers), (f) use of modern information technology, (g) encouraging learner autonomy, self-assessment and cultural awareness of students, (h) increased level of language awareness among students, (i) changes in assessment (fewer traditional written and oral tests, more project work). The business English language teaching profession has been rather slow to incorporate corpus methods into its working practices. On the contrary, materials and teachers rely on a well-established canon of apparently self-evident 'facts' about the language, which have, more or less, the status of tradition in which knowledge is simply handed down from teacher to student. Corpus-based approach in teaching represents a shift towards a more learner-centred paradigm of discovery learning, which enables students to test their own hypotheses and discover their own rules in the process of the so-called <b>data</b> <b>driven</b> <b>learning.</b> When a substantial body of research demonstrates that old concepts are wrong, it is time to adopt new ways of thinking otherwise business English teaching based on intuition and impressionistic interpretations may lead us towards pseudo teaching. Above all, age-old prescriptive attitudes toward grammar and usage in general English that have been reapplied to business English and which inevitably lead to rote learning and regurgitating should be replaced by corpus-based data-driven hypothesis testing learner-centred approach. In other words, oversimplified views about what business English is should be replaced by a more learner-centred paradigm of discovery learning, which enables students to test their own hypotheses or discover their own rules in the process of the so-called data-driven learning. ...|$|E
40|$|Abstract. This paper investigates an {{approach}} to model the space of brain images through a low-dimensional manifold. A <b>data</b> <b>driven</b> method to <b>learn</b> a manifold from a collections of brain images is proposed. We hypothesize that the space spanned {{by a set of}} brain images can be captured, to some approximation, by a low-dimensional manifold, i. e. a parametrization of the set of images. The approach builds on recent advances in manifold learning that allow to uncover nonlinear trends in data. We combine this manifold learning with distance measures between images that capture shape, in order to learn the underlying structure of a database of brain images. The proposed method is generative. New images can be created from the manifold parametrization and existing images can be projected onto the manifold. By measuring projection distance of a held out set of brain images we evaluate the fit of the proposed manifold model to the data and we can compute statistical properties of the data using this manifold structure. We demonstrate this technology on a database of 436 MR brain images. ...|$|R
40|$|Computational {{linguistics}} is a {{field that}} was founded by linguists, but more recently is the domain of more computer scientists than linguists. Use of <b>data</b> <b>driven</b> and machine <b>learning</b> methods for computational linguistics applications is now more common than handwritten linguistic rules. In order for a linguist to enter the field, {{it is essential that}} he or she be familiar with methods and techniques from computer science. The {{purpose of this paper is}} twofold. The first is to serve as a linguist 2 ̆ 7 s introduction to concepts from outside of linguistics that are used in computational linguistics. The second purpose is to illustrate the use of linguistic features for a specific task known as sentiment analysis. This task involves determining the sentiment of a piece of text. By way of examining linguistics within sentiment analysis, this paper will begin to gesture at the potential role for linguists in the modern field of computational linguistics as a whole. The goal is to encourage and enable linguists to reengage with computational linguistics by providing a suitable introductory work...|$|R
40|$|The {{overall goal}} {{of this study is}} to {{contribute}} to the advancement of hydrologic education as a multi-faceted discipline. The specific objectives are to deliver visual, case-based, <b>data</b> and simulation <b>driven</b> <b>learning</b> experiences to instructors and students through open source web technologies and community based data and modeling sources. The approach is to use three different regional-scale natural hydrologic systems as educational “observatories” and have the learning experiences embedded within. These hydro-systems (Coastal Louisiana, Florida Everglades, and Utah Great Salt Lake Basin) provide a wealth of hydrologic concepts and scenarios that can be used in many curricula. Several student-centered learning modules are currently under development along with an instructional interface to guide and support the learner and the instructor. The developments also include an instructor 2 ̆ 7 s guide containing adaptation and implementation procedures. The web-based modules are intended to be applicable in a wide range of courses, in different programs within institutions, as well as at different levels within the same program. Independent users will test the system to obtain feedback for necessary revisions and enhance the adaptability of the project. Read More: [URL]...|$|R
