48|38|Public
40|$|In 1983, Aldous {{proved that}} {{randomization}} can speedup local search. For example, {{it reduces the}} query complexity of local search over [1 : n] d from Θ(n d− 1) to O(d 1 / 2 n d/ 2). It remains open whether randomization helps <b>fixed-point</b> <b>computation.</b> Inspired by this open problem and recent advances on equilibrium computation, we have been fascinated by the following question: Is a fixed-point or an equilibrium fundamentally harder to find than a local optimum? In this paper, we give a nearly-tight bound of (Ω (n)) d− 1 on the randomized query complexity for computing a fixed point of a discrete Brouwer function over [1 : n] d. Since the randomized query complexity of global optimization over [1 : n] d is Θ(n d), the randomized query model over [1 : n] d strictly separates these three important search problems: Global optimization is harder than <b>fixed-point</b> <b>computation,</b> and <b>fixed-point</b> <b>computation</b> is harder than local search. Our result indeed demonstrates that randomization does not help much in <b>fixed-point</b> <b>computation</b> in the query model; the deterministic complexity of this problem is Θ(n d− 1) ...|$|E
40|$|Abstract—In a {{companion}} paper [6] we presented theoretical analysis of an analog network for <b>fixed-point</b> <b>computation.</b> This paper applies these results to several applications from numerical analysis and combinatorial optimization, in particular: 1) solving systems of linear equations; 2) nonlinear programming; 3) dynamic programing; and 4) network flow computations. Schematic circuits are proposed for representative cases and implementation issues are discussed. Exponential convergence is established for a <b>fixed-point</b> <b>computation</b> that determines the stationary probability vector for a Markov chain. A fixedpoint {{formulation of the}} single source shortest path problem (SPP) that will always converge to the exact shortest path is described. A proposed implementation, on a 2 - &quot; complementary metal–oxide–semiconductor (CMOS) process, for a fully connected eight-node network is described in detail. The accuracy and settling time issues associated with the proposed design approach are presented. I...|$|E
30|$|During {{the past}} few decades, neural {{networks}} (NN) with time delays have found wide applications such as image processing, <b>fixed-point</b> <b>computation,</b> pattern recognition, associative memory, and so on. A lot of interesting results on the dynamical behaviors in different delayed neural networks {{have been published in}} the literature (see [1 – 9] and the references therein).|$|E
40|$|Various {{kinds of}} graph problems, {{including}} shortest path computation, proof-number search, dataflow analysis, etc., {{can be solved}} by <b>fixed-point</b> <b>computations</b> over functions defined on natural numbers or integers. In this paper, we prove that <b>fixed-point</b> <b>computations</b> are possible for the algebra Z ∞ = Z∪{∞,−∞}, which has the operators min, max and plus. Since Z ∞ is not well-ordered, we formulate a kind of acceleration technique to guarantee termination of <b>fixed-point</b> <b>computations.</b> ...|$|R
40|$|AbstractThis {{paper is}} {{concerned}} with memory-efficient solution techniques for Boolean fixed-point equations. We show how certain structures of fixed-point equation systems, often encountered in solving verification problems, can be exploited in order to substantially improve the performance of <b>fixed-point</b> <b>computations.</b> Also, we investigate the space complexity {{of the problem of}} solving Boolean equation systems, showing a NL-hardness result. A prototype of the proposed technique has been implemented and experimental results on a series of protocol verification benchmarks are reported...|$|R
40|$|Abstract. Existing {{predicate}} abstraction tools rely on both theorem provers (to abstract {{the original}} program) and model checkers (to check the abstract program). This paper combines these theorem proving and model checking components in a unified algorithm. The correctness of the original, infinite-state program is {{expressed as a}} single query in constraint logic, which is sufficiently expressive to encode recursion and least <b>fixed-point</b> <b>computations.</b> The satisfiability of this query is decided {{using a combination of}} predicate abstraction, counterexample-based predicate inference, and proof-based explication. Our algorithm avoids the Cartesian approximation while reducing the number of theorem prover queries. ...|$|R
40|$|Abstract. We {{consider}} {{a collection of}} related multiparty computation protocols that provide core operations for secure integer and <b>fixed-point</b> <b>computation.</b> Thehigher-levelprotocolsofferintegertruncationandcomparison,whicharetypicallythemainperformancebottlenecksincomplex applications. We present techniques and building blocks that allow to improve the efficiency of these protocols, {{in order to meet}} the performance requirements of a broader range of applications. The protocols can be constructed using different secure computation methods. We focus on solutions for multiparty computation using secret sharing...|$|E
40|$|Abstract — Mismatched {{front-ends}} {{reduce the}} performance of precoding in multi-antenna OFDM systems, which results in a poor bit error rate. With a relative downlink channel calibration the transmission quality will be enhanced. An excellent calibration technique {{is based on a}} total least squares optimization problem. For the hardware implementation an efficient <b>fixed-point</b> <b>computation</b> will be presented, which provides a brilliant calibration performance. This approach has low complexity and can efficiently be implemented in hardware by using the CORDIC algorithm. I...|$|E
40|$|We {{consider}} {{a collection of}} related multiparty computation protocols that provide core operations for secure integer and <b>fixed-point</b> <b>computation.</b> The higher-level protocols offer integer truncation and comparison, which are typically the main performance bottlenecks in complex applications. We present techniques and building blocks that allow to improve the efficiency of these protocols, {{in order to meet}} the performance requirements of a broader range of applications. The protocols can be constructed using different secure computation methods. We focus on solutions for multiparty computation using secret sharing...|$|E
40|$|This paper extends our Real-Time Maude {{formalization}} of the semantics of flat Ptolemy II discrete-event (DE) {{models to}} hierarchical models, including modal models. This is a challenging task that requires combining synchronous <b>fixed-point</b> <b>computations</b> with hierarchical structure. The synthesis of a Real-Time Maude verification model from a Ptolemy II DE model, and the formal verification of the synthesized model in Real-Time Maude, have been integrated into Ptolemy II, enabling a model-engineering process that combines {{the convenience of}} Ptolemy II DE modeling and simulation with formal verification in Real-Time Maude. Comment: In Proceedings RTRTS 2010, arXiv: 1009. 398...|$|R
40|$|Training of {{large-scale}} deep neural networks is often {{constrained by the}} available computational resources. We study the effect of limited preci-sion data representation and computation on neu-ral network training. Within the context of low-precision <b>fixed-point</b> <b>computations,</b> we observe the rounding scheme to {{play a crucial role}} in de-termining the network’s behavior during train-ing. Our results show that deep networks can be trained using only 16 -bit wide fixed-point num-ber representation when using stochastic round-ing, and incur little to no degradation in the classification accuracy. We also demonstrate an energy-efficient hardware accelerator that imple-ments low-precision fixed-point arithmetic with stochastic rounding. 1...|$|R
40|$|International audienceWe {{present a}} {{scalable}} reachability algorithm for hybrid systems with piecewise affine, non-deterministic dynamics. It combines polyhedra and support function representations of continuous sets to compute an over-approximation of the reachable states. The algorithm improves over previous work by using variable time steps {{to guarantee a}} given local error bound. In addition, we propose an improved approximation model, which drastically improves {{the accuracy of the}} algorithm. The algorithm is implemented as part of SpaceEx, a new verification platform for hybrid systems, available at spaceex. imag. fr. Experimental results of full <b>fixed-point</b> <b>computations</b> with hybrid systems with more than 100 variables illustrate the scalability of the approach...|$|R
40|$|International audienceThis article {{deals with}} the <b>fixed-point</b> <b>computation</b> of the sum-of-products, {{necessary}} {{for the implementation of}} several algorithms, including linear filters. Fixed-point arithmetic implies output errors to be controlled. So, a new method is proposed to perform accurate computation of the filter and minimize the word-lengths of the operations. This is done by removing bits from operands that don't impact the final result under a given limit. Then, the final output of linear filter is guaranteed to be a faithful rounding of the real output...|$|E
40|$|We {{propose a}} new {{approach}} to heap analysis through an abstract domain of automata, called automatic shapes. The abstract domain uses a particular kind of automata, called quantified data automata on skinny trees (QSDAs), that allows to define universally quantified properties of singly-linked lists. To ensure convergence of the abstract <b>fixed-point</b> <b>computation,</b> we introduce a sub-class of QSDAs called elastic QSDAs, which also form an abstract domain. We evaluate our approach on several list manipulating programs and we show that the proposed domain is powerful enough to prove a large class of these programs correct...|$|E
40|$|This paper {{resolves}} {{a common}} complexity {{issue in the}} Bethe approximation of statistical physics and the Belief Propagation (BP) algorithm of artificial intelligence. The Bethe approximation and the BP algorithm are heuristic methods for estimating the partition function and marginal probabilities in graphical models, respectively. The computational complexity of the Bethe approximation is decided {{by the number of}} operations required to solve a set of non-linear equations, the so-called Bethe equation. Although the BP algorithm was inspired and developed independently, Yedidia, Freeman and Weiss (2004) showed that the BP algorithm solves the Bethe equation if it converges (however, it often does not). This naturally motivates the following question to understand limitations and empirical successes of the Bethe and BP methods: is the Bethe equation computationally easy to solve? We present a message-passing algorithm solving the Bethe equation in a polynomial number of operations for general binary graphical models of n variables where the maximum degree in the underlying graph is O(log n). Our algorithm can be used as an alternative to BP fixing its convergence issue and is the first fully polynomial-time approximation scheme for the BP <b>fixed-point</b> <b>computation</b> in such a large class of graphical models, while the approximate <b>fixed-point</b> <b>computation</b> is known to be (PPAD-) hard in general. We believe that our technique is of broader interest to understand the computational complexity of the cavity method in statistical physics...|$|E
40|$|Abstract. Model {{checking}} {{complex systems}} always {{suffers from the}} state explosion problem. Over the last 10 {{years there has been}} lots of researches on how to mitigate the state explosion problem. As a result, many techniques have been emerged such as absiraction, compositional reasoning, and exploiting symmetry. In line with these efforts, this paper proposes stepwise model checking which exploits hierarchical structure in model checking to reduce a set of states to be considered at one time. Thus it makes model checking faster and mitigates the state explosion. This paper shows how to effectively handle an ECTL model checking or an ACTL model checking in such a way with an example. Keywords. Model checking, Flattening, Temporal logic, <b>Fixed-point</b> <b>computations</b> 1...|$|R
40|$|In this paper, we symbolically compute a {{minimally}} restrictive nonblocking {{supervisor for}} timed discrete event systems, in the supervisory control theory context. The method {{is based on}} Timed Extended Finite Automata, which is an augmentation of extended finite automata (EFAs) by incorporating discrete time into the model. EFAs are ordinary automaton extended with discrete variables, guard expressions and action functions. To tackle large problems all computations are based on binary decision diagrams (BDDs). The main feature {{of this approach is}} that the BDD-based <b>fixed-point</b> <b>computations</b> is not based on “tick” models that have been commonly used in this area, leading to better performance in many cases. As a case study, we effectively computed the minimally restrictive nonblocking supervisor for a well-known production cell...|$|R
40|$|International audienceThis article {{introduces}} RangeLab, {{a simple}} tool {{to validate the}} accuracy of floating-point or <b>fixed-point</b> <b>computations.</b> Given intervals for the inputs, RangeLab computes {{the range of the}} outputs of simple functions with conditionals and loops as well as a range for the roundoff errors arising during the computation. Hence the user not only obtains the range of the result of the computation in the computer arithmetic but also a bound on the difference between the computer result and the result in infinite precision. RangeLab is based on static analysis by abstract interpretation and, in this article, we describe the techniques implemented in the tool. In particular, RangeLab uses a hybrid numerical-formal evaluation technique used to limit the wrapping effect in interval computations...|$|R
40|$|We {{introduce}} Partitioned Dependency Graphs (PDGs), {{an abstract}} {{framework for the}} specification and evaluation of arbitrarily nested alternating fixed points. The generality of PDGs subsumes that of similarly proposed models of nested <b>fixed-point</b> <b>computation</b> such as Boolean graphs, Boolean equation systems, and the propositional modal mu-calculus. Our main result is an efficient local algorithm for evaluating PDG fixed points. Our algorithm, which we call LAFP, combines the simplicity of previously proposed induction-based algorithms (such as Winskel's tableau method for µ-calculus model checking) with the efficiency of semantics-based algorithms (such as the bit-vector method of Cleaveland, Klein, and Steffen for the equational µ-calculus). In particular, LAFP is sim [...] ...|$|E
40|$|Abstract. We {{propose a}} new {{approach}} to heap analysis through an ab-stract domain of automata, called automatic shapes. Automatic shapes are modeled after a particular version of quantified data automata on skinny trees (QSDAs), that allows to define universally quantified prop-erties of programs manipulating acyclic heaps with a single pointer field, including data-structures such singly-linked lists. To ensure convergence of the abstract <b>fixed-point</b> <b>computation,</b> we introduce a subclass of QSDAs called elastic QSDAs, which forms an abstract domain. We eval-uate our approach on several list manipulating programs and we show that the proposed domain is powerful enough to prove a large class of these programs correct. ...|$|E
40|$|Portable {{devices such}} as PDA phones and smart phones are {{increasingly}} popular. Many of these devices already have voice dialing capability. The {{next step is to}} offer more powerful personal-assistant features such as speech translation. In this paper, we propose a system that can translate speech commands in Chinese into English, in realtime, on small, portable devices with limited memory and computational power. We address the various computational and platform issues of speech recognition and translation on portable devices. We propose <b>fixed-point</b> <b>computation,</b> discrete front-end speech features, bi-phone acoustic models, grammar-based speech decoding, and unambiguous inversion transduction grammars for transfer-based translation. As a result, our speech translation system requires only 500 k memory and a 200 MHz CPU. 1...|$|E
40|$|Abstract—This article {{introduces}} RangeLab, {{a simple}} tool {{to validate the}} accuracy of floating-point or <b>fixed-point</b> <b>computations.</b> Given intervals for the inputs, RangeLab computes {{the range of the}} outputs of simple functions with conditionals and loops as well as a range for the roundoff errors arising during the computation. Hence the user not only obtains the range of the result of the computation in the computer arithmetic but also a bound on the difference between the computer result and the result in infinite precision. RangeLab is based on static analysis by abstract interpretation and, in this article, we describe the techniques implemented in the tool. In particular, RangeLab uses a hybrid numerical-formal evaluation technique used to limit the wrapping effect in interval <b>computations.</b> Keywords-Formal verification, <b>fixed-point</b> arithmetic, floating-point arithmetic, numerical stability. I...|$|R
40|$|Approximating automata are finite-state {{representations}} of the sequential inputoutput behaviors of hybrid systems characterized by threshold events that trigger discrete changes in the continuous dynamic equations. Procedures proposed for constructing approximating automata require forward and backward mappings of sets of continuous state trajectories [...] mappings which are not available for arbitrary continuous dynamics. This paper develops the foundations for constructing approximating automata automatically for hybrid systems in which the continuous dynamics are defined by convex polytopes in the vector space of the derivatives of the continuous state trajectories. The computations are illustrated for a simple example which also demonstrates the use of approximating automata to solve verification problems that may be intractable using <b>fixed-point</b> <b>computations</b> for linear hybrid automata. 1 Introduction This paper concerns the generation of purely discrete models (finite automata) for [...] ...|$|R
40|$|The model {{checking}} of higher-order recursion schemes {{has been}} actively studied {{and is now}} becoming a basis of higher-order program verification. We propose a new algorithm for trivial automata model checking of higher-order recursion schemes. To our knowledge, {{this is the first}} practical model checking algorithm for recursion schemes that runs in time linear {{in the size of the}} higher-order recursion scheme, under the assumption that the size of trivial automata and the largest order and arity of functions are fixed. The previous linear time algorithm was impractical due to a huge constant factor, and the only practical previous algorithm suffers from the hyper-exponential worst-case time complexity, under the same assumption. The new algorithm is remarkably simple, consisting of just two <b>fixed-point</b> <b>computations.</b> We have implemented the algorithm and confirmed that it outperforms Kobayashi’s previous algorithm in a certain case...|$|R
40|$|We present {{global and}} local {{algorithms}} for evaluating minimal fixed points of dependency graphs, a general problem in <b>fixed-point</b> <b>computation</b> and model checking. Our algorithms run in linear-time, matching {{the complexity of}} the best existing algorithms for similar problems, and are simple to understand. The main novelty of our global algorithm {{is that it does not}} use the counter and "reverse list" data structures commonly found in existing linear-time global algorithms. This distinction plays an essential role in allowing us to easily derive our local algorithm from our global one. Our local algorithm is distinguished from existing linear-time local algorithms by a combination of its simplicity and suitability for direct implementation. We also provide linear-time reductions from the problems of computing minimal an [...] ...|$|E
40|$|Abstract. Monads {{have been}} {{employed}} in programming languages for modeling various language features, most importantly those that involve side effects. In particular, Haskell’s IO monad {{provides access to}} I/O operations and mutable variables, without compromising referential transparency. Cyclic definitions that involve monadic computations give rise {{to the concept of}} value-recursion, where the <b>fixed-point</b> <b>computation</b> takes place only over the values, without repeating or losing effects. In this paper, we describe a semantics for a lazy language based on Haskell, supporting monadic I/O, mutable variables, usual recursive definitions, and value recursion. Our semantics is composed of two layers: A natural semantics for the functional layer, and a labeled transition semantics for the IO layer. Mathematics Subject Classification. 68 N 18, 68 Q 55, 18 C 15...|$|E
40|$|The goal {{of logic}} {{programming}} {{is that the}} program, or database, can be understood by logic along, independently of any execution model. Attempts to realize this goal {{have made it clear}} that the logic involved must go beyond ordinary first-order logic. This survey will explore several topics of current interest in the logical meaning of logic programs, with particular attention paid to: (1) the meaning of negation; this still remains problematical, although many partial results are known. (2) The meaning of recursions; these imply a least <b>fixed-point</b> <b>computation</b> in deductive databases, and something else in Prolog. (3) The meaning of the Prolog built-in predicates, such as the evaluation of numeric terms. (4) The semantic meaning of the order in which a stream of answers is returned...|$|E
40|$|A general {{method that}} {{represents}} the state space symbolically instead of explicitly is described. The generality of the method comes from using a dialect of the mu-calculus as the primary specification language. A model-checking algorithm for mu-calculus formulas which uses R. E. Bryant 2 ̆ 7 s (1986) binary decision diagrams to represent relations and formulas symbolically is described. It is then shown how the novel mu-calculus model checking algorithm {{can be used to}} derive efficient decision procedures for CTL model checking, satisfiability of linear-time temporal logic formulas, strong and weak observational equivalence of finite transition systems, and language containment of finite ω-automata. This eliminates the need to describe complicated graph-traversal or nested <b>fixed-point</b> <b>computations</b> for each decision procedure. The authors illustrate the practicality of their approach to symbolic model checking by discussing how {{it can be used to}} verify a simple synchronous pipelin...|$|R
40|$|We {{propose a}} design {{methodology}} for explicit Model Predictive Control (MPC) that guarantees hard constraint {{satisfaction in the}} presence of finite precision arithmetic errors. The implementation of complex digital control techniques, like MPC, is becoming increasingly adopted in embedded systems, where reduced precision computation techniques are embraced to achieve fast execution and low power consumption. However, in a low precision implementation, constraint satisfaction is not guaranteed if infinite precision is assumed during the algorithm design. To enforce constraint satisfaction under numerical errors, we use forward error analysis to compute an error bound on the output of the embedded controller. We treat this error as a state disturbance and use this to inform the design of a constraint-tightening robust controller. Benchmarks with a classical control problem, namely an inverted pendulum, show how it is possible to guarantee, by design, constraint satisfaction for embedded systems featuring low precision, <b>fixed-point</b> <b>computations...</b>|$|R
40|$|International audienceIn {{embedded}} systems, efficient implementations of numerical algorithms typically use the fixed-point arithmetic {{rather than}} the standardized and costly floating-point arithmetic. But, fixed-point programmers face two difficulties: First, writing fixed-point codes is tedious and error prone. Second, the low dynamic range of fixed-point numbers leads to the persistent belief that <b>fixed-point</b> <b>computations</b> are inherently inaccurate. In this article, we address these two limitations by introducing a methodology to design and implement tools that synthesize fixed-point programs. To strengthen the user's confidence in the synthesized code, analytic methods are presented to automatically assert its numerical quality. Furthermore, we use this framework to generate fixed-point code for linear algebra basic blocks such as matrix multiplication and inversion. For example, the former task involves trade-offs such as choosing to maximize the code's accuracy or minimize its size. For the two cases of matrix multiplication and inversion, we describe, implement, and experiment with several algorithms to find trade-offs between the conflicting goals...|$|R
40|$|Abstract. We {{consider}} imperfect-information parity {{games in}} which strategies rely on observations that provide imperfect information {{about the history of}} a play. To solve such games, i. e., to determine the winning regions of players and corresponding winning strategies, one can use the subset construction to build an equivalent perfect-information game. Recently, an algorithm that avoids the inefficient subset construction has been proposed. The algorithm performs a <b>fixed-point</b> <b>computation</b> in a lattice of antichains, thus maintaining a succinct representation of state sets. However, this representation does not allow to recover winning strategies. In this paper, we build on the antichain approach to develop an algorithm for constructing the winning strategies in parity games of imperfect information. We have implemented this algorithm as a prototype. To our knowledge, this is the first implementation of a procedure for solving imperfect-information parity games on graphs. ...|$|E
40|$|Abstract. We {{present a}} {{symbolic}} extension of dependency graphs by Liu and Smolka {{in order to}} model-check weighted Kripke structures against the logic CTL with upper-bound weight constraints. Our extension introduces {{a new type of}} edges into dependency graphs and lifts the computation of fixed-points from boolean domain to nonnegative integers in order to cope with the weights. We present both global and local algorithms for the <b>fixed-point</b> <b>computation</b> on symbolic dependency graphs and argue for the advantages of our approach compared to the direct encoding of the model checking problem into dependency graphs. We implement all algorithms in a publicly available tool prototype and evaluate them on several experiments. The principal conclusion is that our local algorithm is the most efficient one with an order of magnitude improvement for model checking problems with a high number of “witnesses”. ...|$|E
40|$|We {{consider}} imperfect-information parity {{games in}} which strategies rely on observations that provide imperfect information {{about the history of}} a play. To solve such games, i. e., to determine the winning regions of players and corresponding winning strategies, one can use the subset construction to build an equivalent perfect-information game. Recently, an algorithm that avoids the inefficient subset construction has been proposed. The algorithm performs a <b>fixed-point</b> <b>computation</b> in a lattice of antichains, thus maintaining a succinct representation of state sets. However, this representation does not allow to recover winning strategies. In this paper, we build on the antichain approach to develop an algorithm for constructing the winning strategies in parity games of imperfect information. We have implemented this algorithm as a prototype. To our knowledge, this is the first implementation of a procedure for solving imperfect-information parity games on graphs...|$|E
40|$|AbstractThis paper {{presents}} {{a combination of}} Reference Attributed Grammars (RAGs) and Circular Attribute Grammars (CAGs). While RAGs allow the direct and easy specification of non-locally dependent information, CAGs allow iterative <b>fixed-point</b> <b>computations</b> to be expressed directly using recursive (circular) equations. We demonstrate how the combined formalism, Circular Reference Attributed Grammars (CRAGs), {{can take advantage of}} both these strengths, making it possible to express solutions to many problems in an easy way. We exemplify with the specification and computation of the nullable, first, and follow sets used in parser construction, a problem which is highly recursive and normally programmed by hand using an iterative algorithm. We also present a general demand-driven evaluation algorithm for CRAGs and some optimizations of it. The approach has been implemented and experimental results include computations on a series of grammars including that of Java 1. 2. We also revisit some of the classical examples of CAGs and show how their solutions are facilitated by CRAGs...|$|R
40|$|Contemporary field-programmable gate arrays (FPGAs) are {{predestined for}} the {{application}} of finite impulse response (FIR) filters. Their embedded digital signal processing (DSP) blocks for multiply-accumulate operations enable efficient <b>fixed-point</b> <b>computations,</b> in cases where the filter structure is accurately mapped to the dedicated hardware architecture. This brief presents a generic systolic structure for high-order FIR filters, efficiently exploiting the hardware resources of an FPGA in terms of routability and timing. Although this seems to be an easily implementable task, the synthesizing tools require an adaptation of the straightforward digital filter implementation for an optimal mapping. Using the example of a symmetric FIR filter with 90 taps, we demonstrate the performance of the proposed structure with FPGAs from Xilinx and Altera. The implementation utilizes less than 1 % of slice logic and runs at clock frequencies up to 526 MHz. Moreover, an enhancement of the structure ultimately provides an extended dynamic range for the quantized coefficients without the costs of additional slice logic...|$|R
40|$|ISSN 1476 - 2986 We {{implement}} a model checker for the modal mu-calculus as a derived rule in a fully expansive mechanical theorem prover, without causing an unacceptable performance penalty. We use a restricted {{form of a}} higher order logic representation calculus for binary decision diagrams (BDDs) to interface the model checker to a high-performance BDD engine. This is used with a formalised theory of the modal mu-calculus (which we also develop) for model checking in which all steps of the algorithm are justified by fully expansive proof. This provides a fine-grained integration of model checking and theorem proving using a mathematically rigourous interface. The generality of our theories allows us to perform much of the proof offline, in contrast with earlier work. This substantially reduces the inevitable performance penalty of doing model checking by proof. To demonstrate the feasibility of our approach, optimisations to the model checking algorithm are added. We add naive caching and also perform advanced caching for nested non-alternating <b>fixed-point</b> <b>computations...</b>|$|R
