3|30|Public
40|$|Abstract: One especial {{characteristic}} of the PMBOK fourth edition is that the data flow between processes is defined with the definition of individual processes. Based on relations of input and the output during an adjacent management process, we can visualize the network structure of 42 project management processes analytically. The author showed that we could estimate {{the density of the}} process flow from the network structure based on the relations during the process of the first proximity. However, this network structure based on relations of first proximity is not including the indirect relationship among management processes. Therefore, it is necessary to extract a cross-sectional <b>data</b> <b>flowchart</b> on knowledge areas by expanding analysis range of the management pass in consideration of a highly advanced proximity element (process). Based on this cross-sectional <b>data</b> <b>flowchart,</b> it is able to visualize a complicated management processing flow. As a result, it is found that there were complementary relations between the flow by way and by no way of the project integration management knowledge area. This suggests that network analysis technique is effective as method to visualize the flow of the management process of project. In this paper, I would like to report the example of visualization of the management processing flow of some project management knowledge areas...|$|E
40|$|AbstractThe syntax of a {{systolic}} system {{is given by}} {{a systolic}} flowchart scheme. Systolic schemes differ from ordinary ones in their edges having a nonnegative integer, called the delay number associated with them. If {{the value of the}} delay number is d, then the edge {{is considered to be a}} buffer holding d data elements in each moment of the computation. The buffers are handled in a FIFO way, transmitting data between the corresponding i/o ports of two interconnected processors. The algebraic language which is used to express schemes is different from the most frequently used one, containing composition, pairing and iteration as basic operations. The present language contains sum and a new operation called the “feedback” beyond composition, and only five constants. The axiomatization is carried out in two steps. First we present a set of equational axioms for the class of loop-free schemes, which are called <b>data</b> <b>flowchart</b> schemes. This set of axioms is extended by further axioms describing the syntactic features of the feedback operation...|$|E
40|$|This study {{aimed to}} explore the {{services}} proposed by IBM, Service Sciences, Management and Engineering (SSME), and this concept is created since {{that a lot of}} companies continued to introduce new technology, but ignored is it really necessary for the consumers, and often overlook the real needs of customers, thus creating market demand and supply generated asymmetry. And often lead to new product failure. The failure of new products often leads to an enterprise in terms of reputation, and great pecuniary loss. So, having a good product development process on an enterprise is very important. Service Science from the service science, management, and engineering is discussing about three aspects of product development and customer relations, to enhance customer interaction with product development, improve product demand asymmetry phenomenon. In this study, we take Company A as an example to explore the product development process and the concept of service science, to observe the product development process through service science aspect. Company A is currently the largest fitness equipment manufacturer in Asia, the world''s second-largest fitness equipment manufacturer, year of production of 500 000 fitness equipment, marketing products to countries around the world. 摘要	i Abstract	ii Chapter 1 Introduction	 3 1. 1 Research Background and Research Motivation	 3 1. 3 Research Process	 4 1. 4 Organization of Research	 6 Chapter 2 Literature Review	 7 2. 1 Service	 7 2. 1. 1 Definition of Service	 7 2. 1. 2 Distinctive Characteristics of Services	 8 2. 2 Definition of Service Science, Management, and Engineering (SSME) 	 11 2. 3 AHP (Analytic Hierarchy Process) 	 12 2. 3. 1 Basic Concepts of Analytic Hierarchy Process	 14 2. 4 Service Blueprint	 17 2. 4. 1 Concepts of Service Blue Print Method	 18 2. 5 The Benefits of Fitness	 21 Chapter 3 Research Methodology	 23 3. 1 Research Design	 23 3. 2 Qualitative Research	 23 3. 3 Research Object	 24 3. 4 Research Methodology	 24 3. 5 Research Framework	 26 Chapter 4 Case Study	 27 4. 1 Case Background	 27 4. 2 Research Sample	 29 4. 3 Customer Requirements Analysis	 31 4. 4 AHP Questionnaire Design and Result Analysis	 36 4. 5 Design of Treadmill	 43 4. 6 Service Blueprint Flowchart	 45 4. 7 <b>Data</b> <b>Flowchart</b>	 50 Chapter 5 Conclusions	 53 5. 1 Conclusion	 53 5. 2 Research Limitation and Future Study	 55 References	 5...|$|E
5000|$|<b>Data</b> <b>flowcharts,</b> showing {{controls}} over a data-flow in {{a system}} ...|$|R
5000|$|... #Caption: <b>Data</b> science process <b>flowchart</b> from [...] "Doing Data Science", Cathy O'Neil and Rachel Schutt, 2013 ...|$|R
40|$|Purpose- The {{purpose of}} this study is to examine the current {{environment}} management accounting practices and concept of cleaner production relating to one of the major media firms, a news paper printing company, in Sri Lanka. Design / Methodology/Approach- The case study method was followed in the study. The primary data were collected mainly by face to face unstructured interviews and telephone interviews with the General Manager and the Operations Manager of the site. In order to get further clarifications, email communications were also made. In addition, the researchers visited the factory and collected data through observations. Secondary data were gathered by browsing web site sources, internal company records, presentations done by the General Manager, etc. Multiple data gathered were analyzed by creating <b>data</b> <b>flowcharts</b> and tabulating the frequency of different events (Quantity wise and monetary wise). Findings- The study illustrates that the news paper printing company has successfully implemented many environmental management accounting an...|$|R
40|$|The {{overview}} {{reported here}} {{is meant to}} represent an inventory of 'simple' methods to estimate missing data on Persistence (P), Toxicity (T) and Bioaccumulative potential (B) of substances. Estimation models offer the quickest and cheapest ways of doing this, and are relatively more reliable than expert judgement or default values. Prior to estimating the PTB properties, a distribution profile, i. e. {{the distribution of the}} substance over the three major environmental compartments of air, soil and water, had to be determined. The information required for substances in estimating the PTB properties varies from a SMILES notation to detailed quantum-mechanical <b>data.</b> <b>Flowcharts</b> are provided in the overview to guide the reader through the required steps for determining the PTB properties. The PTB properties and PTB criteria can be used for simplified hazard identification for human health and the environment. A substance-specific PTB profile can thus be derived to include the PTB properties. Comparing PTB properties to 'cut-off' values for substances in relation to a particular policy aim can result in categorization of substances into a PTB class. The establishment of 'cut-off' values is a policy choice still under discussion, as is the use of PTB criteria for policy purposes, both are therefore outside the scope of the report...|$|R
5000|$|In [...]NET 4, Windows Workflow Foundation {{was greatly}} updated, with new {{features}} such as <b>Data</b> Contract Resolver, <b>Flowchart,</b> and other flow control activities added. Workflow in [...]NET 4 uses the SystemActivities namespace. Most notably, {{there is no longer}} a Workflow Runtime object in version 4; workflows are executed directly using WorkflowApplication or WorkflowInvoker instead.|$|R
5000|$|Business Administration Management (BAM) is {{designed}} for students interested in related data processing professions. Students receive instruction in keyboarding, <b>data</b> entry, accounting, <b>flowchart</b> logic and internet applications. Microsoft Word, Excel, Access, PowerPoint and automated accounting applications are integrated into the curriculum. This Tech Prep program {{provides an opportunity for}} 13 hours of college credit. Grades: 10, 11, 12 ...|$|R
40|$|Methodological, technical, and {{practical}} organizational problems are considered of constructing {{a long term}} data bank. <b>Data</b> processing <b>flowcharts</b> are presented {{which are based on}} an analysis of the tasks which the data bank must fulfill, an estimate of the existing and predicted data flows in the processing center, and the selection of the data storage media and the forms in which the data are presented. Questions related to the use of standard and special hardware and software in the data bank are discussed. Reasons are presented for the adopted structure of the document-fact type information retrieval system which permits the mechanization and automation of various stages in the retrieval and selection of the data...|$|R
30|$|The MetaDP {{platform}} is a one-stop 16 S rRNA sequencing <b>data</b> analysis <b>flowchart</b> with a friendly user interface {{that aims to}} help researchers investigate the structure and diversity of human microbial flora and provide deep insight into microorganisms associated with the disease. An automatic analysis workflow can be performed once users upload their raw sequencing data with barcodes. In this version, our platform provides a set of universal 16 S rRNA data analysis tools to constitute a workflow for data from the 454 and Illumina platforms. The workflow outputs the bacterial distribution, alpha diversity, beta diversity, and disease risk assessment with a plug-in prediction model. To build the prediction model, we used IBS as an example {{with a total of}} 108 microbial samples. In the near future, we will increase the sample size of intestinal microbial diseases and improve the prediction model.|$|R
40|$|Along {{with the}} times when {{technology}} is growing rapidly, as well as increased competition among business firms then {{the need for the}} application of knowledge management concepts that are implemented into a web chat application that is expected to assist the company in terms of communication delivery. Method of this thesis is FAST (Framework for the Application of Systems Thinking), which consists of several phases of system developers. The first phase of the scope of the definition of directly observing the company 2 ̆ 7 s operational processes, {{the second phase of the}} analysis of problems occurring within the company, the third phase of requirements analysis using the framework Pieces, the four phases of decision analysis provides an assessment and recommendations contained in the system. These five logical design phase to design the system in the form of <b>data</b> flow diagrams, <b>flowcharts,</b> <b>data</b> tables, and ERD, the sixth phase of the construction and testing program has been completed, the seventh phase of the implementation of the system by running and training. This application is designed using PHP as a software application program, and MySQL as the database. The results of this analysis are expected to help the communication process that occurs and is able to shorten the time in terms of work related to communication processes that exist within the company...|$|R
40|$|Natural {{language}} {{access to}} databases {{is a research}} area shrouded by many unresolved issues. This paper presents a methodology of comprehending Swahili NL statements with an aim of forming corresponding SQL statements. It presents a Swahili grammar based information extraction approach which is thought of being generic enough to cover many Bantu languages. The proposed methodology uses overlapping layers which integrate lexical semantics and syntactic knowledge. The framework under which the proposed model works is also presented. Evaluation was done through simulation using field <b>data</b> on corresponding <b>flowcharts.</b> The results show a methodology that is promising. 1...|$|R
40|$|Abstract, Information {{literacy}} {{is an important}} skills for 21 st century learners. One of methods to evaluate the implementation of information literacy program in school library is assessment of information literacy competence. The objectives of this research were to establish a standard of information literacy for Indonesian students and to design a webbased information literacy assessment system. This research employed Delphi technique with two rounds questionnaire distributed among panelists of 9 experts. The experts consists of three school librarians, two teachers and four information literacy researchers. Six standards and 40 performance indicators were identified as information literacy standard. The design of system resulted models which presented in System <b>Flowchart,</b> <b>Data</b> Flow Diagram and Entity-Relationship Diagram. Keywords: competency standard, information literacy assessment, web-based syste...|$|R
40|$|The {{purpose of}} this final project {{is to build a}} {{database}} system associated with the computer-based system to help provide alternative solutions to problems and issues calculation calculation of the amount of goods inventory so that the process is carried out can take place more quickly and can achieve the desired results and can minimize error happened. Research methodology is the data collection includes literature studies, interviews, direct observation, data processing method includes secondary data and primary data, data analysis and preparation of systems methodology. The system design is based on the computer through the stages of the <b>Data</b> Flow Diagram, <b>Flowchart</b> Systems, Technical Normalization, Database Design, to produce a database that integrated. The model database includs data collection process goods cv agung pratama...|$|R
40|$|ABSTRACT. This article {{surveys the}} methods and tools of quality {{improvement}} used today in health care. Specifically, we describe how clinicians can use these methods to impact the clinical practice of medicine. Improvement teams {{from a variety of}} health care organizations have reported the successful use of basic methods such as group work, <b>flowcharting,</b> <b>data</b> collection, and graphical data analysis. In addition to these incremental, problem-solving methods borrowed from the industrial practice of improvement, we have also seen the use of specific process design methods in health care applications such as care path development. The pace of change in health care has also led to the practical development of newer methods for rapid cycle improvement. We will review the basic approach behind these methods and illustrate key elements such as the idea...|$|R
40|$|The goal {{of making}} Selling and Inventory Application Program on Toko SURYA JAYA is to minimalize errors on {{counting}} stocks and prices, also to record {{all of the}} transactions done. The benefit of making this Application Program is to help and to optimize the operation flow of the business. The computerization {{and the creation of}} the application program are done through several steps which are planning, analyzing, designing, and implementing. Several designing tools were used on this application program: <b>Flowchart,</b> <b>Data</b> Flow Diagram, Entity Relationship Diagram, and table intergration. MySQL is used as the database, Xampp as the connector between database and the display, Visual Basic as the programming language and display setting application. Blackbox testing dan user acceptance testing methods were used for the testing of this application...|$|R
40|$|Inventory {{is one of}} the {{important}} assets in the company and become one of the company's working capital. To obtain inventory information quickly, precisely and accurately inventory required an effective information system. In writing this essay, the author took the title "Accounting Information Systems In Computerized Merchandise preparations on pharmacy gift Farma". In this paper, the authors tried to better implement computerized accounting information systems in the gift Farma Pharmacy. The methods used for data analysis such as <b>flowcharts,</b> <b>data</b> flow diagrams, entity relationship diagrams, and normalization. The results showed that the Accounting Information Systems at the warehouse, in the presentation of the data has not been computerized. So, there is a mismatch between the data on the computer with the data available in the warehouse. The author suggests that pharmacy gift Farma in supporting the effectiveness, increasing the necessary aspects, such as human resources aspects and control aspects...|$|R
40|$|One of {{the most}} {{important}} concerns of the current institutions of higher education is the management process to ensure quality. The most important problems facing these institutions is the quality assurance evaluation process. One {{of the best ways to}} overcome this problem building a system based on a computer to manage that process. We will define this system as "a Quality Assurance Management system For Higher Education (QAMS) ". During this paper we will explain our vision and analysis to build such a system. During the system construction we must identify the main modules for the system and the relationships between them. Our QAMS will be constructed to enable the quality evaluator to evaluate the institution quality and generate the final quality report automatically without additional efforts. The main purpose from this paper is to explain our QAMS components. This view will be illustrated by using the UML language diagrams as use-case diagram, <b>data</b> flow diagram, <b>flowchart,</b> and activity diagram...|$|R
40|$|AbstractAccording to two present China {{national}} standards, {{a software}} as Soil Liquid Limit and Plastic Limit Data Treating System, with analytic method, was developed using object-oriented visual programming tool. The analytic method {{used in the}} developed system was different to traditional method of treating soil liquid limit and plastic limit <b>data.</b> N-S algorithm <b>flowchart</b> demonstrated that switch statement and condition statement were taken as main algorithm and second level select nested structure was taken as main frame for the developed system. Three kinds of soil specimens were tested with liquid and plastic limit combined test and the test data was treated with graphic method, Excel software and Soil Liquid Limit and Plastic Limit Data Treating System. The comparative conclusion indicated that Soil Liquid Limit and Plastic Limit Data Treating System improved efficiency and accuracy evidently for treating soil liquid and plastic limit data and had advantages of easy operation and high reliability...|$|R
40|$|The paper {{describes}} a computer program, DSNLOAD, which provides the Deep Space Network (DSN) loading information given a proposed future NASA mission set. The DSNLOAD model includes required pre- and post-calibration periods, and station 'overhead' such as maintenance or 'down' time. The analysis is presented which transforms station view period {{data for the}} mission set into loading matrices used to assess loading requirement. Assessment of future loading on the DSN {{for a set of}} NASA missions by estimating the tracking situation and presenting the DSN loading <b>data,</b> and a <b>flowchart</b> for selecting a possible future mission, determining a heliocentric orbit for the mission, generating view period schedules, and converting these schedules into basic loading data for each mission for each station are given. The tracking schedule model which considers the tracking schedule to be represented by passes of maximum required length and centered within the view period of available tracking time for each mission is described, and, finally, an example of typical loading study is provided...|$|R
30|$|Formality and {{understandability}} of ontology-based representation {{for medical}} services have been researched in (Huser et al. 2010; Mabotuwana & Warren 2009). The authors of (Mabotuwana & Warren 2009) propose a framework to indentify hypertensive patients who satisfy evidence-based criteria for quality improvement potential. They propose three issues for domain-modelling: (i) shareability, (ii) extensibility, and (iii) easy visualization {{of knowledge base}} for domain-modelling. On the other hand, the authors of (Huser et al. 2010) establish a query system of electoric health record <b>data</b> based on <b>flowchart</b> that indicates processes to treat patients. The authors propose an trade-off problem of readability and expressiveness of query representation. The authors of (Huser et al. 2010; Mabotuwana & Warren 2009) focus on how to represent queries correctly and/or easily {{on the basis of}} considerably restricting the domain of the querie, and their approaches are not easy to extend for evaluation of general medical service quality. This paper enhances formality and understandability of QI-RS by MSO that provides sufficient vocabulary words to define quality indicators and by establishing a general framework of ontology-based graph representation.|$|R
40|$|Due to the {{significant}} role of Small and Medium-sized Enterprises (SMEs) in {{economic and social}} improvement of a country, further the shortage of a fairly extensive model which holds required factors for their decision makers {{in order to be}} successful in foreign market presence, “A Model for Successful Presence of Iranian SMEs in International Markets” has been chosen as the topic for this research. Furthermore because of competition ability of Iranian food industry in international markets, this industry selected for the statistical community. Actually, within this study ESPM as the original model has been considered to be tested for Iranian SMEs which are or going to be active in the foreign markets. Totally 246 valid questionnaire were gathered and by means of “Factor Analysis” method both data and model were evaluated trough EFA and CFA. In other words, “Exploratory Factor Analysis” postpones the usual assumptions about what kind of model the data follow with the more direct approach of allowing the data itself to reveal its underlying structure and model. In addition, “Confirmatory Factor Analysis” hypothesizes the structure of the model which has been built during the exploratory phase. Finally the model fits will be testified, but the effects among the constructs will be considered for marking the difference between confirmatory factor analysis and Structural Equation Modeling (SEM). Furthermore, AMOS 16 and Statistica 7. 0 were used as the softwares during this research for data analysis. According to the presumed hypotheses in this research, out of 22, the number of 17 hypotheses has been accepted and six of the total number rejected. In this research also a <b>data</b> analysis <b>flowchart</b> has been designed thorough a teamwork activity as a contribution. Finally the research limitations and some recommendations for further researches have been offered. Validerat; 20101217 (root...|$|R
40|$|Cхарактеризовано розроблену концептуальну узагальнену технологічну модульну схему оброблення, дешифрування і геологічної інтерпретації матеріалів аерокосмічних знімань у комплексі з даними геолого-геофізичних досліджень на підставі використання геоінформаційних технологій. Охарактеризована разработанная концептуальная обобщенная технологическая модульная схема обработки, дешифрирования и геологической интерпретации материалов аэрокосмических съемок в комплексе с данными геолого-геофизических исследований на основе использования геоинформационных технологий. The {{designed}} conceptual generic modular flowchart of transformation, decoding and geologic {{interpretation of}} remote sensing {{data in the}} complex with geological and geophysical data is characterised. The flowchart is based on geoinformation technologies application. As far as the novelty of elaboration this flowchart has the generalisable character relative to the previous analogues that allows conducting aero-space-geological studies in the multidimensional aspects instead of the restricted thematic one only. Furthermore the article shows the more complete version for the proper logical block scheme of remote and geological-geophysical data processing. In general, the flowchart consists of four main stages: 1) setting up a problem; 2) composing knowledge and data bases; 3) processing and analyses of data using the geographic information systems (GIS); 4) complex analysis and geological interpretation for the information integrated into the GIS. The flowchart is modular. Consequently its different parts (constituent elements) may be applied depending on the research level (global, regional, zonal or local scales) for the prospecting geological objects (i. e. disjunctive, petroleum promising and other ones), their complexity and completeness {{as well as the}} availability of remote sensing and geological-geophysical <b>data.</b> The <b>flowchart</b> is practically realized to study the features of the rupture dislocation of the Earth crust in the conditions of the different landscape-geological structure of Ukraine in frame of the scientific and applied problems of the use of subsurface resources and geoecology. The single modules of the flowchart are used {{to solve the problem of}} predicting the potential hydrocarbon traps...|$|R
40|$|Karya Asih Charitas Hospital {{is one in}} Palembang Hospital. Based on observations, data {{processing}} and information retrieval outpatient done manually. So that work processes are not effective and efficient in terms of processing time report. Therefore, to boost the service {{it is necessary to}} design information system of outpatient medical records in the work of Karya Asih Charitas Hospital Palembang. Development system used is FAST. Which consists of several phases. The first phase is to observe directly the definition of the scipe of the company’s operational processes, {{the second phase of the}} analysis of problems within the company, the third phase of requirements analysis using the framework of Pieces, the fourth phase of decision analysis provides an assessment and advice. These five logical design phase to design the system in the form of DFD, <b>flowchart,</b> <b>data</b> tables, and ERD, the sixth phase of the construction and testing. Testing is performed only limited functional system using blackbox testing. The result gives the ease of administration in the creation of {{data processing}} reports and seek outpatient information, so the work becomes more effective and efficient that can benefit the work of Karya Asih Charitas Palembang...|$|R
40|$|The {{purpose of}} this paper is to report results on the {{development}} of a new computer-assisted methodology for creating parallel test forms using the item response theory (IRT) information function. Recently, several researchers have approached test construction from a mathematical pr gramming perspective. However, these procedures require formidable computations, particularly as more constraints (i. e., the number of forms and the number of content areas) are added. In the test construction methodology proposed in this study, items are sampled from an ordered domain of item information values according to differences between test information curves of forms that are in the process of being created and a target test information curve. This new heuristic:rocedure, which uses a program known as TESTGEN, is being examined by the American College Testing (ACT) Program, which develops sip parallel forms for the ACT Assessment Program each year. Research has concentrated on the Mathematics Usage Test. Results appear to be quite promising. Two <b>data</b> tables, one <b>flowchart,</b> and six graphs are presented. (Author/T 3 H) ******************************g**************************************** Reproductions supplied by EDRS are the best that can be made from the original document. f%. c 1...|$|R
40|$|SummaryObjectiveTo {{present the}} {{methodology}} {{and the results}} of a field survey to assess the chain costs of procedures for treatment of acute myocardial infarction (AMI), carried out in 11 Brazilian reference and specialized hospitals. MethodsThe cost assessment used the cost per procedure and per pathology systems. The procedures associated with the treatment of AMI were organized and their logical sequence (protocols) was used to create a <b>flowchart.</b> <b>Data</b> collection tools gathered information on prices and quantities in 2008 (private, health insurance, SUS, and Brazilian Medical Association – AMB price lists), as well as the applicable costs. ResultsOverall, the total cost of the procedures involving the ‘standard treatment’ of AMI was R$ 12, 873. 69, if percutaneous coronary intervention (PCI) did not involve stent use. If the stent becomes necessary, the cost increases to R$ 23, 461. 87. ConclusionAmong the results, we emphasize the fact that the costs of the more expensive procedures did not present statistically significant variations between hospitals, regardless of their location, predominant clientele or legal nature, and the fact that hospitals that treat predominantly users of the Brazilian Unified Health System registered the lowest costs, albeit not statistically significant regarding the entire chain of procedures associated with the pathology...|$|R
40|$|The {{evolving}} {{of global}} economic trade fosters every company finding strategic ways {{in order to}} stand survive. "XYZ" Company, a service industry, is a system integrator concentrates on networking and hardware provider. As service industries having direct contact with their customer encourage {{them to think about}} what customers do really want and how to make customers satisfied and loyaL. The company insists to increase the annual sales revenue. However, at this time, some obstacles in doing business activities have decreased the overall company performances. Thus the director assigns someone to examine the system and do some improvements. Solving those problems is conducted through analyzing the current business process, proposing the new system and visualizing them by making <b>flowchart,</b> <b>data,</b> and process diagram. The endpoint solution is creating and managing customer relationship database as an Executive Information System device. Having reliable customer database will ease managerial staff when making relation with customer either maintaining the remaining customers or finding the new ones. As known that customers are the center point of the profit revenue thus how to satisfy what customer wants must be the main concerned immediately. Actually, this customer database can be integrated with other related database such as Enterprise Resource Planning database (ERP) and Supply Chain Management database (SCM) ...|$|R
40|$|Management of the {{temporomandibular}} {{joint in}} ablative {{head and neck}} surgery is controversial with no standardized approach. The aim {{of the study was}} to establish risk-based guidelines for the management of the temporomandibular joint after ablative surgery. Analysis of all patients' records receiving ablative surgery involving the temporomandibular joint in the Department of Cranio-Maxillofacial and Oral Surgery, University Hospital of Zürich, from 2001 to 2012, was performed, identifying 15 patients and 14 reconstructive procedures. A literature search was done identifying all relevant literature on current approaches. Applicable cohorts were constructed, and relevant risks were extrapolated. Evaluated studies are not uniform in their reporting with nonhomogeneous patient groups. A diverse approach is used in the management of these patients with complications such as infection, ankylosis, limited mouth opening, plate penetration in the skull base, and plate loosening. Risk factors for complications appear to be radiation, costochondral graft, disk loss, and plate use alone. Clinical data suggest use of a plate with metal condyle reconstructions and previous radiation therapy as potential risks factors. Employing literature evidence and cumulated clinical <b>data,</b> a risk-based <b>flowchart</b> was developed to assist surgical decision making. Risk factors such as radiation, disk preservation, and soft tissue conditions are important complication-associated factors when planning surgery. Free vascularized fibula grafts appear to have the least complications that must be weighed against donor site morbidity...|$|R
40|$|The {{purpose of}} this {{research}} is to develop the knowledge management system in audit of compensation fund, establish the prototype of knowledge management system, and make a recommendation of design of web base knowledge management in audit of compensation fund. {{in order to make the}} thesis complete, the data are collected from the relevant printed document, discussion with competent personnel and observation of the audit process by using the qualitative description method and prototyping development approach. The tools which used in analysis are component matrix, content diagram, <b>data</b> flow diagram, <b>flowchart,</b> entity relationship diagram, and data dictionary. The knowledge management system developed is a web based application system categorized informational, interaction and download oriented. Content design comprises of external data from the executing agency, best practice, the audit reports, monitoring and evaluation documents and compilation audit reports as the main output proposed to government. Data input can be done by entry data or file uploads that suitable format in the system. The output form can be obtained as report display on screen or download files. Interface should be friendly for users on the web application. Navigation usage is basic requirement. On the system architecture design, screen format and navigation are consistent for the whole screen and function. The system is designed to have leveling data security devices, from networking (firewall), [URL] (secured [URL] and authentication, access control using user/password, and access level control consist of user, checker, authorizer and administrator...|$|R
40|$|The {{condition}} of the water distribution networks in Canada has been deteriorating {{over the past few}} decades due to the lack of preventive maintenance and asset management programs. It was reported that 60 percent of the water mains in Canada became unacceptable and inefficient for use. A study conducted by the Canadian Water and Wastewater Association (CWWA) estimates an outlay of $ 34 billion is needed to replace the existing 112, 000 Km of water mains in Canada. Trenchless technology is one of the rapidly developing areas in rehabilitation and replacement of water mains. Selection of the most suitable trenchless method(s) is currently performed manually by a decision-maker, thus other more efficient and new methods may be overlooked. This thesis studies the methods used and the decision-making process involved in the rehabilitation of water mains with a focus on trenchless technology. A decision-support methodology has been developed using information gathered from the literature, a survey questionnaire form, and from a field investigation carried out by the author. The methodology incorporates Multi-Attribute Utility Theory and Analytical Hierarchy Process in its decision support system. The methodology has been implemented in an automated system composed of three modules: interactive <b>flowcharts,</b> <b>Data</b> Files and Query System, and a Decision Support System. The developed system automates the selection of the most suitable trenchless method for the rehabilitation of a specified water main project taking into consideration the project's characteristics and the decision-maker's preference. The system was tested using a case study of a water main rehabilitation project...|$|R
40|$|Program {{design is}} just an aspect of {{software}} development life cycle. Design {{is seen as the}} foundation for coding, debugging and testing, maintenance activities, and it also portrays how the final product will meet the requirement. In this paper, I formulated a data encryption problem and its algorithm, and I represented the algorithm using <b>Flowchart,</b> <b>Data</b> Flow Diagram (DFD), Trees, Structure Chart, and Hierarchy Diagram (H-Diagram) design methods. Questionnaire and these design methods (to compute data encryption problem) were administered to Computer Science experts only to ascertain program design quality from which analysis were made on the measures (text attributes / intuitive attributes) for each of the design method, using the program quality rating as Excellent = 5, Very Good = 4, Good = 3, Fair = 2, and Poor = 1). The average of the program quality rating of each measure becomes the metric. The result obtained from my research shows that the quality of the program design depends on the amount of the characteristics of evaluation measures desired and strict top-down sequencing- structured design and programming. The mean total of the different design methods examined, Flowchart has the lowest mean value of 31. 85, while Structure Chart has the highest mean value of 38. 4, with respect to text attributes. Again, Flowchart has the lowest mean value of 45. 05, while Structure Chart has the highest mean value of 58. 10, with respect to intuitive attributes as reported in the bar charts, which clearly shows the dependency nature relating intuitive attributes and text attributes...|$|R
40|$|Promotor: Tomasz Barszcz. Niepublikowana praca doktorska. Tyt. z ekranu tyt. Praca doktorska. Akademia Górniczo-Hutnicza im. Stanisława Staszica (Kraków), Katedra Robotyki i Mechatroniki, 2013. Zawiera bibliogr. Dostępna również w wersji drukowanej. Tryb dostępu: Internet. State {{of the art}} of wind {{turbines}} monitoring, objects of wind turbine condition monitoring, condition monitoring techniques, system design and configuration, system performance and maintenance, fields of automatization of wind turbine condition monitoring, justification of the work, goal and scope of the work, {{wind turbines}} as objects of vibration-based condition monitoring, typical constructions of wind turbines, power control of wind turbines, overview of mechanical drive train elements, wind turbine characteristic frequencies, typical malfunctions and faults, data preprocessing, elements of data acquisition in condition monitoring systems, criteria for correct data acquisition, process parameters validation, independent process parameters validation, relative process parameters validation, vibration data selection, selection based on fixed time intervals, selection based on operational states, selection based on process parameters tracking, fluctuation of non-stationary process parameters, validation of system configuration range dynamics, validation of vibration signals, need for on-line signal validation, literature review on signal validation, classifications of vibration signals, features of correct and incorrect vibration signals, examples of correct and incorrect vibration signals, methods for amplitude based validation of vibration signals, minimum energy rule, N-point rule, Z-point rule, U-point rule, amplitude range dynamics rule, statistical rules, comparative signal assessment methods, software implementation remarks, determination of machine operational states, algorithm presentation, signal assumptions, data clustering, outliers removal, case study, outliers removal, initial selection of number of states hierarchical clustering, clustering k-means and mixture Gaussian model methods, indicator initial states verification, modification of cluster range, selection of input set for states definition, signal features extraction, decomposition of vibration signals, signal decomposition benefits, separation methods overview, proposition of a frequency-domain decomposition technique, max med estimator as alternative to kurtosis based estimators, removal of deterministic components, algorithm description, narrowband envelope analysis, problem background, selection of the optimal bandwidth, selection of the optimal center frequency, methods for optimal freqeuncy band selection OFB, direct spectrum comparison, spectrogram, spectral kurtosis, band selection optimilization criteria, protrugram as a novel frequency band selection method, method description, simulated signal, test rig case study, selection of protrugram step size, method extention utilization of statistical estimators, description of extension algorithm, algorithm steps, algorithm block diagram, instantaneous Circular Pitch Cyclic Power ICPCP a novel tool for diagnosis of planetary gearboxes, characteristics of wind turbine planetary gearbox, overview of PG diagnostic methods, method description, comparison with other methods, selection and automatization of diagnostic methods, data acquisition, reference stage, continuous monitoring stage, a complete algorithm for data acquisition in wind turbines continuous condition monitoring, hardware realization, parallel data acquisition, data acquisition time lag, determination of alarm levels, threshold setting requirements, probability distributions for threshold setting, weibull probability distribution, generalized extreme value probability distribution, extreme value probability distribution, inverse Gaussian probability distribution, description of real data, threshold setting procedure, symmetrical approach, positive amplitude approach, method <b>flowchart,</b> <b>data</b> preprocessing, distribution model fitting, setting the reference and threshold values, case study optimized fits on the real datasets, distribution function fit assessment, comparison of selected probability distributions, development of referential data, diagnostic reports, tools for reports creation, reports interface, diagnostic center, introduction, diagnostic center architecture, realization of data access within condition monitoring systems, integration with matlab environment, integration schem...|$|R

