21|288|Public
50|$|Synapse is an {{industry}} <b>interface</b> <b>event</b> where CEOs, entrepreneurs, leaders and corporate people are invited to speak on management-related topics.|$|E
50|$|BOOPSI (Basic Object Oriented Programming System for Intuition) is an {{object-oriented}} programming system for AmigaOS. It extends the AmigaOS windowing environment (Intuition) with an object-oriented subsystem allowing {{a hierarchy of}} object classes in which every class defines a single GUI widget or <b>interface</b> <b>event.</b>|$|E
50|$|The event {{dispatching}} thread (EDT) is {{a background}} thread used in Java to process events from the Abstract Window Toolkit (AWT) graphical user <b>interface</b> <b>event</b> queue. It {{is an example}} of the generic concept of event-driven programming, that is popular in many other contexts than Java, for example, web browsers, or web servers.|$|E
40|$|Modern window-based user {{interface}} systems generate user <b>interface</b> <b>events</b> as natural products of their normal operation. Because such events can be automatically captured {{and because they}} indicate user behavior with respect to an application's {{user interface}}, they have long been regarded as a potentially fruitful source of information regarding application usage and usability. However, because user <b>interface</b> <b>events</b> are typically voluminos and rich in detail, automated support is generally required to extract information {{at a level of}} abstraction that is useful to investigators interested in analyzing application usage or evaluating usability. This survey examines computer-aided techniques used by HCI practitioners and researchers to extract usability-related information from user <b>interface</b> <b>events.</b> A framework is presented to help HCI practitioners and researchers categorize and compare the approaches that have been, or might fruitfully be, applied to this problem. Because many of the techniques in the research literature have not been evaluated in practice, this survey provides a conceptual evaluation to help identify some of the relative merits and drawbacks of the various classes of approaches. Ideas for future research in this area are also presented. This survey addresses the following questions: How might user <b>interface</b> <b>events</b> be used in evaluating usability? How are user <b>interface</b> <b>events</b> related to other forms of usability data? What are the key challenges faced by investigators wishing to exploit this data? What approaches have been brought to bear on this problem and how do they compare to one another? What are some of the important open research questions in this area...|$|R
40|$|The Every Earthquake a Precursor According to Scale (EEPAS) {{long-range}} earthquake forecasting {{model has}} been shown to be informative in several seismically active regions, including New Zealand, California and Japan. In previous applications of the model, the tectonic setting of earthquakes has been ignored. Here we distinguish crustal, plate interface, and slab earthquakes and apply the model to earthquakes with magnitude M≥ 4 in the Japan region from 1926 onwards. The target magnitude range is M≥ 6; the fitting period is 1966 - 1995; and the testing period is 1996 - 2005. In forecasting major slab earthquakes, it is optimal to use only slab and <b>interface</b> <b>events</b> as precursors. In forecasting major <b>interface</b> <b>events,</b> it is optimal to use only <b>interface</b> <b>events</b> as precursors. In forecasting major crustal events, it is optimal to use only crustal events as precursors. For the smoothed-seismicity component of the EEPAS model, it is optimal to use slab and <b>interface</b> <b>events</b> for earthquakes in the slab, <b>interface</b> <b>events</b> only for earthquakes on the interface, and crustal and <b>interface</b> <b>events</b> for crustal earthquakes. The optimal model parameters indicate that the precursor areas for slab earthquakes are relatively small compared to those for earthquakes in other tectonic categories, and that the precursor times and precursory earthquake magnitudes for crustal earthquakes are relatively large. The optimal models fit the learning data sets better than the raw EEPAS model, with an average information gain per earthquake of about 0. 4. The average information gain is similar in the testing period, although it is higher for crustal earthquakes and lower for slab and interface earthquakes than in the learning period. These results show that earthquake interactions are stronger between earthquakes of similar tectonic types and that distinguishing tectonic types improves forecasts by enhancing the depth resolution where tectonic categories of earthquakes are vertically separated. However, when depth resolution is ignored, the model formed by aggregating the optimal forecasts for each tectonic category performs no better than the raw EEPAS model...|$|R
5000|$|Microsoft.MSAGL.Drawing.dll, a device-independent {{implementation}} of graphs as {{graphical user interface}} objects, {{with all kinds of}} graphical attributes, and support for <b>interface</b> <b>events</b> such as mouse actions; ...|$|R
50|$|AmigaOS 2.0 was {{released}} with {{the launch of}} the Amiga 3000 in 1990. Until AmigaOS 2.0 there was no unified look and feel design standard and application developers had to write their own widgets (both buttons and menus) if they wished to enhance the already-meager selection of standard basic widgets provided by Intuition. With AmigaOS 2.0 gadtools.library was created, which provided standard widget sets. The Amiga User Interface Style Guide, was published which explained how applications should be laid out for consistency. Intuition was improved with BOOPSI (Basic Object Oriented Programming system for Intuition) which enhanced the system with an object-oriented interface to define a system of classes in which every class individuate a single widget or describes an <b>interface</b> <b>event.</b> It can be used to program object oriented interfaces into Amiga at any level.|$|E
40|$|While {{the web of}} {{linked data}} gets {{increasingly}} richer in size and complexity, its use is still constrained {{by the lack of}} applications consuming this data. We propose a Web-based tool to build and execute complex applications to transform, integrate and visualize SemanticWeb data. Applications are composed as pipelines of a few basic components and completely based on Semantic Web standards, including SPARQL Construct for data transformation and SPARQL Update for state transition. The main novelty of the approach lays in the support to interaction, through the availability of user <b>interface</b> <b>event</b> streams as pipeline inputs...|$|E
40|$|End users {{often need}} {{the ability to}} tailor diagrammingbased design tools and to specify dynamic {{interactive}} behaviours of graphical user interfaces. However most want {{to avoid having to}} use textual scripting languages or programming language approaches directly. We describe a new visual language for user <b>interface</b> <b>event</b> handling specification targeted at end users. Our visual language provides end users with abstract ways to express both simple and complex event handling mechanisms via visual specifications. These specifications incorporate event filtering, tool state querying and action invocation. We describe our language, its incorporation into a metatool for building visual design environments, examples of its use and results of evaluations of its effectiveness...|$|E
40|$|Abstract – Modern {{interactive}} {{applications are}} event-driven. User <b>interface</b> <b>events</b> {{are referred to}} as those that are generated when the user interacts with the application via its user interface. Relevant user <b>interface</b> <b>events</b> provide crucial data for usability evaluation. Due to iterative design, evaluation, and redesign of the user interface in early stages of application development, automated support for data collection and analysis is desirable. We in this paper describe an aspect-oriented approach to automated data collection and as shown in a case study the data collected with our approach is amenable to subsequent analysis...|$|R
40|$|We {{present a}} {{compositional}} approach to analyze timing behavior of complex platforms with different scheduling strategies. The approach uses <b>event</b> <b>interfacing</b> {{in order to}} couple previously incompatible analysis techniques which provide subsystem and component behavior. Based on these <b>interfaces,</b> <b>event</b> propagation using abstract models is used to derive global system timing properties. 1...|$|R
40|$|Abstract- User <b>interface</b> <b>events</b> provide {{valuable}} information about user behavior {{with respect to}} an application’s user interface and therefore are considered as {{an important source of}} data for usability evaluation. Since usability evaluation is based on tasks that users perform, it is crucial to capture user <b>interface</b> <b>events</b> with suff icient information for task identification. However, how to make it possible is still an open question. We describe an approach to investigate the use of the aspect-oriented technique with assistance of localized instrumentation to capture task-based event traces. We also present a proof-of-concept tool to demonstrate its effectiveness and discuss its limitations...|$|R
40|$|Empirical {{evaluation}} of software systems in actual usage situations {{is critical in}} software engineering. Prototyping, beta testing, and usability testing are widely used to refine system requirements, detect anomalous or unexpected system and user behavior, and to evaluate software usefulness and usability. The World Wide Web enables cheap, rapid, and large-scale distribution of software for evaluation purposes. However, current techniques for collecting usage data have not kept pace with the opportunities presented by Web-based deployment. This paper presents an approach and prototype system that makes large-scale collection of usage data over the Internet a practical possibility. A general framework for comparing software monitoring systems is presented and {{used to compare the}} proposed approach to existing techniques. Keywords Internet-scale usability data collection, remote usability testing, user <b>interface</b> <b>event</b> monitoring, agent-based architectures, human-computer interaction an [...] ...|$|E
40|$|This survey {{examines}} computer-aided {{techniques used}} by HCI practitioners and researchers to extract usabilityrelated information from human-computer interaction events. A framework {{is presented to}} help HCI practitioners and researchers categorize, evaluate, and compare the strengths and limitations of approaches that have been, or might fruitfully be, applied to this problem. An agenda for future {{research in this area}} is also presented. Keywords User <b>interface</b> <b>event</b> monitoring, sequential data analysis, usability evaluation, human-computer interaction 1 INTRODUCTION User interface events (UI events) are typically generated as natural products of the normal operation of window-based user interface systems such as those provided by Microsoft Windows, the Macintosh Operating System, the X Window System, and the Java Abstract Window Toolkit (AWT). Such events indicate user behavior with respect to the components that make up an application's user interface (e. g. movements of the mouse [...] ...|$|E
30|$|On 1 April 2016, the Off-Mie {{earthquake}} (MW 5.9) occurred ~[*] 50  km off the Kii Peninsula {{at depth}} of 11.4  km directly beneath DONET (Wallance et al. 2016; Fig.  1). It {{was classified as}} a plate <b>interface</b> <b>event</b> from the analysis of ocean bottom seismometer data, seafloor and subseafloor geodetic data from DONET, and tsunami modeling (Wallace et al. 2016). This earthquake appears to have ruptured the same plate boundary fault responsible for great interplate earthquakes such as the 1944 Tonankai earthquake (MW 8.1), although its rupture area was much smaller {{than that of the}} 1944 earthquake. Tsuji et al. (2017) showed that the fault planes of the 2016 Off-Mie earthquake and its aftershocks were influenced by the geometry of the plate boundary décollement and the older landward part of the accretionary prism along the coast of the Kii Peninsula. The aftershocks of the 2016 event occurred where the décollement soles onto the top of the oceanic crust beneath the old prism.|$|E
40|$|Modern window-based {{applications}} are event-driven. User <b>interface</b> <b>events</b> carry valuable information about user behavior and are considered {{as an important}} source of data for usability evaluation. Aspect-oriented techniques provide an effective way to capture user <b>interface</b> <b>events.</b> However, it is insufficient to analyze event traces based on the information carried within events themselves. We describe a grammatical approach to analyzing event traces and identifying user tasks {{in the context of a}} task model. We also describe a proof-of-concept experiment to demonstrate its feasibility. Our approach paves the way for automatic support for task identification and therefore is beneficial to user interface evaluation that relies on task-based usability data...|$|R
5000|$|Graphical user {{interface}} testing. A testing framework that generates user <b>interface</b> <b>events</b> such as keystrokes and mouse clicks, and observes {{the changes that}} result in the {{user interface}}, to validate that the observable behavior {{of the program is}} correct.|$|R
40|$|In {{this thesis}} actual use logging from a {{graphical}} user interface is studied. For this purpose, a model and a software implementation for collecting the actual use logging events from a generic browser-based user interface are developed. The model utilises the logging features of the web server so that the studied software need not be changed. By collecting the user activatable elements from the user interface description, {{it is possible to}} form a hierarchical map of the interface. The intentional user actions are filtered from the collected and abstracted weblog by combining it into the hierarchical map. This thesis presents three analyses, which process the single user <b>interface</b> <b>events</b> and transform them to semantically rich information. The user <b>interface</b> <b>events</b> provide an interesting insight into the user in the application context, and the aim of this thesis is to demonstrate how these events may be collected and analysed. The collection model presented in this thesis may make it easier to collect the user <b>interface</b> <b>events</b> so that they can contribute to the user interface design process. Within this thesis, the software implemen-tation is published under the GNU GPL license. Keywords: actual use logging, GUI, usabilit...|$|R
40|$|Think-aloud {{usability}} analysis provides extremely useful data but is very {{time-consuming and}} expensive to perform {{because of the}} extensive manual video analysis that is required. We describe a simple method for automated detection of usability problems from client user interface events for a developing medical intelligent tutoring system. The method incorporates (1) an agent-based method for communication that funnels all interface events and system responses to a centralized database, (2) a simple schema for representing interface events and higher order subgoals, and (3) an algorithm that reproduces the criteria used for manual coding of usability problems. A correction factor was empirically determining {{to account for the}} slower task performance of users when thinking aloud. We tested the validity of the method by simultaneously identifying usability problems using TAU and manually computing them from stored <b>interface</b> <b>event</b> data using the proposed algorithm. All usability problems that did not rely on verbal utterances were detectable with the proposed method...|$|E
40|$|Increasingly power-hungry {{processors}} have {{reinforced the}} need for aggressive power management. Dynamic volt-age scaling has become a common design consideration allowing for energy efficient CPUs by matching CPU per-formance with the computational demand of running pro-cesses. In this paper, we propose Interaction-Aware Dy-namic Voltage Scaling (IADVS), a novel fine-grained ap-proach to managing CPU power during interactive work-loads, which account {{for the bulk of}} the processing de-mand on modern mobile or desktop systems. IADVS is built upon a transparent, fine-grained interaction capture sys-tem. Able to track CPU usage for each user <b>interface</b> <b>event,</b> the proposed system sets the CPU performance level to the one that best matches the predicted CPU demand. Com-pared to the state-of-the-art approach of user-interaction-based CPU energy management, we show that IADVS im-proves prediction accuracy by 37 %, reduces processing de-lays by 17 %, and reduces energy consumed of the CPU by as much as 4 %. The proposed design is evaluated with both a detailed trace-based simulation as well as implementa-tion on a real system, verifying the simulation findings. ...|$|E
40|$|Increasingly, mobile {{computers}} use dynamic voltage scaling (DVS) {{to reduce}} CPU voltage and speed and thereby increase battery life. To {{determine how to}} change voltage and speed when responding to user interface events, we analyze traces of real user workloads. We evaluate a new heuristic for inferring when user interface tasks complete and find it is more efficient and nearly as effective as other approaches. We compare DVS algorithms and find that for a given performance level, the PACE algorithm uses the least energy and the Stepped algorithm uses the second least. We find that different types of user <b>interface</b> <b>event</b> (mouse movements, mouse clicks, and keystrokes) trigger tasks with significantly different CPU use, suggesting one should use different speeds for different event types. We also find differences in CPU use between categories of the same event type, e. g., between pressing spacebar and pressing enter, and between events of different applications. Thus, {{it is better to}} predict task CPU use based solely on tasks of the same category and application. However, energy savings from such improved predictions are small...|$|E
40|$|Modern window-based user {{interface}} systems generate user <b>interface</b> <b>events</b> as natural products of their normal operation. Because such events can be automatically captured {{and because they}} indicate user behavior with respect to an application’s {{user interface}}, they have long been regarded as a potentially fruitful source of information regardin...|$|R
50|$|Using the {{information}} in these XML client application files, Jargon Reader renders (draws) the graphical user interface and executes logic functions in response to user <b>interface</b> <b>events</b> such as selecting a button. Various peripherals such as barcode readers, mag-card readers, RFID readers and mobile printers are also supported.|$|R
25|$|SVG {{images can}} {{interact}} with users in many ways. In addition to hyperlinks as mentioned below, {{any part of}} an SVG image can be made receptive to user <b>interface</b> <b>events</b> such as changes in focus, mouse clicks, scrolling or zooming the image and other pointer, keyboard and document events. Event handlers may start, stop or alter animations as well as trigger scripts in response to such events.|$|R
40|$|Abstract—We {{report the}} {{implementation}} of a text input applica-tion (speller) based on the P 300 event related potential. We obtain high accuracies by using an SVM classifier and a novel feature. These techniques enable us to maintain fast performance without sacrificing the accuracy, thus making the speller usable in an on-line mode. In order to further improve the usability, we perform various studies on the data with a view to minimizing the training time required. We present data collected from nine healthy sub-jects, along with the high accuracies (of the order of 95 % or more) measured online. We show that the training time can be further reduced by a factor of two from its current value of about 20 min. High accuracy, fast learning, and online performance make this P 300 speller a potential communication tool for severely disabled individuals, who have lost all other means of communication and are otherwise cut off from the world, provided their disability does not interfere with the performance of the speller. Index Terms—P 300, brain–computer <b>interface,</b> <b>event</b> related po-tential, speller, support vector machine (SVM). I...|$|E
40|$|Machine {{learning}} {{techniques have}} been applied to several kinds of human data including speech recognition and goal or user identification. When learning on such data, {{it is important to}} use models that are not strongly biased against properties of the data, or the variable assignments learned may be largely incorrect. We are working with data sources for user <b>interface</b> <b>event</b> data and examining the applicability of dynamic Bayesian networks (DBNs) to context tracking. Specifically, we identify the value and transition points of a hidden task variable; this problem is known as segmentation. Our data is drawn from command line interaction collected in a real work setting and window event traces taken during a controlled behavioral study. We have applied discrete time hidden Markov models (HMMs) and DBNs to these data sets, but these methods are fundamentally Markovian and, as a result, cannot correctly learn the properties of hidden variables with nongeometrically distributed dwell times. We believe that using semi-Markov models may better capture some underlying structure and allow for better segmentation. In this paper, we describe the experimental protocols performed, examine the bias of typical DBNs and HMMs towards geometric variable dwell times, and assess the validity of this assumption. We discuss the issues of applying semi-Markov DBNs to the available data...|$|E
40|$|As {{computer}} networks and systems become {{more complex and}} more heterogeneous (often involving systems from multiple vendors), the importance of network and system management increases. During the last 10 years, the overall industry effort to develop, enhance and integrate management systems has crystallized {{in the concept of}} management platforms. The goal of this thesis is to investigate and discuss distributed networks and systems management platforms (called IT management platforms) in general terms and in real life. This is done by first performing a thorough theoretical study of IT management technologies, history, protocols (mainly SNMP) and architectures. IT management platform components are then studied, including graphical user <b>interface,</b> <b>event</b> management, communications, objects and security. Theory about expert systems is used to highlight and understand important concepts regarding IT management platforms and functionality. A case study is then performed at a company that is about to start planning and later implementing a commercial IT management solution. The IT management platform used is HP OpenView Operations 7. x and Network Node Manager 6. x for Unix. Using these two methods as a fundament I evaluate and analyse how the company tries to implement and tackle the complexity of an IT management system in real life. Due to some serious flaws in planning, implementing and project management, a few key success factors are revealed to achieve functional IT management platform implementation. Another important finding is that {{there seems to be a}} misconception about what IT management platforms should be able to do, and what they are in fact able to do with today’s technology...|$|E
40|$|Online Material: Horizontal-component {{data for}} {{subduction}} zone earthquakes. It {{has come to}} our attention that the ground-motion database used in the Atkinson and Boore (2003) prediction equations (AB 03) for interface earthquakes contains errors. The response spectral values at 2. 5 and 5 Hz for <b>interface</b> <b>events</b> were inadvertently switched in the database for nearly 2 = 3 of the interface records. The in-slab database is unaf...|$|R
40|$|CORBA is a {{promising}} software platform for CSCW applications. However, the current CORBA ORBs only provide low-level services. Building CSCW applications {{is still a}} complex task. In this paper, we discuss how a common notification service {{can be added to}} the CORBA architecture to deal with common user <b>interface</b> <b>events</b> in a distributed environment. This notification service is based on the already standardized Event Service and is design to support awareness in distributed environments...|$|R
40|$|A {{fundamental}} {{timing analysis}} {{problem in the}} verification and synthesis of interface logic circuitry is the determination of allowable time separations, or skews between <b>interface</b> <b>events,</b> given timing constraints and circuit propagation delays. These skews are used to verify timing properties and determine allowable propagation delays for logic synthesis. This paper presents an algorithm that provides tighter skew bounds with better asymptotic running time than previous methods, and shows how to apply the method to synthesis tasks...|$|R
40|$|The {{simulation}} {{of the network}} control center (NCC) is {{in the second phase}} of development. This phase seeks to further develop the work performed in phase one. Phase one concentrated on the computer systems and interconnecting network. The focus of phase two will be the implementation of the network message dialogues and the resources controlled by the NCC. These resources are requested, initiated, monitored and analyzed via network messages. In the NCC network messages are presented in the form of packets that are routed across the network. These packets are generated, encoded, decoded and processed by the network host processors that generate and service the message traffic on the network that connects these hosts. As a result, the message traffic is used to characterize the work done by the NCC and the connected network. Phase one of the model development represented the NCC as a network of bi-directional single server queues and message generating sources. The generators represented the external segment processors. The served based queues represented the host processors. The NCC model consists of the internal and external processors which generate message traffic on the network that links these hosts. To fully realize the objective of phase two it is necessary to identify and model the processes in each internal processor. These processes live in the operating system of the internal host computers and handle tasks such as high speed message exchanging, ISN and NFE <b>interface,</b> <b>event</b> monitoring, network monitoring, and message logging. Inter process communication is achieved through the operating system facilities. The overall performance of the host is determined by its ability to service messages generated by both internal and external processors...|$|E
40|$|This work {{presents}} the re-configurable processor ROBIN, {{which is a}} key element of the data-acquisition-system of the ATLAS experiment, located at the new LHC at CERN. The ATLAS detector provides data over 1600 channels simultaneously towards the DAQ system. The ATLAS dataflow model follows the “PULL” strategy in contrast to the commonly used “PUSH” strategy. The data volume transported is reduced by a factor of 10, however the data must be temporarily stored at the entry to the DAQ system. The input layer consists of approx. 160 ROS read-out units comprising 1 PC and 4 ROBIN modules. Each ROBIN device acquires detector data via 3 input channels and performs local buffering. Board control is done via a 64 -bit PCI <b>interface.</b> <b>Event</b> selection and data transmission runs via PCI in the baseline bus-based ROS. Alternatively, a local GE interface can take over part or all of the data traffic in the switch-based ROS, {{in order to reduce the}} load on the host PC. The performance of the ROBIN module stems from the close cooperation of a fast embedded processor with a complex FPGA. The efficient task-distribution lets the processor handle all complex management functionality, programmed in “C” while all movement of data is performed by the FPGA via multiple, concurrently operating DMA engines. The ROBIN-project was carried-out by and international team and comprises the design specification, the development of the ROBIN hardware, firmware (VHDL and C-Code), host-code (C++), prototyping, volume production and installation of 700 boards. The project was led by the author of this thesis. The hardware platform is an evolution of a FPGA processor previously designed by the author. He has contributed elementary concepts of the communication mechanisms and the “C”-coded embedded application software. He also organised and supervised the prototype and series productions including the various design reports and presentations. The results show that the ROBIN-module is able to meet its ambitious requirements of 100 kHz incoming fragment rate per channel with a concurrent outgoing fragment rate of 21 kHz per channel. At the system level, each ROS unit (12 channels) operates at the same rates, however for a subset of the channels only. The ATLAS DAQ system – with 640 ROBIN modules installed – has performed a successful data-taking phase at the start-up of the LHC in September...|$|E
30|$|Sensor data {{is stored}} in a sensor data repository; the sensor data agent {{retrieves}} this sensor data (1) and then sends a sensor data message to the sensor agent (2). Once this message has been received, the sensor agent sends a sensor event message to the context agent. The context agent determines how the context has changed, (3 – 5) and from this a context message is formed {{and sent to the}} interventions agent (6). The intervention agent receives this message and determines the appropriate intervention to make. Once an intervention has been determined an intervention message is sent to the GUI Agent (7) and a record of the intervention is kept by the feedback agent (8 – 9). Once the GUI Agent has received this message, it sends a profile check message to the profile agent (10 – 11), the profile details are then retrieved from the profile data store (not explicitly indicated in the figure). Once the correct profile has been selected, the GUI Agent chooses the appropriate interaction method and interface components to use, the interface is then adapted accordingly (12). The person is then able to interact with the interface (13). For example, the subject is told the back door is open, after a period of time the subject closes the back door and this generates an <b>interface</b> <b>event</b> (14) that is processed by the GUI agent (15). The GUI Agent ksends a message to the intervention agent that details the back door has been closed, resulting in a contextual change occurring (17) and this is recorded (18). If the subject chooses to receive feedback, they interact (19) with the touch screen device (visual interactions) or issue the keyword command ‘feedback’ (auditory interactions). The GUI agent provides feedback menu options to the person (21 – 22) and the person is then able to navigate through the available feedback using the touch screen device or listen to the feedback listening options. Once a choice has been made (25), the GUI Agent sends a message to the feedback agent to retrieve the feedback (26). The chosen feedback is gathered from the feedback data store (27 – 28) and the feedback message is sent to the GUI Agent (29). Depending on the current profile, the feedback will either be spoken to the person or displayed on the touch screen device screen (30). The person then receives the chosen feedback (31) and by carrying out the feedback activity, the person may be able to identify issues and correct these issues themselves. The following sections detail what an intervention and feedback is.|$|E
30|$|LostCarrier. The wired {{interface}} {{has lost}} its carrier on the wired <b>interface.</b> This <b>event</b> can occur only if the node is in the Wired state.|$|R
5000|$|An XML Event is the {{representation}} of some [...] occurrence (such as a mouse button click) that gets associated with a data element in an XML document. XML Events provides a static, syntactic binding to the DOM <b>Events</b> <b>interface,</b> allowing the <b>event</b> to be handled.|$|R
40|$|We propose an {{approach}} to enhance the fault diagnosis in black-box component-based systems, in which only <b>events</b> on component <b>interfaces</b> are observable, and assume that causal dependencies between component <b>interface</b> <b>events</b> within components are not known. For such systems, we describe a causality analysis framework that helps us establish the causal relationship between component failures and system failures, given an observed system execution trace. The analysis {{is based on a}} formalization of counterfactual reasoning, and applicable to real-time systems. We illustrate the analysis with a case study from the medical device domain...|$|R
