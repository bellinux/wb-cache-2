13|65|Public
40|$|Modern {{microprocessors}} <b>extract</b> <b>instruction</b> level paral-lelism (ILP) from sequential {{programs by}} issuing instructions from an active instruction window. Data dependencesamong instructions, {{and not the}} original program order, determine when an instruction may be issued from the win-dow. Dependences involving register data are detected easily because register designators are completely specifiedwithin instructions. However, dependences involving memory data (e. g. between a load and a store or two stores) areambiguous until the memory addresses are computed...|$|E
40|$|The Multiscalar {{architecture}} executes {{a single}} sequential program following multiple flows of control. In the Multiscalar hardware, a global sequencer, {{with help from}} the compiler, takes large steps through the program's control flow graph (CFG) speculatively, starting a new thread of control (task) at each step. This is inter-task control flow speculation. Within a task, traditional control flow speculation is used to <b>extract</b> <b>instruction</b> level parallelism. This is intra-task control flow speculation. This pape...|$|E
40|$|In this paper, {{we present}} a novel {{approach}} to detect unknown virus using dynamic instruction sequences mining techniques. We collect runtime instruction sequences from unknown executables and organize instruction sequences into basic blocks. We <b>extract</b> <b>instruction</b> sequence patterns based on three types of instruction associations within derived basic blocks. Following a data mining process, we perform feature extraction, feature selection and then build a classification model to learn instruction association patterns from both benign and malicious dataset automatically. By applying this classification model, we can predict the nature of an unknown program. Our result shows that our approach is accurate, reliable and efficient...|$|E
50|$|The PSW may {{be loaded}} by the LOAD PSW {{instruction}} (LPSW or LPSWE). Its contents may be examined with the <b>Extract</b> PSW <b>instruction</b> (EPSW).|$|R
5000|$|Conditional random fields (CRF) are {{commonly}} {{used in conjunction with}} IE for tasks as varied as extracting information from research papers to <b>extracting</b> navigation <b>instructions.</b>|$|R
40|$|Embedded {{processors}} {{are increasingly}} deployed in applications requiring high performance with good real-time characteristics whilst being low power. Parallelism {{has to be}} extracted {{in order to improve}} the performance at an architectural level. <b>Extracting</b> <b>instruction</b> level parallelism requires extensive speculation which adds complexity and increases power consumption. Alternatively, parallelism can be provided at the thread level. Many embedded applications can be written in a threaded manner in Java which can be directly translated to use hardware-level multithreaded operations. This paper presents an architectural study of JMA, a high-performance multithreaded architecture which supports Java-multithreading and realtime scheduling whilst remaining low-power. 1...|$|R
40|$|A {{significant}} {{fraction of}} the circuitry in a modern processor is dedicated to converting the linear instruction stream into a representation that allows the execution of instructions in data dependence order, rather than program order, to <b>extract</b> <b>instruction</b> level parallelism. All errors caused by hardware faults in this circuitry—which includes the fetch and decode stages, renaming and scheduling logic, {{as well as the}} commit stage—will manifest themselves as incorrectly constructed dataflow graphs. Dynamic Dataflow Verification (DDFV) compares the dynamically constructed and executed dataflow graph to the expected dataflow graph of the static program binary, represented by a signature embedded in the instruction stream. The signature compariso...|$|E
40|$|We {{describe}} a VLIW architecture designed speci cally {{as a target}} for dynamic compilation of an existing instruction set architecture. This design approach o ers the simplicity and high performance of statically scheduled architectures, achieves compatibility with an established architecture, and makes use of dynamic adaptation. Thus, the original architecture is implemented using dynamic compilation, a process we refer to as DAISY (Dynamically Architected Instruction Set from Yorktown). The dynamic compiler exploits runtime pro le information to optimize translations so as to <b>extract</b> <b>instruction</b> level parallelism. This work reports di erent design trade-o s in the DAISY system, {{and their impact on}} nal system performance. The results show high degrees of instruction parallelism with reasonable translation overhead and memory usage...|$|E
30|$|Whitham {{discusses}} {{that the}} execution {{time of a}} basic block has to be independent of the execution history [16]. As a consequence, his MCGREP architecture reduces pipelining to two stages (fetch and execute) and avoids caches all together. To reduce the WCET, Whitham proposes to implement the time-critical functions in microcode on a reconfigurable function unit (RFU). The main processor implements an RISC ISA as a microprogrammed, sequential processor. The interesting approach in MCGREP is that the RFUs implement the same architecture and microcode as the main CPU. Therefore, mapping a sequence of RISC instructions to microcode for one or several RFUs is straightforward. With several RFUs, {{it is possible to}} explicitly <b>extract</b> <b>instruction</b> level parallelism (ILP) from the original RISC code in a similar way to VLIW architectures.|$|E
40|$|This paper {{deals with}} retargetable {{compiler}} generation. After {{an introduction to}} application-specific instruction set processor design and a review of code generation in compiler backends, ISAC architecture description language is introduced. Automatic approach to instruction se-mantics extraction from ISAC models which result is usable for backend generation is presented. This approach was successfully tested on three models of MIPS, ARM and TI MSP 430 architec-tures. Further backend generation process that uses <b>extracted</b> <b>instruction</b> is semantics presented. This process was currently tested on the MIPS architecture and some preliminary results are shown. Digital Object Identifier 10. 4230 /OASIcs. MEMICS. 2010. 47...|$|R
5000|$|... #Caption: A homebrewing kit {{consisting}} of hopped malt <b>extract,</b> yeast and <b>instructions</b> ...|$|R
40|$|Closely {{coupling}} a reconfigurable fabric with {{a conventional}} processor {{has been shown}} to successfully improve the system performance. However, today's superscalar processors are both complex and adept at <b>extracting</b> <b>Instruction</b> Level Parallelism (ILP), which introduces many complex issues to the design of a hybrid CPU-RFU system. This paper examines the design of a superscalar processor augmented with a closely-coupled reconfigurable fabric. It identifies architectural and compiler issues that affect the performance of the overall system. Previous efforts at combining a processor core with a reconfigurable fabric are examined in the light of these issues. We also present simulation results that emphasize the impact of these factors...|$|R
40|$|The Multiscalar {{architecture}} executes {{a single}} sequential program following multiple flows of control. In the Multiscalar hardware, a global sequencer, {{with help from}} the compiler, takes large steps through the program's control flow graph (CFG) speculatively, starting a new thread of control (task) at each step. This is inter-task control flow speculation. Within a task, traditional control flow speculation is used to <b>extract</b> <b>instruction</b> level parallelism. This is intra-task control flow speculation. This paper focuses on mechanisms to implement intertask control flow speculation (task prediction) in a Multiscalar implementation. This form of speculation has fundamental differences from traditional branch prediction. We look in detail at the issues of prediction automata, history generation and target buffers. We present implementations in each of these areas that offer good accuracy, size and performance characteristics. Keywords: Multiscalar Architecture, Control-flow Speculation, [...] ...|$|E
40|$|Abstract — In this paper, {{we present}} a novel {{approach}} to detect unknown virus using dynamic instruction sequences mining techniques. We collect runtime instruction sequences from unknown executables and organize instruction sequences into basic blocks. We <b>extract</b> <b>instruction</b> sequence patterns based on three types of instruction associations within derived basic blocks. Following a data mining process, we perform feature extraction, feature selection and then build a classification model to learn instruction association patterns from both benign and malicious dataset automatically. By applying this classification model, we can predict the nature of an unknown program. We also build a program monitor which is able to capture runtime instruction sequences of an arbitrary program. The monitor utilizes the derived classification model to make an intelligent guess {{based on the information}} extracted from instruction sequences to decide whether the tested program is benign or malicious. Our result shows that our approach is accurate, reliable and efficient...|$|E
40|$|With the {{flexibility}} of the FPGA, reconfigurable systems are able to get significant speedups for some applications. Several architectures have been proposed to integrate a processor with an FPGA in the same chip. Based on the role played by the FPGA, we can divide these architectures into two categories: FPGA as a coprocessor or FPGA as a reconfigurable functional unit (RFU). This thesis describes a C compiler for Chimaera, which is a processor/RFU architecture. First, it talks about the construction of a compiler framework based on the GCC compiler. Second, it presents three compilation techniques to <b>extract</b> <b>instruction</b> sequences from the applications {{so that they can be}} mapped onto the RFU. Next, it discusses the building of the simulator for the Chimaera architecture. Finally, it presents some experimental results, which evaluate both the compiler techniques and the architecture. The average speedup of all the benchmarks is 2. 6. This thesis makes three contributions. First, it desc [...] ...|$|E
5000|$|In {{a packet}} {{switched}} network, burst switching is a capability {{in which each}} network switch <b>extracts</b> routing <b>instructions</b> from an incoming packet header {{to establish and maintain}} the appropriate switch connection {{for the duration of the}} packet, following which the connection is automatically released.|$|R
40|$|The {{problem of}} <b>extracting</b> <b>Instruction</b> Level Parallelism at levels of 10 {{instructions}} per clock and higher is considered. Two different architectures which use speculation on memory accesses {{to achieve this}} level of performance are reviewed. It is pointed out that while this form of speculation gives high potential parallelism {{it is necessary to}} retain execution state so that incorrect speculation can be detected and subsequently squashed. Simulation results show that the space to store such state is a critical resource in obtaining good speedup. To make good use of the space it is essential that state be stored efficiently and that it be retired as soon as possible. A number of techniques for extracting the best usage from the available state storage are introduced...|$|R
50|$|These <b>instructions</b> <b>extracts</b> the {{fractional}} part of floating point, {{that is the}} part that would be lost in conversion to integer.|$|R
40|$|The {{complexity}} of uniprocessor design attempting to <b>extract</b> <b>instruction</b> level parallelism has motivated the computer architects to leverage parallelism through multiple simple cores {{on a single}} chip. Also, with continuous advancement in chip technology chip multiprocessors (CMP) have become a reality. Multicores are becoming ubiquitous, not only in general-purpose but also embedded computing. However, on such platforms prediction of timing behavior of real-time tasks is becoming increasingly difficult. While real-time multicore scheduling approaches help to assure deadlines based on firm theoretical properties, their reliance on task migration poses a significant challenge to timing predictability in practice. Task migration actually (a) reduces timing predictability for contemporary multicores due to cache warm-up overheads while (b) increasing traffic on the network-on-chip (NoC) interconnect. 2. Related Work Real-time tasks are usually periodic in nature {{and have to be}} completed before a predefined deadline. Missing a deadline could have serious consequences for hard real time systems. Recent work has shown that the impact of task migration could lead t...|$|E
40|$|In this {{dissertation}} a new {{architecture is}} described and analyzed {{to determine its}} capability to <b>extract</b> <b>instruction</b> level parallelism from applications written in the C programming language. The architecture is novel in its use of multiple independent instructions streams to exploit the very fine grained parallelism found in these applications. The research consists of three parts: {{the development of the}} new architecture, the development of a compiler model to translate the source program into machine code for that architecture {{and the development of a}} new cache structure capable of satisfying data requests at a sufficiently high rate to feed the processor without performance degradation. Keywords: decoupled architecture, instruction level parallelism, compiler design, cache organization. ii Contents 1 Introduction 1 1. 1 Finding Parallelism in a Program : : : : : : : : : : : : : : : : : : : 1 1. 1. 1 Instruction Pipelining : : : : : : : : : : : : : : : : : : : : : 1 1. 1. 2 Instructi [...] ...|$|E
40|$|Hardware accelerators are {{an energy}} {{efficient}} alternative to general purpose processors for specific program regions. They {{have relied on}} the compiler to <b>extract</b> <b>instruction</b> level parallelism but may waste significant energy in memory disambiguation and discovering memory level parallelism (MLP). Currently, accelerators either i) Define the problem away, and rely on massively parallel programming models [1, 48] to extract MLP. ii) Reuse the Out of Order (OoO) processor [7, 28], and rely on power hungry load-store queues (LSQs) for memory disambiguation, or iii) Serialize – some accelerators [47] focus on program regions where MLP is not important and simply serialize memory operations. We present NACHOS, a compiler assisted energy efficient approach to memory disambiguation, which completely {{eliminates the need for}} an LSQ. NACHOS classifies memory operations pairwise into those that don’t alias (i. e., independent memory operations), must alias (i. e., ordering is required between memory operations), and may alias (i. e., compiler is unsure). To enforce program order between must alias memory operations, the compiler inserts ordering edges that are enforced as def-use data dependencies. When the compiler is unsure (i. e., may alias) about a pair of memory operations, the hardware checks if they are independent. We demonstrate that compiler alias analysis with additional refinement can achieve high accuracy for hardware accelerated regions. In our workload suite comprising of SPEC 2 k, SPEC 2 k 6, and PARSEC workloads; Across 15 applications NACHOS imposes no energy overhead over the function units (i. e., compiler resolves all dependencies), and in another 12 applications NACHOS consumes = 17 % of function unit energy (max: 53 % in povray). Overall NACHOS achieves performance similar to an optimized LSQ and adds an overhead equal to 2. 3 X of compute energy...|$|E
40|$|<b>Extracting</b> <b>instruction</b> level {{parallelism}} is a {{key issue}} in superscalar architecture. We propose a graph theoretic model to identify parallelism in a sequence of instructions. The System Graph Model (SGM), presented here, is a fundamental source of information regarding the resource dependencies, intra-instruction and interinstruction parallelism, and the cost-performance of the architecture. Additionally, we propose a new technique called Hierarchical Identification of Parallelism (HIP), which is a systematic approach to identify parallelism. Using this technique, an optimizing compiler can obtain a better static schedule of the assembly level instructions. For {{better understanding of the}} techniques developed, we have presented a case study of Hewlett-Packard's PARISC microprocessor. Finally, we discuss potential application of the proposed graph model in architectural level testing. 1 INTRODUCTION In the realm of superscalar computing the most fundamental issue is the identification [...] ...|$|R
40|$|This paper {{describes}} a single chip Multiple Instruction Stream Computer (MISC) capable of <b>extracting</b> <b>instruction</b> level parallelism {{from a broad}} spectrum of programs. The MISC architecture uses multiple asynchronous processing elements to separate a program into streams that can be executed in parallel, and integrates a conflict-free message passing system into the lowest level of the processor design to facilitate low latency intra-MISC communication. This approach allows for increased machine parallelism with minimal code expansion, and provides an alternative approach to single instruction stream multi-issue machines such as SuperScalar and VLIW. # # 1. Introduction The goal of most high-performance computers is to maximize the amount of work that can be done per unit time. This quantity (work) can be expressed by the following equation [HePa 90]: work = clock rate× instruction count 1 ############### × Clocks per Instruction 1 ################### A number of different approa [...] ...|$|R
40|$|This paper {{describes}} a single chip Multiple Instruction Stream Computer (MISC) capable of <b>extracting</b> <b>instruction</b> level parallelism {{from a broad}} spectrum of programs. The MISC architecture uses multiple asynchronous processing elements to separate a program into streams that can be executed in parallel, and integrates a conflict-free message passing system into the lowest level of the processor design to facilitate low latency intraMISC communication. This approach allows for increased machine parallelism with minimal code expansion, and provides an alternative approach to single instruction stream multi-issue machines such as SuperScalar and VLIW. 1. The MISC Design The MISC processor, a direct descendant of the PIPE project [CGKP 87, GHLP 85] will exploit both the instruction and data parallelism available in a task by combining the capabilities of traditional data parallel architectures with those found in machines designed to exploit instruction level parallelism. Unlike the two pro [...] ...|$|R
40|$|In modern high {{performance}} microprocessors, {{there has been}} a trend toward increased superscalarity and deeper speculation to <b>extract</b> <b>instruction</b> level parallelism. As issue rates rise, more aggressive instruction fetch mechanisms are needed to be able to fetch multiple basic blocks in a given cycle. One such fetch mechanism that shows a great deal of promise is the trace cache, originally proposed by Rotenburg, et. al. In this thesis, critical design issues regarding the trace cache fetch mechanism are explored in order to develop techniques to further improve trace cache performance. The thesis research presents an optimized trace cache design that show an average 34. 9 % improvement for integer benchmarks and 11. 0 % improvement for floating-point benchmarks, relative to the originally proposed trace cache design. This corresponds to a 67. 9 % and 16. 3 % improvement in fetch bandwidth over a traditional instruction cache, for integer and floating -point benchmarks respectively. The results demonstrate the viability of the trace cache as a {{high performance}} fetch mechanism and provide justification for additional research. Thesis Supervisor: Arvind Title: Professor of Computer Science and Engineering ii Acknowledgments First and foremost, I would like to express my gratitude to my Mom and Dad, for all their love and encouragement throughout the years. I definitely would not be where I am today, {{had it not been for}} them. I also want to thank my little sister, Emily, who has always made me feel important and special. To Marilyn, I give my utmost appreciation and thankfulness. I wish I could show her how grateful I am for her unconditional support. She has been an inspiration to me, patiently sticking by my side through the countless days and nights while I worked on my th [...] ...|$|E
40|$|ILP {{is one way}} of {{effectively}} {{using the}} large number of transistors available on modern CPUs. Two different architectures which use speculation on memory accesses to do this are reviewed. While this form of speculation gives high potential parallelism, it is necessary to retain execution state so that the incorrect speculation can be detected and subsequently squashed. It is shown by theoretical arguments and simulation that the space to store such state is a critical resource in obtaining good speedup. The state must be stored efficiently and retired as soon as possible. It is also shown that larger problem sizes may achieve lower extracted parallelism, despite having a higher potential parallelism. 1 Introduction Increasingly computer architects and system designers seek to extract more computer performance by making use of parallelism. There are a number of ways of approaching this. This paper considers the problem of <b>extracting</b> <b>instruction</b> level parallelism (ILP), that is, paral [...] ...|$|R
40|$|AbstractBasic block {{vectorization}} {{consists in}} <b>extracting</b> <b>instruction</b> level parallelism inside basic blocks {{in order to}} generate SIMD instructions and thus speedup data processing. It is however a double-edged technique, because the vectorized program may actually be slower than the original one. Therefore, {{it would be useful}} to predict beforehand whether or not vectorization could actually produce any speedup. In this article, we propose to do so by using a machine learning technique called support vector machine. We consider a benchmark suite containing 151 loops, unrolled with factors ranging from 1 to 20. We do our prediction offline after as well as before unrolling. Our contribution is threefold. First, we manage to predict correctly the profitability of vectorization for 70 % of the programs in both cases. Second, we propose a list of static software characteristics that successfully describe our benchmark with respect to our goal. Finally, we determine that machine learning makes it possible to significantly improve the quality of the code generated by Intel Compiler, with speedups up to 2. 2 times...|$|R
40|$|Abstract — The issue queue {{keeps the}} {{instructions}} that {{are waiting for}} the availability of input operands and issue slots. While some instructions remain for a few cycles in the issue queue, the instructions dependent on L 2 misses may remain there for hundreds of cycles due to the L 2 miss latency. Some authors have proposed mechanisms to <b>extract</b> these <b>instructions</b> from the issue queue. However, these mechanisms increase the issue-queue activity because the <b>extracted</b> <b>instructions</b> must be replayed, that is, issued twice (at least). Firstly, to be extracted from the issue queue. Secondly, after resolving the L 2 miss, to be executed. We propose delaying the insertion of some instructions in the issue queue. After predicting which load instructions are going to miss in L 2, the instructions dependent on these load instructions will be stored in an instruction buffer instead of being inserted in the issue queue. After resolving the miss, the instruction buffer will be traversed in order to insert in the issue queue the instructions dependent on the resolved memory access. The advantages of this proposal with respect to proposals that extract from the issue queue the instructions dependent on L 2 misses are twofold. First, it avoids filling the issue queue with instructions dependent on L 2 misses. Second, it reduces the amount of instruction replays. The evaluations show that delaying the insertion of instructions in the issue queue reduces the amount of instruction replays between 27 % and 31 % in integer benchmarks and between 33 % and 39 % in floating-point benchmarks with respect to processors that extract from the issue queue the instructions dependent on L 2 misses. The evaluations also show that this replay reduction does not harm processor performance. Index Terms — Instruction issue, L 2 hit/miss prediction, Instruction replays...|$|R
5000|$|In a {{preface to}} the 1905 (and, later, 1912) edition, [...] {{published}} as a popular edition by Methuen, Robert Ross, Wilde's literary executor, published an <b>extract</b> from Wilde's <b>instructions</b> to him which included the author's own summation of the work: ...|$|R
40|$|The {{practice}} of using speculation in resolving data dependences based on value prediction {{has been studied}} {{as a means of}} <b>extracting</b> more <b>instruction</b> level parallelism. There are many studies on value prediction mechanisms with high predictabilities. However, {{to the best of our}} knowledge, the influence of compiler optimizations on value prediction has not been investigated. In this paper, we evaluate the efficiency of value prediction on several binaries, which are compiled with different optimization levels. Detailed simulations reveal that value prediction is still effective for highly optimized binaries...|$|R
40|$|Thread level {{parallelism}} (TLP) {{has become}} a popular trend to improve processor performance, overcoming the limitations of <b>extracting</b> <b>instruction</b> level parallelism. Each TLP paradigm, such as Simultaneous Multithreading or Chip-Multiprocessors, provides di erent bene ts, which has motivated processor vendors to combine several TLP paradigms in each chip design. Even if most of these combined-TLP designs are homogeneous, they present di erent levels of hardware resource sharing, which introduces complexities on the operating system scheduling and load balancing. Commonly, processor designs provide two levels of resource sharing: Inter-core in which only {{the highest levels of}} the cache hierarchy are shared, and Intracore in which most of the hardware resources of the core are shared. Recently, Sun Microsystems has released the UltraSPARC T 2, a processor with three levels of hardware resource sharing: InterCore, IntraCore, and IntraPipe. In this work, we provide the rst characterization of a three-level resource sharing processor, the UltraSPARC T 2, and we show how multi-level resource sharing a ects the operating system design. We further identify the most critical hardware resources in the T 2 and the characteristics of applications that are not sensitive to resource sharing. Finally, we present a case study in which we run a real multithreaded network application, showing that a resource sharing aware scheduler can improve the system throughput up to 55...|$|R
40|$|Extensive {{research}} as {{been done on}} extracting parallelism from single instruction stream processors. This paper presents our investigation i to ways to modify MIMD architectures {{to allow them to}} <b>extract</b> he <b>instruction</b> level parallelism achieved by current superscalar and VLIW machines. A new architecture is proposed which utilizes the advantages of a multiple instruction stream design while addressing some of the limitations that have prevented MIMD architec-tures from performing ILP operation. A new code scheduling mechanism is described to support his new architecture by partitioning instructions across multiple processing elements in order to exploit his level of parallelism...|$|R
40|$|Nowadays, {{numerous}} attacks {{made by the}} malware, such as viruses, backdoors, spyware, trojans and worms, {{have presented}} a major security threat to computer users. The most significant {{line of defense against}} malware is anti-virus products which detects, removes, and characterizes these threats. The ability of these AV products to successfully characterize these threats greatly depends on the method for categorizing these profiles of malware into groups. Therefore, clustering malware into different families is one of the computer security topics that are of great interest. In this paper, resting on the analysis of the <b>extracted</b> <b>instruction</b> of malware samples, we propose a novel parameter-free hybrid clustering algorithm (PFHC) which combines the merits of hierarchical clustering and K-means algorithms for malware clustering. It can not only generate stable initial division, but also give the best K. PFHC first utilizes agglomerative hierarchical clustering algorithm as the frame, starting with N singleton clusters, each of which exactly includes one sample, then reuses the centroids of upper level in every level and merges the two nearest clusters, finally adopts K-means algorithm for iteration to achieve an approximate global optimal division. PFHC evaluates clustering validity of each iteration procedure and generates the best K by comparing the values. The promising studies on real daily data collection illustrate that, compared with popular existing K-means and hierarchical clustering approaches, our proposed PFHC algorithm always generates much higher quality clusters and it can be well used for malware categorization...|$|R
40|$|This form {{provides}} an <b>extract</b> of the <b>instructions</b> included in Circular Number 52, Disposition of Unserviceable and Surplus Ordnance Stores, November 12, 1863 : Authority for Making Transfers of Property Must be Furnished. Also includes proper observations for officers invoicing ordnance stores. 28 X 22 cm. Single page, Double sided, tri-folded; Form Number 2 -(b) on back. 1 of 5 copies in folder...|$|R
50|$|Automated Linux From Scratch (ALFS) is {{a project}} {{designed}} to automate {{the process of creating}} an LFS system. It is aimed at users who have gone through the LFS and BLFS books several times and wish {{to reduce the amount of}} work involved. A secondary goal is to act as a test of the LFS and BLFS books by directly <b>extracting</b> and running <b>instructions</b> from the XML sources of the LFS and BLFS books.|$|R
40|$|Binary code reuse is {{the process}} of {{automatically}} identifying the interface and <b>extracting</b> the <b>instructions</b> and data dependencies of a code fragment from an executable program, so that it is self-contained and can be reused by external code. Binary code reuse is useful for a number of security applications, including reusing the proprietary cryptographic or unpacking functions from a malware sample and for rewriting a network dialog. In this paper we conduct the first systematic study of automated binary code reuse and its security applications. The main challenge in binary code reuse is understanding the code fragment’s interface. We propose a novel technique to identify the prototype of an undocumented code fragment directly from the program’s binary, without access to source code or symbol information. Further, we must also extract the code itself from the binary so that it is self-contained and can be easily reused in another program. We design and implement a tool that uses a combination of dynamic and static analysis to automatically identify the prototype and <b>extract</b> the <b>instructions</b> of an assembly function into a form that can be reused by other C code. The extracted function can be run independently {{of the rest of the}} program’s functionality and shared with other users. We apply our approach to scenarios that include extracting the encryption and decryption routines from malware samples, and show that these routines can be reused by a network proxy to decrypt encrypted traffic on the network. This allows the network proxy to rewrite the malware’s encrypted traffic by combining the extracted encryption and decryption functions with the session keys and the protocol grammar. We also show that we can reuse a code fragment from an unpacking function for the unpacking routine for a different sample of the same family, even if the code fragment is not a complete function. ...|$|R
