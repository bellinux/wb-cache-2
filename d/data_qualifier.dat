1|12|Public
40|$|This report {{documents}} {{the results of}} Quality Assurance activities conducted in conjunction with sampling performed by EPA's Environmental Monitoring and Assessment Program's Estuaries study (EMAP-Estuaries) in the Virginian Province from 1990 through 1993. As part of the planning stage for each years activities, a QA Plan was developed. All sampling and analytical activities were required to be conducted {{in accordance with the}} prescribed methods, and following the standards stated in the QA Plan. This report discusses the results of Quality Assurance activities by indicator, <b>data</b> <b>qualifier</b> flags, data quality, and, where appropriate, discusses lessons learned and proposes changes or solutions to improve data quality. Data collected in the Virginian Province from 1990 to 1993 were generally of high quality. A total of 446 Base Sampling Sites were scheduled for sampling over this period. Twenty one stations were eliminated due to inadequate water depth or logistical concerns. With the exception of total suspended solids (samples for this indicator were not collected in 1990), the success rate for all indicators exceeded 80 % (percent of stations with data passing QC), with most exceeding 85 %. Some significant problems were encountered in the chemical analysis of sediment samples resulting in the deletion of some data from the database. The specific problems, and a discussion of the data deleted or qualified are included in this report...|$|E
30|$|Observation-specific <b>data</b> <b>qualifiers</b> {{would be}} useful for the IWN to support user quality control {{information}} needs, but <b>data</b> <b>qualifiers</b> as defined in the WaterML 2 standard (e.g. <wml 2 :qualifier xlink>) are not yet supported in the 52  N SOS database model. Observation-specific qualifiers can be included with InsertObservation requests using the[*]<[*]om:parameter[*]>[*]tag in the current development branch for 52  N SOS, but cannot be entered in InsertResult requests. Implementation of wml 2 qualifiers and/or om parameters is desirable.|$|R
3000|$|QA/QC status. Although some {{providers}} (e.g. the US Geological Survey (...) [...]) {{are able}} to provide observation-specific <b>data</b> <b>qualifiers,</b> QC status is generally not consistently available, and is not directly represented in the catalog data model. QC status is instead encoded {{as part of the}} SOS procedures.|$|R
40|$|Home {{healthcare}} {{services are}} {{emerging as a}} new frontier in healthcare practices. Data reliability, however, is crucial for the acceptance of these new services. This work presents a semi-automated system to evaluate the quality of medical measurements taken by patients. The system relies on <b>data</b> <b>qualifiers</b> to evaluate various quality aspects of measurements. The overall quality of measurements is determined {{on the basis of}} these qualifiers enhanced with a troubleshooting mechanism. Namely, the troubleshooting mechanism guides healthcare professionals in the investigation of the root causes of low quality values...|$|R
40|$|This {{document}} {{describes the}} process {{used by the}} Surface Water Ambient Monitoring Program (SWAMP) Quality Assurance Team (QAT) and the SWAMP Data Management Team (DMT) to classify data batches and sample results that {{will be included in}} the SWAMP database. Data batches and sample results are assigned classifications based on conformance to SWAMP measurement quality objectives (MQOs), holding times, and other requirements specified in the Surface Water Ambient Monitoring Program Quality Assurance Program Plan (QAPrP). Once the results have been classified and moved to the permanent side of the SWAMP database, the classification level can be used to evaluate comparability across SWAMP datasets. 2. Responsibilities The SWAMP QAT is responsible for designing and finalizing the SWAMP data classification system. This includes creating and defining the classification levels and assigning the relationships between <b>data</b> <b>qualifiers</b> and classification levels. The SWAMP DMT is responsible for creating and defining the program’s <b>data</b> <b>qualifiers.</b> They then assign these qualifiers to contract laboratory data batches and sample results during their data verification and classification process. Finally, the DMT ensures that the correct compliance level is associated with each data batch. The SWAMP Roundtable is responsible for reviewing and approving these procedures. The Roundtable also provides guidance on program-wide issues. Program end users are responsible for determining {{the degree to which they}} want to incorporate SWAMP data classification in their data assessment...|$|R
5000|$|Type qualifiers {{are a way}} {{of expressing}} {{additional}} information about a value through the type system, and ensuring correctness {{in the use of}} the <b>data.</b> Type <b>qualifiers</b> are not generally used outside the C/C++ family of languages: many languages have a notion of constants, but express this by the name binding being constant (a [...] "variable that doesn't vary"), rather than through the type system; see alternatives, below.|$|R
40|$|The {{samples were}} {{received}} {{in accordance with}} the Chain of Custody and no significant deviations were encountered during the preparation or analysis unless otherwise noted. Sample Receipt, Container Information, and the Chain of Custody are located {{at the back of the}} report. Results contained within this report relate only to the samples submitted under this Alpha Lab Number and meet all of the requirements of NELAC, for all NELAC accredited parameters. The data presented in this report is organized by parameter (i. e. VOC, SVOC, etc.). Sample specific Quality Control data (i. e. Surrogate Spike Recovery) is reported at the end of the target analyte list for each individual sample, followed by the Laboratory Batch Quality Control at the end of each parameter. If a sample was re-analyzed or re-extracted due to a required quality control corrective action and if both sets of data are reported, the Laboratory ID of the re-analysis or re-extraction is designated with an "R " or "RE", respectively. When multiple Batch Quality Control elements are reported (e. g. more than one LCS), the associated samples for each element are noted in the grey shaded header line of each data table. Any Laboratory Batch, Sample Specific % recovery or RPD value that is outside the listed Acceptance Criteria is bolded in the report. Definitions of all <b>data</b> <b>qualifiers</b> and acronym...|$|R
5000|$|The Higher Education Statistics Agency gathers and publishes annual {{statistics}} {{relating to}} the higher qualifications awarded in the UK. The Students and <b>Qualifiers</b> <b>data</b> sets indicate {{that the percentage of}} [...] "GOOD" [...] first degree classifications have increased annually since 1995. For example, 7% of all first-degree students who graduated in the academic year 1995/96 achieved first class honours; by 2008/09 this had risen to 14%.|$|R
5000|$|Types can be {{qualified}} to indicate special properties of their <b>data.</b> The type <b>qualifier</b> [...] {{indicates that a}} value does not change once it has been initialized. Attempting to modify a [...] qualified value yields undefined behavior, so some C compilers store them in rodata or (for embedded systems) in read-only memory (ROM). The type qualifier [...] indicates to an optimizing compiler {{that it may not}} remove apparently redundant reads or writes, as the value may change even if it was not modified by any expression or statement, or multiple writes may be necessary, such as for memory-mapped I/O.|$|R
40|$|Eye {{tracking}} is a {{field that}} has been growing immensely over the last decade. Accompanying this growth {{is a need for}} simplified and automatic analysis of eye tracking data. A part of that analysis is eye movement classification, and while there are many adequate classification methods for fixations and saccades, the tools for smooth pursuit classification are still lacking. This thesis gives an overview of the field,and analyses five different methods for classifying smooth pursuits, fixations,and saccades. The analysis also explores evaluation methods that avoid the laborious way of manually tagging data to get a reference classification. Despite earlier reports of decent performance, the overall results for all the analysed algorithms is poor. In particular, the slowest pursuits are consistently misclassified. Most certainly, the inclusion of the slow pursuits have skewed the results, but even disregarding them doesn’t yield particularly impressive results. This begs the question of what concessions one has to make in terms of prerequisites on the <b>data,</b> or <b>qualifiers</b> for the resulting analysis, to achieve adequate performance,and given those, when would such a classification be preferred to something tailored to the problem at hand...|$|R
40|$|Quality {{assurance}} (QA) {{objectives for}} Phase 2 were that (1) scientific data generated would withstand scientific and legal scrutiny; (2) data would be gathered using appropriate procedures for sample collection, sample handling and security, chain of custody, laboratory analyses, and data reporting; (3) data {{would be of}} known precision and accuracy; and (4) data would meet data quality objectives defined in the Phase 2 Sampling and Analysis Plan. A review of the QA systems and quality control (QC) data associated with the Phase 2 investigation is presented to evaluate whether the data were of sufficient quality to satisfy Phase 2 objectives. The data quality indicators of precision, accuracy, representativeness, comparability, completeness, and sensitivity were evaluated to determine any limitations associated with the data. Data were flagged with qualifiers that were associated with appropriate reason codes and documentation relating the qualifiers to the reviewer of the <b>data.</b> These <b>qualifiers</b> were then consolidated into an overall final qualifier to represent {{the quality of the}} data to the end user. In summary, reproducible, precise, and accurate measurements consistent with CRRI objectives and the limitations of the sampling and analytical procedures used were obtained for the data collected in support of the Phase 2 Remedial Investigation...|$|R
40|$|This study {{examines}} {{the structure of}} environmental argumentation through {{two of the most}} influential environmental comments of our time. As milestones of the popular environmental debate, Rachel Carson's Silent Spring and Al Gore's An Inconvenient Truth have participated in shaping environmental consciousness and politics. The aim is to explicate and compare how, why and based on what environmental issues are constructed as problems and what kind of rhetorical means are used in the process. Carson's novel about the dangers of pesticides and Gore's global warming documentary are discussed in the context of Stephen Toulmin's theory of rhetoric. Focusing on the structures of natural argumentation, it offers a convenient theoretical and methodological framework for approaching persuasive environmental argumentation. The elements essential for 'logically candid argumentation' – <b>data,</b> warrant, backing, <b>qualifier,</b> rebuttal and conclusion – are examined and discussed on the macro-level and placed in the argument diagram. A Toulminian analysis of environmental argumentation and rhetoric reveals striking similarities between the arguments of Silent Spring and An Inconvenient Truth. Both Gore and Carson base their claims on scientific data and based on this empirical evidence, a normative conclusion stating the absolute necessity of the recommended measures is drawn. The demand for action is warranted by the desirability of ensuring the future of 'our' planet, and the advantages of taking action are further underlined by the backings presented. A multi-field strategy of backing appears as an essential feature in persuasive environmental argumentation – the desirability of taking action is presented in terms of anthropocentric, ecosystemic and financial benefit and as morally just and aesthetically inspiring. Respectively, also differences in argumentation can be characterized. Whereas Carson indicates uncertainty in the science forming the data, Gore declares the grounds of his conclusion as absolutely certain – still, Carson effortlessly draws a certain conclusion based on uncertain grounds. Gore's personal authority plays {{a crucial role in the}} construction of his comment, leaving no room for rebuttal; for Carson, the reaction is left, in principle, for the public to decide. In addition to the similarity in patterning the argument as a whole, Silent Spring and An Inconvenient Truth share one more feature distinctively present in all elements of argumentation. Sharp critique towards the dominance of anthropocentrism, technology and economy dictating the relationship to nature is constantly presented – global warming and chemical contamination are manifestations of the profound distortion of human-environment relationship. Curiously enough, the keys for solving the problem are placed in the hands of the human race and its technological achievements – also, taking action is encouraged with the promise of financial gain. The logic behind the solutions provided participates in further enforcing the dominance it criticizes...|$|R
40|$|This study aims {{at finding}} {{out how the}} two presidential nominees “Hillary Clinton” and “Barack Obama” from Democratic Party {{formulate}} their claim, <b>data,</b> warrant, rebuttal, <b>qualifier,</b> and backing on their argumentative statements. This is a descriptive qualitative research. The data {{of this study are}} the transcripts which were taken from three times debates during primary elections season. Those three debates are debate on January 31 st, 2008 in Hollywood, California sponsored by CNN, The Los Angles Times and Politico, on February 21 st, 2008 in Austin Texas sponsored by CNN, and debate on February 26 th, 2008 in Cleveland, Ohio sponsored by MSNBC. The debates were taken from www. cnn. com and www. nytimes. com. The Toulmin’s model and the criteria of recognizing argumentative elements by Zahro are utilized to recognize the argumentative elements in the candidates’ statements. The procedure proposed by Miles and Huberman is applied to analyze the data. The result {{of this study is that}} both Barack Obama and Hillary Clinton had delivered convincing arguments in the debates due to the fact that they had fulfilled criteria of forming an argument as stated by Toulmin. The domestic policies which were mostly debated are Health care issue, Mortgage crisis, Immigration, and Economy. There are many ways of Obama and Clinton in formulating their argumentative statements. Obama had eighteen ways in delivering his arguments. Those are he proposed policy claim followed by fact, policy claim followed by data and motivational warrant, policy claim followed by rebuttal, policy claim and no data supporting the claim, policy claim followed by fact and substantive warrant, factual claim followed by rebuttal, factual claim followed by fact, factual claim followed by statistical data, factual claim but no data supporting the claim, factual claim with qualifier followed by fact, value claim with data inside the claim, value claim but no data supporting the claim, value claim followed by information and motivational warrant, value claim followed by information, value claim followed by rebuttal, fact followed by policy claim and motivational warrant, authoritative warrant followed by policy claim and data, and fact followed by value claim. Meanwhile, Clinton had twenty one ways in delivering her arguments. Those are policy claim followed by information, policy claim followed by fact, policy claim with qualifier followed by information, policy claim followed by observation result, policy claim with fact inside the claim, policy claim with qualifier followed by information and authoritative warrant, policy claim followed by statistical data, policy claim followed by rebuttal, policy claim with example inside the claim, policy claim with fact inside followed by motivational warrant, policy claim but no data supporting the claim, policy claim followed by information and authoritative warrant, factual claim with qualifier followed by information, factual claim followed by narrative, factual claim but no data supporting the claim, value claim with qualifier followed by rebuttal, value claim followed by information, value claim followed by substantive warrant and narrative, value claim followed by fact, value claim but no data supporting the claim, value claim with fact inside followed by substantive warrant. Generally, Obama and Clinton proposed their claims in the form of complete declarative sentence. The most common words Obama and Clinton used are the words “I think” and “I believe” before they proposed their claims. Moreover, they used the linguistic indicator “so” and “consequently” in proposing claims. And, oftentimes, they used reason indicator “because”, “the reason is [...] ” in their data. In those three debates Obama used qualifier “extensively” and “absolutely” in his claim, while Clinton used qualifier “absolutely”, “necessarily”, “obviously”, “passionately”, and “certainly” in her claims. In proposing rebuttal, Obama used linguistic indicator “but”, “if [...] ”, and “otherwise”, while Clinton used linguistic indicator “if [...] ”, “but,if [...] ” and “except”...|$|R

