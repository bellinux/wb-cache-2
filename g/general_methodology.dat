2683|1083|Public
25|$|The director's {{commentary}} on the McCabe & Mrs. Miller DVD, while focusing on that film, also to some degree covers Altman's <b>general</b> <b>methodology</b> as a director.|$|E
25|$|A <b>general</b> <b>methodology</b> and {{epistemology}} {{of engineering}} {{can be inferred}} from the historical case studies and comments provided by Walter Vincenti. Though Vincenti's case studies are from the domain of aeronautical engineering, his conclusions can be transferred into many other branches of engineering, too.|$|E
2500|$|The <b>general</b> <b>methodology</b> of the LRR was {{to build}} a line into an area, {{complete}} the logging operation, then remove the line. [...] In all, the LRR built [...] of track, none of which still exists.|$|E
5000|$|Given the {{complexity}} of RWA, there are two <b>general</b> <b>methodologies</b> for solving the problem: ...|$|R
30|$|Finally, 4 papers {{cited the}} use of <b>general</b> <b>methodologies,</b> that is, they were not {{classified}} as guidelines or Best practices. Among these papers, paper [W 37] stands out because it makes a comparative study between methodologies applied in Linked Open Data and Digital Libraries and thus references 12 methodologies, in which 5 guidelines are included.|$|R
40|$|Knowledge {{engineering}} {{has shown}} that besides the <b>general</b> <b>methodologies</b> from software engineering {{it is useful to}} develop special purpose methodologies for knowledge based systems (KBS). PROforma is a newly developed methodology for a specific type of knowledge based systems. PROforma is intended for decision support systems and in particular for clinical procedures in the medical domain. This pape...|$|R
2500|$|The {{preceding}} {{claim is}} based on Stiglitz 1986 paper, [...] "Externalities in Economies with Imperfect Information and Incomplete Markets", which describes a <b>general</b> <b>methodology</b> to deal with externalities and for calculating optimal corrective taxes in a general equilibrium context. In the opening remarks for his prize acceptance [...] "Aula Magna", Stiglitz said: ...|$|E
2500|$|The {{variety of}} terms is {{basically}} the result of grouping software mechanisms that relate to a given aspect of software development. Automation specifically relates to exporting the function of an application or component (as an application programming interface (API)) {{so that it can}} be controlled by other applications instead of by human users only, [...]NET is a self-contained <b>general</b> <b>methodology</b> and technology to develop desktop and web applications written in a variety of just-in-time (JIT) compiled languages.|$|E
2500|$|During the interbellum period, Polish {{sociology}} {{was most}} {{closely related to}} the neopositivist currents of thought. During the communist time, in addition to unavoidable stress on the Marxist approach, Polish sociologists also pursued Znaniecki's humanistic sociology and other approaches. After the fall of communism, the Marxist approach became quickly marginalized; two major research institutions which advocated the Marxist approach to sociology - the Institute for Basic Problems of Marxism-Leninism and the Academy for Social Sciences were closed. Marxist themes are still present in Polish sociology, but are not dominant. No single theory or ideology has replaced it, although many Polish sociologists are adherents of theoretical liberalism. There is also a trend of a retreat from [...] "theory as such" [...] and from the <b>general</b> <b>methodology</b> of the social sciences. Studies into methodology of empirical research, both qualitative and quantitative, are popular.|$|E
30|$|Haase et al. [10] {{review the}} power {{estimation}} and power profiling strategies for WSNs. They categorize the WSN simulation tools from cycle accurate simulation to pure functional simulation into three groups: microcontroller emulators, operating system emulator, and network and system simulator. They mainly {{focus on the}} power consumption estimation. However, we consider more <b>general</b> <b>methodologies</b> of existing WSN simulation tools.|$|R
50|$|There are broad <b>general</b> <b>methodologies</b> used to {{calculate}} the density of a liquid at specific conditions. In order to discuss a specific methodology, one must choose a liquid that holds sufficient interest to warrant a calculation specific to it. EOS 87.3 is a density calculation for seawater; API chapter 11 specifies calculations pertaining to oil, fuels and natural gas liquids.|$|R
40|$|Abstract — This paper {{presents}} <b>general</b> <b>methodologies</b> {{for comparing}} distributed algorithms, which are exemplified by clustering algorithms in sensor networks. Significant metrics {{for evaluating the}} algorithms are introduced including aspects of a structural, analytical and simulative comparison. Finally a short, exemplary comparison of two clustering algorithms HEED and WCA is made. Index Terms — clustering algorithm, wireless sensor networks base station cluster-head cluster-member I...|$|R
5000|$|Mueller, K. [...] "Towards a <b>General</b> <b>Methodology</b> for Second-Order Science." [...] Systemics, Cybernetics And Informatics 12.5 (2014): 33-42.|$|E
50|$|Lehrberger, L.; Bourbeau, L.: Machine Translation: Linguistic Characteristics {{of machine}} {{translation}} Systems and <b>General</b> <b>Methodology</b> of Evaluation, Amsterdam/Filadelfia, John Benjamins, 1988.|$|E
5000|$|Choose a {{high level}} test plan where a <b>general</b> <b>methodology</b> is chosen, and {{resources}} such as people, computers, and software licenses are identified and acquired.|$|E
40|$|This {{thesis is}} focused on the methodological {{documents}} improvement of the company in the field of project management. The changes are based on the theoretical base, which is made up of the <b>general</b> project <b>methodologies</b> selected by the author. The first part describes two chosen methodologies, use of which, is based on knowledge of the company environment. The second part then describes the existing guidance documents that can be used as inspiration to create a new methodological document. The output of the thesis is the methodological project document, which takes into account both the principles and practices described in the context of <b>general</b> <b>methodologies,</b> current guidance documents and knowledge of the company environment...|$|R
40|$|Image {{rendering}} maps scene parameters {{to output}} pixel values; animation maps motion-control parameters to trajectory values. Because these mapping functions are usually multidimensional, nonlinear, and discontinuous, #nding input parameters that yield desirable output values {{is often a}} painful process of manual tweaking. Interactiveevolution and inverse design are two <b>general</b> <b>methodologies</b> for computer-assisted parameter setting in which the computer plays a prominent role. In this paper we present another such methodology...|$|R
40|$|We {{introduce}} <b>general</b> <b>methodologies</b> for benchmarking {{the availability}} and maintainability of computer systems. Our methodologies are based on fault injection, used to purposefully compromise availability and to bring systems to a state where maintenance is required. Our availability benchmarks leverage existing performance benchmarks for workload generation and data collection, measure availability in terms of quality of service variation over time, and can produce results in both detail-rich graphical presentations or in distilled numerical summaries. Ou...|$|R
5000|$|The Ossowscy {{acknowledged}} {{the existence of}} an approximate German-language equivalent to the expression [...] "science of science": [...] "Wissenschaftslehre". But they explained that, leaving aside Johann Gottlieb Fichte (1762-1814), who had called his whole philosophical speculation by that name, the term had been used in Germany chiefly to denote logic with <b>general</b> <b>methodology,</b> or logic with <b>general</b> <b>methodology</b> and questions usually included in epistemology. [...] "Wissenschaftslehre" [...] had also been used in almost the same sense by Bernard Bolzano (1781-1848) — as logic, understood in a very wide sense, later made familiar {{at the turn of the}} 20th century.|$|E
50|$|The <b>general</b> <b>methodology</b> of the LRR was {{to build}} a line into an area, {{complete}} the logging operation, then remove the line. In all, the LRR built 150 mi of track, none of which still exists.|$|E
50|$|Algorithm {{engineering}} {{focuses on the}} design, analysis, implementation, optimization, profiling and experimental evaluation of computer algorithms, bridging the gap between algorithm theory and practical applications of algorithms in software engineering.It is a <b>general</b> <b>methodology</b> for algorithmic research.|$|E
40|$|Online {{newspapers}} and magazines still {{find it difficult to}} let readers discover and just read news. A plethora of stories on the front (home) page, overuse of complex grids, vast navigation lists and advertising immaturity still prevail. This paper deals with the <b>general</b> <b>methodologies,</b> the specific mechanisms and the enabling technologies associated with the design and the developing of personalized electronic front pages. Three approaches are presented and their particular implementations are discussed and evaluated...|$|R
40|$|This diploma thesis {{addresses}} {{a project of}} evaluating {{the selection of a}} supplier for purchase of a chosen commodity. The theoretical part describes <b>general</b> <b>methodologies</b> of supplier evaluation and selection. It also includes information on the production process and commodity purchase. The analytical part focuses on evaluation and selection of a supplier based on a point rating, where the output is a recommendation of the best supplier, which receives the highest number of points...|$|R
40|$|The chapter {{deals with}} the methodologies focused on the seismic {{analyses}} of the so-called secondary (sometimes attachments) elements {{that are part of}} a construction whose seismic resistance is delegated to a primary resistant structure. Although secondary elements can be decontextualized from the primary resistant structures, they will be subjected to seismic action as well and, having their own structures, need to be modeled and analyzed by means of methods included in the <b>general</b> <b>methodologies</b> proper of seismic branch. Among the methodologies usually adopted for secondary element analyses, the Floor Response Spectra (FRS) -based analyses become popular due to their recognized simplicity. FRSs provide acceleration (consequently velocity and displacement) to which the secondary element (with a given period and damping) will be subjected to when attached (from which the alternative name attachments derives) to a given part of the structures such as a building floor (from which the name Floor Response Spectra derives). Given that FRS generation could require onerous numerical analyses, simplified expressions are proposed in literature and discussed in the following together with the <b>general</b> <b>methodologies</b> tailored to secondary element modeling and seismic analyses...|$|R
50|$|A <b>general</b> <b>methodology</b> and {{epistemology}} {{of engineering}} {{can be inferred}} from the historical case studies and comments provided by Walter Vincenti. Though Vincenti's case studies are from the domain of aeronautical engineering, his conclusions can be transferred into many other branches of engineering, too.|$|E
50|$|Recursive transcompiling {{can be used}} to {{distribute}} a language independent specification across many different technologies, with each technology potentially keeping an authoritative description of {{a different part of the}} specification. Recursive transcompiling provides the <b>general</b> <b>methodology</b> for distributing this authoritative information through the rest of the derivative code pipeline.|$|E
5000|$|The {{preceding}} {{claim is}} based on Stiglitz 1986 paper, [...] "Externalities in Economies with Imperfect Information and Incomplete Markets", which describes a <b>general</b> <b>methodology</b> to deal with externalities and for calculating optimal corrective taxes in a general equilibrium context. In it he considers a model with households, firms and a government.|$|E
2500|$|There are {{multiple}} methods for preparing {{data for the}} [...] that fall into two <b>general</b> <b>methodologies</b> – pool and molecular dynamics (MD) approaches (diagrammed in the figure). The pool based approach uses the protein’s amino acid sequence to create a massive pool of random conformations. This pool is then subjected to more computational processing that creates a set of theoretical parameters for each conformation based on the structure. Conformational subsets from this pool whose average theoretical parameters closely match known experimental data for this protein are selected.|$|R
40|$|Today's rapid {{development}} of Internet demands highly concurrent and distributed systems. In this context, {{it is interesting}} to note that correct protocol specifications can be derived from a given service specification of the application. The main objective of this thesis is to introduce protocol derivation and develop <b>general</b> <b>methodologies</b> for designing distributed systems. Protocol synthesis focuses on generating an error-free protocol specification automatically from a higher-level service specification and it is a very important step in the protocol development process. Petri net is a very powerful model for describing and analyzing distributed, concurrent and asynchronous systems; therefore, we use it in protocol synthesis. Furthermore, we review SOAP (Simple Object Access Protocol), Java RMI (Remote Method Invocation) and J 2 EE (Java 2 Platform, Enterprise Edition) technologies and discuss their usages in decentralized, distributed applications. This thesis gives an overview of protocol engineering background knowledge, presents several protocol synthesis methods using Petri nets, gives <b>general</b> <b>methodologies</b> of distributed system implementation and presents a distribution prototype: An example service specification is used to derive a corresponding abstract protocol specification, which is implemented with three different approaches: SOAP, Java RMI and J 2 EE. Finally, the performance of these different implementation approaches is compared...|$|R
40|$|Knowledge {{engineering}} {{has shown}} that besides the <b>general</b> <b>methodologies</b> from software engineering {{it is useful to}} develop special purpose methodologies for knowledge based systems (KBS). PROforma is a newly developed methodology for a specific type of knowledge based systems. PROforma is intended for decision support systems and in particular for clinical procedures in the medical domain. This paper reports on an evaluation study of PROforma, and on the trade-off that is involved between general purpose and special purpose development methods in Knowledge Engineering and Medical AI. Our method for evaluating PROforma is based on re-engineering a realistic system in two methodologies: the new and special purpose KBS methodology PROforma and the widely accepted, and more <b>general</b> KBS <b>methodology</b> CommonKADS. The four most important results from our study are as follows. Firstly, PROforma has some strong points which are also strong related to requirements of medical reasoning. Secondly, PRO [...] ...|$|R
50|$|A {{particular}} development team {{may also}} agree to programming environment details, such as which {{integrated development environment}} is used, and one or more dominant programming paradigms, programming style rules, or choice of specific software libraries or software frameworks. These details are generally not dictated by the choice of model or <b>general</b> <b>methodology.</b>|$|E
50|$|CrossFit {{programming}} is decentralized but its <b>general</b> <b>methodology</b> {{is used by}} thousands of private affiliated gyms, fire departments, law enforcement agencies, and military organizations including the Royal Danish Life Guards, {{as well as by}} some U.S. and Canadian high school physical education teachers, high school and college sports teams, and the Miami Marlins.|$|E
50|$|The Hanken PhD Programme {{corresponds}} {{to four years}} of full-time studies, during which students produce a doctoral thesis and complete 60 ECTS of coursework. The courses consist of 44 credits in the major and related subjects, and 16 credits in <b>general</b> <b>methodology,</b> philosophy of science, or other similar courses of a methodological nature.|$|E
40|$|Abstract. Requirements Evolution {{represents}} one of the major problems in developing computer-based systems. Current practice in Requirement Engineering relies on process-oriented methodologies, which lack of product features. The resulting scenario then is a collection of <b>general</b> <b>methodologies,</b> which do not take into account product features that may enhance our ability in monitoring and controlling Requirements Evolution. This paper shows empirical investigations of two industrial case studies. The results point out evolutionary product features and identify an Empirical Framework to analysing Requirements Evolution. This work represents a shift from process to product-oriented management of Requirements Evolution. ...|$|R
40|$|EET- 2008 European Ele-Drive Conference - Inter{{national}} Advanced Mobility Forum, GENEVE, SUISSE, 11 -/ 08 / 2008 - 13 / 08 / 2008 The French national MEGEVH project {{deals with}} energy management of hybrid electric vehicles (HEV). The {{objective is to}} provide <b>general</b> <b>methodologies</b> to model HEV and optimize their energy flows. A graphical modeling has been chosen to highlight energetic properties of the studied vehicles. In this paper an inversion-based methodology is used to define the control structure of the studied HEV. A parallel HEV with a clutch is taken as an example...|$|R
40|$|The {{success of}} Semantic Web will heavily rely on t h e {{availability}} of formal ontologies to structure machine understanding data. However, {{there is still}} a lack of <b>general</b> <b>methodologies</b> for ontology automatic learning and population, i. e. the generation of domain ontologies from various kinds of resources by applying natural language processing and machine learning techniques In this paper, t h e authors present an ontology learning and population system that combines both statistical and semantic methodologies. Several experiments have been carried out, demonstrating the effectiveness of the proposed approach...|$|R
