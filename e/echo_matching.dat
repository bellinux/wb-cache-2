0|28|Public
5000|$|Quinn {{signed for}} Sunderland in 1946, {{and made his}} debut early in the 1947-48 First Division season in a 4-2 win against Grimsby Town. According to the Sunderland <b>Echos</b> <b>match</b> report, [...] "despite his {{inexperience}} he showed a pleasing directness and unselfishness {{which was to be}} admired". He kept his place for the next two games, and when brought back in to face Liverpool in November, he scored twice in a 5-1 win. But {{by the end of the}} season, he had only made six appearances, and was allowed to leave for Third Division North club Darlington for a four-figure fee.|$|R
5000|$|When you get homesick, {{nothing will}} stop you {{returning}} to the arms of those you love...The European Cup didn't fancy Paolo. She wanted Steven, {{but it took a}} series of remarkable chat-up lines from the Liverpool manager to ensure his skipper got his wicked way.The only reason Liverpool weren't fatally wounded by a first half blitz is the fortunate fact immortals can't be destroyed.Gerrard and company have rewritten football [...] "possibilities" [...] throughout this campaign, but even the heroic efforts of Olympiakos, Juventus and Chelsea were rendered insignificant compared to this.It shouldn't have happened. Some of us aren't convinced it did. Only the pinch marks confirm it. We thought it was all over. It wasn't. The Liverpool <b>Echo</b> <b>match</b> report At the start of the second half, Liverpool made a substitution with Dietmar Hamann replacing Steve Finnan and also changed to a 3-5-2 formation to reduce the deficit, with Riise and Šmicer on the flanks, Alonso and Hamann as holding midfielders and Gerrard playing as an attacking midfielder. Liverpool had the best chance early on with Xabi Alonso sending an effort from 35 yd narrowly past Milan's right hand post. Two minutes later, Shevchenko forced a save from Dudek with a strong free kick from just outside the Liverpool box.|$|R
40|$|The {{synthetic}} aperture focusing technique (SAFT) {{has been shown}} to increase lateral resolution of appropriately acquired B-scan images [1, 2, 3, 4]. The requirements of very accurate transducer position information and a well understood divergent ultrasonic beam can make it difficult to incorporate the technique into conventional inspections or to use it on previously acquired data. By using a reference reflector and an <b>echo</b> locus <b>matching</b> procedure it is possible to ease the latter requirement so that data acquired using conventional focused or flat transducers can be enhanced using the SAFT process...|$|R
3000|$|Therefore, {{we propose}} {{a method to}} select the matched pole pairs from raw pole sets as the {{enhancement}} of RE-CC, called pre-match processing. The selection principle {{is based on the}} assumption mentioned earlier; that is, every radar displays same target scattering characteristics. In other words, the relative phase between poles of each reconstructed clean echo is approximately fixed, in spite of disparate absolute pole phase, which can be traced in (16). Assuming pole A and pole B are the raw pole sets stemmed from two different reconstructed clean <b>echoes,</b> the <b>matched</b> pole pairs can be selected by: [...]...|$|R
5000|$|Hellbound was {{initially}} rated X by the Motion Picture Association of America, {{which would have}} limited it to those 17 and older. Barker attributed this to preferring explicit displays of the grotesque rather than hinting at it. [...] Released December 1988 in the US, Hellbound grossed $12,090,735 (US) and £980,503 (UK). Critical response {{was initially}} mixed, and many critics cited stronger violence and an incoherent plot. Flimsy props and sets have also been criticized, as well as praised for their scope and design for such a low-budget picture. Critics later commended the film on strong visuals that <b>echo</b> and <b>match</b> Barker's own original. The film has a 50% approval rating on Rotten Tomatoes based on 20 reviews.|$|R
40|$|Triphenyltetrazolium {{chloride}} (TTC) staining and echocardiography (ECHO) are {{methods used}} to determine experimental myocardial infarction (MI) size, whose practical applicability should be expanded. Our objectives were to analyze the accuracy of ECHO in determining infarction size in rats during the first days following coronary occlusion and to test whether a simplified single measurement by TTC correctly indicates MI size, {{as determined by the}} average value for multiple slices. Infarction was induced in female Wistar rats by coronary artery occlusion and MI size analysis was performed after the acute (7 th day) and chronic periods (after 4 weeks) by <b>ECHO</b> <b>matched</b> with TTC. <b>ECHO</b> and TTC showed similar values of MI size (% of left ventricle perimeter) in acute (ECHO: 33 ± 11, TTC: 35 ± 14) and chronic (ECHO: 38 ± 14, TTC: 39 ± 13 periods), and also presented an excellent correlation (r = 0. 92, P < 0. 001). Although measurements from different heart planes showed discrepancies, a single measurement acquired from the mid-ventricular level by TTC was a good estimate of MI size calculated by the average of multiple planes, with minimal disagreement (Bland-Altman test with mean ratio bias of 0. 99 ± 0. 07) and close to an ideal correlation (r = 0. 99, P < 0. 001). In the present study, ECHO was confirmed as a useful method for the determination of MI size even in the acute phase. Also, the single measure of a mid-ventricular section proposed as a simplification of the TTC method is a satisfactory prediction of average MI extension. Universidade Federal de São Paulo (UNIFESP) Escola Paulista de Medicina Departamento de MedicinaUniversidade Federal de São Paulo (UNIFESP) Escola Paulista de Medicina Departamento de FisiologiaUNIFESP, EPM, Depto. de MedicinaUNIFESP, EPM, Depto. de FisiologiaSciEL...|$|R
50|$|The <b>match</b> <b>echoed</b> the 1987 Rugby World Cup Final {{which was}} also held at Eden Park between the same teams, and also the 2007 Rugby World Cup Final in that both teams had progressed from the same pool. In the 2011 pool stage, France lost to New Zealand and Tonga, {{and it was only}} Canada's {{previous}} upset 25-20 victory over Tonga that allowed the French to progress. New Zealand won every match they played in the tournament.|$|R
5|$|Paris and {{its close}} suburbs {{is home to}} {{numerous}} newspapers, magazines and publications including Le Monde, Le Figaro, Libération, Le Nouvel Observateur, Le Canard enchaîné, La Croix, Pariscope, Le Parisien (in Saint-Ouen), Les <b>Échos,</b> Paris <b>Match</b> (Neuilly-sur-Seine), Réseaux & Télécoms, Reuters France, and L'Officiel des Spectacles. France's two most prestigious newspapers, Le Monde and Le Figaro, are the centrepieces of the Parisian publishing industry. Agence France-Presse is France's oldest, {{and one of the}} world's oldest, continually operating news agencies. AFP, as it is colloquially abbreviated, maintains its headquarters in Paris, as it has since 1835. France 24 is a television news channel owned and operated by the French government, and is based in Paris. Another news agency is France Diplomatie, owned and operated by the Ministry of Foreign and European Affairs, and pertains solely to diplomatic news and occurrences.|$|R
50|$|A further {{critical}} principle {{put forward}} by Knorozov was that of synharmony. According to this, Mayan words or syllables which had the form consonant-vowel-consonant (CVC) were often to be represented by two glyphs, each representing a CV-syllable (i.e., CV-CV). In the reading, the vowel of the second {{was meant to be}} ignored, leaving the reading (CVC) as intended. The principle also stated that when choosing the second CV glyph, it would be one with an <b>echo</b> vowel that <b>matched</b> the vowel of the first glyph syllable. Later analysis has proved this to be largely correct.|$|R
30|$|In {{the heart}} sounds video (Additional file 1 : Video S 1) are {{instructions}} for an exercise {{designed to improve}} auscultation skills. Students work in pairs with one student performing an ECHO while the other student listens with a stethoscope at various locations on the chest. While listening, the student watches the real-time <b>ECHO</b> and <b>matches</b> the heart sounds with the cardiac cycle and valve closure. We have created several additional videos such as aortic insufficiency (Additional file 2 : Video S 2) in which one can hear the first or S 1 heart sound with closure of the mitral valve and the second or S 2 heart sound with closure of the aortic valve followed by the murmur of aortic insufficiency. Aortic Insufficiency with Doppler (Additional file 3 : Video S 3) visualizes the murmur of aortic insufficiency with color Doppler. These videos were created by simultaneously recording the ECHO and the corresponding heart sounds. Students have reported this auscultation exercise and the ECHOs with heart sounds helpful in learning the heart examination.|$|R
30|$|The {{timestamp}} {{gap between}} a send packet and its <b>matched</b> <b>echo</b> packet collected at H 1 (the sensor) {{can be used}} to indicate the length of the connection chain from H 1 to Hn+ 1. It is denoted as RTTe =[*]te − ts. If we want to use the connection from H 1 to H 2 as a scale to measure the length of other connections, the connection length from H 1 to H 2 must be estimated. It is apparently not correct to use the timestamp gap between a send and its <b>matched</b> <b>echo</b> to represent the length of the connection from H 1 to H 2. What Yung used is the timestamp gap between a send packet and its acknowledgement packet collected at H 1. We denote this gap as RTTa =[*]ta − ts. Since H 2 is directly connected to H 1 in an ssh connection, so any packet sent from host H 1 is acknowledged at host H 2. The acknowledgement will sooner or later go back to H 1. Upon receiving a packet, an acknowledgement packet would be generated immediately. From the packet acknowledgement process, we understand even though it is not accurate to use RTTa to represent the length of a connection chain, it still makes some sense. The reason that it is not accurate is because RTTa tends to be smaller due to lacking of packet processing time. Any acknowledgement packet is generated at transport layer which needs less time than an echo packet which is generated at application layer in a ssh connection.|$|R
40|$|Sonar {{broadcasts}} {{are followed}} by echoes at different delays from objects at different distances. When broadcasts are emitted rapidly in cluttered surroundings, echo streams from successive broadcasts overlap and cause ambiguity in <b>matching</b> <b>echoes</b> to corresponding broadcasts. To identify reactions to ambiguity in clutter, echolocating bats that emit multiple-harmonic FM sounds were trained to fly into a dense, extended array of obstacles (multiple rows of vertically hanging chains) while the sonar sounds the bat emitted were recorded with a miniature radio microphone carried by the bat. Flight paths were reconstructed from thermal-infrared video recordings. Successive rows of chains extended more than 6 m in depth, so each broadcast {{was followed by a}} series of echoes from multiple rows of chains that lasted up to 40 ms. Bats emitted sounds in pairs (“strobe groups”) at short (20 – 40 ms) interpulse intervals (IPIs) alternating with longer IPIs (> 50 ms). For many short IPIs, the stream of echoes from the first broadcast was still arriving when the second broadcast was emitted. This overlap caused ambiguity about <b>matching</b> <b>echoes</b> with broadcasts. Bats shifted frequencies of the first sound in each strobe group upward and the second sound downward by 3 – 6 kHz. When overlap and ambiguity ceased, frequency shifts ceased also. Frequency differences were small compared with the total broadcast band, which was 75 – 80 kHz wide, but the harmonic structure of echoes enhances the differences in spectrograms. Bats could use time–frequency comparisons of echoes with broadcasts to assign echoes to the corresponding broadcasts and thus avoid ambiguity...|$|R
40|$|Abstract. In this paper, Lifted Wavelet Transform (LWT) and BP {{neural network}} {{are used for}} {{automatic}} flaw classification of pipeline girth welds. LWT is proposed to extract flaw feature from ultrasonic <b>echo</b> signals, ideally <b>matched</b> local characteristics of original signal and increasing the computational speed and flaw classification efficiency. After extracting features of all flaw echoes, a feature library is constructed. A modified BP neural network is followed as a classifier, trained by the library. When feature of any flaw echo is extracted and sent to BP network, flaw type is the output, realizing automatic flaw classification. Experiment results prove the proposed method, LWT with BP neural network, is more fit for automatic flaw classification than traditional methods...|$|R
40|$|A {{sediment}} geoacoustic {{parameter estimation}} technique is described which compares bottom returns, {{measured by a}} calibrated monostatic sonar oriented within 15 ° of vertical and having a 10 °– 21 ° beamwidth, with an echo envelope model based on high-frequency (10 – 100 kHz) incoherent backscattertheory and sediment properties such as: mean grain size, strength, and exponent of the power law characterizing the interface roughness energy density spectrum, and volume scattering coefficient. An average <b>echo</b> envelope <b>matching</b> procedure iterates on the reflection coefficient to <b>match</b> the peak <b>echo</b> amplitude and separate coarse from fine-grain sediments, followed by a global optimization {{using a combination of}} simulated annealing and downhill simplex searches over mean grain size, interface roughness spectral strength, and sediment volume scattering coefficient. Error analyses using Monte Carlo simulations validate this optimization procedure. Moderate frequencies (33 kHz) and orientations normal with the interface are best suited for this application. Distinction between sands and fine-grain sediments is demonstrated based on acoustic estimation of mean grain size alone. The creation of feature vectors from estimates of mean grain size and interface roughness spectral strength shows promise for intraclass separation of silt and clay. The correlation between estimated parameters is consistent with what is observed in situ...|$|R
25|$|Over the years, the Nebraska–Oklahoma {{game has}} {{produced}} several upsets. On sixteen occasions, the lower-ranked {{team won the}} game. The 1959 game, described above, is considered Nebraska's greatest upset victory. On four occasions, the lower-ranked team defeated the top-ranked team in the nation: 1978, 1984, 1987, 2000. With {{the exception of the}} 1978 game, all of these games involved Oklahoma taking down #1 Nebraska. Notably, the 1987 <b>match</b> <b>echoed</b> the 1971 game, pitting #2 Oklahoma against #1 Nebraska. Unlike the 1971 game, however, the Sooners knocked off the Cornhuskers, winning 17–7. Other high-stake upsets include the 1963 game, #10 Nebraska vs. # 6 Oklahoma; 1975, #7 Oklahoma vs. # 2 Nebraska; 1985, #5 Oklahoma vs. #2 Nebraska; and 2001, #3 Nebraska vs. #2 Oklahoma. The most recent upset occurred in 2009 when an unranked Nebraska team, carried by a Blackshirts defense, defeated #20 Oklahoma, 10–3.|$|R
40|$|Thesis (M. S.) University of Alaska Fairbanks, 2007 This thesis {{reports the}} {{observations}} of the Magnetospherically Reflected (MR) Whistler Mode (WM) echoes on the IMAGE (Imager for Magnetopause-to-Aurora Global Exploration) satellite. These observations and interpretations were first reported in Sonwalkar et at. [2006]. MR-WM echoes were observed when RPI (Radio Plasma Imager) onboard the IMAGE satellite transmitted 3. 2 ms pulses in the 6 kHz to 63 kHz frequency band. These echoes occurred at frequencies less than ~ 12 kHz with time delays ranging from 40 ms to 130 ms. MR-WM echoes were recorded when the satellite was at altitudes ranging from 700 km to 4000 km, geomagnetic latitudes from - 30 ° to 50 °, and magnetic local times 3 to 17. Ray tracing simulations confirmed that MR- WM echoes {{are a result of}} WM waves propagating along the geomagnetic field line and reflecting at an altitude where local flh [almost equal] f, where flh is the lower hybrid frequency and f is the wave frequency. In this interpretation, the lower and upper cutoff frequencies of the MR- WM echoes are equal to the flh at the satellite and the maximum flh along the geomagnetic field line passing through the satellite, respectively. These echoes were frequently accompanied by discrete WM echoes at frequencies greater than the maximum frequency of the MR- WM <b>echoes.</b> By <b>matching</b> the measured dispersions of the MR- WM and discrete WM echoes with that calculated from ray tracing simulations, remote estimates of electron density and ion effective mass were obtained along the geomagnetic field line passing through the satellite...|$|R
40|$|This study {{examined}} the Kodaly approach to music teaching and investigated four different approaches to teaching first graders in elementary school to sing on pitch, echo (clap) rhythms, audiate tonal patterns, and audiate rhythm patterns. The approaches were the Kodaly approach, the traditional approach, and two eclectic approaches. One emphasized some of the techniques of the Kodaly approach, and the other emphasized some of the techniques of the Orff approach. The sample for this study consisted of one hundred twenty-one students in five classes from four different elementary schools. Two instruments were utilized: the standardized Primary Measures of Music Audiation (PMMA) by Gordon and the Individual Performance Test (IPT) designed by the investigator. The PMMA had two sections of forty examples each and measured the child's ability to audiate tonal and rhythmic patterns. This test was administered to the children as a group and they recorded their answers on an answer sheet. The IPT was tape recorded and administered individually by the investigator and assistants. It had two sections, rhythm and tonal. The children matched pitches and clapped the rhythms they heard. Responses were tape recorded and evaluated. Pretests were given shortly after the school year began and post-test were given eight weeks later. A completely randomized analysis of covariance was {{used to analyze the}} data. It was hypothesized {{that there would be no}} difference in the achievement of the children in the different classes to perform the selected skills. Findings revealed that the approach to music teaching does make a difference in the musical achievement of first-graders and their abilities to <b>echo</b> rhythms, <b>match</b> pitches, and to audiate rhythm patterns. The approach to music teaching does not make a difference in the musical achievement of the subjects and their abilities to audiate tonal patterns...|$|R
40|$|Since {{the late}} eighties the sonar {{performance}} model ALMOST of TNO Defence, Security and Safety is under development. For active detection performance first a point target with one Target Strength (TS) value dependent on aspect angle was used, based on measurements or other sources. Within the Torpedo Defence System Test Bed (TDSTB), developed at TNO, with ALMOST as the acoustic kernel, {{there is a}} demand for target echo (TS) modelling for ships, wakes, and mine-like targets. Therefore modelling of extended (nonpoint) targets was investigated. The method is based on coherent scattering from a 3 -D surface constituted from dense pixels representing the specific {{size and shape of}} the target. Additionally normal vectors on this surface are included in the pixel file. ALMOST computes the response of the target <b>echo</b> after <b>matched</b> filtering, including the phase. Close range effects are fully taken into account. The ALMOST results are taken as simulator input for the Synthetic Aperture Sonar (SAS) processor, developed at TNO, as a first validity check ofALMOST. The model validity is checked further by comparing SAS results from ALMOST, with SAS results from SIMONA, a simulator for time signals, also developed at TNO. After these successful validity tests, ALMOST results for a mine-like target at close range (0. 5 to 3 m) are compared with measurements, obtained with a so-called “scan frame”. Identical geometry is used in ALMOST and the scan frame data, and both data sets are SAS processed. The SAS processor uses 2500 sonar positions with spacing 2 mm, on a straight line, some decimetres above the target. SAS reconstructs the target shape into a two dimensional picture. Some differences between model and measurements can be explained from assumptions made in the pixel file representing the real target measurements...|$|R
500|$|In {{the third}} round of the League Cup, Arsenal faced Derby County at Pride Park. Wenger made several first team changes to give his younger players playing time; Arsenal ran out 2–1 winners, a {{performance}} where [...] "every touch by a Derby player was greeted with ironic cheers." [...] However, the team were beaten comprehensively in the next round to Chelsea at Highbury, losing 0–5. The result inflicted Arsenal's biggest defeat in over eight years and Wenger defended his team selection, virtually a 'second team': [...] "I knew before the game that this kind of thing might happen. You only had to look at the team sheets. If we had won I would still have gone on playing the same side because the players need the experience." [...] Bergkamp, who was rested for the <b>match,</b> <b>echoed</b> his manager's comments: [...] "We had a lot of young players on the field against Chelsea and, although they were feeling very down after losing like that, they will learn from it. To be honest, the scoreline doesn't mean anything, whether it was 1–0 or 5–0. The supporters will feel bad but I hope they understand Saturday will be a different game [...]" ...|$|R
40|$|Small-footprint {{airborne}} laser scanners with waveform-digitising {{capabilities are}} becoming increasingly available. Waveformdigitising is particularly advantageous when the backscattered echo waveform is complex because it allows selecting processing algorithms adjusted to the task. In addition, waveform-digitising laser scanners depict the physical measurement process in its entire complexity. This opens the possibility to derive the backscatter cross section which {{is a measure of}} the electromagnetic energy intercepted and reradiated by objects. In this paper approaches for deriving the cross section along the laser ray path are discussed. For data storage and processing reasons a practical approach is to model the waveform as the sum of a number of echoes backscattered from individual scatterers. This approach involves estimating the number of <b>echoes,</b> finding a <b>match</b> between the modelled echoes and the measured waveform, and estimating the cross section using calibration targets. For estimating the number and position of echoes the Average Square Difference Function (ASDF) method, which is a discrete time delay estimation technique, is tested. The results show that ASDF is a promising approach which appears to be less affected by noise compared to more traditional echo detection methods. 1...|$|R
5000|$|In {{the third}} round of the League Cup, Arsenal faced Derby County at Pride Park. Wenger made several first team changes to give his younger players playing time; Arsenal ran out 2-1 winners, a {{performance}} where [...] "every touch by a Derby player was greeted with ironic cheers." [...] However, the team were beaten comprehensively in the next round to Chelsea at Highbury, losing 0-5. The result inflicted Arsenal's biggest defeat in over eight years and Wenger defended his team selection, virtually a 'second team': [...] "I knew before the game that this kind of thing might happen. You only had to look at the team sheets. If we had won I would still have gone on playing the same side because the players need the experience." [...] Bergkamp, who was rested for the <b>match,</b> <b>echoed</b> his manager's comments: [...] "We had a lot of young players on the field against Chelsea and, although they were feeling very down after losing like that, they will learn from it. To be honest, the scoreline doesn't mean anything, whether it was 1-0 or 5-0. The supporters will feel bad but I hope they understand Saturday will be a different game home to Tottenham Hotspur." ...|$|R
40|$|AbstractThe goal of {{this work}} is to develop {{software}} that enables the rapid implementation of custom MRI spectrometers using commercially-available software defined radios (SDRs). The developed gr-MRI software package comprises a set of Python scripts, flowgraphs, and signal generation and recording blocks for GNU Radio, an open-source SDR software package that is widely used in communications research. gr-MRI implements basic event sequencing functionality, and tools for system calibrations, multi-radio synchronization, and MR signal processing and image reconstruction. It includes four pulse sequences: a single-pulse sequence to record free induction signals, a gradient-recalled echo imaging sequence, a spin echo imaging sequence, and an inversion recovery spin echo imaging sequence. The sequences were used to perform phantom imaging scans with a 0. 5 Tesla tabletop MRI scanner and two commercially-available SDRs. One SDR was used for RF excitation and reception, {{and the other for}} gradient pulse generation. The total SDR hardware cost was approximately $ 2000. The frequency of radio desynchronization events and the frequency with which the software recovered from those events was also measured, and the SDR’s ability to generate frequency-swept RF waveforms was validated and compared to the scanner’s commercial spectrometer. The spin <b>echo</b> images geometrically <b>matched</b> those acquired using the commercial spectrometer, with no unexpected distortions. Desynchronization events were more likely to occur {{at the very beginning of}} an imaging scan, but were nearly eliminated if the user invoked the sequence for a short period before beginning data recording. The SDR produced a 500 kHz bandwidth frequency-swept pulse with high fidelity, while the commercial spectrometer produced a waveform with large frequency spike errors. In conclusion, the developed gr-MRI software can be used to develop high-fidelity, low-cost custom MRI spectrometers using commercially-available SDRs...|$|R
40|$|Expanding human {{presence}} in space, and enabling {{the commercialization of}} this frontier, {{is part of the}} strategic goals for NASA's Human Exploration and Development of Space (HEDS) enterprise. Future near-Earth and planetary missions will support the use of high-frequency Earth-space communication systems. Additionally, increased commercial demand on low-frequency Earth-space links in the S- and C-band spectra have led to increased interest in the use of higher frequencies in regions like Ku and Ka-band. Attenuation of high-frequency signals, due to a precipitating medium, can be quite severe and can cause considerable disruptions in a communications link that traverses such a medium. Previously, ground radar measurements were made along the Earth-space path and compared to satellite beacon data that was transmitted to a ground station. In this paper, quantitative estimation of the attenuation along the propagation path is made via inter-comparisons of radar data taken from the Tropical Rainfall Measuring Mission (TRMM) Precipitation Radar (PR) and ground-based polarimetric radar observations. Theoretical relationships between the expected specific attenuation (k) of spaceborne measurements with ground-based measurements of reflectivity (Zh) and differential propagation phase shift (Kdp) are developed for various hydrometeors that could be present along the propagation path, which are used to estimate the two-way path-integrated attenuation (PIA) on the PR return <b>echo.</b> Resolution volume <b>matching</b> and alignment of the radar systems is performed, and a direct comparison of PR return echo with ground radar attenuation estimates is made directly on a beam-by-beam basis. The technique is validated using data collected from the TExas and Florida UNderflights (TEFLUN-B) experiment and the TRMM large Biosphere-Atmosphere experiment in Amazonia (LBA) campaign. Attenuation estimation derived from this method can be used for strategiC planning of communication systems for future HEDS missions...|$|R
40|$|Ankara : The Department of Electrical and Electronics Engineering and the Institute of Engineering and Sciences of Bilkent University, 2010. Thesis (Master's) [...] Bilkent University, 2010. Includes bibliographical {{references}} leaves 62 - 64. Among {{various types}} of radar systems, the pulse-Doppler radar is {{the most widely used}} one, especially in military applications. Pulse Doppler radars have a primary objective to detect and estimate the range and the radial velocity of the targets. In order to have a basis for the detection, first reflected <b>echo</b> signals are <b>matched</b> filtered and then the time-alligned pulse returns are transformed to the Fourier domain to obtain the range-Doppler matrix. The resulting range-Doppler matrix is input to target detection algorithms. For this purpose, constant false alarm rate (CFAR) algorithms are run on the range-Doppler matrix. It is useful to run different CFAR algorithms inside the clutter region and outside the clutter region because the statistics are different inside and outside of the clutter. In order to achieve this discrimination, the position of the clutter has to be detected in the range-Doppler matrix. Moreover, the clutter may not always appear around zero Doppler frequency when realistic terrain models and moving platforms are considered. Two algorithms for clutter detection using range-Doppler matrix elements are investigated and their performance analysis is presented in this thesis. The first algorithm has higher error rates but lower computational complexity,whereas, the second one has lower error rates but higher computational complexity. Both algorithms detect clutter position by filtering the range-Doppler matrix elements via non-linear filters. In addition to the probabilistic error rate analysis, simulation results on some realistic cases are presented. It is concluded that the first algorithm is a good choice for low clutter-to-noise ratio values when a low-complexity algorithm is required. On the other hand, the second algorithm has better performance in all clutter-to-noise ratio values but it requires more computational power. Güngör, AhmetM. S...|$|R
40|$|Diffusion Tensor Imaging (DTI) is a {{well-established}} magnetic resonance technique that can non-invasively interpret tissue geometry and track neural pathways by sampling {{the diffusion of}} water molecules in the brain tissue. However, it is currently limited to tracking large nerve fiber bundles and fails to faithfully resolve thinner fibers. Conventional DTI studies use a diffusion time, t[subscript diff] of 30 ms - 55 ms for diffusion measurements. This work proposes the use of DTI at long t[subscript diff] to enhance {{the sensitivity of the}} method towards regions of low diffusion anisotropy and improve tracking of smaller fibers. The Stimulated Echo Acquisition Mode (STEAM) sequence was modified to allow DTI measurements at long t[subscript diff] (approximately 200 ms), while avoiding T 2 signal loss. For comparison, DTI data was acquired using STEAM at the shorter value of t[subscript diff] and with the standard Double Spin <b>Echo</b> sequence with <b>matched</b> signal-to-noise ratio. This approach was tested on phantoms and fixed monkey brains and then translated to in vivo studies in rhesus macaques. Qualitative and quantitative comparison of the techniques was based on fractional anisotropy, diffusivity, three-phase plots and directional entropy. Tensor-field maps and probabilistic connectivity fronts were evaluated for all three acquisitions. Comparison of the tracked nerve pathways showed that fibers obtained at long t[subscript diff] were much longer. Further, the optic tract was tracked in ex vivo fixed rhesus brains for cross validation. The optic tract, traced at long t[subscript diff], conformed to the well documented anatomical description, thus confirming the accuracy of tract tracing at long t[subscript diff]. The benefits of DTI at long t[subscript diff] indeed help to realize the potential of tensor based tractography towards studying neural development and diagnosing neuro-pathologies, albeit the improvement is more significant ex vivo than in vivo. Ph. D. Committee Chair: Hu, Xiaoping; Committee Member: Brummer, Marijn; Committee Member: Duong, Tim; Committee Member: Keilholz, Shella; Committee Member: Schumacher, Eri...|$|R
40|$|The {{objective}} {{of this research is}} to widen the applicability of gas flooding to shallow oil reservoirs by reducing the pressure required for miscibility using gas enrichment and increasing sweep efficiency with foam. Task 1 examines the potential for improved oil recovery with enriched gases. Subtask 1. 1 examines the effect of dispersion processes on oil recovery and the extent of enrichment needed in the presence of dispersion. Subtask 1. 2 develops a fast, efficient method to predict the extent of enrichment needed for crude oils at a given pressure. Task 2 develops improved foam processes to increase sweep efficiency in gas flooding. Subtask 2. 1 comprises mechanistic experimental studies of foams with N{sup 2 } gas. Subtask 2. 2 conducts experiments with CO{sup 2 } foam. Subtask 2. 3 develops and applies a simulator for foam processes in field application. Regarding Task 1, several results related to subtask 1. 1 are given. In this period, most of our research centered on how to estimate the dispersivity at the field scale. Simulation studies (Solano et al. 2001) show that oil recovery for enriched gas drives depends on the amount of dispersion in reservoir media. But the true value of dispersion, expressed as dispersivity, at the field scale, is unknown. This research investigates three types of dispersion in permeable media to obtain realistic estimates of dispersive mixing at the field scale. The dispersivity from single-well tracer tests (SWTT), also known as echo dispersivity, is the dispersivity that is unaffected by fluid flow direction. Layering in permeable media tends to increase the observed dispersivity in well-to-well tracer tests, also known as transmission dispersivity, but leaves the echo dispersivity unaffected. A collection of SWTT data is analyzed to estimate echo dispersivity at the SWTT scale. The estimated <b>echo</b> dispersivities closely <b>match</b> a published trend with length scale in dispersivities obtained from groundwater tracer tests. This unexpected result [...] it was thought that transmission dispersivity should be greater than echo dispersivity [...] is analyzed with numerical simulation. A third type of dispersive mixing is local dispersivity, or the mixing observed at a point as tracer flows past it. Numerical simulation results show that the local dispersivity is always less than the transmission dispersivity and greater than the echo dispersivity limits. It is closer to one limit or the other depending on the amount and type of heterogeneity, the autocorrelation structure of the medium's permeability, and the lateral (vertical) permeability. The agreement between the SWTT echo dispersivities and the field trend suggests that the field data are measuring local dispersivities. All dispersivities appear to grow with length. Regarding Task 2, two results are described: (1) An experimental study of N{sup 2 } foam finds the two steady-state foam-flow regimes at elevated temperature and with acid, adding evidence that the two regimes occur widely, if not universally, in foam in porous media. (2) A simulation finds that the optimal injection strategy for overcoming gravity override in homogeneous reservoirs is injection of large alternating slugs of surfactant and gas at fixed, maximum attainable injection rates. A simple model for the process explains why the this strategy works so well. Before conducting simulations of SAG displacements, however, it is important to analyze the given foam model using fractional-flow theory. Fractional-flow theory predicts that some foam processes will give foam collapse immediately behind the gas front. In simulations, numerical dispersion leads to a false impression of good sweep efficiency. In this case simply grid refinement may not warn of the inaccuracy of the simulation...|$|R

