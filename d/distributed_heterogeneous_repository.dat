0|3342|Public
40|$|Today's {{networked}} {{software engineering}} environment {{is characterized by}} a multitude of autonomous, <b>heterogeneous</b> information <b>repositories,</b> a variety of incompatible user interfaces, diverse, unconventional data types, including text, graphics, and possibly video and sound, rapid change, both in structure and content, and multiple ways of viewing relationships among the same information items. Existing information storage mechanisms fail to combine diverse data types/models, complex objects and storage structures, personal views and organizations of shared objects, access to <b>distributed,</b> <b>heterogeneous</b> <b>repositories,</b> and ease of evolution. This paper examines these issues and describes a Distributed Hypertext architecture that provides transparent access to autonomous, <b>heterogeneous</b> software object <b>repositories,</b> resulting in both a powerful organizational tool and a simple yet effective integration mechanism. Keywords: Hypertext, <b>Distributed</b> Systems, <b>Heterogeneous</b> <b>Distributed</b> Object Manage [...] ...|$|R
40|$|This paper {{describes}} {{the architecture of}} a knowledge man-agement system that exploits social and semantic web tech-nology in order to ease and promote user-centered modeling, evolution, sharing and access to knowledge in <b>distributed</b> and <b>heterogeneous</b> <b>repositories.</b> For that, several knowledge engineering processes are improved in order to exploit social information between users and communities...|$|R
40|$|The {{abundance}} of data {{at our disposal}} empowers data-driven applications and decision making. The knowledge captured in the data, however, has not been utilized to full potential, as it is only accessible to human interpretation and data are <b>distributed</b> in <b>heterogeneous</b> <b>repositories.</b> Ontologies are a key technology unlocking the knowledge in the data by providing means to model {{the world around us}} and infer knowledge implicitly captured in the data. As data are hosted by independent organizations we often need to use several ontologies and discover the relationships between them in order to support data and knowledge transfer. Broadly speaking, while ontologies provide formal representations and thus the basis, ontology alignment supplies integration techniques and thus the means to turn the data kept in <b>distributed,</b> <b>heterogeneous</b> <b>repositories</b> into valuable knowledge. While many automatic approaches for creating alignments have already been developed, user input is still required for obtaining the highest-quality alignments. This thesis focuses on supporting users during the cognitively intensive alignment process and makes several contributions. We have identified front- and back-end system features that foster user involvement during the alignment process and have investigated their support in existing systems by user interface evaluations and literature studies. We have further narrowed down our investigation to features in connection to the, arguably, most cognitively demanding task from the users’ perspective—manual validation—and have also considered the level of user expertise by assessing the impact of user errors on alignments’ quality. As developing and aligning ontologies is an error-prone task, we have focused on the benefits of the integration of ontology alignment and debugging. We have enabled interactive comparative exploration and evaluation of multiple alignments at different levels of detail by developing a dedicated visual environment—Alignment Cubes—which allows for alignments’ evaluation {{even in the absence of}} reference alignments. Inspired by the latest technological advances we have investigated and identified three promising directions for the application of large, high-resolution displays in the field: improving the navigation in the ontologies and their alignments, supporting reasoning and collaboration between users...|$|R
40|$|Interoperation among <b>distributed,</b> <b>heterogeneous</b> and {{autonomous}} <b>repositories</b> can {{be achieved}} via relationships established between terms across the ontologies defined over the repositories. In this paper we present the type of relationships used, one way of storing them and how new relationships are deduced from some defined ones when a query processing over different data repositories is needed. Keywords : Global Information Systems, Query processing, Metadata, Ontologies, Description Logics. 1...|$|R
40|$|Modern medical {{decision}} making systems require users to manually collect and process information from <b>distributed</b> and <b>heterogeneous</b> <b>repositories</b> {{to facilitate the}} decision mak-ing process. There are many factors (such as time, volume of information and technical ability) that can potentially compromise the quality of decisions made for patients. In this work we demonstrate and evaluate a new medical de-cision making support system, called OMeD, which auto-matically answers medical queries in real time, by collect-ing and processing medical information. OMeD utilizes a natural-language-like user interface (for querying) and se-mantic web techniques (for knowledge representation and reasoning) to answer queries. We compare OMeD {{to a set of}} standard machine learning techniques across a series o...|$|R
40|$|This paper {{describes}} the first iteration {{of a working}} model for searching <b>heterogeneous</b> <b>distributed</b> metadata <b>repositories</b> for sound recording collections, focusing on techniques used for real-time querying and harmonizing diverse metadata models. The initial model for a metadata infrastructure presented here {{is the first of}} its kind for sound recordings. 1...|$|R
40|$|Social media {{technologies}} offer {{potential benefits}} {{for a variety}} of scenarios to support access to digital resources. The involvement of users that do not only consume, but also participate and contribute information, allows for promising approaches such as social browsing and crowdsourcing. Yet, a lot of resources and metadata are contained in <b>distributed</b> and <b>heterogeneous</b> <b>repositories</b> that follow a traditional top-down approach in which only experts can contribute information. A social hub that can aggregate such information, {{while at the same time}} offering social media technologies, enables new ways to search and browse these contents, and to maintain underlying structures. We will present how the ALOE system that realises such a social backbone was integrated into the MACE portal. First evaluation results provide evidence about the usefulness of the presented approach...|$|R
40|$|In this article, we {{describe}} a Smart Space for LearningTM (SS 4 L) framework and infrastructure that enables personalized access to <b>distributed</b> <b>heterogeneous</b> knowledge <b>repositories.</b> Helping a learner {{to choose an}} appropriate learning resource or activity is a key problem which we address in this framework, enabling personalized access to federated learning repositories with {{a vast number of}} learning offers. Our infrastructure includes personalization strategies both at the query and the query results level. Query rewriting is based on learning and language preferences, rule-based and ranking-based personalization improves these results further. Rule-based reasoning techniques are supported by formal ontologies we have developed based on standard information models for learning domains, ranking based recommendations are supported through ensuring minimal sets of predicates appearing in query results. Our evaluation studies show that the implemented solution enables learners to find relevant learning resources in a distributed environment and throug...|$|R
40|$|Web {{search engines}} have become {{increasingly}} ineective {{as the number of}} documents on the web have proliferated. Typical queries retrieve hundreds of documents, most of which have no relation with what the user was looking for. The objective of this work is to propose new techniques to cluster the results of a query from a search engine into groups. These groups and their associated keywords are presented to the user, who can then look into the URLs for the group(s) that s/he nds interesting. N-gram and vector space methods are used to create the dissimliarity matrix for clustering. We compare these distance metrics by clustering the data using a robust fuzzy algorithm and evaluating the results. 1 Introduction Today, the WWW represents one of the largest, <b>distributed,</b> <b>heterogeneous,</b> semi-structured <b>repositories</b> of multimedia content. With the proliferation of Web servers and pages, users have experienced the exitement of the Web providing a large information repository, toget [...] ...|$|R
40|$|Ontologies {{and agents}} are two topics that raise a {{particular}} attention those {{days from the}} theoretical {{as well as from}} the application point of view. In this paper we present a software gathering service that is mainly supported by an ontology, SoftOnt, and several agents. The main goal of the paper is to show how the SoftOnt ontology is built from <b>distributed</b> and <b>heterogeneous</b> software <b>repositories.</b> In the particular domain considered, software repositories, we advocate for an automatic creation of a global unique ontology versus a manual creation and the use of multiple ontologies. Keywords: ontologies as metadata, agent technology, distributed software retrieval...|$|R
40|$|Research on {{microorganisms}} has a {{great impact}} on many application domains, such as health, food, energy, waste management. Information on microorganisms is <b>distributed</b> in many <b>heterogeneous</b> <b>repositories.</b> There is a clear need for methods and systems able to merge sources, offer a comprehensive and clear vision of microorganisms data, and integrate this data with information from other data sources. The Microbial Resource Research Infrastructure (MIRRI) pan-European research infrastructure ([URL] aims to connect European mBRCs with the goal of providing improved and extended services to the research and industry (1). Among its main objectives is the design of improved integration methods for mBRCs data for: i) assessing available information, ii) pointing out discrepancies, errors and gaps, iii) carrying out in-silico analyses, and iv) curating mBRC catalogues' data...|$|R
40|$|Abstract. Resource {{discovery}} {{supports the}} core functions of virtual learning environments and digital repository systems. The function enables existing resources {{to be identified}} and re-purposed for teaching. This paper describes the purpose {{and the development of}} a search service developed within a project funded by the UK Joint Information Systems Committee (JISC). The search service corresponds to an emerging framework for implementing e-learning web services. It mediates resource discovery among <b>distributed</b> and <b>heterogeneous</b> <b>repositories</b> via a service-oriented approach. This paper provides a review of the elearning technical framework, and discusses the development of the service along with the application scenarios in which it has been deployed. 1. Service-Oriented Approach and e-Learning A main challenge in delivering high quality e-learning has been the provision of an infrastructure that is capable of fulfilling the diverse requirements of educational processes. Current developments of e-learning infrastructures involve an increased adoption of service-oriented and distributed computing technologies. The Grid, for example, has become a prominent area of development. As an advanced form of resources-sharing and service-oriented network infrastructure originally developed for e-science purposes, e. g. the Enabling Grid for E-science (EGEE) projec...|$|R
40|$|Artificial Intelligence Lab, Department of MIS, University of ArizonaThe Information Infrastructure Technology and Applications (IITA) Working Group, {{the highest}} level of the country's National Information Infrastructure (NII) {{technical}} committee, held an invited workshop in May 1995 to define a research agenda for digital libraries. The shared vision is an entire net of distributed repositories in which objects of any type and any size can be organized and searched within and across different indexed collections. The ultimate goal, as described in the IITA report, is the Grand Challenge of Digital Libraries: "deep semantic interoperability [...] the ability of a user to access, consistently and coherently, similar (though autonomously defined and managed) classes of digital objects and services, <b>distributed</b> across <b>heterogeneous</b> <b>repositories,</b> with federating or mediating software compensating for site-by-site variations [...] . Achieving this will require breakthroughs in description as well as retrieval, object interchange and object retrieval protocols. Issues here include the definition and use of metadata and its capture or computation from objects (both textual and multimedia), the use of computed descriptions of objects, federation and integration of <b>heterogeneous</b> <b>repositories</b> with disparate semantics, clustering and automatic hierarchical organization of information, and algorithms for automatic rating, ranking, and evaluation of information quality, genre, and other properties. " "The use of computed descriptions of (multimedia) objects" and "clustering and automatic hierarchical organization of information" present pressing scientific and engineering problems that have a significant potential impact on the US society in this era of the Internet and distributed, multimedia computing...|$|R
40|$|Many {{interoperable}} database systems offer {{the possibility of}} defining integrated schemata on top of heterogeneous databases. A very important challenge for these {{interoperable database}} systems is to maintain {{the autonomy of the}} component databases while preserving the correct semantics of the integrated schemata. This paper presents a mechanism that responds automatically to design changes made in component databases which are relevant to one or more integrated schemata. Further, this mechanism provides each component that decides to participate in the interoperable system with the opportunity to choose between assuming the default monitoring provided by the system or customizing it by defining the system responses. 1 Introduction It is widely recognized that many organizations possess their data stored in <b>distributed,</b> <b>heterogeneous,</b> autonomous data <b>repositories.</b> In order to support coordinated access to this data, interoperable systems have been defined. In the literature we can find [...] ...|$|R
40|$|Modern {{organizations}} have strong requirements for tools that support coordinated {{access to data}} stored in <b>distributed,</b> <b>heterogeneous,</b> autonomous data <b>repositories.</b> There are several motivations for this need. The first is that organizations evolve over time. This evolution process influences the way data is managed within an organization. Indeed, {{the choice of a}} data base management system (DBMS) depends on the application requirements and on the available technology. As those evolve over time, an organization acquires several, possibly heterogeneous, data management systems. Second, many new applications are so complex that they cannot be effectively supported by a single data management system. Therefore, different data management systems need to inter-operate in order to completely support complex applications. Finally, not all data sources belong to the organizations using them. This is the case, for example, of data banks such as library catalogs, containing on-line information about all the books and journal...|$|R
40|$|This paper {{presents}} a customizable architecture for software agents that capture and access information in large, <b>heterogeneous,</b> <b>distributed</b> electronic <b>repositories.</b> The key {{idea is to}} exploit underlying structure at various levels of granularity to build high-level indices with task-specific interpretations. Information agents construct such indices and are configured as a network of reusable modules called structure detectors and segmenters. We illustrate our architecture with the design and implementation of smart information filters in two contexts: retrieving stock market data from Internet newsgroups, and retrieving technical reports from Internet ftp sites. 1 Introduction The proliferation of information in electronic form {{and the development of}} high-speed networking make the problem of locating and retrieving information in vast electronic environments one of the grand challenges of computer science. Examples of electronic corpora include repositories of newspapers and technic [...] ...|$|R
40|$|The MyView system aims at {{gathering}} {{bibliographic information}} from a diversity of <b>heterogeneous</b> <b>distributed</b> Internet <b>repositories</b> like electronic journals and traditional libraries. It maintains a personalized warehouse for bibliographic data in a unified scheme which is locally available for browsing, ad-hoc queries, rearrangements and analysis. On the one hand, users {{should be able to}} specify their interests in a simple and comfortable way. Building on experiences gained by the information retrieval community we propose sets of weighted terms and bestmatch retrieval for this purpose. On the other hand, many on-line library catalogues exclusively provide a Boolean interface (exact-match retrieval). We therefore have to tackle the problem of mapping a set of weighted terms on an appropriate collection of Boolean queries, {{while at the same time}} restrictions of local warehouse resources and the generated net load have to be taken into account. In this paper the mapping problem and optima [...] ...|$|R
40|$|The MyView system aims at {{gathering}} {{bibliographic information}} from a diversity of <b>heterogeneous</b> <b>distributed</b> Internet <b>repositories</b> like electronic journals, text archives, and traditional libraries. It maintains a personalized warehouse for bibliographic data in a unified scheme which is locally available for browsing, ad-hoc queries, rearrangements, and analysis. To specify a user's information need we suggest its definition in a simple and comfortable way, namely by just a set of terms and not by a complex query language. Traditional libraries, however, often exclusively offer a Boolean interface. To fill the warehouse a user's information need thus has to be translated into a sequence of Boolean queries. Furthermore, the additional restriction of limited storage resources {{has to be taken}} into account, when data are transferred into the warehouse. In this paper the mapping problem and optimal solutions are defined in exact terms. We additionally present two heuristically guided algori [...] ...|$|R
40|$|Abstract: Some of the {{universities}} in Malaysia are still implementing hybrid Electronic Theses and Dissertations (ETD) approach in managing Theses and Dissertations (TD). One {{of the limitations of}} the hybrid ETD approach is its online cataloguing method, which is only available at the physical location of the TD instead of enabling the information to be retrieved online. Maintaining the performance and the data accessing rate of an ETD system has become challenging, {{due in part to the}} high number of scholars who utilise and access the system. In order to allow remote access and maintain the services such as scalability, accessibility, availability and expressibility, a Grid Enabled E-Theses and dissertations repository system (GREET) has been proposed in this paper to provide uniform access of knowledge integration among <b>distributed</b> <b>heterogeneous</b> platforms and <b>repositories</b> by using data grid technology. Comparative performance results between a non-grid architecture and GREET has been benchmarked. It has been proven that GREET is able to increase the processing time approximately three times faster than the non-grid architecture. Furthermore, multiple file streams can be opened to support larger volume and larger capacity of file operation so that GREET is able to decrease the chances of network congestion caused by input/output file operations. For future direction, research will be focused on searching algorithm using data mining or pattern discovery to minimise the respond time...|$|R
40|$|We {{present a}} generic {{architecture}} for content-based retrieval of images, {{which can be}} extended {{to the requirements of}} large <b>distributed</b> and <b>heterogeneous</b> collections. The system is modeled as a multi-agent system where an autonomous search agent encapsulates an independent image retrieval algorihtms. An optimal team of agents is dynamically selected for every retrieval problem. A flexible protocol allows for dynamic addition of search agents incorporating new pattern recognition techniques. These agents are coded as mobile agents, so that they can travel across a wide area network and analyze the documents at their sources. The separation of physical image forms and their logical structural composition allows the search agents to operate over <b>heterogeneous</b> <b>repositories.</b> A prototype implementation validates the effectiveness of the architecture. ...|$|R
5000|$|<b>Distributed</b> <b>heterogeneous</b> {{augmented}} and hyper-reality systems ...|$|R
40|$|Abstract. Discovering hidden {{patterns}} in <b>distributed</b> <b>heterogeneous</b> textual databases and unstructured data {{is a new}} challenge in data mining. Traditional data mining often assumes that preprocessing is already done [...] homogeneous data {{are available on the}} needed level. For <b>distributed</b> <b>heterogeneous</b> textual data thi...|$|R
5000|$|... the {{integration}} of <b>distributed,</b> <b>heterogeneous</b> computing environments, and ...|$|R
40|$|As {{database}} technology advances rapidly, {{there are}} usually heterogeneous databases, (hierarchical, relational or object-oriented databases) used by different departments in an enterprise. On the other hand, the object-oriented technology is becoming the dominant application development pradigm. Thus, there is a data modeling gap between applications and heterogeneous databases. In this paper we present different architecture aspects of the system VHDBS (VHDBS is abbreviated from "Verteilte Heterogene Datenbanksysteme", <b>Distributed</b> <b>Heterogeneous</b> Database Systems)., which has been developed by an ongoing research project. This architecture provides a way to support cooperative access to <b>distributed</b> <b>heterogeneous</b> databases and to fill the data modeling gap in a <b>distributed</b> <b>heterogeneous</b> environmen...|$|R
40|$|Successful {{resource}} discovery across <b>heterogeneous</b> <b>repositories</b> {{is strongly}} {{dependent on the}} semantic and syntactic homogeneity of the associated resource descriptions. Ideally, resource descriptions are easily extracted from pre-existing standardized sources, expressed using standard syntactic and semantic structures, and managed and accessed within a distributed, flexible, and scaleable software framework...|$|R
40|$|Abstract. We {{propose a}} {{mediator}} architecture {{that allows a}} learning system to retrieve learning objects from <b>heterogeneous</b> <b>repositories.</b> A mediating component accepts queries formulated in a uniform query language, translates them into repository specific queries and passes them to each connected repository. For the translation of queries, a novel ontology-based query-rewriting method has been developed. The architecture has been realized in the Web-based, user-adaptive and interactive e-learning environment ActiveMath. Currently, it enables the ActiveMath’s course planner to access four <b>heterogeneous</b> learning object <b>repositories.</b> ...|$|R
40|$|The prime {{objective}} of the <b>Distributed</b> <b>Heterogeneous</b> Database Management System approach is to support database integration across organizational, application, and geographical boundaries. This is achieved by efforts that a at providing a unified global schema and common query facilities to users, without changing existing Database Management Systems or their application programs. Design methodologies for such systems differ {{from each other in}} a number of ways. The additional complexity of translating between multiple systems and data models makes <b>Distributed</b> <b>Heterogeneous</b> Database Management Systems more challenging than conventional database systems. This paper identifies critical aspects of <b>Distributed</b> <b>Heterogeneous</b> Database Management Systems. It aims at providing a basis for the study of these systems, comparati analysis between such systems, and directions for further extensions * 0 n leave from School of Computer and System Sciences...|$|R
40|$|<b>Distributed</b> <b>heterogeneous</b> environments {{are being}} {{increasingly}} used {{to execute a}} variety of large size simulations and computational problems. We are developing Arcade, a web-based environment to design, execute, monitor, and control distributed applications. These targeted applications consist of independent heterogeneous modules which can be executed on a <b>distributed</b> <b>heterogeneous</b> environment. In this paper we describe the overall design {{of the system and}} discuss the prototype implementation of the core functionalities required to support such a framework...|$|R
40|$|In {{this paper}} we present some main {{architecture}} {{aspects of the}} system VHDBS (VHDBS is abbreviated from "Verteilte Heterogene Datenbanksysteme", <b>Distributed</b> <b>Heterogeneous</b> Database Systems) which has been developed by an ongoing research project. This architecture provides a way to support cooperative access to distributed hetero-geneous databases and to fill the data modeling gap in a <b>distributed</b> <b>heterogeneous</b> environment. Our work contributes not only to an implementation solution but also to an architectural framework and paradigmatic solution...|$|R
40|$|In {{this paper}} {{we present a}} system that {{supports}} users in retrieving data in <b>distributed</b> and <b>heterogeneous</b> archives and <b>repositories.</b> The architecture {{is based on the}} metaphor of the software agents and incorporates innovative hints from other fields: distributed architectures, relevance feedback and active interfaces. The system has a cooperative and supportive role: it understands the user's needs and learns from his behavior. Its aim is to disengage the user from learning complex tools and from performing tedious and repetitive actions. 1 Introduction The storage and retrieval of data has undergone substantial modifications during the years. More recently the development of Internet has turned the classical view of database as a centralized collection of homogeneous data into <b>distributed,</b> <b>heterogeneous</b> collections of information. A datum is not any more a structured entity, but it could be almost any kind of representable item, e. g., a picture, a sound, a text, a record, etc. The sp [...] ...|$|R
40|$|Under {{guidance}} of the Andrew W. Mellon Foundation, the Coalition for Networked Information (CNI), the Digital Library Federation (DLF), the Joint Information Systems Committee (JISC) and Microsoft, a meeting was held aimed at identifying concrete steps that could be taken to augment interoperability across <b>heterogeneous</b> scholarly <b>repositories.</b> The specific goal of the meeting was to try and reach a common understanding regarding a data model and a limited set of core, protocol-based repository interfaces that would allow services and downstream applications to interact with <b>heterogeneous</b> <b>repositories</b> in a consistent manner. Such repository interfaces include interfaces that support locating, identifying, harvesting, obtaining and depositing compound digital objects...|$|R
30|$|HLA is a {{specification}} of a software architecture {{which has the}} purpose of facilitating intercommunication between <b>distributed</b> <b>heterogeneous</b> systems, mainly simulations, and allows the division of tasks among members [3]. This standard is a general-purpose architecture defined by the Defense Modeling and Simulation Office (DMSO) and designed to use a wide number {{of different types of}} simulators [2]. In this paper, HLA is used in an innovative way to provide interoperability of <b>distributed</b> <b>heterogeneous</b> hardware devices, instead of only simulations.|$|R
40|$|Abstract. Between each node {{database}} {{there must}} be all different in the <b>distributed</b> <b>heterogeneous</b> database, so how to resolve these differences(It's said that realize the mutual transformation between heterogeneous databases) was an basic problem in the heterogeneous database integration, synchronous and optimized. This paper analyzes the conversion mechanism for the <b>distributed</b> <b>heterogeneous</b> database between node databases and {{the realization of the}} conversion module theoretical includeing the conversion information extraction module, structural conversion module, structure formation module and put forward a concrete realization solutions...|$|R
40|$|Abstract. With {{the advent}} of the Web along with the {{unprecedented}} amount of information coming from sources of heterogeneous data, Formal Concept Analysis (FCA) is more useful and practical than ever, because this technology addresses important limitations of the systems that currently support users in their quest for information. In this paper, we will focus on the unique features of FCA for searching in <b>distributed</b> <b>heterogeneous</b> information. The development of FCA-based applications for <b>distributed</b> <b>heterogeneous</b> information returns a major gain. ...|$|R
40|$|This paper {{focuses on}} {{advanced}} software research This paper focuses on advanced software research This paper focuses on advanced software research This paper focuses on advanced software research directions which {{are important to}} overcome a lot of bottlenecks directions which are important to overcome a lot of bottlenecks directions which are important to overcome a lot of bottlenecks directions which are important to overcome a lot of bottlenecks already present in <b>distributed</b> <b>heterogeneous</b> environments. Special already present in <b>distributed</b> <b>heterogeneous</b> environments. Special already present in <b>distributed</b> <b>heterogeneous</b> environments. Special already present in <b>distributed</b> <b>heterogeneous</b> environments. Special attention is given to remote programming attention is given to remote programming attention is given to remote programming attention is given to remote programming, a new communication, a new communication, a new communication, a new communication paradigm based on mobile intelligent agents and active networks as a paradigm based on mobile intelligent agents and active networks as a paradigm based on mobile intelligent agents and active networks as a paradigm based on mobile intelligent agents and active networks as a building blocks of future client/server environments. building blocks of future client/server environments. building blocks of future client/server environments. building blocks of future client/server environments...|$|R
40|$|Heterogeneous Associative Computing (HAsC) {{is a new}} <b>distributed</b> <b>heterogeneous</b> {{computing}} paradigm that is {{a combination}} of associative computing, superconcurrency, and <b>distributed</b> <b>heterogeneous</b> computing. Its task mapping and resulting execution decision is based on data locality along with a variety of system, data, and algorithmic factors. In this paper, we present Data Placement Analysis (DPA) that is an effective and efficient method of placing the right data set on suitable machines for execution. Thus, when incorporated into HAsC task mapping, DPA will strongly influence the machine selection / task mapping process. The effectiveness of DPA is then shown with experimental results. 1. 0 Introduction <b>Distributed</b> <b>heterogeneous</b> high performance computing, also called metacomputing (Smarr and Callett 1992), is where a single program's tasks are distributed among a network of heterogeneous machines. Although this network of machines is viewed by the user's program as a single unified v [...] ...|$|R
