2|3804|Public
40|$|The current {{research}} examines {{the effects of}} exposure to ideal images on women’s self-evaluations, {{taking into account the}} moderating influence of social contextual and individual difference factors. In Study 1, women were exposed to either ideal images of women or neutral <b>images.</b> <b>Participants</b> <b>viewed</b> these images in a context in which (a) men were not present, (b) men were present, or (c) men were present and made comments about some of the images. Results indicated that participants’ weight esteem was negatively affected in the ideal image/men present condition but that those in the ideal image/men comment condition actually exhibited higher levels of weight-esteem. A second study replicated the results of Study 1 and also showed that the importance participants placed on physical attractiveness influenced the effects of viewing ideal images...|$|E
40|$|Visual {{judgments}} of human movement {{play an important}} role in social interactions, but relatively little is known about how retinal motion signals are used to estimate human movement speed. We report a new effect which demonstrates that these judgments are subject to modification by exposure to dynamic <b>images.</b> <b>Participants</b> <b>viewed</b> videos of real scenes depicting either groups of figures walking along a High Street or contestants running in the London Marathon. When video playback was speeded up or slowed down slightly relative to natural speed, participants could readily report whether the figures in each video appeared to be moving unnaturally quickly or slowly. However after adapting to slowed-down walking, natural walking speed appeared too fast, and after adapting to speeded-up walking, natural walking speed appeared too slow. Corresponding effects were found for running videos. Adaptation to natural-speed playback had no effect on apparent locomotion speed. These effects are quite different in a number of respects from those previously reported in studies of retinal velocity adaptation using simple patterns such as gratings. Unlike the stimuli used in most previous studies our videos contained a range of speeds and directions due to the unpredictability of natural scenes. Walkers and runners moved in different directions at different speeds, and at varying distances from the camera. Participants also engaged in free viewing rather than fixation. Furthermore over the range of retinal velocities our stimuli contained, adaptation to simple moving patterns causes a significant reduction in apparent velocity at all test velocities, including at the adapting velocity. Our data are consistent with the operation of a qualitatively different process in judgements of locomotion speed in natural scenes...|$|E
40|$|Symmetry {{detection}} is slow when {{patterns are}} distorted by perspective, {{perhaps due to}} a time-consuming normalization process, or because discrimination relies on remaining weaker regularities in the retinal <b>image.</b> <b>Participants</b> <b>viewed</b> symmetrical or random dot patterns, either in a frontoparallel or slanted plane (± 50 °). One group performed a color discrimination task, while another performed a regularity discrimination task. We measured a symmetry-related event- related potential (ERP), beginning around 300 ms. During color discrimination, the ERP was reduced for slanted patterns, indexing only the remaining retinal structure. During regularity discrimination, the same ERP was view invariant, and identical for frontoparallel or slanted presentation. We conclude that normalization occurs rapidly during active symmetry discrimination, while symmetry-sensitive networks respond only to regularity in the retinal image when people are attending to other features...|$|R
40|$|We {{examined}} {{the role of}} conceptual and visual similarity in a memory task for natural images. The important novelty of our approach was that visual similarity was determined using an algorithm [1] instead of being judged subjectively. This similarity index takes colours and spatial frequencies into account. For each target, four distractors were selected that were (1) conceptually and visually similar, (2) only conceptually similar, (3) only visually similar, or (4) neither conceptually nor visually similar to the target <b>image.</b> <b>Participants</b> <b>viewed</b> 219 <b>images</b> with the instruction to memorize them. Memory for a subset of these images was tested subsequently. In Experiment 1, participants performed a two-alternative forced choice recognition task and in Experiment 2, a yes/no-recognition task. In Experiment 3, testing occurred after a delay of one week. We analyzed the distribution of errors depending on distractor type. Performance was lowest when the distractor image was conceptually and visually similar to the target image, indicating that both factors matter in such a memory task. After delayed testing, these differences disappeared. Overall performance was high, indicating a large-capacity, detailed visual long-term memory...|$|R
40|$|One of {{the major}} lessons of memory {{research}} has been that human memory is fallible, imprecise, and subject to interference. Thus, although observers can remember thousands of images, it is widely assumed that these memories lack detail. Contrary to this assumption, here we show that long-term memory is capable of storing a massive number of objects with details from the <b>image.</b> <b>Participants</b> <b>viewed</b> pictures of 2, 500 objects {{over the course of}} 5. 5 h. Afterward, they were shown pairs of images and indicated which of the two they had seen. The previously viewed item could be paired with either an object from a novel category, an object of the same basic-level category, or the same object in a different state or pose. Performance in each of these conditions was remarkably high (92 %, 88 %, and 87 %, respectively), suggesting that participants successfully maintained detailed representations of thousands of images. These results have implications for cognitive models, in which capacity limitations impose a primary computational constraint (e. g., models of object recognition), and pose a challenge to neural models of memory storage and retrieval, which must be able to account for such a large and detailed storage capacity...|$|R
40|$|Recent {{models of}} emotion {{regulation}} {{suggest that the}} cognitive costs of reappraisal depend on stimulus intensity and habitual reappraisal. In the current experiment, we tested these hypotheses by manipulating the intensity of unpleasant and pleasant <b>images,</b> which <b>participants</b> reappraised, <b>viewed,</b> or suppressed their emotions to. To assess cognitive costs, we measured participants' performance on a concurrent simple reaction time task. Participants also reported on their everyday use of reappraisal and suppression. Higher intensity stimuli were associated with greater cognitive costs of reappraisal, for unpleasant, but not pleasant pictures. Also, greater habitual reappraisal predicted lower cognitive costs of reappraisal and greater reductions in subjective feelings. Results support the role of stimulus intensity and habitual use of reappraisal in predicting the cognitive costs of reappraisal...|$|R
40|$|Abstract in Undetermined Complex stimuli and tasks elicit {{particular}} {{eye movement}} sequences. Previous {{research has focused}} on comparing between these scanpaths, particularly in memory and imagery research where it has been proposed that observers reproduce their eye movements when recognizing or imagining a stimulus. However, {{it is not clear whether}} scanpath similarity is related to memory performance and which particular aspects of the eye movements recur. We therefore compared eye movements in a picture memory task, using a recently proposed comparison method, MultiMatch, which quantifies scanpath similarity across multiple dimensions including shape and fixation duration. Scanpaths were more similar when the same participant's eye movements were compared from two viewings of the same image than between different <b>images</b> or different <b>participants</b> <b>viewing</b> the same <b>image.</b> In addition, fixation durations were similar within a participant and this similarity was associated with memory performance...|$|R
40|$|We {{present a}} system that assists users in viewing videos of lectures on small screen devices, such as cell phones. It {{automatically}} identifies semantic units on the slides, such as bullets, groups of bullets, and <b>images.</b> As the <b>participant</b> <b>views</b> the lecture, the system magnifies the appropriate semantic unit while it {{is the focus of}} the discussion. The system makes this decision based on cues from laser pointer gestures and spoken words that are read off the slide. It then magnifies the semantic element using the slide image and the homography between the slide image and the video frame. Experiments suggest that the semantic units of laser-based events identified by our algorithm closely match those identified by humans. In the case of identifying bullets through spoken words, results are more limited but are a good starting point for more complex methods. Finally, we show that this kind of magnification has potential for improving learning of technical content from video lectures when the resolution of the video is limited, such as when being viewed on hand held devices...|$|R
40|$|Foulsham, T., Dewhurst, R., Nyström, M., Jarodzka, H., Johansson, R., Underwood, G., & Holmqvist, K. (2012). Comparing scanpaths during scene {{encoding}} and recognition: A multidimensional approach. Journal of Eye Movement Research, 5 (4) : 3, 1 - 12. Complex stimuli and tasks elicit particular {{eye movement}} sequences. Previous {{research has focused}} on comparing between these scanpaths, particularly in memory and imagery research where it has been proposed that observers reproduce their eye movements when recognizing or imagining a stimulus. However, {{it is not clear whether}} scanpath similarity is related to memory performance and which particular aspects of the eye movements recur. We therefore compared eye movements in a picture memory task, using a recently proposed comparison method, MultiMatch, which quantifies scanpath similarity across multiple dimensions including shape and fixation duration. Scanpaths were more similar when the same participant’s eye movements were compared from two viewings of the same image than between different <b>images</b> or different <b>participants</b> <b>viewing</b> the same <b>image.</b> In addition, fixation durations were similar within a participant and this similarity was associated with memory performance...|$|R
40|$|Objective: The {{purpose of}} this {{research}} was {{to assess the impact of}} nonstereotypical, positive media portrayals of obese persons on biased attitudes, as well as propose a change in media practices that could reduce public weight bias and consequent negative health outcomes for those who experience weight stigma. Method: Two online experiments were conducted in which <b>participants</b> <b>viewed</b> either a stigmatizing or a positive photograph of an obese model. In Experiment 1 (N � 146), <b>participants</b> <b>viewed</b> a photograph of either a Caucasian or African American obese woman; in Experiment 2 (N � 145), <b>participants</b> <b>viewed</b> either a Caucasian male or female obese model. Multiple linear regression models were used to analyze outcomes for social distance attitudes toward the obese models depicted in the images, in addition to other negative attitudes and <b>image</b> preferences. Results: <b>Participants</b> who <b>viewed</b> the stigmatizing images endorsed stronger social distance attitudes and more negative attitudes toward obese persons than <b>participants</b> who <b>viewed</b> the positive images, and there was a stronger preference for the positive images than the stigmatizing images. These results were consistent regardless of the race or gender of the obese model pictured. Conclusion: The findings indicate that more positive media portrayals of obese individuals may help reduce weight stigma and its associated negative health outcomes...|$|R
40|$|This {{research}} {{examined the}} relationship between thinking styles and nonverbal sending and receiving ability. An experimental design using the slide viewing technique developed by Buck, Savin, Miller, and Caul (1972) was utilized to test participants 2 ̆ 7 nonverbal communication accuracy. Sixty-eight <b>participants</b> (senders) <b>viewed</b> a series of ten slides from five different categories and rated their emotional reactions to each <b>image.</b> While <b>participants</b> were <b>viewing</b> the slides their spontaneous facial displays were secretly videotaped. The videotapes of the senders were then edited and shown to other participants, receivers (N = 167) who each rated six senders on several dimensions. The receivers rated the senders 2 ̆ 7 expressiveness, tried to determine what type of slide the sender viewed, and rated their perceptions of each person 2 ̆ 7 s emotional reaction to each of the slides on the dimensions of happy, sad, afraid, angry, surprise, disgust, and pleasant. Participants 2 ̆ 7 rational and experiential thinking styles were measured using Pacini 2 ̆ 6 Epstein 2 ̆ 7 s (1999) Rational Experiential Inventory. Participants 2 ̆ 7 extraversion was also measured. The experiential thinking measure did not relate to the encoding and decoding of spontaneous communication displays, however, it was positively correlated with expressiveness and extraversion. Communication accuracy was high overall and women were more proficient than men at encoding and decoding. This research found a similar pattern of communication accuracy to those reported by Buck et al. (1972). The limitations of using a written measure of syncretic (experiential) cognition are discussed. ...|$|R
30|$|To {{test for}} other-race effects in this task, we {{recruited}} participants in both Japan and the UK to view both Asian and Western masks. An other-race effect {{should result in}} poorer detection of hyper-realistic masks for Other-race trials (Japanese <b>participants</b> <b>viewing</b> Western masks and British <b>participants</b> <b>viewing</b> Asian masks), compared with Own-race trials (Japanese <b>participants</b> <b>viewing</b> Asian masks and British <b>participants</b> <b>viewing</b> Western masks). Finally, we examined effects of viewing distance by comparing performance in Near (5  m) and Far (20  m) conditions. We expected improved detection of high-realism masks at the closer viewing distance, where more detail is visible.|$|R
40|$|The aim of {{the present}} study was to {{determine}} the effect of social attitudes, empathy and autism on motor priming and imitation of an observed action. There were 60 female participants in the study. The <b>participants</b> <b>viewed</b> a video of a model using a straight or an exaggerated reach trajectory to grasp an object. After the model completed her movement participants were instructed to execute a straight reach to grasp the target object. Prior to the video of the model participants’ social attitudes were primed using either non-social or pro-social <b>images.</b> <b>Participants</b> then filled out measures of empathy (QCAE) and autismlike traits (AQ). It was hypothesized that participants’ reach trajectories would be higher after viewing the model making an exaggerated movement compared to making a straight movement. It was hypothesized that after being primed with pro-social <b>images</b> <b>participants</b> would imitate the models higher reach trajectory compared with the trials in which the participants were primed with non-social images and that this effect would be strongest for participants who scored highly on the QCAE and low on the AQ. Participants’ reaches were significantly higher after viewing the exaggerated reach compared to the straight reach, supporting previous research. Social attitude priming did not affect reach trajectory and the QCAE did not correlate with the imitation effect. AQ correlated with some reach effects. Further research is required to understand the modulating effects of priming and social attitudes on kinematic measures of imitation...|$|R
40|$|When using within - {{subjects}} designs lineup researchers generally use targets {{distinct from}} each other to avoid confusability of targets. Participants (N = 128) learned face-name pairings for 12 targets that were confusable versus distinct (matched vs. not matched on basic descriptors). <b>Participants</b> <b>viewing</b> distinct targets correctly named more targets (. 91 vs. 65). For lineup tasks <b>participants</b> <b>viewing</b> distinct targets had greater correct IDs (. 74 vs. 46) and correct rejections (. 73 vs. 59). <b>Participants</b> <b>viewing</b> distinct targets correctly named more targets (. 97 vs. 72) at a final memory test. Within designs employing distinct targets inflate the apparent accuracy of eyewitness identification decisions. identification...|$|R
30|$|H 4 -a: The more {{negative}} body <b>image</b> <b>participants</b> show the greater likelihood they will engage in cosmetic surgery.|$|R
3000|$|RQ 3 : What {{communication}} or organizational technologies do the <b>participants</b> <b>view</b> as {{pertinent to}} quality school outcomes? [...]...|$|R
40|$|Emotive {{responses}} to foods {{in people with}} eating disorders are incompletely understood in relation to whether the extent of emotional response {{is due to the}} eating disorder or non-specific emotional states. The aims of the present study were to investigate negative and positive emotive {{responses to}} food images in adults with an eating disorder, and to compare responses to a (i) healthy and a (ii) clinic (psychiatry) control group. <b>Participants</b> <b>viewed</b> 20 <b>images</b> (16 of foods previously found to evoke fear, disgust and happiness and 4 neutral images) at half-minute intervals and rated emotive responses on 3 visual analogue scales for each <b>image.</b> <b>Participants</b> with an eating disorder (n = 26) were found to have significantly increased negative emotive (disgust and fear) responses and reduced positive (happiness) responses to the images compared to the 20 clinic and 61 healthy participants. Differences between groups remained significant when controlling for baseline levels of fear, disgust and happiness. Thus, the emotive responses to foods did not appear due to non- specific increases in anxiety or depression but rather was due to the presence of an eating disorder...|$|R
50|$|Arousal induced after {{learning}} reduces source confusion, allowing participants to better retrieve accurate details and reject misinformation. In {{a study of}} how to reduce the misinformation effect, <b>participants</b> <b>viewed</b> four short film clips, each followed by a retention test, which for some participants included misinformation. Afterward, <b>participants</b> <b>viewed</b> another film clip that was either arousing or neutral. One week later, the arousal group recognized significantly more details and endorsed significantly fewer misinformation items than the neutral group.|$|R
40|$|A chapter {{report issued}} by the General Accounting Office with an {{abstract}} that begins "Pursuant to a congressional request, GAO reviewed issues relating to mutual fund fees, focusing on: (1) the trend in mutual fund advisers' costs and profitability; (2) the trend in mutual fund fees; (3) how mutual funds compete; (4) how fees are disclosed to fund investors and how industry <b>participants</b> <b>view</b> these disclosures; and (5) what mutual fund directors' responsibilities are regarding fees and how industry <b>participants</b> <b>view</b> directors' activities. ...|$|R
5000|$|Lurking drop-outs {{represent}} {{a combination of}} 3 and 4. Such a <b>participant</b> <b>views</b> {{some of the questions}} without answering, but also quits the survey prior to reaching the end.|$|R
30|$|To be {{sure that}} there were no {{differences}} in the estimates based on the orientation of the picture, <b>participants</b> <b>viewed</b> all 16 pictures in their original orientation and rotated 180 °. This allowed us to calculate any bias due to body position relative to the <b>image.</b> Finally, <b>participants</b> were shown the pictures a third time and asked to identify each picture. For any response given a confidence rating of 0 or 1, we further probed the participants’ uncertainty by asking them which of the following reasons best described their confidence rating: (a) they have no idea what the orientation could be, (b) the orientation is not knowable from the picture, or (c) there could be a range of possible orientations at which the region extended into the object. After this, participants completed three measures of spatial reasoning.|$|R
40|$|Recent {{research}} has shown that the color red can influence psychological functioning. In the present research we tested the hypothesis that red influences impression formation related to another person’s abilities. We conducted three experiments examining the influence of red on the evaluation of male target persons. In Experiment 1, <b>participants</b> <b>viewing</b> red, relative to green, on the shirt of a person presented on a photograph perceived him to be less intelligent. This effect was strongest in a job application context compared to other contexts. In Experiment 2, focusing solely on the job application context, <b>participants</b> <b>viewing</b> red, relative to blue, on an applicants’ tie perceived him to have less earning and leadership potential. In Experiment 3, <b>participants</b> <b>viewing</b> red, relative to green, on a job applicants’ tie rated him as less likely to be hired, and perceptions of ability and leadership potential mediated this effect. Both the conceptual and applied implications of these findings are discussed...|$|R
40|$|Background. Electronic {{personal}} health records offer a promising {{way to communicate}} medical test results to patients. We compared the usability of tables and hori-zontal bar graphs for presenting medical test results elec-tronically. Methods. We conducted experiments with {{a convenience sample of}} 106 community-dwelling adults. In the first experiment, <b>participants</b> <b>viewed</b> either table or bar graph formats (between subjects) that presented medical test results with normal and abnormal findings. In a second experiment, <b>participants</b> <b>viewed</b> table and bar graph formats (within subjects) that presented test re-sults with normal, borderline, and abnormal findings. Results. <b>Participants</b> required less <b>viewing</b> time when using bar graphs rather than tables. This overall differ-ence was due to superior performance of bar graphs in vi...|$|R
50|$|Because <b>participants</b> <b>view</b> the {{protection}} of vessel data from unauthorized use as crucial, MSSIS enables password-protected, Internet-based sharing of AIS data using encrypted data links (TCP/IP SSL Secure Socket Layer).|$|R
30|$|The final image set {{consisted}} of 148 photographs (37 high-realism masks, 37 low-realism masks, 74 real faces). Each <b>participant</b> <b>viewed</b> the 148 <b>images</b> intermixed {{in a different}} random order (within-subjects design).|$|R
40|$|Young adults’ {{reactions}} to breastfeeding images were assessed using varied approaches. In Study 1, <b>participants</b> <b>viewed</b> posters from a breastfeeding campaign; many anticipated negative {{reaction to the}} campaign. In Study 2, <b>participants</b> <b>viewed</b> novel infant-feeding posters; breastfeeding posters were viewed for less time than bottle-feeding posters, regardless of the task assigned. In Study 3, {{participants were asked to}} rate their comfort level viewing infant-feeding images; greater discomfort was reported for breastfeeding images. Taken together, we argue that many young adults expect, and experience, discomfort viewing breastfeeding, {{but it is important to}} continue using breastfeeding images in promotion efforts...|$|R
5000|$|When <b>participants</b> <b>viewed</b> {{videos of}} {{interactions}} between a sales clerk and a shopper, slow and soothing music {{led to more}} negative evaluations toward the store and salesperson, if the sales pitch was weaker.21 The type of music affected cognitive processing (slow music allowed for greater resources {{to be used in}} evaluating the sales pitch). Thus <b>participants</b> <b>viewed</b> a weaker sales pitch more critically, except when faster music drew more resources.21 Musical fit also applies to retail situations. Regardless of the type of music, however, it needs to at least match the store environment and product to garner positive reactions.21 ...|$|R
30|$|<b>Participants</b> <b>viewed</b> stop-point {{photographs}} with arrows superimposed {{onto them}} and then indicated which of three possible actions they recalled taking at each stop-point (continued on course, turned right, or turned left) (Fig.  3).|$|R
30|$|<b>Participants</b> <b>viewed</b> {{the video}} pairs {{presented}} simultaneously on one computer screen. The videos played three times, {{and then the}} participant responded (same or different). A response triggered the next point light video pair.|$|R
50|$|Singer {{organized}} the 12th Siyum HaShas at Yeshivas Chachmei Lublin on 1 August 2012. <b>Participants</b> <b>viewed</b> a simultaneous broadcast from the event taking place {{that same day}} at the MetLife Stadium in New Jersey.|$|R
40|$|Nonverbal {{behaviors}} {{have the}} ability to affect how we perceive social communications. One of these nonverbal behaviors, a smile, is not always genuinely expressed. Our experiment attempted to improve discernment between genuine and fake smiles by manipulating training and feedback. The training/feedback group received feedback for each video and training. Our control was the no training/no feedback group, in which <b>participants</b> <b>viewed</b> a PowerPoint that presented smile information not relevant to distinguishing among smiles. The training group was given applicable information, through PowerPoint, on distinguishing among smiles along with viewing two videos of genuine and fake smiles. Prior to training, <b>participants</b> <b>viewed</b> 10 smile videos and marked whether they believed the smile was genuine or fake. Following training, the <b>participants</b> <b>viewed</b> 10 new videos. Our sample was comprised of 98 participants from the General Psychology course at Valparaiso University. The results indicated that a very brief and simple training program improved participants’ ability to distinguish between genuine and fake smiles. Surprisingly, our feedback manipulation did not improve detection...|$|R
40|$|The Effect of Exercise Intensity on Memory Consolidation The {{physiological}} response to stress involves {{activation of the}} fight or flight response. In particular, sympathetic nervous system (SNS) activity, circulating catecholamines and glucocorticoids (cortisol) are elevated. Acute stress is associated with enhanced memory consolidation, a result linked to catecholamine and cortisol {{at the time of}} information presentation. Since physical exercise elicits a physiological stress response, it is possible that exercise-induced stress could mimic the memory consolidation processes of other stressors. PURPOSE: To examine the effect of exercise intensity on memory consolidation. METHODS: College-aged participants (n= 40; female = 18, male = 22) were shown 20 IAPS rated images (10 seconds per image) following 25 minutes of seated rest (REST; n= 10) or cycle ergometer exercise designed to elicit either 40 % (LOW; n= 10), 60 % (MOD; n= 9), or 80 % (HIGH; n= 11) of maximal oxygen consumption. Saliva samples were taken before and after each exercise bout for the analysis of salivary cortisol. Seven days following <b>image</b> <b>viewing,</b> <b>participants</b> were asked to recall as many images as possible and both correct and incorrect recalls were recorded for analysis. Data are presented as means and (SD). RESULTS: Salivary cortisol change was greatest after HIGH [87. 6 (154. 7) μg/dL] but only significantly different than REST [4. 4 (33. 1) μg/dL], pCONCLUSIONS: An acute exercise bout of sufficient intensity can improve memory consolidation, particularly of information rated less pleasurable and arousing. However, more information is needed to determine the mechanisms behind this exercise-induced response...|$|R
30|$|In {{addition}} to the trials supervisor who was present in all trials realised, a driving instructor was present in the vehicle during the trials conducted in real traffic conditions. After {{the completion of the}} driving sessions, each participant completed a questionnaire which concerned his/her perception of the driving simulator realism, a questionnaire concerning the simulator sickness symptoms-Simulator Sickness Questionnaire [43], a Rating Scale of Mental Effort [44], aiming to collect <b>participants</b> <b>views</b> on the mental effort required during driving in the driving simulator and a Driving Quality Scale [45], aiming to collect <b>participants</b> <b>views</b> on how good they drove in relation to their average driving in real traffic conditions.|$|R
50|$|The {{activity}} {{found by}} Gauthier when <b>participants</b> <b>viewed</b> non-face objects {{was not as}} strong as when <b>participants</b> were <b>viewing</b> faces, however this could be because we have much more expertise for faces than for most other objects. Furthermore, not all findings of this research have been successfully replicated, for example, other research groups using different study designs have found that the fusiform gyrus is specific to faces and other nearby regions deal with non-face objects.|$|R
40|$|In {{a series}} of experiments, {{it was found that}} {{emotional}} arousal can influence height perception. In Experiment 1, <b>participants</b> <b>viewed</b> either arousing or nonarousing images before estimating the height of a 2 -story balcony and the size of a target on the ground below the balcony. People who viewed arousing images overestimated height and target size more than did those who viewed nonarousing images. However, in Experiment 2, estimates of horizontal distances were not influenced by emotional arousal. In Experiment 3, both valence and arousal cues were manipulated, and it was found that arousal, but not valence, moderated height perception. In Experiment 4, participants either up-regulated or down-regulated their emotional experience while viewing emotionally arousing images, and a control group simply viewed the arousing <b>images.</b> Those <b>participants</b> who up-regulated their emotional experience overestimated height more than did the control or down-regulated participants. In sum, emotional arousal influences estimates of height, and this influence can be moderated by emotion regulation strategies...|$|R
30|$|The {{experiment}} {{was conducted on}} a Macintosh, MacBook Pro using in-house JavaScript scripts. All <b>participants</b> <b>viewed</b> the experiment on a 13.3 -inch, liquid-crystal color screen with a 2560 [*]×[*] 1600 resolution, 227 pixels per inch, and refresh rate of 60  Hz.|$|R
