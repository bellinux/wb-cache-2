2821|4685|Public
25|$|As an example, {{consider}} two-stage linear programs. Here {{the decision}} maker takes some action in the first stage, after which a random event occurs affecting {{the outcome of the}} first-stage decision. A recourse decision can then be made in the second stage that compensates for any bad effects that might have been experienced {{as a result of the}} first-stage decision. The optimal policy from such a model is a single first-stage policy and a collection of recourse decisions (a <b>decision</b> <b>rule)</b> defining which second-stage action should be taken in response to each random outcome.|$|E
500|$|Utilitarianism {{is often}} {{referred}} to as exchange theory or rational choice theory in the context of sociology. This tradition tends to privilege the agency of individual rational actors and assumes that within interactions individuals always seek to maximize their own self-interest. As argued by Josh Whitford, rational actors are assumed to have four basic elements, the individual has (1) [...] "a knowledge of alternatives," [...] (2) [...] "a knowledge of, or beliefs about the consequences of the various alternatives," [...] (3) [...] "an ordering of preferences over outcomes," [...] (4) [...] "A <b>decision</b> <b>rule,</b> to select among the possible alternatives" [...] Exchange theory is specifically attributed to the work of George C. Homans, Peter Blau and Richard Emerson. Organizational sociologists James G. March and Herbert A. Simon noted that an individual's rationality is bounded by the context or organizational setting. The utilitarian perspective in sociology was, most notably, revitalized in the late 20th century by the work of former ASA president James Coleman.|$|E
2500|$|Given the {{hypotheses}} about the currency and the constraints, the optimal <b>decision</b> <b>rule</b> is the model's prediction {{of what the}} animal's best foraging strategy should be. Possible examples of optimal decision rules could be the optimal number of food items that an animal should carry back to its nesting site or the optimal size of a food item that an animal should feed on. [...] Figure 1, shows {{an example of how}} an optimal <b>decision</b> <b>rule</b> could be determined from a graphical model. The curve represents the energy gain per cost (E) for adopting foraging strategy x. [...] Energy gain per cost is the currency being optimized. [...] The constraints of the system determine the shape of this curve. The optimal <b>decision</b> <b>rule</b> (x*) is the strategy for which the currency, energy gain per costs, is the greatest. [...] Optimal foraging models can look very different and become very complex, depending {{on the nature of the}} currency and the number of constraints considered. [...] However, the general principles of currency, constraints, and optimal <b>decision</b> <b>rule</b> remain the same for all models.|$|E
50|$|A general {{criticism}} of non-probabilistic <b>decision</b> <b>rules,</b> discussed in detail at decision theory: alternatives to probability theory, is that optimal <b>decision</b> <b>rules</b> (formally, admissible <b>decision</b> <b>rules)</b> {{can always be}} derived by probabilistic methods, with a suitable utility function and prior distribution (this is the statement of the complete class theorems), and thus that non-probabilistic methods such as info-gap are unnecessary and do not yield new or better <b>decision</b> <b>rules.</b>|$|R
40|$|In {{this article}} we study Markov {{decision}} process (MDP) problems with the restriction that at decision epochs, only {{a finite number of}} given Markov <b>decision</b> <b>rules</b> are admissible. For example, the set of admissible Markov <b>decision</b> <b>rules</b> D could consist of some easy-implementable <b>decision</b> <b>rules.</b> Additionally, many open-loop control problems can be modeled as an MDP with such a restriction on the admissible <b>decision</b> <b>rules.</b> Within the class of available policies, optimal policies are generally nonstationary {{and it is difficult to}} prove that some policy is optimal. We give an example with two admissible <b>decision</b> <b>rules</b> - D={...|$|R
5000|$|The {{introduction}} of randomised <b>decision</b> <b>rules</b> thus creates a larger decision space {{from which the}} statistician may choose his decision. As non-randomised <b>decision</b> <b>rules</b> are a special case of randomised <b>decision</b> <b>rules</b> where one <b>decision</b> or action has probability 1, the original decision space [...] is a proper subset of the new decision space [...]|$|R
2500|$|An optimal {{foraging}} model generates quantitative {{predictions of}} how animals maximize their fitness while they forage. [...] The model building process involves identifying the currency, constraints, and appropriate <b>decision</b> <b>rule</b> for the forager.|$|E
2500|$|The {{optimization}} {{of these}} different foraging and predation strategies {{can be explained by}} the optimal foraging theory. [...] In each case, there are costs, benefits, and limitations that ultimately determine the optimal <b>decision</b> <b>rule</b> that the predator should follow.|$|E
2500|$|OFT is an {{ecological}} {{application of the}} optimality model. This theory assumes that the most economically advantageous foraging pattern will be selected for in a species through natural selection. When using OFT to model foraging behavior, organisms {{are said to be}} maximizing a variable known as the currency, such as the most food per unit time. In addition, the constraints of the environment are other variables that must be considered. Constraints are defined as factors that can limit the forager's ability to maximize the currency. The optimal <b>decision</b> <b>rule,</b> or the organism's best foraging strategy, is defined as the decision that maximizes the currency under the constraints of the environment. [...] Identifying the optimal <b>decision</b> <b>rule</b> is the primary goal of the OFT.|$|E
5000|$|... #Caption: The extreme {{points of}} the risk set, denoted by empty circles, {{correspond}} to nonrandomised <b>decision</b> <b>rules,</b> whereas the thick lines denote the admissible <b>decision</b> <b>rules.</b>|$|R
40|$|Abstract. The {{problem of}} {{learning}} <b>decision</b> <b>rules</b> for sequential tasks is addressed, {{focusing on the}} problem of learning tactical <b>decision</b> <b>rules</b> from a simple flight simulator. The learning method relies on the notion of competition and employs genetic algorithms to search the space of decision policies. Several experiments are presented that address issues arising from differences between the simulation model on which learning occurs and the target environment on which the <b>decision</b> <b>rules</b> are ultimately tested. Key words: sequential <b>decision</b> <b>rules,</b> competition-based learning, genetic algorithm...|$|R
50|$|Further, as {{discussed}} at decision theory: alternatives to probability theory, probabilists, particularly Bayesians probabilists, argue that optimal <b>decision</b> <b>rules</b> (formally, admissible <b>decision</b> <b>rules)</b> {{can always be}} derived by probabilistic methods (this is the statement of the complete class theorems), and thus that non-probabilistic methods such as info-gap are unnecessary and do not yield new or better <b>decision</b> <b>rules.</b>|$|R
2500|$|Decide {{to either}} reject the null {{hypothesis}} {{in favor of the}} alternative or not reject it. The <b>decision</b> <b>rule</b> is to reject {{the null hypothesis}} H0 if the observed value tobs is in the critical region, and to accept or [...] "fail to reject" [...] the hypothesis otherwise.|$|E
2500|$|Another {{limitation}} of OFT {{is that it}} lacks precision in practice. [...] In theory, an optimal foraging model gives researchers specific, quantitative predictions about a predator's optimal <b>decision</b> <b>rule</b> based on the hypotheses about the currency and constraints of the system. [...] However, in reality, {{it is difficult to}} define basic concepts like prey type, encounter rates, or even a patch as the forager perceives them. Thus, while the variables of OFT can seem neat and tidy theoretically, in practice, they can be a bit arbitrary and extremely difficult to measure.|$|E
2500|$|In this model, the {{currency}} being optimized is usually net energy gain per unit time. [...] The constraints are the travel {{time and the}} shape of the curve of diminishing returns. Graphically, {{the currency}} (net energy gain per unit time) is given by the slope of a diagonal line that starts at the beginning of traveling time and intersects the curve of diminishing returns (Figure 3). [...] In order to maximize the currency, one wants the line with the greatest slope that still touches the curve (the tangent line). The place that this line touches the curve provides the optimal <b>decision</b> <b>rule</b> of {{the amount of time that}} the animal should spend in a patch before leaving.|$|E
40|$|A {{structure}} and component {{parts of a}} computer system for diagnostics of malignant neoplasms {{on the base of}} biochemical blood testing indexes are considered. Parametric discriminant analysis and logistic regression method are used as <b>decision</b> <b>rules.</b> The computer system includes both the classic <b>decision</b> <b>rules</b> and robust <b>decision</b> <b>rules</b> that are stable under presence of anomalous observations...|$|R
50|$|Soft <b>decision</b> <b>rules</b> {{may create}} agent {{behaviors}} that emerge as unique within any class of agents that were originally defined as identical (except for incidental {{variables such as}} agent location).The soft <b>decision</b> <b>rules</b> can have a narrow range, indicating a well disciplined, homogenous group whose <b>decision</b> <b>rules</b> are similar or identical, or {{they can have a}} wide range, providing for significant variation among individuals. Soft <b>decision</b> <b>rules</b> can be used with all of an agent’s attributes, as well as leadership style and effectiveness, marksmanship, engagement desire, group affiliation preferences and other characteristics of the agent.|$|R
40|$|In {{this paper}} we study Markov Decision Process (MDP) {{problems}} with the restriction that at decision epochs only {{a finite number of}} given Markovian <b>decision</b> <b>rules</b> may be applied. The elements of the finite set of allowed <b>decision</b> <b>rules</b> should be mixed to improve the performance. The set of allowed Markovian <b>decision</b> <b>rules</b> could for example consist of some easy-implementable <b>decision</b> <b>rules,</b> but also many open-loop control problems can be modelled as an MDP for which the applicable <b>decision</b> <b>rules</b> are restricted. For various subclasses of Markovian policies methods to maximize the performance are obtained, analyzed and illustrated with examples. Advantages and disadvantages of optimizing over particular subclasses of applicable policies are discussed and optimal performances are compared. One of the main results gives sufficient conditions for the existence of an optimal Markovian policy belonging to the subclass of applicable policies having a so-called regular structure. Markov Decision Process, Mixing <b>Decision</b> <b>Rules,</b> Optimization, Regular Sequences...|$|R
2500|$|Day {{concluded}} that custom and law both accorded the Deakins line {{the status of}} official boundary, even if the state of Maryland routinely contested that line as such. [...] "...the evidence contained in this record leaves no room to doubt that after {{the running of the}} Deakins line the people of that region knew and referred to it as the line between the state of Virginia and the state of Maryland." [...] Day cited numerous examples in which both states and the people of both states treated the Deakins line as the boundary between the two states. Such evidence determined the true boundary under principles of equity, Day said. [...] He referred to Virginia v. Tennessee, 148 U.S. 503 (1893), and quoted the holding in that case:"'...a boundary line ... which has been run out, located, and marked upon the earth, and afterwards recognized and acquiesced in by the parties for a long course of years, is conclusive, even if it be ascertained that it varies somewhat from the courses given in the original grant...'" [...] Day traced the lineage of this <b>decision</b> <b>rule</b> back through Penn vs. Baltimore (1750), State of Rhode Island and Providence Plantations v. Commonwealth of Massachusetts, 37 U.S. 657 (1838), State of Rhode Island v. State of Massachusetts, 45 U.S. 591 (1846), State of Indiana v. State of Kentucky, 136 U.S. 479 (1890), and State of Louisiana v. State of Mississippi, 202 U.S. 1 (1906).|$|E
60|$|PRECEDENT, n. In Law, a {{previous}} <b>decision,</b> <b>rule</b> or practice which, {{in the absence}} of a definite statute, has whatever force and authority a Judge may choose to give it, thereby greatly simplifying his task of doing as he pleases. As there are precedents for everything, he has only to ignore those that make against his interest and accentuate those in the line of his desire. Invention of the precedent elevates the trial-at-law from the low estate of a fortuitous ordeal to the noble attitude of a dirigible arbitrament.|$|E
6000|$|Wo to thee, de Launay, {{in such an}} hour, if thou canst not, {{taking some}} one firm <b>decision,</b> <b>rule</b> circumstances! Soft speeches will not serve; hard grape-shot is questionable; but {{hovering}} {{between the two is}} unquestionable. Ever wilder swells the tide of men; their infinite hum waxing ever louder, into imprecations, perhaps into crackle of stray musketry,--which latter, on walls nine feet thick, cannot do execution. The Outer Drawbridge has been lowered for Thuriot; new deputation of citizens (it is the third, and noisiest of all) penetrates that way into the Outer Court: soft speeches producing no clearance of these, de Launay gives fire; pulls up his Drawbridge. A slight sputter;--which has kindled the too combustible chaos; made it a roaring fire-chaos! Bursts forth insurrection, at sight of its own blood (for there were deaths by that sputter of fire), into endless rolling explosion of musketry, distraction, execration;--and overhead, from the Fortress, let one great gun, with its grape-shot, go booming, to shew what we could do. The Bastille is besieged! ...|$|E
40|$|This paper {{analyzes}} {{an evolutionary}} {{version of the}} Public Good game in which boundedly rational agents can use imitation and best-reply <b>decision</b> <b>rules.</b> Several possibilities for both <b>decision</b> <b>rules</b> {{to be present in}} the population are considered. I show that altruistic behavior might survive if switching between the <b>decision</b> <b>rules</b> occurs less often than the probabilities of errors in choosing a strategy and if local neighborhoods are not too small or too large...|$|R
50|$|In 1950, the Indian Statistical Institute {{was visited}} by Abraham Wald, who {{was giving a}} lecture tour {{sponsored}} by the International Statistical Institute. Wald greatly impressed Basu. Wald had developed a decision-theoretic foundations for statistics in which Bayesian statistics was a central part, because of Wald's theorem characterising admissible <b>decision</b> <b>rules</b> as Bayesian <b>decision</b> <b>rules</b> (or limits of Bayesian <b>decision</b> <b>rules).</b> Wald also showed the power of using measure-theoretic probability theory in statistics.|$|R
40|$|A {{family of}} supervised, nonparametric <b>decision</b> <b>rules,</b> based on {{tolerance}} regions, is described {{which includes the}} k-Nearest Neighbor <b>decision</b> <b>rules</b> when there are two classes. There are two practical reasons for doing so: first, a family of <b>decision</b> <b>rules</b> similar to the k-Nearest Neighbor rules can be specified which applies to a broader collection of pattern recognition problems. This is because in the general class of rules constraints are weakened {{between the number of}} training samples required in each training sample set and the respective a priori class probabilities; and, a discrete loss function weighting the importance of the finite number of ways to make a decision error can be introduced. Second, within the family of <b>decision</b> <b>rules</b> based on tolerance regions, there are <b>decision</b> <b>rules</b> which have a property allowing for preprocessing of the training set data resulting in significant data reduction. Theoretical performance for a special case is presented...|$|R
5000|$|Whether a <b>decision</b> <b>rule</b> [...] has {{low risk}} {{depends on the}} true state of nature [...] A <b>decision</b> <b>rule</b> [...] dominates a <b>decision</b> <b>rule</b> [...] {{if and only if}} [...] for all , and the {{inequality}} is strict for some [...]|$|E
5000|$|In {{decision}} theory, an admissible <b>decision</b> <b>rule</b> is a maximal element {{with respect}} to the partial order of dominating <b>decision</b> <b>rule.</b>|$|E
50|$|In {{statistical}} decision theory, a randomised <b>decision</b> <b>rule</b> {{or mixed}} <b>decision</b> <b>rule</b> is a <b>decision</b> <b>rule</b> that associates probabilities with deterministic decision rules. In finite decision problems, randomised decision rules define a risk set {{which is the}} convex hull of the risk points of the nonrandomised decision rules.|$|E
40|$|The {{problem of}} {{learning}} <b>decision</b> <b>rules</b> for sequential tasks is addressed, {{focusing on the}} problem of learning tactical <b>decision</b> <b>rules</b> from a simple flight simulator. The learning method relies on the notion of competition and employs genetic algorithms to search the space of decision policies. Several experiments are presented that address issues arising from differences between the simulation model on which learning occurs and the target environment on which the <b>decision</b> <b>rules</b> are ultimately tested. Key words: sequential <b>decision</b> <b>rules,</b> competition-based learning, genetic algorithms Running Head: Learning Sequential <b>Decision</b> <b>Rules</b> Machine Learning 5 (4), 355 - 381. - 2 - 1. Introduction In response to the knowledge acquisition bottleneck associated with the design of expert systems, research in machine learning attempts to automate the knowledge acquisition process and to broaden the base of accessible sources of knowledge. The choice of an appropriate learning technique depends on [...] ...|$|R
40|$|It {{is argued}} that the {{efficiency}} of an organization structure is determined by how well it fits into the culture {{in which it is}} set. What a fit is, and what makes it good or bad is discussed in terms of those <b>decision</b> <b>rules</b> and rewards in organizations that make them efficient {{in the context of the}} beliefs and values in Islamic cultures. The kinds of organization structure <b>decision</b> <b>rules</b> that fit well the <b>decision</b> <b>rules</b> of Islamic cultures are derived. Also identified are the bases of organization rewards that fit well with Islamic beliefs about man's control over transformations and the relation of work to earthly and heavenly rewards. culture <b>decision</b> <b>rules</b> fit Islam organization structure rewards...|$|R
40|$|The {{concept of}} {{transformative}} <b>decision</b> <b>rules</b> provides auseful tool for analyzing {{what is often}} referred to as the`framing', or `problem specification', or `editing' phase ofdecision making. In the present study we analyze a fundamentalaspect of transformative <b>decision</b> <b>rules,</b> viz. permutability. A setof transformative <b>decision</b> <b>rules</b> is, roughly put, permutable justin case it does not matter in which order the rules are applied. It is argued that in order to be normatively reasonable, sets oftransformative <b>decision</b> <b>rules</b> have to satisfy a number ofstructural conditions that together imply permutability. Thisformal result gives support to a non-sequential theory of framing,i. e., a theory which prescribes no uniform order in which differentsteps in the framing process have to be performed...|$|R
5000|$|An {{admissible}} <b>decision</b> <b>rule</b> is {{one that}} is not dominated by any other <b>decision</b> <b>rule,</b> i.e. there is no <b>decision</b> <b>rule</b> that has equal risk as or lower risk than it for all parameters and strictly lower risk than it for some parameter. In a finite decision problem, the risk point of an admissible <b>decision</b> <b>rule</b> has either lower x-coordinates or y-coordinates than all other risk points or, more formally, it is the set of rules with risk points of the form [...] such that [...] Thus {{the left side of the}} lower boundary of the risk set is the set of admissible decision rules.|$|E
50|$|Each <b>decision</b> <b>rule</b> {{should be}} minimal. Since a <b>decision</b> <b>rule</b> is an implication, by a minimal <b>decision</b> <b>rule</b> we {{understand}} such an implication {{that there is}} no other implication with an antecedent of at least the same weakness (in other words, rule using a subset of elementary conditions or/and weaker elementary conditions) and a consequent of at least the same strength (in other words, rule assigning objects to the same union or sub-union of classes).|$|E
50|$|Majority rule is a <b>decision</b> <b>rule</b> that selects {{alternatives}} {{which have}} a majority, that is, {{more than half the}} votes. It is the binary <b>decision</b> <b>rule</b> used most often in influential decision-making bodies, including the legislatures of democratic nations.|$|E
40|$|Set-valued {{information}} system is an important formal framework {{for the development of}} decision support systems. We focus on the <b>decision</b> <b>rules</b> acquisition for the inconsistent disjunctive set-valued ordered decision {{information system}} in this paper. In order to derive optimal <b>decision</b> <b>rules</b> for an inconsistent disjunctive set-valued ordered decision information system, we define the concept of reduct of an object. By constructing the dominance discernibility function for an object, we compute reducts of the object via utilizing Boolean reasoning techniques, and then the corresponding optimal <b>decision</b> <b>rules</b> are induced. Finally, we discuss the certain reduct of the inconsistent disjunctive set-valued ordered decision information system, which can be used to simplify all certain <b>decision</b> <b>rules</b> as much as possible...|$|R
40|$|In most {{synthesis}} evaluation {{systems and}} decision-making systems, data {{are represented by}} objects and attributes of objects {{with a degree of}} belief. Formally, these data can be abstracted by the form (objects; attributes; P), where P represents a kind degree of belief between objects and attributes, such that, P is a basic probability assignment. In the paper, we provide a kind of probability information system to describe these data and then employ rough sets theory to extract probability <b>decision</b> <b>rules.</b> By extension of Dempster-Shafer evidence theory, we can get probabilities of antecedents and conclusion of probability <b>decision</b> <b>rules.</b> Furthermore, we analyze the consistency of probability <b>decision</b> <b>rules.</b> Based on consistency of probability <b>decision</b> <b>rules,</b> we provide an inference method to finish inference of probability <b>decision</b> <b>rules,</b> which can be used to decide the class of a new object x′. The conclusion points out that the inference method of the paper not only deals with precise information, but also imprecise or uncertain information as well...|$|R
40|$|The {{problem of}} <b>decision</b> <b>rules</b> extracting (or more general {{knowledge}} discovery) from experimental data is intensively studied (see e. g. [2], [3], [9], [11], [12], [14], [18], [20], [21], [22], [27]). We apply rough set methods and boolean reasoning for <b>decision</b> <b>rules</b> discovery from <b>decisions</b> tables. It {{is not possible}} in general to extract general laws from experimental data by computing first all reducts of a decision table representing data and next <b>decision</b> <b>rules</b> from these reducts. We investigate a problem how information about changes of reducts in random samples of the decision table {{can be used to}} generate these laws. The reducts stable in the process determined by different samples of decision table are called dynamic reducts. The set of <b>decision</b> <b>rules</b> is generated from theses dynamic reducts [2], [3]. We present also applications of a new idea of dynamic <b>decision</b> <b>rules</b> for object classification. We report the results of experiments with monk's problem data, market data and hand [...] ...|$|R
