1096|1756|Public
5000|$|Failure reporting, {{analysis}} and corrective action systems (<b>failure</b> <b>data</b> collection) ...|$|E
50|$|The {{criticality}} analysis may be quantitative or qualitative, {{depending on the}} availability of supporting part <b>failure</b> <b>data.</b>|$|E
5000|$|Every node in {{the cluster}} has the same role. There is no single point of <b>failure.</b> <b>Data</b> is {{distributed}} across the cluster (so each node contains different data), {{but there is no}} master as every node can service any request.|$|E
5000|$|... #Subtitle level 2: Startup <b>failures,</b> <b>data</b> {{corruption}} and hardware issues ...|$|R
50|$|Government and {{commercial}} failure rate data: Handbooks of <b>failure</b> rate <b>data</b> for various components {{are available from}} government {{and commercial}} sources. MIL-HDBK-217F, Reliability Prediction of Electronic Equipment, is a military standard that provides <b>failure</b> rate <b>data</b> for many military electronic components. Several <b>failure</b> rate <b>data</b> sources are available commercially that focus on commercial components, including some non-electronic components.|$|R
40|$|Abstract. In {{biomedical}} studies, correlated <b>failure</b> time <b>data</b> arise often. Although {{point and}} confidence interval estimation for quantiles with independent censored <b>failure</b> time <b>data</b> have been extensively studied, estimation for quantiles with correlated <b>failure</b> time <b>data</b> {{has not been}} developed. In this article, we propose a nonparametric estimation method for quantiles with correlated <b>failure</b> time <b>data.</b> We derive the asymptotic properties of the quantile estimator and propose confidence interval estimators based on the bootstrap and kernel smoothing methods. Simulation studies are carried out to investigate the finite sample properties of the proposed estimators. Finally, we illustrate the proposed method with a data set from a study of patients with otitis media...|$|R
50|$|Testing: The most {{accurate}} {{source of data}} is to test samples of the actual devices or systems in order to generate <b>failure</b> <b>data.</b> This is often prohibitively expensive or impractical, so that the previous data sources are often used instead.|$|E
5000|$|According to the African Development Bank, Somalia is [...] "characterized by {{a severe}} lack of basic {{economic}} and social statistics". This situation has been exacerbated by {{the civil war and}} institutional collapse, although even prior to Somalia's state <b>failure,</b> <b>data</b> was often unreliable.|$|E
50|$|NonStop OS is a message-based {{operating}} system designed for fault tolerance. It works with process pairs and ensures that backup processes on redundant CPUs take over {{in case of}} a process or CPU <b>failure.</b> <b>Data</b> integrity is maintained during those takeovers; no transactions or data are lost or corrupted.|$|E
40|$|In {{clinical}} trials and engineering studies that {{are followed by}} periodic follow-ups, it is predominantly to have partly interval-censored <b>failure</b> time <b>data.</b> Partly interval-censored <b>failure</b> time <b>data</b> is composed of exact observations and interval-censored observations. This paper discusses two-sample parametric comparison of reliability function {{in the existence of}} partly interval-censored <b>failure</b> time <b>data.</b> We have constructed a score test and likelihood ratio test for this kind of <b>failure</b> time <b>data</b> under piecewise exponential distribution by using multiple imputation technique. Simulation study is established to assess the proposed test, which indicates that the presented procedure works well. Finally, an example is given for illustration purposes...|$|R
40|$|ABSTRACT: The main aim of {{this paper}} is to analyze the failure of IC engine components. By {{analyzing}} the failure rate of the components in IC engines and also to find out failure range for each and every component. For doing, the real time <b>failure</b> <b>data’s</b> and their life periods for each components in the IC engines has been analyzed, from these data’s the amount of defects in their original production activities and also defects after the design modification work also been concluded. Based on the <b>failure</b> <b>data’s</b> the criticality for each component has been ranked out and risk priority number (RPN) and the corresponding transformed scale for each component has been sorted. Keyword(s) : risk priority number, failure range, transformed scale, Design modification. I...|$|R
50|$|Under-reporting is a <b>failure</b> in <b>data</b> reporting.|$|R
5000|$|In 2013, the BSEE and the U.S. Department of Transportation Statistics (BTS) {{signed an}} Interagency Agreement (IAA) to create SafeOCS, for {{voluntary}} confidential reporting of ‘near misses’ happening on Outer Continental Shelf. It was later {{expanded to include}} mandatory reporting of equipment <b>failure</b> <b>data</b> as required in 30 CFR 250.730 and 30 CFR 250.803.|$|E
5000|$|Given a {{component}} database calibrated with field <b>failure</b> <b>data</b> that is reasonably accurate , the method can predict product level failure rate and failure mode data {{for a given}} application. The predictions {{have been shown to}} be more accurate [...] than field warranty return analysis or even typical field failure analysis given that these methods depend on reports that typically do not have sufficient detail information in failure records.|$|E
50|$|Predictive Failure Analysis (PFA) {{refers to}} {{computer}} mechanisms that analyse trends in corrected errors to predict future failures of hardware components and proactively enabling mechanisms to avoid them. Predictive Failure Analysis was originally used as {{term for a}} proprietary IBM technology for monitoring the likelihood of hard disk drives to fail, although the term is now used generically {{for a variety of}} technologies for judging the imminent failure of CPU's, memory and I/O devices. See also first <b>failure</b> <b>data</b> capture.|$|E
5000|$|Fault-tolerant availability: Riak {{replicates}} key/value stores {{across a}} cluster of nodes with a default n_val of three. In the case of node outages due to network partition or hardware <b>failures,</b> <b>data</b> can still be written to a neighboring node beyond the initial three, and read-back due to its [...] "masterless" [...] peer-to-peer architecture.|$|R
40|$|Now a days, Internet plays a {{major role}} in our day to day {{activities}} e. g., for online transactions, online shopping, and other network related applications. Internet suffers from slow convergence of routing protocols after a network failure which becomes a growing problem. Multiple Routing Configurations [MRC] recovers network from single node/link failures, but does not support network from multiple node/link failures. In this paper, we propose Enhanced MRC [EMRC], to support multiple node/link <b>failures</b> during <b>data</b> transmission in IP networks without frequent global re-convergence. By recovering these <b>failures,</b> <b>data</b> transmission in network will become fast...|$|R
5000|$|... 4xx (Client <b>Failure),</b> {{response}} <b>data</b> {{which indicates}} that the request has failed.|$|R
50|$|Aul led {{the effort}} to build Microsoft's first product {{telemetry}} systems. Before then, Microsoft had no idea about how many problems were occurring on customer systems, nor were they able to debug them. Aul led {{part of the team}} creating the technologies to allow upload of crash, hang, and other <b>failure</b> <b>data</b> (Windows Error Reporting) as well as Microsoft's anonymous data collection system for usage data (Customer Experience Improvement Program.) Aul won several engineering awards, patents, and published a paper based on this work.|$|E
50|$|According to the H2 documentation, such {{problems}} are related {{not only to}} the DB engine design, but also to the storage caching mechanism. As storage devices use write cache in order to increase speed, in a situation of power <b>failure,</b> <b>data</b> in the device's cache is lost. Administrators have then to assess the common trade off between speed and data loss risks {{in the context of the}} business requirements and must carefully consider the design of the power supply and UPS of critical servers.|$|E
50|$|Safety {{testing of}} mine shaft {{elevator}} rails is routinely undertaken. The method involves destructive testing of {{a segment of}} the cable. The ends of the segment are frayed, then set in conical zinc molds. Each end of the segment is then secured in a large, hydraulic stretching machine. The segment is then placed under increasing load to the point of <b>failure.</b> <b>Data</b> about elasticity, load, and other factors is compiled and a report is produced. The report is then analyzed {{to determine whether or not}} the entire rail is safe to use.|$|E
5000|$|<b>Failure</b> rate <b>data</b> can be {{obtained}} in several ways. The most common means are: ...|$|R
40|$|Multivariate {{correlated}} <b>failure</b> time <b>data</b> can {{be classified}} into two different groups: structural <b>failure</b> time <b>data</b> and longitudinal <b>failure</b> time <b>data.</b> As compared {{to the analysis of}} the structural <b>failure</b> time <b>data,</b> the analysis of longitudinal <b>failure</b> time <b>data</b> has however proven to be difficult, perhaps because of the difficulty in the modeling the true longitudinal correlation structures. In the present thesis, following certain longitudinal correlation models, recently developed for discrete data, we develop three longitudinal correlation models for exponential failure times to deal with such multivariate longitudinal data. Under these three models, we construct the co-variance structures of the martingales of the failure times for both uncensored and censored cases, and use them to develop a generalized estimating equation approach to estimate the parameters of main interest, namely, the hazard ratio parameters. The efficiency loss due to misspecification of the correlation structure is studied for both uncensored and censored cases. As the proposed generalized estimating equation approach use either the underlying true correlation structure for both uncensored and censored cases or a suitable robust correlation structure for the uncensored case, the methodology yields consistent as well as efficient estimators for the hazard ratio parameters. We apply the methodology to a numerical example...|$|R
5000|$|... #Caption: Media that's {{suffered}} a catastrophic electronic <b>failure</b> requires <b>data</b> recovery {{in order to}} salvage its contents.|$|R
50|$|Virtual Organization for Innovative Conceptual Engineering Design (VOICED) is {{a virtual}} {{organization}} that promotes innovation in engineering design. This project is the collaborative work of researchers at five universities across the United States, and is funded by the National Science Foundation. The goal of this virtual organization is to facilitate the sharing of design information between often geographically dispersed engineers and designers {{through the use of}} a robust and sophisticated design repository. Additionally, functional data can be mapped to historical <b>failure</b> <b>data</b> and possible components to create a conceptual design.|$|E
5000|$|The {{stricken}} F4 did {{not remain}} a complete <b>failure.</b> <b>Data</b> from F4's failure permitted the saving of F1 from a premature failure. Since {{all of the}} Leasats are spin-stabilized, they have a bearing point that connects the non-rotating and rotating parts of the spacecraft. After F4's communication failure, it suffered a spin lock while attempting to jostle the communications payload: the spun and despun sections locked together. Remembering this second failure of F4, and with F1 beginning to wear out at the spin bearing, {{it was decided to}} [...] "flip" [...] F1 every six months to keep the payload in the sun. Thus F1 went on to operate smoothly for its remaining life and never encountered a locked despun section.|$|E
50|$|For {{existing}} systems, it is arguable {{that any}} attempt by a responsible programs {{to correct the}} root cause of discovered failures may render the initial MTBF estimate invalid, as new assumptions (themselves subject to high error levels) of the effect of this correction must be made. Another practical issue is the general un-availability of detailed <b>failure</b> <b>data,</b> with those available often featuring inconsistent filtering of failure (feedback) data, and ignoring statistical errors (which are very high for rare events like reliability related failures). Very clear guidelines must be present to count and compare failures related to different type of root-causes (e.g. manufacturing-, maintenance-, transport-, system-induced or inherent design failures). Comparing different types of causes may lead to incorrect estimations and incorrect business decisions about the focus of improvement.|$|E
40|$|Title from PDF {{of title}} page (University of Missouri [...] Columbia, viewed on September 13, 2010). The entire thesis text is {{included}} in the research. pdf file; the official abstract appears in the short. pdf file; a non-technical public abstract appears in the public. pdf file. Dissertation advisor: Dr. Jianguo Sun. Vita. Includes bibliographical references. Ph. D. University of Missouri [...] Columbia 2009. Dissertations, Academic [...] University of Missouri [...] Columbia [...] Statistics. [ACCESS RESTRICTED TO THE UNIVERSITY OF MISSOURI AT AUTHOR'S REQUEST. ] This dissertation discusses regression analysis of interval-censored <b>failure</b> time <b>data,</b> which occur in many fields including demographical, epidemiological, financial, medical, and sociological studies (Sun, 2006). It consists of three parts. The first part considers regression analysis of current status data under the additive hazards model and in particular, we considered the situation where the observation times depend on covariates. The second part considers regression analysis of interval-censored <b>failure</b> time <b>data</b> under the additive hazards model and time-dependent covariates. The third part considers regression analysis of interval-censored <b>failure</b> time <b>data</b> under the linear transformation model. For these situations, we proposed a general semiparametric method based on multiple imputation for inference under the regression models. This multiple imputation converts the analysis of interval-censored <b>failure</b> time <b>data</b> to that of right-censored <b>failure</b> time <b>data.</b> A major advantage of the approach is its simplicity and it can be easily implemented by using the existing software packages for right-censored <b>failure</b> time <b>data.</b> Extensive simulation studies are conducted and indicate that the approaches perform well for practical situations and are comparable to the existing methods. Real data applications are provided and model checking is discussed...|$|R
40|$|Thesis (M. Sc.) [...] Memorial University of Newfoundland, 2001. Mathematics and StatisticsBibliography: leaves 87 - 89. Multivariate {{correlated}} <b>failure</b> time <b>data</b> can {{be classified}} into two different groups: structural <b>failure</b> time <b>data</b> and longitudinal <b>failure</b> time <b>data.</b> As compared {{to the analysis of}} the structural <b>failure</b> time <b>data,</b> the analysis of longitudinal <b>failure</b> time <b>data</b> has however proven to be difficult, perhaps because of the difficulty in the modeling the true longitudinal correlation structures. In the present thesis, following certain longitudinal correlation models, recently developed for discrete data, we develop three longitudinal correlation models for exponential failure times to deal with such multivariate longitudinal data. Under these three models, we construct the co-variance structures of the martingales of the failure times for both uncensored and censored cases, and use them to develop a generalized estimating equation approach to estimate the parameters of main interest, namely, the hazard ratio parameters. The efficiency loss due to misspecification of the correlation structure is studied for both uncensored and censored cases. As the proposed generalized estimating equation approach use either the underlying true correlation structure for both uncensored and censored cases or a suitable robust correlation structure for the uncensored case, the methodology yields consistent as well as efficient estimators for the hazard ratio parameters. We apply the methodology to a numerical example...|$|R
5000|$|... #Caption: Media {{that has}} {{suffered}} a catastrophic electronic <b>failure</b> requires <b>data</b> recovery in order to salvage its contents.|$|R
50|$|Forensic {{inquiry into}} the failed process or product is the {{starting}} point of failure analysis. Such inquiry is conducted using scientific analytical methods such as electrical and mechanical measurements, or by analysing <b>failure</b> <b>data</b> such as product reject reports or examples of previous failures of the same kind. The methods of forensic engineering are especially valuable in tracing product defects and flaws. They may include fatigue cracks, brittle cracks produced by stress corrosion cracking or environmental stress cracking for example. Witness statements can be valuable for reconstructing the likely sequence of events and hence the chain of cause and effect. Human factors can also be assessed when the cause of the failure is determined. There are several useful methods to prevent product failures occurring in the first place, including failure mode and effects analysis (FMEA) and fault tree analysis (FTA), methods which can be used during prototyping to analyse failures before a product is marketed.|$|E
50|$|The POWER4 has {{a unified}} L2 cache, {{divided into three}} equal parts. Each has its own {{independent}} L2 controller which can feed 32 bytes of data per cycle. The Core Interface Unit (CIU) connects each L2 controller to either the data cache or instruction cache in {{either of the two}} processors. The Non-Cacheable (NC) Unit is responsible for handling instruction serializing functions and performing any noncacheable operations in the storage topology. There is an L3 cache controller, but the actual memory is off-chip. The GX bus controller controls I/O device communications, and there are two 4-byte wide GX buses, one incoming and the other outgoing. The Fabric Controller is the master controller for the network of buses, controlling communications for both L1/L2 controllers, communications between POWER4 chips {4-way, 8-way, 16-way, 32-way} and POWER4 MCM’s. Trace-and-Debug, used for First <b>Failure</b> <b>Data</b> Capture, is provided. There is also a Built In Self Test function (BIST) and Performance Monitoring Unit (PMU). Power-on reset (POR) is supported.|$|E
50|$|Once {{systems or}} parts are being produced, {{reliability}} engineering attempts to monitor, assess, and correct deficiencies. Monitoring includes electronic and visual surveillance of critical parameters identified during the {{fault tree analysis}} design stage. Data collection is highly dependent {{on the nature of}} the system. Most large organizations have quality control groups that collect <b>failure</b> <b>data</b> on vehicles, equipment and machinery. Consumer product failures are often tracked by the number of returns. For systems in dormant storage or on standby, it is necessary to establish a formal surveillance program to inspect and test random samples. Any changes to the system, such as field upgrades or recall repairs, require additional reliability testing to ensure the reliability of the modification. Since it is not possible to anticipate all the failure modes of a given system, especially ones with a human element, failures will occur. The reliability program also includes a systematic root cause analysis that identifies the causal relationships involved in the failure such that effective corrective actions may be implemented. When possible, system failures and corrective actions are reported to the reliability engineering organization.|$|E
40|$|The {{statistical}} problem {{considered in}} this article is the parametric treatment comparison when partly interval-censored <b>failure</b> time <b>data</b> exist. Partly interval-censored <b>failure</b> time <b>data</b> are composed of exact observations and interval-censored observations. This phenomenon often occurs in clinical trials and health studies that require periodic following up with patients. The authors constructed a score test and likelihood ratio test for this type of <b>failure</b> time <b>data</b> under Weibull distributions using multiple imputation technique. A simulation study and a modified secondary data set from breast cancer study are used to assess the proposed test and illustrate {{the differences between the two}} tests. The results indicate that the presented procedure works well for both tests, but the likelihood ratio test is better than the score test in certain situations...|$|R
40|$|This paper {{discusses}} {{regression analysis}} of interval-censored <b>failure</b> time <b>data,</b> which occur in many fields including demographical, epidemiological, financial, medical, and sociological studies. For the problem, {{we focus on}} the situation where the survival time of interest can be described by the additive hazards model and a multiple imputation approach is presented for inference. A major advantage of the approach is its simplicity and it can be easily implemented by using the existing software packages for right-censored <b>failure</b> time <b>data.</b> Extensive simulation studies are conducted which indicate that the approach performs well for practical situations and is comparable to the existing methods. The methodology is applied to a set of interval-censored <b>failure</b> time <b>data</b> arising from an AIDS clinical trial. ...|$|R
5000|$|Backup of {{individual}} disk partitions. Volume backups are very useful for {{recovery in the}} case of a disk <b>failure</b> or <b>data</b> corruption ...|$|R
