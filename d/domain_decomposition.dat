4290|197|Public
2500|$|<b>Domain</b> <b>decomposition</b> method (Distribution {{of system}} data for {{parallel}} computing) ...|$|E
2500|$|GEM {{uses the}} delta-f particle-in-cell (PIC) plasma {{simulation}} method. An expansion about an adiabatic response {{is made for}} electrons to overcome the limit of small time step, which {{is caused by the}} fast motion of electrons. [...] GEM uses a novel electromagnetic algorithm allowing direct numerical simulation of the electromagnetic problem at high plasma pressures. [...] GEM uses a two-dimensional <b>domain</b> <b>decomposition</b> (see <b>domain</b> <b>decomposition</b> method) of the grid and particles to obtain good performance on massively parallel computers. [...] A Monte Carlo method is used to model small angle Coulomb collisions.|$|E
50|$|In {{overlapping}} <b>domain</b> <b>decomposition</b> methods, the subdomains overlap by {{more than}} the interface. Overlapping <b>domain</b> <b>decomposition</b> methods include the Schwarz alternating method and the additive Schwarz method. Many <b>domain</b> <b>decomposition</b> methods can be written and analyzed as a special case of the abstract additive Schwarz method.|$|E
40|$|Summary. In this paper, we {{establish}} {{the existence of}} a stable decomposition in the Sobolev space H 1 0 for <b>domain</b> <b>decompositions</b> which are not shape regular in the usual sense. In particular, we consider <b>domain</b> <b>decompositions</b> where the largest subdomain is significantly larger than the smallest subdomain. We provide an explicit upper bound for the stable decomposition that is independent of the ratio between the diameter of the largest and the smallest subdomain. ...|$|R
40|$|Non shape regular domain decompositions: an {{analysis}} using a stable decomposition in H 1 0 Martin Gander 1, Laurence Halpern 2, and Kévin Santugini Repiquet 3 Abstract In this paper, we establish {{the existence of}} a stable decomposition in the Sobolev space H 1 0 for <b>domain</b> <b>decompositions</b> which are not shape regular in the usual sense. In particular, we consider <b>domain</b> <b>decompositions</b> where the largest subdomain is significantly larger than the smallest subdomain. We provide an explicit upper bound for the stable decomposition that is independant of the ratio between the diameter of the largest and the smallest subdomain. ...|$|R
40|$|The Community Atmosphere Model (CAM) is the {{atmosphere}} {{component of the}} Community Climate System Model (CCSM), and is the largest consumer of computing resources in typical CCSM simulations. The parallel implementation of the Community Atmosphere Model (CAM) employs {{a number of different}} <b>domain</b> <b>decompositions.</b> Currently, each decomposition must utilize the same number of MPI processes, limiting the scalability of CAM to that of the least scalable decomposition. This limitation becomes unacceptably restrictive when including additional physical processes such as atmospheric chemistry or cloud-resolving physics. This paper reports on current efforts to improve CAM scalability by allowing the number of active MPI processes to vary between <b>domain</b> <b>decompositions.</b> 1...|$|R
5000|$|In mathematics, Neumann-Neumann {{methods are}} <b>domain</b> <b>decomposition</b> preconditioners named {{so because they}} solve a Neumann problem on each {{subdomain}} {{on both sides of}} the interface between the subdomains. [...] Just like all <b>domain</b> <b>decomposition</b> methods, so that the number of iterations does not grow with the number of subdomains, Neumann-Neumann methods require the solution of a coarse problem to provide global communication. The balancing <b>domain</b> <b>decomposition</b> is a Neumann-Neumann method with a special kind of coarse problem.|$|E
50|$|<b>Domain</b> <b>decomposition</b> methods solve a {{boundary}} value problem by splitting it into smaller {{boundary value problem}}s on subdomains and iterating to coordinate the solution between adjacent subdomains. A coarse problem with one or few unknowns per subdomain is used to further coordinate the solution between the subdomains globally. The problems on the subdomains are independent, which makes <b>domain</b> <b>decomposition</b> methods suitable for parallel computing. <b>Domain</b> <b>decomposition</b> methods are typically used as preconditioners for Krylov space iterative methods, such as the conjugate gradient method or GMRES.|$|E
50|$|In mathematics, {{numerical}} analysis, and numerical partial differential equations, <b>domain</b> <b>decomposition</b> methods solve {{a boundary}} value problem by splitting it into smaller {{boundary value problem}}s on subdomains and iterating to coordinate the solution between adjacent subdomains. A coarse problem with one or few unknowns per subdomain is used to further coordinate the solution between the subdomains globally. The problems on the subdomains are independent, which makes <b>domain</b> <b>decomposition</b> methods suitable for parallel computing. <b>Domain</b> <b>decomposition</b> methods are typically used as preconditioners for Krylov space iterative methods, such as the conjugate gradient method or GMRES.|$|E
40|$|This chapter {{presents}} the basic features of high-order integral collocation techniques and demonstrates their application to engineering problems. Emphasis {{is placed on}} the advantage of the integral collocation approach over the conventional differential approach in the treatment of multiple boundary conditions, complex geometries and <b>domain</b> <b>decompositions...</b>|$|R
40|$|Abstract Load {{balancing}} {{is one of}} the key {{problems in}} distributed computing. Its influence is expected to increase even further as systems grow towards exascale dimensions, as systems do not simply grow, but become more complex and heterogeneous. In order to find good <b>domain</b> <b>decompositions,</b> the characteristics of hardware and software must be known to the partitioning algorithm. This thesis presents Dodo, an extensible framework to describe HPC hardware as well as large-scale scientific simulations. Dodo uses a hardware model, a worker model, data elements, and algorithms which are all described using graph-based data structures. These data structures are annotated with custom meta data to describe each layer in detail. <b>Domain</b> <b>decompositions</b> are expressed through graph mappings. These mappings combine the different models to form a comprehensive view of a simulation run. Each sub-model is described separately, which increases reusability and allows to exchange specific sub-models to adapt the description to a given situation. Mappings and metadata can be modified at run-time to describe dynamic behavior of hardware and software. The C ++ -based implementation is capable of expressing hardware models well within the expected range of upcoming exascale cluster systems. All data structures are based on widely used libraries and can be interfaced with third-party tools. Through these features, Dodo forms the base for tools that can specialize in the creation of optimized <b>domain</b> <b>decompositions</b> and mappings...|$|R
40|$|AbstractThe {{application}} of a conforming spectral collocation method to certain nonconforming <b>domain</b> <b>decompositions</b> leads to global matrices which have a particular block structure. We study the performance of various direct linear system solvers, some of which exploit this block structure, on a Cray J- 916 vector computer, an SGI Power Challenge 8000, and an IBM RS 6000 workstation...|$|R
5000|$|... #Caption: Two {{levels of}} <b>domain</b> <b>decomposition</b> in dynamic substructuring.|$|E
50|$|Non-overlapping <b>domain</b> <b>decomposition</b> {{methods are}} also called {{iterative}} substructuring methods.|$|E
5000|$|<b>Domain</b> <b>decomposition</b> method (Distribution {{of system}} data for {{parallel}} computing) ...|$|E
40|$|This study proposes an {{algorithm}} {{capable of}} working in parallel for solving large and sparse linear equations under given right hand side (RHS) ranges. A comparative study to the direct linear programming method is reported theoretically, computationally and discussed. Moreover, the approach can be adapted for the system under <b>domain</b> <b>decompositions</b> structure leading to a better efficiency experimentally...|$|R
40|$|<b>Domain</b> <b>decompositions</b> are {{typically}} pursued {{in order to}} split up large elliptic boundary-value problems into a set of smaller problems that can each be solved separately, with {{the solution to the}} larger prob-lem obtained through iterative application of inter-domain boundary conditions. Here we review a related problem that arises in the study of unsteady advection-diusion with two solvent phases. A boundar...|$|R
40|$|We {{characterize}} the capacitance matrix associated with <b>domain</b> <b>decompositions</b> by spectral collocation methods for {{the solution of}} elliptic problems. Richardson and conjugate gradient iterations with preconditioners wel suited for computation in a parallel environment are discussed. The spectral properties of the preconditioned capacitance matrix are analyzed, also for the case of substructures with internal vertices. © 1988 Instituto di Elaborazione della Informazione del CNR...|$|R
5000|$|Efficient {{parallel}} processing support based on <b>domain</b> <b>decomposition</b> and message passing paradigms.|$|E
5000|$|The {{roots of}} dynamic substructuring {{can be found}} in the field of <b>domain</b> <b>decomposition.</b> In 1890 the {{mathematician}} Hermann Schwarz came up with an iterative procedure for <b>domain</b> <b>decomposition</b> which allows to solve for continuous coupled subdomains. However, many of the analytical models of coupled continuous subdomains do not have closed-form solutions, which led to discretization and approximation techniques such as the Ritz method (which is sometimes called the Raleigh-Ritz method due the similarity between Ritz's formulation and the Raleigh ratio) the boundary element method (BEM) and the finite element method (FEM). These methods can be considered as [...] "first level" [...] <b>domain</b> <b>decomposition</b> techniques.|$|E
5000|$|Implementation of {{short-range}} potentials via linked-cell {{method and}} parallelization by dynamic load-balanced <b>domain</b> <b>decomposition</b> ...|$|E
40|$|We {{address the}} {{coupling}} of an advection equation with a diffusion-advection equation, for solutions featuring boundary layers. We consider non-overlapping <b>domain</b> <b>decompositions</b> and we face up the heterogeneous problem using an extended variational formulation. We will prove the equivalence between the latter formulation and a treatment {{based on a}} singular perturbation theory. An exhaustive comparison in terms of solution and computational efficiency between these formulations is carried ou...|$|R
40|$|In this paper, a new {{numerical}} scheme {{based on}} non-overlapping <b>domain</b> <b>decompositions</b> and integrated Chebyshev approximations for solving elliptic differential equations is presented. The distinguishing feature of the present scheme is that it achieves a Cp continuous solution across the interfaces (p is {{the order of the}} differential equation). Several test problems are employed to verify the method. The obtained results indicate that the achievement of higher-order smoothness leads to a significant improvement in accuracy...|$|R
40|$|The virtual control method, {{recently}} introduced to approximate elliptic and parabolic problems by overlapping <b>domain</b> <b>decompositions</b> (see [7 - 9]), is proposed here for heterogeneous problems. Precisely, we address the coupling of an advection equation with a diffusion-advection equation, {{with the aim}} of modelling boundary layers. We investigate both overlapping and non-overlapping (disjoint) subdomain decompositions. In the latter case, several cost functions are considered and a numerical assessment of our theoretical conclusions is carried out...|$|R
50|$|Jinchao Xu is an American-Chinese mathematician, {{known for}} his work on multigrid methods and <b>domain</b> <b>decomposition</b> methods.|$|E
5000|$|Charbel Farhat, <b>Domain</b> <b>Decomposition</b> and Parallel Processing, Postgraduate Studies in Supercomputing, ed. FNRS/NFWO, Universie de Liege, Belgium, 1992.|$|E
5000|$|... (2) The <b>domain</b> <b>decomposition</b> {{may be used}} to in the BPM boundary-only {{solution}} of large-gradient source functions problems.|$|E
40|$|The moment realizability {{criteria}} {{have been}} used to test the domains of validity of the Boltzmann and Euler Equations. With the help of this criteria teh coupling of the Boltzmann and Euler equations have been performed in two dimensional spatial space. The time evolution of <b>domain</b> <b>decompositions</b> for such equations have been presented in different time steps. The numerical resulta obtained from the coupling code have been compared with those from the pure Boltzmann one...|$|R
40|$|The {{potential}} benefits of employing optimal discretization-based (ODB) refinement criteria for vector tetrahedra to achieve load balancing in three-dimensional parallel adaptive finite-element electromagnetic analysis are considered. Specifically, the ability of this class of adaption refinement criteria to resolve effective <b>domain</b> <b>decompositions</b> based on initial discretizations with only relatively few tetrahedra is examined for generalized vector Helmholtz systems. The effectiveness of the new load balancing method is demonstrated with adaptively refined finite-element meshes for benchmark systems...|$|R
40|$|The {{alternate}} strip-based iterative substructuring algorithms are preconditioning {{techniques for}} the discrete systems which {{arise from the}} finite element approximation of symmetric elliptic boundary value problems. The algorithms {{presented in this paper}} may be viewed as simple, direct extensions of the two disjoint subdomains case to the multiple <b>domains</b> <b>decomposition</b> with interior cross-points. The separate treatment of vertex points is avoided by dividing the original nonoverlapping subdomains into strip-subregions. Both scalability and efficiency are enhanced by alternating the direction of the strips...|$|R
5000|$|Andrea Toselli and Olof Widlund, <b>Domain</b> <b>Decomposition</b> Methods - Algorithms and Theory, Springer Series in Computational Mathematics, Vol. 34, 2004 ...|$|E
5000|$|Solution of {{large-scale}} finite element problems with <b>domain</b> <b>decomposition</b> and data handling techniques on high performance parallel and distributed computer environments ...|$|E
50|$|He {{has worked}} in the field of multigrid methods and <b>domain</b> <b>decomposition</b> methods. He {{developed}} the balancing <b>domain</b> <b>decomposition</b> method and, with coauthors, published the convergence proofs of the FETI, FETI-DP, and BDDC methods, and the proof of the equivalence of the FETI-DP and the BDDC methods. He has been involved in the field of dynamic data driven application systems and data assimilation with applications in wildfire and epidemic modeling. He has contributed to the WRF-Fire software.|$|E
40|$|This {{article is}} {{concerned}} with the use of integrated radial-basis-function networks (IRBFNs) and non-overlapping <b>domain</b> <b>decompositions</b> (DDs) for numerically solving one- and two-dimensional elliptic problems. A substructuring technique is adopted, where subproblems are discretized by means of one-dimensional IRBFNs. A distinguishing feature of the present DD technique is that the continuity of the RBF solution across the interfaces is enforced with one order higher than with conventional DD techniques. Several test problems governed by second- and fourth-order differential equations are considered to investigate the accuracy of the proposed technique...|$|R
40|$|MD Nastran tackles all {{important}} Normal Mode Analyses utilizing both Shared Memory Parallelism (SMP) and Distributed Memory Parallelism (DMP). The technical approaches include Frequency and Geometry <b>domain</b> <b>decompositions</b> and their Hierarchical and Recursive executions. Efficient execution of above two paradigms and solutions requires extreme care in allocating hardware resources. The topic {{is even more}} important given hardware variety today, ranging from single node multi-core workstations through multiple nodes clusters to single image many-core systems addressing very large memory space. This paper will explore Memory, Input/Output, Communication latency and bandwidth requirement...|$|R
40|$|This paper investigates two {{numerical}} implementations of continuum {{boundary conditions}} in parallel high performance computing (HPC) systems {{in conjunction with}} multiscale modelling comprising molecular dynamics (MD) and computational fluid dynamics (CFD) methods. The multiscale method provides the best compromise in terms of accuracy and computational cost in mesoscale regimes, however, there are still algorithmic challenges preventing the practical application of these methods. The present study investigates some of these challenges, namely different <b>domain</b> <b>decompositions</b> of the momentum transferred from the continuum domain to the atomistic region in conjunction with HPC parallelisatio...|$|R
