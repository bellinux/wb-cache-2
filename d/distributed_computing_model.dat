131|10000|Public
50|$|The {{object-oriented}} {{approach is}} not just a programming model. It can be used equally well as an interface definition language for distributed systems. The objects in a <b>distributed</b> <b>computing</b> <b>model</b> tend to be larger grained, longer lasting, and more service-oriented than programming objects.|$|E
50|$|A {{population}} protocol is a <b>distributed</b> <b>computing</b> <b>model</b> {{formed by}} resource-limited mobile agents which {{meet in a}} random way according to an interaction graph. Functions are computed by updating the state of agents whenever they meet based on the previous value of the states, {{and the result of}} the computation can be read in the states of the agents once the computation has converged.|$|E
50|$|Crypto cloud {{computing}} {{is a new}} secure {{cloud computing}} architecture. Cloud computing is a large-scale <b>distributed</b> <b>computing</b> <b>model</b> that is driven by economies of scale. It integrates a set of abstracted, virtualized, dynamically-scalable, and managed resources, such as computing power, storage, platforms, and services. External users can access to resources over the Internet using terminals, especially mobile terminals. Cloud architectures are developed in on-demand fashion. That is, the resources are dynamically assigned to a user according to his request, and relinquished after the job is done.|$|E
40|$|<b>Distributed</b> <b>computing</b> <b>models</b> {{for sharing}} {{resources}} such as Grids, Peer-to-Peer systems, or voluntary computing are becoming increasingly popular. This book intends to discover fresh avenues of research and amendments to existing technologies, aiming at the successful deployment of commercial distributed system...|$|R
40|$|The {{immediate}} {{past has}} witnessed an increased amount {{of interest in}} local algorithms, i. e., constant time distributed algorithms. In {{a recent survey of}} the topic (Suomela, ACM Computing Surveys, 2013), it is argued that local algorithms provide a natural framework {{that could be used in}} order to theoretically control infinite networks in finite time. We study a comprehensive collection of <b>distributed</b> <b>computing</b> <b>models</b> and prove that if infinite networks are included in the class of structures investigated, then every universally halting distributed algorithm is in fact a local algorithm. To contrast this result, we show that if only finite networks are allowed, then even very weak <b>distributed</b> <b>computing</b> <b>models</b> can define nonlocal algorithms that halt everywhere. The investigations in this article continue the studies in the intersection of logic and <b>distributed</b> <b>computing</b> initiated in (Hella et al., PODC 2012) and (Kuusisto, CSL 2013) ...|$|R
50|$|Contributions {{that combine}} theory and {{practice}} and that exploit formal methods and theoretical foundations to present novel solutions to problems arising from the development of distributed systems are encouraged. This conference covers <b>distributed</b> <b>computing</b> <b>models</b> and formal specification, testing and verification methods. The application domains include all kinds of application-level distributed systems, telecommunication services, Internet, embedded and real-time systems, as well as networking and communication security and reliability.|$|R
50|$|Objectivity/DB is a {{distributed}} {{database that}} provides a single logical view across a federation of databases distributed across the network. It uses a <b>distributed</b> <b>computing</b> <b>model</b> that links a small software library with the client application. The client transparently communicates with remote servers that are functionally simpler than their equivalents in centralized database server architectures. There are lock, remote data transfer and query agent server processes. The distributed architecture helps make Objectivity/DB inherently scalable and reliable. It has sustained ingest rates in excess of one terabyte per hour while simultaneously supporting data fusion and query operations.|$|E
5000|$|There are {{tradeoffs}} {{between the}} two models. Larger numbers of computers means increased management complexity, {{as well as a}} more complex programming model and issues such as throughput and latency between nodes; also, some applications do not lend themselves to a <b>distributed</b> <b>computing</b> <b>model.</b> In the past, the price difference {{between the two}} models has favored [...] "scale up" [...] computing for those applications that fit its paradigm, but recent advances in virtualization technology have blurred that advantage, since deploying a new virtual system over a hypervisor (where possible) is often less expensive than actually buying and installing a real one. Configuring an existing idle system has always been less expensive than buying, installing, and configuring a new one, regardless of the model.|$|E
50|$|Astropulse {{searches}} for both single pulses and regularly repeating pulses. This experiment represents {{a new strategy}} for SETI, postulating microsecond timescale pulses as opposed to longer pulses or narrowband signals. They may also discover pulsars and exploding primordial black holes, both of which would emit brief wideband pulses. The {{primary purpose of the}} core Astropulse algorithm is coherent de-dispersion of the microsecond radio pulses for which Astropulse is searching. Dispersion of a signal occurs as the pulse passes through the interstellar medium (ISM) plasma, because the high frequency radiation goes slightly faster than the lower frequency radiation. Thus, the signal arrives at the radio-telescope dispersed depending upon the amount of ISM plasma between the Earth and the source of the pulse. Dedispersion is computationally intensive, thus lending itself to the <b>distributed</b> <b>computing</b> <b>model.</b>|$|E
40|$|Embedded systems greatly outnumber desktop {{computing}} systems and are witnessing rapid growth as {{increasing numbers of}} industrial, commercial and consumer devices incorporate embedded intelligence. In addition, there are emerging application classes which were hitherto not feasible, but will be enabled by the programmability and connectivity of these pervasive computing elements. The scale and fragility of these networks make traditional <b>distributed</b> <b>computing</b> <b>models</b> inadequate. Presented is a system [...] ...|$|R
30|$|The {{convergence}} of the <b>distributed</b> <b>computing</b> <b>models</b> is proposed {{to solve the}} tasks of collecting, processing and integration of big sensor data in the monitoring of distributed objects and processes. This approach includes: GRID convergence models, cloud, fog and mobile computing [13, 14]; association of computing clusters (grid, cloud and fog) in a single system; integration server application business logic, operating platforms, data warehouses; unification of administrative mechanism computing medium, information security on all data processing and storage levels.|$|R
40|$|This project {{addresses}} {{a set of}} problems that require intensive computation and that come from different scientific and technological fields. In these computationally expen-sive applications, efficient approaches are paramount for {{the solution of the}} problems in practical terms. The problems to be tackled in this project are: image processing applied to determination of the structure of biological specimens in electron microscopy; Coding and compression for progressive transmission of image and video; Nonlinear programming techniques and new global optimization (both deterministic and stochastic) methods for solving real problems; Numerical methods for the simulation of complex systems that are described by means of integral-differential equations. The research to be carried out in this project is focused from different perspectives: (1) development of novel specific methods to face the problems above mentioned; (2) Analysis, design and development of <b>distributed</b> <b>computing</b> <b>models</b> under heterogeneous multiprocessor systems (e. g. dynamic load bal-ancing, hybrid computation paradigms, such as the combination multithreading-message passing, etc.) to efficiently deal with the real applications addressed in this project; (3) Implementation of the developed methods, according to the <b>distributed</b> <b>computing</b> <b>models,</b> to be executed on heterogeneous parallel environments...|$|R
50|$|By late 1996, JD Edwards {{delivered}} to its customers {{the result of}} a major corporate initiative: the software was now ported to platform-independent client-server systems. It was branded JD Edwards OneWorld, an entirely new product with a graphical user interface and a <b>distributed</b> <b>computing</b> <b>model</b> replacing the old server-centric model. The architecture JD Edwards had developed for this newer technology, called Configurable Network Computing or CNC, transparently shielded business applications from the servers that ran those same applications, the databases in which the data were stored, and the underlying operating system and hardware.By first quarter 1998, JD Edwards had 26 OneWorld customers and was moving its medium-sized customers to the new client-server flavor of ERP. By second quarter 1998, JDE had 48 customers, and by 2001, the company had more than 600 customers using OneWorld, a fourfold increase over 2000.|$|E
3000|$|We {{assume a}} {{standard}} <b>distributed</b> <b>computing</b> <b>model</b> (see, e.g., [5, 21] for additional details) where n robots, p 1,…,p [...]...|$|E
40|$|Distributed {{applications}} can {{be quite}} difficult to design and implement due to problems such as: the latency of communication, the synchronization between processes and the recovery from partial failures. JavaSpaces provides a <b>distributed</b> <b>computing</b> <b>model</b> that {{takes care of the}} inherent problems in distributed computing on behalf of the developers...|$|E
5000|$|... μFluids@Home — a <b>distributed</b> <b>computing</b> {{project that}} <b>models</b> the {{behavior}} of liquid rocket propellants in micro-g ...|$|R
40|$|Membrane systems (P systems) are <b>distributed</b> <b>computing</b> <b>models</b> {{inspired}} by living cells where {{a collection of}} processors jointly achieves a computing task. The problem of maximal independent set (MIS) selection in a graph is to choose a set of nonadjacent nodes to which no further nodes can be added. In this letter, we design a class of simple neural-like P systems to solve the MIS selection problem efficiently in a distributed way. This new class of systems possesses two features that are attractive for both <b>distributed</b> <b>computing</b> and membrane computing: first, the individual processors do not need any information about the overall size of the graph; second, they communicate using only one-bit messages...|$|R
40|$|Due to {{the advent}} of {{multicore}} machines, shared memory <b>distributed</b> <b>computing</b> <b>models</b> taking into account asynchrony and process crashes {{are becoming more and}} more important. This paper visits some of the models for these systems, and analyses their properties from a computability point of view. Among them, the snapshot model and the iterated model are particularly investigated. The paper visits also several approaches that have been proposed to model crash failures. Among them, the wait-free case where any number of processes can crash is fundamental. The paper also considers models where up to t processes can crash, and where the crashes are not independent. The aim of this survey is to help the reader to better understand recent advances on what is known about the power and limits of <b>distributed</b> <b>computing</b> shared memory <b>models</b> and their underlying mathematics. Ce rapport est une introduction au modèles de calcul asynchrone pour les systèmes à mémoire partagée...|$|R
40|$|We {{show that}} it is {{impossible}} to " the level of fault-tolerance of a system solving consensus by combining less fault-tolerant components into a more fault-tolerant system. To do this, we consider an asynchronous <b>distributed</b> <b>computing</b> <b>model</b> in which a known set of processes interact in two ways: by using reliable point-to-point channels, and by accessing shared services...|$|E
40|$|The computability {{power of}} a <b>distributed</b> <b>computing</b> <b>model</b> is {{determined}} by the communication media available to the processes, the timing assumptions about processes and communication, and the nature of failures that processes can suffer. In a companion paper we showed how dynamic epistemic logic can be used to give a formal semantics to a given <b>distributed</b> <b>computing</b> <b>model,</b> to capture precisely the knowledge needed to solve a distributed task, such as consensus. Furthermore, by moving to a dual model of epistemic logic defined by simplicial complexes, topological invariants are exposed, which determine task solvability. In this paper we show how to extend the setting above to include in the knowledge of the processes, knowledge about the model of computation itself. The extension describes the knowledge processes gain about the current execution, in problems where processes have no input values at all. Comment: arXiv admin note: text overlap with arXiv: 1703. 1100...|$|E
40|$|Abstract. On {{the basis}} of a case study of {{agent-based}} distributed computation, we develop a more integrative perspective on agent-based system theoretically and experientially. We construct a multi-agent system which exchange KQML message by a mobile agent based on IBM Aglet mobile developing platform and IBM JKQML. Compared with existing <b>distributed</b> <b>computing</b> <b>model,</b> our multi-agent example improves the computational efficiency...|$|E
40|$|The {{traditional}} <b>models</b> of <b>distributed</b> <b>computing</b> focus {{mainly on}} networks of computer-like devices that can exchange large messages {{with their neighbors}} and perform arbitrary local computations. Recently, there is a trend to apply <b>distributed</b> <b>computing</b> methods to networks of sub-microprocessor devices, e. g., biological cellular networks or networks of nano-devices. However, the suitability of the traditional <b>distributed</b> <b>computing</b> <b>models</b> to these types of networks is questionable: do tiny bio/nano nodes "compute" and/or "communicate" {{essentially the same as}} a computer? In this paper, we introduce a new model that depicts a network of randomized finite state machines operating in an asynchronous environment. Although the computation and communication capabilities of each individual device in the new model are, by design, much weaker than those of a computer, we show that {{some of the most important}} and extensively studied <b>distributed</b> <b>computing</b> problems can still be solved efficiently...|$|R
40|$|AbstractMembrane systems, {{also called}} P systems, were {{introduced}} by Gh. Păun, {{as a new}} class of biologically inspired <b>distributed</b> <b>computing</b> <b>models.</b> Several variants of P systems were already shown to be computationally universal. One of these variants, introduced in Gh. Păun (J. Automata Languages Combin. 6 (1) (2001) 75), is able to solve SAT in linear time. In this paper, we show how this class of P systems (with membrane division) can theoretically break the most widely used cryptosystem, DES. We prove that given an arbitrary (plain-text, cipher-text) pair, one can recover the DES key in linear time with respect to the length of the key...|$|R
40|$|In {{this paper}} we present {{practical}} experiences {{gathered from the}} employment of two popular Java-based mobile-agent platforms, IBM's Aglets and Mitsubishi's Concordia. We present some basic <b>distributed</b> <b>computing</b> <b>models</b> and describe their adaptation to the mobile-agent paradigm. Upon these models we develop a set of frameworks for distributed database access over the World-Wide Web, using IBM's Aglets and Mitsubishi's Concordia platforms. We compare the two platforms both quantitatively and qualitatively. For the quantitative comparison, we propose, employ, and validate an approach to evaluate and analyze mobile-agent framework performance. For the qualitative assessment, we present our observations about the programmability and robustness of, and mobility provided by, the two platforms...|$|R
40|$|Large {{volumes of}} data are being {{produced}} by modern applications at an ever increasing rate. The automatic analysis of such huge data volume is a challenging task since {{a large amount}} of interesting knowledge can be extracted. Association rule mining allows discovering interesting and hidden correlations among data. Since this mining process is characterized by computationally intensive tasks, efficient distributed approaches are needed to increase its scalability. This paper proposes a novel cloud-based service, named SeARuM, to efficiently mine association rules on a <b>distributed</b> <b>computing</b> <b>model.</b> SeARuM consists of a series of distributed MapReduce jobs run in the cloud. Each job performs a different step in the association rule mining process. As a case study, the proposed approach has been applied to the network data scenario. The experimental validation, performed on two real network datasets, shows the effectiveness and the efficiency of SeARuM in mining association rules on a <b>distributed</b> <b>computing</b> <b>model...</b>|$|E
40|$|Web-Services {{can be seen}} as a newly {{emerging}} <b>distributed</b> <b>computing</b> <b>model</b> for the Web. They cater for {{the need}} to establish business-to-business (B 2 B) interactions on the Web. Web-Services consider a loosely coupled component model encapsulating business logic and interact with other components using XML protocols. Based on one case study, this paper discusses architectural issues and requirements for software configuration, distribution, and deployment of web-services...|$|E
40|$|MapReduce是一种并行分布式计算模型，用于大规模数据集的并行运算。它具有良好的可扩展性、容错性、可用性，现在，无论在工业界还是在学术界都得到了广泛的应用。MapReduce比较热门的一个应用领域是处理大型表的连接操作，其中连接操作广泛应用于日志分析、数据分析处理以及联机分析处理等方面。应用MapReduce模型来处理连接操作，可以大幅度提高连接操作的速度，进而提高了数据分析效率和用户满意度。 现有的基于MapReduce的连接算法，按连接表的数量可以分为两表连接和多表连接两种。目前，针对两表连接的研究优化已经相当成熟，而针对多表连接的算法及其优化仍有很大的改进空间。特别是在处理链式多表 [...] . MapReduce, a {{parallel}} and <b>distributed</b> <b>computing</b> <b>model,</b> {{has been used}} to process parallel computing for large-scale data sets. It has a good scalability, fault tolerance and availability. Now it has been widely used in industry and academia. And processing join operations for large tables {{is one of the most}} popular aspects in MapReduce applications. Join operations are widely used in log analysis, [...] . 学位：工学硕士院系专业：信息科学与技术学院_计算机科学与技术学号： 2302013115316...|$|E
40|$|Autonomous {{agents are}} mobile {{applications}} that are launched on data warehouses to perform specific queries or {{to search for}} patterns in data. With mobile agent technology, a developer is not bound by more traditional <b>distributed</b> <b>computing</b> <b>models,</b> for example, two-tier client-server models, three-tier middleware-oriented models, and so on. The Mobile Agent technology facilitates flexible code distribution, i. e., factoring functionality and communications using the most appropriate strategies for the task at hand. Moreover, this functionality can move to the most appropriate network host, as needed, on demand. In this paper, we investigate the suitability of mobile agent technology for <b>distributed</b> <b>computing</b> applications. Our discussion and observations are based on two practical case studies i. e. distributed sorting and searching using IBM-ASDK (Aglet Software Development Kit) framework for employing mobile agents...|$|R
40|$|<b>Distributed</b> <b>computing</b> remains {{inaccessible}} {{to a large}} number of users, in spite of many open source platforms and extensive commercial offerings. While distributed computation frameworks have moved beyond a simple map-reduce model, many users are still left to struggle with complex cluster management and configuration tools, even for running simple embarrassingly parallel jobs. We argue that stateless functions represent a viable platform for these users, eliminating cluster management overhead, fulfilling the promise of elasticity. Furthermore, using our prototype implementation, PyWren, we show that this model is general enough to implement a number of <b>distributed</b> <b>computing</b> <b>models,</b> such as BSP, efficiently. Extrapolating from recent trends in network bandwidth and the advent of disaggregated storage, we suggest that stateless functions are a natural fit for data processing in future computing environments...|$|R
40|$|DIRAC (Distributed Infrastructure with Remote Agent Control) {{has been}} {{developed}} by the CERN LHCb physics experiment to facilitate large scale simulation and user analysis tasks spread across both grid and non-grid computing resources. It consists of a small set of distributed stateless Core Services, which are centrally managed, and Agents which are managed by each computing site. DIRAC utilizes concepts from existing <b>distributed</b> <b>computing</b> <b>models</b> to provide a lightweight, robust, and exible system. This paper will discuss the architecture, performance, {{and implementation of the}} DIRAC system which has recently been used for an intensive physics simulation involving more than forty sites, 90 TB of data, and in excess of one thousand 1 GHz processor-years...|$|R
40|$|As a new <b>distributed</b> <b>computing</b> <b>model,</b> {{crowdsourcing}} lets people leverage {{the crowd}} 2 ̆ 7 s intelligence and wisdom toward solving problems. This article proposes {{a framework for}} characterizing various dimensions of quality control in crowdsourcing systems, a critical issue. The authors briefly review existing quality-control approaches, identify open issues, and look to future research directions. In the Web extra, the authors discuss both design-time and runtime approaches in more detail...|$|E
40|$|In {{this article}} the {{requirements}} for the future experiments of elementary particle physics are discussed. The nature of physics phenomena expected at the LHC collider at CERN leads to an unprecedented scale of the computing infrastructure for the data storage and analysis. The possible solution {{is based on the}} <b>distributed</b> <b>computing</b> <b>model,</b> and is presented {{within the context of the}} global unification of the computer resources as proposed by the GRID projects. (7 refs) ...|$|E
40|$|We {{present a}} new {{approach}} to distributing processed telemetry data among spacecraft flight controllers within the control centers at NASA's Johnson Space Center. This approach facilitates the development of application programs which integrate spacecraft-telemetered data and ground-based synthesized data, then distributes this information to flight controllers for analysis and decision-making. The new approach combines various distributed computing models into one hybrid <b>distributed</b> <b>computing</b> <b>model.</b> The model employs both client-server and peer-to-peer distributed computing models cooperating to provide users with information throughout a diverse operations environment. Specifically, it provides an attractive foundation upon which we are building critical real-time monitoring and control applications, while simultaneously lending itself to peripheral applications in playback operations, mission preparations, flight controller training, and program development and verification. We have realized the hybrid <b>distributed</b> <b>computing</b> <b>model</b> through an information sharing protocol. We shall describe the motivations that inspired us to create this protocol, along with a brief conceptual description of the distributed computing models it employs. We describe the protocol design in more detail, discussing many of the program design considerations and techniques we have adopted. Finally, we describe how this model is especially suitable for supporting the implementation of distributed expert system applications...|$|E
40|$|This thesis compares weak <b>distributed</b> <b>computing</b> <b>models</b> {{that are}} suit- able for {{extremely}} limited wireless networks. The comparison is mainly between multiple variations of radio networks and population protocols. The analysis {{is based on}} model features, computability and algorithmic complexity. The thesis analyses essential and optional model features, and organizes the models accordingly. It discusses the applicability of results from stronger models to radio network models, including impossibility results, algorithms and their runtime. It analyzes different radio network algorithms for the classical problems {{in terms of their}} features, and it discusses their applicability to other radio network models. It reviews the fundamental differences between population protocols and radio networks. Lastly, the comparative analysis summarizes fundamental differences and separating features...|$|R
40|$|Introduction In this paper, {{we study}} {{the problem of}} pricing American {{securities}} using a multithreaded parallel <b>computing</b> <b>model</b> known as the Efficient Architecture for Running Threads (EARTH). In essence, the EARTH model differs from other <b>distributed</b> <b>computing</b> <b>models</b> in that each processing node consists of an Execution Unit (EU), where actual computing takes place, and a Synchronization Unit (SU), where communication and synchronization tasks are performed. By delegating communication and synchronization tasks to the SU, these tasks can proceed concurrently with processing, hiding network latencies and thereby producing significant speedups in overall execution time. In the EARTH execution model, a program is divided into threads that are scheduled atomically using dataflow [...] like synchronization operations (see Hum, Maquelin, Theobald, Tian, Gao and Hendren (1996)). These "EARTH Operations" comprise a rich set of primitives, and are initiated by the threads...|$|R
40|$|ISBN: 0 - 7695 - 2256 - 4 International audienceDIRAC (Distributed Infrastructure with Remote Agent Control) {{has been}} {{developed}} by the CERN LHCb physics experiment to facilitate large scale simulation and user analysis tasks spread across both grid and non-grid computing resources. It consists of a small set of distributed stateless Core Services, which are centrally managed, and Agents which are managed by each computing site. DIRAC utilizes concepts from existing <b>distributed</b> <b>computing</b> <b>models</b> to provide a lightweight, robust, and flexible system. This paper will discuss the architecture, performance, {{and implementation of the}} DIRAC system which has recently been used for an intensive physics simulation involving more than forty sites, 90 TB of data, and in excess of one thousand 1 GHz processor-years...|$|R
