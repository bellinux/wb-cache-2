59|0|Public
40|$|Figure. 1 is {{the flow}} chart of our web spam {{detection}} strat-egy. The detection {{is based on the}} content analysis features, WebGraph related features and HostGraph related features. Next,we will introduce the feature extraction. Con ten t based <b>Featu</b> r es+ W ebgr aph r e la ted <b>Featu</b> r es+ HostGr aph r e la ted <b>Featu</b> r es W eb Spam Detect ion Detect ion r esu lt Figure 1 : Flow chart of the spam detection strategy. 1. 1 Content Analysis Features and WebGrap...|$|E
40|$|Featural {{representations}} of similarity data assume that people represent stimuli {{in terms of}} a set of discrete properties. We consider the differences in <b>featu</b> al representations that arise from making fo u di#erent assu;LK' ns abo u how similarity ismeasu) q' Three of these similarity models [...] - the common <b>featu</b> 2 L model, the distinctive <b>featu</b> es model, and Tversky's seminal contrast model [...] - have been considered previoued. The other model is new, and modifies the contrast model byassu ming that each individu al <b>featu</b> re only ever acts as a common or distinctive feature. Each of the four models is tested on previou sly examined similarity data, relating to kinship terms, and on a new data set, relating to faces. In fitting the models, we use the Geometric Complexity Criterion to balance the competing demands of data-fit and model complexity. The resuq 2 show that both common and distinctive features are important for stimuim representation, and we argue that the modified contrast model combines these two components in a more effective and interpretable way than Tversky's original formulation...|$|E
40|$|We propose in {{this paper}} {{a new way of}} {{considering}} retrieval of stru ctu red docu m ents, b y ex ploiting non-stru ctu ral rela-tions b etween stru ctu red docu m ent elem ents (dox els). T hese relations m ay b e de ned b y hu m an b eings (e. g. b y the au-thors of the docu m ents for navigation or reference pu rposes), b u t m ay also b e created b y the inform ation retrieval system (e. g. u sing k N N). U nlik e P agerank or H IT S that separate <b>featu</b> res link and content <b>featu</b> res, we integrate these two aspects b y de ning a relative speci city and a relative ex-hau stivity b etween dox els. We u se these <b>featu</b> res, as well as the dox el content, in a com prehensive m atching process. O ne concern here is to facilitate the ex ploration of the resu lt space b y selecting the relevant dox els, and b y indicating po-tential good neighb ou rs to access from one dox el. R esu lts of ex perim ents on the IN E X 2 0 0 5 test collection are presented...|$|E
40|$|This summary {{presents}} {{the development of}} a real-time probing sy accurately (better than 0. 5 micrometer) scanning a circular <b>featu</b> 100 % inspection. This uses a closed-loop control method employin translated in a radial direction and that is mounted on a precision s of the stylus tip relative to the probe base as it is maintained a applied force is then used to represent deviation of the surface pr...|$|E
40|$|Modern Thermodynamics: From Heat Engines to Dissipative Structures, Second Edition {{presents}} a comprehensive introduction to 20 th century thermodynamics {{that can be}} applied to both equilibrium and non-equilibrium systems, unifying what was traditionally divided into 'thermodynamics' and 'kinetics' into one theory of irreversible processes. This comprehensive text, suitable for introductory as well as advanced courses on thermodynamics, has been widely used by chemists, physicists, engineers and geologists.   Fully revised and expanded, this new edition includes the following updates and <b>featu...</b>|$|E
40|$|Praise for the First Edition"If {{there is}} {{anything}} you want to know, or remind yourself, about probabilities, then look no further than this comprehensive, yet wittily written and enjoyable, compendium of how to apply probability calculations in real-world situations. "- Keith Devlin, Stanford University, National Public Radio's "Math Guy" and author of The Math Gene and The Unfinished GameFrom probable improbabilities to regular irregularities, Probabilities: The Little Numbers That Rule Our Lives, Second Edition investigates the often surprising effects of risk and chance in our lives. <b>Featu...</b>|$|E
40|$|This trip {{examines}} exposures in the Adirondack Lowlands {{that contain}} Paleozoic hydrothermal and fault-related features hosted by Mesoproterozoic ‘Grenville ’ marbles and Cambrian Potsdam Sandstone. These features {{have been the}} source of some debate historically and are now explicable as resulting from hydrothermal activity within an ancient w lt system. This system is similar to the deep structures that give rise to economically important gas include localities where the be seen, and the results of r explain outcrop-scale <b>featu</b> demonstrates on a small sca be linked to basement fault also be considered...|$|E
40|$|In image rer ieval systems, {{images can}} berO r esented by single <b>featu</b> r vect or or by clouds of points. A cloud of points o#e r a mor {{flexible}} descr 4 tion but su#e rfrL class overO 2. We prO ose a novel appr ach for descr bing clouds of points based on suppor t vector data descr ption (SVDD). We show that combining SVDD-based classifier impr ves ther etr evalpr cision. We investigate the per or mance of the pr posed rtr eval technique on {{a database of}} 368 textur images and compar e it to other methods...|$|E
40|$|The {{osteology}} of Gorgasia punctata is described, figured, {{and compared}} with that of other congrids. Gorgasia is clearly referable to the subfamily Heterocongrinae. The heterocongrines agree with the Congridae in several important <b>featu</b> res, and do not differ in fund amental respects. Therefore, the group is recognized as a subfamily of the Congridae. Gorgasia is the most primitive heterocongrine, and agrees with the anagoine congrids in having a lateral ethmoid process. Because of this and other similarities it is suggested that the Anagoinae and Heterocongrinae arose from a common stem. The genus Xarifania was erected on the erroneous basis of lack of caudal rays. It is synonymized with Taenioconger...|$|E
40|$|The {{method is}} based on {{recognizing}} that certain local binary patterns, termed are fundamental propertiesof local image texture and their occurrence histogram is {{proven to be a}} very powerful texture feature. TheLocal Binary Pattern (LBP) is a texture descriptorbased on the probability of occurrence of elementarybinary patterns (texels) defined over a circular window. A new feature set derived from the LBP, called theLBP-Constant-Symmetry (LBP-CS) and LBP-High-Symmetry (LBP-HS) are proposed for recognition ofstone textures. The features are computed from eachband of an isotropic color LBP Matrix for recognition. The tests were conducted in a variety of industrialsamples. The obtained results are promising and showthe possibility of efficiently recognizing complexindustrial products based on color and texture <b>featu...</b>|$|E
40|$|The p r esent paper p r esents a st r uctu r e of R oman date, {{cut into}} bedrock, and {{possibly}} used for fish farming purposes. S o fa r, this so r t of evidence, which is w ell attested in I talian villae maritimae dating to th e Lat e R epubli c an d th e Earl y E mpi r e, ha d onl y bee n foun d i n th e I beria n P eninsul a i n th e southern T arraconense (coast of Alicante). The ab o v e mentioned st r uctu r e is, the r efo r e, {{the first of}} its kind found in the B aetica. I nterp r etation must combine a r chaeological evidence for R oman fish farming in Andalusia (ost r ea r um vi v aria at T r aducta, cur r ent Algeciras) and geoa r chaeological <b>featu</b> r es; the st r uctu r e is located in the inte r tidal z one and enj o ys f r esh water supply f r om the near b y halieutic site of T rafalgar Cape (B arbate, Cádiz). This paper aims at the r e-interp r etation of this coastal site, p r eviously interp r eted as a salted p r oducts facto r y, or cetaria, but the topographical and a r chitectural <b>featu</b> r es of which (v ats with inner steps, cisterns, terraced st r uctu r es, etc.) a r e rather suggesti v e of a villa maritima or a complex cent r e for the exploitation of marine r esou r ces. </p...|$|E
40|$|Purpose:Mammographic {{density is}} a strong and highly {{of this study was}} to examine the extent to which mamm history of breast cancer with risk of the disease. d case We es y at b facto as 3. 1 more canc (95 % nt ma densi elativ <b>featu</b> amm; 19 (2) The te widely r is though it is estim breast ca ed by th known g ity gene and low-remains of the di We co breast ca factor for women t tissue X-rays, where-graphic ing the t that is n ≥ 75 % ix times ex with ociated risk of arous or of hor-tamoxi-versely unt for plained by {{inherited}} factors (5). As PMD is a risk factor breast cancer. Some previous studies, using qualitative c features, have ry of the diseas...|$|E
40|$|Dismal is a speadsheet that wo ks {{within the}} GNU Emacs editor, a widely {{available}} p og ammable edito. Dismal has th ee pa ticula <b>featu</b> es {{of interest to}} those inte ested in studying behavio : (a) the ability to manipulate and align sequential data, (b) an open a chitectu e that allows use s to expand it to meet thei pa ticula needs, and (c) an inst umented and accessible inte face fo studies of human-compute inte action (HCI). Example uses of these capabilities a e p ovided including two cognitive models that have had thei behavio aligned with p otocols, extensions useful fo teaching and doing HCI design, and studies using keyst oke logs f om the timing package in Dismal. Dismal is distributed {{with the help of}} the Free Software Foundation...|$|E
40|$|In this article, {{we present}} a n {{integrative}} per-spective on temperament and personality development. Personality and temperament are concep tualized as regu-latory systems that start as physiological reactivity toenvironmenta l <b>featu</b> res early in life, but are increasinglysupplemented by regulation efforts oriented toward refer-ence values such as personal goals and social norms. These re ference values change during developme nt associety expects increasingly mature behaviors, but it takesregulatory resource s and incremental practice beforepeople can conform to these higher standards. Consistentwith this view, a meta-analysis of mean-level developmentof personality t raits in ado lescence revealed a decrease inconscientiousness and openness during ea rly adolescence. Negative discrepancies between reference values andactual behavior are apparentl y responsible for decreasesin perceived maturity, but more direct evidence is neededto sup port this claim...|$|E
40|$|Fine-grain {{parallelism}} {{is the key}} to {{high performance}} muticomputing. By partitioning problems into small sub-tasks [...] grain-sizes as small as 70 cycles have been found in common benchmark programs [...] fine-grain parallelization accelerates existing applications beyond current limits, and promises efficient exploitation of multicomputers consisting of thousands of processors. However, contemporary multiprocessor architectures are not equipped to exploit parallelism at this level, due to high communication and synchronization costs that must be amortized over a large grain size. Operating system-managed message interfaces account for most of the high inefficiency in traditional systems. Conversely, in contemporary user-level network interfaces, fast hardware is defeated by software layers that are needed to provide safeguards against starvation and protection violation. This thesis addresses both the efficiency and robustness issues in the message interface. I propose a design which <b>featu</b> [...] ...|$|E
40|$|In the {{production}} of high speed steel, the rolling affects the micro-structure of the steel, which in turn influences the mechanical properties. Specifically, the distribution of carbide is essential, since cracks propagate within the carbide agglomerations. In current quality control, {{the properties of the}} steel are assessed manually by comparison with a standard chart, containing representative patterns for each steel class. Interestingly, the standard technique for classifying carbide distributions is two-dimensional, where the first dimension basically corresponds to scale ("degree" [...] - the size of the largest carbide agglomeration) and the the second dimension basically reflects the directional distribution ("type" [...] - how strongly the net structure of carbide has been stretched). In this paper, we present an automatic method for such classification based on scale-space operations, in which the size information is measured using recently developed techniques for <b>featu</b> [...] ...|$|E
40|$|We {{consider}} {{the notion of}} decision function as acting over conditional frequency distributions computed from a data table. We draw the connection between decision functions and approaches to generating uncertain decision rules for the object classification. We introduce the notion of decision implicant {{with respect to a}} decision function and show properties of such implicants for exemplar types of functions. As a conclusion, we obtain a wide class of approximate implicants providing an intuitive and flexible tool for extracting information about dependencies from data. 1 Introduction Concerning uncertain information about a distinguished feature (decision, output) conditioned by other features (conditional attributes, inputs), refers to the task of decision rule generation. In case of consistent data tables, where such conditional information is always deterministic, decision rules can be generated from implicants developed in rough sets theory ([1]) to describe subsets of <b>featu</b> [...] ...|$|E
40|$|Sudán, concretamente las relativas al periodo Neolítico, han constatado la presencia de algunas figuritas humanas fundamentalmente femeninas. Dichas representaciones, podría tener algún paralelismo con las aparecidas en asentamientos neolíticos del Mediterráneo oriental como ´Ain Ghazal (Jordania), o tell Mureybet (Siria). PALABRAS CLAVE: Prehistoria, Neolítico, Egipto, Próximo Oriente, figuritas femeninas, culto a la divinidad. ABSTRACT: Recent archaeological {{excavations}} in Neolithic {{sites in}} Egypt and Sudan have revealed an number of figures, {{both human and}} animals. Possibly, {{there would be some}} parallels between these deceptions and those recovered in contempo-raries sites located in the Oriental Mediterranean Area like ´Ain Ghazal (Jordan), or tell Mureybet (Syria). KEY WORDS: Prehistoric, Neolithic, Egypt, Near East, females figures, cult of divinities. There is a group of figurines among the most important materials produced by Neolithic populations living in the Nile Valley. Human <b>featu...</b>|$|E
40|$|Micro-terrain {{features}} are topographic structures {{relevant to the}} behavior of a simulation but with a horizontal extent significantly less than the resolution of the base-level terrain data covering the area in which these structures occur. These {{features are}} thus not directly extractable from elevation data. While they are often apparent in aerial imagery, micro-terrain features are easily missed or confused with other features, making reliable detection based on imagery alone problematic. This paper describes an automated method for extracting high fidelity models of small-scale ravine features by augmenting a hydrological analysis with computer vision techniques. Introduction Sensor technology, limitations of photogrammetry, storage constraints, and requirements for real-time rendering all limit the fidelity with which terrain can be effectively represented in a geospatial database. For certain applications, it is critical that these databases include specific micro-terrain <b>featu</b> [...] ...|$|E
40|$|A good {{evaluation}} function {{is needed for}} a good game program, and good features, which are primitive metrics of a state, are needed for a good {{evaluation function}}. In order to obtain good features, automatic generation of features by machine learning is promising. However, the generated features are usually written in logic programs, whose evaluation is much slower than that of other native expressions due to the interpretive evaluation of the logic programs. In order to solve this problem, we propose a method which constructs a specialized evaluator {{using a combination of}} techniques: partial evaluation, Boolean tables, and incremental calculation. It exhaustively unfolds logical programs until they can be represented as simple Boolean tables. The constructed specialized evaluator is ecient since it consults only these compiled tables. Experiments with Othello showed that speed can be increased approximately 2, 000 times. 1 Introduction 1. 1 Evaluation Function and <b>Featu</b> [...] ...|$|E
40|$|Maximum Likelihood #ML# {{modeling}} of multiclass data using gaussian distributions for classi#cation often su#ers {{from the following}} problems: a# data insu#ciency implying overtrained or unreliable models b# large storage requirementc# large computational requirement and#or d# ML is not discriminating between classes. Sharing parameters across classes #or constraining the parameters# clearly tends to alleviate the #rst three problems. It this paper we show {{that in some cases}} it can also lead to better discrimination #as evidenced by reduced misclassi#cation error#. The parameters considered are the means and variances of the gaussians and linear transformations of the feature space #or equivalently the gaussian means#. Some forms of sharing #either explicit or implicit via constraints# on the parameters are shown to lead to Linear Discrimination Analysis #a well-known result# while others #like diagonal, block-diagonal and factor analyzed covariances # are shown to lead to optimal <b>featu</b> [...] ...|$|E
40|$|Metaphorical use of {{language}} is often thought to {{be at odds with}} compositional, truth-conditional approaches to semantics: after all, most metaphors are literally false. In this paper we sketch an approach to metaphors based on standard type theory. Our approach is classical: we do not invent a new logic. The approach models sense extension in a simple and elegant way: the properties (supertypes) shared between tenor and vehicle include the extensions of at least both. The original predicates remain unchanged. Our approach captures an asymmetry between metaphor and simile: the literal interpretation of a metaphor comes out as (mostly) false while its non-literal interpretation is that of a corresponding reduced simile. A compositional syntax [...] semantics interface is provided and a deductive account of metaphor resolution is outlined. The approach readily translates into a simple computational implementation in Prolog. We discuss how our approach addresses issues of generalisation, <b>featu</b> [...] ...|$|E
40|$|In {{this paper}} we {{introduce}} {{the concept of}} continual queries, describe {{the design of a}} distributed event-driven continual query system [...] OpenCQ, and outline the initial implementation of OpenCQ on top of the distributed interoperable information mediation system DIOM [21, 19]. Continual queries are standing queries that monitor update of interest and return results whenever the update reaches specified thresholds. In OpenCQ, users may specify to the system the information they would like to monitor (such as the events or the update thresholds they are interested in). Whenever the information of interest becomes available, the system immediately delivers it to the relevant users; otherwise, the system continually monitors the arrival of the desired information and pushes it to the relevant users as it meets the specified update thresholds. In contrast to conventional pull-based data management systems such as DBMSs and Web search engines, OpenCQ exhibits two important <b>featu</b> [...] ...|$|E
40|$|Control {{independence}} {{has been}} put forward as a significant new source of instruction-level parallelism for future generation processors. However, its performance potential under practical hardware constraints is not known, and even less is understood about the {{factors that contribute to}} or limit the performance of control independence. Important aspects of control independence are identified and singled out for study, and a series of idealized machine models are used to isolate and evaluate these aspects. It is shown that much of the performance potential of control independence is lost due to data dependences and wasted resources consumed by incorrect control dependent instructions. Even so, control independence can close the performance gap between real and perfect branch prediction by as much as half. Next, important implementation issues are discussed and some design alternatives are given. This is followed by a more detailed set of simulations, where the key implementation <b>featu</b> [...] ...|$|E
40|$|We {{assess the}} {{possibility}} that baryonic acoustic oscillations in adiabatic models may explain the observations of excess power in large-scale structure on 100 h - 1 Mpc scales. The observed location restricts models to two extreme areas of parameter space. In either case, the baryon fraction must be large (# b =# 0 > 0 : 3) to yield signicant features. The rst region requires# 0 1 : 4) to satisfy cluster abundance constraints. The power spectrum also continues to rise toward larger scales in these models. The second region requires# 0 1, implying # b well out {{of the range of}} big bang nucleosynthesis constraints; moreover, the peak is noticeably wider than the observations suggest. Testable features of both solutions are that they require moderate reionization and thereby generate potentially observable (1 K) large-angle polarization, as well as sub-arc-minute temperature fluctuations. In short, baryonic <b>featu</b> [...] ...|$|E
40|$|This paper {{analyzes}} {{the use of}} histograms of low level image features, such as color and luminance, as descriptors for image retrieval purposes. A novel denition of histogram capacity curve {{taking into account the}} density distribution of histograms in the corresponding spaces is proposed and used to quantify the eectiveness of image descriptors and histogram dissimilarities in image retrieval applications. The results permit the design of scalable image retrieval systems which make optimal use of computational and storage resources. Keywords: image retrieval, histograms, density estimation, distribution comparison. 1. Introduction A currently active line of research and development in the Computer Vision community is the design and development of ecient tools for accessing multimedia material, such as video and still images, using their media specic features. In particular, several research papers and tools have been presented for image retrieval based on low level visual <b>featu</b> [...] ...|$|E
40|$|A novel {{method of}} gender Classification froom {{fingerprint}} is pr roposed based on discrete wave elet transform (DDWT) and singular value decomposiition (SVD). The classification {{is achieved by}} exxtracting the ennergy computed from all the suub-bands of DWWT coombined with the spatial <b>featu</b> ures of non-zerro singular valuues obbtained from the SVD of finger rprint images. K nearest neighbbor (KKNN) used as a classifier. This method is expeerimented with the innternal database of 3570 fingerp prints finger prinnts in which 1980 were male fingerrprints and 1590 were female finngerprints. Fingeer wise gender classsification is achi ieved which is 94. 32 % for the left hand little fingers of female pers sons and 95. 46 % for the left haand inndex finger of male persons. Ge ender classificattion for any fingger of male persons tested is attained as 91. 67 % and 84. 69 % for feemale persons respectively. Ove erall classification rate is 88. 288 % has been achievedd...|$|E
40|$|We {{describe}} a new logic called typed predicate calculus (T PC) that gives declarative meaning to logic programs with type declarations and type inference. T PC supports all popular types of polymorphism, such as parametric, inclusion, and ad hoc polymorphism. The proper interaction between parametric and inclusion varieties of polymorphism is achieved {{through a new}} construct, called type dependency, which is reminiscent of implication types of [PR 89] but yields more natural and succinct specifications. Unlike other proposals where typing has extra-logical status, in T PC the notion of type-correctness has precise model-theoretic meaning that is independent of any specific type-checking or type-inference procedure. Moreover, many different approaches to typing that were proposed in the past can be studied and compared {{within the framework of}} our logic. As an illustration, we apply T PC to interpret and compare the results reported in [MO 84, Smo 88, HT 90, Mis 84, XW 88]. Another novel <b>featu</b> [...] ...|$|E
40|$|We {{describe}} a relational method for specifying features and detecting feature interactions. The method allows {{for an independent}} specification of system features, and for a detection of interaction between features. The method {{is based on the}} lattice of relational specifications: the system specification is given as the conjunction (lattice operator meet) of the features; a feature interaction is detected when the meet of the features does not exist. Examples of detection are given using logic programming. 1 Introduction To deal with feature interactions at the specification phase, a method must allow for the independent definition of features. At the validation step, a method must allow for the detection of interactions between features. To tackle these two aspects, we base our approach on the refinement lattice of specifications [3]. In this framework, the specification of a feature is given by a relation between the inputs and the outputs of the system. The combination of the <b>featu</b> [...] ...|$|E
40|$|Feature point (FP) {{detection}} is {{an important}} preprocessing step in image registration, data fusion, object recognition and in many other tasks. This paper deals with multiframe FP detection, i. e. detection in two or more images of the same scene which {{are supposed to be}} blurred, noisy, rotated and shifted with respect to each other. We present a new method invariant under rotation that can handle differently blurred images. Thanks to this, the point sets extracted from different frames have relatively high number of common elements. This property is highly desirable for further multiframe processing. The performance of the method is demonstrated experimentally on satellite images and application on medical data is 1 Introduction Detection of feature points (FP) or landmarks {{is an important}} step in image processing and computer vision. It provides input information for further operations, such as image registration, image fusion, time-sequence analysis and object recognition. By <b>featu</b> [...] ...|$|E
40|$|This paper {{presents}} an algorithm for inducing recursive first order Horn clause programs from examples without background knowledge. This algorithm invents new predicates and their definitions exhaustively until the instances {{of a new}} predicate become the same as examples except {{for the name of}} the predicate. Our system CIRP switches into constructive induction mode using a new heuristic taking advantage of the goal directed usefulness of incomplete clauses and {{of the fact that it}} is supplied with no background knowledge. It enables CIRP to avoid exhaustive search and to overcome some difficulties associated with employing encoding length principle as a switching element for constructive induction. This paper also describes a method for deciding the argument set for a new predicate by employing the structure of the arguments of the original predicate and reports the scope, limitation and remedy of limitation of this method. 1 Introduction Due to the lack of expressive power in <b>featu</b> [...] ...|$|E
40|$|This paper {{presents}} {{an overview of}} the programming language Modula- 3, and a more detailed description of its type system. 1 Introduction The design of the programming language Modula- 3 was a joint effort by the Digital Systems Research Center and the Olivetti Research Center, undertaken with the guidance and inspiration of Niklaus Wirth. The language is defined by the Modula- 3 Report [3], and is currently being implemented by the Olivetti Research Center. This paper gives {{an overview of the}} language, focusing primarily upon its type system. Modula- 3 is a direct descendent of Mesa [8], Modula- 2 [14], Cedar [5], and Modula- 2 + [9, 10]. It also resembles its cousins Object Pascal [13], Oberon [15], and Euclid [6]. Since these languages already have more raw material than fits comfortably into a readable fifty-page language definition, which we were determined to produce, we didn't need to be inventive. On the contrary, we had to leave many good ideas out. Instead of exploring new <b>featu</b> [...] ...|$|E
40|$|We {{consider}} again a {{user defined}} syntax feature, the conctype, {{which is a}} new datatype construction. An embedded language can easily be introduced into a programming language using conctypes, and computations are easily expressed using the concrete syntax and a special pattern matching form. Context-free grammars serve {{as a basis for}} the definition of the new syntax. A problem that is investigated in this paper is how to use precedences to resolve ambiguity. The way precedences are used in LR-parsers is sometimes unnatural and is hard to translate to other parsing techniques. We isolate one kind of ambiguity which can be resolved with precedence rules and show that it is easy for a user to augment a grammar with precedence rules. We define the generated language for such a grammar in terms of an attribute grammar and show that it is easy to automatically construct a parser that recognizes the language. 1 Conctypes In a previous paper [APS 88] we described a user defined syntax <b>featu</b> [...] ...|$|E
40|$|We give a {{proof of}} the {{regularity}} of bundle functors on certain class of categories over manifolds and a description of all bundle functors on fibred manifolds with fixed dimensions of bases and fibers. Further we describe {{in the terms of}} Weil algebras all bundle functors on fibred manifolds with fixed dimension of bases which preserve fibred products. Finally we discuss certain natural operations with vector fields. In this paper, all manifolds are smooth and paracompact. We denote by N 0 the set of all non-negative integers. 1. Preliminaries The classical theory of natural bundles and operators originated by A. Nijenhuis has been developed and extended by several authors, see e. g. [Epstein,Thurston, 79], [Palais, Terng, 77], [Janyska, 85]. The foundations of a general theory are outlined in the survey paper [Kol'ar, 89], a collection of the most of basic results on both the bundles and operators is prepared in [Kol'ar, Michor, Slov'ak]. In this paper, we present some specific <b>featu</b> [...] ...|$|E
40|$|There has {{recently}} been nu merou applications of kernel methods {{in the field of}} bioinformatics. In particuT() the problem of protein homology has served as a benchmark for the performance of many new kernels which operate directly on strings(su h as amino-acid sequfiET(I Several new kernels have been developed andsuIflq(ET(fi# applied to this type of data, inclu#) E spectru# string, mismatch, and profile kernels. In this paper we introdufi a general probabilistic framework for stringtype kernels whichu ses the fisher-kernel approach and inclub spectru mismatch and profile kernels, among others, as special cases. Theu se of a probabilistic model however provides additional flexibility both in definition and for the re-weighting of featu(X throu# <b>featu)</b> selection methods, prior knowledge orsemi-su ervised approaches whichu(data repositoriessu h as BLAST. We give details of the framework, place wellknown kernels in the framework and give preliminary experimental resu) which show some e#ects ofu sing the probabilistic approach. ...|$|E
40|$|This paper {{describes}} an Active Character Recognition methodology, henceforth {{referred to as}} ACR. Wepresentin this paper a method that uses an active heuristic function {{similar to the one}} used by A* search algorithm that adaptively determines the length of the feature vector as well as the features themselves used to classify an input pattern. ACR adapts to factors such as the quality of the input pattern, its intrinsic similarities and differences from patterns of other classes it is being compared against and the processing time available. Furthermore, the finer resolution is accorded to only certain "zones" of the input pattern which are deemed important given the classes that are being discriminated. Experimental results support the methodology presented. Recognition rate of ACR is about 96 % on the NIST data sets and the speed is better than traditional classification methods. 1 Introduction In this paper, we present an active character recognizer which uses a hierarchical <b>featu</b> [...] ...|$|E
