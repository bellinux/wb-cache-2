5|1|Public
40|$|Traditional <b>data-oriented</b> <b>programming</b> {{languages}} such as dataflow {{languages and}} stream languages provide a natural abstraction for parallel programming. In these languages, a developer {{focuses on the}} flow of data through the computation and these systems free the developer from the complexities of low-level, thread-oriented concurrency primitives. This simplification comes at a cost — traditional data-oriented approaches restrict the mutation of state and, in practice, the types of data structures a program can effectively use. Bamboo borrows from work in typestate and software transactions to relax the traditional restrictions of <b>data-oriented</b> <b>programming</b> models to support mutation of arbitrary data structures. We have implemented a compiler for Bamboo which generates code for the TILEPro 64 many-core processor. We have evaluated this implementation on six benchmarks: Tracking, a feature tracking algorithm from computer vision; KMeans, a K-means clustering algorithm; MonteCarlo, a Monte Carlo simulation; FilterBank, a multi-channel filter bank; Fractal, a Mandelbrot set computation; and Series, a Fourier series computation. We found that our compiler generated implementations that obtained speedups ranging from 26. 2 × to 61. 6 × when executed on 62 cores...|$|E
40|$|This paper {{presents}} a novel middleware for developing flex-ible interactive multi-surface applications. Using a scenario-based approach, we identify {{the requirements for}} this type of applications. We then introduce Substance, a data-oriented framework that decouples functionality from data, and Shared Substance, a middleware implemented in Sub-stance that provides powerful sharing abstractions. We de-scribe our implementation of two applications with Shared Substance and discuss the insights gained from these ex-periments. Our finding is that the combination of a <b>data-oriented</b> <b>programming</b> model with middleware support for sharing data and functionality provides a flexible, robust so-lution with low viscosity at both design-time and run-time...|$|E
40|$|The {{widespread}} use of memory unsafe programming languages (e. g., C and C++), especially in embedded systems and the Internet of Things (IoT), leaves many systems vulnerable to memory corruption attacks. A variety of defenses have been proposed to mitigate attacks that exploit memory errors to hijack the control flow of the code at run-time, e. g., (fine-grained) ASLR or Control Flow Integrity (CFI). However, recent work on <b>data-oriented</b> <b>programming</b> (DOP) demonstrated the possibility to construct highly-expressive (Turing-complete) attacks, even {{in the presence of}} these state-of-the-art defenses. Although multiple real-world DOP attacks have been demonstrated, no suitable defenses are yet available. We present run-time scope enforcement (RSE), a novel approach designed to mitigate all currently known DOP attacks by enforcing compile-time memory safety constraints (e. g., variable visibility rules) at run-time. We also present HardScope, a proof-of-concept implementation of hardware-assisted RSE for the new RISC-V open instruction set architecture. We demonstrate that HardScope mitigates all currently known DOP attacks at multiple points in each attack. We have implemented HardScope in hardware on the open-source RISC-V Pulpino microcontroller. Our cycle-accurate simulation shows a real-world performance overhead of 7. 1 % when providing complete mediation of all memory accesses...|$|E
40|$|Model {{checking}} is {{a formal}} verification technique that exhaustively tests {{a piece of}} hardware or software on all possible inputs (usually up to a given size) and on all possible nondeterministic schedules. For hardware, model checkers have successfully verified fairly complex finite state control circuits with up to a few hundred bits of state information; but not circuits in general that have large data paths or memories. Similarly, for software, model checkers have primarily verified control-oriented programs with respect to temporal properties; but not much {{work has been done}} to verify <b>data-oriented</b> <b>programs</b> with respect to complex data-dependent properties. This dissertation presents glass box software model checking, a novel software model checking approach that achieves a high degree of state space reduction in the presence of complex data-dependent properties. Our key insight is that there are classes of operations that affect a program's state in similar ways. By discovering these similarities, we dramatically reduce the state space of our model checker by checking each class of states in a single step. To achieve this state space reduction, we employ a dynamic analysis to detect similar state transitions and a static analysis to check the entire class of transitions. These analyses employ a symbolic execution technique that increases their effectiveness. We also present a modular extension to glass box software model checking, to further improve the efficiency of checking large programs composed of multiple modules. In a modular checking approach program modules are replaced with abstract implementations, which are functionally equivalent but vastly simplified versions of the modules. We also apply the glass box model checking technique to the problem of checking type soundness. Since proving type soundness can be extremely difficult, a model checking approach takes a considerable burden off the language designer. Our experimental results indicate that glass box model checking is efficient and effective at checking a variety of programs and properties, including program invariants, equivalence to an abstraction, and type soundness. Comparisons with other model checking techniques show that our technique is more efficient at checking these programs and properties...|$|R
40|$|Since the mid 90 ’s, Desktop Grid Computing - i. e {{the idea}} of using a large number of remote PCs {{distributed}} on the Internet to execute large parallel applications - has proved to be an efficient paradigm to provide a large computational power at the fraction of the cost of a dedicated computing infrastructure. This document presents my contributions over the last decade to broaden the scope of Desktop Grid Computing. My research has followed three different directions. The first direction has established new methods to observe and characterize Desktop Grid resources and developed experimental platforms to test and validate our approach in conditions close to reality. The second line of research has focused on integrating Desk- top Grids in e-science Grid infrastructure (e. g. EGI), which requires to address many challenges such as security, scheduling, quality of service, and more. The third direction has investigated how to support large-scale data management and data intensive applica- tions on such infrastructures, including support for the new and emerging <b>data-oriented</b> <b>programming</b> models. This manuscript not only reports on the scientific achievements and the technologies developed to support our objectives, but also on the international collaborations and projects I have been involved in, as well as the scientific mentoring which motivates my candidature for the Habilitation `a Diriger les Recherches...|$|E
40|$|Development on {{embedded}} devices, even on today’s hardware, limits us to {{a minimum}} of third party-library dependencies due to hardware memory and power restrictions. In setups requiring intense geometric operations on limited hardware, such as in robotics, this problem can often lead to a tedious reimplementation of matrix, vector, and quaternion operations. Furthermore, certain unnecessary floating point operations are hard to avoid, because C++-features like expression template libraries such as eigen [2] can possibly not be used, because of strict C enforcement. Memory accesses are often the most limiting factor in today’s applications due to high memory latency. Yet traditional programming techniques unfortunately steer into the wrong direction by not easing <b>data-oriented</b> <b>programming,</b> which is often cumbersome to implement in C or C++. Many of the restrictions above are in a similar form the case on modern heterogeneous architectures such as AMD’s embedded Accelerated Processing Units or in GPGPU written in OpenCL/CUDA. Our technology based on Geometric Algebra and a Domain Specific language called CLUCalc will especially excel under these conditions. The focus of this work is Gaalop Precompiler, a new technology combining the advanced processing power of Accelerated Processing Units (APU) with the geometric intuitiveness of a new mathematical concept named Geometric Algebra [6]. The combination of both not only promises a more compact and maintainable code for graphics, vision, robotics and other scientific and engineering applications, but also automatically exploits parallelism on GPU or combined computing unit (APU) through OpenCL [8] or CUDA [9]. C/C++ CPU targeting is also supported. It {{is presented in the}} following, after a short introduction on Geometric Algebra...|$|E

