262|19|Public
25|$|Some {{of these}} {{optimizations}} performed {{at this level}} include <b>dead</b> <b>code</b> elimination, partial redundancy elimination, global value numbering, sparse conditional constant propagation, and scalar replacement of aggregates. Array dependence based optimizations such as automatic vectorization and automatic parallelization are also performed. Profile-guided optimization is also possible.|$|E
50|$|<b>Dead</b> <b>code</b> is {{normally}} considered dead unconditionally. Therefore, {{it is reasonable}} attempting to remove <b>dead</b> <b>code</b> through <b>dead</b> <b>code</b> elimination at compile time.|$|E
50|$|<b>Dead</b> <b>code</b> {{elimination}} {{is a form}} of compiler optimization {{in which}} <b>dead</b> <b>code</b> is removed from a program. <b>Dead</b> <b>code</b> analysis can be performed using live variable analysis, a form of static code analysis and data flow analysis. This is in contrast to unreachable code analysis which is based on control flow analysis.|$|E
40|$|Software {{testing is}} the process that aims to detect the errors in the {{software}} product by using test cases, and to discover {{the components of the}} software that are responsible of these errors. The testers need to ensure that every component of the software is tested correctly in order to achieve high coverage in terms of testing {{one or more of the}} software aspects such as: code, user interface, etc. Many coverage aspects were proposed in testing research field such as node, edge, edge-pair coverage, prime path coverage, etc. By reading many of these studies, we can notice that they propose many solutions for detecting and discovering infeasible paths. An infeasible path is simply any path that cannot be traversed by test cases. Some of the causes of the infeasible paths are <b>dead</b> <b>codes,</b> correlated predicates with respect to a certain variable (which is one of the main reasons for infeasibility in the software programs) or according to the test cases itself. In this paper, a tool is developed to automatically detect the infeasible paths that may exist in source code and that are caused by the logically inconsistent predicates related to <b>dead</b> <b>codes,</b> and by the correlated conditional statements with respect to a certain variable. Our application tool is evaluated against four source codes, and the experimental results showed that the tool can effectively detect infeasible paths except in the source codes that contain while loop structures...|$|R
50|$|The {{errors that}} C/C++test discovers include uninitialized or invalid memory, null pointer dereferencing, array and buffer overflow, {{division}} by zero, memory and resource leaks, duplicate code, and {{various types of}} <b>dead</b> or unreachable <b>code.</b>|$|R
40|$|Abstract—Wireless mobile {{communications}} {{have experienced}} the phenomenal growth through last decades. The advances in wireless mobile technologies have brought about a demand for high quality multimedia applications and services. For such applications and services to work, signaling protocol is required for establishing, maintaining and tearing down multimedia sessions. The Session Initiation Protocol (SIP) is an application layer signaling protocols, based on request/response transaction model. This paper considers SIP INVITE transaction over an unreliable medium, since it has been recently modified in Request for Comments (RFC) 6026. In order to help in assuring that the functional correctness of this modification is achieved, the SIP INVITE transaction is modeled and analyzed using Colored Petri Nets (CPNs). Based on the model analysis, it is concluded that the SIP INVITE transaction is free of livelocks and <b>dead</b> <b>codes,</b> {{and in the same}} time it has both desirable and undesirable deadlocks. Therefore, SIP INVITE transaction should be subjected for additional updates in order to eliminate undesirable deadlocks. In order to reduce the cost of implementation and maintenance of SIP, additional remodeling of the SIP INVITE transaction is recommended...|$|R
50|$|Unreachable code is {{sometimes}} also called <b>dead</b> <b>code,</b> although <b>dead</b> <b>code</b> may also refer to code that is executed {{but has no}} effect on the output of a program.|$|E
50|$|<b>Dead</b> <b>code</b> elimination: Removes {{instructions}} {{that will not}} affect the behaviour of the program, for example definitions which have no uses, called <b>dead</b> <b>code.</b> This reduces code size and eliminates unnecessary computation.|$|E
50|$|In {{compiler}} theory, <b>dead</b> <b>code</b> elimination (also {{known as}} DCE, <b>dead</b> <b>code</b> removal, <b>dead</b> <b>code</b> stripping, or <b>dead</b> <b>code</b> strip) is a compiler optimization to remove code {{which does not}} affect the program results. Removing such code has several benefits: it shrinks program size, an important consideration in some contexts, and it allows the running program to avoid executing irrelevant operations, which reduces its running time. It can also enable further optimizations by simplifying program structure.Dead code includes code that can never be executed (unreachable code), and code that only affects dead variables (written to, but never read again), that is, irrelevant to the program.|$|E
50|$|Similar {{techniques}} are sometimes also employed {{for the purpose}} of dynamic dead-code elimination to remove conditionally <b>dead</b> or unreachable <b>code</b> at load or runtime, and recombine the remaining code to minimize its memory footprint or improve speed.|$|R
5000|$|<b>Dead</b> or Alive: <b>Code</b> Chronos - A prequel to the Dead or Alive series, {{which was}} {{going to focus on}} the backstory of Kasumi and Ayane, and {{reportedly}} {{was not going to be}} a fighting game. It was cancelled in November 2010.|$|R
5000|$|JavaScript {{example of}} a dead store:function func(a, b) { var x; var i = 300; while (i--) { x = a + b; // <b>dead</b> store }}"The <b>code</b> in the loop {{repeatedly}} overwrites the same variable, {{so it can be}} reduced to only one call." ...|$|R
50|$|The {{techniques}} used to dynamically detect demand, identify and resolve dependencies, remove such conditionally <b>dead</b> <b>code,</b> and to recombine the remaining code at load or runtime are called dynamic <b>dead</b> <b>code</b> elimination or dynamic dead instruction elimination.|$|E
50|$|In {{computer}} programming, <b>dead</b> <b>code</b> is {{a section}} in the source code of a program which is executed but whose result is never used in any other computation. The execution of <b>dead</b> <b>code</b> wastes computation time and memory.|$|E
50|$|In Microsoft's {{preliminary}} SunSpider benchmarks for {{the third}} 32-bit Internet Explorer 9 Platform Preview, it outperformed the Internet Explorer 8 engine {{by a factor of}} 10 and also outperformed the newest Firefox 4.0 pre-release. Microsoft provided information that its new javascript engine uses <b>dead</b> <b>code</b> elimination optimization for faster performance, which included a small section of code in the SunSpider test as <b>dead</b> <b>code.</b> Robert Sayre, a Mozilla developer investigated this further, showing that Internet Explorer 9's preview 3 <b>dead</b> <b>code</b> elimination had bugs, providing test cases exposing these bugs resulting in wrong compilation.|$|E
50|$|Washington {{made sure}} that the Culper Ring spies had more support and {{operated}} in greater secrecy than previous Continental spies, perhaps with Nathan Hale in mind. Through Tallmadge, he provided them with <b>codes,</b> <b>dead</b> drops, and aliases. Tallmadge, Woodhull, and Townsend were given code names. They were also given code numbers, along with Washington, Brewster, Roe, and Rivington. George Washington's code number was 711.|$|R
2500|$|The Code {{remained}} in effect {{until the early}} 10th century, after which it became an obsolete <b>dead</b> letter law <b>code,</b> but not formally repealed and hence valid at least [...] "in paper" [...] until the Meiji Restoration. During the feudal age in Japan, various ministerial offices were awarded to as formality to samurai (e.g., Ishida Mitsunari as jibu-no-shō; Furuta Oribe, Ii kamon-no-kami, Sakai uta-no-kami etc.) without any responsibilities or authorities vested in the office under the code.|$|R
40|$|The {{need for}} {{adaptability}} {{in a rapidly}} expanding embedded systems market makes it important to design virtual execution environments (VEEs) specifically targeting embedded platforms. We believe {{the first step in}} this direction should be to replace the performance focus of traditional VEE design with a combined memory and performance focus, given the memory constraints on embedded systems. In this work, we present techniques that reduce the large code cache sizes of VEEs by continually eliminating <b>dead</b> cached <b>code</b> as the guest application executes. We use both a time-based heuristic and an execution count-based heuristic to predict code lifetime. When we determine that the lifetime of code has ended, we remove it from the code cache. We found that at least 20 % code cache reduction can be achieved on average, without a significant performance degradation. 1...|$|R
50|$|Most {{programming}} languages, compilers {{and operating}} systems offer no or little more support than dynamic loading of libraries and late linking, therefore software utilizing dynamic <b>dead</b> <b>code</b> elimination {{is very rare}} with languages compiled ahead-of-time or written in assembly language. However, language implementations doing just-in-time compilation may dynamically optimize for <b>dead</b> <b>code</b> elimination.|$|E
5000|$|<b>Dead</b> <b>code</b> removal, the {{automatic}} removal of unnecessary code by compilers ...|$|E
50|$|In practice, {{much of the}} <b>dead</b> <b>code</b> that an optimizer finds {{is created}} by other transformations in the optimizer. For example, the classic {{techniques}} for operator strength reduction insert new computations into the code and render the older, more expensive computations dead. Subsequent <b>dead</b> <b>code</b> elimination removes those calculations and completes the effect (without complicating the strength-reduction algorithm).|$|E
40|$|The goal of points-to {{analysis}} for Java {{is to determine}} the set of objects pointed to by a reference variable or a reference object field. In this paper we define and evaluate a points-to {{analysis for}} Java which extends Andersen's points-to analysis for C [4]. Andersen's analysis for C can be implemented efficiently by using systems of set-inclusion constraints and by employing several techniques for constraint representation and resolution. We extend these techniques to efficiently represent and solve systems of annotated inclusion constraints. The annotations play two roles in our analysis. Method annotations are used to model precisely and efficiently the semantics of virtual calls. Field annotations allow us to distinguish the flow of values through different fields of an object. In addition, our analysis keeps track of all methods reachable from the entry point of the program, and avoids analyzing <b>dead</b> library <b>code.</b> We evaluate the performance of the analysis on a large set of realist [...] ...|$|R
50|$|Itagaki classifies his {{projects}} into core projects (for business and technical excellence purposes), and those purely for self-fulfillment. The Dead or Alive Xtreme Beach Volleyball series and <b>Dead</b> or Alive: <b>Code</b> Chronos {{fall into the}} latter. The Dead or Alive Xtreme Beach Volleyball games are just meant for simple fun, and to fulfill a 'love' for the female characters, letting the player nurture and watch the girls partaking in simple joys. Even though he admits to there being sexual content in the game, Itagaki refuses to create scenarios which he feels are vulgar for his 'daughters', a term he uses to call the female characters. Code Chronos falls into the same category of development, developed as Itagaki's hobby for style.|$|R
5000|$|<b>Dead</b> or Alive: <b>Code</b> Chronos was {{the code}} {{name for a}} {{cancelled}} video game that was in development by Team Ninja for the Xbox 360 during the mid-2000s. In a February 2005 interview, Team Ninja's Tomonobu Itagaki said that Code Chronos would be set prior to the original Dead or Alive and will relay the story of characters Ayane and Kasumi before the first tournament. Itagaki to said it would [...] "not be a fighting game" [...] and instead act as a prequel to the series proper, and the game {{was supposed to be}} related to the part of the opening cinematic of Dead or Alive Ultimate that showed the child versions of Kasumi and Ayane. Earlier reports had implied the character of Helena would be more heavily involved. In 2008, Itagaki officially resigned from Tecmo, thus leaving the Dead or Alive franchise. In November 2010, Yousuke Hayashi, the new head of Team Ninja, confirmed in an interview that the project has been officially cancelled.|$|R
50|$|While most {{optimization}} techniques seek {{to remove}} <b>dead</b> <b>code</b> in an implementation, in extreme forms of optimization for size it may sometimes be desirable to deliberately introduce and carefully shape seemingly <b>dead</b> <b>code,</b> when it allows to fold otherwise unrelated code sections together (and thereby reduce their combined size) {{so that the}} extra code will effectively not harm the first path of execution through the code but is used {{to carry out the}} actions necessary for the alternative paths of execution, for which other sections of the code may become <b>dead</b> <b>code.</b> On a more functional level, this can be seen as both, artificially introduction of harmless/useful side-effects and reduction of the redundancy of the code, {{but it can also be}} used down to opcode level in order to allow the usage of shorter instructions, which would not be possible when folding code sequences without the concerted introduction of side-effects caused by the <b>dead</b> <b>code.</b>|$|E
50|$|In {{computer}} science, sparse conditional constant propagation is an optimization frequently {{applied in}} compilers after conversion to static single assignment form (SSA). It simultaneously removes {{some kinds of}} <b>dead</b> <b>code</b> and propagates constants throughout a program. Moreover, it can find more constant values, and thus more opportunities for improvement, than separately applying <b>dead</b> <b>code</b> elimination and constant propagation in any order or any number of repetitions.|$|E
50|$|A {{common use}} of <b>dead</b> <b>code</b> {{elimination}} is {{as an alternative}} to optional code inclusion via a preprocessor. Consider the following code. int main(void) { int a = 5; int b = 6; int c; c = a * (b / 2); if (0) { /* DEBUG */ printf("%d\n", c); } return c; }Because the expression 0 will always evaluate to false, the code inside the if statement can never be executed, and <b>dead</b> <b>code</b> elimination would remove it entirely from the optimized program. This technique is common in debugging to optionally activate blocks of code; using an optimizer with <b>dead</b> <b>code</b> elimination eliminates the need for using a preprocessor to perform the same task.|$|E
5000|$|<b>Dead</b> or Alive: <b>Code</b> Chronos, a DOA series' prequel game {{which was}} to feature Kasumi and Ayane, was {{cancelled}} in 2010 following Itagaki's departure from Tecmo. In 2003, Itagaki said, [...] "the fact that we registered this trademark for Kasumi-den should {{tell you that we}} have a big plan for it." [...] Kasumi appears as a playable character in the 2012 action game Ninja Gaiden 3: Razor's Edge, which was made available as free DLC for the Wii U, and was included in the PlayStation 3 and Xbox 360 versions. In it, she is armed with a long sword and kunai throwing knives and by default wears hooded black armor with a scarf. The player can also select three of her costumes from DOA5. In 2013, Kasumi appeared in the smart phone action card game Hyakuman-nin no Ninja Gaiden, in which Hitomi from Dead or Alive and Rio from Rio: Rainbow Gate! also appear dressed in Kasumi's DOA costumes.|$|R
5000|$|Although many of {{its members}} {{supported}} the overthrow of Emperor Haile Selassie, the CELU came to ally itself with the radical intelligentsia in pressuring the Derg to share power. The CELU also demanded shop-floor control over production. Despite numerous strikes in and around Addis Ababa, which sometimes ended in bloody confrontations, on May 19, 1975, the Derg temporarily closed CELU headquarters {{on the grounds that}} the union needed to be reorganized. The military authorities also demanded that workers should elect their future leaders according to the aims and objectives of Ethiopian socialism. This order ostensibly did not rescind traditional workers' rights, such as the right to organize freely, to strike, and to bargain collectively over wages and working conditions. Instead, the intent was to control the political activities of the CELU leadership. As expected, CELU rejected these actions and continued to demand democratic changes and civilian rights. After battling one another for most of the year, the Derg at last decreed a curfew and martial law on 30 September, and arrested 1,500 union members; although the CELU responded with a general strike, it failed to gather support in the main industrial sectors. As Rene Lafort concludes, [...] "The CELU was <b>dead.</b> The Labour <b>Code</b> promulgated on 6 December 1975 was its obituary." ...|$|R
40|$|This {{paper is}} based on dust aerosol cycle {{modelling}} in the atmospheric model ALADIN (Aire Limitée Adaptation dynamique Développement InterNational) coupled with the EXternalised SURFace scheme SURFEX. Its main {{goal is to create}} a global mineral dust emission parameterization compatible with the global database of land surface parameters ECOCLIMAP and the Food and Agriculture Organization (FAO) soil type database in SURFEX, based on both Shao (1993) and Marticorena and Bergametti (1995) parameterizations. An arrangement on the Dust Entrainment And Deposition scheme (DEAD) is proposed in this paper by introducing the geographic variation of surface size distribution, the Marticorena and Bergametti (1995) formulation of horizontal saltation flux and the Shao (2001) formulation of sandblasting efficiency α. To show the importance of the modifications introduced in the <b>code</b> <b>DEAD,</b> both sensitivity and comparative studies are realized in 0 dimensions (0 -D) and then in 3 dimensions (3 -D) between the old DEAD and that developed in this paper. The results in the 0 -D simulations indicate that the developed DEAD scheme represents the dust source emission better, particularly in the Bodélé depression and provides a reasonable friction threshold velocity. In 3 -D simulations, small differences are found between the DEAD and developed DEAD schemes for the simulated Aerosol Optical Depth (AOD) compared with the photometer AErosol RObotic NETwork (AERONET) measurements available in the African Monsoon Multidisciplinary Analyses (AMMA) databases. But, for the surface concentration a remarkable improvement is noted for the developed DEAD scheme...|$|R
50|$|Footage {{from the}} game {{was used in the}} opening {{sequence}} of the 2008 film WarGames: The <b>Dead</b> <b>Code.</b>|$|E
50|$|The <b>dead</b> <b>code</b> {{elimination}} {{technique is}} in the same class of optimizations as unreachable code elimination and redundant code elimination.|$|E
5000|$|<b>Dead</b> <b>code</b> elimination. If no side {{effected}} operation {{depends on}} a variable, this variable is considered dead and can be removed.|$|E
40|$|BACKGROUND: Most {{measures}} of health-related {{quality of life}} are undefined for people who die. Longitudinal analyses are often limited to a healthier cohort (survivors) that cannot be identified prospectively, and that may have had little change in health. OBJECTIVE: To develop and evaluate methods to transform a single self-rated health item (excellent to poor; EVGGFP) and the physical component score of the SF- 36 (PCS) to new variables that include a defensible value for death. METHODS: Using longitudinal data from two large studies of older adults, health variables were transformed to the probability of being healthy in the future, conditional on the current observed value; death then has the value of 0. For EVGGFP, the new transformations were compared with some that were published earlier, based on different data. For the PCS, how well three different transformations, based on different definitions of being healthy, discriminated among groups of patients, and detected change in time were assessed. RESULTS: The new transformation for EVGGFP {{was similar to that}} published previously. Coding the 5 categories as 95, 90, 80, 30, and 15, and <b>coding</b> <b>dead</b> as 0 is recommended. The three transformations of the PCS detected group differences and change at least as well as the standard PCS. CONCLUSION: These easily interpretable transformed variables permit keeping persons who die in the analyses. Using the transformed variables for longitudinal analyses of health when deaths occur, either for secondary or primary analysis, is recommended. This approach can be applied to other {{measures of}} health...|$|R
40|$|Developers of JavaScript web {{applications}} {{have little}} tool support for catching errors early in development. In comparison, {{an abundance of}} tools exist for statically typed languages, including sophisticated integrated development environments and specialized static analyses. Transferring such technologies to the domain of JavaScript web applications is challenging. In this paper, we discuss the challenges, which include the dynamic aspects of JavaScript and the complex interactions between JavaScript, HTML, and the browser. From this, we present the first static analysis {{that is capable of}} reasoning about the flow of control and data in modern JavaScript applications that interact with the HTML DOM and browser API. One application of such a static analysis is to detect typerelated anddataflow-related programmingerrors. Wereport on experiments with a range of modern web applications, including Chrome Experiments and IE Test Drive applications, to measure the precision and performance of the technique. The experiments indicate that the analysis is able to show absence of errors related to missing object properties and to identify <b>dead</b> and unreachable <b>code.</b> By measuring the precision of the types inferred for object properties, the analysis is precise enough to show that most expressions have unique types. By also producing precise call graphs, the analysis additionally shows that most invocations in the programs are monomorphic. We furthermore study the usefulness of the analysis to detect spelling errors in the code. Despite the encouraging results, not all problems are solved and some of the experiments indicate a potential for improvement, which allows us to identify central remaining challenges and outline directions for future work. Categories andSubject Descriptor...|$|R
40|$|Abstract: The paper {{shows that}} the {{excessive}} value of the <b>dead</b> loa design <b>code</b> implies a size effect. The size effect implied, however, d types of failure in which very different size effects apply. This size e primarily the size effect due to energy release, from the current code s load factor without simultaneously introducing size effect provisions i he de eff-b ign strain energy stored in a structure increases roughly quadratically plastic limit analysis—the theory underlying the current building codes. However, such an overdesign helps to counteract the ne-glect of the size effect in the current codes, which is inherent to plastic limit analysis concepts ~and to all theories in which the failure is decided by criteria expressed solely in terms of stress and strain, ignoring the energy release rate effect! ~Bažant 2000 !. There are many instances of brittle failures of reinforced con-crete structures exhibiting a large deterministic size effect that has with its size, the energy release per unit advance of the cracking band or fracture increases roughly linearly with the structure size, while the rate of energy consumed by cracking or fracture re-mains approximately the same. The material strength at different points of the failure surface is mobilized almost simultaneously in small structures and far from simultaneously in large structures. Due to stress reduction caused by localized cracking or fracture, the material failure in large structures propagates through the cross section. In plain concrete structures, such as gravity dams and arch dams, foundation plates and plinths, and retaining walls, a large deterministic size effect is also present. It is caused by stress redistribution, the extent of which is significant in a material with pronounced heterogeneity because a large zone of cracking devel-ops before the maximum load is attained ~this cracking zone rep-resents the fracture process zone of a continuous fracture whose propagation normally begins at maximum load; see Bažant an...|$|R
