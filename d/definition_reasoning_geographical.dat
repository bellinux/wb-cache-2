0|97|Public
40|$|This paper {{present a}} {{research}} project involved in legal expert system. The expertise domain concerns Public Procurement Market (PPM) in software acquisition. A very few civil servants have the necessary skill to combine public procurement regulations, data processing and computer law knowledge. The system should assist the Belgian administration in writing legal documents. During the consultation, the user can call several help-modules such as concept <b>definition,</b> <b>reasoning</b> justification power or can access a legal sources base...|$|R
40|$|The {{development}} of <b>geographical</b> <b>reasoning</b> {{is essential in}} geographical education. Strategies developed by the English Thinking Through Geography group (TTG) offer a promising approach to promote <b>geographical</b> <b>reasoning.</b> In the last decade, the TTG approach has become a regular element in geographical education in several countries. Research suggests that teachers acquainted with TTG do not always {{take full advantage of}} the possibilities of these strategies. The adoption of the TTG approach is explored ten years after its introduction in the Netherlands. Findings are presented of a survey conducted among Dutch geography teachers (N = 307) about the significance they assign to <b>geographical</b> <b>reasoning</b> and their use of TTG assignments. The results suggest that teachers use TTG selectively and adapt TTG assignments to fit them into existing practices and beliefs about students and teaching geography. © 2014 Taylor & Francis...|$|R
40|$|An {{approach}} to nonmonotonic inference {{based on a}} closure operation on a conditional knowledge base is presented The central idea is that, given a theory of default conditionals, an extension to the theory le defined that satisfies certain intuitive restrictions Two notions for forming an extension are given, corresponding to the incorporation of irrelevant properties in conditionals and of transitivity among condi tionals, in this approach these notions coincide Several equivalent definitions for an extension are developed general nonconstructive definitions, and a general &quot;pseudo-iterative &quot; <b>definition</b> <b>Reasoning</b> with irrelevant properties is correctly handled, as is specificity, reasoning within exceptional circumstances, and inheritance reasoning Tina approach is intented to ultimately serve as the proof-theoretic analogue to an extant semantic development based on preference orderings among possible worlds...|$|R
40|$|Clinical {{reasoning}} and medical decision. According to Newble’s <b>deﬁnition,</b> clinical <b>reasoning</b> is “the intellectual activity which synthesizes information {{obtained from the}} clinical situation, integrates it with previous knowledge and experience, and uses it for making diagnostic and therapeutic decisions”. This article is a review of several reasoning strategies to help analyze complex problems and warn physicians against the traps of hurried decision...|$|R
50|$|The <b>definition</b> of {{inductive}} <b>reasoning</b> {{described in}} this article excludes mathematical induction, which is a form of deductive reasoning that is used to strictly prove properties of recursively defined sets.|$|R
40|$|Abstract. We {{present a}} {{framework}} for a declarative approach to spatiotemporal <b>reasoning</b> on <b>geographical</b> data, based on the constraint logical language STACLP, which offers deductive and inductive capabilities. It can be exploited for a deductive rule-based approach to represent domain knowledge on data. Furthermore it is well suited to model trajectories of moving objects, which can be analysed by using inductive techniques, like clustering, {{in order to find}} common movement patterns. A sketch of a case study on behavioral ecology is presented. ...|$|R
40|$|Abstract. For years, the {{aerospace}} industry has relied on people and their knowledge to make critical decisions. This method of decision-making has become very expensive and unreliable, particularly when used to monitor increasingly complex systems. Intelligent systems and tools are now available {{that can be used}} to reduce costs and improve operations. Much work has been done in the area of intelligent systems to support aerospace-related activities. Computer Sciences Corporation (CSC) has conducted studies and developed prototypes using three forms of intelligent systems: case-based reasoning, rule-based reasoning, and model-based reasoning. This paper will present an overview of these technologies and related CSC projects, and how these technologies can be used to benefit {{the aerospace}} industry. Technology Overview Model-Based <b>Reasoning</b> <b>Definition</b> Model-based <b>reasoning</b> (MBR) is an intelligent system technology that reasons by storing causal models of devices or domains to avoid reasoning from scratch. MBR is used to identify failures by comparing a rea...|$|R
40|$|International audienceHaving {{defended the}} {{usefulness}} of our <b>definition</b> of <b>reasoning,</b> we stress that reasoning is not only for convincing but also for evaluating arguments, and that as such it has an epistemic function. We defend the evidence supporting the theory against several challenges: People are good informal arguers, they reason better in groups, {{and they have a}} confirmation bias. Finally, we consider possible extensions, first in terms of process-level theories of reasoning, and second in the effects of reasoning outside the lab...|$|R
30|$|In {{information}} systems, {{the division}} of a domain into relevant concepts and its formal representation is known as ontology [12]. The ThinkHome ontology {{can be seen as}} basis for the proposed system. All data has to be stored and provided in an intelligent way, supplying the system with needed knowledge. For the storage of information it was decided to use the Web Ontology Language (OWL), mainly because of its formal <b>definition</b> and <b>reasoning</b> capabilities. Furthermore, OWL is one major technology of the so-called Semantic Web. This additionally supports the openness of the ThinkHome knowledge representation.|$|R
40|$|This thesis {{explored}} how {{differences of}} opinion, associated with student 2 ̆ 7 s perspectives about earthquakes; impacts, influenced {{the level of}} geographical thinking displayed during group conversation. The findings formulated a Model for <b>Geographical</b> <b>Reasoning</b> {{which could be used}} by teachers to support their translation of the concepts and skills outlined in the Australian Curriculum for Geography into their pedagogical decisions...|$|R
40|$|This paper {{presents}} {{proposals for}} augmenting OWL Full with constructs necessary for supporting identity, an essential facility for ontologies governing interoperating information systems. These constructs include declaration that a property is one-to-one, {{a representation of}} the image of a property, and composition of properties. Using definitions from Category theory, property composition allows definition of Cartesian product without requiring that an individual have any internal structure. Category theory-style <b>definitions</b> and <b>reasoning</b> work entirely with properties, therefore are not affected by the open world semantics of OWL. The definitions permit representation of n-ary relations, association classes, parameterised families of properties and indexed families of classes...|$|R
40|$|Abstract. This paper {{presents}} {{a new approach}} for spatial event prediction that combines a value function approximation algorithm and case-based reasoning predictors. Each of these predictors makes unique contributions to the overall spatial event prediction. The function value approximation prediction is particularly suitable to <b>reasoning</b> with <b>geographical</b> features such as the (x,y) coordinates of an event. The case-based prediction is particularly well suited to deal with non-geographical features such {{as the time of}} the event or income level of the population. We claim that the combination of these two predictors results in a significant improvement of the accuracy in the spatial event prediction compared to pure geographically-based predictions. We support our claim by reporting on an ablation study for the prediction of improvised explosive device (IED) attacks...|$|R
40|$|It {{has been}} {{recently}} recognized that fuzzy set theory provides useful concepts and tools {{for both the}} representation {{and analysis of the}} uncertainty related to geographical data. Hence the incorporation of fuzzy set methodologies into a DBMS repository for the application domain of GIS should be beneficial and will improve its level of intelligence. Focusing in this area the paper addresses both a representation and a reasoning issue. Specifically, it extends a general spatial data model to deal with the uncertainty of geographical entities, and shows how the standard data interpretation operations available in GIS packages may be extended to support the fuzzy spatial <b>reasoning.</b> Representative <b>geographical</b> operations, such as the fuzzy overlay, fuzzy distance and fuzzy select, are examined, while several real world examples are given...|$|R
40|$|The Region Connection Calculus (RCC) is a {{well-known}} calculus for representing part-whole and topological relations. It {{plays an important role}} in qualitative spatial <b>reasoning,</b> <b>geographical</b> information science, and ontology. The computational complexity of reasoning with RCC 5 and RCC 8 (two fragments of RCC) as well as other qualitative spatial/temporal calculi has been investigated in depth in the literature. Most of these works focus on the consistency of qualitative constraint networks. In this paper, we consider the important problem of redundant qualitative constraints. For a set Γ of qualitative constraints, we say a constraint (x R y) in Γ is redundant if it is entailed by the rest of Γ. A prime subnetwork of Γ is a subset of Γ which contains no redundant constraints and has the same solution set as Γ. It is natural to ask how to compute such a prime subnetwork, and when it is unique. In this paper, we show that this problem is in general intractable, but becomes tractable if Γ is over a tractable subalgebra S of a qualitative calculus. Furthermore, if S is a subalgebra of RCC 5 or RCC 8 in which weak composition distributes over nonempty intersections, then Γ has a unique prime subnetwork, which can be obtained in cubic time by removing all redundant constraints simultaneously from Γ. As a byproduct, we show that any path-consistent network over such a distributive subalgebra is weakly globally consistent and minimal. A thorough empirical analysis of the prime subnetwork upon real geographical data sets demonstrates the approach is able to identify significantly more redundant constraints than previously proposed algorithms, especially in constraint networks with larger proportions of partial overlap relations. Comment: An extended abstract appears in Proceedings of the 14 th International Conference on the Principles of Knowledge Representation and Reasoning (KR- 14), Vienna, Austria, July 20 - 24, 201...|$|R
40|$|In {{the recent}} years, photo context {{metadata}} (e. g., date, GPS coordinates) have been {{proved to be}} useful {{in the management of}} personal photos. However, these metadata are still poorly considered in photo retrieving systems. In order to overcome this limitation, we propose an approach to incorporate contextual metadata, in a keyword-based photo retrieval process. We use metadata about the photo shot context (address location, nearby objects, season, light status…) to generate a bag of words for indexing each photo. We extend the Vector Space Model in order to transform these shot context words into document-vector terms. In addition, spatial <b>reasoning</b> and <b>geographical</b> ontologies are used to infer new indexing terms. This facilitates the query-document matching process and also allows performing semantic comparison between the query terms and photo annotations. 1...|$|R
40|$|The AI {{literature}} {{contains many}} <b>definitions</b> of diagnostic <b>reasoning</b> {{most of which}} are defined in terms of the logical entailment relation. We use existing work on approximate entailment to define notions of approximation in diagnosis. We show how such a notion of approximate diagnosis can be exploited in various diagnostic strategies. We illustrate these strategies by performing diagnosis in a small car domain example. ...|$|R
3000|$|Therefore, {{taking into}} account the issues {{associated}} with more complex approaches (particularly the lack of the necessary information), simple log-distance path loss would commonly be the most feasible solution to estimate the AOIs in many real deployments scenarios. In this case, for the AOIs <b>definition,</b> a similar <b>reasoning</b> to the one followed in [25] for coverage probability estimation is adopted. For each point (x,[*]y,[*]z), the expected received power from cell [...]...|$|R
40|$|A logical {{framework}} is a meta-language for the formalization of deductive systems {{as used in}} the description of logics and programming languages. It should directly support common notions and techniques of this domain, thereby achieving two related goals: on one hand, it provides a conceptual tool for the concise <b>definition</b> and rigorous <b>reasoning</b> about programming languages and logics; on the other hand, it significantly reduces the effort required to actually implement deductive systems...|$|R
50|$|The {{philosophical}} <b>definition</b> of inductive <b>reasoning</b> is {{more nuanced}} than simple progression from particular/individual instances to broader generalizations. Rather, {{the premises of}} an inductive logical argument indicate some degree of support (inductive probability) for the conclusion but do not entail it; that is, they suggest truth but do not ensure it. In this manner, {{there is the possibility}} of moving from general statements to individual instances (for example, statistical syllogisms, discussed below).|$|R
40|$|We {{investigate}} {{the development of}} a general-purpose framework for mechanized reasoning about the meta-theory of programming languages. In order to provide a standard, uniform account of a programming language, we propose to define it as a logic in a logical framework, using the same mechanisms for <b>definition,</b> <b>reasoning,</b> and automation that are available to other logics. Then, in order to reason about the language's meta-theory, we use reflection to inject the programming language into (usually richer and more expressive) meta-theory. One of the key features of our approach is that structure of the language is preserved when it is reflected, including variables, meta-variables, and binding structure. This allows the structure of proofs to be preserved as well, and there is a one-to-one map from proof steps in the original programming logic to proof steps in the reflected logic. The act of reflecting a language is automated; all definitions, theorems, and proofs are preserved by the transformation and all the key lemmas (such as proof and structural induction) are automatically derived. The principal representation used by the reflected logic is higher-order abstract syntax (HOAS). However, reasoning about terms in HOAS can be awkward in some cases, especially for variables. For this reason, we define a computationally equivalent variable-free de Bruijn representation that is interchangeable with the HOAS in all contexts. The de Bruijn representation inherits the properties of substitution and alpha-equality from the logical framework, and it is not complicated by administrative issues like variable renumbering. We further develop the concepts and principles of proofs, provability, and structural and proof induction. This work is fully implemented in the MetaPRL theorem prover. We illustrate with an application to F<: as defined in the POPLmark challenge...|$|R
40|$|Abstract. This paper {{investigates the}} use of Separation Logic with {{inductive}} <b>definitions</b> in <b>reasoning</b> about programs that manipulate dy-namic data structures. We propose a novel approach for exploiting the inductive definitions in automating program proofs based on inductive invariants. We focus on iterative programs, although our techniques ap-ply to recursive programs as well, and specifications that describe not only {{the shape of the}} data structures, but also their content or their size. This approach is based on a careful inspection of the typical lem-mas needed in such program proofs and efficiently checkable criteria for recognizing inductive definitions that satisfy these lemmas. Empirically, we find that our approach is powerful enough to deal with sophisticated benchmarks, e. g., iterative procedures for searching, inserting, or delet-ing elements in binary search tress, red-black trees, and AVL trees, in a very efficient way. ...|$|R
40|$|Finite {{computing}} {{agents that}} interact with an environment are {{shown to be}} more expressive than Turing machines according to a notion of expressiveness that measures problem-solving ability and is specified by observation equivalence. Sequential interactive models of objects, agents, and embedded systems are shown to be more expressive than algorithms. Multi-agent (distributed) models of coordination, collaboration, and true concurrency are shown to be more expressive than sequential models. The technology shift from algorithms to interaction is expressed by a mathematical paradigm shift that extends inductive <b>definition</b> and <b>reasoning</b> methods for finite agents to coinductive methods of set theory and algebra. An introduction to models of interactive computing is followed by an account of mathematical models of sequential interaction in terms of coinductive methods of non-well-founded set theory, coalgebras, and bisimulation. Models of distributed information flow and multi-agent inter [...] ...|$|R
30|$|Teachers in {{practitioner}} level {{have demonstrated}} {{at least two}} out of four indicators in each components of the four dimensions. They generally have knowledge about the mathematics content and mastery in procedural knowledge, and showed understanding of the new K to 12 curriculum. Though they used questions effectively to scaffold instruction and always used wait time and questioning effectively to diagnosed problems with learning and improved instruction, they used generic self-evaluation strategies or tools which did not explicitly show improvement on students’ self-learning and showed a limited sensitivity to student affect, the teacher tailored feedback {{for only a few}} students because the teacher gave more emphasis on teaching the specific content. Also they have showed basic knowledge of ICT but did not use it in class. In addition, practitioner teachers appreciated the beauty and importance of mathematics and highly passionate about teaching mathematics. They did not engage also any organization in related to mathematics except in their subject area department. While teachers in master level have shown three out of four indicators in each components of the four SEARS-MT dimensions. They demonstrated understanding of the nature and scope of mathematics content to be taught throughout the curriculum and its relevance to teaching, have the ability to explain fundamental principles in terms of precision, <b>definition,</b> <b>reasoning,</b> connections, coherence and purposefulness as well as procedural fluency. They generally used questions effectively to scaffold instruction and always used wait time and questioning effectively to diagnose problems with learning and improve instruction. They provided varied strategies for students to use for self-evaluation during instruction in an effort to regulate and improve the students’ self-learning by utilizing tools such as the use checklists, rubrics, drawings, a self-assessment inventory, journaling, and/or reflection statements. Also, utilized technology in class to increase visual, graphing and computing efficiency. Furthermore, master teachers exhibit enthusiasm and confidence for both mathematics and learning. Continuously enrich and upgrade knowledge and skills pertaining to mathematics and mathematics teaching and enrich educational experience by affiliating with professional organizations and community and promote mathematics in school and outside school.|$|R
40|$|Nonmonotonic {{logic is}} {{a branch of}} logic that has been {{developed}} to model situations with incomplete information. We {{argue that there is}} a connection between AOP and nonmonotonic logic which deserves further study. As a concrete technical contribution and “appetizer”, we outline an AO semantics defined in default logic (a form of nonmonotonic logic), propose a <b>definition</b> of modular <b>reasoning,</b> and show that the default logic version of the language semantics admits modular reasoning whereas a conventional language semantics based on weaving does not. 1...|$|R
40|$|The appropiate <b>definition</b> of {{argumentative}} <b>reasoning</b> systems {{requires a}} careful {{study of the}} dialectical analyses that are carried out in these formalisms. In thiswork we present a research line that points to the correct definition of such dialectical analyses. These dialectical analyses must be accomplished correctly, guided by proper criteria {{in order to prevent}} the construction of fallacious or ill formed argumentation lines. In this context, we analyze the definition of acceptable argumentation line in DELP and propose a revised version. Eje: Inteligencia artificia...|$|R
40|$|In this study, firstly we {{endeavor}} to prescribe logic <b>definitions</b> and <b>reasoning</b> process for obtaining correct rocket power and relevant efficiency equations. With the Lagrangian Reynolds transport approach, we also rigorously derive these highly generalized equations for rocket total kinetic power, thrust power and related propulsive, thermal, and overall efficiencies. They involve {{a few more}} physical effects including rocket acceleration, relative flow velocity/steadiness, outlet pressure, and gravity, thus open an original route for improving rocket propulsion analysis/design. Incidentally, {{it is interesting to}} note that under some conditions, a rocket in flight may retain less kinetic energy due to ejecting more kinetic energy of burning propellant per second than the thrust power acquired. Also, the derived correct rocket total kinetic power equations are quite reasonable in that all the velocities involved are of relative nature, thus invariant with respect to different observers and shielding the possibility of violating energy conservation law...|$|R
50|$|A {{deduction}} is {{a three-part}} system composed of premises, a conclusion, and chain of intermediates — steps of reasoning showing that its conclusion {{is a consequence}} of its premises. The reasoning in a deduction is by <b>definition</b> cogent. Such <b>reasoning</b> itself, or the chain of intermediates representing it, has also been called an argument, more fully a deductive argument. In many cases, an argument can be known to be valid by means of a deduction of its conclusion from its premises but non-deductive methods such as Venn diagrams and other graphic procedures have been proposed.|$|R
40|$|Performance Assurance is a {{methodology}} that, when applied during {{the design and}} development cycle, will greatly increase the chances of an e-Commerce project satisfying user performance requirements first time round. This paper discusses the primary risk factors in development projects, the keys to a successful risk management programme, and the tools required. It also discusses problems that can occur in e-Commerce systems and some examples of how these might manifest themselves. A <b>definition</b> and the <b>reasoning</b> behind a performance assurance methodology is given, and the performance assurance methodology that is proposed is outlined. 1...|$|R
40|$|We {{introduce}} {{the class of}} weak process dependency relations, and give definitions of starvation and deadlock cycles in terms of these. We show the usefulness of our <b>definitions</b> in <b>reasoning</b> about deadlocks, in the general sense {{of all forms of}} infinite process suspension, including the local form also known as livelock. In particular, we make a formal distinction between three complementary cases of deadlock: starvation, deadlock cycles, and a form we call non-closing deadlocks. Furthermore, we state assumptions under which absence of deadlocks may be verified for a program by verifying absence of deadlock cycles, and discuss when dependencies between deadlocked processes can safely be excluded. We give a generalised framework for verifying absence of deadlock cycles, in terms of our definitions, extending the method developed by Stephen P. Masticola to local deadlocks. Lastly, we demonstrate how Masticola's method can be mapped onto our framework, and briefly discuss the relation betw [...] ...|$|R
40|$|Contextual Vocabulary Acquisition (CVA) is {{the act of}} {{deriving}} {{the meaning}} of a word from the context in which it appears. The goal of the CVA project is to develop a computational model of this task. To accomplish this, the SNePS knowledge representation and reasoning system is used to model both the mind of a reader and the process of learning a new word. A cognitive agent known as Cassie is given a representation of a passage and an appropriate set of background knowledge. She then comes up with an approximate <b>definition</b> using <b>reasoning</b> and a CVA algorithm designed for a particular part of speech. In this paper, a revision to the verb algorithm using a package known as the SNePS Rational Engine is introduced. The benefits of this approach are discussed and the new algorithm is tested by comparing its performance against the results of a previous version of the verb algorithm...|$|R
5000|$|Though the Topics, as a whole, {{does not}} deal {{directly}} with the [...] "forms of syllogism", clearly Aristotle contemplates the use of topics as places from which dialectical syllogisms (i.e. arguments from the commonly held , éndoxa) may be derived. This {{is evidenced by the}} fact that the introduction to the Topics contains and relies upon his <b>definition</b> of <b>reasoning</b> ( [...] , syllogismós): a verbal expression ( [...] , lógos) in which, certain things having been laid down, other things necessarily follow from these.. Dialectical reasoning is thereafter divided by Aristotle into inductive and deductive parts. The endoxa themselves are sometimes, but not always, set out in a propositional form, i.e. an express major or minor proposition, from which the complete syllogism may be constructed. Often, such propositional construction is left as a task to the practitioner of the dialectic art; in these instances Aristotle gives only the general strategy for argument, leaving the [...] "provision of propositions" [...] to the ingenuity of the disputant.|$|R
40|$|Noel Castree (2009) regrets that {{academic}} geographers let pass without much fuss, the sesquicentenary {{of the publication}} of Charles Darwin's The Origin of Species. In part, this {{is the voice of}} Madison Avenue admonishing the sales team for missing a glorious promotional opportunity: `buy evolution, get geography free'. Castree has also a more serious point to make in remarking that Darwin used <b>geographical</b> <b>reasoning</b> to fundamentally alter the way people think about human life on earth. These issues still matter and Castree implies that the neglect of Darwin is part of geography's more general failure to engage critically with the sort of big-picture views of life on earth that could gain the discipline the popular attention it deserves...|$|R
40|$|This {{quarter was}} largely {{devoted to a}} {{detailed}} study of temperature data acquired by the Cryogenic Limb Array Etalon Spectrometer (CLAES) on UARS. Our analysis used the same sequence of methods that have been developed, tested and refined on a more limited subset of temperature data acquired by the CRISTA instrument. We focused on a limited subset of our <b>reasoning</b> that <b>geographical</b> and vertical trends in the small-scale temperature variability could be compared with similar trends observed in November 1994 by the CRISTA-SPAS satellite. Results, backed up with hindcasts from the Mountain Wave Forecast Model (MWFM), reveal strong evidence of mountain waves, most persuasively in the Himalayas on 16 - 17 November, 1992. These CLAES results are coherent over the 30 - 50 km range and compare well with MWFM hindcasts for the same period. This constitutes, we believe, the first clear evidence that CLAES explicitly resolved long wavelength gravity waves in its CO 2 temperature channel. A series of other tasks, related to mesoscale modeling of mountain waves in CRISTA data and fitting of ground-based and HRDI data on global scales, were seen through to publication stage in peer-reviewed journals...|$|R
40|$|Abstract. Social Network {{applications}} are gaining momentum. However, equally important, privacy is being shown a crucial requirement. Nowadays, privacy preferences on Social Network applications consist only on allowing or restricting {{access to information}} based on attributes of users who are part in the very same network. This paper tries to enhance privacy and provide automatic reactions to events via a very flexible specification of privacy policies and the reasoning associated to them. In our approach {{it is possible to}} include Social Semantic data exposed on the Web into the policy <b>definition</b> and <b>reasoning</b> process. We introduce the notion of reactive Semantic Web policies offering higher control of the communications and interactions among Social Network applications and/or its users. We also present SPoX (Skype Policy Extension), which is an implementation that allows policy-driven behaviour control based on the Social Network and communication software Skype, including the capacity of automatically react in certain situations based on user-defined reactive policies such as, for instance, to automatically deny or let through Skype calls and messages based on existing online Social Web data. ...|$|R
40|$|Abstract. The {{design of}} large and complex {{distributed}} systems requires a modular approach to support reuse and verification. We propose an object-oriented programming model based on concurrently executing communicating agents (concurrent objects) and an associated proof methodology that exploits the class hierarchy {{to allow for}} modular verification. We propose to separate protocol from functionality in class definitions, and advocate separate hierarchies of protocol classes {{as a way to}} overcome the inheritance anomaly of concurrent object-oriented programming. We formalize an agent in Lamport's Temporal Logic of Actions. Modular verification is achieved by restricting inheritance in a way that ensures that subclasses refine superclasses. Interesting properties can thus be verified at an abstract level, ignoring unnecessary implementation detail. 1 Introduction The object-oriented paradigm in software construction promises modular, incremental design and has therefore become very attractive to practitioners. On the other hand, its semantical foundations are still not well-understood, and few formalisms [3, 10] have been defined that allow the verification of object-oriented programs. In particular, it is notoriously hard to exploit the modular structure of object (or class) <b>definitions</b> in <b>reasoning</b> about object-oriented systems...|$|R
40|$|In this paper, I wish {{to point}} out an {{important}} problem which has largely escaped notice in the field(s) of natural language processing ~ Curiously, it is implicit in the topic title of this session, "Reasoning and Inference" ~ The fact that two terms {{were used in the}} title instead of one implies a meaningful distinction between two different types of intelligent processing~ The dictionary <b>definitions</b> of <b>reasoning</b> and inference are not much help in making a sharp distinction, but in actual use in artificial intelligence work these are two quite different traditions, each laying claim to one of the terms ~ Reasoning refers to the processing of abstract propositions to reach abstract conclusions ~ Reasoning is formal; {{it is based on the}} use of logical or mathematical rules, or special devices in a particular problem-solving domain~ Inferencing, on the other hand, refers to the processing of concrete facts to reach concrete conclusions ~ It is informal and "common-sensical " (whatever we quite mean by that) ~ It includes the curren ~ vein of wor...|$|R
