1730|757|Public
25|$|ArcGIS for Desktop Advanced (formerly {{known as}} ArcInfo), which {{includes}} capabilities for <b>data</b> <b>manipulation,</b> editing, and analysis.|$|E
25|$|Underscore.js is {{a utility}} JavaScript library for <b>data</b> <b>manipulation</b> {{that is used}} in both {{client-side}} and server-side network applications.|$|E
25|$|Scientific {{malpractice}} involving shoddy {{research or}} <b>data</b> <b>manipulation</b> does occur in rare instances. Often, however, {{the quality of}} manufacturers' studies {{are at least as}} good as studies that were not funded by a special interest. Therefore, bias usually occurs for other reasons.|$|E
5000|$|<b>Data</b> <b>manipulations</b> (INSERT, UPDATE, DELETE) may be {{done from}} a spreadsheet-like interface. Both raw table data and a result set from a query can be manipulated.|$|R
50|$|If no errors {{occurred}} during {{the execution of the}} transaction then the system commits the transaction. A transaction commit operation applies all <b>data</b> <b>manipulations</b> within the scope of the transaction and persists the results to the database. If an error occurs during the transaction, or if the user specifies a rollback operation, the <b>data</b> <b>manipulations</b> within the transaction are not persisted to the database. In no case can a partial transaction be committed to the database since that would leave the database in an inconsistent state.|$|R
50|$|The {{environment}} supplies built-in record creation, query, {{and update}} modes, {{each with its}} own default <b>data</b> <b>manipulations.</b> This minimizes the need to program common and tedious operations, such as creating dynamic SQL, sensing changed fields, and locking rows.|$|R
25|$|According to IFFRI study {{number of}} suicides during 2005–09 in Gujarat 387, Kerala 905, Punjab 75 and Tamil Nadu 26. While 1802 farmers {{committed}} suicide in Chhattisgarh in 2009 and 1126 in 2010, its farmers suicide dropped to zero in 2011, leading to accusations of <b>data</b> <b>manipulation.</b>|$|E
25|$|This form of <b>data</b> <b>manipulation</b> {{allows for}} rapid {{computer}} visualisation and analysis, with data presented as point cloud data with additional information, such as each ion's mass to charge (as computed from the velocity equation above), voltage or other auxiliary measured quantity or computation therefrom.|$|E
25|$|Coordinating {{applications}} on Grids can be {{a complex}} task, especially when coordinating {{the flow of information}} across distributed computing resources. Grid workflow systems have been developed as a specialized form of a workflow management system designed specifically to compose and execute a series of computational or <b>data</b> <b>manipulation</b> steps, or a workflow, in the Grid context.|$|E
40|$|This paper {{describes}} {{our experiences}} with the hardware description language Verilog during {{the development of the}} Xputer prototype. At first it introduces the novel non-von Neumann architecture of the Xputer, its need for efficient address generation and the basic structure of the Generic Address Generator. After a short introduction to Verilog, we discuss the problems with this hardware description language and show how to get around using some design restrictions. At the end a outlook on testing and simulation possibilities is given. Many applications require the same <b>data</b> <b>manipulations</b> to be performed on a large amount of data. These so called generic algorithms (e. g. systolic algorithms) are normally described as nested loops. A conventional von Neumann computer is not able to optimize such loops. Repetitive address patterns and <b>data</b> <b>manipulations</b> are interpreted on a per instruction basis. Thu...|$|R
25|$|Star and {{snowflake}} schemas {{are most}} {{commonly found in}} dimensional data warehouses and data marts where speed of data retrieval {{is more important than}} the efficiency of <b>data</b> <b>manipulations.</b> As such, the tables in these schemas are not normalized much, and are frequently designed at a level of normalization short of third normal form.|$|R
40|$|Introduction — Software {{architectures}} model {{systems at}} high levels of abstraction. They capture information about a system’s components and how those components are interconnected. Some software architectures also capture information about the possible states of components and about the component behaviors that involve component interaction; behaviors and <b>data</b> <b>manipulations</b> internal to a component are typically not considered at thi...|$|R
25|$|Visual FoxPro: Visual FoxPro is a {{data-centric}} object-oriented {{and procedural}} programming language produced by Microsoft. It derives from FoxPro (originally known as FoxBASE) which {{was developed by}} Fox Software beginning in 1984. Visual FoxPro is tightly integrated with its own relational database engine, which extends FoxPro's xBase capabilities to support SQL queries and <b>data</b> <b>manipulation.</b> Visual FoxPro is a full-featured, dynamic programming language that {{does not require the}} use of an additional general-purpose programming environment. In 2007, Visual FoxPro was discontinued after version 9 Service Pack 2. It was supported until 2015.|$|E
25|$|On 21 February 2007 it was {{reported}} that thirteen Adam Air employees, as well as an employee of airport operator PT Angkasa Pura, working at Soekarno-Hatta International Airport had been arrested for fraudulent <b>data</b> <b>manipulation.</b> The scheme involved manipulating passenger data to show passengers as 'leaving the country'. This meant that they were automatically charged a duty of 30,000 Rupiah each, when in reality they owed none. The money was then split between fourteen staff members. A computer from the check-in desk, as well as passenger tickets and lists, were seized.|$|E
25|$|By {{a similar}} token, Cocoa {{provides}} a pervasive <b>data</b> <b>manipulation</b> method called key-value coding (KVC). This allows {{a piece of}} data or property of an object to be looked up or changed at runtime by name. The property name acts {{as a key to}} the value. In traditional languages, this late binding is impossible. KVC leads to great design flexibility. An object's type need not be known, yet any property of that object can be discovered using KVC. Also, by extending this system using something Cocoa terms key-value observing (KVO), automatic support for undo-redo is provided.|$|E
50|$|In May 2014, {{the company}} {{announced}} protection for <b>data</b> from <b>manipulation,</b> malicious attacks, breaches, or deletion.|$|R
40|$|IQ-Services are application-specific, resource-aware code modules {{executed}} by data transport middleware. They constitute a `thin' layer between application components {{and the underlying}} computational and communication resources that implements the <b>data</b> <b>manipulations</b> necessary to permit wide-area collaborations to proceed smoothly, despite dynamic resource variations. IQ-Services interact with the application and resource layers via dynamic performance attributes, and end-to-end implementations of such attributes also permit clients to interact with data providers...|$|R
5000|$|<b>Data</b> bitfield <b>manipulation</b> - {{the ability}} to change certain data fields {{contained}} in the packet as it is being processed.|$|R
25|$|Articles by Inge Ropke (2004, 2005) and Clive Spash (1999) {{cover the}} {{development}} and modern history of ecological economics and explain its differentiation from resource and environmental economics, {{as well as some}} of the controversy between American and European schools of thought. An article by Robert Costanza, David Stern, Lining He, and Chunbo Ma responded to a call by Mick Common to determine the foundational literature of ecological economics by using citation analysis to examine which books and articles have had the most influence on the development of the field. However, citations analysis has itself proven controversial and similar work has been criticized by Clive Spash for attempting to pre-determine what is regarded as influential in ecological economics through study design and <b>data</b> <b>manipulation.</b> In addition, the journal Ecological Economics has itself been criticized for swamping the field with mainstream economics.|$|E
500|$|COBOL 2014 has 47 {{statements}} (also called [...] ), {{which can}} be grouped into the following broad categories: control flow, I/O, <b>data</b> <b>manipulation</b> and the report writer. The report writer statements are covered in the report writer section.|$|E
500|$|SQL three-valued {{logic is}} {{encountered}} in <b>Data</b> <b>Manipulation</b> Language (DML) in comparison predicates of DML statements and queries. The WHERE clause causes the DML statement {{to act on}} only those rows for which the predicate evaluates to True. [...] Rows for which the predicate evaluates to either False or Unknown are not acted on by INSERT, UPDATE, or DELETE DML statements, and are discarded by SELECT queries. Interpreting Unknown and False as the same logical result is a common error encountered while dealing with Nulls. [...] The following simple example demonstrates this fallacy: ...|$|E
40|$|Main {{objective}} {{of this paper is}} to design secure auditing protocol, during the data uploading to the server (Regular server/Cloud) through the data owner. Auditor place main role of monitoring the data transmission and <b>data</b> <b>manipulations</b> between the <b>data</b> owner and server. We introduced a secure and efficient dynamic auditing protocol by using the File segmentation and distribution, Tag generation, and Random Challenge and verification algorithms. Our proposed approach is efficient than the traditional protocols...|$|R
30|$|Regarding the {{available}} research {{works in the}} area, new forecasting approaches and techniques of input–output <b>data</b> <b>manipulations</b> are still in demand {{in order to enhance}} prediction accuracy and decrease the uncertainty in wind power forecasting, while keeping practically acceptable computation time. This objective leads to the new double-stage hybrid approach proposed in this research paper to utilize both statistical (wind farm SCADA records) and physical (NWP meteorological variables) data sources for achieving an effective and more accurate short-term wind power forecaster model.|$|R
40|$|A {{numerical}} homogenization {{method is}} here presented to solve problems governed by partial differential equations with coefficients that are generic functions in $R^ 2 $. It consists of a recursive finite elements discretization and an algebraic homogenization. This method takes advantages for speed and memory occupation from the hierarchy of elements and nodes defined by the recursive discretization. It turns out that using state-of-the-art general linear algebra techniques, all non-numerical <b>data</b> <b>manipulations</b> that are typically done before real computations, can be avoided...|$|R
500|$|Following {{the events}} of Chicago, San Francisco becomes the next city to install the ctOS (central Operating System), which connects {{everyone}} with everything. Hacker Marcus Holloway (Ruffin Prentiss) is punished for a crime he did not commit by the upgraded ctOS – ctOS 2.0 – which categorizes him as the suspect. Realizing the system covertly brings harm to the innocent citizens of San Francisco, he decides {{to work with the}} hacking group DedSec to take down the ctOS 2.0, and Blume, the company behind it. Marcus joins DedSec and works with fellow hackers Sitara (Tasya Teles), Wrench (Shawn Baichoo), Horatio (Michael Xavier) and Josh (Jonathan Dubsky), and they begin using their skills to expose corrupt organizations and corporations that are secretly using stolen personal ctOS data for their own ends. The game begins with Marcus – known also by his hacker alias Retr0 – having an initiation test: deleting his own ctOS profile. Accepted into DedSec, he is alerted to a Church called New Dawn that serves as a criminal organization, after which, Marcus mainly serves to bring about awareness of the hackers' goals through both social media and hacks to help get enough computers to bring down Blume, the 'figurehead' of ctOS. Eventually, they stumble upon the existence of a subliminal message and Bellwether, a <b>data</b> <b>manipulation</b> program being fed ctOS data by Dušan Nemec (Christopher Jacot), Blume's CTO, to manipulate world finance and politics. DedSec later manages to recruit the assistance of Raymond [...] "T-Bone" [...] Kenney (John Tench), who is determined to battle Blume three years after attacking the ctOS in Chicago.|$|E
2500|$|In 1992, CoSort added related <b>data</b> <b>manipulation</b> {{functions}} {{through a}} control language interface based on DEC VAX/VMS sort utility syntax, which evolved {{through the years}} to handle file-based data integration and staging functions in data warehouse ETL operations: ...|$|E
2500|$|Measuring {{software}} size {{requires that}} the whole source code be correctly gathered, including database structure scripts, <b>data</b> <b>manipulation</b> source code, component headers, configuration files etc. There are essentially two types of software sizes to be measured, the technical size (footprint) and the functional size: ...|$|E
40|$|We {{introduce}} a new transformation method to eliminate intermediate data structures occurring in functional programs due to repeated list concatenations and other <b>data</b> <b>manipulations</b> (additionally exemplified with list reversal and mapping of functions over lists). The general idea is to uniformly abstract from data constructors and manipulating operations by means of rank- 2 polymorphic combinators that exploit algebraic properties of these operations to provide an optimized implementation. The correctness of transformations is proved by using the free theorems derivable from parametric polymorphic types...|$|R
30|$|Through our {{experimental}} results, we verified {{that the}} proposed scheme for localizing the discrimination ability of the compact MPEG- 7 and MPEG- 7 -like global descriptors is an effective strategy for CBIR. A significant boost of their retrieval performance is reported not only compared to their original global form, but moreover, the proposed local features tested in the most straightforward retrieval model perform comparably and even outperform {{some of the most}} recently proposed retrieval models that base their success in much more complex <b>data</b> <b>manipulations.</b>|$|R
5000|$|Means for <b>data</b> storage, retrieval, <b>manipulation</b> and presentation; ...|$|R
2500|$|Several {{negative}} {{reviews of}} the book {{have been published in}} the scholarly literature. Susan Barnett and Wendy Williams wrote that [...] "we see an edifice built on layer upon layer of arbitrary assumptions and selective <b>data</b> <b>manipulation.</b> The data on which the entire book is based are of questionable validity and are used in ways that cannot be justified." [...] They also wrote that cross country comparisons are [...] "virtually meaningless." ...|$|E
2500|$|Current {{reports of}} the {{proportion}} of those killed who were civilians/militants are incomplete, and real-time errors, intentional <b>data</b> <b>manipulation,</b> and diverse methodologies produce notable variations in various sides' figures. For example, the Hamas-run Interior Ministry has issued instructions for activists to always refer to casualties as [...] "innocent civilians" [...] or [...] "innocent citizens" [...] in internet posts. However, B'Tselem has stated that after the various groups finish their investigations, their figures are {{likely to end up}} about the same. UNICEF and the Gaza Health Ministry reported that from 8 July to 2 August 296–315 Palestinian children died due to Israeli action, and 30% of civilian casualties were children; by 27 August, the total number of children killed had risen to 495–578, according to OCHA and the Gaza Health Ministry. In March 2015, OCHA reported that 2,220 Palestinians had been killed, of whom 1,492 were civilians (551 children and 299 women), 605 militants and 123 of unknown status. According to ITIC, 48.7% of the identified casualties were militants and in some cases children and women participated in military operations.|$|E
2500|$|The {{recent cases}} of Joachim Boldt and Yoshitaka Fujii in anaesthesiology have {{focussed}} {{attention on the}} role that journals play in perpetuating scientific fraud {{as well as how}} they can deal with it. In the Boldt case, the Editors-in-Chief of 18 specialist journals (generally anaesthesia and intensive care) made a joint statement regarding 88 published clinical trials conducted without Ethics Committee approval. In the Fujii case, involving nearly 200 papers, the journal Anesthesia & Analgesia, which published 24 of Fujii's papers, has accepted that its handling of the issue was inadequate. [...] Following publication of a Letter to the Editor from Kranke and colleagues in April 2000, along with a non-specific response from Dr. Fujii, there was no follow-up on the allegation of <b>data</b> <b>manipulation</b> and no request for an institutional review of Dr. Fujii's research. Anesthesia & Analgesia went on to publish 11 additional manuscripts by Dr. Fujii following the 2000 allegations of research fraud, with Editor Steven Shafer stating in March 2012 that subsequent submissions to the Journal by Dr. Fujii should not have been published without first vetting the allegations of fraud. In April 2012 Shafer led a group of editors to write a joint statement, {{in the form of an}} ultimatum made available to the public, to a large number of academic institutions where Fujii had been employed, offering these institutions the chance to attest to the integrity of the bulk of the allegedly fraudulent papers.|$|E
40|$|International audienceUser-centric {{business}} intelligence aims at empowering analysts who interact with complex tools, {{by allowing them}} to perform accurate <b>data</b> <b>manipulations</b> and analysis without necessarily requiring IT expertise and knowledge of underlying data speci cations. Recommender systems contribute to easing their tasks, but most of them operate inside walled gardens and cannot assist properly the user throughout his BI workflow. In this paper we introduce a lightweight vocabulary intended to capture fragments of analytical workflows as multidimensional data transformations, within a Semantic Web framework. We utilize this model for calculating content-based recommendations...|$|R
40|$|The article puts {{an accent}} on three aspects, which are shown {{through the prism}} of the {{specific}} cognitive potential of the statistical aggregate characteristics: the place of statistical information in the investigation of the social practice and in the scientific knowledge; the most widespread unintentional errors of the analysis, explanation and presentation of the aggregate statistical characteristics; the deliberate confusions from <b>data</b> <b>manipulations,</b> connected with unscrupulous and corrupt intentions. The main problem here is whether it is possible and in what way, the interests of society should be protected from such errors and deliberate confusions. ...|$|R
50|$|The {{concurrency}} and transaction aspects {{are significantly}} different also. In particular, transactions, the smallest {{unit of work}} performed by databases, are much larger in relational databases than are any operations performed by classes in OO languages. Transactions in relational databases are dynamically bounded sets of arbitrary <b>data</b> <b>manipulations,</b> whereas the granularity of transactions in an OO language is typically {{on the level of}} individual assignments to primitive-typed fields. In general, OO languages have no analogue of isolation or durability, so atomicity and consistency are only ensured when writing to fields of those primitive types.|$|R
