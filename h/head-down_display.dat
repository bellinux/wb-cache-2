56|48|Public
50|$|The {{output from}} the ILS {{receiver}} {{goes to the}} display system (<b>head-down</b> <b>display</b> and head-up display if installed) and may go to a Flight Control Computer. An aircraft landing procedure can be either coupled where the autopilot or Flight Control Computer directly flies the aircraft and the flight crew monitor the operation, or uncoupled where the flight crew flies the aircraft manually to keep the localizer and glideslope indicators centered.|$|E
50|$|An Enhanced flight {{vision system}} (EFVS, {{sometimes}} EVS) {{is a system}} for imaging the external world from an aircraft, and to provide an image in which objects can be better detected. In other words, an EFVS is a system to provide an image which is better than unaided human vision. An EFVS includes sensors (one or many) such as a color camera, infrared camera or radar, and typically a display for the pilot, {{which can be a}} head-up display or <b>head-down</b> <b>display.</b> An EFVS may be combined with a synthetic vision system to create a combined vision system.|$|E
50|$|The term PHMD {{includes}} {{devices such}} as Google Glass, which are often missclassified as a Head-up display (HUD). if following the original definition by NASA. While NASA defined this term over centuries of space flight research, it actually describes a display that addresses the eyes-free problem, by absolving the user from the need to angle down their head. Furthermore, it provides augmented information in the user’s forward Field-of-View (FOV), which is commonly projected on a windshield. In contrast, the <b>Head-Down</b> <b>Display</b> (HDD) {{is located at the}} instrument control panel. Also, a HUD is mainly used to augment additional information into reality, which is technically not feasible yet for products such as Google Glass (lens focus on the display causes a blurred environment - see figure below).|$|E
40|$|Five {{variables}} were studied {{relating to the}} emergence of sociality in hand-reared cowbirds (Molothrus ater) : proximity, sex assortment, reactions to adults, <b>head-down</b> <b>displays,</b> and vocalizations. The authors were especially interested in female sociality because adult female birds influence male courtship, song content, and use through proximity, attention, and displays. The authors found that young female birds failed to show same-sex affiliation typical of the species at any point in the study. Brief introduction of adults did not affect social patterns. Adults used more <b>head-down</b> <b>displays</b> than juveniles, who used more displays with familiar peers. Directed and undirected singing emerged concurrently; directed singing was positively correlated with earlier hatching. This is the first demonstration of the need for early learning in the development of female sociality...|$|R
40|$|Experiments were {{conducted}} in a fixed-base, high-fidelity simulator to evaluate selected in-vehicle route guidance systems. Drivers navigated a simulated network using five route guidance systems: paper map, <b>head-down</b> turn-by-turn <b>display,</b> <b>head-down</b> electronic route map, head-up turn-by-turn display, and an audio guid-ance system. The primary measure of driving performance was the reaction time to a scanning task. Other measures included navigation errors, workload, and percep-tion ratings. Censored regression models were developed to study the effect of route guidance type on reaction times. Results indicated that the drivers responded the fastest while using the audio system and the slowest while using the paper map. The head-up turn-by-turn display was associated with lower reaction times compared with an identically designed <b>head-down</b> turn-by-turn <b>display.</b> The <b>head-down</b> elec-tronic map, despite its complexity, performed better than the <b>head-down</b> turn-by-turn <b>display...</b>|$|R
40|$|The Terrain Portrayal for <b>Head-Down</b> <b>Displays</b> (TP-HDD) {{simulation}} experiment addressed multiple objectives involving twelve display concepts (two baseline concepts without {{terrain and}} ten synthetic vision system (SVS) variations), four evaluation maneuvers (two en route and one approach maneuver, plus a rare-event scenario), and three pilot group classifications. The TP-HDD SVS simulation {{was conducted in}} the NASA Langley Research Center's (LaRC's) General Aviation WorkStation (GAWS) facility. The results from this simulation establish the relationship between terrain portrayal fidelity and pilot situation awareness, workload, stress, and performance and are published in the NASA TP entitled Terrain Portrayal for Synthetic Vision Systems <b>Head-Down</b> <b>Displays</b> Evaluation Results. This {{is a collection of}} pilot comments during each run of the TP-HDD simulation experiment. These comments are not the full transcripts, but a condensed version where only the salient remarks that applied to the scenario, the maneuver, or the actual research itself were compiled...|$|R
40|$|Feasibility of an EVS head-down {{procedure}} is examined that {{may provide the}} same operational benefits under low visibility as the FAA rule on Enhanced Flight Visibility that {{requires the use of}} a head-up display (HUD). The main element of the described EVS head-down {{procedure is}} the crew procedure within cockpit for flying the approach. The task sharing between Pilot-Flying and Pilot-Not-Flying is arranged such that multiple head-up/head-down transitions can be avoided. The Pilot-Flying is using the <b>head-down</b> <b>display</b> for acquisition of the necessary visual cues in the EVS image. The pilot not flying is monitoring the instruments and looking for the outside visual cues. Results of simulation trials suggest that pilots can fly an EVS approach using the proposed EVS <b>head-down</b> <b>display</b> {{with the same kind of}} performance (accuracy) as they do with the HUD. There seems to be no loss of situation awareness. Further on, there is not significant trend that the use of the EVS <b>head-down</b> <b>display</b> leads to higher workload compared to the EVS HUD approach. In conclusion, EVS-Head-Down may be as well a feasible option for getting extra operational credit under low visibility conditions. ...|$|E
40|$|This {{document}} {{presents the}} results of the human factors-oriented real time simulations on the cockpit simulator GECO at DLR-Braunschweig for the EVS head-down procedure. Two different crew procedures have been tested against the already operational EVS head-up procedure. The investigations showed that pilots can fly an EVS approach using the proposed EVS <b>head-down</b> <b>display</b> {{with the same kind of}} performance (accuracy) as they do with the HUD. There seems to be no loss of situation awareness. Further on, there is not significant trend that the use of the EVS <b>head-down</b> <b>display</b> leads to higher workload compared to the EVS HUD approach. In conclusion, EVS-Head-Down may be as well a feasible option for getting extra operational credit under low visibility conditions...|$|E
40|$|Due to the {{character}} of the original source materials and the nature of batch digitization, quality control issues may be present in this document. Please report any quality issues you encounter to digital@library. tamu. edu, referencing the URI of the item. Includes bibliographical references: p. 93 - 94. Issued also on microfiche from Lange Micrographics. Modem computing technology can be useful for improving safety in the general aviation industry. Intelligent systems can be developed that aid the dual goals of increasing pilot situational awareness and decreasing pilot workload, which, in turn, should lead to improved safety. The Aerospace and Electrical Engineering Departments at Texas A&M University, along with Knowledge Based Systems, Inc., have joined together in a research program titled General Aviation Pilot Advisory and Training System (GAPATS). GAPATS research is focused on integrating inexpensive, yet powerful, computing technology into general aviation aircraft. The system architecture consists of several components, one of which is a <b>head-down</b> <b>display.</b> A <b>head-down</b> <b>display</b> is a display that, in general, is embedded in the cockpit instrument panel. When viewing a <b>head-down</b> <b>display,</b> the pilot looks "down" into the cockpit, rather than up and out through the windshield, hence the term, "head-down" display. In GAPATS, the <b>head-down</b> <b>display</b> operates in several display modes spanning a wide range of functions. Thus, it is also called a Multi-Function Display. The various display modes have been designed with careful attention to the aforementioned system goals of reduced pilot workload and increased situational awareness. This thesis provides a thorough overview of the design and development of the Multi-Function Display. Inadequacies of the Multi-Function Display are also cited, particularly pertaining to the user interface. Finally, suggestions for future enhancements are proposed...|$|E
5000|$|Since being {{introduced}} on HUDs, both the FPV and acceleration symbols are becoming standard on <b>head-down</b> <b>displays</b> (HDD). The actual {{form of the}} FPV symbol on an HDD is not standardized but is usually a simple aircraft drawing, such as a circle with two short angled lines, (180 ± 30 degrees) and [...] "wings" [...] {{on the ends of}} the descending line. Keeping the FPV on the horizon allows the pilot to fly level turns in various angles of bank.|$|R
40|$|Eight 757 {{commercial}} airline captains flew 22 approaches using the Reno Sparks 16 R Visual Arrival under simulated Category I conditions. Approaches were flown using a <b>head-down</b> synthetic vision <b>display</b> to evaluate four tunnel ("minimal", "box", "dynamic pathway", "dynamic crow s feet") and three guidance ("ball", "tadpole", "follow-me aircraft") concepts and compare their efficacy to a baseline condition (i. e., no tunnel, ball guidance). The {{results showed that}} the tunnel concepts significantly improved pilot performance and situation awareness and lowered workload compared to the baseline condition. The dynamic crow s feet tunnel and follow-me aircraft guidance concepts were found to be the best candidates for future synthetic vision <b>head-down</b> <b>displays.</b> These results are discussed with implications for synthetic vision display design and future research...|$|R
2500|$|The Harrier II's cockpit has day {{and night}} {{operability}} and is equipped with head-up <b>display</b> (HUD), two <b>head-down</b> <b>displays</b> known as multi-purpose colour displays (MPCD), a digital moving map, an inertial navigation system (INS), and a hands-on-throttle-and-stick system (HOTAS). Like the British Aerospace Sea Harrier, the Harrier II used an elevated bubble canopy to provide a significantly improved all-round view. A combination of the new design of the control system and the greater [...] stability of the aircraft made the Harrier II fundamentally easier to fly than the first generation Harrier GR1/GR3 models.|$|R
40|$|In the {{currently}} existing {{rules for the}} use of EVS in combination with operational benefits (FAA rule on Enhanced Flight Visibility or the respective JAA approach published in the NPA OPS 41 Subpart E All Weather Operations) do not allow an EVS <b>head-down</b> <b>display.</b> The rule requires that EFVS include a head-up display rather than the alternative of a <b>head-down</b> <b>display</b> because the pilot is conducting an instrument approach procedure in lower visibility conditions, but with no change in the prescribed instrument approach minima and must accomplish several visually-related judgments and control tasks in quick succession. While the regulatory requirements {{for the use of}} EFVS are analogous to the conventional requirements for descent and operation below DH or MDA, the pilot needs to use the imagery, the flight reference information, and eventually the outside view, at the same time. The pilot must be able to look for the outside visual references in the same location as they appear in the EFVS image and readily see them as soon as visibility conditions permit, without any delays or distraction due to multiple head-up/ head-down transitions. When scanning between the head-up and head-down views, it takes additional time for the pilot to reacquire the information in each view and for the pilot’s eyes to readjust for differences in light level and changes in focus between optical infinity and the distance to the instrument panel. Repeated scanning between the head-up and head-down views would be distracting, increase pilot workload and potentially degrade path performance during a critical phase of flight. However, our proposal for the use of EVS does allow for a <b>head-down</b> <b>display</b> to continue the descent below DH/MDA. The above mentioned concerns against <b>head-down</b> <b>display</b> can be overcome by an introduction of an adequate crew procedure and display design The task sharing between Pilot-Flying and Pilot-Not-Flying has to be arranged such that multiple head-up/head-down transitions can be avoided. The Pilot-Flying is using the <b>head-down</b> <b>display</b> for acquisition of the necessary visual cues in the EVS image. The pilot flying is monitoring the instruments and looking for the outside visual cues. The use of reduced RVR (as described in the JAA NPA OPS 41) will help the crew to define the point when one can expect the runway to become visible. Thus, this aspect is included in the approach briefing. In addition, the approach briefing covers the aspect of who will conduct the visual landing once visual contact to the runway is established and how - in case there will be no hand-over of the controls – the pilot-not-flying can support the pilot-flying in immediately detection the runway after his transition from head-down to head-up. This contribution focuses on the results of simulation trials with pilots using DLR’s cockpit simulator GECO. The simulation trials compares {{the currently}} used head-up display design with the new <b>head-down</b> <b>display</b> in combination with the defined crew procedure. Results are given in terms of performance and workload assessments. ...|$|E
40|$|Report evaluates three similar video {{displays}} for guidance of helicopter pilots in low-level flight {{at night in}} adverse weather. Computer produces guidance information for pilot by integrating data from terrain-following radar, forward-looking infrared (FLIR) imagery, and data from such autonomous navigation instruments as inertial navigation systems and Doppler radar. FLIR imagery, information on status of helicopter, and command symbols incorporated in one <b>head-down</b> <b>display...</b>|$|E
40|$|An {{analytical}} and {{experimental study of}} human pilot control strategies in a manned rotorcraft simulation is described. The task simulated involves a low-speed, constant-altitude maneuvering task in which a <b>head-down</b> <b>display</b> is utilized to allow the pilot to track a moving hover point. The efficacy of the display law driving an 'acceleration symbol' is determined {{and the manner in}} which the prediction and measurement of pilot/vehicle dynamics can be made part of man/machine system evaluations is demonstrated...|$|E
40|$|High-fidelity color {{pictorial}} displays {{that incorporate}} depth cues {{in the display}} elements are currently available. Depth cuing applied to advanced <b>head-down</b> flight <b>display</b> concepts potentially enhances the pilot's situational awareness and improves task performance. Depth cues provided by stereopsis exhibit constraints that must be fully understood so depth cuing enhancements can be adequately realized and exploited. A fundamental issue (the goal of this investigation) is whether the use of <b>head-down</b> stereoscopic <b>displays</b> in flight applications degrade the real-world depth perception of pilots using such displays. Stereoacuity tests are {{used in this study}} as the measure of interest. Eight pilots flew repeated simulated landing approaches using both nonstereo and stereo 3 -D <b>head-down</b> pathway-in-the-sky <b>displays.</b> At this decision height of each approach (where the pilot changes to an out-the-window view to obtain real-world visual references) the pilots changed to a stereoacuity test that used real objects. Statistical analysis of stereoacuity measures (data for a control condition of no exposure to any electronic flight display compared with data for changes from nonstereo and from stereo displays) reveals no significant differences for any of the conditions. Therefore, changing from short-term exposure to a <b>head-down</b> stereo <b>display</b> has no more effect on real-world relative depth perception than does changing from a nonstereo display. However, depth perception effects based on sized and distance judgements and on long-term exposure remain issues to be investigated...|$|R
40|$|Trials {{were run}} on a six degree of freedom combat {{helicopter}} simulator to evaluate <b>head-down</b> <b>displays</b> with integrated FLIR imagery for terrain-following, course-steering, and transition to approach and hover helicopter pilot tasks. Three display formats were tested, providing varying levels of symbology for, e. g., the flight path angle, pitch-attitude data, vertical speed, altitude, etc. The pilots were also furnished flight director guidance, i. e., terrain-following, course steering, airspeed hold, and approach to hover. All the displays permitted the pilots to fly satisfactory mission in the CGI scenarios. The results revealed that the pilots preferred a nonconformal FLIR display superposition...|$|R
40|$|This report {{describes}} the software products and their application which {{were developed by}} Lockheed-Martin to facilitate Land and Hold Short operations, {{in support of the}} combined Runway Incursion Prevention System and Hold Short Advisory Landing Technology (RIPS-HSALT) research project carried out by NASA Langley Research Center as part of the Aviation Safety Program's Synthetic Vision System element. The motivation behind this effort was the desire to improve airport capacity by increasing the acceptance of Land and Hold Short operations, which would improve situational awareness and safety margins. This effort was built on previous work in using integrated head-up and <b>head-down</b> <b>displays</b> to improve ground operations at airports [1, 2...|$|R
40|$|US Army Research Laboratory {{researchers}} {{designed a}} head-up display (HUD) that overlays driving {{information on a}} switchable vision block. Bradley and Stryker drivers were surveyed for recommendations to incorporate in the prototype. A simulation experiment was conducted to evaluate a HUD versus a traditional <b>head-down</b> <b>display</b> (HDD). Results about driving task performance were mixed, with the HUD associated with poorer performance in some measures and the HDD with others. Participants detected significantly more roadside improvised explosive devices (IEDs) with the HDD than with the HUD; they also detected the IEDs from a farther distance wit...|$|E
40|$|Feasibility of an EVS head-down {{procedure}} is examined that {{may provide the}} same operational benefits under low visibility as the FAA rule on Enhanced Flight Visibility that {{requires the use of}} a head-up display (HUD). The main element of the described EVS head-down {{procedure is}} the crew procedure within cockpit for flying the approach. The task sharing between Pilot-Flying and Pilot-Not-Flying is arranged such that multiple head-up/head-down transitions can be avoided. The pilot-flying is using the <b>head-down</b> <b>display</b> for acquisition of the necessary visual cues in the EVS image. The pilot-not-flying is monitoring the instruments and looking for the outside visual cues...|$|E
40|$|The {{purpose of}} this study was to {{evaluate}} various cues on a background display format that depicted attitude information. A combined <b>head-down</b> <b>display</b> format was evaluated where the central rectangular area focused on tactical information and the background border presented attitude information. The attitude information, in essence, framed the tactical display format. A comparison was conducted among variations of the original background attitude indicator (BAI) created by General Dynamics personnel. Three types of cues were investigated: color shading, color patterns, and pitch lines with numbers. These cues were tested individually and in combination with one another. Results showed that in terms of initial input time, the combination of color shading and color patterns performed the best...|$|E
40|$|To {{minimize}} the mental workload {{for the driver}} {{and to keep the}} increasing amount of information easily accessible, sophisticated display and interaction techniques are essential. This contribution focuses on a user-centered analysis for an authoritative grading of head-up displays (HUDs) in cars. Two studies delivered the evaluation data. In a field test, the potential and the usability of the HUD were analyzed. For special driving situations the according display needs and requirements of the users have been identified and compared with in-car <b>displays,</b> so-called <b>head-down</b> <b>displays</b> (HDD). As major result, a high acceptance of the HUD by the driver and a good performance compared to other in-car displays had been reached. 1...|$|R
40|$|This {{experiment}} {{investigates the}} capability of Synthetic Vision Systems (SVS) to provide significant situation awareness in terminal area operations, specifically in low visibility conditions. The use of a Head-Up <b>Display</b> (HUD) and <b>Head-Down</b> <b>Displays</b> (HDD) with SVS is contrasted to baseline standard head down displays in terms of induced workload and pilot behavior in 1400 RVR visibility levels. Variances across performance and pilot behavior were reviewed for acceptability when using HUD or HDD with SVS under reduced minimums to acquire the necessary visual components to continue to land. The data suggest superior performance for HUD implementations. Improved attentional behavior is also suggested for HDD implementations of SVS for low-visibility approach and landing operations...|$|R
40|$|During Apollo, the {{constraints}} placed by {{the design of}} the Lunar Module (LM) window for crew visibility and landing trajectory were a major problem. Lunar landing trajectories were tailored to provide crew visibility using nearly 70 degrees look-down angle from the canted LM windows. Apollo landings were scheduled only at specific times and locations to provide optimal sunlight on the landing site. The complications of trajectory design and crew visibility are still a problem today. Practical vehicle designs for lunar lander missions using optimal or near-optimal fuel trajectories render the natural vision of the crew from windows inadequate for the approach and landing task. Further, the sun angles for the desirable landing areas in the lunar polar regions create visually powerful, season-long shadow effects. Fortunately, Synthetic and Enhanced Vision (S/EV) technologies, conceived and developed in the aviation domain, may provide solutions to this visibility problem and enable additional benefits for safer, more efficient lunar operations. Piloted simulation evaluations have been conducted to assess the handling qualities of the various lunar landing concepts, including the influence of cockpit displays and the informational data and formats. Evaluation pilots flew various landing scenarios with S/EV displays. For some of the evaluation trials, an eye glasses-mounted, monochrome monocular display, coupled with head tracking, was worn. The head-worn display scene consisted of S/EV fusion concepts. The results of this experiment showed that a head-worn system did not increase the pilot s workload when compared to using just the <b>head-down</b> <b>displays.</b> As expected, the head-worn system did not provide an increase in performance measures. Some pilots commented that the head-worn system provided greater situational awareness compared to just <b>head-down</b> <b>displays...</b>|$|R
40|$|An AGATE Concepts Demonstration was {{conducted}} at the Annual National Air Transportation Association (NATA) Convention in 1997. Following, a 5 -minute introductory briefing, an interactive simulation of a single-pilot, single-engine aircraft {{was conducted}}. The participant {{was able to take}} off, fly a brief enroute segment, fly a Global Positioning System (GPS) approach and landing, and repeat the approach and landing segment. The participant was provided an advanced 'highway-in-the-sky' presentation on both a simulated head-up display and on a large LCD <b>head-down</b> <b>display</b> to follow throughout the flight. A single-lever power control and display concept was also provided for control of the engine throughout the flight. A second head-down, multifunction display in the instrument panel provided a moving map display for navigation purposes and monitoring of the status of the aircraft's systems...|$|E
40|$|Flight path primary {{flight display}} formats were {{incorporated}} on head-up and head-down electronic displays and integrated into an Advanced Concepts Flight Simulator. Objective and subjective {{data were collected}} while ten airline pilots evaluated the formats by flying an approach and landing task under various ceiling, visibility and wind conditions. Deviations from referenced/commanded airspeed, horizontal track, vertical track and touchdown point were smaller using the head-up display (HUD) format than the <b>head-down</b> <b>display</b> (HDD) format, but not significantly smaller. Subjectively, the pilots overwhelmingly preferred (1) flight path formats over attitude formats used in current aircraft, and (2) the head-up presentation over the head-down, primarily because it eliminated the head-down to head-up transition during low visibility landing approaches. This report describes the simulator, the flight displays, the format evaluation, {{and the results of}} the objective and subjective data...|$|E
40|$|Field-of-view (FOV) {{effects are}} {{investigated}} in simulated flights with sensor imagery appearing on a head-up display (HUD) and a <b>head-down</b> <b>display</b> (HDD). The pilots fly a simulated slalom course and are given {{information from a}} sensor image with a 25 -, 40 -, or 50 -deg FOV and no additional information. The factors which most significantly affect performance are thereby identified, and the speed of flying, level of training, and FOV {{are found to be}} the most important characteristics. FOV affects performance regardless of the choice of HUD or HDD, and the narrow FOV caused the pilots to fly closer to the obstacles than the wider FOVs. No statistically significant difference between the use of HUD and HDD is identified, but the pilots appear to regard the displays in general as the entire world and not as a 'window on the world'...|$|E
40|$|A {{critical}} component of SVS displays is the appropriate presentation of terrain to the pilot. At {{the time of this}} study, the relationship between the complexity of the terrain presentation and resulting enhancements of pilot SA and pilot performance had been largely undefined. The terrain portrayal for SVS <b>head-down</b> <b>displays</b> (TP-HDD) simulation examined the effects of two primary elements of terrain portrayal on the primary flight display (PFD) : variations of digital elevation model (DEM) resolution and terrain texturing. Variations in DEM resolution ranged from sparsely spaced (30 arc-sec) to very closely spaced data (1 arc-sec). Variations in texture involved three primary methods: constant color, elevation-based generic, and photo-realistic, along with a secondary depth cue enhancer {{in the form of a}} fishnet grid overlay...|$|R
40|$|Both the {{effectiveness}} of pilot training {{and the safety of}} flight can be influenced by the distribution of texture in the visual scene, the distance to which the eyes accommodate, and the associated shifts in the apparent size and distance of objects in central and peripheral vision. Studies reviewed and original results presented indicate that these factors are involved in various misjudgments and illusions experienced by pilots: (1) when searching for other airborne traffic or targets, (2) when making approaches to airports over water at night, (3) when breaking out of low clouds on a final approach to a landing by reference to head-up or <b>head-down</b> <b>displays,</b> and (4) when practicing simulated approaches and landings or air-to-surface weapon deliveries by reference to synthetically generated visual systems...|$|R
40|$|Spatial {{disorientation}} {{induced by}} inadvertent flight into {{instrument meteorological conditions}} (IMC) {{continues to be a}} leading cause of fatal accidents in general aviation. The Synthetic Vision Systems – General Aviation (SVS-GA) research element, an integral part of NASA’s Aviation Safety and Security Program (AvSSP), is investigating a revolutionary display technology designed to mitigate low visibility events such as controlled flight into terrain (CFIT) and low-visibility loss of control (LVLoC). The integrated SVS Primary Flight Display (SVS-PFD) utilizes computer generated 3 -dimensional imagery of the surrounding terrain augmented with flight path guidance symbology. This unique combination will provide GA pilots with an accurate representation of their environment and projection of their flight path, regardless of time of day or out-the-window (OTW) visibility. The initial Symbology Development for <b>Head-Down</b> <b>Displays</b> (SD-HDD) simulation experiment examined 1...|$|R
40|$|Quantifying pilot visual {{behavior}} allows {{researchers to}} determine not only where a pilot is looking and when, but holds implications for specific behavioral tracking when {{these data are}} coupled with flight technical performance. Remote eye tracking systems have been integrated into simulators at NASA Langley with effectively {{no impact on the}} pilot environment. This paper discusses the installation and use of a remote eye tracking system. The data collection techniques from a complex human-in-the-loop (HITL) research experiment are discussed; especially, the data reduction algorithms and logic to transform raw eye tracking data into quantified visual behavior metrics, and analysis methods to interpret visual behavior. The findings suggest superior performance for Head-Up Display (HUD) and improved attentional behavior for <b>Head-Down</b> <b>Display</b> (HDD) implementations of Synthetic Vision System (SVS) technologies for low visibility terminal area operations. Keywords: eye tracking, flight deck, NextGen, human machine interface, aviatio...|$|E
40|$|Research {{literature}} are reviewed and summarized {{to evaluate the}} awareness and detection of traffic and obstacles when using Synthetic Vision Systems (SVS) and Enhanced Vision Systems (EVS). The study identifies the critical issues influencing the time required, accuracy, and pilot workload associated with recognizing and reacting to potential collisions or conflicts with other aircraft, vehicles and obstructions during approach, landing, and surface operations. This work considers the effect of <b>head-down</b> <b>display</b> and head-up display implementations of SVS and EVS {{as well as the}} influence of single and dual pilot operations. The influences and strategies of adding traffic information and cockpit alerting with SVS and EVS were also included. Based on this review, a knowledge gap assessment was made with recommendations for ground and flight testing to fill these gaps and hence, promote the safe and effective implementation of SVS/EVS technologies for the Next Generation Air Transportation Syste...|$|E
40|$|A flight {{simulator}} experiment {{was conducted to}} explore the benefits of 3 -dimensional (3 -D) audio to support in-cockpit tasks regarding performance and workload. In half of the conditions, 1 or 2 tasks requiring information from a <b>head-down</b> <b>display</b> (HDD) were supported by 3 -D audio. The performance on several tasks improved when 3 -D audio was present, whereas no negative performance effects were found. Furthermore, the frequency of eye movements to the HDD was reduced more than 50 % in all 3 -D audio conditions. Physiological measures were not affected, indicating that mental effort was the same in all conditions. Only a small reduction in subjective workload in some 3 -D audio conditions was observed. Pilots were also able to process the information from 2 independent 3 -D auditory displays that were present at the same time. The results show that pilots can perform flight and in-cockpit tasks more efficiently when they are supported by 3 -D audio...|$|E
25|$|The Typhoon {{features}} a glass cockpit without any conventional instruments. It incorporates three full colour multi-function <b>head-down</b> <b>displays</b> (MHDDs) (the formats on which are manipulated {{by means of}} softkeys, XY cursor, and voice (Direct Voice Input or DVI) command), a wide angle head-up display (HUD) with forward-looking infrared (FLIR), a voice and hands-on throttle and stick (Voice+HOTAS), a Helmet Mounted Symbology System (HMSS), a Multifunctional Information Distribution System (MIDS), a manual data-entry facility (MDEF) located on the left glareshield and a fully integrated aircraft warning system with a dedicated warnings panel (DWP). Reversionary flying instruments, lit by LEDs, are located under a hinged right glareshield. Access to the cockpit is normally via either a telescopic integral ladder or an external version. The integral ladder is stowed in the port side of the fuselage, below the cockpit.|$|R
40|$|Human {{cognitive}} and physiological performance tends to enfeeble during time. Evidently a distinct attenuation of reaction-times spatial and situational awareness {{appears in the}} older segments of the driving population which increases rapidly in the western civilisation. Additionally, greater dependence on private automotive transportation and the unremitting raise of the elderly population, contributes to a significant increase of collision occurrences. To this end we have designed a prototype Head-Up-Display (HUD) interface which offers crucial information to the driver, in a timely manner. The interface comprises symbolic representation of the lead vehicles and road information acting as a vision enhancement system. The evaluation of the system contrasted the proposed HUD interface to the existing <b>Head-Down</b> <b>Displays</b> (HDD) offering encouraging results, with significantly decrease collision occurrences tested different accident scenarios. Our future tentative plan of work encompasses a highly customisable interface symbols and calibration which will encounter visual impairments of each driver...|$|R
40|$|Aircraft {{functional}} {{systems and}} crew systems were defined for a 1995 transport aircraft {{through a process}} of mission analysis, preliminary design, and evaluation in a soft mockup. This resulted in a revolutionary pilot's desk flight station design featuring an all-electric aircraft, fly-by-wire/light flight and thrust control systems, large electronic color <b>head-down</b> <b>displays,</b> head-up displays, touch panel controls for aircraft functional systems, voice command and response systems, and air traffic control systems projected for the 1990 s. The conceptual aircraft, for which crew systems were designed, is a generic twin-engine wide-body, low-wing transport, capable of worldwide operation. The flight control system consists of conventional surfaces (some employed in unique ways) and new surfaces not used on current transports. The design will be incorporated into flight simulation facilities at NASA-Langley, NASA-Ames, and the Lockheed-Georgia Company. When interfaced with advanced air traffic control system models, the facilities will provide full-mission capability for researching issues affecting transport aircraft flight stations and crews of the 1990 s...|$|R
