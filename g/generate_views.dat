25|1163|Public
40|$|Traditional VR methods {{allow the}} user to tour and view the virtual world from {{different}} perspectives. Increasingly, more interactive and adaptive worlds are being generated, potentially allowing {{the user to}} interact with and affect objects in the virtual world. We describe and compare four models of operation that allow the publisher to <b>generate</b> <b>views,</b> with the client manipulating and affecting specific objects in the world. We demonstrate these approaches through a problem in archaeological visualization...|$|E
40|$|Abstract — We {{propose a}} method for visual robot {{localization}} using a panoramic image volume as the representation from which we can <b>generate</b> <b>views</b> from virtual viewpoints and match them to the current view. We use a geometric imagebased rendering formalism in combination with a subspace representation of images, which allows us to synthesize views at arbitrary virtual viewpoints from a compact low-dimensional representation. Index Terms — visual localization, panoramic images, subspace representation, mobile robots I...|$|E
30|$|The {{remaining}} of {{the paper}} is structured as follows: Section 3 presents the moti- vation of our research based on the experience gained in the three modernization projects mentioned before. Section 4 elaborates on the MDE solution; i.e., the chain of model transformations to <b>generate</b> <b>views</b> for a particular source technology, and how the chain is parameterized with annotations. Section 5 presents an evaluation. Section 6 extends related work. Section 7 summarizes conclusions and perspectives for the future.|$|E
5000|$|... #Subtitle level 3: Self-censorship <b>generates</b> <b>view</b> {{from nowhere}} ...|$|R
5000|$|... #Caption: 3D {{computer}} <b>generated</b> <b>view</b> of the Me 261 {{from the}} top, front and left sides.|$|R
50|$|EPESI {{framework}} {{takes advantage}} of some third party libraries like database driver ADOdb or jQuery. The framework allows development of new modules, especially when utilizing Record Browser - a module that automatically <b>generates</b> <b>views,</b> limits queries, stores historical data, etc.|$|R
40|$|Abstract: We present Anagora, {{a graphic}} tool tracing {{discussion}} threads along a time axis. Anagora displays overlapping discussion threads over {{time on a}} single screen. Its special feature is to calculate the best resolution for a forum to fit on a screen by choosing the most appropriate time scale. Anagora is used to <b>generate</b> <b>views</b> of fora or forum thumbnails. Several discussion fora coming from e-learning platforms illustrate how Anagora is used by tutors and moderators to monitor students ’ collaborative work...|$|E
40|$|We {{present results}} {{on the design of}} a visual {{interaction}} environment for GISs based on focus+context visualisation and details-on-demand data presentation. We consider databases consisting of spatially related collections of regions with features, hierarchically organised as a nested partition. Interaction processes <b>generate</b> <b>views</b> on the database, displayed by maps preserving topological properties. An efficient navigation hence requires the adoption of topological invariants for representing such views. Since each step of the interaction process modifies only a portion of the invariant, we propose an efficient approach which dynamically updates the current topological invariant...|$|E
30|$|In Bertino et al. (2017) {{provenance}} {{techniques have}} been proposed to check {{the quality of the}} specified access control policies for a scenario where collaborations are carried out by autonomous cognitive devices. However, {{to the best of our}} knowledge, so far no proposal has yet targeted Big Data platforms. The model centric approach previously discussed may be exploited as a basis for the definition of such policy analysis framework. For instance, it may be used to <b>generate</b> <b>views</b> of the protected resources that show the authorized and unauthorized contents when different policies and configuration options are used, as well as to quantify policy coverage for a requesting subject with respect to an execution context.|$|E
40|$|Before {{heterogeneous}} devices {{will be able}} {{to access}} the same application, a mechanism for <b>generating</b> multiple <b>views</b> within a single model is needed. Current approaches for <b>generating</b> multiple <b>views</b> within a single model are greatly limited. By applying software stability concepts [10], this paper is able to propose a high-level architecture pattern, Stable Model-View-Mapping (MVM), as a novel approach for <b>generating</b> multiple <b>views</b> from multiple models and vise versa. The proposed architecture confronts the limitations of current approaches and considers the mapping when designing the solution...|$|R
5000|$|... #Caption: Computer <b>generated</b> aerial <b>view</b> of the {{arrondissement}} ...|$|R
5000|$|... #Caption: The Lingan <b>Generating</b> Station <b>viewed</b> {{from the}} north.|$|R
40|$|Imagination {{or mental}} imagery is the {{capability}} of generating sensory experiences without actual sensory inflow. These sen-sory experiences might be the results of actions that are not carried out physically but only simulated within the cognitive system of an agent. We propose a model architecture for men-tal imagery that enables an artificial agent to <b>generate</b> <b>views</b> of parts of himself based {{on a set of}} given pose parameters and according to a specific viewing direction. The architecture is evaluated in a robotic study with an agent consisting of a robotic manipulator and a camera head. The agent adaptively learns to associate views of its gripper with its current pose. Furthermore, a visual forward model predicts visual changes according to the agent’s gaze direction...|$|E
40|$|Photorealistic {{rendering}} {{is used to}} <b>generate</b> <b>views</b> {{of computer}} stored scenes. Global illumination algorithms take all transfers {{of light in the}} scene into account thereby creating a realistic looking image. Previously several approaches have been presented which are able to deal with global illumination for diffuse surfaces. More general surfaces are handled only by few methods. This work presents a new algorithm for the generation of photorealistic images for scenes with arbitrary surfaces. Initially particle tracing and a reconstruction phase are used to obtain a good approximation to the directionally dependent illumination in the scene. The illumination information is stored and can be used subsequently to generate images from different viewpoints directly from the stored solution. The whole system is structured into several independent phases and is designed to allow parallel processing and incremental refinement. 1 Introduction and Background This paper presents a new method fo [...] ...|$|E
40|$|One of {{the major}} uses of the {{ontology}} IS to support interoperation of information systems which that ontology is a result ofInterlocking Institutional Worlds (IWs). In this context, typically, application development in collaborative setting requires users to commit particular applications to an ontology. In such environment, the user employs an ontology server to identify ontology objects the user considers essential to commit the application. Since there are many users, therefore their different perspectives will require server to <b>generate</b> <b>views</b> on the ontologies. The ontology views are fairly established in ontology modularization research but {{in the context of}} IWs we argue that the problems may be distinct. Therefore, this paper is to define several ontology views problems and subsequently propose some sort of requirements for ontology views with respect to IWs. Furthermore, we discuss our analysis in the sense of ontology modularization approaches and argue that our problems make differences thus require another new approach to solve it...|$|E
5000|$|... #Caption: The Trenton <b>Generating</b> Station <b>viewed</b> {{from the}} east.|$|R
5000|$|... #Caption: Beesley's Point <b>Generating</b> Station <b>viewed</b> {{from the}} east.|$|R
5000|$|... #Caption: Brandon Shores <b>Generating</b> Station <b>viewed</b> {{from the}} south ...|$|R
40|$|The {{necessary}} and sufficient conditions {{for being able}} to estimate scene structure, motion and camera calibration from a sequence of images are very rarely satisfied in practice. What exactly can be estimated in sequences of practical importance, when such conditions are not satisfied? In this paper we give a complete answer to this question. For every camera motion that fails to meet the conditions, we give explicit formulas for the ambiguities in the reconstructed scene, motion and calibration. Such a characterization is crucial both for designing robust estimation algorithms (that do not try to recover parameters that cannot be recovered), and for generating novel views of the scene by controlling the vantage point. To this end, we characterize explicitly all the vantage points that give rise to a valid Euclidean reprojection regardless of the ambiguity in the reconstruction. We also characterize vantage points that <b>generate</b> <b>views</b> that are altogether invariant to the ambiguity. All [...] ...|$|E
30|$|Several {{of these}} {{approaches}} (except by VizDSL, Modigen, EuGENia, Moose, and GRAPH) create views for a restricted number of technologies and languages; e.g., Smalltalk, Java, C++ and ADA. In the same way, the views are predefined {{and it is not}} possible to easily define new ones. CodeCity and eCity+ <b>generate</b> <b>views</b> whose notation is based on the city metaphor: the neighborhoods represent packages and the buildings represent classes. In the case of SAABs, UML classes diagrams are obtained. In Softwarenaut, module views and their dependencies are obtained. Fi- nally, AIVA produces components and classes views. In contrast, our approximation is open from the technology point of view for several reasons. Firstly, according to the working technology, it allows new parsers to be plugged to the rest of infrastruc- ture. Secondly, it allows the definition of new views with the relevant architectural elements for the developer. Thirdly, it gives freedom to define the used notation instead of using something fixed such as UML (Snajberk et al. 2012) because not all the technologies obey the object oriented programming paradigm.|$|E
40|$|Abstract [...] In this paper, we {{introduce}} a novel method for employing image-based rendering {{to extend the}} range of use of human motion recognition systems. We demonstrate the use of image-based rendering to generate additional training sets for view-dependent human motion recognition systems. Input views orthogonal to the direction of motion are created automatically to construct the proper view {{from a combination of}} non-orthogonal views taken from several cameras. To extend motion recognition systems, image-based rendering can be utilized in two ways: (i) to generate additional training sets for these systems containing a large number of nonorthogonal views, and (ii) to generate orthogonal views (the views those systems are trained to recognize) from a combination of non-orthogonal views taken from several cameras. In this case, image-based rendering is used to <b>generate</b> <b>views</b> orthogonal to the mean direction of motion. We tested the method using an existing viewdependent human motion recognition system on two different sequences of motion, and promising initial results were obtained. Index Terms—image-based rendering, human motion recognition, computer vision, visual tracking, shape reconstruction. I...|$|E
5000|$|... #Caption: The Annapolis Royal <b>Generating</b> Station <b>viewed</b> at high tide.|$|R
5000|$|... #Caption: The Point Tupper <b>Generating</b> Station <b>viewed</b> {{from the}} north.|$|R
5000|$|... #Caption: The Tufts Cove <b>Generating</b> Station <b>viewed</b> {{from the}} west.|$|R
40|$|Abstract. The {{necessary}} and sufficient conditions {{for being able}} to estimate scene structure, motion and camera calibration from a sequence of images are very rarely satisfied in practice. What exactly can be estimated in sequences of practical importance, when such conditions are not satisfied? In this paper we give a complete answer to this question. For every camera motion that fails to meet the conditions, we give explicit formulas for the ambiguities in the reconstructed scene, motion and calibration. Such a characterization is crucial both for designing robust estimation algorithms (that do not try to recover parameters that cannot be recovered), and for generating novel views of the scene by controlling the vantage point. To this end, we characterize explicitly all the vantage points that give rise to a valid Euclidean reprojection regardless of the ambiguity in the reconstruction. We also characterize vantage points that <b>generate</b> <b>views</b> that are altogether invariant to the ambiguity. All the results are presented using simple notation that involves no tensors nor complex projective geometry, and should be accessible with basic background in linear algebra...|$|E
40|$|The {{evolution}} of complex software systems is promoted by software engineering principles and techniques like separation of concerns, encapsulation, stepwise refinement, and reusability of design solutions. Design patterns capture the expertise for reusable design solutions. Aspect-oriented programming is a methodology {{that enables the}} modularization of cross-cutting concerns. Traceability links designate dependencies between requirements, design, and source code. In order to support maintenance, documentation has to enable understandability by describing these issues. Descriptions have to facilitate tool support for automating documentation activities. In this paper, we use the notion of patterns, aspects and traces for a homogeneous documentation approach. We integrate various types of documentation, keep track of traces from requirements to the source code, keep design information in the source code, and generate additional design views on software systems. We have implemented these ideas as an extension to javadoc, the documentation approach used by Java. This extension {{can be used to}} automatically <b>generate</b> <b>views</b> on the design and on aspects as well as on traceability links as part of the standard javadoc system documentation...|$|E
30|$|The {{advanced}} 3 D video (3 DV) {{systems are}} mostly based on multi-view video plus depth (MVD) format [1] as the recommended 3 D video format {{adopted by the}} moving picture experts group (MPEG). In the 3 DV system, smaller number of captured views is transmitted and greater number of views is generated at the receiver side from the transmitted texture views and their associated depth maps using depth-image-based rendering (DIBR) technology. DIBR techniques {{can be used to}} <b>generate</b> <b>views</b> for different 3 D video applications: free viewpoint television, 3 DTV, 3 D technology based entertainment products, and 3 D medical applications. The perceptual quality of the synthesized view is considered as the most significant evaluation criterion for the whole 3 D video processing system. Reliable quality assessment metric for synthesized views is of a great importance for the 3 D video technology development. The use of subjective tests is expensive, time consuming, cumbersome, and practically no feasable in systems where real-time quality score of an image or video sequence is needed. Objective metrics are intended to predict human judgment. The reliability of objective metrics is based on their correlation to subjective assessment results.|$|E
5000|$|The Download to Donate widget <b>generated</b> 9.7M <b>views</b> and 1.75M plays ...|$|R
5000|$|... #Caption: Part of the Kintigh <b>Generating</b> Station, <b>viewed</b> {{from the}} west.|$|R
50|$|In the Rfam {{database}} {{a single}} covariation model (AHBV_epsilon box right) best discriminates between the true instances of the element in sequence databases and background. The secondary structure diagram {{is a computer}} <b>generated</b> <b>view</b> of the structure with highly conserved bases shown in red. It includes the major elements shown in Figures 1 and 2.|$|R
40|$|Teachers {{have been}} ‘visualising’ ideas or {{information}} {{that emerge from}} data for a long time. Mark books have provided teachers with ‘visual’, albeit normally numerical, records of pupil attainment and achievement, which they have used to <b>generate</b> <b>views</b> about progress, trends, or the identification of appropriate learning support, for example. The advent of {{information and communication technologies}} (ICT) has brought potential to provide perspectives from data in more visual forms; these visual forms would previously have taken a long time to generate, and would have been unlikely to have been dynamic (that is, updated with regularly changing background data, to offer up-to-date pictures). What differences have been made {{as a result of this}} potential? Has it meant that ‘visualisation’ of forms of presentation have changed, that forms of analyses have been introduced, that reliability and robustness have been more focused on, or that different types of needs have arisen? This paper will explore evolving visualisations of curriculum data, and will conclude that different forms of visualisation are being introduced, but do not necessarily make it easier for the teacher to identify necessary or precise detail (or to consider fundamental statistical questions or specific professional needs) ...|$|E
40|$|AbstractThe Gene Ontology (GO) {{project is}} a {{collaborative}} effort to construct ontologies which facilitate biologically meaningful annotation of gene products. In some situations, only a generic or a species-specific subset of all GO terms is required to annotate and analyze {{the results of a}} particular biomedical experiment. We show that by defining explicit links between terms in the GO and terms in the Taxonomy of Species (TS) it is possible to automatically create partitions of the GO according to various taxonomic criteria. Our framework is based on three logically defined relations—validity, specificity, and relevance—used to link terms in the Gene Ontology with terms in the Taxonomy. The major advantages of this approach, as compared to the traditional GO slims methodology, are: unambiguous semantics of GO–TS annotations, significant reduction of the effort needed to manually select GO terms appropriate for a particular taxonomic context, ability to <b>generate</b> <b>views</b> of the GO even for taxa for which no explicit links with GO terms exist, logical consistency of such views, and automated updates of TS-dependent GO subsets. Incorporation of the proposed framework into the GO may improve the usability of the ontology for those scientists who focus their research on a particular species or a specific class of organisms...|$|E
40|$|Abstract: Teachers of {{networked}} collaborative classrooms, {{with multiple}} groups interacting in parallel, need assistance for better understanding and regulating the learning process. They may use tools that collect and process students ’ activity data, and <b>generate</b> <b>views</b> of students ’ activities. Classroom management tools {{may be used}} to observe and control students ’ screens, but often fail to exploit interaction data. We present the results of a study where teachers used a classroom management environment to monitor students ’ collaborative activities, and a discussion of the alternative views provided by a cscl tool, designed for teacher’s support. Monitoring Groups ’ Collaborative activities: A task for the teacher In CSCL research community there is an increasing interest in the design of tools that support students ’ computer mediated collaborative learning. Tool designers build tools for students and teachers; however they seem to pay more attention on students ’ needs than on teachers ’ (Dimitracopoulou 2005). Examples of teacher tools include Prof-CHENE with a communication space for the teacher, that was used to investigate, the nature of knowledge of teachers on students collaborative problem solving (Baker et al 2001). González and Suthers (2002) have proposed a pedagogical agent that helps students collaborate while solving Entity Relationship modeling problems in COLER. The generated advice, during online intervention, was based primaril...|$|E
5000|$|... #Caption: Clipped view of Tetrahedral mesh; <b>generated</b> and <b>viewed</b> in Gmsh 2.3.1 ...|$|R
5000|$|... #Caption: Computer <b>generated</b> {{perspective}} <b>view</b> of pancake domes in Venus's Alpha Regio ...|$|R
40|$|The Mining Mart project (Enabling End-User Data Warehouse Mining) {{proposes a}} case-based {{reasoning}} system for maximum support of end users during data preprocessing. Our approach 1) uses a case base for efficient support for data preprocessing, respectively the persistent storage of cases as metadata, 2) machine learning tools for preprocessing, and 3) <b>generates</b> <b>views</b> as results of preprocessing operators...|$|R
