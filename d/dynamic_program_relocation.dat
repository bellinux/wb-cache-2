0|10000|Public
40|$|What is <b>dynamic</b> <b>programming?</b> This {{paper is}} {{concerned}} with the class of all dynamic programmings - with or without optimization. Where is an origin in the class? What is it? The paper is a travel which leads to the origin. We present a primitive form of <b>dynamic</b> <b>programming.</b> It is a non-deterministic <b>dynamic</b> <b>programming,</b> which generates stochastic <b>dynamic</b> <b>programming,</b> which in turn reduces to deterministic <b>dynamic</b> <b>programming.</b> Thus we propose the nondeterministic <b>dynamic</b> <b>programming</b> as a primitive <b>dynamic</b> <b>programming...</b>|$|R
40|$|An {{efficient}} {{numerical solution}} scheme entitled adaptive differential <b>dynamic</b> <b>programming</b> is developed {{in this paper}} for multiobjective optimal control problems with a general separable structure. For a multiobjective control problem with a general separable structure, the "optimal" weighting coefficients for various performance indices are time-varying as the system evolves along any noninferior trajectory. Recognizing this prominent feature in multiobjective control, the proposed adaptive differential <b>dynamic</b> <b>programming</b> methodology combines a search process to identify an optimal time-varying weighting sequence with the solution concept in the conventional differential <b>dynamic</b> <b>programming.</b> Convergence of the proposed adaptive differential <b>dynamic</b> <b>programming</b> methodology is addressed. Key Words: Multiobjective optimal control, <b>dynamic</b> <b>programming,</b> multiobjective <b>dynamic</b> <b>programming,</b> differential <b>dynamic</b> <b>programming,</b> adaptive differential <b>dynamic</b> <b>programming.</b> Department of Mathem [...] ...|$|R
40|$|New cache-oblivious and cache-aware {{algorithms}} {{for simple}} <b>dynamic</b> <b>programming</b> based on Valiant’s context-free language recognition algorithm are designed, implemented, analyzed, and empirically evaluated with timing studies and cache simulations. The {{studies show that}} for large inputs the cache-oblivious and cache-aware <b>dynamic</b> <b>programming</b> algorithms are significantly faster than the standard <b>dynamic</b> <b>programming</b> algorithm. Keywords: <b>Dynamic</b> <b>Programming,</b> Cache-Oblivious Algorithms, Cache-Aware Algorithms...|$|R
40|$|<b>Dynamic</b> <b>programming</b> is a {{powerful}} technique for solving optimization problems efficiently. We consider a <b>dynamic</b> <b>program</b> as simply a recursive program that is evaluated with memoization and lookup of answers. In this paper we examine how, given a function calculating a bound {{on the value of}} the <b>dynamic</b> <b>program,</b> we can optimize the compilation of the <b>dynamic</b> <b>program</b> function. We show how to automatically transform a <b>dynamic</b> <b>program</b> to a number of more efficient versions making use of the bounds function. We compare the different transformed versions on a number of example <b>dynamic</b> <b>programs,</b> and show the benefits in search space and time that can result...|$|R
5000|$|<b>Dynamic</b> <b>programming</b> is {{used when}} we compute the maximum-weight {{independent}} set for each [...] This <b>dynamic</b> <b>program</b> works because each [...] is a -outerplanar graph. Many NP-complete {{problems can be}} solved with <b>dynamic</b> <b>programming</b> on -outerplanar graphs.|$|R
40|$|Dynamic] {{also has}} a very {{interesting}} property as an adjective, and that is its impossible to use the word, dynamic, in a pejorative sense. Try thinking of some combination that will possibly give it a pejorative meaning. Its impossible. Thus, I thought <b>dynamic</b> <b>programming</b> was a good name. ”-Richard Bellman Most of our applications of optimal control involved choosing something {{as a function of}} time. <b>Dynamic</b> <b>programming</b> is another approach to solving optimization problems that involve time. <b>Dynamic</b> <b>programming</b> can be especially useful for problems that in-volve uncertainty. <b>Dynamic</b> <b>programming</b> has the advantage that it lets us focus on one period at a time, which can often be easier to think about than the whole sequence. Be-cause it only requires maximizing over a few variables at a time, <b>dynamic</b> <b>programming</b> can be a much more efficient way to calculate solutions. The computational advantage of <b>dynamic</b> <b>programming</b> is especially pronounced when some of the variables being max-imized over are discrete. 1. REFERENCES These notes are about <b>dynamic</b> <b>programming.</b> References from our text books are chap-ter 11 of Dixit (1990). Adda and Cooper (2003) is very nice and available online from UBC library. Stokey, Lucas Jr, and Prescott (1989) is the classic economics reference for <b>dynamic</b> <b>programming,</b> but is more advanced than what we will cover. Applied <b>dynamic</b> <b>programming</b> by Bellman and Dreyfus (1962) and <b>Dynamic</b> <b>programming</b> and the calculus of variations by Dreyfus (1965) provide a good introduction to the main idea of <b>dynamic</b> <b>programming,</b> and are especially useful for contrasting the dynamic pro-gramming and optimal control approaches. Dreyfus (2002) has some amusing anecdotes from Bellman about the initial development of <b>dynamic</b> <b>programming.</b> Bertsekas (1976) is the classic reference for <b>dynamic</b> <b>programming</b> with uncertainty. 1 DYNAMIC PROGRAMMIN...|$|R
40|$|Although <b>dynamic</b> <b>programming</b> could ideally solve any {{combinatorial}} optimization problem, {{the curse of}} dimensionality of the search space seriously limits its application to large optimization problems. For example, only few papers in the literature have reported the application of <b>dynamic</b> <b>programming</b> to workforce scheduling problems. This paper investigates approximate <b>dynamic</b> <b>programming</b> to tackle nurse scheduling problems of size that <b>dynamic</b> <b>programming</b> cannot tackle in practice. Nurse scheduling {{is one of the}} problems within workforce scheduling that has been tackled with a considerable number of algorithms particularly meta-heuristics. Experimental results indicate that approximate <b>dynamic</b> <b>programming</b> is a suitable method to solve this problem effectively...|$|R
40|$|The network revenue {{management}} (RM) problem arises in airline, hotel, media, and other industries where the sale products use multiple resources. It can be formulated as a stochastic <b>dynamic</b> <b>program</b> but the <b>dynamic</b> <b>program</b> is computationally intractable {{because of an}} exponentially large state space, {{and a number of}} heuristics have been proposed to approximate it. Notable amongst these -both for their revenue performance, as well as their theoretically sound basis- are approximate <b>dynamic</b> <b>programming</b> methods that approximate the value function by basis functions (both affine functions as well as piecewise-linear functions have been proposed for network RM) and decomposition methods that relax the constraints of the <b>dynamic</b> <b>program</b> to solve simpler <b>dynamic</b> <b>programs</b> (such as the Lagrangian relaxation methods). In this paper we show that these two seemingly distinct approaches coincide for the network RM <b>dynamic</b> <b>program,</b> i. e., the piecewise-linear approximation method and the Lagrangian relaxation method are one and the same. network {{revenue management}}, linear <b>programming,</b> approximate <b>dynamic</b> <b>programming,</b> Lagrangian relaxation methods...|$|R
40|$|This paper reviews {{a variety}} of ways to use {{trajectory}} optimization to accelerate <b>dynamic</b> <b>programming.</b> <b>Dynamic</b> <b>programming</b> provides a way to design globally optimal control laws for nonlinear systems. However, the curse of dimensionality, the exponential dependence of space and computation resources needed on the dimensionality of the state and control, limits the application of <b>dynamic</b> <b>programming</b> in practice. We explore trajectory-based <b>dynamic</b> <b>programming,</b> which combines many local optimizations to accelerate the global optimization of dynamic programmin...|$|R
40|$|International audienceDynamic {{programming}} {{is a powerful}} technique for solving optimization problems efficiently. We consider a <b>dynamic</b> <b>program</b> as simply a recursive program that is evaluated with memoization and lookup of answers. In this paper we examine how, given a function calculating a bound {{on the value of}} the <b>dynamic</b> <b>program,</b> we can optimize the compilation of the <b>dynamic</b> <b>program</b> function. We show how to automatically transform a <b>dynamic</b> <b>program</b> to a number of more efficient versions making use of the bounds function. We compare the different transformed versions on a number of example <b>dynamic</b> <b>programs,</b> and show the benefits in search space and time that can result...|$|R
40|$|We {{propose a}} <b>dynamic</b> <b>program</b> {{to find the}} {{shortest}} path in a network having gamma probability distributions as arc lengths. Two operators of sum and comparison need to be adapted for the proposed <b>dynamic</b> <b>program.</b> Convolution approach is used to sum two gamma probability distributions being employed in the <b>dynamic</b> <b>program...</b>|$|R
40|$|The generic <b>dynamic</b> <b>programming</b> {{problem is}} given {{by a set of}} (<b>dynamic</b> <b>programming)</b> {{recurrence}} equations. It is an important problem with several applications, such as chain matrix multiplication, optimal binary search trees and polygon triangulation, see [9], [2]. The problem we address in this paper {{is given by}} <b>dynamic</b> <b>programming</b> recurrences...|$|R
40|$|International audienceNew cache-oblivious and cache-aware {{algorithms}} {{for simple}} <b>dynamic</b> <b>programming</b> based on Valiant's context-free language recognition algorithm are designed, implemented, analyzed, and empirically evaluated with timing studies and cache simulations. The {{studies show that}} for large inputs the cache-oblivious and cache-aware <b>dynamic</b> <b>programming</b> algorithms are significantly faster than the standard <b>dynamic</b> <b>programming</b> algorithm...|$|R
40|$|For countable-state {{decision}} processes (<b>dynamic</b> <b>programming</b> problems), {{a general}} class of objective functions is identified {{for which it}} is shown that good Markov strategies always exist. This class includes product and lim inf rewards, as well as practically all the classical <b>dynamic</b> <b>programming</b> expected payoff functions. <b>dynamic</b> <b>programming</b> Markov decision process Markov strategy...|$|R
40|$|<b>Dynamic</b> <b>programming</b> (DP) is a {{recursive}} optimization {{approach to}} solving a sequential decision problems. <b>Dynamic</b> <b>Programming</b> {{has much to}} offer to problems requiring a sequence of related decisions. Many applications of <b>dynamic</b> <b>programming</b> reduce to finding the shortest or longest path. Moreover, unlike the transportation algorithm that presumes a standard structure, D...|$|R
40|$|Markov {{decision}} processes (MDPs) are {{a general}} framework used in artificial intelligence (AI) to model decision theoretic planning problems. Solving real world MDPs {{has been a}} major and challenging research topic in the AI literature, since classical <b>dynamic</b> <b>programming</b> algorithms converge slowly. We discuss two approaches in expediting <b>dynamic</b> <b>programming.</b> The first approach combines heuristic search strategies with <b>dynamic</b> <b>programming</b> to expedite the convergence process. The second makes use of graphical structures in MDPs to perform <b>dynamic</b> <b>programming</b> in a better order...|$|R
40|$|Determining {{the optimal}} {{coalition}} structure {{is a central}} problem in multi-agent systems. Two popular techniques include <b>dynamic</b> <b>programming</b> and anytime search algorithms. <b>Dynamic</b> <b>programming</b> algorithms guarantee an optimal solution and have the best worst case running time. Anytime algorithms are flexible as they can terminate before the search has completed, but have a significantly poorer worst case runtime. This paper provides an anytime <b>dynamic</b> <b>programming</b> algorithm with the worst case runtime of <b>dynamic</b> <b>programming</b> and the flexibility of anytime search...|$|R
40|$|In (1998), Kovalyov and Kubiak {{studied the}} problem of {{scheduling}} deteriorating jobs on a single machine to minimize makespan. They presented a fully polynomial-time approximation scheme {{which is based on}} a <b>dynamic</b> <b>programming.</b> Unfortunately, their <b>dynamic</b> <b>programming</b> is incorrect. So the fully polynomial-time approximation scheme is also invalid. In this paper, we construct an instance to show how their <b>dynamic</b> <b>programming</b> does not work and provide a correct <b>dynamic</b> <b>programming,</b> based on which a new fully polynomial-time approximation scheme is derived...|$|R
40|$|Ambiguity in <b>dynamic</b> <b>programming</b> {{arises from}} two {{independent}} sources, the non-uniqueness of optimal solutions {{and the particular}} recursion scheme by which the search space is evaluated. Ambiguity, unless explicitly considered, leads to unnecessarily complicated, inflexible, and sometimes even incorrect <b>dynamic</b> <b>programming</b> algorithms. Building upon the recently developed algebraic approach to <b>dynamic</b> <b>programming,</b> we formalize the notions of ambiguity and canonicity. We argue {{that the use of}} canonical yield grammars leads to transparent and versatile <b>dynamic</b> <b>programming</b> algorithms. They provide a master copy of recurrences, that can solve all DP problems in a well-defined domain. We demonstrate the advantages of such a systematic approach using problems from the areas of RNA folding and pairwise sequence comparison. 1 Motivation and Overview 1. 1 Ambiguity Issues in <b>Dynamic</b> <b>Programming</b> <b>Dynamic</b> <b>Programming</b> (DP) solves combinatorial optimization problems. It is a classical p [...] ...|$|R
2500|$|To derive a <b>dynamic</b> <b>programming</b> {{functional}} equation for this puzzle, let {{the state of}} the <b>dynamic</b> <b>programming</b> model be a pair s = (n,k), where ...|$|R
25|$|When {{a problem}} shows optimal {{substructures}} – meaning the optimal {{solution to a}} problem can be constructed from optimal solutions to subproblems – and overlapping subproblems, meaning the same subproblems are used to solve many different problem instances, a quicker approach called <b>dynamic</b> <b>programming</b> avoids recomputing solutions that have already been computed. For example, Floyd–Warshall algorithm, the shortest path to a goal from a vertex in a weighted graph can be found by using the shortest path to the goal from all adjacent vertices. <b>Dynamic</b> <b>programming</b> and memoization go together. The main difference between <b>dynamic</b> <b>programming</b> and divide and conquer is that subproblems are more or less independent in divide and conquer, whereas subproblems overlap in <b>dynamic</b> <b>programming.</b> The difference between <b>dynamic</b> <b>programming</b> and straightforward recursion is in caching or memoization of recursive calls. When subproblems are independent and there is no repetition, memoization does not help; hence <b>dynamic</b> <b>programming</b> is not a solution for all complex problems. By using memoization or maintaining a table of subproblems already solved, <b>dynamic</b> <b>programming</b> reduces the exponential nature of many problems to polynomial complexity.|$|R
40|$|The <b>Dynamic</b> <b>Programming</b> {{algorithm}} {{proposed by}} Rosenblatt and Kaspi (Rosenblatt, M. J., M. Kaspi. 1985. A <b>dynamic</b> <b>programming</b> algorithm for joint replenishment under general order cost functions. Management Sci. 31 (March) 369 [...] 373.) for an optimum partition problem {{is shown to}} be incorrect. An alternative <b>Dynamic</b> <b>Programming</b> algorithm is presented for this problem. ...|$|R
40|$|<b>Dynamic</b> <b>programming</b> {{approach}} {{offers an}} exact solution to solving complex reservoir operational problems. In this research analysis, an {{attempt was made}} to evaluate the relevance of <b>dynamic</b> <b>programming</b> as an optimization tool. A brief overview including the characteristics, advantages and disadvantages of <b>dynamic</b> <b>programming</b> model was understudied. The focus was on the application of <b>dynamic</b> <b>programming</b> to handling the optimal allocation of the available water resources. Cases of large scale reservoir expansion problems were also considered and finally the optimal release policy for reservoir operations. The end result of the model formulation reveals the applicability of <b>dynamic</b> <b>programming</b> in resolving long time operational, water allocation and expansion problems in reservoir dynamics, operations and maintenance...|$|R
2500|$|... nonnegative integers, the {{knapsack}} {{problem can be}} solved in pseudo-polynomial time using <b>dynamic</b> <b>programming.</b> The following describes a <b>dynamic</b> <b>programming</b> solution for the unbounded {{knapsack problem}}.|$|R
40|$|Abstract — Modeling {{error is}} a common problem for modelbased control techniques. We present {{multiple}} model <b>dynamic</b> <b>programming</b> (MMDP) as a method to generate controllers that are robust to modeling error. Our method generates controllers that are approximately optimal for a collection of models, thereby forcing the controller to be less model-dependent. We compare MMDP to stochastic <b>dynamic</b> <b>programming,</b> minimax <b>dynamic</b> <b>programming,</b> and a baseline implementation of <b>dynamic</b> <b>programming</b> on the test problem of pendulum swing-up. We simulate modeling error by varying model parameters. I...|$|R
40|$|Introduction to <b>Dynamic</b> <b>Programming</b> {{provides}} information {{pertinent to the}} fundamental aspects of <b>dynamic</b> <b>programming.</b> This book considers problems that can be quantitatively formulated and deals with mathematical models of situations or phenomena {{that exists in the}} real world. Organized into 10 chapters, this book begins with an overview of the fundamental components of any mathematical optimization model. This text then presents the details of the application of <b>dynamic</b> <b>programming</b> to variational problems. Other chapters consider the application of <b>dynamic</b> <b>programming</b> to inventory theory, Mar...|$|R
40|$|We {{introduce}} a rapid grid search method {{in solving the}} <b>dynamic</b> <b>programming</b> problems in economics. Compared to mainstream grid search methods, by using local information of the Bellman equation, this method can significantly increase the efficiency in solving <b>dynamic</b> <b>programming</b> problems by reducing the grid points searched in the control space. <b>Dynamic</b> <b>Programming,</b> Grid Search, Control Space...|$|R
40|$|This work {{deals with}} {{building}} a program system for solving <b>dynamic</b> <b>programming</b> problems on a computer. The theoretical part describes <b>dynamic</b> <b>programming</b> {{as a tool}} used for optimizing multistage decision processes and <b>dynamic</b> <b>programming</b> problems implemented in the program system. The practical part describes the design {{and implementation of the}} program system and verification of its functionality...|$|R
40|$|We {{introduce}} {{an extension}} of Dual <b>Dynamic</b> <b>Programming</b> (DDP) to solve convex nonlinear <b>dynamic</b> <b>programming</b> equations. We call Inexact DDP (IDDP) this extension which applies to situations where some or all primal and dual subproblems to be solved along the iterations of the method are solved with a bounded error. We show that any accumulation point of the sequence of decisions is an approximate solution to the <b>dynamic</b> <b>programming</b> equations. When these errors tend to zero {{as the number of}} iterations goes to infinity, we show that IDDP solves the <b>dynamic</b> <b>programming</b> equations. We extend the analysis to stochastic convex nonlinear <b>dynamic</b> <b>programming</b> equations, introducing Inexact Stochastic Dual <b>Dynamic</b> <b>Programming</b> (ISDDP), an inexact variant of SDDP corresponding to the situation where some or all problems to be solved in the forward and backward passes of SDDP are solved approximately. We also show the almost sure convergence of ISDDP for vanishing errors...|$|R
40|$|Recently, {{optimization}} {{techniques have}} been applied {{to the problem of}} minimizing pressure transients in a pipeline created by valve operation. One such technique is <b>dynamic</b> <b>programming,</b> and a computer program incorporating the method of characteristics and a <b>dynamic</b> <b>programming</b> scheme has been used to calculate the pressure changes at a valve at the downstream end of a series pipeline and to select a valve operating policy which minimizes those pressure changes. The series pipeline either increases or decreases in diameter at an arbitrary location along the pipeline. The valve closure policy determined by <b>dynamic</b> <b>programming</b> creates less severe transients at the valve than a linear policy. A valve opening policy specified by <b>dynamic</b> <b>programming</b> does not offer significant advantages over a linear policy. The <b>dynamic</b> <b>programming</b> scheme allows convenient manipulation of system characteristics, and the policies selected by <b>dynamic</b> <b>programming</b> promise to be applicable to real systems...|$|R
40|$|Abstract—Dynamic {{programming}} is a recursive approach to solving optimization problems. It works by finding solutions to subproblems and combining those solutions. By storing solutions to solved problems, <b>dynamic</b> <b>programming</b> {{can be particularly}} efficient. In this paper we will discuss an approach to solving optimization problems based on specialization of an abstract <b>dynamic</b> <b>programming</b> algorithm. This provides not only reuse of the algorithm, but also reuse of its proof. Application of <b>dynamic</b> <b>programming</b> includes Matrix chain multiplication and Largest black square. Index Terms—formal methods, <b>dynamic</b> <b>programming,</b> divide and conquer, predicative style I...|$|R
40|$|In this paper, we analyze <b>dynamic</b> <b>programming</b> as a novel {{approach}} {{to solve the problem}} of maximizing the profits of a bank. The mathematical model of the problem and the description of a bank's work is described in this paper. The problem is then approached using the method of <b>dynamic</b> <b>programming.</b> <b>Dynamic</b> <b>programming</b> makes sure that the solutions obtained are globally optimal and numerically stable. The optimization process is set up as a discrete multi-stage decision process and solved with the help of <b>dynamic</b> <b>programming.</b> Comment: 8 page...|$|R
5000|$|If all weights (...) arenonnegative integers, the {{knapsack}} {{problem can be}} solved in pseudo-polynomial time using <b>dynamic</b> <b>programming.</b> The following describes a <b>dynamic</b> <b>programming</b> solution for the unbounded {{knapsack problem}}.|$|R
40|$|In (Stochastic Process. Appl. 103 (2003) 293), {{a pair of}} <b>dynamic</b> <b>programming</b> inequalities {{were derived}} for the 'separated' ergodic control problem for {{partially}} observed Markov processes, using the 'vanishing discount' argument. In this note, we strengthen these results to derive a single <b>dynamic</b> <b>programming</b> equation for the same. Controlled Markov processes <b>Dynamic</b> <b>programming</b> Partial observations Ergodic cost Vanishing discount Pseudo-atom...|$|R
50|$|Originally {{introduced}} by Richard E. Bellman in , stochastic <b>dynamic</b> <b>programming</b> {{is a technique}} for modelling and solving problems of decision making under uncertainty. Closely related to stochastic <b>programming</b> and <b>dynamic</b> <b>programming,</b> stochastic <b>dynamic</b> <b>programming</b> represents the problem under scrutiny {{in the form of}} a Bellman equation. The aim is to compute a policy prescribing how to act optimally in the face of uncertainty.|$|R
50|$|From a <b>dynamic</b> <b>programming</b> {{point of}} view, Dijkstra's {{algorithm}} is a successive approximation scheme that solves the <b>dynamic</b> <b>programming</b> functional equation for the shortest path problem by the Reaching method.|$|R
