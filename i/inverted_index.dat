477|268|Public
25|$|When a {{full text}} query is {{received}} by the SQL Server query processor, it is {{handed over to the}} FTS query processor in the Search process. The FTS query processor breaks up the query into the constituent words, filters out the noise words, and uses an inbuilt thesaurus to find out the linguistic variants for each word. The words are then queried against the <b>inverted</b> <b>index</b> and a rank of their accurateness is computed. The results are returned to the client via the SQL Server process.|$|E
25|$|The Full Text Search {{engine is}} divided into two {{processes}}: the Filter Daemon process (msftefd.exe) and the Search process (msftesql.exe). These processes interact with the SQL Server. The Search process includes the indexer (that creates the full text indexes) and the full text query processor. The indexer scans through text columns in the database. It can also index through binary columns, and use iFilters to extract meaningful text from the binary blob (for example, when a Microsoft Word document is stored as an unstructured binary file in a database). The iFilters are hosted by the Filter Daemon process. Once the text is extracted, the Filter Daemon process breaks it up into a sequence of words and hands it over to the indexer. The indexer filters out noise words, i.e., words like A, And etc., which occur frequently and are not useful for search. With the remaining words, an <b>inverted</b> <b>index</b> is created, associating each word with the columns they were found in. SQL Server itself includes a Gatherer component that monitors changes to tables and invokes the indexer in case of updates.|$|E
50|$|With the <b>inverted</b> <b>index</b> created, {{the query}} {{can now be}} {{resolved}} by jumping to the word ID (via random access) in the <b>inverted</b> <b>index.</b>|$|E
40|$|Bitmap indexes {{are widely}} used in Decision Support Systems (DSSs) to improve query performance. In this paper, we {{evaluate}} the use of compressed <b>inverted</b> <b>indexes</b> with adapted query processing strategies from Information Retrieval as an alternative. In a thorough experimental evaluation on both synthetic data and data from the Star Schema Benchmark, we show that <b>inverted</b> <b>indexes</b> are more compact than bitmap indexes in almost all cases. This compactness combined with efficient query processing strategies results in <b>inverted</b> <b>indexes</b> outperforming bitmap indexes for most queries, often significantly...|$|R
50|$|In pre-computer times, concordances to {{important}} books were manually assembled. These were effectively <b>inverted</b> <b>indexes</b> {{with a small}} amount of accompanying commentary that required a tremendous amount of effort to produce.|$|R
40|$|We {{introduce}} new compressed <b>inverted</b> <b>indexes</b> for highly repetitive document collections. They {{are based on}} runlength, Lempel-Ziv, or grammar-based compression of the differential inverted lists, instead of gap-encoding them as is the usual practice. We show that our compression methods significantly reduce the space achieved by classical compression, {{at the price of}} moderate slowdowns. Moreover, many of our methods are universal, that is, they do not need to know the versioning structure of the collection. We also introduce compressed self-indexes in the comparison. We show that techniques can compress much further, using {{a small fraction of the}} space required by our new <b>inverted</b> <b>indexes,</b> yet they are orders of magnitude slower...|$|R
5000|$|The {{rationale}} behind developing a forward index {{is that as}} documents are parsed, {{it is better to}} immediately store the words per document. The delineation enables Asynchronous system processing, which partially circumvents the <b>inverted</b> <b>index</b> update [...] The forward index is sorted to transform it to an <b>inverted</b> <b>index.</b> The forward index is essentially a list of pairs consisting of a document and a word, collated by the document. Converting the forward index to an <b>inverted</b> <b>index</b> {{is only a matter of}} sorting the pairs by the words. In this regard, the <b>inverted</b> <b>index</b> is a word-sorted forward index.|$|E
50|$|There are {{two main}} {{variants}} of inverted indexes: A record-level <b>inverted</b> <b>index</b> (or inverted file index or just inverted file) contains a list of references to documents for each word. A word-level <b>inverted</b> <b>index</b> (or full <b>inverted</b> <b>index</b> or inverted list) additionally contains the positions of each word within a document. The latter form offers more functionality (like phrase searches), but needs more processing power and space to be created.|$|E
50|$|After parsing, the indexer {{adds the}} {{referenced}} document to the document {{list for the}} appropriate words. In a larger search engine, the process of finding each word in the <b>inverted</b> <b>index</b> (in order to report that it occurred within a document) may be too time consuming, and so this process is commonly split up into two parts, {{the development of a}} forward index and a process which sorts the contents of the forward index into the <b>inverted</b> <b>index.</b> The <b>inverted</b> <b>index</b> is so named because it is an inversion of the forward index.|$|E
40|$|<b>Inverted</b> <b>indexing</b> is {{a popular}} {{non-exhaustive}} solution to large scale search. An inverted file is built by a quantizer such as k-means or a tree structure. It {{has been found that}} multiple inverted files, obtained by multiple independent random quantizers, are able to achieve practically good re-call and speed. Instead of computing the multiple quantizers indepen-dently, we present a method that creates them jointly. Our method jointly optimizes all codewords in all quantizers. Then it assigns these codewords to the quantizers. In exper-iments this method shows significant improvement over var-ious existing methods that use multiple independent quan-tizers. On the one-billion set of SIFT vectors, our method is faster and more accurate than a recent state-of-the-art <b>inverted</b> <b>indexing</b> method. 1...|$|R
40|$|<b>Inverted</b> <b>indexes</b> in image {{retrieval}} {{not only}} allow fast access to database images but also summarize all {{knowledge about the}} database, so that their discriminative capacity largely determines the retrieval performance. In this paper, for vocabulary tree based image retrieval, we propose a semantic-aware co-indexing algorithm to jointly embed two strong cues into the inverted indexes: 1) local invariant features that are robust to delineate low-level image contents, and 2) semantic attributes from large-scale object recognition that may reveal image semantic meanings. For an initial set of <b>inverted</b> <b>indexes</b> of local features, we utilize 1000 semantic attributes to filter out isolated images and insert semantically similar images to the initial set. Encoding these two distinct cues together effectively enhances the discriminative capability of <b>inverted</b> <b>indexes.</b> Such co-indexing operations are totally off-line and introduce small computation overhead to online query cause only local features but no semantic attributes are used for query. Experiments and comparisons with recent retrieval methods on 3 datasets, i. e., UKbench, Holidays, Oxford 5 K, and 1. 3 million images from Flickr as distractors, manifest the competitive performance of our method 1. 1...|$|R
40|$|Inspired by {{the success}} of <b>inverted</b> <b>indexing</b> in the textual search domain, we provide sparseness {{justifications}} for using <b>inverted</b> file <b>indexing</b> on image content, which paves the way for developing scalable image content search systems. We use clustering to automatically generate a content vocabulary. To avoid the problem of generating cluster centers that are overcrowded in high density areas for sparse data sets, we use a clustermerge procedure for cluster post-processing. We further use visual codewords to represent low level image features, which not only makes the <b>inverted</b> file <b>indexing</b> and search applicable to image content, but also helps bridge the gap between the low level image features and high-level human visual perception. Experimental results confirm the success of our methods. 1. Introduction and Relate...|$|R
50|$|Document-oriented {{database}} Clusterpoint uses inverted indexing {{model to}} provide fast full-text search for XML or JSON data objects and to deliver scale out ability for Big data. Clusterpoint has built-in computing engine that allows {{execution of a}} combined SQL query, free text search and JavaScript code right inside the distributed database. Both data and <b>inverted</b> <b>index</b> through scalable sharding and replication can be distributed across {{a large number of}} servers to support billions of data objects in the same Clusterpoint database. Clusterpoint query language JS/SQL blends together SQL and JavaScript syntax with full text search, where <b>inverted</b> <b>index</b> is being used to deliver milliseconds-range text search performance and relevant pagination in web and mobile applications. In Clusterpoint database architecture <b>inverted</b> <b>index</b> also supports programmable relevance ranking enabling to customize search output without extra coding efforts. Similarly to relational databases, Clusterpoint supports distributed ACID-compliant database transactions for strong document database consistency, where <b>inverted</b> <b>index</b> data is immediately updated along any XML or JSON document content updates. <b>Inverted</b> <b>index</b> is also used to support near real-time Big data reporting, analytics, drill-down and data mining over REST API in Clusterpoint database.|$|E
50|$|This {{correlation}} {{process is}} similar to what occurs in a text-search oriented <b>Inverted</b> <b>index.</b>|$|E
50|$|The <b>inverted</b> <b>index</b> data {{structure}} {{is a central}} component of a typical search engine indexing algorithm. A goal of a search engine implementation is to optimize {{the speed of the}} query: find the documents where word X occurs. Once a forward index is developed, which stores lists of words per document, it is next inverted to develop an <b>inverted</b> <b>index.</b> Querying the forward index would require sequential iteration through each document and to each word to verify a matching document. The time, memory, and processing resources to perform such a query are not always technically realistic. Instead of listing the words per document in the forward index, the <b>inverted</b> <b>index</b> {{data structure}} is developed which lists the documents per word.|$|E
50|$|Manatee is a {{database}} management system specifically devised for effective indexing of large text corpora. It {{is based on the}} idea of <b>inverted</b> <b>indexing</b> (keeping an index of all positions of a given word in the text). It has been used for indexing of billion-word-size text corpora.|$|R
40|$|Large <b>inverted</b> <b>indices</b> are by now {{common in}} the {{construction}} of web-scale search engines. For faster access, <b>inverted</b> <b>indices</b> are indexed internally so {{that it is possible to}} skip quickly over unnecessary documents. The classical approach to skipping dictates that a skip should be positioned every √ f document pointers, where f is the overall number of documents where the term appears. We argue that due to the growing size of the web more refined techniques are necessary, and describe how to embed a compressed perfect skip list in an inverted list. We provide statistical models that explain the empirical distribution of the skip data we observe in our experiments, and use them to devise good compression techniques that allow us to limit the waste in space, so that the resulting data structure increases the overall index size by just a few percents, still making it possible to index pointers with a rather fine granularity. ...|$|R
40|$|Graph {{reordering}} is {{a powerful}} technique to increase the locality of the representations of graphs, which {{can be helpful in}} several applications. We study how the technique can be used to improve compression of graphs and <b>inverted</b> <b>indexes.</b> We extend the recent theoretical model of Chierichetti et al. (KDD 2009) for graph compression, and show how it can be employed for compression-friendly reordering of social networks and web graphs and for assigning document identifiers in <b>inverted</b> <b>indexes.</b> We design and implement a novel theoretically sound reordering algorithm that is based on recursive graph bisection. Our experiments show a significant improvement of the compression rate of graph and indexes over existing heuristics. The new method is relatively simple and allows efficient parallel and distributed implementations, which is demonstrated on graphs with billions of vertices and hundreds of billions of edges...|$|R
5000|$|Many {{search engines}} {{incorporate}} an <b>inverted</b> <b>index</b> when evaluating a search query to quickly locate documents containing {{the words in}} a query and then rank these documents by relevance. Because the <b>inverted</b> <b>index</b> stores {{a list of the}} documents containing each word, the search engine can use direct access to find the documents associated with each word in the query in order to retrieve the matching documents quickly. The following is a simplified illustration of an inverted index: ...|$|E
50|$|<b>Inverted</b> <b>index</b> : Stores {{a list of}} {{occurrences of}} each atomic search criterion, {{typically}} {{in the form of}} a hash table or binary tree.|$|E
50|$|The <b>inverted</b> <b>index</b> {{is filled}} via a merge or rebuild. A rebuild {{is similar to}} a merge but first deletes the {{contents}} of the <b>inverted</b> <b>index.</b> The architecture may be designed to support incremental indexing, where a merge identifies the document or documents to be added or updated and then parses each document into words. For technical accuracy, a merge conflates newly indexed documents, typically residing in virtual memory, with the index cache residing on one or more computer hard drives.|$|E
40|$|Formulating and {{processing}} phrases and other term dependencies to improve query effectiveness {{is an important}} problem in information retrieval. However, accessing these types of statistics using standard <b>inverted</b> <b>indexes</b> requires unreasonable processing time or incurs a substantial space overhead. Establishing a balance between these competing space and time trade-offs can dramatically improve system performance...|$|R
40|$|This paper {{describes}} Ivory, {{an attempt}} to build a distributed retrieval system around the open-source Hadoop implementation of MapReduce. We focus on three noteworthy aspects of our work: a retrieval architecture built directly on the Hadoop Distributed File System (HDFS), a scalable Map-Reduce algorithm for <b>inverted</b> <b>indexing,</b> and webpage classification to enhance retrieval effectiveness. 1...|$|R
40|$|All pairs {{similarity}} {{search is}} used in many web search and data mining applications. Previous work has used comparison filtering, <b>inverted</b> <b>indexing,</b> and parallel accumulation of partial intermediate results to expedite its execution. However, shuffling intermediate results can incur significant communication overhead as data scales up. This paper studies a scalable two-step approach called Partition-based Similarity Search (PSS) which incorporates several optimization techniques. First, PSS uses a static partitioning algorithm that places dissimilar vectors into different groups and balance the comparison workload with a circular assignment. Second, PSS executes comparison tasks in parallel, each using a hybrid data structure that combines the advantages of forward and <b>inverted</b> <b>indexing.</b> Our evaluation {{results show that the}} proposed approach leads to an early elimination of unnecessary I/O and data communication while sustaining parallel efficiency. As a result, it improves performance by an order of magnitude when dealing with large datasets...|$|R
50|$|On {{the search}} level, several {{independent}} ranking algorithms processes the <b>inverted</b> <b>index</b> together {{with hundreds of}} search parameters to produce the final ranking for each document.|$|E
50|$|The <b>inverted</b> <b>index</b> is a sparse matrix, since not all {{words are}} present in each document. To reduce {{computer}} storage memory requirements, it is stored differently from a two dimensional array. The index {{is similar to the}} term document matrices employed by latent semantic analysis. The <b>inverted</b> <b>index</b> can be considered a form of a hash table. In some cases the index is a form of a binary tree, which requires additional storage but may reduce the lookup time. In larger indices the architecture is typically a distributed hash table.|$|E
5000|$|The {{benefit of}} adding a search layer to the {{architecture}} stack is rapid response time large dynamic datasets {{made possible by}} search indexing technology such as an <b>inverted</b> <b>index.</b>|$|E
40|$|Library {{records and}} their {{utilization}} are described {{and the various}} types of file organization available are examined. The serial file with a series of <b>inverted</b> <b>indexes</b> is preferred to the simple serial file or a threaded list file. It is shown how various records should be stored, according to their utilization, in the available storage devices in order to achieve optimum cost-performance...|$|R
40|$|Abstract. Highly {{heterogeneous}} XML {{collections are}} thematic collections exploiting different structures: the parent-child or ancestor-descendant relationships are not preserved and vocabulary discrepancies in the element names can occur. In this setting current approaches return answers with low precision. By means of similarity measures and semantic <b>inverted</b> <b>indices</b> we present an approach {{for improving the}} precision of query answers without compromising performance. ...|$|R
50|$|Radix {{trees are}} useful for {{constructing}} associative arrays with keys that can be expressed as strings. They find particular application {{in the area of}} IP routing, where the ability to contain large ranges of values with a few exceptions is particularly suited to the hierarchical organization of IP addresses. They are also used for <b>inverted</b> <b>indexes</b> of text documents in information retrieval.|$|R
50|$|The content based {{approach}} exploits semantic {{connections between}} documents and parts thereof, and semantic connections between queries and documents. Most content based document retrieval systems use an <b>inverted</b> <b>index</b> algorithm.|$|E
5000|$|To {{perform the}} basic variant of ESA, one {{starts with a}} {{collection}} of texts, say, all Wikipedia articles; let the number of documents in the collection be [...] These are all turned into [...] "bags of words", i.e., term frequency histograms, stored in an <b>inverted</b> <b>index.</b> Using this <b>inverted</b> <b>index,</b> one can find for any word the set of Wikipedia articles containing this word; in the vocabulary of Egozi, Markovitch and Gabrilovitch, [...] "each word appearing in the Wikipedia corpus can be seen as triggering each of the concepts it points to in the inverted index." ...|$|E
50|$|Lookeen {{is built}} upon the open source software, Lucene. The index {{framework}} builds an <b>inverted</b> <b>index</b> to allow fast full text searches within indexed content. Lookeen uses Microsoft add-in technology to integrate a search bar and ribbon into the Outlook client.|$|E
40|$|With the {{advances}} in cloud computing and huge RAMs provided by 64 -bit architectures, {{it is possible}} to tackle large problems using memory-based solutions. Construction of term-based, partitioned, parallel <b>inverted</b> <b>indexes</b> is a communication intensive task and suitable for memory-based modeling. In this paper, we provide an efficient parallel framework for in-memory construction of term-based partitioned, <b>inverted</b> <b>indexes.</b> We show that, by utilizing an efficient bucketing scheme, we can eliminate the need for the generation of a global vocabulary. We propose and investigate assignment schemes that can reduce the communication overheads while minimizing the storage and final query processing imbalance. We also present a study on how communication among processors should be carried out with limited communication memory {{in order to reduce the}} total inversion time. We present several different communication-memory organizations and discuss their advantages and shortcomings. The conducted experiments indicate promising results. © 2012 The Author. Published by Oxford University Press on behalf of The British Computer Society...|$|R
40|$|Cataloged from PDF {{version of}} article. With the {{advances}} in cloud computing and huge RAMs provided by 64 -bit architectures, {{it is possible}} to tackle large problems using memory-based solutions. Construction of term-based, partitioned, parallel <b>inverted</b> <b>indexes</b> is a communication intensive task and suitable for memory-based modeling. In this paper, we provide an efficient parallel framework for in-memory construction of term-based partitioned, <b>inverted</b> <b>indexes.</b> We show that, by utilizing an efficient bucketing scheme, we can eliminate the need for the generation of a global vocabulary. We propose and investigate assignment schemes that can reduce the communication overheads while minimizing the storage and final query processing imbalance. We also present a study on how communication among processors should be carried out with limited communication memory {{in order to reduce the}} total inversion time. We present several different communication-memory organizations and discuss their advantages and shortcomings. The conducted experiments indicate promising results. © 2012 The Author. Published by Oxford University Press on behalf of The British Computer Society...|$|R
40|$|Encoding {{lists of}} {{integers}} efficiently {{is important for}} many applications in different fields. Adjacency lists of large graphs are usually encoded to save space and to improve decoding speed. <b>Inverted</b> <b>indexes</b> of Information Retrieval systems keep the lists of postings compressed in order to exploit the memory hierarchy. Secondary indexes of DBMSs are stored similarly to <b>inverted</b> <b>indexes</b> in IR systems. In this paper we propose Vector of Splits Encoding (VSEncoding), a novel class of encoders that work by optimally partitioning a list of integers into blocks which are efficiently compressed by using simple encoders. In previous works heuristics were applied during the partitioning step. Instead, we find the optimal solution by using a dynamic programming approach. Experiments show that our class of encoders outperform all the existing methods in literature by more than 10 % (with the exception of Binary Interpolative Coding with which they, roughly, tie) still retaining a very fast decompression algorithm...|$|R
