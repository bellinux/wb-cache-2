0|7930|Public
5000|$|<b>Data</b> <b>entry</b> and {{conversion}} services include: academic <b>data</b> <b>entry,</b> database {{content and}} support, survey digitization, and direct marketing support.|$|R
40|$|Routine {{capture of}} patient data for a {{computer-based}} patient record system remains {{a subject of}} study. Time constraints that require fast <b>data</b> <b>entry</b> and maximal expression power {{are in favor of}} free text <b>data</b> <b>entry.</b> However, using patient data directly for decision support systems, for quality assessment, etc. requires structured <b>data</b> <b>entry,</b> which appears to be more tedious and time consuming. In this paper, a prototype clinical <b>data</b> <b>entry</b> application is described that combines free text and structured <b>data</b> <b>entry</b> in one single application and allows clinicians to smoothly switch between these two different input styles. A knowledge base involving a semantic network of clinical <b>data</b> <b>entry</b> terms and their properties and relationships is used by this application to support structured <b>data</b> <b>entry.</b> From structured <b>data,</b> sentences are generated and shown in a text processor together with the free text. This presentation metaphor allows for easy integrated presentation of structured data and free text...|$|R
40|$|<b>Grid</b> <b>data</b> sources {{may have}} schema- and data-level {{conflicts}} {{that need to}} be addressed using data transformation and integration technologies not supported by the current generation of <b>Grid</b> <b>data</b> access and querying middleware. We present an architecture that combines <b>Grid</b> <b>data</b> access and distributed querying with fine-grained data transformation/integration technologies, and the results of a query performance evaluation on this architecture. The performance evaluation indicates that it is indeed feasible to combine such technologies while achieving acceptable query performance. We also discuss the significance of our results for the further development of query performance over heterogeneous <b>Grid</b> <b>data</b> sources. Key words: data integration, query processing, Grid computing, bioinformatic...|$|R
50|$|While {{this method}} of quality control clearly is not proof against {{systematic}} errors or operator misread entries from a source document, it is very useful in catching and correcting random miskeyed strokes which occur even with experienced <b>data</b> <b>entry</b> operators. However, {{it proved to be}} a fatally tragic flaw in the Therac 25 incident. This method has survived the keypunch and is available in some currently available <b>data</b> <b>entry</b> programs (e.g. PSPP/SPSS <b>Data</b> <b>Entry).</b> At least one study suggests that single-pass <b>data</b> <b>entry</b> with range checks and skip rules approaches the reliability of two-pass data entry; however, it is desirable to implement both systems in a <b>data</b> <b>entry</b> application.|$|R
40|$|Gridded {{rainfall}} datasets {{are used}} in many hydrological and climatological studies, in Australia and elsewhere, including for hydroclimatic forecasting, climate attribution studies and climate model performance assessments. The attraction of the spatial coverage provided by <b>gridded</b> <b>data</b> is clear, particularly in Australia where the spatial and temporal resolution of the rainfall gauge network is sparse. However, the question that must be asked is whether it is suitable to use <b>gridded</b> <b>data</b> {{as a proxy for}} observed point <b>data,</b> given that <b>gridded</b> <b>data</b> is inherently "smoothed" and may not necessarily capture the temporal and spatial variability of Australian rainfall which leads to hydroclimatic extremes (i. e. droughts, floods) ? This study investigates this question through a statistical analysis of three monthly gridded Australian rainfall datasets – the Bureau of Meteorology (BOM) dataset, the Australian Water Availability Project (AWAP) and the SILO dataset. To demonstrate the hydrological implications of using <b>gridded</b> <b>data</b> as a proxy for gauged data, a rainfall-runoff model is applied to one catchment in South Australia (SA) initially using <b>gridded</b> <b>data</b> as the source of rainfall input and then gauged rainfall data. The results indicate a markedly different runoff response associated with each of the different sources of rainfall data. It should be noted that this study does not seek to identify which gridded dataset is the "best" for Australia, as each <b>gridded</b> <b>data</b> source has its pros and cons, as does gauged or point data. Rather the intention is to quantify differences between various <b>gridded</b> <b>data</b> sources and how they compare with gauged data so that these differences can be considered and accounted for in studies that utilise these gridded datasets. Ultimately, if key decisions are going {{to be based on the}} outputs of models that use <b>gridded</b> <b>data,</b> an estimate (or at least an understanding) of the uncertainties relating to the assumptions made in the development of <b>gridded</b> <b>data</b> and how that <b>gridded</b> <b>data</b> compares with reality should be made...|$|R
5000|$|IBM 3740 <b>Data</b> <b>Entry</b> System was a <b>data</b> <b>entry</b> {{system that}} was {{announced}} by IBM in 1973. It recorded data on a Diskette, a new recording medium from IBM, for fast, flexible, efficient <b>data</b> <b>entry</b> to either high-production, centralized operations or to decentralized, remote operations. The [...] "Diskette" [...] was more commonly known as an 8-inch floppy disk, ...|$|R
40|$|Self-service {{technologies}} have been gaining increasing importance {{in public and}} private organizations over recent years. One of the predominant responsibilities of the customers in the context of self-service is to enter their data on their own. Self-service for <b>data</b> <b>entry</b> can help organizations to further enhance the efficiency of their processes and to make customer experience smoother. However, as self-service for <b>data</b> <b>entry</b> is intended to be handled without intensive employee assistance, inexp erienced <b>data</b> <b>entry</b> can lead to data quality problems. Although academic research has explored several effects of self-service technologies, there is still a lack of research investigating the effect of self-service <b>data</b> <b>entry</b> on <b>data</b> quality. Thus, in an in-depth case study in cooperation with the German Federal Employment Agency we analyzed how customer self-service for <b>data</b> <b>entry</b> affects <b>data</b> quality and found that assisted self-service <b>data</b> <b>entry</b> leads to highest data qualit...|$|R
5000|$|<b>Data</b> <b>entry</b> by geologists in {{the field}} may take less total time than {{subsequent}} <b>data</b> <b>entry</b> in the office, potentially reducing the overall time needed to complete a project.|$|R
40|$|Repertory grids {{are used}} widely in Personal Construct Psychology (PCP) research. An array of {{accepted}} techniques for analysing <b>grid</b> <b>data</b> {{is available to}} researchers. This paper revisits the use of formal concept analysis (FCA) in analysing repertory grids. It particular, this paper focuses on using FCA to explore hierar-chical structures in <b>grid</b> <b>data.</b> A description of the technique is provided, along with a review of its applica-tion in PCP research. The technique is also compared with other approaches for identifying structures in <b>grid</b> <b>data...</b>|$|R
5000|$|SuperMICAR automates the MICAR <b>data</b> <b>entry</b> process. This {{program is}} {{designed}} as an enhancement of the earlier PC-MICAR <b>Data</b> <b>Entry</b> program. Super-MICAR is designed to automatically encode cause-of-death data into numeric entity reference numbers.|$|R
40|$|The {{objective}} {{was to determine the}} conditions under which Automatic Speech Recognition (ASR) is an efficient choice for <b>data</b> <b>entry.</b> In particular the focus was on <b>data</b> <b>entry</b> tasks that are part of constructing military messages. The ADF Formatted Messaging System utilises a structured formatting system to constrain the semantics of a message but also includes a field for unlimited and unstructured text. Hence the <b>data</b> <b>entry</b> tasks involved range from form-filling to free dictation of short phrases. In the experiments, ASR and manual input modes are compared for three <b>data</b> <b>entry</b> tasks: textual phrase entry, selection from a list, and numerical <b>data</b> <b>entry.</b> To effect fair comparisons, the tasks minimised the transaction cycle for each input mode and data type and the main comparisons use only times from correct <b>data</b> <b>entry.</b> The results indicate that for inputting short phrases ASR only competes if the typist's speed is below 45 wpm. For selecting an item from a list, ASR offered an advantage only if the list length was greater than 15 items. For entering numerical data, ASR offered no advantage over keypad or mouse. The general conclusion for formatted <b>data</b> <b>entry</b> is that a keyboard/mouse interface designed to match the data to be entered will be more time efficient than any equivalent ASR interface...|$|R
5000|$|ISO/TR 19121:2000 Geographic {{information}} -- Imagery and <b>gridded</b> <b>data</b> ...|$|R
40|$|Introduction: Use of {{electronic}} health record (EHR) systems can place a considerable <b>data</b> <b>entry</b> burden upon {{the emergency department}} (ED) physician. Voice recognition <b>data</b> <b>entry</b> has been proposed as one mechanism to mitigate some of this burden; however, no reports are available specifically comparing emergency physician (EP) time use or number of interruptions between typed and voice recognition data entry-based EHRs. We designed this study to compare physician time use and interruptions between an EHR system using typed <b>data</b> <b>entry</b> versus an EHR with voice recognition. Methods: We collected prospective observational data at 2 academic teaching hospital EDs, one using an EHR with typed <b>data</b> <b>entry</b> {{and the other with}} voice recognition capabilities. Independent raters observed EP activities during regular shifts. Tasks each physician performed were noted and logged in 30 second intervals. We compared time allocated to charting, direct patient care, and change in tasks leading to interruptions between sites. Results: We logged 4, 140 minutes of observation for this study. We detected no statistically significant differences in the time spent by EPs charting (29. 4 % typed; 27. 5 % voice) or the time allocated to direct patient care (30. 7 %; 30. 8 %). Significantly more interruptions per hour were seen with typed <b>data</b> <b>entry</b> versus voice recognition <b>data</b> <b>entry</b> (5. 33 vs. 3. 47; p= 0. 0165). Conclusion: The use of a voice recognition <b>data</b> <b>entry</b> system versus typed <b>data</b> <b>entry</b> did not appear to alter the amount of time physicians spend charting or performing direct patient care in an ED setting. However, we did observe a lower number of workflow interruptions with the voice recognition <b>data</b> <b>entry</b> EHR. Additional research is needed to further evaluate the <b>data</b> <b>entry</b> burden in the ED and examine alternative mechanisms for chart entry as EHR systems continue to evolve. [West J Emerg Med. 2014; 15 (4) : 541 - 547. ]...|$|R
3000|$|<b>Data</b> <b>Entry</b> Methods: The input methods {{available}} for mobile devices {{are different from}} those for desktop computers and require a certain level of proficiency. This problem increases the likelihood of erroneous input and decreases the rate of <b>data</b> <b>entry.</b>|$|R
3000|$|... [*]“… In {{case of a}} <b>data</b> <b>entry</b> zone, a Web page could {{contain more}} than one <b>data</b> <b>entry</b> zone with {{different}} purposes. The technique could allow the verification of all these repeated zones in a particular way.” - Inspector 4.|$|R
40|$|Capturing {{clinical}} data is a multi-faceted problem. This paper discusses clinical <b>data</b> <b>entry</b> problems encountered {{during the}} development of an intelligent clinical <b>data</b> <b>entry</b> system. Based on a review of the problems, recommendations are made for an approach to the design of clinical <b>data</b> <b>entry</b> programs. These recommendations include a discussion of key components in the design process as illustrated by the development of MedIO, a C++ computer program for the entry of history and physical exam information...|$|R
40|$|Work-related {{musculoskeletal}} disorders (WMSDs) negatively impact worker’s health, ability to work, and {{their quality of}} life. Non-invasive methods for assessing the physiological responses to workload may provide information on physiological markers leading to increased risk of WMSDs. The following study aimed to evaluate the feasibility of using thermography to quantify differences in thermal readings of participants during and following a <b>data</b> <b>entry</b> task and assess the repeatability of thermal readings. Skin surface temperature measurements of the dorsal forearm were obtained from 12 participants (6 females, 6 males) during a <b>data</b> <b>entry</b> task (35 minutes) and a 30 -minute post-task period. Participants also reported their perceived forearm discomfort during <b>data</b> <b>entry</b> and recovery. Three forearm analysis regions were analyzed based on statistical findings; Upper Left, Lower Left and Right regions. Temperature trends were found to increase during <b>data</b> <b>entry</b> and decrease during recovery. The Upper Left region was warmer during both <b>data</b> <b>entry</b> and recovery phases {{in comparison to the}} other regions. Repeatability of surface temperatures, based on intraclass correlations (ICCs), was found to be fair for magnitudes and trends during <b>data</b> <b>entry,</b> and poor for magnitudes and trend...|$|R
40|$|The before/after {{study of}} {{physiological}} and biochemical parameters {{was used to}} delineate the effects of VDT <b>data</b> <b>entry</b> work on operators. Twenty-nine healthy Chinese students were chosen and divided at random into the simple and the complicated <b>data</b> <b>entry</b> group. The subjects were instructed to work as quickly and correctly as possible according to the 'Data Entry Work Programme’ for 150 min. Work performance (correct entry) was automatically recorded once every lOmin. The before/after parameters were tested respectively. The results showed that performance fluctuated over time. It decreased obviously after 50 – 60 min of work, followed by a rebound, {{and there was a}} terminal motivation phenomenon {{at the end of the}} test, which was associated with the auto-arousal and cerebral compensatory effort. Changes in physiological parameters revealed that operators were fatigued after <b>data</b> <b>entry</b> work. The adrenaline excretion in urine showed a tendency to increase after simple <b>data</b> <b>entry</b> work. The noradrenaline excretion showed a tendency to decrease after complicated <b>data</b> <b>entry</b> work. The differences in performance, diastolic blood pressure in a standing position and neurobehaviour between two groups indicated that much stress was experienced when performing complicated <b>data</b> <b>entry</b> work...|$|R
30|$|A graphic user {{interface}} is designed and implemented to make <b>data</b> <b>entry</b> easier {{for people who are}} not expert in Structured Query Language (SQL). Control mechanisms are also implemented to constrain and regulate <b>data</b> <b>entry</b> by checking errors, data completeness, and consistency.|$|R
50|$|One {{major new}} {{facility}} provided on this range was Direct <b>Data</b> <b>Entry,</b> a system comprising {{up to eight}} dedicated VDU <b>data</b> <b>entry</b> stations, with which card image files could be created; these could be assigned to a program's card reader and processed accordingly.|$|R
5000|$|However, as double-entry {{needs to}} be carried out by two {{separate}} <b>data</b> <b>entry</b> officers, the expenses associated with double <b>data</b> <b>entry</b> are substantial. Moreover, in some institutions this may not be possible. Therefore M. Khushi et al. suggest another semi-automatic technique called 'eAuditor'.|$|R
40|$|Point-of-care <b>data</b> <b>entry</b> is an {{important}} part of a clinical information system. Unfortunately, many health care providers refuse to perform <b>data</b> <b>entry</b> because they feel computers are difficult to use and require more time than traditional paper based forms. We designed a user interface for entry of outpatient visit information that gives the health care provider several alternative methods of entering data. The system audits the use of the individual interface elements and measures the time required for completion of the <b>data</b> <b>entry...</b>|$|R
5000|$|Transferring {{data from}} paper to {{electronic}} format involves labor-intensive <b>data</b> <b>entry</b> work. This has prompted {{a movement to}} [...] "offshore" [...] the <b>data</b> <b>entry</b> of the information on checks to countries (e.g., India) that have abundant employees which helps in ultimately lowering the costs.|$|R
30|$|It is {{important}} to point out that we used data from stations in China to calculate the precipitation, while we used <b>grid</b> <b>data</b> to calculate the water vapor budget. The <b>grid</b> <b>data</b> may cover a larger region compared to China, for example, in SW, the water vapor budget is larger than in only the SW of China, thus possibly causing inaccuracy.|$|R
50|$|Case report {{forms are}} {{manually}} filled at site and {{mailed to the}} company for which trial is being performed. The data on forms is transferred to the CDMS tool through data entry.The most popular method being double <b>data</b> <b>entry</b> where two different <b>data</b> <b>entry</b> operators enter the data in the system independently and both the entries are compared by the system. In case the entry of a value conflicts, system alerts and a verification can be done manually. Another method is Single <b>Data</b> <b>Entry.</b>|$|R
50|$|Appraisers {{provide all}} the data needed to input in {{appraisal}} reports. A <b>data</b> <b>entry</b> team does the rest; it searches, consolidates and types the data into reports, such as subject <b>data</b> and comparable <b>grid</b> prior sales history. Most <b>data</b> <b>entry</b> organizations work 24 hours a day, 7 days a week, 365 days a year. The appraiser sends empty reports, and the <b>data</b> <b>entry</b> team works all day and night, even while the appraiser is sleeping. This process increases the appraiser's efficiency, and frees up his/her time.|$|R
40|$|The UltraSTAR {{structured}} <b>data</b> <b>entry</b> {{system is}} now in routine use for reporting ultrasound studies at Brigham and Women's Hospital, having been used for 3722 reports in its first ten months of service. Reports entered through GUI-based forms are uploaded via HL 7 to a radiology information system and distributed through a hospital network. UltraSTAR introduces collaborative reporting, in which nonmedical and medical staff collaborate to produce a single report for each patient visit. Performance of UltraSTAR was measured as user satisfaction, <b>data</b> <b>entry</b> time, report completeness, free text annotation rate, and referring-physician satisfaction with reports. Results show high satisfaction with UltraSTAR among radiologists and acceptance of the system among ultrasound technicians. <b>Data</b> <b>entry</b> times averaged 5. 3 minutes per report. UltraSTAR reports were slightly more complete than comparable narrative reports. Free text annotations were needed in only 25. 2 % of all UltraSTAR reports. Referring physicians were neutral to slightly positive toward UltraSTAR's outline-format reports. UltraSTAR is successful at structured <b>data</b> <b>entry</b> despite somewhat long reporting times. Its success {{can be attributed to}} efficiencies from collaborative reporting and from integration with existing information systems. UltraSTAR shows that the advantages of structured <b>data</b> <b>entry</b> can outweigh its difficulties even before problems of <b>data</b> <b>entry</b> time and concept representation are solved...|$|R
40|$|Theory {{building}} in nursing and midwifery both {{to explain and}} inform practice is important to advance these professions via provision of a theoretical foundation. This research explored the process of perinatal <b>data</b> <b>entry</b> undertaken by midwives to explore {{the impact of the}} movement from paper to computer collection of data. Use of grounded theory methodology enabled theory building, leading to a theoretical understanding of the phenomenon and development of the Theory of Beneficial Engagement grounded in the data. Methods involved in-depth semistructured interviews with 15 users of perinatal data systems. Participants were recruited from 12 different healthcare locations and were utilizing three different electronic systems for <b>data</b> <b>entry.</b> The research question that guided the study focused on examining the influences of using the computer for perinatal <b>data</b> <b>entry.</b> Findings indicated that qualities particular to some midwives denoted engagement with perinatal <b>data</b> <b>entry,</b> suggesting a strong desire to enter complete, timely, and accurate data. The Theory of Beneficial Engagement provides a model of user engagement with systems for perinatal <b>data</b> <b>entry</b> consistent with other theories of engagement. The theory developed describes this phenomenon in a simple, elegant manner that can be applied to other areas where mandatory <b>data</b> <b>entry</b> is undertaken. Copyright © 2016 Wolters Kluwer Health, Inc. All rights reserved...|$|R
40|$|This video poster is {{a summary}} of {{experiences}} we have made with <b>data</b> <b>entry</b> when introducing SAS to medical students or physicians. For preparing their theses or doing scientific work {{they are involved in}} data collection and data analysis. An important phase between data collection and data analysis is <b>data</b> <b>entry,</b> the topic to which this paper is devoted to. Most books concerning data analysis using SAS demonstrate <b>data</b> <b>entry</b> only in combination with the data step using the cards or datalines statement. Nowadays, however, hardly someone can be convinced to enter data in this ancient way. This paper introduces more attractive possibilities of <b>data</b> <b>entry</b> and should serve as a guide for SAS novices. Advantages and disadvantages of <b>data</b> <b>entry</b> using VIEWTABLE, SAS Analyst, Enterprise Guide, SAS/INSIGHT, SAS Stat Studio and the FSEDIT Procedure (SAS/FSP) are discussed. Recommendations are provided to help choosing the most efficient strategy for <b>data</b> <b>entry</b> and suggestions to improve some features are made. Topics such as data creation, adding rows and columns to data sets, or computing columns are covered as well. Above all the import facility for Microsoft ® EXCEL and ACCESS data sets will be highlighted. SAS Software refers to Version 9. 2 for Microsoft ® Window...|$|R
40|$|Nowadays, huge {{volumes of}} imagery and <b>gridded</b> <b>data</b> are accessible. However they vary in formats and are stored at various {{organizations}} leading to problems of data discovery, data interoperability and usability. ISO 19115, Content Standard for Digital Geospatial Metadata {{and some other}} norms don’t provide enough provision for imagery and <b>gridded</b> <b>data.</b> UML and XML schema of metadata also don’t provide semantic description of the data content within the dataset. So we provide the additional structure to describe the derivation of imagery and <b>gridded</b> <b>data.</b> This structure is intended to augment the existing metadata standard described in ISO 19115. We focus on identification information, data quality information, spatial representation information, content information, acquisition Information in ISO 19115, we extend these dataset packages, in order to describe the metadata of imagery and <b>gridded</b> <b>data</b> during the cycle of the image product. OWL permits a much richer table of semantics {{as well as a}} more flexible definition of classes and their attributes when compared to UML and XML schema. We propose the mapping rule between UML and OWL, summarize the similarities between UML and OWL concepts. Then we explain in detail the conventions we have adopted to translate the metadata UML model for imagery and <b>gridded</b> <b>data</b> into an OWL ontology, including naming conventions, data types, and restriction conditions between the two concepts. Finally, we store imagery and <b>gridded</b> <b>data</b> metadata ontologies and individuals in a semantic registry prototype, to demonstrate how to fully utilizing the semantic information implicitly embedded in metadata. 1...|$|R
5000|$|ISO 19115-2:2009 Geographic {{information}} -- Metadata -- Part 2: Extensions for {{imagery and}} <b>gridded</b> <b>data</b> ...|$|R
5000|$|Nepal (Programming, Customer Support, Transcription and <b>Data</b> <b>Entry)</b> ...|$|R
50|$|Model 74 (1974) Keybatch was a RJE {{terminal}} with key-to-disk capabilities. These direct <b>data</b> <b>entry</b> (DDE) devices {{consisted of}} a keyboard and a 256 characters display. Dial-up remote <b>data</b> <b>entry</b> terminal were available in 1975. In 1977 the Canadian branch developed support for Optical Mark Reader device OMR.|$|R
5000|$|STANAG 6022 (Edition 2, 22 March 2010): Adoption of a Standard <b>Gridded</b> <b>Data</b> Meteorological Message (METGM) ...|$|R
50|$|For {{a mailing}} company, <b>data</b> <b>entry</b> clerks might be {{required}} to type in reference numbers for items of mail which had failed to reach their destination, so that the relevant addresses could be deleted from the database used to send the mail out. If the company was compiling a database from addresses handwritten on a questionnaire, the person typing those into the database would be a <b>data</b> <b>entry</b> clerk. In a cash office, a <b>data</b> <b>entry</b> clerk might {{be required to}} type expenses into a database using numerical codes.|$|R
40|$|Background: The {{clinical}} and scientific usage of patient-reported outcome measures is increasing {{in the health}} services. Often paper forms are used. Manual double <b>entry</b> of <b>data</b> {{is defined as the}} definitive gold standard for transferring data to an electronic format, but the process is laborious. Automated forms processing may be an alternative, but further validation is warranted. Methods: 200 patients were randomly selected from a cohort of 5777 patients who had previously answered two different questionnaires. The questionnaires were scanned using an automated forms processing technique, as well as processed by single and double manual <b>data</b> <b>entry,</b> using the EpiData <b>Entry</b> <b>data</b> <b>entry</b> program. The main outcome measure was the proportion of correctly entered numbers at question, form and study level. Results: Manual double-key <b>data</b> <b>entry</b> (error proportion per 1000 fields = 0. 046 (95 % CI: 0. 001 – 0. 258)) performed better than single-key <b>data</b> <b>entry</b> (error proportion per 1000 fields = 0. 370 (95 % CI: 0. 160 – 0. 729), (p = 0. 020)). There was no statistical difference between Optical Mark Recognition (error proportion per 1000 fields = 0. 046 (95 % CI: 0. 001 – 0. 258)) and double-key <b>data</b> <b>entry</b> (p = 1. 000). With the Intelligent Character Recognition method, there was no statistical difference compared to single-key <b>data</b> <b>entry</b> (error proportion per 1000 fields = 6. 734 (95 % CI: 0. 817 – 24. 113), (p = 0. 656)), as well as double-key <b>data</b> <b>entry</b> (error proportion per 1000 fields = 3. 367 (95 % CI: 0. 085 – 18. 616)), (p = 0. 319)) ...|$|R
