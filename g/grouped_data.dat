467|10000|Public
2500|$|Log–log plots are an {{alternative}} way of graphically examining {{the tail of}} a distribution using a random sample. This method consists of plotting the logarithm of an estimator of the probability that a particular number of the distribution occurs versus the logarithm of that particular number. Usually, this estimator is the proportion of times that the number occurs in the data set. If the points in the plot tend to [...] "converge" [...] to a straight line for large numbers in the x axis, then the researcher concludes that the distribution has a power-law tail. Examples of the application of these types of plot have been published. A disadvantage of these plots is that, {{in order for them to}} provide reliable results, they require huge amounts of data. In addition, they are appropriate only for discrete (or <b>grouped)</b> <b>data.</b>|$|E
5000|$|Logistic regression#Minimum chi-squared {{estimator}} for <b>grouped</b> <b>data</b> ...|$|E
50|$|PYLL can be {{calculated}} using individual level data or using age <b>grouped</b> <b>data.</b>|$|E
30|$|The {{limits on}} test {{conditions}} mainly {{refers to the}} situation in which the performance parameters of the product could only be periodically inspected. Periodic inspection generates <b>group</b> <b>data.</b> In theory, there have special methods of data analysis and optimal plan design for <b>group</b> <b>data</b> [5 – 11, 34 – 39, 88]. However, from the application point of view, the method of the data analysis and plan design for life data are relatively simple. Therefore, in practice, the engineers tend to use the method for life data to deal with the <b>group</b> <b>data,</b> by transferring the <b>group</b> <b>data</b> into life data by interpolation methods [102, 103]. However, a systematic study on the accuracy of this method has not yet been reported.|$|R
5000|$|Hullian and post-Hullian: theoretical, <b>group</b> <b>data,</b> not dynamic, physiological; ...|$|R
5000|$|<b>Group</b> <b>data</b> in {{consistently}} meaningful ways {{to decrease}} search time.|$|R
5000|$|The {{hierarchical}} Dirichlet process {{extends the}} ordinary Dirichlet process for modelling <b>grouped</b> <b>data.</b>|$|E
5000|$|The idea of <b>grouped</b> <b>data</b> can be {{illustrated}} {{by considering the}} following raw dataset: ...|$|E
5000|$|An estimate, , of {{the mean}} of the {{population}} from which the data are drawn can be calculated from the <b>grouped</b> <b>data</b> as: ...|$|E
40|$|Abstract. Clustering {{is a task}} of <b>grouping</b> <b>data</b> {{based on}} similarity. A popular k-means {{algorithm}} <b>groups</b> <b>data</b> by firstly assigning all data points to the closest clusters, then determining the cluster means. The algorithm repeats these two steps until it has converged. We propose a variation called weighted k-means to improve the clustering scalability. To speed up the clustering process, we develop the reservoir-biased sampling as an efficient data reduction technique since it performs a single scan over a data set. Our algorithm {{has been designed to}} <b>group</b> <b>data</b> of mixture models. We present an experimental evaluation of the proposed method. ...|$|R
2500|$|Focus <b>groups</b> <b>data</b> {{collection}} {{method has}} several advantages in conducting a qualitative research. The following are various advantages {{of using a}} focus <b>group</b> to obtain <b>data.</b>|$|R
5000|$|The {{ability to}} assign {{different}} leadership responsibilities {{and access to}} the <b>group</b> <b>data</b> ...|$|R
50|$|Raw {{information}} is called Data. A record {{is a set}} of logical <b>grouped</b> <b>data.</b> e.g. an employee record will have data stored in the form of fields/attributes like his name, address etc.|$|E
50|$|<b>Grouped</b> <b>data</b> are data {{formed by}} {{aggregating}} individual observations of a variable into groups, {{so that a}} frequency distribution of these groups serves as a convenient means of summarizing or analyzing the data.|$|E
50|$|The {{ecological}} fallacy may occur when conclusions about individuals {{are drawn from}} analyses conducted on <b>grouped</b> <b>data.</b> The nature {{of this type of}} analysis tends to overestimate the degree of association between variables.|$|E
30|$|Cluster {{analysis}} <b>groups</b> <b>data</b> objects {{based only}} on information found in the data that describes the objects and their relationships. This technique can <b>group</b> and evaluate <b>data</b> without knowing possible relationship in advance.|$|R
30|$|No {{effect was}} {{observed}} in the zebrafish embryos of the dilution solvent control <b>group</b> (<b>data</b> not shown).|$|R
3000|$|Measure for {{the size}} of the effect of <b>grouping</b> <b>data</b> after a certain criterion, {{calculated}} from analysis of variance’s [...]...|$|R
50|$|GLMMs {{provide a}} broad range of models for the {{analysis}} of <b>grouped</b> <b>data,</b> since the differences between groups can be modelled as a random effect. These models are useful in the analysis of many kinds of data, including longitudinal data.|$|E
50|$|A {{bar chart}} or bar graph is a chart or graph that {{presents}} <b>grouped</b> <b>data</b> with rectangular bars with lengths {{proportional to the}} values that they represent. The bars can be plotted vertically or horizontally. A vertical bar chart is sometimes called a Line graph.|$|E
5000|$|In this formula, x {{refers to}} the {{midpoint}} of the class intervals, and f is the class frequency. Note that the result of this will be different from the sample mean of the ungrouped data. The mean for the <b>grouped</b> <b>data</b> in the above example, can be calculated as follows: ...|$|E
30|$|In all experiments, {{statistical}} significance was determined using Student's t test (P[*]<[*] 0.05) for <b>group</b> <b>data</b> analysis. Values were expressed as means[*]±[*]S.E.M.|$|R
40|$|Abstract. The Zero-inflated Poisson {{model has}} been widely used in many fields for count data with {{excessive}} zeroes. In fact, <b>group</b> <b>data</b> are often collected for many count data, such as cigarette consumption. In order to solve the problem, Zero-inflated Poisson model with <b>group</b> <b>data</b> is investigated in this paper. Parameter estimation is given by the maximum likelihood estimate, model selection is discussed by the Chi-square test, and one real example is given for application in the end...|$|R
40|$|Clustering is {{a process}} that <b>groups</b> <b>data</b> with respect to data {{similarity}} so that similar data take part same cluster. In image domain clustering is used for various types of problem e. g. image quantization, image segmentation. A good clustering algorithm must <b>group</b> <b>data</b> to homogeneous subsets as possibble. Similarity is most critical step in a clustering algorithm that determine how the clustering algorithm <b>groups</b> <b>data.</b> K-means clustering {{is one of the most}} popular clustering algorithm that <b>groups</b> <b>data</b> to k dissimilar clusters. It is an unsupervised learning algorithm for clustering problem and the main idea is to define k centroids one of each cluster. These centroids is randomly assigned to data space for first iteration. In the next steps, for each data point, distance to these centroids is calculated and data points are assigned to nearest centoids as cluster elements. Then for each cluster, new k centroids are calculated from k clusters. This steps go on until clusters centroids unchange. 1 Overview In this assignment, you will use k-means clustering algorithm for image segmentation by using superpixel representation of an input image. For this purpose you must carry out the following steps...|$|R
5000|$|This model {{description}} is sourced from. The HDP {{is a model}} for <b>grouped</b> <b>data.</b> What {{this means is that}} the data items come in multiple distinct groups. For example, in a topic model words are organized into documents, with each document formed by a bag (group) of words (data items). Indexing groups by , suppose each group consist of data items [...]|$|E
5000|$|Recent {{examples}} {{provide a}} nonparametric approaches to estimating the baseline hazard {{and the distribution}} of the unobserved heterogeneity under fairly weak assumptions. [...] In <b>grouped</b> <b>data,</b> the strict exogeneity assumptions for time-varying covariates are hard to relax. Parametric forms can be imposed for the distribution of the unobserved heterogeneity, even though semiparametric methods that do not specify such parametric forms for the unobserved heterogeneity are available.|$|E
5000|$|Another {{method of}} {{grouping}} {{the data is}} to use some qualitative characteristics instead of numerical intervals. For example, suppose in the above example, there are three types of students: 1) Below normal, if the response time is 5 to 14 seconds, 2) normal if it is between 15 and 24 seconds, and 3) above normal if it is 25 seconds or more, then the <b>grouped</b> <b>data</b> looks like: ...|$|E
5000|$|InterPro [...] a {{centralized}} database, <b>grouping</b> <b>data</b> from databases of protein families, domains and functional sites - {{part of the}} data come from PROSITE.|$|R
5000|$|Offer {{a new way}} to filter, order, or <b>group</b> <b>data</b> {{by using}} a field not exposed in the default {{functions}} of the original design.|$|R
30|$|When {{expression}} of membrane proteins; Her 2, Fas, TGFβR 1 and IGF 1 Rb were analyzed, {{no differences were}} observed between <b>groups</b> (<b>Data</b> not shown).|$|R
5000|$|Categorical data is the {{statistical}} data type consisting of categorical variables or {{of data that}} has been converted into that form, for example as <b>grouped</b> <b>data.</b> More specifically, categorical data may derive from observations made of qualitative data that are summarised as counts or cross tabulations, or from observations of quantitative data grouped within given intervals. Often, purely categorical data are summarised {{in the form of}} a contingency table. However, particularly when considering data analysis, it is common to use the term [...] "categorical data" [...] to apply to data sets that, while containing some categorical variables, may also contain non-categorical variables.|$|E
5000|$|The {{study of}} {{heteroscedasticity}} has been generalized to the multivariate case, {{which deals with}} the covariances of vector observations instead of the variance of scalar observations. One version {{of this is to}} use covariance matrices as the multivariate measure of dispersion. Several authors have considered tests in this context, for both regression and grouped-data situations. Bartlett's test for heteroscedasticity between <b>grouped</b> <b>data,</b> used most commonly in the univariate case, has also been extended for the multivariate case, but a tractable solution only exists for 2 groups. Approximations exist for more than two groups, and they are both called Box's M test ...|$|E
5000|$|In 1954 Kulldorff {{earned a}} licentiate {{degree from the}} Department of Statistics at Lund University. Taking a {{teaching}} positions in the same department, he did his doctoral studies {{under the supervision of}} Carl-Erik Quensel and Harald Cramér. Kulldorff's research led to a PhD in 1961 for his thesis [...] "Contributions to the Theory of Estimation from Grouped and Partially Grouped Samples". His thesis was republished by John Wiley & Sons {{as well as by the}} Soviet Union in a Russian translation. In a review for the Journal of the American Statistical Association, W. Edwards Deming wrote that [...] "here is a book that faces reality, carrying the reader, in a modest 144 pages, on a wondrous excursion into the problems of <b>grouped</b> <b>data,</b> in which the reader cannot fail to catch the contagious enthusiasm of the author" [...]|$|E
5000|$|Data mining - to {{categorise}} and <b>group</b> <b>data</b> {{and automatically}} identify associations and rules {{that may be}} indicative of remarkable patterns, including those connected to fraud.|$|R
50|$|The {{analysis}} of focus <b>group</b> <b>data</b> presents both {{challenges and opportunities}} {{when compared to other}} types of qualitative data. Some authors have suggested that data should be analysed {{in the same manner as}} interview data, while others have suggested that the unique features of focus <b>group</b> <b>data</b> - particularly the opportunity that it provides to observe interactions between group members - means that distinctive forms of analysis should be used. Data analysis can take place at the level of the individual or the group.|$|R
40|$|Despite the {{abundance}} of published material on conducting focus groups, scant specific information exists on how to analyze focus <b>group</b> <b>data</b> in social science research. Thus, the authors provide a new qualitative framework for collecting and analyzing focus <b>group</b> <b>data.</b> First, they identify types of data that can be collected during focus groups. Second, they identify the qualitative data analysis techniques best suited for analyzing these data. Third, they introduce what they term as a micro-interlocutor analysis, wherein meticulous information about which participant responds to each question, {{the order in which}} each participant responds, response characteristics, the nonverbal communication used, and the like is collected, analyzed, and interpreted. They conceptualize how conversation analysis offers great potential for analyzing focus <b>group</b> <b>data.</b> They believe that their framework goes far beyond analyzing only the verbal communication of focus group participants, thereby increasing the rigor of focus group analyses in social science research...|$|R
