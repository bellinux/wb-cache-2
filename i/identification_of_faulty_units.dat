1|10000|Public
40|$|System-level {{diagnosis}} aims at the <b>identification</b> <b>of</b> <b>faulty</b> <b>units</b> in {{a system}} by {{the analysis of the}} system syndrome, that is, the outcomes of a set of interunit tests. For any given syndrome, it is possible to produce a correct (although possibly incomplete) diagnosis of the system if the number of faults is below a syndrome-dependent bound and the degree of diagnosis completeness, that is, the number of correctly diagnosed units, is also dependent on the actual syndrome sigma. The worst-case diagnosis completeness is a syndrome-independent bound that represents the minimum number of units that the diagnosis algorithm correctly diagnoses for any syndrome. This paper provides a lower bound to the worst-case diagnosis completeness for regular graphs for which vertex-isoperimetric inequalities are known and it shows how this bound can be applied to toroidal grids. These results prove a previous hypothesis about the influence of two topological parameters of the diagnostic graph, that is, the bisection width and the diameter, on the degree of diagnosis completeness...|$|E
40|$|We {{show the}} {{advantages}} of modular and hierarchical design in obtaining fault-tolerant software. Modularity enables the <b>identification</b> <b>of</b> <b>faulty</b> software <b>units</b> simplifying key operations, like software removal and replacement. We describe three approaches to repair faulty software based on replication, namely, Passive Replication, N-Version Replication, and Active Replication, based on modular components. We show that the key construct to represent these tactics {{is the ability to}} make ad hoc changes in software topologies. We consider hierarchical mobility as a useful operation to introduce new software <b>units</b> for replacing <b>faulty</b> ones. For illustration purposes, we use connecton, a hierarchical, modular, and self-modifying software specification formalism, and its implementation in the Desmos framework...|$|R
30|$|Masquerading failures, {{which are}} part of the value domain, occur, if one node impersonates the {{identity}} of another node. In case of CAN, one node could send its messages with the CAN identifier reserved for another node, which might lead to severe consequences. For example consider an environment where node A sends a temperature value, node B sends a velocity value, and node C opens a valve according to the temperature value from node A. If node B sends velocity values with the identifier of node A, node C misinterprets the velocity value as a temperature value. Masquerading failures in combination with diagnostic deficiencies of CAN are {{one of the reasons why}} today’s automotive breakdown logs do not assist the technician adequately in the <b>identification</b> <b>of</b> <b>faulty</b> Electronic Control <b>Units</b> (ECUs) [9, 18].|$|R
40|$|System-level fault {{diagnosis}} of massively parallel computers requires efficient algorithms, handling a many processing {{elements in a}} heterogeneous environment. Probabilistic {{fault diagnosis}} is an approach to make the diagnostic problem both easier to solve and more generally applicable. The {{price to pay for}} these advantages is that the diagnostic result is no longer guaranteed to be correct and complete in every fault situation. In an earlier paper [2] the authors presented a novel methodology, called local information diagnosis, and applied it to create a family of probabilistic diagnostic algorithms. This paper examines the <b>identification</b> <b>of</b> fault-free and <b>faulty</b> <b>units</b> in detail by defining three heuristic methods of fault classification and comparing the diagnostic accuracy provided by these heuristics using measurement results. Keywords: multiprocessor systems, system-level fault diagnosis, probabilistic algorithm...|$|R
40|$|Consider {{a network}} G of n units, {{each of which}} can be tested by those units from which there is a test connection. The outcome of each test is binary (good or faulty) and is the {{judgment}} of the testing unit on the tested unit. We present an algorithm for identifying the minimum number <b>of</b> <b>faulty</b> <b>units</b> based on the test outcomes. It works in time proportional to τ(G) m, provided the number <b>of</b> <b>faulty</b> <b>units</b> is no more than τ(G), where m is the number of test connections and τ(G) is a parameter of G such that if the number <b>of</b> <b>faulty</b> <b>units</b> is no more than τ(G), then they are uniquely identifiable...|$|R
40|$|A novel {{approach}} to the diagnosis of hypercubes, called Self-Validating Diagnosis, is introduced. An algorithm based on this approach, called SVD algorithm, is presented and evaluated. Given any fault set and the resulting syndrome, the algorithm returns a diagnosis and a syndrome-dependent bound, Ts, with the property that diagnosis is correct (although possibly incomplete) if the actual number <b>of</b> <b>faulty</b> <b>units</b> is less than Ts. The average of Ts is very large and the diagnosis is almost complete even when the percentage <b>of</b> <b>faulty</b> <b>units</b> in the system approaches 50 %. Moreover, the diagnosis correctness can be validated deterministically by individually probing {{a very small number}} of units. These results suggest that the SVD algorithm is suitable for applications requiring a large degree of diagnosability, as it is the case of wafer-scale testing of VLSI chips, where the percentage <b>of</b> <b>faulty</b> <b>units</b> may be as large as 50 %...|$|R
40|$|A novel {{approach}} to the diagnosis of hypercubes, called Self-Validating Diagnosis, is introduced. An algorithm based on this approach, called SVD algorithm, is presented and evaluated. Given any fault set and the resulting syndrome, the algorithm returns a diagnosis and a syndrome-dependent bound, To, with the property that diagnosis is correct (although possibly incomplete) if the actual number <b>of</b> <b>faulty</b> <b>units</b> is less than To...|$|R
40|$|In {{this paper}} we {{introduce}} a self-diagnosis algorithm for hypercube-connected systems. The algorithm produces a diagnosis which is provably correct {{if the number}} <b>of</b> <b>faulty</b> <b>units</b> in the system {{is less than a}} thereshold T&# 417; asserted by the algorithm itself. Although the diagnosis may be incomplete, simulations show that the expected number of unidentified units is very small. The application of the diagnosis strategy to the manufacturing test of VLSI chips is also considered...|$|R
40|$|Abstract—In this paper, we {{introduce}} a new model for diagnosable systems called t; k-diagnosable system which guarantees that at least k <b>faulty</b> <b>units</b> (processors) in a system are detected provided that the number <b>of</b> <b>faulty</b> <b>units</b> does not exceed t. This system includes classical one-step diagnosable systems and sequentially diagnosable systems. We prove a necessary and sufficient condition for 8 ̆ 5 t; k-diagnosable system, and discuss a lower bound for diagnosability. Finally, we deal with a relation between 8 ̆ 5 t; k-diagnosability and diagnosability of classical basic models. Index Terms—Fault diagnosis, PMC model, one-step t-diagnosis, sequential t-diagnosis, diagnosability, Cartesian product...|$|R
30|$|The present work {{considers}} {{the problem of}} building a connection assignment of the sensors in a WSN {{in order to ensure}} an energy-aware diagnosable system. The PMC model defines a system of n units as t-diagnosable if all <b>faulty</b> <b>units</b> can be diagnosed provided the number <b>of</b> <b>faulty</b> <b>units</b> does not exceed t [19] (t is also called the diagnosability of the system). In order to diagnose t units, the following conditions must hold: (c 1) the number n of units in the system must be {{greater than or equal to}} 2 t+ 1, and (c 2) a unit must be tested by at least t other units [19].|$|R
40|$|AbstractIn this paper, a {{comparison}} model is considered for multiprocessor fault diagnosis. In this approach, system tasks {{are assigned to}} pairs of processors (or units) {{and the results are}} compared. These agreements and disagreements among units are the basis for identifying <b>faulty</b> <b>units.</b> Such a system is said to be t 1 -diagnosable if, given any complete collection of comparison outcomes, the set <b>of</b> <b>faulty</b> <b>units</b> can be isolated to within a set of at most t 1 units, assuming that no more than t 1 <b>units</b> can be <b>faulty.</b> This paper shows an optimal O(|E|) algorithm (where |E| corresponds to the number of comparisons), by which, {{on the basis of the}} collection of comparison outcomes, all the <b>faulty</b> <b>units</b> except at most one can be correctly identified and all the <b>faulty</b> <b>units</b> can be isolated to within a set of t 1 or fewer units in which at most one can possibly be fault-free...|$|R
40|$|We {{present an}} {{efficient}} computational framework {{to quantify the}} impact of individual observations in four dimensional variational data assimilation. The proposed methodology uses first and second order adjoint sensitivity analysis, together with matrix-free algorithms to obtain low-rank approximations of ob- servation impact matrix. We illustrate the application of this methodology to important applications such as data pruning and the <b>identification</b> <b>of</b> <b>faulty</b> sensors for a two dimensional shallow water test system...|$|R
40|$|Abstract- The {{present day}} systems {{are in need}} of high level of fault {{tolerance}} in the Multicore processors without substantial loss of overall performance. The commodity processors that are available now have handled mainly soft errors (transient errors) and a very small amount of work is done for handling hard faults. In this paper we propose to include a Reconfigurable Hardware Unit (RHU) inside the core which can detect and isolate the faults in the functional units inside a core using stored test patterns. Once the <b>faulty</b> <b>unit</b> is isolated, a part of the RHU is reconfigured by loading stored configuration to perform the functions <b>of</b> the <b>faulty</b> <b>unit</b> and the register values <b>of</b> the <b>faulty</b> <b>unit</b> is forwarded to the reconfigured RHU. The test patterns and configurations should be stored in fast access non-volatile storage devices such as flash memory. This improved architecture will help to solve many fault tolerance issues with no visible loss of performance at low cost and space...|$|R
40|$|We {{propose a}} {{distributed}} disabling algorithm for a multiprocessing {{system in which}} each processor or unit is prevented from doing computation when it fails some number of tests by other units. The goal is to disable all <b>faulty</b> <b>units</b> and to enable all fault-free units. Specifically, a unit is disabled iff it fails d or more tests by enabled units (d-disabling rule). A multiprocessor system is c-correctable using the d-disabling ntle iff all <b>faulty</b> <b>units</b> are permanently disabled and all fault-free units are permanently enabled after {{a finite number of}} applications of the disabling rule, pro-vided there are no more than c <b>faulty</b> <b>units.</b> This models an unattended system where the removal <b>of</b> <b>faulty</b> <b>units</b> is done locally by simple and reliable circuitry. We give a sufficient condition for c-correctability in general systems and a necessary and sufficient condition in general systems where c <d. Then, we give necessary and sufficient conditions for c-correctability of two types of systems, (1) complete digraphs and (2) a new class of systems called segmented systems. I...|$|R
40|$|In {{the present}} paper a method for the <b>identification</b> <b>of</b> <b>faulty</b> stages in a {{multistage}} compressor is presented. The values of overall compressor parameters namely mass flow rate, pressure ratio and efficiency, at different operating points are the input data to the method. Employing these data the method gives the location and the number <b>of</b> <b>faulty</b> stages, {{as well as the}} amount of deviation from intact condition performance. It is shown that the kind of fault which has caused stage performance deterioration can be identified. Features of the method such as generality of applicability, input data requirement and reliability of the findings, are discussed...|$|R
40|$|Abstract — The {{continuously}} miniaturization of CMOS technology {{leads to}} increasing concerns regarding reliability. Thereby, challenges arise from temporary {{as well as}} permanent faults. Amongst the various methods proposed in order to diminish {{the impact of the}} latter, Alternating Module Activation (AMA) proved to be promising. The aim of this work is the presentation of the implementation of this approach in a proprietary RISC processor. Further, Built-In Self-Test (BIST) capability has been added in order to enable to <b>identification</b> <b>of</b> <b>faulty</b> blocks. Experiments indicate the feasibility of the approach...|$|R
40|$|Cascaded H-Bridge (CHB) {{converters}} can {{be directly}} connected to medium-voltage grids without using transformers and they possess the advantages of large capacity and low harmonics. They are significant tools for providing grid connections in large-capacity renewable energy systems. However, the reliability of a grid-connected CHB converter can be seriously influenced {{by the number of}} power switching devices that exist in the structure. This paper proposes a fault-tolerant control strategy based on double zero-sequence voltage injection and DC voltage optimization to improve the reliability of star-connected CHB converters after one or more power units have been bypassed. By injecting double zero-sequence voltages into each phase cluster, the DC voltages of the healthy units can be rapidly balanced after the <b>faulty</b> <b>units</b> are bypassed. In addition, optimizing the DC voltage increases the number <b>of</b> <b>faulty</b> <b>units</b> that can be tolerated and improves the reliability of the converter. Simulations and experimental results are shown for a seven-level three-phase CHB converter to validate the efficiency and feasibility of this strategy...|$|R
40|$|We {{present a}} new {{diagnosis}} algorithm (NDA) for regular interconnected structures. The diagnosis algorithm has time complexity O(kn) {{when applied to}} k-regular systems of n units. It provides a correct diagnosis, although incomplete. The diagnosis is correct if the number <b>of</b> <b>faulty</b> <b>units</b> is not above a specified bound T#, asserted by the algorithm itself. The correctness and completeness of NDA is studied through simulations on toroidal grids and hypercubes. Simulation results show that NDA provides a correct diagnosis even {{when the number of}} faults is very high (near half of the system size). The comparison between algorithm NDA and other diagnostic algorithms shows that NDA provides a better diagnosis, i. e., it has a higher degree of completeness than other diagnostic algorithms...|$|R
40|$|We {{propose a}} simple {{structure}} which provides optimal system-level fault diagnosis. Each unit {{of a system}} can diagnose itself using test outcomes generated within its associated structure. This property makes the structure suitable for systems in a distributed environment where no central processor exists for fault diagnosis. We present a simple diagnosis algorithm based on this structure. Furthermore, we show that the proposed structure always exists for every unit in a system whose graph connectiviq {{is not less than}} the number <b>of</b> <b>faulty</b> <b>units.</b> We provide some examples of applying this unit-diagnosis approach to such systems as Boolean N-cube, generalized hypercube and DeBrujin networks. Distributed diagnosis can, therefore, be efficiently done for these fault-tolerant systems with results superior to those previously obtained...|$|R
40|$|This paper {{presents}} techniques which base on {{the concept}} of flows thinning together with the identification techniques. These methods are proposed to determine the expected number of failures to assess the efficiency of technical diagnostics of instruments. Additionally, this research focuses on the improvement of multi-machine troubleshooting systems, based on the ‘AND-OR’ graphs. Respective algorithms are presented. The majority principle uses the input information to check the correctness of the decision regarding <b>identification</b> <b>of</b> <b>faulty</b> machines. In this paper we {{base on the}} complete testing algorithm for elements of multi-computer complexes searching by criteria of failed element...|$|R
40|$|This paper {{presents}} a topologically based theoretical background for desiening tests for <b>identification</b> <b>of</b> <b>faulty</b> pararrleter values in linear subnetworks. Nodal voltages arc {{assumed to be}} ohtainableither bv measurements or, indirectlv, {{as a result of}} a nodal fault analysis. A formulatiorr of nodal fault analvsis for subnctworks is prcscnted. It 'I'hc is shown how this approach can be used to evaluatc faultv clcments within in:rccessible <b>faulty</b> subnetw,orks. objective <b>of</b> this work is the reduction of the number of required currcnt excitations and, theieby, the number of voltage measurements. l-he Coates flow-graph representation of a network is uscd. I...|$|R
40|$|We {{consider}} {{problems of}} fault diagnosis in multiprocessor systems. Preparata, Metze and Chien (1967) introduced a graph theoretical model for system-level diagnosis, in which processors perform tests {{on one another}} via links in the system. Faultfree processors correctly identify the status of tested processors, while the faulty processors can give arbitrary test results. The goal is to identify faulty processors based on the test results. A system {{is said to be}} t-diagnosable if <b>faulty</b> <b>units</b> can be identified, provided the number <b>of</b> <b>faulty</b> <b>units</b> present does not exceed t. We explore here diagnosis problems for n-cube systems and give bounds for diagnosability of the n-cube. We also describe a simple diagnosis algorithm A which is linear in time and which can be used for sequential diagnosis as well as for incomplete diagnosis in one step. In particular the algorithm applied to arbitrary topology based interconnection systems G with N processors improves previously known ones. It has sequential diagnosability tA(G) ≥ ⌈ 2 N 1 2 ⌉ − 3, which is optimal in the worst case. ...|$|R
40|$|Comput., 1975, pp. 167 - 170] if, given a {{syndrome}} (complete {{collection of}} test results), the set <b>of</b> <b>faulty</b> <b>units</b> can be isolated {{to within a}} set of at most + units, assuming that at most units in the system are faulty. This paper presents a methodology for determining when a unit v can belong to an allowable fault set of cardinality at most t. Based on this methodology, for a given syndrome in a t/(t+ 1) -diagnosable system, the authors establish a necessary and sufficient condition for a vertex v to be long to an allowable fault set of cardinality at most and certain properties of t/(t+ 1) -diagnosable systems. This condition leads to an o(na’ 5) t/(t+ 1) -diagnosis algorithm. This t/(t+ 1) diagnosis algorithm complements the /(t+ 1) -diagnosability algorithm of Sullivan [The complexity of system-leve...|$|R
40|$|Self-diagnosis of multi-unit {{digital system}} is reconsidered {{following}} hypotheses: 1) Faults are not equal probable. Each unit {{of a system}} has associated its own probability of failure. Unit malfunctions {{are assumed to be}} statistically independent. 2) The outcomes of tests perforned between units are not deterministic. They are characterized by their conditional probability for any possible status of testing and tested unit. Attemption is restricted to the case where test results are independent of one another. Given a set of test results, the problem of finding the most likely set <b>of</b> <b>faulty</b> <b>units</b> (probabilistic one-step diagnosability) is considered here. Moreover an approach to probabilistic diagnosability with repair is presented. It is shown that there exists a significant class of systems for which this problem is easily solved and a decoding procedure is given whose complexity is O(n) where n is the number of system units...|$|R
40|$|This {{publication}} {{is a work}} of the U. S. Government {{as defined}} in Title 17, United States Code, Section 101. As such, it is in the public domain, and under the provisions of Title 17, United States Code, Section 105, may not be copyrighted. Proceedings of the 26 th Annual Allerton Conference on Communication, Control, and Computing, Sept. 1988, regular (full) paper, pp. 408 - 416 (Unrefereed) We propose a distributed disabling algorithm for a multiprocessing system in which each processor or unit is prevented from doing computation when it fails some number of tests by other units. The goal is to disable all <b>faulty</b> <b>units</b> and to enable all fault-free units. Specifically, a unit is disabled if it fails d or more tests by enabled units (d-disabling rule). A multiprocessor system is c-correctable using the d-disabling rule if all <b>faulty</b> <b>units</b> are permanently disabled and all fault-free units are permanently enabled after a finite number of applications of the disabling rule, provided there are no more thna c <b>faulty</b> <b>units.</b> This models an unattended system where the removal <b>of</b> <b>faulty</b> <b>units</b> is done locally by simple and reliable circuitry. We give a sufficient condition for c-correctability in general systems and a necessary and sufficient condition in general systems where c < d. Then, we give necessary and sufficient conditions for c-correctability of two types of systems, (1) complete digraphs and (2) a new class of systems called segmented systems...|$|R
40|$|AbstractWe {{consider}} {{problems of}} fault diagnosis in multiprocessor systems. Preparata, Metze and Chien [F. P. Preparata, G. Metze, R. T. Chien, On the connection assignment problem of diagnosable systems, IEEE Trans. Comput. EC 16 (12) (1967) 848 – 854] introduced a graph theoretical model for system-level diagnosis, in which processors perform tests {{on one another}} via links in the system. Fault-free processors correctly identify the status of tested processors, while the faulty processors can give arbitrary test results. The goal is to identify faulty processors based on the test results. A system {{is said to be}} t-diagnosable if <b>faulty</b> <b>units</b> can be identified, provided the number <b>of</b> <b>faulty</b> <b>units</b> present does not exceed t. We explore here diagnosis problems for n-cube systems and give bounds for diagnosability of the n-cube. We also describe a simple diagnosis algorithm A which is linear in time and which can be used for sequential diagnosis as well as for incomplete diagnosis in one step. In particular, the algorithm applied to arbitrary topology based interconnection systems G with N processors improves previously known ones. It has sequential diagnosability tA(G) ≥⌈ 2 N 12 ⌉− 3, which is optimal in the worst case...|$|R
40|$|A novel first-principles-based {{expert system}} is {{proposed}} for on-line detection and <b>identification</b> <b>of</b> <b>faulty</b> component candidates during incipient off-normal process operations. The system performs function-oriented diagnostics {{and can be}} reused for diagnosing single-component failures in different processes and different plants through the provision of the appropriate process schematics information. The function-oriented and process-independent diagnostic features of the proposed expert system are achieved by constructing a knowledge base containing three distinct types of information, qualitative balance equation rules, functional classification of process components, and the process piping and instrumentation diagram. The various types of qualitative balance equation rules for processes utilizing single-phase liquids are derived and their usage is illustrated through simulation results of a realistic process in a nuclear power plant...|$|R
40|$|Multiprocessor arrays {{have the}} {{property}} of regularity, enabling a low-cost VL 81 implementation. However, multiprocessor systems with a fixed structure tend to be error prone and restricted to specialized applications, which makes them less attractive to the semiconductor industry. Consequently, reconfigurability and fault-tolerance are desirable features of a multiprocessor array. A multiprocessor array with a flexible structure {{can be adapted to}} many applications and may restructure itself upon failure of a processor, to avoid using faulty processors. The objective of this work is to demonstrate the feasibility of a multiprocessor array having these properties. An example of such an array is introduced, and distributed structuring algorithms for it are presented. A novel strategy for internal testing and for <b>identification</b> <b>of</b> <b>faulty</b> processors is developed, and the structuring algorithms are modified to accommodate faulty processors...|$|R
50|$|Distribution of the {{propulsion}} {{among the}} cars also {{results in a}} system that is less vulnerable to single-point-of-failure outages. Many classes of DMU are capable <b>of</b> operating with <b>faulty</b> <b>units</b> still in the consist. Because of the self-contained nature of diesel engines, {{there is no need to}} run overhead electric lines or electrified track, which can result in lower system construction costs.|$|R
40|$|Abstract—Due {{to their}} loose {{coupling}} and highly dynamic nature, service-oriented systems offer many benefits for realizing fault tolerance and supporting trustworthy computing. They enable automatic system reconfiguration in case that a faulty service is detected. Spectrum-based fault localization (SFL) is a statistics-based diagnosis technique that can effectively {{be applied to}} pinpoint problematic services. It works by monitoring service usage in system transactions and comparing service coverage with pass/fail observations. SFL exhibits poor performance in diagnosing faulty services in cases when services are tightly coupled. In this paper, we study how and to which extent an increase in monitoring granularity can help to improve correct diagnosis <b>of</b> tightly coupled <b>faulty</b> services. We apply SFL in a real service-based system, for which we show that 100 % correct <b>identification</b> <b>of</b> <b>faulty</b> services can be achieved through {{an increase in the}} monitoring granularity. Keywords-residual defect, fault localization, online monitoring, simulator, service framework; I...|$|R
40|$|This thesis {{consists}} of two relate but self-sustaining parts. In Part I a new diagnosability measure, t/ $-$ 1 -diagnosability, is proposed for interconnected systems. This new diagnosability assures that all <b>faulty</b> <b>units,</b> except for at most one, can be correctly identified in one step, {{as long as the}} total number <b>of</b> <b>faulty</b> <b>units</b> does not exceed t. The class of t/ $-$ 1 -diagnosable systems is fully characterized. A polynomial algorithm is presented for determining the degree of t/ $-$ 1 -diagnosability for any given system. A polynomial diagnosis algorithm is also given for any t/ $-$ 1 -diagnosable systems. It is shown that the degree of t/ $-$ 1 -diagnosability could be twice as large as the degree of t-diagnosability for a given system. In Part II a probabilistic diagnosis algorithm is presented for constant degree structures such as grids. It is shown that almost all <b>faulty</b> <b>units</b> can be correctly identified under a binomial failure distribution even when the probability of failure is rather high. The performance is very insensitive to yield variations under a negative binomial failure distribution. The application of this algorithm to the production testing of chips and wafers is explored. A simple test structure is provided for wafer testing, which utilizes the test access port of each die to facilitate comparison testing. The diagnosis algorithm is localized and incorporated into the test structure to determine the status of each die. The scheme is unique in that it is shown to work well when faults are clustered and even when the yield is low...|$|R
40|$|International audienceFuture chip multiprocessors (CMPs) will {{be capable}} <b>of</b> deconfiguring <b>faulty</b> <b>units</b> {{in order to}} permit {{continued}} operation {{in the presence of}} wear-out failures. However, the unforeseen downside is pipeline imbalance due to other portions of the pipeline now being overprovisioned with respect to the deconfigured functionality. We propose PowerTransfer, a novel CMP architecture that dynamically redistributes the chip power under pipeline imbalances that arise from deconfiguring <b>faulty</b> <b>units.</b> Through rebalancing – achieved by temporary, symbiotic deconfiguration of additional functionality within the degraded core – power is harnessed for use elsewhere on the chip. This additional power is dynamically transferred to portions of the multi-core chip that can realize a performance boost from turning on previously dormant microarchitectural features. We demonstrate that a realistic PowerTransfer manager achieves chip-wide performance improvements of up to 25 % compared to architectures that simply deconfigure <b>faulty</b> <b>units</b> without regard to the resulting inefficiency...|$|R
30|$|As in any data {{gathering}} task relying on volunteer user contributions, {{there is a}} risk <b>of</b> <b>faulty</b> input by human errors or even service misuse. The risk of misuse may be even higher when no registration to the service is required and the abusers cannot be tracked. It is important to determine the quality of user observations, especially when using the data for evaluating and validating predictive models or as ground-truth data for reference. During the performed pilot trials, no service misuse was detected, and no actions to remedy that kind of activity were necessary. Obvious test uses of the system were detected manually, but in the future some automatic <b>identification</b> <b>of</b> <b>faulty</b> or accidental observations should be implemented to improve the data quality. For example, Alabri and Hunter ([2010]) describe a framework combining data quality control and trust metrics to enhance the reliability of citizen science data, and Kuan et al. ([2010]) as well as Yang et al. ([2011]) propose reputation management systems to evaluate the trustworthiness of gathered data by co-observers and data end-users.|$|R
40|$|Major dams in {{the world}} are often {{instrumented}} in order to validate numerical models, to gain insight into the behavior of the dam, to detect anomalies, and to enable a timely response either in the form of repairs, reservoir management, or evacuation. Advances in automated data monitoring system makes it possible to regularly collect data on a large number of instruments for a dam. Managing this data is a major concern since traditional means of monitoring each instrument are time consuming and personnel intensive. Among tasks that need to be performed are: <b>identification</b> <b>of</b> <b>faulty</b> instruments, removal <b>of</b> outliers, data interpretation, model fitting and management of alarms for detecting statistically significant changes in the response of a dam. Statistical models such as multiple linear regression, and back propagation neural networks have been used to estimate the response of individual instruments. Multiple linear regression models are of two kinds, (1) Hydro-Seasonal-Time (HST) models and (2) models that consider concrete temperatures as predictors. Univerariate, bivariate, and multivariate methods are proposed for the <b>identification</b> <b>of</b> anomalies in the instrumentation data. The source of these anomalies can be either bad readings, faulty instruments, or changes in dam behavior. The proposed methodologies are applied to three different dams, Idukki, Daniel Johnson and Chute-a-Caron, which are respectively an arch, multiple arch and a gravity dam. Displacements, strains, flow rates, and crack openings of these three dams are analyzed. This research also proposes various multivariate statistical analyses and artificial neural networks techniques to analyze dam monitoring data. One of these methods, Principal Component Analysis (PCA) is concerned with explaining the variance-covariance structure of a data set through a few linear combinations of the original variables. The general objectives are (1) data reduction and (2) data interpretation. Other multivariate analysis methods such as canonical correlation analysis, partial least squares and nonlinear principal component analysis are discussed. The advantages of methodologies for noise reduction, the reduction of number of variables that have to be monitored, the prediction of response parameters, and the <b>identification</b> <b>of</b> <b>faulty</b> readings are discussed. Results indicated that dam responses are generally correlated and that only a few principal components can summarize the behavior of a dam...|$|R
40|$|International audienceTo {{efficiently}} {{control a}} process, accurate sensor measurements {{must be provided}} of the signals used by the controller to decide which actions to actuate {{in order to maintain}} the system in the desired conditions. Noisy or faulty sensors must, then, be promptly detected and their signals corrected in order to avoid wrong control decisions. In this work, sensor diagnostics is tackled within an ensemble of Principal Component Analysis (PCA) models whose outcomes are aggregated by means of a local fusion (LF) strategy. The aggregated model thereby obtained is used for both the early detection and <b>identification</b> <b>of</b> <b>faulty</b> sensors, and for correcting their measured values. The fault detection decision logic is based on the Sequential Probability Ratio Test (SPRT). The proposed approach is demonstrated on a simulated case study concerning the pressure and level control in the pressurizer of a Pressurized Water Reactor (PWR). The obtained results show the possibility to achieve an adequate control of the process even when a sensor failure occurs...|$|R
40|$|AbstractThis paper proposes fault {{detection}} and classification scheme for transmission line protection using WT and {{linear discriminant analysis}} (LDA). Current signals of each phase are used for the detection and <b>identification</b> <b>of</b> <b>faulty</b> phases and zero sequence currents are used {{for the detection of}} ground. Current signals are processed using discrete wavelet transform with DB- 4 wavelet up to level 3. Approximate coefficients are reconstructed using wavelet reconstruction. Performance of the proposed based scheme is tested by variations of parameters such as fault type, location, fault resistance, fault inception angle and power flow angle. The scheme is applicable for both single circuit and double circuit transmission line. All shunt faults and multi-location faults which occur in different locations at the same time are also detected and classified by the proposed scheme within one cycle time. The simulation results show that the proposed scheme is not affected by non-linear high impedance fault and CT saturation...|$|R
