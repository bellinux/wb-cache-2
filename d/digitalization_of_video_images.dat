0|10000|Public
40|$|We {{study the}} flow behind {{an array of}} equally spaced {{parallel}} cylinders. A system of Stuart-Landau equations with complex parameters is used to model the oscillating wakes. Our purpose is to identify the 6 scalar parameters which most accurately reproduce the experimental data of Chauve and Le Gal [Physica D 58, pp 407 [...] 413, (1992) ]. To do so, we perform a computational search for the minimum of a distance. We define as the sum-square difference of the data and amplitudes reconstructed using coupled equations. The search algorithm is made more efficient {{through the use of}} a partially analytical expression for the gradient ∇ J. Indeed ∇ J can be obtained by the integration of a dynamical system propagating backwards in time (a backpropagation equation for the Lagrange multipliers). Using the parameters computed via the backpropagation method, the coupled Stuart-Landau equations accurately predicted the experimental data from Chauve and Le Gal over a correlation time of the system. Our method turns out to be quite robust as evidenced by using noisy synthetic data obtained from integrations of the coupled Stuart-Landau equations. However, a difficulty remains with experimental data: in that case the several sets of identified parameters are shown to yield equivalent predictions. This is due to a strong discretization or "round-off" error arising from the <b>digitalization</b> <b>of</b> the <b>video</b> <b>images</b> in the experiment. This ambiguity in parameter identification has been reproduced with synthetic data subjected to the same kind of discretization. Comment: 25 pages uuencoded compressed PostScript file (58 K) with 13 figures (155 K in separated file) Submitted to Physica...|$|R
30|$|About a one-second delay <b>of</b> <b>video</b> {{and sound}} occurs, due to {{encoding}} and decoding <b>of</b> <b>video</b> <b>images</b> 3 times.|$|R
50|$|A method <b>of</b> {{segmentation}} <b>of</b> <b>video</b> <b>images</b> involving identification <b>of</b> object contours and segmenting contours {{using an}} estimation of weighted length of contour segments.|$|R
30|$|At continuation, {{results of}} {{implementation}} for proposed algorithm {{on the number}} <b>of</b> <b>video</b> <b>image</b> sequences is presented specially under complicated condition on the MATLAB software environment.|$|R
50|$|Video editing is the {{manipulation}} and arrangement <b>of</b> <b>video</b> <b>images.</b> <b>Video</b> editing {{is used to}} structure and present all video information, including films and television shows, video advertisements and video essays. Video editing has been dramatically democratized {{in recent years by}} editing software available for personal computers.|$|R
50|$|In {{order to}} {{increase}} the resolution <b>of</b> <b>video</b> <b>images,</b> therefore, new schemes have been created that capture full-frame images for each frame. <b>Video</b> composed <b>of</b> such frames is called progressive scan video.|$|R
40|$|In {{low light}} environment, the {{surveillance}} <b>video</b> <b>image</b> has lower contrast ， less information and uneven brightness. To solve this problem, this paper puts forward a contrast resolution compensation algorithm based on human visual perception model. It extracts Y component from the YUV <b>video</b> <b>image</b> acquired by camera originally to subtract contrast feature parameters, then makes a proportional integral type contrast resolution compensation for low light pixels in Y component and makes index contrast resolution compensation for high light pixels adaptively to enhance brightness <b>of</b> the <b>video</b> <b>image</b> while maintains the U and V components. Then it compresses the <b>video</b> <b>images</b> and transmits them via internet. Finally, it decodes and displays the <b>video</b> <b>image</b> on the device of intelligent surveillance system. The experimental results show that, the algorithm can effectively improve the contrast resolution <b>of</b> the <b>video</b> <b>image</b> {{and maintain the}} color <b>of</b> <b>video</b> <b>image</b> well. It also can meet the real-time requirement <b>of</b> <b>video</b> monitoring...|$|R
50|$|<b>Video</b> or <b>image</b> jitter {{occurs when}} the {{horizontal}} lines <b>of</b> <b>video</b> <b>image</b> frames are randomly displaced due to the corruption of synchronization signals or electromagnetic interference during video transmission. Model based dejittering study {{has been carried out}} under the framework of digital image/video restoration.|$|R
5000|$|... •TRAVIS, A. R. L. 1997. The display <b>of</b> {{three-dimensional}} <b>video</b> <b>images.</b>|$|R
40|$|This paper {{presents}} a fast algorithm for de-interlacing <b>of</b> <b>video</b> <b>images</b> using a shortest path technique. The algorithm applies dynamic programming techniques {{to find a}} shortest path in a cost matrix. The motion information obtained from this shortest path is used to re-align the fields <b>of</b> a <b>video</b> <b>image.</b> By using the shortest path via dynamic programming, the motion information estimated is more reliable than simply performing a search in a local neighbourhood. A variety of real images have been tested, and good results have been obtained...|$|R
40|$|The 90 degree {{rotation}} {{is important}} for the geometrical transformation <b>of</b> the <b>video</b> <b>image.</b> This paper describes a functional memory for the 90 degree rotation <b>of</b> <b>video</b> <b>image.</b> The functional memory consists of a memory cell array, data registers, data selectors, address decoders and a address buffer. Their components are designed by use of MOS FET. Especially, the memory cell is designed in a DRAM structure. The chip area of the memory cell is about two times compared to the one of a conventional DRAM cell...|$|R
40|$|Includes bibliographical {{references}} (leaf 33) Recently, Field Programmable Gate Array (FPGA) {{technology has}} become a viable target {{for the implementation of}} algorithms suited to <b>video</b> <b>image</b> processing applications. The unique architecture of the FPGA has allowed the technology to be used in many such applications encompassing all aspects <b>of</b> <b>video</b> <b>image</b> processing. (See more in text. ...|$|R
40|$|The general {{capabilities}} of the Langley Research Center Data Visualization and Animation Laboratory is described. These capabilities include digital image processing, 3 -D interactive computer graphics, data visualization and analysis, video-rate acquisition and processing <b>of</b> <b>video</b> <b>images,</b> photo-realistic modeling and animation, video report generation, and color hardcopies. A specialized <b>video</b> <b>image</b> processing system is also discussed...|$|R
40|$|Based on the {{interpretation}} <b>of</b> vertical <b>video</b> <b>images</b> taken from an helicopter, a geornorphological {{survey of the}} coast of Isla del Carmen, Campeche, was made in connection with hurricane "Roxanne" Geomorphological processes and derived coastal fandforms are identified, which indicate a general receding trend of the coastline during the event, although some local accumulative features are recognized. The most affected areas correspond to ancient channels, today closed, reactivated during extraordinary storm events. Some conclusions area also drawn {{in relation to the}} use <b>of</b> <b>video</b> <b>images</b> as a tool for a rapid assessment and detection of damages to infrastructure...|$|R
40|$|The {{traditional}} moving object extraction method {{based on}} Gaussian model has such defects as poor anti-noise performance, bad real-time performance. Considering these shortcomings, this paper propo s ed a new moving object extraction method for color <b>video</b> <b>image</b> based on regional kernel histogram. The method first proposed {{the idea of}} kernel histogram description theory which utilizing the kernel histogram to describe the area <b>of</b> <b>video</b> <b>image.</b> Then a new metric function for measuring the kernel histogram model is proposed. According to the features of measurement values, using the Gaussian mixture model and the metric of kernel histogram model to build the model. At last, based on this model, the moving object <b>of</b> <b>video</b> <b>images</b> is extracted. The experimental {{results show that the}} algorithm have a better segmentation result and have the better anti-noise and real-time performance compared with the traditional Gaussian mixture model algorithm...|$|R
40|$|Interior flow fields under {{drastically}} transform-ing solitary waves were visualized {{and recorded}} using a high-speed video system. Flow velocities were estimated by tracing fluid particles through spatial correlation analysis <b>of</b> <b>video</b> <b>images.</b> A Lagrangian equation system was successfully employed to numerically simulate two-dimensional wave transformations in a vertical plane...|$|R
40|$|A software/hardware system {{designed}} and developed to perform automated video imagery analysis is described. Major elements {{included in the}} analysis system are: (1) sampling oscilloscope; (2) programmable trigger unit; (3) central computer; and (4) software processing library. The function of the scope and trigger unit, in conjunction with the control computer, is to digitize the selected portion <b>of</b> the <b>video</b> <b>image</b> and store as amplitude and time data in computer memory. Evaluation <b>of</b> the <b>video</b> data, analogus to interpretation of a visual image, is accomplished by the processing software. It is indicated that this technique <b>of</b> <b>video</b> <b>image</b> analysis is applicable {{to a wide variety of}} nonaerospace applications involving <b>video</b> data and <b>image</b> analysis...|$|R
40|$|Currently, {{there is}} a rapid {{development}} in the techniques of the automated image based modelling (IBM), especially in advanced structure-from-motion (SFM) and dense image matching methods, and camera technology. One possibility is to use video imaging to create 3 D reality based models of cultural heritage architectures and monuments. Practically, video imaging {{is much easier to}} apply when compared to still image shooting in IBM techniques because the latter needs a thorough planning and proficiency. However, one is faced with mainly three problems when <b>video</b> <b>image</b> sequences are used for highly detailed modelling and dimensional survey of cultural heritage objects. These problems are: the low resolution <b>of</b> <b>video</b> <b>images,</b> the need to process a large number <b>of</b> short baseline <b>video</b> <b>images</b> and blur effects due to camera shake on a significant number of images. In this research, the feasibility <b>of</b> using <b>video</b> <b>images</b> for efficient 3 D modelling is investigated. A method is developed to find the minimal significant number <b>of</b> <b>video</b> <b>images</b> in terms <b>of</b> object coverage and blur effect. This reduction in <b>video</b> <b>images</b> is convenient to decrease the processing time and to create a reliable textured 3 D model compared with models produced by still imaging. Two experiments for modelling a building and a monument are tested using a <b>video</b> <b>image</b> resolution <b>of</b> 1920 × 1080 pixels. Internal and external validations of the produced models are applied to find out the final predicted accuracy and the model level of details. Related to the object complexity and video imaging resolution, the tests show an achievable average accuracy between 1 – 5 cm when using video imaging, which is suitable for visualization, virtual museums and low detailed documentation...|$|R
40|$|The {{invention}} {{relates to}} {{a method of}} detecting manipulations <b>of</b> digital <b>video</b> stream data, wherein the video stream data represents a sequence (17) <b>of</b> <b>video</b> <b>images</b> comprising at least one moving object that moves relatively to other objects and/or relatively to a background scenery and wherein the method comprises: a) detecting {{the at least one}} moving object from the video stream data, b) identifying (19) a kinematic model (21) which describes the movement of the moving object, c) determining (23) deviations of the movement which is performed by the moving object according to the video stream data and of a modelled movement which should have been performed by the moving object according to the kinematic model (21), d) deciding (25) if the deviations indicate a manipulation <b>of</b> the <b>video</b> stream data. In particular, the sequence (17) <b>of</b> <b>video</b> <b>images</b> may be obtained by decompressing (15) compressed video stream data...|$|R
50|$|He is {{co-author}} <b>of</b> Digital <b>video</b> <b>image</b> {{quality and}} perceptual coding, (with H.R. Wu) (Taylor and Francis 2006).|$|R
40|$|We {{propose a}} {{sharpness}} enhancement technique for <b>video</b> and decoded <b>image</b> sequences. Basically, the enhancement {{is accomplished by}} adding overshoot to luminance edges in an Unsharp Masking-like way. However, the optimal amount of overshoot added for a high image quality depends on the local image statistics. For this purpose, controls are introduced, to improve the performances and to adapt the operator to moving sequences with different characteristics. Both spatial and temporal information is used to enhance details, avoiding blocking artifacts and noise. 1 Introduction In scenarios where TV and PC systems merge their functionality, especially in home environment, high-quality displaying <b>of</b> <b>video</b> <b>images</b> in PC architectures becomes a challenging issue for industries oriented to the consumer market. Among the main topics in such a field, improving the low sharpness <b>of</b> <b>video</b> <b>images</b> {{is probably the most}} interesting feature for the end-user, who usually compares the sharpness of images di [...] ...|$|R
40|$|This thesis {{examines}} the influence <b>of</b> <b>video</b> surveillance <b>images</b> on institutional practices. The three institutions examined are police, private businesses and the courts. The research is theoretically grounded by the orienting {{concept of the}} surveillant assemblage. The research found that the three institutions {{are influenced by the}} availability <b>of</b> <b>video</b> surveillance <b>images.</b> Impacts included changes in workload and institutional restructuring. Furthermore, institutions external to those examined also influenced the use <b>of</b> <b>video</b> surveillance <b>images.</b> Each institution was found to use the <b>video</b> surveillance <b>images</b> for various purposes and to represent the images in particular ways {{to make use of the}} information provided. The research has also contributed to the refinement of the concepts of the surveillant assemblage, data-double, and function creep...|$|R
40|$|This {{proposal}} encompasses {{an objective}} video quality measurement method to automatically measure the perceived {{quality of a}} stream <b>of</b> <b>video</b> <b>images.</b> The method {{is based on a}} combined measure of distortioninvisibility, block-fidelity, and content richness fidelity. There is a need for automatic and objective video quality measurement method that is able to emulate the human vision to detect the perceived quality <b>of</b> a <b>video</b> stream. Traditionally, video quality is performed via a subjective test where a large number of human subjects are used to gauge the quality <b>of</b> a <b>video</b> but this process is not only time-consuming but and tedious and expensive to perform. This proposal describes an objective video quality measurement method for automatically gauging the perceived quality of a stream <b>of</b> <b>video</b> <b>images</b> using a combined feature of distortion-invisibility, block-fidelity, and content richness fidelity. It basically replaces the need of a subjective test {{in order to be able}} to gauge the perceived quality <b>of</b> a <b>video</b> stream. 2...|$|R
30|$|This {{system has}} a {{capability}} <b>of</b> transmitting <b>video</b> <b>images</b> and stereo sound with quality almost {{as high as}} TV broadcasting.|$|R
40|$|Research {{has shown}} how {{incumbent}} firms in content- based industries (e. g. music, news and photography) were radically affected by digitalization as powerful digital platforms emerged as new loci of innovation. While scholars {{have suggested that}} digital technology calls for novel organizing logics and value creation processes, {{there is a need}} for further knowledge of what characterizes them, and how they emerge in practice. In addressing this gap we studied United Screens, a firm that capitalizes on the <b>digitalization</b> <b>of</b> <b>video</b> contents by managing major YouTubers and connecting them with advertisers. The study shows how United Screens leverages the layered modularity of digital product architectures for new constellation- based modes of value co-creation. Overall, the paper contributes to research on digital innovation by shedding light on how a novel actor category champions content-driven value creation, an underexplored aspect of digital platform ecosystems...|$|R
40|$|Solid-state {{cameras and}} {{computer-controlled}} image-acquisition system measure deformations of wind-tunnel models. Digital video model-deformation (VMD) system includes solid-state-array cameras and digital image-acquisition system controlled by personal computer. Eliminates both vibration-induced distortion associated with tube cameras and manual processing <b>of</b> <b>video</b> hardcopy <b>images</b> necessary in earlier version. AT-class personal computer controls two commercially available image-capture boards ganged to capture simultaneously two <b>video</b> <b>images,</b> each 752 picture elements wide and 480 picture elements high, in one-thirtieth <b>of</b> second. <b>Video</b> <b>images</b> digitized into 256 gray levels. Figure block diagram of system...|$|R
30|$|The {{so-called}} video segmentation is {{to separate}} the object or objects in video sequences that are important or {{people are interested in}} (Video Object; VO) from the background, or that is to draw respectively consistent attributes of each area and, at the same time, to distinguish the background and foreground regions. <b>Video</b> <b>images</b> can be regarded as a kind of 3 D image. In other words, the <b>video</b> <b>image</b> is composed <b>of</b> a series of time-continuous 2 D images. From the perspective <b>of</b> spatial segmentation, <b>video</b> <b>image</b> segmentation is mainly the use of both the spatial and temporal information to pick out the independent motion regions <b>of</b> the <b>video</b> <b>image</b> in a frame by frame detection [25]. Video segmentation is the premise and foundation <b>of</b> other <b>video</b> <b>image</b> processing, such as video coding, video retrieval, and video database operation. The segmentation quality has a direct impact on the work of the late. So, the research <b>of</b> <b>video</b> segmentation technology is important and challenging.|$|R
30|$|Integrity <b>of</b> <b>Videos.</b> <b>Image</b> data {{coming from}} a camera can be {{intentionally}} modified by an attacker during transmission or when stored in a database. Using checksums and digital signatures, data integrity can be ensured. An often overlooked issue is that integrity protection is not only important for single frames but also for sequences. Simple reordering of images can substantially change the meaning <b>of</b> a <b>video.</b>|$|R
30|$|As for {{the actual}} talking head image synthesis, this can be {{produced}} {{using a variety of}} techniques, typically based on manipulation <b>of</b> <b>video</b> <b>images</b> [8, 9] parametrically deformable models of the human face and/or speech organs [10, 11] or as a combination thereof [12]. In our system we employ a deformable 3 D model (see Section 2) for reasons of speed and simplicity.|$|R
40|$|Enhancement <b>of</b> <b>video</b> <b>images</b> was {{proposed}} {{as an aid}} for the visually impaired, and was shown to be effective using the Adaptive Enhancement algorithm in optical simulations (Peli and Peli, 1984), and in computational simulations of static images (Peli, et al., 1991). The same adaptive enhancement was demonstrated to improve recognition of static, black and white images of faces for patients with centra...|$|R
40|$|Digital {{compression}} <b>of</b> <b>video</b> <b>images</b> is {{a possible}} avenue for high definition television (HDTV) transmission. Compression needs to be optimized while picture quality remains high. Two techniques for compression the digital images are explained and comparisons are drawn between the human vision system and artificial compression techniques. Suggestions for improving compression algorithms {{through the use of}} neural and analog circuitry are given...|$|R
40|$|Recent {{past has}} {{witnessed}} rapid growth on the usage <b>of</b> CCTV and <b>video</b> camera to beep up security {{in almost all}} aspects of life. This has resulted in tremendous growth <b>of</b> <b>video</b> content and its processing time. One of the challenges faced {{in this area is}} fast and efficient processing of these huge contents <b>of</b> <b>video</b> <b>images.</b> Therefore, integrating the principles of parallelism with the processing <b>of</b> the <b>video</b> <b>images</b> techniques has almost become mandatory for extraction of the desired information and achieving better performance. In this paper, a parallel algorithm has been proposed for extraction of person features from video frames that can execute on a cluster of workstations. The person behaviors are classified using Minimum distance classifier by the extracted feature vector. The algorithm has been implemented using MPI to estimate the time complexity and efficiency...|$|R
50|$|Using IMA bus, Tseng {{created the}} {{category}} <b>of</b> mainstream motion <b>video</b> accelerator {{with a series}} <b>of</b> <b>video</b> <b>image</b> processing circuits, branded VIPeR. VIPeR chips provided relatively high quality live and computer generated video. The chips were used in on high-end video solutions from companies like Matrox and Jazz Multimedia. Competitors integrated less elegant algorithms inside their mainstream graphics controllers - a trend Tseng followed with its latter generation of chips.|$|R
40|$|A new hand gesture {{recognition}} method {{based on}} Input– Output Hidden Markov Models is presented. This method {{deals with the}} dynamic aspects of gestures. Gestures are extracted from a sequence <b>of</b> <b>video</b> <b>images</b> by tracking the skin–color blobs corresponding to the hand into a body– face space centered {{on the face of}} the user. Our goal is to recognize two classes of gestures: deictic and symbolic. 1...|$|R
40|$|This paper {{presents}} a wearable groupware {{system designed to}} enhance the communication and cooperation of highly mobile network technicians. It provides technicians in the field with the capabilities for real-time audio-conferencing, transmission <b>of</b> <b>video</b> <b>images</b> back to the office, and context-sensitive access to a shared notebook. An infrared location-tracking device allows for the automatic retrieval of notebook entries depending on the user’s current location. 1...|$|R
40|$|Thesis (PhD (Mathematical Sciences. Applied Mathematics)) [...] University of Stellenbosch, 2006. This thesis {{addresses}} {{the problem of}} bulding a video-based traffic monitoring system. We employ clustering, trackiing and three-dimensional reconstruction of moving objects over a long image sequence. We present an algorithms that robustly recovers the motion and reconstructs three-dimensional shapes from a sequence <b>of</b> <b>video</b> <b>images,</b> Magaia et al [91]. The problem [...] ...|$|R
