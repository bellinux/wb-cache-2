19|146|Public
40|$|Empirically validating new 3 D-printing related {{algorithms}} and implementations requires testing data {{representative of}} inputs {{encountered in the}} wild. An ideal benchmarking dataset should not only draw from the same distribution of shapes people print in terms of class (e. g., toys, mechanisms, jewelry), representation type (e. <b>g.,</b> <b>triangle</b> soup meshes) and complexity (e. g., number of facets), but should also capture problems and artifacts endemic to 3 D printing models (e. g., self-intersections, non-manifoldness). We observe that the contextual and geometric characteristics of 3 D printing models differ significantly from those used for computer graphics applications, not to mention standard models (e. g., Stanford bunny, Armadillo, Fertility). We present a new dataset of 10, 000 models collected from an online 3 D printing model-sharing database. Via analysis of both geometric (e. <b>g.,</b> <b>triangle</b> aspect ratios, manifoldness) and contextual (e. g., licenses, tags, classes) characteristics, we demonstrate that this dataset represents a more concise summary of real-world models used for 3 D printing compared to existing datasets. To facilitate future research endeavors, we also present an online query interface to select subsets of the dataset according to project-specific characteristics. The complete dataset and per-model statistical data are freely available to the public...|$|E
40|$|The rapid {{advances}} in 3 D scanning and acquisition techniques have {{given rise to}} the explosive increase of volumetric digital models in recent years. This dissertation systematically trailblazes a novel volumetric modeling framework to represent 3 D solids. The need to explore more efficient and robust 3 D modeling framework has gained the prominence. Although the traditional surface representation (e. <b>g.,</b> <b>triangle</b> mesh) has many attractive properties, it is incapable of expressing the interior space and materials. Such a serious drawback overshadows many potential modeling and analysis applications. Consequently volumetric modeling techniques become the well-known solution to this problem. Nevertheless, many unsolved research issues remain when developing an efficient modeling paradigm for existing 3 D models: complex geometry (fine details and extreme concaveness), arbitrary topology, heterogenous materials, large-scale data storage and processing, etc. Comment: Master Thesis, Computer Science Department, Stony Brook Universit...|$|E
40|$|Sampling is a {{standard}} approach in big-graph analytics; {{the goal is to}} efficiently estimate the graph properties by consulting a sample of the whole population. A perfect sample is assumed to mirror ev-ery property of the whole population. Unfortunately, such a perfect sample is hard to collect in complex populations such as graphs (e. g. web graphs, social networks), where an underlying network connects the units of the population. Therefore, a good sample will be representative in the sense that graph properties of interest can be estimated with a known degree of accuracy. While previous work focused particularly on sampling schemes to estimate certain graph properties (e. <b>g.</b> <b>triangle</b> count), much less is known for the case when we need to estimate various graph properties with the same sampling scheme. In this paper, we pro-pose a generic stream sampling framework for big-graph analytics...|$|E
40|$|A {{multigraph}} <b>G</b> is <b>triangle</b> decomposable if {{its edge}} set can be partitioned into subsets, {{each of which}} induces a <b>triangle</b> of <b>G,</b> and rationally <b>triangle</b> decomposable if its triangles can be assigned rational weights such that for each edge e of G, {{the sum of the}} weights of the triangles that contain e equals 1...|$|R
5000|$|Chaetodon triangulum <b>G.</b> Cuvier, 1831 (<b>Triangle</b> butterflyfish) ...|$|R
50|$|If in {{addition}} the group G is abelian, then for any a, b ∈ <b>G</b> the <b>triangle</b> inequality is satisfied: |a + b| ≤ |a| + |b|.|$|R
40|$|We {{present a}} {{technique}} for computing piecewise linear approximations of geodesics on point set surfaces by minimizing an energy function defined for piecewise linear path. The function considers path length, closeness {{to the surface}} for the nodes of the piecewise linear path and for the intermediate line segments. Our method is robust with respect to noise and outliers. In order to avoid local minima, a good initial piecewise linear approximation of a geodesic is provided by Dijkstra’s algorithm that is applied to a proximity graph constructed over the point set. As the proximity graph we use a sphere-of-influence weighted graph extended for surfel sets. The convergence of our method has been studied and compared to results of other methods by running experiments on surfaces whose geodesics can be computed analytically. Our method is presented and optimized for surfel-based representations {{but it has been}} implemented also for MLS surfaces. Moreover, it can also be applied to other surface representations, e. <b>g.,</b> <b>triangle</b> meshes, radial-basis functions, etc...|$|E
40|$|International audienceWe {{propose a}} model to {{represent}} graphically the information system {{and the impact of}} cyber events (e. g., attacks, countermeasures) as a prismatic instance of n-sides. The approach considers information about all entities composing an information system (e. g., users, IP addresses, communication protocols, physical and logical resources, etc.), as well as information about the attacker's knowledge, motivation and capabilities. The base of the prism is represented as an n-side polygon (e. <b>g.,</b> <b>triangle,</b> square, pentagon, etc.) which depicts the internal information of the system, whereas the height of the prism is represented as a single axis which depicts the external information of the system. We propose geometrical operations to determine the impact of cyber security events (i. e., area, volume, event coverage, residual risk, and potential collateral damages). A case study is proposed {{at the end of the}} paper to show the applicability of the model in a scenario with multiple attack...|$|E
40|$|Two {{experiments}} examined conditional {{discrimination in}} 4 - to 6 -year-olds. Children learned {{to choose one}} of two objects (e. g., circle) when the background was, say, red and to choose the other object (e. <b>g.,</b> <b>triangle)</b> when the background was, say, blue. Awareness was assessed and interpreted as a marker of relational processing. In Experiment 1, most 4 - and 5 -year-olds did not reach the learning criterion. Children in Experiment 2 solved simpler reversal learning problems before the conditional discrimination problems. Most 4 - to 6 -year-olds reached criterion, {{but they did not}} necessarily demonstrate awareness, suggesting that reversal learning and conditional discrimination can be acquired through associative or relational processing. Relational processing increased with age and was used more on simpler problems. Fluid intelligence predicted Problem 2 performance in children who used relational (not associative) processing on Problem 1. Prior experience with simpler problems and awareness of relational structure are influential in children's conditional discrimination. Griffith Health, School of Applied PsychologyFull Tex...|$|E
40|$|Given a {{fuzzy logic}} system, {{how can we}} {{determine}} the membership functions {{that will result in}} the best performance? If we constrain the membership functions to a speci¯c shape (e. <b>g.,</b> <b>triangles</b> or trapezoids) then each membership function can be parameterized by a few variables and the membership optimization problem can be reduced to a parameter optimization problem. The parameter optimization problem can then be formulated as a nonlinear ¯ltering problem. In this paper we solve the nonlinear ¯ltering problem using H 1 state estimation theory. However, th...|$|R
40|$|An on-line {{graphics}} recognition {{system is}} presented, which provides users a natural, convenient, and {{efficient way to}} input rigid and regular shapes or graphic objects (e. <b>g.,</b> <b>triangles,</b> rectangles, ellipses, straight line, arrowheads, etc.) by quickly drawing their sketchy shapes in single or multiple strokes. An input sketchy (hand-drawn) shape is immediately converted into the user-intended rigid shape based on the shape similarity and the time constraint of the sketchy line. Three different (rule-based, SVM-based, and ANN-based) approaches have been applied and compared in the system. Experiments and evaluation are also presented, which show good performance of the system...|$|R
40|$|FIGURE 11. Map of voucher {{collection}} localities of Garra in Bhutan. Crosses represent {{sites with}} voucher specimens of Garra annandalei, white stars G. arupi, black circles <b>G.</b> bimaculacauda, black <b>triangles</b> <b>G.</b> b i ro s t r i s, grey squares G. gotyla, black stars G. lissorhynchus, and white circles G. parastenorhynchus. Crosses overlap with grey squares and white stars at some sites...|$|R
40|$|Simple spatial {{relations}} may {{be represented}} {{either in a}} propositional format that is dependent on verbal rehearsal or in a picture-like format that is maintained by visual-spatial rehearsal. In sentence-picture and picture-picture verification tasks, we examined the effect of an articulatory suppression and a spatial tapping dual task on the encoding of simple spatial relations (e. <b>g.,</b> <b>triangle</b> left of circle). Articulatory suppression did not interfere, while spatial tapping lowered performance in both tasks. Apparently, both linguistic and perceptual inputs of simple spatial relations engaged the visual-spatial working memory. In the sentence-picture verification experiments, spatial tapping only hampered performance of participants who were classified {{on the basis of}} their RT patterns as having used a visual-spatial strategy, while it had no effect for those who were classified as having applied a verbal strategy. Therefore, this study provides converging evidence, using a dual-task methodology, that both separate verbal and visual-spatial strategies exist for the processing of simple spatial sentences...|$|E
40|$|Finite element solvers are a basic {{component}} of simulation applications; they {{are common in}} computer graphics, engineering, and medical simulations. Although adaptive solvers can be of great value in reducing the often high computational cost of simulations they are not employed broadly. Indeed, building adaptive solvers can be a daunting task especially for 3 D finite elements. In this paper we are introducing {{a new approach to}} produce conforming, hierarchical, adaptive refinement methods (CHARMS). The basic principle of our approach is to refine basis functions, not elements. This removes a number of implementation headaches associated with other approaches and is a general technique independent of domain dimension (here 2 D and 3 D), element type (e. <b>g.,</b> <b>triangle,</b> quad, tetrahedron, hexahedron), and basis function order (piecewise linear, higher order B-splines, Loop subdivision, etc.). The (un-) refinement algorithms are simple and require little in terms of data structure support. We demonstrate the versatility of our new approach through 2 D and 3 D examples, including medical applications and thin-shell animations...|$|E
40|$|Solid {{shapes in}} {{computer}} graphics are often represented with boundary descriptions, e. <b>g.</b> <b>triangle</b> meshes, but animation, physicallybased simulation, and geometry processing are more realistic and accurate when explicit volume representations are available. Tetrahedral meshes which exactly contain (interpolate) the input boundary description are desirable but difficult to construct {{for a large}} class of input meshes. Character meshes and CAD models are often composed of many connected components with numerous selfintersections, non-manifold pieces, and open boundaries, precluding existing meshing algorithms. We propose an automatic algorithm handling all of these issues, resulting in a compact discretization of the input’s inner volume. We only require reasonably consistent orientation of the input triangle mesh. By generalizing the winding number for arbitrary triangle meshes, we define a function that is a perfect segmentation for watertight input and is well-behaved otherwise. This function guides a graphcut segmentation of a constrained Delaunay tessellation (CDT), providing a minimal description that meets the boundary exactly and may be fed as input to existing tools to achieve element quality. We highlight our robustness {{on a number of}} examples and show applications of solving PDEs, volumetric texturing and elastic simulation...|$|E
40|$|Abstract. In {{this paper}} {{we show that}} an outerplanar graph G with maximum degree at most 3 has a 2 -D {{orthogonal}} drawing with no bends {{if and only if}} <b>G</b> contains no <b>triangles.</b> We also show that an outerplanar graph G with maximum degree at most 6 has a 3 -D orthogonal drawing with no bends if and only if <b>G</b> contains no <b>triangles.</b> ...|$|R
40|$|When an {{occluded}} horizontal row {{of shapes}} is shifted laterally, apparent motion can be experienced {{in either the}} leftward or the rightward direction. Four experiments provide evidence for a motion bias in the direction that shapes appear to face. The bias tended to be largest when directionality was specified geometrically (e. <b>g.,</b> <b>triangles),</b> next largest when it was specified biologically (e. g., mice), and absent when it was specified calligraphically (e. g., letter R). The bias increased parametrically {{as a function of}} triangle pointedness and was consistent with the directional interpretation of an ambiguous duck-rabbit. The results support the existence of a cognitively specified forward-facing attribute that can influence experienced direction of motion...|$|R
5000|$|The trilinear {{coordinates}} of {{the centroid}} X2 (also denoted by <b>G)</b> of <b>triangle</b> ABC are ( [...] 1 / a : 1 / b : 1 / c [...] ). So the central line {{associated with the}} centroid is the line whose trilinear equation is ...|$|R
40|$|Figure 136 - 139 - 136 Map of Xizang (China), {{showing the}} localities of the Chaerilus species. Map abbreviations: a (ellipse and rhombus) Chaerilus conchiformus b (round) Chaerilus dibangvalleycus c (rhombus) Chaerilus mainlingensis d ({{triangle}} and round) Chaerilus tryznai (macula) e (star) Chaerilus tricostatus f (pentagram) Chaerilus pictus <b>g</b> (<b>triangle)</b> Chaerilus wrzecionkoi h (ellipse, triangle and macula) Chaerilus tessellatus. The red line showing the scorpions {{appears to be}} restricted to latitude north of 31 °N, bordered by Burang - Lhasa- Maizhokunggar - Gongbo'gvamda – Bomê line 137 Map of Xizang (China), showing the localities of Euscorpiops species. Map abbreviations: a (triangle) Euscorpiops asthenurus b (pentagram) Euscorpiops kamengensis c (rhombus) Euscorpiops karschi d (round) Euscorpiops novaki 138 Map of Xizang (China), showing the localities of Scorpiops species, Heterometrus tibetanus and Hottentotta songi. Map abbreviations: a (round) Scorpiops atomatus, Scorpiops langxian and Scorpiops luroris b (black triangle) Scorpiops leptochirus c (pentagram) Scorpiops lhasa d (ellipse) Scorpiops margerisonae e (square) Scorpiops tibetanus f (yellow rhombus) Scorpiops pococki g (purple rhombus) Heterometrus tibetanus h (green triangle), Hottentotta songi 139 Map of China, showing the localities of Scorpios species. Map abbreviations: a (pentagon), Scorpiops sp. from Hubei (Huzhaoshan Mountains) b (rhombus), Scorpiops jendeki from Yunnan (Gaoligongshan Mountains) c (green part), the area rich in Scorpiops (Xizang) ...|$|E
40|$|The {{problem of}} {{counting}} occurrences of query graphs {{in a large}} data graph, known as subgraph counting, is fundamental to several domains such as genomics and social network analysis. Many important special cases (e. <b>g.</b> <b>triangle</b> counting) have received significant attention. Color coding is a very general and powerful algorithmic technique for subgraph counting. Color coding {{has been shown to}} be effective in several applications, but scalable implementations are only known for the special case of tree queries (i. e. queries of treewidth one). In this paper we present the first efficient distributed implementation for color coding that goes beyond tree queries: our algorithm applies to any query graph of treewidth 2. Since tree queries can be solved in time linear in the size of the data graph, our contribution is the first step into the realm of colour coding for queries that require superlinear running time in the worst case. This superlinear complexity leads to significant load balancing problems on graphs with heavy tailed degree distributions. Our algorithm structures the computation to work around high degree nodes in the data graph, and achieves very good runtime and scalability on a diverse collection of data and query graph pairs as a result. We also provide theoretical analysis of our algorithmic techniques, showing asymptotic improvements in runtime on random graphs with power law degree distributions, a popular model for real world graphs...|$|E
40|$|A {{method for}} {{reaching}} longitudinal dispersion coefficient accounting sinuosity effects is suggested. The proposed method was verified using 43 sets of measured field data from previous study {{were collected from}} 30 streams and these data were chosen depends on characteristics availability (flow parameters, fluid properties and Sinuosity). Statistical programs namely MINITAB and SPSS were used to derive the relationship between measured longitudinal dispersion coefficient and geometric parameters were used. The new predicted formulas of the longitudinal dispersion coefficient, were correlated with a high coefficient compared to the measured data (i. e. R 2 = 0. 92 and 0. 94) excluding and including sinuosity in the calculations respectively. Comparisons made among 16 other studies of over long period of measured, experimental, and predicted longitudinal dispersion coefficient from different cross-sectional areas (e. <b>g.</b> <b>triangle,</b> rectangular, full and half full circular pipe, parabolic, narrow and deep and, wide and shallow). The correlation coefficients increased when including irregularities (Sinuosity) term of the natural streams of different cross section in the calculations. Also, the second equation which including sinuosity is more precisely describing the longitudinal dispersion in the rivers and streams. Thus, we strongly prefer and recommend using the second equation for better result than the one not including sinuosity especially for mixing {{in the case of}} brine and wastewater discharge. The two results were compared for RMSE (30. 1, 24. 0, 51. 0, 48. 9, 90. 6, and 70. 0) to previous studies e. g. Kashefipour and Falconer (2002), Deng et al. (2001), Seo and Cheong (1998), and Iwasa and Aya (1991) respectively...|$|E
40|$|FIGURE 5. Trogolaphysa stannardi sp. nov. A, Dorsal chaetotaxy of head; B, Eye patch detail; C, Thoracic macrochaetae, insets show {{variation}} in mesothoracic macrochaetae number, {{and organization of}} inner metathoracic chaetae; D, Mucro; E-F, Spines on distal margin of labrum variants; <b>G,</b> Labial <b>triangle...</b>|$|R
40|$|A {{multigraph}} <b>G</b> is <b>triangle</b> decomposable if {{its edge}} set can be partitioned into subsets, {{each of which}} induces a <b>triangle</b> of <b>G,</b> and rationally <b>triangle</b> decomposable if its triangles can be assigned rational weights such that for each edge e of G, {{the sum of the}} weights of the triangles that contain e equals 1. We present a necessary and sufficient condition for a planar multigraph to be triangle decomposable. We also show that if a simple planar graph is rationally triangle decomposable, then it has such a decomposition using only weights 0, 1 and 1 / 2. This result provides a characterization of rationally triangle decomposable simple planar graphs. Finally, if G is a multigraph with the complete graph of order 4 as underlying graph, we give necessary and sufficient conditions on the multiplicities of its edges for <b>G</b> to be <b>triangle</b> and rationally triangle decomposable. Comment: 14 pages, 3 figure...|$|R
5000|$|... #Caption: Kiepert {{hyperbola}} of triangle ABC. The hyperbola {{passes through}} the vertices (A,B,C), the orthocenter (O) and the centroid (<b>G)</b> of the <b>triangle.</b>|$|R
40|$|Sampling is a {{standard}} approach in big-graph analytics; {{the goal is to}} efficiently estimate the graph properties by consulting a sample of the whole population. A perfect sample is assumed to mirror every property of the whole population. Unfortunately, such a perfect sample is hard to collect in complex populations such as graphs (e. g. web graphs, social networks etc), where an underlying network connects the units of the population. Therefore, a good sample will be representative in the sense that graph properties of interest can be estimated with a known degree of accuracy. While previous work focused particularly on sampling schemes used to estimate certain graph properties (e. <b>g.</b> <b>triangle</b> count), much less is known for the case when we need to estimate various graph properties with the same sampling scheme. In this paper, we propose a generic stream sampling framework for big-graph analytics, called Graph Sample and Hold (gSH). To begin, the proposed framework samples from massive graphs sequentially in a single pass, one edge at a time, while maintaining a small state. We then show how to produce unbiased estimators for various graph properties from the sample. Given that the graph analysis algorithms will run on a sample instead of the whole population, the runtime complexity of these algorithm is kept under control. Moreover, given that the estimators of graph properties are unbiased, the approximation error is kept under control. Finally, we show the performance of the proposed framework (gSH) on various types of graphs, such as social graphs, among others...|$|E
40|$|How humans produce cognitively driven {{fine motor}} {{movements}} {{is a question}} of fundamental importance in how we interact with the world around us. For example, we are exposed to a constant stream of information and we must select the information that is most relevant by which to guide our actions. In the present study, we employed a well-known behavioral assay called the Simon task to better understand how humans are able to learn to filter out irrelevant information. We trained subjects for four days with a visual stimulus presented, alternately, in central and lateral locations. Subjects responded with one hand moving a joystick in either the left or right direction. They were instructed to ignore the irrelevant location information and respond based on color (e. g. red to the right and green to the left). On the fifth day, an additional testing session was conducted where the task changed and the subjects had to respond by shape (e. <b>g.</b> <b>triangle</b> to the right and rectangle to the left). They were instructed to ignore the color and location, and respond based solely on the task relevant shape. We found that the magnitude of the Simon effect decreases with training, however it returns in the first few trials after a break. Furthermore, task-defined associations between response direction and color did not significantly affect the Simon effect based on shape, and no significant associative learning from the specific stimulus-response features was found for the centrally located stimuli. We discuss how these results are consistent with a model involving route suppression/gating of the irrelevant location information. Much of the learning seems to be driven by subjects learning t...|$|E
40|$|Aenigmatite-group {{compositions}} {{conform to}} the general formulaA 2 B 6 T 6 O 2 p, where t 8 lA cations are Na and Ca, t 6 J 3 - " t"z*, Fe 3 *, Mg, Al, Cr, Ti, and Sb 5 r, and talz are Si, Al, B, and Be in named end-members. These include the sodic minerals aenig-matite, krinovite, and wilkinsonite, and the calcic minerals rhdnite, serendibite, dorrite, welshite, and h 6 gtuvaite (a new Be-bearing end-member: Grauch et al. 1994). Graphical rcpresentafion of the compositional relations among these phases is {{made possible by the}} vector method, which has recently been applied to a number of other mineral groups. The fundamental principle is that a chemical displacement such as CaAl(NaSi) - 1, having both direction and magtitude, {{can be thought of as}} a vector of unit length and arbitrary orientation. Compositional relations are simplified by condensing on vectors of isovalent substitution, such as Fe 3 *Al-, and Fe 2 +Mg-r. In vector diagrams, bound vectors are attached to a point and show the relations among basis and derived vectors. The conespondingfee vectors generate the accessible compositional range (e. <b>g.,</b> <b>triangle,</b> quadrilateral, or pentagon), starting from an initial formula or composition (additive component of J. B. Thompson, Jr.). When this approach is used on the aenigmatite group, the compositions of the main minerals are derived ftom that of aenigmatite by application of the basis vecton CaAl(NaSi) - 1, Al 2 (MgTi) -,, and Al 2 (MgSi) -r. Hogtuvaite is derived by BeSiAl- 2 acting on rhtlnite, and welshite by AlSbBe(MgTiSi) _ 1 acting on hpgtuvaite. Other theoretical end-members can be generated by the vector method; in the aenigmatite group, many are probably unstable with regmd to a mixture of clinopytoxene plus olivine or spinel, especially if they lack Ti or excess A 1...|$|E
40|$|A general {{method for}} {{designing}} parallel PDE solvers on dynamic data structures is presented. The method is validated by the parallelization of a real-world example code, a finite-volume Euler solver based on arbitrary polyhedral control volumes with adaptive remeshing. The resulting grid database is highly dynamic throughout the solution process, which enforces a layer-based strategy to handle complex, distributed data structures. The positive {{impacts of the}} object-oriented paradigm for (parallel) numeric computing are shown, although the general parallelization method is not restricted to OO programs. An example computation will be presented. 1 Parallel Adaptive Algorithms Adaptive algorithms for the numerical solution of PDE problems using unstructured grids require complex, dynamic data structures [2]. References provide a common technique for representing the connectivity relations between certain data objects (e. <b>g.</b> <b>triangles</b> and nodes in a finite-element context). The actual im [...] ...|$|R
40|$|Three {{groups of}} normal, right handed {{subjects}} {{were trained to}} give same-different responses to pairs of stimuli presented simultaneously to the right or {{the left side of}} a fixation point. The subjects exhibited faster reactions (pressing 1 of 2 keys) to stimuli appearing in the right visual field when the stimuli were simple geometrical figures (e. <b>g.</b> <b>triangles</b> and squares) or nonsense patterns. By contrast, drawings subjects showed a left visual field advantage when the stimuli were complex geometrical figures (e. g. 10 and 11 sided regular polygons). These differences in performance for the 2 halves of the visual field are attributed to differential hemispheic specializations. The opposite hemispheric superiorities found with different classes of stimuli are in turn attributed to the discrimination of single features by the left hemisphere and to the use of a spatial strategy by the right hemispher...|$|R
40|$|SummaryThe spatial {{organization}} of cells {{depends on their}} ability to sense their own shape and size. Here, we investigate how cell shape affects the positioning of the nucleus, spindle and subsequent cell division plane. To manipulate geometrical parameters in a systematic manner, we place individual sea urchin eggs into microfabricated chambers of defined geometry (e. <b>g.,</b> <b>triangles,</b> rectangles, and ellipses). In each shape, the nucleus is positioned at the center of mass and is stretched by microtubules along an axis maintained through mitosis and predictive of the future division plane. We develop a simple computational model that posits that microtubules sense cell geometry by probing cellular space and orient the nucleus by exerting pulling forces that scale to microtubule length. This model quantitatively predicts division-axis orientation probability {{for a wide variety of}} cell shapes, even in multicellular contexts, and estimates scaling exponents for length-dependent microtubule forces...|$|R
40|$|Abstract—We {{present an}} {{interactive}} and accurate collision detection algorithm for deformable, polygonal objects {{based on the}} streaming computational model. Our algorithm can detect all possible pairwise primitive-level intersections between two severely deforming models at highly interactive rates. In our streaming computational model, we consider a set of axis aligned bounding boxes (AABBs) that bound each of the given deformable objects as an input stream and perform massively-parallel pairwise, overlapping tests onto the incoming streams. As a result, {{we are able to}} prevent performance stalls in the streaming pipeline that can be caused by expensive indexing mechanism required by bounding volume hierarchy-based streaming algorithms. At run-time, as the underlying models deform over time, we employ a novel, streaming algorithm to update the geometric changes in the AABB streams. Moreover, in order to get only the computed result (i. e., collision results between AABBs) without reading back the entire output streams, we propose a streaming en/decoding strategy that can be performed in a hierarchical fashion. After determining overlapped AABBs, we perform a primitive-level (e. <b>g.,</b> <b>triangle)</b> intersection checking on a serial computational model such as CPUs. We implemented the entire pipeline of our algorithm using off-the-shelf graphics processors (GPUs), such as nVIDIA GeForce 7800 GTX, for streaming computations, and Intel Dual Core 3. 4 G processors for serial computations. We benchmarked our algorithm with different models of varying complexities, ranging from 15 K up to 50 K triangles, under various deformation motions, and the timings were obtained as 30 ∼ 100 FPS depending on the complexity of models and their relative configurations. Finally, we made comparisons with a well-known GPU-based collision detection algorithm, CULLIDE [4] and observed about three times performance improvement over the earlier approach. We also made comparisons with a SW-based AABB culling algorithm [2] and observed about two times improvement...|$|E
40|$|For the {{numerical}} simulation of many problems of engineering interest, {{it is desirable}} to have an automated mesh adaption tool. This is important especially for problems characterized by anisotropic features and require mesh clustering {{in the direction of}} high gradients. Another significant issue in meshing emerges in unsteady simulations with moving boundaries, where the boundary motion has to be accommodated by deforming the computational grid. Similarly, there exist problems where current mesh needs to be adapted to get more accurate solutions. To solve these problems, we propose three novel procedures. In {{the first part of this}} work, we present an optimization procedure for three-dimensional anisotropic tetrahedral grids based on metric-driven h-adaptation. Through the use of topological and geometrical operators, the mesh is iteratively adapted until the final mesh minimizes a given objective function. We propose an optimization process based on an ad-hoc application of the simulated annealing technique, which improves the likelihood of removing poor elements from the grid. Moreover, a local implementation of the simulated annealing is proposed to reduce the computational cost. Many challenging unsteady multi-physics problems are characterized by moving boundaries and/or interfaces. When the boundary displacements are large, degenerate elements are easily formed in the grid such that frequent remeshing is required. We propose a new r-adaptation technique that is valid for all types of elements (e. <b>g.,</b> <b>triangle,</b> tet, quad, hex, hybrid) and deforms grids that undergo large imposed displacements at their boundaries. A grid is deformed using a network of linear springs composed of edge springs and a set of virtual springs. The virtual springs are constructed in such a way as to oppose element collapsing. Both frequent remeshing, and exact-pinpointing of clustering locations are great challenges of numerical simulations, which can be overcome by adaptive meshing algorithms. Therefore, we conclude this work by defining a novel mesh adaptation technique where the entire mesh is adapted upon application of a force field in order to comply with the target mesh or to get more accurate solutions. The method has been tested for two-dimensional problems of a-priori metric definitions as well as for oblique shock clusterings. Ph. D. Committee Chair: Bottasso, Carlo; Committee Member: Dieci, Luca; Committee Member: Ruffin, Stephen; Committee Member: Rusak, Zvi; Committee Member: Sankar, Lakshm...|$|E
40|$|Metal-organic {{materials}} (MOMs) {{represent an}} emerging class of materials comprised of molecular building blocks (MBBs) linked by organic linker ligands. MOMs recently {{attract great attention}} because {{of their ability to}} exhibit permanent porosity, thereby enabling study of properties in the context of gas storage, gas separation, solid supports for sensors, catalysis and so on. Although MOMs have been studied for over 60 years, the porous nature of MOMs was not systematically and widely explored until the early 19902 ̆ 7 s. This {{may be one of the}} reasons why template-directed synthesis of MOMs remains relatively underexplored, especially when compared to other classes of porous material (e. g. zeolite and mesoporous silicates). However, the study of template-directed synthesis exhibits great significance to the research field of MOMs as these considerations: (i) to access analogues of prototypal MOM platforms that cannot be prepared directly; (2) to create porous materials with new topologies; (3) to transfer the functionality of templates to MOMs; (4) to exert fine control over structural features. In this dissertation, I chose a functional organic material, porphyrin, as templates and succeeded to synthesize a series of porphyrin-encapsulating MOMs, (porph@MOMs), in which the porphyrins were encapsulated inside the cavities as guests. Porphyrins molecules can template the formation cavities with different shapes and sizes (e. <b>g.</b> <b>triangle,</b> square or hexagon) to accommodate the porphyrins molecules when organic ligands with different size and symmetry were utilized during the synthesis. On the other hand, the porphyrins molecules can also template the formation of octahemioctahedral cages or hexahedron cages with porphyrins trapped inside, which further built the tbo, pcu, rtl, zzz, mzz networks. By selecting templated porph@MOMs as platforms, post-synthetic modifications (PSMs) of porph@MOMs were further studied. A cadmium MOM, porph@MOM- 10, can undergo PSM by Mn(II) or Cu(II) via single-crystal-to-single-crystal processes. The Mn- and Cu- exchanged PSM variants exhibit catalytic activity for epoxidation of trans-stilbene. Porph@MOM- 11 can serve as a platform to undergo a new PSM process involving cooperative addition of metal salts via single-crystal-to-single-crystal processes. The incorporation of the salts leads to higher H 2 and CO 2 volumetric uptake and higher CO 2 vs CH 4 selectivity. Porph@MOM- 11 was also found to be a versatile platform that can undergo metal ion exchange with Cu 2 + in single-crystal-to-single-crystal fashion. The use of mixed metal salt solutions (Cu 2 +/Cd 2 +) with varying ratios of metal salts enabled systematic study of the metal exchange process in porph@MOM- 11 in such a manner that, at one extreme, only the Cd porphyrin moieties undergo metal ion exchange, whereas at the other extreme both the framework and the porphyrin moiety are fully exchanged. It is also observed that a concerted PSMs approach of metal ion exchange and ligand addition towards a porphyrin-walled MOM, porphMOM- 1 affords a porphyrin-encapsulating MOM, porph@MOM- 14, in which porphyrin anions are encapsulated in the octahemioctahedral polyhedral cage via weak interactions. Beside of the template-directed synthesis and post-synthetic modification of porph@MOMs, pre-synthetic control of metal-organic materials 2 ̆ 7 structures was also studied in this dissertation. Due to the partial flexibility of 1, 3 -benzenedicarboxylate linkers, kagom[eacute] lattice and NbO supramolecular isomers were observed from a complexation of bulky 1, 3 -benzenedicarboxylate ligand to Cu(II) paddlewheel moieties. In addition, a new family of hybrid nanoball vanadium MOM structures (Hyballs) was prepared by the self-assemble of trimesic acid with tetranuclear and pentanuclear vanadium polyoxometalates. These hyballs are robust, permanently porous and their exterior surfaces facilitate cross-linking via hydrogen bonds or coordination bonds to generate pcu networks...|$|E
40|$|The {{benefits}} of visual exposure to natural environments for human well-being {{in areas of}} stress reduction, mood improvement, and attention restoration are well documented, but the effects of natural environments on impulsive decision-making remain unknown. Impulsive decision-making in delay discounting offers generality, predictive validity, and insight into decision-making related to unhealthy behaviors. The present experiment evaluated differences in such decision-making in humans experiencing visual exposure {{to one of the}} following conditions: natural (e. g., mountains), built (e. g., buildings), or control (e. <b>g.,</b> <b>triangles)</b> using a delay discounting task that required participants to choose between immediate and delayed hypothetical monetary outcomes. Participants viewed the images before and during the delay discounting task. Participants were less impulsive in the condition providing visual exposure to natural scenes compared to built and geometric scenes. Results suggest that exposure to natural environments results in decreased impulsive decision-making relative to built environments...|$|R
40|$|FIGURE 2. Panorpodes kuandianensis sp. nov. A. Wings of male; B. Wings of female; C. Head of male, frontal view; D. Head of female, frontal view; E. Middle part of mandibles, {{showing the}} serrate inner margin; F. Distal portion of mandible; <b>G.</b> Ocellar <b>triangle,</b> showing ocellar bristles; H. Thorax, dorsal view; I. Distal tarsomeres and pretarsus, dorsal view; J. Claw, lateral view...|$|R
40|$|We {{consider}} {{the problem of}} constructing embeddings of 2 dimensional FEM graphs into grids. Our goal is to minimize the edgecongestion and dilation and optimize the load. We introduce some heuristics, analyze their performance, and present experimental results comparing the heuristics with the methods based on the usage of standard graph partitioning libraries. 1 Introduction We {{consider the}} problem to embed large scale FEM graphs for the solution of partial differential equations into massively parallel computing systems. Roughly speaking, solving such equations {{with respect to a}} function F, say in two dimensions, requires to partition the domain of F into simple polygons (e. <b>g.</b> <b>triangles</b> or rectangles). Afterwards the value of the function F is computed in the nodes of the obtained partition. It turns out that accuracy requirements are not constant in the considered region but might vary considerably. This may lead to a partition of the area into polygons where the polygons si [...] ...|$|R
