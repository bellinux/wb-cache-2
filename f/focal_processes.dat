5|100|Public
40|$|With the {{establishment}} of high-throughput sequencing technologies and new methods for rapid and extensive single nucleotide (SNP) discovery, marker-based genome scans in search of signatures of divergent selection between populations occupying ecologically distinct environments are becoming increasingly popular.; On the basis of genome-wide SNP marker data generated by RAD sequencing of lake and stream stickleback populations, we show that the outcome of such studies can be systematically biased if markers with a low minor allele frequency {{are included in the}} analysis. The reason is that these 'uninformative' polymorphisms lack the adequate potential to capture signatures of drift and hitchhiking, the <b>focal</b> <b>processes</b> in ecological genome scans. Bias associated with uninformative polymorphisms is not eliminated by just avoiding technical artifacts in the data (PCR and sequencing errors), as a high proportion of SNPs with a low minor allele frequency is a general biological feature of natural populations.; We suggest that uninformative markers should be excluded from genome scans based on empirical criteria derived from careful inspection of the data, and that these criteria should be reported explicitly. Together, this should increase the quality and comparability of genome scans, and hence promote our understanding of the processes driving genomic differentiation...|$|E
40|$|Abstract Background With the {{establishment}} of high-throughput sequencing technologies and new methods for rapid and extensive single nucleotide (SNP) discovery, marker-based genome scans in search of signatures of divergent selection between populations occupying ecologically distinct environments are becoming increasingly popular. Methods and Results On the basis of genome-wide SNP marker data generated by RAD sequencing of lake and stream stickleback populations, we show that the outcome of such studies can be systematically biased if markers with a low minor allele frequency {{are included in the}} analysis. The reason is that these ‘uninformative’ polymorphisms lack the adequate potential to capture signatures of drift and hitchhiking, the <b>focal</b> <b>processes</b> in ecological genome scans. Bias associated with uninformative polymorphisms is not eliminated by just avoiding technical artifacts in the data (PCR and sequencing errors), as a high proportion of SNPs with a low minor allele frequency is a general biological feature of natural populations. Conclusions We suggest that uninformative markers should be excluded from genome scans based on empirical criteria derived from careful inspection of the data, and that these criteria should be reported explicitly. Together, this should increase the quality and comparability of genome scans, and hence promote our understanding of the processes driving genomic differentiation. </p...|$|E
40|$|The present thesis {{examined}} {{whether the}} interference-by-process construct, {{as applied to}} auditory distraction during visual-verbal serial recall (the irrelevant sound effect, ISE), also holds as a useful framework for interpreting auditory-semantic distraction whereby performance on tasks requiring semantic <b>focal</b> <b>processes</b> is disrupted by the semantic properties of irrelevant sound. To address this goal, several semantic focal tasks were {{used in conjunction with}} manipulations of task-instruction and of the semantic properties of irrelevant sounds. Empirical Series 1 showed that episodic recall of lists comprising exemplars drawn from a single semantic-category was disrupted by the lexicality of the irrelevant items and their semantic similarity to the to-be-remembered exemplars, but only when the task-instructions emphasised free, not serial, recall and when the irrelevant category items were dominant exemplars of a category. Moreover this series also demonstrated that irrelevant category items are often included erroneously as responses, and that this is due to a breakdown in the source-monitoring process. These results provide evidence for the interference-by-process construct in that the semantic properties of speech disrupt semantic, and source-monitoring, processing in the focal task and may also produce interference through giving rise to inhibitory processes. Series 2 showed that the presence of semantic properties in the irrelevant sound impaired semantic categorization (or category-clustering) and category, and category-exemplar, recall in the episodic recall of lists of exemplars drawn from several semantic categories, but, like Series 1, failed to produce disruption when task-instruction demanded serial recall. This finding provides yet further evidence for a conflict between two semantic processes. Finally, Series 3 showed that the semantic, but not acoustic, properties of irrelevant sound impaired retrieval from semantic memory when the focal task required retrieval from a semantic-category (requiring semantic processing), but not phonemic-category (not necessitating semantic processing). The implications of the findings for other approaches to auditory-semantic distraction, and auditory distraction generally, are discussed...|$|E
3000|$|... 8.0). Detailed seismic {{intensity}} maps {{based on the}} report of human perceptions in 1952 and the {{seismic intensity}} meter network in 2003 also show resemblance. Similar aftershock pattern and seismic intensity distribution imply that both earthquakes are a pair of characteristic earthquakes {{of the same size}} sharing the same source area and the same <b>focal</b> <b>process.</b>|$|R
40|$|While {{organizations}} have focused increasing attention towards the acquisition {{and use of}} process knowledge {{for the purposes of}} quality performance, significant advances in information systems have occurred. The emergence of these two forces creates an opportunity for organizations to benefit from the integration of information systems and quality systems. The basic purpose of an information system is to acquire and represent knowledge. The basic purposes of a quality system are quality planning, quality control, and quality improvement. We therefore define a process quality knowledge base (PQKB) as an information system that acquires process knowledge and represents it for the purposes of quality planning, quality control, and quality improvement. This paper proposes that the presence of a PQKB can improve the quality performance of the <b>focal</b> <b>process,</b> as well as the quality performance of processes similar to the <b>focal</b> <b>process.</b> We argue that {{the degree to which a}} PQKB can effect quality performance is moderated by the richness of the process description encapsulated inside the PQKB, and the diversity of knowledge sources that are engaged during the construction and use of the PQKB. Managerial and research implications are highlighted. 1 1...|$|R
40|$|Long-period strain {{seismogram}} {{recorded at}} Pasadena {{is used to}} determine the <b>focal</b> <b>process</b> of the 1960 Chilean earthquake. Synthetic seismograms computed for various fault models are matched with the observed strain seismogram to determine the fault parameters. A low-angle (∼ 10 °) thrust model with rupture length of 800 km and rupture velocity of 3. 5 km/sec is consistent with the observed Rayleigh/Love wave ratio and the radiation asymmetry. A seismic moment of 2. 7 · 10 ^(30) dyn · cm is obtained for the main shock. This value, together with the estimated fault area of 1. 6 · 10 ^ 5 km^ 2, gives an average dislocation of 24 m. The strain seismogram clearly shows unusually long-period (300 – 600 sec) wave arriving at the P time of a large foreshock which occurred about 15 minutes before the main shock, suggesting a large slow deformation in the epicentral area prior to the major failure. A simple dislocation model shows that a dislocation of 30 m, having a time constant of 300 – 600 sec, over a fault plane of 800 × 200 km^ 2 is required to explain this precursory displacement. The entire <b>focal</b> <b>process</b> may be envisaged in terms of a large-scale deformation which started rather gradually and eventually triggered the foreshocks and the “main” shock. This mechanism may explain the large premonitory deformations documented, but not recorded instrumentally, for several Japanese earthquakes. The moments of the main shock and the precursor add to 6 · 10 ^(30) dyn · cm which is large enough to affect the earth's polar motion...|$|R
30|$|One {{interpretation}} {{is that the}} central manual tracking task and the peripheral target detection task tapped into partially independent pools of information-processing resources (Wickens, 2002). Although multiple resource theory includes visual attention as one form of processing resource, it posits separate pools of processing resources for both focal and ambient vision, linking focal processing to the central visual field and ambient to the peripheral visual field. The theory thus allows that the task-load manipulation might not have affected processing efficiency because the tracking task engaged central resources and the target detection task engaged ambient resources. Contrary to this hypothesis, though, mean single-target RTs for dual-task conditions were credibly longer than those for single-task conditions in across all experiments. These results suggest the central tracking and peripheral detection tasks likely tapped common processing resources, presumably at the stages that Wickens (2002) labels perception or cognition; the target and distractor stimuli of Experiment 3 were in fact designed to be indiscriminable in ambient vision, ensuring competition for focal attention between the central and peripheral tasks. Moreover, the Wickens (2002) model proposes that <b>focal</b> <b>processes</b> are specialized for detailed object perception and recognition, whereas ambient processes are specialized for spatial processing. Assuming that participants fixated near the display center to perform the tracking task, the central and peripheral processing demands in the current experiments, therefore, would not have aligned well with the attentional pools hypothesized by multiple resource theory. To optimize the distribution of resources under the model, participants {{would have had to}} fixate near the boundary of the display while tracking the moving target with peripheral vision. Eye movement data might test whether any participants adopted such a strategy, or to estimate more generally how often eye movements occurred between the central and peripheral tasks. At best, though, the data indicate that distributing task load over different resource pools would have attenuated dual-tasks costs, not eliminated them.|$|E
30|$|Our {{contributions}} must {{be viewed}} {{in the light of}} potential limitations of our study. First, it is possible that our participants withheld information from us, particularly information that might cast a negative light on their values and motivations for network participation or their ways of exerting influence. However, this problem has probably been mitigated, because we considered multiple perspectives from different data sources, and we looked for coherence in our data (Charmaz 2014). For instance, in the early phase of our research we were surprised by the somewhat striking “harmony” in the network settings. We tried to better understand this phenomenon and learned successively that our participants developed a certain and basically very relaxed attitude toward consensus finding and included this as a subcategory in our analysis. Because nobody is compelled to do anything in the network, the collective (leadership) processes that were revealed and appeared to be extremely harmonious are not “always present”, and not are easily achieved. Shared leadership will only emerge “voluntarily” based on participants’ ideas, values, and actual concerns. Thus, even though differences may exist, they do not necessarily always have to be fully resolved. Second, it was neither possible nor intended to provide an all-encompassing description of facilitators’ and interaction dynamics, e.g. related to network evolution or relationship development. Rather, and in line with our grounded theory approach (and its core procedures of constant comparison and theoretical sampling), which implies focused coding and selections, we focused on inductively derived themes that more accurately advance understanding the <b>focal</b> <b>processes</b> of non-leadership emergence and shared leadership development, as summarized in our model. Nevertheless, and third, we recognize that our suggestions with regard to the network level outcomes are an initial step. That is, given our network-centered perspective the assessment of outcomes focuses on the network level and neglects other possible outcomes. Therefore, future research should expand this perspective and assess (ideally various forms of) outcomes at the member organizations’ level. Fourth, although our study’s findings include individual level dimensions in terms of value orientation and (motivational) orientations towards network engagement, further individual-level/intra-psychical or intrapersonal characteristics such as our participants’ personality structures are potentially also relevant and thus deserve further investigation. Finally, concerning the transferability of findings to other contexts, we described the contextual conditions and mapped the domain of our network cases. Based on this, we argue that our suggestions for shared leadership development are limited in their applicability to traditional organization contexts; rather they apply to the core domain of collaborative non-hierarchical network contexts and similar cooperative and low structured organizational settings (e.g. self-managing and self-governing teams/organizations). Future research should further develop our key concepts in relation to other contexts. Beyond that, our grounded theory model provides ample scope for studying various relations in depth. For example, future research should explore in more detail the content of the values and orientations related to joint-motivational network identity. This should involve the study of potential “negative values”, which—in contrast to the positive values of network members in our context (cf. RedNet)—would probably not contribute to the common good. Concerning the motivational dimensions of our model, it would be promising to study in more detail how probably existing participants’ individual level motivation could be lifted to the (collective) network level.|$|E
40|$|Play is, by definition, {{internally}} motivated, flexible, {{spontaneous and}} voluntary. Yet some researchers {{claim to have}} taught children with autism to play using behavioural interventions that are heavily structured, repetitive and make use of external reinforcements. In the current systematic review, we examine {{the extent to which}} these claims are supported by the evidence presented by the researchers themselves. We conclude that the most effective behavioural interventions have been those which have built on children's existing abilities or have relied on the motivating nature of activities themselves rather than on external rewards. We discuss the problems inherent in distinguishing between behavioural and cognitive change in children's play and highlight generalization as a poorly understood but <b>focal</b> <b>process.</b> Finally, we discuss the value of teaching children with autism play behaviours when these are not characterized by the defining qualities of play as a disposition. No Full Tex...|$|R
40|$|Heterogeneity {{of motor}} phenotypes is a {{clinically}} well-recognized fundamental aspect of {{amyotrophic lateral sclerosis}} (ALS) and is determined by variability of 3 independent primary attributes: body region of onset; relative mix of upper motor neuron (UMN) and lower motor neuron (LMN) deficits; and rate of progression. Motor phenotypes {{are determined by the}} anatomy of the underlying neuropathology and the common defining elements underlying their heterogeneity are that motor neuron degeneration is fundamentally a <b>focal</b> <b>process</b> and that it spreads contiguously through the 3 -dimensional anatomy of the UMN and LMN levels, thus causing seemingly complex and varied clinical manifestations. This suggests motor neuron degeneration in ALS is in actuality a very orderly and actively propagating process and that fundamental molecular mechanisms may be uniform and their chief properties deduced. This also suggests opportunities for translational research to seek pathobiology directly in the less affected regions of the nervous system...|$|R
40|$|We have {{developed}} a model for representing the image of segments of blood vessels in x-ray angiograms, and a software package for generating the model from digitized angiograms. The model is based on projections of linearly tapering cylinders and is suitable {{for the analysis of}} vessel lumen position, size and shape. This is of interest for research into the disease atherosclerosis. The system has been validated using a set of post mortem samples. The accuracy of representation of the lumen radius is between + 0 % and + 10 % (95 % confidence limits) and the accuracy of simple shape information is 81 %. Atherosclerosis is a common arterial disease. It is obliterative and its principal effect is due to the encroachment of a lesion on the lumen, with consequent effect on blood flow through the artery. It is a <b>focal</b> <b>process</b> and many foci ma...|$|R
40|$|We have {{investigated}} regional changes in dopamine metabolism within the basal ganglia with clinical progression of idiopathic Parkinson's disease, using coregistration of [] 8 F]dopa-PET and MRI images and comparing six normal subjects with 15 Parkinson's disease {{patients in a}} cross-sectional study. We have demonstrated that [i&F]dopa metabolism in the dorsal putamen is reduced to almost 50 % of normal both caudally and rostrally early in the disease whilst the ventral putamen is not significantly affected. With progression of symptoms there is loss of dopa metabolism from the ventral putamen, the ventrocaudal putamen {{in advance of the}} ventrorostral putamen. Throughout the disease the ventrorostral putamen is relatively preserved; even in the most advanced group [lsF]dopa uptake is reduced here by only 30 %. We conclude that the progression of Parkinson's disease is associated with a <b>focal</b> <b>process</b> affecting only the dorsal putamen in its early (and preclinical) phase then affecting the ventral putamen with increasing disease severity...|$|R
40|$|New {{concepts}} of governance {{take account of}} ambivalence, uncertainty, and distributed power in societal change. They aim for reflexivity regarding the limits of prognostic knowledge and actual control of complex processes of change. Adaptive management and transition management are two examples that evolved from the analysis of social&# 8211;ecological and sociotechnical systems, respectively. Both feature strategies of collective experimentation and learning. In this paper, we ask how these two designs of reflexive governance consider politics. Based on a framework of different dimensions and levels of politics, we {{show that they are}} mainly concerned with problem solving by a <b>focal</b> <b>process,</b> but conflict and asymmetric power relations, as well as the embedding of processes within broader political contexts, are neglected. We suggest two routes for integrating politics into the design of reflexive governance: (1) recognize the politics of learning for sustainable development and develop safeguards against domination and capture by powerful actors, and (2) systematically consider the embedding of governance designs in political contexts and their ongoing dynamics for political fit...|$|R
50|$|Although these {{seizures}} {{are usually}} due to large, acute brain lesions resulting from strokes in adults and <b>focal</b> cortical inflammatory <b>processes</b> in children (Rasmussen's encephalitis), possibly caused by chronic viral infections, edema, or autoimmune processes.|$|R
40|$|The {{advances}} of computational methods and tools can greatly support other areas in doing tasks {{from the most}} tedious or repetitive to the most complex. In this paper, these advances were manipulated in civil structures maintenance specifically in pipeline corrosion assessment. This paper describes mechanize method developed to automatically detect and quantitY important parameters for future prediction of corrosion growth using In-line inspection (Ill) data. The <b>focal</b> <b>process</b> in this system includes data conversion, data filtering, parameter tolerance or sizing configuration, matching, and data trimming. A sensitivity analysis using linear regression method was used to correlates defects from one inspection to the next. Issues and advantage gain from this mechanize system is threefold~ Firstly, timeliness (manual matching procedure consumed {{a great deal of}} time). Secondly, accuracy and consistencies in data sampling (current implementation, different researcher obtain a different number of sample even though the method used in matching were the same), and finally, reduction of data matching error (manual matching was prone to human error due to the masses of inspection data to be match. Furthermore this method is impractical when facing the large amount of real inspection data) ...|$|R
50|$|Organizations {{may create}} a Software Engineering Process Group (SEPG), {{which is the}} <b>focal</b> point for <b>process</b> improvement. Composed of line {{practitioners}} who have varied skills, the group {{is at the center}} of the collaborative effort of everyone in the organization who is involved with software engineering process improvement.|$|R
40|$|Abstract—Vascular cell {{adhesion}} molecule- 1 (VCAM- 1 /Vcam 1) is a cytokine-inducible {{member of the}} immunoglobulin gene superfamily that is expressed by arterial endothelial cells in regions predisposed to atherosclerosis and at borders of atherosclerotic plaques. To determine whether VCAM- 1 expression regulates atherosclerotic lesion formation, we crossed Vcam 1 domain 4 –deficient (D 4 D) mice, which partially circumvent the embryonic lethality of Vcam 1 null mice, with apolipoprotein E null (Apoe 2 / 2) mice, which spontaneously develop hypercholesterolemia and atheroscle-rosis. In the Apoe 2 / 2 background, mice homozygous for the Vcam 1 D 4 D allele had markedly reduced arterial VCAM- 1 expression, monocyte adherence in the aortic root, and fatty streak formation. Heterozygous Vcam 1 D 4 D mice revealed a Vcam 1 gene-dosage effect and had intermediate, yet significant, reductions in these parameters. Our data demonstrate that VCAM- 1 plays {{a pivotal role in}} the initiation of atherosclerosis in Apoe 2 / 2 mice. (Arterioscler Thromb Vasc Biol. 2001; 21 : 1662 - 1667.) Key Words: vascular {{cell adhesion}} molecule- 1 n apolipoprotein E n hypercholesterolemia n gene targeting n monocytes Atherosclerosis begins as a <b>focal</b> <b>process</b> at specificregions of the vasculature, so-called lesion-prone areas, where hemodynamic flow is altered. The arterial endothelium expresses numerous adhesion molecules, such as P-selectin...|$|R
40|$|This {{article was}} first {{published}} in the Journal Ecology and Society at [URL] Voß, Jan-Peter; Bornemann, Basil: The politics of reflexive governance: challenges for designing adaptive management and transition management. - In: Ecology and Society : a Journal of Integrative Science for Resilience and Sustainability. - ISSN: 1708 - 3087 (online). - 16 (2011), 2, art. 9. New concepts of governance take account of ambivalence, uncertainty, and distributed power in societal change. They aim for reflexivity regarding the limits of prognostic knowledge and actual control of complex processes of change. Adaptive management and transition management are two examples that evolved from the analysis of social–ecological and sociotechnical systems, respectively. Both feature strategies of collective experimentation and learning. In this paper, we ask how these two designs of reflexive governance consider politics. Based on a framework of different dimensions and levels of politics, we show that they are mainly concerned with problem solving by a <b>focal</b> <b>process,</b> but conflict and asymmetric power relations, as well as the embedding of processes within broader political contexts, are neglected. We suggest two routes for integrating politics into the design of reflexive governance: (1) recognize the politics of learning for sustainable development and develop safeguards against domination and capture by powerful actors, and (2) systematically consider the embedding of governance designs in political contexts and their ongoing dynamics for political fit...|$|R
50|$|Epilepsia partialis {{continua}} {{is a rare}} type of focal motor seizure (hands and face) which recurs {{every few}} seconds or minutes for extended periods (days or years). It is usually due to strokes in adults and <b>focal</b> cortical inflammatory <b>processes</b> in children (Rasmussen's encephalitis), possibly caused by chronic viral infections or autoimmune processes.|$|R
40|$|It is {{well known}} that {{ecological}} processes such as population regulation and natural enemy interactions potentially occur over a range of spatial scales, and there is a substantial body of literature developing theoretical understanding of the interplay between these processes. However, there are comparatively few studies quantifying the long-term effects of spatial scaling in natural ecosystems. A key challenge is that trophic complexity in real-world biological communities quickly obscures the signal from a <b>focal</b> <b>process.</b> Seagrass meadows provide an excellent opportunity in this respect: in many instances, seagrasses effectively form extensive natural monocultures, in which hypotheses about endogenous dynamics can be formulated and tested. We present amongst the longest unbroken, spatially explict time series of seagrass abundance published to date. Data include annual measures of shoot density, total above-ground abundance, and associated epiphyte cover from five Zostera marina meadows distributed around the Isles of Scilly, UK, from 1996 to 2011. We explore empirical patterns at the local and metapopulation scale using standard time series analysis and develop a simple population dynamic model, testing the hypothesis that both local and metapopulation scale feedback processes are important. We find little evidence of an interaction between scales in seagrass dynamics but that both scales contribute approximately equally to observed local epiphyte abundance. By quantifying the long-term dynamics of seagrass-epiphyte interactions we show how measures of density and extent are both important in establishing baseline information relevan...|$|R
40|$|The <b>focal</b> <b>process</b> of the Sanriku {{earthquake}} of March 2, 1933, {{is discussed}} {{in relation to the}} bending mechanism of the lithosphere. On the basis of the P times obtained at more than 200 stations, it is confirmed that the hypocenter of this earthquake is within the lithosphere beneath the Japan trench. The P wave fault plane solution, the amplitude of long-period (100 s) Love and Rayleigh waves and two near-field observations suggest, almost definitely, that the Sanriku earthquake represents a predominantly normal faulting on a plane dipping 45 ° towards N 90 ° W. A fault size of 185 × 100 km^ 2, in agreement with the size of the aftershock area, is required to yield a slip dislocation of 3. 3 m, a value consistent with the tsunami data. This result suggests that the fracture took place over the entire thickness of the lithosphere, thereby precluding the possibility that the Sanriku earthquake merely represents a surface tensile crack due to the bending of the lithosphere. This large scale lithospheric faulting is presumably due to a gravitational pull exerted by the cold sinking lithosphere. The fracture probably took place on an old fault plane which had once fractured and healed up. The existence of this fracture zone which decouples, to some extent, the oceanic lithosphere from the sinking lithosphere accounts for the sharp bend of the lithosphere beneath oceanic trenches and also the abrupt disappearance of seismic activity across oceanic trenches. The sharp bend of the lithosphere is therefore a result, not the cause, of great earthquakes beneath oceanic trenches...|$|R
40|$|A novel local blur {{estimation}} method {{is presented in}} the paper. <b>Focal</b> blur <b>process</b> is usually modeled as a Gaussian low-pass filtering and then the problem of blur estimation is to identify the Gaussian blur kernel. In the proposed method, the input blurred image first is re-blurred by Gaussian blur kernels with different blur radii. Then the difference ratios between the multiple re-blurred images and the input image are used to determine the unknown blur radius. We show that the proposed method does not require edge detection pre-processing and can estimate a wide range of blur. Experimental results of the proposed method on both synthetic and natural images compared with other methods are presented. 1...|$|R
40|$|Recently, a joint Brazil-France-U. S. program, {{known as}} PIRATA (Pilot Research moored Array in the Tropical Atlantic), was {{proposed}} {{to begin the}} deployment of moored measurement platforms in the tropical Atlantic {{in order to enhance}} the existing observational data base and subsequent understanding of the processes by which the ocean and atmosphere couple in key regions of the tropical Atlantic Ocean. Empirical studies have suggested that there are strong relationships between tropical Atlantic upper ocean variability, SST, ocean-atmosphere coupling and regional climate variability. During the early 1980 's a coordinated set of surface wind, subsurface thermal structure, and subsurface current observations were obtained as part of the U. S. -France SEQUAL- <b>FOCAL</b> <b>process</b> experiment designed to observe the seasonal response of the tropical Atlantic Ocean to surface forcing. Since that time, however, the observational data base for the tropical Atlantic Ocean has disintegrated to a few shiptracks measuring ocean temperatures and a small collection of tide gauge stations measuring sea level. A more comprehensive set of observations, modeling and empirical studies is now in order to make progress on understanding the regional climate variability. The proposed PIRATA program will use mooring platforms similar to the tropical Pacific Ocean TAO array to measure surface fluxes of momentum and heat and the corresponding changes in the upper ocean thermal structure. It is anticipated that the oceanic data from this monitoring array will also be used in a predictive mode for initialization studies of regional coupled climate models. Of particular interest are zonal and meridional modes of ocean-atmosphere variability within the tropical Atlantic basin that have significant impacts on the regional climate of the bordering continents...|$|R
40|$|Characteristic {{neuronal}} heterotopias in {{two cases}} of Zellweger's cerebro-hepato-renal disease were studied with the Golgi method. In the corona radiata, heterotopias consist of large fields of small or medium-sized radial pyramids, and of dense clusters containing larger, randomly oriented pyramidal cells and multipolar neurons, {{some of which}} resemble granule cells. The latter type of heterotopia could result from a <b>focal</b> destructive <b>process</b> at a relatively early stage of neuronal migration. In the cerebellar white matter, heterotopic masses contain Purkinje cells and possibly Golgi neurons but no granule or basket cells. The mispositioned Purkinje cells resemble the subcortical and intragranular Purkinje cells of the reeler mutant mouse {{and those of the}} weaver mutant. The morphology of neurons in the abnormally convoluted olivary nucleus is normal...|$|R
40|$|Application of {{nanotechnology}} (or nanobiotechnology) in biomedicinemay {{contribute to}} significant advances in imaging diagnosis andtreatment of cancer. Superparamagnetic nanoparticles can be usedto immunologically locate tumor cells, to early detect tumors andmicrometastases by nuclear magnetic resonance. Nanoparticlestaining of tumor cells can also facilitate tumor eradication througha <b>focal</b> heat generation <b>process</b> known as magnetohyperthermia. Inthis study prospective applications of nanobiotechnology in cancerdiagnosis and treatment are discussed, {{focusing on the}} improvementof immunological approaches and gene therapies...|$|R
50|$|The {{cutting process}} is {{performed}} by a femtosecond laser, emitting radiation in the near-infrared range. Within this wavelength range, the laser is able to penetrate the tissue {{up to a certain}} depth without causing thermal damage. By tight focusing of the laser radiation, intensities over 1 TW/cm2 (1 TW = 1012 watts) arise inside the laser focus. These extreme intensities induce nonlinear effects and optical breakdown occurs. This causes the disruption of the material, limited to the <b>focal</b> point. The <b>process</b> is known as photodisruption.|$|R
40|$|One hundred twenty-nine 111 In-oxine-labeled {{leukocyte}} scintiscans {{have been}} performed in 117 patients with cancer in order to diagnose localized infectious disease. Of the 115 contributive scans, 40 were in patients with localizing signs, whereas in 75 fever of unknown origin constituted the indication for this examination. The overall specificity of the method was 95. 4 %, the overall sensitivity 86 %, and the global accuracy 91. 3 %. In 10 cases with localizing signs, the 111 In-oxine granulocyte scintigram allowed exclusion of the diagnosis of infection, whereas in 17 instances without localizing signs, a <b>focal</b> infectious <b>process</b> was demonstrated. Heterologous donor leukocytes were used successfully in five instances. With the exception of accumulation of label {{at the site of}} an osteolytic metastasis in one case, no uptake was observed in primary or secondary tumors. It is concluded that 111 In-oxine-labeled leukocytes constitute a valuable tool in the diagnosis and localization of infection in patients with malignant disease. SCOPUS: NotDefined. jFLWINinfo:eu-repo/semantics/publishe...|$|R
40|$|The upper crust {{beneath the}} Vogtland is {{a region of}} active magmatic and tectonic processes, which many {{geophysical}} data, long time gps measurements and hydrothermal activity demonstrate. This project deals with the interpretation of geophysical data, more precisely seismic events and <b>processed</b> <b>focal</b> solutions, {{to get an idea}} which recent tectonic forces are working in this area and how they correlate with potential fault planes. These were modelled from the geophysical data, with the help of already existing fault maps and geomorphological indicators. For the visualisation of the geological and geophysical data we used the program GoCad...|$|R
40|$|Accurate {{stratification}} of tumors {{is imperative}} for adequate cancer management. In addition to staging, morphological subtyping allows stratification of patients into additional prognostic groups. In this study, we used an image-based computational method on pan-cytokeratin immunohistochemical (IHC) stainings to quantify tumor fragmentation (TF), {{a measure of}} tumor invasiveness of lung squamous cell carcinoma (LSCC). In two independent clinical cohorts from tissue microarrays (TMA: n= 208 patients) and whole sections (WS: n= 99 patients), TF was associated with poor prognosis and increased risk of blood vessel infiltration. A third cohort from the cancer genome atlas (TCGA: n= 335 patients) confirmed the poor prognostic value of TF using a similar human-based score on haematoxylin-eosin (H&E) staining. Integration of RNA-seq data from TCGA and LC-MS/MS proteomics from WS revealed an upregulation of extracellular matrix remodeling and <b>focal</b> adhesion <b>processes</b> in tumors with high TF, supporting their increased invasive potential. This proposed histologic parameter is an independent and unfavorable prognostic marker that could be established as a new grading parameter for LSCC...|$|R
40|$|Abstract Introduction Primary {{hyperparathyroidism}} is {{a common}} endocrine disorder characterized by elevated parathyroid hormone levels, which cause continuous osteoclastic bone resorption. Giant cell tumor of bone is an expansile osteolytic tumor that contains numerous osteoclast-like giant cells. There are many similarities in the radiological and histological features of giant cell tumor of bone and brown tumor. This is a rare benign <b>focal</b> osteolytic <b>process</b> most commonly caused by hyperparathyroidism. Case presentation We report the unusual case of a 40 -year-old Caucasian woman in which primary hyperparathyroidism was diagnosed after surgical ablation of a costal mass. The mass was suspected of being neoplastic and histopathology was compatible with a giant cell tumor of bone. On {{the basis of the}} biochemical results (including serum calcium, phosphorous and intact parathyroid hormone levels) primary hyperparathyroidism was suspected and a brown tumor secondary to refractory hyperparathyroidism was diagnosed. Conclusions Since giant cell tumor is a bone neoplasm that has major implications for the patient, the standard laboratory tests in patients with bone lesions are important for a correct diagnosis. </p...|$|R
40|$|The {{yellow fever}} (YF) 17 D vaccine {{is one of}} the most {{effective}} human vaccines ever created. The YF vaccine has been produced since 1937 in embryonated chicken eggs inoculated with the YF 17 D virus. Yet, little information is available about the infection mechanism of YF 17 DD virus in this biological model. To better understand this mechanism, we infected embryos of Gallus gallus domesticus and analyzed their histopathology after 72 hours of YF infection. Some embryos showed few apoptotic bodies in infected tissues, suggesting mild <b>focal</b> infection <b>processes.</b> Confocal and super-resolution microscopic analysis allowed us to identify as targets of viral infection: skeletal muscle cells, cardiomyocytes, nervous system cells, renal tubular epithelium, lung parenchyma, and fibroblasts associated with connective tissue in the perichondrium and dermis. The virus replication was heaviest in muscle tissues. In all of these specimens, RT-PCR methods confirmed the presence of replicative intermediate and genomic YF RNA. This clearer characterization of cell targets in chicken embryos paves the way for future development of a new YF vaccine based on a new cell culture system...|$|R
40|$|This chapter {{presents}} {{a study of}} the doublespeak terms used by Maxine Hong Kingston, the Chinese American writer, in the experiential narrative of her visit to the Arizona-Mexico border in the United States. The study is carried out within a cognitive paradigm, and employs the tools of the Conceptual Integration Theory proposed by Fauconnier and Turner (1994, 1998, 2002). The theoretical part discusses the concept of doublespeak, as researched by Lutz (1990, 1997), and points to its pragmatic functions, common devices, means of identification in a discourse and the folk reaction when doublespeak is encountered. The method employed for this study is the Conceptual Integration Theory, also known as Conceptual Blending or the Theory of Online Meaning Construction, and will be presented with its <b>focal</b> concepts, <b>processes</b> and aims. The analytical section intends to highlight the hidden meanings of euphemisms and instances of jargon from Kingston's narrative, as they emerge in the process of conceptual integration. Thus, the overall aim is to domesticate complex concepts and provide insights into the manipulative modality of doublespeak, a deviant form of political discourse...|$|R
40|$|The {{key to a}} library’s {{success is}} its ability to {{effectively}} and economically deliver services and information that users value. Additionally, the objective of supply chain management is to coordinate the <b>focal</b> firm’s <b>processes</b> and activities with those of its suppliers and customers, such that the firm’s delivered products and services meet or exceed customer requirements. It thus seemed appropriate to analyze a library from a supply chain perspective to assess and improve its ability to serve its users. Consequently, the authors employed an action research methodology to work with library personnel from two departments, User Services and Technical Services, as they merged into one division, to map the information resources supply chain of the University of Nevada, Las Vegas Lied Library. Once the supply chain model was completed, key processes were analyzed and performance measures designed, with the goal of improving division products and services. This paper reviews the relevant literature, presents the Lied Library information resources supply chain model, and provides the performance measures along with several improvement examples...|$|R
40|$|The {{subduction}} of the D'Entrecasteaux fracture zone-seismic ridge {{system in}} the New Hebrides island arc is investigated {{on the basis of}} the <b>focal</b> <b>process</b> of the New Hebrides earthquake of 1969 January 19 (m_b= 6. 4, h= 107 km), mechanisms of some related events, seismicity and regional tectonics. A notable feature of this island arc is the discontinuity of the New Hebrides Trench in the central New Hebrides where the ridge-fracture zone is subducting and intersecting the arc. The 1969 New Hebrides earthquake occurred along the subducted portion of the fracture zone and is characterized by unusual waveforms with remarkably large excitation of long period waves, rare for earthquakes of comparable mb and depth; the P-wave records show anomalously long duration and complexity indicating that the earthquake was a multiple event with a source duration of at least 30 s. P-wave first motions, seismicity data and synthetic body-wave seismogram indicate that the earthquake represents transverse left-lateral motion on a nearly vertical, E—W trending fault plane with a slip vector subparallel to the down-dip direction of the Benioff zone. The total seismic moment is found to be 5 × 10 ^(26) dyne cm by matching the amplitudes and waveforms between observed and synthetic surface waves. The location and mechanism of this earthquake suggest that the D'Entrecasteaux fracture zone structurally extends to the east of the trench. This structural boundary at depth seems to be reflected in the spatial distribution of two earthquake swarms which are bounded sharply at the latitude of 15. 2 °S. At the extension of the ridge-fracture zone, the activity of intermediate depth earthquakes, which are characterized by a very consistent pattern of down-dip extensional mechanism, is much higher and their depths are systematically shallower than in the adjacent regions. These features can be interpreted as a consequence of subduction of a buoyant ridge and the resultant increase in the extensional stress at the intermediate depths of the sinking slab. Fault-plane solutions of 22 earthquakes suggest that the subduction of aseismic ridges in the New Hebrides is characterized by high-angle thrusts. The lithospheres on the two sides of the D'Entrecasteaux fracture zone under the arc subduct more or less independently and generate alternating left-lateral and right-lateral earthquakes along the subducted portion of the fracture zone...|$|R
40|$|The pck rat: A {{new model}} that resembles human {{autosomal}} dominant polycystic kidney and liver disease. BackgroundThe pck rat is a recently identified model of {{polycystic kidney disease}} (PKD) and liver disease (PLD) that developed spontaneously in the rat strain Crj:CD/SD. Its pattern of inheritance is autosomal recessive. MethodsTo characterize this new model, we studied pck rats derived from F 9 breeding pairs from Charles River Japan and control Sprague-Dawley rats. Blood and tissues (kidneys, liver, and pancreas), obtained from these rats at 1, 7, 21, 70, and 182 days of age, were used for biochemical determinations, light and electron microscopy, and immunohistochemistry. ResultsThe pck rats develop progressive cystic enlargement of the kidneys after {{the first week of}} age, and liver cysts are evident by day 1. The renal cysts developed as a <b>focal</b> <b>process</b> from thick ascending loops of Henle, distal tubules, and collecting ducts in the corticomedullary region and outer medulla. Flat and polypoid epithelial hyperplasia were common in dilated tubules and cysts. Apoptosis was common and affected normal, as well as dilated tubules, but less frequently cysts lined by flat epithelium. The basement membranes of the cyst walls exhibited a variety of alterations, including thinning, lamellation, and thickening. Focal interstitial fibrosis and inflammation were evident by 70 days of age. Segmental glomerulosclerosis and segmental thickening of the basement membrane with associated effacement of the podocyte foot processes were noted in some rats at 70 days of age. The PKD was more severe in male than in female pck rats, as reflected by the higher kidney weights, while there was no gender difference in the severity of the PLD. Mild bile duct dilation was present as early as one day of age. With age, it became more severe, and the livers became markedly enlarged. Even then, however, there was only a mild increase in portal fibrosis, without formation of fibrous septae. Slight elevations of plasma blood urea nitrogen levels were detected at 70 and 182 days of age. ConclusionsThe pck rat is a new inherited model of PKD and PLD with a natural history and renal and hepatic histologic abnormalities that resemble human autosomal dominant PKD. This model may be useful for studying the pathogenesis and evaluating the potential therapies for PKD and PLD. The identification of the pck gene may provide further insight into the pathogenesis of autosomal dominant PKD...|$|R
40|$|RivFunction is a pan-European {{initiative}} {{that started in}} 2002 and was aimed at esta- blishing a novel functional-based approach to assessing the ecological status of rivers. Litter decomposition {{was chosen as the}} <b>focal</b> <b>process</b> because it plays a central role in stream ecosystems and is easy to study in the field. Impacts of two stressors that occur across the continent, nutrient pollution and modified riparian vegetation, were exam- ined at > 200 paired sites in nine European ecoregions. In response to the former, decomposition was dramatically slowed at both extremes of a 1000 -fold nutrient gra- dient, indicating nutrient limitation in unpolluted sites, highly variable responses across Europe in moderately impacted streams, and inhibition via associated toxic and addi- tional stressors in highly polluted streams. Riparian forest modification by clear cutting or replacement of natural vegetation by plantations (e. g. conifers, eucalyptus) or pasture produced similarly complex responses. Clear effects caused by specific riparian distur- bances were observed in regionally focused studies, but general trends across different types of riparian modifications were not apparent, in part possibly because of important indirect effects. Complementary field and laboratory experiments were undertaken to tease apart the mechanistic drivers of the continental scale field bioassays by addressing the influence of litter, fungal and detritivore diversity. These revealed generally weak and context-dependent effects on decomposition, suggesting high levels of redundancy (and hence potential insurance mechanisms that can mitigate a degree of species loss) within the food web. Reduced species richness consistently increased decomposition variability, if not the absolute rate. Further field studies were aimed at identifying impor- tant sources of this variability (e. g. litter quality, temporal variability) to help constrain ranges of predicted decomposition rates in different field situations. Thus, although ￼many details still need to be resolved, litter decomposition holds considerable potential in some circumstances to capture impairment of stream ecosystem functioning. For instance, species traits associated with the body size and metabolic capacity of the con- sumers were often the main driver at local scales, and these were often translated into important determinants of otherwise apparently contingent effects at larger scales. Key insights gained from conducting continental scale studies included resolving the appar- ent paradox of inconsistent relationships between nutrients and decomposition rates, as the full complex multidimensional picture emerged from the large-scale dataset, of which only seemingly contradictory fragments had been seen previously...|$|R
