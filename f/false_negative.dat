4883|3023|Public
5|$|However, , {{with the}} {{exception}} of Spiroplasma mirum strain SMCA causing spongiform microcystic encephalitis in suckling rats, other researchers have been unable to duplicate these findings, casting doubt on the Spiroplasma hypothesis. In defense of the Spiroplasma hypothesis, Bastian pointed out that Spiroplasma is hard to culture and that strain variation makes it hard to detect certain strains using PCR and other techniques, thus giving a <b>false</b> <b>negative.</b>|$|E
5|$|Dilation and {{curettage}} or an {{endometrial biopsy}} {{are used to}} obtain a tissue sample for histological examination. Endometrial biopsy is the less invasive option, {{but it may not}} give conclusive results every time. Hysteroscopy only shows the gross anatomy of the endometrium, which is often not indicative of cancer, and is therefore not used, unless in conjunction with a biopsy. Hysteroscopy can be used to confirm a diagnosis of cancer. New evidence shows that D has a higher <b>false</b> <b>negative</b> rate than endometrial biopsy.|$|E
5|$|In Batesian mimicry {{the mimic}} shares signals {{similar to the}} model, but {{does not have the}} {{attribute}} that makes it unprofitable to predators (e.g., unpalatability). In other words, a Batesian mimic is a sheep in wolf's clothing. It is named after Henry Walter Bates, an English naturalist whose work on butterflies in the Amazon rainforest (described in The Naturalist on the River Amazons) was pioneering in this field of study. Mimics {{are less likely to be}} found out (for example by predators) when in low proportion to their model. This phenomenon is called negative frequency dependent selection, and it applies in most forms of mimicry. Batesian mimicry can only be maintained if the harm caused to the predator by eating a model outweighs the benefit of eating a mimic. The nature of learning is weighted in favor of the mimics, for a predator that has a bad first experience with a model tends to avoid anything that looks like it for a long time, and does not re-sample soon to see whether the initial experience was a <b>false</b> <b>negative.</b> However, if mimics become more abundant than models, then the probability of a young predator having a first experience with a mimic increases. Such systems are therefore most likely to be stable where both the model and the mimic occur, and where the model is more abundant than the mimic. This is not the case in Müllerian mimicry, which is described next.|$|E
2500|$|Negative posttest {{probability}} = <b>False</b> <b>negatives</b> / (<b>False</b> <b>negatives</b> + True negatives) ...|$|R
30|$|Errors of S 3 {{come from}} false positives and <b>false</b> <b>negatives.</b> S 3 seeks to achieve higher {{performance}} than prior work by reducing false positives and <b>false</b> <b>negatives.</b> However, {{to choose the}} optimal threshold in the trade-off of false positives and <b>false</b> <b>negatives,</b> we seek less <b>false</b> <b>negatives</b> than <b>false</b> positives. This is because false positives identify normal data as sensitive, and thus cause over protection, while <b>false</b> <b>negatives</b> leave sensitive data unprotected, and cause more serious consequences, e.g., data exposed to attackers. In statistics, Recall can reflect the measure of <b>false</b> <b>negatives</b> and Precision reflects false positives. Therefore we seek higher recall value than precision value in this paper.|$|R
40|$|In many {{classification}} {{problems such}} as spam detection and network intrusion, {{a large number of}} unlabeled test instances are predicted negative by the classifier. However, the high costs as well as time constraints on an expert’s time prevent further analysis of the “predicted false” class instances in order to segregate the <b>false</b> <b>negatives</b> from the true negatives. A systematic method is thus required to obtain an estimate of the number of <b>false</b> <b>negatives.</b> A capture-recapture based method can be used to obtain an ML-estimate of <b>false</b> <b>negatives</b> when two or more independent classifiers are available. In the case for which independence does not hold, we can apply log-linear models to obtain an estimate of <b>false</b> <b>negatives.</b> However, as shown in this paper, lesser the dependencies among the classifiers, better is the estimate obtained for <b>false</b> <b>negatives.</b> Thus, ideally independent classifiers should be used to estimate the <b>false</b> <b>negatives</b> in an unlabeled dataset. Experimental results on the spam dataset from the UCI Machine Learning Repository are presented. ...|$|R
25|$|A <b>false</b> <b>negative</b> {{occurs when}} a spam email is not {{detected}} as spam, but is classified as non-spam. A low number of false negatives is {{an indicator of the}} efficiency of spam filtering.|$|E
25|$|Dehydration {{can change}} the way {{subcutaneous}} insulin is absorbed, so either hyperglycemia or hypoglycemia are possible; dehydration can also cause <b>false</b> <b>negative</b> or positive urine ketone test results. Hyperglycemia means more of a risk for dehydration.|$|E
25|$|Increased {{levels of}} PSA may suggest the {{presence}} of prostate cancer. However, prostate cancer can also {{be present in the}} complete absence of an elevated PSA level, in which case the test result would be a <b>false</b> <b>negative.</b>|$|E
50|$|<b>False</b> <b>negatives</b> {{occur when}} the {{wireless}} intrusion prevention system fails to detect an access point actually connected to the secure network as wired rogue. <b>False</b> <b>negatives</b> result in security holes.|$|R
30|$|The recall is {{sensitive}} to <b>false</b> <b>negatives,</b> {{and on the other}} hand, precision {{is sensitive}} to false positives. If the levenshtein values are higher, then false positives increase, and if the levenshtein values are lower, then <b>false</b> <b>negatives</b> increase.|$|R
5000|$|Two other {{commonly}} used F measures are the [...] measure, which weighs recall higher than precision (by placing {{more emphasis on}} <b>false</b> <b>negatives),</b> and the [...] measure, which weighs recall lower than precision (by attenuating the influence of <b>false</b> <b>negatives).</b>|$|R
25|$|Pregnancy {{tests are}} not {{accurate}} until 1–2 weeks after ovulation. Knowing an estimated date of ovulation can prevent {{a woman from}} getting <b>false</b> <b>negative</b> results due to testing too early. Also, 18 consecutive days of elevated temperatures means a woman is almost certainly pregnant.|$|E
25|$|This {{is because}} the immune system needs to be {{functional}} to mount {{a response to the}} protein derivative injected under the skin. A <b>false</b> <b>negative</b> result may occur in a person who has been recently infected with TB, but whose immune system hasn't yet reacted to the bacteria.|$|E
25|$|False negatives produce {{serious and}} counter-intuitive problems, {{especially}} when the condition being searched for is common. If a test with a <b>false</b> <b>negative</b> rate of only 10%, is used to test a population with a true occurrence rate of 70%, many of the negatives detected by the test will be false.|$|E
3000|$|... are {{the number}} of <b>false</b> <b>negatives,</b> <b>false</b> positives and ID switches, respectively, for time t, while g [...]...|$|R
5000|$|... where , , [...] and [...] are {{the number}} of true positives, <b>false</b> <b>negatives,</b> <b>false</b> positives and true negatives respectively.|$|R
40|$|During Bounded Model Checking (BMC) {{blocks of}} a design are often {{considered}} separately due to complexity issues. Because {{the environment of}} a block is not avail-able for the proof, invalid input sequences frequently lead to <b>false</b> <b>negatives,</b> i. e. counter-examples that can not occur in the complete design. Finding and understanding such <b>false</b> <b>negatives</b> is currently a time-consuming manual task. Here, we propose a method to automatically avoid <b>false</b> <b>negatives</b> which are caused by invalid input sequences for blocks connected by standard communication protocols. 1...|$|R
25|$|One of {{the reasons}} that blood tests are not {{reliable}} for accurate peptic ulcer diagnosis on their own is their inability to differentiate between past exposure to the bacteria and current infection. Additionally, a <b>false</b> <b>negative</b> result is possible with a blood test if the person has recently been taking certain drugs, such as antibiotics or proton-pump inhibitors.|$|E
25|$|To get an {{appropriate}} example in a real-world problem, consider a diagnostic test {{that seeks to}} determine whether a person has a certain disease. A false positive in this case occurs when the person tests positive, but does not actually have the disease. A <b>false</b> <b>negative,</b> on the other hand, occurs when the person tests negative, suggesting they are healthy, when they actually do have the disease.|$|E
25|$|Power {{of a test}} (1−β): The test's {{probability}} of correctly rejecting the null hypothesis. The complement of the <b>false</b> <b>negative</b> rate, β. Power is termed sensitivity in biostatistics. ("This is a sensitive test. Because the result is negative, we can confidently say that the patient {{does not have the}} condition.") See sensitivity and specificity and Type I and type II errors for exhaustive definitions.|$|E
50|$|The {{tuberculin}} skin test, {{commonly used}} for detection of {{other forms of}} tuberculosis, is not useful in the detection of miliary tuberculosis. The tuberculin skin test fails due to the high numbers of <b>false</b> <b>negatives.</b> These <b>false</b> <b>negatives</b> may occur because of higher rates of tuberculin anergy compared {{to other forms of}} tuberculosis.|$|R
30|$|Viola and Jones [12] applied {{asymmetry}} to AdaBoost {{by assigning}} k times larger weight to <b>false</b> <b>negatives</b> than <b>false</b> positives. Fan et al. [21] proposed AdaCost, a cost-sensitive extension of AdaBoost, in which <b>false</b> <b>negatives</b> are assigned larger weights than false positives and true negatives are assigned smaller weights than true positives. Ting [22] proposed {{a method that}} assigns larger weights to <b>false</b> <b>negatives</b> based on a cost function that reflects the importance of misclassified samples. While these methods achieve higher detection performance, the weight update is heuristic, {{making it difficult to}} predict performance prior to in-field use.|$|R
30|$|Note that <b>false</b> <b>negatives</b> in {{counting}} bloom filters {{may occur}} if an erroneous element removal is performed. This removal {{may result in}} a biased and inconsistent probabilistic data structure. For example, if a removed element is not actually hashed, then its removal changes bits indicating memberships of other elements that are actually hashed (Deke et al. 2010). This paper assumes that <b>false</b> <b>negatives</b> cannot be generated in principle if and only if removals are not performed from counting bloom filters. Otherwise, Section “Second level check” illustrates how <b>false</b> <b>negatives</b> are prevented in DIAS if removals are performed.|$|R
25|$|The main {{criticism}} {{applied to}} the yeast two-hybrid screen of protein–protein interactions are {{the possibility of a}} high number of false positive (and <b>false</b> <b>negative)</b> identifications. The exact rate of false positive results is not known, but earlier estimates were as high as 70%. This also, partly, explains the often found very small overlap in results when using a (high throughput) two-hybrid screening, especially when using different experimental systems.|$|E
25|$|Bartonella spp. often evade {{an immune}} response, thus {{antibodies}} {{may not be}} detected even concurrent with an infection, resulting in an IFA <b>false</b> <b>negative</b> rate of up to 83% in chronically infected patients when other test results (e.g. organism isolation or PCR) are positive. IFA sensitivity may range from 14-100%, causing discrepancies between PCR and serology test results. Positive IFA results do not distinguish between current infection and prior exposure.|$|E
25|$|By {{relying on}} the result of one cell from the {{multi-cell}} embryo, PGD operates {{under the assumption that}} this cell is representative of the remainder of the embryo. This may not be the case as the incidence of mosaicism is often relatively high. On occasion, PGD may result in a <b>false</b> <b>negative</b> result leading to the acceptance of an abnormal embryo, or in a false positive result leading to the deselection of a normal embryo.|$|E
30|$|<b>False</b> <b>Negatives</b> (FN) events {{reported}} by INGV but not detected by our system.|$|R
2500|$|... {{avoiding}} the typeII errors (or <b>false</b> <b>negatives)</b> that classify imposters as authorized users.|$|R
30|$|The ‘safer’ {{approach}} to handle inconsistencies is to ignore these aggregation sessions and not perform any aggregation {{that may result}} in inaccurate aggregates. However, not only the aggregates can be influenced in this case. Recall {{from the beginning of}} this section that removal of a membership from a counting bloom filter that is actually not present introduces <b>false</b> <b>negatives</b> (Deke et al. 2010). Therefore, the following aggregation sessions are prone to inaccuracies as the assumption of no <b>false</b> <b>negatives</b> does not hold anymore. By skipping inconsistent aggregation sessions, DIAS makes sure that the condition of no <b>false</b> <b>negatives</b> in counting bloom filters is not violated.|$|R
25|$|As most porphyrias {{are rare}} conditions, general {{hospital}} labs typically {{do not have}} the expertise, technology, or staff time to perform porphyria testing. In general, testing involves sending samples of blood, stool, and urine to a reference laboratory. All samples to detect porphyrins must be handled properly. Samples should be taken during an acute attack; otherwise a <b>false</b> <b>negative</b> result may occur. Samples must be protected from light and either refrigerated or preserved.|$|E
25|$|A {{main problem}} is that, as {{with other types of}} phylogenetic inferences, the actual {{evolutionary}} history cannot be established with certainty. As a result, it is difficult to obtain a representative test set of HGT events. Furthermore, HGT inference methods vary considerably in the information they consider and often identify inconsistent groups of HGT candidates: it is not clear to what extent taking the intersection, the union, or some other combination of the individual methods affects the false positive and <b>false</b> <b>negative</b> rates.|$|E
25|$|The Pap smear {{can be used}} as a {{screening}} test, but is <b>false</b> <b>negative</b> in up to 50% of cases of cervical cancer. Confirmation of the diagnosis of cervical cancer or precancer requires a biopsy of the cervix. This is often done through colposcopy, a magnified visual inspection of the cervix aided by using a dilute acetic acid (e.g. vinegar) solution to highlight abnormal cells on the surface of the cervix. Medical devices used for biopsy of the cervix include punch forceps, SpiraBrush CX, SoftBiopsy, or Soft-ECC.|$|E
2500|$|... the {{acceptable}} level of <b>false</b> <b>negatives</b> (in which an actual match is not detected).|$|R
5000|$|... {{avoiding}} the type II errors (or <b>false</b> <b>negatives)</b> that classify imposters as authorized users.|$|R
30|$|Accuracy is {{the most}} {{important}} criterion for determining the efficiency of a model calculating the exact criterion for the entire category. Based on it, Naïve Bayes for Wiley Online Library has the best result. In another side, recall measures the completeness, or sensitivity, of a classifier. Higher recall means few <b>false</b> <b>negatives,</b> while lower recall means more <b>false</b> <b>negatives</b> [46].|$|R
