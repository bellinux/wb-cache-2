74|197|Public
50|$|Within a micro {{instruction}} <b>execution</b> <b>cycle,</b> the CPU {{as well as}} {{an input}} / output controller is connected to an external 16 kByte huge random access memory device (RAM). Via the input-output controller device, communication with virtual input and output devices is supported by Direct Memory Access mode (DMA), Inter-Integrated Circuit Connection (I2C), and Interrupt request functionality (IRQ). A output port, a display, a timer, an event trigger, a digital-analog converter, a keyboard and data input / output channel is provided as virtual IC device for explaining didactically the communication with external devices.|$|E
30|$|In [12], {{complexity}} profiling is done {{in every}} frame using the <b>execution</b> <b>cycle</b> of each module.|$|E
30|$|Metric: efficiency: A {{participant}} observes if {{the simulation}} is successfully {{triggered by the}} stimuli received during its entire <b>execution</b> <b>cycle.</b>|$|E
40|$|This paper {{presents}} {{the evaluation of}} a non-blocking, decoupled memory/execution, multithreaded architecture known as the Scheduled Dataflow (SDF). Our research explores a simple, yet powerful execution paradigm {{that is based on}} non-blocking threads, and decoupling of memory accesses from execution pipeline. This paper compares the <b>execution</b> <b>cycles</b> required for programs on SDF with the <b>execution</b> <b>cycles</b> required by programs on Superscalar and VLIW architectures...|$|R
5000|$|Every process' {{program can}} be {{partitioned}} into four sections, resulting in four states. Program <b>execution</b> <b>cycles</b> through these four states in order: ...|$|R
40|$|This paper proposes an {{improved}} branch predictor {{that reduces the}} number <b>execution</b> <b>cycles</b> of applications by selectively accessing a specific element in 4 -way associative cache. When a branch instruction is fetched, the proposed branch predictor acquires a branch target address from the selected element in the cache by referring to MRU buffer. Branch prediction rate and application execution speed are considerably improved by {{increasing the number of}} BTAC entries in restricted power condition, when compared with that of previous branch predictor which accesses all elements. The effectiveness of the proposed dynamic branch predictor is verified by executing benchmark applications on the core simulator. Experimental results show that number of <b>execution</b> <b>cycles</b> decreases by an average of 10. 1 %, while power consumption increases an average of 7. 4 %, when compared to that of a core without a dynamic branch predictor. <b>Execution</b> <b>cycles</b> are reduced by 4. 1 % in comparison with a core which employs previous dynamic branch predictor...|$|R
40|$|Contents 1. THE COMPONENTS OF A CLASSIFIER SYSTEM APPLICATION [...] . 1 CLASSIFIERS [...] . 1 MESSAGES AND MESSAGE LISTS [...] 2 THE <b>EXECUTION</b> <b>CYCLE</b> [...] . 4 PRODUCING NEW MESSAGES [...] . 5 THE BUCKET BRIGADE ALGORITHM [...] ...|$|E
30|$|To {{evaluate}} {{the increase in}} speed provided by our hardware-based sensor device implementation, <b>execution</b> <b>cycle</b> counts are compared with the typical sensor devices found in the literature, namely general purpose processor-based solution[7], sensor processor-based solution[11], and event processor-based solution[13].|$|E
30|$|We then {{generated}} the sensitivity matrix by running an experiment where the oracle was accessed {{to confirm the}} matches found by our heuristic algorithm. This test considered the interval [0.40 to 0.90] for each similarity threshold and a variance of 0.05 for each <b>execution</b> <b>cycle.</b>|$|E
40|$|This paper {{presents}} {{the evaluation of}} a non-blocking, decoupled memory/execution, multithreaded architecture known as the Scheduled Dataflow (SDF). The major recent trend in digital signal processor (DSP) architecture is to use complex organizations to exploit instruction level parallelism (ILP). The two most common approaches for exploiting the ILP are Superscalars and Very Long Instruction Word (VLIW) architectures. On the other hand, our research explores a simple, yet powerful execution paradigm {{that is based on}} non-blocking threads, and decoupling of memory accesses from execution pipeline. This paper compares the <b>execution</b> <b>cycles</b> required for programs on SDF with the <b>execution</b> <b>cycles</b> required by programs on Superscalar and VLIW architectures...|$|R
40|$|Intra-task voltage {{scheduling}} (IntraVS), which {{adjusts the}} supply voltage within an individual task boundary, {{is an effective}} technique for developing low-power applications. In this paper, we propose a novel intra-task voltage scheduling algorithm for hard real-time applications based on average-case execution information. Unlike the original IntraVS algorithm where voltage scaling decisions {{are based on the}} worst-case <b>execution</b> <b>cycles,</b> the proposed algorithm improves the energy efficiency by controlling the execution speed based on average-case <b>execution</b> <b>cycles</b> while still meeting the real-time constraints. The experimental results using an MPEG- 4 decoder program show that the proposed algorithm reduces the energy consumption by up to 34 % over the original IntraVS algorithm. 1...|$|R
40|$|For two {{variants}} of runways with abrasive concrete pavements in the prestressed and dowelled technologies, analyses {{have been presented}} regarding labour, materials, use of machinery, and financial outlays, together with the necessary technological-organisational analyses and assessment of work <b>execution</b> <b>cycles,</b> by the example of construction of a runway at the Katowice Airport...|$|R
3000|$|..., is {{measured}} {{in the number of}} complete address vectors generated per <b>execution</b> <b>cycle.</b> For the example program in Algorithm 3 the efficiency can be estimated as follows: in the main loop body, which is repeated 4095 times, every 3 execution cycles a vector with 6 elements is produced. Since this vector is valid 6048 times out of 8192 and a complete vector contains 8 elements, the efficiency is equal to approximately [...]...|$|E
40|$|We {{present the}} design of a BPEL {{orchestration}} engine based on ReSpecT tuple centres, a coordination model extending Linda with the ability of declaratively programming the reactive behaviour of tuple spaces. Architectural and linguistic aspects of our solution are discussed, focussing on how the syntax and semantics of BPEL have been mapped to tuple centres. This is achieved by a translation of BPEL specifications to set of logic tuples, and conceiving the <b>execution</b> <b>cycle</b> of the orchestration engine in terms of ReSpecT reactions. ...|$|E
40|$|This paper {{presents}} an extension to the Arduino framework that introduces multitasking support and allows running multiple concurrent tasks {{in addition to}} the single <b>execution</b> <b>cycle</b> provided by the standard Arduino framework. The extension has been implemented through the ERIKA Enterprise open-source real-time kernel, while maintaining the simplicity of the programming paradigm typical of the Arduino framework. Furthermore, a support for resource sharing has also been integrated in the external Arduino libraries to guarantee mutual exclusion in such a multi-task environment...|$|E
40|$|A {{significant}} portion of a program’s <b>execution</b> <b>cycles</b> are typically dedicated to performing conditional transfers of control. Much {{of the research on}} reducing the costs of these operations has focused on the branch, while the comparison has been largely ignored. In this paper we investigate reducing the cost of comparisons in conditional transfers of control. We decouple the specification of the values to be compared from the actual comparison itself, which now occurs as part of the branch instruction. The specification of the register or immediate values involved in the comparison is accomplished via a new instruction called a comparison specification, which is loop invariant. Decoupling the specification of the comparison from the actual comparison performed before the branch reduces the number of instructions in the loop, which provides performance benefits not possible when using conventional comparison instructions. Results from applying this technique on the ARM processor show that both the number of instructions executed and <b>execution</b> <b>cycles</b> are reduced...|$|R
40|$|The {{quality of}} {{synthesis}} results for most high level synthesis approaches is strongly a ected by {{the choice of}} control ow (through conditions and loops) in the input description. In this paper, we explore the e ectiveness of various types of code motions, such asmoving operations across conditionals, out of conditionals (speculation) and into conditionals (reverse speculation), {{and how they can}} be e ectively directed by heuristics so as to lead to improved synthesis results in terms of fewer <b>execution</b> <b>cycles</b> and fewer number of states in the nite state machine controller. We also study the e ects of the code motions on the area and latency of the nal synthesized netlist. Based on speculative code motions, we present anovel way to perform early condition execution that leads to signi cant improvements in highly control-intensive designs. Overall, reductions of up to 38 % in <b>execution</b> <b>cycles</b> are obtained with all the code motions enabled. 1...|$|R
50|$|If objects have {{properties}} that are rarely used, this can improve startup speed. Mean average program performance may be slightly worse {{in terms of}} memory (for the condition variables) and <b>execution</b> <b>cycles</b> (to check them), but the impact of object instantiation is spread in time ("amortized") rather than concentrated in the startup phase of a system, and thus median response times can be greatly improved.|$|R
30|$|Many {{application}} {{domains of}} VMI {{are limited to}} monitor specific processes. A process could range from any legitimate code, such as API, user application or test code, to malicious code, such as like malware and rootkit. Process introspection {{should be able to}} debug any process at any point of time during its entire <b>execution</b> <b>cycle.</b> It should also be able to detect invocation of a specific module or code snippet. Process introspection helps in the analysis of code. Process introspection is also useful for malware behaviour analysis, debugging, etc.|$|E
40|$|We {{have been}} {{developing}} a computational {{theory of the}} effects of fatigue (especially sleep-related fluctuations in alertness) on the human cognitive system, implemented through mechanisms that impact existing components of the ACT-R architecture (Gunzelmann, Gluck, Kershner, Van Dongen, & Dinges, 2007; Gunzelmann, Gross, Gluck, & Dinges, 2009). These mechanisms include the suppression of activation in the declarative knowledge system, as well as brief breakdowns in the central production <b>execution</b> <b>cycle,</b> which we call micro-lapses. Through an iterative series of mechanistic architectural modifications, model implementations, and goodness-of-fit evaluations in task contexts like the Psychomotor Vigilanc...|$|E
30|$|Memory {{addressing}} {{is eliminated}} via the {{efficient use of}} dual-port FIFOs to store the particles' state vectors. Consequently, significant speed up of the PF process is achieved. There {{is no need to}} add memories to store the particles addresses or indexes as in [2, 7]. The overall memory size is 2 M for the sequential PF. In comparison, required memory sizes for the PFs of references [2, 7] are 3 M and 4 M, respectively. The FIFO eliminates the need to read, write, or store the states addresses/indexes in separate memory, and hence, reduces the <b>execution</b> <b>cycle</b> time.|$|E
40|$|Several {{studies have}} {{considered}} reducing instruction cache misses and branch penalty stall cycles {{by means of}} various forms of code placement. Most proposed approaches rearrange procedures or basic blocks in order to speed up execution on sequential architectures with branch prediction. Moreover, most works focus mainly on instruction cache performance and disregard <b>execution</b> <b>cycles.</b> To {{the best of our}} knowledge, no work has specifically addressed statically scheduled ILP machines like VLIWs, with control-transfer delay slots...|$|R
40|$|Encryption {{algorithms}} commonly {{use table}} lookups to perform substitution, {{which is a}} confusion primitive. The use of table lookups {{in this way is}} especially common in the more recent encryption algorithms, such as the AES finalists like MARS and Twofish, and the AES winner, Rijndael. Workload characterization studies indicate that these algorithms spend a significant fraction of their <b>execution</b> <b>cycles</b> on performing these table lookups, more specifically on effective address calculations. This study.. ...|$|R
40|$|This paper {{describes}} a SIMD optimization method for computing different Euclidean distance algorithms. Distance transforms {{have been widely}} applied to image analysis and pattern recognition problems. The proposed approach {{is based on the}} inherent fine and medium-grain parallelism of considered distance algorithms and has been implemented using Intel Streaming SIMD Extensions (SSE), intrinsics and VTune Analyzer. Experimental results show that optimized prefetched SIMD algorithms improve by four the number of <b>execution</b> <b>cycles</b> in comparison with the initial SISD solutions...|$|R
40|$|International audienceWe {{propose a}} {{software}} pipelining technique adapted to specific hard real-time scheduling problems. Our technique optimizes both computation throughput and <b>execution</b> <b>cycle</b> makespan, with makespan being prioritary. It also {{takes advantage of}} the predicated execution mechanisms of our embedded execution plat-form. To do so, it uses a reservation table formalism allowing the manipulation of the execution conditions of operations. Our reservation tables allow the double reservation of a resource at the same dates by two different operations, if the operations have exclusive execution conditions. Our analyses can determine when double reservation is possible even for operations belonging to different iterations...|$|E
40|$|Abstract—With {{semiconductor}} industry trend of “smaller the better”, from {{an idea to}} a final product, more innovation on product portfolio and yet remaining competitive and profitable are few criteria which are culminating into pressure and need {{for more and more}} innovation for CAD flow, process management and project <b>execution</b> <b>cycle.</b> Project schedules are very tight and to achieve first silicon success is key for projects. This necessitates quicker verification with better coverage matrix. Quicker Verification requires early development of the verification environment with wider test vectors without waiting for RTL to be available. DATA BUS UVC (Driver...|$|E
40|$|Abstract. As {{compared}} to a complex single processor based system, on-chip multiprocessors are less complex, more power efficient, and easier to test and validate. In this work, we focus on an on-chip multiprocessor where each processor has a local memory (or cache). We demonstrate that, in such an architecture, allowing each processor to do off-chip memory requests on behalf of other processors can improve overall performance over a straightforward strategy, where each processor performs off-chip requests independently. Our experimental results obtained using six benchmark codes indicate large <b>execution</b> <b>cycle</b> savings {{over a wide range}} of architectural configurations. ...|$|E
40|$|In this paper, the Scheduled Dataflow (SDF) architecturea {{decoupled}} memory/execution, multithreaded architecture using nonblocking threadsis {{presented in}} detail and evaluated against Superscalar architecture. Recent {{focus in the}} field of new processor architectures is mainly on VLIW (e. g., IA- 64), superscalar, and superspeculative designs. This trend allows for better performance, but at the expense of increased hardware complexity and, possibly, higher power expenditures resulting from dynamic instruction scheduling. Our research deviates from this trend by exploring a simpler, yet powerful execution paradigm that is based on dataflow and multithreading. A program is partitioned into nonblocking execution threads. In addition, all memory accesses are decoupled from the thread's execution. Data is preloaded into the thread's context (registers) and all results are poststored after the completion of the thread's execution. While multithreading and decoupling are possible with control-flow architectures, SDF makes it easier to coordinate the memory accesses and execution of a thread, as well as eliminate unnecessary dependencies among instructions. We have compared the <b>execution</b> <b>cycles</b> required for programs on SDF with the <b>execution</b> <b>cycles</b> required by programs on SimpleScalar (a superscalar simulator) by considering the essential aspects of these architectures {{in order to have a}} fair comparison. The result...|$|R
40|$|Leakage {{power is}} a major concern in current and future {{microprocessor}} designs. In this paper, we explore the potential of architectural techniques to reduce leakage through power-gating of execution units. This paper first develops parameterized analytical equations that estimate the break-even point for application of power-gating techniques. The potential for power gating execution units is then evaluated, for the range of relevant break-even points determined by the analytical equations, using a state-of-the-art out-of-order superscalar processor model. The power gating potential of the floating-point and fixed-point units of this processor is then evaluated using three different techniques to detect opportunities for entering sleep mode; ideal, time-based, and branch-misprediction-guided. Our results show that using the time-based approach, floating-point units can be put to sleep for up to 28 % of the <b>execution</b> <b>cycles</b> at a performance loss of 2 %. For the more difficult to power-gate fixed-point units, the branch misprediction guided technique allows the fixed-point units to be put to sleep for up to 40 % more of the <b>execution</b> <b>cycles</b> compared to the simpler time-based technique, with similar performance impact. Overall, our experiments demonstrate that architectural techniques can be used effectively in power-gating execution units...|$|R
40|$|This paper {{presents}} {{an evaluation of}} a non-blocking, decoupled memory/execution, multithreaded architecture known as the Scheduled Dataflow (SDF). Recent focus {{in the field of}} new processor architectures is mainly on VLIW (e. g. IA- 64), superscalar and superspeculative designs. This trend allows for better performance at the expense of increased hardware complexity, and possibly higher power expenditures resulting from dynamic instruction scheduling. Our research deviates from this trend by exploring a simpler, yet powerful execution paradigm that is based on dataflow and multithreading. A program is partitioned into non-blocking execution threads. In addition, all memory accesses are decoupled from the thread's execution. Data is pre-loaded into the thread's context (registers), and all results are post-stored after the completion of the thread's execution. While multithreading and decoupling are possible with control-flow architectures, we believe that the non-blocking and functional nature of SDF, make it easier to coordinate the memory accesses and execution of a thread, as well as eliminate unnecessary dependencies among instructions. In this paper we compare the <b>execution</b> <b>cycles</b> required for programs on SDF with the <b>execution</b> <b>cycles</b> required by programs on SimpleScalar (a Superscalar simulator) ...|$|R
40|$|We {{propose a}} new intra-task dynamic voltage scaling (DVS) method to capture an {{important}} fact of ‘software runtime distribution ’ and integrate it into DVS effectively. Specifically, the proposed method finds performance levels, {{for a given}} software runtime distribution, i. e. statistical profiling of execution cycles (neither the <b>execution</b> <b>cycle</b> of worst-case execution path nor the worst-case execution cycles of basic blocks), {{which leads to a}} minimal energy consumption while satisfying the given deadline constraints. Experimental results report that the proposed method gives 19. 2 %~ 33. 3 % further energy reduction compared with the best-known methods for two industrial multimedia software programs, H. 264 decoder and MPEG 4 decoder. 1...|$|E
40|$|Abstract. This paper {{deals with}} plan {{execution}} on agents/robots in highly dy-namic environments. Besides a formal semantics of plan execution and a repre-sentation of plans as programs, we introduce {{the concept of}} plan invariants. Plan invariants are similar to loop invariants in imperative programs in {{that they have to}} be true during the whole plan <b>execution</b> <b>cycle.</b> Once a plan invariant fails the plan execution is stopped and other plans that are more appropriate in the current context are considered for execution instead. The use of plan invariants allows for an early detection of problems. Plan assumptions that are required for a plan to succeed are explicitly represented by plan invariants. ...|$|E
30|$|In this article, {{a unique}} {{design of a}} non-preemptive modular {{customizable}} event-driven architecture is proposed for a standalone FPGA based sensor node. Therefore, the standard benchmark tests are not available to test our implementation. Thus, we tried to find standard application that can run on the proposed sensor node. As {{one of the prime}} objectives of WSN is to transmit and receive data packets, a standard ZigBee transceiver application is implemented to test the data packet processing and routing functionality of the proposed FPGA based sensor node. In general, every sensor node in a WSN has to have routing capability. Thus, implementing routing within the FPGA based sensor node is important. However, event handlers can be designed to provide any kind of sensor data processing and packet handling tasks in addition to routing functionality. Thus, the functional testing of routing capability of a sensor node is carried out. However, a full-fledged event-driven architecture for the FPGA based sensor node is designed and implemented using VHDL in this research rather than just FPGA based router. As transceiver application is implemented on a sensor node, measuring packet error rate (PER) and transmission range is the common practice to validate a transceiver. Thus, PER and transmission range are measured experimentally as part of functional verification of the HDL implementation. For performance analysis, the <b>execution</b> <b>cycle</b> count and the minimum clock frequency requirement to achieve the maximum possible throughput are recorded. <b>Execution</b> <b>cycle</b> count and minimum clock frequency requirement are measured using ModelSim simulator.|$|E
40|$|Conditional {{branches}} are expensive. Branches {{require a}} signi cant percentage of <b>execution</b> <b>cycles</b> since they occur frequently and cause pipeline ushes when mispredicted. In addition, branches result in forks {{in the control}} ow, which can prevent other code-improving transformations from being applied. In this paper we describe pro le-based techniques for replacing the execution {{of a set of}} two or more branches with a single branch on a conventional scalar processor. First, we gather pro le information to detect the frequently executed paths in a program...|$|R
40|$|Applications {{that require}} digital signal {{processing}} (DSP) functions are typically mapped onto general purpose DSP processors. With the introduction of advanced FPGA architectures with built-in DSP support, a new hardware alternative is available for DSP designers. By exploiting its inherent parallelism, {{it is expected that}} FPGAs can outperform DSP processors. However, the migration of assembly code to hardware is typically a very arduous process. This paper describes the process and considerations for automatically translating software assembly and binary codes targeted for general DSP processors into Register Transfer Level (RTL) VHDL or Verilog code to be mapped onto commercial FPGAs. The Texas Instruments C 6000 DSP processor architecture has been used as the DSP processor platform, and the Xilinx Virtex II as the target FPGA. Various optimizations are discussed, including loop unrolling, induction variable analysis, memory and register optimizations, scheduling and resource binding. Experimental results on resource usage and performance are shown for ten software binary benchmarks in the signal processing and image processing domains. Results show performance gains of 3 - 20 x in terms of reductions in <b>execution</b> <b>cycles</b> and 1. 3 - 5 x in terms of reductions in execution times for the FPGA designs over that of the DSP processors in terms of reductions of <b>execution</b> <b>cycles...</b>|$|R
40|$|Energy is a {{valuable}} resource in embedded systems as the lifetime of many such systems is constrained by their battery capacity. Recent advances in processor design have added support for dynamic frequency/voltage scaling (DVS) for saving energy. Recent work on real-time scheduling focuses on saving energy in static as well as dynamic scheduling environments by exploiting idle time and slack due to early task completion for DVS of subsequent tasks. These scheduling algorithms rely on a priori knowledge of worst-case execution times (WCET) for each task. They assume that DVS {{has no effect on}} the worst-case <b>execution</b> <b>cycles</b> (WCEC) of a task and scale the WCET according to the processor frequency. However, for systems with memory hierarchies, the WCEC typically does change under DVS due to frequency modulation. Hence, current assumptions used by DVS schemes result in a highly exaggerated WCET. This paper contributes novel techniques for tight and flexible static timing analysis particularly well-suited for dynamic scheduling schemes. The technical contributions are as follows: (1) We assess the problem of changing <b>execution</b> <b>cycles</b> due to scaling techniques. (2) We propose a parametric approach towards bounding the WCET statically with respect to the frequency. Using a parametric model, we can capture the effect of changes in frequency on the WCEC and, thus...|$|R
