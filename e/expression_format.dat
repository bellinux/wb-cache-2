15|44|Public
50|$|Solver: an {{interactive}} expression solver which can, in theory, numerically solve any equation versus any variable, using Newton's method. It may however fail to solve certain classes of equations {{depending on the}} <b>expression</b> <b>format</b> and starting values of the variables, so it is often necessary to rewrite the expression or experiment with initial values.|$|E
50|$|Maintaining {{the notion}} of the musical score, the Media Art Notation System is derived as (and has as its {{underlying}} structure) an interpretation of computer programming languages, drawing primarily from Digital Item Declaration Language (DIDL), a type of Extensible Markup Language (XML) that allows for greater, more granular descriptions of a multi-component digital object. MANS has three layers; the conceptual model of documentation, the preferred <b>expression</b> <b>format</b> (vocabulary) for the model (the interpretation of DIDL XML) and, its top layer, the score, which serves as a record of the work that is database-processable.|$|E
40|$|We {{present a}} large scale model for a {{database}} of multi-track polyphonic songs searchable via a modified regular <b>expression</b> <b>format</b> and stored in a relational database. The regular <b>expression</b> <b>format</b> is of our own design and will likely be familiar to those with experience using common text search utilities. The relational database is a standard, off-theshelf SQL-based database management system. The songs have been decomposed into a relational model and searching is done via a translation between our query language an...|$|E
5000|$|Gerhards {{focused on}} the IETF syslog {{standardization}} and authored four RFCs [...] on syslog. He wrote the base RFC 5424, which describes the syslog protocol architecture and stack. As {{a board member of}} Mitre's CEE effort, he worked on standardizing event <b>expression</b> <b>formats</b> and providing interoperability between different logging systems. He used his software projects as testbeds for IETF standardization including rsyslog for the development of RFC 5424, RFC 5425, and RFC 5426. He implemented RFC 3195, the syslog over RFC 3080 protocol. Later, Gerhards designed the Reliable Event Logging Protocol, and its predecessor Simple Event Transport Protocol (SETP).|$|R
40|$|International audienceAdverbial subordinators {{are free}} or bound morphemes that specify some circumstantial {{relation}} between the subordinate clause over which they operates and the modified matrix clause (Kortmann, 1996). In this paper I {{deal with the issue}} of the grammaticalization of adverbial subordinators in Juba Arabic, an under-described Arabic-based pidgincreole (i. e. expanded pidgin) serving as the major vehicular language of the Republic of South Sudan (Manfredi & Petrollino, 2013; Manfredi, forthcoming). In more detail, this paper aims at reveling the relationship between the semantic types of a number of adverbial clauses and their different <b>expression</b> <b>formats</b> as well as to find out whether this correlation can be linked to the general system of subordination and/or complementation of Juba Arabic (Cristofaro, 2003; Nordström, 2010). The paper is organized in two parts. In the first parts, I provide a synchronic overview of the <b>expression</b> <b>formats</b> of purpose, result, concessive conditional and temporal subordinate clauses. In the second part, I discuss the sources for the grammaticalization of the corresponding adverbial subordinators (i. e. adverbs, verbs, interjections) by enlightening the possible semantic factors underlying their functional specialization. The analysis of adverbial clauses and subordinators is based on a spontaneous speech corpus transcribed and annotated in ELAN (Manfredi, 2012) as well as on elicited data gathered from Juba Arabic native speakers. Adopting a functional-typological perspective, the study finally tries to explain the main features of adverbial subordination in Juba Arabic by fitting it into the broader study of complexsyntax in pidgin and creole languages...|$|R
40|$|Current {{database}} trigger {{systems have}} extremely limited scalability. This paper proposes {{a way to}} develop a truly scalable trigger system. Scalability to large numbers of triggers is achieved with a trigger cache to use main memory effectively, and a memory-conserving selection predicate index based {{on the use of}} unique <b>expression</b> <b>formats</b> called <b>expression</b> signatures. A key observation is that if {{a very large number of}} triggers are created, many will have the same structure, except for the appearance of different constant values. When a trigger is created, tuples are added to special relations created for expression signatures to hold the trigger's constants. These tables can be augmented with a database index or main-memory index structure to serve as a predicate index. The design presented also uses a number of types of concurrency to achieve scalability, including token (tuple) -level, condition-level, rule action-level, and datalevel concurrency. 1. Introduction Trigger feature [...] ...|$|R
40|$|Abstract. Does {{the naming}} of clocks always require {{conceptual}} preparation? To examine this question, speakers were presented with analog and digital clocks {{that had to be}} named in Dutch using either a relative (e. g., “quarter to four”) or an absolute (e. g., “three forty-five”) clock time <b>expression</b> <b>format.</b> Naming latencies showed evidence of conceptual preparation when speakers produced relative time expressions to analog and digital clocks, but not when they used absolute time expressions. These findings indicate that conceptual mediation is not always mandatory for telling time, but instead depends on clock time <b>expression</b> <b>format,</b> supporting a multiple-route account of Dutch clock time naming...|$|E
30|$|This section {{provides}} an overview of the Structured Threat Information <b>eXpression</b> <b>format</b> STIX, which is the state-of-the-art project for semi-structured representation of cyber threat intelligence information. Furthermore, a general view on knowledge and its role in the field of visual analytics is given.|$|E
40|$|We {{present a}} model for a {{database}} of multi-track polyphonic songs searchable via regular expressions and stored in a relational database. The database is a standard off-the-shelf SQL-based relational database management system. The regular <b>expression</b> <b>format</b> used is of our own design, but could be replaced by any equivalent format. Songs are culled from non-analog sources such as MIDI and decomposed into a relational model. Searching is accomplished via a translation between our query language and SQL. relational database, musical regular expres-Keywords: sio...|$|E
40|$|Current {{database}} trigger {{systems have}} extremely limited scalability. Some commercial systems allow only one trigger per table {{to be defined}} {{for each type of}} update event. Application systems could use the ability to create thousands or even millions of triggers. The advent of the Internet and the World Wide Web has made it even more important that trigger systems scale up since users could create large number of triggers via a web interface. This paper presents a way to develop a truly scalable trigger system. Scalability is achieved with a trigger cache to use main memory effectively, and a memory-conserving selection predicate index based on the use of unique <b>expression</b> <b>formats</b> called <b>expression</b> signatures. A key observation is that if {{a very large number of}} triggers are created, most will have the same structure, except for the appearance of different constant values. Expression signatures are used to divide selection predicates of triggers into equivalence classes. When a trigger i [...] ...|$|R
40|$|DNA microarrays are a {{powerful}} tool to investigate differential gene expression for thousands of genes simultaneously. Although DNA microarrays {{have been widely used}} to understand the critical events underlying growth, development, homeostasis, behavior and the onset of disease, the management of the resulting data has received little attention. Presently, the fluorescent dyes Cy 3 and Cy 5 are most often used to prepare labeled cDNA for microarray hybridizations. Raw microarray data are image files that have to be transformed into gene <b>expression</b> <b>formats</b> – a process that requires data manipulation due to systematic variations which may be attributed to differences in the physical and chemical dye characteristics. Since the goal of most microarray applications is to identify differences in transcript levels calculated from fluorescence ratios it is necessary to normalize fluorescence signals to compensate for systematic variations. Here, we will review current normalization strategies applied to cDNA microarrays and discuss their limits. We will show that experimental design determines normalization success...|$|R
40|$|Abstract Background Many {{proteins}} contain {{conserved sequence}} patterns (motifs) {{that contribute to}} their functionality. The process of experimentally identifying and validating novel protein motifs can be difficult, expensive, and time consuming. A means for helping to identify in advance the possible function of a novel motif is important to test hypotheses concerning the biological relevance of these motifs, thus reducing experimental trial-and-error. Results GOmotif accepts PROSITE and regular <b>expression</b> <b>formatted</b> motifs as input and searches a Gene Ontology annotated protein database using motif search tools. The search returns the set of proteins containing matching motifs and their associated Gene Ontology terms. These results are presented as: 1) a hierarchical, navigable tree separated into the three Gene Ontology biological domains - biological process, cellular component, and molecular function; 2) corresponding pie charts indicating raw and statistically adjusted distributions of the results, and 3) an interactive graphical network view depicting {{the location of the}} results in the Gene Ontology. Conclusions GOmotif is a web-based tool designed to assist researchers in investigating the biological role of novel protein motifs. GOmotif can be freely accessed at [URL] </p...|$|R
40|$|Regular {{expressions}} {{are very}} meaningful and now-a-days broadly {{used to represent}} signatures of various attacks. The focal component of today’s security systems like intrusion detection and prevention system is a signature based regular expression matching. Deterministic finite automaton {{is often used to}} represent regular expressions. In regular expression matching, storage space of Deterministic finite automata is very important concern. A massive amount of memory is essential to store transition function of Deterministic finite automata. The method described in this paper reduces size of Deterministic finite automata which is in regular <b>expression</b> <b>format.</b> The performance of the regular expression matching by compressing Deterministic finite automata is evaluated by using regular expression set...|$|E
40|$|This {{document}} specifies an Internet standards track {{protocol for}} the Internet community, and requests discussion {{and suggestions for}} improvements. Please refer to the current edition of the "Internet Official Protocol Standards " (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (1999). All Rights Reserved. In RFC 2533, "A Syntax for Describing Media Feature Sets", an <b>expression</b> <b>format</b> is presented for describing media feature capabilities using simple media feature tags. This memo contains two corrections to that specification: one fixes an error in the formal syntax specification, and the other fixes an error in the rules for reducing feature comparison predicates. Table of Content...|$|E
40|$|This {{document}} specifies an Internet standards track {{protocol for}} the Internet community, and requests discussion {{and suggestions for}} improvements. Please refer to the current edition of the "Internet Official Protocol Standards " (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2000). All Rights Reserved. In "A Syntax for Describing Media Feature Sets", an <b>expression</b> <b>format</b> is presented for describing media feature capabilities using simple media feature tags. This memo defines a media feature tag whose value is a Multipurpose Internet Mail Extensions (MIME) content type. This allows the construction of feature expressions that {{take account of the}} MIM...|$|E
40|$|The participatory, {{collaborative}} {{and open}} character of networked digital media {{is thought to}} disrupt and challenge romantic assumptions and ideals about authorship, authenticity and creative expression, concepts that underpin most copyright regimes. In this article I consider MP 3 blogs in the mid- 2000 s, drawing on an earlier study of MP 3 bloggers in the U. S. and U. K. (Borschke 2012 a, 2012 b). MP 3 blogs, like Napster {{and other forms of}} unauthorized reproduction, are better understood as cultural practices and artifacts when considered alongside piracy's long history. The aesthetic consequences and possibilities of forms of expression that are also methods of distribution, are clarified by identifying and examining a tension that connects MP 3 blogging to other practices of unauthorized use: that is, the persistence of romantic ideals of creativity, authenticity and authorship even while seeming to deny and disregard them. By acknowledging the poetics of piracy practices (including the aesthetic character of distribution and replication) we can begin to understand how new authenticities build up around networked expression and how the meaning of networked forms of <b>expression,</b> <b>formats,</b> practices and artifacts can change over time. 12 page(s...|$|R
5000|$|On August 10, 2000, Hupp {{issued a}} {{decision}} on Ticketmaster's motion for a preliminary injunction against linking and spidering. He ruled that the copyright violation claim was unfounded because [...] "purely factual information", such as a public event's date, location, and cost, could not be copyrighted, regardless {{of the cost of}} time needed to aggregate the facts. He found that [...] "the manner of <b>expression</b> and <b>format</b> of presenting those facts is protectable", and Tickets.com ensured to use their own <b>expression</b> and <b>format</b> to present the facts. Basing his reasoning on Sony Computer Entertainment, Inc. v. Connectix Corp., Hupp wrote that Ticket.com's short-lived copies of Ticketmaster's webpages, which were used to obtain facts, was legal under the fair use doctrine of United States copyright law. He called the duplication a type of [...] "reverse engineering to obtain non-protectable information". It passed legal muster under Sony Computer Entertainment because it was immediately removed after having served its purpose to retrieve non-copyrightable facts and was the ablest, albeit not sole, method to do so. [...] He also found that URLs were not copyrightable because they consisted of [...] "functional and factual elements".|$|R
40|$|This paper {{presents}} suggested semantic representations {{for different}} types of referring <b>expressions</b> in the <b>format</b> of Minimal Recursion Semantics and sketches syntactic analyses which can create them compositionally. We explore cross-linguistic harmonization of these representations, to promote interoperability and reusability of linguistic analyses. ...|$|R
40|$|Embedded {{systems are}} {{becoming}} more widely used but these systems are often resource constrained. Programming models for these systems should take into formal consideration resources such as stack and heap. In this paper, we show how memory resource bounds can be inferred for assembly-level programs. Our inference process captures the memory needs of each method {{in terms of the}} symbolic values of its parameters. For better precision, we infer path-sensitive information through a novel guarded <b>expression</b> <b>format.</b> Our current proposal relies on a Presburger solver to capture memory requirements symbolically, and to perform fixpoint analysis for loops and recursion. Apart from safety in memory adequacy, our proposal can provide estimate on memory costs for embedded devices and improve performance via fewer runtime checks against memory bound. 1...|$|E
40|$|In this paper, we {{describe}} an improved template-based approach to Chinese-to-English Spoken Language Translation (SLT) and present experimental results. The improved template-based translation approach uses flexible <b>expression</b> <b>format</b> {{to describe the}} template condition. The condition of a template may consist of keywords, parts-of-speech and also semantic features, so the input may be matched with a template from shallow level to deep level. In the condition of a template, the distance between two fixed keywords is stretchable, thus some needless words in the input utterances may be skipped in matching operation. And also the translation results of the same template are alterable. The proper results are finally generated according to the specific context. That is, the relation between a template and translated utterance is one-to-n (where, n is an integer and n≥ 1). The experiments were performed with input of both text transcription and results of speech recognition. The preliminary experimental results have proven the approach is practical. 1...|$|E
40|$|In {{the field}} of science and technology, a lot of {{research}} has recently been done for collecting and analyzing information, for example, examination of global research trend, detection of emerging signals and searching for leading researchers from science and technology literature [1]. Since the science and technology literature information collected for the analysis has been produced for the purpose of each information source, the information is differently constructed and expressed [1, 2]. Therefore, it is necessary to integrate and manage the different information with the same structure and <b>expression</b> <b>format</b> [3]. To this end in this study, examination is made of methods of standardizing the data processing process and data format, and of implementing interoperability of data in different format. Examination is also made of a method of semi-automation through machine learning for even more automated data management. It is expected this study will contribute to improving integration of heterogeneous databases and efficient and easy management of contents in different fields and domains...|$|E
50|$|PRINT USING {{statement}} to control format of output. Apple Business BASIC had an option {{in addition to}} directly specifying the format with a string expression, of giving the line number where an IMAGE statement gave the <b>formatting</b> <b>expression,</b> similar to a FORMAT statement in FORTRAN.|$|R
40|$|This paper acquaints {{the reader}} {{with the use of}} {{commercial}} databases for searching prior art. The terminology and operations that are common among many of the major database systems are described to simplify understanding of database searching. Differences among the database systems are summarized in tables for translating common search <b>expressions</b> from the <b>format</b> conventions of one search system to those of another. ...|$|R
30|$|To {{meet these}} {{shortcomings}} we propose a visual analytics concept enabling security experts {{to analyze and}} enrich semi-structured cyber threat intelligence information. Our approach combines an innovative way of persisting this data with an interactive visualization component to analyze and edit the threat information. We demonstrate the feasibility of our concept using the Structured Threat Information <b>eXpression,</b> the state-of-the-art <b>format</b> for reporting cyber security issues.|$|R
30|$|Face {{detection}} and classification follows the methods from [41, 42] {{in order to}} perform human detection, smile detection, gender and human race classification. In order to consider the emotional state of the robot, {{it was used to}} face recognition of a person and acquire smiling information and clarification of gender or race to update the parameters of the emotional state [35]. We apply simple fuzzy inference for facial expression generation crucial for nonverbal communication. We used Laban movement theory to generate robot gesture. This <b>expression</b> <b>format</b> may be determined randomly when each module exists, and when the emotion of the robot is considered important, the facial expression and the gesture are different according to the change of the emotion [37]. The robot’s gestural expression is generated based on Laban Movement Analysis (LMA). The robot’s gestures and body movements consist of four gesture segments based on the emotional model and LMA theory [43]. Emotion perception is the ability to recognize and identify other people’s emotions [44]. This is also an important factor in social interaction. We are inspired by the emotion perception and use the perceptual sensory information to determine the reaction of the robot. Hence, we also consider that human behavior differs based on the situations in nonverbal communication. So, we use sensory information for nonverbal communication in order to consider externally and internally generated emotions [45], e.g., display touch status, camera, microphone, compass, battery status, accelerometer, proximity status, and device shake motion characteristic [46 – 48].|$|E
40|$|This {{dissertation}} {{deals with}} essential issues pertaining to high performance processing for network security and deep packet inspection. The proposed solutions {{keep pace with}} the increasing number and complexity of known attack descriptions providing multi-Gbps processing rates. We advocate the use of reconfigurable hardware to provide flexibility, hardware speed, and parallelism in challenging packet and content inspection functions. This thesis is divided in two parts, firstly content inspection and secondly packet inspection. The first part considers high speed scanning and analyzing packet payloads to detect hazardous contents. Such contents are described in either static patterns or regular <b>expression</b> <b>format</b> and need to be matched against incoming data. The proposed static pattern matching approach introduces pre-decoding to share matching characters in CAM-like comparators and a new perfect hashing algorithm to predict a matching pattern. The FPGA-designs match over 2, 000 static patterns, provide 2 8 Gbps operating throughput and require 10 - 30 % area of a large reconfigurable device; that is half the performance of an ASIC and approximately 30 % more efficient compared to previous FPGA-based solutions. The regular expression design is performed following a Non-Deterministic Finite Automata (NFA) approach and introducing nw basic building blocks for complex regular expressions features. Theoretical grounds in support of the new blocks are established to prove their correctness. In doing so, approximately four times less Finite Automata states need to be stored. The designs achieve 1. 6 - 3. 2 Gbps throughput using 10 - 30 % area of a large FPGA for matching over 1, 500 regular expressions; that is 10 - 20 x more efficient than previous FPGA-based works and comparable to ASICs. The second part of the thesis concerns offloading the overall processing of a packet inspection engine. Packet pre-filtering is introduced as a means to resolve or at least alleviate the processing requirements of matching incoming traffic against large datasets of known attacks. Partially matching descriptions of malicious traffic avoids further processing of over 98 % of the attack descriptions per packet. Packet pre-filtering is implemented in reconfigurable technology and sustains 2. 5 to 10 Gbps processing rates in a Xilinx Virtex 2 device. Electrical Engineering, Mathematics and Computer Scienc...|$|E
40|$|Summary: MADE 4, {{microarray}} ade 4, is {{a software}} package that facilitates {{multivariate analysis of}} microarray gene expression data. MADE 4 accepts {{a wide variety of}} gene <b>expression</b> data <b>formats.</b> MADE 4 takes advantage of the extensive multivariate statistical and graphical functions in the R package ade 4, extending these for application to microarray data. In addition MADE 4 provides new graphical and visualisation tools that aid in interpretation of multivariate analysis of microarray data. Availability: The R package MADE 4 is available from Bioconductor www. bioconductor. org and bioinf. ucd. ie/software/ Supplementary information: MADE 4 is well documented. There are tutorials, in the form of vignettes, which describe typical analyses. In addition the MADE 4 manual provides descriptions and examples for each function. ...|$|R
40|$|Microarray ade 4 or {{known as}} MADE 4 is a multivariate {{software}} analysis package for microarray gene expression data. This software package {{is capable of}} accepting wide variety of gene <b>expression</b> data <b>formats</b> such as Bioconductor Affy Batch and exprSet. This MADE 4 R package extends the advantages of ade 4 package in multivariate statistical and graphical functions for the use in the microarray data application. Moreover, MADE 4 provides new graphical and visualization tools that assist {{in the interpretation of}} multivariate analysis of microarray data. Besides that, LLSimpute algorithm has been incorporated to assist in handling of datasets with missing values and this has eased the application for the users to analysis on gene expression data that contain missing values...|$|R
40|$|Thesis (Ph. D.) [...] University of Washington, 2016 - 12 Previous {{research}} suggests that people make better decisions in weather-related decision tasks when they are given probabilistic uncertainty estimates about the outcomes (Joslyn & Leclerc, 2012; Joslyn & Leclerc, 2013). However, {{it is unclear whether}} all users can take advantage of probabilistic forecasts to the same extent. The research reported here assessed various cognitive and demographic factors to explore {{the extent to which these}} factors were associated with users’ ability to take advantage of probabilistic forecasts. In three studies, participants made decisions about whether to spend limited resources to salt roads to prevent icy conditions. Several <b>expression</b> <b>formats</b> were tested, including numerical uncertainty and explicit advice. Results suggested that increased numeracy was associated with better weather-related decisions when forecasts included numerical uncertainty estimates in all three studies, although no user groups were substantially impaired when given numerical uncertainty. There were also demographic factors such as age and education that explained decision quality, however, their effects were inconsistent or even contradictory between experiments. However, when all other predictors were removed, individuals with higher numeracy made better decisions regardless of the uncertainty communication method, suggesting that the advantage of numeracy may extend beyond understanding the forecast to larger decision strategy issues. This research adds to a growing body of evidence that numerical uncertainty estimates are an effective way to communicate weather danger. It demonstrates that the advantages of numerical expressions are not seriously limited by individual differences and allow users to better differentiate situations that do and do not require precautionary action and increase trust. Moreover, these results might generalize to other domains in which lay people must make important decisions when faced with uncertainty...|$|R
40|$|A {{prototype}} e-mail {{system was}} developed for cognitively disabled users, with four different interfaces (free format, idea prompt, form fill and menu driven). The interfaces differed {{in the level of}} support provided for the user and complexity of facilities for composing e-mail messages. Usability evaluation demonstrated that no one interface was superior because of individual differences in usability problems, although the majority of users preferred interfaces which did not restrict their freedom of <b>expression</b> (free <b>format).</b> In contrast to traditional evaluation studies, no common pattern of usability errors emerged, demonstrating the need for customisation of interfaces for individual cognitively disabled users. A framework for customising user interfaces to individual users is proposed, and usability principles derived from the study are expressed as claims following the task artefact cycle...|$|R
40|$|This {{bachelor}} thesis {{focuses on}} finding suitable methods and algorithms for text segmentation and character recognition using artificial neural networks. Firstly, the thesis covers {{basic principles of}} artificial neuron and artificial neural networks, structure of convolutional neural networks and mainly backpropagation algorithm and stochastic Levenberg-Marquardt algorithm. Then the thesis describes image processing and image segmentation to single symbols using graph algorithms. This thesis also includes implementation of these methods and algorithms in an application which converts digital mathematical <b>expressions</b> to vector <b>format...</b>|$|R
50|$|Dale shows instrumentalist and {{composer}} skills, to an exceptional extent. He was recognized in Norway already in 2008 {{when he and}} saxophonist André Roligheten won Jazzintro award within the duo Albatrosh. Since then he has taken new steps as a performer, composer and producer, until he now presents his own <b>expression</b> in album <b>format.</b> From the first note he {{makes it clear that}} he has a sense of rich, singing piano tone and he does sound treatment seriously. This musical expression is more than mature for world jazz scene.|$|R
5000|$|A regular {{expression}} {{may be used}} to conveniently describe an advanced search pattern in a [...] "find and replace"-like operation of a text processing utility. Glushkov's algorithm can be used to transform it into an NFA, which furthermore is small by nature, as the number of its states equals the number of symbols of the {{regular expression}}, plus one.Subsequently, the NFA can be made deterministic by the powerset construction and then be minimized to get an optimal automaton corresponding to the given regular <b>expression.</b> The latter <b>format</b> is best suited for execution on a computer.|$|R
40|$|Modeling for {{operation}} rules is essential function requirement in equipment simulation training {{system based on}} VR. Aiming at the modeling actuality of present equipment operation rules, which has no systematic, no generality and no <b>formatting</b> <b>expression,</b> layered modeling system framework based on federation is brought forward referencing to the “Federation and Member ” concept of HLA. Open modeling method is adopted to modeling equipment operation rules {{and it can be}} described with XML syntax structure. Finally, the basic implement principle of equipment operation rules is presented combing with some large tactical communication system equipment. It can provide beneficial reference for constructing similar large scale equipment simulation training system based on VR...|$|R
40|$|Abstract. Formulas {{exist in}} {{various kinds of}} {{documents}} with different formats. Extracting and normalizing them into a unique form are the precondition of mathematical retrieval. In this paper, an extraction and conversion method of formulas in Word documents is built for mathematical expression retrieval. Firstly, the mathematical expressions in Word documents are detected through the processing of OLE objects. Then, the matching rules of formula format conversion are defined. Finally, the extracted mathematical <b>expressions</b> in OMML <b>format</b> are converted into LaTeX format follow the defined rules and stored in a txt file. Furthermore, the formulas exist in MathType format are stored in bitmap documents and converted into LaTeX documents through formula recognition and reconstruction module. Experiments show {{the effectiveness of the}} designed approach...|$|R
40|$|In {{this paper}} {{we argue that}} it is {{important}} to introduce liberal arts students to the essence of engineering. Toward this end we have developed Robotic Design Studio, a course where students learn how to design, assemble, and program robots made out of LEGO parts, sensors, motors, and small embedded computers. The course has no prerequisites and has attracted students from a wide range of backgrounds. The course culminates in an exhibition where students show off the robots that they have designed and built. These creative projects tie together aspects of a surprisingly wide range of disciplines. Robotic Design Studio represents an alternative vision of how robot design can be used to teach engineering in a way that is more inclusive and provides more room for artistic <b>expression</b> than contest-centered <b>formats...</b>|$|R
