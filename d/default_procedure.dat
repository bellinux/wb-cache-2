31|56|Public
2500|$|The general {{procedure}} (the [...] "7/50" [...] procedure) - section 38. [...] The amendment must be {{passed by the}} House of Commons, the Senate, and at least two-thirds of the provincial legislative assemblies representing at least 50% {{of the total population}} of the provinces. This is the <b>default</b> <b>procedure</b> and it covers any amendment procedure not covered more specifically in sections 41, 43, 44 or 45. The general formula must be used for any of the six situations identified in section 42.|$|E
50|$|An {{application}} usually calls DefWindowProc {{at the end}} of its own WindowProc function so {{that whatever}} messages it has not processed are passed on to the <b>default</b> <b>procedure.</b>|$|E
5000|$|... : This {{variable}} specifies the directory, {{where the}} Windows [...] {{to be used}} by the DR-DOS [...] multitasker is located, overriding the <b>default</b> <b>procedure</b> to locate the file.|$|E
50|$|Many of the <b>default</b> <b>procedures</b> of the MNCA are {{different}} from standard parliamentary procedure, {{though they may be}} superseded by a provision either in the articles of incorporation or in the bylaws of the corporation.|$|R
40|$|The Erie {{doctrine}} governs, {{among other}} things, when {{a federal court}} sitting in diversity jurisdiction may use a federal procedure that differs from the procedure a state court would use. Displacing the state procedure with the federal procedure (or not) may impact the substantive objectives of either state or federal law, but the current Erie doctrine provides little guidance. This Article argues that the Erie doctrine is best understood as governing a choice of enforcement defaults. As argued below, the primary function of civil liability is to protect a substantive entitlement to avoid the legal violation, either directly through specific performance remedies or through deterrence. Accordingly, procedures in federal and state court {{can be understood as}} <b>default</b> <b>procedures</b> to enforce this substantive entitlement, and these defaults are often abrogated by private contract or through legislation. Understood in this way, the Erie doctrine governs when a federal court may abrogate a state enforcement default {{and replace it with a}} federal one. This Article then uses the existing literature on default rules to argue that the Erie doctrine itself should use default rules to force information from both state and federal governments about the relationship of <b>default</b> <b>procedures</b> to substantive policies. This way, federal courts can make better choices between enforcement defaults...|$|R
40|$|Zellner’s g prior {{remains a}} popular {{conventional}} prior {{for use in}} Bayesian variable selection, despite several undesirable consistency issues. In this article we study mixtures of g priors {{as an alternative to}} default g priors that resolve many of the problems with the original formulation while maintaining the computational tractability that has made the g prior so popular. We present theoretical properties of the mixture g priors and provide real and simulated examples to compare the mixture formulation with fixed g priors, empirical Bayes approaches, and other <b>default</b> <b>procedures...</b>|$|R
50|$|The Ontario {{amendments}} {{changed the}} test for summary judgment from asking whether the case presents “a genuine issue for trial” to asking {{whether there is a}} “genuine issue requiring a trial”. The new rule, with its enhanced fact‑finding powers, demonstrates that a trial is not the <b>default</b> <b>procedure.</b>|$|E
5000|$|The general {{procedure}} (the [...] "7/50" [...] procedure) - section 38. The amendment must be {{passed by the}} House of Commons, the Senate, and at least two-thirds of the provincial legislative assemblies representing at least 50% {{of the total population}} of the provinces. This is the <b>default</b> <b>procedure</b> and it covers any amendment procedure not covered more specifically in sections 41, 43, 44 or 45. The general formula must be used for any of the six situations identified in section 42.|$|E
50|$|SCL is {{designed}} to allow both line-at-a-time interactive use from a console or from a command file, and creation of executable scripts or programs (when the language is compiled into object module format {{in the same way}} as any other VME programming language). The declaration of a procedure within SCL also acts as the definition of a simple form or template allowing the procedure to be invoked from an interactive terminal, with fields validated according to the data types of the underlying procedure parameters or using the <b>default</b> <b>procedure</b> parameter values.|$|E
40|$|Robust {{statistics}} has slowly {{become familiar}} to all practitioners. Books entirely {{devoted to the}} subject are without any doubts responsible for the increased practice of robust statistics in all fields of applications. Even classical books often {{have at least one}} chapter (or parts of chapters) which develops robust methodology. The improvement of computing power has also contributed {{to the development of a}} wider and wider range of available robust procedures. However, this success story is now menacing to get backwards: non specialists interested in the application of robust methodology are faced with a large set of (assumed equivalent) methods and with over-sophistication of some of them. Which method should one use? How the (numerous) parameters should be optimaly tuned? These questions are not so easy to answer for non specialists! One could then argue that <b>default</b> <b>procedures</b> are available in most statistical softwares (Splus, R, SAS, Matlab, [...] .). However, using as illustration the detection of outliers in multivariate data, it is shown that, on one hand, it is not obvious that one would feel confident with the output of <b>default</b> <b>procedures,</b> and that, on the other hand, trying to understand thoroughly the tuning parameters involved in the procedures might require some extensive research. This is not conceivable when trying to compete with the classical methodology which (while clearly unreliable) is so straightfoward. The aim of the paper is to help the practitioners willing to detect in a reliable way outliers in a multivariate data set. The chosen methodology is the Minimum Covariance Determinant estimator being widely available and intuitively appealing. Peer reviewe...|$|R
50|$|As the CCP {{concentrates}} {{the risk}} of settlement failures into itself {{and is able to}} isolate the effects of a failure of a market participant, it also needs to be properly managed and well-capitalized in order to ensure its survival {{in the event of a}} significant adverse event, such as a large clearing firm defaulting. Guarantee funds are capitalized with collateral from the member firms. In the event of a settlement failure, the defaulting firm may be declared to be in default and the CCP's <b>default</b> <b>procedures</b> utilized, which may include the orderly liquidation of the defaulting firm's positions and collateral. In the event of a significant clearing firm failure, the CCP may draw on its guarantee fund in order to settle trades on behalf of the failed clearing firm.|$|R
40|$|The use of {{powerful}} low or {{very low frequency}} (LF/VLF) transmitter signals (mainly in the range 15 - 60 kHz) is a well established technique for remote sensing of the lower ionosphere. Standard tools for calculating the the world wide propagation conditions – like the Long Wave Propagation Capability (LWPC) code- usually rely on <b>default</b> <b>procedures</b> for modeling the day-night transition conditions that do not map reality sufficiently for modeling purposes, {{especially with regard to}} timing and shape of the terminators. We propose an improved method to cover with these problems by making use of the possibility to introduce charge density profiles into the LWPC that vary appropriately over the day-night cycle and additionally can model disturbances caused by forcing of the lower ionosphere from above (X-rays, particle precipitations) and below (atmospheric waves). 1...|$|R
50|$|The Hague Convention Abolishing the Requirement for Legalisation for Foreign Public Documents has supplanted legalization as the <b>default</b> <b>procedure</b> by {{a system}} of apostille. It is {{available}} if both the origin country of the document and the destination country are party to the treaty. The apostille is a stamp on which standard validating information is supplied. It is available (dependent on the document) from the competent authority of the origin country, and often the document has to be notarized {{before it can be}} apostilled. In the United States the Secretaries of State for the various states are the competent authorities who can apply an apostille. A list of the competent authorities designated by each country that has joined the treaty is maintained by the Hague Conference on Private International Law.|$|E
5000|$|Maravall’s {{research}} {{has centered on}} time series analysis and modeling and their application to economic series. His main contribution (an important part of it coauthored with Victor Gómez) has been {{the development of a}} model-based procedure to jointly solve several statistical time series problems that affect analysis and interpretation of economic time series. The standard (<b>default)</b> <b>procedure</b> performs, first, automatic identification and forecasting of regression-ARIMA models (that includes adjusting for outliers and calendar effects) in the possible presence of missing observations.1 Then, the model is decomposed into models for the unobserved components (such as seasonal, trend, transitory, and cyclical components) and, from these models, filters are derived to estimate and forecast the components.234 The model-based structure provides the joint distribution of  the estimators, from which parametric tests and inferences (such as the standard errors of all estimators and forecasts) are derived.5a,b ...|$|E
5000|$|The Mitterrand {{doctrine}} {{was based}} on a supposed superiority of French law and its alleged greater adherence to European standards and principles concerning the protection of human rights. This vision entered in crisis, from a legal viewpoint, when the European Court of Human Rights finally ruled against the French procedure in absentia, often used as a touchstone to consider the Italian procedure as in fault. In a ruling, which breaks down to the root of the French institute, the ECHR decided that the so-called process of purgation in the absence - namely the new trial following the arrest of the fugitive - is only a mere procedural device. So the new process can not be comparable to a guarantee for the prisoner, given that in France under Article 630 of the Code of Criminal Procedure, the first trial in absentia is held without the presence of lawyers, in explicit violation of the right to defense enshrined in Article 6, paragraph 3 letter c) the European Convention for the Protection of Human Rights and Fundamental Freedoms (ECtHR: Krombach v. France, application no. 29731/96). Following this ruling, France partly amended its <b>default</b> <b>procedure</b> by the 9 March 2004 [...] "Perben II" [...] Act, untenable for European standards on human rights. The current procedure in the absence is defined as [...] "par défaut" [...] and allows for the defense by a lawyer.|$|E
50|$|Hundreds of {{different}} messages are produced {{as a result}} of various events taking place in the system, and typically, an application processes {{only a small fraction of}} these messages. In order to ensure that all messages are processed, Windows provides a <b>default</b> window <b>procedure</b> called DefWindowProc that provides default processing for messages that the application itself does not process.|$|R
40|$|In recent years, we {{have seen}} an {{explosion}} of data collected from individuals, firms, or countries across short or long periods of time. This type of data gives {{us an opportunity to}} study the dynamics of change while controlling for time-invariant unobserved heterogeneity. Unfortunately, this type of heterogeneity, which is usually in the form of individual-specific fixed effects, creates problems for identification, estimation, and inference, especially if we continue to use <b>default</b> <b>procedures</b> without modification or without critical exploration. This dissertation revolves around a common theme – what practices and methods can be considered appropriate responses to the incidental parameter problem in panel data models. My approach to research is firmly rooted in the examination of empirical and theoretical practices so that we can come to an understanding of what we can and cannot do. (ECGE - Sciences économiques et de gestion) [...] UCL, 201...|$|R
40|$|Rita Franceschini has edited a {{book that}} deals with various {{elements}} of auto-/ biographical and multicultural studies. Most of the authors' arguments draw on linguistic, literary and ethnological approaches. In several chapters attempts are made to exemplify the interdependencies between biography and culture, specifically between individual and collective constructions of reality. In addition, various chapters focus on biographical structural effects resulting from speakers’ experience with foreign language challenges in bilingual or even trilingual contact situations. The review of the volume is framed by a cultural heuristic of an understanding explaining concept (Max WEBER); the reviewer's criticism is supported by qualitative standards of socio-pragmalinguistic and textlinguistic work. From {{this point of view}} evidence is provided that explains why literary studies' approaches tend to employ individual sampling procedures as well as other <b>default</b> <b>procedures</b> in gaining methodically controlled insights into properties and dimensions at issue. The linguistic contributions are discussed at length because of their efforts to connect micro- and macro-theoretical perspectives to each other, as such efforts are viewed as building blocks of a cultural studies' approach to research on (language) biographies...|$|R
30|$|These {{data report}} our early {{experience}} with a TLH and demonstrate a satisfactory record during its introduction to a new unit. This new procedure offers a safe alternative to TAH for many women with no increased morbidity in agreement with recent literature [2, 9]. There is an excepted bias in the reported cases as the route chosen was not randomised; however, since introducing TLH, {{it has become the}} <b>default</b> <b>procedure</b> for endometrial pathology, reserving TAH as the <b>default</b> <b>procedure</b> for a grossly enlarged uterus.|$|E
40|$|The {{purpose of}} this work is to assess the {{accuracy}} at low frequencies of measurements performed using the <b>default</b> <b>procedure</b> of ISO 140 - 4 (the same of ISO/DIS 16283 - 1) in test rooms with volumes greater than 25 cubic meters. About 100 previous measurements were analyzed, referring to in-situ airborne sound insulation from 50 to 5000 Hz...|$|E
40|$|Aortic valve {{replacement}} (AVR) {{has been the}} <b>default</b> <b>procedure</b> for the surgical management of aortic valve disease, with repair techniques heterogeneously and infrequently used. However, surgical aortic valve repair has evolved with improved techniques. Yet many questions remain regarding the ideal techniques and real-world applicability and effectiveness of valve repair. The AORTA Great Debate highlighted and discussed the controversies regarding the surgical management of aortic valve disease...|$|E
5000|$|Entering a zero ("0") for menu {{meant that}} no menu would be displayed. The S/36 [...] "command display" [...] would appear with no menu options. Entering a zero for library would {{override}} the default library {{and use the}} system library (#LIBRARY.) Entering a zero for procedure would override the <b>default</b> sign-on <b>procedure</b> and no procedure would run at sign-on. Mandatory menus cannot be overridden or respecified in libraries other than the named library.|$|R
5000|$|Apart from {{applications}} for the rescission of <b>default</b> judgments, the <b>procedure</b> by means of which a party will make an application for the rescission or variation of a judgment in the Magistrates' Courts is set out in rule 49(7), which requires that such applications be ...|$|R
40|$|Abstract. An aspect-oriented design model {{consists}} {{of a set of}} aspect models and a primary model. Each of these models {{consists of}} a number of different kinds of UML diagrams. The models must be composed to identify conflicts and analyze the system as a whole. We have developed a systematic approach for composing class diagrams in which a <b>default</b> composition <b>procedure</b> based on name matching can be customized by user-defined composition directives. This paper describes a set of composition directives that constrain how class diagrams are composed. ...|$|R
30|$|The {{data show}} {{that the success of}} {{achieving}} a TLH increased with time; as cases were unselected, this increase is likely to be due to increase in surgical expertise. Over the whole study, excluding cases where other clinicians chose the surgical route (2 cases), performed the surgery (9 cases) or the patient had a VH (17 cases), 95  % (138 / 145) of all cases offered a TLH had a TLH. The results show that TLH can justifiably be offered to all patients undergoing non-vaginal hysterectomy as the <b>default</b> <b>procedure</b> providing the surgeon is appropriately experienced in the technique.|$|E
40|$|It {{has been}} the subject of debate in the {{translation}} process literature whether human translation is a sequential and iterative process of comprehension-transfer- production or whether and to what extent comprehension and production activities may occur in parallel. Tirkkonen-Condit (2005) suggests a “monitor model” according to which translators start in a literal default rendering mode, and a monitor interrupts the <b>default</b> <b>procedure</b> when a problem occurs. This paper proposes an extension of the monitor model in which comprehension and production are processed in parallel by the <b>default</b> <b>procedure.</b> The monitor supervises text production processes, and triggers disintegration of the translation activity into chunks of sequential reading and writing behavior. To investigate this hypothesis, we compare text copying with translation activities under the assumption that text copying represents a typical literal default rendering procedure. Both, translation and text copying, require decoding, retrieval and encoding of textual segments, but translation requires in addition a transfer step into the target language. Comparing reading and writing behaviour obtained in the copying and translation experiments, we observe surprisingly many similarities, which also suggests similarities in the underlying processes. Copyists deviate from the default literal text reproduction into more effortful text understanding, and much of the translators’ behaviour looks like simple text copying. During translation as well as during text copying we observe that translators and copyists resort to sequential reading and writing patterns which seem to be triggered through target text production problems...|$|E
40|$|We {{study the}} {{influence}} of minimum quality standards in a two-region partial-equilibrium model of vertical product differentiation and trade. Three alternative standard setting arrangements are considered: Full Harmonization, National Treatment and Mutual Recognition. The analysis integrates {{the choice of a}} particular standard setting alternative by governments into the model. We provide a set of sufficient conditions for which Mutual Recognition emerges as one regulatory alternative that always improves welfare in both regions when compared to the case without regulation. We show that Mutual Recognition, being the <b>default</b> <b>procedure</b> if governments do not reach a unanimous decision, is the only possible equilibrium of the game. product differentiation, oligopoly, trade, quality standards, policy coordination...|$|E
5000|$|Exceptions {{are raised}} in the code via the throw (...) procedure. Try {{statements}} allow the program to bail out of any nested block, {{and serve as a}} better replacement for intra-procedure gotos (which are still supported under Pascaline). Since unhandled exceptions generate errors by <b>default,</b> the throw (...) <b>procedure</b> can serve as a general purpose error flagging system.|$|R
40|$|A {{series of}} monte carlo studies were {{performed}} to compare the behavior of some alternative procedures for reasoning under uncertainty. The behavior of several Bayesian, linear model and <b>default</b> reasoning <b>procedures</b> were examined {{in the context of}} increasing levels of calibration error. The most interesting result is that Bayesian procedures tended to output more extreme posterior belief values (posterior beliefs near 0. 0 or 1. 0) than other techniques, but the linear models were relatively less likely to output strong support for an erroneous conclusion. Also, accounting for the probabilistic dependencies between evidence items was important for both Bayesian and linear updating procedures. Comment: Appears in Proceedings of the Seventh Conference on Uncertainty in Artificial Intelligence (UAI 1991...|$|R
40|$|This paper {{addresses}} {{the relationship of}} Reiter's default logic, Moore's autoepistemic logic as well as Marek and Truszczynski's strong autoepistemic logic from a new point of view. Earlier research results on their interconnection {{support the view that}} default reasoning is a special case of autoepistemic reasoning. To the contrary, this paper shows how autoepistemic theories can be faithfully translated into default theories. Consequently, autoepistemic reasoning can be seen a form of default reasoning. This indicates together with the previous research results that autoepistemic logic and default logic are of equal generality. As a practical application of the presented translation, it is demonstrated how <b>default</b> decision <b>procedures</b> can be systematically used as autoepistemic decision procedures...|$|R
40|$|Projected body {{frontal area}} is used when {{estimating}} the parasite drag of bird flight. We investigated {{the relationship between}} projected frontal area and body mass among passerine birds, and compared it with an equation based on waterfowl and raptors, which is used as <b>default</b> <b>procedure</b> in a widespread software package for flight performance calculations. The allometric equation based on waterfowl/raptors underestimates the frontal area compared to the passerine equation presented here. Consequently, revising the actual frontal areas of small birds will concomitantly change {{the values of the}} parasite drag coefficient. We suggest that the new equation S-b = 0. 0129 m(B) (0. 61) (m(2)) where m(B) is body mass (kg) should be used when a value of frontal area is needed for passerines...|$|E
30|$|In LTE, {{the network}} {{architecture}} is flat such {{that when a}} UE is handed over, to improve latency and efficiency, the handover procedure is exclusively controlled by the source and destination eNBs [25]. For intra-LTE handover, the <b>default</b> <b>procedure</b> is that the source eNB buffers the data and passes it to the destination eNB over the X 2 interface. If no X 2 connection exists between the source and destination eNBs, the handover is performed over the S 1 interface. However, from the UE's viewpoint, {{there is no difference}} between the two types of handover [25]. In the case of closed-access femto-cells, where a handover is not possible between a source H/eNB and a destination HeNB, the proposed resource partitioning procedure requires that signaling information is conveyed from the source eNB to the destination HeNB.|$|E
40|$|The most {{important}} asset of semisupervised classification methods {{is the use}} of available unlabeled data combined with a clearly smaller set of labeled examples, so as to increase the classification accuracy compared with the <b>default</b> <b>procedure</b> of supervised methods, which on the other hand use only the labeled data during the training phase. Both the absence of automated mechanisms that produce labeled data and the high cost of needed human effort for completing the procedure of labelization in several scientific domains rise the need for semisupervised methods which counterbalance this phenomenon. In this work, a self-trained Logistic Model Trees (LMT) algorithm is presented, which combines the characteristics of Logistic Trees under the scenario of poor available labeled data. We performed an in depth comparison with other well-known semisupervised classification methods on standard benchmark datasets and we finally reached {{to the point that the}} presented technique had better accuracy in most cases...|$|E
50|$|The {{emphasis}} of CPC2013 is on contemporaneous Issue Resolution by an appropriate expert. CPC2013 {{it also provides}} for an escalating Dispute Resolution procedure, embracing negotiation, mediation, adjudication and arbitration. Where issues are required {{to be determined by}} Issue Resolution within a certain timescale, if the procedure is not invoked there are deeming provisions which determine the outcome of an issue. If Dispute Resolution is required, the expert, adjudicator or arbitrator are either those named in the contract or, in default, they are appointed by the Academy of Experts in London or the CIOB. The default adjudication rules are those of the Scheme for Construction Contracts and the <b>default</b> arbitration <b>procedure</b> is that of the London Court of International Arbitration.|$|R
40|$|Due {{to their}} great flexibility, nonparametric Bayes methods {{have proven to}} be a {{valuable}} tool for discovering complicated patterns in data. The term "nonparametric Bayes" suggests that these methods inherit model-free operating characteristics of classical nonparametric methods, as well as coherent uncertainty assessments provided by Bayesian procedures. However, as the authors say in the conclusion to their article, nonparametric Bayesian methods may be more aptly described as "massively parametric. " Furthermore, I argue that many of the <b>default</b> nonparametric Bayes <b>procedures</b> are only Bayesian in the weakest sense of the term, and cannot be assumed to provide honest assessments of uncertainty merely because they carry the Bayesian label. However useful such procedures may be, we should be cautious about advertising <b>default</b> nonparametric Bayes <b>procedures</b> as either being "assumption free" or providing descriptions of our uncertainty. If we want our nonparametric Bayes procedures to have a Bayesian interpretation, we should modify default NP Bayes methods to accommodate real prior information, or at the very least, carefully evaluate the effects of hyperparameters on posterior quantities of interest. Comment: Invited discussion of "Bayesian Nonparametric Inference - Why and How" by Mueller and Mitra, to appear in Bayesian Analysis, June 201...|$|R
30|$|Different {{handover}} execution modes are {{specified in the}} standard: the HHO and two soft handover modes, namely, FBSS and Macro Diversity handover (MDHO). While HHO is the <b>default</b> handover <b>procedure,</b> FBSS and MDHO are useful alternatives. The HHO mechanism, unlike similar ones used in 3 G technologies such as HSDPA[8], is highly efficient and {{has the potential to}} minimize handover overhead and achieve a handover delay of less than 50 ms. Nevertheless, soft handover strategies obviously offer significantly better handover performance compared with HHO. Their main drawback is that their deployment cost is considerably greater since they require a larger number of BSs within a specified area, perfect synchronization of the active or diversity set of BSs, and accurate sharing of the same frequency. All these issues are difficult to implement in a long distance deployment such as a high-speed railway.|$|R
