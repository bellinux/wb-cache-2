12|7|Public
5000|$|These same forced vibrations, however, {{may serve}} as {{sensation}} guides for the singer, regardless of their effect on the external sound. These sensations may provide evidence to the singer that his vocal folds are forming strong primary vibrations which are being carried from them to the head and chest. Thus these vibratory sensations can supply sensory feedback about {{the efficiency of the}} whole phonatory process to the singer. In contrast, the sound a person hears from a singer is a product of sympathetic resonance. Air vibrations generated {{at the level of the}} vocal folds in the larynx propagate through the vocal tract, i.e. the ducts and cavities of the airways, being considerably modified. In other words, the <b>glottal</b> <b>wave</b> created in the vocal source is filtered by the vocal tract, a phenomenon of sympathetic resonance. The vocal resonator is not a sounding board, comparable with stringed instruments, but rather a column of air, the vocal tract, with a shape that is not only complex, but highly variable. Vennard says: ...|$|E
40|$|The {{field of}} animal vocal {{communication}} has benefited greatly from improved understanding of vocal production mechanisms and specifically from the generalization of the sourcefilter theory of speech production to non-human mammals. The {{application of the}} sourcefilter theory has enabled researchers to decompose the acoustic structure of vocal signals according to their mode of production and thereby to predict the acoustic variation that is caused by anatomical or physiological attributes of the caller. The sourcefilter theory states that vocal signals result from a two-stage production, with the <b>glottal</b> <b>wave</b> generated in the larynx (the source), being subsequently filtered in the supralaryngeal vocal tract (the filter). This theory predicts that independent indexical information such as body size, weight, age and sex can be contained in both the <b>glottal</b> <b>wave</b> (mostly characterized by its fundamental frequency), and the spectral envelope of the radiated vocalization (mostly characterized by the vocal tract resonances or formant frequencies). Additionally, physiological fluctuations in emotional or motivational state {{have been found to}} influence the acoustic characteristics of signals in a reliable and predictable manner that is perceptually available to receivers. While animal vocalizations contain some dynamic attributes, their static attributes are sufficient to provide an effective means of acoustic individual discrimination both within and across call types. In this paper, we draw together a wealth of experimental work conducted within the sourcefilter framework over the last decade and we review how such experiments have elucidated the communicative value of animal vocalizations...|$|E
40|$|Naturalness {{of sound}} quality is {{essential}} for singing-voice synthesis. Since 95 % of singing is voiced sound (Cook, 1990), {{the focus of this}} paper is to improve the naturalness of the vowel tone quality via glottal excitation modeling. We propose to use the LF-model (Fant et al., 1985) for the <b>glottal</b> <b>wave</b> shape in conjunction with pitch-synchronous, amplitude-modulated Gaussian noise, which adds an aspiration component to the glottal excitation. The associated analysis and synthesis procedures are also provided in this paper. By analyzing baritone recordings, we have found simple rules to change voice qualities from “laryngealized ” (or “pressed”), to normal, to “breathy ” phonation. 1...|$|E
40|$|A new {{numerical}} {{model of the}} vocal folds is presented based on the well-known two-mass models of the vocal folds. The two-mass model is coupled to a model of glottal airflow based on the incompressible Navier–Stokes equations. <b>Glottal</b> <b>waves</b> are produced using different initial glottal gaps and different subglottal pressures. Fundamental frequency, glottal peak flow, and closed phase of the <b>glottal</b> <b>waves</b> have been compared with values known from the literature. The phonation threshold pressure was determined for different initial glottal gaps. The phonation threshold pressure obtained using the flow model with Navier–Stokes equations corresponds better to values determined in normal phonation than the phonation threshold pressure obtained using the flow model based on the Bernoulli equation. Using the Navier–Stokes equations, an increase of the subglottal pressure causes the fundamental frequency and the glottal peak flow to increase, whereas the fundamental frequency in the Bernoulli-based model does not change with increasing pressure. ...|$|R
40|$|Emotional speech makes speech more expressive, {{emotional}} speech conversion {{is needed}} in many systerms. Analyzing of <b>glottal</b> source <b>wave</b> {{plays an important role}} in emotional speech conversion. The purpose of this paper is to analyze glottal source of emotional speech for emotional speech conversion based on the Auto-Regressive eXogenous (ARX) model combined with Liljencrant-fant (LF) model, in which the Glottal Clsure Instant (GCI) and Glottal Opening Instant (GOI) are two important parameters and greatly affect the accuracy of the ARX-LF model. Therefore, a mean-based signal method is suggested to improve the estimation accuracy of GCI, and GOI is estimated from the Hilbert envelope of LP residual. The ARXLF model with accurate GCI and GOI is applied for analysis of glottal source of emotional speech. The results show that the proposed approach improve the accuracy of <b>glottal</b> source <b>wave</b> of speech, and the different <b>glottal</b> source <b>waves</b> of different emotional speech can be obtained...|$|R
40|$|The Glottal Source is an {{important}} component of voice as it can be considered as the excitation signal to the voice apparatus. Nowadays, new techniques of speech processing such as speech recognition and speech synthesis use the glottal closure and opening instants. Current models of the <b>glottal</b> <b>waves</b> derive their shape from approximate information rather than from exactly measured data. General method concentrate on assessment of the glottis opening using optical, acoustical methods, or on visualization of the larynx position using ultrasound, computer tomography or magnetic resonance imaging techniques. In this work, circuit model of Human Glottis using MOS is designed by exploiting fluid volume velocity to current, fluid pressure to voltage, and linear and nonlinear mechanical impedances to linear and nonlinear electrical impedances. The glottis modeled as current source includes linear, non-linear impedances to represent laminar and turbulent flow respectively, in vocal tract. The MOS modelling and simulation results of glottal circuit has been carried out on BSIM 3 v 3 model in TSMC 0. 18 micrometer technology using ELDO simulator. Comment: International Journal of Computer Science Issues online at [URL]...|$|R
40|$|In ongoing {{basic human}} vocal chord {{functionality}} research, scientists try {{to describe the}} dependency of the <b>glottal</b> <b>wave</b> characteristics on tone generation and vocal chord properties. One of the affordable vocal chord visualization techniques for clinics is the Videokymography - technique based on recording the vocal chord vibration using a CCD camera modified to a line-scanner. Recorded rows are than combined to form a spatial-time recording. These records are suitable for computer based extraction of the vocal chord characteristics, including {{the characteristics of the}} glottal waves. In this thesis the method for automatic detection of the glottal waves was developed and implemented utilizing the digital image processing techniques. The proposed method is primarily focused on processing the healthy vocal chords videokymographic images as they gives us a good reference for the physiology of the human vocal chord organ...|$|E
40|$|The {{singing voice}} {{is the oldest}} and most complex musical instrument. A {{familiar}} singer's voice is easily recognizable for humans, even when hearing a song for the first time. On the other hand, for automatic identification this is a difficult task among sound source identification applications. The signal processing techniques aim to extract features that are related to identity characteristics. The research presented in this paper considers 32 Mel-Frequency Cepstral Coefficients in two subsets: the low order MFCCs characterizing the vocal tract resonances and the high order MFCCs related to the <b>glottal</b> <b>wave</b> shape. We explore possibilities to identify and discriminate singers using the two sets. Based on the results we can affirm that both subsets have their contribution in defining the identity of the voice, but the high order subset is more robust to changes in singing style...|$|E
40|$|Current model-based speech {{analysis}} {{tends to}} be incomplete- {{only a part of}} parameters of interest (e. g. only the pitch or vocal tract) are modeled, while the rest that might as well be important are disre-garded. The drawback is that without joint modeling of parameters that are correlated, the analysis on speech parameters may be inac-curate or even incorrect. Under this motivation, we have proposed such a model called PAT (Probabilistic Acoustic Tube), where pitch, vocal tract and energy are jointly modeled. This paper proposes an improved version of PAT model, named PAT 2, where both signal and probabilistic modeling are tremendously renovated. Compared to re-lated works, PAT 2 is much more comprehensive, which incorporates mixed excitation, <b>glottal</b> <b>wave</b> and phase modeling. Experimental results show its ability in decomposing speech into desirable param-eters and its potential for speech synthesis. Index Terms — Probabilistic generative model, model-based speech processing, speech modelin...|$|E
40|$|To {{study the}} {{mechanical}} {{behavior of the}} vocal folds, lumped parameter models of the vocal folds have been developed in the past. Coupling with {{a model of the}} aerodynamics in the glottis provides the possibility of simulating <b>glottal</b> <b>waves.</b> A new method is presented to obtain values for the masses and springs of the lumped parameter models by using a finite-element method model of the vocal folds. This finite-element method model is based on geometry and material data from the literature, resulting in a model that describes the vocal fold in a realistic way. Requiring the dynamic behavior of the lumped parameter model of the vocal fold to be equal to the dynamic behavior of the finite-element method model of the vocal fold, parameter values are obtained that are purely based on dynamic considerations. Therefore, the behavior of the vocal folds is described in a realistic way by these parameters. These values are compared with the values used by previous authors and are implemented in lumped parameter models. Self-sustained oscillation is achieved with the new values for masses and springs. (C) 1999 Acoustical Society of America. [S 0001 - 4966 (99) 03412 - 8]...|$|R
40|$|The myoelastic-aerodynamic {{model of}} {{phonation}} implies that aerodynamic factors {{are crucial to}} the evaluation of voice function, Subglottal pressure and mean flow rate represent the vocal power source. If they {{can be related to}} the magnitude of the radiated sound power, they may provide an index of vocal efficiency. Methods of evaluating the aerodynamic characteristics associated with the ventilatory and laryngeal systems are critically discussed, and normative aerodynamic values for use in diagnosis and physiologic investigations are presented. Measurements having excellent time resolution of the <b>glottal</b> flow <b>wave</b> and of pressure changes {{in the vicinity of the}} larynx itself demonstrate the importance of study vocal tract acoustics...|$|R
40|$|Seven women, {{all without}} any known voice problems, served as informants. They ranged from {{speakers}} with no voice training to a speech therapist and amateur choir singers. Typical examples of fundamental frequencies and formant frequencies and bandwidths for all seven speakers {{are given in}} Table 1. The women were recorded un-der Hi-fi conditions. At this session the informants read a sentences list and an excerpt from a novel. The novel excerpt {{has been used by}} a speech therapist to judge and clas-sify the different speakers. For each speaker a rendering of the sentence "ja adjo. " (IPA: ja: ajd:) has been inverse filtered using an interactive computer program. After inverse filtering the bandwidth of the signal was 25 - 4000 Hz. The dynamic glottal parameters used h the LF-model were measured through the whole utterances from the inverse fil-tered signal, that is from the <b>glottal</b> pressure <b>wave.</b> The LF-model parameters are demonstrated in Fig 1. The mean values of these dynamic source parameters for a 35 -msec part of each of the two long vowels /a / and /el for each speaker are given in Table 2...|$|R
40|$|Two new {{approaches}} to feature extraction for automatic emotion classification in speech are described and tested. The methods are based on recent laryngological experiments testing the glottal air flow during phonation. The proposed approach calculates the area under the spectral energy envelope of the speech signal (AUSEES) and the glottal waveform (AUSEEG). The new methods provided very high recognition rates for seven emotions (contempt, angry, anxious, dysphoric, pleasant, neutral and happy). The speech data included 170 adult speakers (95 female and 75 male). The classification {{results showed that the}} new features provided significantly higher classification results (89. 95 % for AUSEEG, 76. 07 % for AUSEES) compared to the baseline MFCC approach (37. 81 %). The glottal waveform based AUSEEG features provided better results than the speech based AUSEES features, indicating {{that the majority of the}} emotion information is likely to be added to speech during the <b>glottal</b> <b>wave</b> formatio...|$|E
40|$|Previous {{studies of}} an {{automated}} detection of Major Depression in adolescents based on acoustic speech analysis identified the glottal and the Teager Energy features as the strongest correlates of depression. This study investigates {{the effectiveness of}} these features in an early prediction of Major Depression in adolescents using a fully automated speech analysis and classification system. The prediction was achieved through a binary classification of speech recordings from 15 adolescents who developed Major Depression within two years after these recordings were made and 15 adolescents who did not developed Major Depression within the same time period. The results provided a proof of concept that an acoustic speech analysis can be used in early prediction of depression. The glottal features made the strongest predictors of depression with 69 % accuracy, 62 % specificity and 76 % sensitivity. The TEO feature derived from <b>glottal</b> <b>wave</b> also provided good results, specifically when calculated at frequency range of 1. 3 kHz to 5. 5 kHz...|$|E
40|$|Aerodynamic {{aspect of}} the {{laryngeal}} function have been studied by many peoples. The method which is hoped for {{this study is to}} have a data right at the glottis without any supraglottic intervention. Application of the inverse filter which is calculated theoretically may remove the supra-glottic effect. This method, however, require some troublesome procedures. It is not practical at least for clinical use. In 1975 Sondhi has devised a reflectionless tube which is proved to be useful to get a glottal waveform(l). The rationale of this method is that the effect of vocal tract resonances on the glottal waveform is considerably reduced by phonating into a reflectionless uniform tube. The details of clinical application of this method is reported elsewhere (2) • A pneumotachograph which has been used in voice study for many years has a frequency response of less than 50 Hz. Therefore this is not useful for a purpose to obtain a information of each cycle or <b>glottal</b> <b>wave.</b> A hot-wire flow meter of recent years has a excellent frequency response. It seems reasonable to try this flow mete...|$|E
40|$|A {{low-dimensional}} physically oriented {{model of}} the glottal source is discussed. The model relies on a lumped mechano-aerodynamic scheme based on the mass-spring paradigm. The vocal folds are represented by a mechanical resonator plus a delay line which {{takes into account the}} vertical phase differences. First, a simple flow model based on Bernoulli’s law is assumed, and the properties of the system are discussed. The class of models under consideration is shown to be able to reproduce a broad range of phonation styles, and to provide interesting control properties. Secondly, an extended flow model is introduced with the aim of reproducing realistic glottal source waveforms obtained by inverse filtering. The new flow model is based on a general parametric nonlinear model. For this new scheme, the principal characteristics of the flow-induced oscillations are retained, and the overall model is suited for an identification approach where real inverse filtered glottal flow signals are to be reproduced. A data-driven identification procedure is outlined, where the parameters of the model are tuned in order to accurately match the target waveform. A set of inverse-filtered <b>glottal</b> flow <b>wave</b> forms with different characteristics are used to test the effectiveness of the approach. The results demonstrate that the model can reproduce a wide range of target waveforms...|$|R
40|$|Abstract—This {{doctoral}} consortium paper {{outlines the}} au-thor’s proposed {{investigation into the}} use of the voice-source waveform for affective computing. A data-driven glottal waveform representation, previously examined in the authors earlier doc-toral studies for its speaker discriminative abilities, is proposed to be studied for both depression detection and emotion recognition, including severity classification when considering depression. ‘Data-driven ’ refers to a parameterisation focus on the small but consistent idiosyncrasies of the <b>glottal</b> <b>wave</b> rather than only the mean shape and ratio measures. A review of the literature is given covering existing studies of the glottal waveform for depression detection and emotion classification. The benefits of developing easily accessible automatic recognition systems is stressed. The value of developing objective tools for clinicians in diagnosing depression is also conveyed. Finally research questions are framed and experimental methodologies discussed in order to address these. The studies proposed here will expand the body of knowledge regarding the information content of the glottal waveform and aim to improve depression detection and emotion classification accuracies based on the voice-source alone...|$|E
40|$|This {{paper is}} a part of a project {{concerning}} the finding of objective characteristics of susceptibility to voice strain. In that project, measurements were made of simultaneous recordings of microphone speech, oral flow, oral pressure and EGG. A comparison is made of parameters extracted from the inverse filtered waveforms of oral flow and speech pressure from these recordings, that is, with and without a face-mask. Microphone and flow recordings of the syllable /pæ / were inverse filtered. The parameters speed quotient (SQ), open quotient (OQ), the amplitude difference {{between the first and second}} harmonic (H 1 -H 2), and a measure of spectral slope were extracted from the <b>glottal</b> <b>wave</b> form. Initial analysis was intended to show a correlation between the parameter values for mask and non-mask recordings. The expected correlation was not forthcoming, and a re-assessment of the methodology was required. A repeated measures analysis of variance was then carried out to examine the effects of three independent variables: presence of the flow-mask, presence of an endoscope, and voicing condition. The results showed that the presence of the mask used for the flow recordings had a significant effect on the parameters which were examined. The explanation for these results include the psychological effect of the mask, inconsistent voicing strategies on behalf of the subjects, possible large within-speaker variation, and the acoustic effects of the flow mask. 1...|$|E
40|$|Background: Until now, it {{has been}} {{impossible}} to discriminate a pathology of the vocal folds and, in many instances, even to distinguish normal from pathological voices with an electroglottographic signal (EGG). Objectives: To introduce a method for analyzing electroglottographic signals and for extracting features able to characterize phonation quantitatively. Methods: The EGG signal recorded during a continuous vocal phonation is processed {{in order to obtain}} the first derivative, which is related to the velocity of movements and contact of the vocal folds. The average fundamental frequency is computed and its corresponding period is taken as the typical duration of the EGG cycle. After each glottal cycle has been identified, the EGG signal and its derivative are locally normalized in time. For each glottal cycle, the amplitude and related velocity signals are plotted in an X-Y graph thus forming a multi-layer display where each EGG cycle appears as a circular trace. This X-Y representation {{can be viewed as a}} polar graph: by increasing the angle from 0 to 360 ° with incremental steps corresponding to the time normalization re-sampling of the EGG cycle, mean value and variance are computed. The results are the curve of the amplitude-velocity mean cycle and the related variance curve. The shape of the mean loop is strictly associated with the relationships between amplitude-velocity changes and phonation phases. The surrounding area represents the variability of local vocal phenomena around the above mean curve. The phonation process can be characterized in more detail by computing couples of indices (mean and variance) as obtained by dividing the polar graph in 4 quadrants, roughly associated with the different phases of the glottal cycle. In our study we carried out the EGG analysis of 21 cases of normal voice and 21 cases of pathological voice, considering the variability based on the combined amplitude-velocity analysis. Results: In normal subjects, the global variability indices (VI) (expression of Amplitude and Velocity variation) and the four VI of different physiological phases of <b>glottal</b> <b>wave</b> (VI 1, VI 2, VI 3 and VI 4), were definitely lower than in pathological subjects. Such difference was statistically significant (p< 0. 03). Conclusions: The above method for analyzing the EGG signal proved to be efficient to discriminate normal subjects from pathological ones. Additional trials with more subjects are needed to confirm this preliminary data and to evaluate possible differences between different pathologies...|$|E

