310|1274|Public
2500|$|The first byte(A) {{contains}} {{two pieces of}} <b>information.</b> <b>Bit</b> A7 (MSB of byte A, the first byte) indicates {{whether or not the}} MIL (check engine light) is illuminated. [...] Bits A6 through A0 represent the number of diagnostic trouble codes currently flagged in the ECU.|$|E
5000|$|DSSS phase-shifts a {{sine wave}} pseudorandomly with a {{continuous}} string of pseudonoise (PN) code symbols called [...] "chips", {{each of which}} has a much shorter duration than an <b>information</b> <b>bit.</b> That is, each <b>information</b> <b>bit</b> is modulated by a sequence of much faster chips. Therefore, the chip rate is much higher than the information signal bit rate.|$|E
50|$|Note {{that this}} is the energy per bit, not the energy per <b>information</b> <b>bit.</b>|$|E
40|$|The {{difference}} between block codes and convolutional codes is the encoding principle. In the block codes, the <b>information</b> <b>bits</b> {{are followed by}} the parity bits. In convolutional codes the <b>information</b> <b>bits</b> are spread along the sequence. That means that the convolutional codes map <b>information</b> to code <b>bits</b> not block wise, but sequentially convolve the sequence of <b>information</b> <b>bits</b> according to some rule...|$|R
3000|$|In {{the two-way}} relay system, we use three slots to send 1, 024 <b>information</b> <b>bits</b> in each {{direction}} (2, 048 <b>information</b> <b>bits</b> in total), yielding a total transmission time of 2, 048 / R [...]...|$|R
40|$|The {{numbers of}} <b>information</b> <b>bits</b> to be {{embedded}} into each block are equal in current image watermarking algorithms. The sensitive positions are overly embedded while the insensitive ones {{are not fully}} utilized {{with a certain amount}} of <b>information</b> <b>bits,</b> which limits the effect of embedding the information. A new image watermarking algorithm is proposed by adaptively determining the number of <b>information</b> <b>bits</b> to be embedded into the blocks. It is also considered when embedding the information that the sensitivity of same texture or brightness on human eye is not same in different circumstances. The original image is divided into blocks, and the number relies on the frequency-domain of the blocks. Experimental results show that the algorithm can well promote the invisibility of the watermarks {{with a certain amount of}} <b>information</b> <b>bits,</b> according to which the amount of <b>information</b> <b>bits</b> can be larger with the same invisibility...|$|R
5000|$|In telecommunication, a user <b>information</b> <b>bit</b> {{is a bit}} {{transferred}} from a source user to a telecommunications system for delivery to a destination user.|$|E
5000|$|Choice of FEC code rate—the FEC code used has {{a rate of}} 1/3, {{but it can be}} varied {{effectively}} by bit puncturing and hybrid automatic repeat request (HARQ) with incremental redundancy. When {{the radio}} link conditions are good more bits are punctured and the <b>information</b> <b>bit</b> rate is increased. In poor link conditions all redundant bits are transmitted and the <b>information</b> <b>bit</b> rate drops. In very bad link conditions retransmissions occur due to HARQ which ensures correct reception of the sent information but further decreases the bit rate.|$|E
50|$|Taking {{the limit}} of this last {{inequality}} as α, β → 1 yields the less general Shannon entropy inequality,valid for any base of logarithm, {{as long as we}} choose an appropriate unit of <b>information,</b> <b>bit,</b> nat, etc.|$|E
3000|$|... the {{a priori}} {{extrinsic}} of <b>information</b> <b>bits</b> {{is equal to}} 0. Output: extrinsic <b>information</b> of coded <b>bits</b> [...]...|$|R
40|$|Index modulation, where <b>information</b> <b>bits</b> are {{conveyed}} through antenna indices (spatial modulation) and subcarrier indices (subcarrier index modulation) {{in addition}} to <b>information</b> <b>bits</b> conveyed through conventional modulation symbols, is getting increased research attention. In this paper, we introduce precoder index modulation, where <b>information</b> <b>bits</b> are conveyed through {{the choice of a}} precoder matrix at the transmitter from a set of pre-determined pseudo-random phase precoder (PRPP) matrices. Combining precoder index modulation (PIM) and spatial modulation (SM), we introduce a PIM-SM scheme which conveys <b>information</b> <b>bits</b> through both antenna index as well as precoder index. Spectral efficiency (in bits per channel use) and bit error performance of these index modulation schemes are presented. Comment: arXiv admin note: substantial text overlap with arXiv: 1401. 654...|$|R
3000|$|... be the {{decoding}} {{error probability}} of <b>information</b> <b>bits</b> and coded bits, respectively, {{of the link}} from source MSj to the relay. We assume, for simplicity, that the network-encoded <b>information</b> <b>bits</b> and network-encoded coded bits are independent (a reasonable assumption if interleavers are used at the relay).|$|R
50|$|The first byte(A) {{contains}} {{two pieces of}} <b>information.</b> <b>Bit</b> A7 (MSB of byte A, the first byte) indicates {{whether or not the}} MIL (check engine light) is illuminated. Bits A6 through A0 represent the number of diagnostic trouble codes currently flagged in the ECU.|$|E
50|$|No {{additional}} information, such as screen resolution, {{color depth}} and palette <b>information,</b> <b>bit</b> planes and so on, is stored. Video adapters were simple when this format was in wide {{use and the}} other information necessary to display the image could usually be inferred by programs that loaded such files.|$|E
5000|$|One form {{is direct}} {{sequence}} spread spectrum (DS-CDMA), used {{for example in}} 3G cell phone systems. Each <b>information</b> <b>bit</b> (or each symbol) is represented by a long code sequence of several pulses, called chips. The sequence is the spreading code, and each message signal (for example each phone call) uses a different spreading code.|$|E
40|$|Error Correcting {{codes are}} {{normally}} used for protecting transmitted <b>information</b> <b>bits</b> in a noisy channel. The <b>information</b> <b>bits</b> are encoded into error correcting codes {{which will be}} transmitted into the channel and on the receiver side, the received codes will be decoded back into the transmitted <b>information</b> <b>bits.</b> In this paper, a technique of generating binary error correcting codes that meet the Gilbert-bound and a simple encoding-decoding mechanism will be presented. To show {{the performance of the}} error correcting codes, a Binary Symmetric Channel is considered for transmission...|$|R
40|$|We {{consider}} query-based {{data acquisition}} {{and the corresponding}} information recovery problem, where {{the goal is to}} recover k binary variables (<b>information</b> <b>bits)</b> from parity measurements of those variables. The queries and the corresponding parity measurements are designed using the encoding rule of Fountain codes. By using Fountain codes, we can design potentially limitless number of queries, and corresponding parity measurements, and guarantee that the original k <b>information</b> <b>bits</b> can be recovered with high probability from any sufficiently large set of measurements of size n. In the query design, the average number of <b>information</b> <b>bits</b> that is associated with one parity measurement is called query difficulty (d̅) and the minimum number of measurements required to recover the k <b>information</b> <b>bits</b> for a fixed d̅ is called sample complexity (n). We analyze the fundamental trade-offs between the query difficulty and the sample complexity, and show that the sample complexity of n=c{k,(k k) /d̅} for some constant c> 0 is necessary and sufficient to recover k <b>information</b> <b>bits</b> with high probability as k→∞...|$|R
50|$|User <b>information</b> <b>bits</b> are encoded to form channel bits.|$|R
50|$|The {{task of the}} {{justification}} opportunity bits (R-bits) is to be available as extra bits {{that can be used}} when the rate of the incoming tributaries is higher than its nominal value (within the margin specified by ITU-T) by an amount that makes this necessary. In this case, the opportunity bit is no longer mere stuffing, but becomes an <b>information</b> <b>bit</b> instead.|$|E
50|$|Thus HSDPA adapts {{to achieve}} very high bit rates, {{of the order}} of 14 megabit/sec, on clear {{channels}} using 16-QAM and close to 1/1 coding rate. On noisy channels HSDPA adapts to provide reliable communications using QPSK and 1/3 coding rate but the <b>information</b> <b>bit</b> rate drops to about 2.4 megabit/sec. This adaptation is performed up to 500 times per second.|$|E
5000|$|If {{the cost}} of each user is known, in terms of {{consumed}} resources per transferred <b>information</b> <b>bit,</b> the FSSE measure may be redefined to reflect proportional fairness. In a proportional fair system, this [...] "proportionally fair shared spectrum efficiency" [...] (or [...] "fairly shared radio resource cost") is maximized. This policy is less fair since [...] "expensive" [...] users are given lower throughput than others, but still scheduling starvation is avoided.|$|E
3000|$|... [...]. The symbol {{repetition}} {{rate and the}} code rate for the convolutional codes is also given. The average number of <b>information</b> <b>bits</b> per data-symbol is given, which {{takes into account the}} {{repetition rate}} and the modulation order of the data symbols. The spectral efficiency includes the average number of <b>information</b> <b>bits</b> per data-symbol and the code rate.|$|R
30|$|K <b>information</b> <b>bits,</b> and {{the overall}} word error rate is denoted by Pew.|$|R
3000|$|... {{and with}} M 1 −PSK constellation, {{a total of}} Q = n_T!M_ 1 ^n_T - 1 {{matrices}} X in the signal space ΩHR−DSM can be obtained. Therefore, one matrix X is able to carry l= log_ 2 (n_T!M_ 1 ^n_T - 1) <b>information</b> <b>bits.</b> In addition, one M−PSK constellation symbol corresponds to m=log 2 M <b>information</b> <b>bits.</b> Both of them are transmitted within n [...]...|$|R
50|$|In 1953, Léon Brillouin derived {{a general}} {{equation}} {{stating that the}} changing of an <b>information</b> <b>bit</b> value requires at least kT ln(2) energy. This is the same energy as the work Leó Szilárd's engine produces in the idealistic case. In his book, he further explored this problem concluding that any cause of this bit value change (measurement, decision about a yes/no question, erasure, display, etc.) will require {{the same amount of}} energy.|$|E
5000|$|Choice of {{modulation}} type—the link can employ QPSK for noisy {{channels and}} 16QAM for clearer channels. The former is more robust and can tolerate {{higher levels of}} interference but has lower transmission bit rate. The latter has twice higher bit rate but is more prone to errors due to interference and noise hence it requires stronger forward error correction (FEC) coding which in turn means more redundant bits and lower <b>information</b> <b>bit</b> rate; ...|$|E
5000|$|The PICtor {{format is}} a device-independent raster image format; the file header stores {{information}} about the display hardware (screen resolution, color depth and palette <b>information,</b> <b>bit</b> planes and so on) separately from the actual image information, allowing the image to be properly transferred and displayed on computer systems with different hardware. PIC files commonly stored palette-indexed images ranging from 2 or 4 colors to 16 and 256 colors, although the format has been extended to record true-color (24-bit) images as well.|$|E
30|$|For {{decoding}} data successfully the eavesdropper {{must first}} perform blind channel estimation to map its received joint constellation symbols to <b>information</b> <b>bits.</b> Finding the bit mapping {{is an act}} of deciphering, where the received joint symbols are the cipher-text, the channel coefficients are the encryption key and the <b>information</b> <b>bits</b> are the encrypted message. After deciphering, the eavesdropper must decode the data from a deteriorated signal.|$|R
30|$|Note {{that the}} <b>information</b> <b>bits</b> of a source {{need to be}} split in two parts: bits of the type 1 i and 2 i. This allows the {{introduction}} of the matrices R 1 and R 2 in Equation 19, so that all <b>information</b> <b>bits</b> have a random matrix in their corresponding block column in the parity-check matrix. Now, the LDPC code can conform any degree distribution.|$|R
3000|$|... as {{at least}} one channel, the source-destination channel, needs to fail to loose the {{corresponding}} <b>information</b> <b>bits.</b>|$|R
5000|$|Let's say three errors corrupt the {{transmitted}} {{bits and}} the received sequence is [...] Decoding is usually {{done by a}} simple majority decision for each code word. That lead us to [...] as the decoded information bits, because {{in the first and}} second code word occurred less than two errors, so the majority of the bits are correct. But in the third code word two bits are corrupted, which results in an erroneous <b>information</b> <b>bit,</b> since two errors lie above the error correcting capacity.|$|E
50|$|In these systems, {{the symbol}} {{rate of the}} {{physically}} transmitted high-frequency signal rate is called chip rate, which also is the pulse rate of the equivalent base band signal. However, in spread spectrum systems, the term symbol may also be used at a higher layer and refer to one <b>information</b> <b>bit,</b> or a block of information bits that are modulated using for example conventional QAM modulation, before the CDMA spreading code is applied. Using the latter definition, the symbol rate is equal to or lower than the bit rate.|$|E
50|$|The Jigsaw Islands are {{two small}} islands lying off the {{southwest}} end of Wiencke Island, in the Palmer Archipelago, Antarctica. One {{of the islands}} {{was used as a}} main triangulation station by the British Naval Hydrographic Survey Unit in 1956-57, and by the Falkland Islands and Dependencies Aerial Survey Expedition in March 1957. The islands were so named by the UK Antarctic Place-Names Committee because of the difficulty with which the station was recovered, the surveyors piecing together the available <b>information</b> <b>bit</b> by bit to narrow down the exact spot on the island where the station had been established.|$|E
3000|$|After convergence, the <b>information</b> <b>bits</b> are {{determined}} by taking hard decisions based on the beliefs b(u [...]...|$|R
3000|$|... [t]), i= 1, 2,…, K, the {{relation}} between the <b>information</b> <b>bits</b> and coded symbols transmitted from each user.|$|R
3000|$|... <b>information</b> <b>bits</b> {{including}} cyclic {{redundancy check}} (CRC) bits for error detection, is first encoded by a rate- [...]...|$|R
