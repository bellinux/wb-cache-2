10|46|Public
5|$|Houston pioneered American car {{culture in}} the early 1900s thanks to the ready {{availability}} of inexpensive gasoline. By the 1920s traffic congestion had become so serious that the city became {{the first in the}} nation to install <b>interconnected</b> <b>traffic</b> lights. Visitors to the city were often astonished at the lack of pedestrian access to shopping venues and the importance of the automobile within the city. Though mass transit had been successful in Houston's earlier years, later efforts aimed at promoting mass transit and urban planning were largely defeated in Houston because of opposition by the public, which favored public investment in roads over mass transit. Urban concepts pioneered in Houston, like establishing shopping centers outside the city's core and encouraging suburban sprawl, became major trends adopted in many cities, both within the state and around the country.|$|E
50|$|The first <b>interconnected</b> <b>traffic</b> {{signal system}} was {{installed}} in Salt Lake City in 1917, with six connected intersections controlled simultaneously from a manual switch. Automatic control of <b>interconnected</b> <b>traffic</b> lights was introduced March 1922 in Houston, Texas.|$|E
50|$|He {{devised a}} durable metal stoplight, using the {{smokestack}} {{from an old}} locomotive engine for the frame, but without a yellow caution light. He thought of having it patented, but ended up not doing so. Some believed the reason to be that Wire had been drafted to serve in World War I, and {{could not see the}} patent process through. Five years after Wire's invention, Salt Lake City became the first <b>interconnected</b> <b>traffic</b> signal system in the United States. Based on Wire's designs the lights were first installed on August 5, 1914 in Cleveland, Ohio on the corner of East 105th street and Euclid Avenue.|$|E
40|$|We {{present the}} first shared-memory {{algorithms}} for k-exclusion {{in which all}} process blocking is achieved {{through the use of}} "local-spin" busy waiting. Such algorithms are designed to reduce <b>interconnect</b> <b>traffic,</b> which is important for good performance. Our k-exclusion algorithms are starvation-free, and are designed to be fast in the absence of contention, and to exhibit scalable performance as contention rises. In contrast, all previous starvation-free k-exclusion algorithms require unrealistic operations or generate excessive <b>interconnect</b> <b>traffic</b> under contention. We also show that efficient, starvation-free k-exclusion algorithms can be used to reduce the time and space overhead associated with existing wait-free shared object implementations, while still providing some resilience to delays and failures. The resulting "hybrid" object implementations combine the advantages of local-spin spin locks, which perform well in the absence of process delays (caused, for example, by preemptio [...] ...|$|R
40|$|Abstract [...] Trinity College Dublin has {{designed}} {{and is currently}} prototyping a trace instrument that allows deep traces of high speed <b>interconnect</b> <b>traffic</b> [5]. An initial implementation for the Scalable Coherent Interface (SCI) proves the concept. SCI {{is one of the}} enabling interconnect technologies for high performance computing on PC Clusters. Figure 1. shows how the trace instrument’s hardware and software components are related to each other during trace data acquisition and a subsequent off-line data analysis. Such an instrument is essential for a detailed spatial and temporal analysis of parallel executed algorithms on loosely coupled clusters. Currently, there are no commercial instruments available that sample and store very deep (>> 10 Mbyte) interconnect traces per target node. The technology enables the non-intrusive real-time acquisition of high speed <b>interconnect</b> <b>traffic</b> into a database. The database, which over time is expected to represent the major investment, provides a powerful means for a fine-grained analysis of a large quantity of trace data. This paper describes the technical features of the SCI trace instrument and outlines the tool’s potential for further research and development activities...|$|R
40|$|This RFC {{specifies}} an IAB standards track {{protocol for}} the Internet community, and requests discussion {{and suggestions for}} improvements. Please refer to the current edition of the "IAB Official Protocol Standards " for the standardization state and status of this protocol. Distribution of this memo is unlimited. This memo describes two encapsulations methods for carrying network <b>interconnect</b> <b>traffic</b> over ATM AAL 5. The first method allows multiplexing of multiple protocols over a single ATM virtual circuit whereas the second method assumes that each protocol is carried over a separate ATM virtual circuit. 1...|$|R
50|$|Houston pioneered American car {{culture in}} the early 1900s thanks to the ready {{availability}} of inexpensive gasoline. By the 1920s traffic congestion had become so serious that the city became {{the first in the}} nation to install <b>interconnected</b> <b>traffic</b> lights. Visitors to the city were often astonished at the lack of pedestrian access to shopping venues and the importance of the automobile within the city. Though mass transit had been successful in Houston's earlier years, later efforts aimed at promoting mass transit and urban planning were largely defeated in Houston because of opposition by the public, which favored public investment in roads over mass transit. Urban concepts pioneered in Houston, like establishing shopping centers outside the city's core and encouraging suburban sprawl, became major trends adopted in many cities, both within the state and around the country.|$|E
50|$|Planning {{began in}} the early 1920s for the Boulevard of the Allies, {{extending}} east from Second Avenue and Grant Street to Oakland. The first part of the Boulevard of the Allies was dedicated on August 8, 1921, and the entire highway opened to traffic on October 2, 1923, including several viaducts and widenings of the existing Emily Street to a terminus at Wilmot Street and Forbes Avenue. One of the first <b>interconnected</b> <b>traffic</b> signal systems was installed a month later (November 13) on the Boulevard downtown as an experiment. Prior to completion, its cost was reported as $1.6 million per mile, the most expensive road in the world at the time. In 1924, the Boulevard became part of an alternate bypass route of the Lincoln Highway, whose original route used Bigelow Boulevard into downtown; this left the Boulevard at Forbes Avenue (its original terminus), following Beeler Street, Wilkins Avenue, and Dallas Avenue to the main route on Penn Avenue near East Liberty.|$|E
5000|$|Second Avenue was widened to a {{width of}} 70 feet (20 m) from Liberty Avenue east to Grant Street in 1920 and 1921. Planning began at {{about that time}} for the Boulevard, {{extending}} east from Second Avenue and Grant Street to Oakland. The {{first part of the}} Boulevard of the Allies was dedicated on August 8, 1921, and the entire highway opened to traffic on October 2, 1923, including several viaducts and widenings of the existing Emily Street to a terminus at Wilmot Street and Forbes Avenue. One of the first <b>interconnected</b> <b>traffic</b> signal systems was installed a month later (November 13) on the Boulevard downtown as an experiment. Prior to completion, its cost was reported as $1.6 million per mile, the most expensive road in the world at the time. In 1924, the Boulevard became part of an alternate bypass route of the Lincoln Highway, whose original route used Bigelow Boulevard into downtown; this left the Boulevard at Forbes Avenue (its original terminus), following Beeler Street, Wilkins Avenue, and Dallas Avenue to the main route on Penn Avenue near East Liberty. [...] The Boulevard at Grant Street was once home to Pittsburgh's Chinatown until the 1950s.|$|E
40|$|This paper {{describes}} Constrained Associative-Mapping-of-Tracking-Entries (C-AMTE), a scalable {{mechanism to}} facilitate flexible and efficient distributed cache management in large-scale chip multiprocessors (CMPs). C-AMTE enables fast locating of cache blocks in CMP cache schemes that employ one-to-one or one-to-many associative mappings. C-AMTE stores in per-core data structures tracking entries to avoid on-chip <b>interconnect</b> <b>traffic</b> outburst or long distance directory lookups. Simulation results using a full system simulator demonstrate that C-AMTE achieves improvement in cache access latency {{by up to}} 34. 4 %, close {{to that of a}} perfect location strategy. © 2010 Elsevier Inc. All rights reserved...|$|R
50|$|The plan {{recommends}} a comprehensive traffic management study to cover these <b>interconnected</b> aspects of <b>traffic</b> management.|$|R
40|$|This paper {{introduces}} {{network interface}} data caching, {{a new technique}} to reduce local <b>interconnect</b> <b>traffic</b> on networking servers by caching frequently-requested content on a programmable network interface. The operating system on the host CPU determines which data to store in the cache and for which packets it should use data from the cache. To facilitate data reuse across multiple packets and connections, the cache only stores application-level response content (such as HTTP data), with application-level and networking headers generated by the host CPU. Network interface data caching can reduce PCI traffic by up to 57 % on a prototype implementation of a uniprocessor web server. This traffic reduction results in up to 31 % performance improvement, leading to a peak server throughput of 1571 Mb/s...|$|R
40|$|International audienceIn {{order to}} meet our goal we have {{provided}} the research community with two tools: (a) a real mobility model (b) an <b>interconnected</b> <b>traffic</b> with the real mobility model. We show that under real mobility and <b>interconnected</b> <b>traffic</b> performance and mobility metrics need to be re-thought. Therefore, we propose availability as a new performance metric that {{is defined as the}} ratio between the number of packets sent by the source and the number of packets received by the destination while the destination is active. Based on the availability metric, protocol performance is dependent on the traffic sent by the type of the nodes (stationary vs. mobile nodes). Furthermore, to improve the efficiency of the current mobility metric algorithms and incentive ad hoc protocols, we use the Maximum Node Degree mobility metric, which has got little attention in the research...|$|E
40|$|Nowadays {{many studies}} are being {{conducted}} to develop solutions {{for improving the}} performance of urban traffic networks. One of the main challenges is the necessary cooperation among different entities such as vehicles or infrastructure systems and how to exploit the information available through networks of sensors deployed as infrastructures for smart cities. In this work an algorithm for cooperative control of urban subsystems is proposed to provide a solution for mobility problems in cities. The <b>interconnected</b> <b>traffic</b> lights controller (TLC) network adapts traffic lights cycles, based on traffic and air pollution sensory information, {{in order to improve}} the performance of urban traffic networks. The presence of air pollution in cities is not only caused by road traffic but there are other pollution sources that contribute to increase or decrease the pollution level. Due to the distributed and heterogeneous nature of the different components involved, a system of systems engineering approach is applied to design a consensus-based control algorithm. The designed control strategy contains a consensus-based component that uses the information shared in the network for reaching a consensus in the state of TLC network components. Discrete event systems specification is applied for modelling and simulation. The proposed solution is assessed by simulation studies with very promising results to deal with simultaneous responses to both pollution levels and traffic flows in urban traffic networks. Authors wish to thank the support given by the project IoSENSE: Flexible FE/BE Sensor Pilot Line for the Internet of Everything, funded by the Electronic Component Systems for European Leadership Joint (ECSEL) Undertaking under grant agreement No 692480. This work has been also supported by MINECO (Spain) through the project RTC- 2015 - 3942 - 4 TCAP: Auto. Moreover, Raúl M. del Toro acknowledges the financial support received from MINECO through grant “Juan de la Cierva-incorporación”, code IJCI- 2014 - 20169. We acknowledge support by the CSIC Open Access Publication Initiative through its Unit of Information Resources for Research (URICI) ...|$|E
40|$|On October 25, 1995, seven {{fatalities}} {{occurred during}} a train collision with {{a school bus}} crossing railroad tracks adjacent to a signalized intersection in Fox River Grove, IL. In 1996 the National Transportation Safety Board (NTSB) : Highway/Railroad Accident Report # PB 96 - 916202 made several recommendations to the the United States Secretary of Transportation, {{one of which was}} “… the use and maintenance of railroad and highway traffic signal recording devices……. to readily determine that the highway signals and railroad-activated warning devices are coordinated and operating properly. ” To date, this particular recommendation had not been addressed. ^ This dissertation proposes (1) screening and prioritizing procedure for signalized intersection adjacent to highway-railroad crossings, (2) performance measures to evaluate track clearing effectiveness, and (3) direct measurement of highway-railroad synchronization operation. The proposed screening and prioritization procedures were applied to 595 state maintained intersections, which identified 20 intersections for future field investigation. Changes in track clearing effectiveness were used to evaluate 2802 preempt events to compare a pre/post steerable signal head installation that was installed based upon the Manual of Uniform Traffic Control Devices (MUTCD) Section 8 D. 07 guidance. This analysis concluded there was no impact on the effectiveness of track clearance based on the signal head change. In regards to the NTSB recommendations, this dissertation defined a procedure for assessing railroad synchronization applied it to over 7, 648 preempt events recorded on a railroad <b>interconnected</b> <b>traffic</b> signal controller. Improvements to the synchronization and transition were made based the incremental analysis of performance measures. As a result of this analysis, the fixed track clear green phase was first extended by 5 seconds, followed by a subsequent refinement implementing a variable track clear green phase that terminated when the gate was down. As a result of those improvements the frequency of gates going down after the end of track clear green was reduced from 42 % to 10 % to 0 % respectively. The effectiveness of track clear green based on post track vehicle presence was also improved reducing vehicle presence from 33 to 3 to 0 vehicles respectively. The dissertation concludes with specific recommendations regarding performance measures, new traffic signal timing techniques, and potential geometric improvements {{that can be used to}} reduce train/vehicle conflicts. ...|$|E
40|$|This paper {{presents}} a low overhead, high performance cache coherence protocol designed to exploit high bandwidth point-to-point and broadcast features of optics. SPEED integrates {{the virtues of}} snoopy-based schemes and directory-based schemes into one efficient protocol. Directory-assist is used exclusively for read traffic to eliminate unnecessary broadcasts while snoopy-assist is used exclusively for write and synchronization traffic to reduce directory overhead and synchronization complexities. The proposed protocol {{has the potential to}} increase performance {{as a result of its}} global independence between read and write operations, concurrency in channel access, reduced contention, and efficient broadcast of coherence and synchronization events. 1 Introduction Caches play a critical role in reducing <b>interconnect</b> <b>traffic</b> and latency in shared memory multiprocessors (SMMPs) by maintaining local copies of shared data. An important factor that determines the performance of cached SMMP [...] ...|$|R
40|$|Multithreaded {{architectures}} {{context switch}} between instruction streams to hide memory access latency. Although this improves processor utilization, it can increase cache interference and degrade overall performance. One technique {{to reduce the}} <b>interconnect</b> <b>traffic</b> is to co-locate threads that share data on the same processor. Multiple threads sharing in the cache should reduce compulsory and invalidation misses, thereby improving execution time. To test this hypothesis, we compared a variety of thread placement algorithms via trace-driven simulation of fourteen coarse- and medium-grain parallel applications on several multithreaded architectures. Our results contradict the hypothesis. Rather than decreasing, compulsory and invalidation misses remained nearly constant across all placement algorithms, for all processor configurations, even with an infinite cache. That is, sharing-based placement had no (positive) effect on execution time. Instead, load balancing was the critical factor t [...] ...|$|R
40|$|A {{model has}} been {{developed}} and solved which captures {{the essence of the}} concept of mobile dispatch service. There are two types of users, dispatch and interconnect (calls routed from the public switched telephone network, of much longer holding times). Also, only some of the available repeaters can be used for <b>interconnect</b> <b>traffic,</b> and blocked <b>interconnect</b> calls are cleared. Dispatch calls, however, can access all repeaters, and then are queued if all repeaters are busy. One design decision involves a trade between blocking of interconnect calls and queueing of dispatch calls. A formula has been derived for both interconnect blocking probability and the mean dispatch queueing time to permit this trade. The results indicate that a good operating point is to have (N - a_d) (rounded down) interconnected repeaters, where there are N total repeaters and a_d Erlangs of dispatch traffic...|$|R
40|$|Nowadays {{many studies}} are {{conducted}} to develop solutions {{for improving the}} performance of urban traffic networks. One of the main challenges is the necessary cooperation among different entities such as vehicles or infrastructure systems and exploit the information available through networks of sensors deployed as infrastructures for smart cities. In this work an algorithm for cooperative control of urban subsystems is applied {{in order to provide}} solutions for mobility related problems in cities. The <b>interconnected</b> <b>traffic</b> lights controllers (TLC) network adapts traffic lights cycles, based on traffic and air pollution information, in order to improve the performance of urban traffic networks. The presence of air pollution in cities is not only caused by road traffic but there are other pollution sources that contribute to increase or decrease of the pollution level. Then the problem becomes more complex. Due to the distributed and heterogeneous nature of the different components involved, a system of systems engineering approach has been followed as design method and a distributed consensus-based control algorithm has been applied. The applied control law contains a consensus-based component that uses the information shared in the network for reaching a consensus in the state of TLC network components. Furthermore, Discrete Event Systems Specification (DEVS) formalism is applied for modelling and simulation purpose. The proposed solution has been tested and validated in a simulated environment corroborating that the proposed solution is a powerful technique to deal with simultaneous responses to both pollution levels and traffic flows in urban traffic networks. Authors wish to thank the support given by the project IoSENSE: Flexible FE/BE Sensor Pilot Line for the Internet of Everything, funded by the Electronic Component Systems for European Leadership Joint (ECSEL) Undertaking under grant agreement No. 692480. This work has been also supported by MINECO (Spain) through the project RTC- 2015 - 3942 - 4 TCAP: Auto. Moreover, Raúl M. del Toro acknowledges the financial support received from MINECO through grant “Juan de la Cierva-incorporación”, code IJCI- 2014 - 20169. We acknowledge support by the CSIC Open Access Publication Initiative through its Unit of Information Resources for Research (URICI) ...|$|E
40|$|Multicore {{machines}} are growing in size, and accordingly shifting from simple bus-based designs to NUMA and CC-NUMA architectures. With this shift, {{the need for}} scalable hierarchical locking algorithms is becoming crucial to performance. This paper presents a novel scalable hierarchical queue-lock algorithm based on the flat combining synchronization paradigm. At {{the core of the}} new algorithm is a scheme for building local queues of waiting threads in a highly efficient manner, and then merging them globally, all with little <b>interconnect</b> <b>traffic</b> and virtually no costly synchronization operations in the common case. In empirical testing on an Oracle SPARC Enterprise T 5440 Server, a 256 -way CC-NUMA machine, our new flat-combining hierarchical lock significantly outperforms all classic locking algorithms, and at high concurrency levels, provides up to a factor of two improvement over HCLH, the most efficient known hierarchical locking algorithm...|$|R
40|$|This RFC {{specifies}} an IAB standards track {{protocol for}} the Internet community, and requests discussion {{and suggestions for}} improvements. Please refer to the current edition of the "IAB Official Protocol Standards " for the standardization state and status of this protocol. Distribution of this memo is unlimited. This memo describes an encapsulation method for carrying network <b>interconnect</b> <b>traffic</b> over a Frame Relay backbone. It covers aspects of both Bridging and Routing. Additionally, it describes a simple fragmentation procedure for carrying large frames over a frame relay network with a smaller MTU. Systems {{with the ability to}} transfer both the encapsulation method described in this document, and others must have a priori knowledge of which virtual circuits will carry which encapsulation method and this encapsulation must only be used over virtual circuits that have been explicitly configured for its use...|$|R
40|$|To {{maintain}} coherence {{in conventional}} shared-memory multiprocessor systems, processors first check other processors’ caches before obtaining data from memory. This coherence checking adds latency to memory requests {{and leads to}} large amounts of <b>interconnect</b> <b>traffic</b> in broadcastbased systems. Our results {{for a set of}} commercial, scientific and multiprogrammed workloads show that on average 67 % (and up to 94 %) of broadcasts are unnecessary. Coarse-Grain Coherence Tracking is a new technique that supplements a conventional coherence mechanism and optimizes the performance of coherence enforcement. The Coarse-Grain Coherence mechanism monitors the coherence status of large regions of memory, and uses that information to avoid unnecessary broadcasts. Coarse-Grain Coherence Tracking is shown to eliminate 55 - 97 % of the unnecessary broadcasts, and improve performance by 8. 8 % on average (and up to 21. 7 %). 1...|$|R
40|$|This {{document}} specifies an Internet standards track {{protocol for}} the Internet community, and requests discussion {{and suggestions for}} improvements. Please refer to the current edition of the "Internet Official Protocol Standards " (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (1999). All Rights Reserved. This memo replaces RFC 1483. It describes two encapsulations methods for carrying network <b>interconnect</b> <b>traffic</b> over AAL type 5 over ATM. The first method allows multiplexing of multiple protocols over a single ATM virtual connection whereas the second method assumes that each protocol is carried over a separate ATM virtual connection. Applicability This specification {{is intended to be}} used in implementations which use ATM networks to carry multiprotocol traffic among hosts, routers and bridges which are ATM end systems. 1...|$|R
40|$|Abstract—Many-core {{processors}} {{provide the}} raw computation power required by modern high-performance multimedia and signal processing workloads. The translation of this into exe-cution performance is often {{constrained by the}} overheads of communication between concurrent tasks. This paper presents Pronto, a low overhead message passing system which simplifies the semantics of data movement between communicating tasks by performing buffer management, message synchronization and address translation directly in hardware. The integration of these functions into hardware results in transfer latencies upto 30 % shorter than {{state of the art}} MPI derivatives. The overheads for communication in a 16 -core processor array are under 5 % for 64 -word burst transfers with Pronto using workloads such as the JPEG decoder and FIR filter. Furthermore, this paper also studies the effect of task mapping and <b>interconnect</b> <b>traffic</b> on the predictability of data block arrival times, and illustrates a method to reduce variations. I...|$|R
40|$|This paper uses a {{characterization}} {{of three different}} types of <b>interconnect</b> <b>traffic</b> to drive {{the development of an}} innovative high-speed interconnect interface. This uses sender-controlled message placement at the recipient, which has the effect of greatly reducing the cost and complexity of message handling. The contributions of this work are in (a) elucidating the traffic model; (b) in defining the sender-driven communication scheme; and (c) in the detailed description of an efficient, protected interface to the interconnect hardware that allows applications running in nonprivileged mode to access the interconnect directly, without operating system intervention. This version of the paper contains a complete high-level design for the first version of Hamlyn [...] -a hardware interface that accommodates all the Hamlyn functionality. Future work on the protocol stacks and implementation work will doubtless improve and modify this interface. Until then, this description serves as a functionally complete snapshot of the Hamlyn approach...|$|R
40|$|A typical {{urban traffic}} network is a {{complicated}} large-scale stochastic system which consists of many <b>interconnected</b> signalized <b>traffic</b> intersections. This paper develops a decentralized real-time adaptive control strategy for the traffic networks based on Markov decision theory. Computer simulation results of this new approach on a five intersection traffic network indicate significant improvement over the traditional fully actuated control algorithm...|$|R
40|$|Prefetching in shared-memory {{multiprocessor}} {{systems is}} an increasingly difficult problem. As system designs grow to incorporate {{larger numbers of}} faster processors, memory latency and <b>interconnect</b> <b>traffic</b> increase. While aggressive prefetching techniques can mitigate the increasing memory latency, they can harm performance by wasting precious interconnect bandwidth and prematurely accessing shared data, causing state downgrades at remote nodes that force later upgrades. This paper investigates Stealth Prefetching, a new technique that utilizes information from Coarse-Grain Coherence Tracking (CGCT) for prefetching data aggressively, stealthily, and efficiently in a broadcast-based shared-memory multiprocessor system. Stealth Prefetching utilizes CGCT to identify regions of memory that are not shared by other processors, aggressively fetches these lines from DRAM in open-page mode, and moves them close to the processor in anticipation of future references. Our analysis with commercial, scientific, and multiprogrammed workloads show that Stealth Prefetching provides an average speedup of 20 % over an aggressive baseline system with conventional prefetching...|$|R
40|$|Many-core {{processors}} {{provide the}} raw computation power required by modern high-performance multimedia and signal processing workloads. The conversion of this computation power into ex-ecution performance is often {{constrained by the}} overheads of communication between concurrent tasks. This paper presents Pronto, a low overhead message passing system which simplies the semantics of data movement between communicating tasks by performing buffer management, message synchronization and address translation directly in hardware. The integration of these functions into hardware results in transfer latencies upto 30 % shorter than {{state of the art}} MPI derivatives. The overheads for communication with Pronto in an 18 -core processor array are under 5 % for 64 -word burst transfers, and less than 0. 5 % of total execution time using workloads such as the JPEG decoder and FIR lter. Furthermore, this paper also studies the effect of task mapping and <b>interconnect</b> <b>traffic</b> on the predictability of data block arrival times, and provides insight on where interconnect contention can be tolerated...|$|R
40|$|In this paper, {{we present}} a {{hierarchical}} Data Cache Ar-chitecture called DCA to effectively slash local <b>interconnect</b> <b>traffic</b> and thus boost the storage server performance. DCA is composed of a read cache in NIC card called NIC cache and a read/write unify cache in host memory called Helper cache. NIC cache services most portion of read requests without fetching data via PCI bus, while Helper cache 1) supplies some portions of read requests given partial NIC cache hits; 2) directs cache placement for NIC cache and 3) absorbs most transient writes locally. We developed a novel State Locality Aware cache Placement algorithm called SLAP to improve NIC cache hit ratio for mixed read and write workloads. To demonstrate the effectiveness of DCA, we developed a DCA prototype system and evaluated it with open source iSCSI implementation under representa-tive storage server workloads. Experimental results showed that DCA can boost iSCSI storage server throughput by up to 121 % and slash the PCI traffic by up to 74 % compared with an iSCSI target without DCA. 1...|$|R
40|$|The {{parallel}} {{performance of}} applications running on Non-Uniform Memory Access (NUMA) platforms is {{strongly influenced by}} the relative placement of memory pages to the threads that access them. As a consequence there are Linux application programmer interfaces (APIs) to control this. For large parallel codes it can, however, be difficult to determine {{how and when to}} use these APIs. In this paper we introduce the NUMAgrind profiling tool which can be used to simplify this process. It extends the Val grind binary translation framework to include a model which incorporates cache coherency, memory locality domains and <b>interconnect</b> <b>traffic</b> for arbitrary NUMA topologies. Using NUMAgrind, cache misses can be mapped to memory locality domains, page access modes determined, and pages that are referenced by multiple threads quickly determined. We show how the NUMAgrind tool can be used to guide the use of Linux memory and thread placement APIs in the Gaussian computational chemistry code. The performance of the code before and after use of these APIs is also presented for three different commodity NUMA platforms...|$|R
50|$|An {{interconnect}} {{agreement is}} a business contract between telecommunications organizations {{for the purpose of}} interconnecting their networks and exchanging telecommunications <b>traffic.</b> <b>Interconnect</b> agreements are found both in the public switched telephone network and the Internet.|$|R
50|$|In 1981 Aussat Pty Ltd was {{established}} as a GBE to operate domestic satellite telecommunication and broadcasting services. Aussat's charter restricted it from acting as a competitor to Telecom, including a prohibition on <b>interconnecting</b> public switched <b>traffic</b> with Telecom's network.|$|R
40|$|Best IP AwardInternational audienceFuture {{applications}} {{will require}} processors with many cores communicating through a regular interconnection network. Meanwhile, the Deep submicron technology foreshadows highly defective chips era. In this context, not only fault-tolerant designs become compulsory, but their performance under failures gains importance. In this paper, {{we present a}} deadlock-free fault-tolerant adaptive routing algorithm featuring Explicit Path Routing in order to limit the latency degradation under failures. This is particularly interesting for streaming applications, which transfer huge amount of data between the same source-destination pairs. The proposed routing algorithm is able to route messages {{in the presence of}} any set of multiple nodes and links failures, as long as a path exists, and does not use any routing table. It is scalable and can be applied to multicore chips with a 2 D mesh core interconnect of any size. The algorithm is deadlock-free and avoids infinite looping in fault-free and faulty 2 D meshes. We simulated the proposed algorithm using the worst case scenario, with different failure rates. Experimentation results confirmed that the algorithm tolerates multiple failures even in the most extreme failure patterns. Additionally, we monitored the <b>interconnect</b> <b>traffic</b> and average latency for faulty cases. For 20 × 20 meshes, the proposed algorithm reduces the average latency by up to 50 %...|$|R
40|$|Code {{placement}} {{techniques for}} instruction code have shown to increase an SOCs performance mostly {{due to the}} increased cache hit ratios and as such those techniques can be a major optimization strategy for embedded systems. Little has been investigated on the interdependencies between code placement techniques and <b>interconnect</b> <b>traffic</b> (e. g. bus traffic) and optimization techniques combining both. In this paper we show as the first approach of its kind that a carefully designed known code placement strategy combined and adapted to a known interconnect encoding scheme does not only lead to a performance increase but it does also lead to a significant reduction of interconnect-related energy consumption. This becomes especially interesting since future SOC bus systems (or more general: ”networks on a chip”) are predicted to be a dominant energy consumer of an SOC. We show that a high-level optimization strategy like code placement and a lower-level optimization strategy like interconnect encoding are NOT orthogonal. Specifically, we report cache miss reduction ratios of 32 % in average combined with bus related energy savings of 50. 4 % in average (with a maximum of up to 95. 7 %) by means of our combined optimization strategy. The results have been verified by means of diverse real-world SOC applications. ...|$|R
40|$|While {{scalable}} coherence {{has been}} extensively stud-ied {{in the context of}} general purpose chip multiprocessors (CMPs), GPU architectures present a new set of challenges. Introducing conventional directory protocols adds unneces-sary coherence traffic overhead to existing GPU applica-tions. Moreover, these protocols increase the verification complexity of the GPU memory system. Recent research, Library Cache Coherence (LCC) [34, 54], explored the use of time-based approaches in CMP coherence protocols. This paper describes a time-based coherence framework for GPUs, called Temporal Coherence (TC), that exploits globally synchronized counters in single-chip systems to de-velop a streamlined GPU coherence protocol. Synchronized counters enable all coherence transitions, such as invali-dation of cache blocks, to happen synchronously, eliminat-ing all coherence traffic and protocol races. We present an implementation of TC, called TC-Weak, which eliminates LCC’s trade-off between stalling stores and increasing L 1 miss rates to improve performance and reduce <b>interconnect</b> <b>traffic.</b> By providing coherent L 1 caches, TC-Weak improves the performance of GPU applications with inter-workgroup communication by 85 % over disabling the non-coherent L 1 caches in the baseline GPU. We also find that write-through protocols outperform a writeback protocol on a GPU as the latter suffers from increased traffic due to unnecessary re-fills of write-once data. ...|$|R
40|$|A {{real-time}} data management system which uses data generated {{at different rates}} by multiple heterogeneous incompatible data sources are presented. In one embodiment, the invention is as an airport surface traffic data management system (traffic adviser) that electronically <b>interconnects</b> air <b>traffic</b> control, airline, and airport operations user communities to facilitate information sharing and improve taxi queuing. The system uses an expert system to fuse dam {{from a variety of}} airline, airport operations, ramp control, and air traffic control sources, in order to establish, predict, and update reference data values for every aircraft surface operation...|$|R
