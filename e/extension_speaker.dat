10|15|Public
500|$|The {{smallest}} Leslie is the Model 16, made in 1970. It has a Fender-like speaker {{body and}} a rotating foam dispersion block. It was built for guitarists, portable, and had [...] "Leslie" [...] written on the front. It contained just a single 10-inch speaker, and {{was designed to be}} powered by an external amplifier, and contained an additional output for an <b>extension</b> <b>speaker.</b> Control of the speaker was via two switches, one of which controlled the speed and one switched the rotors on and off. It was also released later as the Fender Vibratone.|$|E
2500|$|Besides {{instrument}} {{inputs and}} speaker outputs (typically via 1/4" [...] jacks), an amp may have other inputs and outputs. These can include an auxiliary input jack (sometimes {{with its own}} level control, for a drum machine), [...] "send" [...] and [...] "return" [...] jacks to create an effects loop, a “line out” jack and an <b>extension</b> <b>speaker</b> jack. Practice amps sometimes have a 1/4" [...] headphone jack, or stereo RCA or mini jacks for connecting a CD player, portable media player or other sound source. Some guitar amps have an XLR input so that a microphone can be plugged in for singing. Guitar amps that include a mic input are in effect small, portable PA systems. Some amps, typically bass amps, have an XLR connector to provide a balanced output from the preamp section {{to go into a}} PA system or recording input.|$|E
5000|$|AM-100L15 - Self-powered <b>extension</b> <b>speaker</b> {{system with}} JBL D-130 for the 100L15 ...|$|E
50|$|Another {{factor that}} {{may need to}} be {{considered}} is the length of the speaker cable. Very long speaker cable runs may affect the performance of the system, either by causing line loss of power or by affecting the impedance. For best performance and highest wattage output with bass stacks or combos with <b>extension</b> <b>speakers,</b> bassists typically use the shortest possible speaker cable.|$|R
50|$|Languages {{are also}} offered as Beginners, Continuers, <b>Extension,</b> Background <b>Speakers</b> and recently, Heritage courses. Only one course {{of any one}} {{language}} may be taken, {{with the exception of}} Extension, available only to students taking the Continuers course. Due to the large number of language courses, they have been listed separately. The letters B (beginners), C (continuers), E (<b>extension),</b> BS (background <b>speakers),</b> H (heritage) indicate which courses are available for study.|$|R
40|$|In {{this paper}} we discuss the {{relevance}} of bandwidth <b>extension</b> for <b>speaker</b> identification tasks. Mainly we want to study if {{it is possible to}} recognize voices that have been bandwith extended. For this purpose, we created two different databases (microphonic and ISDN) of speech signals that were bandwidth extended from telephone bandwidth ([300, 3400] Hz) to full bandwidth ([100, 8000] Hz). We have evaluated different parameterizations, and we have found that the MELCEPST parameterization {{can take advantage of the}} bandwidth extension algorithms in several situations. 1...|$|R
50|$|Some {{keyboard}} amps may {{be equipped}} with a compressor or limiter to protect the speaker from damage when the amplifier is being used at high volume levels. Some keyboard amps (e.g., Yorkville's 200 watt keyboard amp and Peavey's KB-4) have an <b>extension</b> <b>speaker</b> jack, which enables the amp {{to be connected to}} a second speaker cabinet for more volume.|$|E
5000|$|The {{smallest}} Leslie is the Model 16, made in 1970. It has a Fender-like speaker {{body and}} a rotating foam dispersion block. It was built for guitarists, portable, and had [...] "Leslie" [...] written on the front. It contained just a single 10-inch speaker, and {{was designed to be}} powered by an external amplifier, and contained an additional output for an <b>extension</b> <b>speaker.</b> Control of the speaker was via two switches, one of which controlled the speed and one switched the rotors on and off. It was also released later as the Fender Vibratone.|$|E
5000|$|Besides {{one or more}} {{instrument}} inputs (typically a 1/4" [...] jack), other jacks {{may also}} be provided, such as an auxiliary input jack (sometimes with its own level control, for a drum machine), [...] "send" [...] and [...] "return" [...] jacks to create an effects loop, an <b>extension</b> <b>speaker</b> jack. Practice amps may have stereo RCA or mini jacks for connecting a CD player, portable media player or other sound source and a 1/4" [...] headphone jack. Some guitar amps have an XLR input so that a microphone can be plugged in for singing. Guitar amps that include a mic input are in effect small, portable PA systems.|$|E
5000|$|The {{meaning of}} 'Aryan' that was adopted into the English {{language}} in the late 18th century was the one associated with the technical term used in comparative philology, which in turn had the same meaning as that evident in the very oldest Old Indic usage, i.e. as a (self-) identifier of [...] "(speakers of) North Indian languages". This usage was simultaneously influenced by a word that appeared in classical sources (Latin and Greek Ἀριάνης Arianes, e.g. in Pliny 1.133 and Strabo 15.2.1-8), and recognized {{to be the same}} as that which appeared in living Iranian languages, where it was a (self-)identifier of the [...] "(speakers of) Iranian languages". Accordingly, 'Aryan' came to refer to the languages of the Indo-Iranian language group, and by <b>extension,</b> native <b>speakers</b> of those languages.|$|R
5000|$|Danny Yamashiro won the Harvard <b>Extension</b> School Commencement <b>Speaker</b> Prize (2017). He {{was awarded}} Biola University's Young Alumni Award (2000) and {{received}} numerous Certificates of Recognition from the Hawaii Senate, Hawaii House of Representatives, Honolulu City Council and the Mayor of Honolulu, Jeremy Harris. Yamashiro {{was the first}} ordained clergyman selected for the Pacific Century Fellows and offered a prayer at a celebratory dinner hosted by the Governor of Hawaii, Benjamin Cayetano at the historic [...] "Washington Place" [...] (1999).|$|R
30|$|This paper {{presents}} {{an overview of}} a state-of-the-art text-independent speaker verification system. First, an introduction proposes a modular scheme of the training and test phases of a speaker verification system. Then, the most commonly speech parameterization used in speaker verification, namely, cepstral analysis, is detailed. Gaussian mixture modeling, which is the speaker modeling technique used in most systems, is then explained. A few speaker modeling alternatives, namely, neural networks and support vector machines, are mentioned. Normalization of scores is then explained, as {{this is a very}} important step to deal with real-world data. The evaluation of a speaker verification system is then detailed, and the detection error trade-off (DET) curve is explained. Several <b>extensions</b> of <b>speaker</b> verification are then enumerated, including speaker tracking and segmentation by speakers. Then, some applications of speaker verification are proposed, including on-site applications, remote applications, applications relative to structuring audio information, and games. Issues concerning the forensic area are then recalled, as we believe it is very important to inform people about the actual performance and limitations of speaker verification systems. This paper concludes by giving a few research trends in speaker verification for the next couple of years.|$|R
5000|$|I used a Gibson Hummingbird {{acoustic}} {{tuned to}} open D, six string. Open D or open E, {{which is the}} same thing - same intervals - but it would be slackened down some for D. Then there was a capo on it, to get that really tight sound. And there was another guitar over the top of that, but tuned to Nashville tuning. I learned that from somebody in George Jones' band in San Antonio in 1964. The high-strung guitar was an acoustic, too. Both acoustics were put through a Philips cassette recorder. Just jam the mic right in the guitar and play it back through an <b>extension</b> <b>speaker.</b>|$|E
5000|$|On some amps with {{a number}} of input and output jacks, the jacks may be {{consolidated}} in a patch bay. Some amps have an input jack for a foot-operated switch which can be used to turn on an effect or switch to a solo channel. Some higher-end amps have a Speakon speaker jack for an <b>extension</b> <b>speaker.</b> In the 2010s, the Speakon jack is often used in high wattage amplifiers, because the design of the connector, which is shielded from human touch, prevents electrical shock from a high-powered amplifier. Some amplifiers have a [...] "tuner out" [...] jack, for sending the instrument signal to an external electronic tuner. Bass speaker cabinets often have two 1/4" [...] jacks. These are provided so that one speaker cable can be plugged into the first jack and connected to the power amp; if the bassist wants to use a second cabinet, a second speaker cable is plugged into the second jack and then into second speaker.|$|E
40|$|We {{provide a}} tool for {{communicating}} about insects in isiZulu to facilitate research and knowledge sharing {{in the fields of}} indigenous knowledge, cultural entomology, environmental education and community <b>extension</b> involving isiZulu <b>speakers.</b> A total of 213 different names for 64 insect specimens were encountered among a sample of 67 respondents in 11 communities distributed across the province of KwaZulu-Natal, South Africa. This list includes 93 names that can be considered core isiZulu vocabulary and which are widely used to identify insects that are agriculturally, medically, domestically, culturally or ecologically common or significant. Substantial variation was found regarding the names for particular insects, especially between regions, suggesting dialectal differences between isiZulu speakers. Grammatical and social variation in names was also recorded. This study highlights interdisciplinary teamwork in the field of indigenous knowledge research and the influences affecting the standardisation of South African languages for technical and scientific work...|$|R
40|$|We {{report the}} results of some {{preliminary}} experiments with a new method of acoustic-phonetic modeling for large vocabulary applications that {{can be viewed as}} a far-reaching <b>extension</b> of Bayesian <b>speaker</b> adaptation. This method adapts all of the Gaussian mean vectors in a speaker-independent HMM for a given speaker (and not just the mean vectors present in the speaker’s adaptation data as in classical Bayesian adaptation). It is based on an explicit model of the correlations between all of the speakers in the training set, the idea being that if there is not enough data to estimate a Gaussian mean vector for a given speaker then data from other speakers can be used provided that we know how the speakers are correlated with each other. Our new approach has resulted in 10 – 15 % reductions in error rate on a French language dictation task. 1...|$|R
40|$|An <b>extension</b> of {{conventional}} <b>speaker</b> segmentation framework is presented for a {{scenario in which}} a number of microphones record the activity of speakers present at a meeting (one microphone per speaker). Although each microphone can receive speech from both the participant wearing the microphone (local speech) and other participants (cross-talk), the recorded audio can be broadly classified in three ways: local speech, cross-talk, and silence. This paper proposes a technique which takes into account cross-correlations, values of its maxima, and energy differences as features to identify and segment speaker turns. In particular, we have used classical cross-correlation functions, time smoothing and in part temporal constraints to sharpen and disambiguate timing differences between microphone channels that may be dominated by noise and reverberation. Experimental results show that proposed technique can be successively used for speaker segmentation of data collected {{from a number of}} different setups. 1...|$|R
40|$|Learning {{representations}} is {{a central}} challenge in machine learning. For speech recognition, {{we are interested in}} learning robust representations that are stable across different acoustic environments, recording equipment and irrelevant inter– and intra– speaker variabilities. This thesis is concerned with representation learning for acoustic model adaptation to speakers and environments, construction of acoustic models in low-resource settings, and learning representations from multiple acoustic channels. The investigations are primarily focused on the hybrid approach to acoustic modelling based on hidden Markov models and artificial neural networks (ANN). The first contribution concerns acoustic model adaptation. This comprises two new adaptation transforms operating in ANN parameters space. Both operate at the level of activation functions and treat a trained ANN acoustic model as a canonical set of fixed-basis functions, from which one can later derive variants tailored to the specific distribution present in adaptation data. The first technique, termed Learning Hidden Unit Contributions (LHUC), depends on learning distribution-dependent linear combination coefficients for hidden units. This technique is then extended to altering groups of hidden units with parametric and differentiable pooling operators. We found the proposed adaptation techniques pose many desirable properties: they are relatively low-dimensional, do not overfit and can work in both a supervised and an unsupervised manner. For LHUC we also present <b>extensions</b> to <b>speaker</b> adaptive training and environment factorisation. On average, depending on the characteristics of the test set, 5 - 25...|$|R
5000|$|The term [...] "Aryan" [...] {{came to be}} used as {{the term}} for the newly {{discovered}} Indo-European languages, and, by <b>extension,</b> the original <b>speakers</b> of those languages. In the 19th century, [...] "language" [...] was considered a property of [...] "ethnicity", and thus the speakers of the Indo-Iranian or Indo-European languages came to be called the [...] "Aryan race", as contradistinguished from what came to be called the [...] "Semitic race". By the late 19th century, among some people, the notions of an [...] "Aryan race" [...] became closely linked to Nordicism, which posited Northern European racial superiority over all other peoples. This [...] "master race" [...] ideal engendered both the [...] "Aryanization" [...] programs of Nazi Germany, in which the classification of people as [...] "Aryan" [...] and [...] "non-Aryan" [...] was most emphatically directed towards the exclusion of Jews. By the end of World War II, the word 'Aryan' had become associated by many with the racial ideologies and atrocities committed by the Nazis.|$|R
40|$|Abstract One of {{the ways}} for a speaker {{to make sense of}} an object or event in the real world is to make use of iconicity between two things. Through iconic metaphorical <b>extensions,</b> the <b>speaker</b> connects the object or event to {{something}} else. In this study, I consider how speakers form concepts through iconic metaphorical extensions, examining how they metaphorically extend one concept to another. I suggest that all speakers use the same ways of forming metaphorical extensions and control metaphorical extensions according to their intentions and contexts. Using basic and simple shapes (e. g. 0) and their related metaphorical expressions (e. g. `a circular argument'), I discuss the role of iconicity in metaphorical understanding, the relationship between concept and language, and metaphorical extensions as tools of concept formation. I conduct descriptive investigations using dictionaries and compare related senses for particular basic shapes between English and Japanese, looking at their polysemous networks and historical changes. Using questionnaires, interviews and tasks with native speakers of English and Japanese, I conduct experimental investigations to examine the speakers' associations in relation to basic shapes and the degree of iconicity in metaphorical extensions. This study suggests that concepts, although probably stored in the mental space, are recreated every time they occur. Concept formation through iconic metaphorical extensions must be dynamic because it is based on 'extensions' of existing concepts, and must be universal to all <b>speakers</b> because metaphorical <b>extensions</b> are among the most basic mental activities of human beings. I propose dynamic and universal models which represent the way in which a speaker forms concepts, connecting a linguistic form and a mental picture and controlling iconic metaphorical extensions. These models contribute to understanding both similarities and differences in use of metaphorical extensions between English and Japanese...|$|R
40|$|The classic {{model of}} voiced fricatives {{includes}} two sound sources, a periodic glottal source and a random noise source at the constriction. The amplitude {{of the noise}} source has long been assumed to be modulated by the voicing (Fan, 1960; Stevens, 1971; Flanagan, 1972), but the amount of this change has not been studied systematically, {{and the possibility of}} a change in spectral shape has been ignored. Spectral analysis of a voiced fricative that is F 0 -synchronized by the use of a simultaneous laryngograph channel shows that modulation of the noise source by voicing causes not only amplitude changes but also changes in the spectral shape. These changes, consisting of a 5 -dB variation in amplitude above 10 kHz in [v], are consistent with changes observed in time-averaged spectra of sustained fricatives at different effort levels, and with spectra of mechanical models having different constriction shapes. The amount of spectral change due to such modulation is likely to vary with strength and place of the noise source, and thus will depend on the particular glottis-constriction coordination employed by the <b>speaker.</b> <b>Extension</b> of this work to more fricatives and more subjects is planned...|$|R

