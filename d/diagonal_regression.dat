5|5|Public
25|$|In short, total {{least squares}} {{does not have}} the {{property}} of units-invariancei.e. it is not scale invariant. For a meaningful model we require this property to hold. A way forward is to realise that residuals (distances) measured in different units can be combined if multiplication is used instead of addition. Consider fitting a line: for each data point the product of the vertical and horizontal residuals equals twice the area of the triangle formed by the residual lines and the fitted line. We choose the line which minimizes the sum of these areas. Nobel laureate Paul Samuelson proved in 1942 that, in two dimensions, it is the only line expressible solely in terms of the ratios of standard deviations and the correlation coefficient which (1) fits the correct equation when the observations fall on a straight line; (2) exhibits scale invariance, and (3) exhibits invariance under interchange of variables. This line has been rediscovered in different disciplines and is variously known as standardised major axis (Ricker 1975, Warton et al., 2006), the reduced major axis, the geometric mean functional relationship (Draper and Smith, 1998), least products regression, <b>diagonal</b> <b>regression,</b> line of organic correlation, and the least areas line. Tofallis (2002) has extended this approach to deal with multiple variables.|$|E
40|$|In {{this work}} we apply {{the method of}} <b>diagonal</b> <b>regression</b> to derive an {{alternative}} version of Principal Component Analysis (PCA). <b>Diagonal</b> <b>regression</b> was introduced by Ragnar Frisch (the first economics Nobel laureate) in his paper Correlation and Scatter in Statistical Variables (1928). The benefits of using <b>diagonal</b> <b>regression</b> in PCA are that it provides components that are scale-invariant (i. e. changing the units of measurement leads to an equivalent result), and which reflect both the correlation structure of the data set, and the variance structure as well. By contrast PCA based on the correlation matrix will only reflect the correlation structure of the data. The problem is formulated as a generalized eigen-analysis and is demonstrated using a numerical example which highlights some desirable properties {{of what we call}} Invariant Principal Components Analysis (IPCA) ...|$|E
40|$|In this paper, {{we propose}} {{a new type}} of {{frame-based}} hidden Markov models (HMMs), in which a sequence of observations are generated using state-dependent autoregressive feature models. Based on this correlation model, it can be proved that expressing the probability of a sequence of observations as a product of probabilities of decorrelated individual observations doesn't require the assumption of frame independence. Under the maximum likelihood (ML) criteria, we also derived re-estimation formulae for the parameters (mean vectors, covariance matrix, and <b>diagonal</b> <b>regression</b> matrice) of the new HMMs using an Expectation Maximization (EM) algorithm. From the formulae, it's interesting to see that the new HMMs have extended the standard HMMs by relaxing the frame independence limitation. Initial experiment conducted on WSJ 20 K task shows an encouraging performance improvement with only 117 additional parameters in all...|$|E
40|$|This project used GIS {{as a tool}} {{to study}} the effect of survey {{configurations}} on the accuracy of DEM that maps the bathymetry of the Fraser River. The industry sponsor of this project was the Fraser River Project Group at UBC Department of Geography. River bathymetry is a good tool for the study of river morphological changes over time. In this project, two study areas with different channel morphologies were chosen — the Mission reach and Chilliwack reach of the lower Fraser River. Reference bathymetric surfaces were created from a set of densely distributed survey points collected in 1991. For each study area, DEM surfaces were then created using 40 different sets of data points that had different survey configurations (sample pattern, line and point density). In general, two survey configurations were under consideration in this project: cross-sections and <b>diagonals.</b> Linear <b>regression</b> was performed to assess the accuracy of the DEMs relative to the reference bathymetric surfaces that were created with the complete set of data. The results of the statistical analysis suggested that the optimal survey configuration had a transect line spacing of 100 m, and the cross-section survey pattern was superior to the diagonal pattern. This project started on January 3, 2001 and ended on May 17, 2001, and a total of 273 hours of work was devoted to complete this project. i...|$|R
40|$|Combining {{multiple}} microarray datasets increases {{sample size}} and leads to improved reproducibility in identification of informative genes and subsequent clinical prediction. Although microarrays have increased the rate of genomic data collection, sample size is still a major issue when identifying informative genetic biomarkers. Because of this, feature selection methods often suffer from false discoveries, resulting in poorly performing predictive models. We develop a simple meta-analysis-based feature selection method that captures the knowledge in each individual dataset and combines the results using a simple rank average. In a comprehensive study that measures robustness in terms of clinical application (i. e., breast, renal, and pancreatic cancer), microarray platform heterogeneity, and classifier (i. e., logistic <b>regression,</b> <b>diagonal</b> LDA, and linear SVM), we compare the rank average meta-analysis method to five other meta-analysis methods. Results indicate that rank average meta-analysis consistently performs well compared to five other meta-analysis methods...|$|R
40|$|In this paper, {{we present}} an eigenspace-based {{approach}} toward prior density selection for the MAPLR framework. The proposed eigenspace-based MAPLR approach {{was developed by}} introducing a priori knowledge analysis on the training speakers via probabilistic principal component analysis (PPCA), so as to construct an eigenspace for speaker-specific full regression matrices {{as well as to}} derive a set of bases called eigen-matrices. The priors of MAPLR transformations for each outside speaker are then chosen in the space spanned by the first K eigen-matrices. By incorporating the PPCA model into the MAPLR scheme, the number of free parameters in choosing the priors can be effectively reduced, while the underlying structure of the acoustic space as well as the precise modeling of the inter-dimensional correlation among the model parameters can be well preserved. Both supervised and unsupervised adaptation experiments showed that the proposed approach significantly outperformed the conventional MLLR approach using either <b>diagonal</b> or full <b>regression</b> matrices...|$|R
40|$|We {{present a}} {{multiple}} regression fitting method which, unlike least-squares regression, treats each {{variable in the}} same way. It can be used when seeking an empirical relationship between a number of variables for which data is available. It does not suffer from being scale-dependent - a disadvantage of orthogonal regression (total least squares). Thus changing the units of measurement will still lead to an equivalent model - this is clearly important if a model is to be meaningful. By formulating the estimation procedure as a fractional programming problem, we show that the optimal solution will be both global and unique. For the case of two variables the method has appeared under different names in different disciplines throughout the twentieth century- as the reduced major axis or line of organic correlation in biology, as Stromberg's impartial line in astronomy, and as <b>diagonal</b> <b>regression</b> in economics (in which field two Nobel laureates have published work on the method). We gather together the most important results already established...|$|E
40|$|Copyright © 2012 John H. Phan et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Combining multiple microarray datasets increases sample size and leads to improved reproducibility in identification of informative genes and subsequent clinical prediction. Although microarrays have increased the rate of genomic data collection, sample size is still a major issue when identifying informative genetic biomarkers. Because of this, feature selection methods often suffer from false discoveries, resulting in poorly performing predictive models. We develop a simple meta-analysis-based feature selection method that captures the knowledge in each individual dataset and combines the results using a simple rank average. In a comprehensive study that measures robustness in terms of clinical application (i. e., breast, renal, and pancreatic cancer), microarray platform heterogeneity, and classifier (i. e., logistic <b>regression,</b> <b>diagonal</b> LDA, and linear SVM), we compare the rank average meta-analysis method to five other meta-analysis methods. Results indicate that rank average meta-analysis consistently performs well compared to five other meta-analysis methods. 1...|$|R
40|$|This paper {{presents}} {{our recent}} {{effort on the}} development of the eigenspace-based linear transformation approach for rapid speaker adaptation. The proposed approach toward prior density selection for the MAPLR framework was developed by introducing a priori knowledge analysis on the training speakers via probabilistic principal component analysis (PPCA), so as to construct an eigenspace for speaker-specific full regression matrices as well as to derive a set of bases called eigen-transformations. The prior densities of MAPLR transformations for each outside speaker are then chosen in the space spanned by the first few eigen-transformations. By incorporating the PPCA model of transformation parameters into the MAPLR scheme, the number of free parameters can be significantly reduced, while the underlying structure of the acoustic space as well as the precise modeling of the inter-dimensional correlation among the model parameters can be well preserved. Rapid supervised adaptation experiments showed that the proposed approach not only is superior to the conventional MLLR approach using either <b>diagonal</b> or block-diagonal <b>regression</b> matrices, but also outperformed by a great amount the full-matrix MLLR with either a global transformation or multiple transformations corresponding to different phonetic classes. 1...|$|R

