2867|6224|Public
5|$|The {{preferred}} <b>data</b> <b>format</b> for files {{submitted to}} the SRA is the BAM format, which is capable of storing both aligned and unaligned reads. Internally the SRA relies on the NCBI SRA Toolkit, used at all three INSDC member databases, to provide flexible data compression, API access and conversion to other formats such as FASTQ.|$|E
5|$|After the Square Enix merger, {{however, the}} {{individual}} teams still continued to program and customize their own tools for each game, which would eventually {{go to waste}} as only their respective creators {{knew how to use}} them. With the amount of assets and tools required by the in-development Final Fantasy XII and the impending advent of the seventh console generation, a common <b>data</b> <b>format</b> for the company was proposed in 2004. It was to be developed in-house and replace general-purpose formats such as FBX and COLLADA. Realizing the goal of an engine with a common set of tools proved to be difficult, as many production teams wanted to further their own interests rather than those of the company as a whole. Select staff members from different company divisions teamed up to work on the project on a voluntary basis, but their loose organizational structure failed to yield results. Nevertheless, Murata considered this group effort a first step in the right direction. In 2005, he was appointed general manager of the newly formed Technology Division. Although this enabled Murata and his subordinates to talk about a company-wide engine more extensively, the lack of manpower again prevented any significant achievements.|$|E
25|$|AcroForms {{can keep}} form field values in {{external}} stand-alone files containing key:value pairs. The external files may use Forms <b>Data</b> <b>Format</b> (FDF) and XML Forms <b>Data</b> <b>Format</b> (XFDF) files. The usage rights (UR) signatures define rights for import form data files in FDF, XFDF and text (CSV/TSV) formats, and export form data files in FDF and XFDF formats.|$|E
5000|$|Bits 11 to 29 {{contain the}} data. Bit-field, Binary Coded Decimal (BCD), and Binary Number Representation (BNR) are common ARINC 429 <b>data</b> <b>formats.</b> <b>Data</b> <b>formats</b> {{may also be}} mixed.|$|R
50|$|Multipart/report is {{a message}} type that {{contains}} <b>data</b> <b>formatted</b> for a mail server to read. It is split between a text/plain (or some other content/type easily readable) and a message/delivery-status, which contains the <b>data</b> <b>formatted</b> for the mail server to read.|$|R
40|$|<b>Data</b> <b>formats</b> {{which can}} offer {{a full range of}} {{tradeoffs}} between bit-serial and bit-parallel computation are described. The design of arithmetic operators based on these <b>data</b> <b>formats,</b> especially a digit-serial multiplier, is presented. It is shown that these <b>data</b> <b>formats</b> can combine the advantage of limited interconnection and small chip size of bit-serial computation with the advantage of throughput of parallel computation and that they lead to the most efficient pipelined implementation of the desired function...|$|R
25|$|XML Forms <b>Data</b> <b>Format</b> (XFDF) is the XML {{version of}} Forms <b>Data</b> <b>Format,</b> but the XFDF {{implements}} only {{a subset of}} FDF containing forms and annotations. There are not XFDF equivalents for some entries in the FDF dictionary - such as the Status, Encoding, JavaScript, Pages keys, EmbeddedFDFs, Differences and Target. In addition, XFDF does not allow the spawning, or addition, of new pages based on the given data; as can be done when using an FDF file. The XFDF specification is referenced (but not included) in PDF 1.5 specification (and in later versions). It is described separately in XML Forms <b>Data</b> <b>Format</b> Specification. The PDF 1.4 specification allowed form submissions in XML format, but this was replaced by submissions in XFDF format in the PDF 1.5 specification. XFDF conforms to the XML standard.|$|E
25|$|Array {{and object}} literals: Like many {{scripting}} languages, arrays and objects (associative arrays in other languages) can each be created with a succinct shortcut syntax. In fact, these literals {{form the basis}} of the JSON <b>data</b> <b>format.</b>|$|E
25|$|As of December 2016, XFDF 3.0 is an ISO/IEC {{standard}} {{under the}} formal name ISO 19444-1:2016 - Document management - XML Forms <b>Data</b> <b>Format</b> - Part 1: Use of ISO 32000-2 (XFDF 3.0). This standard is a normative reference of ISO 32000-2.|$|E
5000|$|WG 3: <b>Data</b> {{interchange}} <b>format</b> standards: {{specify the}} content, meaning, and representation of biometric <b>data</b> <b>formats</b> which {{are specific to}} a particular biometric modality.|$|R
50|$|Data conversion: Conversion between {{different}} <b>data</b> <b>formats.</b>|$|R
5000|$|Interface {{agents for}} various flightplan <b>data</b> <b>formats</b> (d-fplIa) ...|$|R
25|$|The design {{goals of}} XML {{emphasize}} simplicity, generality, and usability across the Internet. It is a textual <b>data</b> <b>format</b> with strong support via Unicode for different human languages. Although {{the design of}} XML focuses on documents, the language is widely used for the representation of arbitrary data structures such as those used in web services.|$|E
25|$|JSON was {{originally}} {{intended to be a}} subset of the JavaScript scripting language (specifically, Standard ECMA-262 3rd Edition—December 1999) and is commonly used with Javascript, but it is a language-independent <b>data</b> <b>format.</b> Code for parsing and generating JSON data is readily available in many programming languages. JSON's Web site lists JSON libraries by language.|$|E
25|$|Asynchronous JavaScript and JSON (or AJAJ) {{refers to}} the same dynamic web page {{methodology}} as Ajax, but instead of XML, JSON is the <b>data</b> <b>format.</b> AJAJ is a web development technique that provides for {{the ability of a}} webpage to request new data after it has loaded into the web browser. Typically it renders new data from the server in response to user actions on that webpage. For example, what the user types into a search box, client-side code then sends to the server, which immediately responds with a drop-down list of matching database items.|$|E
40|$|Problem {{moves from}} scaling {{architecture}} [...] . Problem moves from not only scaling architecture [...] . To how to scale the knowledge Battling the 3 V’s Battling the 3 V’s Daily, weekly, monthly uploads Battling the 3 V’s Daily, weekly, monthly uploads 60 + different <b>data</b> <b>formats</b> Battling the 3 V’s Daily, weekly, monthly uploads 60 + different <b>data</b> <b>formats</b> Constant streams for near real time Battling the 3 V’s Daily, weekly, monthly uploads 2 + TB of streaming data daily 60 + different <b>data</b> <b>formats</b> Constant streams for near real tim...|$|R
40|$|Abstract Background Several <b>data</b> <b>formats</b> {{have been}} {{developed}} for large scale biological experiments, using a variety of methodologies. Most <b>data</b> <b>formats</b> contain a mechanism for allowing extensions to encode unanticipated data types. Extensions to <b>data</b> <b>formats</b> are important because the experimental methodologies tend to be fairly diverse and rapidly evolving, which hinders the creation of formats that will be stable over time. Results In this paper we review the <b>data</b> <b>formats</b> that exist in functional genomics, some of which have become de facto or de jure standards, with a particular focus on how each domain has been modelled, and how each format allows extensions. We describe the tasks that are frequently performed over <b>data</b> <b>formats</b> and analyse how well each task is supported by a particular modelling structure. Conclusion From our analysis, we make recommendations as to the types of modelling structure that are most suitable for particular types of experimental annotation. There are several standards currently under development that we believe could benefit from systematically following a set of guidelines. </p...|$|R
5000|$|... #Subtitle level 2: The Difference Between Parasitic <b>Data</b> <b>Formats</b> ...|$|R
25|$|Unlike {{analytics}} products {{offered by}} SAS Institute, R does not natively handle datasets larger than main memory. In 2010 Revolution Analytics introduced ScaleR, a package for Revolution R Enterprise {{designed to handle}} big data through a high-performance disk-based data store called XDF (not related to IBM's Extensible <b>Data</b> <b>Format)</b> and high performance computing across large clusters. The release of ScaleR marked a push away from consulting and services alone to custom code and a la carte package pricing. ScaleR also works with Apache Hadoop and other distributed file systems and Revolution Analytics has partnered with IBM to further integrate Hadoop into Revolution R. Packages to integrate Hadoop and MapReduce into open source R {{can also be found}} on the community package repository, CRAN.|$|E
25|$|XHTML was {{developed}} to make HTML more extensible and increase interoperability with other data formats. In addition, browsers were forgiving of errors in HTML, and most websites were displayed despite technical errors in the markup; XHTML introduced stricter error handling. HTML 4 was ostensibly an application of Standard Generalized Markup Language (SGML); however the specification for SGML was complex, and neither web browsers nor the HTML 4 Recommendation were fully conformant to it. The XML standard, approved in 1998, provided a simpler <b>data</b> <b>format</b> closer in simplicity to HTML 4. By shifting to an XML format, it was hoped HTML would become compatible with common XML tools; to work…}} servers and proxies {{would be able to}} transform content, as necessary, for constrained devices such as mobile phones.|$|E
25|$|Following this announcement, {{there was}} {{widespread}} condemnation of CompuServe and Unisys, and many software developers threatened {{to stop using}} GIF. The PNG format (see below) was developed in 1995 as an intended replacement. However, obtaining support from the makers of Web browsers and other software for the PNG format proved difficult {{and it was not}} possible to replace GIF, although PNG has gradually increased in popularity. Therefore, GIF variations without LZW compression were developed. For instance the libungif library, based on Eric S. Raymond's giflib, allows creation of GIFs that followed the <b>data</b> <b>format</b> but avoided the compression features, thus avoiding use of the Unisys LZW patent. A 2001 Dr. Dobbs article described another alternative to LZW compression, based on square roots.|$|E
30|$|<b>Data</b> <b>formats</b> used to {{represent}} reporting templates and radiology reports.|$|R
5000|$|<b>Data</b> <b>formats</b> {{that are}} {{currently}} supported on the Sci2 platform: ...|$|R
50|$|As of version 1.9.0, GDAL {{provides}} {{at least}} partial support {{for more than}} 120 raster geospatial <b>data</b> <b>formats.</b> The next version is expected to provide up to 200 drivers. A subset of <b>data</b> <b>formats</b> is supported to ensure the ability to directly create files and georeferencing them with the default GDAL compiling options.|$|R
25|$|Published in February 2014 by the OpenID Foundation, {{the third}} {{generation}} of OpenID technology, OpenID Connect, is an authentication layer that sits {{on top of the}} OAuth 2.0 authorization framework. It allows computing clients to verify the identity of an end-user based on the authentication performed by an authorization server, as well as to obtain the basic profile information about the end-user in an interoperable and REST-like manner. In technical terms, OpenID Connect specifies a RESTful HTTP API, using JSON as a <b>data</b> <b>format.</b> OpenID Connect allows a range of organizations, including web-based, mobile and JavaScript clients, to request and receive information about authenticated sessions and end-users. The OpenID Connect specification is extensible, supporting optional features such as encryption of identity data, discovery of OpenID providers, and session management.|$|E
25|$|On April 22, 2010, Voyager 2 {{encountered}} scientific <b>data</b> <b>format</b> problems. On May 17, 2010, JPL engineers {{revealed that}} a flipped bit in an on-board computer had caused the issue, and scheduled a bit reset for May 19. On May 23, 2010, Voyager 2 resumed sending science data from deep space after engineers fixed the flipped bit. Currently research is being made into marking the area of memory with the flipped bit off limits or disallowing its use. The Low-Energy Charged Particle Instrument is currently operational, and data from this instrument concerning charged particles is being transmitted to Earth. This data permits measurements of the heliosheath and termination shock. There {{has also been a}} modification to the on-board flight software to delay turning off the AP Branch 2 backup heater for one year. It was scheduled to go off February 2, 2011 (DOY 033, 2011–033).|$|E
25|$|The SIMD vector {{processor}} (VMX128) was modified for the Xbox {{to include a}} dot-product instruction. The dot-product instruction took far less latency than discrete instructions. The VMX128 was also modified {{by the addition of}} direct 3D (D3D) compressed <b>data</b> <b>format.</b> This led to an approximate 50 percent savings in required band-width and memory footprint making the CPU having a theoretical peak performance of 115.2GFLOPS, being capable of 9.6 billion dot products per second. Each core of the CPU was capable of simultaneous multithreading and was clocked at 3.2GHz. However, to reduce CPU die size, complexity, cost, and power demands, the processor used in-order execution in contrast to the Intel Coppermine 128-based Pentium III used in the original Xbox, which used more complex out of order execution. The original chip used a 90nm process, although a newer 65nm process SOI revision was implemented on later models, which was in-turn superseded by a 45nm combined CPU and GPU chip. A 21.6GB/s front side bus, aggregated 10.8GB/s upstream and downstream, connected Xenon with the graphics processor/northbridge. Xenon was equipped with an 8th way set associative 1MB Level 2 cache on-die running at half CPU clock speed. This cache was shared amongst the three CPU cores. Each core had separate L1 caches, each containing a two-way set associative 32-Kbyte L1 instruction cache and a four-way set associative 32-Kbyte L1 data cache. The write-through data cache did not allocate cache lines on writes. The CPU also contained ROM storing Microsoft private encrypted keys, used to decrypt game data. The heat sink implemented to cool the Xenon CPU was composed of aluminum fins with a copper base, and a heat pipe. Newer revisions, which had a smaller core, do not feature the heat pipe or copper base. The heat sink was cooled by two 70mm fans {{at the rear of the}} console on original-style consoles, while a single fan mounted on the side of the consoles was used in Xbox 360 S consoles. There were several types of fan used in Xbox 360s, which were produced by Nidec, Sunon and Delta Electronics.|$|E
50|$|Related: EXI {{is being}} adapted for non-XML <b>data</b> <b>formats</b> as well.|$|R
5000|$|Schemes have {{different}} <b>data</b> <b>formats</b> (e.g. John Doe or Doe, John) ...|$|R
5000|$|Allow code to work {{together}} which otherwise cannot (e.g. incompatible <b>data</b> <b>formats)</b> ...|$|R
2500|$|XML Forms <b>Data</b> <b>Format</b> (XFDF) (external XML Forms <b>Data</b> <b>Format</b> Specification, Version 2.0; {{supported}} since PDF 1.5; it {{replaced the}} [...] "XML" [...] form submission format defined in PDF 1.4) ...|$|E
2500|$|The Forms <b>Data</b> <b>Format</b> (FDF) {{is based}} on PDF, it uses the same syntax and has {{essentially}} the same file structure, but is much simpler than PDF, since the body of an FDF document consists of only one required object. Forms <b>Data</b> <b>Format</b> is defined in the PDF specification (since PDF 1.2). The Forms <b>Data</b> <b>Format</b> can be used when submitting form data to a server, receiving the response, and incorporating into the interactive form. It {{can also be used}} to export form data to stand-alone files that can be imported back into the corresponding PDF interactive form.|$|E
2500|$|... {{the number}} of {{platforms}} and independent groups and <b>data</b> <b>format</b> (Standardization) ...|$|E
5000|$|Green Kenue {{supports}} import {{and export}} for common GIS <b>data</b> <b>formats</b> including: ...|$|R
5000|$|Deal with {{multiple}} <b>data</b> <b>formats,</b> including Apache Avro, Apache Parquet and JSON ...|$|R
5000|$|Here {{are some}} {{examples}} of <b>data</b> <b>formats</b> used in regards to genomics ...|$|R
