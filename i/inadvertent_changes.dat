16|23|Public
5000|$|... {{determine}} steps {{needed for}} the recovery of <b>inadvertent</b> <b>changes</b> to data ...|$|E
50|$|With two {{minor and}} {{possibly}} <b>inadvertent</b> <b>changes</b> that remove the game {{further from the}} European games (declarer must discard before taking up the widow, {{and in the second}} round of bidding players bid by paying immediately into the pot), these rules are still published on the USPCC website. Although this is not stated in any of the rules, players must also agree on a penalty in case declarer wins less than 6 tricks.|$|E
50|$|User Account Control in Windows Vista {{improves}} this {{by limiting}} application software to standard user privileges until an administrator authorizes {{an increase in}} privilege level. In this way, UAC prevents users from making <b>inadvertent</b> <b>changes</b> to system settings and locks down the computer to prevent unauthorized applications from installing or performing malicious actions. Windows Vista is able to work around many LUA bugs in third party applications with its file and Registry virtualisation feature, as well as application compatibility shims. Internet Explorer 7's Protected Mode utilizes User Account Control to isolate IE from other applications and prevent it from writing content to any location, except the Temporary Internet Files folder. Internet Explorer 7 is available for XP, but does not support Protected Mode on XP. Windows Vista also includes Windows Defender, a spyware scanning and removal tool that is also available for Windows XP for free. Enterprise and Ultimate editions of Windows Vista include BitLocker Drive Encryption, which aims to help protect data {{in the case of}} stolen devices.|$|E
5000|$|Aeroflot Flight 593, a 1994 {{accident}} {{in which an}} <b>inadvertent</b> <b>change</b> to the autopilot settings went unnoticed by the crew ...|$|R
40|$|In {{a complex}} {{computer}} environment {{there is ample}} opportunity for error, a mistake by a programmer, or a software-induced undesirable side effect. In insurance, errors can cost a company heavily, so protection against <b>inadvertent</b> <b>change</b> is a must for the efficient firm. The data processing center at Transport Life Insurance Company has taken a step to guard against accidental changes by adopting a software package called EQNINT (Equations Interpreter Program). EQNINT cross checks the basic formulas in a program against the formulas {{that make up the}} major production system. EQNINT assures that formulas are coded correctly and helps catch errors before they affect the customer service or its profitability...|$|R
30|$|Broad {{configurability}} of the Twhirleds clients allows flexible deployment. Variable {{transmission gain}} can scale control:display ratio, gearing down rotation to allow fine control and allowing fast twirling {{to be shared}} as more leisurely turning, or even overdriven to exaggerate such torque. Network transmission may be one-shot (pulsed) or continuous, including thresholded filtering for choked bandwidth, azimuthal (rotation) and/or circumferential (revolution) events, invertible polarity, and wrapped (folding over at 360 °) or unwrapped yaw. Device vertical orientation may be upright or inverted (as was seen in Fig. 2), “trim tabs” are used for calibration, and a modal timer can disable control while spinning {{on the face of}} a tablet, preventing <b>inadvertent</b> <b>change</b> of settings.|$|R
40|$|Assay {{cocktail}} modification such as {{addition of}} effector can cause <b>inadvertent</b> <b>changes</b> in {{the concentration of}} other metalligand and free species. In some cases, e. g. in the assay for phosphoenolpyruvate carboxylase under a limiting-substrate condition, unintentional changes in substrate concentration are significant and confound an interpretation {{based solely on the}} total concentration of each component. A cautionary argument is developed on the basis of examples from the current literature...|$|E
40|$|Key Words carbon sequestration, {{measurement}} techniques, climate, Kyoto protocol n Abstract Agriculture {{and industrial}} development {{have led to}} <b>inadvertent</b> <b>changes</b> in the natural carbon cycle. As a consequence, concentrations {{of carbon dioxide and}} other greenhouse gases have increased in the atmosphere and may lead to changes in climate. The current challenge facing society is to develop options for future manage-ment of the carbon cycle. A variety of approaches has been suggested: direct reduction of emissions, deliberate manipulation of the natural carbon cycle to enhance seques-tration, and capture and isolation of carbon from fossil fuel use. Policy development to date has laid out some of the general principles to which carbon management should adhere. These are summarized as: how much carbon is stored, by what means, and for how long. To successfully manage carbon for climate purposes requires increased understanding of carbon cycle dynamics and improvement in the scientific capabilitie...|$|E
40|$|Climate-sensitive {{urban design}} is an {{increasingly}} important consideration for city planners and policy makers. This study demonstrates {{the use of a}} biophysical model to assess the response of urban climate to various changes, including population growth, reduced energy use, urban development and urban greening initiatives. Model inputs are intentionally derived using only publicly available information and assumptions involved in collating the data are discussed. Results are summarised in terms of the energy partitioning which captures changes in meteorology, surface characteristics and human behaviour. The model has been recently evaluated for the region, and those findings are drawn upon here to discuss the model’s capabilities and limitations. Model simulations demonstrate how both intentional and <b>inadvertent</b> <b>changes</b> to the urban landscape can alter the urban climate. For example, the impact of population growth depends on where, and how, people are housed, and recent changes in garden composition have reduced evaporation. This study has been designed so that model output could be combined with socio-economic data in future, enabling both risk and vulnerability to be considered together...|$|E
40|$|Since {{existing}} basins support heavy growths of unicellular {{green algae}} {{which may be}} killed by temperature variation or by <b>inadvertent</b> pH <b>changes</b> in waste and then deposited on the basin floor, information {{on the effects of}} dead algae on soil permeability was needed. This study was designed to show the effects of successive algal kills on the permeability of laboratory soil columns...|$|R
50|$|Oral traditions {{face the}} {{challenge}} of accurate transmission and verifiability of the accurate version, particularly when the culture lacks written language or has limited access to writing tools. Oral cultures have employed various strategies that achieve this without writing. For example, a heavily rhythmic speech filled with mnemonic devices enhances memory and recall. A few useful mnemonic devices include alliteration, repetition, assonance, and proverbial sayings. In addition, the verse is often metrically composed with an exact number of syllables or morae - such as with Greek and Latin prosody and in Chandas found in Hindu and Buddhist texts. The verses of the epic or text are typically designed wherein the long and short syllables are repeated by certain rules, so that if an error or <b>inadvertent</b> <b>change</b> is made, an internal examination of the verse reveals the problem. Such strategies help facilitate transmission of information from individual to individual without a written intermediate, and they can also be applied to oral governance.|$|R
40|$|Extant M&A {{research}} has focused on how acquiring firms may use acquisitions to source human talents from target companies. In this study, we argue that acquirers incorporate expectations about employee mobility into decisions regarding whether to bid for a firm, suggesting a negative relationship between the expected employee mobility in a firm and the likelihood of the firm becoming an acquisition target. We exploit a natural experiment in Michigan wherein an <b>inadvertent</b> <b>change</b> in the enforcement of non-compete agreements provides an observable, exogenous source of variation in employee mobility. Using a differencein-differences approach, we find causal evidence that constraints on employee mobility in Michigan raise the likelihood that a Michigan firm becomes an acquisition target. We also find that the effect is stronger when a firm is more exposed to the negative consequences of employee mobility, such as when a firm employs more knowledge workers in its work force and when a firm faces greater in-state competition; by contrast, the effect is weaker when a firm is protected by a stronger intellectual property regime that mitigates the consequences of employee mobility...|$|R
40|$|Hollow fiber {{membranes}} (HFMs) {{formed through}} phase inversion methods exhibit specific physicochemical characteristics and generally favorable surface and mechanical properties, supporting {{their use in}} diverse applications including ultrafiltration, dialysis, cell culture, bioreactors, and tissue engineering. Characterization of, and modifications to, such membranes are important steps in achieving desired characteristics for specific applications. HFMs subject to gas, irradiation, and chemical sterilization techniques were characterized based on several analytical techniques. It was revealed that these common sterilization techniques can cause <b>inadvertent</b> <b>changes</b> to HFM properties. While these changes may cause detrimental effects to HFMs used in filtration, the methods of sterilization are also presented as a facile means of tuning properties toward specific applications. Modifications to HFM surface chemistries were also sought {{as a method of}} adsorbing bacterial lipopolysaccharide (LPS) from solutions used in hemodialysis treatments and bioprocessing applications. It was found that additives such as polyvinylpyrrolidone (PVP), polyethyleneglycol (PEG), and poly-L-lysine (PLL) can facilitate adsorption capacities of HFMs toward LPS. Additionally, chemical changes are presented as a means of preferentially adsorbing LPS to specific locations on the HFM surface...|$|E
40|$|This paper investigates pricing by Japanese {{manufacturing}} {{firms in}} export and domestic markets. The paper reports equations explaining the margin between export prices in yen and domestic prices {{for a wide}} range of final goods including many of the electronic and transport products which have figured so prominently in recent trade discussions. Evidence is presented showing that Japanese firms respond to changes in real exchange rates by "pricing to market", varying their export prices in yen relative to their domestic prices. The empirical specification makes it possible to disentangle planned changes in the margin between export and domestic prices from <b>inadvertent</b> <b>changes</b> in this margin due to unanticipated changes in exchange rates. The degree of pricing to market varies widely across products, but there is strong evidence that pricing to market occurs. The paper also investigates whether pricing to market has increased in scale in the period since 1985 when the yen began a sustained appreciation, but finds that only five of seventeen products experienced a shift in price behavior over that period. ...|$|E
40|$|A {{modified}} critical-incident analysis {{technique was}} used in a retrospective examination {{of the characteristics of}} human error and equipment failure in anesthetic practice. The objective was to uncover patterns of frequently occurring incidents that are in need of careful prospective investigation. Forty seven interviews were conducted with staff and resident anesthesiologists at one urban teaching institution, and descriptions of 359 preventable incidents were obtained. Twenty three categories of details from these descriptions were subjected to computer-aided analysis for trends and patterns. Most of the preventable incidents involved human error (82 %), with breathing-circuit disconnections, <b>inadvertent</b> <b>changes</b> in gas flow, and drug syringe errors being frequent problems. Overt equipment failures constituted only 14 % {{of the total number of}} preventable incidents, but equipment design was indictable in many categories of human error, as were inadequate experience and insufficient familiarity with equipment or with the specific surgical procedure. Other factors frequently associated with incidents were inadequate communication among personnel, haste or lack of precaution, and distraction. Results from multi-hospital studies based on the methodology developed could be used for more objective determination of priorities and planning of specific investments for decreasing the risk associated with anesthesia...|$|E
50|$|The {{exposure}} meter uses a circular CdS cell 8.5 mm in diameter (coverage with 50 mm lens = 21°), {{and having a}} sensitivity of -0 (some estimates claim -1) - 20 Ev at 100 ASA (0.3-0.4 asb at f/1.4 to 200 000 asb; 0,06 to 32.000 cd/m2). Information from the {{exposure meter}} is displayed using a dual match needle system {{at the bottom of}} the viewfinder. An additional illuminator window at the top of the viewfinder illuminates the readout bar. The M5 exposure meter can be set from ISO 6/9° to ISO 3200/36°. The ASA/DIN film speed knob is designed to prevent <b>inadvertent</b> <b>change.</b> The meter's circuit is powered up by winding the camera, and shuts down when the shutter is released. The M5 exposure meter required the PX625 1.35 V mercuric oxide coin type cell which was banned because of its mercury content. The M5 continues to run on a number of alternatives including the WeincellTM MRB625. The battery compartment is located between the strap lugs. It is accessed by using a coin slot type threaded cap and is superior in design to that of the bayonet caps that surfaced as of the M6.|$|R
40|$|Anterior chamber-associated immune {{deviation}} (ACAID) is {{a systemic}} form of tolerance that is elicited by introducing antigens into the anterior {{chamber of the}} eye. ACAID is characterized by deficiencies in delayed-type hypersensitivity and complement-fixing antibodies upon subsequent challenge with antigen. The mechanisms responsible for the generation of this form of tolerance are not yet completely clear. Here we asked whether γδ T cells, which are critical in the induction of oral tolerance and nasal tolerance, {{play a role in}} ACAID. The percentage of splenic γδ T cells was higher in mice that received antigen via the anterior chamber compared to untreated mice. In addition, CD 44 was up-regulated on some splenic γδ and αβ T cells after the intraocular injection of antigen. Moreover, administration of antigen into the anterior chamber did not induce ACAID in the C 57 BL/ 6 mice pretreated with anti-mouse δ-chain monoclonal antibody or in the γδ T-cell-receptor-deficient (δ−/−) mice. γδ T cells from wild-type mice reconstituted ACAID when transferred into the δ−/− mice before injection of antigen, verifying that the deficiency in δ−/− mice results from the lack of γδ T cells rather than from an <b>inadvertent</b> <b>change</b> caused by deletion of the δ-chain. These findings indicate that γδ T cells play a very important role in ocular tolerance...|$|R
40|$|DE 102006019124 A 1 UPAB: 20071119 NOVELTY - The {{system has}} a camera unit formed from linearly {{arranged}} optical channels with a micro lens (2), where a detector extracts a pixel from a micro-image behind the micro-lens. The camera unit {{is mounted on}} a rotating or rotational swinging axis (4). A drive (5) e. g. engine, a stepper motor or a coil {{in connection with a}} spring, is coupled in the axis of rotation. The optical axis of the individual optical channels has different inclinations such that they represent a function of the distance of the optical channel {{from the center of the}} side of the camera unit turned to the image. DETAILED DESCRIPTION - An INDEPENDENT CLAIM is also included for a method for recording an image in circumferential visibility. USE - Used in a medical technology e. g. endoscopy, for recording image and inspecting hole-like recesses. Can also be utilized in a vehicle (claimed). ADVANTAGE - The camera unit is mounted on the rotating or rotational swinging axis, where the drive is coupled in the axis of rotation, thus achieving a mechanical balancing in the image recording system and avoiding the undesired and the <b>inadvertent</b> <b>change</b> of the line of sight of the camera and providing the stable mechanical structure for the system...|$|R
40|$|The Systems Analysis Programs for Hands-on Integrated Reliability Evaluations (SAPHIRE) Version 8 is a {{software}} application developed for performing a complete probabilistic risk assessment using {{a personal computer}} running the Microsoft Windows™ operating system. SAPHIRE 8 is funded by the U. S. Nuclear Regulatory Commission (NRC). The role of the Idaho National Laboratory (INL) in this project is that of software developer and tester. In older versions of SAPHIRE, the model creation and analysis functions were intermingled. However, in SAPHIRE 8, the act of creating a model has been separated from the analysis of that model {{in order to improve}} the quality of both the model (e. g., by avoiding <b>inadvertent</b> <b>changes)</b> and the analysis. Consequently, in SAPHIRE 8, the analysis of models is performed by using what are called Workspaces. Currently, there are Workspaces for three types of analyses: (1) the NRC’s Accident Sequence Precursor program, where the workspace is called “Events and Condition Assessment (ECA);” (2) the NRC’s Significance Determination Process (SDP); and (3) the General Analysis (GA) workspace. Workspaces for each type are created and saved separately from the base model which keeps the original database intact. Workspaces are independent of each other and modifications or calculations made within one workspace will not affect another. In addition, each workspace has a user interface and reports tailored for their intended uses...|$|E
40|$|Proteomics {{and other}} protein-based {{analysis}} {{methods such as}} Westem blotting all {{face the challenge of}} discriminating changes in the levels of proteins of interest from <b>inadvertent</b> <b>changes</b> "in the amount loaded for analysis. Massspectrometry -based proteomics can now estimate the relative and absolute amounts of thousands of proteins across diverse biological systems. We reasoned that this new technology could prove useful for selection of very stably expressed proteins that could serve as better loading controls than those traditionally employed. Large-scale proteomic analyses of SDS lysates of cultured cells and tissues revealed deglycase DJ- 1 as the protein with the lowest variability in abundance among different cell types in human, mouse, and amphibian cells. The protein constitutes 0. 069 +/- 0. 017 % of total cellular protein and occurs at a specific concentration of 34. 6 +/- 8. 7 pmol/mg of total protein. Since DJ- 1 is ubiquitous and therefore easily detectable with several peptides, it can be helpful in normalization of proteomic data sets. In addition, DJ- 1 appears to be an advantageous loading control for Western blot that is superior to those used commonly used, allowing comparisons between tissues and cells originating from evolutionarily distant vertebrate species. Notably, this is not possible by the detection and quantitation of housekeeping proteins, which are often used in the Western blot technique. The approach introduced here can be applied to select the most appropriate loading controls for MS-based proteomics or Western blotting in any biological system...|$|E
40|$|Background: Correlated genetic {{response}} in survival to selection for high growth {{has not been}} reported in giant freshwater prawn (GFP) (Macrobrachium rosenbergii). The main {{aim of this study}} was to measure genetic changes and estimate heritability for this character (survival rate) and its genetic associations with body traits in a GFP population selected over eight generations from 2008 to 2015. Statistical analyses were conducted on 106, 696 data records, using threshold logistic mixed model. Results: The estimated heritability for survival was 0. 14 ± 0. 04 and significant. Genetic associations of survival with body traits (weight, length and width) were weak, with the estimates of genetic correlations between the traits close to zero. Realised genetic changes in survival, calculated as the difference in estimated breeding values between the selection line and control group within the same generation, was in positive direction but the estimates were not significantly different from zero regardless of the expression unit used either in actual unit of measurement or genetic standard deviation unit. On the other hand, communal testing of stocks in the latest generation, namely G 7 (2015), showed that the selection line had 18 % higher survival rate than progeny of the wild prawns originated from Mekong river. This result suggests that <b>inadvertent</b> <b>changes</b> in survival occurred during domestication-selection. Conclusions: It is concluded that selection for high growth had no significant effect on survival in the present population of M. rosenbergi...|$|E
5000|$|According to Allen Holub, {{the main}} problem with {{implementation}} inheritance is that it introduces unnecessary coupling {{in the form of}} the [...] "fragile base class problem": modifications to the base class implementation can cause <b>inadvertent</b> behavioral <b>changes</b> in subclasses. Using interfaces avoids this problem because no implementation is shared, only the API. Another way of stating this is that [...] "inheritance breaks encapsulation". The problem surfaces clearly in open object-oriented systems such as frameworks, where client code is expected to inherit from system-supplied classes and then substituted for the system's classes in its algorithms.|$|R
50|$|It was {{revealed}} via changes to {{electronic program guide}} systems and through an <b>inadvertent</b> image <b>change</b> on the Weather Channel media kit website that the shows time slots would be given to a relaunched version of Weather Center, which contains a mix of the traditional Evening Edition format {{as well as new}} segments. Weekends were also slated to feature PM Edition Weekend in place of Evening Edition, but only for three hours - it later turned out that Weather Center was to take this over too. The remainder of the weekend evenings now featured long-form programming.|$|R
40|$|International audienceAgriculture has {{significantly}} transformed {{the face of}} the planet. In particular, croplands have replaced natural vegetation over large areas of the global land surface, covering around 18 million km 2 of the land surface today. To grow crops, humans have taken advantage of the resource provided by climate — optimum temperature and precipitation. However, the clearing of land for establishing croplands might have resulted in an <b>inadvertent</b> <b>change</b> in the climate. This feedback might, in turn, have altered the suitability of land for growing crops. In this sensitivity study, we used a combination of land cover data sets, numerical models, and cropland suitability analysis, to estimate {{the degree to which the}} replacement of natural vegetation by croplands might have altered the land suitability for cultivation. We found that the global changes in cropland suitability are likely to have been fairly small, however large regional changes in cropland suitability might have occurred. Our theoretical study showed that major changes in suitability occurred in Canada, Eastern Europe, the Former Soviet Union, northern India, and China. Although the magnitude, sign, and spatial patterns of change indicated by this study may be an artifact of our particular model and experimental design, our study is illustrative of the potential inadvertent consequences of human activities on the land. Moreover, it offers a methodology for evaluating how climate changes due to human activities on the land may alter the multiple services offered by ecosystems to human beings...|$|R
40|$|Bioinformatics is a {{field of}} science that deals with storing, organizing, {{retrieving}} and analyzing biological data. With recent advances {{in the field of}} bioinformatics the amount of biological data that is being produced is very voluminous. This has led to the mushrooming of many open source online libraries of information related to life science known as biological databases and tools. As they do not need to register under any authority before going online, a comprehensive list of the databases is unavailable. Along with that the databases are not properly categorized. To utilize the biological resources many research facilities have setup computer laboratories for bioinformatics related research. These labs are difficult to manage as systems constantly malfunction due to <b>inadvertent</b> <b>changes</b> by the researchers. To overcome this problem most labs opt for expensive softwares that restore the system to its original state or restrict the users in certain ways. But these are broad systems and none of them are fully able to cater to the needs of a bioinformatics computer laboratory. Thus arise the need for a user-friendly graphical user interface for a bioinformatics workstation that uses open source bioinformatics tools and online databases. This study was aimed to develop an initial version of such a software for a kiosk-type bioinformatics workstation. The software is designed to run on system startup and categorizes an upgradable list of online databases into a user friendly graphical object. The software also prevents the user from closing the application by all possible means such as shortcuts like Alt+Tab, Alt+F 4 etc. It also clears the downloads of the user on system shutdown and reboots the system to its original state prior to using the program. The program is named “Catholicon” which means “a solution to all problems” and will be available freely upon demand...|$|E
40|$|The {{purpose of}} this study was to {{estimate}} the marginal costs of instruction in several types of public colleges and universities in the United States. If marginal costs vary with enrollment size or differ from average costs, then <b>inadvertent</b> <b>changes</b> in the financial status of those institutions are likely to accompany changes in their enrollments, granted current funding patterns. Long-run total cost functions were developed within a microeconomic framework. The unit of analysis was the institution. A variety of additive and multiplicative functions were tested, as no particular functional form was assumed to be correct a priori. The dependent variable was instructional expenditures; the primary independent variables included lower, upper, and graduate division enrollments, while control variables included average faculty salary, a state price index, sponsored research expenditures per faculty, dummy variables for whether the institution is in a formula-funding state and whether it is a traditionally black institution, and a program vector consisting of the proportion of degrees earned in a representative set of curricular areas. The primary data source was the 1977 - 78 Higher Education General Information Survey published by the National Center for Higher Education Statistics. The cost functions were estimated using ordinary least-squares regression. Four types of institutions offering primarily a baccalaureate or higher degree and three types of two-year institutions were analyzed. The estimated marginal cost curves were interpreted as reflecting average institutional efficiency. Cost behavior differed considerably by type of institution and by student level with respect to the estimated marginal costs at mean enrollment and the variability of estimated marginal costs across the range of observed enrollments, i. e., the shape of the marginal cost curves. Overall, the results of the study support the concern that current funding patterns for public higher education, with their reliance on average costs, may yield other than intended results when enrollments change substantially; but this implied incongruence varied by institutional type and by student level within institutional types...|$|E
40|$|The {{increasing}} number of applications and tools which use Cryptography, watermarking, and Steganography principles and procedures shows the necessity of developing and improving these methods, algorithms and techniques to make them as efficient as possible to harden the applications and tools against deliberate or <b>inadvertent</b> <b>changes</b> and modifications, and {{to benefit from the}} maximum efficiency we can obtain through these improvements. The intent of this research is to develop the watermarking methods and techniques by building an application of watermarking trying to prove that side information techniques are sufficient (virtually) to cancel the effect of cover works on the detectability of the hidden messages through these steps: Presenting and theoretically proving the limitations of simple watermarking techniques. Explaining and theoretically proving the efficiency of side information techniques in the cancelation process of the effect of cover works on the watermarked messages themselves. Building watermarking application for both simple and side information techniques using MATLAB (Different techniques in spatial and frequency domains), taking in consideration that it is enough to apply this application to one type of multimedia files as a sample of all types of multimedia files (image files are the considered multimedia sample in this research). Applying different samples to our application to test the functionality of its techniques in addition to gather the results to be considered in the conclusions and discussions. Discussing experimental results to present the similarities between theoretical principles and experimental findings, in addition to explaining the reasons and causes of differences when they exist. Finally, this research is to give some recommendations and future work assumptions to develop the techniques which are applied in the designed MA TLAB application, and to improve the efficiency of watermarking, in addition to increase the resistance of watermarked media against attacks and distortions. The main target achieved by this project is building the MATLAB application contains the algorithms and procedures of many simple and side information watermarking techniques. The designed application was the core task which makes it available to compare these algorithms and functions to obtain the results we need to discuss and explain the weaknesses of simple watermarking techniques in addition to the efficiency of side information techniques. Faculty of Technolog...|$|E
40|$|The Workshop process {{led to a}} set of {{proposed}} actions that have been summarised in the following three recommendations: 1. The Meat Research Corporation should lead a process of concerted effort for the use of monitoring procedures to assist in improving the management of grazing properties in Northem Australia 2. This process should involve the use of a Coordinating Group with producer leaders in pilot groups working as focal points in selected action regions 3. Research and agency service providers should assist in developing monitoring and management protocols that create positive opportunities and incentives to raise the management practices and resource status on grazing properties. These recommendations were arrived at ttrough an iterative sequence of sessions that discussed why, what and how of monitoring on pastoral lands in the Northem Ausralia Program Phase 3. The rapporteur's task It was my task to summarise the individual sessions and then draw these together in a synthesis that led to the above recommendations. l. Why monitor? Working groups agreed that monitoring: o is essential for good resource management and use a is a tool to be used in a manner appropriate to the manager's needs and scale of operation, rather than an end in itself o provides base-lines from which to assess deliberate or <b>inadvertent</b> <b>change</b> over time o is a valuable learning process for improving management of both resource use and enterprise success a must thus be developed {{in the context of the}} operator's goals. Ann Hambli...|$|R
30|$|Many {{planning}} and operation {{tasks such as}} determination of transmission line operating limits, network expansion, relay settings and the integration of renewable generators {{are based on the}} simulation results of power system models. Validation and calibration of power system models and parameters are of great importance {{due to the fact that}} these parameters can vary over time either due to intentional adjustments or <b>inadvertent</b> gradual <b>changes.</b> In 2006, the Western Electricity Coordinating Council (WECC) developed a generating unit model validation policy, which required generator models to be validated against recordings every five years [17]. And North American Electric Reliability Council (NERC) required that the models of all generating units be validated every 10 years.|$|R
30|$|Human {{activities}} {{have been the}} drivers of certain ongoing environmental changes. It {{is important to recognize}} the loop: societal feedbacks in response to these changes may facilitate the recurrence of disasters or cause a second cycle of <b>inadvertent</b> environmental <b>change</b> if the response misses the target or is ill-designed. For instance, reforestation may cause more intense rainfall and dykes may increase flood peaks. Curbing industrial development may negatively impact human well-being and overall societal resilience. This means that studies of the impact of environmental changes on societies and the development of adaptation and mitigation measures in response to their detrimental consequences should be accompanied by thorough assessments of the “end state” resulting from the environmental changes and the actual and projected societal response to these changes. This can be implemented only by mainstreaming all these kinds of impacts and feedbacks into comprehensive Earth system and integrated assessment models (see the next section of this paper).|$|R
40|$|The Systems Analysis Programs for Hands-on Integrated Reliability Evaluations (SAPHIRE) is a {{software}} application developed for performing a complete probabilistic risk assessment (PRA) using {{a personal computer}} (PC) running the Microsoft Windows operating system. SAPHIRE Version 8 is funded by the U. S. Nuclear Regulatory Commission (NRC) and developed by the Idaho National Laboratory (INL). INL's primary role in this project is that of software developer and tester. However, INL also {{plays an important role}} in technology transfer by interfacing and supporting SAPHIRE users, who constitute a wide range of PRA practitioners from the NRC, national laboratories, the private sector, and foreign countries. SAPHIRE can be used to model a complex system’s response to initiating events and quantify associated consequential outcome frequencies. Specifically, for nuclear power plant applications, SAPHIRE 8 can identify important contributors to core damage (Level 1 PRA) and containment failure during a severe accident which leads to releases (Level 2 PRA). It can be used for a PRA where the reactor is at full power, low power, or at shutdown conditions. Furthermore, it can be used to analyze both internal and external initiating events and has special features for managing models such as flooding and fire. It can also be used in a limited manner to quantify risk in terms of release consequences to the public and environment (Level 3 PRA). In SAPHIRE 8, the act of creating a model has been separated from the analysis of that model in order to improve the quality of both the model (e. g., by avoiding <b>inadvertent</b> <b>changes)</b> and the analysis. Consequently, in SAPHIRE 8, the analysis of models is performed by using what are called Workspaces. Currently, there are Workspaces for three types of analyses: (1) the NRC’s Accident Sequence Precursor program, where the workspace is called “Events and Condition Assessment (ECA);” (2) the NRC’s Significance Determination Process (SDP); and (3) the General Analysis (GA) workspace. Workspaces are independent of each other and modifications or calculations made within one workspace will not affect another. In addition, each workspace has a user interface and reports tailored for their intended uses. This report provides an overview of the functions and features available in SAPHIRE 8 and presents general instructions for using the software. Since SAPHIRE 8 expands upon Version 7, new and improved features will be discussed...|$|E
40|$|In hospitals, {{the use of}} {{approved}} {{names for}} prescribing and labelling is an essential requirement for precision and safety in giving medicines. Substitution is an unavoidable consequence of using approved names which brings benefits, but creates problems that demand more widespread recognition and urgent attention. In particular, dangerous variations in response following brand changes can occur in patients stabilized on certain products. The Licensing Authority and the Pharmaceutical Industry {{have a responsibility to}} eliminate brand bio-availability differences. But there is an immediate need; firstly, to identify the small number of products where brand changes in patients stabilized on them can result in potentially dangerous variations in response; and secondly, to safeguard patients being treated with these products, by avoiding substitution and preventing <b>inadvertent</b> brand <b>changes</b> by including brand or manufacturer's names on labels and in all communications between hospital doctors and general practitioners. The complete elimination of substitution is not feasible and the indiscriminate use of brand names in hospitals causes confusion and increases risks of error in giving medicines...|$|R
5000|$|In {{some cases}} {{schooling}} {{has been used}} as a tool for assimilation and a both deliberate and <b>inadvertent</b> tool to <b>change</b> local culture and economics into another form. Opponents of this effect argue it is a human right for a culture to be maintained, and education can violate this human right. [...] Forced schooling has been used to forcibly assimilate Native Americans in the United States and Canada, which some have said is cultural genocide. Many psychologists believe the forced assimilation of native cultures has contributed to their high suicide rates and poverty. [...] Western education encourages Western modes of survival and economic systems, which can be worse and poorer than the existing modes of survival and economic systems of an existing culture.|$|R
40|$|Wireless sensor {{networks}} (WSNs) as {{an emerging}} technology face numerous challenges. Sensor nodes are usually resources constrained,also, they {{are vulnerable to}} physical attacks or node compromises. Autonomic Computing is a steadily emerging and promising research field. In the domain of simplifying interoperability, it aims to diminish the management complexity in several industries and systems. Self-protection in WSNshasn’t been deeply studied before, because ofthe high rate of fails. The major concern in WSN is to maximize the network’s Lifetime. In this paper,a framework that embeds autonomic capabilities into WSN systems is proposed. The proposed framework provides self-protection features in cases of unauthorized, <b>inadvertent</b> and intentional <b>change</b> in security parameters. 2. WIRELESS SENSOR NETWORK Wireless sensor networks are often used in military systems[2], {{but they are also}} employed in various other systems (in commerce, in the service industry, in medicine, etc.). The WSN combines sensing, computation and communication in a single small device, called Sensor Node. The sensor node mainly contains radio, battery, microcontroller and power devices [3]. Figure 1 shows the Architecture of WSN [4, 5]...|$|R
40|$|Purpose Opening wedge high tibial {{osteotomy}} (HTO) is {{an accepted}} treatment option for medial compartment knee osteoarthritis with associated varus lower limb axis in younger, more active patients. A {{concern with the}} use of this technique is that posterior tibial slope (PTS) and tibial rotation can be altered. We hypothesized that {{there is a tendency to}} increase the PTS and internal rotation of the distal tibia during the procedure and that certain intra-operative parameters may influence the amount of change that can be expected. Methods A cadaveric model and surgical navigation system were used to evaluate the influence of certain intra-operative factors of the degree of PTS and tibial rotation change observed during medial opening HTO. Parameters evaluated included: degree of osteotomy opening, knee flexion angle, location of limb support (thigh versus foot), performance of a posteromedial release, the status of the lateral cortical hinge, and the degree of osteoarthritis present in the knee. Results Combining measurements of all specimens and parameters, a mean PTS increase of 2. 7 ° ± 3. 9 ° and a mean tibial internal rotation of 1. 5 ° ± 2. 9 ° were observed. Clinically, significant changes in tibial slope (> 2 °) occurred in 50. 4 % of corrections, while significant changes in tibial rotation (> 5 °) occurred in only 11. 9 % of corrections. Patients with significant osteoarthritis and concomitant flexion contracture, cases where large corrections were required, and procedures in which the lateral cortical hinge was disrupted were associated with increased PTS change. The other factors evaluated did not exert a significant influence of the degree of PTS change observed. Conclusions Surgeons should be vigilant for possible PTS change, particularly in high-risk situations as outlined above. Routine use of an intra-operative measure of PTS is recommended to avoid <b>inadvertent</b> slope <b>change...</b>|$|R
40|$|Satellite {{data for}} climate {{monitoring}} {{have become increasingly}} important over the past decade, especially with increasing concern for <b>inadvertent</b> antropogenic climate <b>change.</b> Although most satellite based data are of short record, satellites can provide the global coverage that traditional meteorological observations network lack. In addition, satellite data are invaluable for the validation of climate models, and they are useful for many diagnostic studies. Herein, several satellite data sets were processed and transposed into 'history tape' format for use with the Community Climate Model (CCM) modular processor. Only {{a few of the}} most widely used and best documented data sets were selected at this point, although future work will expand the number of data sets examined as well as update the archived data sets. An attempt was made to include data of longer record and only monthly averaged data were processed. For studies using satellite data over an extended period, {{it is important to recognize}} the impact of changes in instrumentation, drift in instrument calibration, errors introduced by retrieval algorithms and other sources of errors such as those resulting from insufficient space and/or time sampling...|$|R
