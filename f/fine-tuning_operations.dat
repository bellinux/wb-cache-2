10|24|Public
40|$|ABB {{has written}} {{a new chapter in}} the book of robot applications. While in the past it had been a tedious and {{time-consuming}} effort to program a robot for delicate <b>fine-tuning</b> <b>operations,</b> robots can now learn how to best manage such tasks themselves. This innovative approach can reduce overall programming times by up to 80 percent for robots used to grind castings, vastly improving productivity levels. With ABB’s new Flex Finishing system featuring RobotWare Machining FC (force control), one of the last real barriers to productivity improvement in this sector has been lifted...|$|E
40|$|Despite the {{possibility}} of overbidding, the Eurosystem has con- tinued using the fixed rate tender in its liquidity management. We document this fact for liquidity-absorbing <b>fine-tuning</b> <b>operations,</b> the USD term auc- tion facility, and EUR/CHF foreign exchange swaps. The mechanism is then studied in an auction-theoretic setting with privately known declining marginal valuations. An equilibrium exists even when bids are costless and the allotment is pre-announced. In this equilibrium, the extent of strate- gic overbidding is limited, {{and there is a}} bound below which the allotment quota never falls. In an extension with adaptive expectations, temporarily elevated overbidding factors quickly return to equilibrium levels. Eurosystem, Fixed rate tender, Overbidding, Existence of Bayesian Nash equilibrium, Dynamics, Efficiency...|$|E
40|$|This model {{provides}} a simple weekly {{model of the}} regular supply of liquidity in the euro area, {{with a view to}} understanding the functioning of the euro area money market. The main result of the analysis is that liquidity has normally been provided by the ECB in a neutral and smooth manner, but also that there has been attempt, albeit very limited, to correct deviations of the overnight rate from the main refinancing rate. Moreover, the paper finds that liquidity has affected the overnight interest rate to a significant extent only after the last main refinancing operation of the maintenance period, when it is not possible for the ECB to adjust liquidity imbalances except by making recourse to <b>fine-tuning</b> <b>operations.</b> JEL Classification: E 52, E 43, G 21 Bank reserves, liquidity effect, liquidity policy, martingale hypothesis, monetary policy...|$|E
50|$|Early in August 2007, the {{subprime}} crisis {{began to spread}} to sectors outside mortgage and real-estate finance. The ECB began distributing funds through a discount window or <b>fine-tuning</b> <b>operation.</b> By August 9, the ECB lent €95 billion ($112 billion in the days conversion) to EU banks, and the Fed distributed $12 billion through repo operations. Empirical {{results indicate that the}} Term Auction Facility had a strong effect in reducing financial strains in the inter-bank money market, primarily through relieving financial institutions' liquidity concerns.|$|R
40|$|A {{cognitive}} learning {{perspective is}} used to develop and test {{a model of the}} relationship between information acquisition and learning in the executive support systems (ESS) context. The model proposes two types of learning: mental model maintenance in which new information fits into existing mental models and confirms them; and mental model building in which mental models are changed to accommodate new information. It also proposes that information acquisition objectives determine the type of learning that is possible. When ESS are used to answer specific questions or solve well-defined problems, they help to <b>fine-tune</b> <b>operations</b> and verify assumptions-in other words, they help to maintain current mental models. However, ESS may be able to challenge fundamental assumptions and help to build new mental models if executives scan through them to help formulate problems and foster creativity. status: publishe...|$|R
50|$|In the mid-1980s, Sheller-Globe began <b>fine-tuning</b> its <b>operations,</b> largely abandoning {{automotive}} {{replacement parts}} (aftermarket) sales. Instead, it {{focused more on}} original equipment interior automotive products for the automotive manufacturers. Sheller-Globe's automotive related divisions supplied {{a wide range of}} original equipment parts, components and assemblies to the vehicle manufacturers. Products included thermoplastic, urethane and leather-wrapped steering wheels, instrument panel pads, padded consoles, arm rests and other padded components, tail lamp assemblies and a larger number of other products for vehicles.|$|R
40|$|This paper {{examines}} the interday and intraday {{dynamics of the}} euro area overnight money market {{on the basis of}} an original set of market activity and liquidity proxies constructed from both pre- and post-trade data. The empirical literature provides extensive evidence supporting the rejection of the martingale hypothesis both between days and within days, primarily for interest rates and volatility. We extend this analysis and investigate the seasonality of market activity and liquidity in a market dominated by utilitarian traders. We provide evidence that the Eurosystem's operational framework and calendar effects cause the observed regular patterns. We additionally show that utilitarian trading intensifies {{at the turn of the}} reserve maintenance period. The increased uncertainty associated with greater information asymmetry between market participants when reserve requirements become binding lead to a deterioration of market liquidity. Our analysis additionally turns out to be sensitive to the implementation in March 2004 of structural changes to the operational framework and to the more frequent occurrence of <b>fine-tuning</b> <b>operations</b> since October 2004. JEL Classification: E 43, E 58, C 22, C 32 Eurosystem's operational framework, market microstructure, Overnight money market, seasonality, tick data...|$|E
40|$|Alternating between task sets {{involves}} detection {{that the}} current task set is unfavorable, initiation {{of a change in}} set, and application of the new task set while fine-tuning to optimally adjust {{to the demands of the}} environment. Functional magnetic resonance imaging (fMRI) studies of cognitive flexibility consistently report activation of the anterior cingulate cortex and/or adjacent pre-supplementary motor regions (ACC/pre-SMA, medial Brodmann's areas 24 / 32 / 6), suggesting that these cortical regions are involved in switching task set. In the current study, our objective was to probe whether ACC/pre-SMA activation would decrease for a number of trials following a switch in task set, implying longer-term involvement in fine-tuning adjustments. By measuring activation when switching between word reading and color naming in response to Stroop stimuli, ACC/pre-SMA activation was observed when actively countering the influence of the irrelevant task set, and this activation decreased as a function of the number of trials since a task switch. Basal ganglia and thalamic regions also displayed a decreased response over successive trials after task switches. These findings suggest that the ACC/pre-SMA are not only involved in generating a new course of action, but are also involved (along with subcortical regions) in <b>fine-tuning</b> <b>operations</b> that resolve competition between task sets over subsequent repetitions of the same task...|$|E
40|$|It is {{generally}} recognised that the operational {{framework for the}} monetary policy of the Eurosystem 1 has been functioning well since {{the launch of the}} euro in 1999. There has been little need to conduct <b>fine-tuning</b> <b>operations,</b> because of the averaging provision of the minimum reserve system {{and the quality of the}} Eurosystem’s liquidity forecasts. Also, credit institutions have had only limited recourse to the standing facilities, which shows that the money market has been working efficiently. And the small and fairly stable spread between the ECB’s fixed or minimum bid rate on its main refinancing operations and the short-term money market rates displays the ability of the ECB to influence short-term interest rates. Despite th{{is generally}} positive assessment, some possible measures have been examined with the aim of further improving the efficiency of the operational framework. There are three changes to be considered: (1) changing the timing of the reserve maintenance period, so that it would always start on the settlement day of the main refinancing operation following the Governing Council meeting at which the discussion of monetary policy is pre-scheduled, so that – as a rule – the implementation of changes to the standing facility rates would be aligned with the start of a new reserve maintenance period...|$|E
50|$|At {{the wrist}} of the {{manipulator}} a force-torque-sensor is installed. The information from this sensor {{is used to}} detect collisions or for <b>fine-tuning</b> during manipulative <b>operations,</b> e.g. when the robot arm should put a gripped object in a small opening. This ensures robustness during execution.|$|R
40|$|Those {{of us on}} {{the western}} side of the Atlantic woke up the morning of Thursday 9 August to learn that the European Central Bank had engaged in a <b>fine-tuning</b> <b>operation</b> of € 94. 8 billion – by far the largest in history. The {{following}} day, as these overnight repurchase agreements expired, the operation to renew them was two-thirds the size – a still very large € 61. 1 billion. 1 Meanwhile, the Open Market Trading Desk of the Federal Reserve Bank of New York used one-day repurchase agreements to injected $ 24 billion in reserves into the U. S. banking system on Thursday; and when those expired on Friday the Desk upped the amount by $ 38 billion for the weekend. 2 On Friday 17 August, a week after these extraordinary open market operations, the Federal Reserve made two announcements: (1) The Federal Open Market Committee (FOMC) issued a statement. And, (2) The Federal Reserve Board announced a reduction in the primary credit discount rate from 6. 25 percent to 5. 75 percent. This entire set of actions was aimed at calming what are generally called money markets. These are the short-term lending markets where banks borrow from each other and industrial companies issue commercial paper with maturities from several days to several months. Th...|$|R
40|$|In May 2011, the IceCube {{neutrino}} observatory {{with one}} cubic kilometer instrumented volume started full operation with 5160 sensors on 86 strings and 324 sensors on 162 IceTop detectors. The <b>fine-tuning</b> of <b>operation</b> and calibration of the detector {{is still in}} progress while a very high uptime of well above 98 % is obtained. New analysis techniques rely on veto techniques for enhanced rejection of atmospheric muon and neutrino backgrounds. We will give an overview of recent results including the techniques of searching for starting tracks and some comments on the reported evidence of astrophysical neutrinos at energies above 30 TeV. Comment: 11 pages, 10 figures, to appear in Proceedings for the XVth Workshop on Neutrino Telescopes, held in Venice, March 201...|$|R
40|$|The Swiss National Bank (SNB) {{provides}} {{reserves to}} market participants via {{fixed rate tender}} auctions. We analyze the banks' bidding behavior and identify the determinants for the decision to participate {{as well as on}} the amount to tender. Therefore, we estimate bidding functions for banks which participate regularly in the SNB's auctions. We find that a bank's bids from the previous day and the amount of maturing repo operations with the SNB have for most banks a significant effect. The autonomous factors (government balances at the SNB and currency in circulation) are of only minor importance. A further determinant of the bidding behavior is the attractiveness of the SNB's auction rate compared to the prevailing interbank market repo rate. The spread of unsecured and repo rates as well as the attractiveness of funding Euros indirectly via a Swiss franc repo transaction with the SNB are only for few banks significant. Further, the question is addressed whether the bidding behavior changed in the financial market crisis of 2007 / 2008. There is little evidence of a systematic change in bidding behavior in the crisis. This results from the fact that the SNB has addressed the volatile demand for reserves in the crisis with overnight <b>fine-tuning</b> <b>operations.</b> Open Market Operations, Bidding Behavior, FixedRate Tender Auction, Repo, Switzerland...|$|E
40|$|The {{financial}} markets turmoil of 2007 - 09 impacted on the overnight segment, {{which is the}} first step of monetary policy implementation. We model the volatility of the EONIA spread as an EGARCH. However, the nature of the EGARCH considered will be different in the period before the fixed rate full allotment policy of the ECB (2004 - 2008) where we follow the approach of Hamilton (1996) and in the period afterwards (2008 - 2009) where a conventional EGARCH seems sufficient to capture the behaviour of volatility. The results suggest a greater difficulty during the turmoil for the ECB to steer the level of the EONIA spread relative to the main reference rate. The liquidity effect has been reduced since 2007 and in particular since the full allotment policy at the refinancing operations. On the other hand, the liquidity policy and especially the provision of long-term liquidity followed was effective in reducing market volatility. Liquidity provision conditions were also found to have influenced the EONIA spread only since the financial market turmoil. <b>Fine-tuning</b> <b>operations</b> contributed to stabilize money market conditions, especially during the turmoil. The EGARCH parameter estimates also suggest a structural change in the behaviour of the EONIA spread in reaction to shocks. ...|$|E
40|$|In {{the past}} few months, euro area money markets {{have been exposed to}} intense tensions. On 8 August, {{overnight}} interest rates rose to very high levels which required interventions of the Eurosystem in order to stabilise short-term money market interest rates around the target level, i. e. the minimum bid rate on the main refinancing operations. The article explains how the Eurosystem steers very short-term money market interest rates by adjusting its supply of liquidity on the money market. It is shown how the Eurosystem’s liquidity management stabilised short-term money market interest rates around the minimum bid rate on the main refinancing operations {{in the first half of}} 2007. Although short-term money market interest rates were more volatile during the period of financial turmoil, the Eurosystem nevertheless managed to safeguard the signalling function of the short-term money market interest rates by applying its operational framework in a flexible way. More specifically, the Eurosystem decided to allot more liquidity than the benchmark amount in the main refinancing operations early within the maintenance period. It was also decided to conduct <b>fine-tuning</b> <b>operations</b> on a more frequent basis in order to stabilise short-term rates. Finally, the Eurosystem also decided to increase the share of longer-term refinancing operations in the total amount of outstanding open market operations. Despite the relative success in stabilising very short-term money market interest rates, longer maturity unsecured interest rates – for instance the 3 -month Euribor – increased significantly during the period of financial turmoil. These movements cannot be controlled directly by central banks as they are determined predominantly by private sector behaviour. However, when assessing the appropriate monetary policy stance, the Governing Council of the ECB takes these possibly changing financing conditions into account. monetary policy implementation, Eurosystem, open market operations...|$|E
40|$|Although {{learning}} {{has been associated}} with information technology, a theory of how technology, learning and organizational performance are related has never been developed. This dissertation employs a cognitive learning perspective to investigate the impact that executive support systems (ESS) have on organizations by proposing and testing a model of the relationships among these constructs.;The model describes the process by which ESS lead to learning and increased organizational performance. It proposes two types of learning: mental model maintenance in which new information fits into existing mental models and confirms them; and mental model building in which mental models are changed to accommodate new information. The model also proposes that mental model maintenance leads to improvements in efficiency and mental model building leads to effectiveness. Efficiency and effectiveness both lead to improvements in organizational performance.;Finally, the model proposes that information retrieval behaviour determines the type of learning that is possible. When ESS are used to answer specific questions or solve well-defined problems, they help to <b>fine-tune</b> <b>operations</b> and verify assumptions [...] in other words, they help to maintain mental models. However, ESS may be able to challenge fundamental managerial assumptions and build new mental models if executives scan through them to help formulate problems and foster creativity.;The dissertation comprises three empirical phases: an initial survey administered to 73 executive ESS users in nine companies; seven case studies involving 36 executives; and a second survey of 361 executives in 18 organizations. Rarely, if ever, has such a large group of executives participated in MIS research that relates so directly to their particular information needs. In addition, the interplay between quantitative and qualitative methodologies strengthens the conclusions of both by providing context to understand quantitative results and quantitative results to support qualitative findings.;All three phases provide substantive, statistically significant evidence of the links among information retrieval behaviours, learning, and organizational performance hypothesized by the research model. The results can help organizations understand and evaluate the potential ESS have for improving organizational performance. They can also help them develop systems that are better able to support executive learning...|$|R
40|$|Developing an {{effective}} memetic algorithm that integrates the Particle Swarm Optimization (PSO) algorithm {{and a local}} search method is a difficult task. The challenging issues include when the local search method should be called, the frequency of calling the local search method, as well as which particle should undergo the local search operations. Motivated by this challenge, we introduce a new Reinforcement Learning-based Memetic Particle Swarm Optimization (RLMPSO) model. Each particle is subject to five operations {{under the control of}} the Reinforcement Learning (RL) algorithm, i. e. exploration, convergence, high-jump, low-jump, and <b>fine-tuning.</b> These <b>operations</b> are executed by the particle according to the action generated by the RL algorithm. The proposed RLMPSO model is evaluated using four uni-modal and multi-modal benchmark problems, six composite benchmark problems, five shifted and rotated benchmark problems, as well as two benchmark application problems. The experimental results show that RLMPSO is useful, and it outperforms a number of state-of-the-art PSO-based algorithms...|$|R
40|$|This paper {{presents}} {{a case study}} for Continuous Commissioning? (CC?) of a 520, 000 square foot medical research facility. All of the primary energy using systems in the building were investigated to determine their existing condition and operation. Using these findings, the needed CC? measures were developed. Some of the CC? measures include repairing the heat exchangers, valves, and dampers that are not working. Also, reset schedules for air handling unit supply temperature and static pressure were created. Chilled and hot water loop ?P setpoints were <b>fine-tuned.</b> Economizer <b>operation</b> and air-to-air heat exchanger operation were also optimized. The airflow stations {{in many of the}} terminal boxes were found to be in need of cleaning and addition of filters. From January 2004 through March 2006 the CC? engineers implemented the CC? measures with the assistance of facility staff. Cumulative CC? savings from April 2004 to July 2006 was over $ 1, 900, 000 and the building experiencd significant comfort improvements...|$|R
40|$|Mención Internacional en el título de doctorThe {{performance}} of the global routing system is vital to thousands of entities operating the Autonomous Systems (ASes) which make up the Internet. The Border Gateway Protocol (BGP) is currently responsible for the exchange of reachability information and the selection of paths according to their specified routing policies. BGP thus enables traffic to flow from any point to another connected to the Internet. The manner traffic flows if often influenced by entities in the Internet according to their preferences. The latter are implemented {{in the form of}} routing policies by tweaking BGP configurations. Routing policies are usually complex and aim to achieve a myriad goals, including technical, economic and political purposes. Additionally, individual network managers need to permanently adapt to the interdomain routing changes and, by engineering the Internet traffic, optimize the use of their network. Despite the flexibility offered, the implementation of routing policies is a complicated process in itself, involving <b>fine-tuning</b> <b>operations.</b> Thus, it is an error-prone task and operators might end up with faulty configurations that impact the efficacy of their strategies or, more importantly, their revenues. Withal, even when correctly defining legitimate routing policies, unforeseen interactions between ASes have been observed to cause important disruptions that affect the global routing system. The main reason behind this resides {{in the fact that the}} actual inter-domain routing is the result of the interplay of many routing policies from ASes across the Internet, possibly bringing about a different outcome than the one expected. In this thesis, we perform an extensive analysis of the intricacies emerging from the complex netting of routing policies at the interdomain level, in the context of the current operational status of the Internet. Abundant implications on the way traffic flows in the Internet arise from the convolution of routing policies at a global scale, at times resulting in ASes using suboptimal ill-favored paths or in the undetected propagation of configuration errors in routing system. We argue here that monitoring prefix visibility at the interdomain level can be used to detect cases of faulty configurations or backfired routing policies, which disrupt the functionality of the routing system. We show that the lack of global prefix visibility can offer early warning signs for anomalous events which, despite their impact, often remain hidden from state of the art tools. Additionally, we show that such unintended Internet behavior not only degrades the efficacy of the routing policies implemented by operators, causing their traffic to follow ill-favored paths, but can also point out problems in the global connectivity of prefixes. We further observe that majority of prefixes suffering from limited visibility at the interdomain level is a set of more-specific prefixes, often used by network operators to fulfill binding traffic engineering needs. One important task achieved through the use of routing policies for traffic engineering is the control and optimization of the routing function in order to allow the ASes to engineer the incoming traffic. The advertisement of more-specific prefixes, also known as prefix deaggregation, provides network operators with a fine-grained method to control the interdomain ingress traffic, given that the longest-prefix match rule over-rides any other routing policy applied to the covering lessspecific prefixes. Nevertheless, however efficient, this traffic engineering tool comes with a cost, which is usually externalized to the entire Internet community. Prefix deaggregation is a known reason for the artificial inflation of the BGP routing table, which can further affect the scalability of the global routing system. Looking past the main motivation for deploying deaggregation in the first place, we identify and analyze here the economic impact of this type of strategy. We propose a general Internet model to analyze the effect that advertising more-specific prefixes has on the incoming transit traffic burstiness. We show that deaggregation combined with selective advertisements (further defined as strategic deaggregation) has a traffic stabilization side-effect, which translates into a decrease of the transit traffic bill. Next, we develop a methodology for Internet Service Providers (ISPs) to monitor general occurrences of deaggregation within their customer base. Furthermore, the ISPs can detect selective advertisements of deaggregated prefixes, and thus identify customers which may impact the business of their providers. We apply the proposed methodology on a complete set of data including routing, traffic, topological and billing information provided by an operational ISP and we discuss the obtained results. Programa Oficial de Doctorado en Ingeniería TelemáticaPresidente: Arturo Azcorra Saloña. - Secretario: Steffano Vissichio. - Vocal: Kc. Claff...|$|E
40|$|This paper {{describes}} {{the development of}} an off-line emulation tool, entitled REALTRAN (REAL-time TRANsyt), that can emulate the SCOOT version 2. 2 signal optimization logic. REALTRAN was derived from the TRANSYT- 7 F model (TRANSYT version 7 F) by introducing various constraints into the optimization logic of TRANSYT- 7 F. These constraints allow the user to select optimization parameters that enable REALTRAN to operate in a similar fashion to the original SCOOT signal optimizer logic. The REALTRAN model is currently intended to serve as an educational tool, but can, in the future, serve as a tool to <b>fine-tune</b> the <b>operation</b> of the real-time controls of the SCOOT system in a laboratory environment, where scientific and statistically valid testing and sensitivity analyses of the signal optimization algorithms can be performed. Alternatively, REALTRAN may be utilized to estimate off-line the expected benefits of SCOOT using location specific network and flow data. (Keywords: Simulation, Real-Time signal control, ATMS, SCOOT, TRANSYT...|$|R
40|$|Abstract. We {{propose a}} dynamic, ad-hoc {{communication}} network consisting of mobile units that can warn about traffic jams on motorways. Our {{goal is to}} provide a practical, low cost solution. Therefore we consider very simple wireless communication hardware, without collision detection, with very small bandwidth and a probabilistic model of link failure. We provide a complete system architecture. For this purpose we design and analyze solutions for size approximation, leader election and broadcasting. Our algorithms are <b>fine-tuned</b> for fast <b>operation</b> in a practical setting. We provide both a theoretical and experimental evaluation of our solutions. Our contribution is much different from the previous work, where either pure theoretical models with a pure theoretical analysis are provided or algorithms working in practical models are evaluated only through simulations. ...|$|R
40|$|Abstract: This paper {{studies the}} {{evolution}} of hurricane insurance in Florida over the last decades. Hurricanes (and other natural catastrophes) are typically referred to as “uninsurable” risks. The more exposed property owners {{find it difficult to}} obtain insurance cover from the private market and/or can do so only at premiums that substantially exceed their expected claims costs. The state of Florida has reacted to the incapacity of the private sector to insure hurricane risks at reasonable premium levels with the creation of Citizens Property Insurance Corporation (an insurer of last resort) and the Florida Hurricane Catastrophe Fund. Their existence has resulted in substantial premium reductions for the Florida property owners. Both institutions have the possibility of spreading the costs of a major hurricane over a (very) large number of policy holders through after the event compulsory assessments. The risk borne by each individual property owner is thus reasonably small, with substantial benefits for consumers as a group. Looking forward the challenge to the policy maker will be to <b>fine-tune</b> the <b>operation</b> (premium structure) of these two institutions so as to increase their political acceptance. To this end {{it will be necessary to}} limit the implicit subsidy of the “bad risks” through the “good risks”...|$|R
40|$|This paper {{studies the}} {{evolution}} of hurricane insurance in Florida over the last decades. Hurricanes (and other natural catastrophes) are typically referred to as "uninsurable" risks. The more exposed property owners {{find it difficult to}} obtain insurance cover from the private market and/or can do so only at premiums that substantially exceeds their expected claims costs. The state of Florida has reacted to the incapacity of the private sector to insure hurricane risks at reasonable premium levels with the creation of Citizens (an insurer of last resort) and the Florida Hurricane Catastrophe Fund. Their existence has resulted in substantial premium reductions for the Florida property owners. Both institutions have the possibility of spreading the costs of a major hurricane over a (very) large number of policy holders through after the event compulsory assessments. The risk borne by each individual property owner is thus reasonably small. The benefits for consumers as a group have thus been substantial. Looking forward the challenge to the policy maker will be to <b>fine-tune</b> the <b>operation</b> (premium structure) of these two institutions so as to increase their political acceptance. To this end {{it will be necessary to}} limit the implicit subsidy of the "bad risks" through the "good risks". hurricane; catastrophe insurance; regulation; market failure; Florida...|$|R
40|$|An {{electronic}} {{version of}} the paper may be downloaded • from the SSRN website: www. SSRN. com • from the RePEc website: www. RePEc. org • from the CESifo website: Twww. CESifo-group. org/wpT CESifo Working Paper No. 2768 Hurricane Insurance in Florida This paper studies the evolution of hurricane insurance in Florida over the last decades. Hurricanes (and other natural catastrophes) are typically referred to as “uninsurable ” risks. The more exposed property owners {{find it difficult to}} obtain insurance cover from the private market and/or can do so only at premiums that substantially exceed their expected claims costs. The state of Florida has reacted to the incapacity of the private sector to insure hurricane risks at reasonable premium levels with the creation of Citizens Property Insurance Corporation (an insurer of last resort) and the Florida Hurricane Catastrophe Fund. Their existence has resulted in substantial premium reductions for the Florida property owners. Both institutions have the possibility of spreading the costs of a major hurricane over a (very) large number of policy holders through after the event compulsory assessments. The risk borne by each individual property owner is thus reasonably small, with substantial benefits for consumers as a group. Looking forward the challenge to the policy maker will be to <b>fine-tune</b> the <b>operation</b> (premium structure) of these two institutions so as to increase their political acceptance. To this end {{it will be necessary to}} limit the implicit subsidy of the “bad risks” through the “good risks”...|$|R
40|$|As {{peer-to-peer}} {{systems are}} evolving from simplistic application specific overlays to middleware platforms hosting {{a range of}} potential applications it has become evident that increasingly configurable approaches are required to ensure appropriate overlay support is provided for divergent applications. This is exacerbated by the increasing heterogeneity of networked devices expected to host the overlay. Traditional adaptation approaches rely on simplistic design-time isolated <b>fine-tuning</b> of overlay <b>operations.</b> This, however, cannot fully support the level of configurability required by next generation peer-to-peer systems. To remedy this, a middleware overlay framework is designed that promotes the use of architectural reconfiguration for adaptive purposes. Underpinning this is a generic reusable component pattern that utilises software reflection to enable rich and extensible adaptation of overlays beneath divergent applications operating in heterogeneous environments. This is evaluated {{through a number of}} case-study experiments showing how overlays developed using the framework have been adapted to address a range of application and environmental variations...|$|R
40|$|The term Continuous Commissioning (CC) {{was first}} used by {{engineers}} at the Energy Systems Lab (ESL) at Texas A&M University to describe an ongoing process which improves the operation of buildings using measured hourly energy use and environmental data. The first buildings to undergo a continuous commissioning process were in the Texas LoanSTAR program [Liu, et al, 1994, Claridge, et al, 1994]. These buildings had been retrofitted with various energy efficiency improvements, and measured hourly data were available to verify that the retrofits were performing as desired, and to analyze the overall building performance. The ESL engineers, using hourly data, site visits, and ESL-developed software [Liu and Claridge 1995], then worked with the facility engineers to <b>fine-tune</b> the building <b>operation.</b> These efforts were so successful that another 15 to 30 % of the annual building energy cost was saved ~ and these were in buildings that supposedly had all cost effective retrofits and operating improvements already implemented [Liu 1996]...|$|R
40|$|The first Chapter in {{this thesis}} aims to present an {{adequate}} background information on the previous work. Short of introducing routine antepartum prophylaxis programme, the only avenues open to impact on the incidence of RhD alloimmunisation, were efforts to <b>fine-tune</b> the <b>operation</b> of the existing postpartum prophylaxis programme.   This included improvement of the accuracy of measuring the volume of transplacental bleeds, {{in order to ensure}} that sufficient dose of anti-D is administered to afford protection against sensitisation.   Chapter II discusses the results of a Kleihauer Quality Assurance Scheme in Scotland, and demonstrates that, this scheme was effective in bringing about a change in the practice of Kleihauer testing in Scotland, and introduction of greater standardisation and harmonisation of practice with trends towards improved test results. The data presented in Chapter III, provide data on the incidence of RhD alloimmunisation in Scotland and relate this incidence to similar results obtained using different methodologies and denominators.   These data show that there had been no significant changes in the alloimmunisation rates over the previous decade. Mortality due to Rh disease had been underestimated, due to reliance on registry data.   Combining registry data, information from the case notes of alloimmunised mothers and data from tertiary referral centre in Scotland, as set out in chapter IV demonstrated the true magnitude of fetal / neonatal loss in Scotland between 1987 - 1991 and provides some information on the long term sequelea of Rh disease.   A total of 20 fetal losses occurred over this period, several fold greater than suggested by the registry data. Finally, in collaboration with Health Economic Research Unit in Aberdeen University, the above information was utilised to assess the economic aspects of introducing routine antenatal prophylaxis. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Stimulus-induced {{response}} conflict (e. g., in Simon or Stroop tasks) {{is often}} reduced after conflict trials—the Gratton effect. It is generally assumed that {{this effect is}} due to a strengthening of the representation of the current intention or goal, which in turn increases the degree of stimulus and/or response control. Recent evidence suggests that the motivational signal driving the Gratton effect might be affective in nature. If so, individual differences in either the strength of affective signals and/or the ability to interpret such signals might explain individual differences in cognitive-control adjustments as reflected in the Gratton effect. We tested this hypothesis by relating individual sizes of the Gratton effect in a Simon task to scores on the affective and the cognitive dimension of the Bermond/Vorst Alexithymia Questionnaire (BVAQ) —which we assumed to assess individual differences in affective-signal strength and ability to interpret affective signals, respectively. Results show that the cognitive, but not the affective dimension predicted control adjustment, while the accuracy of heartbeat detection was only (and only weakly) related to online control. This suggests that the motivation to <b>fine-tune</b> one’s cognitive-control <b>operations</b> is mediated by, and may depend on one’s ability to interpret one’s own affective signals...|$|R
40|$|APEX (Airborne Prism EXperiment) is {{a project}} being {{developed}} by a joint Swiss-Belgian consortium {{on behalf of the}} European Space Agency ESA-PRODEX programme. It comprises an airborne dispersive pushbroom imaging spectrometer, a Calibration Home Base (CHB) for instrument calibration operations and a dedicated data Processing and Archiving Facility (PAF). A unique In-Flight Characterization (IFC) unit is integrated within the optical sensor, providing pre- and post- data-take characterization data to monitor the instrument stability along the mission and improve the delivered data. The imaging spectrometer sensor is operating in the solar reflected wavelengths range between 380 nm and 2500 nm, by means of two dispersive spectrometer channels that partially share the optical path. The achieved resolution amounts to 1000 spatial across track samples over an overall FoV of 28 °, with more than 300 configurable spectral bands. The instrument has been engineered to provide high quality data for scientific applications, in particular focusing on topics as limnology, vegetation, snow and soil analyses among others, and to simulate and support the development of future spaceborne remote sensing instrumentation. The APEX PAF includes (a) the calibration of the acquired data from raw instrument data stream to physical units, (b) geometric and atmospheric correction for each scene, and (c) instrument calibration data management. APEX is now in a pre-operational setup and testing activities, including <b>fine-tuning,</b> extended calibration <b>operations</b> and test flights are taking place. This paper outlines the system validation procedures as well as preliminary performance results...|$|R
40|$|Rabies Virus (RABV) is {{a deadly}} {{pathogen}} that causes disease in humans and animals. In Pennsylvania, RABV is endemic among wild animals, such as raccoons, skunks, and bats. The public health {{significance of this}} issue is {{in part due to}} the rare possibility of RABV transmission to humans, thus it is imperative that public health institutions control wild animal rabies cases. The “Raccoon Oral Rabies Vaccination (ORV) Program” is a one-week program that has taken place in Allegheny County, Pennsylvania, every August since 2002. The main goal of the program is to manage wild animal rabies cases by orally vaccinating raccoons, which are the primary carriers of RABV in Pennsylvania. Since the program is planned to continue for years to come, with the goal of eventually eliminating RABV, it is essential to evaluate the implementation or process of the program. This preliminary evaluation will help gain knowledge about program activities and <b>fine-tune</b> existing program <b>operations</b> and strategies, mainly focusing on stakeholder involvement (i. e., organizers and volunteers). This evaluation may also be useful to document activities of raccoon baiting week for potential replication in other counties. Our preliminary process evaluation utilized responses to a stakeholder survey collected shortly after the program end date in August, 2016. The survey was divided into various aspects of the program, including participant details, recruitment of participants, training to bait, and general baiting experiences. Many respondents to our post-baiting survey made helpful comments and suggestions on the various aspects of the ORV baiting program. Their insight into the program was useful for documenting overall activities and providing recommendations. Although some limitations to this essay exist, the importance of evaluating the process of the ORV baiting program is more significant. We learned that there are various aspects of the program that may benefit by minor adjustment. These include recruitment strategy, scheduling methods, training plans, and overall baiting experience. By offering recommendations that refine various features of the program process, we want to continue the ORV baiting program in a more efficient and enjoyable manner for years to come...|$|R
40|$|Thesis (MIng (Mechanical Engineering)) [...] North-West University, Potchefstroom Campus, 2013. Energy shortage, {{escalation}} of energy cost {{and climate change}} have led to an increased focus on energy conservation worldwide. In order to curb the increase in electricity demand, Eskom has introduced demand-side management (DSM) to improve energy efficiency and to shift peak-time load to off-peak periods in order to postpone additional capacity requirements. In the past, several mine DSM projects have been implemented {{without the use of}} system simulations as part of the analysis of project planning. Many of these projects are characterised by contractual energy saving targets that have not been met, projects that are delayed, potential energy savings projects that have been overlooked and additional savings that have not realised. This study demonstrates the potential of simulations to plan new and correct implemented DSM solutions. This is done by allowing analysis of energy consumption in complex technical systems and quantification of the savings potential of DSM interventions to inform design changes in order to attain energy savings. In applying simulations to a well-instrumented compressed air system, it was possible to compare the theoretical and measured values for system parameters. The simulation was <b>fine-tuned</b> for low-pressure <b>operation</b> (with the system operating well within design constraints) by incorporating estimated flow losses. By simulating high-pressure operation in which the system operates closer to design limits, the constraints that were experienced, were revealed. This application exemplifies the approach that has been adopted in the case studies to follow. The value of the use of simulation models for mine DSM projects Simulations that have been applied to four case studies demonstrate the use in improving existing DSM projects as well as in planning new DSM projects. Two case studies demonstrate the use of simulations in rectifying problems that have been encountered during the implementation of existing mine DSM projects. Simulations have been employed to propose corrections to these project implementations; this demonstrates significant value for the customer. In two additional case studies, the value of simulation models is demonstrated where simulations have been developed prior to the implementation of DSM projects. It demonstrates that projects can be implemented with less effort, in a shorter time span and at a reduced cost (both capital and man-hours) by using simulations in the planning phases of DSM projects. Master...|$|R
40|$|Ultra-wideband (UWB) is an {{appealing}} transmission technology for short-range, bandwidth demanded wireless communications. With the data rate {{of several hundred}} megabits per second, UWB demonstrates great potential in supporting multimedia streams such as high-definition television (HDTV), voice over Internet Protocol (VoIP), and console gaming in office or home networks, known as the wireless personal area network (WPAN). While vast research effort has been made on the physical layer issues of UWB, the corresponding medium access control (MAC) protocols that exploit UWB technology have not been well developed. Given an extremely wide bandwidth of UWB, a fundamental problem on how to manage multiple users to efficiently utilize the bandwidth is a MAC design issue. Without explicitly considering the physical properties of UWB, existing MAC protocols are not optimized for UWB-based networks. In addition, the limited processing capability of UWB devices poses challenges {{to the design of}} low-complexity MAC protocols. In this thesis, we comprehensively investigate the MAC protocols for UWB networks. The objective is to link the physical characteristics of UWB with the MAC protocols to fully exploit its advantage. We consider two themes: centralized and distributed UWB networks. For centralized networks, the most critical issue surrounding the MAC protocol is the resource allocation with fairness and quality of service (QoS) provisioning. We address this issue by breaking down into two scenarios: homogeneous and heterogeneous network configurations. In the homogeneous case, users have the same bandwidth requirement, and the objective of resource allocation is to maximize the network throughput. In the heterogeneous case, users have different bandwidth requirements, and the objective of resource allocation is to provide differentiated services. For both design objectives, the optimal scheduling problem is NP-hard. Our contributions lie in the development of low-complexity scheduling algorithms that fully exploit the characteristics of UWB. For distributed networks, the MAC becomes node-based problems, rather than link-based problems as in centralized networks. Each node either contends for channel access or reserves transmission opportunity through negotiation. We investigate two representative protocols that have been adopted in the WiMedia specification for future UWB-based WPANs. One is a contention-based protocol called prioritized channel access (PCA), which employs the same mechanisms as the enhanced distributed channel access (EDCA) in IEEE 802. 11 e for providing differentiated services. The other is a reservation-based protocol called distributed reservation protocol (DRP), which allows time slots to be reserved in a distributed manner. Our goal is to identify the capabilities of these two protocols in supporting multimedia applications for UWB networks. To achieve this, we develop analytical models and conduct detailed analysis for respective protocols. The proposed analytical models have several merits. They are accurate and provide close-form expressions with low computational effort. Through a cross-layer approach, our analytical models can capture the near-realistic protocol behaviors, thus useful insights into the protocol can be obtained to improve or <b>fine-tune</b> the protocol <b>operations.</b> The proposed models can also be readily extended to incorporate more sophisticated considerations, which should benefit future UWB network design...|$|R
40|$|Title from PDF {{of title}} page, viewed on February 28, 2017 VitaDissertation advisor: Deb ChatterjeeIncludes bibliographical {{references}} (pages 107 - 118) Thesis (Ph. D.) [...] School of Computing and Engineering. University of Missouri [...] Kansas City, 2016 Ultra-wideband (UWB), low-profile microstrip patch antennas and phased arrays have their niche in many wireless communication and medical applications. In recent years, the U-slot patch antenna established {{itself as a}} versatile antenna that can be <b>fine-tuned</b> for ultra-wideband <b>operations.</b> The L-shaped probe feeding method has additionally led to improved impedance bandwidth for the U-slot patch antenna. The L-probe’s simple structure together with its low production cost makes it an attractive feeding method for the U-slot microstrip patch antenna. In phased arrays, scan blindness due to surface wave excitations can reduce the scan bandwidth range. By reducing the mutual coupling between array elements, the scan blindness effects will be reduced. Also, by reducing the sidelobe levels and minimizing the effect of grating lobes in phased arrays, the array’s scan performance and power efficiency can be improved. In this dissertation, (1) a parametric study is performed on εr = 2. 2 and 4. 5 substrates {{for the design of}} ideal L-probe feed dimensions with optimum impedance bandwidth. Results show that first-pass optimum impedance bandwidth of over 50 % is achieved using the ideal L-probe feed dimensions. (2) The mutual coupling between a 2 -element UWB microstrip array using different patch orientations and U-slot topologies is examined for εr = 2. 2 and 4. 5 substrates to reduce the effect of scan blindness. Results, for εr = 2. 2 substrate, indicate that a diamond patch orientation with opposite U-slot topology presents the least coupling between the array elements. For εr = 4. 5 substrate, the E-plane patch orientation with parallel U-slot topology has the least coupling. (3) The scan behavior of 5 x 5 planar phased arrays using different patch orientations and U-slot topologies is examined for εr = 2. 2 substrate. Results indicate that blind spots are less prevalent in the diamond patch orientation and more prevalent in the E-plane patch orientation which has the most coupling between the array elements. (4) The array patterns of a 17 -element L-probe-fed U-slot microstrip linear phased array are examined at different combinations of uniform and nonuniform excitation and inter-element spacing. Results indicate that using nonuniform excitation and inter-element spacing can reduce the sidelobe levels by over - 10 dB as the array is scanned 60 ° away from broadside. (5) Lastly, the Theory of Characteristic Modes (TCM) is used to characterize the resonant behavior of different microstrip patch shapes, substrates and excitation feeds to realize a microstrip patch antenna design with optimum broadband behavior. Results indicate that a single-layer U-slot rectangular patch on εr = 4. 4 substrate presents a highly radiating structure. Further modal analysis of this single-layer structure with a single T-probe feed shows that VSWR ≤ 2 impedance bandwidth in the order of 96 % can be achieved. Experimental results show VSWR ≤ 2 impedance bandwidth in the order of 71 %. Introduction [...] UWB microstrip patch antenna feed design guidelines [...] Mutual coupling characterization of UWB u-slot antenna array [...] Scan behavior of microstrip phased array antennas [...] UWB enhancement of mocrostrip patch antenna using the theory characteristic modes [...] Conclusion and future work [...] Appendix A. MATLAB cod...|$|R

