5|2184|Public
40|$|Surveillance in wide-area spatial environments is characterised by complex spatial layouts, {{large state}} space, {{and the use}} of {{multiple}} cameras/sensors. To solve this problem, {{there is a need for}} representing the dynamic and noisy data in the tracking tasks, and dealing with them at different levels of detail. This requirement is particularly suited to the Layered <b>Dynamic</b> <b>Probabilistic</b> <b>Network</b> (LDPN), a special type of <b>Dynamic</b> <b>Probabilistic</b> <b>Network</b> (DPN). In this paper, we propose the use of LDPN as the integrated framework for tracking in wide-area environments. We illustrate, with the help of a synthetic tracking scenario, how the parameters of the LDPN can be estimated from training data, and then used to draw predictions and answer queries about unseen tracks at various levels of detail. <br /...|$|E
40|$|In {{this paper}} {{we deal with}} the problem of {{interpreting}} data coming from a dynamic system by using Causal Probabilistic Networks, a probabilistic graphical model particularly appealing in Intelligent Data Analysis. We discuss the different approaches presented in the literature, outlining their pros and cons through a simple training example. Then, we present a new method for reconstructing the state of the dynamic system, based on Markov Chain Monte Carlo algorithms, called <b>Dynamic</b> <b>Probabilistic</b> <b>Network</b> smoothing (DPN-smoothing). Finally, we present an example of the application of DPN-smoothing in the field of signal deconvolution...|$|E
40|$|In {{applications}} such as tracking and surveillance in large spatial environments, {{there is a need}} for representing dynamic and noisy data and at the same time dealing with them at different levels of detail. In the spatial domain, there has been work dealing with these two issues separately, however, there is no existing common framework for dealing with both of them. In this paper, we propose a new representation framework called the Layered <b>Dynamic</b> <b>Probabilistic</b> <b>Network</b> (LDPN), a special type of <b>Dynamic</b> <b>Probabilistic</b> <b>Network</b> (DPN), capable of handling uncertainty and representing spatial data at various levels of detail. The framework is thus particularly suited to applications in wide-area environments which are characterised by large region size, complex spatial layout and multiple sensors/cameras. For example, a building has three levels: entry/exit to the building, entry/exit between rooms and moving within rooms. To avoid the problem of a relatively large state space associated with a large spatial environment, the LDPN explicitly encodes the hierarchy of connected spatial locations, making it scalable to the size of the environment being modelled. There are three main advantages of the LDPN. First, the reduction in state space makes it suitable for dealing with wide area surveillance involving multiple sensors. Second, it offers a hierarchy of intervals for indexing temporal data. Lastly, the explicit representation of intermediate sub-goals allows for the extension of the framework to easily represent group interactions by allowing coupling between sub-goal layers of different individuals or objects. We describe an adaptation of the likelihood sampling inference scheme for the LDPN, and illustrate its use in a hypothetical surveillance scenario...|$|E
40|$|<b>Dynamic</b> <b>probabilistic</b> <b>networks</b> are {{a compact}} {{representation}} of complex stochastic processes. In this paper we examine {{how to learn}} {{the structure of a}} DPN from data. We extend structure scoring rules for standard <b>probabilistic</b> <b>networks</b> to the <b>dynamic</b> case, and showhow to search for structure whensome of the variables are hidden. Finally, we examine two applications where such a technology might be useful: predicting and classifying dynamic behaviors, and learning causal orderings in biological processes. We provide empirical results that demonstrate the applicability of our methods in both domains. 1 Introduction <b>Probabilistic</b> <b>networks</b> (PNs), also known as Bayesian networks or belief networks, are already well-established as representations of domains involving uncertain relations among several random variables. Somewhat less wellestablished, but perhaps of equal importance, are <b>dynamic</b> <b>probabilistic</b> <b>networks</b> (DPNs), which model the stochastic evolution of a set of random v [...] ...|$|R
40|$|<b>Dynamic</b> <b>probabilistic</b> <b>networks</b> are {{a compact}} {{representation}} of complex stochastic processes. In this paper we examine {{how to learn}} {{the structure of a}} DPN from data. We extend structure scoring rules for standard <b>probabilistic</b> <b>networks</b> to the <b>dynamic</b> case, and show how to search for structure when some of the variables are hidden. Finally, we examine two applications where such a technology might be useful: predicting and classifying dynamic behaviors, and learning causal orderings in biological processes. We provide empirical results that demonstrate the applicability of our methods in both domains. ...|$|R
40|$|Stochastic {{simulation}} algorithms for <b>dynamic</b> <b>probabilistic</b> <b>networks</b> Stochastic simulation algorithms such aslikelihood weighting often give fast, accurate approximations to posterior probabilities in <b>probabilistic</b> <b>networks,</b> and are {{the methods}} of choice for very large networks. Unfortunately, the special characteristics of <b>dynamic</b> <b>probabilistic</b> <b>networks</b> (DPNs), which are used to represent stochastic temporal processes, mean that standard simulation algorithms perform very poorly. In essence, the simulation trials diverge further and further from reality as the process is observed over time. In this paper, we present simulation algorithms that use the evidence observed at each time step to push the set of trials back towards reality. The rst algorithm, reversal &quot; (ER) restructures each time slice of the DPN so that the evidence nodes for the slice become ancestors of the state variables. The second algorithm, called of the ttest &quot; sampling (SOF), &quot; the set of trials at each time step using a stochastic reproduction rate weighted by {{the likelihood of the}} evidence according to each trial. We compare the performance of each algorithm with likelihood weighting on the original network, and also investigate the bene ts of combining the ER and SOF methods. The ER/SOF combination appears to maintain bounded error independent of the number of time steps in the simulation...|$|R
40|$|AbstractModeling and {{detecting}} {{bursts in}} data streams {{is an important}} area of research {{with a wide range}} of ap-plications. In this paper, we present a novel method to analyze and identify correlated burst patterns by consider-ing multiple data streams that co-evolve over time. The main technical contribution of our research is the use of a <b>dynamic</b> <b>probabilistic</b> <b>network</b> to model the dependency structures observed within these data streams. Such de-pendencies provide meaningful information concerning the overall system dynamics and should be explicitly integrated into the burst detection process. Using both synthetic sce-narios and two real-world datasets, we compare our method with an existing burst detection algorithm. Initial experi-mental results indicate that our approach allows for more balanced and accurate burst quantification. Factorial HMMs, probabilistic network, burst detection, multiple data streams I...|$|E
40|$|In this paper, we {{consider}} the problem of tracking an object and predicting the object 2 ̆ 7 s future trajectory in a wide-area environment, with complex spatial layout {{and the use of}} multiple sensors/cameras. To solve this problem, {{there is a need for}} representing the dynamic and noisy data in the tracking tasks, and dealing with them at different levels of detail. We employ the Abstract Hidden Markov Models (AHMM), an extension of the well-known Hidden Markov Model (HMM) and a special type of <b>Dynamic</b> <b>Probabilistic</b> <b>Network</b> (DPN), as our underlying representation framework. The AHMM allows us to explicitly encode the hierarchy of connected spatial locations, making it scalable to the size of the environment being modeled. We describe an application for tracking human movement in an office-like spatial layout where the AHMM is used to track and predict the evolution of object trajectories at different levels of detail...|$|E
40|$|<b>Probabilistic</b> <b>networks</b> {{which provide}} compact {{descriptions}} of complex stochastic relationships among several random variables are rapidly becoming the tool {{of choice for}} uncertain reasoning in artificial intelligence We show that networks with fixed structure containing hidden variables can be learned automatically from data using a gradient-descent mechanism {{similar to that used}} in neural networks We alio extend the method to networks with intensionally represented distributions, including networks with continuous variables and <b>dynamic</b> <b>probabilistic</b> <b>networks</b> Because <b>probabilistic</b> <b>networks</b> provide explicit representations of causal structure human experts can easily contribute pnor knowledge to the training process, thereby significantly improving the learning rate Adaptive <b>probabilistic</b> <b>networks</b> (APNs) may soon compete directly with neural networks as models in computational neuroscience as well as in industrial and financial applications...|$|R
40|$|<b>Dynamic</b> <b>probabilistic</b> <b>networks</b> are {{a compact}} {{representation}} of complex stochastic processes. In this paper we examine {{how to learn}} {{the structure of a}} DPN from data. We extend structure scoring rules for standard <b>probabilistic</b> <b>networks</b> to the <b>dynamic</b> case, and show how to search for structure when some of the variables are hidden. Finally, we examine two applications where such a technology might be useful: predicting and classifying dynamic behaviors, and learning causal orderings in biological processes. We provide empirical results that demonstrate the applicability of our methods in both domains. Comment: Appears in Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence (UAI 1998...|$|R
40|$|<b>Probabilistic</b> <b>networks,</b> {{which provide}} compact {{descriptions}} of complex stochastic relationships among several random variables, are rapidly becoming the tool {{of choice for}} uncertain reasoning in artificial intelligence. We show that networks with fixed structure containing hidden variables can be learned automatically from data using a gradient-descent mechanism {{similar to that used}} in neural networks. We also extend the method to networks with intensionally represented distributions, including networks with continuous variables and <b>dynamic</b> <b>probabilistic</b> <b>networks.</b> Because <b>probabilistic</b> <b>networks</b> provide explicit representations of causal structure, human experts can easily contribute prior knowledge to the training process, thereby significantly improving the learning rate. Adaptive <b>probabilistic</b> <b>networks</b> (APNs) may soon compete directly with neural networks as models in computational neuroscience as well as in industrial and financial applications. 1 Introduction Intelligent systems, [...] ...|$|R
40|$|Abstract. In this work, {{we present}} a unified {{bottom-up}} and top-down automatic model selection based approach for modelling complex activities of multiple objects in cluttered scenes. An activity of multiple objects is represented based on discrete scene events and their behaviours are modelled by reasoning about the temporal and causal correlations among different events. This is {{significantly different from the}} majority of the existing techniques that are centred on object tracking followed by trajectory matching. In our approach, object-independent events are detected and classified by unsupervised clustering using Expectation-Maximisation (EM) and classified using automatic model selection based on Schwarz’s Bayesian Information Criterion (BIC). <b>Dynamic</b> <b>Probabilistic</b> <b>Networks</b> (DPNs) are formulated for modelling the temporal and causal correlations among discrete events for robust and holistic scene-level behaviour interpretation. In particular, we developed a Dynamically Multi-Linked Hidden Markov Model (DML-HMM) based on the discovery of salient dynamic interlinks among multiple temporal processes corresponding to multiple event classes. A DML-HMM is built using BIC based factorisation resulting in its topology being intrinsically determined by the underlying causality and temporal order among events. Extensive experiments are conducted on modelling activities captured in different indoor and outdoor scenes. Our experimental results demonstrate that the performance of a DML-HMM on modelling group activities in a noisy and cluttered scene is superior compared to those of other comparable <b>dynamic</b> <b>probabilistic</b> <b>networks</b> including...|$|R
40|$|We {{present an}} {{algorithm}} for arc reversal in Bayesian networks with tree-structured conditional probability tables, and consider {{some of its}} advantages, especially for the simulation of <b>dynamic</b> <b>probabilistic</b> <b>networks.</b> In particular, the method allows one to produce CPTs for nodes involved in the reversal that exploit regularities in the conditional distributions. We argue that this approach alleviates some of the overhead associated with arc reversal, {{plays an important role}} in evidence integration and can be used to restrict sampling of variables in DPNs. We also provide an algorithm that detects the dynamic irrelevance of state variables in forward simulation. This algorithm exploits the structured CPTs in a reversed network to determine, in a timeindependent fashion, the conditions under which a variable does or does not need to be sampled. ...|$|R
40|$|Bayesian {{networks}} {{have been successfully}} applied to the assessment of user properties which remain unchanged during a session. However, many properties of a person vary over time, thus raising new questions of network modeling. In this paper we characterize different types of dependencies that occur in networks that deal with the modeling of temporally variable user properties. We show how existing techniques of applying <b>dynamic</b> <b>probabilistic</b> <b>networks</b> can be adapted for the task of modeling the dependencies in dynamic Bayesian networks. We illustrate the proposed techniques using examples of emergency calls to the fire department {{of the city of}} Saarbr ucken. The fire department officers are experienced in dealing with emergency calls from callers whose available working memory capacity is temporarily limited. We develop a model which reconstructs the officers' assessments of a caller's working memory capacity...|$|R
40|$|<b>Dynamic</b> <b>probabilistic</b> <b>networks</b> (DPNs) are a {{powerful}} and efficient method for encoding stochastic temporal models. In the past, however, their use has been largely confined to the description of uniform temporal processes. In this paper we show how to combine specialized DPN models to represent inhomogeneous processes that progress through a sequence of different stages. We develop a method that takes a set of DPN submodels and a stochastic finite state automaton that defines a legal set of submodel concatenations, and constructs a composite DPN. The composite DPN is shown to represent correctly the intended probability distribution over possible histories of the temporal process. The use of DPNs allows us {{to take advantage of}} efficient, general-purpose inference and learning algorithms and can confer significant advantages over HMMs in terms of statistical efficiency and representational flexibility. We illustrate these advantages in the context of speech recognition. 1 Introduction [...] ...|$|R
40|$|<b>Dynamic</b> <b>Probabilistic</b> <b>Networks</b> (DPNs) are {{exploited}} for modelling the temporal relationships among {{a set of}} different object temporal events in the scene for a coherent and robust scene-level behaviour interpretation. In particular, we develop a Dynamically Multi-Linked Hidden Markov Model (DML-HMM) to interpret group activities involving multiple objects captured in an outdoor scene. The model {{is based on the}} discovery of salient dynamic interlinks among multiple temporal events using DPNs. Object temporal events are detected and labelled using Gaussian Mixture Models with automatic model order selection. A DML-HMM is built using Schwarz’s Bayesian Information Criterion based factorisation resulting in its topology being intrinsically determined by the underlying causality and temporal order among different object events. Our experiments demonstrate that its performance on modelling group activities in a noisy outdoor scene is superior compared to that of a Multi-Observation Hidden Markov Model (MOHMM), a Parallel Hidden Markov Model (PaHMM) and a Couple...|$|R
40|$|The {{problem of}} driving an {{autonomous}} vehicle in highway traffic engages {{many areas of}} AI research and has substantial economic significance. We describe work in progress on {{a new approach to}} this problem based on a decision-theoretic architecture using <b>dynamic</b> <b>probabilistic</b> <b>networks.</b> The architecture provides a sound solution to the problems of sensor noise, sensor failure, and uncertainty about the behavior of other vehicles and about the effects of one's own actions. Our approach has been implemented in a computer simulation system, and the autonomous vehicle successfully negotiates a variety of difficult situations. 1 The BAT Project Several government agencies and corporations in Europe, Japan, and the US are currently undertaking research in IVHS (Intelligent Vehicle and Highway Systems) with the aim of substantially reducing congestion and accidents, which cost $ 500 billion/year and 100, 000 lives/year, respectively. In the near future, several research projects expect to demonst [...] ...|$|R
40|$|We {{present a}} new {{technique}} for time series analysis based on <b>dynamic</b> <b>probabilistic</b> <b>networks.</b> In this approach, the observed data are modeled in terms of unobserved, mutually independent factors, as in the recently introduced technique of Independent Factor Analysis (IFA). However, unlike in IFA, the factors are not i. i. d.; each factor has its own temporal statistical characteristics. We derive a family of EM algorithms that learn {{the structure of the}} underlying factors and their relation to the data. These algorithms perform source separation and noise reduction in an integrated manner, and demonstrate superior performance compared to IFA. 1 Introduction The technique of independent factor analysis (IFA) introduced in [1] provides a tool for modeling L 0 -dim data in terms of L unobserved factors. These factors are mutually independent and combine linearly with added noise to produce the observed data. Mathematically, the model is dened by y t = Hx t + u t; (1) where x t is the v [...] ...|$|R
40|$|<b>Dynamic</b> <b>probabilistic</b> <b>networks</b> (DPNs) are {{a useful}} tool for {{modeling}} complex stochastic processes. The simplest inference task in DPNs is monitoring (aka filtering) task [...] - that is, computing a posterior distribution for the state variables at each time step given all observations up to that time. Recursive, constantspace algorithms are well-known for monitoring in DPNs and other models. This paper is concerned with hindsight (aka smoothing) [...] - that is, computing a posterior distribution given both past and future observations. Hindsight is an essential subtask of learning DPN models from data. Existing algorithms for hindsight in DPNs use O(S 2 T) space and time, where T is the total length of the observation sequence and S is the state space size for each time step. They are therefore impractical for hindsight in complex models with long observation sequences. This paper presents an O(S 2 log T) space, O(S 2 T log T) time hindsight algorithm. We demonstrates the effectiv [...] ...|$|R
40|$|This paper {{examines}} use of <b>dynamic</b> <b>probabilistic</b> <b>networks</b> (DPN) {{for human}} action recognition. The actions of lifting objects and {{walking in the}} room, sitting {{in the room and}} neutral standing pose were used for testing the classification. The research used the dynamic interrelation between various different regions of interest (ROI) on the human body (face, body, arms, legs) and the time series based events related to the these ROIs. This dynamic links are then used to recognize the human behavioral aspects in the scene. First a model is developed to identify the human activities in an indoor scene and this model is dependent on the key features and interlinks between the various dynamic events using DPNs. The sub ROI are classified with DPN to associate the combined interlink with a specific human activity. The recognition accuracy performance between indoor (controlled lighting conditions) is compared with the outdoor lighting conditions. The accuracy in outdoor scenes was lower than the controlled environment. Comment: 7 pages, 4 figure...|$|R
40|$|The BATMobile [1] is one {{approach}} {{to the implementation of}} a system capable of driving autonomously in normal highway traffic. As with human drivers, the BATMobile would be a superior driver if it were able to make predictions about the actions of other drivers, effectively giving it the ability to respond before such actions even occur. The ability to predict driver behavior would also be helpful in the creation of accurate models of traffic behavior used in freeway design and analysis. In this report, we discuss the creation of <b>dynamic</b> <b>probabilistic</b> <b>networks</b> (DPNs) that constitute models of driver behavior. Specifically, we discuss three model structures we have created, the data used to learn the models, and how well the models predict driver behavior. We compare the three models to observe the benefits of modeling hidden state and using deterministic variables. We also analyze the models to see what aspects of driver behavior the models have learned. 1 Introduction The BATMobile [ [...] ...|$|R
40|$|In this work, {{we present}} a unified {{bottom-up}} and top-down automatic model selection based approach for modelling complex activities of multiple objects in cluttered scenes. An activity of multiple objects is represented based on discrete scene events and their behaviours are modelled by reasoning about the temporal and causal correlations among different events. This is {{significantly different from the}} ma-jority of the existing techniques that are centred on object tracking followed by trajectory matching. In our approach, object-independent events are detected and classified by unsupervised clustering us-ing Expectation-Maximisation (EM) and classified using automatic model selection based on Schwarz’s Bayesian Information Criterion (BIC). <b>Dynamic</b> <b>Probabilistic</b> <b>Networks</b> (DPNs) are formulated for mod-elling the temporal and causal correlations among discrete events for robust and holistic scene-level be-haviour interpretation. In particular, we developed a Dynamically Multi-Linked Hidden Markov Model (DML-HMM) based on the discovery of salient dynamic interlinks among multiple temporal processes corresponding to multiple event classes. A DML-HMM is built using BIC based factorisation result-ing in its topology being intrinsically determined by the underlying causality and temporal order among events. Extensive experiments are conducted on modelling activities captured in different indoor an...|$|R
40|$|No sensor {{will deliver}} {{accurate}} information at all times. Many uncertain influences may add noise to sensor readings, or cause a total malfunction of the sensor. To avert these effects, {{and to maintain}} {{the high level of}} safety that {{is an integral part of}} intelligent transportation sys-tems, we propose a fault tolerant supervisory con-trol architecture. It consists of five main modules: sensor validation, sensor fusion, fault diagnosis, haz-ard analysis, and a safety decision maker. Two methods have been identified and developed for these modules. One is based on probability theory, the other on fuzzy logic. The probability approach models the sensors, along with potential failures, as probabilistic events and adaptively esti-mates the probabilities of these events on-line. For this purpose vector <b>dynamic</b> <b>probabilistic</b> <b>networks</b> have been developed, and rules have been derived for inference in these networks. Such networks pro-vide a theoretically sound method for modeling the uncertainty inherent in a system. The process of sensor validation, data fusion, and fault diagnosis is thus converted to a decision-analytic problem, where consistent decisions can be made to maxi-mize expected utility. The fuzzy logic approach makes use of fuzzy time series for predictions, validation gates for fusion, and abductive inference for diagnosis. The fuzzy validation gates are bound by the physical possible changes from one time step to the next. Curves de-noting confidence values for each sensor reading are fitted into the validation gates, which have their maximum value at the predicted value (calculate...|$|R
25|$|Bayesian {{networks}} {{are a very}} general tool {{that can be used}} for a large number of problems: reasoning (using the Bayesian inference algorithm), learning (using the expectation-maximization algorithm), planning (using decision networks) and perception (using <b>dynamic</b> Bayesian <b>networks).</b> <b>Probabilistic</b> algorithms can also be used for filtering, prediction, smoothing and finding explanations for streams of data, helping perception systems to analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).|$|R
40|$|In {{this paper}} we {{introduce}} {{the idea of}} probability {{in the definition of}} a Sequential Dynamical System (SDS), thus obtaining a new concept, that of Probabilistic Sequential System (PSS). Due to its particular <b>dynamic,</b> the <b>Probabilistic</b> Boolean <b>Network</b> (PBN) model has been applied to genetic regulatory networks. The model we introduce combines the sequential aspect of the SDSs and the dynamic of the PBNs. The notion of simulation of a PSS is introduced using the concept of morphism of PSSs. We prove that the PSSs with the PSS-morphisms form a category PSS. Several examples of morphisms, subsystems and simulations are given...|$|R
40|$|Abstract. The paper {{faces the}} {{challenge}} to generalize existing trends and approaches {{in the field of}} artificial intelligence. Under consideration are expert systems, <b>dynamic</b> neural <b>networks,</b> <b>probabilistic</b> reasoning, fuzzy logic, genetic algorithms, multi-agent systems, bio-inspired algorithms, distributed nonlinear computing, chaos-driven pattern recognition. Each approach strengths and limitations are stated without exhaustive treatment to involve specialist from adjacent fields in discussion. The most perspective research directions are revealed and analyzed in reference to Turing’s way in artificial intelligence and beyond. ...|$|R
40|$|In this paper, {{we propose}} a novel Behavioral Information Flow (BIF) model {{which can be}} used to predict how {{information}} is propagated through a complex social network. We consider both the <b>dynamic</b> and <b>probabilistic</b> characteristics of human behavior in receiving and redirecting information. Information can be duplicated without any distortion and send to as many people as the user has in his social network connections. In a sense, this is similar to the epidemic or computer virus propagation. However, previous studies were mostly focused on the overall societal properties. Seldom did previous studies focus on the factors of both personal behavior and network topology. Neither did we see the changing properties of human behavior and probabilistic nature being considered. In this paper, we first propose to model a <b>Dynamic</b> <b>Probabilistic</b> Complex <b>Network</b> as a combination of the state probabilities of user nodes and connection edges and two transition functions that are dependent on the network topology and user properties. Then, we propose to model user transitions as Susceptible-Active-Informed (SAI) states and edge transitions as a Markov Model with Susceptible-Dormant-Active-Removed (SDAR) stages. Based on these modeling methods, we can then predict information flows in a social network. We have applied this model for the applications of finding important people. Our experimental results have demonstrated the effectiveness of the proposed models...|$|R
40|$|In general, a <b>probabilistic</b> <b>network</b> is {{considered}} a representation {{of a set of}} conditional independency statements. However, <b>probabilistic</b> <b>networks</b> also represent dependencies. In this paper an axiomatic characterization of conditional dependence is given. Furthermore, a criterion is given to read conditional dependencies from a <b>probabilistic</b> <b>network...</b>|$|R
40|$|The <b>probabilistic</b> <b>network</b> {{framework}} is {{an approach to}} apply probability theory to reasoning with uncertainty in knowledge-based systems. Whereas researchers have studied the properties of parameter sensitivity analysis for <b>probabilistic</b> <b>networks</b> to quite some extent, evidence sensitivity analysis has received far less attention. The aim of my thesis is to present new, fundamental insights on sensitivity to evidence in <b>probabilistic</b> <b>networks...</b>|$|R
5000|$|... 1971. <b>Dynamic</b> <b>Probabilistic</b> Systems (two volumes), John Wiley & Sons, Inc., New York City.|$|R
40|$|<b>Probabilistic</b> neural <b>network</b> has {{successfully}} solved {{all kinds of}} engineering problems in various fields since it is proposed. In <b>probabilistic</b> neural <b>network,</b> Spread has great influence on its performance, and <b>probabilistic</b> neural <b>network</b> will generate bad prediction results if it is improperly selected. It is difficult to select the optimal manually. In this article, a variant of <b>probabilistic</b> neural <b>network</b> with self-adaptive strategy, called self-adaptive <b>probabilistic</b> neural <b>network,</b> is proposed. In self-adaptive <b>probabilistic</b> neural <b>network,</b> Spread can be self-adaptively adjusted and selected and then the best selected Spread is used to guide the self-adaptive <b>probabilistic</b> neural <b>network</b> train and test. In addition, two simplified strategies are incorporated into the proposed self-adaptive <b>probabilistic</b> neural <b>network</b> {{with the aim of}} further improving its performance and then two versions of simplified self-adaptive <b>probabilistic</b> neural <b>network</b> (simplified self-adaptive <b>probabilistic</b> neural <b>networks</b> 1 and 2) are proposed. The variants of self-adaptive <b>probabilistic</b> neural <b>networks</b> are further applied to solve the transformer fault diagnosis problem. By comparing them with basic <b>probabilistic</b> neural <b>network,</b> and the traditional back propagation, extreme learning machine, general regression neural network, and self-adaptive extreme learning machine, the results have experimentally proven that self-adaptive <b>probabilistic</b> neural <b>networks</b> have a more accurate prediction and better generalization performance when addressing the transformer fault diagnosis problem...|$|R
40|$|Qualitative <b>probabilistic</b> <b>networks</b> {{have been}} {{designed}} for probabilistic reasoning in a qualitative way. As a consequence of their coarse level of representation detail, qualitative <b>probabilistic</b> <b>networks</b> do not provide for resolving trade-offs and typically yield ambiguous results upon inference. We present an algorithm for computing more informative results for unresolved trade-offs. The algorithm builds upon the idea of zooming in on the truly ambiguous part of a qualitative <b>probabilistic</b> <b>network</b> and identifying the information that would serve to resolve the trade-offs present...|$|R
40|$|Fuzziness and {{randomness}} are {{two distinct}} components of uncertainty. While fuzzy sets are a rigorous softening of random sets, {{many of the}} operations de#ned in fuzzy logic lack a complete formalism, and are not strongly supported by experimental evidence. Causal <b>Probabilistic</b> <b>Networks</b> #CPN# or Bayesian networks provide an ultimately #exible inferencemechanism based on Bayesian probability principles. However, CPNs su#er from the overwhelmingly large conditional probability tables with discrete variables. Fuzzi#cation of continuous or crisp variables reduces the size of conditional probability tables to practically acceptable levels and these tables exhaustively encompass all the intuitive and fuzzy rules for inferenceproblems. In this way, we reach a new inference engine, called fuzzy causal <b>probabilistic</b> <b>networks,</b> which provides a rigorous formalism for inference under fuzziness and randomness. Keywords: Causal <b>probabilistic</b> <b>networks,</b> fuzzy logic, fuzzy causal <b>probabilistic</b> <b>networks,</b> [...] ...|$|R
40|$|This {{literature}} review discusses different methods under the general rubric of learning Bayesian networks from data, and includes some overlapping work on more general <b>probabilistic</b> <b>networks.</b> Connections are drawn between the statistical, neural network, and uncertainty communities, {{and between the}} different methodological communities, such as Bayesian, description length, and classical statistics. Basic concepts for learning and Bayesian networks are introduced and methods are then reviewed. Methods are discussed for learning parameters of a <b>probabilistic</b> <b>network,</b> for learning the structure, and for learning hidden variables. The presentation avoids formal definitions and theorems, as these are plentiful in the literature, and instead illustrates key concepts with simplified examples. Keywords [...] - Bayesian networks, graphical models, hidden variables, learning, learning structure, <b>probabilistic</b> <b>networks,</b> knowledge discovery. I. Introduction <b>Probabilistic</b> <b>networks</b> or <b>probabilistic</b> gra [...] ...|$|R
40|$|Semi-qualitative <b>probabilistic</b> <b>networks</b> (SQPNs) merge two {{important}} graphical model formalisms: Bayesian <b>networks</b> and qualitative <b>probabilistic</b> <b>networks.</b> They provade a very Complexity of inferences in polytree-shaped semi-qualitative <b>probabilistic</b> <b>networks</b> and qualitative <b>probabilistic</b> <b>networks.</b> They provide a very general modeling framework {{by allowing the}} combination of numeric and qualitative assessments over a discrete domain, and can be compactly encoded by exploiting the same factorization of joint probability distributions that are behind the bayesian networks. This paper explores the computational complexity of semi-qualitative <b>probabilistic</b> <b>networks,</b> and takes the polytree-shaped networks as its main target. We show that the inference problem is coNP-Complete for binary polytrees with multiple observed nodes. We also show that interferences can be performed in time linear {{in the number of}} nodes if there is a single observed node. Because our proof is construtive, we obtain an efficient linear time algorithm for SQPNs under such assumptions. To the best of our knowledge, this is the first exact polynominal-time algorithm for SQPn. Together these results provide a clear picture of the inferential complexity in polytree-shaped SQPNs. CNP...|$|R
30|$|Nothing {{prevents}} us from defining ad-hoc <b>probabilistic</b> <b>networks</b> {{to estimate}} link probabilities. However, {{by doing so}} we are expected to define a large propositionalized network (a relational Bayesian network) [25] or estimate local <b>probabilistic</b> <b>networks</b> [31]. These approaches do not scale well, since computing probabilistic inference for large networks is expensive.|$|R
