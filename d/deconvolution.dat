8883|54|Public
5|$|In 2005, the {{diameter}} of Eris {{was measured to be}} , using images from the Hubble Space Telescope (HST). The size of an object is determined from its absolute magnitude (H) and the albedo (the amount of light it reflects). At a distance of 97AU, an object with a diameter of 3,000km would have an angular size of 40milliarcseconds, which is directly measurable with the Hubble Space Telescope. Although resolving such small objects is at the very limit of its capabilities, sophisticated image processing techniques such as <b>deconvolution</b> can be used to measure such angular sizes fairly accurately.|$|E
5|$|In ES MS spectrum, a given {{oligonucleotide}} {{generates a}} set of ions that correspond to different ionization states of the compound. Thus, the oligonucleotide with molecular mass M generates ions with masses (M– nH)/n where M is the molecular mass of the oligonucleotide {{in the form of}} a free acid (all negative charges of internucleosidic phosphodiester groups are neutralized with H+), n is the ionization state, and H is the atomic mass of hydrogen (1 Da). Most useful for characterization are the ions with n ranging from 2 to 5. Software supplied with the more recently manufactured instruments is capable of performing a <b>deconvolution</b> procedure that is, it finds peaks of ions that belong to the same set and derives the molecular mass of the oligonucleotide.|$|E
5|$|The {{effect of}} the mirror flaw on {{scientific}} observations depended on the particular observation—the core of the aberrated PSF was sharp enough to permit high-resolution observations of bright objects, and spectroscopy of point sources was only affected through a sensitivity loss. However, the loss of light to the large, out of focus halo severely reduced {{the usefulness of the}} telescope for faint objects or high-contrast imaging. This meant that nearly all of the cosmological programs were essentially impossible, since they required observation of exceptionally faint objects. NASA and the telescope became the butt of many jokes, and the project was popularly regarded as a white elephant. For instance, in the 1991 comedy , Hubble was pictured with the Lusitania, the Hindenburg, and the Edsel. Nonetheless, during {{the first three years of}} the Hubble mission, before the optical corrections, the telescope still carried out a large number of productive observations of less demanding targets. The error was well characterized and stable, enabling astronomers to partially compensate for the defective mirror by using sophisticated image processing techniques such as <b>deconvolution.</b>|$|E
25|$|Post-capture {{manipulation}} of the image is ignored. Sharpening via techniques such as <b>deconvolution</b> or unsharp mask can increase the apparent sharpness in the final image; conversely, image noise reduction can reduce sharpness.|$|E
25|$|A model {{based on}} {{electron}} crystallographic density and {{nuclear magnetic resonance}} <b>deconvolution</b> has been proposed to explain the binding of docetaxel to β-tubulin. In this T-shaped/butterfly model, a deep hydrophobic cleft exists near {{the surface of the}} β-tubulin where three potential hydrogen bonds and multiple hydrophobic contacts bind to docetaxel. The hydrophobic pocket walls contain helices H1, H6, H7 and a loop between H6 and H7 that form hydrophobic interactions with the 3’-benzamido phenyl, 3’-phenyl, and the 2-benzoyl phenyl of docetaxel. 3’-phenyl also has contact with β-sheets B8 and B10. The C-8 methyl of docetaxel has Van der Waals interactions with two residues, Thr-276 and Gln-281 near the C-terminal end of β-tubulin. Docetaxel’s O-21 experiences electrostatic attraction to Thr-276 and the C-12 methyl has proximity with Leu-371 on the loop between B9 and B10.|$|E
500|$|On February 11, 2005, Deep Impacts rockets {{were fired}} as planned {{to correct the}} spacecraft's course. This {{correction}} was so precise that the next planned correction maneuver on March 31, 2005 was unnecessary and canceled. The [...] "commissioning phase" [...] verified that all instruments were activated and checked out. During these tests {{it was found that}} the HRI images were not in focus after it underwent a bake-out period. After mission members investigated the problem, on June 9, 2005, it was announced that by using image processing software and the mathematical technique of <b>deconvolution,</b> the HRI images could be corrected to restore much of the resolution anticipated.|$|E
2500|$|Where [...] is the {{additive}} noise. Knowing {{this point}} spread function {{means that it}} is possible to reverse this process to a certain extent by computer-based methods commonly known as <b>deconvolution</b> microscopy. There are various algorithms available for 2D or 3D <b>deconvolution.</b> They can be roughly classified in nonrestorative and restorative methods. While the nonrestorative methods can improve contrast by removing out-of-focus light from focal planes, only the restorative methods can actually reassign light to its proper place of origin. Processing fluorescent images in this manner can be an advantage over directly acquiring images without out-of-focus light, such as images from confocal microscopy, because light signals otherwise eliminated become useful information. For 3D <b>deconvolution,</b> one typically provides a series of images taken from different focal planes (called a Z-stack) plus the knowledge of the PSF, which can be derived either experimentally or theoretically from knowing all contributing parameters of the microscope.|$|E
2500|$|A {{wide range}} of fluorophores {{can be used as}} labels in flow cytometry. Fluorophores, or simply [...] "fluors", are {{typically}} attached to an antibody that recognizes a target feature on or in the cell; they may also be attached to a chemical entity with affinity for the cell membrane or another cellular structure. Each fluorophore has a characteristic peak excitation and emission wavelength, and the emission spectra often overlap. Consequently, the combination of labels which can be used depends on the wavelength of the lamp(s) or laser(s) used to excite the fluorochromes and on the detectors available. The maximum number of distinguishable fluorescent labels is thought to be 17 or 18, and this level of complexity necessitates laborious optimization to limit artifacts, as well as complex <b>deconvolution</b> algorithms to separate overlapping spectra. Flow cytometry uses fluorescence as a quantitative tool; the utmost sensitivity of flow cytometry is unmatched by other fluorescent detection platforms such as confocal microscopy. Absolute fluorescence sensitivity is generally lower in confocal microscopy because out-of-focus signals are rejected by the confocal optical system and because the image is built up serially from individual measurements at every location across the cell, reducing the amount of time available to collect signal.|$|E
5000|$|In image processing, blind <b>deconvolution</b> is a <b>deconvolution</b> {{technique}} that permits {{recovery of the}} target scene from a single or set of [...] "blurred" [...] images {{in the presence of}} a poorly determined or unknown point spread function (PSF).Regular linear and non-linear <b>deconvolution</b> techniques utilize a known PSF. For blind <b>deconvolution,</b> the PSF is estimated from the image or image set, allowing the <b>deconvolution</b> to be performed. Researchers have been studying blind <b>deconvolution</b> methods for several decades, and have approached the problem from different directions.|$|E
5000|$|Seismic data, or a seismogram, may be {{considered}} as a convolution of the source wavelet, the reflectivity and noise. Its <b>deconvolution</b> is usually implemented as a convolution with an inverse filter. Various well-known <b>deconvolution</b> techniques already exist for one dimension, such as predictive <b>deconvolution,</b> Kalman filtering and deterministic <b>deconvolution.</b> In multiple dimensions, however, the <b>deconvolution</b> process is iterative due to the difficulty of defining an inverse operator. The output data sample may be represented as: ...|$|E
50|$|Most of {{the work}} on blind <b>deconvolution</b> started in early 1970s. Blind <b>deconvolution</b> is used in astronomical imaging and medical imaging.|$|E
50|$|In mathematics, <b>de{{convolution}}</b> is an algorithm-based process used {{to reverse}} the effects of convolution on recorded data. The concept of <b>deconvolution</b> is widely used in the techniques of signal processing and image processing. Because these techniques are in turn widely used in many scientific and engineering disciplines, <b>deconvolution</b> finds many applications.|$|E
5000|$|<b>Deconvolution</b> - Small {{fluorescent}} microspheres (<200 nanometers) {{are required}} to obtain an experimental Point spread function to characterise microscopes and perform image <b>deconvolution</b> ...|$|E
50|$|The Wiener <b>deconvolution</b> {{method has}} {{widespread}} use in image <b>deconvolution</b> applications, as the frequency spectrum of most visual images is fairly well behaved {{and may be}} estimated easily.|$|E
5000|$|In {{electrical}} engineering and applied mathematics, blind <b>deconvolution</b> is <b>deconvolution</b> without explicit {{knowledge of the}} impulse response function used in the convolution. This is usually achieved by making appropriate assumptions of the input to estimate the impulse response by analyzing the output. Blind <b>deconvolution</b> is not solvable without making assumptions on input and impulse response. Most of the algorithms {{to solve this problem}} are based on assumption that both input and impulse response live in respective known subspaces. However, blind <b>deconvolution</b> remains very challenging non-convex optimization problem even with this assumption.|$|E
5000|$|<b>Deconvolution</b> {{is usually}} {{performed}} by computing the Fourier Transform of the recorded signal h and {{the transfer function}} g, apply <b>deconvolution</b> in the Frequency domain, which {{in the case of}} absence of noise is merely: ...|$|E
50|$|In recent years, Alain Gringarten {{spent a lot}} of time in {{research}} of <b>deconvolution</b> as a well-interpretation tool. He is one of the main contributors in establishing a stable algorithm of <b>deconvolution</b> as a least squares mathematical problem.|$|E
50|$|When the PSF is unknown, {{it may be}} {{possible}} to deduce it by systematically trying different possible PSFs and assessing whether the image has improved. This procedure is called blind <b>deconvolution.</b> Blind <b>deconvolution</b> is a well-established image restoration technique in astronomy, where the point nature of the objects photographed exposes the PSF thus making it more feasible. It is also used in fluorescence microscopy for image restoration, and in fluorescence spectral imaging for spectral separation of multiple unknown fluorophores. The most common iterative algorithm for the purpose is the Richardson-Lucy <b>deconvolution</b> algorithm; the Wiener <b>deconvolution</b> (and approximations) are the most common non-iterative algorithms.For some specific imaging systems such as laser pulsed terahertz systems, PSF can be modeled mathematically. As a result, as shown in the figure, <b>deconvolution</b> of the modeled PSF and the terahertz image can give a higher resolution representation of the terahertz image.|$|E
50|$|In mathematics, Wiener <b>deconvolution</b> is an {{application}} of the Wiener filter to the noise problems inherent in <b>deconvolution.</b> It works in the frequency domain, attempting to minimize the impact of deconvolved noise at frequencies which have a poor signal-to-noise ratio.|$|E
5000|$|<b>Deconvolution</b> is {{a process}} that tries to extract the {{reflectivity}} series of the Earth, under the assumption that a seismic trace is just the reflectivity series of the Earth convolved with distorting filters. [...] This process improves temporal resolution by collapsing the seismic wavelet, but it is nonunique unless further information is available such as well logs, or further assumptions are made. <b>Deconvolution</b> operations can be cascaded, with each individual <b>deconvolution</b> designed to remove a particular type of distortion.|$|E
50|$|For <b>deconvolution</b> to be effective, all {{variables}} in the image scene and capturing device need to be modeled, including aperture, focal length, distance to subject, lens, and media refractive indices and geometries. Applying <b>deconvolution</b> successfully to general-purpose camera images is usually not feasible, because the geometries of the scene are not set. However, <b>deconvolution</b> is applied in reality to microscopy and astronomical imaging, where the value of gained sharpness is high, imaging devices and the relative subject positions are both well defined, and the imaging devices would cost {{a great deal more}} to optimize to improve sharpness physically. In cases where a stable, well-defined aberration is present, such as the lens defect in early Hubble Space Telescope images, <b>deconvolution</b> is an especially effective technique.|$|E
50|$|Wiener <b>deconvolution</b> {{is named}} after Norbert Wiener.|$|E
50|$|Computing {{the inverse}} of the {{convolution}} operation {{is known as}} <b>deconvolution.</b>|$|E
5000|$|... #Caption: From left: Original image, blurred image, image deblurred using Wiener <b>deconvolution.</b>|$|E
50|$|The first {{approach}} uses correct mathematical <b>deconvolution</b> {{that takes}} {{account of the}} known aperture design pattern; this <b>deconvolution</b> can identify where and by what degree the scene has become convoluted by out of focus light selectively falling on the capture surface, and reverse the process. Thus the blur-free scene may be retrieved together {{with the size of}} the blur.|$|E
5000|$|Convex {{constraint}} analysis - A natural <b>deconvolution</b> of circular-dichroism {{curves of}} proteins (1991) ...|$|E
50|$|Sometimes, {{motion blur}} {{can be removed}} from images {{with the help of}} <b>deconvolution.</b>|$|E
50|$|<b>Deconvolution</b> of imaged data is {{essential}} for accurate 3D reconstructions. <b>Deconvolution</b> is an image restoration approach where 'a priori' knowledge of the optical system {{in the form of}} a point spread function (PSF) is used to obtain a better estimate of the object. A point spread function can be either calculated from the actual microscope parameters, measured with beads, or estimated and iteratively refined (<b>Deconvolution).</b> PSFs can be adjusted locally to account for variations in refractive characteristics of the tissue with depth and sample characteristics. For automated use with large, tiled tissue blocks, this is faster and more accurate than using an experimentally determined PSF.|$|E
50|$|See: Linear transformation, Harmonic analysis, Linear filter, Wavelet, Principal {{component}} analysis, Independent component analysis, <b>Deconvolution.</b>|$|E
50|$|There {{are three}} main {{processes}} in seismic data processing: <b>deconvolution,</b> common-midpoint (CMP) stacking and migration.|$|E
5000|$|... #Caption: <b>Deconvolution</b> {{image of}} U2OS cells stained with {{fluorescent}} phalloidin {{taken on a}} confocal microscope.|$|E
50|$|This filter is {{frequently}} {{used in the}} process of deconvolution; for this application, see Wiener <b>deconvolution.</b>|$|E
50|$|<b>Deconvolution</b> {{has been}} applied {{extensively}} to absorption spectra. The Van Cittert algorithm (in German) may be used.|$|E
5000|$|... #Caption: Application of PSF: <b>Deconvolution</b> of the mathematically modeled PSF and the low-resolution image {{enhances the}} resolution.|$|E
5000|$|Best Paper Honorable Mention: Understanding and {{evaluating}} blind <b>deconvolution</b> algorithms, Anat Levin, Yair Weiss, Fredo Durand, Bill Freeman ...|$|E
5000|$|In general, the {{objective}} of <b>deconvolution</b> {{is to find the}} solution of a convolution equation of the form: ...|$|E
