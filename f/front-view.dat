62|4|Public
5000|$|... #Caption: The <b>front-view</b> of Padmanabhaswamy Temple in Thiruvananthapuram, Kerala ...|$|E
5000|$|... #Caption: <b>Front-view</b> of Kerala Sangeetha Nataka Academy in Thrissur ...|$|E
50|$|While {{unique in}} appearances, its {{gameplay}} is a customary {{one for a}} role-playing game; buying items in shops, equipping gadgets, random encounters, boss battles, leveling up, explorations, communicating with townspeople, and so forth. Its battle system is the default one of RPG Tsukūru 95 so that battles are operated in a <b>front-view,</b> turn-based fashion that resembles to that of SNES Dragon Quest games.|$|E
40|$|A {{high quality}} 3 D display {{requires}} a high amount of optical information throughput, which needs an appropriate mechanism to distribute information in space uniformly and efficiently. This study proposes a <b>front-viewing</b> system which {{is capable of}} managing the required amount of information efficiently from a high bandwidth source and projecting 3 D images with a decent size and a large viewing angle at video rate in full colour. It employs variable gratings to support a high bandwidth distribution. This concept is scalable and the system can be made compact in size. A horizontal parallax only (HPO) proof-of-concept system is demonstrated by projecting holographic images from a digital micro mirror device (DMD) through rotational tiled gratings before they are realised on a vertical diffuser for <b>front-viewing.</b> This work was supported by Huawei Innovation Research Program FLAGSHIP (HIRP FLAGSHIP) project at University of Cambridge...|$|R
40|$|Reading facial {{emotion is}} {{disrupted}} by both psychopathology, such as autism, and altered function of neurotransmitter, such as serotonin. These effects could result from reduced sensitivity of emotional processing systems to facial emotion. The impact of facial expression is also greater when personally directed than when averted. We therefore hypothesized that brain activity associated with emotional representation, {{would be more}} susceptible to manipulation of serotonin function by Acute Tryptophan Depletion (ATD) for <b>front-viewed</b> than side-viewed faces, measured using functional imaging (fMRI). ATD reduced activity independent of face view in left superior temporal sulcus (STS) and anterior cingulate. In temporal pole, medial frontal cortex and orbitofrontal cortex, ATD also reduced activity, but specifically for <b>front-viewed</b> faces. In right STS, ATD increased activity, but specifically for side-viewed faces. Activity in the amygdalae depended on face view and emotion type. We suggest that engagement of empathic and associative learning functions when viewing faces is facilitated by direct facial view and intact serotonin transmission. Averted faces, and reduced serotonin function facilitate attention to the external goal of gaze. These changes could be adaptive in a threatening context and markedly affect empathic function in conditions associated with impaired serotonin function, such as depression and autism...|$|R
40|$|Endoscopic biliary {{drainage}} {{has been}} established to provide effective treatment for acute obstructive jaundice and cholangitis. A recently developed ultrathin transnasal videoendoscope (TNE) is minimally invasive even for critically ill patients and can be performed without conscious sedation. Transnasal endoscopic biliary drainage (TNE-BD) is performed using a <b>front-viewing</b> TNE with approximately 5 mm outer diameter and 2 mm working channel diameter. Finally, 5 F naso-biliary tube or plastic stent are placed. Technical success rates are approximately 100 % and 70 % for post-endoscopic sphincterotomy or placement of self-expandable metallic stent, and intact papilla, respectively. There are no serious complications. In conclusion, although further cases should be accumulated, TNE-BD and in particular, one-step naso-biliary drainage using TNE may be a useful and novel technique {{for the treatment of}} acute cholangitis...|$|R
5000|$|The default battle {{system in}} RPG Maker VX is an update of the <b>front-view</b> battle system seen in RPG Maker 2000 ("Dragon Warrior" [...] style), {{which does not}} allow for {{character}} graphics. However, user-made add-on scripts exist that change the battle system; side-view battles reminiscent of Final Fantasy, real time battle systems and even tactical battle systems may all be implemented by the user.|$|E
50|$|A typical {{mug shot}} is two-part, with one side-view photo, and one <b>front-view.</b> The {{background}} is usually stark and simple, to avoid distraction from the facial image (as distinguished from a casual snapshot {{in a more}} naturalistic setting). Mug shots may be compiled into a mug book {{in order to determine}} the identity of a criminal. In high-profile cases, mug shots may also be published in the mass media.|$|E
50|$|The RPG Maker {{interface}} {{was somewhat}} user-friendly, and battles were <b>front-view</b> style only. Item, Monster, Skill/Magic, and Dungeons {{had a small}} limit cap, as did the effects of any given Item, Magic or Skill (9,999). Items were all inclusive; Weapons and Armors were created in the Items interface. The types of items were as follows: None (mainly used for Key Items), Weapon, Armor, Key (up to 8 sub types), Magic (for binding Magic created in the Magic interface to an item), Healing, and Food (which raises stats and more interestingly, EXP or Experience Points in which this particular software {{is the only one}} of the series to do so natively).|$|E
40|$|BACKGROUND: Body size {{scales are}} a common method for {{diagnosing}} body image disturbances and assessing the cultural valorisation of stoutness, a phenomenon that {{plays a role in}} the development of overweight, especially among African populations. Traditionally, body size scales present a front view. In this study, we evaluated a complementary model of representing body shape: the side view of body outlines. In particular, we examined the association between the side-view and a set of bio-anthropometric indices in men and women. METHODS: To cover the inter-ethnic variability in the Niger-Congo area, we selected a balanced sex-ratio sample of 80 Cameroonians and 81 Senegalese. Individuals wearing close-fitting clothes were photographed from the front-and side-view, and measured following a bio-anthropometric protocol synthesizing body shape variation: Body Mass Index, percentage body fat, somatotype profile, waist circumference, waist-to-hip ratio, mean blood pressure and glycaemia. The shape of each front and side body outline was extracted and characterised by Normalized Elliptic Fourier Descriptors (NEFD). Finally, we assessed associations between NEFD and bio-anthropometric indices. RESULTS: Variation in the shape of both front and side body outlines was associated with all bio-anthropometrics for at least one sex-population combination. Overall, the side view best captured body shape variation related to changes in almost all bio-anthropometrics in both sexes and populations, with the exceptions of female mesomorphy, male blood pressure and glycaemia (in both sexes). We found that the details of the relationship between bio-anthropometrics and body shape differed between the two male populations, a finding that was reflected in side-views for all criteria, but not <b>front-views.</b> CONCLUSIONS: Variation in body shape assessed by several bio-anthropometrics related to health and nutritional status was larger for side than front body outlines. Integrating side views in body size scales would improve the accuracy of body size assessment and thus, the assessment of behaviours leading to overweight, as well as symptoms of body image disturbances, in Africa and potentially in other populations...|$|R
50|$|This picture shows a {{scene where}} a small head, in profile, sees an object and begins to talk happily about it, his {{speaking}} expressed by a cello playing. Another man comes next to him, facing him, and sees the object as well. He discusses it with him, but the two heads soon begin arguing harshly. A pillar grows {{out from under the}} left head, making him sit above the other. He responds by growing another column underneath him, and the two heads quickly try to one-up each other, their columns growing and their arguing becoming worse. Soon, they can't go any higher, and push themselves into each other, forming a babbling head in <b>front-view.</b> The scene zooms out to show dozens of these heads on high columns, chattering away. Beauty's vision ends here, and he bows to the other two.|$|E
50|$|RPG Maker XP, also {{referred}} to as RMXP, is the first RPG Maker which can use Ruby, making it the most powerful, programming-wise. However, many normal, simplified features present in RM2k(3) have been removed. Most of these features, however, have been programmed with Ruby, and distributed online. RMXP runs at 1024x768 resolution (though games made in it run at 640x480), while offering four times the playable area of its predecessors. Additionally, it allows greater user control over sprite size (there is no specific image size regulation for sprite sheets) and other aspects of game design. This more open-ended arrangement, coupled with the inclusion of the Ruby Game Scripting System (RGSS), makes RPG Maker XP more versatile than older versions in the series, at the cost of a steeper learning curve. Upon the release of Windows Vista, many users experienced compatibility problems, although the fix was relatively simple..XP used a <b>front-view</b> non-sprite battle system that allowed for the use of Battle backgrounds (Battlebacks). Both characters and enemies had static battle sprites, and the interface was quite simple.|$|E
40|$|Evolutionary {{accounts}} of the centrality of social interaction for our species might anticipate more efficient affective processing for faces. The current study assessed whether mere exposure to upright faces resulted in greater generalization of liking than mere exposure to inverted faces, as might be predicted by special-process views of face perception. We presented upright and inverted photographs of faces taken from three different horizontal angles (full <b>front-view,</b> 45 -degree, and full-profile), then asked participants to rate their liking for <b>front-view</b> photographs of the same faces. For inverted faces, but not upright faces, {{there was a significant}} linear trend for liking to decrease as presentation angle increased (from <b>front-view</b> through 45 -degree to full-profile). Thus, upright <b>front-view</b> faces that had previously been presented in full-or semi-profile were liked at equivalent levels to upright <b>front-view</b> faces that had previously been presented in <b>front-view.</b> These findings suggest that mere exposure for upright faces presented at any angle may easily generalize to other views of the face, but that generalization is less efficient for perceptually matched inverted faces. These findings are consistent with evolutionary arguments for enhanced affective discrimination. ...|$|E
30|$|We {{propose a}} novel CNN {{architecture}} with triple input and the doubly convolutional layer which both are {{adapted to the}} characteristics of refrigerator <b>front-view</b> images.|$|E
30|$|As an {{emerging}} problem, image-based automatic classification {{of the refrigerator}} is of great importance because it can potentially provide a valuable tool for industrial automation of refrigerator. There have been various machine-learning-based image classification methods proposed in industrial automation. However, {{none of them was}} designed for the automatic classification of the refrigerator, which mainly relies on human’s visual system at present. The machine-learning-based classification methods can be roughly divided into two categories, including classifier combined with handcrafted features and automatically extracted features. With experiments, we respectively testify the support vector machine (SVM)-based methods [5 – 8] and CNN-based methods, in which the <b>front-view</b> image of the refrigerator is exploited due to the rich information captured by this image in recognizing and differentiating refrigerators. Experimental results show that the CNN-based methods outperform the state-of-the-art SVM-based methods with handcrafted features. Both SVM-based methods and CNN-based methods are effective in the classification of refrigerator <b>front-view</b> images. However, we observe fundamental challenges in the <b>front-view</b> image of the refrigerator, including the dense clutter, varying backgrounds, large homogeneous areas, sparse salient regions, and the specular reflection.|$|E
40|$|The primary {{objective}} of this research work is to develop an efficient and intuitive deformation technique for virtual human modeling by silhouettes input. With our method, the reference silhouettes (the <b>front-view</b> and right-view silhouettes of the synthetic human model) and the target silhouettes (the <b>front-view</b> and right-view silhouettes of the human from the photographs) are used to modify the synthetic human model, which is represented by a polygonal mesh. The system moves the vertices of the polygonal model so that the spatial relation between the original positions and the reference silhouettes {{is identical to the}} relation between the resulting positions and the target silhouettes. Our method is related to the axial deformation. The self-intersection problem is solved...|$|E
30|$|Our {{method is}} {{employed}} to classify refrigerator {{according to the}} <b>front-view</b> images of the refrigerator. From the observation, we have found various challenges in the images. Aiming at solving these difficulties, we propose a novel CNN architecture as described in Section 2.2.|$|E
30|$|In this paper, {{we propose}} a CNN-based image {{classification}} method {{based on the}} <b>front-view</b> images of the refrigerator {{to cope with the}} present challenges including dense clutter, varying background, large homogeneous areas, and specular reflection. Our experimental results validate the ability of the proposed technique in solving the refrigerator classification task in practical industrial automation.|$|E
40|$|Abstract — We {{present a}} new method for <b>front-view</b> gait {{biometrics}} {{which uses a}} single non-calibrated camera and extracts unique signatures from descriptors of a silhouette’s deformation. The proposed approach is particularly suitable for identification by gait in the real world, where the advantages of completely unobtrusiveness, remoteness and covertness of the biometric system preclude the availability of camera information and where the CCTV images usually present subjects from an upper <b>front-view.</b> Tests on three different gait databases with subjects walking towards the camera have been performed. The obtained results, with mean CCR of 96. 3 %, show that gait recognition of individuals observed the front can be achieved without any knowledge of camera parameters. Moreover, the method {{has been applied to}} three different walking directions and the results have been compared with the algorithms found in literature. The performance of the proposed system is particularly encouraging for its appliance in surveillance scenarios. I...|$|E
40|$|Abstract. Face {{recognition}} under varying pose is {{a challenging}} problem, especially when illumination variations are also present. Under Lambertian model, spherical harmonics representation {{has proved to}} be effective in modelling illumination variations for a given pose. In this paper, we extend the spherical harmonics representation to encode pose information. More specifically, we show that 2 D harmonic basis images at different poses are related by close-form linear combinations. This enables an analytic method for generating new basis images at a different pose which are typically required to handle illumination variations at that particular pose. Furthermore, the orthonormality of the linear combinations is utilized to propose an efficient method for robust face recognition where only one set of <b>front-view</b> basis images per subject is stored. In the method, we directly project a rotated testing image onto the space of <b>front-view</b> basis images after establishing the image correspondence. Very good recognition results have been demonstrated using this method. ...|$|E
40|$|Prosopagnosia {{has largely}} been {{regarded}} as an untreatable disorder. However, recent case studies using cognitive training have shown {{that it is possible}} to enhance face recognition abilities in individuals with developmental prosopagnosia. Our goal was to determine if this approach could be effective in a larger population of developmental prosopagnosics. We trained 24 develop-mental prosopagnosics using a 3 -week online face-training program targeting holistic face processing. Twelve subjects with developmental prosopagnosia were assessed before and after training, and the other 12 were assessed before and after a waiting period, they then performed the training, and were then assessed again. The assessments included measures of <b>front-view</b> face discrimination, face discrimination with view-point changes, measures of holistic face processing, and a 5 -day diary to quantify potential real-world improvements. Compared with the waiting period, developmental prosopagnosics showed moderate but significant overall training-related improvements on measures of <b>front-view</b> face discrimination. Those who reached the more difficult levels of training (‘better ’ trainees) showed the strongest improvements in <b>front-view</b> face discrimination and showed significantly increased holistic face processing to the point of being similar to that of unimpaired control subjects. Despite challenges in characterizing developmental prosopagnosics ’ everyday face recognition and potential biases in self-report, results also showed modest but consistent self-reported diary improvements. In summary, we demonstrate that by using cognitive training that targets holistic processing, it is possible to enhance face perception across a group of developmental prosopagnosics and further suggest that those who improved the most on the training task received the greates...|$|E
30|$|Specular reflection. Due to {{the mirror}} {{surfaces}} of the refrigerators, noticeable effects of specular reflection are observed in the captured images. Two refrigerators of the same classification are shown in Fig.  4; there is more apparent specular reflection shown {{on the surface of}} the left refrigerator than the right refrigerator. It would produce redundant information of the surroundings in the <b>front-view</b> images of the refrigerator.|$|E
40|$|Photograph of {{a drawing}} by Vischer of Geyser Gulch and Pluton Creek, Sonoma, 1858 - 1866. Caption: "The geysers. <b>Front-view</b> of Geyser Gulch, and Pluton-Creek, {{from the hills}} near the hotel (Mountain of Fire), Sonoma C[oun]ty, Vischer". Riders on horseback race along a dirt road leading from a small {{building}} which is near a few grazing cattle and people. Rolling hills rise in the background...|$|E
40|$|Abstract—Following the {{paradigm}} shift where physical controls {{are replaced by}} touch-enabled surfaces, we report on an experimental evaluation of a user interface concept that allows touchscreen-based panels to be manipulated partially blindly (aircrafts, cars). The proposed multi-touch interaction strategy – involving visual <b>front-view</b> feedback to the user from {{a copy of the}} peripheral panel being manipulated – compares favourably against trackballs or head-down interactions...|$|E
40|$|Abstract. In {{order for}} the {{effective}} recognition of face in the videos of complex environments, this paper presents an algorithm of face tracking of robust. Basing on the rigid constraints, this algorithm generates the potential rectangular area of face tracking,generates the isosceles triangle for the <b>front–view</b> images, generates the right angled triangle for the side images, and reaches the effective rate as 98. 18 % of face recognition in different sizes, lightings, poses,expressions and even under different noises...|$|E
30|$|In this paper, {{we present}} {{a useful tool for}} {{classifying}} refrigerator based on images taken from its front view, which is accomplished by using a novel CNN architecture adapted to the specialty of refrigerator images. Our approach is data driven and free from handcrafted image features. It leverages a training process to automatically extract multi-scale image features which combine both the local and global characteristics of the refrigerator <b>front-view</b> image. The mapping between the refrigerator and its corresponding category, which is learned from these features, offers a function to automatically specify the classification of a refrigerator given a new input image. The proposed CNN architecture takes triple images as input, from which a triplet loss (similarity loss) is produced. Meanwhile, the traditional convolution layer is modified into a doubly convolutional layer in our proposed CNN architecture. The details of triplet loss and the doubly convolutional layer will be fully discussed in Section 2. Our experimental results from 31, 247 refrigerator <b>front-view</b> images of 30 categories show that the proposed CNN architecture produces an impressive classification accuracy of 99.96 %, which is considerably better than conventional classification techniques.|$|E
30|$|As {{mentioned}} in Section 2.2, {{the local and}} global features are automatically extracted by our proposed CNN. Similar to human’s visual system, our proposed CNN can extract the global features including the color, shape of the refrigerators and the local features from the display, crack, ice maker, and handle of the refrigerators. The global features integrated with local features form a layout for each category of refrigerators. The whole layout is utilized to establish the mapping between the input <b>front-view</b> image of the refrigerator and the output classification label.|$|E
40|$|This paper dawribcs a {{new face}} {{identification}} algo-rithm with two stages. This fitst stage monitors a sequence of face images to select a desired frame for identification and Face identification is performed in the second stage. The face identification algorithm is hased on the geometric parameters of size and distance of the facia [feature ohjwts (the eyes, the nose. the mouth. etc) The frame selection of the <b>front-view</b> face from a se-quence of motion images is effectively executed by a simple calculation. Experimental resuhs have verified that this face identification algorithm can improve the man-machine interface to become friendly in a security system. ...|$|E
40|$|Abstract—This {{contribution}} {{consists of}} a frame-rate, vision-based, on-board method which detects vehicles within the attentional visual area of the driver. The method herein uses the 3 D absolute gaze point of the driver obtained through the combined use of a <b>front-view</b> stereo imaging system and a non-contact 3 D gaze tracker, alongside hypothesis-generation reducing techniques for vehicular detection such as horizon line detection. Trained AdaBoost classifiers {{are used in the}} detection process. This technique is {{the first of its kind}} in that it identifies vehicles the driver is most likely to be aware of at any moment while in the act of driving. I...|$|E
30|$|A first {{evaluation}} of the system was performed at the LIPS' 08 lipsync challenge [34]. With minor corrections, it winned the intelligibility test at the next LIPS' 09 challenge. The trainable trajectory formation model PHMM, the shape and appearance models were parameterized using OC data. The texture model was trained using the <b>front-view</b> images from the corpus with thousands of beads (see left part of Figure 2 (b)). The system was rated closest to the original video considering both audiovisual consistency and intelligibility. It was ranked second for audiovisual consistency and {{very close to the}} winner. Concerning intelligibility, several systems outperformed the original video. Our system offers the same visual benefit as the natural video is not less not more.|$|E
40|$|Traffic sign {{detection}} and recognition systems are essential components of Advanced Driver Assistance Systems and self-driving vehicles. In this contribution {{we present a}} vision-based framework which detects and recognizes traffic signs inside the attentional visual field of drivers. This technique {{takes advantage of the}} driver 2 ̆ 7 s 3 D absolute gaze point obtained through the combined use of a <b>front-view</b> stereo imaging system and a non-contact 3 D gaze tracker. We used a linear Support Vector Machine as a classifier and a Histogram of Oriented Gradient as features for detection. Recognition is performed by using Scale Invariant Feature Transforms and color information. Our technique detects and recognizes signs which are in the field of view of the driver and also provides indication when one or more signs have been missed by the driver...|$|E
40|$|Profile face silhouettes have {{recently}} been used to generate a behaviorally validated face space. An important method for studying perceptual spaces is the elicitation of aftereffects, shifts in perceptual judgments that occur after prolonged exposure to stimuli that occupy one locus in the perceptual space. Here we show that face silhouettes elicit gender aftereffects (changes in gender judgments following exposure to gendered faces) in a rapid, implicit adaptation paradigm. Further, we observe that these aftereffects persist across image transformations that preserve the perception of a silhouette as a face but not across transformations that disrupt it. Moreover, the aftereffects transfer between two-tone, profile-view silhouettes and gray-scale, <b>front-view</b> face photographs. Together {{these results suggest that}} gender processing occurs at a high level of visual representation and can be parametrically investigated within the silhouette face space methodology...|$|E
40|$|Active {{contours}} are {{an attractive}} choice {{to extract the}} head boundary, for deployment within a face recognition or model-based coding scenario. However, conventional snake approaches can suffer difficulty in initialisation and parameterisation. A dual active contour configuration using dynamic programming has been developed to resolve these difficulties by using a global energy minimisation technique and a simplified parameterisation, to enable a global solution to be obtained. The merits of conventional gradient descent based snake (local) approaches, and search based (global) approaches are discussed. In application to find head and face boundaries in <b>front-view</b> face images, the new technique employing dynamic programming is deployed to extract the inner face boundary, along with a conventional normal-driven contour to extract the outer (head) boundary. The extracted contours appear to offer sufficient discriminatory capability for inclusion within an automatic face recognition system...|$|E
40|$|In this paper, a novel {{method for}} {{automatic}} localization of human eyes from <b>front-view</b> face images is presented. By applying the grayscale morphology operation to a face image, we can obtain a valley map {{with a good}} property in which as a whole the number of pixels at a grayscale decreases significantly as the grayscale level increases. The valley map is then binarized {{with a set of}} threshold values determined adaptively, and several candidate eye locations are detected from the resultant binary images. The final eye positions are determined using a Principle Component Analysis (PCA) method. Experimental results on the AR, Yale and our own face image databases show that the correct eye location rate is over 93 % and the location disparity on average is below 1 / 3 of the radius of an eye ball. Department of Electronic and Information Engineerin...|$|E
40|$|We {{address the}} problem of {{detecting}} rear-view (obstacle free) ground surface using a vehicle production camera. This task is considerably more challenging than general <b>front-view</b> road detection, as the associated challenges widely range from low picture quality, fisheye distortion and large objects, to the ab-sence of useful priors such as vanishing points and road struc-ture. Regarding the challenges, we propose a feature that can simultaneously capture local appearance and context infor-mation. In addition, the task suffers from strong appearance variations such as shadows and ground markers. Therefore, we propose a novel conditional random field (CRF) model which includes hidden states indicating confident nodes and propagate their confidence to neighboring nodes. We show that our proposed feature and model can jointly achieve ro-bustness against large objects and shadows/markers, showing excellent detection performance under low quality inputs. Index Terms — ground surface detection, CRF, semantic segmentation, confidence propagation...|$|E
40|$|The {{present study}} {{examined}} whether strategy moderated {{the relationship between}} visuospatial perspective-taking and empathy. Participants (N= 96) undertook both a perspective-taking task requiring speeded spatial judgements made {{from the perspective of}} an observed figure and the Empathy Quotient questionnaire, a measure of trait empathy. Perspective-taking performance was found to be related to empathy in that more empathic individuals showed facilitated performance particularly for figures sharing their own spatial orientation. This relationship was restricted to participants that reported perspective-taking by mentally transforming their spatial orientation to align with that of the figure; it was absent in those adopting an alternative strategy of transposing left and right whenever confronted with a <b>front-view</b> figure. Our finding that strategy moderates the relationship between empathy and visuospatial perspective-taking enables a reconciliation of the apparently inconclusive findings of previous studies and provides evidence for functionally dissociable empathic and non-empathic routes to visuospatial perspective-taking...|$|E
