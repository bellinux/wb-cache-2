0|10000|Public
50|$|The Oerlikon KBA 25 mm cannon is a fully automatic, {{positively}} locked, gas-operated weapon with {{a rotating}} bolt head and double belt feed. These features <b>guarantee</b> <b>high</b> <b>reliability</b> and safety, {{even under the}} most extreme environmental conditions.|$|R
40|$|Transcription factor binding {{sites are}} found in either nucleosome-free or nucleosome-embedded locations, thus in vivo {{relationships}} between nucleosome position and gene activation are not fully understood. In this issue of Developmental Cell, Bai et al. show that binding sites located in nucleosome depleted regions <b>guarantee</b> <b>high</b> <b>reliability,</b> not amplitude, of promoter firing...|$|R
30|$|Broadcasting {{protocols}} (e.g., [5 – 9]), {{that have}} been proposed for VANETs have a common factor in that they cannot <b>guarantee</b> <b>high</b> <b>reliability</b> for safety-related data dissemination with [5] concluding that the probability of successful reception of the data decreases with growing distance from the sender. These factors have serious consequences for safety-related data dissemination where dangerous situations can be aggravated through unsuccessful broadcast communications.|$|R
40|$|Structured {{programming}} {{principles are}} {{not strong enough}} to control complexity and <b>guarantee</b> <b>high</b> <b>reliability</b> of software at the module level. Stronger organizing principles and stronger properties of components are needed to make significant gains in the quality of software. Practical proposals, based on the definition of normal forms which have a mathematical/logical foundation, are suggested as a vehicle for constructing software that is both simpler and of higher quality with regard to clearly defined and justifiable criteria. An Unassigned Group, An Unassigned DepartmentFull Tex...|$|R
40|$|We discuss {{wireless}} broadcasting {{of multimedia}} streams within a framework which allows asynchronous media access. Receivers subscribe {{at any time}} to the ongoing broadcast session, but are still able to display the media stream from the beginning. A fully scalable broadcasting scheme is presented where the media stream is appropriately segmented and segments are protected by fountain codes. Erasure based decoding as well as soft-decoding is discussed. Asynchronous data reception and full reliability are achieved at the same time. Depending on its receiving conditions the receiver adapts its initial playout delay to <b>guarantee</b> <b>high</b> <b>reliability</b> of successful playout. I...|$|R
40|$|Assuring <b>high</b> <b>reliability</b> {{levels in}} complex {{software}} systems is difficult. The spread of component-based paradigm brought, {{along with many}} advantages, new thorny problems and challenges. Various approaches have been proposed to <b>guarantee</b> <b>high</b> <b>reliability</b> and cope with such problems – among these, proactive policies are particularly effective and inexpensive. The ability to monitor the system at runtime and to give online estimations about the trend of dependability attribute of interest, {{is the key to}} implement strategies aiming at forecasting, and thus proactively preventing, the system failure occurrence. In this paper, an online reliability monitoring approach is proposed. It combines benefits of architecture- based reliability model and dynamic analysis, so as to integrate static modeling power with representative operational data. Its usage is illustrated by a prototype implementation, a case-study and preliminary results...|$|R
40|$|There {{are many}} general {{requirements}} for colliders, such as <b>high</b> <b>reliability</b> and availability, reasonable power efficiency, lower construction cost, simplicity, and flexible operation. A smart modulator {{is necessary to}} realize a linear collider with a reasonable performance. A capacitor-charging power supply using high frequency inverter technology is strongly recommended for the charging section in the smart modulator. A high frequency inverter switching makes the overall system size small. The command-charging feature can <b>guarantee</b> <b>higher</b> <b>reliability</b> of switching function. The protection circuit can be easily included {{in the system and}} the good regulation of charging voltage can be achieved by the feedback system. Several modules can be stacked to supply required output power and a failed module is easily replaced. A 50 -kV, 42 -kW capacitor charging power supply is developed. Design detail and test results of a prototype unit are presented. ...|$|R
40|$|Real-time {{monitoring}} of cloud resources {{is crucial for}} a variety of tasks such as performance analysis, workload management, capacity planning and fault detection. Applications producing big data make the monitoring task very difficult at high sampling frequencies because of high computational and communication overheads in collecting, storing, and managing information. We present an adaptive algorithm for monitoring big data applications that adapts the intervals of sampling and frequency of updates to data characteristics and administrator needs. Adaptivity allows us to limit computational and communication costs and to <b>guarantee</b> <b>high</b> <b>reliability</b> in capturing relevant load changes. Experimental evaluations performed on a large testbed show the ability of the proposed adaptive algorithm to reduce resource utilization and communication overhead of big data monitoring without penalizing the quality of data, and demonstrate our improvements to the state of the art. Real-time {{monitoring of}} cloud resources is crucial {{for a variety of}} tasks such as performance analysis, workload management, capacity planning and fault detection. Applications producing big data make the monitoring task very difficult at high sampling frequencies because of high computational and communication overheads in collecting, storing, and managing information. We present an adaptive algorithm for monitoring big data applications that adapts the intervals of sampling and frequency of updates to data characteristics and administrator needs. Adaptivity allows us to limit computational and communication costs and to <b>guarantee</b> <b>high</b> <b>reliability</b> in capturing relevant load changes. Experimental evaluations performed on a large testbed show the ability of the proposed adaptive algorithm to reduce resource utilization and communication overhead of big data monitoring without penalizing the quality of data, and demonstrate our improvements to the state of the art...|$|R
40|$|Abstract. New WiMAX {{technology}} offers several advantages over currently available (GSM or UMTS-based) solutions. It is a cost effective, evolving, and robust technology providing {{quality of service}} <b>guarantees,</b> <b>high</b> <b>reliability,</b> wide coverage and non-line-of-sight transmission capabilities. All these features make it especially suitable for densely populated- urban environments. In the paper we discuss design and implementation difficulties concerning network coverage, discovered in the test-bed implementation during measurements and tests. We point out unexpected “coverage white spots ”- not characteristic to WiMAX technology. As one of possible solutions of this significant drawback of the very promising technology we consider reconfigurable mesh organization of WiMAX base stations. We also suggest directions for further development {{of this kind of}} network operation, partly based on our practical experience...|$|R
40|$|The upper limit, of {{electron}} and proton fluences for a thermoelectric {{outer planet}} spacecraft mission in a near-Jupiter environment, {{for use as}} radiation design restraints, were extracted from {{a model of the}} Jovian trapped radiation belts. Considerations of radiation effects in semiconductor devices were employed to construct simplified radiation test levels based on the design restraints. Corresponding levels, based on the nominal belt models, are one to three orders of magnitude smaller. In terms of expected radiation-induced degradation in semiconductor devices, an encounter with an environment as severe as the design restraints would require hardening the system in order to <b>guarantee</b> <b>high</b> <b>reliability.</b> On the other hand, the nominal levels would only necessitate care in the selection of components and the avoidance of certain semiconductor components...|$|R
40|$|The {{introduction}} of new automotive system architectures that exploit the benefits offered by advanced electronic control will require the dependability of the electronic systems to be assured over the vehicle's life, This is particularly important in safety critical subsystems such as braking steering and ride control. Improved processes, designs and minimal connector strategies are all contributing to these goals however, aggressive pricing and specifications are eliminating the possibilities of extensive reliability screening. In addition, degradation mechanisms and intermittent faults still occur in IC's despite radical improvements in processing technology. It is clear therefore that self test and diagnostic strategies are required in addition to techniques that <b>guarantee</b> <b>high</b> <b>reliability</b> levels if ZERO failure electronics is to be realised in modem automotive systems...|$|R
40|$|In this paper, {{a sensor}} node which could {{function}} {{according to the}} execute specified algorithms despite a fault was developed for IoT based vehicle to vehicle communication. As {{for the detection of}} fault, the output values of 2 equivalent systems were compared and if different signals occurred, it was read as fault. If the fault signal developed into an error, it was recognized as failure, preventing the output of data and by switching to a spare system, it enabled the execution of the stipulated algorithm. The proposed system accommodates various services for vehicle to vehicle and vehicle to base station {{and at the same time}} provides uninterrupted and safe service. It can be applied to plant facilities such as petroleum and gas management as it <b>guarantees</b> <b>high</b> <b>reliability.</b> © 2015 International Information Institute...|$|R
40|$|Abstract — This study solely {{focuses on}} {{exploring}} {{the effects of}} flywheel geometry on its energy storage/deliver capability per unit mass,further defined as specific energy. In this paper we have studied various profiles of flywheel and the stored kinetic energy is calculated for the respective flywheel. various profiles designed are solid disk, disk rim,webbed/section cut, arm/spoke flywheel. It shows that smart design of flywheel geometry could both {{have a significant effect}} on the Specific Energy performance and reduce the operational loads exerted on the shaft/bearings due to reduced mass at high rotational speeds. Efficient flywheel design used to maximizes the inertia of moment for minimum material used and <b>guarantee</b> <b>high</b> <b>reliability</b> and long life. FE analysis is carried out for different cases of loading on the flywheel and maximum von mises stresses and total deformation are determined...|$|R
40|$|Reliability {{is one of}} {{the major}} {{concerns}} for software engineers. The increasing size of software systems and their inherent complexity - which is essentially related to the intricate interdependencies among many heterogeneous components - pose serious difficulties to its assessment and assurance. The actual system runtime behavior is difficult to forecast during the development phase, and just relying upon sound design and testing techniques is often not sufficient to deliver highly reliable systems. In order to <b>guarantee</b> <b>high</b> <b>reliability,</b> system behavior needs to be monitored at runtime and its reliability needs to be periodically estimated during operation, taking into account both structural/static and behavioral/dynamic information. In this paper, we propose an online reliability monitoring approach, which combines static reliability modeling and dynamic analysis to periodically evaluate system reliability trend during operation. Its usage is illustrated by a prototype implementation and a case- study...|$|R
30|$|Another key {{application}} is vital data collection for workers such as firefighters, soldiers, {{and police officers}} in an urgent/life-critical scenario and for athletes in a sports-training scenario. For the former scenario, {{it is essential to}} monitor in real-time their physical and physiological states through collecting vital data from sensor nodes: body temperature meter, electro-cardio-graph (ECG), electro-myo-graph (EMG), tri-accelerometer, and SpO 2 meter (for oxygen saturation) put on various positions of their bodies: left and right arms, left and right ankles, chest, finger and so on. On the other hand, for the latter scenario, {{it is also important to}} collect vital data in real-time, since trainers can train athletes with feedback information on their physical states. For the application, <b>high</b> <b>reliability</b> such as low packet error rate and low packet delay is the most important factor, in other words, because of their short operating times, the energy consumption of sensor nodes is not so critical. In this paper, we pay attention to how to <b>guarantee</b> <b>high</b> <b>reliability</b> in a WBAN.|$|R
40|$|Abstract. Military {{electronic}} components apply in high temperature conditions {{has become one}} of the hot research field of reliability field, then the temperature characteristics of the military {{electronic components}} are known by designers is key to <b>guarantee</b> <b>high</b> <b>reliability</b> of military equipment under high temperature conditions. So, a scheme of the high temperature dynamic test based on low consumed power test circuits and PC is worked out in this paper. It can be used for test the temperature performance of the military electronic components, and feasibility of the schemes are tested and verified by experiment. And the changing law of the components parameter are got in this conditions which found out components parameters approximate linear in 25 ℃～? 200 ℃, of nonlinear in large range in the very high temperature of 200 ℃～? 350 ℃ conditions, which can offer some reference value to prolong lifetime of military electron device...|$|R
40|$|It is {{very common}} to use dynamic methods to detect {{deadlocks}} in MPI programs {{for the reason that}} static methods have some restrictions. To <b>guarantee</b> <b>high</b> <b>reliability</b> of some important MPI-based application software, a model of MPI synchronization communication is abstracted and a type of static method is devised to examine deadlocks in such modes. The model has three forms with different complexity: sequential model, single-loop model and nested-loop model. Sequential model is a base for all models. Single-loop model must be treated with a special type of equation group and nested-loop model extends the methods for the other two models. A standard Java-based software framework originated from these methods is constructed for determining whether MPI programs are free from synchronization communication deadlocks. Our practice shows the software framework is better than those tools using dynamic methods because it can dig out all synchronization communication deadlocks before an MPI-based program goes into running. Comment: accepted by HPC Asia 200...|$|R
40|$|Monitoring {{critical}} {{conditions is}} of outmost importance in any system for achieving long life and stability. In this process, various parameters {{can be classified}} as critical and their values must be kept within a bounded interval by means of monitoring and acting upon {{a change in the}} value. A practical example of critical conditions monitoring is temperature monitoring in data centers (server rooms) where the temperature value must be kept below a certain threshold in order to achieve long life and stability of equipment. This paper presents a system designed for monitoring temperatures and alerting of their critical values is proposed - PRSMA. With a parallel redundancy feature that <b>guarantees</b> <b>high</b> <b>reliability</b> of the proposed solution, this approach achieves timely alerting upon critical condition, real-time supervision of temperature values and forecasting of critical conditions. The redundancy aspect is realized by using a mobile operator link alongside with the Internet-based landline connection to a cloud-based service – the Internet of Things concept. The proposed architecture is tested in laboratory conditions and the advantages of this approach are shown through measurement and testing...|$|R
40|$|As {{the world}} around us is {{increasingly}} becoming defined by software and the size and complexity of the software systems increases, as well as our dependance on them, it becomes all the more important that the software is thoroughly tested in an attempt to <b>guarantee</b> <b>high</b> <b>reliability.</b> In order to measure the thoroughness of testing, code coverage is often applied as an attempt at measuring the software testing. The paper aims to explore how code coverage is correlated with software quality and reliability. The paper also examines what code coverage actually is and how the state-of-the-art suggests the usage of code coverage for optimal result. Through a Systematic Literature Review, with a holistic approach, the paper concludes that code coverage and software reliability are not directly correlated, but possibly indirectly with a varying correlation factor. When it comes to recommended code coverage practices and optimal use, the literature strongly argues for not having code coverage as an absolute goal of the testing, instead using it to evaluate the test suite and find its flaws {{so that it can be}} improved...|$|R
40|$|Is {{computer}} benchmarking {{only about}} performance? �NO!!! � E. g. nowadays most systems need to <b>guarantee</b> <b>high</b> availability and <b>reliability</b> � It is mandatory {{to shift the}} focus from measuring performance to the measurement of both performance and dependability � Don’t computers fail? � What {{is the impact of}} failures into the system...|$|R
40|$|Design {{diversity}} {{has long}} been used to protect redundant systems against common-mode failures. The conventional notion of diversity relies on "independent" generation of "different" implementations. This concept is qualitative and {{does not provide a}} basis to compare the reliabilities of two diverse systems. In this paper, for the first time, we present a metric to quantify diversity among several designs. Based on this metric, we derive analytical reliability models that show a simple relationship between design diversity, system failure rate, and mission time. In addition, we present simulation results to demonstrate the effectiveness of design diversity in Duplex and Triple Modular Redundant (TMR) systems. For independent multiple-module failures, we show that, mere use of different implementations does not always <b>guarantee</b> <b>higher</b> <b>reliability</b> compared to redundant systems with identical implementations [...] - it is important to analyze the reliability of redundant systems using our metric. For common-mode failures and design faults, there is a significant gain in using different implementations [...] - however, as our analysis shows, the gain diminishes as the mission time increases. Our simulation results also demonstrate the usefulness of diversity for enhancing the self-testing properties of redundant systems...|$|R
40|$|Abstract — Resource Monitoring and Discovery {{of large}} {{computational}} data Grids {{is essential to}} <b>guarantee</b> <b>high</b> performance and <b>reliability.</b> In this paper, we identify the various resource monitoring and discovery issues and challenges {{that need to be}} solved in a large adaptive Grid environment. We survey the existing Grid monitoring solutions and discuss the monitoring and discovery framework that we have developed for the en...|$|R
40|$|With the {{unprecedented}} growth {{of data and}} the use of low commodity drives in local disk-based storage systems and remote cloud-based servers has increased the risk of data loss and an overall increase in the user perceived system latency. To <b>guarantee</b> <b>high</b> <b>reliability,</b> replication has been the most popular choice for decades, because of simplicity in data management. With the high volume of data being generated every day, the storage cost of replication is very high and is no longer a viable approach. Erasure coding is another approach of adding redundancy in storage systems, which provides <b>high</b> <b>reliability</b> {{at a fraction of the}} cost of replication. However, the choice of erasure codes being used affects the storage efficiency, reliability, and overall system performance. At the same time, the performance and interoperability are adversely affected by the slower device components and complex central management systems and operations. To address the problems encountered in various layers of the erasure coded storage system, in this dissertation, we explore the different aspects of storage and design several techniques to improve the reliability, performance, and interoperability. These techniques range from the comprehensive evaluation of erasure codes, application of erasure codes for highly reliable and high-performance SSD system, to the design of new erasure coding and caching schemes for Hadoop Distributed File System, which is one of the central management systems for distributed storage. Detailed evaluation and results are also provided in this dissertation...|$|R
30|$|In this paper, we {{investigate}} reliability {{and performance of}} DSRC ad hoc V 2 V communication networks with two levels of safety-related services analytically and by simulation. Several important performance indices for broadcast such as channel throughput, packet reception rates, and packet delivery delay are derived from the proposed analytical model taking IEEE 802.11 backoff counter process, fading channel, hidden terminal, nonsaturation traffic, mobility, and so forth, into account. Numerical results reveal characteristics of the DSRC communication system for safety application. From the analysis of DSRC safety services on highway, we observe that (1) under typical DSRC environment, IEEE 802.11 a is {{able to meet the}} safety message delay requirement, but is not able to <b>guarantee</b> <b>high</b> <b>reliability</b> because of possible transmission collision and harsh channel fading; (2) hidden terminal problem in broadcast is more severe than that in unicast; (3) high mobility of vehicles has minor impact on the reliability and performance of the direct single hop broadcast network with high data rate; (4) with direct broadcast and preemptive emergent message transmission, it is possible to meet both performance requirement and reliability requirement simultaneously through adjusting backoff window size, appropriate number of packet repetitions, and enough range of carrier sensing.|$|R
40|$|Abstract—The node {{mobility}} {{makes it}} difficult to <b>guarantee</b> a <b>high</b> <b>reliability</b> of data delivery for existing multicast routing protocols, but it is a major concern in protocol design for Mobile Ad-hoc NETworks (MANETs). We propose a novel scalable and reliable multicast protocol based on clustering technique and gossip methodology. Local Retransmission and Gossip-Based mechanisms (LRG) are combined to provide the <b>high</b> <b>reliability</b> of data delivery. Dynamical changes of gossip probability and gossip scope upgrade the spreading ratio of messages and they make the protocol adaptive to the rapid changes of network environment. The proposed protocol is compared with the wellknown Route Driven Gossip (RDG) protocol with regard to communication overhead, reliability, and latency. Theoretical analysis and simulation studies show that LRG is reliable and scalable in MANETs. Keywords-MANETs; multicast; gossip; reliability I...|$|R
40|$|International audienceWith {{increasing}} interest among mainstream users to run HPC applications, Infrastructure-as-a-Service (IaaS) cloud computing platforms represent {{a viable alternative}} to the acquisition and maintenance of expensive hardware, often out of the financial capabilities of such users. Also, one of the critical needs of HPC applications is an efficient, scalable and persistent storage. Unfortunately, storage options proposed by cloud providers are not standardized and typically use a different access model. In this context, the local disks on the compute nodes can be used to save large data sets such as the data generated by Checkpoint-Restart (CR). This local storage offers high throughput and scalability but it needs to be combined with persistency techniques, such as block replication or erasure codes. One of the main challenges that such techniques face is to minimize the overhead of performance and I/O resource utilization (i. e., storage space and bandwidth), {{while at the same time}} <b>guaranteeing</b> <b>high</b> <b>reliability</b> of the saved data. This paper introduces a novel persistency technique that leverages Reed-Solomon (RS) encoding to save data in a reliable fashion. Compared to traditional approaches that rely on block replication, we demonstrate about 50 % higher throughput while reducing network bandwidth and storage utilization by a factor of 2 for the same targeted reliability level. This is achieved both by modeling and real life experimentation on hundreds of nodes...|$|R
40|$|The {{professional}} {{language training}} and its optimization is an urgent problem for air traffic  service. The monitoring system provides efficient definition of psycholinguistic professional possibilities of controllers. The expert estimation and classification of temporal delays are used for definition of professional suitability. The total results allow defining {{the level of}} psycholinguistic possibilities of controllers in on-line language system «controller-pilot». The individual typological features of every test person and additional two-language estimation (in English and in Russian) <b>guarantee</b> <b>high</b> level <b>reliability.</b> Such results confirm suitability or unsuitability to work as “air traffic controller” in extreme situations. The obtained data can be used when you are going to modify phraseology in language system «controller-pilot», or when you are going to approve new methods of professional language trainin...|$|R
40|$|In the paper, {{we propose}} a {{reliable}} asynchronous image transfer protocol, RAIT. RAIT applies a double sliding window method to node-to-node transfer, with one sliding window for the receiving queue, {{which is used}} to prevent packet loss caused by communication failure between nodes, and another sliding window for the sending queue, which prevents packet loss caused by network congestion. The routing node prevents packet loss between nodes by preemptive scheduling of multiple packets for a given image. RAIT implements a double sliding window method by means of a cross-layer design between the RAIT layer, routing layer, and queue layer. We demonstrate that RAIT <b>guarantees</b> a <b>higher</b> <b>reliability</b> of image transmission compared to the existing protocols...|$|R
40|$|Abstract — As IC process {{geometries}} {{scale down}} to the nanometer territory, industry faces severe challenges of manufacturing limitations. To <b>guarantee</b> <b>high</b> yield and <b>reliability,</b> routing for manufacturability and reliability has {{played a pivotal role}} in resolution and thus yield enhancement for the imperfect manufacturing process. In this article, we introduce major routing challenges arising from nanometer process, survey key existing techniques for handling the challenges, and provide some future research directions in routing for manufacturability and reliability. I...|$|R
40|$|The {{properties}} of interfaces of functional parts used in micro actuators {{are very important}} to <b>guarantee</b> a <b>high</b> <b>reliability</b> for the whole life cycle of the device. In this paper, surface modifications by the deposition of diamondlike carbon (DLC) were studied with the aim of the improvement of the tribological properties. Atomic force microscopy (AFM) was applied to reveal the surface structure. The mechanical properties and wear of the materials with a DLC coating were characterized using nanoindentation techniques. The influence of the coating thickness on the wear behavior of different substrates was investigated by single and oscillating scratch tests. Nano-scratch tests were applied to study the scratch resistance. The measurements showed an increase in surface hardness and wear resistance by the deposition of the DLC layers...|$|R
40|$|The {{existing}} klystron modulator in the Linac use a 60 Hz {{high voltage}} power supply and adopt traditional L-C resonant charging scheme with De-Qing circuit. The {{stability of the}} output high voltage is not satisfactory especially when the AC line voltage fluctuations. If an inverter power supply is used as a HV generator, it will just meet the demands A high frequency inverter switching makes the overall system size small. The command-charging feature can <b>guarantee</b> the <b>high</b> <b>reliability</b> of switching function. In order to increase the stability, operating reliability and comply with the PLC (programming logic controller) and touch screen control system of PLS, an upgrading works is now in progress. This paper will discuss some inverter power supply design considerations and show the test results...|$|R
40|$|Based on {{experiences}} from {{an autonomous}} mobile robot project called MOBOT -III, we found hard realtime-constraints for the operating-system-design. ALBATROSS is "A flexible multi-tasking and realtime network-operatingsystem-kernel", not limited to mobile- robot-projects only, but which might be useful also wherever you have to <b>guarantee</b> a <b>high</b> <b>reliability</b> of a realtime-system. The focus {{in this article is}} on a communication-scheme fulfilling the demanded (hard realtime-) assurances although not implying time-delays or jitters on the critical informationchannels. The central chapters discuss a locking-free shared buffer management, without the need for interrupts and a way to arrange the communication architecture in order to produce minimal protocol-overhead and short cycle-times. Most of the remaining communication-capacity (if there is any) is used for redundant transfers, increasing the reliability of the whole system. ALBATROSS is actually implemented on a multi-processor VMEbus-system...|$|R
40|$|Abstract- Because network-level {{reliable}} {{group communication}} protocols rely on IP multicast and have lack of reliability, this motivates the demand on application-level group communication. Epidemic-style protocols among these application-level approaches <b>guarantee</b> reasonably <b>high</b> <b>reliability,</b> provide good scalability and {{are easy to}} deploy. But, earlier versions of these protocols often rely {{on the assumption that}} every process knows every other process. There exist epidemic-style broadcast protocols based on partially randomized individual views providing totally ordered delivery of broadcast messages to members of large groups. However, there is no such epidemic-style broadcast protocol providing causally ordered delivery property, which is very useful for many distributed applications such as video-conferencing and multi-party games. This paper proposes an efficient epidemic-style broadcast protocol to guarantee causally ordered delivery semantics based on the local view of every individual member consisting of a subset of members, which continuously evolves, but never exceeds a fixed size...|$|R
40|$|Capsule {{endoscopy}} is a {{non-invasive procedure}} for gastrointestinal diagnosis. It {{does not require}} sedation and it is comfortable and well tolerated by patient. However, the problem with such procedure is that {{a huge number of}} images is collected, which require time to investigate and diagnose; furthermore, the capsule movement is not controlled leading, in some cases, to inaccurate diagnosis. In this context, a mapping of the lumen is required to <b>guarantee</b> a <b>higher</b> <b>reliability</b> of the inspection, enabling the medical doctor to evaluate all the parts of the lumen for a better diagnosis. In this paper, we propose a method for mapping images from a capsule-based endoscope: the technique uses visual and inertial-based data fusion to obtain a 3 D map of the lumen from 2 D capsule images, also paving the way for the implementation of a path planning and autonomous locomotion and inspection...|$|R
40|$|Ultra-scale devices {{based on}} {{technologies}} below 20 nm are nowadays widely adopted {{due to their}} elevated computing features and low power consumption. These characteristics made them attractive even for fields where the <b>high</b> <b>reliability</b> is the major concern like automotive or aerospace ones. In order to <b>guarantee</b> a <b>high</b> <b>reliability</b> level, {{one of the major}} challenge in these application fields is the protection versus the micro latch-up effect: a phenomenon that temporarily affects the logical behavior of technology cells at various locations across the die provoking circuit misbehavior. In this paper, we propose a new analysis flow for detecting the occurrences of micro latch-up event considering the physical layout of a circuit. In details, a circuit layers has been developed in order to identify the micro latch-up sensitive points in the 3 D layout geometry, while a Monte-Carlo approach has been developed to calculate the micro latch-up error rate on routing interconnection nodes. Experimental results have been performed by fault simulation on a benchmark circuit implemented in six different variants of routing congestion using a 15 nm COTS technology library demonstrating the feasibility of the proposed approach...|$|R
40|$|International audienceTime Slotted Channel Hopping (TSCH) {{is among}} the {{proposed}} Medium Access Control (MAC) layer protocols of the IEEE 802. 15. 4 - 2015 standard for low-power wireless communications in Internet of Things (IoT). TSCH aims to <b>guarantee</b> <b>high</b> network <b>reliability</b> by exploiting channel hopping and keeping the nodes time-synchronized at the MAC layer. In this paper, {{we focus on the}} traffic isolation issue, where several clients and applications may cohabit under the same wireless infrastructure without impacting each other. To this end, we present an autonomous version of 6 TiSCH where each device uses only local information to select their timeslots. Moreover, we exploit 6 TiSCH tracks to guarantee flow isolation, defining the concept of shared (best-effort) and dedicated (isolated) tracks. Our thorough experimental performance evaluation campaign, conducted over the open and large scale FIT IoT-LAB testbed (by employing the OpenWSN), highlight the interest of this solution to provide reliability and low delay while not relying on any centralized component...|$|R
