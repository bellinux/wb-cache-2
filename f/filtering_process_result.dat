0|10000|Public
40|$|We apply several {{tests to}} analyze the {{existence}} of long-term dependence in 10 Euro-pean stock indexes. After a <b>filtering</b> <b>process,</b> <b>results</b> point {{to the absence of}} linear autocorrelation. However, with other tests, we found non-linear serial dependences that affect return rates. Results of mutual information and global correlation confirm these results and Lyapunov point to the existence of deterministic behavior in all time series. With DFA, we found that most return rate series have long-range dependence, more pronounced in Spain, Greece and Portugal. These results could constitute an indicator of the effiency level of the sotock markets under analysis...|$|R
3000|$|The {{changes of}} timbre due to {{distance}} can {{be accounted for}} physically in terms of air absorption. The main perceptual effect of air absorption on sounds {{is due to a}} low-pass <b>filtering</b> <b>process,</b> the <b>result</b> of which depends on the distance between source and listener. Note that, under usual conditions, the [...]...|$|R
30|$|The {{described}} <b>filtering</b> and merging <b>process</b> <b>resulted</b> in 157 diseases. We assigned them {{to their}} corresponding disease type using Revision 10 of the ICD (WHO 2016).|$|R
40|$|Graduation date: 1993 The {{thesis is}} {{a case study of}} two {{traditional}} family farms that were settled in Oregon in 1850 and 1915. The study embraces the theory that material culture reflects customs and values. The material culture indicators within the study are the architectural structures of the Oregon farms. The study filters the architecture through theoretical and historical data of both Oregon and the Upland South. The farms are recorded with oral history, photographs, architectural descriptions, and evolutionary settlement patterns. The <b>filtering</b> <b>process</b> <b>results</b> in two constructs that correlate the commonalities of both the Oregon farms and the Upland South architecture. The results point out that, with the disappearance of vernacular architecture on family farms, it follows that historic traditional cultures vanish...|$|R
40|$|Abstract-Wireless OFDM signals {{typically}} have a cyclicprefixed guard interval. The FFT timing synchronisation at the receiver is traditionally {{based on the}} peak point of the correlation output between the guard interval and its corresponding duplicate at the OFDM symbol’s tail. This approach does not in general find the optimum timing position for the FFT when the channel contains more than one path. This is particularly true when the first arriving replica of the signal is not the strongest, potentially resulting in the timing position that is outside the acceptable range, causing ISI. In this paper, the OFDM FFT timing synchronisation problem under multi-path channel conditions are studied. Algorithms that produce improved FFT timing synchronisation are developed, which exploit either the channel information obtained, say, through scattered pilots or the characteristics exhibited by combining a modified correlation scheme with a special <b>filtering</b> <b>process.</b> <b>Results</b> from simulation study are presented which have shown a noticeable performance improvement...|$|R
40|$|This thesis {{investigates the}} {{possibilities}} of using GIS (Geographic Information Sys-tem) data with an airborne autonomous vehicle developed in the WITAS project. Available for the thesis are high resolution (0. 16 meter sample interval) aerial pho-tographs over Stockholm, and vector data in a common GIS format containing all roads in the Stockholm area. A method for removing cars from aerial photographs is presented, using the filter-ing method normalized convolution, originally developed for filtering uncertain and incomplete data. By setting the certainty to zero over the cars, this data is disre-garded in the <b>filtering</b> <b>process,</b> <b>resulting</b> in an image without cars. This method is further improved by choosing an anisotropic applicability function, resulting in a filtering that preserves structures oriented in certain directions. The available vector data is investigated with regard to its use in a simulator for vehicle movement, and {{is found to be}} missing much of the essential information needed in such a simulator. A new data format better suited to these requirement...|$|R
40|$|Abstract—In this paper, we {{investigate}} {{the problem of}} non-myopic (multi-step ahead) quantizer design for target tracking using a wireless sensor network. Adopting the alternative condi-tional posterior Cramér-Rao lower bound (A-CPCRLB) as the optimization metric, we theoretically show that this problem can be temporally decomposed over a certain time window. Based on sequential Monte-Carlo methods for tracking, i. e., particle filters, we design the local quantizer adaptively by solving a particle-based non-linear optimization problem which is well suited {{for the use of}} interior-point algorithm and easily embedded in the <b>filtering</b> <b>process.</b> Simulation <b>results</b> are provided to illustrate the effectiveness of our proposed approach. I...|$|R
40|$|International audienceA {{theoretical}} {{study is}} presented to evaluate {{the influence of the}} structure size of laser-textured surfaces on the tribological performance of reciprocating automotive components. A topographic image representing a laser-textured liner surface is progressively filtered, using morphological alternating sequential filters of increasing size, in order to transform the roughness of the initial surface. A numerical tool simulating the hydrodynamic contact between piston rings and liner is then used to compare the performance of the textures issued from the <b>filtering</b> <b>process.</b> The <b>results</b> of this analysis can constitute key data for the definition of new and efficient textured surfaces with this type of application...|$|R
40|$|Thermal {{convective}} {{air flows}} are of great relevance in fundamental studies and technical {{applications such as}} heat exchangers or indoor ventilation. Since these kinds of flow are driven by temperature gradients, simultaneous measurements of instantaneous velocity and temperature fields are highly desirable. A possible solution is the combination of particle image velocimetry (PIV) and particle image thermography (PIT) using thermochromic liquid crystals (TLCs) as tracer particles. While combined PIV and PIT is already {{state of the art}} for measurements in liquids, this is not yet the case for gas flows. In this study we address the adaptation of the measuring technique to gaseous fluids with respect to the generation of the tracer particles, the particle illumination and the image <b>filtering</b> <b>process.</b> <b>Results</b> of the simultaneous PIV/PIT stemming from application to a fluid system with continuous air exchange are presented. The measurements were conducted in a cuboidal convection sample with air in- and outlet at a Rayleigh number Ra ≈ 9. 0 × 10 ^ 7. They prove the feasibility of the method by providing absolute and relative temperature accuracies of σT = 0. 19 K and σ� dT = 0. 06 K, espectively. Further open issues that have to be addressed in order to mature the technique are identified...|$|R
40|$|In this paper, we {{investigate}} {{the problem of}} nonmyopic (multi-step ahead) quantizer design for target tracking using a wireless sensor network. Adopting the alternative conditional posterior Cramer-Rao lower bound (A-CPCRLB) as the optimization metric, we theoretically show that this problem can be temporally decomposed over a certain time window. Based on sequential Monte-Carlo methods for tracking, i. e., particle filters, we design the local quantizer adaptively by solving a particlebased non-linear optimization problem which is well suited {{for the use of}} interior-point algorithm and easily embedded in the <b>filtering</b> <b>process.</b> Simulation <b>results</b> are provided to illustrate the effectiveness of our proposed approach. Comment: Submitted to 2013 Asilomar Conference on Signals, Systems, and Computer...|$|R
40|$|The {{singular}} diffusion equation called total variation (TV) flow {{plays an}} important role in image processing and appears to be suitable for reducing oscillations in other types of data. Due to its singularity for zero gradients, numerical discretizations have to be chosen with care. We discuss different ways to implement TV flow numerically, and we show that a number of discrete versions of this equation may introduce oscillations such that the scheme is in general not TV-decreasing. On the other hand, we show that TV flow may act self-stabilising: even if the total variation increases by the <b>filtering</b> <b>process,</b> the <b>resulting</b> oscillations remain bounded by a constant that is proportional to the ratio of mesh widths. For our analysis we restrict ourselves to the one-dimensional setting...|$|R
40|$|Bump-maps, like texture maps or {{any other}} maps {{consisting}} of discretely stored data have to be properly filtered, if they are being resampled {{in the process of}} rendering an image. If, however, bump maps are filtered in the traditional way, the bumps are lost in the <b>filtering</b> <b>process</b> and the <b>result</b> is a smooth surface. We introduce a bump map pyramid, that contains and preserves isotropic or anisotropic roughness information in all resolution levels. (orig.) Available from TIB Hannover: RR 4367 (97 - 15) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|R
40|$|AbstractThis article {{introduces}} {{an experimental}} paradigm to selectively probe the multiple levels of visual processing {{that influence the}} formation of object contours, perceptual boundaries, and illusory contours. The experiments test the assumption that, to integrate contour information across space and contrast sign, a spatially short-range <b>filtering</b> <b>process</b> that is sensitive to contrast polarity inputs to a spatially long-range grouping process that pools signals from opposite contrast polarities. The stimuli consisted of thin subthreshold lines, flashed upon gaps between collinear inducers which potentially enable the formation of illusory contours. The subthreshold lines were composed {{of one or more}} segments with opposite contrast polarities. The polarity nearest to the inducerss was varied to differentially excite the short-range <b>filtering</b> <b>process.</b> The experimental <b>results</b> are consistent with neurophysiological evidence for cortical mechanisms of contour processing and with the Boundary Contour System model, which identifies the short-range <b>filtering</b> <b>process</b> with cortical simple cells, and the long-range grouping process with cortical bipole cells. © 1997 Elsevier Science Ltd. All rights reserved...|$|R
30|$|Non-rain {{events were}} {{separated}} from the rain events for the experimental data. The rain events were determined {{with the use of}} a rain gauge. The clear-sky level was indicated by using a spectrum analyzer and a rain gauge whereby rain periods have been removed. The raw data were inspected visually to remove any spurious samples as much as possible resulting from loss of lock due to the satellite propellant saving option and satellite movement. The data were extracted by passing through a fifth-order high-pass Butterworth filter with a 0.04 -Hz cutoff frequency based on performing a spectral analysis. After the <b>filtering</b> <b>process,</b> the <b>resulting</b> data consists of positive (enhancement) and negative (fade) scintillation amplitude fluctuations above the mean level. The scintillation intensity is calculated as the standard deviation of the amplitude fluctuations over 1  min (Garcia-del-Pino et al. 2012).|$|R
40|$|We {{propose a}} new method for {{implementing}} Karhunen–Loeve transform (KLT) -based speech enhancement to exploit vector quantization (VQ). The method {{is suitable for}} real-time processing. The proposed method consists of a VQ learning stage and a filtering stage. In the VQ learning stage, the autocorrelation vectors comprising the first$K$elements of the autocorrelation function are extracted from learning data. The autocorrelation vectors are used as codewords in the VQ codebook. Next, the KLT bases that correspond to all the codeword vectors are estimated through eigendecomposition (ED) of the empirical Toeplitz covariance matrices constructed from the codeword vectors. In the filtering stage, the autocorrelation vectors that are estimated from the input signal are compared to the codewords. The nearest one is chosen in each frame. The precomputed KLT bases corresponding to the chosen codeword are used for filtering instead of performing ED, which is computationally intensive. Speech quality evaluation using objective measures shows that the proposed method is comparable to a conventional KLT-based method that performs ED in the <b>filtering</b> <b>process.</b> <b>Results</b> of subjective tests also support this result. In addition, processing time is reduced to about 1 / 66 that of the conventional method in the case where a frame length of 120 points is used. This complexity reduction is attained after the computational cost in the learning stage and a corresponding increase in the associated memory requirement. Nevertheless, these results demonstrate that the proposed method reduces computational complexity while maintaining the speech quality of the KLT-based speech enhancement...|$|R
40|$|Based on {{the problem}} of extracting {{relevant}} information from complex signals, a framework of methods is proposed that apply c lustering techniques already on the signal level in order to automate the tasks of transforming, reducing and characterizing raw data usually performed by the sy stem designer. Low-level clustering extracts elementary patterns from a sequence. Higher-level clustering searches for structure in a sequence. Interesting signal components are selected in a <b>filtering</b> <b>process.</b> Clustering <b>results</b> are automatically evaluated in order to derive relevant features for pattern recognition, prediction, data compression and modelling. As a first result, an algorithm - Fuzzy Sequence Clustering - is presented that processes signals in an online f ashion and that uses a learning criterion to supply an underlying corealgorithm with only those training patterns that are relevant to the learning task. The algorithm is applied to an artificial and to a real-world monitoring problem [...] ...|$|R
40|$|This {{article was}} {{published}} in the journal, Measurement Science and Technology [© IOP Publishing Ltd] and the definitive version is available at: [URL] Image Velocimetry methodology results in a spatial averaging of the real velocity field into a set of discrete measured velocities: one for each interrogation cell. In the absence of measurement noise this <b>filtering</b> <b>process</b> <b>results</b> in a reduction of the measured turbulent kinetic energy and other second order statistics of the velocity field. The reduction in this energy will naturally be dependent upon the amount of turbulent energy at lengthscales smaller than can be resolved by the interrogation cells that make up the measurement grid. This paper investigates the effects of sub-grid scale filtering on the second order statistics of velocity. Several experiments are reported for which interrogation cell size to turbulent integral length scale ratios were varied. In addition, synthetic turbulent velocity fields with known spatial correlation functions are used to support experimental results and provide calibration for the estimation of the level of sub-grid filtering. It is suggested that to accurately capture all turbulent kinetic energy using PIV the interrogation cell should be at least of order 10 times smaller than the integral lengthscale of the flow. A method is then provided to estimate the level of sub-grid filtering should the interrogation cell be larger than this limit up to around the size of the integral lengthscale. With interrogation cells larger than this lengthscale then sub-grid filtering is such that second order statistics are reduced by over 50 % and it should be considered unwise to rely on any second order statistics from such a scenario, corrected or otherwise...|$|R
40|$|The speckle effect inevitably {{exists in}} the image of the Synthetic Aperture Radar (SAR). The removal of the speckle noise is the {{necessary}} approach before automatic partition, classification, target detection and abstraction of other quantitative special information in the SAR image, so it is very meaningful to eliminate or furthest restrain the speckle noises when the spatial resolution of the image is not be reduced. In this paper, the FIR filter is used to remove the noise in the SAR image, and optimal filtering coefficient is selected through experiment and analysis in the <b>filtering</b> <b>process.</b> The <b>results</b> show that the FIR filter used to remove noises in the SAR image is better than other traditional filtering methods in keeping the radiolocation feature and restraining the speckle noises, and the filtering speed is quicker. At the same time, the selection of the filtering coefficient will largely influence the de-noising effect of the FIR filter. </p...|$|R
40|$|We {{present a}} new {{iterative}} approach to solving neutral-particle transport problems. The scheme divides the transport solution into its particular and homogeneous or ?source-free? components. The particular problem is solved directly, while the homogeneous problem is found iteratively. To organize the iterative inversion of the homogeneous components, we exploit {{the structures of}} the so called Case-modes that compose it. The asymptotic Case-modes, those that vary slowly in space and angle, are assigned to a diffusion solver. The remaining transient Case-modes, those with large spatial gradients, are assigned to a transport solver. The scheme iterates on the contribution from each solver until the particular plus homogeneous solution converges. The iterative method is implemented successfully in slab geometry with isotropic scattering and one energy group. The convergence rate of the method is only weakly dependent on the scattering ratio of the problem. Instead, the rate of convergence depends strongly on the material thickness of the slab, with thick slabs converging in few iterations. The transient solution is obtained by applying a One Cell Inversion scheme instead of a Source Iteration based scheme. Thus, the transient unknowns are calculated with little coordination between them. This independence among unknowns makes our scheme ideally suited for transport calculations on parallel architectures. The slab geometry iterative scheme is adapted to XY geometry. Unfortunately, this attempt to extend the slab geometry iterative scheme to multiple dimensions has not been successful. The exact filtering scheme needed to discriminate asymptotic and transient modes has not been obtained and attempts to approximate this <b>filtering</b> <b>process</b> <b>resulted</b> in a divergent iterative scheme. However, {{the development of this}} iterative scheme yield valuable analysis tools to understand the Case-mode structure of any spatial discretization under arbitrary material properties...|$|R
40|$|The {{structure}} tensor is {{a powerful}} tool describing the local intensity structure of an image or image sequence. In this paper we give {{a model for the}} noise distribution of the components of the tensor. In order to do so we have also investigated some properties of the gamma distribution. We show that, given an input image corrupted with Gaussian noise, the noise in the structure tensor can be modeled well by gamma distributions. We apply our model to automatic contrast enhancement of images taken under poor illumination. We show how our noise model can be used for automatic parameter selection in the <b>filtering</b> <b>process,</b> giving powerful <b>results</b> without the need for cumbersome parameter tuning...|$|R
40|$|This article {{introduces}} {{an experimental}} paradigm to selectively probe the multiple levels of visual processing {{that influence the}} formation of object contours, perceptual boundaries, and illusory contours. The experiments test the assumption that, to integrate contour information across space and contrast sign, a spatially short-range <b>filtering</b> <b>process</b> that is sensitive to contrast polarity inputs to a spatially long-range grouping process that pools signals from opposite contrast polarities. The stimuli consisted of thin subthreshold lines, flashed upon gaps between collinear inducers which potentially enable the formation of illusory contours. The subthreshold lines were composed {{of one or more}} segments with opposite contrast polarities. The polarity nearest to the inducers was varied to differentially excite the short-range <b>filtering</b> <b>process.</b> The experimental <b>results</b> are consistent with neurophysiological evidence for cortical mechanisms of contour processing and with the Boundary Contour System model, which identifies the short-range <b>filtering</b> <b>process</b> with cortical simple cells, and the long-range grouping process with cortical bipole cells. Office of Naval Research (N 00014 - 95 - 1 - 0409, N 00014 - 95 - 1 - 0657); Centre National de la Recherche Scientifique (France) URA (1939...|$|R
40|$|Airborne {{laser scanner}} data {{is of great}} utility for digital terrain model generation. Points {{measured}} by the sensor on objects can be filtered out of the data with different methods. Some methods were developed and impemented on commercial softwares as the TerraScan. Beyond commercial solutions there is also at least one alternative implemented on free open source software: the GRASS. In this work, digital terrain models are generated with these two softwares, from airborne laser scanner data gotten in a forest area. The models are compared with a reference surface, generated with topographical survey. Considerations about the <b>filtering</b> <b>processes</b> and the <b>results</b> of the comparisons between the different surfaces are presented. This work shows that the GRASS software is a free and interesting alternative for digital terrain model generation. Pages: 3653 - 366...|$|R
40|$|Abstract: In this paper, {{comparison}} of classic adaptivefiltering algorithms, such as LMS and RLS of Volterra filter, consist of adapting the coefficients of linear filters in real time. These algorithms have applications {{in a number}} of situations where the signals measured in the environment can be well modeled as Gaussian noises applied to linear systems, and their combinations are of additive type and analysis the performance of the DSSS receiver containing the Volterra Jilter {{in the presence of the}} broadband BPSK interference is addressed. Recursive least square (RLS) is used in the <b>filter</b> adaptation <b>process.</b> Obtained <b>results</b> show that the Volterra filter receiver obtains the excellent interference suppression, compared to the receiver containing the two-sided transversal filter...|$|R
40|$|In this work, an {{implementation}} of linear filtering and morphological image operation using a EDK 11. 1 FPGA Spartan 3 E is implemented in Field Programmable Gate Array this technology {{has become a}} viable target for the {{implementation of}} real time algorithms suited to video image processing and image processing applications. The unique architecture of the FPGA has allowed the technology to be used in many applications encompassing all aspects of video image processing and image processing. Among those algorithms, dilation, erosion and linear filtering, represent a basic set of image operations for a number of applications. the system is connected to a USB port of a personal computer, which in that way form a powerful and low-cost design station. A comparison between different HDL language and the described FPGA-based implementation is presented. Image processing algorithms are conventionally implemented in DSP, ARM processors and some special purpose processors. However all these implementation styles are limited by throughput which becomes very critical parameter for several image processing applications. The FPGA technologies offer basic digital blocks with flexible interconnections to achieve high speed digital hardware realization. The image will be transferred from computer to FPGA board using JTAG cable. After performing the required <b>filtering</b> <b>process</b> the <b>result</b> will be transferred back to computer...|$|R
40|$|E-mail {{has emerged}} as one of the primary means of {{communication}} used in the world today. Its rapid adoption has left it ripe for misuse and abuse. This came in the guise of Unsolicited Commercial E-mail (UCE) or as it is otherwise known Spam. For a time spam was considered only a nuisance but due mainly to the copious amounts of spam being sent it has progressed from being a nuisance to become a major problem. The volume of spam has reached epidemic proportions with estimates of up to 80 % of all e-mail sent actually being spam. Spam filtering offers a way to curb the problem. Identifying and removal of spam from the e-mail delivery system allows end-users to regain a useful means of communication. A lot of research in spam filtering has been centred on more sophistication in the classifiers used. This thesis begins to investigate the impact of applying more sophistication to lower layers in the <b>filtering</b> <b>process,</b> namely extracting information from e-mail. Several types of obfuscation are discussed which are becoming ever more present in spam in order to try confuse and circumvent the current <b>filtering</b> <b>processes.</b> The <b>results</b> obtained by removing certain types of obfuscation show to improve the classification process. The main theory under investigation was the impact of pair tokens on the classification process. It is quite reasonable to think that pairs of tokens will offer more value than single tokens alone. For example ?enlarge your? seems to suggest more information than single tokens alone. Results obtained show conclusively that pair tokens offer no value and in fact increase error over three independent data sets...|$|R
40|$|Long-term ozone {{variations}} at 60 - 70 degS {{in spring}} are investigated using ground-based and satellite measurements. Strong positive correlation is shown between year-to-year variations of ozone and {{temperature in the}} Antarctic collar region in Septembers and Octobers. Based on this relationship, the effect of year-to-year variations in vortex dynamics has been <b>filtered</b> out. This <b>process</b> <b>results</b> in an ozone time series that shows increasing springtime ozone losses over the Antarctic until the mid- 1990 s. Since approximately 1997 the ozone losses have leveled off. The analysis confirms that this change is consistent across all instruments and is statistically significant at the 95 % confidence level. This analysis quantifies {{the beginning of the}} recovery of the ozone hole, which is expected from the leveling off of stratospheric halogen loading due to the ban on CFCs and other halocarbons initiated by the Montreal Protocol...|$|R
40|$|AbstractNoisy objects {{have been}} known to affect {{negatively}} on the performance of clustering algorithms. This paper addresses the problem of high false positive rates in using self-organizing map (SOM) for DNA motif prediction due to the noisy background sequences in the input dataset. We propose the use of sequence filter in the pre-processing step to remove portion of the noisy background before applying to the SOM. Our method is motivated by the evolutionary conservation property of binding sites as opposed to randomness of background sequences. Our contributions are: (a) propose the use of string mismatch as filtering threshold function; and (b) two filtering methods, namely sequence driven and gapped consensus pattern, are proposed for filtering. We employed real datasets to evaluate the performance of SOM for DNA prediction after the <b>filtering</b> <b>process.</b> Our evaluation <b>results</b> show promising improvements in term of precision rates and also data reduction. We conclude that filtering background sequences is a feasible solution to improve prediction accuracy of using SOM for DNA motif prediction...|$|R
40|$|Abstract—In this paper, {{we present}} an {{approach}} performing object behavior classification {{embedded in a}} complex and efficient perception method. This method, applied in dynamic outdoor environments using a moving vehicle equipped with a laser scanner, is composed of a local simultaneous localization and mapping (SLAM) with detection and tracking of moving objects (DATMO). While the SLAM is performed by an implementation of incremental scan matching method, the tracking if performed by a Multiple Hypothesis Tracker (MHT) coupled with an adaptive Interacting Multiple Models Filter (IMM). The classification process {{takes place in the}} filtering stage and is based on one of the key parameters of the IMM filter which is the Transition Probability Matrix (TPM) modeling objects motion transitions. It permits to automatically classify object behavior and to reuse the classification output to enhance the prediction step in the <b>filtering</b> <b>process.</b> The experimental <b>results</b> on datasets collected from a Daimler Mercedes demonstrator in the framework of the European Project PReVENT-ProFusion 2 demonstrate the capacity of the proposed algorithm. Index Terms—Object behavior classification, SLAM, DATMO, TPM...|$|R
40|$|This thesis {{investigates the}} {{possibilities}} of using GIS (Geographic Information System) data with an airborne autonomous vehicle developed in the WITAS project. Available for the thesis are high resolution (0. 16 meter sample interval) aerial photographs over Stockholm, and vector data in a common GIS format containing all roads in the Stockholm area. A method for removing cars from aerial photographs is presented, using the filtering method normalized convolution, originally developed for filtering uncertain and incomplete data. By setting the certainty to zero over the cars, this data is disregarded in the <b>filtering</b> <b>process,</b> <b>resulting</b> in an image without cars. This method is further improved by choosing an anisotropic applicability function, resulting in a filtering that preserves structures oriented in certain directions. The available vector data is investigated with regard to its use in a simulator for vehicle movement, and {{is found to be}} missing much of the essential information needed in such a simulator. A new data format better suited to these requirements is created, using the extensible markup language (XML) which generates a humanreadable data format and can use existing parsers to make the implementation simpler. The result is a somewhat complex, but highly general data format that can accurately express almost any type of road and intersection. Cars can follow arbitrary paths in the road database and move with a smooth motion suitable for use as input to image processing equipment. The simulator does not allow any dynamic behaviour such as changing speeds, starting or stopping, or interaction between cars, takeovers or intelligent behavior in intersections. In the airborne vehicle, a mapping from pixels in a camera image (like the ones output from the simulator) to locations in the road database is needed. This is an inverse mapping with respect to visualizing as described above. This gives important information to a car tracking system regarding the probable movement of cars and also making it possible to determine if a car breaks traffic regulations. A mapping of this kind is created using a simplified form of ray tracing known as ray casting, together with space partitioning methods used to vastly improve efficiency. All above mentioned tasks are implemented using C++ and object oriented methods, giving maintainable and extendable code suiting a quickly changing research area. The interface to the simulator is designed to be compatible to the existing simulation software used in the WITAS project. Visualization is done through the OpenGL graphics library, providing realistic effects such as lighting and shading...|$|R
40|$|Order {{statistic}} and morphological filters {{belong to}} a class of nonlinear filters that have recently found many applications in signal analysis and image processing. In this paper, order statistic and morphological filters have been applied to enhance {{the features of the}} ultrasonic signal when it has been contaminated by multiple interfering microstructure echoes with random amplitudes and phases. These interfering echoes (i. e., speckles or grain scattering noise) often become significant to the point where detection of flaw echoes becomes very difficult. We have examined frequency diverse order statistic and time domain morphological and recursive median filters for improved ultrasonic flaw detection. In particular, the performance of these filters is evaluated using different ranks of order statistics and different shapes of structuring elements in the application of morphological <b>filters.</b> The <b>processed</b> experimental <b>results</b> in testing steel samples demonstrate that these filters are capable of improving flaw detection in ultrasonic systems...|$|R
40|$|A {{programming}} model called distributed <b>filter</b> <b>processes</b> for transparent <b>filtering</b> in {{distributed systems}} is presented. <b>Filter</b> <b>processes</b> are modelled as extensions to distributed processes. Messages can be captured transparently by intermediate <b>filter</b> <b>processes.</b> The programming abstractions {{are presented with}} applications {{to the evolution of}} programs. Copyright (c) 2005 John Wiley & Sons, Ltd...|$|R
40|$|AbstractStationary {{response}} and first-passage failure of hysteretic systems, such as bilinear and Bouc-Wen hysteretic models, are investigated under random excitations of Poisson white noise and its <b>filtered</b> <b>processes</b> by Monte Carlo simulation. Results are {{compared with those}} of hysteretic systems under random excitations of Gaussian white noise and its <b>filtered</b> <b>processes</b> in the same intensity condition. It is found that stationary probability densities of responses of hysteretic systems subject to Poisson white noise and its <b>filtered</b> <b>processes</b> are close to those subject to Gaussian ones when mean arrival rate of random impulses increases and first-passage failures are more likely to happen when excitations are Poisson white noise and its <b>filtered</b> <b>processes</b> for different values of intensity of random excitation...|$|R
40|$|Consider a <b>filtering</b> <b>process</b> {{associated}} to a hidden Markov model with densities for which {{both the state}} space and the observation space are complete, separable, metric spaces. If the underlying, hidden Markov chain is strongly ergodic and the <b>filtering</b> <b>process</b> fulfills a certain coupling condition we prove that, in the limit, {{the distribution of the}} <b>filtering</b> <b>process</b> is independent of the initial distribution of the hidden Markov chain. If furthermore the hidden Markov chain is uniformly ergodic, then we prove that the <b>filtering</b> <b>process</b> converges in distribution. Comment: 54 pages revision. Rewritten introduction. Theorem 12. 1 sharper than Theorem 16. 1 (v 1). Proofs and results reorganised. Example 18. 3 (v 1) exclude...|$|R
40|$|This article {{considers}} a comparison study between different non-normal process capability estimation methods and utilizing {{them in the}} leukocyte <b>filtering</b> <b>process</b> in blood service sectors. Since the amount of leukocyte in {{a unit of the}} blood is a critical issue in the blood transfusion process and patient safety, estimating and monitoring the capability of the leukocyte <b>filtering</b> <b>process</b> to meet the target window is very important for blood service sectors. However, observed data from the leukocyte <b>filtering</b> <b>process</b> show that the leukocyte levels after filtering demonstrate a right skewed distribution and applying conventional methods with a normality assumption fails to provide trustful results. Hence, we first conduct a simulation study to compare different methods in estimating the process capability index of non-normal processes and then we apply these techniques to obtain the process capability of the leukocyte <b>filtering</b> <b>process.</b> The study reveals that the Box-Cox transformation method provides reliable estimation of the process capability of the leukocyte <b>filtering</b> <b>process...</b>|$|R
40|$|The SAGA editor {{provides}} a {{mechanism by which}} separate processes can be invoked during an editing session to traverse portions of the parse tree being edited. These <b>processes,</b> termed <b>filter</b> <b>processes,</b> read, analyze, and possibly transform the parse tree, returning the result to the editor. By defining new commands with the editor's user defined command facility, which invoke <b>filter</b> <b>processes,</b> authors of <b>filter</b> can provide complex operations as simple commands. A tree plotter, pretty printer, and Pascal tree transformation program were already written using this facility. The <b>filter</b> <b>processes</b> are introduced, parse tree structure is described and the library interface {{made available to the}} programmer. Also discussed is how to compile and run <b>filter</b> <b>processes.</b> Examples are presented to illustrate aspect of each of these areas...|$|R
50|$|Crowdsourced {{drivers must}} undergo an {{extensive}} <b>filtering</b> <b>process.</b>|$|R
