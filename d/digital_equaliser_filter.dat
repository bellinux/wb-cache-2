0|15|Public
40|$|Shingled Magnetic Recording (SMR) {{has been}} {{recognised}} {{as one of}} the alternative technologies to achieve an areal density beyond the limit of the perpendicular recording technique, 1 Tb/in 2, which has an advantage of extending the use of the conventional method media and read/write head. This work presents SMR system subject to both Inter Symbol Interference (ISI) and Inter Track Interference (ITI) and investigates different equalisation/detection techniques {{in order to reduce the}} complexity of this system. To investigate the ITI in shingled systems, one-track one-head system model has been extended into two-track one-head system model to have two interfering tracks. Consequently, six novel decoding techniques have been applied to the new system in order to find the Maximum Likelihood (ML) sequence. The decoding complexity of the six techniques has been investigated and then measured. The results show that the complexity is reduced by more than three times with 0. 5 dB loss in performance. To measure this complexity practically, perpendicular recording system has been implemented in hardware. Hardware architectures are designed for that system with successful Quartus II fitter which are: Perpendicular Magnetic Recording (PMR) channel, <b>digital</b> <b>filter</b> <b>equaliser</b> with and without Additive White Gaussian Noise (AWGN) and ideal channel architectures. Two different hardware designs are implemented for Viterbi Algorithm (VA), however, Quartus II fitter for both of them was unsuccessful. It is found that, Simulink/Digital Signal Processing (DSP) Builder based designs are not efficient for complex algorithms and the eligible solution for such designs is writing Hardware Description Language (HDL) codes for those algorithms. The Iraqi Governmen...|$|R
50|$|The lattice phase <b>equaliser,</b> or <b>filter,</b> is {{a filter}} {{composed}} of lattice, or X-sections. With single element branches it {{can produce a}} phase shift up to 180°, and with resonant branches it can produce phase shifts up to 360°. The filter {{is an example of}} a constant-resistance network (i.e., its image impedance is constant over all frequencies).|$|R
5|$|The {{nominal value}} of the input, output or image {{impedance}} of a port of a network, especially a network intended for use with a transmission line, such as <b>filters,</b> <b>equalisers</b> and amplifiers.|$|R
5000|$|... d2 and d3 Plugins - Equaliser and Comp/Limiter (1995) In 1995, Focusrite {{moved into}} a new area for the company, {{in the form of a}} {{collaboration}} with Digidesign (now Avid Audio) on the development of two software plugins for the market-leading Pro Tools digital audio workstation environment. These were the first software plugins to not only emulate the processing capabilities of a piece of hardware, but also their look and feel: Focusrite d2 is a high-quality <b>digital</b> <b>equaliser</b> based on the Focusrite Red 2 Equaliser, whose design can be traced back to Rupert Neve; while d3 emulates the Red 3 Compressor/limiter. Both are still available at the time of writing (April 2013). These plugins included modelling of a suitably red front-panel with controls like those on the physical products, plus a large graph display showing how the plugin was configured - not something that would have been possible to do on the hardware.|$|R
40|$|In {{current high}} bit rate long haul point to point optical {{communication}} system, the chromatic dispersion of a single mode fibre is the main limitation to increase the bit rate. This paper proposes a promising technique to compensate chromatic dispersion, hence improving the bit error rate and repeater-less span. This compensation scheme uses an optical all pass <b>filter</b> <b>equaliser</b> that is optimised by {{minimum mean square error}} technique. The practical implementation of an optical all pass filter using passive infinite impulse response digital filter structure is also introduced. The simulated results showed that a dispersed rectangular pulse is fully compensated at full-width half at maximum after propagating 160 km of SMF and the resultant eye pattern showed an improvement to the bit error rate when the proposed optical all pass <b>filter</b> <b>equaliser</b> is used...|$|R
40|$|Channel Equalisation {{is carried}} out to {{mitigate}} the effect of non-ideal channel behaviour in digital communication systems. The first <b>equalisers</b> were linear <b>filters</b> which slowly led to more complex but better performance non-linear methods. Wavelets have also been successfully applied to this domain. This document intends to give an overview of the use of wavelets to equalisation of non-ideal channels...|$|R
5000|$|When valve {{amplifiers}} {{were the}} norm, user-adjustable [...] "tone controls" [...] (a simple two-band non-graphic <b>equaliser)</b> and electronic <b>filters</b> {{were used to}} allow the listener to change frequency response according to taste and room acoustics; this has become uncommon. Some modern equipment uses graphic equalisers, but valve preamplifiers tend not to supply these facilities (except for RIAA and similar equalisation needed for vinyl and shellac discs).|$|R
40|$|Blind channel {{identification}} and equalisation are the {{processes by which}} a channel impulse response can be identified and proper <b>equaliser</b> <b>filter</b> coefficients can be obtained, without knowledge of the transmitted signal. Techniques that exploit cyclostationarity can reveal information about systems which are nonminimum phase; nonminimum phase channels cannot be identified using only second-order statistics (SOS), because these do not contain the necessary phase information. Cyclostationary blind equalisation methods exploit the fact that, sampling the received signal at a rate higher than the transmitted signal symbol rate, the received signal becomes cyclostationary. In general, cyclostationary blind equalisers can identify a channel with less data than higher-order statistics (HOS) methods, and unlike these, no constraint is imposed on the probability distribution function of the input signal. Nevertheless, cyclostationary methods suffer from some drawbacks, such {{as the fact that}} some channels are unidentifiable when they exhibit a number of zeros equally spaced around the unit circle. In this thesis the performance of a cyclostationary blind {{channel identification}} algorithm combined with a maximum-likelihood sequence estimation receiver is analysed. The simulations were conducted in the pan-European mobile communication system GSM environment and the performance of the blind technique was compared with conventional channel estimation methods using training. It is shown that although blind equalisation techniques can converge in a few hundred symbols in a time-invariant channel environment, the degradation with respect to methods with training is still considerable. Yet, the fact that a dedicated training sequence is not needed makes blind techniques attractive, because the data used for training purposes can be re-allocated as information data. In the concluding part of this thesis a new blind channel identification algorithm which combines methods that exploit cyclostationarity implicitly and explicitly is presented. It is shown that the properties of cyclostationary statistics are exploited in the new algorithm, and enhance the performance of the technique that solely exploits fractionally-spaced sampling. The algorithm is robust in the presence of correlated noise and interference from adjacent users...|$|R
50|$|A lattice phase <b>equaliser</b> or lattice <b>filter</b> is {{an example}} of an all-pass filter. That is, the {{attenuation}} of the filter is constant at all frequencies but the relative phase between input and output varies with frequency. The lattice filter topology has the particular property of being a constant-resistance network and for this reason is often used in combination with other constant resistance filters such as bridge-T equalisers. The topology of a lattice filter, also called an X-section is identical to bridge topology. The lattice phase equaliser was invented by Otto Zobel. using a filter topology proposed by George Campbell.|$|R
50|$|This more {{predictable}} response of video allows a different design approach. The video equaliser is {{built as a}} single bridged T section but with a rather more complex network for Z. For short lines, or for a trimming <b>equaliser,</b> a Bode <b>filter</b> topology might be used. For longer lines a network with Cauer filter topology might be used. Another driver for this approach {{is the fact that}} a video signal occupies a large number of octaves, around 20 or so. If equalised with simple basic sections, a large number of filter sections would be required. Simple sections are designed, typically, to equalise a range of one or two octaves.|$|R
2500|$|This more {{predictable}} response of video allows a different design approach. [...] The video equaliser is {{built as a}} single bridged T section but with a rather more complex network for Z. [...] For short lines, or for a trimming <b>equaliser,</b> a Bode <b>filter</b> topology might be used. [...] For longer lines a network with Cauer filter topology might be used. [...] Another driver for this approach {{is the fact that}} a video signal occupies a large number of octaves, around 20 or so. [...] If equalised with simple basic sections, a large number of filter sections would be required. [...] Simple sections are designed, typically, to equalise a range of one or two octaves.|$|R
40|$|Adaptive Wireless Transceivers {{provides}} {{the reader with}} a broad overview of near-instantaneously adaptive transceivers {{in the context of}} TDMA, CDMA and OFDM systems. The adaptive transceivers examined employ powerful turbo codecs, turbo equalisers and space-time codecs, equipping the reader with a future-proof technological road map. It demonstrates that adaptive transceivers are capable of mitigating the channel quality fluctuations of the wireless channel as a lower-complexity alternative to space-time coding. By contrast, if the higher complexity of multiple transmitters and multiple receiver-assisted systems is deemed acceptable, the advantages of adaptability erode. • Provides an in-depth introduction to channel <b>equalisers</b> and Kalman <b>filtering</b> and discusses the associated complexity versus performance trade-offs • Introduces wideband near-instantaneously adaptive transceivers and studies their performance both with and without turbo channel coding • Describes how to optimise adaptive modulation mode switching and highlights a range of practical considerations • Introduces neural network based channel equalisers and discusses Radial Basis Function (RBF) assisted equalisers embedded into adaptive modems supported by turbo channel coding and turbo channel equalisation • Employs the above adaptive principles also in the context of CDMA and OFDM transceivers and discusses {{the pros and cons of}} space-time coding versus adaptive modulation Researchers, advanced students and practising development engineers working in wireless communications will all find this valuable text an informative read...|$|R
40|$|A Doctoral Thesis. Submitted in partial {{fulfillment}} of the requirements for the award of Doctor of Philosophy of Loughborough University. In the testing of highly absorbent materials, {{it is necessary to}} use high transmitted power to obtain echoes with an acceptable signal-to-noise ratio from deep defects. However, the maximum peak power which can be used is limited by the construction problems of the probes and the physical properties of the crystal materials. Using longer pulses to transmit more energy could improve the detection, but would reduce the resolution of the system. Pulse compression techniques which overcome the conflict between resolution and pulse duration, provide a possible solution to the above problem. The method involves the transmission of a long coded pulse and the processing of the received echo to obtain a relatively narrow pulse, thus preserving resolution. After a study of the principles of pulse compression, various practical schemes were investigated, and the linear frequency-modulated pulse compression systems were found to be most economical to implement. Upon being received, the pulse may be compressed by means of a dispersive ultrasonic delay line, and simple Gaussian shape filter may be employed to reduce the resulting sidelobes. Theoretical studies on the dispersive modes of propagation of elastic waves in narrow metallic strips were then made, and demonstrated the feasibility of using a metallic strip as the dispersive delay device, provided that equalisers are introduced to compensate for the inherent time delay non-linearities in the strip. Design problems associated with the piezoelectric bar transducers for use with the line were also investigated. Based on the above studies, a pulse compression testing system consisting of a transmitting unit, a pair of wide-band transmitting and receiving transducers and a receiving unit, has been constructed. The transmitting unit comprises a linear frequency-modulated oscillator and timing circuits; the receiving unit incorporates <b>equalisers,</b> a weighting <b>filter</b> and an aluminium strip delay line. The operating system achieves a time bandwidth product of 80 and a sidelobe level of - 25 dB. Practical tests were carried out and test results are reported. Finally, the power and limitations of the testing system are discussed...|$|R
40|$|Effective {{interactive}} computing {{methods are}} needed {{in a number of}} specific areas of geophysical interpretation, even though the basic algorithms have been established. One approach to raise the quality of interpretation is to promote better interaction between human and the computer. The thesis is concerned with improving this dialog in three areas: automatic event picking, data visualization and sparse data imaging. Fully automatic seismic event picking methods work well in relatively good conditions. They collapse when the signal-to-noise ratio is low and the structure of the subsurface is complex. The interactive seismic event picking system described here blends the interpreter's guidance and judgment into the computer program, as it can bring the user into the loop to make subjective decisions when the picking problem is complicated. Several interactive approaches for 2 -D event picking and 3 -D horizon tracking have been developed. Envelope (or amplitude) threshold detection for first break picking {{is based on the assumption}} that the power of the signal is larger than that of the noise. Correlation and instantaneous phase pickers are designed for and better suited to picking other arrivals. The former is based on the cross-correlation function, and a model trace (or model traces) selected by the interpreter is needed. The instantaneous phase picker is designed to track spatial variations in the instantaneous phase of the analytic form of the arrival. The picking options implemented into the software package SeisWin were tested on real data drawn from many sources, such as full waveform sonic borehole logs, seismic reflection surveys and borehole radar profiles, as well as seven of the most recent 3 -D seismic surveys conducted over Australian coal mines. The results show that the interactive picking system in SeisWin is efficient and tolerant. The 3 -D horizon tracking method developed especially attracts industrial users. The visualization of data is also a part of the study, as picking accuracy, and indeed the whole of seismic interpretation depends largely on the quality of the final display. The display is often the only window through which an interpreter can see the earth's substructures. Display is a non-linear operation. Adjustments made to meet display deficiencies such as automatic gain control (AGC) have an important and yet ill-documented effect on the performance of pattern recognition operators, both human and computational. AGC is usually implemented in one dimension. Some of the tools in wide spread use for two dimensional image processing which are of great value in the local gain control of conventional seismic sections such as edge detectors, histogram <b>equalisers,</b> high-pass <b>filters,</b> shaded relief are discussed. Examples are presented to show the relative effectiveness of various display options. Conventional migration requires dense arrays with uniform coverage and uniform illumination of targets. There are, however, many instances in which these ideals can not be approached. Event migration and common tangent plane stacking procedures were developed especially for sparse data sets as a part of the research effort underlying this thesis. Picked-event migration migrates the line between any two points on different traces on the time section to the base map. The interplay between the space and time domain gives the interpreter an immediate view of mapping. Tangent plane migration maps the reflector by accumulating the energy from any two possible reflecting points along the common tangent lines on the space plane. These methods have been applied to both seismic and borehole-radar data and satisfactory results have been achieved...|$|R

