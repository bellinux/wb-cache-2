2|47|Public
40|$|A plastic {{constitutive}} theory {{incorporating the}} directional {{dependence of the}} plastic strain increment dε^p on the stress increment dσ' was proposed by Goya and Ito. The expression was given in terms of two transition parameters μ(α) and β(α) which denote the magnitude and the direction angle of the plastic increment, where α denotes the direction angle of the stress increment measured from a particular direction n_N, named "natural direction", in which {{the direction of the}} stress increment coincide with that of the plastic strain increment. In this report, a computer code for a finite element polycrystalline model is used for the numerical investigation of the variation of the two constitutive parameters μ(α) and β(α) of anisotropic plastic materials. The results show that the approximate functions for the two transition parameters are numerically determined and the direction <b>dependence</b> <b>rule</b> can be naturally extended for anisotropic plastic materials. It is also suggested that several quadratic functions used for classical plastic potential may be introduced for the natural direction potential whose normal is identical to the natural direction...|$|E
40|$|The {{occultation}} of epsilon Geminorum by Mars on 1976 April 8 {{was observed}} at three wavelengths and 4 ms time resolution with the 91 cm telescope. Temperature, pressure, and number density profiles of the Martian atmosphere were obtained for both the immersion and emersion events. Within the altitude range of 50 to 80 km above the mean surface, the mean temperature is 145 K, and the profiles exhibit wavelike structures with a peak to peak amplitude of 35 K and a vertical scale of about 20 km. The ratio of the refractivity of the atmosphere at 4500 A and 7500 A, determined from the time shift of the light curves for these wavelengths, {{is consistent with the}} atmospheric composition measured by Viking 1, 15 weeks later. From the central flash - a bright feature in the light curve midway between immersion and emersion - an optical depth is found at 4500 A of 3. 3 plus or minus 1. 7 per km atm (about 0. 23 per equivalent Martian air mass) for the atmosphere about 25 km above the mean surface, near the south polar region. This large value and its weak wavelength <b>dependence</b> <b>rule</b> out Rayleigh scattering as the principal cause of the observed extinction...|$|E
40|$|In {{the paper}} a new data mining {{algorithm}} for finding {{the most interesting}} <b>dependence</b> <b>rules</b> is described. <b>Dependence</b> <b>rules</b> are derived from the itemsets with support significantly different from its expected value and therefore considered interesting. Since such itemsets are distributed non-monotonically in the lattice of all itemsets the support monotonicity property cannot be used for their search. Instead we estimate upper/lower bounds for the support to find itemsets with large interval of possible support values called support quota. Since the support quota {{is known to be}} monotonically decreasing the search space can be effectively restricted. Strongly dependent itemsets are selected by computing their expected support using iterative proportional fitting algorithm and comparing it with the real itemset support...|$|R
40|$|This paper {{shows how}} the use of Galois lattices and formal concept {{analysis}} �FCA) can support CBR application designers, in the task of discovering knowledge embedded in the cases. FCA applied on a case library provides an internal sight of the conceptual structure and allows ®nding patterns, regularities and exceptions among the cases. Moreover, it extracts certain <b>dependence</b> <b>rules</b> between the attributes describin...|$|R
40|$|One of {{the more}} well-studied {{problems}} in data mining is the search for association rules in market basket data. Association rules are intended to identify patterns of the type: "A customer purchasing item A often also purchases item B. " Motivated partly by the goal of generalizing beyond market basket data and partly by the goal of ironing out some problems {{in the definition of}} association rules, we develop the notion of <b>dependence</b> <b>rules</b> that identify statistical dependence in both the presence and absence of items in itemsets. We propose measuring significance of dependence via the chi-squared test for independence from classical statistics. This leads to a measure that is upward-closed in the itemset lattice, enabling us to reduce the mining problem to the search for a border between dependent and independent itemsets in the lattice. We develop pruning strategies based on the closure property and thereby devise an efficient algorithm for discovering <b>dependence</b> <b>rules.</b> We demonstrat [...] ...|$|R
40|$|Prompted by the {{generally}} poor {{understanding of the}} nature of magnetic phenomena in 3 d-metal doped ZnO, we have undertaken on-line Fe- 57 Mossbauer spectroscopy on ZnO single crystals in an external magnetic field of 0. 6 T, following the implantation of radioactive Mn- 57 ions at room temperature. The Mossbauer spectra of the dilute Fe impurities are dominated by sextets whose angular <b>dependence</b> <b>rules</b> out an ordered magnetic state (which had been previously proposed) but are well accounted for on the basis of Fe 3 + paramagnetic centers on substitutional Zn sites with unusually long relaxation times (> 20 ns). (C) 2010 American Institute of Physics. {[}doi: 10. 1063 / 1. 3490708...|$|R
50|$|As a {{historical}} institution, bureaucracy {{developed during the}} emergence of the European nation-state, when breakup of feudal and postfeudal hierarchies made <b>dependence</b> on <b>rules</b> necessary. As bureaucracy developed, bureaucratic staffs acquired interests of their own. Systems of rules and hierarchy allowed bureaucracies to resist encroachments of rulers and social groups and pretend to be above politics.|$|R
40|$|There is {{a strong}} body of {{evidence}} that patterns of collective behaviour in grouping animals are governed by interactions between small numbers of individuals within the group. These findings contrast with study of the ‘selfish herd’, where increasingly complex individual-level movement rules have been proposed to explain the rapid increase in aggregation observed when prey groups are startled by or detect a predator. While individuals using simple rules {{take into account the}} position of only a few neighbours, those using complex rules incorporate multiple neighbours, and their relative distance, to determine their movement direction. Here, we simulate the evolution of selfish herd behaviour to assess the conditions under which simple and complex movement rules might evolve, explicitly testing predictions arising from previous work. We find that complex rules outperform simple ones under a range of predator attack strategies, but that simple rules can fix in populations particularly when they are already in the majority, suggesting strong positive frequency <b>dependence</b> in <b>rule</b> success. In addition, we explore whether a movement rule derived from studies of collective behaviour (where individuals use the position of seven neighbours to determine movement direction) performs as successfully as more complex rules, finding again positive frequency <b>dependence</b> in <b>rule</b> success, and a particular role for predator attack strategy (from within or outside the group). PostprintPeer reviewe...|$|R
40|$|In the {{beginning}} of this bachelor's thesis, the packet filtering and a base of the packet classification are discussed. It studies several basic classification algorithms. In the second half of this work, the Distributed Crossproducting of Field Labels algorithm is shown in detail. Finally, the software implementation in Python is described and the evaluation containing the memory <b>dependence</b> on various <b>rule</b> sets is presented...|$|R
40|$|This paper {{describes}} a general framework for representing iteration-reordering transformations. These transformations {{can be both}} matrix-based and non-matrix-based. Transformations are defined by <b>rules</b> for mapping <b>dependence</b> vectors, <b>rules</b> for mapping loop bound expressions, and rules for creating new initialization statements. The framework is extensible, {{and can be used}} to represent any iterationreordering transformation. Mapping rules for several common transformations are included in the paper. 1 Introduction Iteration-reordering transformations are a special class of program transformations that only change the execution order of loop iterations in a perfect loop nest without changing the contents of the loop body. Iterationreordering transformations are used extensively by restructuring compilers for optimizing vector execution, parallel execution, and data locality. Prior work on iterationreordering loop transformations can mainly be classified as either a) proposing new iterat [...] ...|$|R
40|$|The thesis {{objective}} was to study the partnership between the municipality of Gothenburg and three nonprofit organizations concerning the mobile EU-citizens. The study examines how the EU-enlargement affected Sweden and eventually the municipality of Gothenburg, and how Gothenburg responded to the new situation regarding the target group. The thesis contains one case study and the empirical data are based on semi structured interviews with politicians and officials from both the public- and the nonprofit sector. The results were screened with New Institutional Theory, Resource Dependence Theory and Decision Making Theory: Rule Following. The theories were used to locate any type of isomorphism, resource <b>dependence</b> and <b>rule</b> following in the partnership. The {{results show that the}} partnership turned out successful and that the municipality of Gothenburg may become standard-setting in this specific area...|$|R
40|$|SUMMARY: The {{conventional}} {{approach to}} calculating biomolecular structures from {{nuclear magnetic resonance}} (NMR) data is often viewed as subjective due to its <b>dependence</b> on <b>rules</b> of thumb for deriving geometric constraints and suitable values for theory parameters from noisy experimental data. As a result, {{it can be difficult}} to judge the precision of an NMR structure in an objective manner. The Inferential Structure Determination (ISD) framework, which has been introduced recently, addresses this problem by using Bayesian inference to derive a probability distribution that represents both the unknown structure and its uncertainty. It also determines additional unknowns, such as theory parameters, that normally need be chosen empirically. Here we give an overview of the ISD software package, which implements this methodology. AVAILABILITY: The program is available at [URL]...|$|R
40|$|Abstract — Co-development {{of design}} rules and layout methodologies {{is the key}} to {{successful}} adoption of a technology. In this work, we propose Chip-level Design Rule Evaluator (ChipDRE), the first framework for systematic evaluation of design rules and their interaction with layouts, performance, margins and yield at the chip scale (as opposed to standard cell-level). A “good chips per wafer ” metric is used to unify area, performance, variability and yield. The framework uses a generated virtual standard-cell library coupled with a mix of physical design, semi-empirical, and machine-learning-based models to estimate area and delay at the chip level. The result is a unified design-quality estimate that can be computed fast enough to allow using ChipDRE to optimize a large number of complex design rules. For instance, a study of well-to-active spacing rule reveals a non-monotone <b>dependence</b> of <b>rule</b> value to chip area (although the dependence to cell area is monotone) due to delay changes coming from well-proximity effect. I...|$|R
40|$|WOS: 000360272500005 International audienceSinglet {{excitons}} in pi-stacked molecular crystals can {{split into}} two triplet excitons in a process called singlet fission that opens a route to carrier multiplication in photovoltaics. To resolve controversies about the mechanism of singlet fission, we have developed a first principles nonadiabatic quantum dynamical model that reveals the critical role of molecular stacking symmetry and provides a unified picture of coherent versus thermally activated singlet fission mechanisms in different acenes. The slip-stacked equilibrium packing structure of pentacene derivatives is found to enhance ultrafast singlet fission mediated by a coherent superexchange mechanism via higher-lying charge transfer states. By contrast, the electronic couplings for singlet fission strictly vanish at the C- 2 h symmetric equilibrium pi stacking of rubrene. In this case, singlet fission is driven by excitations of symmetry-breaking intermolecular vibrations, rationalizing the experimentally observed temperature <b>dependence.</b> Design <b>rules</b> for optimal singlet fission materials therefore need {{to account for the}} interplay of molecular pi-stacking symmetry and phonon-induced coherent or thermally activated mechanisms...|$|R
40|$|Using {{field data}} from a large U. S. {{technology}} transfer organization with over $ 50 million in annual revenue, we investigate four related issues regarding the sharing of licensing revenues by academic teams. First, {{we find that the}} main empirical regularity is a heuristic-based allocation of shares 1 /n, equal shares to all unique inventors in a single invention team, {{and the use of the}} partition <b>dependence</b> (PD) <b>rule,</b> whereby inventors receive equal share within an invention and shares across inventions included in the same contract are equal. Second, when we examine the performance consequences of such equal sharing, we find it is negatively related to performance. Third, using both matched sample estimations and examining strategic switchers, i. e., the case of inventors who switch between equal and unequal sharing, we find that self-selection rather than shirking explains the negative performance. Finally, the pattern of their switching is random in time — i. e., there is no movement toward unequal rules over time so inventors are not learning to use unequal rules...|$|R
40|$|Abstract. Generating {{decision}} rule sets from observational data is an established branch of machine learning. Although such rules may be well-suited to machine execution, {{a human being}} may have problems interpreting them. Making inferences about the dependencies {{of a number of}} attributes on each other by looking at the rules is hard, hence the need to summarize and visualize a rule set. In this paper we propose using dependence diagrams as a means of illustrating the amount of influence each attribute has on others. Such information is useful in both causal and non-causal contexts. We provide examples of <b>dependence</b> diagrams using <b>rules</b> extracted from two datasets. ...|$|R
40|$|The Poverty of the Stimulus (PoS) {{argument}} {{holds that}} {{children do not}} receive enough evidence to infer the exis-tence of core aspects of language, such as the <b>dependence</b> of linguistic <b>rules</b> on hierarchical phrase structure. We reevaluate one version of this argument with a Bayesian model of grammar induction, and show that a rational learner without any initial language-speci¯c biases could learn this dependency given typical child-directed input. This choice enables the learner to master aspects of syn-tax, such as the auxiliary fronting rule in interrogative formation, even without having heard directly relevant data (e. g., interrogatives containing an auxiliary in a relative clause in the subject NP). Amy Perfors, Joshua B. Tenenbaum and Terry Regie...|$|R
40|$|Linear density {{response}} {{functions are}} calculated for symmetric nuclear matter of normal density by time-evolving two-time Green's functions in real time. The feasability and convenience {{of this approach}} to this particular problem {{has been shown in}} previous publications. Calculations are here improved by using more 'realistic' interactions derived from phase-shifts by inverse scattering. Of particular interest is the effect of the strong correlations in the nuclear medium on the response. This as well as the related energy weighted sum <b>rule,</b> <b>dependence</b> on mean field and effective mass are some of the main objects of this investigation. Comparisons are made with the collision-less limit, the HF+RPA method. The importance of vertex corrections is demonstrated...|$|R
40|$|To {{investigate}} the network-growth <b>rule</b> <b>dependence</b> of certain geometric aspects of percolation clusters, we propose a generalized network-growth rule introducing a generalized parameter q and we study the time {{evolution of the}} network. The rule we propose includes a rule in which elements are randomly connected step by step and the rule recently proposed by Achlioptas et al. [Science 323 (2009) 1453]. We consider the q-dependence {{of the dynamics of}} the number of elements in the largest cluster. As q increases, the percolation step is delayed. Moreover, we also study the q-dependence of the roughness and the fractal dimension of the percolation cluster. Comment: 4 pages, 5 figures, accepted for publication in Journal of the Physical Society of Japa...|$|R
40|$|The optical {{conductivity}} of {{the double}} exchange and the orbital degenerate Kondo lattice Hamiltonian (orbital t-J model) are invetigated by means of finite temperature diagonalization for different doping concentrations. The temperature <b>dependence</b> of sum <b>rules,</b> kinetic energy and Drude weight are studied. In particular it is shown that the double exchange model cannot explain the anomalous absorption in the uniform ferromagnetic phase of manganites discovered Okimoto et al. [Phys. Rev. Lett. 75, 109 (1995) ]. The orbital t-J model explains the increase of the anomalous absorption with decreasing temperature, its energy scale (~ 1 eV) and intensity. It also explains {{the appearance of the}} additional narrow Drude peak at low temperature. Comment: 24 pages, 17 figure...|$|R
2500|$|Mattey elaborates further [...] on the positive, redeeming {{aspect of}} the {{seemingly}} bleak, frustrating themes of existentialism that are so apparent in Nausea: [...] "Sartre considered the subjectivity of the starting-point for what a human is as a key thesis of existentialism. The starting-point is subjective because humans make themselves what they are. Most philosophers consider subjectivity {{to be a bad}} thing, {{particularly when it comes to}} the motivation for action... Sartre responds by claiming that subjectivity is a dignity of human being, not something that degrades us." [...] Therefore, the characteristic anguish and forlornness of existentialism are temporary: only a prerequisite to recognizing individual responsibility and freedom. The basis of ethics is not rule-following. A specific action may be either wrong or right and no specific rule is necessarily valid. What makes the action, either way, ethical is [...] "authenticity," [...] the willingness of the individual to accept responsibility rather than <b>dependence</b> on <b>rules,</b> and to commit to his action. Despair, the existentialist says, is the product of uncertainty: being oriented exclusively to the outcome of a decision rather than to the process yields uncertainty, as we cannot decide the future, only our action.|$|R
40|$|In many real-life situations, we do {{not know}} the actual {{dependence}} y = f(x 1, [...] ., xn) between the physical quantities xi and y, we only know expert <b>rules</b> describing this <b>dependence.</b> These <b>rules</b> are often described by using imprecise (2 ̆ 2 fuzzy 2 ̆ 2) words from natural language. Fuzzy techniques have been invented with the purpose to translate these rules into a precise dependence y = f(x 1, [...] ., xn). For deterministic dependencies y = f(x 1, [...] ., xn), there are universal approximation results according to which for each continuous function on a bounded domain and for every ε 3 ̆e 0, there exist fuzzy rules for which the resulting approximate dependence y = F(x 1, [...] ., xn) is ε-close to the original function f(x 1, [...] ., xn). In practice, many dependencies are random, in the sense that for each combination of the values x 1, [...] ., xn, we may get different values y with different probabilities. It has been proven that fuzzy systems are universal approximators for such random dependencies as well. However, the existing proofs are very complicated and not intuitive. In this paper, we provide a simplified proof of this universal approximation property...|$|R
40|$|The {{mechanism}} of high temperature superconductivity is not resolved {{for so long}} because the normal state of cuprates is not yet understood. Here we show that the normal state pseudo-gap exhibits an unexpected non-monotonic temperature <b>dependence,</b> which <b>rules</b> out the possibility to describe it by a single mechanism such as superconducting phase fluctuations. Moreover, this behaviour, being remarkably similar to the behaviour of the charge ordering gap in the transition-metal dichalcogenides, completes the correspondence between these two classes of compounds: the cuprates in the PG state and the dichalcogenides in the incommensurate charge ordering state reveal virtually identical spectra of one-particle excitations as function of energy, momentum and temperature. These {{results suggest that the}} normal state pseudo-gap, which was considered to be very peculiar to cuprates, seems to be a general complex phenomenon for 2 D metals. This may not only help to clarify the normal state electronic structure of 2 D metals but also provide new insight into electronic properties of 2 D solids where the metal-insulator and metal-superconductor transitions are considered on similar basis as instabilities of particle-hole and particle-particle interaction, respectively...|$|R
5000|$|Mattey elaborates further [...] on the positive, redeeming {{aspect of}} the {{seemingly}} bleak, frustrating themes of existentialism that are so apparent in Nausea: [...] "Sartre considered the subjectivity of the starting-point for what a human is as a key thesis of existentialism. The starting-point is subjective because humans make themselves what they are. Most philosophers consider subjectivity {{to be a bad}} thing, {{particularly when it comes to}} the motivation for action... Sartre responds by claiming that subjectivity is a dignity of human being, not something that degrades us." [...] Therefore, the characteristic anguish and forlornness of existentialism are temporary: only a prerequisite to recognizing individual responsibility and freedom. The basis of ethics is not rule-following. A specific action may be either wrong or right and no specific rule is necessarily valid. What makes the action, either way, ethical is [...] "authenticity," [...] the willingness of the individual to accept responsibility rather than <b>dependence</b> on <b>rules,</b> and to commit to his action. Despair, the existentialist says, is the product of uncertainty: being oriented exclusively to the outcome of a decision rather than to the process yields uncertainty, as we cannot decide the future, only our action.|$|R
40|$|The {{value of}} the {{theoretical}} constant used to scale daily volatility to both a five-day volatility estimate and a ten-day volatility estimate is compared with empirical estimates using a volatility modeling framework. Five composite stock indexes are analyzed to determine the different behaviors of scaling across markets. Both developed and emerging markets are considered, to provide additional detail to the comparisons. The results provided are considered in a value-at-risk application. While using the square-root-of-time rule on a weekly or ten-day basis is appropriate in certain cases, for time series with a linear <b>dependence</b> component the <b>rule</b> can drastically err from observed volatility levels. It is demonstrated that there are potential hazards when using the square-root-of-time rule for risk or compliance purposes...|$|R
30|$|Similar to the {{previous}} attack scenario, the accuracy in detecting Sybil attacks depends on {{the accuracy of the}} UWB distance measurements. As shown in Figure 7 b, the detection accuracy of Sybil attacks ranges between 99 % and 78.8 %. The drop in the detection accuracy is higher when compared to {{the previous}} attack scenario. This is actually an indication of the higher <b>dependence</b> between the <b>rule</b> being applied to detect this kind of attack and the distance estimation error, εr. Apparently, the distance-matching criterion could not be satisfied when inaccuracies in the range estimates, εr, are introduced. Following this observation, we then relaxed the matching criterion and adjusted the rule, taking into account errors in the distance estimation in the order of 2 %. By doing this, we slightly reduced the number of generated false negatives (see Figure 8 b).|$|R
40|$|Abstract: In formal ontology, {{infinite}} regresses {{are generally}} considered a bad sign. One debate where such regresses {{come into play}} is the debate about fundamentality. Arguments in favour of some type of fundamentalism are many, but they generally share the idea that infinite chains of ontological <b>dependence</b> must be <b>ruled</b> out. Some motivations for this view will be assessed, with the conclusion that such infinite chains {{may not always be}} vicious. Indeed, there may even be room for a type of fundamentalism combined with infinite descent as long as this descent is ‘boring’, i. e., the same structure repeats ad infinitum. In this paper, a start will be made towards a systematic account of this type of infinite descent. The philosophical prospects and scientific tenability of the account are briefly evaluated using an example from physics...|$|R
40|$|Because of its researching object {{always be}} {{provided}} with spatial attribute, spatial statistics differs from traditional statistics. In this paper, besides {{of the definition of}} Spatial Statistics, the difference between them is discussed. Compared to statistics, spatial statistics is a very young one. Five models are introduced in this paper. They are Spatial Autoregressive Model, Spatial Aotucorrelated Model, The mixed Autoregressive-regressive Model, Spatial autoregressive error mode and The General Spatial Mode. On the application aspect, by Using the Spatial Autoregressive Model, SAR (the spatial autocorrelative mode) and SAC (the general spatial model)., from the Moran’s I statistics, the marginal probability, the spatial autocorrelation parameter and R-square values we could gain the spatial <b>dependence</b> and evolvement <b>rule</b> of radio and TV industry in China. And the conclusion is that they are fitting the data famously, and the quantities could be explained fully. 1...|$|R
40|$|In formal ontology, {{infinite}} regresses {{are generally}} considered a bad sign. One debate where such regresses {{come into play}} is the debate about fundamentality. Arguments in favour of some type of fundamentalism are many, but they generally share the idea that infinite chains of ontological <b>dependence</b> must be <b>ruled</b> out. Some motivations for this view are assessed in this article, with the conclusion that such infinite chains {{may not always be}} vicious. Indeed, there may even be room for a type of fundamentalism combined with infinite descent as long as this descent is “boring,” that is, the same structure repeats ad infinitum. A start is made in the article towards a systematic account of this type of infinite descent. The philosophical prospects and scientific tenability of the account are briefly evaluated using an example from physic...|$|R
40|$|Summation. A {{specifically}} modern {{approach to}} the interpretation of art is distinguished, rooted in the insight that cognitivity in interpretation must be oriented by sensitivity to the subject-object paradigm. It is shown that specific modern theory of interpretation has become established in twentieth-century theory and practice. That theory is demonstrated to be a set of interpretative <b>rules.</b> The hidden <b>dependence</b> of those <b>rules</b> on specific conceptions {{of the nature of}} a work of art (qua hermeneutic entity) is revealed. Three such conceptions of the work of art that are basic to modern art history are articulated and critically examined by careful attention to actual works. Interpretation is shown to exceed the strictures of each model, with the specific consequence that the meaning of the work of art in modern times is systematically narrowed. Motives for that narrowing are discussed. (Abstract shortened by UMI. ...|$|R
5000|$|The dual-route {{theory of}} reading aloud was first {{described}} in the early 1970s. This theory suggests that two separate mental mechanisms, or cognitive routes, are involved in reading aloud. One mechanism is the lexical route, which is the process whereby skilled readers can recognize known words by sight alone, through a [...] "dictionary" [...] lookup procedure. The other mechanism is the nonlexical or sublexical route, which is the process whereby the reader can [...] "sound out" [...] a written word. This is done by identifying the word's constituent parts (letters, phonemes, graphemes) and applying knowledge of how these parts are associated with each other, for example, how a string of neighboring letters sound together. The dual-route system could explain the different rates of dyslexia occurrence between different languages (e.g. the Spanish language <b>dependence</b> on phonological <b>rules</b> accounts {{for the fact that}} Spanish-speaking children show a higher level of performance in non-word reading, when compared to English-speakers).|$|R
40|$|We present three-band {{simultaneous}} {{observations of}} a weak-line T-Tauri star CVSO 30 (PTFO 8 - 8695), {{which is one}} of the youngest objects having a candidate transiting planet. The data were obtained with the Multicolor Simultaneous Camera for studying Atmospheres of Transiting exoplanets (MuSCAT) on the 188 cm telescope at Okayama Astrophysical Observatory in Japan. We observed the fading event in the g^'_ 2 -, r^'_ 2 -, and z_ s, 2 -bands simultaneously. As a result, we find a significant wavelength dependence of fading depths of about 3. 1 %, 1. 7 %, 1. 0 % for the g^'_ 2 -, r^'_ 2 -, and z_ s, 2 -bands, respectively. A cloudless H/He dominant atmosphere of a hot Jupiter cannot explain this large wavelength <b>dependence.</b> Additionally, we <b>rule</b> out a scenario by the occultation of the gravity-darkened host star. Thus our result is in favor of the fading origin as circumstellar dust clump or occultation of an accretion hotspot. Comment: 6 pages, 3 figures, Accepted for PASJ Letter...|$|R
40|$|Nonlinear {{electrical}} circuits {{can be used}} to model fluid flow in pipe networks when the resistance of any element in the network is assumed to be dependent on the flow rate through that element. This relationship is often assumed in classical models of pressure drops at orifices and through valves. More recently, it has also been used to model blood flow through vessels, and may potentially have applications in nano-fluid systems. Motivated by these applications, in this thesis we investigate circuits where the resistors have linear and affine (linear plus offset) <b>dependence</b> on current. <b>Rules</b> for their reduction in series and parallel are derived for the general case as well as for special cases of their linear coefficients and offset terms. Other adapted circuit analysis and manipulation techniques are also discussed, including mesh current analysis and delta-wye transformation, and avenues for further investigation of this topic are illuminated. The methods developed in this thesis may have potential applications in simplifying the analysis of complex nonlinear flow networks in cardiovascular systems, especially those at the nano-scale...|$|R
40|$|The {{characterization}} of the charge carrier transport in disordered fullerene films, grown by physical vapor deposition, is important for organic electronics {{in order to improve}} carrier mobility and understand transport processes. In this contribution, the electron mobility in the bulk of the fullerene film and at the interface with dielectrics are compared. The bulk mobility is measured in diode structures using the Charge Extraction by Linearly Increasing Voltage (CELIV) technique, which allows a simultaneous study of the electric field, concentration and temperature dependence. The interface mobility is determined using organic field effect transistor (OFET) geometry. The electron mobility values are lower and the dependence on carrier density, field and temperature is stronger in diodes compared to OFETs. In both structures different temperature dependence of the mobility on the carrier concentration and on the electric field is obtained. The <b>dependence</b> shows Meyer-Neldel <b>rule</b> (MN-rule) behavior with similar MN temperatures and MN energies. Activation energy for electron transport plotted {{as a function of the}} square root of electric field is linear (Gill 2 ̆ 7 s law behavior), in accordance with Poole-Frenkel-type charge carrier transport...|$|R
40|$|The {{performance}} of production {{programs can be}} improved by firing multiple rules in a production cycle. Although considerable amount of {{research has been done}} on parallel processing of production programs, the problem of multiple rule firing has not been thoroughly investigated yet. In this paper, we begin by identifying the problems associated with multiple rule firing systems: the compatibility problem and the convergence problem and present three multiple rule firing models which address them. The <b>rule</b> <b>dependence</b> model (RDM) addresses the compatibility problem using inter-rule data dependence analysis. The single-context-multiple-rules (SCMRJ model and the multiple-contexts-multiple-rules (MCMR) model address both the compatibility and the convergence problems. A production program executed under the SCMR and the MCMR models is guaranteed to reach a solution which is equivalent to the sequential execution. These three multiple rule firing models have been simulated on the RUB 1 C simulator, and the MCMR model, which has the highest performance, has been implemented on the Intel iPSC/ 2 hypercube. The simulation and implementation results are reported. ...|$|R
40|$|As {{the world}} faces war with Iraq, many are understandably {{concerned}} with the immediate horror that war would bring. Beyond these very real dangers, we should {{take this opportunity to}} re-examine whether militarism is a healthy thing for our society and our planet. Reducing <b>dependence</b> on the <b>rule</b> of force and de-militarizing society would not only make the world more peaceful and free up resources to address the underlying causes of terrorism, it would also have a dramatically positive impact on global health and the environment. Here are ten reasons why. 1. Militaries are notorious polluters. According to geographer Joni Seager, “anywhere in the world, a military presence is virtually the single most reliable predictor of environmental damage. ” Since the end of the Cold War, many plans to convert military bases to civilian use have been cancelled because the sites are contaminated beyond any hope of restoration. And military pollution isn’t limited to bases, it does significant damage to the environment at large. In the US – the world's most oil-thirsty country – the largest single consumer of oil is the Pentagon. Together, the world’s militaries consume as much petroleum as Japan – th...|$|R
