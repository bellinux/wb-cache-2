83|76|Public
5000|$|Hardware {{fault-tolerance}} is {{the most}} common application of these systems, designed to prevent failures due to hardware components. Most basically, this is provided by redundancy, particularly dual modular redundancy. Typically, components have multiple backups and are separated into smaller [...] "segments" [...] that act to contain a fault, and extra redundancy is built into all physical connectors, power supplies, fans, etc. There are special software and instrumentation packages designed to detect failures, such as <b>fault</b> <b>masking,</b> which is a way to ignore faults by seamlessly preparing a backup component to execute something as soon as the instruction is sent, using a sort of voting protocol where if the main and backups don't give the same results, the flawed output is ignored.|$|E
40|$|<b>Fault</b> <b>masking</b> {{can reduce}} the {{effectiveness}} of a test suite. We propose an information theoretic measure, Squeeziness, as the theoretical basis for avoiding <b>fault</b> <b>masking.</b> We begin by explaining <b>fault</b> <b>masking</b> and the relationship between collisions and <b>fault</b> <b>masking.</b> We then define Squeeziness and demonstrate by experiment that there is a strong correlation between Squeeziness and the likelihood of collisions. We conclude with comments on how Squeeziness could be the foundation for generating test suites that minimise the likelihood of <b>fault</b> <b>masking...</b>|$|E
40|$|The {{shrinking}} {{of process}} technologies in conjunction to the manufacturing and transient faults may be abundant in high density reconfigurable architectures. Design of reliable applications on such unreliable architectures requires techniques {{able to provide}} {{a balance between the}} desired <b>fault</b> <b>masking</b> and the associated performance and power degradation. Starting from a well established solution for reliability improvement in field-programmable gate arrays (FPGAs) domain, we discuss a software-supported methodology that removes redundancy as much as possible from the design without affecting it's efficiency in terms of <b>fault</b> <b>masking.</b> Based on experimental results, our proposed methodology achieves comparable <b>fault</b> <b>masking</b> with commercial solutions, but in reasonable lower mitigation cost. Â© 2010 IEEE...|$|E
40|$|The Triple Modular Redundant (TMR) {{architecture}} {{is based on}} the triplication of application modules. To <b>mask</b> <b>faults,</b> copies of modules are mapped on processing units, capable of direct communication. In the approach used in this paper, each processing unit (or a processor) mapping a module, is equipped with a kernel. This kernel allows it to <b>mask</b> <b>faults</b> via an agreement protocol involving the two other processors (mapping the two other copies). <b>Faults</b> are <b>masked,</b> under user requests, through kernel primitives. Robot movements are observed when its path following controller is mapped on a TMR architecture. The output of the velocity controller is then submitted to an agreement. The study of resulted robot movements shows that single <b>faults</b> are efficiently <b>masked.</b> There is no perceptible difference among the robot behaviors, when using or not using fault-masking kernel, unless when processors faults occur. Keywords: Triple Modular Redundancy, Software Voter, Robot Navigation, Real-Time [...] . ...|$|R
30|$|For Very Large Scale Integration {{circuits}} (VLSI), the Built-In Self-Testing (BIST) {{concept is}} well used. Embedding the whole or {{major part of}} the tester into the circuit is considered as BIST. Production standard involves the use of Linear Feedback Shift Registers (LSFR) that are used as a Test Pattern Generators (TPG) and Test Response Compactors (TRC) in a signature analysis [2]. These LFSR registers can generate pseudo-random test vectors that may cover many faults. For the evaluation of the effectiveness of coating defects by sequence of test vectors, the Fault Coverage (FC) is applied. Multi-Input Signature Registers (MISR) and Single-Input Signature Registers (SISR) are mainly used as TRC registers [3]. These Compactors perform data compression generally lossy, but are known lossless Zero-Aliasing ones without <b>faults</b> <b>masking</b> phenomena.|$|R
40|$|The {{purpose of}} this paper is to present {{evidence}} on a practical implementation of a recently proposed RTL BIST approach [...] m-BIST, or masked BIST. In order to detect random pattern-resistant faults, partially defined vectors, referred as masks (activating the lowaccessible parts of the RTL functionality) modulate pseudo-random vectors generated by the LFSR. Using ITC' 99 benchmarks as case studies, we evaluate the costs of two hardware solutions for mask injection and show that the overall solution leads to significant reductions in power (and especially) energy consumption of the BIST session, while leading to high Defects Coverage (bridging and line stuck-at <b>faults).</b> <b>Mask</b> injection is automated for both solutions. It is shown that one solution [...] synthesized multiplexers - is much more area-efficient, while the other solution (matrix-based) leads to lower speed degradation...|$|R
40|$|Distributed storage systems {{increase}} {{performance of}} storage subsystems yet introduce performance variability which can create bottlenecks in a storage system. This paper introduces performance <b>fault</b> <b>masking</b> for network-attached storage devices to decrease performance variations in parallel storage systems. Performance <b>fault</b> <b>masking</b> key components are a global cache and a cost-aware caching policy. Trace driven simulations of synthetic workloads have shown promise with this technique. Performance variations are reduced whereas average request times increase for most workloads. 1...|$|E
40|$|Recently, {{there has}} been a growing concern that, in {{relation}} to process technology scaling, the soft-error rate will become a major challenge in designing reliable systems. In this work, we introduce a high-fidelity, high-performance simulation infrastructure for quantifying the derating e#ects on soft-error rates while considering microarchitectural, timing and logic-related masking, using realistic workloads on a CMP switch design. We use a gate-level model for the CMP switch design, enabling us to inject faults into blocks of combinational logic. We are then able to track logic-related and time-related <b>fault</b> <b>masking,</b> as well as microarchitecturalrelated <b>fault</b> <b>masking,</b> at the architecture level. We find out that for complex designs, logic-and time-related <b>fault</b> <b>masking</b> account for more than 50 % of the masked faults. We also observe that only 3 - 4 % of the injected faults propagate an error at the design's output and cause an error in the application's execution, resulting in a derating factor of 30. From our experiments, we also demonstrate that soft-error derating e#ects highly depend on the design's characteristics and utilization...|$|E
40|$|A regular {{structure}} and capability to implement arbitrary logic functions in a two-level logic form have placed crossbar-based Programmable Logic Arrays (PLAs) as promising implementation architectures {{in the emerging}} nanoelectronics environment. Yet reliability constitutes an important concern in the nanoelectronics environment, necessitating a thorough investigation and its effective augmentation for crossbar-based PLAs. We investigate in this paper <b>fault</b> <b>masking</b> for crossbar-based nanoelectronics PLAs. Missing nanoelectronics devices at the crosspoints have been observed as {{a major source of}} faults in nanoelectronics crossbars. Based on this observation, we present a class of <b>fault</b> <b>masking</b> approaches exploiting logic tautology in two-level PLAs. The proposed approaches enhance the reliability of nanoelectronics PLAs significantly at low hardware cost. 1...|$|E
40|$|Design-for-testability (DFT) for {{synchronous}} sequential circuits causes redundant faults in {{the original}} circuit to be detectable in the circuit with DFT logic. It {{has been argued that}} such faults should not be detected in order to avoid reducing the yield unnecessarily. One way to deal with such <b>faults</b> is to <b>mask</b> (or ignore) their fault effects when they appear on the circuit outputs, without masking the detection of faults that need to be detected. To investigate the extent to which this can be accomplished, we describe a procedure for masking the effects of redundant faults of the original circuit under a given test set generated for the circuit with DFT logic. The procedure attempts to maximize the number of redundant <b>faults</b> that are <b>masked</b> while minimizing (or holding to zero) the number of other <b>masked</b> <b>faults.</b> 1...|$|R
40|$|It {{is known}} that modern {{electronic}} systems require increased safety in their operation. Despite of the remarcable technological achievments reached mostly {{in the last two}} decades, faults remains unavoidable in electronic systems. Therefore, failures occurrence in electronic circuits are the main causes of important material or finacial losses. This paper deals with challenging issues o fintelligent and high reliability electronic structures implementation for safety industrial applications. An intuitive development exemple it is unfolded in the paper that embedds both outstanding intelligence and high level of reliability. High reliability has been achieved by following redundancy implementation paradigms reyling in <b>faults</b> <b>masking</b> and and dynamic commutation strategy. Intelligence is expressed by electronic topologies that enables self-configuration of their internal structure in fault occurence operation states. These behaviors have beeen reached by using reconfigurable electronics and grid computing technologies. The final result of the unfolded research efforts is a high-reliability electronic system endowed both with high reliability and intelligent behaviors for a large scale of safety industrial applications. ...|$|R
40|$|AbstractâIn this paper, we {{investigate}} {{the effect of}} the representation of safety specification on the complexity of adding <b>masking</b> <b>fault</b> tolerance to programsâwhere, in the presence of faults, the program 1) recovers to states from where it satisfies its (safety and liveness) specification and 2) preserves its safety specification during recovery. Specifically, we concentrate on two approaches for modeling the safety specifications: 1) the bad transition (BT) model, where safety is modeled as a set of bad transitions that should not be executed by the program, and 2) the bad pair (BP) model, where safety is modeled as a set of finite sequences consisting of at most two successive transitions. If the safety specification is specified in the BT model, then it is known that the complexity of automatic addition of <b>masking</b> <b>fault</b> tolerance to high atomicity programsâwhere processes can read/write all program variables in an atomic step â is polynomial in the state space of the program. However, for the case where one uses the BP model to specify safety specification, we show that the problem of adding <b>masking</b> <b>fault</b> tolerance to high atomicity programs is NPcomplete. Therefore, we argue that automated synthesis of fault-tolerant programs is likely to be more successful if one focuses on problems where safety can be represented in the BT model. Index TermsâFault-tolerance, automatic addition of fault tolerance, safety specification, formal methods, program synthesis. ...|$|R
40|$|Optimal <b>fault</b> <b>masking</b> N-Version Genetic Programming (NVGP) is a {{technique}} for building fault tolerant software via ensemble of automatically generated modules {{in such a way}} as to maximize their collective <b>fault</b> <b>masking</b> ability. Decision Abstaining N-Version Genetic Programming is NVGP that abstains from decision-making, when there is no decisive vote among the modules to make a decision. A special course of action may be taken for an abstained instance. We found that decision abstention contributed to error reduction in our experimental Escherichia coli DNA promoter sequence classification problem. Though decision abstention may reduce errors, high abstention rate makes the system of little use. This paper investigates the trade-off between abstention rate and error reduction. ...|$|E
40|$|The {{importance}} of fault tolerance at the processor archi-tecture level {{has been made}} increasingly important due to rapid advancements {{in the design and}} usage of high per-formance devices and embedded processors. System level solutions to the challenge of fault tolerance flag errors and utilize penalty cycles to recover through the re-execution of instructions. This motivates the need for a hybrid technique providing fault detection as well as <b>fault</b> <b>masking,</b> with minimal penalty cycles for recovery from detected errors. We propose three architectural schemes to protect the con-trol logic of microprocessors against Single Event Upsets (SEUs). High fault coverage with relatively low hardware overhead is obtained by using both fault detection with re-covery and <b>fault</b> <b>masking.</b> Control signals are classified a...|$|E
40|$|Four {{kinds of}} {{abstraction}} {{for the design}} and analysis of fault tolerant distributed systems are discussed. These abstractions concern system messages, faults, <b>fault</b> <b>masking</b> voting, and communication. The abstractions are formalized in higher order logic, and are intended to facilitate specifying and verifying such systems in higher order theorem provers...|$|E
40|$|The {{multiple}} {{fault diagnosis}} problem is important, since the single fault assumption {{can lead to}} incorrect or failed diagnoses when multiple faults occur. It is challenging for continuous systems, because <b>faults</b> can <b>mask</b> or compensate each otherâs effects, and the solution space grows exponentially {{with the number of}} possible faults. We present a qualitative approach to multiple fault isolation in dynamic systems based on analysis of fault transient behavior. Our approach uses the observed measurement deviations and their temporal orderings to generate multiple fault hypotheses. The approach has polynomial space requirements and prunes diagnoses, resulting in an efficient online fault isolation scheme...|$|R
40|$|Critical {{infrastructure}} applications {{provide services}} upon which society depends heavily; such applications require survivability {{in the face}} of faults that might cause a loss of service. These applications are themselves dependent on distributed information systems for all aspects of their operation and so survivability of the information systems is an important issue. Fault tolerance is a key mechanism by which survivability can be achieved in these information systems. Much of the literature on fault-tolerant distributed systems focuses on local error recovery by masking the effects of faults. We describe a direction for error recovery {{in the face of}} catastrophic faults where the effects of the <b>faults</b> cannot be <b>masked</b> using available resources. The goal is to provide continued service that is either an alternate or degraded service by reconfiguring the system rather than <b>masking</b> <b>faults.</b> We outline the requirements for a reconfigurable system architecture and present an error recover [...] ...|$|R
40|$|This report {{summarizes}} {{the second year}} of study of techniques for improving digital system reliability through application of logical redundancy. Three major topics are discussed: organization of a computer for efficient use of redundancy techniques, use of redundancy to <b>mask</b> <b>faults</b> in computer memories, and logical redundancy techniques for sequential networks. Each of these three topics is treated in a self-contained part of the report. Â°Â°o III CONTENT...|$|R
40|$|Abstract â In this paper, {{the design}} of a Finite Impulse Response (FIR) filter with fault {{tolerant}} capabilities based on the residue number system is analyzed. Differently from other approaches that use RNS, the filter implementation is fault tolerant not only with respect to a fault inside the RNS moduli, but also in the reverse converter. An architecture allowing <b>fault</b> <b>masking</b> in the overall RNS FIR filter is presented. It avoids the use of a trivial Triple Modular Redundancy (TMR) to protect the blocks that performs the final stages of the RNS based FIR computation. I. INTRODUCTION AND CONCLUSIONS Fault detection and <b>fault</b> <b>masking</b> in the RNS representation have been studied, such as, for example in [1], [2], [3], [4]. These works are based on the so called Redundant Residue Number System (RRNS) representation in which some additiona...|$|E
40|$|Hierarchical {{application}} of Triple-Modular Redundancy (TMR) increases fault tolerance of digital Integrated Circuit (IC). In this paper, a simple probabilistic model was proposed {{for analysis of}} <b>fault</b> <b>masking</b> performance of hierarchical TMR networks. Performance improvements obtained by second order TMR network were theoretically compared with first order TMR network. Comment: Proposition section was adde...|$|E
40|$|Understanding the {{application}} resilience {{in the presence}} of faults is critical to address the HPC resilience challenge. Currently, we largely rely on random fault injection (RFI) to quantify {{the application}} resilience. However, RFI provides little information on how fault tolerance happens, and RFI results are often not deterministic due to its random nature. In this paper, we introduce a new methodology to quantify the application resilience. Our methodology is based on the observation that at the application level, the application resilience to faults is due to the application-level <b>fault</b> <b>masking.</b> The application-level <b>fault</b> <b>masking</b> happens because of application-inherent semantics and program constructs. Based on this observation, we analyze application execution information and use a data-oriented approach to model the application resilience. We use our model to study how and why HPC applications can (or cannot) tolerate faults. We demonstrate tangible benefits of using the model to direct fault tolerance mechanisms. Comment: 11 pages, 9 figures, the manuscript has been submitted to the International Conference for High Performance Computing, Networking, Storage and Analysis (SC ' 17) conferenc...|$|E
40|$|We {{present the}} formal {{verification}} of synchronizing {{aspects of the}} Reliable Computing Platform (RCP), a fault-tolerant computing system for digital flight control applications. The RCP uses NMR-style redundancy to <b>mask</b> <b>faults</b> and internal majority voting to purge the effects of transient faults. The system design has been formally specified and verified using the EHDM verification system. Our formalization {{is based on an}} extended state machine model incorporating snapshots of local processors clocks...|$|R
40|$|We {{present a}} formal {{verification}} of the transient fault recovery {{aspects of the}} Reliable Computing Platform (RCP), a fault-tolerant computing system architecture for digital flight control applications. The RCP uses NMR-style redundancy to <b>mask</b> <b>faults</b> and internal majority voting to purge the effects of transient faults. The system design has been formally specified and verified using the EHDM verification system. Our formalization accommodates {{a wide variety of}} voting schemes for purging the effects of transients...|$|R
40|$|AbstractâDespite {{the best}} design {{practices}} and testing techniques, many faults exist and manifest themselves in deployed software. In this {{paper we propose}} a self-healing framework that aims to <b>mask</b> <b>fault</b> manifestations at runtime in Java applications by automatically applying workarounds. The framework integrates a checkpoint-recovery mechanism to restore a consistent state after the failure, and a mechanism to replace the Java code at runtime to apply the workaround. Keywords-Self-healing; Checkpoint-recovery; Failure avoid-ance; Equivalent sequence...|$|R
40|$|The Architectural Vulnerability Factor (AVF) of a {{hardware}} structure is {{the probability that}} a fault in the structure will affect the output of a program. AVF captures both microarchitectural and architectural <b>fault</b> <b>masking</b> effects; therefore, AVF measurements cannot generate insight into the vulnerability of software independent of hardware. To evaluate the behavior of software in the presence of hardware faults, we must isolate the software-dependent (architecture-level masking) portion of AVF from the hardware-dependent (microarchitecture-level masking) portion, providing a quantitative basis to make reliability decisions about software independent of hardware. In this work, we demonstrate that the new Program Vulnerability Factor (PVF) metric provides such a basis: PVF captures the architecture-level <b>fault</b> <b>masking</b> inherent in a program, allowing software designers to make quantitative statements about a programâs tolerance to soft errors. PVF can also explain the AVF behavior of a program when executed on hardware; PVF captures the workload-driven changes in AVF for all structures. Finally, we demonstrate two practical uses for PVF: choosing algorithms and compiler optimizations to reduce a programâs failure rate. 1...|$|E
40|$|Triple Modular Redundancy (TMR) {{is usually}} used to {{increase}} {{safety and the}} reliability of safety-critical systems where three identical segments are used in identical and the ultimate outcome is reached using voting techniques. <b>Fault</b> <b>masking</b> {{is one of the}} main techniques to improve the normal actions of a range of safety-critical techniques. Some commercial areas which implement such techniques include process control, transport, and atomic power place and army programs. Integrated Voter for majority and weighted-average used to provide for a <b>fault</b> <b>masking</b> capability in safety-critical systems [1]. The Majority voting gives a high level of safety and the weighted-average offers a good level of availability. If integrated these two gives a good level of safety in Majority voting not in integrated voting. Here propose a new voting algorithm for faulty masking taking the disadvantage of previous algorithm. In this Incorporating Majority voting and score based fuzzy voting schemes. Safety performance is evaluated by running proposed, Majority and score based fuzzy voting on a triple modular redundant (TMR) system for 10000 voting cycles in various error scenarios. Experimental results show that proposed fuzzy Voter is given a higher safety than other two voting algorithms...|$|E
40|$|Ab 8 t~ac t- In this paper, {{we propose}} a new {{built-in}} self-diagnosis (BISD) method to simultoneoualy diagnose and repair spatially distributed memory modules with different sizes. Based on the serial interfacing technique, the serial <b>fault</b> <b>masking</b> effect is observed and a bi-directional serial in-terfacing technique is proposed {{to deal with}} such an issue. B y tolerating redundant read/write operations, we develop a new march algorithm called DiagRSMarch to achieve the goals of low hardware overhead, tolemble diagnostic time, and high diagnostic coverage...|$|E
40|$|The {{presence}} of multiple faults {{in a program}} can inhibit the ability of fault-localization techniques to locate the faults. This problem occurs for two reasons: when a program fails, the number of faults is, in general, unknown; and certain <b>faults</b> may <b>mask</b> or obfuscate other faults. This paper presents our approach to solving this problem that leverages the well-known advantages of parallel work flows to reduce the time-to-release of a program. Our approach consists of a technique that enables more effective debugging in the {{presence of}} multiple faults and a methodology that enables multiple developers to simultaneously debug multiple faults. The paper also presents an empirical study that demonstrates that our parallel-debugging technique and methodology can yield a dramatic decrease in total debugging time compared to a one-fault-ata-time, or conventionally sequential, approach...|$|R
40|$|SIP {{infrastructure}} on cloud platforms has {{the potential}} to be both scalable and highly available. In our previous project, we focused on the scalability aspect of SIP services on cloud platforms; the focus of this project is on the high availabil-ity aspect. We investigated the effects of component fault on service availability with the goal of understanding how high availability can be guaranteed even in the face of component faults. The experiments were conducted empirically on a real system that runs on Amazon EC 2. Our analysis shows that most compo-nent <b>faults</b> are <b>masked</b> with a simple automatic failover technique. However, we have also identified fundamental problems that cannot be addressed by simple failover techniques; a problem involving DNS cache in resolvers and a problem involving static failover configurations. Recommendations on how to solve thes...|$|R
40|$|The {{design and}} formal {{verification}} of the Reliable Computing Platform (RCP), a fault tolerant computing system for digital flight control applications is presented. The RCP uses N-Multiply Redundant (NMR) style redundancy to <b>mask</b> <b>faults</b> and internal majority voting to flush {{the effects of}} transient faults. The system is formally specified and verified using the Ehdm verification system. A major goal of this work is to provide the system with significant capability to withstand the effects of High Intensity Radiated Fields (HIRF) ...|$|R
40|$|This paper {{presents}} a new, layout-based approach to board-level shorts diagnosis for bussed drivers, {{with the goal}} of early repair of interconnect shorts so as to mini-mize (a) <b>fault</b> <b>masking</b> during opens testing and (b) driver abuse. This approach leads to an early diagnosis of more than 96 % of shorts and simplifies the subsequent test for opens considerably. Besides, this approach improves the production yield and field survivability of boards. Key words and phrases: Short, open, parallel test vec-tor (PTV) ...|$|E
40|$|International audienceThis paper {{presents}} an efficient platform for fault robustness estimation of digital circuits. The proposed platform, named FIFA, {{was designed as}} a hardware IP to accelerate the Fault Injection and <b>Fault</b> <b>masking</b> Analysis approach. It supports several fault models as well as single and multiple faults. Synthesis results have shown that the proposed platform can exceed those existent in the literature in terms of area efficiency and performance. In addition, the FIFA platform allows the designer to control complexity and completeness of the analysis process...|$|E
40|$|A new {{approach}} for structural, fault-oriented analog test generation methodology {{to test for}} the presence of manufacturing-related defects is proposed. The output of the test generator consists of optimized test stimuli, fault coverage and sampling instants that are sufficient to detect the failure modes in the circuit under test. The tests are generated and evaluated on a multistep ADC taking into account the potential <b>fault</b> <b>masking</b> effects of process spread on the faulty circuit responses. Similarly, the test generator results offer indication for the circuit partitioning within the framework of circuit performance, area and testability...|$|E
40|$|International audienceThis paper {{describes}} an Active Fault Tolerant Control System {{based on a}} Linear Time Varying (LTV) model for a winding machine. It shows that, according to an experimental identification approach, a LTV model is ideally suited to improve the control of web tension. Moreover, based on this model, a sensor fault detection, isolation and estimation module is developed. This estimation {{is of paramount importance}} to compensate for this <b>fault</b> using sensor <b>masking</b> principles and to preserve the system performances. The effectiveness and performances of the strategy are illustrated via real tests...|$|R
40|$|Periodical impulse {{component}} {{is one of}} typical fault characteristics in vibration signals from rotating machinery. However, this {{component is}} very small in the early stage of the <b>fault</b> and <b>masked</b> by various noises such as gear meshing components modulated by shaft frequency, which {{make it difficult to}} extract accurately for fault detection. The adaptive line enhancer (ALE) is an effective technique for separating sinusoidals from broad-band components of an input signal for detecting the presence of sinusoids in white noise. In this paper, ALE is explored to suppress the periodical gear meshing frequencies and enhance the fault feature impulses for more accurate fault diagnosis. The results obtained from simulated and experimental vibration signals of a two stage helical gearbox prove that the ALE method is very effective in reducing the periodical gear meshing noise and making the impulses in vibration very clear in the time-frequency analysis. The results show a clear difference between the baseline and 30...|$|R
30|$|In safety-critical systems, {{the triple}} modular {{redundancy}} (TMR) technique [14] {{is widely used}} for fault tolerance. Although TMR is not a robust mechanism for fault tolerance, the scheme can <b>mask</b> <b>faults</b> quickly and runs efficiently. A state-based schedule can become fault-tolerant {{by the use of}} TMR, but it might not remain effective in unreliable environments due to the possibility of occurring faulty decisions. A faulty decision is an incorrect or inconsistent decision taken by any of the participating stations in the network. This results in state inconsistency and a potential deadline loss, which is unacceptable in real-time systems.|$|R
