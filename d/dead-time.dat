589|27|Public
25|$|EDX spectrometers are {{different}} from WDX spectrometers {{in that they are}} smaller, simpler in design and have fewer engineered parts, however they are not as accurate. WDX has greater resolution power than EDX. They can also use miniature X-ray tubes or gamma sources. This makes them cheaper and allows miniaturization and portability. This type of instrument is commonly used for portable quality control screening applications, such as testing toys for lead (Pb) content, sorting scrap metals, and measuring the lead content of residential paint. On the other hand, the low resolution and problems with low count rate and long <b>dead-time</b> makes them inferior for high-precision analysis. They are, however, very effective for high-speed, multi-elemental analysis. Field Portable XRF analysers currently on the market weigh less than 2kg, and have limits of detection on the order of 2 parts per million of lead (Pb) in pure sand.|$|E
2500|$|In practice, {{considerable}} pre-processing of {{the data}} is required—correction for random coincidences, estimation and subtraction of scattered photons, detector <b>dead-time</b> correction (after the detection of a photon, the detector must [...] "cool down" [...] again) and detector-sensitivity correction (for both inherent detector sensitivity and changes in sensitivity due to angle of incidence).|$|E
2500|$|... {{are now the}} {{preferred}} method of reconstruction. [...] These algorithms compute {{an estimate of the}} likely distribution of annihilation events that led to the measured data, based on statistical principles. [...] The advantage is a better noise profile and resistance to the streak artifacts common with FBP, but the disadvantage is higher computer resource requirements. A further advantage of statistical image reconstruction techniques is that the physical effects that would need to be pre-corrected for when using an analytical reconstruction algorithm, such as scattered photons, random coincidences, attenuation and detector <b>dead-time,</b> can be incorporated into the likelihood model being used in the reconstruction, allowing for additional noise reduction. Iterative reconstruction has also been shown to result in improvements in the resolution of the reconstructed images, since more sophisticated models of the scanner Physics can be incorporated into the likelihood model than those used by analytical reconstruction methods, allowing for improved quantification of the radioactivity distribution.|$|E
5000|$|Nonlinear MPC: Similar to Multivariable MPC {{in that it}} {{incorporates}} dynamic {{models and}} matrix-math based control; however, {{it does not have}} the requirement for model linearity. Nonlinear MPC is capable of accommodating processes with models that have varying process gains and dynamics (i.e. <b>dead-times</b> and lag times).|$|R
40|$|We {{experimentally}} {{demonstrate a}} high-efficiency Bell state measurement for time-bin qubits that employs two superconducting nanowire single-photon detectors with short <b>dead-times,</b> allowing projections onto two Bell states, |Psi>- and |Psi+>. Compared to previous implementations for time-bin qubits, this yields {{an increase in}} the efficiency of Bell state analysis by a factor of thirty...|$|R
40|$|In {{this paper}} a new fuzzy based control concept for {{severely}} disturbed industrial processes with large <b>dead-times</b> is presented which {{is characterized by}} a combination of fuzzy adaptive controllers with a physically based con-ven-tional predictive control concept. It has been success-fully applied to a complex rheological glass manu-facturing process. Practical experiences with the control design, optimization, implementation and process opera-tion will be discussed...|$|R
50|$|The B3 bias {{function}} {{is useful to}} adjust non-overlapping and overlapping variable τ estimator values based on <b>dead-time</b> measurements of observation time τ0 and time between observations T0 to normal <b>dead-time</b> estimates.|$|E
5000|$|The {{samples are}} taken with no <b>dead-time</b> between them, which is {{achieved}} by letting ...|$|E
5000|$|PWM output (some {{devices have}} an {{enhanced}} PWM peripheral {{which includes a}} <b>dead-time</b> generator) ...|$|E
40|$|In {{this paper}} we compare several reinforcement-learning (RL) {{approaches}} {{with respect to}} their ability to solve problems arising in real-world. Thereto, we investigated various RL-agents, ranging from classical value-iteration like Q-learning to policy-iteration tech-niques like ADHDP. These agents try to solve several tasks within a simulated environment featuring proper-ties, that usually characterize real-world problems like continuous state and action space, partial observability, changing goals or <b>dead-times.</b> ...|$|R
40|$|A biologically {{inspired}} {{control algorithm}} for robot control {{was introduced in}} a previous work. The algorithm is robust to noisy sensor information and hardware failures. In this paper {{a new version of}} the algorithm is presented. The new version is able to cope with highly non-linear systems and presents an improved robustness to low-pass filter effects and <b>dead-times.</b> Automatic tuning of the parameters is also introduced, providing a completely parameterless algorithm...|$|R
40|$|The {{development}} of fuzzy internal model control (FIMC) {{is analogous to}} that of linear IMC. At {{the core of the}} FIMC is the novel crisp consequent fuzzy relational model (ccFRM). In this paper, we compare the behaviour of FIMC to IMC on a variety of linear systems. The comparison shows that, although FIMC behaves well when used with SISO systems, it suffers severe difficulties in dealing with MIMO systems with <b>dead-times.</b> A possible solution to this, again from analogy with linear IMC, is to approximate the model inverse with a model predictive controller...|$|R
50|$|The {{time between}} {{measurements}} is denoted with T, {{which is the}} sum of observation time τ and <b>dead-time.</b>|$|E
5000|$|An {{important}} aspect is that -sample variance model can include <b>dead-time</b> by letting the time [...] {{be different from}} that of [...]|$|E
5000|$|July 21, 1964. “Control System for Use in Control of Loops With Dead Time”. (<b>Dead-Time</b> Stabilization) * 3,241,129 Mar. 15, 1966. “Delay Line”. 29 claims, {{jointly with}} Richard Dye.|$|E
40|$|Servovisao e uma tecnica que utiliza visao computacional para obter informacoes visuais (atraves de camera) e um sistema de controle com circuito em malha fechada para controlar robos. Uma das aplicacoes tipicas de servovisao e no rastreamento de objetos sobre esteiras transportadoras em ambientes industriais. Servovisao possui a vantagem em relacao a outros tipos de sensores de permitir a obtencao de um grande numero de informacoes a partir do ambiente e maior flexibilidade nas operacoes. Uma desvantagem sao os atrasos conhecidos como <b>dead-times</b> ou time-delays que podem ocorrer durante o tratamento de informacoes visuais nas tarefas de visao computacional ou em outras tarefas do sistema de controle que necessitam de grande capacidade de processamento. Os <b>dead-times</b> em servovisao aplicada em operacoes industriais como no rastreamento de objetos em esteiras transportadoras sao criticos e podem afetar negativamente na capacidade de producao em ambientes de manufatura. Algumas metodologias podem ser encontradas na {{literatura}} para esse tipo de problema sendo muitas vezes baseadas no filtro de Kalman. Nesse trabalho foi selecionada uma metodologia baseada na formulacao do filtro de Kalman que ja possui um estudo na previsao futura de pose de objetos com movimentacao linear. Essa metodologia foi estudada detalhadamente, testada atraves de simulacoes e analisada sobre outros tipos de movimentos e algumas aplicacoes. No total foram gerados tres tipos de experimentos: um para diferentes tipos de movimentacao e outros dois aplicados em diferentes tipos de sinais no controlador de velocidades. Os resultados a partir da movimentacao do objeto demonstraram que o metodo e capaz de estimar a pose futura de objetos com movimento linear e com curvas suaves, porem e ineficiente para alteracoes drasticas no movimento. Com relacao ao sinal a ser filtrado no controlador de velocidades a metodologia se demonstrou aplicavel (com as condicoes de movimento) somente na estimativa da pose do objeto apos a ocorrencia de <b>dead-times</b> causados por visao computacional e posteriormente essa informacao e utilizada para calcular o erro futuro do objeto em relacao ao manipulador robotico utilizado no calculo da velocidade do robo. A tentativa de aplicacao da tecnica diretamente no erro utilizado no calculo da velocidade a ser aplicada ao robo nao apresentou bons resultados. Com os resultados obtidos a metodologia se demonstrou eficiente para o rastreamento de objetos de forma linear e curvas suaves como no caso de objetos transportados por esteiras em ambientes industriais. Visual servoing is {{a technique}} that uses computer vision to acquire visual information (by camera) and a control system with closed loop circuit to control robots. One typical application of visual servoing is tracking objects on conveyors in industrial environments. Visual servoing {{has the advantage of}} obtaining a large amount of information from the environment and greater flexibility in operations than other types of sensors. A disadvantage are the delays, known as <b>dead-times</b> or time-delays that can occur during the treatment of visual information in computer vision tasks or other tasks of the control system that need large processing capacity. The <b>dead-times</b> in visual servoing applied in industrial operations such as in the tracking of objects on conveyors are critical and can negatively affect production capacity in manufacturing environments. Some methodogies {{can be found in the}} literature for this problem and some of these methodologies are often based on the Kalman filter. In this work a technique was selected based on the formulation of the Kalman filter that already had a study on the prediction of future pose of objects with linear motion. This methodology has been studied in detail, tested and analyzed through simulations for other motions and some applications. Three types of experiments were generated: one for different types of motions and two others applied in different types of signals in the velocity control systems. The results from the motion of the object shown that the technique is able to estimate the future pose of objects with linear motion and smooth curves, but it is inefficient for drastic changes in motion. With respect to the signal to be filtered in the velocity control, the methodogy has been shown applicable (with motions conditions) only in the estimation of pose of the object after the occurrence of <b>dead-times</b> caused by computer vision and this information is subsequently used to calculate the future error of the object related to the robotic manipulator used to calculate the velocity of the robot. The trying to apply the methodogy directly on the error used to calculate the velocity to be applied to the robot did not produce good results. With the results the methodogy can be applied for object tracking with linear motion and smooth curves as in the case of objects transported by conveyors in industrial environments...|$|R
40|$|A {{digital control}} {{technique}} for voltage regulation module (VRM) is investigated, {{which is based}} on a predictive current regulator. Due to the adaptive-voltage-positioning (AVP) of the VRM, the controlled variable includes a combination of output voltage and inductor current. Besides the predictive regulator, a disturbance observer is used for compensation of input voltage variations and any other source of errors, such as <b>dead-times,</b> parameter and model mismatches. Even if aimed to an integrated digital controller, experimental investigation has been performed using discrete components, implementing the digital control in a field programmable gate array (FPGA). Experimental results on a synchronous buck DC-DC converter confirm the properties of the predictive contro...|$|R
40|$|In a {{multifunction}} radar, {{the maximum}} number of targets that can be managed or tracked is an important performance measure. Interleaving algorithms developed to operate radars exploit the <b>dead-times</b> between the transmitted and the received pulses to allocate new tracking tasks that might involve transmitting or receiving pulses, thus increasing the capacity of the system. The problem of interleaving N targets involves a search among N! possibilities, and suboptimal solutions are usually employed to satisfy the real-time constraints of the radar system. In this paper, we present new tight 0 - 1 integer programming models for the radar pulse interleaving problem and develop effective solution methods based on Lagrangian relaxation techniques...|$|R
50|$|Dead time {{effects on}} {{measurements}} {{have such an}} impact on the produced result that much study of the field have been done in order to quantify its properties properly. The introduction of zero <b>dead-time</b> counters removed the need for this analysis. A zero <b>dead-time</b> counter has the property that the stop-event of one measurement is also being used as the start-event of the following event. Such counters creates a series of event and time timestamp pairs, one for each channel spaced by the time-base. Such measurements have also proved useful in order forms of time-series analysis.|$|E
50|$|Circuit {{design changes}} {{with the purpose}} of the TDC, which can either be a very good {{solution}} for single-shot TDCs with long dead times or some trade-off between <b>dead-time</b> and resolution for multi-shot TDCs.|$|E
5000|$|Some {{examples}} of where feedback and feed-forward control {{can be used}} together are <b>dead-time</b> compensation, and inverse response compensation. <b>Dead-time</b> compensation is used to control devices that {{take a long time}} to show any change to a change in input, for example, change in composition of flow through a long pipe. A <b>dead-time</b> compensation control uses an element (also called a Smith predictor) to predict how changes made now by the controller will affect the controlled variable in the future. The controlled variable is also measured and used in feedback control. Inverse response compensation involves controlling systems where a change at first affects the measured variable one way but later affects it in the opposite way. An example would be eating candy. At first it will give you lots of energy, but later you will be very tired. As can be imagined, it is difficult to control this system with feedback alone, therefore a predictive feed-forward element is necessary to predict the reverse effect that a change will have in the future.'''''''' ...|$|E
40|$|The etch {{delay time}} {{commonly}} found during dry etching of AlGaN and GaN has been experimentally {{proven to be}} due to the presence of hard–to–etch surface oxides. A BCl 3 deoxidizing plasma, followed by a Cl 2 etching plasma, was found to give dead-time-free aluminum-mole-fraction-independent etch rates. No selectivity between GaN and AlGaN has been observed up to an aluminum mole fraction of 35 %. The aluminum-mole-fraction-dependent etch rates commonly reported in literature have been related to the different <b>dead-times</b> associated with dissimilar surface oxides, disproving the more common explanations in terms of the higher binding energy of AlN compared to GaN and/or the lower volatility of AlClx compared to GaClx...|$|R
40|$|We {{consider}} {{the problem of}} temperature stabilization of the Large Hadron Collider's (LHC) superconducting magnets, cooled with superfluid helium 4 (He II). The temperature dynamics is highly non-linear, exhibiting inverse response, variable <b>dead-times,</b> strong couplings between process variables and strong saturation effects. Multiple operational constraints must be respected. We present a prototype application of a hybrid Non-linear Moving Horizon State Estimation - Luenberger observer (MHSE-LO) and Non-linear Model Predictive Control (NMPC). It is based on: 1) a detailed, low computing cost, first principles model of the temperature dynamics and 2) a simple optimization approach tailored for systems with stiff dynamics. The prototype control system has been tested at the LHC, demonstrating excellent, robust performance...|$|R
40|$|Abstract. The {{scientific}} {{instrument of}} the AGILE mission is innovative in many ways. It is an integrated instrument based on three detecting systems: (1) a Silicon Tracker, (2) a Mini-Calorimeter, and (3) an ultralight coded mask system with Si-detectors (Super-AGILE). For a relatively low mass (~ 70 kg) and large ratio of expected performance over cost, AGILE is planned to provide (i) Optimal imaging in the energy bands 30 MeV- 50 GeV (5 - 10 arcmin for intense sources) and 10 - 40 keV (1 - 3 arcmin). (ii) Optimal timing capabilities, with independent readout systems and minimal <b>dead-times</b> for the Silicon Tracker, Super-AGILE and Mini-Calorimeter, (iii) A very large field of view for the gamma-ray imaging detector (3 sr) and Super-AGILE (1 sr) ...|$|R
5000|$|Computer Gaming World applauded The President Is Missings premise, plot, and graphics, but criticized its execution. The {{magazine}} concluded, [...] "the {{game has}} simply too much <b>dead-time</b> {{to be truly}} exciting or for players to maintain their initial enthusiasm." ...|$|E
50|$|The {{classical}} M-sample {{variance of}} frequency was analysed by David Allan in {{along with an}} initial bias function. This paper tackles the issues of <b>dead-time</b> between measurements and analyses the case of M frequency samples (called N in the paper) and variance estimators. It provides the now standard α to µ mapping. It clearly builds on James Barnes work as detailed in his article in the same issue. The initial bias functions introduced assumes no <b>dead-time,</b> but the formulas presented includes <b>dead-time</b> calculations. The bias function assumes {{the use of the}} 2-sample variance as a base-case, since any other variants of M may be chosen and values may be transferred via the 2-sample variance to any other variance for of arbitrary M. Thus, the 2-sample variance was only implicitly used and not clearly stated as the preference even if the tools where provided. It however laid the foundation for using the 2-sample variance as the base case of comparison among other variants of the M-sample variance. The 2-sample variance case is a special case of the M-sample variance which produces an average of the frequency derivative.|$|E
50|$|These bias {{functions}} {{are not sufficient}} for handling the bias resulting from concatenating M samples to the Mτ0 observation time over the MT0 with has the <b>dead-time</b> distributed among the M measurement blocks {{rather than at the}} end of the measurement. This rendered the need for the B3 bias.|$|E
40|$|This paper {{proposes a}} simple tuning {{algorithm}} for digital deadbeat control based on error correlation. By injecting a square wave reference input and calculating {{the correlation of}} the control error, a gain correction for deadbeat control is obtained. The proposed tuning algorithm is successfully applied also in predictive algorithms which use disturbance observers for the compensation of input voltage variations and any other source of errors, such as <b>dead-times,</b> parameter and model mismatches. The proposed solution is simple, it requires short tuning time, it is suitable for different dc-dc converter topologies {{and it seems to}} be compliant with the cost/complexity constraint of integrated digital ICs. Simulation and experimental results on synchronous buck converters confirm the properties of the proposed solutio...|$|R
40|$|Abstract This paper {{concerns}} {{the question of}} applicability of adaptive control strategies in real environments. Because of unrobustness to unmodeled dynamics especially dead time model reference adaptive control with all its positive features can not be implemented in industry. But it can be shown that an additional gain-controller within the MRAC-concept leads to a robust adaptive controller applicable to real systems. In this context, the paper gives a possibility of closing the gap between theory and praxis in the eld of adaptive control. As a case study, a two-mass exible servo system with unknown inertia, spring and damping constants is investigated while {{the dynamics of the}} power converter, speed-sensor and further unknown and time-varying <b>dead-times</b> can be neglected. The goal is a perfect dynamic tracking of the load-mass speed with a smooth control output...|$|R
40|$|We {{determine}} the shared {{information that can}} be extracted from time-bin entangled photons using frame encoding. We consider photons generated by a general down-conversion source and also model losses, dark counts and the effects of multiple photons within each frame. Furthermore, we describe a procedure for including other imperfections such as after-pulsing, detector <b>dead-times</b> and jitter. The results are illustrated by deriving analytic expressions for the maximum {{information that can be}} extracted from high-dimensional time-bin entangled photons generated by a spontaneous parametric down conversion. A key finding is that under realistic conditions and using standard SPAD detectors one can still choose frame size so as to extract over 10 bits per photon. These results are thus useful for experiments on high-dimensional quantum-key distribution system. Comment: 18 pages, 6 figure...|$|R
5000|$|In practice, {{considerable}} pre-processing of {{the data}} is required—correction for random coincidences, estimation and subtraction of scattered photons, detector <b>dead-time</b> correction (after the detection of a photon, the detector must [...] "cool down" [...] again) and detector-sensitivity correction (for both inherent detector sensitivity and changes in sensitivity due to angle of incidence).|$|E
5000|$|... where j is the James-Martin {{pressure}} drop correction, m is the sample mass, F is the carrier {{gas flow rate}} at standard temperature and pressure, tR is the gross retention time for the injected probe, to is the retention time for a non-interaction probe (i.e. <b>dead-time),</b> and T is the absolute temperature.|$|E
50|$|As a shorthand, average {{fractional}} frequency {{is often}} written without the average bar over it. This is however formally incorrect as the fractional frequency and average fractional frequency {{are two different}} functions. A measurement instrument able to produce frequency estimates with no <b>dead-time</b> will actually deliver a frequency average time series which only needs to be converted into average fractional frequency and may then be used directly.|$|E
40|$|This paper {{addresses}} the technical {{issues in the}} energy efficiency assessment for inverter-fed motor drives {{according to the international}} technical standard (TS) IEC 60034 - 2 - 3 : 2013. The critical points on the TS procedure are investigated by means of experimental results, with special emphasis on the influence of the DC bus voltage, the thermal aspects, the <b>dead-times</b> influence and compensation on the measurements suggested by the TS. For an easier fulfilment of the thermal constraints on the maximum winding temperature variation during the test, imposed by the Norm, a very simple thermal network is proposed. The model is also useful to evaluate the time duration of the experiment. The results of the experimental activity performed on two different induction motors are included in the paper...|$|R
40|$|<b>Dead-times</b> {{and switch}} voltage drops {{represent}} {{the most important}} sources of distortion of the (average) output voltage in PWM inverters. Their effect {{is a function of}} the parameters of the drive system and of the operating conditions, and is often intolerable in many drives applications, thus requiring a proper compensation strategy. Many techniques are implemented in industrial drives and reported in literature, even very recently. Differently from standard approaches the proposed methodology is based on a detailed physical model of the power converter (including output capacitance), described by a small set of parameters. A novel self-commissioning identification procedure is proposed, adopting Multiple Linear Regression. The technique is tested on a commercial drive in comparison to state-of-the-art techniques. Also back-EMF estimation improvements in a PMSM sensorless drive system are shown to provide additional validation of the method...|$|R
40|$|This paper {{presents}} an Impedance Source Inverter (Z-Source Inverter) for Resistive Load. The Z-source inverter employs a unique impedance network (or circuit) to couple the inverter main circuit {{to the power}} source, thus providing unique features that cannot be obtained in the traditional voltage-source (or voltagefed) and current-source (or current-fed) inverters where a capacitor and inductor are used, respectively. It allows {{the use of the}} shoot-through switching state, which eliminates the need for <b>dead-times</b> that are used in the traditional inverters to avoid the risk of damaging the inverter circuit, also provide ride-through capability during reduces harmonics, improves power factor and high reliability, and extends output voltage range. The effect of filter on inverter load voltage and current is studied. The detailed comparison of Z-Source inverter with Traditional inverter is discussed and simulation results will be presented to demonstrate these new features...|$|R
