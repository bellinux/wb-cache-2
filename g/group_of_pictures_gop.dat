125|10000|Public
5000|$|One Index frame per <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP)</b> - 12 to 30 (IBP) frames ...|$|E
50|$|XAVC {{allows for}} a wide range of content {{production}} including intra frame recording and long <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP)</b> recording.|$|E
50|$|The length between I-frames {{is known}} as the <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP)</b> size. MPEG-1 most {{commonly}} uses a GOP size of 15-18. i.e. 1 I-frame for every 14-17 non-I-frames (some combination of P- and B- frames). With more intelligent encoders, GOP size is dynamically chosen, up to some pre-selected maximum limit.|$|E
30|$|A video {{sequence}} {{is divided into}} WZ frames and key frames. Typically, a periodic coding structure is used with the <b>group</b> <b>of</b> <b>pictures</b> (<b>GOPs)</b> size defining the periodicity of the key frames; a GOP??= 2 {{means that there is}} one WZ frame for each key frame.|$|R
3000|$|Message {{construction}} {{may lead}} to some improvements. Firstly, flexible <b>group</b> <b>of</b> <b>picture</b> (<b>GOP)</b> is available due to different message construction. The first frame in each message can be intraencoded as I frame and the encoding structure of GOP is chosen {{according to the length}} of the message. It is noted that the threshold value [...]...|$|R
3000|$|Packet loss effects [39 – 41]. In [41], the NR metric {{is based}} on the {{estimation}} of mean square error propagation among the <b>group</b> <b>of</b> <b>picture</b> (<b>GOP)</b> in motion compensation-based encoded videos. The idea is to consider the motion activity in the block as initial guess of the distortion caused by the initial packet loss; [...]...|$|R
5000|$|The typical <b>Group</b> <b>Of</b> <b>Pictures</b> (<b>GOP)</b> {{structure}} is IBBPBBP... The I-frame {{is used to}} predict the first P-frame and these two frames are also used to predict {{the first and the}} second B-frames. The second P-frame is predicted also using the first I-frame. Both P-frames join together to predict the third and fourth B-frames. The scheme is shown in the next picture: ...|$|E
50|$|Uncompressed video {{delivers}} maximum quality, {{but with}} a very high data rate.A variety of methods are used to compress video streams, with the most effective ones using a <b>Group</b> <b>Of</b> <b>Pictures</b> (<b>GOP)</b> to reduce spatial and temporal redundancy. Broadly speaking, spatial redundancy is reduced by registering differences between parts of a single frame; this task is known as intraframe compression and {{is closely related to}} image compression. Likewise, temporal redundancy can be reduced by registering differences between frames; this task is known as interframe compression, including motion compensation and other techniques. The most common modern standards are MPEG-2, used for DVD, Blu-ray and satellite television, and MPEG-4, used for AVCHD, Mobile phones (3GP) and Internet.|$|E
5000|$|I-frames store {{complete}} frame info {{within the}} frame and are therefore suited for random access. P-frames provide compression using motion vectors relative to the previous frame ( [...] I or P [...] ). B-frames provide maximum compression but require the previous as well as next frame for computation. Therefore, processing of B-frames requires more buffer on the decoded side. A configuration of the <b>Group</b> <b>of</b> <b>Pictures</b> (<b>GOP)</b> should be selected based on these factors. I-frame only sequences give least compression, but are useful for random access, FF/FR and editability. I- and P-frame sequences give moderate compression but add {{a certain degree of}} random access, FF/FR functionality. I-, P- and B-frame sequences give very high compression but also increase the coding/decoding delay significantly. Such configurations are therefore not suited for video-telephony or video-conferencing applications.|$|E
40|$|Abstract. We {{present a}} {{software-based}} parallel MPEG- 2 video encoder implemented on {{a cluster of}} workstations connected via an ATM switch and also via Ethernet. We exploit parallelism on a <b>Group</b> <b>of</b> <b>Picture</b> (<b>GOP)</b> basis such that each GOP of the video is encoded by a particular processor. We propose a scheme for efficient I/O and data distribution. ...|$|R
30|$|Even if {{the error}} {{resilience}} and error concealment techniques {{have become very}} effective, it is still impossible to solve completely the problem of temporal prediction drift: error concealment is clearly unable to properly compensate for channel losses. In these cases, because of the dependencies introduced by a prediction loop, reconstruction errors in a single frame can propagate across the <b>group</b> <b>of</b> <b>picture</b> (<b>GOP)</b> in the decoded video, leading to serious impairments in the overall quality.|$|R
40|$|This article {{deals with}} the impact of {{compression}} on the video quality. In the first part, a short characteristic of the most used MPEG compression standards is written. In the second part, the parameter <b>Group</b> <b>of</b> <b>Picture</b> (<b>GOP)</b> with particular I, P, B frames is explained. The third part focuses on the objective metrics which were used for evaluating the video quality. In the fourth part, the measurements and the experimental results are described...|$|R
30|$|The TDWZ codec {{splits the}} video {{sequence}} into key frames and WZ frames encapsulated within a <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP).</b>|$|E
30|$|The {{equations}} for estimation {{are dependent}} {{on the structure of}} the <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP).</b> The GOP structures usually used in H. 264 /AVC are shown in Figure  1 a, b. Figure  1 a is a non-dyadic hierarchical structure, and Figure  1 b is dyadic hierarchical structure.|$|E
30|$|Based on {{an opinion}} model from ITU-T[140], an {{automatic}} QoE monitoring method is proposed in[161]. It {{depends on the}} network level information derived from packet loss pattern and loss rank of a frame in a <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP)</b> and a measure of motion vectors to represent motion activity to train an ANN model against subjective scores of expert viewers.|$|E
3000|$|... {{separable}} integer transform as in AVC/H. 264 is {{used with}} properties {{similar to the}} discrete cosine transform (DCT) [7]. Then, the same bands are grouped together and the different bit planes are extracted and then fed to a turbo encoder [8]. The latter offers near-channel capacity error correcting capability. Furthermore, a cyclic redundancy check (CRC) [9] is computed for each quantized bit plane and transmitted to the decoder. The frequency of the key frames {{is defined by the}} <b>group</b> <b>of</b> <b>pictures</b> (<b>GOPs).</b>|$|R
40|$|An MPEG-encoded {{video signal}} {{includes}} <b>groups</b> <b>of</b> <b>pictures</b> (<b>GOPs),</b> each GOP having an intraframe coded (I) picture {{and a series}} of predictively encoded (P) pictures and bi-directionally predictively (B) <b>pictures.</b> Usually, the <b>GOP</b> structure IBBPBBP... is used. However, in order to embed a watermark in the MPEG-encoded video signal, the MPEG encoder is forced to produce a GOP structure which does not normally occur, e. g., a GOP including a BPP sequence. Different symbol values can be assigned to different positions of the BPP sequence in the GOP...|$|R
30|$|Each message can be encoded to bit streams using current {{standard}} codec. Here, H. 264 encoder {{is chosen}} and obviously the proposed scheme {{is compatible with}} the standard codec. It is noted that in each message flexible <b>group</b> <b>of</b> <b>picture</b> (<b>GOP)</b> is employed which is helpful to refresh intraframe adaptively. Compared with the uniform period of intraframe, adaptive refreshment can keep up with the motion change between frames, so better temporal correlation can be maintained to achieve better error concealment if frame loss occurs in one message at the decoder.|$|R
3000|$|We test six {{sequences}} in CIF (352 × 288) resolution {{with various}} characteristics including Akiyo, Hall Monitor, News, Paris, Sign Irene, and Soccer. The {{total number of}} coding frames is 100, and the <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP)</b> is 15 with 1 I picture followed by 14 P pictures. Curve fitting is utilized to model the relationship between bit-rate, NZTC and QP for I frame and P frame, respectively. The accuracy of the fitting result is evaluated via R [...]...|$|E
30|$|Streaming with a merging {{approach}} is applied for MV and FS representation formats for aggregation of two consecutive frames {{and for all}} frames in one <b>group</b> <b>of</b> <b>pictures</b> (<b>GoP).</b> This streaming approach shows significant improvement in variability characteristics, showed by multifractal spectrum, {{in the case of}} the MV video over FS video. The bitrate variability shown in [4], by the means of a coefficient of variation (CoV) and a variability distortion (VD) curve, yields to a very similar conclusion.|$|E
40|$|Abstract. In this work, {{we propose}} {{a system for}} shot {{comparison}} directly working on the MPEG- 1 stream in the compressed domain, extracting both color, texture and motion features considering all frames with a reasonable computational cost, and results comparable to those obtained on uncompressed keyframes. In particular a summary descriptor for each <b>Group</b> <b>Of</b> <b>Pictures</b> (<b>GOP)</b> is computed and employed for shot characterization and comparison. The Mallows distance allows to match different length clips in a unified framework...|$|E
40|$|This paper {{compares the}} {{performances}} of Hierarchical coding (HC) and multiple descriptions coding (MDC) on the transmission of videos over networks {{in the presence of}} packet loss. The paper examines different arrangements <b>of</b> <b>groups</b> <b>of</b> <b>pictures</b> (<b>GOP)</b> to evaluate the robustness against packet loss. The relationship between video quality and bit rate is employed to compare {{the performances of}} HC and MDC. In these experiments, two types of videos, with low and high levels of redundancy, are included and recommendations about the appropriate GOP structure and type of coding under various scenarios are presented...|$|R
30|$|It {{is clear}} that the coding {{performance}} will decrease with the <b>group</b> <b>of</b> frames participated in the pattern formation process of the proposed OCPG algorithm as the generated PC is gradually approximating the shape of the CRMBs. This process imposes restriction on the <b>group</b> <b>of</b> frames size. Thus, we need to refresh the pattern codebook with a regular interval. As shown by experiments, the <b>group</b> <b>of</b> <b>picture</b> (<b>GOP)</b> size would be good candidate to test whether we need to refresh the codebook. The detailed procedure of pattern codebook refreshment and transmission will be described in Section 3.4.|$|R
30|$|It {{should be}} noted that {{changing}} the configuration of the video encoder, for example in terms <b>of</b> the <b>group</b> <b>of</b> <b>picture</b> (<b>GOP)</b> structure properties or the number of slices per frame, will affect the perceived quality. However, these changes do not introduce new types of degradations. As a consequence, they can be captured by simply modifying the video-quality model (Equations (5), (7), and (8)). For instance, additional parameters such as the GOP length could implicitly or explicitly be included in this model. As long as the changed settings do not introduce new types of degradations, {{there is no need to}} modify either of the two variants of the audiovisual quality model.|$|R
30|$|The {{experiments}} {{were conducted by}} using the state-of-the-art transform-coding-based video compression standard, namely, the H. 264 /AVC encoder. The multiple copies of the input video were obtained by encoding the same video content using the coding standard with different target bit rates and coding parameters such as {{the structure of the}} <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP).</b> In what follows, we will discuss various scenarios in which the multiple video copies were compressed in different ways, resulting in various possible performance gains.|$|E
40|$|In {{this paper}} we {{address the problem of}} {{scalable}} video indexing. We propose a new framework combining sparse spatial multiscale patches and <b>Group</b> <b>of</b> <b>Pictures</b> (<b>GoP)</b> motion patches. The distributions of these sets of patches are compared via the Kullback-Leibler divergence estimated in a non-parametric framework using a k-th Nearest Neighbor (kNN) estimator. We evaluated this similarity measure on selected videos from the ICOS-HD ANR project, probing in particular its robustness to resampling and compression and thus showing its scalability on heterogeneous networks. ...|$|E
3000|$|... {{in which}} α, V 0, D 0, and β are {{constants}} {{for a specific}} video codec and video sequence. These parameters can be estimated from three or more trial encodings using nonlinear regression techniques. To allow fast adaptation of the flow rate allocation to abrupt changes in the video content, these parameters can be updated for each <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP)</b> in the encoded video sequence [34]. Since this model {{takes into account the}} effects of intra-coding and spatial loop filtering, it provides accurate estimates for end-to-end distortion [32].|$|E
40|$|In {{this letter}} {{a new model}} for {{variable}} bit rate (VBR) video traffic is presented. The model, {{which could be used}} as a traffic generator, considers two time scales: scenes, for periods of several minutes, and <b>groups</b> <b>of</b> <b>pictures</b> (<b>GOP),</b> for periods <b>of</b> half a second. To model the scene changes a Markov chain is used. For the GOP level a modification for the projected autorregresive (PAR) model is proposed so that the fitting of the autocorrelation function is improved. The model is utilised to imitate two real MPEG video signals, showing that it is able to accurately capture the behaviour of the real traffic in a queue...|$|R
3000|$|Every {{incoming}} {{frame is}} categorized {{as a key}} or a Wyner-Ziv frame, denoted by K and W, respectively, as to construct <b>groups</b> <b>of</b> <b>pictures</b> (<b>GOP)</b> <b>of</b> the form KW [...]...W. The key frames are coded separately using a conventional intra codec, e.g., H. 264 /AVC intra [1] or Motion JPEG.b The Wyner-Ziv frames {{on the other hand}} are encoded in two stages. For every Wyner-Ziv frame, the encoder first generates and codes a hash, which will assist the decoder during the motion estimation process. In the second stage, every Wyner-Ziv frame undergoes a discrete cosine transform (DCT) and is subsequently coded in the transform domain using powerful channel codes, thus generating a Wyner-Ziv bit stream.|$|R
40|$|Abstract—To {{overcome}} the disadvantages of output stream volatility {{due to the}} ignorance {{of the complexity of}} different frame types by IPP development platform for H. 264 in TETRA, a layered rate control algorithm is proposed. According to the channel conditions and buffer state, the proposed algorithm allocates bits to <b>Group</b> <b>of</b> <b>Picture</b> (<b>GOP),</b> frame and MB, respectively. Then, the optimized RD model and allocated bits are used to determine quantization parameter (Qp). Simulation results show the variance of the number of coding bits and coding time per frame decreases respectively by 61. 3 % and 57. 4 %, while the average PSNR increases 0. 2 dB. Keywords-H. 264 video coding; TETRA; rate control; quantization parameter I...|$|R
40|$|Abstract—Three-dimensional (3 -D) wavelet-based {{scalable}} video coding {{provides a}} viable alternative to standard MC-DCT coding. However, many current 3 -D wavelet coders experience severe boundary effects across <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP)</b> boundaries. This paper proposes a memory-efficient transform technique via lifting that effectively computes wavelet transforms of a video sequence continuously on the fly, thus eliminating the boundary effects due to limited length of individual GOPs. Coding results show that the proposed scheme completely eliminates the boundary effects and gives superb video playback quality. Index Terms—Boundary effects, lifting, 3 -D wavelet video coding. I...|$|E
3000|$|... 0 being always set at 1), each frame {{within a}} <b>group</b> <b>of</b> <b>pictures</b> (<b>GOP)</b> will be CS-sampled at the {{determined}} CS {{rates in the}} corresponding DWT levels. We perform the packing process on all frames within each GOP to generate a total number of k packets: the baseband level 0 is put into each packet, whereas the measurements for level 1 (the total number is 3 W× H/ 4 ^L- 1 r_l) is evenly put into k packets, i.e., 3 W× H/ 4 ^L- 1 r_l/k CS data are put into each packet. Notice that because measurements at level [...]...|$|E
40|$|A {{multi-level}} error {{protection technique}} for H. 264 /AVC video bitstreams is proposed. Error protection levels for video frames are determined based on frames’ motion {{activities and the}} importance of the <b>Group</b> <b>of</b> <b>Pictures</b> (<b>GOP)</b> containing the considered frames. The motion activity of a frame is evaluated by the majority of macroblocks having high motion energy, which is defined as the energy necessary for macroblocks movement between two consecutive frames. Then, the importance of a GOP is determined based on the estimation of motion energy of previous GOPs. Simulation results show that the proposed technique provides better video quality compared to other GOPbased Unequal Error Protection (UEP) techniques...|$|E
40|$|Object {{tracking}} is {{of utmost}} importance for automatic indexing of video content. This work presents an object tracker that operates directly on MPEG compressed data. Motion vectors and Discrete Cosine Transform (DCT) coefficients directly available from the compressed video stream are exploited {{for the purpose of}} tracking. Tracking proceeds in two steps: motion vector based tracking in P and B frames within the <b>Groups</b> <b>of</b> <b>Pictures</b> (<b>GOP’s),</b> and object identification in I frames. Colour, {{which is one of the}} strongest cues for tracking is used for the identification step. Such a system offers speed, simplicity and robustness against occlusion and camera motion, with good intra-shot tracking for shots in excess of 500 frames, as shown in the experimental results. 1...|$|R
40|$|Abstract—The IEEE 802. 16 {{standard}} (commonly {{known as}} WiMAX), {{which has been}} proposed as a new wireless broadband standard, is capable of delivering very high data rate and covering wide area. Video multicast service would become one potential application over WiMAX with the popularity of streaming applications in the Internet. Our method mainly uses adaptive modulation to achieve the goal of rate-adaptive multicast, and combines {{with the concept of}} layered multicast. According to the size of video layer, SS distribution, and available symbols, our method adaptively changes the modulations of each video layer in each <b>group</b> <b>of</b> <b>picture</b> (<b>GOP)</b> time. We also propose a Genetic Algorithm (GA) to reduce computational complexity when finding optimal modulation. Experimental results show that the proposed method can achieve promising performance. I...|$|R
40|$|For {{guaranteed}} {{quality of}} service (QoS) and sufficient bandwidth in a communication network which provides an integrated multimedia service, {{it is important to}} obtain an analytical and tractable model of the compressed MPEG data. This paper presents a statistical approach to a <b>group</b> <b>of</b> <b>picture</b> (<b>GOP)</b> MPEG frame size model to increase network traffic performance in a communication network. We extract MPEG frame data from commercial DVD movies and make probability histograms to analyze the statistical characteristics of MPEG frame data. Six candidates of probability distributions are considered here and their parameters are obtained from the empirical data using the maximum likelihood estimation (MLE). This paper shows that the lognormal distribution is the best fitting model of MPEG- 2 total frame data...|$|R
