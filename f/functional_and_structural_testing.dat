24|10000|Public
40|$|ABSTRACT: This paper {{presents}} {{a new approach}} for verification of fault tolerant software in aerospace applications. The approach, called the "Enhanced Condition Table", integrates the merits of <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> in a single framework. The goal is to generate a reasonably sized set of test cases that will reveal operationally significant defects in the software. The method starts with the generation of a conventional condition table based on analysis of the specification. It then proceeds through a definition of possible failure modes by means of fault trees, and finally, the definition of sequences of values for testing of loops...|$|E
40|$|In this chapter, {{we provide}} an {{overview}} of recently proposed approaches and tools for <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> of SOA services. Typically, these two classes of approaches have been considered separately. However, since they focus on different perspectives, they are generally non-conflicting and could be used in a complementary way. Accordingly, we make an attempt at such a combination, briefly showing the approach and some preliminary results of the experimentation. The combined approach provides encouraging results {{from the point of view}} of the achievements and the degree of automation obtained. A very important concern in designing and developing web services is security. In the chapter we also discuss the security testing challenges and the currently proposed solutions...|$|E
40|$|This paper {{presents}} the {{evolution in the}} development of the structural latch for the International Berthing Docking Mechanism (IBDM, see Figure 1). It reports on the lessons learned since completion of the test program on the engineering development unit of the first generation latching system in 2007. The initial latch design has been through a second generation concept in 2008, and now evolved into a third generation of this mechanism. <b>Functional</b> <b>and</b> <b>structural</b> <b>testing</b> on the latest latch hardware has recently been completed with good results. The IBDM latching system will provide the structural connection between two mated space vehicles after berthing or docking. The mechanism guarantees that the interface seals become compressed to form a leak-tight pressure system that creates a passageway for the astronauts...|$|E
40|$|An {{innovative}} Bayesian hierarchical modeling {{approach was}} used to combine longitudinal information from <b>functional</b> <b>and</b> <b>structural</b> <b>tests</b> for detection of glaucomatous progression. The methodology performed significantly better for detection of change over time than did the isolated use of <b>structural</b> or <b>functional</b> <b>tests</b> <b>and</b> the conventional approach of ordinary least-squares linear regression...|$|R
40|$|International audienceIn {{this paper}} {{parallel}} adders with minimum delay and minimum complexity under left-to-right sequential input arrival are investigated. The delay {{is the result}} time after {{the arrival of the}} last input digits which are the least significant ones. An analytical model of the complexity is established and a synthesis algorithm is described. The algorithm is implemented on a powerful multiview layout synthesis tool called GenOptim. This CAD tool outputs a set of different descriptions including: a netlist view, a layout view, a VHDL behaviour view and finally a <b>test</b> view including <b>functional</b> <b>and</b> <b>structural</b> <b>test</b> patterns with a very high fault coverage...|$|R
40|$|In {{this paper}} {{parallel}} adders with minimum delay and minimum complexity under left-to-right sequential input arrival are investigated. The delay {{is the result}} time after {{the arrival of the}} last input digits which are the least significant ones. An analytical model of the complexity is established and a synthesis algorithm is described. The algorithm is implemented on a powerful multiview layout synthesis tool called GenOptim[1]. This CAD tool outputs a set of different descriptions including: a netlist view, a layout view, a VHDL behavior view and finally a <b>test</b> view including <b>functional</b> <b>and</b> <b>structural</b> <b>test</b> patterns with a very high fault coverage. 2. Introduction Addition {{is one of the most}} fundamental operation in digital design. Fast adders has been a research subject for many years. However, most of them assume that all the input digits are ready at the same time. Our concern in this paper is to implement an adder under sequential input arrival condition starting with the most si [...] ...|$|R
40|$|Introduction Software {{reading is}} a key {{technical}} activity that aims at achieving whatever degree of understanding is needed to accomplish a particular objective. The various work documents associated with software development (e. g., requirements, design, code, and test plans) often require continual understanding, review and modification throughout the development life cycle. Thus software reading, i. e., the individual analysis of textual software work products, is the core activity in many software engineering tasks: verification and validation, maintenance, evolution, and reuse. Through our work in the SEL, we have evolved our understanding of reading technologies via experimentation. We have run empirical studies ranging from blocked subject-project experiments (reading by step-wise abstraction vs. <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> [Basili,Selby 87]) to replicated projects (University of Maryland Cleanroom study [Selby,Basili,Baker 87]) to a case study (the first SEL Cleanro...|$|E
40|$|Software Testing {{is one of}} {{the most}} {{important}} parts of the software development lifecycle. <b>Functional</b> <b>and</b> <b>structural</b> <b>testing</b> are the most widely used testing methods to test softwares. Testing effectiveness can be achieved by the State Transition Testing (STT) which is commonly used for carrying out functional testing of software systems. The tester is required to test all the possible transitions in the system under built. Structural testing relies on identifying effective paths of the code. Aim of the current paper is to present a strategy by applying ant colony optimization technique, for the generation of test sequences for state transitions of the system as well as path generation for the Control Flow Graph of the software code using the basic property and behavior of the ants. This Proposed strategy gives maximum software coverage with minimal redundancy...|$|E
40|$|Abstract—Today’s {{system-on-a-chip}} (SoC) {{is designed}} with reusable intellectual property cores to meet short time-to-market requirements. However, the increasing cost of testing becomes a big burden in manufacturing a highly integrated SoC. In this paper, an efficiently testable design technique is introduced for an SoC with an on/off-chip bus bridge for the on-chip advanced high-performance bus and off-chip peripheral-component-in-terconnect bus. The bridge is exploited by maximally reusing the bridge function to achieve efficient <b>functional</b> <b>and</b> <b>structural</b> <b>testing.</b> The testing {{time can be}} significantly reduced by {{increasing the number of}} test channels and shortening the test-control protocols. Experimental results show that area overhead and testing times are considerably reduced in both functional- and structural-test modes. The proposed technique can be extended to the other types of on/off-chip bus bridges. Index Terms—Advanced microcontroller bus architecture (AMBA), bus bridge, peripheral component interconnect (PCI), system-on-a-chip (SoC), test time, testability. I...|$|E
40|$|The visual outcome {{obtained}} after cataract removal may progressively decline {{because of}} posterior capsular opacification (PCO). This condition {{can be treated}} by creating {{an opening in the}} posterior lens capsule by Nd:YAG laser capsulotomy. PCO optical imperfections cause several light reflection, refraction, and diffraction phenomena, which may interfere with the <b>functional</b> <b>and</b> <b>structural</b> <b>tests</b> performed in different ocular locations for the diagnosis and follow-up of ocular disease, like macular and optic nerve diseases. Some parameters measured by visual field examinations, scanning laser polarimetry, and optical coherence tomography (OCT) have changed after PCO removal. Imaging quality also changes following capsulotomy. Consequently, the results of ancillary tests in pseudophakic eyes for studying ocular diseases like glaucoma or maculopathies should be correlated with other clinical examinations, for example, slit-lamp biomicroscopy or funduscopy. If PCO is clinically significant, a new baseline should be set for future comparisons following capsulotomy when using automated perimetry and scanning laser polarimetry. To perform OCT in the presence of PCO, reliable examinations (considering signal strength) apparently guarantee that measurements are not influenced by PCO...|$|R
40|$|In {{this thesis}} we {{describe}} how to systematically test, where our target has been Open Source Systems. We have applied {{a series of}} common and overlapped test design techniques at defined levels, specifically using seven different <b>functional</b> <b>and</b> <b>structural</b> <b>test</b> approaches. Our conclusion is that open source systems often lack fundamental testing, where on average it only takes 6 test cases to reveal the first failure. The first time to failure is 1 hour on average and MTTF (mean time between failures) is approximately 2 hours with our systematic approach. Our systematic approach is not only testing in itself, but we do also describe the process of discovering a system’s requirements. We have also found that some test design techniques {{seem to be more}} effective than others to find failures. We have investigated fifteen different open source systems, attempting to classify these systems in a methodical way. Our process consists in measuring time spent to identify unique part of the system where to apply the test cases. We consider both the system and the test design technique as measures to evaluate the effectiveness and construct test cases...|$|R
40|$|A {{controlled}} experiment {{performed by the}} Software Engineering Laboratory (SEL) to compare the effectiveness of code reading, <b>functional</b> <b>testing,</b> <b>and</b> <b>structural</b> <b>testing</b> as software verification techniques is described. The experiment results indicate that code reading provides the greatest error detection capability at the lowest cost, whereas <b>structural</b> <b>testing</b> is the least effective technique. The experiment plan is explained, the experiment results are described, related results from other studies are discussed. The application of these results {{to the development of}} software in the flight dynamics environment is considered. Appendices summarize the experiment data and list the test programs...|$|R
40|$|Abstract. The {{origin of}} the study {{described}} here is the experiment performed by Basili and Selby, further replicated by Kamsties and Lott, and once again by Wood et al. These experiments investigated the effectiveness and efficiency of different code evaluation techniques (<b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> and code reading). The working hypotheses are the same in all three experiments, although some experimental conditions were changed. The experiments described here use the experiment package elaborated by Kamsties and Lott and examine {{some of the questions}} posed {{as a result of these}} experiments. Wood et al. concluded in their replication of the original study that the relative effectiveness of the techniques depends on the program and fault type. In fact, they suggest formulating a fault taxonomy based on technique sensitivity. Our study intends to compare the relative effectiveness of the testing techniques and to relate the testing techniques to fault types. ...|$|E
40|$|In this paper, we {{describe}} the basic theory underlying BOR (boolean operator) testing and BRO (boolean and relational operator) test-selection criteria, and discuss experimental evidence that shows that BOR testing requires a far smaller number of test-cases than some more traditional strategies, while retaining fault-detection capabilities that are as good as, or better than these strategies. The approach {{we describe}} {{can be used to}} develop test cases based on software specifications, or based on the implementation, that is, it can be used for both <b>functional</b> <b>and</b> <b>structural</b> <b>testing.</b> We evaluate the BOR strategy with respect to branch testing, traditional causeeffect graph testing, and informal functional and random testing. Two simulation experiments showed that BOR testing is very effective at detecting faults in predicates. We also performed two experiments where we applied BOR strategy to software specification cause-effect graphs of a real-time control system and a set of N-version [...] ...|$|E
40|$|This paper {{describes}} a test method for analog and mixed signal device {{at very low}} cost and it‟s based on OBIST (oscillation test) method. This method is built-in self test method appropriate for <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> of analog and mixed signal circuit. In test mode, the test circuit is converted into an oscillator. Then faults inside the test circuit that cause an affordable deviation of the oscillation frequency from its value are detected. Through this test method, no test vector is required to apply. Therefore in this test technique, the test vector generation drawbacks are eliminated and also the test time is reduced because limited number of oscillation frequencies is evaluated for each test circuit. This characteristic implies that Oscillation-test methodology is very attractive for further wafer-probe testing as final production testing. During this paper, the simulation results of this test method has been provided and verified throughout some examples like CMOS inverter and FET (field effect transistor) ...|$|E
40|$|Abstract Background The {{performance}} of glaucoma diagnostic systems could be conceivably improved by {{the integration of}} <b>functional</b> <b>and</b> <b>structural</b> <b>test</b> measurements that provide relevant and complementary information for reaching a diagnosis. The {{purpose of this study}} was to investigate the {{performance of}} data fusion methods and techniques for simple combination of Standard Automated Perimetry (SAP) and Optical Coherence Tomography (OCT) data for the diagnosis of glaucoma using Artificial Neural Networks (ANNs). Methods Humphrey 24 - 2 SITA standard SAP and StratusOCT tests were prospectively collected from a randomly selected population of 125 healthy persons and 135 patients with glaucomatous optic nerve heads and used as input for the ANNs. We tested commercially available standard parameters as well as novel ones (fused OCT and SAP data) that exploit the spatial relationship between visual field areas and sectors of the OCT peripapillary scan circle. We evaluated the performance of these SAP and OCT derived parameters both separately and in combination. Results The diagnostic accuracy from a combination of fused SAP and OCT data (95. 39 %) was higher than that of the best conventional parameters of either instrument, i. e. SAP Glaucoma Hemifield Test (p Conclusions Compared to the use of SAP parameters, input from the combination of fused OCT and SAP parameters, and from fused OCT data, significantly increased the performance of ANNs. Integrating parameters by including a priori relevant information through data fusion may improve ANN classification accuracy compared to currently available methods. </p...|$|R
40|$|INTRODUCTION While the {{employment}} of systematic design and development practices results in increasingly reliable software, some errors are still likely {{to be present in}} the software. The goal of testing is to expose hidden errors by exercising the software on a set of test cases. In its simplest form, a test case consists of program inputs and corresponding expected outputs. Once the software has successfully gone through the testing phase, we have a greater degree of condence in the software's reliability. Software testing is very labor intensive and hence also expensive. It can account for 50 % of the total cost of software development [6]. Therefore tools that automate one or more aspects of testing can greatly help in managing the overall cost of testing. Testing techniques can be broadly classied into two categories, <b>functional</b> <b>and</b> <b>structural.</b> <b>Functional</b> <b>testing</b> is concerned with functionality rather than implementation of the program. T...|$|R
40|$|Software {{testing is}} a {{necessary}} stage in software developement and {{the life cycle of}} software which is an effective method to ensure software quality. Although the current feasible testing method can only help programmer to find out the faults in the software instead of proving its correctness, many people use assorted testing tools to improve the software quality, at least taking it as an efficient approach. In this thesis, the testing methods, structure and other features will be discussed of an easily portable testing tool for FORTRAN programs. The testing method is an combination of <b>functional</b> <b>testing</b> <b>and</b> <b>structural</b> <b>testing.</b> The structure is used deliberately to improve the portability of the system. The functional openness of the system will be evinced in detail. Instrumentation of a program is the main point of a testing system design. After a variety of ideas about instrumentation are shown, a flexible and feasible approach for instrumentation is presented for FORTRAN programs. At last, all elaborate algorithms for fulfillment of the system will be discussed briefly...|$|R
40|$|State-based {{testing is}} a new {{technique}} developed for the testing of object-oriented programs. It compliments the more traditional approaches of <b>functional</b> <b>and</b> <b>structural</b> <b>testing.</b> The features of a class provide the desired behaviour by interacting with the data-representation. Although these interactions are found in programs written in more traditional languages, they are more visible and prevalent in object-oriented programming languages. State-based testing tests these interactions by monitoring the effects that features have {{on the state of}} an object. Work has been conducted by Harrold et al. into the incremental testing of object-oriented programs. Firstly, all the features of the class are categorised into one of six groups. An algorithm is then applied to determine which test cases from a parent class can be reused, and which features require new test cases to be generated. The purpose of this report is to combine the work of state-based testing with the incremental algorithm fo [...] ...|$|E
40|$|Today’s Microprocessors {{consists}} {{of millions of}} transistors operating at extraordinarily high speeds. Verification and Test of these high performance devices continuously challenges engineers in the microprocessor design cycle. This paper gives a broad perspective {{of the field of}} microprocessor testing. Understanding of the design flow of a microprocessor is important so that difference between the various verification and validation efforts from testing is realized. The System and Physical Faults in the system are modeled either by Structural or Functional modeling. And based on the type of modeling; test strategies are developed. The corresponding test methodologies are; Structural and Functional testing. Functional Testing was traditionally adopted for LSI because the classical structural tests became computationally expensive. But Design For Testability approaches have eased structural testing. Both <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> has pros and cons. A balancing act is desired keeping in mind the various microprocessor ‘design and market ’ goals especially cost-performance. The techniques implemented in Power PC 603, a typical modern microprocessor is analyzed in order to illustrate the key ideas. Current high-performance microprocessors are a result of advancements in Integrate...|$|E
40|$|Mathematics {{has many}} useful {{properties}} for developing of complex software systems. One {{is that it}} can exactly describe a physical situation of the object or outcome of an action. Mathematics support abstraction and this is an excellent medium for modeling, since it is an exact medium there is a little possibility of ambiguity. This paper demonstrates that mathematics provides a high level of validation when it is used as a software medium. It also outlines distinguishing characteristics of structural testing which is based on the source code of the program tested. Structural testing methods are very amenable to rigorous definition, mathematical analysis and precise measurement. Finally, it also discusses <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> debate {{to have a sense of}} complete testing. Any program can be considered to be a function in the sense that program input forms its domain and program outputs form its range. In general discrete mathematics is more applicable to functional testing, while graph theory pertains more to structural testing. Comment: IEEE Publication format, ISSN 1947 5500, [URL]...|$|E
40|$|Abstract in Undetermined Background: The {{performance}} of glaucoma diagnostic systems could be conceivably improved by {{the integration of}} <b>functional</b> <b>and</b> <b>structural</b> <b>test</b> measurements that provide relevant and complementary information for reaching a diagnosis. The {{purpose of this study}} was to investigate the {{performance of}} data fusion methods and techniques for simple combination of Standard Automated Perimetry (SAP) and Optical Coherence Tomography (OCT) data for the diagnosis of glaucoma using Artificial Neural Networks (ANNs). Methods: Humphrey 24 - 2 SITA standard SAP and StratusOCT tests were prospectively collected from a randomly selected population of 125 healthy persons and 135 patients with glaucomatous optic nerve heads and used as input for the ANNs. We tested commercially available standard parameters as well as novel ones (fused OCT and SAP data) that exploit the spatial relationship between visual field areas and sectors of the OCT peripapillary scan circle. We evaluated the performance of these SAP and OCT derived parameters both separately and in combination. Results: The diagnostic accuracy from a combination of fused SAP and OCT data (95. 39 %) was higher than that of the best conventional parameters of either instrument, i. e. SAP Glaucoma Hemifield Test (p = 1 quadrant (p = 0. 031). Fused OCT and combined fused OCT and SAP data provided similar Area under the Receiver Operating Characteristic Curve (AROC) values of 0. 978 that were significantly larger (p = 0. 047) compared to ANNs using SAP parameters alone (AROC = 0. 945). On the other hand, ANNs based on the OCT parameters (AROC = 0. 970) did not perform significantly worse than the ANNs based on the fused or combined forms of input data. The use of fused input increased the number of tests that were correctly classified by both SAP and OCT based ANNs. Conclusions: Compared to the use of SAP parameters, input from the combination of fused OCT and SAP parameters, and from fused OCT data, significantly increased the performance of ANNs. Integrating parameters by including a priori relevant information through data fusion may improve ANN classification accuracy compared to currently available methods...|$|R
40|$|Abstract—The {{well-known}} approach towards testing mixed-signal cores is <b>functional</b> testing <b>and</b> basically measuring key {{parameters of}} the core. However, especially if performance requirements increase, and embedded cores are considered, functional testing becomes technically and economically less attractive. A more cost-effective approach could be accomplished {{by a combination of}} reduced <b>functional</b> <b>tests</b> <b>and</b> added <b>structural</b> <b>tests.</b> In addition, it will also improve the debugging facilities of cores. Basic problem remains the large computational effort for analogue <b>structural</b> <b>testing.</b> In this paper, we introduce the concept of Testability Transfer Function for both analogue as well as digital parts in a mixed-signal core. This opens new possibilities for efficient <b>structural</b> <b>testing</b> of embedded mixed-signal cores, thereby adding to the quality of tests...|$|R
40|$|Purpose:: To assess {{agreement}} between <b>functional</b> (mfVEP) <b>and</b> <b>structural</b> (OCT) <b>tests</b> in MS patients {{with or without}} a history of optic neuritis (ON). Methods:: MfVEP and OCT 3 (RNFL) were performed on 35 MS patients diagnosed by the revised McDonald Criteria. Group 1 (29 eyes) had the last ON attack over 6 months before testing, and Group 2 (35 eyes) never had ON. Monocular mfVEPs were obtained from both eyes of each subject using a pattern reversal dartboard stimulus (VERIS) and analyzed with customized software. 1 The mfVEP was considered abnormal if the interocular or monocular amplitude probability plot had 2 or more adjacent points with reduced amplitude P 3 ̆c 1...|$|R
40|$|The OMG 2 ̆ 7 s model-driven {{architecture}} is quickly attracting attention {{as a method}} of constructing systems that offers advantages over traditional approaches in terms of reliability, consistency, and maintainability. The key concepts in the MDA are models that are related by model transformations. However, for the MDA to provide an adequate alternative to existing approaches, it must offer comparable support for software engineering processes such as requirements analysis, design and testing. This paper attempts to explore the application of the last of these processes, testing, to the most novel part of the MDA, that of model transformation. We present a general view of the roles of testing in the different stages of model-driven development, and a more detailed exploration of approaches to testing model transformations. Based on this, we highlight the particular issues for the different testing tasks, including adequacy criteria, test oracles and automatic test data generation. We also propose possible approaches for the testing tasks, and show how existing <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> techniques can be adapted for use in this new development context...|$|E
40|$|An {{automatic}} programming assessment (APA) method aims to support marking and grading of students’ programming exercises. APA requires a test data generation {{to perform a}} dynamic testing on students’ programs. In software testing field, diverse automated methods for test data generation are proposed. Unfortunately, APA seldom adopts these methods. Merely limited studies have attempted to integrate APA and test data generation to include more useful features {{and to provide a}} precise and thorough quality of program testing coverage. Thus, we propose a test data generation approach to cover both the <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> of a program for APA by focusing the structural testing in this paper. We design a test set based on the integration of positive and negative testing criteria that enhanced path coverage criterion to select the desired test data. It supports lecturers of programming courses to furnish an adequate set of test data to assess students’ programming solutions in term of structural testing without necessarily having the expertise in a particular knowledge of test cases. The findings from the experiment depict that the test set improves the criteria of reliability and validity for test data adequacy in programming assessments...|$|E
40|$|Automatic Programming Assessment (APA) has {{recently}} become a significant method in assisting educators of programming courses to automatically mark and grade students’ programming as its counterpart; the typical manual tasks {{are prone to}} errors and leading to inconsistency. By default, test data generation process {{plays an important role}} to perform a dynamic testing on students’ programs. In software testing field, there have been diverse automated methods for test data generation. Unfortunately, APA seldom adopts these methods. Merely limited studies have attempted to integrate APA and test data generation to include more useful features and to provide a precise and thorough quality of program testing. Thus, we propose a framework of test data generation so-called FaSt-Gen to cover both the <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> of a program for APA. It aims to assist the lecturers of programming courses to furnish an adequate set of test data to assess students’ programming solutions regardless of having the concrete expertise in the particular knowledge of test cases design. FaStGen integrates the positive and negative testing criteria (or reliable and valid test adequacy criteria) to derive desired test data and test set schema. The findings from the conducted experiment depict that FaSt-Gen improves the reliability and validity test data adequacy in programming assessments...|$|E
40|$|The {{well-known}} method towards testing mixed-signal cores is <b>functional</b> testing <b>and</b> essentially measuring key {{parameters of}} the core. However, especially if performance requirements increase, and embedded cores are considered, functional testing becomes technically and economically less attractive. A more cost-effective approach could be accomplished {{by a combination of}} reduced <b>functional</b> <b>tests</b> <b>and</b> added <b>structural</b> <b>tests.</b> In addition, it will also improve the debugging options for cores. Basic problem remains the large computational effort for analogue <b>structural</b> <b>testing.</b> In this paper, we introduce the concept of Testability Transfer Function for both analogue as well as digital parts in a mixed-signal core. This opens new possibilities for efficient <b>structural</b> <b>testing</b> of embedded mixed-signal cores, thereby adding to the quality of tests and/or enhanced diagnostic capabilities...|$|R
40|$|Delay test is an {{essential}} <b>structural</b> manufacturing <b>test</b> {{used to determine the}} maximal frequency at which a chip can run without incurring any functional failures. The central unsolved challenge is achieving high delay correlation with the functional test, which is dominated by power supply noise (PSN). Differences in PSN between <b>functional</b> <b>and</b> <b>structural</b> <b>tests</b> can lead to differences in chip operating frequencies of 30 % or more. Pseudo functional test (PFT), based on a multiple-cycle clocking scheme, has better PSN correlation with functional test compared with traditional two-cycle at-speed test. However, PFT is vulnerable to under-testing when applied to delay test. This work aims to generate high quality PFT patterns, achieving high PSN correlation with functional test. First, a simulation-based don?t-care filling algorithm, Bit-Flip, is proposed to improve the PSN for PFT. It relies on randomly flipping a group of bits in the test pattern to explore the search space and find patterns that stress the circuits with the worst-case, but close to functional PSN. Experimental results on un-compacted patterns show Bit-Flip is able to improve PSN as much as 38. 7 % compared with the best random fill. Second, techniques are developed to improve the efficiency of Bit-Flip. A set of partial patterns, which sensitize transitions on critical cells, are pre-computed and later used to guide the selection of bits to flip. Combining random and deterministic flipping, we achieve similar PSN control as Bit-Flip but with much less simulation time. Third, we address the problem of automatic test pattern generation for extracting circuit timing sensitivity to power supply noise during post-silicon validation. A layout-aware path selection algorithm selects long paths to fully span the power delivery network. The selected patterns are intelligently filled to bring the PSN to a desired level. These patterns can be used to understand timing sensitivity in post-silicon validation by repeatedly applying the path delay test while sweeping the PSN experienced by the path from low to high. Finally, the impacts of compression on power supply noise control are studied. Illinois Scan and embedded deterministic test (EDT) patterns are generated. Then Bit-Flip is extended to incorporate the compression constraints and applied to compressible patterns. The experimental results show that EDT lowers the maximal PSN by 24. 15 % and Illinois Scan lowers it by 2. 77 % on un-compacted patterns...|$|R
40|$|The {{strategies}} of code reading, <b>functional</b> <b>testing,</b> <b>and</b> <b>structural</b> <b>testing</b> are compared in three aspects of software testing: fault detection effectiveness, fault detection cost, and classes of faults detected. The major results are the following: (1) Code readers detected more faults {{than did those}} using the other techniques, while functional tester detected more faults than did structural testers; (2) Code readers had a higher fault detection rate than did those using the other methods, while {{there was no difference}} between <b>functional</b> testers <b>and</b> <b>structural</b> testers; (3) Subjects testing the abstract data type detected the most faults and had the highest fault detection rate, while individuals testing the database maintainer found the fewest faults and spent the most effort testing; (4) Subjects of intermediate and junior expertise were not different in number or percentage of faults found, fault detection rate, or fault detection effort; (5) subjects of advanced expertise found a greater number of faults than did the others, found a greater percentage of faults than did just those of junior expertise, and were not different from the others in either fault detection rate or effort; and (6) Code readers <b>and</b> <b>functional</b> testers both detected more omission faults and more control faults than did structural testers, while code readers detected more interface faults than did those using the other methods...|$|R
40|$|Automatic Programming Assessment (or APA) {{has been}} known as an {{important}} method to automatically mark and grade students’ programming exercises. It has been gaining {{a lot of attention}} from many researchers either to emphasize on the aspect of static analysis or dynamic testing (<b>functional</b> <b>and</b> <b>structural</b> <b>testing).</b> To date, not many recent studies attempted to focus on the context of structural testing even though, it is key in the software testing industry. Hence it becomes {{one of the most critical}} aspects of testing to be considered. Besides that, current literatures also lack information on APA’s detailed practices. Thus, we conducted a preliminary study to investigate the test adequacy criteria that have been commonly employed in the current practices of programming assessments which are applicable only to dynamic-structural testing. Specifically, this refers to testing that needs a program execution and focuses on the logic coverage of the tested program. In this paper, we reveal the means of conducting the preliminary study and its analysis and findings. From the findings, it has been discovered that most educators are commonly adopting the identified structural code coverage in programming assessments and even have a great leaning towards allowing those criteria to be considered in implementing AP...|$|E
40|$|Systematic, through {{testing of}} {{decision}} support systems (DSSs) prior to release to general users {{is a critical}} aspect of high quality software design. Omission of this step {{may lead to the}} dangerous, and potentially fatal, condition of relying on a system with outputs of uncertain quality. Thorough testing requires a great deal of effort and is a difficult job because tools necessary to facilitate testing are not well developed. Testing is a job ill-suited to humans because it requires tireless attention to a large number of details. For these reasons, the majority of DSSs available are probably not well tested prior to release. We have successfully implemented a software design and testing plan which has helped us meet our goal of continuously improving the quality of our DSS software prior to release. While requiring large amounts of effort, we feel that the process of documenting and standardizing our testing methods are important steps toward meeting recognized national and international quality standards. Our testing methodology includes both <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> and requires input from all levels of development. Our system does not focus solely on meeting design requirements but also addresses the robustness of the system and the completeness of testing...|$|E
40|$|This study {{compares the}} results of code reading, {{functional}} testing, and structural testing in three aspects of software testing: fault detection effectiveness, fault detection cost, and classes of faults detected. Thirty two professional programmers and 42 advanced students applied the three techniques to four unit-sized programs in a fractional experimental design. The major {{results of this study}} are the following: (1) With the professional programmers, code reading detected more software faults and had a higher detection rate than did functional or structural testing, while functional testing detected more faults than did structural testing, but <b>functional</b> <b>and</b> <b>structural</b> <b>testing</b> were not different in fault detection rate. (2) In one advanced student subject group, code reading and functional testing were not different in faults found, but were superior to structural testing, while in the other advanced student subject group there was no difference among the techniques. (3) With the advanced student subjects, the three techniques were not different in fault deteciton rate. (4) Number of faults observed, fault detection rate, and total effort in detection depended on the type of software tested. (5) Code reading detected more interface faults than did the other methods. (6) Functional testing detected more control faults than did the other methods. (7) When asked to estimate the percentage of faults detected, code readers gave the most accurate estimates while functional testers gave the least accurate estimates. Appendix B includes the source code for the word...|$|E
40|$|Testing is an {{indispensable}} {{part of the}} software development life cycle. It is performed to improve the performance, quality and reliability of the software. Various types of testing such as <b>functional</b> <b>testing</b> <b>and</b> <b>structural</b> <b>testing</b> are performed on software to uncover the faults caused by incorrect code, interaction of input parameters etc. One of the major factors in deciding the quality of testing is the design of relevant test cases which is very crucial {{for the success of}} testing. In this paper we concentrate on generating test cases to uncover faults caused by the interaction of input parameters. It is advisable to perform thorough testing but the number of test cases grows exponentially with the increase in number of input parameters, which makes exhaustive testing of interaction of input parameters imprudent. An alternative to exhaustive testing is combinatorial interaction testing (CIT) which requires that every t-way interaction of input parameters be covered by at least one test case. Here, we present a novel strategy ABC-CAG (Artificial Bee Colony-Covering Array Generator) based on Artificial Bee Colony (ABC) algorithm to generate covering array and mixed covering array for pair-wise testing. The proposed ABC-CAG strategy is implemented in a tool and experiments are conducted on various benchmark problems to evaluate the efficacy of the proposed approach. Experimental results show that ABC-CAG generates better/comparable results as compared to the existing state-of-the-art algorithms...|$|R
40|$|<b>Functional</b> <b>and</b> <b>structural</b> {{reorganization}} in {{the brain}} occurs after stroke. The ability to predict motor outcomes may depend on patterns of brain <b>functional</b> <b>and</b> <b>structural</b> connectivity. We <b>tested</b> the hypothesis that alterations in motor transcallosal and corticospinal connections correlate with motor impairment in patients with chronic stroke. Eleven ischemic stroke patients underwent the Upper Extremity Fugl Meyer assessment, resting state functional magnetic resonance imaging, and diffusion tensor imaging. Twelve healthy control subjects underwent diffusion tensor imaging. We assessed the temporal coupling in neural activity between interhemispheric motor cortex, and white matter integrity by means of fractional anisotropy, in the transcallosal motor fibers and corticospinal tract. Partial correlation analyses were performed to determine whether these connectivity measures correlate with Upper Extremity Fugl Meyer scores. Patients compared to controls had reduced fractional anisotropy in common voxels of transcallosal motor and ipsilesional corticospinal fibers. Within the patient group those with higher interhemispheric motor cortex connectivity and higher fractional anisotropy in the transcallosal motor fibers were less impaired. The results show that markers of <b>functional</b> <b>and</b> <b>structural</b> motor cortex connectivity correlate with motor impairment in the chronic stage of stroke...|$|R
40|$|Integrated {{electronic}} systems are increasingly {{used in an}} wide number of applications and environments, ranging from critical missions to low cost consumer products. Information processing has been thoroughly integrated into everyday objects and activities, in the so-called ubiquitous computing paradigm. This wide distribution is caused mainly by the miniaturization of semiconductor devices (transistor channel length scaling from 180 nm in 1999 to 22 nm in 2012), which allows integrating a complete system on a single chip (SoC). However, there are many difficult challenges associated with continued cost reduction, size reduction, improved performance and improved power efficiency. One of these challenges is the reliability of these {{electronic systems}}. Important research efforts are aimed at improving the reliability of semiconductors. Manufacturing processes, intrinsic aging phenomena of components and environmental stress may cause internal defects and damages during the lifetime of a system, possibly causing misbehaviours or failures. In order to guarantee product quality and consumer satisfaction, it is necessary not only to discover faults {{as soon as possible}} in the manufacturing process, but also to continuously check for their absence throughout a product lifetime. Today's modern systems have become increasingly complex to design and build, while the demand for reliability and cost effective development continues. Reliability {{is one of the most}} important attributes in all these systems, including aerospace applications, real-time control, medical care, defence equipment, transportation, communication, entertainment products, agriculture, energy and environmental systems. Growing international competition has increased the need for all designers, managers, practitioners, scientists and engineers to ensure a high level of reliability of their product before release and during mission time, at the lowest cost. The interest in reliability has been growing in recent years and this trend will continue during the next decade and beyond. With testers being expensive pieces of equipment and the cost of transistors continuously decreasing, it make sense to use some of these low-cost transistors to replace the costly test tools, whenever possible. The first low cost approach we can think about is using the devices themselves to implement their own test. This is the underlying motivation of functional Software-Based Self-Test (SBST) : a fast, powerful microprocessor, which has lots of resources, could certainty help in its testing procedure. Having the outstanding advantages of enabling at-speed testing, zero area overhead and actually testing the device's operation, this approach also has some drawbacks. Even if SBST is essentially suitable for online testing (and sometimes it is the only possible approach), it requires some dedicated system memory for the functional testing data, which can reach very big sizes. Also some faults happen to be functionally untestable; i. e., you cannot detect them exclusively by running proper software routines. For this reason a combination of both <b>functional</b> <b>and</b> <b>structural</b> <b>test</b> approaches is common practise. A second natural approach to low cost testing is design for test (DfT). Add some extra (cheap) area on-chip specifically in charge of performing and managing tests. The DfT path started long ago, but it is still a key element in 2012 International Technology Roadmap for Semiconductors (ITRS) [1] test roadmap. Different sorts of DfT enable the use of low cost testers, contributing to the full checking of a device, and may also be reused for online testing purposes. Logic and Memory Built-In Self Test (BIST) schemas are usual practises. Analogue DfT, even if it is not as advances as digital one, is also an interesting strategy, especially when the analogue or mixed-signal device is integrated in a wider digital system like a SoC Finally, there ar...|$|R
