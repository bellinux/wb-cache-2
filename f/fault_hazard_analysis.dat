0|4734|Public
40|$|The recent Sumatra {{earthquake}} and subsequent tsunami has provoked {{greater awareness of}} the hazard posed by coseismic fault displacement associated with sea-floor subduction zones. This catastrophic event has focused renewed efforts on tsunami forecasting, modeling, and detection. Yet the mechanism that causes this type of tsunami, coseismic fault displacement of a sea-floor subduction zone, is still treated deterministically. This paper describes a methodology for probabilistic <b>fault</b> displacement <b>hazard</b> <b>analysis</b> (PFDHA) for a sea-floor subduction zone, and presents example displacement hazard curves for the Cascadia Subduction Zone. The goal of this probabilistic methodology is to quantify the uncertainty and associated <b>hazard</b> of coseismic <b>fault</b> displacement of sea-floor subduction zones. This will provide tsunami modelers with a probabilistic measure of the occurrence of fault displacement, and decision makers with a rational basis for tsunami hazard mitigation measures...|$|R
40|$|Managing faults {{and their}} {{resultant}} failures {{is a fundamental}} and critical part of developing and operating aerospace systems. Yet, {{recent studies have shown}} that the engineering "discipline" required to manage faults is not widely recognized nor evenly practiced within the NASA community. Attempts to simply name this discipline in recent years has been fraught with controversy among members of the Integrated Systems Health Management (ISHM), Fault Management (FM), <b>Fault</b> Protection (FP), <b>Hazard</b> <b>Analysis</b> (HA), and Aborts communities. Approaches to managing space system faults typically are unique to each organization, with little commonality in the architectures, processes and practices across the industry...|$|R
40|$|The DOE/NASA Stirling Engine Project Office has {{required}} that contractors make safety considerations {{an integral part}} of all phases of the Stirling engine development program. As {{an integral part of}} each engine design subtask, analyses are evolved to determine possible modes of failure. The accepted system safety analysis techniques (<b>Fault</b> Tree, FMEA, <b>Hazards</b> <b>Analysis,</b> etc.) are applied in various degrees of extent at the system, subsystem and component levels. The primary objectives are to identify critical failure areas, to enable removal of susceptibility to such failures or their effects from the system and to minimize risk...|$|R
40|$|A {{methodology}} {{is presented}} on assessing the seismic risk of buried steel pipelines crossing active tectonic faults through a comprehensive analysis by incorporating {{the uncertainty of}} the loading resulting from fault movement, soil response and the response of the pipeline itself. The proposed methodology is a two-step process. In the first step Probabilistic <b>Fault</b> Displacement <b>Hazard</b> <b>analysis</b> is implemented to quantify the probabilistic nature of the load, namely the imposed differential displacement on the pipeline due to large permanent fault displacements, incorporating all pertinent uncertainties regarding, for example, seismicity rate, maximum moment magnitude, etc. The second step is the “transition ” from seismological data to pipeline structural response through a vector intensity measure represented by the fault displacement components in 3 D. Advanced pipeline numerical simulations are then carried out in order to form pipeline strain hazard curves as a useful engineering tool for pipeline fault crossing seismic risk assessment...|$|R
40|$|The {{introduction}} of computers into safety-critical control systems lays {{a heavy burden}} on the software designers. The public and the legislators demand reliable and safe computer control systems, equal to or better than the mechanical or electromechanical parts they replace. The designers must have {{a thorough understanding of}} the system and more accurate software design and verification techniques than have usually been deemed necessary for software development. This document presents existing concepts and methods, relating to the design of software in safety-critical computer control systems. The concepts and methods dealing with fault avoidance, fault removal, <b>fault</b> tolerance, <b>hazard</b> <b>analysis</b> and safe design will be penetrated in detail. The document will enlighten the reader of what kind of realistic expectations the designer can form regarding the reliability and safety of a system's software. The author of the document has concluded that it is not enough to, for example, solely re [...] ...|$|R
25|$|Reliability {{engineering}} is {{the discipline of}} ensuring a system meets customer expectations for reliability throughout its life; i.e., it does not fail more frequently than expected. Next to prediction of failure {{it is just as}} much about prevention of failure. Reliability engineering applies to all aspects of the system. It is closely associated with maintainability, availability (dependability or RAMS preferred by some), and logistics engineering. Reliability {{engineering is}} always a critical component of safety engineering, as in failure modes and effects <b>analysis</b> (FMEA) and <b>hazard</b> <b>fault</b> tree <b>analysis,</b> and of security engineering.|$|R
40|$|A {{methodology}} {{is presented}} on assessing {{the effectiveness of}} flexible joints in mitigating the consequences of faulting on buried steel pipelines through a comprehensive analysis that incorporates the uncertainty of fault displacement magnitude and {{the response of the}} pipeline itself. The proposed methodology is a two-step process. In the first step the probabilistic nature of the fault displacement magnitude is evaluated by applying the Probabilistic <b>Fault</b> Displacement <b>Hazard</b> <b>Analysis,</b> considering also all pertinent uncertainties. The second step is the “transition ” from seismological data to the pipeline structural response through the fault displacement components as the adopted vector intensity measure. To mitigate the consequences of faulting on pipelines, flexible joints between pipeline parts are proposed as innovative measure for reducing the deformation of pipeline walls. Thus, the mechanical behavior of continuous pipelines and pipelines with flexible joints is numerically assessed and strains are extracted in order to develop the corresponding strain hazard curves. The latter are a useful engineering tool for pipeline – fault crossing risk assessment and for the effectiveness evaluation of flexible joints as innovative mitigating measures against the consequences of faulting on pipelines...|$|R
40|$|Abstract. The paper {{presents}} a new method for multivalued simulation of digital circuits based on calculation of Boolean derivatives on BDDs (or structural alternative graphs). A procedure for calculation of maximums of Boolean derivatives {{as the basis}} of multivalued simulation is given. The method is applicable for component level representations of digital circuits where as components arbitrary subcircuits (macros) instead of gates are considered. No dedicated model library for multivalued simulation is needed. Instead of dedicated multi-valued models, generic ones in the form of BDDs are used. Implementation areas of multivalued simulation for delay <b>fault</b> testing and <b>hazard</b> <b>analysis</b> are discussed. Advantages of the new approach compared to the traditional gate-level multivalued simulation are shown. Experimental data for ISCAS benchmarks to demonstrate these advantages are also included. 1...|$|R
40|$|<b>Fault</b> Displacement <b>Hazard</b> <b>Analysis</b> (FDHA) {{plays an}} {{important}} role in the risk assessment and design of both new and existing infrastructures located across and near active and potentially active faults. The primary objective of FDHA is to quantify the spatial distribution and amplitude of surface displacements and deformation caused by tectonic faulting. Lessons learned from recent earthquakes, new research, and implementation of FDHA methodologies in projects, as well as recent guidance documents (e. g. ANS, 2015), provide the current perspective on FDHA in the assessment of tectonic surface deformation of engineering concern. However, compared to other types of seismic <b>hazard</b> <b>analysis</b> (ground motion, liquefaction, slope failure), this field is still considered by many to be in its early stages of development. After a kick-off meeting in Paris (October 2015), sponsored by IRSN, the Menlo Park workshop, co-organized by USGS, CGS, INGV and IRSN, aimed at bringing together researchers, practitioners, and stakeholders interested in the topic of fault displacement, to discuss issues pertaining to FDHA, and to develop a plan for moving FDHA research forward. The workshop was very successful in terms of the quality of presentations and discussions, as well as in attendance. It attracted more than 100 participants from 11 countries (USA, Chile, Japan, China, Singapore, New Zealand, Australia, England, Italy, Austria and France), 8 major infrastructure stakeholders, 11 universities, 12 government agencies and laboratories, and 17 geologic engineering consulting companies. The workshop included talks on “Lessons Learned from Recent Earthquakes” (6 talks), “Observational Data for the Surface Rupture during Earthquakes (SURE) Database” (6 talks), the “Application and Advances in Deterministic and Probabilistic <b>Fault</b> Displacement <b>Hazard</b> Analysis” (10 talks) ” and possible ways for “Moving Forward” (2 talks). The abstracts and slideshows, as well as the attendance list and the schedule, are available on the website of the INQUA Focus Group on Earthquake Hazards ([URL] Researchers, especially from the US, Europe, Japan and New Zealand, are currently updating and compiling existing fault rupture data that will be incorporated into the SURE database, to complete the compilation performed by IRSN in 2017. The US stakeholders have identified potential funding partners (currently PEER [Pacific Earthquake Engineering Research Center] and PG&E [Pacific Gas and Electric Company]) for improving the Database (with western US data), which will be guided and managed by a US Executive committee. The International community will participate in this as much as possible and, in parallel, will identify sources and request funding for its own activities...|$|R
40|$|Prediction of {{location}} {{and amount of}} slip for distributed faulting associated to strong earthquakes is a recently explored issue with major implications in terms of hazard assessment. Currently, the best practice involves the applications of Probabilistic <b>Fault</b> Displacement <b>Hazard</b> <b>Analysis</b> (PFDHA) whose results fit sufficiently well real data in the near-range of the primary fault but show considerable inaccuracies in the far-range. We believe that this inaccuracy descends from the biased earthquake databases used for regression analysis, whose data, relative to old earthquakes, were largely collected only by field surveys focused close to the primary fault (i. e., near-range). Remotely-sensed data (i. e., Interferometric Radar Imaging e InSAR) offer the opportunity to precisely measure the surface deformation induced by strong earthquakes and thus to explore its possible relation with distributed faulting. We analyze the L'Aquila earthquake case study (29 th April, 2009, Mw 6. 3) and explore the correlation between location and slip on distributed faulting and InSAR-derived deformation field. We find a significant correlation between occurrence of distributed faulting and profile curvature of the dislocation field, {{in spite of the}} distance from the primary fault. Moreover, distributed faults tend to occur within the area deformed by the earthquake, as imaged by InSAR data and whose extent is directly proportional to the earthquake magnitude (Mw), according to a dataset of 30 recent earthquakes. We then propose that these observations have to be incorporated into the present PFDHA practice as limit boundaries to possible scenarios of probabilistic analysis and that an integrated use of field-based and remotely data collection have to be implemented, following strong earthquakes...|$|R
60|$|Owen, {{seeing me}} at <b>fault,</b> <b>hazarded</b> a whisper, of which I {{fortunately}} caught the import.|$|R
40|$|The {{potential}} effects of carbon fibers on consumer {{products such as}} dishwashers, microwave ovens, and smoke detectors were investigated. The investigation was divided into two categories to determine the potential <b>faults</b> and <b>hazards</b> that could occur if fibers should enter the electrical circuits of the selected appliances. The categories were a <b>fault</b> <b>analysis</b> and a <b>hazard</b> <b>analysis.</b> <b>Hazards</b> considered were fire, flood, physical harm, explosion, and electrical shock. Electrical shock {{was found to be}} a possible occurrence related to carbon fibers. Faults were considered to be any effect on the performance of an appliance which would result in complaint or require service action...|$|R
40|$|This report {{describes}} the methodology used in conducting the Canister Storage Building (CSB) <b>Hazard</b> <b>Analysis</b> {{to support the}} final CSB Safety Analysis Report and documents the results. This report {{describes the}} methodology used in conducting the Canister Storage Building (CSB) <b>hazard</b> <b>analysis</b> to support the CSB final safety analysis report (FSAR) and documents the results. The <b>hazard</b> <b>analysis</b> process identified hazardous conditions and material-at-risk, determined causes for potential accidents, identified preventive and mitigative features, and qualitatively estimated the frequencies and consequences of specific occurrences. The <b>hazard</b> <b>analysis</b> was performed {{by a team of}} cognizant CSB operations and design personnel, safety analysts familiar with the CSB, and technical experts in specialty areas. The material included in this report documents the final state of a nearly two-year long process. Attachment A provides two lists of <b>hazard</b> <b>analysis</b> team members and describes the background and experience of each. The first list is a complete list of the <b>hazard</b> <b>analysis</b> team members that have been involved over the two-year long process. The second list is a subset of the first list and consists of those <b>hazard</b> <b>analysis</b> team members that reviewed and agreed to the final <b>hazard</b> <b>analysis</b> documentation. The material included in this report documents the final state of a nearly two-year long process involving formal facilitated group sessions and independent <b>hazard</b> and accident <b>analysis</b> work. The <b>hazard</b> <b>analysis</b> process led to the selection of candidate accidents for further quantitative analysis. New information relative to the hazards, discovered during the accident analysis, was incorporated into the <b>hazard</b> <b>analysis</b> data in order to compile a complete profile of facility hazards. Through this process, the results of the hazard and accident analyses led directly to the identification of safety structures, systems, and components, technical safety requirements, and other controls required to protect the public, workers, and environment...|$|R
40|$|The <b>Hazard</b> <b>Analysis</b> Database was {{developed}} {{in conjunction with the}} <b>hazard</b> <b>analysis</b> activities conducted in accordance with DOE-STD- 3009 - 94, Preparation Guide for U S. Department of Energy Nonreactor Nuclear Facility Safety Analysis Reports, for HNF-SD-WM-SAR- 067, Tank Farms Final Safety Analysis Report (FSAR). The FSAR is part of the approved Authorization Basis (AB) for the River Protection Project (RPP). This document describes, identifies, and defines the contents and structure of the Tank Farms FSAR <b>Hazard</b> <b>Analysis</b> Database and documents the configuration control changes made to the database. The <b>Hazard</b> <b>Analysis</b> Database contains the collection of information generated during the initial hazard evaluations and the subsequent <b>hazard</b> and accident <b>analysis</b> activities. The <b>Hazard</b> <b>Analysis</b> Database supports the preparation of Chapters 3, 4, and 5 of the Tank Farms FSAR and the Unreviewed Safety Question (USQ) process and consists of two major, interrelated data sets: (1) <b>Hazard</b> <b>Analysis</b> Database: Data from the results of the hazard evaluations, and (2) Hazard Topography Database: Data from the system familiarization and hazard identification...|$|R
40|$|A <b>hazards</b> <b>analysis</b> {{identifies}} the operation hazards and the positive measures that {{aid in the}} mitigation or prevention of the hazard. If the tasks are human intensive, the <b>hazard</b> <b>analysis</b> often credits the personnel training as contributing to the mitigation of the accident`s consequence or prevention of an accident sequence. To be able to credit worker training, {{it is important to}} understand the role of the training in the <b>hazard</b> <b>analysis.</b> Systematic training, known as systematic training design (STD), performance-based training (PBT), or instructional system design (ISD), uses a five-phase (analysis, design, development, implementation, and evaluation) model for the development and implementation of the training. Both a <b>hazards</b> <b>analysis</b> and a training program begin with a task analysis that documents the roles and actions of the workers. Though the tasks analyses are different in nature, there is common ground and both the <b>hazard</b> <b>analysis</b> and the training program can benefit from a cooperative effort. However, the cooperation should not end with the task analysis phase of either program. The information gained from the <b>hazards</b> <b>analysis</b> should be used in all five phases of the training development. The training evaluation, both of the individual worker and institutional training program, can provide valuable information to the <b>hazards</b> <b>analysis</b> effort. This paper will discuss the integration of the information from the <b>hazards</b> <b>analysis</b> into a training program. The paper will use the installation and removal of a piece of tooling that is used in a high-explosive operation. This example will be used to follow the systematic development of a training program and demonstrate the interaction and cooperation between the <b>hazards</b> <b>analysis</b> and training program...|$|R
40|$|This paper {{presents}} {{an account of}} carrying out a <b>hazard</b> <b>analysis</b> to define the safety requirements for an autonomous robotic excavator. The work is also relevant to the growing generic class of heavy automated mobile machinery. An overview of the excavator design is provided {{and the concept of}} a safety manager is introduced. The safety manager is an autonomous module responsible for all aspects of system operational safety, and is central to the control system's architecture. Each stage of the <b>hazard</b> <b>analysis</b> is described, i. e. system model creation, hazard definition and <b>hazard</b> <b>analysis.</b> Analysis at an early stage of the design process, and on a system that interfaces directly to an unstructured environment, exposes certain issues relevant to the application of current <b>hazard</b> <b>analysis</b> methods. The approach taken in the analysis is described. Finally, it is explained how the results of the <b>hazard</b> <b>analysis</b> have influenced system design, in particular, safety manager specifications. Conclusions are then drawn about the applicability of <b>hazard</b> <b>analysis</b> of requirements in general, and suggestions are made as to how the approach can be taken furthe...|$|R
40|$|This {{viewgraph}} presentation reviews The NASA <b>Hazard</b> <b>Analysis</b> process. The contents include: 1) Significant Incidents and Close Calls in Human Spaceflight; 2) Subsystem Safety Engineering Through the Project Life Cycle; 3) The Risk Informed Design Process; 4) Types of NASA Hazard Analysis; 5) Preliminary <b>Hazard</b> <b>Analysis</b> (PHA); 6) <b>Hazard</b> <b>Analysis</b> Process; 7) Identify Hazardous Conditions; 8) Consider All Interfaces; 9) Work a Preliminary Hazard List; 10) NASA Generic Hazards List; and 11) Final Thought...|$|R
40|$|Techniques for {{analyzing}} {{the safety and}} reliability of analog-based electronic protection systems that serve to mitigate hazards in process control systems have been developed over many years, and are reasonably well understood. An example is the protection system in {{a nuclear power plant}} The extension of these techniques to systems which include digital computers is not well developed, and there is little consensus among software engineering experts and safety experts on how to analyze such systems. One possible technique is to extend <b>hazard</b> <b>analysis</b> to include digital computer-based systems. Software is frequently overlooked during system hazard analyses, but this is unacceptable when the software is in control of a potentially hazardous operation. In such cases, <b>hazard</b> <b>analysis</b> should be extended to fully cover the software. A method for performing software <b>hazard</b> <b>analysis</b> is proposed in this paper. Software Safety <b>Hazard</b> <b>Analysis</b> iv Software Safety <b>Hazard</b> <b>Analysis</b> v CONTENTS A [...] ...|$|R
40|$|Readily {{available}} interferometric data (InSAR) of the coseismic {{deformation field}} caused by recent seismic events clearly show that major earthquakes produce crustal deformation over wide areas, possibly resulting in significant stress loading/unloading of the crust. Such stress {{must be considered}} in the evaluation of seismic hazards of nuclear power plants (NPP) and, in particular, for the potential of surface slip (i. e., probabilistic <b>fault</b> displacement <b>hazard</b> <b>analysis</b> - PFDHA) on both primary and distributed faults. In this study, {{based on the assumption that}} slip on pre-existing structures can represent the elastic response of compliant fault zones to the permanent co-seismic stress changes induced by other major seismogenic structures, we propose a three-step procedure to address fault displacement issues and consider possible influence of surface faulting/deformation on vibratory ground motion (VGM). This approach includes: (a) data on the presence and characteristics of capable faults, (b) data on recognized and/or modeled co-seismic deformation fields and, where possible, (c) static stress transfer between source and receiving faults of unknown capability. The initial step involves the recognition of the major seismogenic structures nearest to the site and their characterization in terms of maximum expected earthquake and the time frame to be considered for determining their ‘‘capability” (as defined in the International Atomic Energy Agency - IAEA Specific Safety Guide SSG- 9). Then a GIS-based buffer approach is applied to identify all the faults near the NPP, possibly influenced by the crustal deformation induced by the major seismogenic structures. Faults inside these areas have to be tested for ‘‘capability” according to the same time window defined for the primary seismogenic structures. If fault capability is confirmed or, eventually, cannot be assessed, the next step is to implement an approach based on the potential to affect the safety of the NPP site in terms of fault geometry, and potential displacement. Finally, in the case where the fault can affect the safety of the site, the third step is the PFDHA or, in other words, the calculation of the annual probability of exceedance of the potential co-seismic fault displacement; this displacement is to be compared with the fault displacement threshold that will impact the safety of the NPP site. We also consider the effect of site vicinity tectonism on site vibratory ground motion and discuss an example in the light of the use of the GMPE...|$|R
40|$|This report {{describes}} the methodology used in conducting the Canister Storage Building (CSB) <b>hazard</b> <b>analysis</b> {{to support the}} CSB final safety analysis report (FSAR) and documents the results. The <b>hazard</b> <b>analysis</b> was performed {{in accordance with the}} DOE-STD- 3009 - 94, ''Preparation Guide for US. Department of Energy Nonreactor Nuclear Facility Safety Analysis Reports'', and meets the intent of HNF-PRO- 704, ''Hazard and Accident <b>Analysis</b> Process''. This <b>hazard</b> <b>analysis</b> implements the requirements of DOE Order 5480. 23, ''Nuclear Safety Analysis Reports''...|$|R
40|$|The {{purpose of}} a fire <b>hazards</b> <b>analysis</b> (FHA) is to {{comprehensively}} assess the risk from fire and other perils within individual fire areas in a DOE facility in relation to proposed fire protection so as to ascertain whether the objectives of DOE 5480. 7 A, Fire Protection, are met. This Fire <b>Hazards</b> <b>Analysis</b> was prepared as required by HNF-PRO- 350, Fire <b>Hazards</b> <b>Analysis</b> Requirements, (Reference 7) {{for a portion of}} the 300 Area N Reactor Fuel Fabrication and Storage Facility...|$|R
40|$|This {{protocol}} {{is intended}} to be used by health and safety experts and those with expertise in anaerobic digesters/systems. It was adapted from basic elements of both traditional job <b>hazard</b> <b>analysis</b> and process <b>hazards</b> <b>analysis</b> (particularly <b>hazard</b> and operability <b>analysis)</b> techniques, and {{is intended to}} overcome some of the limitations of both methods for someone conducting...|$|R
50|$|The college's {{original}} builders {{were unaware}} of local <b>fault</b> <b>hazards,</b> and constructed the campus upon an elevated pressure ridge (the Bunker Hill Dike) along the San Jacinto Fault Zone, which bisects the campus and ran under the foundations of some buildings. Between 2001 and 2010, several of the campus' major buildings have been demolished and new ones built nearby.|$|R
40|$|A joint {{research}} project between MIT and JAXA/JAMSS {{is investigating the}} application of a new <b>hazard</b> <b>analysis</b> to the system and software in the HTV. Traditional <b>hazard</b> <b>analysis</b> focuses on component failures but software does not fail in this way. Software most often contributes to accidents by commanding the spacecraft into an unsafe state (e. g., turning off the descent engines prematurely) or by not issuing required commands. That makes the standard <b>hazard</b> <b>analysis</b> techniques of limited usefulness on software-intensive systems, which describes most spacecraft built today...|$|R
40|$|Abstract. The macroseismic {{intensity}} is a subjective indicator of ground motion intensity. Convex analysis method and China Probabilistic Seismic <b>Hazard</b> <b>Analysis</b> methodology are combined to derive peak acceleration for Ningbo city, China. The peak acceleration interval obtained {{by using the}} convex set theory-based seismic <b>hazard</b> <b>analysis</b> methodology is compared with that calculated by using China Probabilistic Seismic <b>Hazard</b> <b>Analysis</b> methodology. The sensitivity analysis indicates that the interval of peak acceleration is most sensitive to the annual occurrence ratev. Furthermore, the correlation of uncertain variables cannot be neglected for peak acceleration prediction...|$|R
40|$|A new <b>hazard</b> <b>analysis</b> technique, called systems-theoretic process analysis, {{is capable}} of {{identifying}} potential hazardous design flaws, including software and system design errors and unsafe interactions among multiple system components. Detailed procedures for performing the <b>hazard</b> <b>analysis</b> were developed, and the feasibility and utility of using it on complex systems was demonstrated by applying it to the Japanese Aerospace Exploration Agency H-II Transfer Vehicle. In {{a comparison of the}} results of this new <b>hazard</b> <b>analysis</b> technique to those of the standard fault tree analysis used in the design and certification of the H-II Transfer Vehicle, systems-theoretic <b>hazard</b> <b>analysis</b> found all the hazardous scenarios identified in the fault tree analysis as well as additional causal factors that had not been identified by fault tree analysis. Japan Manned Space Systems Corporatio...|$|R
40|$|For any safety-critical system, {{thorough}} and complete <b>hazard</b> <b>analysis</b> must be performed {{if the system}} is to be acceptably safe to operate. For the emerging class of systems known as Systems of Systems (SoS), however, performing <b>hazard</b> <b>analysis</b> is extremely difficult because {{of the complexity of}} SoS and the environments they inhabit. Traditional exploratory <b>hazard</b> <b>analysis</b> techniques commonly rely upon fixed models of component interaction, and have difficulties exploring the effects of multiple coincident failures. They therefore cannot be relied on to provide adequate <b>hazard</b> <b>analysis</b> of SoS. This thesis presents a <b>hazard</b> <b>analysis</b> approach that uses multi-agent modelling and simulation to explore the effects of deviant system behaviour within a SoS. A systematic process is defined for developing multi-agent models of SoS, starting from existing models in the MODAF architecture framework and proceeding to implemented simulation models. Throughout this process, a variety of cross-checks between model artefacts provide confidence that the model remains true to the original description and that it adequately describes the SoS being analysed. The exploratory simulations created by the process generate a substantial amount o...|$|R
40|$|Implementation of <b>hazard</b> <b>analysis</b> {{critical}} control point in jameed production AK Al-Saed 1, RM Al-Groum 2 and MM Al-Dabbas 1 The average of {{standard plate count}} and coliforms, Staphylococcus aureus and Salmonella counts for three home-made jameed samples, a traditional fermented dairy product, before applying <b>hazard</b> <b>analysis</b> {{critical control}} point system were 2. 1 103, 8. 9101, 4 101 and less than 10 cfu/g, respectively. The developed <b>hazard</b> <b>analysis</b> critical control point plan resulted in identifying ten critical control points in the flow chart of jameed production. The critical control points included fresh milk receiving, pasteurization, addition of starter, water and salt, straining, personnel hygiene, drying and packaging. After applying <b>hazard</b> <b>analysis</b> critical control point system, there was significant improvement in the microbiological quality of the home-made jameed. The standard plate count was reduced to 3. 1102 cfu/g whereas coliform and Staphylococcus aureus counts were less than 10 cfu/g and Salmonella was not detected. Sensory evaluation results of color and flavor of sauce prepared from jameed showed {{a significant increase in}} the average scores given after <b>hazard</b> <b>analysis</b> critical control point application...|$|R
40|$|Traditionally, <b>hazard</b> <b>analysis</b> {{has been}} a manual process {{performed}} by safety engineers following a systematic process. This has proved highly effective for existing systems. However, for Systems of Systems of the complexity now being constructed {{it is becoming increasingly}} difficult to use these conventional techniques, particularly when considering the effects of multiple concurrent and distributed failures. It therefore seems advisable to investigate how automation can assist in the <b>hazard</b> <b>analysis</b> process. In order to do this, it is necessary to clearly identify the role of the human in <b>hazard</b> <b>analysis,</b> and determine the unique contribution made by human intelligence. This paper, in particular, identifies the importance of creative input and application of domain knowledge in deriving accurate and complete results. From this, it identifies some parts of the <b>hazard</b> <b>analysis</b> process where automation could be used to improve performance. As an example of how this could work, a partially-automated approach to Systems of Systems <b>hazard</b> <b>analysis</b> is presented, and this is illustrated using a military system case study...|$|R
5000|$|... #Caption: <b>Hazard</b> <b>Analysis</b> and Critical Control Points (HACCP) Flowchart ...|$|R
5000|$|... #Subtitle level 2: <b>Hazard</b> <b>Analysis</b> and Critical Control Points ...|$|R
40|$|In case of {{moderate}} to strong earthquakes (generally for M > 5. 5), coseismic slip along a fault can reach directly the ground surface and produce surface faulting. Although scarcely {{considered in the}} Italian legislation, surface <b>faulting</b> <b>hazard</b> can have a relevant societal impact because it exposes to substantial risk urban areas and/or important infrastructures, facilities and critical lifelines that are settled or planned in coincidence of an active and capable fault trace. In this paper we present a case study from the area hit by the Mw 6. 1 April 6, 2009 L’Aquila earthquake (Central Italy), where buildings and critical lifelines located across or near the coseismic surface ruptures suffered significant damage. High resolution (1 m) LiDAR topographic data contributed to the assessment of surface <b>faulting</b> <b>hazard</b> through a better imaging of the surface geometrical arrangement of the earthquake causative fault and through {{the analysis of the}} spatial relationships between active fault splays and critical lifelines and infrastructures...|$|R
5000|$|<b>Hazard</b> <b>Analysis</b> and Critical Control Points (HACCP), risk {{management}} methodology ...|$|R
40|$|Elicitation of {{requirements}} for safety critical aeroengine control systems {{is dependent on}} the capture of core design intent and the systematic derivation of requirements addressing hazardous deviations from that intent. Derivation of these requirements is inextricably linked to the safety assessment process. Conventional civil aerospace practice (as advocated by guidelines such as ARP 4754 and ARP 4671) promotes the application of Functional Hazard Assessment (FHA) to sets of statements of functional intent. Systematic <b>hazard</b> <b>analysis</b> of scenario-based requirements representations is less well understood. This paper discusses the principles and problems of <b>hazard</b> <b>analysis</b> and proposes an approach to conducting <b>hazard</b> <b>analysis</b> on use case requirements representations. Using the approach, it is possible to justifiably derive hazard-mitigation use cases as first class requirements from systematic <b>hazard</b> <b>analysis</b> of core design intent scenarios. An industrial example is used to illustrate the technique...|$|R
40|$|This paper {{constitutes}} {{the second part}} of a previous one where the importance of geological data and geologically based criteria in the first two steps of a seismic <b>hazard</b> <b>analysis</b> (SHA) were studied. This paper deals now with the last two steps in SHA: Strong ground motion attenuation function and probabilistic calculations. In the first one, geological knowledge is of great importance to identify and classify soil conditions and to effectively incorporate the effect of <b>faulting</b> mechanism in <b>hazard</b> calculations. In the second one, the interest of considering paleoseismological data –e. g., maximum geological magnitude, mean recurrence period, elapsed time since last event– in computing probabilities is reviewe...|$|R
40|$|In system development, epistemic {{uncertainty}} is an ever-present possibility when reasoning about the causal factors during <b>hazard</b> <b>analysis.</b> Such {{uncertainty is}} common when complicated systems interact with one another, {{and it is}} dangerous because it impairs <b>hazard</b> <b>analysis</b> and thus increases the chance of overlooking unsafe situations. Uncertainty around causation thus needs to be managed well. Unfortunately, existing <b>hazard</b> <b>analysis</b> techniques tend to ignore unknown uncertainties, and system stakeholders rarely track known uncertainties well through the system lifecycle. In this paper, we outline an approach to managing epistemic uncertainty in existing <b>hazard</b> <b>analysis</b> techniques by focusing on known and unknown uncertainty. We have created a reference populated {{with a wide range}} of safety-critical causal relationships to recognise unknown uncertainty, and we have developed a model to systematically capture and track known uncertainty around such factors. We have also defined a process for using the reference and model to assess possible causal factors that are suspected during <b>hazard</b> <b>analysis.</b> To assess the applicability of our approach, we have analysed the widely-used MoDAF architectural model and determined that there is potential for our approach to identify additional causal factors that are not apparent from individual MoDAF views. We have also reviewed an existing safety assessment example (the ARP 4761 Aircraft System analysis) and determined that our approach could indeed be incorporated into that process. We have also integrated our approach into the STPA <b>hazard</b> <b>analysis</b> technique to demonstrate its feasibility to incorporate into existing techniques. It is therefore plausible that our approach can increase safety assurance provided by <b>hazard</b> <b>analysis</b> in the face of epistemic uncertainty. Comment: In Proceedings CREST 2017, arXiv: 1710. 0277...|$|R
