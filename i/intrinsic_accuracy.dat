83|33|Public
5000|$|Sufficient {{statistics}} and <b>intrinsic</b> <b>accuracy,</b> Proc. Camb. Phil. Soc. 32, (1936), 567 - 579.|$|E
50|$|The combat {{record of}} U.S. SARH {{missiles}} was unimpressive during the Vietnam War. USAF and US Navy fighters armed with AIM-7 Sparrow attained a {{success rate of}} barely 10%, which tended to amplify the effect of deleting the gun on most F-4 Phantoms, which carried 4 Sparrows. While some of the failures were attributable to mechanical failure of 1960s-era electronics, which could be disturbed by pulling a cart over uneven pavement, or pilot error; the <b>intrinsic</b> <b>accuracy</b> of these weapons was low relative to Sidewinder and guns.|$|E
5000|$|Information quality {{describes}} the value which information provides to the reader. Wang and Strong categorize assessable dimensions of information into <b>intrinsic</b> (<b>accuracy,</b> , believability, reputation), contextual (relevancy, value-added/authenticity, ness, ness, quantity), representational (interpretability, format, coherence, compatibility) and accessibile (accessibility and access security).Humans can base their judgments on quality {{based on experience}} in judging content, style and grammatical correctness. Information systems like search engines need indirect means, allowing concluding {{on the quality of}} information. Google’s PageRank algorithm takes approximately 200 ranking factors included in a learning algorithm to assess information quality ...|$|E
40|$|In {{this paper}} the {{matching}} behaviour of MOS transistors is analyzed for {{the realization of}} an <b>intrinsic</b> [...] <b>accuracy</b> 14 bit current [...] steering D/A [...] converter. It {{is well known that}} the area of a MOS transistor is inversely proportional to the mismatch (Pelgrom mismatch model), related through a technology constant. Also the influence of metal coverage on the mismatch of MOS transistors has been reported. In this work these results are verified. A test chip has been processed and measured. It is an actual implementation of a D/A-converter. From the static linearity measurements the mismatch behavior is extracted, including metal coverage and edge effects. The resulting mismatch error behaviour is important information for the design of future high [...] accuracy circuits. This work paved the ground for the design of the first <b>intrinsic</b> 14 bit <b>accuracy</b> D/A-converter in CMOS known to the authors. I. INTRODUCTION The recent boom in telecommunications systems is pushing circuits to both higher f [...] ...|$|R
5000|$|Another {{challenge}} will be {{the large number of}} sequencing errors that are expected. Next-generation sequencing technologies provide enormous throughput but lower accuracies than older sequencing methods. When sequencing a single genome, the <b>intrinsic</b> lower <b>accuracy</b> of these methods is far more than compensated for by the ability to cover the entire genome multiple times in opposite directions from multiple start points, but this capability provides no improvement in accuracy when sequencing a diverse mixture of genomes. The question will be, how can sequencing errors be distinguished from actual diversity in the collected microbial samples? ...|$|R
40|$|We {{elaborate}} on a Hilbert-Schmidt distance measure assessing the <b>intrinsic</b> metrological <b>accuracy</b> in {{the detection of}} signals imprinted on quantum probe states by signal-dependent transformations. For small signals {{this leads to a}} probe-transformation measure Lambda fully symmetric on the probe rho and the generator G of the transformation Λ(ρ,G) = Λ(G,ρ). Although Λ can be regarded as a generalization of variance, we show that no uncertainty relation holds for the product of measures corresponding to complementary generators. We show that all states with resolution larger than coherent states are nonclassical. We apply this formalism to feasible probes and transformations...|$|R
50|$|The {{original}} Mk 4 FFAR {{was about}} 4 ft (1.2 m) long and weighed 18.5 lb (8.4 kg), with a high-explosive warhead of about 6 lb (2.7 kg). Like the Third Reich Luftwaffe's R4M projectile of World War II, it had folding fins that flipped out on launch to spin-stabilize the rocket, with the FFAR using {{half the number}} (four) of fins {{in comparison to the}} R4M's set of eight folding fins. Its maximum effective range was about 3,700 yards (3,400 m). Because of its low <b>intrinsic</b> <b>accuracy,</b> it was generally fired in large volleys, some aircraft carrying as many as 104 rockets.|$|E
5000|$|Another {{advantage}} is the action size. For example, if we compare the [...]25 WSSM to the [...]25-06 Remington, {{we find that}} the [...]25-06 requires a [...]30-06 length action, commonly called a standard or long action. The [...]25 WSSM case which is almost a full inch shorter, can make use of an existing short action such as used by the [...]308 Winchester family of cartridges. Some manufacturers have even created extra short actions to accommodate newer short rounds. The <b>intrinsic</b> <b>accuracy</b> benefits of a short, stiffer action over a long action are well-established principles of rifle design. The resulting rifle is smaller, lighter, more compact, and quicker handling as well.|$|E
5000|$|The Model 44 or Large Frame Dan Wesson was {{initially}} offered with 4", 6", 8", or 10" [...] interchangeable barrel/shroud options, and most guns shipped with a 6-inch barrel. A 2 1/2" [...] barrel/shroud was later introduced, {{available as a}} separate option from the factory. Like the Model 15-2, the Model 44 could also be purchased {{with a variety of}} shroud configurations - either partial lug or full lug with a solid rib or ventilated-rib barrel. The Model 44 could also be obtained with a [...] "Power Control" [...] barrel compensator. [...] This was a stainless steel barrel drilled radially at the muzzle end with a series of small ports. Two small vents cut into the top of the barrel shroud vented excess gas and reduced apparent recoil of the gun, although this feature eliminated the option of using cast lead bullets due to lead and carbon accumulation. At the time, Dan Wesson M44 was the lightest recoiling [...]44 magnum ever produced. [...] Light recoil was a side benefit in IHMSA silhouette competitions. The Model 44's high level of <b>intrinsic</b> <b>accuracy,</b> combined with an excellent trigger, and fast lock time, caused a surge in popularity of the M44 in heavy-caliber revolver competition, though the gun was also popular with handgun hunters and sportsmen who desired a gun for personal protection against bears or other large predators. The Power Control barrel and vented shroud were eventually dropped, though DW did experiment with an external shroud-mounted compensator in later models.|$|E
40|$|Using high {{precision}} irradiance {{data from the}} Southern Great Plains ARM extended facility network [1], we confirm results of initial efforts by the authors to quantify the effective [...] <b>intrinsic</b> [...] <b>accuracy</b> of hourly global irradiances derived from geostationary satellite observations. We extend this initial analysis to other components –direct and diffuse – {{as well as other}} time steps – 1 -minute and daily. For pixel sizes of the order of 10 km, we show that accuracy achievable with current satellite-based models is remarkably close to the pixel-wide achievable by a ground station located within the considered pixel...|$|R
40|$|Optimization of {{the working}} {{parameters}} in the drift chambers with adjustable electric fields permits stable operation and high accuracies. Full saturation of the drift velocity leads to remarkable improvements, namely a very linear space-time correlation for perpendicular tracks, and simple geometrical distortion of linearity for inclined tracks. The same results can be obtained when properly tilting the electric field equipotentials {{in a wide range}} of external magnetic fields. This simple behaviour should allow a practical use, even for large systems, of the <b>intrinsic</b> high <b>accuracy</b> of the drift chambers (100 â 8 ̆ 09 ̆ 3200 Î¼m). They appear then as a very promising high-resolution fast detector for high-energy particle physics...|$|R
40|$|A new {{technique}} for {{the determination of}} extrinsic and intrinsic camera parameters is presented. Instead of searching for {{a limited number of}} discrete feature points of the calibration test object, the entire image captured with the camera is exploited to robustly determine the unknown parameters. Shape and texture of the test object are described by a 3 -D computer graphics model. With this 3 -D representation, synthetic images are rendered and matched with the original frames in an analysis by synthesis loop. Therefore, arbitrary test objects with sophisticated patterns can be used to determine the camera settings. The scheme can easily be extended to deal with multiple frames for a higher <b>intrinsic</b> parameter <b>accuracy.</b> ...|$|R
40|$|Fundamental {{principles}} of mapping 3 -dimensional quasiparticle dispersions in the valence band using angle-resolved photoemission spectroscopy are discussed. Such mapping is intrinsically limited in accuracy owing to damping {{of the final}} states, resulting in equivalent broadening in the surface-perpendicular wavevector. Mechanisms of the <b>intrinsic</b> <b>accuracy</b> are discussed in depth based on a physically transparent picture involving interplay of the final- and initial-state spectral functions, and illustrated by photoemission simulations and experimental examples. Other interesting effects of 3 -dimensional dispersions include 'ghost' peaks in the unoccupied valence band region and finite peak width at the Fermi level. Finally, optimization of the experiment on the <b>intrinsic</b> <b>accuracy</b> is discussed. Comment: 9 pages, 6 Postscript figures, minor revisions, J. Electr. Spectr. Relat. Phenom. (in press...|$|E
40|$|Many {{methods used}} for {{estimation}} and detection consider only {{the mean and}} variance of the involved noise instead of the full noise descriptions. One {{reason for this is}} that the mathematics is often considerably simplified this way. However, the implications of the simplifications are seldom studied, and this thesis shows that if no approximations are made performance is gained. Furthermore, the gain is quantified in terms of the useful information in the noise distributions involved. The useful information is given by the <b>intrinsic</b> <b>accuracy,</b> and a method to compute the <b>intrinsic</b> <b>accuracy</b> for a given distribution, using Monte Carlo methods, is outlined. A lower bound for the covariance of the estimation error for any unbiased estimator is given by the Cramér-Rao lower bound (CRLB). At the same time, the Kalman filter is the best linear unbiased estimator (BLUE) for linear systems. It is in this thesis shown that the CRLB and the BLUE performance are given by the same expression, which is parameterized in the <b>intrinsic</b> <b>accuracy</b> of the noise. How the performance depends on the noise is then used to indicate when nonlinear filters, e. g., a particle filter, should be used instead of a Kalman filter. The CRLB results are shown, in simulations, to be...|$|E
40|$|The {{development}} of the correlation consistent basis sets, cc-pVnZ (where n = D, T, Q, etc.) have allowed for the systematic elucidation of the <b>intrinsic</b> <b>accuracy</b> of ab initio quantum chemical methods. In density functional theory (DFT), where the cc-pVnZ basis sets are not necessarily optimal in their current form, the elucidation of the <b>intrinsic</b> <b>accuracy</b> of DFT methods cannot always be accomplished. This dissertation outlines investigations into the basis set requirements for DFT and how the <b>intrinsic</b> <b>accuracy</b> of DFT methods may be determined with a prescription involving recontraction of the cc-pVnZ basis sets for specific density functionals. Next, the development and benchmarks {{of a set of}} cc-pVnZ basis sets designed for the s-block atoms lithium, beryllium, sodium, and magnesium are presented. Computed atomic and molecular properties agree well with reliable experimental data, demonstrating the accuracy of these new s-block basis sets. In addition to the {{development of}} cc-pVnZ basis sets, the development of a new, efficient formulism of the correlation consistent Composite Approach (ccCA) using the resolution of the identity (RI) approximation is employed. The new formulism, denoted 'RI-ccCA,' has marked efficiency in terms of computational time and storage, compared with the ccCA formulism, without the introduction of significant error. Finally, this dissertation reports three separate investigations of the properties of FOOF-like, germanium arsenide, and silicon hydride/halide molecules using high accuracy ab initio methods and the cc-pVnZ basis sets...|$|E
40|$|Original article can {{be found}} at: [URL] Copyright American Physical Society. DOI: 10. 1103 /PhysRevA. 77. 063813 We {{elaborate}} on a Hilbert-Schmidt distance measure assessing the <b>intrinsic</b> metrological <b>accuracy</b> in the detection of signals imprinted on quantum probe states by signal-dependent transformations. For small signals {{this leads to a}} probe-transformation measure ?? fully symmetric on the probe ?? and the generator G of the transformation ??(??,G) =??(G,??). Although ?? can be regarded as a generalization of variance, we show that no uncertainty relation holds for the product of measures corresponding to complementary generators. We show that all states with resolution larger than coherent states are nonclassical. We apply this formalism to feasible probes and transformations...|$|R
40|$|Beginning in the 1980 's, Coriolis meters {{have gained}} {{generalised}} acceptance in liquid applications with a worldwide installed base of over 300, 000 units. To {{meet the demands}} of cryogenic applications below 20 K, off-the-shelf Coriolis meters have been used, with minor design modifications and operational changes. The meters were originally calibrated on water and tested on liquid helium at 4. 5 K, supercritical helium around 5 K and superfluid helium below 2 K. The meters maintain their <b>intrinsic</b> robustness and <b>accuracy</b> of better than 1 % of measured value; accuracy is independent of density and temperature...|$|R
40|$|A {{field in}} {{the centre of the}} LMC Bar has been studied for star-formation history and evolution. We used the HST with its WFPC 2 plus Stromgren b and y photometry. The {{programme}} exposures were made during 22 primary spacecraft orbits. A special part of our programme is dedicated to conversion of the b and y data obtained on the WFPC 2 system to corresponding data on the international uvby system. The reduction procedure is designed to extract the full <b>intrinsic</b> photometric <b>accuracy</b> of the material secured. Reduction includes dithering, elimination of effects of cosmic-ray hits and decomposition of crowded images. For the PC field, magnitudes and colour indices are accurate to better than 0. 02 mag down to the lower turn off region at y= 22 and around or better than 0. 04 mag down to y=b= 24. Data from two of the WFC fields show an accuracy only marginally lower than that of the PC material, whilst the remaining WFC field delivers photometry with standard deviations around 30 % higher than t [...] ...|$|R
30|$|The {{obtained}} results emphasise {{the necessity}} of defining standardised methodologies and best practices for different imaging systems. Specifically, we {{draw attention to the}} importance of calibration (spectral, radiometric and spatial) procedures and knowledge of the <b>intrinsic</b> <b>accuracy,</b> precision and limits of the technologies. Furthermore, the RRT made clear the need for regular calibration, validation and testing of every system.|$|E
40|$|We present new {{empirical}} {{and theoretical}} calibrations of two photometric metallicity indices based on Walraven photometry. The empirical calibration {{relies on a}} sample of 48 Cepheids for which iron abundances based on high resolution spectra {{are available in the}} literature. They cover a broad range in metal abundance (- 0. 5 < [Fe/H] < + 0. 5) and the <b>intrinsic</b> <b>accuracy</b> of the Metallicity Index Color (MIC) relations is better than 0. 2 dex. The theoretical calibration relies on a homogeneous set of scaled-solar evolutionary tracks for intermediate-mass stars and on pulsation predictions concerning the topology of the instability strip. The metal content of the adopted evolutionary tracks ranges from Z= 0. 001 to Z= 0. 03 and the <b>intrinsic</b> <b>accuracy</b> of the MIC relations is better than 0. 1 dex. Comment: 6 pages, 5 figures; to appear in Mem. Soc. Astr. Italiana, Vol. 79 / 2 (proceeding Cefalu' Workshop "XXI Century Challenges for Stellar Evolution", ed. S. Cassisi & M. Salaris...|$|E
40|$|An {{iterative}} {{algorithm is}} presented for solving the RPA equations of linear response. The method optimally computes the energy-weighted {{moments of the}} strength function, allowing one to match the computational effort to the <b>intrinsic</b> <b>accuracy</b> of the basic mean-field approximation, avoiding the problem of solving very large matrices. For local interactions, the computational effort for the method scales {{with the number of}} particles N_p as O(N_p^ 3) ...|$|E
40|$|A {{geometric}} {{scheme for}} detecting, representing, and measuring 3 D medical data is presented. The technique {{is based on}} deforming 3 D surfaces, represented via level-sets, towards the medical objects, according to intrinsic geometric measures of the data. The 3 D medical object is represented as a (weighted) minimal surface in a Riemannian space whose metric is induced from the image. This minimal surface is computed using the level-set methodology for propagating interfaces, combined with a narrow band technique which allows fast implementation. This computation technique automatically handles topological changes. Measurements like volume and area are performed on the surface, exploiting the representation and the high <b>accuracy</b> <b>intrinsic</b> to the algorithm...|$|R
40|$|International audienceLadders of RC-cell {{are usually}} used for compact thermal {{representation}} of power modules or assemblies. A {{large number of}} cells are considered in order to balance the <b>intrinsic</b> poor dynamic <b>accuracy</b> of the representation. However the number is limited by convergence problems in simulation. The RC-cells representation is also questionable in terms of relation to physical quantities. These limitations may be overcome using the so-called diffusive representation to build systematically a low-order but accurate thermal model of any assembly, and including thermal couplings. The paper intends to demonstrate how to build practically a diffusive model and assert its validation by experiment and through confrontation to finite-element simulations. A compact diffusive model comes as a state space model and main be easily implemented in circuit simulator...|$|R
40|$|Several {{types of}} Wavefront Sensors (WFS) are {{nowadays}} {{available in the}} field of Adaptive Optics (AO). Generally speaking, their basic principle consists in measuring slopes or curvatures of Wavefront Errors (WFE) transmitted by a telescope, subsequently reconstructing WFEs digitally. Such process, however, {{does not seem to be}} well suited for evaluating co-phasing or piston errors of future large segmented telescopes in quasi real-time. This communication presents an original, recently proposed technique for direct WFE sensing. The principle of the device, which is named "Telescope-Interferometer" (TI), is based on the addition of a reference optical arm into the telescope pupil plane. Then incident WFEs are deduced from Point Spread Function (PSF) measurements at the telescope focal plane. Herein are described two different types of TIs, and their performance are discussed in terms of <b>intrinsic</b> measurement <b>accuracy</b> and spatial resolution. Various error sources are studied by means of numerical simulations, among which photon noise sounds the most critical. Those computations finally help to define the application range of the TI method in an AO regime, including main and auxiliary telescope diameters and magnitude of the guide star. Some practical examples of optical configurations are also described and commented. Comment: 12 pages, 10 figure...|$|R
40|$|Fluorescence {{intensity}} measurements {{have the}} potential to facilitate the diagnoses of many pathological conditions. However, accurate interpretation of the measurements is complicated by the distorting effects of tissue scattering and absorption. Consequently, different techniques have been developed to attempt to compensate for these effects. This paper reviews currently available correction techniques with emphasis on clinical application and consideration given to the <b>intrinsic</b> <b>accuracy</b> and limitations of each technique...|$|E
40|$|Wind speeds {{derived from}} {{versions}} of the least-squares and regression algorithms developed after the JASIN Workshop were evaluated. The accuracy of scanning multichannel microwave radiometer (SMMR) wind retrievals was determined {{in terms of the}} <b>intrinsic</b> <b>accuracy</b> of a baseline surface truth data set in favorable conditions. Effects which degrade the wind retrievals or introduce biases were identified and assessed. The performance of the SMMR in storms was ascertained with particular emphasis on the effects of rain...|$|E
40|$|A {{description}} of the precision triaxial fluxgate magnetometer to be flown aboard the MAGSAT spacecraft is presented. The instrument covers the range of + or - 64, 000 nT with a resolution of + or - 0. 5 nT, an <b>intrinsic</b> <b>accuracy</b> of + or - 0. 001 % of full scale and an angular alignment stability {{of the order of}} 2 seconds of arc. It was developed at NASA's Goddard Space Flight Center and represents the state-of-the-art in precision vector magnetometers developed for spaceflight use...|$|E
40|$|A {{wide range}} of parser and/or grammar {{evaluation}} methods {{have been reported in}} the literature. However, in most cases these evaluations take the parsers independently (intrinsic evaluations), and only in a few cases has the effect of different parsers in real applications been measured (extrinsic evaluations). This paper compares two evaluations of the Link Grammar parser and the Conexor Functional Dependency Grammar parser. The parsing systems, despite both being dependency-based, return different types of dependencies, making a direct comparison impossible. In the <b>intrinsic</b> evaluation, the <b>accuracy</b> of the parsers is compared independently by converting the dependencies into grammatical relations and using the methodology of Carroll et al. (1998) for parser comparison. In the extrinsic evaluation, the parsers' impact in a practical application is compared within the context of answer extraction. The differences in the results are significant. 8 page(s...|$|R
40|$|It {{has long}} been argued that better timing {{precision}} allowed by satelites like Rossi X-ray Timing Experiments (RXTE) {{will allow us to}} measure the orbital eccentricity and the angle of periastron of some of the bright persistent high mass X-ray binaries (HMXBs) and hence a possible measurement of apsidal motion in these system. Measuring the rate of apsidal motion allows one to estimate the apsidal motion constant of the mass losing companion star and hence allows for the direct testing of the stellar structure models for these giant stars present in the HMXBs. In the present paper we use the archival RXTE data of two bright persistent sources, namely Cen X- 3 and SMC X- 1, to measure the very small orbital eccentricity and the angle of periastron. We find that the small variations in the pulse profiles of these sources rather than the <b>intrinsic</b> timing <b>accuracy</b> provided by RXTE, limit the accuracy with which we can measure arrival time of the pulses from these sources. This influences the accuracy with which one can measure the orbital parameters, especially the very small eccentricity and the angle of periastron in these sources. The observations of SMC X- 1 in the year 2000 were taken during the high flux state of the source and we could determine the orbital eccentricity and ω using this data set. Comment: 11 pages, 18 figures, to be published in MNRA...|$|R
40|$|In {{the present}} study, source-monitoring {{processes}} that are required to distinguish a memory trace of a true event from an internally generated false memory were investigated, using the Deese-Roediger-McDermott paradigm (DRM) to induce false memories, while obtaining fMRI measurements. In order to explore individual differences in memory performance and source monitoring abilities, participants were divided into Low False Memory (LFM) and High False Memory (HFM) groups based on accuracy for critical lure words. Subsequent analyses of the two groups’ behavioural data revealed <b>intrinsic</b> differences in <b>accuracy</b> and response time patterns, while post hoc ROI analyses of the groups’ functional data, consistent with the behavioural findings, revealed significant enhanced activations during recognition for the LFM group compared to the HFM group in areas previously shown {{to be linked to}} memory and source monitoring performance. As far as we know, this is the first study to identify possible neural mechanisms underlying individual differences in source monitoring abilities related to false memory susceptibility...|$|R
40|$|The {{accuracy}} of a binary-scale diagnostic test {{can be represented}} by sensitivity (Se), specificity (Sp) and positive and negative predictive values (PPV and NPV). Although Se and Sp measure the <b>intrinsic</b> <b>accuracy</b> of a diagnostic test that {{does not depend on}} the prevalence rate, they do not provide information on the diagnostic {{accuracy of}} a particular patient. To obtain this information we need to use PPV and NPV. Since PPV and NPV are functions of both the <b>intrinsic</b> <b>accuracy</b> and the prevalence of the disease, constructing confidence intervals for PPV and NPV for a particular patient in a population with a given prevalence of disease using data from a case-control study is not straightforward. In this paper, a novel method for the estimation of PPV and NPV is developed using estimates of sensitivity and specificity in a case-control study. For PPV and NPV, standard, adjusted and their logit transformed based confidence intervals are compared using coverage probabilities and interval lengths in a simulation study. These methods are then applied to two examples: a diagnostic test assessing the ability of the ApoE 4 allele on distinguishing patients with late-onset Alzheimer 2 ̆ 7 s disease and a prognostic test assessing the predictive ability of a 70 -gene signature on breast cancer metastasis...|$|E
40|$|Abstract – We have {{investigated}} the <b>intrinsic</b> <b>accuracy</b> of the optical frequency scale in spectra acquired by a Fourier Transform Spectrometer (FTS). The uncalibrated accuracy of the FTS optical frequency axis is about 1 part in 105. This uncertainty can be reduced by at least two orders of magnitude using a multiplicative calibration correction derived from a single wavelength standard line. The work reported here describes {{a new approach to}} accurate calibration of the wavenumber scale for a UV-visible FTS, which we have used to measure accurate wavenumbers and Ar pressure shifts for the prominent lines of 198 Hg...|$|E
40|$|ZEMAX {{provides}} a standard built-in atmospheric model to simulate atmospheric refraction and dispersion. This {{model has been}} compared with other ones to assess its <b>intrinsic</b> <b>accuracy,</b> critical for very demanding application like ADCs for AO-assisted extremely large telescopes. A revised simple model, based on updated published data of the air refractivity, is proposed by using the "Gradient 5 " surface of Zemax. At large zenith angles (65 deg), discrepancies up to 100 mas in the differential refraction are expected near the UV atmospheric transmission cutoff. When high-accuracy modeling is required, the latter model should be preferred. Peer reviewed: YesNRC publication: Ye...|$|E
40|$|This paper present {{improved}} Walsh function (IWF) algorithm as {{an alternative}} approach for active and reactive power measurement in linear and nonlinear, balanced and unbalanced sinusoidal three phase load system. It takes advantage of Walsh function unified approach and its <b>intrinsic</b> high level <b>accuracy</b> {{as a result of}} coefficient characteristics and energy behaviour representation. The developed algorithm was modeled on the Matlab Simulink software; different types of load, linear and nonlinear were also modeled based on practical voltage and current waveforms and tested with the proposed improved Walsh algorithm. The IEEE standard 1459 - 2000 which is based on fast Fourier transform FFT approach was used as benchmark for the linear load system while a laboratory experiment using Fluke 435 power quality analyzer PQA which complies with IEC/EN 61010 - 1 - 2001 standards was used to validate the improved algorithm for nonlinear load measurement. The results showed that the algorithm has the potential to effectively measure three phase power components under different load conditions...|$|R
40|$|Various {{types of}} {{expansions}} in series of Chebyshev-Hermite polynomials currently used in astrophysics for weakly non-normal distributions are compared, namely the Gram-Charlier, Gauss-Hermite and Edgeworth expansions. It is {{shown that the}} Gram-Charlier series is most suspect because of its poor convergence properties. The Gauss-Hermite expansion is better but it has no <b>intrinsic</b> measure of <b>accuracy.</b> The best results are achieved with the asymptotic Edgeworth expansion. We {{draw attention to the}} form of this expansion found by Petrov for arbitrary order of the asymptotic parameter and present a simple algorithm realizing Petrov's prescription for the Edgeworth expansion. The results are illustrated by examples similar to the problems arising when fitting spectral line profiles of galaxies, supernovae, or other stars, and for the case of approximating the probability distribution of peculiar velocities in the cosmic string model of structure formation. (orig.) 41 refs. Available from TIB Hannover: RR 4697 (1051) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|R
40|$|The <b>intrinsic</b> high <b>accuracy</b> {{of modern}} HF {{direction}} finders cannot be realized in practice {{due to the}} perturbations and tilts which exist in the ionosphere. Particular attention is given in this dissertation {{to the effect of}} Travelling Ionospheric Disturbances (TIDs) since their occurrence is difficult to predict and the magnitude of the induced bearing error extremely variable. TID activity is quantified by monitoring simultaneously the bearings of a number of transmitters whose locations and frequencies are well known. This information is then employed to determine the expected bearing error on a target transmission reflected in the same area of the ionosphere. The major limitations of this correction scheme are investigated. The large-scale temporal and spatial variations of the quiet ionosphere (Systematic Ionospheric Tilts, SITs) produce bearing errors of similar magnitude to those due to TIDs. Rapid calculation of these errors for various path geometries and ionospheric conditions is possible by raytracing through 3 -D ionospheric models. The limitations of a correction scheme which employs a 3 -D model based on ionospheric predictions are examined. Variance is a particularly useful statistic in assessing the 'reliability' of bearings made on a particular HF circuit. A scheme is proposed in which the bearings of a network of reference transmitters are monitored continuously allowing a variance to be assigned to any target transmission, even if it is only present for a very short time. These variance values are of considerable value in practical DF applications. Whenever possible the experimental observations are related to the underlying physical processes in the ionosphere which generate these DF errors...|$|R
