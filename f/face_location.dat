78|296|Public
5000|$|In May 2017, Google {{announced}} several updates to Google Photos. [...] "Suggested Sharing" [...] reminds {{users to}} share captured photos after the fact, and also groups photos based on faces and suggests recipients based on facial recognition. [...] "Shared Libraries" [...] lets two users share a central repository for all photos or specific categories of images. [...] "Photo Books" [...] are physical collections of photos, offered either as softcover or hardcover albums, with Photos automatically suggesting collections based on <b>face,</b> <b>location,</b> trip, or other distinction. Towards {{the end of}} the month, Google introduced an [...] "Archive" [...] feature that lets users hide photos from the main timeline view without deleting them. Archived content still appears in relevant albums and in search. In June, the new sharing features announced in May began rolling out to users.|$|E
50|$|Google Photos gives users free, {{unlimited}} {{storage for}} photos up to 16 megapixels and videos up to 1080p resolution. The service automatically analyzes photos, identifying various visual features and subjects. Users can search {{for anything in}} photos, with the service returning results from three major categories: People, Places, and Things. Google Photos recognizes faces, grouping similar ones together; geographic landmarks (such as the Eiffel Tower); and subject matter, including birthdays, buildings, animals, food, and more. Google implements different forms of machine learning into the Photos service, particularly its recognition of photo contents, as well as enabling features that can automatically generate albums, animate similar photos into quick videos, surface past memories at significant times, and {{improve the quality of}} photos and videos. In May 2017, Google announced several updates to Google Photos, including reminders for and suggested sharing of photos, shared photo libraries between two users, and physical albums, with Photos automatically suggesting collections based on <b>face,</b> <b>location,</b> trip, or other distinction.|$|E
40|$|Abstract: In {{order to}} solve the slowly {{processing}} speed, low precision problems in the <b>Face</b> <b>location</b> and detection, the comprehensive <b>face</b> <b>location</b> algorithm based on composite skin color was proposed in this paper. The YCrCb model algorithm and HSV model algorithm are skillfully applied to the comprehensive <b>face</b> <b>location</b> algorithm. The human body region and background region can be detected and judged by the color value of every pixel for image in the YCrCb and HSV space. Then, the connecting region can be screened and decided by the geometric features of human face, and the face can be accurately located and detected. The experimental results confirm that the algorithm can achieve the accuracy ratio of <b>face</b> <b>location</b> in three cases, such as simple, medium and complexity, are 99 %, 92 % and 85 %, respectively. Furthermore, the accuracy ratio of <b>face</b> <b>location</b> and detection speed was improved in this algorithm...|$|E
50|$|The site is chalk {{grassland}} {{which has a}} diverse flora. The main grasses are red fescue, quaking grass and yellow oat grass. Orchids include the common spotted and pyramidal, and the profusion of chalk flowers and its south <b>facing</b> <b>location</b> make the site important for bees, grasshoppers and butterflies.|$|R
5000|$|Apple {{says it has}} {{improved}} the face recognition of the Photos application, adding object and scene recognition. It groups similar pictures together using <b>faces,</b> <b>locations</b> and object recognition to create [...] "memories". Memories contain picture slideshows with transitions and music selected by the algorithm, which can be modified to the user's liking. The [...] "People" [...] album organizes photos by the people in them, and Places shows all photos on a world map.|$|R
50|$|The {{part-time}} MBA can {{be taken}} in face to <b>face</b> satellite <b>locations</b> in Boston, Shrewsbury or Springfield, as well as fully online.|$|R
40|$|This paper proposes the {{automatic}} face recognition method {{based on the}} face representation with five major processing modules- Filters, <b>Face</b> <b>Location,</b> Feature Location, Normalization, and Face Recognition. This precisely reflects the geometric features of the specific subject. We test our proposed algorithm database, and experimental results, show the effectiveness and competitive performance of the proposed method...|$|E
30|$|The {{commonly}} used algorithms of <b>face</b> <b>location,</b> eye location, and fatigue detection and classification are analyzed and improved. In {{the analysis of}} face localization algorithm based on skin color modeling, the corner-based optimization of face region is proposed; {{in the analysis of}} eye localization algorithm based on binary algorithm, a bi-directional integral projection method is proposed to achieve accurate eye localization.|$|E
40|$|Abstract. Face {{recognition}} {{technology is}} a significant branch {{of the study of}} artificial intelligence, the recognition precision is easily affected by facial expressions, skin colors, beam angles in the images and apparels. This essay tests human face images in the format of 24 BMP and realizes <b>face</b> <b>location</b> and mark of five sense organs. Firstly, color space model is adopted to set up skin color distribution model to segment skin regions; secondly, the obtained regions are judged and screened preliminarily, and optimized based on the characteristics of segmented regions with region optimization algorithm of depth-width ratio, rejecting the region with the similar color of the skin caused by some disturbing factors and other naked parts of the body, through which the rough region of human face could be attained and <b>face</b> <b>location</b> could be realized; finally, five organs of the obtained face region is located with the method of grey level region in combination with searching rectangle...|$|E
50|$|At Chatham, the Miramichi River {{is quite}} wide, the water salt and tidal. Just {{downstream}} from the town, the river begins to widen into a broad estuary, where the Miramichi River gradually becomes Miramichi Bay. Because of its eastward <b>facing</b> <b>location,</b> ships {{coming from the}} British Isles in early times had easy access through the Strait of Belle Isle and across the Gulf of St. Lawrence. It was more accessible and safer to get to than the ports of Quebec City or Saint John, New Brunswick.|$|R
5000|$|... 2. Trier Region. Around {{the city}} of Trier and in the valleys of the Saar and Ruwer with their side valleys, the Riesling is the {{predominant}} grape on the shale soils, with over 80% of the crop. One climatic feature of this area is the frequent orientation of often small southwest-southeast <b>facing</b> <b>locations</b> in which the vegetation is exposed to stronger, cooler winds and, especially {{in the light of}} recent global warming, often achieve lower degrees of maturity than in the narrow, often deeply incised valley of the Middle and Lower Moselle.|$|R
3000|$|Because MOBIO {{database}} {{does not}} provide <b>face</b> <b>locations,</b> the OpenCV's Haar Feature-based Cascade Classifier [35] is used to detect faces in each frame. The faces are then tracked over multiple frames using Continuously Adaptive Mean-SHIFT Tracker (CAMSHIFT) [65] with colour histograms. Once the faces are detected, eyes are further located within the face using a Haar-based classifier. If no eyes are located, they are approximated from {{the size of the}} face detected. The faces are then resized and cropped such that the eyes are centered with a 32 -pixel intereye distance. For these experiments, a closely cropped face of [...]...|$|R
40|$|In this paper, {{we present}} a neural network-based {{algorithm}} to detect frontal views of faces in color image. The algorithms and training methods are general, and {{can be applied to}} other views of faces, as well as to similar object and pattern recognition problems. The <b>face</b> <b>location</b> algorithm, which I have used, makes use of a number of classical image processing techniques. All of these techniques possess their ow...|$|E
40|$|New video {{communication}} and multi-media products {{open up a}} range of machine vision applications, in which the potential size of the market can justify a substantial investment {{in the development of}} sophisticated algorithms. <b>Face</b> <b>location</b> can be used to enhance the subjective performance of videophones, while still conforming with international video compression standards. This paper gives an overview of the location techniques employed, describes a real-time implementation, and presents the results of the subjective tests which confirmed the improvement in picture quality. ...|$|E
40|$|Abstract. We {{suggest a}} novel attentional {{mechanism}} for detection of smooth convex and concave objects based on direct processing of in-tensity values. The operator detects {{the regions of}} the eyes and hair in a facial image, and thus allows us to infer the <b>face</b> <b>location</b> and scale. Our operator is robust to variations in illumination, scale, and face ori-entation. Invariance to a large family of functions, serving for lighting improvement in images, is proved. An extensive comparison with edge-based methods is delineated. ...|$|E
40|$|In this paper, an {{intelligent}} {{system that can}} locate and identify the lecturer in a smart environment is presented. The purpose of the presented system is to provide technologies that can assist the lecturer during his/her presentation and to facilitate lecture retrieval {{by means of the}} identity of the lecturer. The system consists of two main building blocks, a robust face detector based 3 D position generation-fusing 2 D <b>face</b> <b>locations</b> from multiple cameras-and a novel face identification system that utilizes data coming from multiple cameras and video. The performance of the system is tested on the seminar data collected under the CHIL project. 1...|$|R
40|$|The Informedia Digital Video Library system {{extracts}} {{information from}} digitized video sources and allows full content search and retrieval over all extracted data. This extracted 2 ̆ 7 metadata 2 ̆ 7 enables users to rapidly find interesting news stories and to quickly identify whether a retrieved TV news story is indeed {{relevant to their}} query. This article highlights two unique features: named <b>faces</b> and <b>location</b> analysis. Named <b>faces</b> automatically associate a name with a <b>face,</b> while <b>location</b> analysis allows the user to visually follow the action in the news story on a map and also allows queries for news stories by graphically selecting a region on the ma...|$|R
50|$|The hotel's beachside <b>{{location}}</b> <b>faces</b> Anibare Bay, {{a popular}} location for swimming on Nauru.|$|R
40|$|We {{suggest a}} novel attentional {{mechanism}} for detection of smooth convex and concave objects based on direct processing of intensity values. The operator detects {{the regions of}} the eyes and hair in a facial image, and thus allows us to infer the <b>face</b> <b>location</b> and scale. Our operator is robust to variations in illumination, scale, and face orientation. Invariance to a large family of functions, serving for lighting improvement in images, is proved. An extensive comparison with edge-based methods is delineated. Key words: Face Detection. Convexity. Gradient Argument. ...|$|E
40|$|Abstract- This work {{presents}} {{a new approach}} to automatic <b>face</b> <b>location</b> on gray-scale static images with complex backgrounds. In a first stage our technique approximately detects the image positions where the probability of finding a face is high; during the second stage the location accuracy of the candidate faces is improved and their existence is verified. The experimentation shows that the algorithm performs very well both in terms of detection rate (just one missed detection on 70 images) and of efficiency (about 13 images/sec. can be processed on Hardware Intel Pentium II 266 MHz) ...|$|E
40|$|This paper {{deals with}} the problem of finding facial {{features}} in images, a problem which arises in face recognition and {{in a number of other}} applications, especially in human-computer interaction, which derive information from human faces. This paper describes a system for finding faces in images and for finding facial features given the estimated <b>face</b> <b>location.</b> The techniques, based on Fisher's linear discriminant and distance from feature space, are presented, and results are presented on faces from the FERET database. The paper further describes how feature collocation statistics can be used to verify feature locations and estimate the locations of missing features...|$|E
40|$|We {{present the}} first method for the {{generation}} of posters directly from video, borrowing the layout and composition from existing poster exemplars as a guide. Our system analyzes a given poster by determining <b>face</b> <b>locations</b> and poses, detecting the title and computing {{an analysis of the}} remaining background image. Processing of the video proceeds by locating major cast members and a suitable background frame. A new poster is then seamlessly constructed from scratch with faces, title and background appropriately sized and positioned as in the example. This work has broad application and potential for widespread use given the increasing importance of Creative Commons amateur film making, as well as internet and personal video...|$|R
50|$|In the USA, {{there are}} beekeepers — from hobbyists to {{commercial}} — in every state. The most lucrative areas for American honey production are Florida, Texas, California, and the Upper Midwest. For paid pollination, the main areas are California, the Pacific Northwest, the Great Lakes States, and the Northeast. An apiary may have other hive management objectives including queen rearing and mating. In the northern hemisphere, {{east and south}} <b>facing</b> <b>locations</b> with full morning sun are preferred. In hot climates, shade is needed and {{may have to be}} artificially provided if trees are not present. Other factors include air and water drainage and accessibility by truck, distance from phobic people, and protection from vandalism.|$|R
40|$|The {{proliferation}} of High Sensitivity (HS) GPS receivers {{in recent years}} has been driven in part by requirements for the provision of location information with user-initiated emergency calls from mobile handsets. Mobile handsets are, by their very nature, restricted in size and so on-board real-estate is at a premium. The GPS antenna may therefore not be positioned in a sky-ward <b>facing</b> <b>location.</b> In addition, when an emergency call is made there is no guarantee that the handset is oriented in the traditional manner. The caller may, for instance, be prone on the ground, or trapped under debris, in which case the handset may be horizontally aligned, or even upside-down. It is therefore of interest to determine how the antenna orientation affects the reception of GPS signals...|$|R
40|$|A {{system for}} {{automatic}} human face detection and recognition is presented. The procedure consists of "ve steps: (1) the Haar wavelet transform, (2) facial edge detection, (3) symmetry axis detection, (4) face detection and (5) face recognition. Step 1 decomposes an input image, reducing image redundancy. Step 2 excludes non-facial areas using edge information, whereas Step 3 narrows down face areas further using gradient orientation. Step 4 restricts face-like areas by template matching. Finally, Step 5 determines the best <b>face</b> <b>location</b> in the face-like areas and identi"es the face based on {{principal component analysis}} (PCA). The system shows a remarkably robust performance under non-uniform lighting conditions...|$|E
40|$|Automatic face {{analysis}} has {{to cope with}} pose and lighting variations. Especially pose variations are dicult to tackle and many face analysis methods {{require the use of}} sophisticated normalization and initialization procedures. We propose a data-driven face analysis approach that is not only capable of extracting features relevant to a given face analysis task, but is also more robust with regard to <b>face</b> <b>location</b> changes and scale variations when compared to classical methods such as e. g. MLPs. Our approach is based on convolutional neural networks that use multi-scale feature extractors, which allow for improved facial expression recognition results with faces subject to in-plane pose variations...|$|E
40|$|Automatic face {{analysis}} has {{to cope with}} pose and lighting variations. Especially pose variations are difficult to tackle and many face analysis methods {{require the use of}} sophisticated normalization procedures. We propose a datadriven face analysis approach that is not only capable of extracting features relevant to a given face analysis task, but is also robust with regard to <b>face</b> <b>location</b> changes and scale variations. This is achieved by deploying convolutional neural networks. We show that the use of multiscale feature extractors and whole-field feature map summing neurons allow to improve facial expression recognition results, especially with test sets that feature scale, respectively, translation changes...|$|E
5000|$|... #Caption: View of a Memorial from Jersey City, New Jersey, that <b>faces</b> {{the former}} <b>location</b> of the Twin Towers ...|$|R
5000|$|... {{recognizing}} the important and dangerous role of game wardens who often work alone in desolate and remote <b>locations,</b> <b>facing</b> armed foes; ...|$|R
25|$|The {{passenger}} station {{was built in}} a classical style, as was usual for public buildings around 1840. The entrance and exit were through {{the front of the}} building, which <b>faced</b> the <b>location</b> of the modern Schweizergarten, the station being considerably closer to Südtiroler Platz then than it is now.|$|R
40|$|Abstract. This paper {{presents}} {{a simple and}} fast technique for geometrical feature detection of several human face organs such as eyes and mouth. Human face gravity-center template is firstly used for <b>face</b> <b>location,</b> from which position information of face organs such as eyebrows, eyes, nose and mouth are obtained. Then the original image is processed by extracting edges and the regions around the organs are scanned on the edge image to detect out 4 key points which determine {{the size of the}} organs. From these key points, eyes and mouth's shape are characterized by fitting curves. The results look well and the procedure is fast...|$|E
40|$|Abstract:- Automatic human <b>face</b> <b>location</b> {{system that}} uses two {{blinking}} eyes and one talking mouth {{to locate the}} only one human face embedded in Internet or video images is presented. The designed system is composed of two principal parts: The first part is to detect the potential face regions that are obtained from the criteria of "the {{combination of the two}} blinking eyes and one talking mouth". The second part of the proposed system is to perform the face verification task by using a support vector machine (SVM) classifier. The experimental results reveal that the proposed method is outstanding in terms of efficiency and accuracy...|$|E
30|$|The single feature cannot {{represent}} the image detail. Some papers use {{different types of}} feature to describe the image. In [10], the color feature and the shape feature are extracted and combined with a high dimensional feature to describe the object in the images, and a good retrieval results is obtained. In [11], the author extracts the color feature and the shape feature and combines a high-dimensional feature in traffic lights recognition; the recognition rate is 95 %. In [12], the color feature and the ellipse shape feature are used for <b>face</b> <b>location</b> and recognition. In addition, the texture feature and the color feature are also used for image content retrieval and have achieved great results [13 – 16].|$|E
40|$|In this paper, a {{real-time}} face {{detection system}} for color image sequences is presented. The system applies three different face detection methods and integrates the obtained results {{to achieve a}} greater location accuracy. The first method localizes the human head through outline analysis, focusing {{the attention of the}} system on a small image area. The second, a skin color method, is applied to the blobs to find skin regions (e. g., faces, hands, etc.). The third. principal component analysis, is used to reduce the dimensionality of the data set and to detect face patterns. Finally. the obtained <b>face</b> <b>locations</b> are fused to increase the detection reliability and to avoid false detections due to occlusions or unfavorable human poses. The proposed approach is used by a video-based surveillance system for monitoring indoor scenes...|$|R
40|$|In {{immersive}} communication applications, {{knowing the}} user’s viewing position can help improve {{the efficiency of}} multiview compression and streaming significantly, since often only {{a subset of the}} views are needed to synthesize the desired view(s). However, uncertainty regarding the viewer location can have negative impacts on the rendering quality. In this paper, we propose an algorithm to improve the robustness of view-dependent compression schemes by jointly performing user tracking and compression. A face tracker tracks the user’s head location and sends the probability distribution of the <b>face</b> <b>locations</b> as one or many particles. The server then applies motion model to the particles and compresses the multiview video accordingly in order to improve the expected rendering quality of the viewer. Experimental results show significantly improved robustness against tracking errors...|$|R
40|$|Three-dimensional face {{recognition}} is illumination invariant,howevertheacquisitionprocessitself isnot. Inactive 3 Drecognition,multipleimagesarecapturedwhilethe face is actively illuminated with different patterns. We propose a 3 D {{face recognition}} paradigm that bypasses reconstructionandexploitstheplethoraof informationavailable in multiple {{images of a}} person acquired while varying the illumination. Illuminationis varied by scanningahorizontal and then a vertical white stripe {{on the computer screen}} in front of the subject. Subtractingambientlight leavesimages illuminated by the screen from different angles. The contourletcoefficientsoftheimagesarecalculatedatdifferent scales andorientationsand then projectedto PCA subspacetoremoveredundancy. Thesubspacecontourletcoefficientsofmultipleimagesarestackedtoformaglobalface representation. Sliding windows are used during matching to remove the disparity between the <b>face</b> <b>locations</b> with respect to the screen. The proposedalgorithm was tested under varying ambient conditions and compared to a known 3 D face recognition technique. Verification results on data from the same subjects show the strength of our algorithm. 1...|$|R
