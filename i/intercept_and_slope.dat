308|10000|Public
25|$|More generally, Shapiro–Wilk test {{uses the}} {{expected}} {{values of the}} order statistics of the given distribution; the resulting plot and line yields the generalized least squares estimate for location and scale (from the <b>intercept</b> <b>and</b> <b>slope</b> of the fitted line).|$|E
2500|$|A {{prediction}} interval instead gives an interval {{in which one}} expects y'd to fall; this is not necessary if the actual parameters α and β are known (together with the error term εi), but if one is estimating from a sample, then one may use the standard error of the estimates for the <b>intercept</b> <b>and</b> <b>slope</b> ( [...] and [...] ), {{as well as their}} correlation, to compute a {{prediction interval}}.|$|E
2500|$|The <b>intercept</b> <b>and</b> <b>slope</b> of {{a linear}} {{regression}} between the quantiles gives {{a measure of}} the relative location and relative scale of the samples. If the median of the distribution plotted on the horizontal axis is 0, the intercept of a regression line is a measure of location, and the slope is a measure of scale. The distance between medians is another measure of relative location reflected in a Q–Q plot. [...] The [...] "probability plot correlation coefficient" [...] is the correlation coefficient between the paired sample quantiles. [...] The closer the correlation coefficient is to one, the closer the distributions are to being shifted, scaled versions of each other. [...] For distributions with a single shape parameter, the probability plot correlation coefficient plot (PPCC plot) provides a method for estimating the shape parameter – one simply computes the correlation coefficient for different values of the shape parameter, and uses the one with the best fit, just as if one were comparing distributions of different types.|$|E
50|$|A {{model that}} {{includes}} both random <b>intercepts</b> <b>and</b> random <b>slopes</b> is likely the most realistic type of model, {{although it is}} also the most complex. In this model, both <b>intercepts</b> <b>and</b> <b>slopes</b> are allowed to vary across groups, meaning that they are different in different contexts.|$|R
3000|$|For {{analysing}} how growth {{response to}} drought {{depends on the}} size of a tree in a stand (Q 2) we first fitted the annual iv-v relationships by OLS regression which yielded the annual <b>intercept</b> a <b>and</b> <b>slope</b> b for all considered groups (see section ‘Quantifying the relationship between tree growth, iv, and tree volume, v <b>and</b> <b>intercepts</b> <b>and</b> <b>slopes</b> presented in Additional file 1 : Tables S 1 –S 6). Then the <b>intercepts</b> <b>and</b> <b>slopes</b> of the annual iv-v relationships at the individual tree level were set in relation to the Martonne index, Mgs. For this purpose we applied the two different OLS regression models: [...]...|$|R
40|$|In this paper, a Bayesian {{hierarchical}} model {{is used to}} anaylze the female breast cancer mortality rates for the State of Missouri from 1969 through 2001. The logit transformations of the mortality rates {{are assumed to be}} linear over the time with additive spatial and age effects as <b>intercepts</b> <b>and</b> <b>slopes.</b> Objective priors of the {{hierarchical model}} are explored. The Bayesian estimates are quite robustness in terms change of the hyperparamaters. The spatial correlations are appeared in both <b>intercepts</b> <b>and</b> <b>slopes...</b>|$|R
50|$|Better {{suited for}} {{extended}} models {{in which the}} model is embedded into a larger path model, or the <b>intercept</b> <b>and</b> <b>slope</b> are used as predictors for other variables. In this way, SEM allows greater flexibility.|$|E
50|$|More generally, Shapiro-Wilk test {{uses the}} {{expected}} {{values of the}} order statistics of the given distribution; the resulting plot and line yields the generalized least squares estimate for location and scale (from the <b>intercept</b> <b>and</b> <b>slope</b> of the fitted line).Although this is not too important for the normal distribution (the location and scale are estimated by the mean and standard deviation, respectively), it can be useful for many other distributions.|$|E
5000|$|A {{prediction}} interval instead gives an interval {{in which one}} expects yd to fall; this is not necessary if the actual parameters α and β are known (together with the error term εi), but if one is estimating from a sample, then one may use the standard error of the estimates for the <b>intercept</b> <b>and</b> <b>slope</b> ( [...] and [...] ), {{as well as their}} correlation, to compute a {{prediction interval}}.|$|E
30|$|Yearly eGFR {{assessment}} {{will allow}} {{to describe the}} evolution of GFR over time and the evaluation of factors associated with eGFR decline. This analysis will be performed using mixed models with random <b>intercepts</b> <b>and</b> <b>slopes.</b>|$|R
40|$|This web-based {{technical}} appendix provides {{additional information}} on the data and estimation techniques used in the above-referenced paper. It also reports the full set of quality index <b>intercepts</b> <b>and</b> <b>slopes</b> discussed in the paper in tabular form, {{as well as their}} standard errors, by country and industry...|$|R
40|$|This paper surveys recent {{developments}} and provides Monte Carlo comparison on various tests proposed for cointegration in panel data. In particular, tests for two panel models, varying <b>intercepts</b> <b>and</b> varying <b>slopes</b> <b>and</b> varying <b>intercepts</b> <b>and</b> common <b>slopes,</b> are presented {{from the literature}} {{with a total of}} five tests being simulated. In all cases, results on empirical size and size-adjusted power are given. Panel Cointegration...|$|R
50|$|In {{multilevel}} modeling, {{an overall}} change function (e.g. linear, quadratic, cubic etc.) is fitted {{to the whole}} sample and, just as in multilevel modeling for clustered data, the slope and intercept may be allowed to vary. For example, in a study looking at income growth with age, individuals might be assumed to show linear improvement over time. However, the exact <b>intercept</b> <b>and</b> <b>slope</b> could be allowed to vary across individuals (i.e. defined as random coefficients).|$|E
50|$|Another way {{to analyze}} {{hierarchical}} data would be through a random-coefficients model. This model assumes that each group {{has a different}} regression model—with its own <b>intercept</b> <b>and</b> <b>slope.</b> Because groups are sampled, the model assumes that the intercepts and slopes are also randomly sampled from a population of group intercepts and slopes. This allows for an analysis in which one can assume that slopes are fixed but intercepts are allowed to vary. However this presents a problem, as individual components are independent but group components are independent between groups, but dependent within groups. This also allows for an analysis in which the slopes are random; however, the correlations of the error terms (disturbances) are dependent on {{the values of the}} individual-level variables. Thus, the problem with using a random-coefficients model in order to analyze hierarchical data is that is still not possible to incorporate higher order variables.|$|E
5000|$|The <b>intercept</b> <b>and</b> <b>slope</b> of {{a linear}} {{regression}} between the quantiles gives {{a measure of}} the relative location and relative scale of the samples. If the median of the distribution plotted on the horizontal axis is 0, the intercept of a regression line is a measure of location, and the slope is a measure of scale. The distance between medians is another measure of relative location reflected in a Q-Q plot. The [...] "probability plot correlation coefficient" [...] is the correlation coefficient between the paired sample quantiles. The closer the correlation coefficient is to one, the closer the distributions are to being shifted, scaled versions of each other. For distributions with a single shape parameter, the probability plot correlation coefficient plot (PPCC plot) provides a method for estimating the shape parameter - one simply computes the correlation coefficient for different values of the shape parameter, and uses the one with the best fit, just as if one were comparing distributions of different types.|$|E
30|$|These prior {{specifications}} are not fixed; {{they can}} be adjusted to specific forecast situations. For example, if a forecaster expected only positive survival improvements, she or he could set the uniformly distributed priors for the overall means of the <b>intercepts</b> <b>and</b> <b>slopes</b> {{to a range of}} nonnegative values (for more information please see additional notes in the “Model and prior specification” section).|$|R
40|$|We {{present a}} method for using <b>slopes</b> <b>and</b> <b>intercepts</b> from a linear {{regression}} of a quantitative trait as outcomes in segregation and linkage analyses. We apply the method {{to the analysis of}} longitudinal systolic blood pressure (SBP) data from the Framingham Heart Study. A first-stage linear model was fit to each subject's SBP measurements to estimate both their <b>slope</b> over time <b>and</b> an <b>intercept,</b> the latter scaled to represent the mean SBP at the average observed age (53. 7 years). The subject-specific <b>intercepts</b> <b>and</b> <b>slopes</b> were then analyzed using segregation and linkage analysis. We describe {{a method for}} using the standard errors of the first-stage <b>intercepts</b> <b>and</b> <b>slopes</b> as weights in the genetic analyses. For the intercepts, we found significant evidence of a Mendelian gene in segregation analysis and suggestive linkage results (with LOD scores ≥ 1. 5) for specific markers on chromosomes 1, 3, 5, 9, 10, and 17. For the slopes, however, the data did not support a Mendelian model, and thus no formal linkage analyses were conducted...|$|R
50|$|The {{dependent}} variables are the <b>intercepts</b> <b>and</b> the <b>slopes</b> for the in{{dependent variables}} at Level 1 in the groups of Level 2.|$|R
5000|$|W. E. Hick (1952) {{devised a}} CRT {{experiment}} which presented {{a series of}} nine tests {{in which there are}} n equally possible choices. The experiment measured the subject's reaction time based on number of possible choices during any given trial. Hick showed that the individual's reaction time increased by a constant amount as a function of available choices, or the [...] "uncertainty" [...] involved in which reaction stimulus would appear next. Uncertainty is measured in [...] "bits", which are defined as the quantity of information that reduces uncertainty by half in information theory. In Hick's experiment, the reaction time is found to be a function of the binary logarithm of the number of available choices (n). This phenomenon is called [...] "Hick's Law" [...] and {{is said to be a}} measure of the [...] "rate of gain of information." [...] The law is usually expressed by the formula , where [...] and [...] are constants representing the <b>intercept</b> <b>and</b> <b>slope</b> of the function, and [...] is the number of alternatives. [...] The Jensen Box is a more recent application of Hick's Law. Hick's Law has interesting modern applications in marketing, where restaurant menus and web interfaces (among other things) take advantage of its principles in striving to achieve speed and ease of use for the consumer.|$|E
5000|$|... 2) Hannum et al. (2013) [...] report several age estimators: one {{for each}} tissue type. Each of these estimators {{requires}} covariate information (e.g. gender, body mass index, batch). The authors mention that each tissue led to a clear linear offset (<b>intercept</b> <b>and</b> <b>slope).</b> Therefore, the authors had to adjust the blood-based age estimator for each tissue type using a linear model. When the Hannum estimator is applied to other tissues, it leads to a high error (due to poor calibration) {{as can be seen}} from Figure 4A in Hannum et al. (2013). Hannum et al. adjusted their blood-based age estimator (by adjusting the slope and the intercept term) in order to apply it to other tissue types. Since this adjustment step removes differences between tissue, the blood-based estimator from Hannum et al. cannot be used to compare the ages of different tissues/organs. In contrast, a salient characteristic of the epigenetic clock is that one does not have to carry out such a calibration step: it always uses the same CpGs and the same coefficient values. Therefore, Horvath's epigenetic clock can be used to compare the ages of different tissues/cells/organs from the same individual. While the age estimators from Hannum et al. cannot be used to compare the ages of different normal tissues, they can be used to compare the age of a cancerous tissue with that of a corresponding normal (non-cancerous) tissue. Hannum et al. reported pronounced age acceleration effects in all cancers. In contrast, Horvath's epigenetic clock [...] reveals that some cancer types (e.g. triple negative breast cancers or uterine corpus endometrial carcinoma) exhibit negative age acceleration, i.e. cancer tissue can be much younger than expected.An important difference relates to additional covariates. Hannum's age estimators make use of covariates such as gender, body mass index, diabetes status, ethnicity, and batch. Since new data involve different batches, one cannot apply it directly to new data. However, the authors present coefficient values for their CpGs in Supplementary Tables which can be used to define an aggregate measure that tends to be strongly correlated with chronological age but may be poorly calibrated (i.e. lead to high errors).|$|E
40|$|The authors analyze {{a control}} problem with data {{generated}} by the linear regression model where <b>intercept</b> <b>and</b> <b>slope</b> coefficients are unknown. They propose a certainty equivalence control rule based on Bayes estimates of the <b>intercept</b> <b>and</b> <b>slope</b> coefficients. It is shown that the control rule converges to the optimal control rule, which requires complete knowledge of <b>intercept</b> <b>and</b> <b>slope</b> coefficients. Furthermore, under the proposed control rule, if the total control cost tends to infinity, they show that the Bayes estimates for slope and intercept are consistent...|$|E
30|$|The second-order rate {{constant}} k 2 and qe are {{obtained from the}} <b>intercept</b> <b>and</b> the <b>slope</b> of the plot obtained by plotting t/q against time t.|$|R
40|$|International audienceWe examine empirically {{returns to}} {{seniority}} in France and estimate cohort effects in both firm specific compensation policies {{and returns to}} job seniority. We demonstrate the biases in several estimators of returns to seniority and show that allowing firm specific compensation policies and returns to seniority to vary by entry cohort uncovers patterns of variance within firm and within cohort in estimated <b>intercepts</b> <b>and</b> <b>slopes</b> that {{can be explained by}} no single theory...|$|R
30|$|A linear {{regression}} with by-subject and by-disease crossed random {{effects on the}} <b>intercept</b> <b>and</b> the <b>slope</b> of the prevalence estimates was also significant (b[*]=[*]. 047, SE[*]=[*]. 017, p[*]=[*]. 008).|$|R
30|$|Accordingly, the {{constants}} (C) and (K id) {{were interpreted}} from <b>intercept</b> <b>and</b> <b>slope</b> {{of the respective}} plot.|$|E
3000|$|F and 1 /n were {{calculated}} from the <b>intercept</b> <b>and</b> <b>slope</b> of the plots, respectively. The Langmuir constants a [...]...|$|E
30|$|The {{linearity}} of {{the method}} was evaluated at different concentrations. Linear correlation coefficient, <b>intercept,</b> <b>and</b> <b>slope</b> values were calculated for statistical analysis.|$|E
50|$|At Level 1, {{both the}} <b>intercepts</b> <b>and</b> <b>slopes</b> in the groups {{can be either}} fixed (meaning that all groups have the same values, {{although}} {{in the real world}} this would be a rare occurrence), non-randomly varying (meaning that the intercepts and/or slopes are predictable from an independent variable at Level 2), or randomly varying (meaning that the intercepts and/or slopes are different in the different groups, and that each have their own overall mean and variance).|$|R
30|$|In general, {{with small}} <b>intercepts</b> <b>and</b> <b>slopes</b> which {{are close to}} one, in all cases, {{there is a good}} match between model output and the {{original}} data. Pearson r coefficients in all cases above 0.85 indicate a very good representation. The scatter is {{a small fraction of the}} maximal perturbations observed at each station. All of these results are consistent with the closeness of the model and data traces in Fig.  6. Certain aspects of the modeling at each station bear further discussion, however.|$|R
40|$|WP 02 / 03 Clave pdf) The {{common factor}} model assumes a linear {{relation}} between the observed variables {{and a set of}} underlying latent traits. It also assumes that the linear coefficients, <b>intercepts</b> <b>and</b> <b>slopes</b> (factor loadings), linking the observed variables to the latent traits are fixed coefficients (i. e., common for all subjects). We partially relax the fixed coefficients assumption by letting the intercepts in the factor model change across subjects while keeping the factor loadings fixed. Difficulty factors, Life Orientation Test, LISREL, Random effects, Structural equation modeling...|$|R
3000|$|... and n are the Freundlich {{constants}} and can {{be calculated}} from the <b>intercept</b> <b>and</b> <b>slope,</b> respectively, of the linear plot of logq [...]...|$|E
3000|$|... {{deriving}} a bestline, {{which is}} a line with the highest <b>intercept</b> <b>and</b> <b>slope</b> such that all measured values are above the line [10, 26].|$|E
30|$|Extrapolation of {{the plot}} between t/qt and t calculates the value of K 2 and qe as <b>intercept</b> <b>and</b> <b>slope</b> of the curve, respectively.|$|E
40|$|We {{consider}} {{a framework for}} analyzing panel data characterized by: (i) a system of regressions equations, (ii) random individual heterogeneity in both <b>intercepts</b> <b>and</b> <b>slope</b> coefficients, <b>and</b> (iii) unbalanced panel data, i. e., panel data where the individual time series have unequal length. A Maximum Likelihood (ML) procedure for joint estimation of all parameters is described. Since it is complicated to implement in numerical calculations, we consider simplified procedures, in particular for estimating the covariance matrices of the random coefficients. An algorithm for modified ML estimation of all parameters is presented...|$|R
30|$|The {{correlation}} coefficient between the 3 D DIC measurements and the LVDT measurements showed an excellent linear agreement in all specimens (R 2 [*]=[*] 0.99). The mean <b>intercept</b> <b>and</b> the <b>slope</b> of the linear correlation were 0.000 and 0.982 respectively.|$|R
3000|$|... [...]) {{as well as}} the {{correlation}} between these <b>intercepts</b> <b>and</b> the <b>slopes</b> (τ 01) would therefore differ as well. As a researcher interprets and attempts to explore the scope of these effects, their conditional nature should be considered and emphasized accordingly.|$|R
