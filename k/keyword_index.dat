80|253|Public
2500|$|... {{some sort}} of <b>keyword</b> <b>index</b> for [...]" [...] In early May, Mr. Martelli posted a summary of his {{responses}} to Usenet, noting that the [...] "most popular suggestion award must definitely go to 'lq-text' package, by Liam Quin, recently posted in alt.sources." ...|$|E
2500|$|The Bibliography of Music Literature (...) , {{also known}} as BMS or , is an {{international}} bibliography of literature on music. It considers all kind of music and includes both current and older literature. Since 1968, the BMS editorial [...] staff has been working as the German committee for RILM, too. The bibliography includes monographs, master’s theses and doctoral dissertations, articles and reviews from journals, Festschriften, conference proceedings, yearbooks, anthologies, and essays from critical reports. It contains printed media as well as online resources, data media, sound recordings, audiovisual media, and microforms. Each record provides the title in the original language (for East European- and Asian entries a German translation is added), full bibliographic data, a <b>keyword</b> <b>index,</b> and mostly an abstract.|$|E
50|$|The site {{includes}} a <b>keyword</b> <b>index</b> and a glossary, {{with links to}} full text versions of Decisions, Directives, Regulations and Commission documents, and to other relevant sites.|$|E
5000|$|The Internet DatabaseSo far it {{contains}} more than 4500 selected Africa-related Internet links. Built up by the ilissAfrica staff this pool of websites is searchable as the sites are classified, categorised, <b>keyword</b> <b>indexed</b> and provided with an abstract.|$|R
50|$|Searchable Encryption is a {{cryptographic}} primitive {{which offers}} secure search functions over encrypted data. In {{order to improve}} search efficiency, SE generally builds <b>keyword</b> <b>indexes</b> to securely perform user queries. SE schemes can be classified into two categories: SE based on secret-key cryptography and SE based on public-key cryptography.|$|R
40|$|Gaudry {{present a}} {{variation}} of index calculus attack for solving the DLP in the Jacobian of hyperelliptic curves. Harley and Thérialut improve these kind of algorithm. Here, we will present {{a variation of}} these kind of algorithm, which is faster than previous ones. <b>Keywords</b> <b>Index</b> calculus attack, Jacobian, Hyperelliptic curve, DLP,...|$|R
5000|$|An online Index to The Fibonacci Quarterly {{covering}} Volumes 1-48 (1963-2010) {{includes a}} Title Index, Author Index, Elementary Problem Index, Advanced Problem Index, Miscellaneous Problem Index, and Quick Reference <b>Keyword</b> <b>Index.</b> The Fibonacci Quarterly is available online to subscribers; on June 29, 2010, online volumes {{ranged from the}} current issue back to volume 41 (2003).|$|E
5000|$|A Microsoft Help 2.x file has a [...] ".hxs" [...] extension. A {{compressed}} [...]HxS help file (help title) is {{compiled from}} {{a set of}} topic pages written in a subset of HTML, a [...]HxC main project file, an [...]HxF include file, a [...]HxT table of contents, a [...]HxA attribute definition file, {{and a number of}} [...]HxK indexes (<b>keyword</b> <b>Index,</b> NamedURL index, optional associated and context links indexes).|$|E
5000|$|The {{desire to}} have a fulltext search index of {{archived}} news articles is not new either, one such request having been made in April 1991 by Alex Martelli who sought to [...] "buildsome sort of <b>keyword</b> <b>index</b> for news archive." [...] In early May, Mr. Martelli posted a summary of his responses to Usenet, noting that the [...] "most popular suggestion award must definitely go to 'lq-text' package, by Liam Quin, recently posted in alt.sources." ...|$|E
40|$|In {{many areas}} of commerce, government, academia, and hospitals, large {{collections}} of digital im-ages are being created. Many of these collections {{are the product of}} digitizing existing collections of analogue photographs, diagrams, drawings, paintings, and prints. Usually, the only way of search-ing these collections was by <b>keyword</b> <b>indexing,</b> or simply by browsing. Digital images database...|$|R
40|$|Despite {{the success}} of general Internet search engines, {{information}} retrieval remains an incompletely solved problem. Our research focuses on supporting domain experts when they search domain-specific libraries to satisfy targeted information needs. The semantic components model introduces a schema specific to a particular document collection. A semantic component schema consists of a two-level hierarchy, document classes and semantic components. A document class represents a document grouping, such as topic type or document purpose. A semantic component is a characteristic type of information that occurs in a particular document class and represents {{an important aspect of}} the document’s main topic. Semantic component indexing identifies the location and extent of semantic component instances within a document and can supplement traditional full text and <b>keyword</b> <b>indexing</b> techniques. Semantic component searching allows a user to refine a topical search by indicating a preference for documents containing specific semantic components or by indicating terms that should appear in specific semantic components. We investigate four aspects of semantic components in this research. First, we describe lessons learned from using two methods for developing schemas in two domains. Second, we demonstrate use of semantic components to express domainspecific concepts and relationships by mapping a published taxonomy of questions asked by family practice physicians to the semantic component schemas for two document collections about medical care. Third, we report the results of a user study, showing that manual semantic component indexing is comparable to manual <b>keyword</b> <b>indexing</b> with respect to time and perceived difficulty and suggesting that semantic component indexing may be more accurate and consistent than manual <b>keyword</b> <b>indexing.</b> Fourth, we report the results of an interactive searching study, demonstrating the ability of semantic components to enhance search results compared to a baseline system without semantic components. In addition, we contribute a formal description of the semantic components model, a prototype implementation of semantic component indexing software, and a prototype implementation adding semantic components to an existing commercial search engine. Finally, we analyze metrics for evaluating instances of semantic component <b>indexing</b> and <b>keyword</b> <b>indexing</b> and illustrate use of a session-based metric for evaluating multiple-query search sessions...|$|R
40|$|<b>Keyword</b> <b>indices,</b> topic directories, and link-based rankings {{are used}} to search and {{structure}} the rapidly growing Web today. Surprisingly little use is made of years of browsing experience of millions of people. Indeed, this information is routinely discarded by browsers. Even deliberate bookmarks are stored in a passive and isolated manner. All this goes against Vannevar Bush's dream of the Memex : an enhanced supplement to personal and community memory...|$|R
5000|$|The book {{arranges}} its entries by author, {{rather than}} by subject, as many other quotation collections, and enters the authors chronologically by date of birth rather than alphabetically. Within years, authors are arranged alphabetically and quotations are arranged chronologically within each author's entry, followed by [...] "attributed" [...] remarks whose source in the author's writings has not been confirmed. The book contains a thorough <b>keyword</b> <b>index</b> and details the source of each quotation.|$|E
5000|$|Indices: Allows {{creating}} of {{a simple}} <b>keyword</b> <b>index</b> or a somewhat more detailed index of {{the information in the}} text using embedded indexing codes. Unlike more sophisticated programs, InDesign is incapable of inserting character style information as part of an index entry (e.g., when indexing book, journal or movie titles). Indices are limited to four levels (top level and three sub-levels). Like tables of contents, indices can be sorted according to the selected language.|$|E
50|$|Throughout the Career Cruising {{there are}} {{hundreds}} of occupations with profiles. These profiles include interviews with people within the career, salary information, job outlook, and locations. In the employee interviews, located in the profiles of each career, they ask key questions including about their typical workday, pros and cons, and advise for students interested in pursuing that career. There are a couple ways to search for careers, including by <b>keyword,</b> <b>index,</b> school, subjects, career cluster, or career selector given to you after using Career Matchmaker.|$|E
40|$|A {{content-based}} image {{retrieval mechanism}} to support complex similarity queries is presented. The image content {{is defined by}} three kinds of features: quantifiable features describing the visual information, non-quantifiable features describing the semantic information, and keywords describing more abstract semantic information. In correspondence with these feature sets, we construct three types of indexes: visual indexes, semantic <b>indexes,</b> and <b>keyword</b> <b>indexes.</b> Index structures are elaborated to provide effective and efficient retrieval of images based on their contents. The underlying index structure used for all indexes is the HG-tree [1]. In addition to the HG-tree, the signature file and hashing technique are also employed to <b>index</b> <b>keywords</b> and semantic features. The proposed indexing scheme combines and extends the HG-tree, the signature file and the hashing scheme to support complex similarity queries. We also propose a new evaluation strategy to process the complex similarity queries. Experiments {{have been carried out}} on large image collections to demonstrate the effectiveness of the proposed retrieval mechanism...|$|R
40|$|The {{storage method}} for XML data in {{database}} {{will affect the}} efficiency of XML <b>keywords</b> querying, <b>indexing</b> and updating significantly. In most cases, the XPath sentences provided by user are not refined. These queries can often achieve minimization by deleting redundant parts. It means the minimized query is one of subsets of this query. Such kind of minimization query is method based on deleting queries. The steps are determining nodes relations, finding redundant nodes, deleting redundant nodes and sub-tree and obtain final minimization query tree. In this paper, we propose an improved XPath query minimization method based on deletion using simulation concept. Experiments analysis results show that with introduction of appropriate indexing and new algorithm, the XML <b>keywords</b> <b>indexing</b> efficiency can be significantly improved...|$|R
3000|$|TrapGen([...] w, ik [...]). This {{algorithm}} takes a <b>keyword</b> w and <b>index</b> generation key ik. It encrypts the <b>keyword</b> w with <b>index</b> generation key ik {{and returns}} the encryption value, {{which is the}} trapdoor T [...]...|$|R
50|$|Central to RILM’s {{work and}} mission is the {{international}} bibliography of scholarship relating to all facets of music. RILM covers significant scholarship in both printed and digital media, and in any language. It consists of citations of articles, books, bibliographies, catalogues, master’s theses and doctoral dissertations, Festschriften, films, videos, technical drawings of instruments, facsimile editions, iconographies, commentaries included with critical editions of music, ethnographic recordings, conference proceedings, and reviews. Each entry provides the title in the original language, an English translation of the title, full bibliographic data, and an abstract with a <b>keyword</b> <b>index.</b> Many of the non-English entries also include an abstract {{in the language of}} the publication. RILM is currently growing at the rate of over 50,000 listings each year.|$|E
5000|$|The Yale Book of Quotations is a {{quotations}} {{collection that}} focuses on modern and American quotations and claims {{a high level of}} scholarship and reliability. Edited by Fred R. Shapiro, it was published by Yale University Press in 2006 with a foreword by Joseph Epstein, [...] Prior to publication it was referred to by its working title, The Yale Dictionary of Quotations. The book presents over 12,000 quotations on 1067 pages. It is arranged alphabetically by author (or, for some quotations, by quotation type), with some information as to the source of each quotation and, where the editor deems this relevant, cross-references to other quotations. A <b>keyword</b> <b>index</b> allows the reader to generally find quotations by significant words in the quotations.|$|E
50|$|HelpNDoc {{allows the}} writer {{to create a}} single source text which it then {{converts}} {{to a number of}} target formats such as HTML Help, PDF, RTF, DocX, Qt Help, and HTML documentations as well as EPUB and Amazon Kindle compatible E-books. HelpNDoc integrates a WYSIWYG editor which aims to look like popular word processing software such as Microsoft Word or OpenOffice.org Writer. HelpNDoc has the ability to include variables and external files. It also has the ability to generate code for the C++, Delphi, Fortran, Pascal and Visual Basic programming languages for integration of the generated CHM help files with the application being developed. As of version 4 HelpNDoc comes with a project analyzer that can track the document’s layout, provide statistics and identify potential problems such as broken links or problems with media items. HelpNDoc {{can also be used to}} publish mobile websites, using the table of contents as a navigation menu, the content of the topics with navigation buttons, the <b>keyword</b> <b>index</b> menu, a built-in search engine, and mobile-specific user interface elements.|$|E
30|$|The <b>keywords</b> <b>index</b> {{found in}} the {{portfolio}} was also analyzed. The highlight is the keyword activity-based costing the search root word, followed by health services, economics, hotels. This may imply that the ABC method is used in service organizations {{with the intention of}} reducing costs and improving productivity. For articles on health, there is a reservation: they focus their application of the ABC method in restricted areas or department of a health organization.|$|R
40|$|Abstract: The {{transfer}} of knowledge between groups of individuals of different levels of expertise and orientation is discussed {{with reference to the}} manner in which knowledge is disseminated using the specialist language of a given domain. A prototype system that allows access to knowledge at these different levels, through the automatic construction of <b>keyword</b> <b>indexes,</b> is outlined. The controversial relationship between knowledge and language is the basis of arguments in this paper...|$|R
40|$|In this work, {{we present}} a {{literature}} review for full-text and <b>keyword</b> <b>indexes</b> {{as well as our}} contributions (which are mostly practice-oriented). The first contribution is the FM-bloated index, which is a modification of the well-known FM-index (a compressed, full-text index) that trades space for speed. In our approach, the count table and the occurrence lists store information about selected q-grams in addition to the individual characters. Two variants are described, namely one using O(n ^ 2 n) bits of space with O(m + m n) average query time, and one with linear space and O(m n) average query time, where n is the input text length and m is the pattern length. We experimentally show that a significant speedup can be achieved by operating on q-grams (albeit at the cost of very high space requirements, hence the name "bloated"). In the category of <b>keyword</b> <b>indexes</b> we present the so-called split index, which can efficiently solve the k-mismatches problem, especially for 1 error. Our implementation in the C++ language is focused mostly on data compaction, which is beneficial for the search speed (by being cache friendly). We compare our solution with other algorithms and we show that it is faster when the Hamming distance is used. Query times in the order of 1 microsecond were reported for one mismatch for a few-megabyte natural language dictionary on a medium-end PC. A minor contribution includes string sketches which aim to speed up approximate string comparison at the cost of additional space (O(1) per string). They can be used in the context of <b>keyword</b> <b>indexes</b> in order to deduce that two strings differ by at least k mismatches with the use of fast bitwise operations rather than an explicit verification. Comment: Master's thesis, 107 page...|$|R
50|$|The Bibliography of Music Literature (Bibliographie des Musikschrifttums), {{also known}} as BMS or BMS online, is an {{international}} bibliography of literature on music. It considers all kind of music and includes both current and older literature. Since 1968, the BMS editorial staff has been working as the German committee for RILM, too. The bibliography includes monographs, master’s theses and doctoral dissertations, articles and reviews from journals, Festschriften, conference proceedings, yearbooks, anthologies, and essays from critical reports. It contains printed media as well as online resources, data media, sound recordings, audiovisual media, and microforms. Each record provides the title in the original language (for East European- and Asian entries a German translation is added), full bibliographic data, a <b>keyword</b> <b>index,</b> and mostly an abstract. Currently, BMS online has more than 315,000 records of literature on music. It is supplemented by the OLC-SSG Musicology, which incorporates the contents of some more 150 music journals from 1993 onward. BMS online participates actively on ViFaMusik, the central gateway for music and musicology in Germany.|$|E
30|$|In DB encryption, {{previous}} {{researchers have}} conducted the <b>keyword</b> <b>index</b> search over encrypted documents with various scenarios; however, the <b>keyword</b> <b>index</b> search scheme is inefficient and impractical aspects {{in a real}} world. The <b>keyword</b> <b>index</b> search enables a legitimate queries to search the encrypted documents with an encrypted keyword over the encrypted indexes without revealing any information on the query and documents, even to the server.|$|E
30|$|We made {{definitions}} {{on group}} search secrecy and <b>keyword</b> <b>index</b> search privacy and analyzed them.|$|E
40|$|In {{many areas}} of commerce, government, academia, and hospitals, large {{collections}} of digital im- ages are being created. Many of these collections {{are the product of}} digitizing existing collections of analogue photographs, diagrams, drawings, paintings, and prints. Usually, the only way of search- ing these collections was by <b>keyword</b> <b>indexing,</b> or simply by browsing. Digital images databases however, open the way to content-based searching. In this paper we survey some technical aspects of current content-based image retrieval systems...|$|R
5000|$|... eXist allows {{software}} developers to persist XML/JSON/Binary documents without writing extensive middleware. eXist follows and extends many W3C XML standards such as XQuery. eXist also supports REST interfaces for interfacing with AJAX-type web forms. Applications such as XForms may save their data by using {{just a few}} lines of code. The WebDAV interface to eXist allows users to [...] "drag and drop" [...] XML files directly into the eXist database. eXist automatically indexes documents using a <b>keyword</b> <b>indexing</b> system.|$|R
40|$|This paper {{exemplifies the}} {{implementation}} of an efficient Information Retrieval (IR) System to compute the similarity between a dataset and a query using Fuzzy Logic. TREC (Text Retrieval Conference) dataset {{has been used for}} the implementation purpose. The dataset is parsed to generate <b>keywords</b> <b>index</b> which is used for the similarity comparison with the user query. Each query is assigned a score value based on its fuzzy similarity with the <b>index</b> <b>keywords.</b> The relevant documents are retrieved based on the score value. The performance and accuracy of the proposed fuzzy similarity model is compared with Cosine similarity model using Precision-Recall curves. The results prove the dominance of Fuzzy Similarity based IR system...|$|R
30|$|Unlinkability {{means that}} when {{resources}} and services are used by someone, the others cannot link these being correlated or used together. In <b>keyword</b> <b>index</b> search system, it {{can be regarded as}} index indistinguishability.|$|E
30|$|Our schemes are in {{the line}} of the <b>keyword</b> <b>index</b> search area, and this paper focuses on more {{practical}} approaches over the encrypted database to resolve the problems--the efficiency and group search of the encrypted database in the cloud datacenter service.|$|E
40|$|Abstract. Combining {{evidence}} of relevance coming from two sources — a <b>keyword</b> <b>index</b> and a keyphrase index — {{has been a}} fundamental part of our INEX-related experiments on XML Retrieval over the past years. In 2008, we focused on {{improving the quality of}} the keyphrase index and finding better ways to use it together with the <b>keyword</b> <b>index</b> even when processing non-phrase queries. We also updated our implementation of the word index which now uses a state-of-the-art scoring function for estimating the relevance of XML elements. Compared to the results from previous years, the improvements turned out to be successful in the INEX 2008 ad hoc track evaluation of the focused retrieval task. ...|$|E
3000|$|Retrieve. The data {{retrieval}} algorithm {{is run by}} CSC. Taken as input the system global parameter GP, the <b>keyword</b> secure <b>index</b> I [...]...|$|R
40|$|EMBL and GenBank <b>keyword</b> <b>indexes</b> have no {{hierarchical}} structure. In {{this paper}} {{we present a}} method for merging and reorganizing them in a tree structure whose primary roots are the keywords 'protein', 'DNA', 'RNA', and 'unclassified'. Synonymous keywords have been grouped together and erroneous keywords have been corrected. This taxonomic organization of keywords results in a more extensive and efficient retrieval which is further aided by "synonyms declaration". The tree has been produced using the computer programs GENPOINT and CREANET...|$|R
5000|$|Text {{articles}} {{are displayed in}} a flat, rather than tree-based, listing. Stored {{articles are}} retrieved using a scheme based on user-defined keywords. This type of keyword-based system {{was based on the}} keyword systems used by common research databases of the 1990s, such as Knowledge Index and CompuServe's file library, and is similar to the <b>keywords</b> <b>Index</b> for a MS Help file. In recent Internet usage, such keywords are now often referred to as metadata [...] "tags". Articles are filtered using various criteria, including keywords, dates, and attachments.|$|R
