2324|1465|Public
25|$|Smaller mobile {{devices such}} as {{personal}} digital assistants (PDAs) and smartphones typically use the WIMP elements with different unifying metaphors, due to constraints in space and available input devices. Applications for which WIMP is not well suited may use newer <b>interaction</b> <b>techniques,</b> collectively termed post-WIMP user interfaces.|$|E
25|$|Information {{visualization}} {{focused on}} the creation of approaches for conveying abstract information in intuitive ways. Visual representations and <b>interaction</b> <b>techniques</b> take advantage of the human eye’s broad bandwidth pathway into the mind to allow users to see, explore, and understand large amounts of information at once. The key difference between scientific visualization and information visualization is that information visualization is often applied to data that is not generated by scientific inquiry. Some examples are graphical representations of data for business, government, news and social media.|$|E
500|$|Almost all input {{is given}} through the touch screen, which understands complex {{gestures}} using multi-touch. The iPad's <b>interaction</b> <b>techniques</b> enable {{the user to}} move the content up or down by a touch-drag motion of the finger. For example, zooming {{in and out of}} web pages and photos is done by placing two fingers on the screen and spreading them farther apart or bringing them closer together, a gesture known as [...] "pinching".|$|E
5000|$|From the computer's perspective, an <b>interaction</b> <b>technique</b> involves: ...|$|R
50|$|In general, {{the less}} {{compatible}} {{the device is}} with the domain object, the more complex the <b>interaction</b> <b>technique.</b> For example, using a mouse to specify a 2D point involves a trivial <b>interaction</b> <b>technique,</b> whereas using a mouse to rotate a 3D object requires more creativity to design the technique and more lines of code to implement it.|$|R
40|$|In this paper, {{we present}} a novel <b>interaction</b> <b>technique</b> – {{combining}} mobile projection and visible, fiducial marker based information display. We vision it to be suitable for small groups e. g. for narrative playful experiences and guided on places, where physical tags would be disturbing. This <b>interaction</b> <b>technique,</b> where one person (guide) is projecting a marker and other users can read it with their mobile devices, enables in situ information delivery while the guide can control {{the dynamics of the}} situation. We present an example use case of using the <b>interaction</b> <b>technique</b> on a guided tour, and a preliminary results from the user evaluatio...|$|R
2500|$|While most {{children}} {{throughout the world}} develop language at similar rates and without difficulty, cultural and socioeconomic differences {{have been shown to}} influence development. [...] An example of cultural differences in language development can be seen when comparing the interactions of mothers in the United States with their infants with mothers in Japan. [...] Mothers in the United States use more questions, are more information-oriented, and use more grammatically correct utterances with their 3-month-olds. [...] Mothers in Japan, on the other hand, use more physical contact with their infants, and more emotion-oriented, nonsense, and environmental sounds, as well as baby talk, with their infants. [...] These differences in <b>interaction</b> <b>techniques</b> reflect differences in [...] "each society's assumptions about infants and adult-to-adult cultural styles of talking." ...|$|E
50|$|<b>Interaction</b> <b>techniques</b> are {{the glue}} between {{physical}} I/O devices and interaction tasks or domain objects. Different types of <b>interaction</b> <b>techniques</b> {{can be used}} to map a specific device to a specific domain object. For example, different gesture alphabets exist for pen-based text input.|$|E
50|$|A {{large part}} of {{research}} in human-computer interaction involves exploring easier-to-learn or more efficient <b>interaction</b> <b>techniques</b> for common computing tasks. This includes inventing new (post-WIMP) <b>interaction</b> <b>techniques,</b> possibly relying on methods from user interface design, and assessing their efficiency with respect to existing techniques using methods from experimental psychology. Examples of scientific venues in these topics are the UIST and the CHI conferences. Other research focuses on the specification of <b>interaction</b> <b>techniques,</b> sometimes using formalisms such as Petri nets {{for the purposes of}} formal verification.|$|E
40|$|Cursive: A novel <b>interaction</b> <b>technique</b> for {{controlling}} expressive avatar gesture We are developing an <b>interaction</b> <b>technique</b> for rich nonverbal communication through an avatar. By writing a single letter on a pen tablet device, a user can express their ideas or intentions, nonverbally, using their avatar body. Our system solves the difficult problem {{of controlling the}} movements of a highly articulated, 3 D avatar model using a common input device {{within the context of}} an office environment. We believe that writing is a richly expressive and natural means {{for controlling}} expressive avatar gesture. KEYWORDS:Avatars, computer-mediated communication, virtual environments, gesture, novel <b>interaction</b> <b>technique,</b> pen gesture, nonverbal...|$|R
5000|$|... #Caption: Fold n' Drop, a crossing-based <b>interaction</b> <b>technique</b> for {{dragging}} {{and dropping}} files between overlapping windows.|$|R
40|$|We propose an <b>interaction</b> <b>technique</b> for editing splines that {{is aimed}} at {{professional}} graphic designers. These users do not {{take full advantage of}} existing spline editing software because their mental representations of drawings do not match the underlying conceptual model of the software. Although editing splines by specifying control points and tangents may be appropriate for engineers, graphic designers think more in terms of strokes, shapes, and gestures appropriate for editing drawings. Our <b>interaction</b> <b>technique</b> matches the latter model: curves can be edited by means of marks, similar to the way strokes are naturally overloaded when drawing on paper. We describe this <b>interaction</b> <b>technique</b> and the algorithms used for its implementation. KEYWORDS: Mark-based interaction, Gestures, Spline editing, Interaction models, Graphic design, CAD...|$|R
5000|$|... #Subtitle level 2: Comparison {{with other}} <b>interaction</b> <b>techniques</b> ...|$|E
50|$|Visualization and <b>Interaction</b> <b>Techniques</b> for the Exploration of Vascular Structures. Horst K. Hahn, Bernhard Preim, Dirk Selle, Heinz-Otto Peitgen, IEEE Visualization'2001.|$|E
50|$|Leonel Valbom {{created a}} 3D {{immersive}} virtual environment with visual 3D representations of musical events and audio spatialization with {{which could be}} interacted using NSM <b>interaction</b> <b>techniques.</b>|$|E
50|$|Loren Brichter is an American {{software}} developer who {{is best known}} for creating Tweetie and the Pull-to-Refresh <b>interaction</b> <b>technique.</b>|$|R
40|$|In {{this paper}} we {{investigate}} a new <b>interaction</b> <b>technique</b> that enables users to capture You-Are-Here maps using their smartphone, and then manipulate the captured image {{in such a}} way that it can be used for navigation purposes. This technique utilises groups of similar You-Are-Here maps, which we call map constellations. Results from our field study, in which we tested a working prototype of our <b>interaction</b> <b>technique,</b> are presented. The results show an insight into users' views towards the <b>interaction,</b> and the <b>techniques</b> they employed to identically frame two You-Are-Here maps using a smartphone camera...|$|R
40|$|This study {{introduced}} an <b>interaction</b> <b>technique</b> that used tangible interaction for 3 D modeling. A hybrid <b>interaction</b> <b>technique</b> using a Kinect {{camera and a}} smartphone with a gyroscope was developed for the navigating objects in a 3 D modeling software. It was then tested on 20 participants categorized as amateurs who had basic 3 D/ CAD modeling experience and 20 participants categorized as the experts who had extensive experience working with the modeling software. This research study presents the need for existence of such <b>interaction</b> <b>technique,</b> gaps from the related previous studies, statistical findings from the current study and possible reasons for the results. The results concluded that the even though the hybrid <b>interaction</b> <b>technique</b> was efficient for both the participant categories and though there existed a statistical significance in efficiency for the amateur category, it did not provide a better user experience for the expert category and user experience for the amateur category was inconclusive. The study suggests that future studies and fine tuning {{of the current study}} could {{have a positive effect on}} the beginners in 3 D modeling without causing a major impact for the experts. ...|$|R
5000|$|... 3D <b>interaction</b> <b>techniques</b> are {{methods used}} {{in order to}} execute {{different}} types of task in 3D space. Techniques are classified according to the tasks that they support.|$|E
50|$|However, using <b>interaction</b> <b>techniques</b> {{that are}} not pointer-based have proven {{problematic}} with both pie and linear menus for cluttered digital tabletop, where physical objects might occlude menu items.|$|E
50|$|<b>Interaction</b> <b>techniques</b> {{that share}} the same metaphor or design {{principles}} {{can be seen as}} belonging to the same interaction style. General examples are command line and direct manipulation user interfaces.|$|E
40|$|Abstract�We {{introduce}} a socially motivated <b>interaction</b> <b>technique</b> with collocated flying robots (a quadrotor {{in our current}} prototype). Instead of the traditional remote interaction controllers often used when interacting with flying robots and UAVs, we explore the collocated interaction space and suggest a direct <b>interaction</b> <b>technique</b> motivated by social human-robot interaction themes. Our approach is inspired by the types of interaction humans have with birds, specifically falconeering, and is facilitated by gestures-based interaction, while the user is {{within the field of}} view of the flying robot. This paper outlines our research goals, task examples, and our overall design approach. The paper also discusses our current prototyping efforts, as well as a preliminary evaluation of our approach, performed through two design critiques, studying our collocated <b>interaction</b> <b>technique</b> concept, and its potential, drawbacks and benefits for users. Keywords-social human-robot interaction, flying robot, UAV, gesture-based interaction, collocated interaction, Wizard of O...|$|R
40|$|This thesis {{presents}} {{a new approach}} to haptic <b>interaction</b> <b>technique</b> design in which haptic feedback is displayed with a device held in the non-dominant hand, while the dominant hand controls a standard mouse. I believe that this approach has the potential to increase the fluency of everyday human-computer interaction by enabling a more effective division of tasks between the haptic and visual modalities. These ideas are expounded in a set of principles intended to guide the design of such techniques. I also present Pokespace, a novel <b>interaction</b> <b>technique</b> which follows those principles. Finally, I describe a series of three user studies intended to investigate and evaluate both the design principles and Pokespace. The results of the studies, though not unanimously positive, confirmed that Pokespace has the potential to support interaction without visual attention, and suggested several improvements to both the <b>interaction</b> <b>technique</b> and the underlying principles...|$|R
50|$|This <b>interaction</b> <b>technique</b> has close {{associations}} with related techniques in {{graphical user interfaces}} that use pointing devices such as a computer mouse (by drag and drop, for example).|$|R
50|$|The visual {{occlusion}} {{is a very}} intuitive {{method to}} provide a more realistic viewpoint of the virtual information in three dimensions. The interfaces provide more natural 3D <b>interaction</b> <b>techniques</b> over base 6.|$|E
5000|$|Visual {{representations}} and <b>interaction</b> <b>techniques</b> {{that take}} advantage of the human eye’s broad bandwidth pathway into the mind to allow users to see, explore, and understand large amounts of information at once.|$|E
5000|$|Florent Berthaut {{created a}} variety of 3D {{reactive}} widgets involving novel representations of musical events and sound, that required a special 3D input device to interact with them using adapted 3D <b>interaction</b> <b>techniques.</b>|$|E
30|$|To conclude, the <b>interaction</b> <b>technique</b> {{we propose}} (a) allows for {{simultaneous}} diverse interactions from multiple users, (b) shorthens the distances {{and thus can}} improve selection time in larger multi-touch screens (in {{the case of a}} menu-selection technique), (c) helps avoiding possible user conflicts by identifying the user or the action due to personal action windows, (d) is a low-cost software solution that works unobtrusively without any training sessions or additional equipment. Researchers and developers can easily use the proposed <b>interaction</b> <b>technique</b> by using the ChordiAction toolkit in their multi-touch applications.|$|R
40|$|PespectiveCursor {{is a new}} <b>interaction</b> <b>technique</b> for multidisplay {{environments that}} {{significantly}} improves human interaction with computer systems. Computer Vision {{has the potential to}} provide a solution for the implementation of this <b>interaction</b> <b>technique</b> that might be better than the current ones. A survey of the current state-of-the-art in 2 D and 3 D vision shows that there are many techniques that might be of use in finding the spatial relationships between {{the point of view of}} users and the displays in the environment, which is the main requirement for an implementation of PerspectiveCursor...|$|R
40|$|We {{describe}} an <b>interaction</b> <b>technique</b> for controlling site-specific mobile services using commercially available camera-phones, public information displays and visual tags. We report results from an experimental study validating this technique {{in terms of}} pointing speed and accuracy. Our results show that even novices can use camera-phones to "point-and-click" on visual tags quickly and accurately. We have built a publicly available client/server software framework for rapid development of applications that exploit our <b>interaction</b> <b>technique.</b> We describe two prototype applications that were implemented using this framework and present findings from user-experience studies based on these applications...|$|R
50|$|While <b>interaction</b> <b>techniques</b> are {{typically}} technology-, platform-, and/or implementation-dependent (see #level of granularity above), human-computer or human-information interactions {{can be characterized}} at higher levels of abstraction that are independent of particular technologies and platforms. At such levels of abstraction, the concern is not precisely how an interaction is performed; rather, the concern is a conceptual characterization of what the interaction is, and what the general utility of the interaction is for the user(s). Thus, any single interaction pattern may be instantiated by any number of <b>interaction</b> <b>techniques,</b> on any number of different technologies and platforms. Interaction patterns {{are more concerned with}} the timeless, invariant qualities of an interaction.|$|E
50|$|Written in C++ the {{framework}} enables {{the development of}} algorithms, visual encodings, <b>interaction</b> <b>techniques,</b> data models, and domain-specific visualizations. Tulip allows the reuse of components; this makes {{the framework}} efficient for research prototyping {{as well as the}} development of end-user applications.|$|E
50|$|Meanwhile, average desktop {{computers}} are still based on WIMP interfaces, and have started undergoing major operational improvements to surpass the hurdles inherent {{to the classic}} WIMP interface. These include the exploration of virtual 3D space, <b>interaction</b> <b>techniques</b> for window/icon sorting, focus, and embellishment.|$|E
40|$|A well-designed {{visualization}} of dynamic networks has {{to support the}} analysis of both temporal and relational features at once. In particular to solve complex synoptic tasks, the users {{need to understand the}} topological structure of the network, its evolution over time, and possible interdependencies. In this paper, we introduce the application of the vertigo zoom <b>interaction</b> <b>technique,</b> derived from filmmaking, to information visualizations. When applied to a two-and-a-half-dimensional view, this <b>interaction</b> <b>technique</b> enables smooth transitions between the relational perspective (node-link diagrams and scatter plots) and the time perspective (trajectories and line charts), supporting a seamless visual analysis and preserving the user’s mental map...|$|R
30|$|Kray, C., et al., Bridging the {{gap between}} the Kodak and the Flickr generations: A novel <b>interaction</b> <b>technique</b> for {{collocated}} photo sharing. Int. J. Hum.-Comput. Stud., 2009. 67 (12): p. 1060 – 1072.|$|R
40|$|Young {{people with}} severe {{physical}} disabilities may benefit greatly from participating in immersive computer games. In-game tasks can be fun, engaging, educational, and socially interactive. But {{for those who are}} unable to use traditional methods of computer input such as a mouse and keyboard, there is a barrier to interaction that they must first overcome. Eye-gaze interaction is one method of input that can potentially achieve the levels of interaction required for these games. How we use eye-gaze or the gaze <b>interaction</b> <b>technique</b> depends upon the task being performed, the individual performing it, and the equipment available. To fully realize the impact of participation in these environments, techniques need to be adapted to the person’s abilities. We describe an approach to designing and adapting a gaze <b>interaction</b> <b>technique</b> to support locomotion, a task central to immersive game playing. This is evaluated by a group of young people with cerebral palsy and muscular dystrophy. The results show that by adapting the <b>interaction</b> <b>technique,</b> participants are able to significantly improve their in-game character control...|$|R
