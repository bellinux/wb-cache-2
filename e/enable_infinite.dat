5|25|Public
40|$|International audienceThis {{demonstration}} paper {{presents a}} space battle simulation, {{which was designed}} using the Interaction-Oriented approach IODA, and implemented within the 3 D professional game engine Unity. After giving {{an overview of the}} simulation, we explain how it was built through a step-by-step setup, and how the use of interactions <b>enable</b> <b>infinite</b> extensions...|$|E
40|$|Guričan Abstract. The {{notion of}} free group is defined, a {{relatively}} wide collection of groups which <b>enable</b> <b>infinite</b> set summation (called commutative pi-group), is introduced. Commu-tative pi-groups are studied from the set-theoretical {{point of view}} and {{from the point of view}} of free groups. Commutativity of the operator which is a special kind of inverse limit and factorization, is proved. Tensor product is defined, commutativity of direct product (also a free group construction and tensor product) with the special kind of inverse limit is proved. Some important examples of tensor product are computed...|$|E
40|$|The {{recently}} developed variational autoencoders (VAEs) {{have proved to}} be an effective confluence of the rich representational power of neural networks with Bayesian methods. However, most work on VAEs use a rather simple prior over the latent variables such as standard normal distribution, thereby restricting its applications to relatively simple phenomena. In this work, we propose hierarchical nonparametric variational autoencoders, which combines tree-structured Bayesian nonparametric priors with VAEs, to <b>enable</b> <b>infinite</b> flexibility of the latent representation space. Both the neural parameters and Bayesian priors are learned jointly using tailored variational inference. The resulting model induces a hierarchical structure of latent semantic concepts underlying the data corpus, and infers accurate representations of data instances. We apply our model in video representation learning. Our method is able to discover highly interpretable activity hierarchies, and obtain improved clustering accuracy and generalization capacity based on the learned rich representations. Comment: Accepted in ICCV 201...|$|E
2500|$|Another unique {{aspect of}} human culture and thought is the {{development}} of complex methods for acquiring knowledge through observation, quantification, and verification. The scientific method has been developed to acquire knowledge of the physical world and the rules, processes and principles of which it consists, and combined with mathematics it enables the prediction of complex patterns of causality and consequence. Some other animals are able to recognize differences in small quantities, [...] but humans are able to understand and recognize much larger, even abstract, quantities, and to recognize and understand algorithmic patterns which <b>enables</b> <b>infinite</b> counting routines and algebra, something that is not found in any other species.|$|R
40|$|State space {{generation}} {{is a powerful}} formal method for analysis of concurrent and distributed finite state systems. It suffers from the state space explosion problem, however: the state space of a system can be far too large to be completely generated. The sleep set method {{is one way to}} try to avoid generating all of the state space when verifying a given property. This paper is concentrated on the transition selection function in the sleep set method applied to a labelled transition system to verify a simple safety property or the existence of <b>enabled</b> <b>infinite</b> transition sequences. The conditions found for the function can be used for combining the sleep set method with other analysis techniques...|$|R
40|$|A {{generalization}} of Wintgen's method for classifying space-group representations {{is made to}} <b>enable</b> the <b>infinite</b> set of co-representations of magnetic space groups to be classified and enumerated. Using this method, all special points, lines and planes in the Brillouin zone model for magnetic crystals are identified. Arithmetic crystal-classes of magnetic space groups are introduced, fully listed and used to classify magnetic space groups and their co-representations, A version of Burnside's theorem adapted to co-representations is constructed and used to solve completely the enumeration problem of co-representations of magnetic space groups...|$|R
40|$|The {{advent of}} Machine to Machine (M 2 M) {{communication}} {{has opened up}} new avenues for the mobile operators and also for the equipment vendors. The ecosystem of communication is fast emerging in to a new dimension. However to make the new realm of M 2 M communication feasible, {{there is a need}} to reduce the power consumption of these devices. Research is being carried out in several directions to reduce the power consumption. Research work has been done to develop new network topologies, architecture and also improve the electronics and embedded systems to reduce power consumption. This thesis explores the third direction which is concerned with developing a prototype using the existing electronics and cellular access techniques to explore the possibility of improving power consumption. This is concerned also with using energy harvesting for recharging the battery supplies. The development of the prototype is aimed at using a CPU, cellular access device and rechargeable power system to develop M 2 M device with battery time in terms of years. We will be using the concept of sleeping devices to <b>enable</b> <b>infinite</b> battery times. The aim of the research is to find sleep times which may lead to sufficiently longer battery times and hence provide a prototype of M 2 M device with energy harvesting solution capable to have independent power source for years...|$|E
40|$|The paper proposes an {{abstract}} execution model for LOTOS specifications, {{which is based}} on a number of cooperating extended finite state machines, applies to whatever LOTOS specification, with the only exclusion of those containing non well guarded recursion, and is suitable for a distributed implementation. Every machine represents a process, which does not necessarily correspond to one of the process definitions the specification is composed of. The machine instances (that is to say processes) can access variables, which correspond to LOTOS value identifiers, and can dynamically create new machine instances, thus <b>enabling</b> any <b>infinite</b> behaviour to be modeled. Synchronisation among the machines is achieved by a distributed algorithm which implements the multi-way rendezvous of LOTOS. The paper shows how the model is derived from LOTOS specifications and how it is execute...|$|R
40|$|Infinite lattice {{summation}} scheme {{based on}} the idea of renormalization is generalized to <b>enable</b> evaluation of <b>infinite</b> lattice sums with Bloch phase factors which can occur when treating long-range interactions in infinite periodic systems. The scheme is fast, with easy to control accuracy and is not limited to any choice of special points in the Brillouin zone. Illustrative calculation for a first few contributions for a simple cubic lattice is presented. Comment: Submitted to Journal of Chemical Physic...|$|R
40|$|The enigma of {{the mind}} has enticed scientists, philosophers, and artists {{throughout}} history. Its universality binds us together, but its potential for plasticity <b>enables</b> an <b>infinite</b> range of human uniqueness. As an essential, defining component of human life, it is necessarily connected to all that life constitutes. The introduction of magnetic resonance imaging (MRI) and the related {{functional magnetic resonance imaging}} (fMRI) {{in the latter part of}} the 1970 s revolutionized the manner in which scientists investigate the structure and function of the brain. These neuroimaging techniques rely on the intrinsic spin of protons in water molecules and the differential signal resulting from atoms of different tissues and of oxygenated versus deoxygenated blood. MRI and fMRI can be performed on a live, conscious individual and have relatively good spatial and temporal resolution. In contrast, earlier investigational methods relied either on post-mortem analysis that divorced the brain from its in-vivo elegance, o...|$|R
50|$|The {{fact that}} a concept is fuzzy does not prevent its use in logical {{reasoning}}; it merely affects the type of reasoning which can be applied (see fuzzy logic). If the concept has gradations of meaningful significance, {{it is necessary to}} specify and formalize what those gradations are, if they can make an important difference. Not all fuzzy concepts have the same logical structure, but they can often be formally described or reconstructed using fuzzy logic or other substructural logics. The advantage of this approach is, that numerical notation <b>enables</b> a potentially <b>infinite</b> number of truth-values between complete truth and complete falsehood, and thus it enables the greatest precision in stating the degree of applicability of a logical rule.|$|R
30|$|Infrastructures are ‘the {{physical}} networks {{through which}} goods, ideas, waste, power, people, and finance are trafficked’ (Larkin, 2013 : 327), although as material forms they also require {{much work to}} build, maintain, repair and sustain. The analysis below develops an infrastructural approach informed by science and technology studies (STS) and related critical data studies. In such work, infrastructures are viewed not just as built structures or physical substrates which form a ‘neutral background that <b>enables</b> an <b>infinite</b> set of activities’ (Slota & Bowker, 2017 : 530). Instead, infrastructure appears as a thoroughly heterogeneous and interpenetrating ‘assemblage’ of technological objects, standards, values, administrative procedures, and organizational work, all of which involve myriad people, institutions, technologies, policies, legalities, and financial arrangements to build, repair, maintain, and reconstruct (Kitchin & Lauriault, 2014). The ‘infrastructures of daily life’ are thus assembled from ‘a maze of cables, connectors and infrastructural components’ but also ‘regulatory authorities who authorize interventions…, committees that resolve conflicting demands {{in the process of}} setting standards, governments that set policy, bureaucrats who implement it, marketers who shape our views {{of the role of the}} infrastructure in our lives, and more’ (Dourish & Bell, 2011 : 4 – 5).|$|R
5000|$|In the 1990s, {{with the}} rise of {{powerful}} home computers with audio capabilities came the mash-up, an unsolicited, unofficial (and often legally dubious) remix created by [...] "underground remixers" [...] who edit two or more recordings (often of wildly different songs) together. Girl Talk is perhaps the most famous of this movement, creating albums using sounds entirely from other music and cutting it into his own. Underground mixing is more difficult than the typical official remix, because clean copies of separated tracks such as vocals or individual instruments are usually not available to the public. Some artists (such as Björk, Nine Inch Nails, and Public Enemy) embraced this trend and outspokenly sanctioned fan remixing of their work; there was once a web site which hosted hundreds of unofficial remixes of Björk's songs, all made using only various officially sanctioned mixes. Other artists, such as Erasure, have included remix software in their officially released singles, <b>enabling</b> almost <b>infinite</b> permutations of remixes by users. The band have also presided over remix competitions for their releases, selecting their favourite fan-created remix to appear on later official releases.|$|R
40|$|A general {{formulation}} of risk load for total cash flows is presented. It allows completely additive co-measures 1 {{at any level}} of detail for any dependency structure between random variables constituting the total. It is founded on the intuition that some total outcomes are more risky per dollar than others, and the measure of that is a “riskiness leverage ratio. ” This riskiness leverage function is an essentially arbitrary choice, <b>enabling</b> an <b>infinite</b> variety of management attitudes toward risk to be expressed. The complete additivity makes these models useful. What makes them interesting is that attention can be turned toward asking “what is a plausible risk measure for the whole, while being prepared to use the indicated allocation technique for the pieces? ” The usual measures are special cases of this form, as shown in some examples. While the author does not particularly advocate allocating capital to do pricing, this class of models does allow pricing at the individual policy clause level, if so desired. Further, the desirability of reinsurance or other hedges can be quantitatively evaluated from the cedant’s point of view by comparing {{the increase in the}} mean cost with the decrease in capital cost from reduction of capital required...|$|R
50|$|CDO {{issuance}} {{grew from}} an estimated $20 billion in Q1 2004 to its peak of over $180 billion by Q1 2007, then declined back under $20 billion by Q1 2008. Further, the credit quality of CDO's declined from 2000 to 2007, as {{the level of}} subprime and other non-prime mortgage debt increased from 5% to 36% of CDO assets. As described in the section on subprime lending, the CDS and portfolio of CDS called synthetic CDO <b>enabled</b> a theoretically <b>infinite</b> amount to be wagered on the finite value of housing loans outstanding, provided that buyers and sellers of the derivatives could be found. For example, buying a CDS to insure a CDO ended up giving the seller the same risk as if they owned the CDO, when those CDO's became worthless.|$|R
40|$|With the advents of {{high-speed}} networks, fast commodity hardware, and the web, distributed data sources have become ubiquitous. The third {{edition of the}} Özsu-Valduriez textbook Principles of Distributed Database Systems [10] reflects the evolution of distributed data management and distributed database systems. In this new edition, the fundamental principles of distributed data management could be still presented based on the three dimensions of earlier editions: distribution, heterogeneity and autonomy of the data sources. In retrospect, the focus on fundamental principles and generic techniques has been useful not only to understand and teach the material, but also to <b>enable</b> an <b>infinite</b> number of variations. The primary application of these generic techniques has been obviously for distributed and parallel DBMS versions. Today, to support the requirements of important data-intensive applications (e. g. social networks, web data analytics, scientific applications, etc.), new distributed data management techniques and systems (e. g. MapReduce, Hadoop, SciDB, Peanut, Pig latin, etc.) are emerging and receiving much attention from the research community. Although they do well in terms of consistency/flexibility/performance trade-offs for specific applications, {{they seem to be}} ad-hoc and might hurt data interoperability. The key questions I discuss are: What are the fundamental principles behind the emerging solutions? Is there any generic architectural model, to explain those principles? Do we need new foundations to look at data distribution...|$|R
40|$|A nonparametric {{multiple}} regression method, {{based on the}} extended Gini that depends on one parameter, v, is investigated. The parameter v <b>enables</b> production of <b>infinite</b> alternative linear approximations to the regression curve which differ in the weighting schemes applied to {{the slopes of the}} curve. The method allows the investigator to stress different sections of one independent variable while keeping the treatment of the other independent variables intact. As an application we investigate nonresponse patterns in a survey of household expenditures to learn about the relationship between nonresponse and income. The empirical results show that the higher the income, the higher the response rate, and the larger the household, the higher the response rate. The Arab population tends to respond more than the Jewish one, whereas the ultrareligious group tends to respond less {{than the rest of the}} population. The implications on the bias in the estimates are discussed. ...|$|R
40|$|Rewrite {{techniques}} {{can be used}} to execute logic programs in order to avoid some drawbacks of classical Prolog resolution. By transforming clauses into logical equivalences considered as rewrite rules, logic programs are represented as rewrite programs whose operational mechanism, inspired from the Knuth-Bendix completion, allows one to prune some unnecessary computations and offers a synthesis ability which <b>enables</b> to represent <b>infinite</b> sets of answers as finite sets of formulas. We propose here a full extension of this approach to Constraint Logic Programming (CLP) with negation. Issued from rewrite techniques, a very powerful simplification rule is defined, available in a more general context than strict instantiation. Thanks to this rule, solutions are obtained as a set of constraint rewrite rules with more expressive power than simple constraints used in a classical CLP framework. Thus, our mechanism, integrating both non symbolic constraints and negation, keeps the loop avoiding [...] ...|$|R
40|$|Rewrite {{techniques}} {{can be used}} to execute logic programs in order to avoid some drawbacks of classical Prolog resolution. Logic programs are represented as rewrite programs whose operational mechanism, inspired from Knuth-Bendix completion, allows to prune some unnecessary computations and offers a synthesis ability which <b>enables</b> to represent <b>infinite</b> sets of answers as finite sets of formulas. We extend this approach to CLP with negation. Our mechanism, integrating both non symbolic constraints and negation, keeps the loop avoiding and synthesis properties. Taking advantage of a simplification rule, the solutions are obtained as a set of constrained rewrite rules with more expressive power than simple constraints used in classical CLP resolution. The system is proved sound and complete with regard to the standard CLP semantics. 1 INTRODUCTION Rewrite techniques, adapted to a pure logic programming framework by Bonacina and Hsiang in [3], provide a new evaluation mechanism for logic [...] ...|$|R
40|$|Is there {{something}} like a 'scientific' approach to the reading or interpretation of literary texts as {{is suggested by the}} German term 'Literaturwissenschaft'? This essay argues that genuinely scientific criteria such as the intersubjective verifiability of a given reading do not apply to the reading of literary texts. The reason is that such texts <b>enable</b> a quasi <b>infinite</b> range of different readings the preconceptions of which are contingent upon the individual readers, their previous experiences, literary as well as non-literary, and their expectations. — What, then, are the tasks of a scholarly reading of literary texts? Firstly, the theoretical reflection upon the status of such texts in comparison to pragmatic texts; secondly, the attempt at reconstructing their historical context (in terms of discursive history), and thirdly, a reading with regard to present-day problems. The 'quality' of a scholarly reading of a literary text would thus be dependent not on its 'objectivity', but rather on its capacity to produce resonances amongst other present-day readers, scholarly and non-scholarly...|$|R
40|$|This {{paper will}} discuss the distinctions between e|mediated and print (typo) graphic design by which its role might be reconsidered as {{significantly}} authorial, not merely formal or technical. Reproducing meaning on-screen alters conventions and assumptions which traditionally inform print-designers' attitudes to visual organisation. Not least amongst these is the increased visual significance of wayfinding requirements. Yet comfortable assumptions about (typo) graphic design as cultural producer must also change. As an ideological, elitist tool of consumerist persuasion {{it is not a}} rigorous discipline of public service. Yet ironically, not only does it exemplify the five arts of ancient rhetoric, the communicative action of the public sphere so central to democratic participation (supplanted by the rationalist abstractions of elitist philosophic discourses), but it also stands uniquely capable of addressing the paradoxical 'fissure' at the heart of contemporary rhetorical practice: the " division of the logos into form and content" (Hariman 227). Emedia <b>enables</b> virtually <b>infinite</b> and free publication, yet within technical constraints which engender possibilities for a radically analytic deconstruction of the conventional form of discursive codex-textuality. Through both static and dynamic juxtapositioning by which oscillation between formality and function may be visually instantiated it is possible to use (typo) graphic designing as a hermeneutic tool to make explicit the 'designing' consciousness behind all literacy, yet which is not normally explicit in writing. In a society saturated with remediation e|media may enable a radical, even humanistic rhetoric of (typo) graphicality. Hosted by the Scholarly Text and Imaging Service (SETIS), the University of Sydney Library, and the Research Institute for Humanities and Social Sciences (RIHSS), the University of Sydney...|$|R
40|$|Abstract—Energy is {{the most}} {{limiting}} factor in wireless sensor networks. Harvesting solar energy is a feasible solution to overcome the energy-constraint in some applications. It <b>enables</b> a theoretically <b>infinite</b> network lifetime, sustaining a mode of operation termed energy neutral consumption rate The challenge arises, how can the harvested energy be utilized to maximize {{the performance of the}} sensor network. Considering a field monitoring application the performance is measured as the sustained sampling rate of the sensors. Maximizing the sampling rate needs to take the spatio-temporal distribution of load and energy into account, to prevent the overloading of nodes. In [1] they introduced a optimal, theoretical solution based on perfect global knowledge. In this paper we propose the solar-aware distributed flow (SDF) approach. SDF enables each node to predict the harvested energy, calculate a sustainable flow and control its local neighborhood. To {{the best of our knowledge}} it is the first practical solution. Extensive simulations confirmed that SDF achieves over 80 % of the theoretical optimum, while introducing negligible overhead. I...|$|R
40|$|Can we lead back consciousness, reality, awareness, {{and free}} will {{on a single}} basic {{structure}} without giving up any of them? Can the universe exist in both real and individual ways without being composed of both? This metaphysical dialogue founds consciousness and freedom of choice {{on the basis of}} a new reality concept that also includes the infinite as far as we understand it. Just the simplest distinction contains consciousness. It is not static, but a constant alternation of perspectives. From its entirety and movement, however, there arises a freedom of choice being more than reinterpreted necessity and unpredictability. Although decisions ultimately involve the whole universe, they are free in varying degrees also here and now. The unity and openness of the <b>infinite</b> <b>enables</b> the individual a creativity that directly and indirectly enters into all other individuals without impeding them. A contrary impression originates only in a narrowed awareness. But even the most conscious and free awareness can neither anticipate all decisions nor extinguish individuality. Their creativity is secured...|$|R
60|$|But now, when I {{appeared}} almost within {{grasp of}} my foe, my hopes were suddenly extinguished, and I lost all trace of him more utterly than I {{had ever done}} before. A ground sea was heard; the thunder of its progress, as the waters rolled and swelled beneath me, became every moment more ominous and terrific. I pressed on, but in vain. The wind arose; the sea roared; and, as with the mighty shock of an earthquake, it split and cracked with a tremendous and overwhelming sound. The work was soon finished; {{in a few minutes}} a tumultuous sea rolled between me and my enemy, and I was left drifting on a scattered piece of ice that was continually lessening and thus preparing for me a hideous death. In this manner many appalling hours passed; several of my dogs died, and I myself was about to sink under the accumulation of distress when I saw your vessel riding at anchor and holding forth to me hopes of succour and life. I had no conception that vessels ever came so far north and was astounded at the sight. I quickly destroyed part of my sledge to construct oars, and by these means was <b>enabled,</b> with <b>infinite</b> fatigue, to move my ice raft in the direction of your ship. I had determined, if you were going southwards, still to trust myself to the mercy of the seas rather than abandon my purpose. I hoped to induce you to grant me a boat with which I could pursue my enemy. But your direction was northwards. You took me on board when my vigour was exhausted, and I should soon have sunk under my multiplied hardships into a death which I still dread, for my task is unfulfilled.|$|R
40|$|Microwave {{photonic}} {{signal processing}} offers unprecedented features for processing high bandwidth signals. It puts forward a new prospect for overcoming the inherent bottlenecks {{caused by the}} limitations in conventional microwave signal processors. The motivation stems from the great potential of exploiting the unique, high time-bandwidth product, low loss, and immunity to electromagnetic interference (EMI) capabilities of photonic signal processing. Microwave photonic signal processing is the new paradigm for processing wideband microwave signals with high tunability and reconfigurability. Amongst the different photonic signal processors, the photonic frequency downconverter is important in many remote antenna, defence and radar systems. Two new microwave photonic mixers are presented in this thesis. The performance of these mixers is substantially improved compared to previous approaches. A new linearised photonic mixer structure, which can fully eliminate the third order intermodulation distortion, is presented. It {{is based on an}} integrated dual-parallel Mach-Zehnder modulator to which an optimised RF split and an optimised optical phase shift is applied, in series with a Mach-Zehnder modulator driven by the LO. The mixer achieves a very high spurious free dynamic range performance, it <b>enables</b> essentially <b>infinite</b> isolation between the RF and LO ports, and it has the ability to function over a multi-octave frequency range. Experimental results demonstrate a record measured spurious free dynamic range performance of 127 dB∙Hz 4 / 5, which is over 22 dB higher than that of the conventional dual-series Mach-Zehnder modulator based microwave photonic mixer. In addition, another new wideband linearised photonic mixer structure is presented. It is based on using stimulated Brillouin scattering effects to suppress the optical carrier, together with a single drive integrated dual-parallel Mach-Zehnder modulator for linearisation. The new structure offers enhanced conversion efficiency through the carrier suppression technique. It also suppresses the third order intermodulation distortion to consequently increase the spurious free dynamic range performance through optimising the bias condition of the dual-parallel Mach-Zehnder modulator. Additionally, the new structure enables multioctave operation, and infinite isolation between the RF and LO ports. Simulation results showed a spurious free dynamic range of 120. 4 dB∙Hz 4 / 5, and a conversion gain of 8. 45 dB, corresponding to 15 dB, and 8. 8 dB improvements respectively when compared to the conventional dual-series Mach-Zehnder modulator based microwave photonic mixer. Experimental results demonstrate a measured spurious free dynamic range performance of 120. 8 dB∙Hz 4 / 5, which corresponds to 16 dB improvement compared to the conventional photonic mixer structure. Access is restricted to staff and students of the University of Sydney. UniKey credentials are required. Non university access may be obtained by visiting the University of Sydney Library...|$|R

