94|10000|Public
2500|$|Before 2013, Google did not encrypt {{data stored}} on its servers. Following {{information}} that the United States' National Security Agency had [...] "direct access" [...] to servers owned by multiple technology companies, including Google, the company began testing encrypting data in July, and enabled encryption for <b>data</b> <b>in</b> <b>transit</b> between its data centers in November. However, as of 2015, Google Drive does not provide client-side encryption.|$|E
2500|$|Information {{assurance}} (IA) is {{the practice}} of assuring information and managing risks related to the use, processing, storage, and transmission of information or data and the systems and processes used for those purposes. Information assurance includes protection of the integrity, availability, authenticity, non-repudiation and confidentiality of user data. It uses physical, technical and administrative controls to accomplish these tasks. While focused predominantly on information in digital form, {{the full range of}} IA encompasses not only digital but also analog or physical form. These protections apply to <b>data</b> <b>in</b> <b>transit,</b> both physical and electronic forms as well as data at rest in various types of physical and electronic storage facilities.|$|E
2500|$|To {{the best}} of {{publicly}} available information, there is no known method which will allow a person or group to break PGP encryption by cryptographic or computational means. Indeed, in 1995, cryptographer Bruce Schneier characterized an early version as being [...] "the closest you're likely to get to military-grade encryption." [...] Early versions of PGP {{have been found to}} have theoretical vulnerabilities and so current versions are recommended. In addition to protecting <b>data</b> <b>in</b> <b>transit</b> over a network, PGP encryption {{can also be used to}} protect data in long-term data storage such as disk files. [...] These long-term storage options are also known as data at rest, i.e. data stored, not in transit.|$|E
40|$|Seeking to {{preserve}} electronically encoded evidence implies that an incident or event has occurred requiring fact extrapolation for presentation, {{as proof of}} an irregularity or illegal act. Whether target <b>data</b> are <b>in</b> <b>transit</b> or at rest, {{it is critical that}} measures be in place to prevent the sought information from being destroyed, corrupted or becoming unavailable for forensic investigation...|$|R
5000|$|SMTD's route {{information}} was integrated into Google Transit on May 12th, 2016. The district also freely provides their schedule <b>data</b> <b>in</b> the General <b>Transit</b> Feed Specification format for developers and hobbyists to incorporate {{in their own}} apps. Other apps using this data include Bing Maps, Here WeGo, Moovit, and Walk Score. Real-time data is not currently available.|$|R
5000|$|The kit {{consists}} of two pieces: a piezoelectric sensor with a Nordic Semiconductor nRF2402 transmitter that is mounted under the inner sole of the shoe and a receiver that connects to the iPod. They communicate using a 2.4 GHz wireless radio and use Nordic Semiconductor's [...] "ShockBurst" [...] network protocol. The wireless <b>data</b> is encrypted <b>in</b> <b>transit,</b> but some uniquely identifying <b>data</b> is sent <b>in</b> the plain. The wireless protocol was reverse engineered and documented by Dmitry Grinberg in 2011.|$|R
50|$|Metadirectory {{products}} support filtering {{and transformation}} of <b>data</b> <b>in</b> <b>transit.</b>|$|E
5000|$|Transmission: {{transferring}} data between {{information systems}} - {{also known as}} <b>data</b> <b>in</b> <b>transit</b> (DIT).|$|E
5000|$|<b>Data</b> <b>in</b> <b>transit</b> is also {{referred}} to as data in motion, [...] and data in flight [...]|$|E
30|$|Over the years, Geographic Information System (GIS) {{technology}} has been implemented {{for a variety of}} purposes within the transit industry. Recently, the GIS has been widely used in accessibility analysis such as the walking accessibility between alternative neighborhood designs [194] and transport accessibility disadvantage [123]. The <b>data</b> and results <b>in</b> <b>transit</b> have the spatial characteristic. To demonstrate the data more clearly and directly, some visualization tools based on GIS have been developed to explore spatial variations <b>in</b> <b>data</b> [195]. The visualization results also provide a better way to find out the character of the data and {{a better understanding of the}} data.|$|R
40|$|AbstractKnowledge, {{information}} and data {{hold the key}} for growth and continuous sustenance in any organization. However, flow of this {{information and}} data across inter disciplinary departments to authorized personnel ensures the authencity and accuracy of this <b>data</b> while <b>in</b> <b>transit.</b> Workflow can be devised as a tool used purely <b>in</b> electronic <b>data</b> processing environment where data is to be transmitted across heterogeneous departments handled by personnel belonging to diverse engineering backgrounds. This proves itself to have a catalytic effect in product oriented, process oriented and data processing modes of working in an industry through its pre-set rules, procedures and flexible modes of operation. Further, the same workflow methodology {{can be used in}} web based applications which only requires installation of the particular tool in server machine, thus providing the freedom from independent client installations. Enhancing the operational ability of workflow can provide information on the approximate time taken for <b>data</b> processing <b>in</b> various inter-disciplinary departments involving process oriented, product oriented and data processing modes of working...|$|R
40|$|The {{availability}} of {{automatic fare collection}} (AFC) data greatly enhances a transit planner's ability to understand and characterize passenger travel demands which have traditionally been estimated by manual surveys handed out to passengers at stations or on board vehicles. The AFC data also presents an unprecedentedly consistent source of information on passenger travel times <b>in</b> those <b>transit</b> networks which have both entry and exit fare gates. By taking the difference between entry and exit times, AFC transactions {{can be used to}} capture the bulk of a passenger's time spent in the system including walking between gates and platforms, platform wait, in-train time, as well as interchange time for multi-vehicle trips. This research aims at demonstrating the potential value of AFC <b>data</b> <b>in</b> rail <b>transit</b> operations and planning. The applications developed in this thesis provide rail transit operators an easy-to-update management tool that evaluates several dimensions of rail service and demand at near real-time. While the concepts of the applications can be adapted to other transit systems, the detailed configurations and unique characteristic...|$|R
50|$|Encryption is {{also used}} to protect <b>data</b> <b>in</b> <b>transit,</b> for example data being {{transferred}} via networks (e.g. the Internet, e-commerce), mobile telephones, wireless microphones, wireless intercom systems, Bluetooth devices and bank automatic teller machines. There have been numerous reports of <b>data</b> <b>in</b> <b>transit</b> being intercepted in recent years. Data should also be encrypted when transmitted across networks in order to protect against eavesdropping of network traffic by unauthorized users.|$|E
50|$|Also, {{there is}} also a {{well-known}} case where PKI is used for <b>data</b> <b>in</b> <b>transit</b> of data at rest.|$|E
5000|$|Security of {{stored data}} and <b>data</b> <b>in</b> <b>transit</b> {{may be a}} concern when storing {{sensitive}} data at a cloud storage provider ...|$|E
40|$|Network coding has {{received}} significant {{attention in the}} networking community for its potential to increase throughput and improve robustness without any centralized control. Unfortunately, network coding is highly susceptible to “pollution attacks ” in which malicious nodes modify packets {{in a way that}} prevents the reconstruction of information at recipients; such attacks cannot be prevented using standard end-to-end cryptographic authentication because network coding requires that intermediate nodes modify <b>data</b> packets <b>in</b> <b>transit.</b> Specialized solutions to the problem have been developed in recent years based on homomorphic hashing and homomorphic signatures. The latter are more bandwidth-efficient but require more computation; in particular, the only known construction uses bilinear maps. We contribute to this area in several ways. We present the first homomorphic signature scheme based solely on the RSA assumption (in the random oracle model), and present a homomorphic hashing scheme based on composite moduli that is computationally more efficient than existing schemes (and which leads to secure network coding signatures based solely on the hardness of factoring in the standard model). Both schemes use shorter public keys than previou...|$|R
40|$|I {{introduce}} batman, a Python {{package for}} modeling exoplanet transit light curves. The batman package supports calculation of light curves for any radially symmetric stellar limb darkening law, {{using a new}} integration algorithm for models that cannot be quickly calculated analytically. The code uses C extension modules to speed up model calculation and is parallelized with OpenMP. For a typical light curve with 100 <b>data</b> points <b>in</b> <b>transit,</b> batman can calculate one million quadratic limb-darkened models in 30 seconds with a single 1. 7 GHz Intel Core i 5 processor. The same calculation takes seven minutes using the four-parameter nonlinear limb darkening model (computed to 1 ppm accuracy). Maximum truncation error for integrated models is an input parameter that can be set as low as 0. 001 ppm, ensuring that the community is prepared for the precise transit light curves we anticipate measuring with upcoming facilities. The batman package is open source and publicly available at [URL]. Comment: 13 pages, 3 figures, accepted to PASP; this version adds an eclipse model and modifies <b>transit</b> parameterization <b>in</b> response to refere...|$|R
40|$|Cryptography {{is often}} used to secure the secrecy and {{integrity}} of data, but its ubiquitious use (for example on every read and write of a program variable) is prohibitive. When protecting the secrecy and integrity of data, applications may choose to reply on the underlying runtime or network, or they may seek to secure the data themselves using cryptographic techniques. However specifying when to rely on the environment, and when to explicitly enforce security, is usually specified informally without recourse to explicit policies. This article considers an approach to making explicit when the runtime or network is trusted to carry <b>data</b> <b>in</b> cleartext, and when the data must be explicitly protected. The approach is based on associating levels of trust to parts of the system where <b>data</b> may reside <b>in</b> <b>transit,</b> and levels of relative sensitivity to data that is transmitted. The trust policy is enforced by a type system, one that distinguishes between security policies for access control and trust policies for controlling the safe distribution of data. ...|$|R
50|$|A packet {{analyzer}} ("packet sniffer") is {{an application}} that captures data packets, {{which can be}} used to capture passwords and other <b>data</b> <b>in</b> <b>transit</b> over the network.|$|E
50|$|<b>Data</b> <b>in</b> <b>transit</b> {{is used as}} a {{complement}} to the terms data in use, and data at rest which together define the three states of digital data.|$|E
50|$|As {{it turns}} out, {{these two types}} of classifications has {{something}} in common: that is, <b>data</b> <b>in</b> <b>transit</b> generally uses public key ciphers, and data at rest generally uses symmetric key ciphers.|$|E
40|$|We present {{randomized}} {{constructions of}} linear-time encodable and decodable codes that can transmit over lossy channels at rates extremely close to capacity. The encoding and decoding algorithms for these codes have fast and simple software implementations. Implementations of our algorithms are faster by {{orders of magnitude}} than the software implementations of previous algorithms. We expect these codes will be extremely useful for applications where lossy channels are common and fast decoding is a requirement, e. g., satellite transmission and multicast transmission over the Internet. I. Introduction In many communication situations, <b>data</b> is lost <b>in</b> <b>transit.</b> A standard response to this problem is to request retransmission of data that is not received. When some of this retransmission is lost, another request is made, and so on. Such communication protocols can lead to delays due {{to the need for}} several rounds of communication between sender and receiver. An alternative [...] ...|$|R
40|$|Following the {{announcement}} of Host Card Emulation (HCE) technology, card emulation mode based Near Field Communication (NFC) services have gained further appreciation as an enabler of the Cloud-based Secure Element (SE) concept. A comprehensive and complete architecture with a centralized and feasible business model for diverse HCE-based NFC services will be highly appreciated, particularly by Service Providers and users. To satisfy the need in this new emerging research area, a Tokenization-based communication architecture for HCE-based NFC services is presented in this paper. Our architecture proposes Two-Phased Tokenization to enable the identity management of both user and Service Provider. NFC Smartphone users can store, manage, and make use of their sensitive data on the Cloud for NFC services; Service Providers can also provide diverse card emulation NFC services easily through the proposed architecture. In this paper, we initially present the Two-Phased Tokenization model and then validate the proposed architecture by providing a case study on access control. We further evaluate the usability aspect {{in terms of an}} authentication scheme. We then discuss the ecosystem and business model comprised of the proposed architecture and emphasize the contributions to ecosystem actors. Finally, suggestions are provided for <b>data</b> protection <b>in</b> <b>transit</b> and at rest. Publisher's Versio...|$|R
40|$|Cloud {{computing}} {{allows users}} to view computing in a new direction, as it uses the existing technologies to provide better IT services at low-cost. To offer high QOS to customers according SLA, cloud services broker or cloud service provider uses individual cloud providers that work collaboratively to form a federation of clouds. It is required in applications like Real-time online interactive applications, weather research and forecasting etc., <b>in</b> which the <b>data</b> and applications are complex and distributed. In these applications secret data should be shared, so secure data sharing mechanism is required in Federated clouds {{to reduce the risk}} of data intrusion, the loss of service availability and to ensure <b>data</b> integrity. So <b>In</b> this paper we have proposed zero knowledge data sharing scheme where Trusted Cloud Authority (TCA) will control federated clouds for data sharing where the secret to be exchanged for computation is encrypted and retrieved by individual cloud at the end. Our scheme is based on the difficulty of solving the Discrete Logarithm problem (DLOG) in a finite abelian group of large prime order which is NP-Hard. So our proposed scheme provides <b>data</b> integrity <b>in</b> <b>transit,</b> <b>data</b> availability when one of host providers are not available during the computation. Comment: 8 pages, 3 Figures, International Journal of Research in Computer Science 2012. arXiv admin note: text overlap with arXiv: 1003. 3920 by other author...|$|R
50|$|Some multibooks are NSA {{certified}} to protect information classified Secret and below. They are approved for Suite B information/processing with <b>data</b> <b>in</b> <b>transit</b> (DIT) encryption protecting information when sent {{to and from}} classified networks.|$|E
5000|$|<b>Data</b> <b>in</b> <b>transit</b> {{is defined}} into two categories, {{information}} that flows over {{the public or}} untrusted network such as the internet and data which flows {{in the confines of}} a private network such as a corporate or enterprise Local Area Network (LAN).|$|E
50|$|Data in use {{has also}} been taken to mean “active data” {{in the context of}} being in a {{database}} or being manipulated by an application. For example, some enterprise encryption gateway solutions for the cloud claim to encrypt data at rest, <b>data</b> <b>in</b> <b>transit</b> and data in use.|$|E
40|$|Faults can corrupt <b>data</b> <b>in</b> storage, <b>in</b> <b>transit,</b> {{or during}} a computation. Like other digital systems, cryptosystems are {{vulnerable}} to natural and artificial faults. However, the effects of faults on cryptosystems far suppress the corruption of data. Attacks that exploit various classes of faults to learn secret data have been proposed and shown to be practical. As such, efficient detection and recovery of errors resulting from faults have a growing importance {{in the design of}} cryptosystems. We tackle the problem of error detection and recovery for transient faults in elliptic curve scalar multiplication structures. We propose the use of frequent validation with partial recomputation during the scalar multiplication for more efficient error detection and recovery. In our approach, the scalar multiplication iterations are grouped into blocks and efficient error detection schemes are used to detect errors early, which significantly limits the propagation of corrupted data. Moreover, we use the same error detection schemes, combined with partial recomputation, to achieve efficient error recovery without requiring complete time and hardware redundancy. Our analysis illustrates that these modifications enable considerably more efficient and reliable structures relative to known error detection and recovery designs. ...|$|R
40|$|There is {{a strong}} trend shift {{in the favor of}} {{adopting}} virtualization to get business benefits. The provisioning of virtualized enterprise resources is one kind of many possible scenarios. Where virtualization promises clear advantages it also poses new security challenges which need to be addressed to gain stakeholders confidence in the dynamics of new environment. One important facet of these challenges is establishing 'Trust' which is a basic primitive for any viable business model. The Trusted computing group (TCG) offers technologies and mechanisms required to establish this trust in the target platforms. Moreover, TCG technologies enable protecting of sensitive <b>data</b> <b>in</b> rest and <b>transit.</b> This report explores the applicability of relevant TCG concepts to virtualize enterprise resources securely for provisioning, establish trust in the target platforms and securely manage these virtualized Trusted Platforms. SMTV...|$|R
40|$|To {{ensure the}} {{confidentiality}} {{and integrity of}} <b>data</b> <b>in</b> storage and <b>transit,</b> various cryptography systems have been developed. Each of these systems has individual strengths and weaknesses. As the number of computer security threats increases, it becomes even more crucial to use methods of concealing {{the true meaning of}} data. This paper will look to strike a balance in providing details of how each of the methods works without explaining in so much detail that a casual reader will be completely lost. It is the goal of this paper to enlighten readers about the cryptography systems all around them and help them {{to gain a better understanding}} of how these systems work. The paper will then conclude with a brief discussion of what future advancements are likely to mean to current cryptography systems. Honors CollegeThesis (B. ?...|$|R
5000|$|CimTrak is {{constructed}} to follow software and communication security standards, and has government and IT security product certifications. Information stored within CimTrak is secure from external modification or access. Data at rest and <b>data</b> <b>in</b> <b>transit</b> are encrypted using the Cimcor Cryptographic Module, which has several certifications, including: ...|$|E
50|$|Although often erroneously {{assigned}} to the application layer, SSL {{is the most common}} method of securing application traffic through an ADN today. SSL uses PKI to establish a secure connection between the client and the ADN, making it difficult for attackers to decrypt the <b>data</b> <b>in</b> <b>transit</b> or hijack the session.|$|E
50|$|<b>Data</b> <b>in</b> <b>transit</b> is {{data that}} is being sent over a network. When the data is between two endpoints, any {{confidential}} information may be vulnerable to snooping. To maintain the confidentiality of the transmission, the payload (confidential information) can be encrypted to protect its confidentiality, {{as well as its}} integrity and non-repudiation.|$|E
40|$|This paper {{addresses}} {{the possibility that}} IP, {{in the role of}} the common service, is not as general as is needed in order to directly address application requirements, including scalable storage services, that go beyond simple datagram delivery. We propose to generalize the view of layer 2 to include local storage and processing services, and to situate a new common protocol between the local and network layers in the current network stack. Since a protocol at this layer would provide an abstraction of services for <b>data</b> that is <b>in</b> <b>transit</b> at the intermediate node, we propose to call it the transit layer Our view is that a transit layer protocol that abstracts the particular characteristics of different technologies at the local layer, while being more general and sitting below the network layer in the stack, would exhibit greater deployment scalability and provide a broader foundation for network interoperability than IP. We present an account of scalable storage middleware developed under the auspices of the Logistical Networking project as an overlay implementation of transit layer functionality over the current Internet 1...|$|R
40|$|Purpose: The {{purpose of}} this work is to develop an {{effective}} model for city transport system ecological state assessment using neural networks general concept. Methods : The proposed model is based on two neural networks work, {{taking into account the}} traffic density effect and the transit capacity level on urban areas. Results : Based on the synthesis of the fuzzy sets theory and neural networks basic principles, the city transport system ecological state assessing model is developed. The graphical representation of the model is given. A forecast reliability high degree is provided even at low learning rates and high dynamics of changing statistical <b>data</b> <b>in</b> the city <b>transit</b> traffic conditions. Conclusions : The use of fuzzy neural networks makes it possible to state a complete correspondence between fuzzy inference procedure mathematical representation and the urban transport system structure. The proposed model allows to formulate well-defined environmental guidelines when making decisions <b>in</b> the <b>transit</b> traffic field, taking into account the interests of enterprises, transport and the urban population, with the subsequent distribution of traffic flows in time and geographical space of the city industrial areas. </p...|$|R
30|$|With the {{evolution}} of distributed computing into the popular cloud paradigm, the aforementioned benefits of document storage {{have come to the}} forefront, considering its support for distributed storage and scalability at will. Cloud exploits this advantage by providing a more cost-efficient, outsourced database management solution that allows enterprises to easily store, manage, and process large volumes of data. Recently, many solutions, such as Mongolab [7], RavenHQ [8], and Cloudant [9] have been developed that commercially provide document-oriented storage in cloud. However, while considerable efforts are being made to enhance the performance and provide flexible scalability options, the more pressing issues of security in document-oriented databases seems to be largely absent from the research landscape (see Section 5). At best, most document databases provide role-based access control, which is coarse-grained, where users having the permission to read from or write to a database can apply the operation on the entire database. Even though this model of access control ensures authorized access, it leaves the database vulnerable to attacks from malicious insiders, which, {{according to a report by}} McAfee [10], poses a considerable threat. In addition, encryption of <b>data,</b> both <b>in</b> <b>transit</b> and at rest, is provided, using SSL for the former and third-party services for the latter (see Table 4). Moreover, there are no holistic solutions specifically tailored for document-oriented databases that fulfill all the security requirements. The recent breaches in cloud databases are a testament to their vulnerabilities [11 – 13].|$|R
