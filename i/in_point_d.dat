4|10000|Public
2500|$|As shown before, {{throttling}} keeps h constant. E.g. throttling from 200 bar and 300 K (point a in fig. 2) {{follows the}} isenthalp (line of constant specific enthalpy) of 430 kJ/kg. At 1 bar {{it results in}} point b which has a temperature of 270 K. So throttling from 200 bar to 1 bar gives a cooling from room temperature to below the freezing point of water. Throttling from 200 bar and an initial temperature of 133 K (point c in fig. 2) to 1 bar results <b>in</b> <b>point</b> <b>d,</b> {{which is in the}} two-phase region of nitrogen at a temperature of 77.2 K. Since the enthalpy is an extensive parameter the enthalpy in d (hd) is equal to the enthalpy in e (he) multiplied with the mass fraction of the liquid in d (xd) plus the enthalpy in f (hf) multiplied with the mass fraction of the gas in d (1 [...] xd). So ...|$|E
5000|$|... that is, the {{enthalpy}} {{per unit}} mass {{does not change}} during the throttling. The consequences of this relation can be demonstrated using the T-s diagram above. Point c is at 200 bar and room temperature (300 K). A Joule-Thomson expansion from 200 bar to 1 bar follows a curve of constant enthalpy of roughly 425 kJ/kg (not shown in the diagram) lying between the 400 and 450 kJ/kg isenthalps and ends <b>in</b> <b>point</b> <b>d,</b> which is at a temperature of about 270 K. Hence the expansion from 200 bar to 1 bar cools nitrogen from 300 K to 270 K. In the valve, {{there is a lot}} of friction, and a lot of entropy is produced, but still the final temperature is below the starting value! ...|$|E
5000|$|As shown before, {{throttling}} keeps h constant. E.g. throttling from 200 bar and 300 K (point a in fig. 2) {{follows the}} isenthalp (line of constant specific enthalpy) of 430 kJ/kg. At 1 bar {{it results in}} point b which has a temperature of 270 K. So throttling from 200 bar to 1 bar gives a cooling from room temperature to below the freezing point of water. Throttling from 200 bar and an initial temperature of 133 K (point c in fig. 2) to 1 bar results <b>in</b> <b>point</b> <b>d,</b> {{which is in the}} two-phase region of nitrogen at a temperature of 77.2 K. Since the enthalpy is an extensive parameter the enthalpy in d (hd) is equal to the enthalpy in e (he) multiplied with the mass fraction of the liquid in d (xd) plus the enthalpy in f (hf) multiplied with the mass fraction of the gas in d (1 &minus; xd). So ...|$|E
50|$|The {{exemption}} mentioned <b>in</b> <b>points</b> c, <b>d</b> and e only {{applies to}} weapons produced before January 1, 1945.|$|R
50|$|One can use {{estimated}} weights for {{the various}} data <b>points</b> <b>in</b> <b>d</b> based on a moving-variance estimation function ewt asfollows.|$|R
5000|$|Radon's theorem, that <b>d</b> + 2 <b>points</b> <b>in</b> <b>d</b> {{dimensions}} may {{always be}} partitioned into two subsets with intersecting convex hulls ...|$|R
40|$|The Euro VI Regulation (EC) No 595 / 2009 and the {{implementing}} Regulation [2] (EC) 582 / 2011 {{introduces a}} procedure for PEMS testing as a mandatory {{part of the}} type approval legislation in order to check the conformity of heavy-duty engines with the applicable emissions certification standards during the normal life of those engines: this is the so-called “In Service Conformity” (ISC) requirements. In addition, Euro VI engines also have to verify their actual in-use emissions already at type approval (PEMS demonstration test). Even if the PEMS procedure has already been introduced into legislation {{there is still a}} need for further evaluation and development. Article 14 (3) of the implementing regulation for Euro VI (EC) No 582 / 2011 states the following: “Any additional requirements with respect to off-cycle in-use vehicle testing referred to <b>in</b> <b>point</b> (<b>d)</b> of paragraph 1 shall be introduced after the assessment of the PEMS procedures set out in Annex II. The assessment shall be finalised by 31 December 2014. ” An assessment of the currently introduced PEMS procedure should therefore be carried out, and based on the outcome of this assessment; proposals for amending the PEMS procedure should be made. The European Commission through DG ENTR in co-operation with DG JRC launched in January 2012 a programme to address the legislative mandate to assess the present PEMS procedure. This report describes the activities during the programme, its findings and recommendations for amending the PEMS procedure. JRC. F. 8 -Sustainable Transpor...|$|E
5000|$|The {{number of}} lines through a fixed point p, not on a maximal arc K, {{intersecting}} K <b>in</b> <b>d</b> <b>points,</b> equals [...] Thus, d divides q.|$|R
30|$|Therefore {{the degree}} of the {{projection}} of H^- 1 (β) on the second coordinate is constant in C×D_r. It {{is easy to see}} that {{the degree of}} the projections is equal to the degree of the polynomial p, by looking at the number of intersections of H^- 1 (β) with the x-axis. The curve H(x-axis)={ (p(x),ax),x∈C} has d connected components inside V, all horizontal-like. The curve β is a vertical-like disk in V, hence β intersects H(x-axis) <b>in</b> exactly <b>d</b> <b>points,</b> which implies that H^- 1 (β) intersects the x-axis <b>in</b> <b>d</b> <b>points.</b>|$|R
40|$|This paper {{describes}} an improved algorithm for the multi-dimensional searching problem introduced by Megiddo. As a result, we obtain a d O(d) n time deterministic algorithms for linear programming in R d with n constraints, for computing the Euclidean 1 -center {{of a set}} of n <b>points</b> <b>in</b> R <b>d,</b> for computing the minimum enclosing ellipsoid {{of a set of}} n <b>points</b> <b>in</b> R <b>d,</b> etc. Our techniques also improve the running time of known algorithms for a number of parametric graph searching problems, including that of finding zero cycles in dynamic graphs [7]...|$|R
40|$|We {{show that}} in the worst case,Ω (n d) {{sidedness}} queries are required {{to determine whether a}} set of n <b>points</b> <b>in</b> IR <b>d</b> is affinely degenerate, i. e., whether it contains <b>d</b> + 1 <b>points</b> on a common hyperplane. This matches known upper bounds. Wegive a straightforward adversary argument, based on the explicit construction of a point set containingΩ (n d) "collapsible" simplices, anyoneof which can be made degenerate without changing the orientation of anyother simplex. As an immediate corollary,wehaveanΩ (n d) lower bound on the number of sidedness queries required to determine the order type of a set of n <b>points</b> <b>in</b> IR <b>d.</b> Using similar techniques, wealsoshowthatΩ (n d+ 1) in-sphere queries are required to decide the existence of spherical degeneracies in a set of n <b>points</b> <b>in</b> IR <b>d.</b> 1 Introduction A fundamental problem in computational geometry is determining whether a given set of <b>points</b> is <b>in</b> "general position. " A simple example of [...] ...|$|R
40|$|We {{show that}} in the worst case,ΩΓ n d) {{sidedness}} queries are required {{to determine whether a}} set of n <b>points</b> <b>in</b> IR <b>d</b> is affinely degenerate, i. e., whether it contains <b>d</b> + 1 <b>points</b> on a common hyperplane. This matches known upper bounds. We give a straightforward adversary argument, based on the explicit construction of a point set containingΩΓ n d) "collapsible" simplices, any one of which can be made degenerate without changing the orientation of any other simplex. As an immediate corollary, we have an ΩΓ n d) lower bound on the number of sidedness queries required to determine the order type of a set of n <b>points</b> <b>in</b> IR <b>d.</b> Using similar techniques, we also show thatΩΓ n d+ 1) in-sphere queries are required to decide the existence of spherical degeneracies in a set of n <b>points</b> <b>in</b> IR <b>d.</b> 1 Introduction A fundamental problem in computational geometry is determining whether a given set of <b>points</b> is <b>in</b> "general posi [...] ...|$|R
50|$|Every {{hyperplane}} intersects {{the moment}} curve in a finite set of at most <b>d</b> <b>points.</b> If a hyperplane intersects the curve <b>in</b> exactly <b>d</b> <b>points,</b> then the curve crosses the hyperplane at each intersection point. Thus, every finite point {{set on the}} moment curve is in general linear position.|$|R
40|$|International audienceThe Point Hyperplane Cover {{problem in}} R d takes as input {{a set of}} n <b>points</b> <b>in</b> R <b>d</b> and a {{positive}} integer k. The objective is {{to cover all the}} given points with a set of at most k hyperplanes. The D-Polynomial Points Hitting Set (D-Polynomial <b>Points</b> HS) problem <b>in</b> R d takes as input a family F of D-degree polynomials from a vector space R in R d, and determines whether there is a set of at most k <b>points</b> <b>in</b> R <b>d</b> that hit all the polynomials in F. For both problems, we exhibit tight kernels where k is the parameter...|$|R
40|$|Abstract. For <b>points</b> <b>in</b> <b>d</b> real dimensions, we {{introduce}} a geometry for general digit sets. We {{introduce a}} positional number system where {{the basis for}} our representation is a fixed d by d matrix over Z. Our starting point is a given pair (A, D) with the matrix A assumed expansive, and D a chosen complete digit set, i. e., in bijective correspondence with the <b>points</b> <b>in</b> Z <b>d</b> /A T Z d. We give an explicit geometric representation and encoding with infinite words in letters from D. We show that the attractor X(A T, D) for an affine Iterated Function System (IFS) based on (A, D) {{is a set of}} fractions for our digital representation of <b>points</b> <b>in</b> R <b>d.</b> Moreover our positional “number representation ” is spelled out {{in the form of an}} explicit IFS-encoding of a compact solenoid SA associated with the pair (A, D). The intricate part (Theorem 6. 15) is played by the cycles in Z d for the initial (A, D) -IFS. Using these cycles we are able to write down formulas for the two maps which do the encoding as well as the decoding in our positional D-representation...|$|R
40|$|Abstract. We generalize a theorem of Nymann {{that the}} density of <b>points</b> <b>in</b> Z <b>d</b> that are visible from the origin is 1 /ζ(d), where ζ(a) is the Riemann zeta {{function}} ∑∞ i= 1 1 /ia. A subset S ⊂ Z d is called primitive {{if it is a}} Z-basis for the lattice Z d ∩ spanR(S), or, equivalently, if S can be completed to a Z-basis of Z d. We prove that if m <b>points</b> <b>in</b> Z <b>d</b> are chosen uniformly and independently at random from a large box, then as the size of the box goes to infinity, the probability that the points form a primitive set approaches 1 /[ζ(d) ζ(d − 1) · · · ζ(d − m + 1) ]. 1...|$|R
40|$|This paper {{investigates the}} length of the longest {{monotone}} subsequence of a set of n <b>points</b> <b>in</b> R <b>d.</b> A sequence of <b>points</b> <b>in</b> R <b>d</b> is called monotone in R d if it is monotone with respect to some order from R d = f; g d, with other words if it is monotone in each dimension i 2 f 1; : : :; dg. The main result of this paper is the construction of a set P which has no monotone subsequences of length larger then dn 1 2 d 1 e. This generalizes to higher dimensions the Erd 7 ̆fos-Szekeres result that there is a 2 -dimensional set of n points which has monotone subsequences of length at most d p n e. ...|$|R
40|$|The {{so-called}} first selection lemma {{states the}} following: given any set P of n <b>points</b> <b>in</b> R <b>d,</b> {{there exists a}} <b>point</b> <b>in</b> R <b>d</b> contained in at least cdn d+ 1 − O(n d) simplices spanned by P, where the constant cd depends on d. We present improved bounds on the first selection lemma in R 3. In particular, we prove that c 3 ≥ 0. 00227, improving the previous best result of c 3 ≥ 0. 0016 by Wagner [Wag 03]. This makes progress, for the three dimensional case, on the open problems of Bukh, Matousek and Nivasch [BMN 10] (where it is proven that c 3 ≤ 1 / 4 4 ≈ 0. 0039) and Boros-Füredi [BF 84] (where the two-dimensional case was settled) ...|$|R
40|$|Let S be a {{data set}} of n <b>points</b> <b>in</b> R <b>d,</b> and ˆµ be a <b>point</b> <b>in</b> R <b>d</b> which “best ” {{describes}} S. Since the term “best ” is subjective, there exist several definitions for finding ˆµ. However, {{it is generally}} agreed that such a definition, or estimator of location, should have certain statistical properties which make it robust. Most estimators of location assign a depth value to any <b>point</b> <b>in</b> R <b>d</b> and define ˆµ to be a point with maximum depth. Here, new results are presented concerning the computational complexity of estimators of location. We prove that in R 2 the computation of simplicial and halfspace depth of a point requires Ω(n log n) time, which matches the upper bound complexities of algorithms by Rousseeuw and Ruts. Our lower bounds also apply to two sign tests, that of Hodges and that of Oja and Nyblom. In addition, we propose algorithms which reduce the time complexity of calculating the points with greatest Oja and simplicial depth. Our fastest algorithms use O(n 3 log n) and O(n 4) time respectively, compared to the algorithms of Rousseeuw and Ruts which use O(n 5 log n) time. One of our algorithms may {{also be used to}} find a point with minimum weighte...|$|R
40|$|We {{consider}} {{the relationship between}} renormalizability and unitarity at a Lifshitz <b>point</b> <b>in</b> <b>d</b> dimensions. We test tree unitarity for theories containing only scalars and fermions, and for pure gauge theory. In both cases, we find the requirement of weighted power-counting renormalizability is equivalent to that of tree unitarity. Comment: 12 pages, version published in Phys. Rev. ...|$|R
40|$|Edelsbrunner and Shah {{have proven}} that {{incremental}} topological flipping works for constructing a regular triangulation for a finite set of weighted <b>points</b> <b>in</b> <b>d</b> space. This paper describes the lexicographical manipulations employed in a recently completed implementation of their method for correctly computing 3 -dimensional regular triangulations. At {{the start of}} the execution of this implementation a regular triangulation for the vertices of an artificial cube that contains the points is constructed. Throughout the execution the vertices of this cube are treated in the proper lexicographical manner so that the final triangulation is correct. Key words. Delaunay triangulation, incremental topological flipping, power diagram, regular triangulation, Voronoi diagram. 1. Introduction Given integer k, 0 k d, and a set R of k + 1 affinely independent <b>points</b> <b>in</b> <b>d</b> space (R d), we say that the convex hull of R, denoted by Δ R, is the k [...] ...|$|R
5000|$|Let K be a maximal arc with degree d. Consider the {{incidence}} structure , where P contains all {{points of the}} projective plane not on K, B contains all line of the projective plane intersecting K <b>in</b> <b>d</b> <b>points,</b> and {{the incidence}} I is the natural inclusion. This is a partial geometry : [...]|$|R
40|$|International audienceThe Colorful Carathéodory theorem by Bárány (1982) {{states that}} given d + 1 sets of <b>points</b> <b>in</b> R <b>d,</b> the convex hull of each {{containing}} the origin, {{there exists a}} simplex (called a 'rainbow simplex') with at most one point from each point set, which also contains the origin. Equivalently, either there is a hyperplane separating one of these d + 1 sets of points from the origin, or there exists a rainbow simplex containing the origin. One of our results is the following extension of the Colorful Carathéodory theorem: given + 1 sets of <b>points</b> <b>in</b> R <b>d</b> and a convex object C, then either one set can be separated from C by a constant (depending only on d) number of hyperplanes, or there is a rainbow simplex intersecting C...|$|R
40|$|Giri Narasimhan Martin Zachariasen y Jianlin Zhu October 12, 1999 Abstract Let S be {{a set of}} n <b>points</b> <b>in</b> ! <b>d.</b> We {{present an}} {{algorithm}} that uses the well-separated pair decomposition and computes the minimum spanning tree of S under any L p or polyhedral metric. It has an expected running time of O(n log n) for uniform distributions. Experimental results show that this approach is practical. Under a variety of input distributions, the resulting implementation is robust and performs well for <b>points</b> <b>in</b> higher dimensional space. 1 Introduction Given a set S of n <b>points</b> <b>in</b> ! <b>d,</b> we refer to the Euclidean minimum spanning tree (EMST) of S as the minimum spanning tree (MST) of the complete graph on S with edge weights equal to the Euclidean distance between the points. If the edge weights are from a Minkowski or polyhedral metric, then we {{refer to it as}} the Geometric minimum spanning tree (GMST). EMST for <b>points</b> <b>in</b> the plane can be computed efficiently in O(n log n) time using [...] ...|$|R
40|$|The {{colorful}} Carathéodory theorem [Bár 82] {{states that}} given d + 1 sets of <b>points</b> <b>in</b> R <b>d,</b> the convex hull of each containing the origin, {{there exists a}} simplex (called a ‘rainbow simplex’) with at most one point from each point set, which also contains the origin. Equivalently, either there is a hyperplane separating one of these d + 1 sets of points from the origin, or there exists a rainbow simplex containing the origin. One of our results is the following extension of the colorful Carathéodory theorem: given ⌊d/ 2 ⌋ + 1 sets of <b>points</b> <b>in</b> R <b>d,</b> and a convex object C, then either one set can be separated from C by a constant (depending only on d) number of hyperplanes, or there is a ⌊d/ 2 ⌋-dimensional rainbow simplex intersecting C...|$|R
40|$|Let S be {{a set of}} n <b>points</b> <b>in!</b> <b>d.</b> We {{present an}} {{algorithm}} that uses the well-separated pair decomposition and computes the minimum spanning tree of S under any Lp or polyhedral metric. It has an expected running time of O(n log n) for uniform distributions. Experimental results show that this approach is practical. Under a variety of input distributions, the resulting implementation is robust and performs well for <b>points</b> <b>in</b> higher dimensional space...|$|R
40|$|Abstract. We develop several linear or near-linear {{space and}} I/Oefficient dynamic data {{structures}} for orthogonal range-max queries and stabbing-max queries. Given {{a set of}} N weighted <b>points</b> <b>in</b> <b>d,</b> the rangemax problem asks for the maximum-weight <b>point</b> <b>in</b> a query hyperrectangle. In the dual stabbing-max problem, we are given N weighted hyper-rectangles, and we wish to find the maximum-weight rectangle containing a query point. Our structures improve on previous structures in several important ways. ...|$|R
40|$|Abstract. In {{this paper}} we study the automorphisms group of some K 3 {{surfaces}} which are double covers of the projective plane ramified over a smooth sextic plane curve. More precisely, we study {{the case of}} a K 3 surface of Picard rank two such that there is a rational curve of degree d which is tangent to the sextic <b>in</b> <b>d</b> <b>points...</b>|$|R
40|$|A {{tensegrity}} is finite {{configuration of}} <b>points</b> <b>in</b> E <b>d</b> suspended rigidly by inextendable cables and incompressable struts. Here it is explained how a stress-energy function, {{given by a}} symmetric stress matrix, {{can be used to}} create tensegrities that are globally rigid {{in the sense that the}} only configurations that satisfy the cable and strut constraints are congruent copies. ...|$|R
40|$|We {{answer a}} {{question}} raised by P. Brass {{on the number of}} maximally repeated subpatterns in a set of n <b>points</b> <b>in</b> R <b>d.</b> We show that this number, which was conjectured to be polynomial, is in fact Θ(2 n/ 2) in the worst case, regardless of the dimension d. Key words: Discrete geometry, point sets, repeated configurations. ...|$|R
40|$|In {{orthogonal}} range reporting {{we are to}} preprocess N <b>points</b> <b>in</b> <b>d</b> dimensions {{such that}} the points inside an axis-aligned query box can be found efficiently. This is a fundamental problem in various fields, including spatial databases and computational geometry. In this paper we construct the first data structure for orthogonal range reporting in the I/O-model in higher dimensions and also significantly improve the best previous space lower bound...|$|R
40|$|We {{study the}} topologically twisted {{compactification}} of the 6 d (2, 0) M 5 -brane theory on an elliptically fibered Kähler three-fold preserving two supercharges. We show that upon reducing on the elliptic fiber, the 4 d theory is N= 4 Super-Yang Mills, with varying complexified coupling τ, {{in the presence}} of defects. For abelian gauge group this agrees with the so-called duality twisted theory, and we determine a non-abelian generalization to U(N). When the elliptic fibration is singular, the 4 d theory contains 3 d walls (along the branch-cuts of τ) and 2 d surface defects, around which the 4 d theory undergoes SL(2,Z) duality transformations. Such duality defects carry chiral fields, which from the 6 <b>d</b> <b>point</b> of view arise as modes of the two-form B in the tensor multiplet. Each duality defect has a flavor symmetry associated to it, which is encoded {{in the structure of the}} singular elliptic fiber above the defect. Generically 2 d surface defects will intersect <b>in</b> <b>points</b> <b>in</b> 4 <b>d,</b> where there is an enhanced flavor symmetry. The 6 <b>d</b> <b>point</b> of view provides a complete characterization of this 4 d- 3 d- 2 d- 0 d `Matroshka'-defect configuration. Comment: 62 pages, 4 figure...|$|R
40|$|For a set P of n <b>points</b> <b>in</b> R <b>d,</b> {{we define}} {{a new type}} of space decomposition. The new diagram {{provides}} an ε-approximation to the distance function associated with the Voronoi diagram of P, while being of near linear size, for d ≥ 2. This contrasts with the standard Voronoi diagram that has Ω � n ⌈d/ 2 ⌉ � complexity in the worst case. ...|$|R
40|$|In {{this paper}} we present an {{effective}} kinetic data structure and algorithm for efficient maintenance of convex hull of moving <b>points</b> <b>in</b> 2 <b>d</b> space. Given n <b>points</b> continuously moving <b>in</b> the plane we give an efficient algorithm for maintaining their convex hull. Our algorithm partitions the original points into several groups, each group’s points forming a convex polygon and the polygons are nested. 1...|$|R
50|$|A 1992 {{article by}} David Avis and Komei Fukuda {{presents}} an algorithm which finds the v vertices of a polytope {{defined by a}} nondegenerate system of n inequalities in d dimensions (or, dually, the v facets of the convex hull of n <b>points</b> <b>in</b> <b>d</b> dimensions, where each facet contains exactly <b>d</b> given <b>points)</b> <b>in</b> time O(ndv) and space O(nd). The v vertices in a simple arrangement of n hyperplanes in d dimensions {{can be found in}} O(n2dv) time and O(nd) space complexity. The Avis-Fukuda algorithm adapted the criss-cross algorithm for oriented matroids.|$|R
40|$|AbstractWe {{describe}} two data {{structures that}} preprocess a set S of n <b>points</b> <b>in</b> Rd (<b>d</b> constant) {{so that the}} sum of Euclidean distances of <b>points</b> <b>in</b> S to a query point q can be quickly approximated to within a factor of ε. This preprocessing technique has several applications in clustering and facility location. Using it, we derive an O(nlogn) time deterministic and O(n) time randomized ε-approximation algorithm for the so called Fermat–Weber problem in any fixed dimension...|$|R
