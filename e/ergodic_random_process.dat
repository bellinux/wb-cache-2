17|7633|Public
40|$|Abstract. In this paper, {{sufficient}} {{conditions are}} {{given for the}} existence of limiting distribution of a nonhomogeneous countable Markov chain with time-dependent transition intensity matrix. The method of proof exploits the fact that if the distribution of random process Q = (Qt) t� 0 is absolutely continuous with respect to the distribution of <b>ergodic</b> <b>random</b> <b>process</b> Q ◦ = (Q ◦ t) t� 0,then la...|$|E
40|$|We {{present a}} simple {{randomized}} procedure for {{the prediction of}} a binary sequence. The algorithm uses ideas from recent developments {{of the theory of}} the prediction of individual sequences. We show that if the sequence is a realization of a stationary and <b>ergodic</b> <b>random</b> <b>process</b> then the average number of mistakes converges, almost surely, to that of the optimum, given by the Bayes predictor. Prediction, ergodic processes, pattern classification...|$|E
40|$|We present simple {{procedures}} for the prediction of a real valued sequence. The algorithms {{are based on a}} combination of several simple predictors. We show that if the sequence is a realization of a bounded stationary and <b>ergodic</b> <b>random</b> <b>process</b> then the average of squared errors converges, almost surely, to that of the optimum, given by the Bayes predictor. We offer an analog result for the prediction of stationary gaussian processes. Sequential prediction, ergodic process, individual sequence, gaussian process...|$|E
3000|$|Users {{are placed}} uniformly on a {{circular}} cell. The channel state of each user {{is the product}} of two independent <b>ergodic</b> <b>random</b> <b>processes,</b> path loss and short-term fading. Path loss is polynomially dependent on the distance of the user from the access point and is assumed to remain constant for a users across transmission slots. The distance dependency is parametrized by the path loss exponent [...]...|$|R
40|$|In {{recent years}} optimal {{portfolio}} selection strategies for sequential investment {{have been shown}} to exist. Although their asymptotical optimality is well established, finite sample properties do need the adjustment of parameters that depend on dimensionality and scale. In this paper we introduce some nearest neighbor based portfolio selectors that solve these problems, and we show that they are also log-optimal for the very general class of stationary and <b>ergodic</b> <b>random</b> <b>processes.</b> The newly proposed algorithm shows very good finite-horizon performance when applied to different markets with different dimensionality or scales without any change: we see it as a very robust strategy...|$|R
40|$|A simple on-line {{procedure}} is {{considered for the}} prediction of a binary-valued sequence in the setup introduced and studied by Weissman and Merhav [13], [14], where only side information is available for the algorithm. The (non-randomized) algorithm {{is based on a}} convex combination of several simple predictors. If the side information is also binary-valued (i. e. original sequence is corrupted by a binary sequence) and both processes are realizations of stationary and <b>ergodic</b> <b>random</b> <b>processes</b> then the average of the loss converges, almost surely, to that of the optimum, given by the Bayes predictor. An analog result is offered for the classification of binary processes...|$|R
40|$|We {{present a}} simple {{randomized}} procedure for {{the prediction of}} a binary sequence. The algorithm uses ideas from recent developments {{of the theory of}} the prediction of individual sequences. We show that if the sequence is a realization of a stationary and <b>ergodic</b> <b>random</b> <b>process</b> then the average number of mistakes converges, almost surely, to that of the optimum, given by the Bayes predictor. The desirable finite-sample properties of the predictor are illustrated by its performance for Markov processes. In such cases the predictor exhibits near optimal behavior even without knowing the order of the Markov process. Prediction with side information is also considered...|$|E
40|$|The {{purpose of}} this work is to explore the role that {{arbitrage}} opportunities play in pricing financial derivatives. We use a non-equilibrium model {{to set up a}} stochastic portfolio, and for the random arbitrage return, we choose a stationary <b>ergodic</b> <b>random</b> <b>process</b> rapidly varying in time. We exploit the fact that option price and random arbitrage returns change on different time scales which allows us to develop an asymptotic pricing theory involving the central limit theorem for random processes. We restrict ourselves to finding pricing bands for options rather than exact prices. The resulting pricing bands are shown to be independent of the detailed statistical characteristics of the arbitrage return. We find that the volatility "smile" can also be explained in terms of random arbitrage opportunities. Comment: 14 pages, 3 fiqure...|$|E
40|$|Abstract—Nonparametric {{estimation}} {{capabilities of}} fuzzy systems in stochastic environments are analyzed in this paper. By using ideas from sieve estimation, increasing sequences of fuzzy rule-based systems, capable of consistently estimating regression surfaces in different settings, are constructed. Results include least squares learning of a mapping perturbed by additive random noise in a static-regression context and least squares learning of a regression surface from data {{generated by a}} bounded stationary <b>ergodic</b> <b>random</b> <b>process.</b> L 1 estimation is also studied, and the consistency of fuzzy rule-based sieve estimators for the L 1 -optimal regression surface is shown, thus giving additional theoretical support to the robust filtering capabilities of fuzzy systems and their adequacy for modeling, prediction and control of systems affected by impulsive noise. Index terms—fuzzy systems, nonparametric sieve estimation, consistency, least squares learning, robust learning 1 I. INTRODUCTION AND MOTIV...|$|E
50|$|In signal processing, the multitaper {{method is}} a {{technique}} developed by David J. Thomson to estimate the power spectrum SX of a stationary <b>ergodic</b> finite-variance <b>random</b> <b>process</b> X, given a finite contiguous realization of X as data. It {{is one of a}} number of approaches to spectral density estimation.|$|R
30|$|Higher order spectra, as {{spectral}} {{representations of}} cumulants or moments, are strictly valid only for <b>ergodic</b> <b>random</b> <b>processes.</b> These requirements are not satisfied by evoked EEG potentials. However, if a sufficiently small observation window in time is employed, {{the process can}} be assumed to be stationary within the window. The time of application of the stimulus serves as a reference. Windows at a given offset from this reference can be assumed to yield consistent averages over an ensemble if the speed of response does not vary. For spontaneous responses such as reaction to an auditory or visual stimulus this can be expected. For learned responses such as memory recall it may not hold true.|$|R
30|$|In this paper, {{we present}} a {{fundamental}} study on the stationarity and ergodicity of eight classes of sum-of-cisoids (SOC) processes for the modeling and simulation of frequency-nonselective mobile Rayleigh fading channels. The {{purpose of this study}} is to determine which classes of SOC models enable the design of channel simulators that accurately reproduce the channel’s statistical properties without demanding information on the time origin or the time-consuming computation of an ensemble average. We investigate the wide-sense stationarity, first-order stationarity of the envelope, mean ergodicity, and autocorrelation ergodicity of the underlying <b>random</b> <b>processes</b> characterizing the different classes of stochastic SOC simulators. The obtained results demonstrate that only the class of SOC models comprising cisoids with constant gains, constant frequencies, and random phases is defined by a set of stationary and <b>ergodic</b> <b>random</b> <b>processes.</b> The analysis presented here can easily be extended with respect to the modeling and simulation of frequency-selective single-input single-output (SISO) and multiple-input multiple-output channels. For the case of frequency-selective SISO channels, we investigate the stationarity and ergodicity in both time and frequency of 16 different classes of SOC simulation models. The findings presented in this paper can be used in the laboratory as guidelines to design efficient simulation platforms for the performance evaluation of modern mobile communication systems.|$|R
40|$|Abstract — We {{consider}} three capacity definitions {{for general}} channels with channel side {{information at the}} receiver, where the channel is modeled as a sequence of finite dimensional conditional distributions not necessarily stationary, ergodic, or information stable. The Shannon capacity is the highest rate asymptotically achievable with arbitrarily small error probability. The outage capacity is the highest rate asymptotically achievable with a given probability of decoder-recognized outage. The expected capacity is the highest expected rate asymptotically achievable with a single encoder and multiple decoders, where the channel side information determines the decoder in use. Expected capacity equals Shannon capacity for channels governed by a stationary <b>ergodic</b> <b>random</b> <b>process</b> but is typically greater for general channels. These alternative definitions essentially relax the constraint that all transmitted information must be decoded at the receiver. We derive equations for these capacity definitions through information density. Examples are also provided to demonstrate their implications. I...|$|E
40|$|During {{the last}} decade Seismic Interferometry or SI, has gained rapidly in {{popularity}} among academia and the industry. One application of SI is the retrieval of the Green’s function from the crosscorrelation of ambient seismic noise. Theory tells us that if uncorrelated noise sources illuminate the recording stations from all directions and if the noise generation is an <b>ergodic</b> <b>random</b> <b>process,</b> then the complete Green’s function, including the body wave reflection response and surface waves, is retrieved from the crosscorrelation-and-summation operation. If the noise is generated mainly by noise sources at or close to the Earth’s surface, then the crosscorrelation-and-summation operation will only retrieve the surface-wave part of the Green’s function. This is the case, for example, in many global and regional studies of surface wave tomography with ambient noise when energy in the primary and double-frequency-microseism bands, approximately between 0. 07 Hz and 0. 5 Hz, is used for correlations. For seismic exploration, the retrieval of body wave reflections is more desirable, as they afford the construction of subsurface velocity models and subsurface reflectio...|$|E
40|$|Abstract — Network {{connectivity}} is {{a critical}} metric for the planning, design, and evaluation of ad hoc networks. In this paper, the connectivity properties of a linear vehicular ad hoc network (VANET) with high speed mobile nodes and dynamic node populations are investigated. The nodes {{are assumed to be}} arriving at the network following a Poisson distribution, and the speed of each node is modeled as a wide sense stationary <b>ergodic</b> <b>random</b> <b>process.</b> Based on these assumptions, a new mobility model is developed to represent the steady state node distributions in terms of random node locations and random node populations. The mobility model accurately captures the statistical properties of a mobile network with rapidly changing network topologies and network densities. Exact closed-form connectivity probability expressions are developed {{with the assistance of the}} volume of an n-dimensional hypercube intersected by an n-dimensional hyperplane. The impacts of key network parameters, such as node arrival rate, random node speed, and node transmission range, are incorporated in the analytical expressions. The results can be used to determine the transmission power that can ensure network connectivity while minimizing interference in a VANET...|$|E
40|$|We {{consider}} {{the problem of}} clustering noisy finite-length observations of stationary <b>ergodic</b> <b>random</b> <b>processes</b> according to their generative models without prior knowledge of the model statistics {{and the number of}} generative models. Two algorithms, both using the $L^ 1 $-distance between estimated power spectral densities (PSDs) as a measure of dissimilarity, are analyzed. The first one, termed nearest neighbor process clustering (NNPC), relies on partitioning the nearest neighbor graph of the observations via spectral clustering. The second algorithm, simply referred to as $k$-means (KM), consists of a single $k$-means iteration with farthest point initialization and was considered before in the literature, albeit with a different dissimilarity measure. We prove that both algorithms succeed with high probability in the presence of noise and missing entries, and even when the generative process PSDs overlap significantly, all provided that the observation length is sufficiently large. Our results quantify the tradeoff between the overlap of the generative process PSDs, the observation length, the fraction of missing entries, and the noise variance. Finally, we provide extensive numerical results for synthetic and real data and find that NNPC outperforms state-of-the-art algorithms in human motion sequence clustering. Comment: 15 pages, 7 figure...|$|R
40|$|Published {{version of}} {{an article in the}} journal: EURASIP Journal on Wireless Communications and Networking. Also {{available}} from the publisher at: [URL] Open accessIn this paper, we present a fundamental study on the stationarity and ergodicity of eight classes of sum-of-cisoids (SOC) processes for the modeling and simulation of frequency-nonselective mobile Rayleigh fading channels. The {{purpose of this study is}} to determine which classes of SOC models enable the design of channel simulators that accurately reproduce the channel’s statistical properties without demanding information on the time origin or the time-consuming computation of an ensemble average. We investigate the wide-sense stationarity, first-order stationarity of the envelope, mean ergodicity, and autocorrelation ergodicity of the underlying <b>random</b> <b>processes</b> characterizing the different classes of stochastic SOC simulators. The obtained results demonstrate that only the class of SOC models comprising cisoids with constant gains, constant frequencies, and random phases is defined by a set of stationary and <b>ergodic</b> <b>random</b> <b>processes.</b> The analysis presented here can easily be extended with respect to the modeling and simulation of frequency-selective single-input single-output (SISO) and multiple-input multiple-output channels. For the case of frequency-selective SISO channels, we investigate the stationarity and ergodicity in both time and frequency of 16 different classes of SOC simulation models. The findings presented in this paper can be used in the laboratory as guidelines to design efficient simulation platforms for the performance evaluation of modern mobile communication systems...|$|R
40|$|This paper {{presents}} {{an analysis of}} the concept of capacity for noisy computations, i. e. algorithms implemented by unreliable computing devices (e. g. noisy Turing Machines). The capacity of a noisy computation is defined and justified by companion coding theorems. Under some constraints on the encoding process, capacity is the upper bound of input rates allowing reliable computation, i. e. decodability of noisy outputs into expected outputs. A model of noisy computation of a perfect function f thanks to an unreliable device F is given together with a model of reliable computation based on input encoding and output decoding. A coding lemma (extending the Feinstein's theorem to noisy computations), a joint source-computation coding theorem and its converse are proved. They apply if the input source, the function f, the noisy device F and the cascade f^{- 1 }F induce AMS and <b>ergodic</b> one-sided <b>random</b> <b>processes.</b> Comment: This paper has been submitted to the Information Theory Workshop 201...|$|R
40|$|In this paper, we outline a geostatistic {{method to}} {{simulate}} the relative precision (coefficient of variation, CV) of total abundance estimates of one species in a predetermined, stratified area when {{it is appropriate to}} treat the observations within each stratum as realizations of a second-order homogenous and <b>ergodic</b> <b>random</b> <b>process.</b> To model the spatial correlations, a variogram is fitted to normal-transformed values of the original observations. Based on the variogram and its corresponding covariance matrix, extensive simulations on a fine grid that includes the sample locations provide random realizations of the process. The normal values are back-transformed to original observation space by nonparametric reversed bootstrap, as well as by a parametric Weibull approach. The method is applied to a total of 1069 shrimp (Pandalus borealis) abundance observations from 11 annual surveys in the Barents Sea (1992 – 2002) where a 20 nautical mile sampling grid has been applied. On average, the CV was estimated to be 6. 4 % for the applied regular grid when the simulations were conditional on the observations, compared with 8. 1 % when the sampling locations within each of the six strata were random...|$|E
40|$|We {{consider}} three capacity definitions {{for general}} channels with channel side {{information at the}} receiver, where the channel is modeled as a sequence of finite dimensional conditional distributions not necessarily stationary, ergodic, or information stable. The Shannon capacity is the highest rate asymptotically achievable with arbitrarily small error probability. The capacity versus outage is the highest rate asymptotically achievable with a given probability of decoder-recognized outage. The expected capacity is the highest average rate asymptotically achievable with a single encoder and multiple decoders, where the channel side information determines the decoder in use. As a special case of channel codes for expected rate, the code for capacity versus outage has two decoders: one operates in the non-outage states and decodes all transmitted information, and the other operates in the outage states and decodes nothing. Expected capacity equals Shannon capacity for channels governed by a stationary <b>ergodic</b> <b>random</b> <b>process</b> but is typically greater for general channels. These alternative capacity definitions essentially relax the constraint that all transmitted information must be decoded at the receiver. We derive capacity theorems for these capacity definitions through information density. Numerical examples are provided to demonstrate their connections and differences. We also discuss th...|$|E
40|$|Abstract. The {{correlation}} method {{had once}} been considered {{as one of the}} best methods for the measurement of multiphase flow. However, if the behavior of flow does not fit the <b>ergodic</b> <b>random</b> <b>process,</b> the measured cross correlation plot will have a gross distortion when the different components of flow do not pervade within one another to the full extent. We measured a variety of parameters of three phase oil/water/gas flow in an oil pipeline. The change of flow pattern is so complex that the measured signals are always contaminated by stochastic noises. The weak signals are very easily covered by the noise so that it will result in great deviation. Wavelet transformation is an analytical method of both time and frequency domain. The method can achieve signal decomposition and location in time and frequency domain through adjustment and translation of scale. An LMS algorithm in wavelet transform is studied for denoising the signals based on the use of a novel smart capacitive sensor to measure three phase oil/water/gas flow in oil pipeline. The results of simulation and data processing by MATLAB reveal that wavelet analysis has better denoising effects for online measurement of crude oils with high measurement precision and a wide application range...|$|E
40|$|In this {{technical}} note, {{we provide}} a necessary and sufficient condition for convergence of consensus algorithms when the underlying graphs {{of the network}} are generated by an <b>ergodic</b> and stationary <b>random</b> <b>process.</b> We prove that consensus algorithms converge almost surely, if and only if, the expected graph of the network contains a directed spanning tree. Our results contain the case of independent and identically distributed graph processes as a special case. We also compute the mean and variance of the random consensus value that the algorithm converges to and provide a necessary and sufficient condition for {{the distribution of the}} consensus value to be degenerate...|$|R
40|$|A {{new class}} of derivative-free {{optimization}} algorithms is developed to solve, with remarkable efficiency, a range of practical nonconvex optimization problems whose function evaluations are computationally (or experimentally) expensive. These new algorithms, which are provably convergent under the appropriate assumptions, are response surface methods which iteratively minimize metrics based on an interpolation of existing datapoints and a synthetic model of the uncertainty of this interpolant, which itself is built on {{the framework of a}} Delaunay triangulation over the existing datapoints. Unlike other response surface methods, our algorithms can employ any well-behaved interpolation strategy. An important subproblem in α-DOGS is the estimation of the averaging process in stationary ergodic processes. A new approach for determining this quantity is also presented which is mathematically rigorous and numerically accurate. There are six main algorithms developed in this class thus far (only four of them are presented in this thesis) which address a wide range of practical optimization problems. The first algorithm, dubbed Δ-DOGS, efficiently minimizes expensive objective functions inside linearly-constrained feasible domains. The second algorithm, Δ-DOGS(C), extends Δ-DOGS to handle efficiently more general convex search domains. The third algorithm incorporates a grid into Δ-DOGS to achieve better convergence by performing fewer function evaluations at the boundary of feasibility. The fourth algorithm, dubbed α-DOGS, efficiently minimizes objective functions which are noisy, generally derived by taking the statistics of stationary and <b>ergodic</b> <b>random</b> <b>processes.</b> An important subproblem in α-DOGS is the estimation of the averaging process in stationary ergodic processes. A new approach for determining this quantity is also presented which is mathematically rigorous and numerically accurate. Rigorous convergence analyses of all of the algorithms proposed are presented, and necessary conditions to guarantee convergence to the global minimum are provided. For validation, the algorithms proposed have been tested on both well-known benchmark optimization problems as well as some new application-oriented optimization problems in ship design; some illustrative results will be shown...|$|R
40|$|Abstract — In this paper, {{we study}} {{the problem of}} dynamic {{allocation}} of heterogeneous processors to parallel heterogeneous job traffic flows. Each traffic flow is a stationary <b>ergodic</b> <b>random</b> marked point <b>process,</b> with a parameter (traffic intensity rate) {{that depends on the}} job class. The service rates of the various job flows depend on both the job class and the processor class. This model captures the essential features of several practical systems, including flexible manufacturing ones, packet switches, distribution systems, etc. We first specify precisely the necessary and sufficient condition for stability of the system. We then identify a family of policies that achieves maximum throughput; i. e. they stabilize the system under the maximum possible input rates. The approach taken introduces the concept of virtual queueing, which proves powerful in establishing strong probabilisti...|$|R
40|$|In {{this paper}} an {{analysis}} methodology is developed {{to evaluate the}} dynamic response on highway bridge decks due to vehicles crossing on the rough pavement surfaces. The analysis methodology follows a statistical model running in the time domain. The mathematical model simulates the bridge structure and the vehicle series as a system, the vehicle-bridge system. The bridge deck follows a straight beam model made discrete by finite elements and nodal concentrated masses, with vertical translations and in-plane rotations as degrees of freedom. The vehicle simulation uses concentrated parameters of mass, stiffness and damping. Four different types of vehicles are modelled as rigid masses connected by springs and dampers with one, two, four or five degrees of freedom. According to each vehicle model, translational and rotational displacements are considered. The deck surface roughness is defined by a weakly stationary, second order and <b>ergodic</b> <b>random</b> <b>process</b> based on a well-known power spectrum density of road pavement profiles. The moving load is modelled by an infinite series of equal vehicles, regularly spaced, and running at constant velocity. Only steady-state response is considered. Response data are produced on reinforced concrete highway bridge decks made of a straight box girder cross section based on several spans and support arrangements. Conclusions {{are concerned with the}} fitness of the developed analysis methodology and the mathematical model adequacy. The influence of the vehicle type on the highway bridge decks dynamic behaviour was observed. The magnitude of the effects due to the interaction of the vehicles with an irregular pavement surface and their consequences about design and maintenance are investigated. Peer Reviewe...|$|E
40|$|The {{objectives}} {{of this paper}} are to provide a systematic analytical approach to the synthesis of continuous nonlinear filters and to apply the results {{to a variety of}} problems, e. g., filtering of signals from noise, characterization of nonlinear systems, and the design of compensation networks for control systems. The problems are illustrated in Fig. 1. The work starts from the concept of a functional as the mathematical representative of a system. The optimum possible functional for any particular problem is approximated by a finite number of Volterra kernels. A typical question which the paper attempts to answer is:“Given an input (signal plus noise) which is a sample function from a stationary, <b>ergodic,</b> <b>random</b> <b>process</b> and using the mean-square error criterion, what is the optimum filter consisting of a finite number of Volterra kernels to filter the signal from the noise?” 11 A filter which consists of h 0, h 1, h 2, h 3, ···, hn is called a filter of degree n and sometimes will be denoted as. Every kernel hj is called a kernel of order j. Its corresponding filter is a filter of order j. This type of question leads to a set of simultaneous integral equations for which an iterative method of solution is provided. Examples and applications to filtering and control are discussed. Part II of the paper will describe an experimental application of the theory to the characterization of the servomechanism associated with the pupil of the human eye. A measure of the complexity of the experiment will be developed and the applicability of the method to real problems will be discussed from this point of view...|$|E
40|$|We {{consider}} three capacity definitions for composite channels with {{channel side}} {{information at the}} receiver. A composite channel consists {{of a collection of}} different channels with a distribution characterizing the probability that each channel is in operation. The Shannon capacity of a channel is the highest rate asymptotically achievable with arbitrarily small error probability. Under this definition, the transmission strategy used to achieve the capacity must achieve arbitrarily small error probability for all channels in the collection comprising the composite channel. The resulting capacity is dominated by the worst channel in its collection, no matter how unlikely that channel is. We, therefore, broaden the definition of capacity to allow for some outage. The capacity versus outage is the highest rate asymptotically achievable with a given probability of decoder-recognized outage. The expected capacity is the highest average rate asymptotically achievable with a single encoder and multiple decoders, where channel side information determines the channel in use. The expected capacity is a generalization of capacity versus outage since codes designed for capacity versus outage decode at one of two rates (rate zero when the channel is in outage and the target rate otherwise) while codes designed for expected capacity can decode at many rates. Expected capacity equals Shannon capacity for channels governed by a stationary <b>ergodic</b> <b>random</b> <b>process</b> but is typically greater for general channels. The capacity versus outage and expected capacity definitions relax the constraint that all transmitted information must be decoded at the receiver. We derive channel coding theorems for these capacity definitions through information density and provide numerical examples to highlight their connections and differences. We also discuss the implications of these alternative capacity definitions for end-to-end distortion, source-channel coding, and separation...|$|E
40|$|Theoretical and {{experimental}} {{work on a}} Universal Indicated Turbulence Meter is described. A mathematical transfer function from turbulence input to output indication was developed. A <b>random</b> <b>ergodic</b> <b>process</b> and a Gaussian turbulence distribution were assumed. A calibration technique based on this transfer function was developed. The computer contains a variable gain amplifier {{to make the system}} output independent of average velocity. The range over which this independence holds was determined. An optimum dynamic response was obtained for the tubulation between the system pitot tube and pressure transducer by making dynamic response measurements for orifices of various lengths and diameters at the source end...|$|R
40|$|Stochastically {{recursive}} sequences, service {{systems with}} the queue and random multiply access are {{considered in the}} paper aiming at the condition investigation of the ergodicity and stability of general stochastically recursive sequences and service nets. As a result new criteria of the capling - and strongcapling - convergences of stochastically recursive sequences have been obtainedas well as new criteria of the ergodicity and stability for service nets of Jackson's type and their generalizations. The coincidence of carrying capacity levels of random multiply access systems for centralized and decentralized algorithms from various classes has been proved. The paper results may find their field of application in <b>ergodic</b> theory of <b>random</b> <b>processes,</b> service system theory, in Russian Academy of Sciences Mathematical Institute, Siberian Department Mathematics Institute, Moscow State University, Novosibirsk SU, etcAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|International audienceIn ocean {{acoustic}} tomography (OAT) (especially {{in shallow water}} where raypaths are mixed), knowledge {{of the number of}} raypath is crucial for inversion algorithm. In this paper, a noise-whitening exponential fitting test (NWEFT) is presented in this context for detecting the number of raypaths. Classically, two suggested approaches are the Akaike information criterion (AIC) and the minimum description length (MDL). Based on ideal assumption of <b>ergodic</b> Gaussian <b>random</b> <b>processes</b> and white Gaussian noise, MDL is shown to be asymptotically consistent, whereas the AIC tends to overestimate the order of model. However, these assumptions could not be fulfilled in practical case of OAT. In order to be adapted for real case of OAT, noise whitening processing is applied as first step. Then, NWEFT bases {{on the fact that the}} profile of the ordered eigenvalues fits an exponential law for short-length samples of white Gaussian noise. The number of raypaths could be detected when a mismatch occurs between observed profile and exponential model. The fact that NWFET works on short-length samples is very important as a long duration of the received signal in OAT is unavailable. Its performance is studied with synthetic and real data set and compared with classical algorithms...|$|R
40|$|The {{availability}} of minicomputers and microprocessors, {{at a reasonable}} cost, has provided a significant stimulus in a critical appraisal of fatigue testing and analysis methods. This thesis reviews and extends {{some of the recent}} fatigue analysis methods. Two major areas investigated in detail are cycle counting methods and methods for prediction of fatigue life to crack initiation. The three recent counting methods, range-pair, Wetzel's and rainflow, which avoid the distortion and inaccuracy from which the traditional cycle counting methods suffer, are described and compared with each other to find out the similarities and differences between them. It is shown that if a service loading history starts and ends at an extreme peak, then all the three methods give an identical count. All relevant methods for the description of measured service histories are reviewed critically in connection with fatigue life assessment, service history regeneration and simulation. Confidence in the rainflow method for better fatigue life predictions and increased use of analytical methods like Finite Element analysis offering frequency domain information about a component have initiated a search for a link between rainflow counting and the power spectral density of a stationary and <b>ergodic</b> <b>random</b> <b>process.</b> Using a Monte Carlo approach and digital simulation techniques, the thesis presents a link {{in the shape of a}} closed-form expression which defines the probability density function of rainflow counted ranges for any given power spectral density. A closed-form expression for the distribution of ordinary ranges is also presented. Methods of predicting fatigue crack initiation life under variable amplitude loading are reviewed. From the basic ingredients of the local-strain approach, various life prediction procedures are assembled methodically with regard to how the local stress and strain are determined for a given load level, how the local stress and strain are linked to the life, and how the mean stress effect is accounted for. Predictions made by these methods are compared with the published test data; however predictions are compared mostly within themselves in order to highlight the differences between methods. It is shown that under certain circumstances, some methods give very erroneous results. A sensitivity analysis is carried out to examine how sensitive various methods are to changes in the material properties. A new procedure of determining the material properties from the experimental data is proposed...|$|E
40|$|We {{study the}} {{structure}} of the ergodic limit functions determined in <b>random</b> <b>ergodic</b> theorems. When the r random parameters are shifted by the -shift transformation with, the major finding is that the (<b>random)</b> <b>ergodic</b> limit functions determined in <b>random</b> <b>ergodic</b> theorems depend essentially only on the random parameters. Some of the results obtained here improve the earlier <b>random</b> <b>ergodic</b> theorems of Ryll-Nardzewski (1954), Gladysz (1956), Cairoli (1964), and Yoshimoto (1977) for positive linear contractions on and Woś (1982) for sub-Markovian operators. Moreover, applications of these results to nonlinear <b>random</b> <b>ergodic</b> theorems for affine operators are also included. Some examples are given for illustrating the relationship between the ergodic limit functions and the random parameters in <b>random</b> <b>ergodic</b> theorems...|$|R
40|$|Of central {{interest}} {{in the study of}} random walks on finite groups are <b>ergodic</b> <b>random</b> walks. <b>Ergodic</b> <b>random</b> walks converge to random in the sense that as the number of transitions grows to infinity, the state-distribution converges to the uniform distribution on G. The study of random walks on finite groups is generalised to the study of random walks on quantum groups. Quantum groups are neither groups nor sets and rather what are studied are finite dimensional algebras that have the same properties as the algebra of functions on an actual group — except for commutativity. The concept of a random walk converging to random — and a metric for measuring the distance to random after k transitions — is generalised from the classical case to the case of random walks on quantum groups. A central tool in the study of <b>ergodic</b> <b>random</b> walks on finite groups is the Upper Bound Lemma of Diaconis and Shahshahani. The Upper Bound Lemma uses the representation theory of the group to generate upper bounds for the distance to random and thus can be used to determine convergence rates for ergodic walks. The representation theory of quantum groups is very well understood and is remarkably similar to the representation theory of classical groups. This allows for a generalisation of the Upper Bound Lemma to an Upper Bound Lemma for quantum groups. The Quantum Diaconis–Shahshahani Upper Bound Lemma is used to study the convergence of <b>ergodic</b> <b>random</b> walks on classical groups Zn, Z n 2, the dual group Scn as well as the ‘truly’ quantum groups of Kac and Paljutkin and Sekine. Note that for all of these generalisations, restricting to commutative subalgebras gives the same definitions and results as the classical theory...|$|R
40|$|Abstract — Capacity {{results for}} Gaussian matrix {{channels}} are investigated where the receiver has {{knowledge of the}} channel realization and the transmitter has knowledge only of the channel statistics. We extend beamforming results and examine arbitrary <b>ergodic</b> <b>random</b> vector channels, {{under the condition that}} the transmit covariance is independent of the channel...|$|R
40|$|Abstract. We study <b>ergodic</b> <b>random</b> Schrödinger {{operators}} on {{a covering}} manifold, where the randomness enters both via the potential and the metric. We prove measurability of the random operators, almost sure constancy of their spectral properties, {{the existence of}} a selfaveraging integrated density of states and a ˇ Subin type trace formula. 1...|$|R
40|$|We {{consider}} a bounded step size random walk in an <b>ergodic</b> <b>random</b> environment with some ellipticity, on an integer lattice of arbitrary dimension. We prove a level 3 large deviation principle, under almost every environment, with rate function {{related to a}} relative entropy. Comment: Proof of (6. 2) corrected. Lemma A. 2 replace...|$|R
