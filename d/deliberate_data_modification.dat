0|1184|Public
50|$|Scrollable cursors can {{potentially}} access the same {{row in the}} result set multiple times. Thus, <b>data</b> <b>modifications</b> (insert, update, delete operations) from other transactions could affect the result set. A cursor can be SENSITIVE or INSENSITIVE to such <b>data</b> <b>modifications.</b> A sensitive cursor picks up <b>data</b> <b>modifications</b> affecting the result set of the cursor, and an insensitive cursor does not. Additionally, a cursor may be INSENSITIVE, {{in which case the}} DBMS tries to apply sensitivity as much as possible.|$|R
40|$|We study {{large-scale}} classification {{problems in}} changing environments {{where a small}} part of the dataset is modified, and the effect of the <b>data</b> <b>modification</b> must be quickly incorporated into the classifier. When the entire dataset is large, even if the amount of the <b>data</b> <b>modification</b> is fairly small, the computational cost of re-training the classifier would be prohibitively large. In this paper, we propose a novel method for efficiently incorporating such a <b>data</b> <b>modification</b> effect into the classifier without actually re-training it. The proposed method provides bounds on the unknown optimal classifier with the cost only proportional to the size of the <b>data</b> <b>modification.</b> We demonstrate through numerical experiments that the proposed method provides sufficiently tight bounds with negligible computational costs, especially when {{a small part of}} the dataset is modified in a large-scale classification problem...|$|R
40|$|This paper {{presents}} the first DBMS for uncertain data that incorporates <b>data</b> <b>modifications</b> {{and a simple}} versioning system. Our work is {{in the context of}} Trio, a project at Stanford for managing data uncertainty and lineage. We establish SQL-based language constructs for <b>data</b> <b>modifications,</b> and an extended data model ULDBv that supports these modifications yielding versioned relations. We show that Trio’s lineage feature enables answering a wide class of queries over ULDBvs efficiently. We also give algorithms that leverage ULDBv’s lineage for propagat-ing data-modifications to Trio’s derived relations efficiently and incrementally. We have incorporated the <b>data</b> <b>modification</b> and versioning capabilities in the Trio system, and we validate our techniques through experiments. I...|$|R
5000|$|So-called [...] {{operation}} mode for the MySQL server, which disables <b>data</b> <b>modification</b> operations even for privileged database accounts ...|$|R
50|$|Phase 3: Further {{segmentation}} and <b>data</b> <b>modification</b> {{will continue}} in collaboration with clinical researchers until sufficient concept coverage is achieved.|$|R
40|$|In {{the past}} decades, focus of {{computation}} {{has shifted to}} high performance computing like Grid Computing and Cloud Computing. In Grid computing, grid server is responsible for managing the all resources like processor, memory and CPU cycles. Grids are basically networks that pool resources, CPU cycles, storage or data from many different nodes used to solve the complex or scientific problem. However in this case, security is a major concern. Even most grid security researches focus on user authentication, authorization and secure communication. This paper presents DDoS and <b>Data</b> <b>Modification</b> attack scenario and also provides the solution to prevent it. In case of <b>data</b> <b>modification</b> attack, it shows how easy to read/forward/modify the data exchanged between a cluster head node and computing nodes. Therefore this paper provides the solution to protect the grid computing environment against <b>Data</b> <b>Modification</b> and DDOS attack...|$|R
5000|$|When {{compared}} to the <b>data</b> <b>modification</b> example above, [...] conversion option is not required as it has no effect when the dd's output file is a block device.|$|R
40|$|Privacy {{preserving}} {{data mining}} and statistical disclosure control {{have received a}} great deal of attention during the last few decades. Existing techniques are generally classified as restriction and <b>data</b> <b>modification.</b> Within <b>data</b> <b>modification</b> techniques noise addition has been one of the most widely studied but has traditionally been applied to numerical values, where the measure of similarity is straightforward. In this paper we introduce VICUS, a novel privacy preserving technique that adds noise to categorical data. Experimental evaluation indicates that VICUS performs better than random noise addition both in terms of security and data quality...|$|R
5000|$|An {{encryption}} algorithm used for data storage has to support independent encryption and decryption of portions of data. So-called narrow-block algorithms operate on relatively small portions of data, while the wide-block algorithms encrypt or decrypt a whole sector. Narrow-block algorithms {{have the advantage}} of more efficient hardware implementation. On the other hand, smaller block size provides finer granularity for <b>data</b> <b>modification</b> attacks. There is no standardized [...] "acceptable granularity"; however, for example, the possibility of <b>data</b> <b>modification</b> with the granularity of one bit (bit-flipping attack) is generally considered unacceptable.|$|R
30|$|The data {{integrity}} attack includes <b>data</b> <b>modification</b> attack, <b>data</b> corruption attack and data insertion attack. The integrity service assures the transmitted data is not modified by an unauthorized entity.|$|R
30|$|Berkovsky et al. [16] {{present a}} {{decentralized}} distributed storage of user data combined with <b>data</b> <b>modification</b> techniques to mitigate privacy issues. Tada et al. presented a privacy-preserving item-based collaborative filtering scheme in [17].|$|R
50|$|Firebird has {{the same}} syntax in <b>Data</b> <b>Modification</b> Language {{statements}} (DSQL); the statement may add at most one row. In stored procedures, triggers and execution blocks (PSQL) the aforementioned Oracle syntax is used.|$|R
30|$|Privacy {{preserving}} {{data mining}} (PPDM) is {{a rapidly growing}} research area aiming at eliminating privacy breaches which may happen during the mining of data (Verykios et al. 2004; Kantarcioglu et al. 2004; Clifton 2009). The goal of PPDM algorithm is to alter the original data {{for the purpose of}} maintaining privacy, leading to a low degree of data leakage. This will give way for obtaining good mining results. The work introduced in (Verykios et al. 2004) observes the PPDM approach in the light of five different dimensions. They are <b>data</b> distribution, <b>data</b> <b>modification,</b> <b>data</b> mining algorithm, data or rule hiding and privacy preservation. Data distribution represents the organization of data that can be centralized or in a distributed fashion. The second step <b>data</b> <b>modification</b> refers to modifying the data.|$|R
5000|$|Audit Trail/DCAA Compliance: Automatically log all {{changes to}} labor and cost {{accounting}} data, facilitating compliance with Sarbanes-Oxley and the Defense Contract Audit Agency (DCAA). ClickTime has a DCAA Compliance setting which tracks user explanations for <b>data</b> <b>modifications.</b>|$|R
40|$|Abstract. Data {{perturbation}} is {{a method}} of reference control in statistical database. <b>Data</b> <b>modification</b> and <b>data</b> swapping are two methods of <b>data</b> perturbation. <b>Data</b> <b>modification</b> replaces the original data with the sample data sequence after deciding probability distribution function of the original data and generating sample data sequence. Data swapping interchanges attribute values of records. While the algorithm of the former is complex, this paper presents a new method in which the sample sequence generation is skipped. We simply sort the original data, divide them into different groups and exchange attribute values of the same group. Experiment show that the proposed method can effectively simplify the former method and guarantee {{the safety of the}} statistical data at the same time...|$|R
30|$|Operations on {{the data}} are simple and limited: there are put, get and delete {{commands}} [10, 60]. In this sense, Voldemort can be considered (as the developers themselves put it), “basically just a big, distributed, persistent, fault-tolerant hash table” [59]. For <b>data</b> <b>modification,</b> the MVCC mechanism is used [10].|$|R
5000|$|... p (preserve) [...] - [...] the p flag {{preserves}} the following characteristics of each source {{path in the}} corresponding target: {{the time of the}} last <b>data</b> <b>modification</b> and the time of the last access, the ownership (only if it has permissions to do this), and the file permission-bits.|$|R
40|$|Abstract — Abstract-Cloud {{computing}} {{has evolved}} from virtualization, utility computing and client-server architectures and {{is an extension of}} service oriented architectures. It has been referred to as a disruptive technology which has implications on a host of issues such as licensing, scalability, cost and performance measures, privacy and security. We propose in this paper a flexible distributed storage integrity auditing mechanism, utilizing the homomorphic token and distributed erasure-coded data. Our method achieves the integrity of storage correctness guaranty and identification of misbehaving servers i. e. whenever <b>data</b> <b>modifications</b> or deletions have been detected during the storage correctness verification and error localization across cloud servers. The performance analysis shows that our scheme is more secure than existing system against Byzantine failure, unauthorized <b>data</b> <b>modification</b> attacks, and even cloud server colluding attacks...|$|R
50|$|Historically, {{encryption}} modes {{have been}} studied extensively in regard to their error propagation properties under various scenarios of <b>data</b> <b>modification.</b> Later development regarded integrity protection as an entirely separate cryptographic goal. Some modern modes of operation combine confidentiality and authenticity in an efficient way, and are known as authenticated encryption modes.|$|R
40|$|Abstract [...] -In this paper, a {{new data}} {{encoding}} scheme is proposed called layered interleaving. It provides good security. Thus, this extensive security {{and analysis of}} the performance shows that the proposed scheme is highly effective and efficient against Byzantine failure, the malicious <b>data</b> <b>modification</b> attacks, and server colluding attacks...|$|R
5000|$|Once a cache {{group is}} defined, the cache group {{can then be}} [...] "loaded", {{allowing}} Oracle Database data to be cached in TimesTen. Applications can then read from and write to cache groups, and all <b>data</b> <b>modifications</b> will then be synchronized with the corresponding Oracle database tables either automatically or manually.|$|R
40|$|It is well {{recognised}} {{that data}} mining and statistical analysis pose a serious treat to privacy. This {{is true for}} financial, medical, criminal and marketing research. Numerous techniques have been proposed to protect privacy, including restriction and <b>data</b> <b>modification.</b> Recently proposed privacy models such as differential privacy and k-anonymity {{received a lot of}} attention and for the latter there are now several improvements of the original scheme, each removing some security shortcomings of the previous one. However, the challenge lies in evaluating and comparing privacy provided by various techniques. In this paper we propose a novel entropy based security measure that can be applied to any generalisation, restriction or <b>data</b> <b>modification</b> technique. We use our measure to empirically evaluate and compare a few popular methods, namely query restriction, sampling and noise addition. Comment: 20 pages, 4 figure...|$|R
40|$|In {{the last}} decade, {{more and more}} {{researches}} have focused on privacy-preserving data min ing(PPDM). The previous work can be div ided into two categories: <b>data</b> <b>modification</b> and <b>data</b> encryption. Data encryption is not used as widely as data modificat ion because of its high cost on computing and communications. Data perturbation, including additive noise, mult iplicative noise, matrix multip lication, data swapping, data shuffling, k-anonymization, Blocking, is an important technology in <b>data</b> <b>modification</b> method. PPDM has two targets: privacy and accuracy, and they are often at odds with each other. Th is paper begins with a proposal of two new noise addition methods for perturbing the original data, followed by a discussion of how they meet the two targets. Experiments show that the methods given in this paper have higher accuracy than existing ones under the same condition of privacy strength...|$|R
50|$|Arrays {{are passed}} by reference, and this {{mechanism}} is an advertised {{feature of the}} language to pass data back out of a subroutine - in contrast, array slices are copied before being passed, so that <b>data</b> <b>modifications</b> do not flow back into array ranges (after the subroutine exits), violating the principle of least surprise.|$|R
40|$|Abstract. Stone Materials Information System use ActionScript {{to connect}} SQLite database. Information of stone materials, transaction, customer, {{employee}} {{can be stored}} by system. Several database tables are created in the system. Functions are used to complete <b>data</b> <b>modification</b> operations. Stone Materials Information System provides convenience for stone material transactions between the manufacturer and the customer...|$|R
5000|$|Given any pair of subvolumes (or snapshots), Btrfs can {{generate}} a binary diff between them (by using the [...] command) {{that can be}} replayed later (by using [...] ), possibly on a different Btrfs file system. The send/receive feature effectively creates (and applies) a set of <b>data</b> <b>modifications</b> required for converting one subvolume into another.|$|R
3000|$|Traditionally, {{watermarking}} was {{preferred to}} preserve the data privacy. It works on serving to the agents after performing <b>data</b> <b>modifications.</b> If the <b>data</b> are discovered {{in the hands of}} an unauthorized agent (who is a malicious recipient), then the watermarks can be destroyed. Thus, in support of privacy by probability some best approaches are presented here, as follows: [...]...|$|R
40|$|A system {{security}} policy is often {{perceived as a}} set of mandatory requirements levied upon the system by an organizational directive or Information System Security Officer (ISSO). To the user, these security requirements may bear little resemblance to his actual working {{system security}} policy, which controls <b>data</b> <b>modification</b> and user privileges. In the course of reengineering business processes an...|$|R
40|$|Abstract — In recent years, {{wireless}} {{networks have}} gained rapid popularity. Wireless networks are inexpensive and provides mobility {{but they are}} prone {{to a variety of}} threats like denial of service, replay attacks, eavesdropping and <b>data</b> <b>modification.</b> This paper discusses the three wireless security protocols with details about the encryption methods used, authentication mechanisms and their limitations...|$|R
40|$|We {{study the}} problem of {{efficiently}} evaluating transactions that automatically invoke the execution of (deferred) database triggers {{at the end of}} the transaction. In particular, we consider an important class of triggers which may express arbitrary integrity constraints and alerters. Their event part specifies <b>data</b> <b>modifications,</b> their condition part is an arbitrary database query, and their action part can raise some alerts, issue a rollback, or "repair" the <b>data</b> <b>modification</b> that triggered the rule. An update transaction that invokes such deferred trigger(s) reads (and locks) new database items before committing. These read operations may entail inter-transactions blockings, thereby degrading the performance of active database applications. We propose a slight extension of the classical multiversion two phase locking (MV 2 PL) protocol whereby these reads access versions and do not take locks. We prove the correctness of this protocol, and show that its implementation requires very f [...] ...|$|R
5000|$|<b>Deliberate</b> {{suppression}} of <b>data,</b> including evidence from clinical trials, that reveal {{adverse effects of}} the medicine.|$|R
40|$|An exact {{one-dimensional}} {{condensation heat}} transfer model for insoluble gases {{has been developed}} and compared with experimental <b>data.</b> <b>Modifications</b> to this model to accommodate soluble gas behavior have also been accomplished, and the effects on gas front behavior demonstrated. Analytical models for condensation heat transfer are documented, and a novel optical method used for measuring gas concentration profiles is outlined...|$|R
50|$|Some {{systems support}} the {{definition}} of INSTEAD OF triggers on views. This technique allows {{the definition of}} other logic for execution in place of an insert, update, or delete operation on the views. Thus database systems can implement <b>data</b> <b>modifications</b> based on read-only views. However, an INSTEAD OF trigger {{does not change the}} read-only or updatable property of the view itself.|$|R
30|$|The Data Safty Monitoring Committee <b>deliberates</b> the <b>data</b> from {{intermediate}} {{safety analysis}} report and contacts the Trial Steering Committee. Interim results are extremely secret and {{once one of}} the three groups shows a distinct advantage over others, the committee will counsel to end the study ahead of schedule.|$|R
30|$|This {{database}} uses a B-tree index [10], updated during <b>data</b> <b>modifications.</b> These modifications have ACID properties on {{the document}} {{level and the}} use of MVCC (Multi-Version Concurrency Control) enables readers to never block [10]. CouchDB’s document manipulation uses optimistic locks by updating an append-only B-tree for data storage, meaning that data must be periodically compressed. This compression, in spite of maintaining availability, may hinder performance [10].|$|R
40|$|A more exact {{one-dimensional}} {{condensation heat}} transfer model for insoluble gases {{was developed and}} compared with experimental <b>data.</b> <b>Modifications</b> to this model to accommodate soluble gas behavior were also accomplished, and the effects on gas front behavior demonstrated. Analytical models for condensation heat transfer are documented, and an optical method used for measuring gas concentration profiles is outlined. Experimental data is then presented and interpreted...|$|R
