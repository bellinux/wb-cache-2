60|8|Public
40|$|This paper {{presents}} a methodology for assessing TSS wet weather event load {{along with the}} associated uncertainties from continuous turbidity measurements. The proposed method is applied to dozens of rainfall events sampled on various urban catchments in the cities of Paris and Nantes. This method {{takes into account the}} dependency between the residual errors made by converting the turbidity values into TSS concentrations using an average TSS-turbidity relationship. Results obtained indicate that the inter-event variations of TSS-turbidity relationships induce significant systematic errors on TSS event loads which can reach ± 30 % of the average TSS event load. Cet article présente une méthodologie pour <b>estimer</b> la charge en suspension durant un éÎnement pluvial...|$|E
40|$|Blind {{separation}} of sources consists in recovering {{a set of}} statistically independent signals whose only instantaneous mixtures are observed. Such mixtures occur in narrow band array data which can then be processed without knowing the array manifold (blindness). This paper introduces a new source separation technique exploiting the possible time coherence of the source signals. In contrast to other previously reported techniques, the proposed approach relies only on second-order statistics, being based on a `joint diagonalization' of correlation matrices. The effectiveness of the method in difficult contexts is illustrated by numerical simulations. 1 Introduction L'approche dite de s'eparation aveugle de sources consiste `a <b>estimer</b> les signaux sources sans information a priori sur la forme du front d'onde ou la g'eom'etrie de l'antenne. Ce probl`eme a d'ej`a fait l'objet de nombreux travaux qui n'exploitent que la structure spatiale instantan'ee du processus en utilisant les statisti [...] ...|$|E
40|$|ABSTRACT. A {{study to}} {{estimate}} nitrogen fixation input. in arctie c m t d tundra {{was carried out}} using the acetylene reduction assay. Areal estimation was attempted by high intensity sampling over a limited area of tundra containing both high-centred and low-centred polygons with their corresponding variations in micro-vegetation. The highest average rates of acetylene reduction were obtained from cores in damp interpolygonal troughs (10. 50 pmoles ethylene/m. z-hr) where mats of the blue-green alga Nostoc were abundant. Wet moss-algal associations in hydric meadows showed high nitrogenase activity (average 6. 86 pmoles ethylene/m. z-hr) and dry high-centred polygons were comparatively inactive (average 2. 80 moles ethylene/m. z-hr). The lichens Peltigera sp. and Stereocaulon sp. were the most active nitrogen fixers in the drier tundra. Nitrogen fixation increased with rising temperature with a measured Ql 0 for Nostoc commune of 3. 7. RÉSUMÉ: Fixation de l'azote dans la toundra côti 2 re arctique, par rapport à la végétation et au micro-relief. Les auteurs ont mené une étude pour <b>estimer</b> l'apport d'azote fixé dans la toundra côtière arctique, par le titrage de la réduction pa...|$|E
40|$|In {{cellular}} communication systems, {{the estimation}} of Doppler spread has {{a wide range of}} applications such as handoff, channel assignment scheme, adaptivetransmission, power control, etc. A great quantity of Doppler spread estimation algorithms have been proposed in the literature. But there has been few investigations which gives a comprehensive comparison of these algorithms. Therefore, it is of great signicance to compare and evaluate the performance of the existing algorithms in the same simulation framework. In this report, the uplink of WCDMA is considered. Four different types of Doppler spread estimation algorithms are evaluated and compared in a link level baseband simulator. The performance and the ability to implement are considered as the metrics for evaluation. Both Rayleigh and Rician fading channel model are applied, and the effect of speed, signal to noise ratio, Rician factor and the angle of arrived line of sight component are also tested. Moreover, the computational complexity is analysed to evaluate the practical value for implementation. Estimatering av en mobils hastighet i form av Dopplerspridning har ett brett spektrum av tillmpningar i cellulra kommunikationssystem ssom fr yttningen avmobiler mellan celler, kanaltilldelningsschema, adaptiv sndning, eektstyrning,etc. En stor mngd algoritmer fr <b>estimering</b> av Dopplerspriding har frslagitsi litteraturen, men det r ovanligt med heltckande jmfrelser mellan med dessaalgoritmer. Drfr r det av stor betydelse att jmfra och utvrdera resultaten avbentliga algoritmer inom ramen fr samma simuleringsvertyg. I denna rapport anvnds upplnken fr WCDMA fr utvrdering av fyra olikatyper av algoritmer fr <b>estimering</b> av Dopplerspridning. Metriker fr utvrderingenr prestanda och implementeringsvnlighet. Bde Rayleigh och Rician fdningskanalmodeller har utvrderas, samt eekten av mobilens hastighet, signaltill brus frhllande, Rician faktor och infallsvinkel i ppet flt scenario. Dessutomhar den berkningsmssiga komplexiteten analyseras fr att utvrdera den praktiskaanvndbarheten i riktiga system...|$|R
40|$|Multifractional Brownian {{motion is}} a type of {{stochastic}} process with time-varying regularity. The main focus of this thesis is estimation of the pointwise regularity of such processes. The need for accurate estimation of the pointwise regularity is necessary as time series are assumed to be multifractional Brownian motion. Utilizing local properties of the multifractional Brownian motion, and a pointwise approximation method, this thesis proposes an estimator that overcomes the problem of separate estimation of a scaling constant known to be present in empirical data. It is shown by Monte Carlo simulation that the estimator manages to capture the behavior of the time-varying Hurst function for three cases of mBm processes. However, the pointwise estimates are volatile when considering a single trajectory. In an attempt to address this issue, a smoothing spline approach is applied. The smoothed single trajectory pointwise estimates shows better accuracy than the original pointwise estimates. For comparison purposes an estimator based on the Increment Ratio Statistic is introduced. Multifraktionell Browniansk rörelseär en typ av stokastisk process med tidsberoende regelbundenhet. I modelleringssyfteär precisa estimat av denna punktvisa regelbundenheten av intresse. Genom lokala egenskaper hos den multifraktionella Brownianska rörelsen och en punktvis approximationsmetod så föreslår denna uppsats en estimator somöverkommer behovet av separat <b>estimering</b> av en skalningskonstant. Denna skalningskonstant har tidigare visats förekomma i empiriska tidsserier. Den föreslagna estimatorn lyckas i genomsnitt fånga Hurstfunktionen i tre olika fall, vilket visas med Monte Carlo-simulering. När enskilda trajektorier beaktas kan det konstateras att de punktvisa estimatenär volatila. I ett försök attöka tillförlitligheten appliceras smoothing splines. Denna metod medför att de punktvisa estimaten får mindre variansän originalestimaten. En estimator baserad på Increment Ratio statistikan introduceras i jämförelsesyfte...|$|R
40|$|In a WCDMA {{transmission}} systems, {{the properties}} of the radio transmissionchannels can be strongly aected by the movement of User Equipment (UE) orthe surrounding objects. The estimation of Doppler spread is therefore of greatimportance since it is closely related to the mobile speed, as it can also be usedto characterize the fast fading in the radio channel. Thus the Doppler spread estimation can have wide range of applications and the relative research on thistopic has drawn much attention. Many Doppler spread estimation algorithms has been proposed in the literature. In this report, these algorithms are divided into four categories, and the comparison is performed from both performanceand implementation point of view to compare these four types of estimators. During the investigation, the Rayleigh fading and Rician fading model withdierent mobile speed and SNR are simulated to analyze the performance of estimation algorithms under dierent conditions. The effect of Rician factor and angle of arrival of Line Of Sight (LOS) component is also taken into consideration in the evaluation. Furthermore, the computational complexity of each algorithm is calculated. Based on simulation results, the underlying reasons for their performances are analyzed individually. The Moser's estimator (correlation based estimator) demonstrates the best performance among these four estimators from the perspective of estimation accuracy. And it also shows the great value for the implementation in real systems. I ett kommunikationssystem baserat p WCDMA kan egenskaperna hos radiotransmissionskanalernapverkas starkt av mobilens eller omgivningens rrelser. <b>Estimering</b> av Doppler spridningen r drfr av stor betydelse eftersom den r nrabeslktad med mobilens hastighet och den kan ocks anvndas fr att karakteriseraden snabba fdning i radiokanalen. Sledes kan estimat av Dopplerspridning ha ettbrett anvndningsomrde och forskningen om detta mne har varit intesiv. Mngaalgoritmer fr estimatering av Doppler spridning har freslagits i litteraturen. Idenna rapport, dessa algoritmer r indelade i fyra kategorier och analysen utfrsbde med avseende p prestanda och implementerbarhet. Simuleringar r utfrdamed Rayleigh fading och Rician modeller med olika hastigheter hos mobilen,och olika signal till brus frhllanden. Simuleringar har ocks gjorts fr olika vrdenav Ricianfaktorn och vinkel fr inkommande signal. Vidare har den berkningsmssigakomplexiteten av varje algoritm analyserats. Utifrn simuleringsresultathar de bakomliggande orsakerna till de olika algoritmernas prestatandadiskuterats. Dopplerspridningsestimat med Mosers metod (korrelation baseradestimator) visar det bsta resultatet bland dessa fyra estimator med avseendep skattningsnoggrannhet. Denna metod har ven frhllandevis lg berkningskomplexitetvilket gr den implementeringsvnlig...|$|R
40|$|Abstract. In general, {{the precise}} date of onset of {{pregnancy}} is unknown and {{may only be}} estimated from ultrasound biometric measurements of the embryo. We want to es-timate {{the density of the}} random variables corresponding to the interval between last menstrual period and true onset of pregnancy. The observations correspond to the vari-ables of interest up to an additive noise. We suggest an estimation procedure based on deconvolution. It requires the knowledge of the density of the noise which is not avail-able. But we have at our disposal another specific sample with replicate observations for twin pregnancies. This allows both to estimate the noise density and to improve the deconvolution step. Convergence rates of the final estimator are studied and compared to other settings. Our estimator involves a cut-off parameter for which we propose a cross-validation type procedure. Lastly, we estimate the target density in spontaneous pregnancies with an estimation of the noise obtained from replicate observations in twin pregnancies. En général, la date précise de début de grossesse est inconnue et est seulement es-timée a ̀ partir de mesures de l’embryon par ultrasons. Nous voulons <b>estimer</b> la densite...|$|E
40|$|The main {{objective}} {{of this research is}} to present a detailed method to numerically estimate the dynamic stresses and the risk of adverse health effects to which professional drivers are particularly prone. A parametric finite element model of the lumbar rachis has been generated to compute the dynamic stresses and the risk of fracture under harmonic excitations. An injury risk factor (IRF) has been developed. A design of experiments has been conducted by using the IRF as the dependent variable and by considering the posture, the body type, the apparent bone density, the damping rate and the body weight as independent variables. The design of experiment is based on 648 numerical simulations. In this study, the effect of ageing is considered as representing a decrease of the apparent density of the vertebral cancellous bone and damping rate of intervertebral disks. The results show that, if a young driver (25 years old) can support a level of acceleration of 3 m/s 2 without direct adverse health effect, this threshold level must be reduced to 2 m/s 2 after 45 years of exposition to vibrations. RÉSUMÉ L’objectif de cette étude est de présenter une méthode numérique pour <b>estimer</b> les contrainte...|$|E
40|$|The maximum {{wind gust}} speed {{can be defined}} as the highest wind speed that will occur, on the average, once in a given number of years. These high wind gusts usually last for only a few seconds and can {{therefore}} be measured only with an anemometer whose response is of the order of a second or two. There are few such anemometers connected to recording apparatus in Canada; in practice, therefore, these gusts must be estimated from records of mean wind speeds. On peut d 9 terminer que la vitesse de pointe du vent en rafale correspond 0 la vitesse maximale du vent atteinte au cours d'un certain nombre d'ann 9 es. Ces rafales de vent ne durent g 9 n 9 ralement que quelques secondes; on ne peut donc en mesurer la vitesse qu'au moyen d'un an 9 mom 8 tre dont le temps de r 9 ponse est d'une ou deux secondes. Bien peu de ces an 9 mom 8 tres sont branch 9 s 0 des dispositifs d'enregistrement au Canada. On doit donc <b>estimer</b> ces rafales 0 partir des vitesses moyennes du vent enregistr 9 es. Peer reviewed: NoNRC publication: Ye...|$|E
40|$|Denne oppgaven er skrevet som en del av større forskningsprosjekt hvor det overordnede målet er å utvikle enzymer som mest mulig effektivt degraderer den uløselige biopolymeren kitin (β-(1, 4) -bundet N-acetylglucosamine (GlcNAc)) og dets vannløselige analoge kitosan (delvis deacetylert kitin) til oligosakkarider av en gitt lengde. Siden kitin er veldig likt cellulose, som benyttes til produksjon av andre generasjons bioetanol, og de enzymatisk katalyserte hydrolyser av disse også er like er degraderingsstudier av kitin svært aktuelt. Hovedmålet i studiet har vært å finne den best egnede metoden for måling av prosessivitet i familie 18 kitinaser, samt undersøke effekten åtte ulike mutasjoner har på den katalytiske mekanismen til kitinase B (ChiB) fra jordbakterien Serratia marcescens. I tillegg har enzymene blitt testet mot ulike {{substrat}}varianter da det er økende interesse for om andre faktorer enn enzymet selv, som for eksempel substrattilgjengelighet, kan påvirke grad av prosessivitet. Det har også blitt utført bindingsassay hvor målet var å undersøke om bindingsstyrken mellom enzym og substrat er proporsjonal forgrad av prosessiv katalyse. Størrelsesekslusjonskromatografi, <b>estimering</b> av initiell hastighet for substratnedbrytning, apparent kcat, og viskositetsmålinger ble benyttet for måling av prosessivitet mot det løselige substratet kitosan hos de ulike enzymvariantene. Når substratet var kitin ble prosessivitet målt ved å bestemme konsentrasjon av resulterende dimerer etter hydrolyse delt på det samme for monomerer ([(GlcNAc) 2]/ [GlcNAc] ratio). Samtlige analyser indikerte at mutantene F 190 A, W 97 A, W 220 A, W 97 A/ W 220 A og W 97 A/ D 316 A for ChiB har redusert prosessiviteten både mot kitin og kitosan. ChiB villype, samt mutantene R 446 (deletering av det kitinbindende domene til ChiB), F 191 A og D 316 A viste prosessive egenskaper mot kitosan i samtlige analyser bortsett fra viskositetsmålinger for mutant D 316 A som ga avvikende resultater. R 446 var prosessiv mot det vannløselige substrate kitosan, men hadde sterkt redusert prosessivitet mot det vannuløselige kitin som antyder at det kitinbindende domenet er viktigere for prosessiv hydrolyse av uløselige substrater. Resultatene viser derfor at kunnskap om degradering av løselig kitosan ikke alltid direkte kan overføres til degradering av krystallinsk kitin. Sammenligning av de ulike fremgangsmåtene for måling av grad av prosessivitet antydet at størrelsesekslusjonskromatografi, <b>estimering</b> av apparent kcat og [(GlcNAc) 2]/ [GlcNAc] ratioen er de best egnede metodene. Apparent kcat- verdier for de ulike enzymene viste og at ikke-prosessive enzymer var mer effektive mot løselig substrat enn de prosessive, og motsatt for uløselig substrat. Dette sammenfaller med tidligere forslag om at prosessive enzymer er mer effektive mot krystallinske substrater og mindre mot løselige substrater. Degraderingsforsøk av ulike former for kitin med hensyn på substrattilgjengelighet (sonikert og ikke-sonikert) og med og uten hjelpeprotein (CBP 21) ble også utført i nærvær av ChiB-WT og mutant R 446 for å bestemme forholdet mellom substrattilgjengelighet og grad av prosessiv hydrolyse. En klar, positiv korrelasjon mellom substrattilgjengelighet og grad av prosessivitet ble observert. I tillegg var det en positiv korrelasjon mellom bestemte kcat- verdier og substrattilgjengelighet som videre bygger under teorien om at økende grad av prosessivitet fører til økning i aktivitet mot kitin. Bindingsstyrken mellom enzym og kitin ble beregnet for ChiB-WT, R 446, F 190 A, F 191 A, D 316 A, W 97 A og W 97 A/ W 220 A ved å måle dissosiasjonskonstanten, KD, og Gibbs frie energi, G, for samtlige dissosieringsreaksjoner. Alle enzymvariantene viste tilnærmet like verdier, uavhengig om de hydrolyserer kitin prosessivt eller ikke- prosessivt. Dette tyder på at enzymets affinitet for kitin ikke har noen direkte sammenheng med prosessivitet. Abstract This {{paper is}} written {{as part of}} larger research project with the overall goal of developing enzymes that most efficiently degrades chitin (β-(1, 4) -bundet N-acetylglucosamine (GlcNAc)) and its water soluble analogue chitosan (partially deacetylated chitin) to oligosaccharides of a given length. Since chitin {{is very similar to}} cellulose which is used in production of second generation bioethanol, and the enzymatically catalyzed hydrolysis of these also is very similar, degradation studies of chitin is particularly relevant. The main objective {{of the study was to}} determine the most suitable method for measuring processivity in family 18 chitinases and investigate the effect of eight different mutations on the catalytic mechanism of chitinase B (ChiB) from the soil bacterium Serratia marcsescens. In addition, enzymes have been tested against various substrates as there is an increasing interest in whether other factors than the enzyme itself, such as substrate accessibility, may affect the degree of processivity. There have also been carried out binding assays where the goal was to investigate if the binding strength between the enzyme and substrate is propotional to the degree of processive catalysis. Size exclusion chromatography, estimating the initial rate of substrate hydrolysis, apparent kcat, and viscosity measurements were used for measuring processivity against the soluble substrate chitosan with the different enzyme variants. When the substrate was chitin, processivity was measured by determeting the concentration of the resulting dimers after hydrolysis divided by the same for monomers ([(GlcNAc) 2]/ [GlcNAc] ratio). All of the analysis indicated that the mutants F 190 A, W 97 A, W 220 A, W 97 A / W 97 A and W 220 A / D 316 A for ChiB have reduced their processivity against both chitin and chitosan. ChiB wild type and the mutants R 446 (deletion of the chitin binding domain to ChiB), F 191 A and D 316 A showed processive properties against chitosan in all analysis except for the viscosity measurements for the D 316 A mutant that gave abnormal results. R 446 had a processive mode of action towards the soluble substrate chitosan, but showed strongly reduced processivity against the insoluble substrate chitin suggesting that the chitin binding domain is more important for processive hydrolysis of insoluble substrates. The results therefor indicate that knowledge of the degradation of soluble chitosan is not always directly transferable to the degradation of crystalline chitin. Comparison of different methods for measuring processivity suggested that size exclusion chromatography, estimation of apperent kcat and the [(GlcNAc) 2]/ [GlcNAc] ratio are the best suited methods. Apperent kcat-values for the different enzymes also showed that the non-processive enzymes were more effective against soluble substrate than processive enzymes, and vice versa for the insoluble substrate. This coincides with earlier suggestions that processive enzymes are more effective against crystalline substrates and less effective towards soluble substrates. Degradation experiments with different types of chitin with respect for substrate accessibility (both sonicated and non-soincated) and with and without chitin- binding protein (CBP 21) was also performed in the presence of ChiB wild type and mutant R 446 to determine the relationship between substrate accessability and the degree of processivity. A clear, positive correlation between the substrate accessibility and the degree of prosessivitet was observed. In addition there was a positive correlation between specific kcat-values and substrate accessability which strengthens the theory that an increase in the degree of prosessivity will lead to an increase in activity towards chitin. Binding strength between the enzyme and chitin were calculated for ChiB wild type, R 446, F 190 A, F 191 A, D 316 A, W 97 A and W 97 A / W 220 A by measuring the dissociation constant, KD, and Gibbs free energy, ΔG, for all dissociation reactions. All enzyme variants showed approximately the same values, whether they hydrolyze chitin processive or non-processive way. This suggests that the enzyme's affinity for chitin does not directly relate to processivity...|$|R
40|$|With {{the advent}} of next {{generation}} sequencing {{there has been an}} explosion of the size of data that needs to be processed, where next generation sequencing yields basepairs of DNA in the millions. The rate at which the size of data increases supersedes Moores law therefore there is a huge demand for methods to nd meaningful labels of sequenced data. Studies of microbial diversity of a sample is one such challenge in the eld of metagenomics. Finding the distribution of a bacterial community has many uses for example, obesity control. Existing methods often resort to read-by-read classication which can take several days of computing time in a regular desktop environment, excluding genomic scientists without access to huge clusters of computational units. By using sparsity enforcing methods from the general sparse signal processing eld (such as compressed sensing), solutions have been found to the bacterial community composition estimation problem by a simultaneous assignment of all sample reads to a pre-processed reference database. The inference task is reduced to a general statistical model based on kernel density estimation techniques that are solved by existing convex optimization tools. The objective is to o er a reasonably fast community composition estimation method. This report proposes, clustering as a means of aggregating data to improve existing techniques run-time and biological delity. Use of convex optimization tools to increase the accuracy of mixture model parameters are also explored and tested. The work is concluded by experimentation on proposed improvements with satisfactory results. The use of Dirichlet mixtures is explored as a parametric model of the sample distribution where it is deemed that the Dirichlet is a good choice for aggregation of k-mer feature vectors but the use of Expectation Maximization is unt for parameter estimation of bacterial 16 s rRNA samples. Finally, a semi-supervised learning method found on distance based classication of taxa has been implemented and tested on real biological data with high biological delity. Nya tekniker inom DNA-sekvensering har givit upphov till en explosion pa data som nns att tillga. Nasta generations DNA-sekvensering generar baspar som stracker sig i miljonerna och mangden data okas i en exponentiell takt, vilket ar varfor det nns ett stort behov av ny skalbar metodik som kan analysera kvantitiv data for att fa ut relevant information. Den bakteriella artfordelning av ett provror ar en sadan problemst allning inom meta-genomik, vilket har era tillampningsomraden som exempelvis, studier av fettma. I dagslaget sa ar den vanligaste metoden for att fa ut artfordelningen genom att klassiera DNA-strangarna av bakterierna, vilket ar en tidskravande losning som kan ta upp emot ett dygn for att processera data med hog upplosning. En snabb och tillforlitlig losning skulle darfor tillata er forskare att ta del av nasta generations sekvensering och analysera dess data som i sin tur skulle ge upphov till mer innovation inom omradet. Alternativa losningar med inspiration fran signalbehandlig har hittats som nyttjar problemestallningens glesa natur genom anvandning av Compressed Sensing. Svar hittas genom att simultant tilldela strangar till en for-processerad referensdatabas. Problemstallningen har forenklats till en statistisk modell av provror med ickeparametrisk <b>estimering</b> for att implicit fa ut fordelningen av bakteriearter med hjalp av konvex optimering. Denna rapport foreslar anvandningen av klustrering for aggregering av data for att forbattra tillforlitligheten av svaren och minska tiden for berakning av dessa. Anvandningen av parametriska modeller, Dirichlet fordelningen, har utforskats dar rapporten har kommit fram till att antaganden for lampligheten av denna som ett medel att aggregera k-mer vektorer ~Ar rimliga men att parameterestimeringen med Expectation Maximization ej fungerar val i samband med Dirichlet och en omskrivning av parametern skulle behovas i vektorrymden som spans av 16 S rRNA genen. Slutligen sa har distansbaserad tilldelning av bakterier testats pa data fran verklig biologisk kontext med valdigt hog noggranhet. i...|$|R
40|$|Denne masteroppgaven omhandler utviklingen av plantepatogenene klosopp (Mycocentrospora acerina) og gulrothvitflekksopp (Rhizoctonia carotae) på gulrot under langtidslagring. Det er blitt undersøkt hvordan faktorene sår i gulrotvevet (på 0, 1 og 3 mm dybde), alder på gulrøttene ved høsting (modningsgrad 1, 2 og 3 på henholdsvis 13, 16 og 20 uker), lagringstemperaturen (0 - 1, 3 og 5 °C) og lagringstiden påvirker sykdomsutviklingen. Klosoppens råteflekker ble målt både i form av den bredeste diameteren på overflaten av gulrota og i form av råteflekkens utvikling innover i gulrotvevet. For gulrothvitflekksoppen ble det kun registrert eventuell tilstedeværelse av symptomer i form av myceldotter. For klosoppen indikerer resultatene at både modningsgrad, lagringstemperatur, lagringstid og sårdybde har signifikant betydning for utviklingen av bredden på råteflekken. Bredden på råteflekken var signifikant størst for modningsgrad 3 (20 uker), mens modningsgrad 2 (16 uker) viste de laveste verdiene. Det ble også vist en signifikant større bredde på råteflekkene med økende temperatur, økende sårdybde og økende lagringstid frem til 14 uker. Resultatene antyder at en intakt {{periderm}} er en svært viktig faktor for å unngå infeksjoner av klosopp. Råteflekkens utvikling innover i gulrotvevet ble signifikant påvirket av lagringstemperaturen og sårdybden. Mens råteflekkens utstrekning i bredden begrenses av lave temperaturer, antyder dette forsøket at lave temperaturer og økt sårdybde kan føre råten lengre inn i gulrotvevet. Gulrothvitflekksoppen viste seg først etter 20 uker. På grunn av en lav grad av etablering og en sakte utvikling var det for få registreringer for kjøring av regresjonsanalyse. Resultatene antyder et økt angrep av gulrothvitflekksopp med økende temperatur og sårdybde. Det ble observert flest tilfeller av gulrothvitflekk ved modningsgrad 2. Sårdybden og modningsgraden til gulrøttene viser potensiale som faktorer for en tidlig <b>estimering</b> av lagringsevnen med tanke på angrep av klosopp, så lenge faktorene sees i sammenheng med ønsket lagringstid og lagringstemperatur. Abstract The aim of {{this thesis}} has been to examine how the carrots maturity at harvest (maturity level 1, 2 and 3 at respectively 13, 16 and 20 weeks), wounding (at 0, 1 and 3 mm depth), storage temperature (0 - 1, 3 and 5 °C) and storage time effects disease development of “liquorice rot” (Mycocentrospora acerina) and “crater rot” (Rhizoctonia carotae) on carrots during long time storage. The lesions of M. acerina were measured both as the diameter {{on the surface of}} the carrot and as the development of the lesions towards the centre of the carrot. For R. carotae the disease was measured as presence of hyphal knots. For M. acerina, the results indicate that the maturity of the carrot, the storage temperature, the time in storage and the depth of the wounds in the carrot tissue have significant importance for the development of the lesions diameter. The diameter of the lesions was significantly larger for maturity level 3 (20 weeks), while maturity level 2 (16 weeks) showed the lowest values. Significantly larger lesions were also found with increasing temperature, increasing depth of the wounds and increasing time in storage until 14 weeks. The results indicate that an intact periderm is important to avoid infections. The development of the lesions towards the centre of the carrot was significantly affected by storage temperature and the depth of the wounds. While the diameter of the lesions is limited by low temperatures, the results in this study suggest that low storage temperature and increasing depth of the wounds may cause decay further into the carrot tissue. The symptoms of R. carotae were first observed after 20 weeks of storage. Due to few observations and a slow development, there were too few recordings for a regression analysis. The results indicate increased development of the disease with increasing temperature and depth of wounding. More symptoms were observed in the carrots of maturity level 2 than maturity level 1 and 3. The maturity of the carrots at harvest and the depth of the wounds have potential for an early estimation of the storage capacity in relation to attacks by M. acerina, as long as the factors are considered in relation to the required storage time and temperature...|$|R
40|$|This thesis {{presents}} a visual registration system suitable for mechanical objects. The {{aim of this}} work is to perform an accurate and automatic estimation of the 3 D position and orientation of a known object, from a single camera image. The studied objects are complex, generally metallic and textureless. To solve this problem, we introduce an object model which characterizes both the visual aspect and the 3 D geometry of the object. This model is generated through a completely automatic learning process which exploits a small set of images of the object, registered with its CAD model. To estimate the object position and orientation, we propose a two-step matching process which exploits both visual and geometric data of the object model. The first step {{is based on a}} new local contour descriptor which characterizes exclusively the visual aspect of the object. We show that such a process is generally insufficient when applied to complex mechanical objects. Most of the time, the presence of repetitive patterns (bore series, [...] .) generates such a large amount of false matches that a pose computation becomes computationally prohibitive. We suggest completing the matching process by a step of false matches filtering based on the knowledge of the 3 D geometry. This process is based on a special feature which allows a pose computation from a single match. Experimental evaluations show that this filtering reduces the false match rate enough to envisage a pose computation. A pose estimation process is then explained. Finally, an experimental evaluation of the complete visual registration process is exposed. This evaluation was lead on industrial mechanical objects (a car door, an automotive cylinder-head, [...] .). The results underline the accuracy and the robustness of the proposed solution. Ce mémoire présente un système de recalage visuel adapté aux pièces mécaniques. Il s'agit d'estimer, de manière automatique et précise, la position et l'orientation d'un objet connu, à partir de son image vidéo. Les objets considérés possèdent la particularité d'être complexes, généralement métalliques et non-texturés. La solution proposée exploite un modèle d'objet caractérisant à la fois l'apparence et la géométrie de l'objet. Afin de pouvoir <b>estimer</b> la pose de l'objet, nous proposons un processus de mise en correspondance exploitant conjointement les informations d'apparence et de géométrie du modèle. Cette étape exploite la capacité à <b>estimer</b> une pose approximative de l'objet à partir d'un seul appariement pour filtrer efficacement les faux appariements. Un processus d'estimation précise de la pose est ensuite proposé. L'évaluation du processus complet sur des pièces mécaniques issues de l'industrie souligne la précision et la robustesse de ce dernie...|$|E
40|$|Abstract-A {{non linear}} least squares based method is {{presented}} to estimate activity data from measured interdilfusivity data for isomorphous binary metals. The interdilfusion coefficient is modelled {{as a product of}} two functions, one representing the thermodynamic contributions and another the contribution of the phenomenological coefficients. The proposed method factors the interdilfusion coefficient into its two constituent functions. This leads to the existence of non unique solutions and hence yields a set of possible solutions which on an activity-composition diagram exhibit positive and negative deviations from ideality. One additional piece of information, such as the experimentally measured activity at a particular composition or the slope of the Henry's law line at infinite dilution, is needed to select the correct solution. The method successfully predicted the thermodynamics of the CoNi system from calculations based on the interdiffusion coefficient. Resume-on presente une methode non lineaire basee sur Ia methode des moindres carres pour <b>estimer</b> Ies donnees d'activite a partir de donnees d'interdilfusivite mesurees pour des mchaux binaires isomorphes. Le coefficient d'interdilfusion est modelise par le produit de deux fonctions, l'une representant les contributions therrnodynarniques et!'autre Ia contribution des coefficients pbenomenologiques. La methode proposce factorise le coefficient d'interdiffusion en ses deux fonctions constituantes. Ceci condui...|$|E
40|$|Summary- Genetic {{parameters}} and bull transmitting abilities were estimated for twinning in the Maine-Anjou breed. Twin calving performance was analyzed as a threshold binary trait assuming direct and fetal effects and polygenic inheritance. The statistical model included {{the effects of}} parity, year-season, herd, sire of the fetus, sire of the cow and cow within sire. Heritabilities were 0. 13 and 0. 02 for direct and fetal effects, respectively, with a correlation between both effects of 0. 36. Transmitting abilities of bulls were expressed on the underlying and observed scales; the bull ranked first had an observed twinning rate of 13. 7 % among its 259 female progeny, corresponding to an estimated breeding value of 2. 6 units of underlying standard deviation or 13. 9 % as the probability for a future daughter to have a twin calving in her second parity. It is concluded that there is considerable place for twinning selection among Maine-Anjou bulls. cattle / twinning / genetic parameter / sire evaluation / threshold model Résumé &mdash; Paramètres génétiques de la gémellité en race Maine-Anjou. Cette étude vise à <b>estimer</b> les paramètres et les valeurs génétiques de la gémellité en race bovine Maine-Anjou. L’analyse du taux de vêlages gémellaires a été effectuée en traitant ce caractèr...|$|E
40|$|This thesis’ {{objective}} is to explore {{the existence of a}} Weekend Volatility Effect in the market for gold futures at the Chicago Mercantile Exchange during the period 1992 -­‐ 2012, providing the much needed updated conclusions concerning this effect in the market for this particular commodity. The analysis includes open and close prices allowing for the comparison of weekend-­‐, trading day-­‐ and overnight returns. A largely negative Weekend Volatility Effect is detected as the weekend’s annual return standard deviation on its lowest, for contract maturities ranging from two to three months, is estimated to 5, 88 % while that of the general trading day is estimated to 20, 77 %. The 24 -­‐hour return variance during the weekend is therefore only 7, 6 % of that of the general trading day posing a valid argument for the Trading-­‐ Time Hypothesis, over the Calendar-­‐Time Hypothesis, due to the significantly greater relevance of trading relative to news on return variability. Further, the Weekend Volatility Effect is largely visible in an analysis of both VaR and option pricing. For the weekend’s parametrically estimated VaR at a 99 % confidence level, ignoring the present effect results in an estimated loss level of 2, 17 % points more than the loss-­‐ level acknowledging the effect. For a 10 % delta call option, priced at the time of Friday’s close and maturing {{at the time of the}} following Monday’s open, assuming the Calendar-­‐Time Hypothesis to hold result in an option overvaluation of 1149 %. Equivalently, a call option priced at the time of Monday’s open with maturity set to the time of Friday’s close is, when priced according to the Calendar-­‐Time Hypothesis undervalued by 63 %. The significance of the over-­‐ and undervaluation is seen to rapidly reduce as whole weeks are added to the options’ maturities. Out-­‐of-­‐the-­‐ money options prove much more sensitive, in terms of percentage option over-­‐ and undervaluation, to the present Weekend Volatility Effect relative to in-­‐the-­‐money options. Concluding recommendations strongly advice acknowledging the present negative Weekend Volatility Effect in risk estimation and management, with the obvious better fit of trading-­‐ than calendar-­‐time as the market’s price-­‐generating time-­‐measure. Sammendrag Det er denne oppgavens formal å undersøke om det finnes en Weekend Volatilitetseffekt i markedet for gull futures ved Chicago Mercantile Exchange i løpet av perioden 1992 -­‐ 2012, og dermed gi sårt tiltrengte konklusjoner om denne effekten i dette bestemte råvaremarkedet. Analysen inkluderer open og close priser slik at helge-­‐, handledag-­‐ og over-­‐natten avkastninger kan sammenlignes. En significant negativ Weekend Volatilitetseffekt påvises ettersom helgens årlige standard avvik, for kontrakter med en maturitet på to til tre måneder, er estimert til 5, 88 % mens den i løpet av en generell handledag er på 20, 77 %. Avkastningenes 24 -­‐timers varians i løpet av helgen er derfor bare 7, 6 % av den i løpet av en generell handledag, og resultatene argumenterer derfor for Handletid Hypotesen, over Kalendertid Hypotesen, grunnet den synlige større påvirkningen av handel enn nyheter på variansen i avkastningene. Videre er Weekend Volatilitetseffekten meget synlig i en analyse av VaR og prising av opsjoner. For helgens parametrisk estimerte VaR, med et sikkerhetsnivå på 99 %, å ignorere effekten, resulterer i et tapsnivå på 2, 17 % mer enn det tapsnivået som tar hensyn til effekten. For en 10 % delta call opsjon, priset ved fredags close med maturitet satt til tidspunktet for mandags open, å anta Kalendertid Hypotesen til å holde fører til en overestimering av opsjonsverdien med hele 1149 %. På same måte fører Kalendertid Hypotesen til en underestimering på 63 % av prisen på an call opsjon dersom opsjonen prises ved mandags open med maturitet satt til fredags close. Størrelsen på over-­‐ og underprisingen av opsjonene reduseres kraftig når hele uker legges til opsjonenes maturiteter. Out-­‐of-­‐the-­‐money opsjoner viser seg å være mye mer sensitive, i prosent, til den eksisterende Weekend Volatilitetseffekten enn in-­‐the-­‐money opsjoner. Konkluderende anbefalinger råder en anerkjennelse av den eksisterende negative Weekend Volatilitets Effekten ved risiko <b>estimering</b> og håndtering, med en åpenbart bedre passform av handletid i forhold til kalendertid som markedets relevante pris-­‐genererende tidsmål...|$|R
40|$| startes opp. For å kunne håndtere usikkerheten har prosjektfaget fra begynnelsen av jobbet med å utvikle metoder og systematikk som gjør prosjektledelsen i stand til å håndtere prosjektets kritiske faktorer. Men for store og komplekse prosjekter er forutsigbarhet nærmest en illusjon. Tidligere var et prosjekt noe som leverte en unik leveranse, mens det i dag sees på som et middel for å skape endring som leverer maksimal nytte og effekt for oppdragsgiver og prosjekteierne. Denne måten å betrakte prosjekter på skaper nye krav til hvordan prosjekter skal ledes og styres, og det utløser et behov for vurdering av det eksisterende teorigrunnlaget i prosjektledelsesfaget I den tidlige prosjektledelsesteorien ble det sagt at prosjekter skulle holde seg til planene og levere det som ble bestilt i henhold til de tids- og kostnadsrammer som ble avtalt ved starten av prosjektet. Men når prosjektet strekker seg over flere år vil prosjektets interessenter og eier stadig utvikle ny forståelse for hva som skal leveres og det vil dermed kunne være uklart hva som egentlig bør være prosjektets leveranser. Prosjektledelsen opplever at usikkerhetsbildet (strategisk, taktisk og operasjonell) skifter, stiger og synker over hele prosjektforløpet, og det vil derfor i mange prosjekt være umulig å identifisere all usikkerheten i begynnelsene av prosjektet. Prosjektets eier og prosjektledelsen må håndtere og styre usikkerhet gjennom prosjektforløpet. Oppsummering av avhandlingens viktigste funn og forskningsbidrag De empiriske dataene fra gjennomgang av 6 bedrifters systematikk og håndtering av usikkerhet i prosjekt indikerer at usikkerhetsstyring i mange prosjekter har langt større fokus på de {{negative}} aspektene (truslene eller risikoene) enn den positiv delen av usikkerheten (mulighetene). Mønsteret som ble avdekket i casestudiene viste at uavhengig av om man ser på prosjekter ledet av en privat eller offentlig aktør er det er langt flere trusler eller risikoer i usikkerhets-/riskregisteret enn det er muligheter. Videre viste gjennomgangen at de fleste prosjektene kun var opptatt av muligheter i planfasen, mens muligheter som ble identifisert på et sent stadie i prosjektet (i gjennomføringsfasen) som regel ikke utforsket eller tatt. Antagelsen om {{at private}} prosjektaktører vil ha større fokus på muligheter enn offentlige aktører ble i stor grad avkreftet. Resultatet fra to større casestudier viste at de offentlige og private hadde tilnærmet samme fokus på trusler/risiko, og at den private aktøren ikke var bedre enn den offentlige til å identifisere og håndtere muligheter som kom opp i løpet av prosjektforløpet. Alle prosjektene som ble analysert i casestudiene vurderes å være relativt konservative i sin holdning til endringer og de fleste av dem jobbet ikke med å finne eller utforske muligheter i gjennomføringsfasen. Det ble i flere av de undersøkte prosjektene identifisert muligheter i gjennomføringsfasen vha. av usikkerhetsseminar (gjennomført i gjennomføringsfasen). Men det at de ble identifisert og nye muligheter avdekket var ikke ensbetydende med at prosjektet i etterkant av seminaret satt i gang arbeid med å utnytte disse mulighetene. De empiriske dataene viser at styring av trusler eller risiko ofte er svært vanskelig, og at aktiv utnyttelse av muligheter ofte enda vanskeligere. Det vil derfor ofte kreve en annen tilnærming enn det som i dag praktiseres i de fleste norske prosjekt dersom eier ønsker at muligheter aktivt skal håndteres som en del av usikkerhetsstyringen som prosjektledelsen er satt til å håndtere. Prosjekteier og prosjektledelsen må være villige til å akseptere endringer i planer og leveranser dersom muligheter skal utnyttes, og begge må ha vilje og evne til å håndtere endring av planer, løsninger og leveranser. Det er ofte en krevende øvelse å motivere prosjektledelsen til gjøre større endringer i et prosjekt i gjennomføringsfase, og motstand mot endring øker normalt etter hvert som prosjektet nærmer seg overlevering. En identifisert endring i gjennomføringsfasen må være langt bedre enn det som allerede er planlagt for at prosjektledelsen i det hele tatt skal vurdere den som interessant å gjennomføre, siden det betyr at man må bruke tid og penger på forandre det som alt anses som godkjent, og i verste fall må man reversere løsninger og forandre på deler eller hele prosjektleveransen. De empiriske dataene viser at "nye" muligheter i liten grad er ønskelig eller interessante når man er kommet over i gjennomføringsfasen. Det å holde seg til planene vurderes av mange prosjektledere som den beste og mest fornuftig strategien. En mulighet som kommer opp på et sent stadium i prosjektforløpet blir ofte vurdert som svært usikker og en "gamble" i forhold til om den vil gi positiv nytte for prosjektet og for eier/oppdragsgiver. Og vurderes nytten som positiv for eier kan prosjektledelsen allikevel velge å avstå fra å ta muligheten fordi endring kan gi økte kostnader og mindre mulighet til å levere på avtalt tid. For å få inn en mulighet som representerer en endring av prosjektets planer og leveranser må prosjektledelsen ha fullmakter fra eier/oppdragsgiver og begge må være enige i at muligheten representerer en større nytte enn det som alt er avtalt og i noen tilfeller også levert. Noe som igjen antyder at en mulighet, hvis den kommer opp i gjennomføringsfasen, må være svært interessant eller ha høy nytte for at den i det hele tatt skal bli vurdert, fordi det vil bety at: Prosjektledelsen må være villig til å forandre planer og inngåtte kontrakter for å utnytte en mulighet - Prosjektledelsen må forlate noe som de har investert tid og penger i å utvikle. - Prosjektledelse må investere ressurser for å bekrefte eller avkrefte mulighetens potensial, og er de i det minste tvil om nytten vil de forholde seg til det som allerede er planlagt. Denne avhandlingens seks viktigste bidrag vurderes å være: 1. Det er påvist at de seks deltagerbedriftene som deltok i PUS-prosjektet har økt sin kompetanse og modenhet i forhold til styring og håndtering av usikkerhet i prosjekt. 2. Prosjektets strategiske og taktiske omgivelser påvirker prosjektet, og hvem som deltar i identifisering og styring av usikkerhetene i de ulike fasene er avgjørende for hvilket fokus usikkerhetsstyringen får. 3. Det er utviklet og testet en ny 9 stegs modell for håndtering av usikkerhet over prosjektforløpet. 4. Det er utviklet og testet ulike praktiske verktøyer for styring av usikkerhet. 5. Fem karakteristika ved prosjekters forståelse og håndtering av usikkerhet er foreslått. 6. Fire karakteristika for hvordan prosjekter forstår og håndterer muligheter er foreslått. Det er mye som tyder på at forskning på organisasjoner og prosjekter har skiftet fokus, fra tidligere å være mest fokusert på verktøy og metoder, til å bli mer fokuser på de ulike ledelsesprosessene og den menneskelige adferd i samspillet mellom aktørene i og rundt prosjektet. Dagens forskere innen prosjektledelsesfaget anerkjenner at metoder og verktøy har en naturlig plass i dette samspilt. De fleste anerkjenner også at to prosjekter ikke vil være 'like" og at kontekst som prosjektene gjennomføres i og menneskene som er del av prosjektet betyr noe for løsningen som skapes og for de metodiske valgene som man som forsker observerer når man studerer prosjekter. Hvis et firma eller en organisasjon ønsker å utvikle og forbedre evnen til å styre usikkerhet må man forstå de ansattes behov, forstå kulturen i firmaet, prosjekteierens rolle og hvordan indre og ytre interessenter samspiller og påvirker usikkerhetene som prosjektledelsen og prosjekteier er satt til å håndtere. Skal et prosjekt bli effektivt i håndtering av usikkerhet, må prosjektledelsen være i stand til å identifisere og vurdere prosjektets reelle usikkerhet, forstå sitt mandat og være i stand til å forstå om de skal håndtere eiers strategiske og taktiske usikkerheter, eller konsentrerer seg om prosjektets operasjonelle usikkerhet. En viktig del av håndtering av usikkerheten er refleksjon og læring underveis i prosjektforløpet. Prosjektledelsen må kontinuerlig vurdere hvordan valg og disponeringer påvirker fremdriften og de leveransene som man er satt til å utvikle. Effektiv styring av usikkerhet fordrer evne til å reflektere over hvordan beslutninger som løpende tas vil komme til å påvirke prosjektets slutt-resultat, og det krever evne til å vurdere hvordan gjenstående usikkerheten kan påvirke delleveranser, sluttresultatet og prosjektets effekt. Skal et firma eller organisasjon bli bedre til å håndtere usikkerhet i prosjekter, er det helt sentralt at moderorganisasjonen tilrettelegger for læring og refleksjon kan finne sted underveis og i etterkant at prosjektere er gjennomført. Siden 2005 har det forgått to større parallelle forskningsinitiativ i Norge, Forskningsprosjektet "Praktisk styring av usikkerhet i et prosjekteier perspektiv" ("PUS prosjektet") og Concept forskningsprogram ved NTNU. Dette har bidratt til økt kunnskap og modenhet hos mange av de store prosjektaktørene i Norge, men det er ingen garanti for at alle prosjekter vil oppnå suksess i fremtiden. Studier gjennomført av Concept antyder at offentlige prosjekter har færre kostnadsoverskridelser i dag enn tidligere. Men det er viktig at man er klar over at mindre kostnadsoverskridelser har sin pris. Mer penger til hvert prosjekt som gjennomføres vil bety at estimatet blir sikrere og budsjetter holdes oftere, men det er også en reell fare for at det settes av for mye penger i hvert prosjekt, og dermed får man færre veier, mindre jernbane, færre skoler og oljeinstallasjoner i dag enn vi fikk for de samme pengene tilbake på midten av 2000 tallet. Økt modenhet på usikkerhetsstyring betyr ikke at alle prosjekter i Norge som har aktiv usikkerhetsstyring er effektiv i måten de planlegges og gjennomføres på. Det er ikke bevist eller bekreftet om prosjekter i Norge reelt sett har blitt bedre på <b>estimering</b> av usikkerhet, om estimatene er mer realistisk i dag enn ved år 2000 eller om prosjektledere og prosjekteiere har blitt bedre til å øke sine rammer og usikkerhetsbuffere, eller at prosjektledere og eier har blitt bedre til å styre den reelle usikkerheten som dagens prosjekt opplever i vår omskiftelige verden...|$|R
40|$|Regression {{analysis}} was used to estimate the dependence of CPUE and average weight of bigeye on the temperature of surface water, the temperature of water at hook depth, the depth of the hook and the depth of thermocline. Hydrological data, catch and effort data and length/weight data were collected during four cruises of the Polish longliner WIECZNO from 1981 to 1985. The vessel operated in the Central Atlantic (37 oN- 09 oS and 15 oW- 38 oW). A total of 220 sets were analysed. Bigeye tuna was represented in 59 % of sets. The daily CPUE of bigeye ranged up to 620 kg/ 1000 hooks in different years. The average length and weight of bigeye was 130 cm and 45. 5 kg respectively. Since standard longlines with 5 -hook baskets were used, the prevailing depth range for bigeye was 60 - 100 metres. The most efficient water temperature at hook depth was 12 - 16 o C. Statistically significant dependencies were found between CPUE and hook depth, CPUE and the depth of thermocline and CPUE and surface temperature. The dependence between average weight of fish and water temperature at hook depth was also significant. RÉSUMÉ L’analyse de régression a été utilisée pour <b>estimer</b> la dépendance de la CPUE et du poid...|$|E
40|$|ABSTRACT. Subsistence fishing {{provides}} {{an important source}} of food for the remote Ojibwa community of Webequie, located along the Winisk River in northem Ontario. Field observations during the summer of 1988 were combined with a recall survey to estimate catches from October 1987 through September 1988. Of 133 potential fishermen, 90 were surveyed. The total community harvest was estimated to be 83 810 fish, round weight 108 210 kg. After adjustments, this provided 118 kg round weight/person/year, or 0. 21 kg/person/day edible fish for consumption. Lake whitefish (Coregonus clupeaformis), walleye (Stizostedion vifreum), northern pike (Esox Zucius) and suckers (Catostomus commersoni and C. carostomus) were dominant in the catch. Lake sturgeon (Acipenserfruvescens) attracts special fishing effort. Older males (> 40 years old) are the primary fisher-men. Fixed gill nets take 95 % of the harvest, most of which is consumed. Commercial fishing seems to be disappearing. Recreational fishing is a potential source of revenue. Subsistence fishing tends to be overlooked in development and management schemes but is clearly an important activity. Key words: subsistence fishing, Ojibwa, native harvest survey, northern O tario fisheries &SUMk. La pêche de subsistance est une source alimentaire importante pour la communaue isolte d’Ojibwa de Webequie situte le long de la riv-ikre Winisk au nord de l’Ontario. Des observations sur place de l’kt 6 1988 furent combinks avec un sondage de rappel pour <b>estimer</b> le nombre d...|$|E
40|$|Abstract: Acoustic {{surveys are}} {{routinely}} {{used to assess}} fish abundance. To ensure accurate population estimates, the characteristics of echoes from constituent species must be quantified. Kirchhoff-ray mode (KRM) backscatter models were used to quantify acoustic characteristics of Bering Sea and Gulf of Alaska pelagic fish species: capelin (Mallotus villosus), Pacific herring (Clupea pallasii), walleye pollock (Theragra chalcogramma), Atka mackerel (Pleurogrammus monopterygius), and eulachon (Thaleichthys pacificus). Atka mackerel and eulachon do not have swimbladders. Acous-tic backscatter was estimated {{as a function of}} insonifying frequency, fish length, and body orientation relative to the incident wave front. Backscatter intensity and variance estimates were compared to examine the potential to discrimi-nate among species. Based on relative intensity differences, species could be separated in two major groups: fish with gas-filled swimbladders and fish without swimbladders. The effects of length and tilt angle on echo intensity depended on frequency. Variability in target strength (TS) resulting from morphometric differences was high for species without swimbladders. Based on our model predictions, a series of TS to length equations were developed for each species at the common frequencies used by fisheries acousticians. Résumé: Les inventaires acoustiques sont utilisés régulièrement pour <b>estimer</b> l’abondance des poissons. Pour obtenir des estimations précises, les caractéristiques des échos provenant des différentes espèces doivent être quantifiées. Des modèles de réflexion acoustique fondées sur l’approximation de Kirchhoff ont été utilisés pour mesurer les propriété...|$|E
40|$|A simple {{technique}} is proposed {{in this paper}} to estimate the coefficient of permeability of unsaturated soils based solely on conventional soil properties; namely, the saturated coefficient of permeability, degree of saturation (or water content), and the plasticity index, Ip of the soil. The {{technique is}} developed based on a relationship derived between the relative coefficient of permeability, krel (defined as the ratio between unsaturated and saturated coefficient of permeability, kunsat / ksat) and the (degree of saturation) γ. The data from the literature for different soils ranging from sand (Ip = 0 %) to clay (Ip = 50 %) {{were used in the}} development of the presented technique. The results of the study suggest that the fitting parameter γ is strongly dependent on the type of soil, particularly for soils with Ip range of 0 to 20 %. A relationship between the fitting parameter, γ and the plasticity index, Ip of the soil is also proposed. The influence of various parameters that influence the coefficient of permeability of unsaturated soils such as the compaction water content, stress state, compaction energy and the wetting-drying cycles were also studied. The results of the research study suggest that the proposed simple technique is a useful tool to estimate the coefficient of permeability of unsaturated soils as a function of degree of saturation or water content. RÉSUMÉ Cet article décrit une méthode simple pour <b>estimer</b> le coefficient de perméabilité de sols non-saturés. Cette méthod...|$|E
40|$|Background: Psychiatric {{disorders}} are common among patients with physical illnesses. Objectives: To estimate {{the prevalence of}} anxiety and depression in Arab dermatology patients and to study its association with the patients ’ characteristics. Materials and Methods: A cross-sectional study was carried out on 875 patients attending the Dermatology Clinic at King Khalid University Hospital in Riyadh, Saudi Arabia. Each patient was {{asked to complete the}} Hospital Anxiety and Depression Scale and the demographic-clinical questionnaire. Results: The frequency of anxiety and depression in Arab dermatology patients was 29 % for anxiety and 14 % for depression. These frequencies were not related to sociodemographic and clinical variables (p [...] 05), except skin disease type (p,. 05). Patients suffering from hair loss had the highest anxiety and depression scores (OR 1. 725 [95 % CI 1. 247 – 2. 386] and OR 1. 686 [95 % CI 1. 101 – 2. 581], respectively). On the other hand, patients suffering from psoriasis had the highest depression scores (OR 2. 909 [95 % CI 1. 611 – 5. 254]). Conclusion: Anxiety and depression are frequent among Arab dermatology patients. Contexte: Les troubles psychiatriques sont fréquents chez les patients atteints de maladies physiques. Objectifs: L’étude visait a ̀ <b>estimer</b> la prévalence de l’anxiéte ́ et de la dépression chez les patients arabes traités en dermatologie, et a ̀ examiner l’association de ces troubles avec les caractéristiques des patients...|$|E
40|$|CETTE THESE TRAITE D'IDENTIFICATION DITE AUTODIDACTE DE CANAUX DE TRANSMISSION LINEAIRES A TEMPS DISCRET. ON S'INTERESSE PLUS PARTICULIEREMENT AUX TECHNIQUES D'IDENTIFICATION BASEES SUR LES STATISTIQUES DU SECOND ORDRE DU SIGNAL RECU REPRESENTEES PAR SA FONCTION DE COVARIANCE. LA PREMIERE PARTIE DE CETTE THESE CONCERNE L'IDENTIFICATION D'UNE FONCTION DE TRANSFERT RATIONNELLE MULTI-ENTREE MULTI-SORTIE A PARTIR DE LA FONCTION DE COVARIANCE ASSOCIEE A CETTE FONCTION PRIVEE DU COEFFICIENT DE COVARIANCE CENTRAL. CE PROBLEME SE RENCONTRE DANS LES SITUATIONS CONCRETES OU LE BRUIT ADDITIF EST SPATIALEMENT COLORE. DEUX APPROCHES INDEPENDANTES QUI RECLAMENT DES CONDITIONS PEU RESTRICTIVES SUR LA FONCTION DE TRANSFERT A <b>ESTIMER</b> SONT PROPOSEES. CES DEUX METHODES EXPLOITENT UNE FONCTION MATRICIELLE QUI NE DEPEND EXPLICITEMENT QUE DES COEFFICIENTS DE COVARIANCE CONNUS. - LA PREMIERE APPROCHE ESTIME LE COEFFICIENT CENTRAL A L'AIDE D'UNE TECHNIQUE DE TYPE SOUS-ESPACE APPLIQUEE A CETTE FONCTION MATRICIELLE. UNE FOIS CE COEFFICIENT ESTIME, L'ESTIMATION DE LA FONCTION DE TRANSFERT ELLE-MEME EST UN PROBLEME DU SECOND ORDRE CLASSIQUE. - LA DEUXIEME APPROCHE EST BASEE SUR LA FACTORISATION DE WIENER-HOPF DE CETTE FONCTION MATRICIELLE PAR RAPPORT AU CERCLE-UNITE. ELLE DEBOUCHE SUR L'ESTIMATION DIRECTE DE LA FONCTION DE TRANSFERT. LA DEUXIEME PARTIE DE LA THESE CONCERNE L'ESTIMATION DE CANAUX CDMA EN LIAISON MONTANTE. LES CONDITIONS D'IDENTIFIABILITE REQUISES PAR LES ALGORITHMES SOUS-ESPACE CONNUS NE SONT PAS CLAIRES. UN ALGORITHME QUI REQUIERT UNE CONDITION D'IDENTIFIABILITE CLAIRE ET NON RESTRICTIVE EST PROPOSE. UNE ANALYSE DES PERFORMANCES THEORIQUES DE CET ALGORITHME DANS LES CONDITIONS ASYMPTOTIQUES EST EGALEMENT PROPOSEEPARIS-EST Marne-la-Vallee-BU (774682101) / SudocSudocFranceF...|$|E
40|$|Enhancing {{road safety}} by {{developing}} active safety {{system is the}} general purpose of this thesis. A challenging task {{in the development of}} active safety system is to get accurate information about immeasurable vehicle dynamics states. More specifically, we need to estimate the vertical load, the lateral frictional force and longitudinal frictional force at each wheel, and also the sideslip angle at center of gravity. These states are the key parameters that could optimize the control of vehicle's stability. The estimation of vertical load at each tire enables the evaluation of the risk of rollover. Estimation of tire lateral forces could help the control system reduce the lateral slip and prevent the situation like spinning and drift out. Tire longitudinal forces can also greatly influence the performance of vehicle. The sideslip angle {{is one of the most}} important parameter to control the lateral dynamics of vehicle. However, in the current market, very few safety systems are based on tire forces, due to the lack of cost-effective method to get these information. For all the above reasons, we would like to develop a perception system to monitor these vehicle dynamics states by using only low-cost sensor. In order to achieve this objective, we propose to develop novel observers to estimate unmeasured states. However, construction of an observer which could provide satisfactory performance at all condition is never simple. It requires : 1, accurate and efficient models; 2, a robust estimation algorithm; 3, considering the parameter variation and sensor errors. As motivated by these requirements, this dissertation is organized to present our contribution in three aspects : vehicle dynamics modelization, observer design and adaptive estimation. In the aspect of modeling, we propose several new models to describe vehicle dynamics. The existent models are obtained by simplifying the vehicle motion as a planar motion. In the proposed models, we described the vehicle motion as a 3 D motion and considered the effects of road inclination. Then for the vertical dynamics, we propose to incorporate the suspension deflection to calculate the transfer of vertical load. For the lateral dynamics, we propose the model of transfer of lateral forces to describe the interaction between left wheel and right wheel. With this new model, the lateral force at each tire can be calculated without sideslip angle. Similarly, for longitudinal dynamics, we also propose the model of transfer of longitudinal forces to calculate the longitudinal force at each tire. In the aspect of observer design, we propose a novel observation system, which is consisted of four individual observers connected in a cascaded way. The four observers are developed for the estimation of vertical tire force, lateral tire force and longitudinal tire force and sideslip angle respectively. For the linear system, the Kalman filter is employed. While for the nonlinear system, the EKF, UKF and PF are applied to minimize the estimation errors. In the aspect of adaptive estimation, we propose the algorithms to improve sensor measurement and estimate vehicle parameters in order to stay robust in presence of parameter variation and sensor errors. Furthermore, we also propose to incorporate the digital map to enhance the estimation accuracy. The utilization of digital map could also enable the prediction of vehicle dynamics states and prevent the road accidents. Finally, we implement our algorithm in the experimental vehicle to realize real-time estimation. Experimental data has validated the proposed algorithm. Le développement des systèmes intelligents pour contrôler la stabilité du véhicule et éviter les accidents routier est au cœur de la recherche automobile. L'expansion de ces systèmes intelligents à l'application réelle exige une estimation précise de la dynamique du véhicule dans des environnements diverses (dévers et pente). Cette exigence implique principalement trois problèmes : ⅰ), extraire des informations non mesurées à partir des capteurs faible coût; ⅱ), rester robuste et précis face aux les perturbations incertaines causées par les erreurs de mesure ou de la méconnaissance de l'environnement; ⅲ), <b>estimer</b> l'état du véhicule et prévoir le risque d'accident en temps réel. L’originalité de cette thèse par rapport à l’existant, consiste dans le développement des nouveaux algorithmes, basés sur des nouveaux modèles du véhicule et des différentes techniques d'observation d'état, pour <b>estimer</b> des variables ou des paramètres incertains de la dynamique du véhicule en temps réel. La première étape de notre étude est le développement de nouveaux modèles pour mieux décrire le comportement du véhicule dans des différentes situations. Pour minimiser les erreurs de modèle, un système d'estimation composé de quatre observateurs est proposé pour <b>estimer</b> les forces verticales, longitudinales et latérales par pneu, ainsi que l'angle de dérive. Trois techniques d'observation non linéaires (EKF, UKF et PF) sont appliquées pour tenir compte des non-linéarités du modèle. Pour valider la performance de nos observateurs, nous avons implémenté en C++ des modules temps-réel qui, embarqué sur le véhicule, estiment la dynamique du véhicule pendant le mouvement...|$|E
40|$|Abstract – • Sample size is a {{critical}} issue for genetic diversity studies and conservation programs. However, sample size evaluation requires previous knowledge of allele frequencies estimated with precision {{and this is not}} often the case. • Here, we evaluated sample size requirements for accurate genetic diversity in adult trees and family arrays in a 12 ha plot of Fraxinus excelsior L. (Oleaceae) in a community forest in central France. Data consisted of 579 adult trees and 480 offspring from 24 families genotyped at four nuclear microsatellites. • Mean square errors (MSE) estimates performed on Monte Carlo simulations of resampled data indicated that several adult individuals (> 300) are necessary for accurate measures of allele richness. However, expected heterozygosity requires smaller samples (< 30). Seeds captured about 90 % of adult allelic diversity requiring a sampling effort roughly 50 % larger than that of adult trees (480 seeds vs. 300 adults) suggesting that seed sampling is heavily penalized for allele counts. Nevertheless, gene diversity of seeds was essentially identical to that of the adult population. • Extrapolation of these results to other ash tree populations appears feasible because of similar levels of diversity reported in the literature but it is not granted for species with significant selfing or high genetic structure. Fraxinus excelsior / microsatellite / genetic variation / sampling Résumé – Quel échantillonnage pour des estimations fiables de la diversité génétique chez Fraxinus excelsior L. (Oleaceae) ? • La taille d’un échantillonnage est un paramètre difficile à <b>estimer</b> a priori pour les études de diversité génétique ainsi que pour les programmes d...|$|E
40|$|Abstract: Flow cytometry {{has been}} used to {{estimate}} nuclear DNA content of 13 C O ~ ~ C C J species (Rubiaceae) investigated. Isolated nuclei from 77 genotypes were stained with propidium iodide (PI: not hase specific). Thirty-nine genotypes were stained with 4 ', 6 -diamidino-?-phenylindole (DAPI; AT specific). Nuclear DNA content (3 C values). estimated with PI. ranged from 0. 95 to 1. 78 pg. By aggregative clustering. three groups of accessions with increasing DNA content were identified. Three species. namely C. sessilifora, C. racmosu. and C. pscir~f@~cinRuchnri. ne. had a low DNA content (0. 90 - 1. 30 pg). Three species. namely C. ezcgmioiu'es. C. srenophTllu, and C. sp. F, were exclusively f k n d in the intermediate group (1. 31 - 1. 60 pg). The remaining species were distrihuted hetween the intermediate group and the last group (1. 61 - 1. 80 pgl. The values determined for the Coffeu species are compared, inter- and intra-specifically, to those of other angiosperm species. The observed differences are discussed according to the ecogeographic origin of the species. their phenological characteristics. and the fertility of the FI interspecific hyhrids. K q ivords: Africa. Cq&. flow cytometrq. nuclear DNA content. genome evolution [...] o+:. IIULl. e tû Africa. Tw. el-;e diplnid! 2 [...] 1 = 22) 2 nd m e tetrq!oid (C. rmbicr!. ?ri = 41) speciec were Résumé: La cytométrie en flus a été utilisée pour <b>estimer</b> la quantité d'ADN nucléaire chez 13 espkces de Cofeu (Rubiaceae) originaires d'Afrique. Douze espkces diploïdes (?ri = 2 2) et l'espèce tétraploïd...|$|E
40|$|Abstract: An intertemporal spatial {{equilibrium}} {{model of}} the eastern Oregon softwood log market was employed to es-timate the market and economic welfare impacts of restoration thinning programs established on national forests in the region. Programs treated only lands with sawtimber thinning volume and varied by the extent of public subsidies for costs, the types of costs that could be subsidized, and {{the form of the}} subsidy payment. Impacts on private harvest tim-ing, numbers of mills, and postprogram log prices in the region were found to vary markedly with the form of the pro-gram. Log consumers (lumber mills) consistently realized relatively large surplus gains, while private log producers' surplus showed smaller but consistent losses. For a comparable subsidy budget, programs that subsidized only hazard removal costs, on sites where net unsubsidized sawtimber returns promised to be less that these costs, led to a larger area treated than did programs with more flexible subsidy conditions. Across all programs, net agency receipts from sawtimber sales were estimated to be insufficient to cover the costs of all areas in need of thinning treatment (lands with and without sawtimber thinning volume). Rbsumb: Les auteurs considkrent le march 6 des billes rksineuses de l'est de I'Oregon, dEfini A l'aide d'un modMe d'kquilibre spatial inter-temporel, pour <b>estimer</b> I'impact des programmes d'klaircie de restauration mis en aeuvre dans les forCts nationales de la rkgion sur le bien-Ctre kconomique et sur le march 6 cornme tel. Ces programmes visent seu-lement Ies zones presentant des volurnes d'eclaircie de qualit 6 sciage. 11 s varient selon l'envergure des subventions qu...|$|E
40|$|Une méthodologie globale et cohérente de raisonnement de la {{valorisation}} du bois d'oeuvre d'une forêt donnée est développée. La méthodologie intègre les aspects techniques, économiques et stratégiques {{au niveau}} première transformation. Elle est développée en 5 étapes avec possibilités de feed-back : déterminer au plan technique quels types de produits peuvent être fabriqués, <b>estimer</b> la rentabilité par filière de première transformation (tranchage, déroulage, sciage), <b>estimer</b> la rentabilité par essence et par filière afin d'écarter celles nettement déficitaires, optimiser les procédés de transformation, sélectionner les filières en s'appuyant sur l'analyse économique et financière. Une étude de cas est réalisée sur une forêt au Cameroun. La poursuite de la recherche devrait s'attacher à obtenir une meilleure précision de l'évaluation de la ressource, intégrer des outils méthodologiques complémentaires, créer un support informatique et adapter la méthodologie à d'autres cas concrets. This work {{deals with the}} development of a methodology allowing to globally and consistently consider wood valorisation from a given forest resource. The methodology has been developed for the mostly encountered case in the Congo basin, where forest harvesting and wood processing activities are most often performed by the same company. This approach enables the integration of technical and economic specificity peculiar to each wood species and to logs quality, as weil as their consequences on productivity. Base on a well known of wood market, the competitiveness estimation of each kind of wood process by species and by production type, {{as well as in the}} specifie conditions of each project constitute a tool for decision making. This tool allows to structure the approach and simulate sorne of the strategie choices that have to be made. The proposed methodology is developing in five steps, with one or more possible feedback : The first step consists in analysing the technical consistence between the available resource and the products which can be produced : from the resource inventory (species, log quality [...] .) and from the corresponding wood properties, the type of wood products to be manufactured is deterrnined (technical requirements to be met related to intrinsic wood characteristics). The second step consists in performing a rough evaluation of the profitability of the targeted productions for each wood species. The aim is to eliminate non competitive productions and to deterrnine the processing costs of the remaining productions. The third step is a detailed estimation of the profitability by wood species and by production type. This enables the elimination of those of the species which should stay non competitive even after process optimisation. The fourth step corresponds to the use of methods for process optimisation. It is mainly based on the functional analysis concepts applied to wood processes. The fifth step allows the selection of the productions to be kept (slicing, peeling, softwoods sawing, hardwoods sawing [...] .), referring to economic and financial analysis of each type of them, completed by strategie aspects. In case of surrender of any type of production, a feedback allow to make a new evaluation ofthe allocation of the resource. The methodology is further applied to the concrete case of a 80 000 ha forest unit in eastern Cameroon. This work led to assess its operational character as a tool for decision making. Finally, the main limits and proposaIs for future research orientations are presented : absolute necessary increase in the accuracy ofresource evaluation (quantity and quality), development of a software for assistance and capitalisation, integration of recently developed methods and concepts from innovation management, from strategie decision making on marketed products, adaptation of the methodology to other types of forest sector organisation...|$|E
40|$|Abstract: Tree {{mortality}} {{is often the}} result of both long-term and short-term stress. Growth rate, an indicator of long-term stress, {{is often used to}} estimate probability of death in unburned stands. In contrast, probability of death in burned stands is modeled as a function of short-term disturbance severity. We sought to narrow this conceptual gap by deter-mining (i) whether growth rate, in addition to crown scorch, is a predictor of mortality in burned stands and (ii) whether a single, simple model could predict tree death in both burned and unburned stands. Observations of 2622 unburned and 688 burned Abies concolor (Gord. & Glend.) Lindl. (white fir) in the Sierra Nevada of California, U. S. A., indicated that growth rate {{was a significant predictor of}} mortality in the unburned stands, while both crown scorch and radial growth were significant predictors of mortality in the burned stands. Applying the burned stand model to unburned stands resulted in an overestimation of the unburned stand mortality rate. While failing to create a general model of tree death for A. concolor, our findings underscore the idea that similar processes may affect mortal-ity in disturbed and undisturbed stands. Résumé: Chez les arbres, la mortalité est souvent le résultat de stress à long et à court termes. Le taux de croissance, un indicateur de stress à long terme, est souvent utilisé pour <b>estimer</b> les risques de mortalité dans les peuplements qui n’ont pas été endommagés par le feu. Par contre, dans les peuplements endommagés par le feu, le risque de mortalité est modélisé en fonction de la sévérité d’une perturbation à court terme. Nous avons tenté de réconcilier cet écar...|$|E
40|$|It i s often {{important}} {{to estimate the}} abundance of a fish stock when the stock is somewhat depleted. For pelagic species this presents great operational difficulties, because adult surveys may be prohibitively expensive and time consuming. Here we introduce a method for estimating the spawning biomass of a stock by means of egg or larval surveys. In particular, we develop a series of models for presence-absence sampling of eggs or larvae and show how presence-absence data {{can be used to}} estimate adult spawning biomass. The models are based on an underlying probabilistic description of the aggregation of eggs or larvae, a search process, and a description of habitat structure. Methodologies are given for estimating the distribution {{of the size of the}} spawning biomass from presence-absence data. A case study of sardine is used to justify a number of the assumptions. The methods are applied to a 1985 survey for sardine eggs and are compared to an alternative method based on egg production. Dans bon nombre de cas, il est important d’estimer I’abondance d’un stock de poissons lorsque ses effectifs sont quelque peu rauits. Pour les esp&es Nlagiques, cela entraine des difficult & op 6 rationnelles majeures, car le denombrement des adultes peut Ctre excessivement coirteux et long. Les auteurs ont mis au point une methode permettant d‘estimer la biomasse des geniteurs d‘un stock par la presence ou I’absence de leurs oeufs ou de leurs larves. A cette fin, ils ont 6 labor 6 une serie de modeles et demontrent comment I’on peut se servir de donnks relatives a la presence ou a I’absence des wufs ou des larves de poisson pour <b>estimer</b> la biomasse des geniteur...|$|E
40|$|ABSTRACT. Historical {{records of}} {{commercial}} whalers operating in northwestern Hudson Bay during the 19 th century were examined {{for information on}} size, age, sex, and location of bowhead whales that were either sighted or killed. Correlations between body size and either oil yield or baleen length were used to estimate the relative age classes (calf, subadult, adult) of whales for which no explicit age-class information {{was reported in the}} whaling logbooks. Cow-calf pairs and subadults, as well as adult whales, were sighted or killed throughout the whaling season in the area extending from Wager Bay south to Marble Island. This finding indicates that whales of many different age classes were present south of Wager Bay, even during the open-water period when whaling activity shifted northward to include Repulse Bay and Lyon Inlet. Recent observations suggest that few bowhead whales occur south of Wager Bay during the open-water season and that the population in this area has not recovered from the effects of commercial whaling. It is not clear whether this group of bowheads was a separate stock or, alternatively, waters south from Wager Bay constituted a second calf-rearing area for a single Hudson Bay-Foxe Basin stock. Key words: bowhead whale, Balaena mysticetus, Hudson Bay, Foxe Basin, stock structure RÉSUMÉ. On s’est penché sur des documents historiques provenant de baleiniers commerciaux en activité dans le nord-ouest de la baie d’Hudson au XIXe siècle, afin d’extraire de l’information sur la taille, l’âge, le sexe et l’emplacement des baleines boréales qui avaient été aperçues ou tuées. On s’est servi des corrélations entre la taille des cétacés et la production d’huile ou la longueur des fanons pour <b>estimer</b> les groupes d’âge relatifs (baleineau, subadulte, adulte) de baleines pour lesquelles aucun...|$|E
40|$|Abstract: The Brownie {{models for}} tagging data allow one to {{estimate}} age- and year-specific total survival rates {{as well as}} tag recovery rate parameters. The latter can provide estimates of exploitation rates if the tag reporting, tag shedding, and tag-induced mortality rates can be estimated. A limitation of the models {{is that they do}} not allow for newly tagged animals to have different survival rates than previously tagged animals because of lack of complete mixing. We develop a model that allows for the animals to be incompletely mixed, or not fully recruited, into the population during the entire year in which they are tagged. There is a penalty in terms of precision {{associated with the use of}} this model. To increase the precision, we also developed a model for which it is assumed that animals become fully mixed (recruited) after a portion of the year has elapsed. Sometimes, animals must be tagged after the fishing season has begun. In this case, newly tagged animals experience fishing and natural mortality for only a fraction of the year. The partial-year non-mixing model can be modified to account for this situation. Résumé: Les modŁles de Brownie pour les donnØes de marquage permettent dØvaluer le taux de survie totale propre à un âge et à une annØe ainsi que des paramŁtres du taux de rØcupØration des marques. Ces derniers peuvent fournir des Øvaluations du taux dexploitation lorsquon peut <b>estimer</b> les taux de dØclaration des marques, de perte des marques et de mortalitØ induite par les marques. Le fait que dans ces modŁles les sujets nouvellement marquØs ne peuvent pas avoir des taux de survie diffØrents de ceux des animaux dØjà marquØs en raison dun mØlange incomplet constitue une limitation. Nous avons Ølabor...|$|E
40|$|Summary- The inoculaùon of Prunus cerastfera {{hardwood}} cuttings {{in containers}} by {{a population of}} Me/oidogyne arenaria was done by transfering roots and soil of a tomato plant grown in pot that was inoculated 2 months before with 500 juveniles (2) of this nematode. Containers with a non host clone of P. cerasifera were first used to estimate the release of J 2 inoculum into the soil from rotting tomato roots. Mean total inoculum produced in one container was 160 000 J 2 s + eggs. Juvenile inoculum recovered monthly in Prunus soil varied between 5000 and 17 000 ail along the 4 -month experiment thus providing a high and durable inoculum pressure. Then eleven other P. cerasifera clones (five hosts and six non hosts) inoculated with the same method were harvested after 4 months to determine suitability of several criteria of evaluation of resistance. Gall index was highJy significantly correlated with the 10 glO(x + 1) transformed numbers of the different nematode stages in roots of host clones. The best linear correlaùon was observed with females, followed by eggs and J 2 s. Presumably because of the extracùon technique, gall index, root eggs and root J 2 s resulted the best criteria to differentiate sratistically weakly-galled clones from non host clones. Gall index is therefore a good crirerion ro evaluare resistance in P. ceras ifera. Résumé- Méthode et critères d'évaluation de la résistance à Me 1 oidogyne arenaria chez Prunus cerasifera Ehr. -L'infestation de boutures ligneuses de Prunus cerasifera en conteneur par une population de Me/oidogyne arenaria est assuree par le transfert du systeme racinaire et du sol d'un godet de tomate inocule 2 mois auparavant avec 500 juveniles (2) de ce nematode. Un clone non hôte de P. cerasifera est d'abord uùlise pour <b>estimer</b> l'evolution des effectifs de J 2 libéres dans le sol par les racine...|$|E
40|$|Résumé- Il est proposé d'utiliser des {{particules}} sphériques ëchangeuses d'ions comme étalon pour <b>estimer</b> la proportion des divers éléments dans les tissus biologiques. Abstract- The use of {{ion exchange}} beads is proposed as {{standards for the}} estimation of various elements in biological tissues. Elements to be detected or quantitated in biological tissues occur in three forms: as free ions or salts, in a crystalline phase, and bound to a matrix. For the latter category a standard system using ChelexlOO-jon exchange beads is proposed. Cations can be attached in a controlled way to such an artificial polystyrene divinyl benzene matrix, furnished with negatively charged iminodiacetate functional groups by replacing the sodium ions present in the commercial product. In Fig. 1 beads measuring 35 - 75 ym in 0 are shown in the SEM-mode as standards for bulk analysis, attached to a graphite plate with graphite glue (Leit C). The analysis of Co-loaded beads is given in Fig. 2. Loading conditions from salt solutions are described elsewhere (1). The binding is controlled mainly by the pH of the reaction. After loading, the ex-cess of the equilibrium solution can be washed away by rinsing with a buffer having the same pH as the equilibrium solution. When the beads are maximally loaded, the concentration of the various elements vary- according to the differences in affinity-between 2 and 15 w/w % (as far as we have measured them), but almost every concen-tration below the maximum value {{can be obtained by}} changing the equilibrium con-ditions. The concentration on the maximally loaded beads was determined at 40 or 60 kV on 35 - 75 ym 0 beads with either the pure metal or copper as a reference. On iden-tical samples the concentration was determined by neutron activation (Interuniversi...|$|E
40|$|CETTE THESE A UN DOUBLE OBJECTIF: D'UNE PART IL S'AGIT DE L'APPLICATION DE L'IMAGERIE X PAR CONTRASTE DE PHASE (AVEC CRISTAL ANALYSEUR) POUR L'ETUDE DES CARTILAGES, OS ET IMPLANTS A L'AIDE DU RAYONNEMENT SYNCHROTRON ET D'AUTRE PART CE TRAVAIL CONTRIBUE AU DEVELOPPEMENT, THEORIQUE ET EXPERIMENTAL, DES TECHNIQUES D'IMAGERIE PAR CONTRASTE DE PHASE. PLUSIEURS ECHANTILLONS HUMAINS POST MORTEM ONT ETE IMAGES PAR UNE TECHNIQUE DE CONTRASTE DE PHASE UTILISANT UN CRISTAL ANALYSEUR (ABI). L'ETUDE COMPREND L'IMAGERIE PAR PROJECTION ET TOMOGRAPHIQUE D'ARTICULATIONS DE HANCHE, ORTEIL ET CHEVILLE. LES IMAGES PAR ABI ONT ETE CONFRONTEES A CELLES OBTENUES PAR DES TECHNIQUES CONVENTIONNELLES: RADIOGRAPHIE, TOMODENSITOMETRIE, ECHOGRAPHIE, IMAGERIE PAR RESONANCE MAGNETIQUE ET A DE L'HISTOLOGIE, QUI SERT DE REFERENCE. LES RESULTATS MONTRENT QUE SEULE L'IMAGERIE PAR ABI PERMET DE VISUALISER OU <b>ESTIMER</b> CORRECTEMENT LE STATUT PATHOLOGIQUE PRECOCE DU CARTILAGE. LA CROISSANCE DE L'OS APRES IMPLANTS A AUSSI ETE ETUDIEE SUR LES ECHANTILLONS POST MORTEM DE MOUTON : LA TECHNIQUE D'IMAGERIE PAR ABI PERMET DE FAIRE LA DIFFERENCE ENTRE UNE BONNE GUERISON ET UN RECUPERATION INCOMPLETE DE L'OS. DES EXPERIENCES PIONNIERES, lN VIVO, REALISEES AVEC DES COCHONS DE GUINEE ONT EGALEMENT ETE MENEES AVEC SUCCES, CONFIRMANT AINSI L'UTILISATION POSSIBLE DE LA TECHNIQUE POUR LE SUIVI DES MALADIES AFFECTANT LES ARTICULATIONS, L'ASSIMILATION DES IMPLANTS OU ENCORE L'ETUDE DE L'EFFICACITE DE MEDICAMENTS. EN CE QUI CONCERNE LE DEVELOPPEMENT DES TECHNIQUES PAR CONTRASTE DE PHASE, DEUX OBJECTIFS ONT ETE ATTEINTS. POUR LA PREMIERE FOIS, IL A ETE DEMONTRE EXPERIMENTALEMENT QUE LES TECHNIQUES D'IMAGERIE UTILISANT LE CONTRASTE DE PHASE PAR ABI ET PAR PROPAGATION (PPI) PEUVENT ETRE COMBINEES POUR CREER DES IMAGES AYANT DES CARACTERISTIQUES PROPRES (IMAGERIE HYBRIDE HI). DEUXIEMEMENT, UNE NOUVELLE CONFIGURATION EXPERIMENTALE SIMPLIFIEE, POUR L'ACQUISITION D'IMAGES PROCHES DE CELLES OBTENUES PAR ABI OU HI, EST PROPOSEE ET TESTEE. ENFIN, LES DEUX TECHNIQUES D'IMAGERIE PAR ABI OU HI ONT ETE ETUDIEES D'UN POINT DE VUE THEORIQUE AVEC UN CODE DE SIMULATION ORIGINAL QUI EST CAPABLE DE REPRODUIRE LES RESULTATS EXPERIMENTAUX. GRENOBLE 1 -BU Sciences (384212103) / SudocSudocFranceF...|$|E
40|$|Abstract: Present {{understanding}} of fire ecology in forests subject to surface fires {{is based on}} fire-scar evidence. We present theory and empirical results that suggest that fire-history data have uncertainties and biases when used to esti-mate the population mean fire interval (FI) or other parameters of the fire regime. First, the population mean FI is dif-ficult to estimate precisely because of unrecorded fires and can only be shown to lie in a broad range. Second, the interval between tree origin and first fire scar estimates a real fire-free interval that warrants inclusion in mean-FI cal-culations. Finally, inadequate sampling and targeting of multiple-scarred trees and high scar densities bias mean FIs to-ward shorter intervals. In ponderosa pine (Pinus ponderosa Dougl. ex P. & C. Laws.) forests of the western United States, these uncertainties and biases suggest that reported mean FIs of 2 – 25 years significantly underestimate popula-tion mean FIs, which instead may be between 22 and 308 years. We suggest that uncertainty be explicitly stated in fire-history results by bracketing the range of possible population mean FIs. Research and improved methods may nar-row the range, {{but there is no}} statistical or other method that can eliminate all uncertainty. Longer mean FIs in ponder-osa pine forests suggest that (i) surface fire is still important, but less so in maintaining forest structure, and (ii) some dense patches of trees may have occurred in the pre-Euro-American landscape. Creation of low-density forest structure across all parts of ponderosa pine landscapes, particularly in valuable parks and reserves, is not supported by these results. Résumé: La compréhension actuelle de l’écologie du feu dans les forêts sujettes aux feux de surface repose sur la pré-sence des cicatrices laissées par le feu. Nous présentons des résultats théoriques et empiriques qui montrent que les don-nées sur l’historique des feux comportent des incertitudes et des biais lorsqu’elles sont utilisées pour <b>estimer</b> l’intervalle moyen entre les feux ou d’autres paramètres du régime des feux. Premièrement, il est difficile d’estimer avec précisio...|$|E
