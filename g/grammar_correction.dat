41|35|Public
50|$|The {{first version}} of Microsoft’s machine {{translation}} system was developed between 1999 and 2000 within Microsoft Research. This system was based on semantic predicate-argument structures known as logical forms (LF), and was spun from the <b>grammar</b> <b>correction</b> feature developed for Microsoft Word. This system was eventually used to translate the entire Microsoft Knowledge Base into Spanish, French, German, and Japanese.|$|E
5000|$|Several {{developers}} {{of the systems}} that drive electronic dictionary software offer API and SDK - Software Development Kit tools for adding various language-based (dictionary, translation, definitions, synonyms, and spell checking and <b>grammar</b> <b>correction)</b> functions to programs, and web services such as the AJAX API used by Google. These applications manipulate language in various ways, providing dictionary/translation features, and sophisticated solutions for semantic search. They are often available as a C++ API, an XML-RPC server, a [...]NET API, or as a Python API for many operating systems (Mac, Windows, Linux, etc.) and development environments, and {{can also be used}} for indexing other kinds of data.|$|E
50|$|Honeywood {{grew up in}} Australia {{and spent}} time in Japan as a foreign {{exchange}} student in high school. He earned degrees in computer science and Japanese at University of Sydney and spent his fourth year at its sister school, Hosei University. He {{began his career as}} a game programmer at Rise Corporation, a subsidiary of Seibu Kaihatsu. Honeywood and some members of this development team left Rise to form Digital Eden, a new company that worked on a number of Nintendo 64DD games in collaboration with HAL Laboratory. When it became clear that the 64DD's protracted development would render their efforts meaningless, Digital Eden agreed to disband without releasing a single game. Satoru Iwata, then-president of HAL Laboratory, personally offered Honeywood the opportunity to work on an early Pokémon game but he declined, instead joining Square in 1997. Originally, he was to work as a programmer on Final Fantasy VII under Ken Narita. However, the impressive sales of Final Fantasy VII in Western markets prompted Square to look into improving the quality of its translated products—Final Fantasy VII was widely criticized for its rushed translation, which had been handled entirely by Michael Baskett, the company's only in-house translator at the time. Compounding this critical staff shortage, text in the game could only be input in Shift JIS, a standard Japanese character encoding format, which was incompatible with spelling and <b>grammar</b> <b>correction</b> software. Honeywood and Aiko Ito were brought on as localization producers to recruit for a dedicated localization team within the company. This team established best practices with respect to code preservation—localization efforts for Chocobo no Fushigi na Dungeon and Tobal 2 were halted at the gate when a complete copy of the source code could not be pieced together from the disbanded development team's computers. For Final Fantasy VIII, Honeywood had written a text parser that would automatically convert text from English ASCII to Shift JIS format required by the game engine's compiler, streamlining the translation process dramatically.|$|E
40|$|Abstract. We {{investigate}} {{a new paradigm}} {{in the context of}} learning in the limit, namely, learning <b>correction</b> <b>grammars</b> for classes of r. e. languages. Knowing a language may feature a representation of the target language in terms of two sets of rules (two grammars). The second grammar is used to make corrections to the first grammar. Such a pair of grammars {{can be seen as a}} single description of (or grammar for) the language. We call such <b>grammars</b> <b>correction</b> <b>grammars.</b> <b>Correction</b> <b>grammars</b> capture the observable fact that people do correct their linguistic utterances during their usual linguistic activities. Is the need for self-corrections implied by using <b>correction</b> <b>grammars</b> instead of normal grammars compensated by a learning advantage? We show that learning <b>correction</b> <b>grammars</b> for classes of r. e. languages in the TxtEx-model (i. e., converging to a single correct <b>correction</b> <b>grammar</b> in the limit) is sometimes more powerful than learning ordinary grammars even in the TxtBc-model (where the learner is allowed to converge to infinitely many syntactically distinct but correct conjectures in the limit). For each n ≥ 0, there is a similar learning advantage, again in learning correctio...|$|R
50|$|Though most {{changes are}} small {{spelling}} and <b>grammar</b> <b>corrections,</b> critics claim that even these are significant {{in light of}} Smith's claims of divine inspiration. Critics assert {{that some of these}} changes were systematic attempts to hide the book's flaws.|$|R
40|$|We {{investigate}} {{a new paradigm}} {{in the context of}} learning in the limit, namely, learning <b>correction</b> <b>grammars</b> for classes of computably enumerable (c. e.) languages. Knowing a language may feature a representation of it in terms of two grammars. The second grammar is used to make corrections to the first grammar. Such a pair of grammars {{can be seen as a}} single description of (or grammar for) the language. We call such <b>grammars</b> <b>correction</b> <b>grammars.</b> <b>Correction</b> <b>grammars</b> capture the observable fact that people do correct their linguistic utterances during their usual linguistic activities. We show that learning <b>correction</b> <b>grammars</b> for classes of c. e. languages in the TxtEx-model (i. e., converging to a single correct <b>correction</b> <b>grammar</b> in the limit) is sometimes more powerful than learning ordinary grammars even in the TxtBc-model (where the learner is allowed to converge to infinitely many syntactically distinct but correct conjectures in the limit). For each n >= 0, there is it similar learning advantage, again in learning <b>correction</b> <b>grammars</b> for classes of c. e. languages, but where we compare learning <b>correction</b> <b>grammars</b> that make n + 1 corrections to those that make it corrections. The concept of a <b>correction</b> <b>grammar</b> can be extended into the constructive transfinite, using the idea of counting-down from notations for transfinite constructive ordinals. This transfinite extension call also be conceptualized as being about learning Ershov-descriptions for c. e. languages. For it a notation in Kleene's general system (O, <(0)) of ordinal notations for constructive ordinals. we introduce the concept of an u-correction grammar. where it is used to bound the number of <b>corrections</b> that the <b>grammar</b> is allowed to make. We prove a general hierarchy result: if it and v are notations for constructive ordinals such that u <(0) v, then there are classes of c. e. languages that can be TxtEx-learned by conjecturing v-correction grammars but not by conjecturing u-correction grammars. Surprisingly, we show that-above "omega-many" corrections-it is not possible to strengthen the hierarchy: TxtEx-learning u-correction grammars of classes of c. e. languages, where it is a notation in O for any ordinal, can be simulated by TxTBc-learning w-correction grammars, where in is any notation for the smallest infinite ordinal omega...|$|R
40|$|We {{introduce}} a novel technique that uses hierarchical phrase-based {{statistical machine translation}} (SMT) for <b>grammar</b> <b>correction.</b> SMT systems provide a uniform platform for any sequence transformation task. Thus <b>grammar</b> <b>correction</b> {{can be considered a}} translation problem from incorrect text to correct text. Over the years, <b>grammar</b> <b>correction</b> data in the electronic form (i. e., parallel corpora of incorrect and correct sentences) has increased manifolds in quality and quantity, making SMT systems feasible for <b>grammar</b> <b>correction.</b> Firstly, sophisticated translation models like hierarchical phrase-based SMT can handle errors as complicated as reordering or insertion, which were difficult to deal with previously throuh the mediation of rule based systems. Secondly, this SMT based correction technique is similar in spirit to human correction, because the system extracts grammar rules from the corpus and later uses these rules to translate incorrect sentences to correct sentences. We describe how to use Joshua, a hierarchical phrase-based SMT system for <b>grammar</b> <b>correction.</b> An accuracy of 0. 77 (BLEU score) establishes the efficacy of our approach. ...|$|E
40|$|Practical text {{processing}} systems need wide covering grammars. When parsing unrestricted language, such grammars {{often fail to}} generate all of the sentences that humans would judge to be grammatical. This problem undermines successful parsing {{of the text and}} is known as undergeneration. There are two main ways of dealing with undergeneration: either by sentence correction, or by <b>grammar</b> <b>correction.</b> This thesis concentrates upon automatic <b>grammar</b> <b>correction</b> (or machine learning of grammar) as {{a solution to the problem}} of undergeneration. Broadly speaking, <b>grammar</b> <b>correction</b> approaches can be classified as being either datadriven, or model-based. Data-driven learners use data-intensive methods to acquire grammar. They typically use grammar formalisms unsuited to the needs of practical {{text processing}} and cannot guarantee that the resulting grammar is adequate for subsequent semantic interpretation. That is, data-driven learners acquire grammars that generate strings that humans would jud [...] ...|$|E
40|$|Ferris (1999) rejects my {{case against}} <b>grammar</b> <b>correction</b> in L 2 writing classes (Truscott, 1996) and {{attempts}} to build her own case for the practice. This paper responds to her criticisms. I argue that these criticisms are both unfounded and highly selective, leaving large portions of my case unchal-lenged and, in some cases, even strengthening them. If the case for correc-tion has any appeal, it rests on a strong bias-that critics must prove beyond any doubt that correction is never a good idea, while supporters need only show that uncertainty remains. My decision to write “The Case Against <b>Grammar</b> <b>Correction</b> in L 2 Writing Classes ” (Truscott, 1996) was based on two considerations. One, of course, was my conviction that <b>grammar</b> <b>correction</b> is a bad idea. The second factor, no {{less important than the}} first, was the state of the field. Then, as now, grammar correc-tion was the norm. Then, as now, the reasons for changing the norm were out there. But these reasons were largely disregarded. The literature was full of confident assertions-and assumptions-that gram...|$|E
40|$|We {{prove the}} minimax {{equality}} for the spectral radius ρ(AB) {{of the product}} of matrices A∈A and B∈B, where A and B are compact sets of non-negative matrices of dimensions N× M and M× N, respectively, satisfying the so-called hourglass alternative. Comment: 11 pages, 15 bibliography references. Numerous style and <b>grammar</b> <b>corrections,</b> expanded the bibliography. arXiv admin note: text overlap with arXiv: 1507. 0049...|$|R
40|$|This article {{considers}} {{the classification of}} matrix superpotentials that corresponds to exactly solvable systems of Schrodinger equations. Superpotentials of the following form are considered: $W_k = kQ + P + \frac 1 kR$, where $k$ [...] - parameter, $P, Q$ and $R$ [...] - hermitian matrices, that depend on a variable $x$. The list of three-dimensional matrix superpotentials is presented explicitly. Comment: 13 pages, <b>grammar</b> <b>corrections</b> were adde...|$|R
40|$|In the finite-temperature Yang-Mills theory we {{calculate}} the functional determinant for fermions in the fundamental {{representation of the}} SU(N) {{in the background of}} an instanton with non-trivial values of the Polyakov line at spatial infinity. This object, called the Kraan [...] van Baal [...] Lee [...] Lu caloron, can be viewed as composed of N Bogomolny [...] Prasad [...] Sommerfeld monopoles (or dyons). We compute analytically two leading terms of the fermionic determinant at large separations between dyons. Comment: 17 pages, 2 figures, <b>grammar</b> <b>corrections,</b> introduction revise...|$|R
40|$|In {{this paper}} we briefly review and analyze three {{published}} proofs of Chaitin's theorem, the celebrated information-theoretic version of Gödel's incompleteness theorem. Then, we discuss our main perplexity concerning a key step {{common to all}} these demonstrations. Comment: 6 pages, no figures. Few <b>grammar</b> <b>correction...</b>|$|E
40|$|Undergeneration is {{a problem}} that {{undermines}} successful parsing of unrestricted texts. A popular solution to this problem is automatic <b>grammar</b> <b>correction</b> (or machine learning of grammar). Broadly speaking, <b>grammar</b> <b>correction</b> approaches can be classified as being either data-driven, or modelbased. Data-driven learners use data-intensive methods to acquire grammar. They typically use grammar formalisms unsuited to the needs of practical text processing. That is, data-driven learners acquire grammars that overgenerate and fail to assign linguistically plausible parses. Model-based learners are knowledge-intensive and are reliant for success upon the completeness of a model of grammaticality. But, in practice, the model will be incomplete and so since we deal with undergeneration by learning, we hypothesise that the combined use of data-driven and model-based learning would allow data-driven learning to compensate for model-based learning's incompleteness, whilst model-based l [...] ...|$|E
40|$|Recent {{results from}} CLEO {{on the search}} for CP {{violation}} in beauty and charm meson decays are reviewed. Comment: 7 pages, 5 figures, contribution to the proceedings of CPconf 2000, International Conference On CP Violation Physics, September 18 - 22, 2000, Ferrara, ITALY. Replacement version with typos and <b>grammar</b> <b>correction...</b>|$|E
40|$|From {{the point}} of view of {{radiation}} safety, interstellar space is not an empty void. Interstellar gas and cosmic rays, which consist of hydrogen and helium nucleons, present a severe radiation hazard to crew and electronics aboard a relativistic interstellar ship. Of the two, the oncoming relativistic flow of interstellar gas produces the most intence radiation. A protection shield will be needed to block relativistic interstellar gas that can also absorb most of the cosmic rays which, as a result of relativistic aberration, form into a beamed flow propagating toward the front of the ship. Comment: 16 pages, 4 figures, minor <b>grammar</b> <b>corrections,</b> references added, submitted to Acta Astronautic...|$|R
40|$|There {{has been}} recent {{progress}} on computing real-time equilibrium 3 -point functions in finite-temperature strongly-coupled N= 4 super Yang-Mills (SYM). In this paper, {{we show an}} example of how to carry out a similar analysis for a 4 -point function. We look at the stopping of high-energy "jets" in such strongly-coupled plasmas and relate the question of whether, on an event-by-event basis, each jet deposits its net charge over a narrow (~ 1 /T) or wide (>> 1 /T) spatial region. We relate this question to the calculation of a 4 -point equilibrium correlator. Comment: 41 pages, 20 figures [change from v 2 : just a handful of minor <b>grammar</b> <b>corrections...</b>|$|R
40|$|In its {{theoretical}} part this bachelor thesis focuses on introducing how spelling and <b>grammar</b> <b>corrections</b> in text processors work on basic level. Brief history of text processors {{as well as}} linguistic basics needed for comprehension of the discussed problems are mentioned. In its practical part the bachelor thesis focuses on a research. Its goal is to examine {{whether there is a}} connection between using <b>grammar</b> and spelling <b>correction</b> in Microsoft Office Word 2007 and the level of grammatical expression of the youth. Another goal is to examine the hand written text conducted in the research for distribution of errors recognized by Microsoft Office Word 2007 in relation to errors not recognized by this program. A questionnaire and a dictate, which is first written in hand and then later in same form using Microsoft Office Word 2007, are used to gather the data necessary for the research. The evaluation of the research reveals some interesting results, however the hypotheses of the research are not validated...|$|R
30|$|This {{work was}} {{supported}} by the National Natural Science Foundation of China (Project No. 81101800), the  12 th Six Talents Peak Project of Jiangsu Province (No. 2015 -WSN- 028), the Research Project of Education of Nanjing Medical University (No. NY 2222015030) and the Research Project of Chinese Medical Association & Chinese High Education Association (No. 2016 B-KC 019). And high tribute shall be paid to Doctor Lin–Lin, Huang Xia-Yue for critical reviews and Doctor Hong-Jie Zhang for enlightening the discussion and Doctor Hong Zhu for <b>grammar</b> <b>correction.</b>|$|E
40|$|This {{research}} {{is to examine the}} students‘ motivational factors and attitude towards the learning of English grammar in a Computer-supported Learning System. Twenty-nine students were taught with a student-centered approach and three grammar learning web sites were used frequently for classroom and individual English grammar practice, whereas another twenty-nine were taught with the traditional teachercentered approach. Both groups were given <b>grammar</b> <b>correction</b> and explanation tests before and after the study. After comparing the results of the pre-test and post-test with those of the control group, {{it was found that the}} experimental group excelled over the control group in both <b>grammar</b> <b>correction</b> and grammar explanation. It proved that students‘ implicit and explicit knowledge on English grammar was greatly improved by the computer-supported teaching methods and environment. Further interviews with the students also revealed that the new pedagogical practice had provided many positive motivational factors in supporting students‘ learning process. ...|$|E
40|$|September 1994 ‘It is {{high time}} {{we turned to}} Grammar now, ’ said Doctor Cornelius in a loud voice. ‘Will your Royal Highness be pleased to open Pulverulentus Siccus at the fourth page of his Grammatical Garden or the Arbour of Accidence pleasantlie open’d to Tender Wits?’ After {{that it was all}} nouns and verbs till lunchtime, but I don’t think Caspian learned much. C. S. Lewis, Prince Caspian. Practical text {{processing}} systems need wide covering grammars. When parsing unrestricted language, such grammars often fail to generate all of the sentences that humans would judge to be grammatical. This problem undermines successful parsing of the text and is known as undergeneration. There are two main ways of dealing with undergeneration: either by sentence correction, or by <b>grammar</b> <b>correction.</b> This thesis concentrates upon automatic <b>grammar</b> <b>correction</b> (or machine learning of grammar) as {{a solution to the problem}} of undergeneration. Broadl...|$|E
30|$|As {{learners}} {{engaged in}} FFPR, they sought and provided suggestions or advice {{on a particular}} point of text revision, elicited and provided opinions or evaluation (Mendonca & Johnson, 1994; Mendonca & Johnson, 1994; Lockhart & Ng, 1995; Zhu, 1995; Villamil & De Guerrero, 1996; De Guerrero & Villamil, 2000; Hanjani & Li, 2014) and exchanged information (McGroarty & Zhu, 1997). They also exchanged restatement, <b>grammar</b> <b>corrections</b> (Mendonca & Johnson, 1994; Mendonca & Johnson, 1994), identfied problems in their texts (Beason, 1993; Zhu, 1995; Min, 2005; Lin & Samuel, 2013), summarized points, expressed intentions (Lockhart & Ng, 1995) and decribed various aspects of texts (Beason, 1993) and restating or repeating (Lin & Samuel, 2013; Hanjani & Li, 2014).|$|R
40|$|State-of-art {{systems for}} <b>grammar</b> error <b>correction</b> often correct errors based on word {{sequences}} or phrases. In this paper, we describe a <b>grammar</b> error <b>correction</b> system which corrects grammatical errors at tree level directly. We cluster all error {{into two groups}} and divide our system into two modules correspondingly: the general module and the special module. In the general module, we propose a TreeNode Language Model to correct errors related to verbs and nouns. The TreeNode Lan-guage Model is easy to train and the de-coding is efficient. In the special module, two extra classification models are trained to correct errors related to determiners and prepositions. Experiments show that our system outperforms the state-of-art sys-tems and improves the F 1 score. ...|$|R
40|$|Speech {{recognition}} {{errors are}} inevitable {{in a speech}} dialog system. This paper presents an error handling method based on <b>correction</b> <b>grammars</b> which recognize the correction utterances which follow a recognition error. <b>Correction</b> <b>grammars</b> are dynamically created from existing grammars {{and a set of}} correction templates. We also describe a prototype dialog system which incorporates this error handling method, and provide empirical evidence that this method can improve dialog success rate and reduce the number of dialog turns required for error recovery. ...|$|R
40|$|Response to {{criticism}} of oral <b>grammar</b> <b>correction</b> in second-language (L 2) instruction which argues {{that while there}} are challenges and complexities in providing effective feedback, error correction should not be abandoned. Continued systematic, rigorous research to investigate whether different types of feedback are more effective, {{and to what extent}} this depends on instructional contexts and learner characteristics is recommended. (MSE...|$|E
40|$|When parsing {{unrestricted}} language, wide-covering grammars often undergenerate. Undergeneration can be tackled {{either by}} sentence correction, or by <b>grammar</b> <b>correction.</b> This thesis concentrates upon automatic <b>grammar</b> <b>correction</b> (or machine learning of grammar) {{as a solution}} to the problem of undergeneration. Broadly speaking, <b>grammar</b> <b>correction</b> approaches can be classified as being either data-driven, or model-based. Data-driven learners use data-intensive methods to acquire grammar. They typically use grammar formalisms unsuited to the needs of practical text processing and cannot guarantee that the resulting grammar is adequate for subsequent semantic interpretation. That is, data-driven learners acquire grammars that generate strings that humans would judge to be grammatically ill-formed (they overgenerate) and fail to assign linguistically plausible parses. Model-based learners are knowledge-intensive and are reliant for success upon the completeness of a model of grammaticality. But in practice, the model will be incomplete. Given that in this thesis we deal with undergeneration by learning, we hypothesise that the combined use of data-driven and model-based learning would allow data-driven learning to compensate for model-based learning's incompleteness, whilst model-based learning would compensate for data-driven learning's unsoundness. We describe a system that we have used to test the hypothesis empirically. The system combines data-driven and model-based learning to acquire unification-based grammars that are more suitable for practical text parsing. Using the Spoken English Corpus as data, and by quantitatively measuring undergeneration, overgeneration and parse plausibility, we show that this hypothesis is correct. Comment: DPhil thesis, self-unpacking latex file, 114 pages with 33 pages of appendices...|$|E
40|$|The {{grammar of}} natural {{language}} is generally complex. Often, {{it is very}} difficult to describe it precisely in a formal way. There are several approaches to <b>grammar</b> <b>correction</b> using computer technologies. This thesis deals with the construction of a simple rule-based Czech grammar checker. It focuses on subordinate relative constructions. The corrector is designed to identify missing comma in them. If such a sentence is found the program proposes possible suggestions how to correct it. The application operates as a plugin for OpenOffice suite...|$|E
40|$|We {{evaluate}} {{in great}} detail one-loop four-graviton field theory amplitudes in pure N= 4 D= 4 supergravity. The expressions are obtained by taking the field theory limits of (4, 0) and (2, 2) space-time supersymmetric string theory models. For each model we extract {{the contributions of the}} spin- 1 and spin- 2 N= 4 supermultiplets running in the loop. We show that all of those constructions lead to the same four-dimensional result for the four-graviton amplitudes in pure supergravity even though they come from different string theory models. Comment: 46 pages. One figure. v 2 : minor corrections and clarifications. References added. v 3 : (2, 2) analysis corrected, four-graviton amplitudes found to be indentical in all models. Various clarifications and precisions added. References list updated. v 4 : Assorted spelling and <b>grammar</b> <b>corrections.</b> Version to be publishe...|$|R
40|$|Second Place {{winner of}} poster presentations at the 8 th Annual Symposium on Graduate Research and Scholarly Projects (GRASP) {{held at the}} Marcus Welcome Center, Wichita State University, April 18, 2012. Research {{completed}} at the Department of Curriculum and Instruction, College of EducationGrammar, the order and coordination of words in the English language, is essential to useful and elegant communication. This study addresses the effect of teacher feedback on student writing. Three groups of five freshmen students wrote three essays, and following teacher critique, revised the writing. Each group received different styles of feedback: explicit <b>grammar</b> <b>corrections</b> within the text, marginal notes without specific correction, or narrative teacher response. The results showed that all students improved their writing, but the group receiving a narrative response from the teacher developed {{a higher level of}} ideas and organizational structure within their writing. Graduate School, Office of Research Administration, University Librarie...|$|R
40|$|We {{investigate}} {{the effects of}} random density fluctuations on neutrino oscillations in the Sun environment. We show how the average of certain quantities {{which can be used}} to describe the MSW effect can be computed analytically. We examine also the hypothesis commonly accepted that only perturbations inside the resonance layer can have relevance. The average amplitud, which gives the "coherent probability", is computed in an analytical and exact way for the case of colored δ-correlated gaussian noise: the random perturbation induces a renormalization of the matter density which adquires an imaginary part proportional to the fluctuation amplitud at the resonance region. Integral equations are given for the density matrix of the system in the "optical" approximation. PACS: 96. 60. Kx, 02. 50. Ey, 14. 60. Pq, 95. 30. Cq, 96. 60. Hv, 14. 60. Gh. Comment: 27 latex pages, 6 latex figures, > 10. ps uuencoded figures (epsfig acro neccesary) Minor, but numerous, <b>grammar</b> <b>corrections...</b>|$|R
40|$|The goal of {{this thesis}} is to explore the area of natural {{language}} correction and to design and implement neural network models {{for a range of}} tasks ranging from general <b>grammar</b> <b>correction</b> to the specific task of diacritization. The thesis opens with a description of existing approaches to natural language correction. Existing datasets are reviewed and two new datasets are introduced: a manually annotated dataset for grammatical error correction based on CzeSL (Czech as a Second Language) and an automatically created spelling correction dataset. The main part of the thesis then presents design and implementation of three models, and evaluates them on several natural language correction datasets. In comparison to existing statistical systems, the proposed models learn all knowledge from training data; therefore, they do not require an error model or a candidate generation mechanism to be manually set, neither they need any additional language information such as a part of speech tags. Our models significantly outperform existing systems on the diacritization task. Considering the spelling and basic <b>grammar</b> <b>correction</b> tasks for Czech, our models achieve the best results for two out of the three datasets. Finally, considering the general grammatical correction for English, our models achieve results which are [...] ...|$|E
40|$|We {{describe}} our <b>grammar</b> <b>correction</b> sys-tem for the CoNLL- 2013 shared task. Our system corrects {{three of}} the five er-ror types specified for the shared task-noun-number, determiner and subject-verb agreement errors. For noun-number and determiner correction, we apply a classi-fication approach using rich lexical and syntactic features. For subject-verb agree-ment correction, we propose a new rule-based system which utilizes dependency parse information and a set of conditional rules to ensure agreement of the verb group with its subject. Our system ob-tained an F-score of 11. 03 on the official test set using the M 2 evaluation method (the official evaluation method). ...|$|E
30|$|Written {{corrective}} feedback (WCF) is also commonly referred as <b>grammar</b> <b>correction</b> or written error correction in SLA research (Ferris 2012). In this study, however, we adopt a broad definition of “written {{corrective feedback}}” {{by using the}} term to refer to instructors’ corrective activities toward both grammatical and content aspects of students’ written assignments. This decision is based upon two considerations: first, the central research question of the reported study is ELF learners’ perceptions {{of the relation between}} WCF and the overall effectiveness of their writing; second, instructors from disciplines such as communication, sociology, and political science also conduct extensive WCF activities, yet these activities’ focuses often go beyond grammatical errors.|$|E
40|$|This thesis explores {{language}} and gender on Facebook. A discussion board on a popular Facebook {{group is the}} focus of the study. 19 topic threads from the discussion board were examined. The first theme that I identified in the data is that males made disruptive statements in discussions. Next, males were more likely than females to attack other participants through the use of sarcasm and name calling, often using harsh and aggressive name calling. Although some females utilized personal attacks in discussions, {{they were more likely to}} criticize another participant‟s grammar. Females also used <b>grammar</b> <b>corrections</b> to facilitate relationships. Additionally, female participation was low in discussion threads that contained many arguments and attacks. Females seem to be more engaged in topics where arguments did not take place such as topics devoted to game board discussions where conflict was low. Limitations of the research are discussed and suggestions for future research are offered...|$|R
40|$|The Cobb County Board of Education (Board) {{reserves}} {{the right}} to review Administrative Rules at its discretion. The proposed Rule(s) shall {{be sent to the}} Board for their review in advance of issuance. Specifically, their review shall include at least the ten (10) days immediately prior to the next Board Work Session. If no objection is indicated by Board member(s) to the Chair prior to the adjournment of the Board Work Session, the Rule(s) shall be deemed accepted. If there is an objection, the objecting Board member shall notify the Chair of the objection and the Chair shall add the proposed Rule to the Work Session agenda for discussion and action if appropriate. Changes in wording of a conforming or editorial nature such as <b>grammar</b> <b>corrections,</b> changes of personnel titles, wording clarification, etc., which do not alter the intent or provisions of the Rule, may be made by administration but only published after such changes have been communicated to the Board...|$|R
5000|$|On February 4, 2010, Uforia {{announced}} {{that they would be}} publishing the game as Camon Hero and it would be released later that same year in North America. In March 2010, the company {{announced that}} closed beta testing would run from March 2 to March 5. JK Kim, CEO of Uforia stated, [...] "We are eager to open the game up to players during the closed beta and look forward to their insightful feedback." [...] In celebration of the closed beta test, Uforia offered several events up for players. The first was leveling event where players who reach level 25 during the beta test were given the Private Store Guard Card (30 days), an item that would be offered in the item mall at launch. The [...] "Search for Incorrect Spelling and Grammar Event" [...] challenged players to help find any errors in the game and the top 3 players who submitted the most spelling and <b>grammar</b> <b>corrections</b> for the game client first, would win a large amount of Meso (in game currency) that they can use at launch.|$|R
