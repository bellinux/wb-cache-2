53|10000|Public
40|$|A highly {{integrated}} Front-End readout and <b>Data</b> <b>Acquisition</b> <b>scheme</b> for Silicon trackers is presented. In this context, a 16 -channel readout chip for Silicon strips detector {{has been}} designed in 180 nm CMOS technology, having in view a highly multiplexed and sparsified readout global strategy. First results are presented...|$|E
3000|$|... between them. Such a <b>data</b> <b>acquisition</b> <b>scheme</b> has {{intrinsically}} three modes: time, distance, and components. The proposed method needs multilinear algebra {{in order}} to preserve data structure and avoid reorganization. The data is thus stored in tridimensional arrays rather than matrices. Higher-order eigenvalue decomposition (HOEVD) for fourth-order tensors is considered to achieve subspaces estimation and to compute the eigenelements. We propose a tensorial version of the MUSIC algorithm for a vector-sensor array allowing a joint estimation of DOA and signal polarization estimation. Performances of the proposed algorithm are evaluated.|$|E
30|$|Compressed sensing (CS) [1 – 4] {{is a novel}} <b>data</b> <b>acquisition</b> <b>scheme</b> that samples {{a signal}} at a sub-Nyquist rate, which allows {{simultaneous}} data acquisition and compression. The original signal can be faithfully recovered from the measurement samples, if it is sparse {{with respect to a}} particular basis and sampled via a random projection. With efficient measurement and stable reconstruction, the CS technique has been of interest in a variety of research fields, e.g., communications [5 – 7], sensor networks [8 – 10], image processing [11 – 13], and radar [14].|$|E
40|$|We {{evaluated}} several, previously published, complex conjugate artifact removal {{methods and}} algorithms {{that have been}} proposed for Fourier domain optical coherence tomography (Fd-OCT). To ensure comparable conditions, only one OCT system was used, but with modified <b>data</b> <b>acquisition</b> <b>schemes,</b> depending on the requirements of each method/algorithm. This limited our evaluation to single spectrometer based Fd-OCT approaches. The suppression ratio of complex conjugate artifact images using a paperboard is assessed for all tested methods. Several other metrics are also used for comparison, including a list of additional hardware requirements (beyond standard Fd-OCT components) and <b>data</b> <b>acquisition</b> <b>schemes.</b> Finally, in vivo human finger pad and nail images are presented for comparison to the standard Fd- OCT images and full-range images. © 2010 Copyright SPIE - The International Society for Optical Engineering...|$|R
40|$|Single spectrometer-based complex {{conjugate}} artifact removal {{methods are}} evaluated for in vivo imaging with {{complementary metal-oxide semiconductor}} line scan camera based high-speed Fourier-domain optical coherence tomography (FD-OCT) at 100, 000 axial scans per second. Performance of three different phase-shifting methods with the same OCT engine is evaluated using modified <b>data</b> <b>acquisition</b> <b>schemes,</b> depending on the requirements of each phase-shifting technique. The suppression ratio of complex conjugate artifact images using a paperboard is assessed for all tested methods. Several other characteristics, including a list of additional hardware requirements (beyond standard FD-OCT components) and <b>data</b> <b>acquisition</b> <b>schemes</b> {{for each of the}} methods is presented. In vivo full-range images of human fingerpad and nail are shown and compared with standard FD-OCT images. Additionally, a complex-conjugate-free human retinal volume acquired at the speed of 100, 000 A-scans/s is presented. © 2010 Society of Photo-Optical Instrumentation Engineers...|$|R
40|$|A least-squares {{digital filter}} is {{proposed}} for impulse-response <b>data</b> <b>acquisition</b> <b>schemes.</b> The filter operates {{in real time}} by fitting each signal transient to a filter function. The optimal filter function {{is found to be}} the signal waveform for the case of white noise. The signal-to-noise ratio improvement of the filter is proportional to the square root of the number of data points used in the filter-function waveform...|$|R
30|$|Aside {{from the}} {{imperfection}} in the optical performance of {{transmission electron microscopes}} (TEMs), such as optical aberrations [6, 7], the quality of an electron tomogram depends on additional factors. These arise from the interaction between a sample and the electron beam, the <b>data</b> <b>acquisition</b> <b>scheme</b> and the reconstruction process. While the electron beam damage in a plastic-embedded material mostly depends on the dose rate and not the accumulated dose [8], {{the overall quality of}} EMT data would clearly be improved from collecting more micrographs of a sample, if the micrographs alignment could be effectively optimized to handle the sample warping and other optical distortions.|$|E
40|$|ABSTRACT: The barrel {{time-of-flight}} (TOF) detector for the PANDA experiment at FAIR in Darm-stadt {{is planned}} as a scintillator tile hodoscope (SciTil) using 8000 small scintillator tiles. It will provide fast event timing for a software trigger in the otherwise trigger-less <b>data</b> <b>acquisition</b> <b>scheme</b> of PANDA, relative timing in a multiple track event topology {{as well as}} additional particle iden-tification in the low momentum region. The goal is to achieve a time resolution of σ ' 100 ps. We have conducted measurements using organic scintillators coupled to Silicon Photomultipliers (SiPM). The results are encouraging such that we are confident to reach the required system time resolution...|$|E
40|$|Purpose: The authors’ {{laboratory}} {{is developing}} a dual-panel, breast-dedicated PET system. The detector panels are built from dual-LSO-position-sensitive avalanche photodiode (PSAPD) modules—units holding two 8 × 8 arrays of 1 mm 3 LSO crystals, where each array is coupled to a PSAPD. When stacked to form an imaging volume, these modules are capable of recording the 3 -D coordinates of individual interactions of a multiple-interaction photon event (MIPE). The small size of the scintillation crystal elements used {{increases the likelihood of}} photon scattering between crystal arrays. In this article, the authors investigate how MIPEs impact the system photon sensitivity, the <b>data</b> <b>acquisition</b> <b>scheme,</b> and the quality and quantitative accuracy of reconstructed PET images...|$|E
40|$|The {{application}} of laser anemometry to {{the measurement of}} turbomachinery flow fields is reviewed. Choices of optical configuration, seed particle generation, and seed injection techniques are discussed. The modification of experimental facilities to gain optical access is considered. The efficiency of <b>data</b> <b>acquisition</b> <b>schemes</b> is analyzed and issues related to data integrity and error estimation are addressed. Data reduction and analysis techniques for extracting and understanding the flow physics from laser anemometer measurements are presented...|$|R
40|$|In {{order to}} {{optimize}} a Computed Tomography (CT) system {{with respect to}} quantitative accuracy of the reconstructed value the CT reconstruction process was evaluated. The conventional Feldkamp algorithm for cone-beam reconstruction produces insufficient image quality especially for large cone-angle. So, to get quantitative accurateness, alternative <b>data</b> <b>acquisition</b> <b>schemes</b> like helical scanning were evaluated and tested. In addition, an iterative multi-material beam hardening correction method was developed and implemented which allows for a drastic reduction of beam-hardening artefacts in objects containing several chemically different materials...|$|R
40|$|In this paper, {{we propose}} a dual {{particle}} swarm optimization (PSO) algorithm for parameter identification of chaotic systems. We also consider altering the search range of individual particles adaptively according to their objective function value. We consider both noiseless and noisy channels between the original system and the estimation system. Finally, we verify {{the effectiveness of the}} proposed dual PSO method by estimating the parameters of the Lorenz system using two different <b>data</b> <b>acquisition</b> <b>schemes.</b> Simulation results show that the proposed method always outperforms the traditional PSO algorithm. Department of Electronic and Information Engineerin...|$|R
40|$|Abstract—this paper first {{introduces}} {{social network}} data sets, {{the definition of}} technology and the current situation and challenges in the research of social network, which introduces the research significance of multi-dimensional social network data sets. Then this paper introduces 3 D social <b>data</b> <b>acquisition</b> <b>scheme,</b> including the scheme, the reality of social information acquisition scheme of virtual social information acquisition and self-assessment information acquisition scheme. This paper collected and made three- dimensional social data mobile social network data sets, explored the law of motion of users, from the angle of multiple social data mining to explore the difference and connection between the multi-dimensional social characteristics, the experimental {{results show that the}} prediction accuracy of forecasting model has higher in the paper...|$|E
40|$|Global Navigation Satellite Systems (GNSS) -Reflectometry (GNSS-R) {{has proved}} to be a useful {{technique}} for the estimation of Soil Moisture (SM). In the past 10 years, different techniques such as the Interference Pattern Technique (IPT), the Interferometric Complex Field (ICF) or power measurements of direct and reflected GNSS signals have been used. This work presents a reflectometer concept that can be used for air-borne, Unmanned Aerial Vehicle (UAV), car-borne, and ground-based measurements. It also presents the hardware implementation and the <b>data</b> <b>acquisition</b> <b>scheme.</b> An algorithm for the estimation of the reflectivity of the surface under observation has been developed and compared to concurrent radiometric measurements. Initial results from an airborne field experiment have shown a good correlation between both data sets. Peer ReviewedPostprint (published version...|$|E
40|$|This thesis {{deals with}} chosen aspects of {{terahertz}} (THz) technology that have potential in defense and security-related applications. A novel method for simultaneous data acquisition in time-resolved THz spectroscopy experiments is developed. This technique {{is demonstrated by}} extracting the sheet conductivity of photoexcited charge carriers in semi-insulating gallium arsenide. Comparison with results obtained us-ing a standard <b>data</b> <b>acquisition</b> <b>scheme</b> shows that the new method minimizes errors originating from fluctuations in the laser system out-put and timing errors in the THz pulse detection. Furthermore, a new organic material, BNA, is {{proved to be a}} strong and broadband THz emitter which enables spectroscopy with a bandwidth twice as large as conventional spectroscopy in the field. To access electric fields allowing exploration of THz nonlinear phenom-ena, field enhancement properties of tapered parallel plate waveguide...|$|E
40|$|Several <b>data</b> <b>acquisition</b> <b>schemes</b> for {{diffusion}} MRI {{have been}} proposed and explored to date for {{the reconstruction of the}} 2 nd order tensor. Our main contributions in this paper are: (i) the definition of a new class of sampling schemes based on repeated measurements in every sampling point; (ii) two novel schemes belonging to this class; and (iii) a new reconstruction framework for the second scheme. We also present an evaluation, based on Monte Carlo computer simulations, of the performances of these schemes relative to known optimal sampling schemes for both 2 nd and 4 th order tensors. The results demonstrate that tensor estimation by the proposed sampling schemes and estimation framework is more accurate and robust...|$|R
40|$|Abstract: The {{objective}} {{of this research is}} to develop a strategy to build a mobile system which can be useful for the road safety analysis. Most commonly used data for the road safety analysis are road geometric information. In order to collect and analyze road geometric data, various sensors were tested and installed to collect position data, attitude data, and image data. The development strategies for the RoSSAV are suggested for the various sensors, signal synchronization devices, and the applications of sensor data. Based on the research performed, first, road <b>data</b> <b>acquisition</b> <b>schemes</b> were made; second, required sensors were defined; third, a proto-type analysis vehicle was developed; fourth, a signal synchronization device for the multiple-sensors were designed and developed; fifth, a three dimensional image analysis software was developed...|$|R
40|$|The need {{to reduce}} <b>data</b> <b>acquisition</b> times of multidimensional NMR {{experiments}} has fostered considerable interest in novel <b>data</b> <b>acquisition</b> <b>schemes.</b> A recurring theme is that of reduced dimensionality experiments, in which time evolutions in the indirect dimensions are incremented together, rather than independently. Spectral analysis of such data is carried out using methods such as filtered back-projection, GFT, or parametric signal modeling. By using Maximum Entropy reconstruction of reduced-dimensionality data, we show that the artifacts that arise in reduced dimensionality experiments are intrinsic to the data sampling, and are not, in general, {{the result of the}} methods used to compute spectra. Our results illustrate that reduced dimensionality is a special case of non-uniform sampling in the time domain. We show that MaxEnt reconstruction yields more accurate spectra for reduced dimensionality data than back-projection reconstruction and that randomly choosing time increments based on an exponentially weighted distribution is more efficient, with fewer artifacts, than the systematic coupling of time increments used in most reduced dimensionality approaches...|$|R
40|$|Laser {{velocimetry}} {{has been}} applied successfully in the measurement of mean velocities and Reynolds stresses in a zero pressure gradient, Mach 2. 9 boundary layer, and upstream and downstream of a two-dimensional, shock-wave boundary layer interaction for the same Mach number. The Reynolds stresses were obtained using a one-component, dual-scatter laser velocimeter operated in a manner analogous to the 'slanted hot-wire' technique. Signal processing was of the single-particle counting type which permitted {{measurements to be made}} using only the naturally occurring particles in the tunnel air stream for light scattering. The results for the shock-wave boundary layer interaction are presented along with hot-wire anemometer and pitot-static pressure measurements obtained in the same flow. Also, a <b>data</b> <b>acquisition</b> <b>scheme</b> for use with a two-component laser velocimeter is presented which should provide even better accuracies in future studies...|$|E
40|$|Time-resolved cardiac imaging is {{particularly}} interesting in the interventional setting {{since it would}} provide both image guidance for accurate procedural planning and cardiac functional evaluations directly in the operating room. Imaging the heart in vivo using a slowly rotating C-arm system is extremely challenging due to {{the limitations of the}} data acquisition system and the high temporal resolution required to avoid motion artifacts. In this paper, a <b>data</b> <b>acquisition</b> <b>scheme</b> and an image reconstruction method are proposed to achieve time-resolved cardiac cone-beam computed tomography imaging with isotropic spatial resolution and high temporal resolution using a slowly rotating C-arm system. The data are acquired within 14 s using a single gantry rotation with a short scan angular range. The enabling image reconstruction method is the prior image constrained compressed sensing (PICCS) algorithm. The prior image is reconstructed fro...|$|E
40|$|The {{implemented}} online {{urban noise}} pollution monitoring system is presented {{with regard to}} its conceptual assumptions and technical realization. A concept of the noise source parameters dynamic assessment is introduced. The idea of noise modeling, based on noise emission characteristics and emission simulations, was de-veloped and practically utilized in the system. Furthermore, the working system architecture and the <b>data</b> <b>acquisition</b> <b>scheme</b> are described. The method for increas-ing the speed of noise map calculation employing a supercomputer is explained. The practical implementation of noise maps generation and visualization system is pre-sented, together with introduced improvements {{in the domain of}} continuous noise monitoring and acoustic maps creation. Some results of tests performed using the system prototype are shown. The main focus is put on assessing the efficiency of the acoustic maps created with the discussed system, in comparison to results obtained with traditional methods...|$|E
40|$|Oral {{presentation}} - IUS 1 -B 2 : 3 D and vector velocity imaging: abstract no. US 1 -B 2 - 6 The Conference program & abstracts' website {{is located}} at [URL] MOTIVATION AND OBJECTIVE: Realization of flow imaging at high frame rates can undoubtedly benefit the visualization of complex flow patterns with significant spatiotemporal variations. It would be even better if fluid motion can be coherently rendered through parallel display of both flow trajectory and flow speed. Driven by these motivations, we have developed a new high-frame-rate ultrasound flow visualization technique called color-encoded speckle imaging (CESI). It provides a visually intuitive interpretation of complex flow through a hybrid display format that shows both flow speckle pattern and color-encoded velocity mapping. STATEMENT OF CONTRIBUTION/METHODS: CESI works by integrating two key principles: 1) using broad-view <b>data</b> <b>acquisition</b> <b>schemes</b> …postprin...|$|R
40|$|We present {{methods for}} {{predicting}} {{the solution of}} time-dependent partial differential equations when that solution is so complex that it cannot be properly resolved numerically, but when prior statistical information can be found. The sparse numerical data are viewed as constraints on the solution, and the gist of our proposal {{is a set of}} methods for advancing the constraints in time so that regression methods can be used to reconstruct the mean future. For linear equations we offer general recipes for advancing the constraints; the methods are generalized to certain classes of nonlinear problems, and the conditions under which strongly nonlinear problems and partial statistical information can be handled are briefly discussed. Our methods are related to certain <b>data</b> <b>acquisition</b> <b>schemes</b> in oceanography and meteorology. 1 Introduction There are many problems in science whose solution is described in principle by a set of partial differential equations, but where the solutions [...] ...|$|R
40|$|This paper {{investigates the}} {{application}} of a compressed sampling (CS) algorithm as a spectrum sensing and signal analysis preprocessor for vector measurements of digital modulations. Compressed sampling is a paradigm which exploits sparsity, a feature common to several signals of interest, to allow the design of efficient <b>data</b> <b>acquisition</b> <b>schemes.</b> These need to be followed by more complex signal processing algorithms for accurate signal reconstruction. The discussion focuses on {{the application of}} a CS algorithm to spectrum sensing and modulation analysis in wireless communications. When the signals of interest occupy only a few among several possible bands, and do so only for short time bursts, feeding a vector signal analyser with the required preliminary information becomes increasingly important, but also more challenging. Results presented in the paper show that a CS algorithm can successfully extract such information from a record of signal samples, providing spectrum-blind sensing capabilities...|$|R
30|$|Traditionally in EMT, the <b>data</b> <b>acquisition</b> <b>scheme</b> {{consists}} in single or double tilt series [9, 10], with rather large angle increments (≃ 2 °) {{in order to}} reduce the specimen full exposure to the electron beam radiations. In particular, assuming a full pixel resolution can be achieved, we note that the basic sampling requirement arising from a 2 D analysis, Δθ = (2 /L)* 180 ^∘/π [25], would not be fulfilled with the latest detector size—with for instance L= 4 k pixels, Δθ≃ 0.03 ^∘. Refined sampling schemes have been developed within the context of Fourier slice theorem to optimize the resolution of the obtained reconstructions [26, 27]. Nevertheless, the reconstruction artifacts caused by (i) the missing data issue (this is the missing wedge/pyramid problem) and (ii) the discretization problem, can only be attenuated through more sampling, and in some extent by computationally intensive iterative reconstruction methods.|$|E
40|$|This paper {{discusses}} improving performance (throughput) of {{data server}} systems by introducing proper data redundancy into the system. General performance properties of a server system with redundant data are described. We show that proper data redundancy in a server system can signicantly improve the performance, {{in addition to}} the reliability of the system. Two problems related to the performance together with their solutions are proposed, namely, the problems of ecient data distribution scheme for the servers and <b>data</b> <b>acquisition</b> <b>scheme</b> for the client. Both schemes utilize array codes, a class of error-correcting codes whose encoding and decoding procedures only use simple binary exclusive-OR operations, which can be implemented eciently in software and/or hardware. Construction of general MDS array codes suitable for the both schemes is discussed. A new property of MDS array codes, called the strong MDS property, is also dened to improve the data acquisition performance [...] ...|$|E
30|$|In {{order to}} improve the {{electron}} tomogram quality of dose tolerant specimens, we developed a multiple-tilt series <b>data</b> <b>acquisition</b> <b>scheme</b> for the EMT. In contrast to the traditional single/double tilt series acquisition protocol [9, 10], this approach involves recording {{of a very large}} number of low dose or low-dose rate micrographs distributed across a wider range of specimen rotations. By sampling the specimen of interest through more orientations, the data folding into the reconstructed volume become more evenly distributed, further reducing sampling artifacts and producing higher quality tomograms. The visibility of weakly contrasted structures and thus overall specimen contrast is also enhanced by the additional summing of feature densities which accrues from the convergence of the greater multiplicity of views of the same weakly stained objects. To reduce the additional complexity of this extreme sampling and multiple tilt series reconstruction strategy, we have developed automated procedures for alignment and volume generation processes, reducing (or eliminating) the requirement for user input.|$|E
40|$|Technology {{concerning}} mobile devices {{has presented}} revolutionary growth {{during the last}} decade. Mobile phones do not serve only {{as a means of}} communication, but also as portable computers with advanced communication capabilities. Smartphones are able to store a rich set of personal information {{and at the same time}} provide powerful services, such as location-based services, Internet sharing via tethering, and intelligent voice, thus increasing the likelihood of a such devices being involved in a criminal activities. Mobile forensics is the science of recovering digital evidence from a mobile device under forensically sound conditions using accepted methods. During the last few years, a significant amount of research has been conducted, concerning various mobile device platforms forensics, <b>data</b> <b>acquisition</b> <b>schemes,</b> and information extraction methods. This paper provides a comprehensive overview of the field, by presenting a detailed assessment of methodologies regarding Android forensic and anti-forensic techniques...|$|R
40|$|Wireless {{smart sensor}} {{networks}} {{have become an}} attractive alternative to traditional wired sensor systems {{in order to reduce}} implementation costs of structural health monitoring systems. The onboard sensing, computation, and communication capabilities of smart wireless sensors have been successfully leveraged in numerous monitoring applications. However, the current <b>data</b> <b>acquisition</b> <b>schemes,</b> which completely acquire data remotely prior to processing, limit the applications of wireless smart sensors (e. g., for real-time visualization of the structural response). While real-time <b>data</b> <b>acquisition</b> strategies have been explored, challenges of implementing highthroughput real-time <b>data</b> <b>acquisition</b> over larger network sizes still remain due to operating system limitations, tight timing requirements, sharing of transmission bandwidth and unreliable wireless radio communication. This report presents the implementation of real-time wireless <b>data</b> <b>acquisition</b> on the Imote 2 platform. The challenges presented by hardware and software limitations are addressed in the application design. The framework is then expanded for highthroughput applications that necessitate larger networks sizes with higher sampling rates. Two approaches are implemented and evaluated based on network size, associated sampling rate, and data delivery reliability. Ultimately, the communication and processing protocol allows for nearreal- time sensing of 108 channels across 27 nodes with minimal data loss. published or submitted for publicationnot peer reviewe...|$|R
40|$|Available {{industrial}} {{energy meters}} offer high accuracy and reliability, but are typically expensive and low-bandwidth, making them poorly suited to multi-sensor <b>data</b> <b>acquisition</b> <b>schemes</b> and power quality analysis. An alternative measurement system is proposed {{in this paper}} that is highly modular, extensible and compact. To minimise cost, the device makes use of planar coreless PCB transformers to provide galvanic isolation for both power and data. Samples from multiple acquisition devices may be concentrated by a central processor before integration with existing host control systems. This paper focusses on the practical design and implementation of planar coreless PCB transformers to facilitate the module's isolated power, clock and data signal transfer. Calculations necessary to design coreless PCB transformers, and circuits designed for the transformer's practical application in the measurement module are presented. The designed transformer and each application circuit have been experimentally verified, with test data and conclusions made applicable to coreless PCB transformers in general...|$|R
40|$|International audienceThis paper {{addresses}} {{the problem of}} high-resolution polarized source detection and introduces a new eigenstructure-based algorithm that yields direction of arrival (DOA) and polarization estimates using a vector-sensor (or multicomponent-sensor) array. This method is based on separation of the observation space into signal and noise subspaces using fourth-order tensor decomposition. In geophysics, in particular for reservoir acquisition and monitoring, a set of Nx-multicomponent sensors is laid {{on the ground with}} constant distance Δx between them. Such a <b>data</b> <b>acquisition</b> <b>scheme</b> has intrinsically three modes: time, distance, and components. The proposed method needs multilinear algebra in order to preserve data structure and avoid reorganization. The data is thus stored in tridimensional arrays rather than matrices. Higher-order eigenvalue decomposition (HOEVD) for fourth-order tensors is considered to achieve subspaces estimation and to compute the eigenelements. We propose a tensorial version of the MUSIC algorithm for a vector-sensor array allowing a joint estimation of DOA and signal polarization estimation. Performances of the proposed algorithm are evaluated...|$|E
40|$|Multiple {{scattering}} of elastic waves in disordered media offers a {{complexity of the}} wave field that is challenging to unravel. The subsurface {{is an example of}} a medium with disordered inhomogeneity at all scales. However, because waves that bounce around for a long time and/or distance sample the Earth well, they potentially offer great insight into the structure of the subsurface. A surface wave scattering model is presented to aid the understanding of multiple scattering. Advantages of this model include accessibility of the wave field within the scattering medium, tunable scattering strength, availability of phase and amplitude information, and the relative longevity of surface waves. Accompanied by a state-ofthe-art non-contacting <b>data</b> <b>acquisition</b> <b>scheme,</b> this system proved ideal for unveiling the effects of multiple scattering. When a pulse is launched in a strongly scattering medium, it travels ballistically at first, but turns diffusive as multiply scattered waves interfere with the incident pulse. Radiative transfer has proven to describe both the transmission of the coheren...|$|E
40|$|Introduction This work {{is part of}} a test {{project for}} the third level trigger and on-line full event {{reconstruction}} for the HERA-B experiment[1]. The high event rate (10 MHz - corresponding to the bunch crossing rate) with multiple interactions per bunch crossing will produce more than 10 7 particles per second per square centimeter in the innermost detector region. The event rate is expected to be reduced by about five orders of magnitude by a three-level trigger system. The 1 AIHENP' 96 SE- 142 2 Corresponding author. Tel. :+ 49 3762 77 350, fax: + 49 3762 77 330, e-mail: legrand@ifh. de Preprint submitted to Elsevier Preprint 11 November first and second level trigger will operate on a limited range of data, due to the hard time constraints for these systems. In the <b>data</b> <b>acquisition</b> <b>scheme</b> the event building is performed after the second level trigger decision. The events are then routed to the third level trigger, a...|$|E
40|$|Quantitative mass {{spectrometry}} is a rapidly evolving methodology applied {{in a large}} number of omics-type research projects. During the past years, new designs of mass spectrometers have been developed and launched as commercial systems while in parallel new <b>data</b> <b>acquisition</b> <b>schemes</b> and <b>data</b> analysis paradigms have been introduced. Core facilities provide access to such technologies, but also actively support the researchers in finding and applying the best-suited analytical approach. In order to implement a solid fundament for this decision making process, core facilities need to constantly compare and benchmark the various approaches. In this article we compare the quantitative accuracy and precision of current state of the art targeted proteomics approaches single reaction monitoring (SRM), parallel reaction monitoring (PRM) and <b>data</b> independent <b>acquisition</b> (DIA) across multiple liquid chromatography {{mass spectrometry}} (LC-MS) platforms, using a readily available commercial standard sample. All workflows are able to reproducibly generate accurate quantitative data. However, SRM and PRM workflows show higher accuracy and precision compared to DIA approaches, especially when analyzing low concentrated analytes...|$|R
40|$|Computed {{tomography}} {{entails the}} reconstruction of a function from measurements of its line integrals. In this article we explore the question: How many and which line integrals should be measured {{in order to achieve}} a desired resolution in the reconstructed image? Answering this question may help {{to reduce the amount of}} measurements and thereby the radiation dose, or to obtain a better image from the data one already has. Our exploration leads us to a mathematically and practically fruitful interaction of Shannon sampling theory and tomography. For example, sampling theory helps to identify efficient <b>data</b> <b>acquisition</b> <b>schemes,</b> provides a qualitative understanding of certain artifacts in tomographic images, and facilitates the error analysis of some reconstruction algorithms. On the other hand, applications in tomography have stimulated new research in sampling theory, e. g., on nonuniform sampling theorems and estimates for the aliasing error. The focus of this article will be the application of sampling theory to the so-called fan-beam geometry. Its dual aim is an exposition of the main principles involved as well as the development of some new insights...|$|R
40|$|Subproject A 2 'logistics {{solutions}} for medium-sized firms' of the integrated materials flow systems research project, stage II, {{was dedicated to}} the development of practical computerized solutions to logistic planning and operation. An economic scheme for the structural, technical and organizational logistics of a medium-sized mechanical-seals production firm was developed based on the optimization of different intra-plant logistics levels. The factory space level was optimized by improving the layout, storage and buffering structures and the plant's autonomous logistics subsystems. Optimization at the technology level was achieved by improving the means of production, the materials handling and storage techniques and the handling systems. The organization and control level was optimized by developing better production planning and control, logistics control and operations scheduling schemes. Optimization at the information level was ensured by improved document handling, information process and production <b>data</b> <b>acquisition</b> <b>schemes.</b> A supra-plant logistics-oriented information system was developed in addition. (orig.) Available from TIB Hannover: F 94 B 0528 / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEBundesministerium fuer Forschung und Technologie (BMFT), Bonn (Germany) DEGerman...|$|R
