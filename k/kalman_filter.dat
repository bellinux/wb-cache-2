10000|3578|Public
5|$|Given {{the number}} of {{navigation}} algorithms calculating simultaneously to provide all the information in real time, {{research has been conducted}} to improve the computation time of some numerical methods using field-programmable gate arrays. The research focused on visual perception. The first part was focused on the simultaneous localization and mapping with an extended <b>Kalman</b> <b>filter</b> that estimates the state of a dynamic system from a series of noisy or incomplete measures. The second focused on the location and the detection of obstacles.|$|E
5|$|Control {{systems have}} a need for {{smoothing}} filters in their feedback loops with criteria to maximise the speed of movement of a mechanical system to the prescribed mark {{and at the same}} time minimise overshoot and noise induced motions. A key problem here is the extraction of Gaussian signals from a noisy background. An early paper on this was published during WWII by Norbert Wiener with the specific application to anti-aircraft fire control analogue computers. Rudy Kalman (<b>Kalman</b> <b>filter)</b> later reformulated this in terms of state-space smoothing and prediction where it is known as the linear-quadratic-Gaussian control problem. Kalman started an interest in state-space solutions, but according to Darlington this approach can also be found in the work of Heaviside and earlier.|$|E
25|$|The update {{equations}} {{are identical}} {{to those of the}} discrete-time <b>Kalman</b> <b>filter.</b>|$|E
40|$|For linear time {{invariant}} continuous-time {{systems with}} either unknown or white noise input, two well-known filtering problems are considered. These are the unknown input observer {{problem and the}} <b>Kalman</b> <b>filtering</b> problem. Most of the available literature on <b>Kalman</b> <b>filtering</b> considers the so-called regular filtering problem. We consider here the general singular filtering problem. We show that such a <b>Kalman</b> <b>filtering</b> problem for a given system can be transformed to the unknown input observer problem for an auxiliary system constructed from the data of the given system. Such transformations between these two filtering problems enable us to study various properties of <b>Kalman</b> <b>filtering,</b> including existence and uniqueness of <b>Kalman</b> <b>filters,</b> computation of performance indices of <b>Kalman</b> <b>filtering,</b> and performance limitations of <b>Kalman</b> <b>filtering</b> as related to the structural properties of the given system...|$|R
40|$|<b>Kalman</b> <b>Filtering</b> with Real-Time Applications {{presents}} a thorough {{discussion of the}} mathematical theory and computational schemes of <b>Kalman</b> <b>filtering.</b> The filtering algorithms are derived via different approaches, including a direct method consisting {{of a series of}} elementary steps, and an indirect method based on innovation projection. Other topics include <b>Kalman</b> <b>filtering</b> for systems with correlated noise or colored noise, limiting <b>Kalman</b> <b>filtering</b> for time-invariant systems, extended <b>Kalman</b> <b>filtering</b> for nonlinear systems, interval <b>Kalman</b> <b>filtering</b> for uncertain systems, and wavelet <b>Kalman</b> <b>filtering</b> for multiresolution analysis of random signals. Most filtering algorithms are illustrated by using simplified radar tracking examples. The style of the book is informal, and the mathematics is elementary but rigorous. The text is self-contained, suitable for self-study, and accessible to all readers with a minimum knowledge of linear algebra, probability theory, and system engineering...|$|R
30|$|In this paper, we give {{a survey}} of new results on <b>Kalman</b> <b>filtering</b> leading to {{boundary}} value problems. Such a connection between <b>Kalman</b> <b>filtering</b> and boundary value problems arise in cases when the noises involved to the <b>Kalman</b> <b>filtering</b> problem are delayed in time.|$|R
25|$|Extensions and generalizations to {{the method}} {{have also been}} developed, such as the {{extended}} <b>Kalman</b> <b>filter</b> and the unscented <b>Kalman</b> <b>filter</b> which work on nonlinear systems. The underlying model is a Bayesian model similar to a hidden Markov model except that the state space of the latent variables is continuous and all latent and observed variables have Gaussian distributions.|$|E
25|$|The <b>Kalman</b> <b>filter</b> can be {{presented}} {{as one of}} the simplest dynamic Bayesian networks. The <b>Kalman</b> <b>filter</b> calculates estimates of the true values of states recursively over time using incoming measurements and a mathematical process model. Similarly, recursive Bayesian estimation calculates estimates of an unknown probability density function (PDF) recursively over time using incoming measurements and a mathematical process model.|$|E
25|$|The Kalman–Bucy filter (named after Richard Snowden Bucy) is a {{continuous}} time {{version of the}} <b>Kalman</b> <b>filter.</b>|$|E
40|$|Abstract:- Two main {{difficulties}} in process monitoring are lack of reliable measurements of key process variables and difficulty in defining quantitative relationships between state variables. In this study sensor networks {{are used to}} demonstrate an approach based on <b>Kalman</b> <b>filtering</b> to model the specific monitoring systems. <b>Kalman</b> <b>filtering</b> at both local nodes and fusion center are the covariance matrices of tracking errors. Performance analysis {{is dedicated to the}} distributed <b>Kalman</b> <b>filtering</b> fusion for distributed recursive state estimators of dynamic systems under consideration. Key-Words:- Distributed processing, performance, sensors, <b>Kalman</b> <b>filtering...</b>|$|R
40|$|This {{new edition}} {{presents}} a thorough {{discussion of the}} mathematical theory and computational schemes of <b>Kalman</b> <b>filtering.</b> The filtering algorithms are derived via different approaches, including a direct method consisting {{of a series of}} elementary steps, and an indirect method based on innovation projection. Other topics include <b>Kalman</b> <b>filtering</b> for systems with correlated noise or colored noise, limiting <b>Kalman</b> <b>filtering</b> for time-invariant systems, extended <b>Kalman</b> <b>filtering</b> for nonlinear systems, interval <b>Kalman</b> <b>filtering</b> for uncertain systems, and wavelet <b>Kalman</b> <b>filtering</b> for multiresolution analysis of random signals. Most filtering algorithms are illustrated by using simplified radar tracking examples. The style of the book is informal, and the mathematics is elementary but rigorous. The text is self-contained, suitable for self-study, and accessible to all readers with a minimum knowledge of linear algebra, probability theory, and system engineering. Over 100 exercises and problems with solutions help deepen the knowledge. This new edition has a new chapter on filtering communication networks and data processing, together with new exercises and new real-time applications...|$|R
30|$|Nonlinear {{filtering}} {{methods can}} be classified into five types [10, 11]: 1) extended <b>Kalman</b> <b>filtering</b> (EKF), 2) interpolation <b>filtering,</b> 3) unscented <b>Kalman</b> <b>filtering</b> (UKF), 4) particle filtering, and 5) neural network filtering.|$|R
25|$|This <b>Kalman</b> <b>filter</b> {{was first}} {{described}} and partially developed in technical papers by Swerling (1958), Kalman (1960) and Kalman and Bucy (1961).|$|E
25|$|Bousquet, O., Balakrishnan, K. and Honavar, V. (1998). Is the Hippocampus a <b>Kalman</b> <b>Filter?.</b> In: Proceedings of the Pacific Symposium on Biocomputing. Singapore: World Scientific. pp.655–666.|$|E
25|$|In some applications, it {{is useful}} to compute the {{probability}} that a <b>Kalman</b> <b>filter</b> with a given set of parameters (prior distribution, transition and observation models, and control inputs) would generate a particular observed signal. This probability is known as the marginal likelihood because it integrates over ("marginalizes out") the values of the hidden state variables, so it can be computed using only the observed signal. The marginal likelihood can be useful to evaluate different parameter choices, or to compare the <b>Kalman</b> <b>filter</b> against other models using Bayesian model comparison.|$|E
40|$|This {{paper is}} {{concerned}} with distributed <b>Kalman</b> <b>filtering</b> for linear time-varying systems over multi-agent sensor networks. We propose a diffusion <b>Kalman</b> <b>filtering</b> algorithm based on a covariance intersection method, where local estimates are fused by incorporating the covariance information of local <b>Kalman</b> <b>filters.</b> Our algorithm leads to a stable estimate for each agent {{regardless of whether the}} system is uniformly observable with respect to local measurements as long as the system is uniformly observable under global sensor measurements and the communication is sufficiently fast compared to the sampling period. Simulation results validate the effectiveness of the proposed distributed <b>Kalman</b> <b>filtering</b> algorithm...|$|R
40|$|Dimirovski, Georgi M. (Dogus Author) This paper {{introduces}} {{an extended}} {{environment for the}} unscented <b>Kalman</b> <b>filtering</b> that considers also the presence of additive noise on input observations in order {{to solve the problem}} of optimal estimation of noise-corrupted input and output sequences. This environment includes as sub-cases both errors-in-variables <b>filtering</b> and unscented <b>Kalman</b> <b>filtering.</b> The unscented <b>Kalman</b> <b>filtering</b> to the presence of additive noise on input observations is considered, and is used {{to solve the problem of}} optimal estimation of noise-corrupted input and output sequences. A Monte Carlo simulation shows that the performance of the unscented <b>Kalman</b> <b>filtering</b> technique leads to the expected minimal variance estimates...|$|R
40|$|This paper {{proposes a}} new {{distributed}} <b>Kalman</b> <b>filtering</b> fusion with random state transition and measurement matrices, i. e., random parameter matrices <b>Kalman</b> <b>filtering.</b> It is proved that under a mild condition the fused state estimate {{is equivalent to}} the centralized <b>Kalman</b> <b>filtering</b> using all sensor measurements; therefore, it achieves the best performance. More importantly, this result can be applied to <b>Kalman</b> <b>filtering</b> with uncertain observations including the measurement with a false alarm probability as a special case, as well as, randomly variant dynamic systems with multiple models. Numerical examples are given which support our analysis and show significant performance loss of ignoring the randomness of the parameter matrices...|$|R
25|$|The <b>Kalman</b> <b>filter</b> {{does not}} make any {{assumption}} that the errors are Gaussian. However, the filter yields the exact conditional probability estimate in the special case that all errors are Gaussian-distributed.|$|E
25|$|In the {{extended}} <b>Kalman</b> <b>filter</b> (EKF), the state transition and observation models {{need not be}} linear functions of the state but may instead be non-linear functions. These functions are of differentiable type.|$|E
25|$|At each timestep the Jacobian is {{evaluated}} with current predicted states. These matrices {{can be used in}} the <b>Kalman</b> <b>filter</b> equations. This process essentially linearizes the non-linear function around the current estimate.|$|E
40|$|AbstractUsing {{the modern}} time series {{analysis}} method, by the left-coprime factorization, the autoregressive moving average (ARMA) innovation model is constructed, by which two measurement fusion steady-state <b>Kalman</b> <b>filtering</b> algorithms are presented. They have asymptotically global optimality. A numerical simulation example for threesensor tracking system verifies their functional equivalence to the centralized fusion steady-state <b>Kalman</b> <b>filtering</b> algorithms based on the ARMA innovation model {{and based on the}} Riccati equation by the classical <b>Kalman</b> <b>filtering</b> method...|$|R
40|$|In this paper, {{we study}} the optimal <b>Kalman</b> <b>filtering</b> problem for multiparameter {{singularly}} perturbed sys-tem (MSPS). The {{attention is focused}} on the design of the high–order approximate <b>Kalman</b> <b>filters.</b> It is shown that the resulting filters in fact remove ill–conditioning of the original full–order singularly perturbed <b>Kalman</b> <b>filters.</b> In addition the resulting filters can be used compared with the previously proposed result even if the Hamiltonian matrices for the fast subsystems have eigenvalues in common. ...|$|R
40|$|A {{rigorous}} {{performance analysis}} {{is dedicated to}} the distributed <b>Kalman</b> <b>filtering</b> fusion with feedback for distributed recursive state estimators of dynamic systems. It is shown that the <b>Kalman</b> <b>filtering</b> track fusion formula with feedback is, like the track fusion without feedback, exactly equivalent to the corresponding centralized <b>Kalman</b> <b>filtering</b> formula. Moreover, the so-called P matrices in the feedback <b>Kalman</b> <b>filtering</b> at both local trackers and fusion center are still the covariance matrices of tracking errors. Although the feedback here cannot improve the performance at the fusion center, the feedback does reduce the covariance of each local tracking error. The above results can be extended to a hybrid track fusion with feedback received by a part of the local trackers...|$|R
25|$|The basic <b>Kalman</b> <b>filter</b> {{is limited}} to a linear assumption. More complex systems, however, can be nonlinear. The {{non-linearity}} can be associated either with the process model or with the observation model or with both.|$|E
25|$|In {{autonomous}} robotics, Monte Carlo localization {{can determine}} {{the position of a}} robot. It is often applied to stochastic filters such as the <b>Kalman</b> <b>filter</b> or particle filter that forms the heart of the SLAM (simultaneous localization and mapping) algorithm.|$|E
25|$|However, {{when the}} <b>Kalman</b> <b>filter</b> {{is used to}} {{estimate}} the state x, the probability distribution of interest is that associated with the current states conditioned on the measurements up to the current timestep. This is achieved by marginalizing out the previous states and dividing by the probability of the measurement set.|$|E
40|$|<b>Kalman</b> <b>filtering</b> is {{a classic}} state {{estimation}} technique used widely in engineering applications such as statistical signal processing and control of vehicles. It is now being used to solve problems in computer systems, such as controlling the voltage and frequency of processors to minimize energy while meeting throughput requirements. Although there are many presentations of <b>Kalman</b> <b>filtering</b> in the literature, they are usually focused on particular problem domains such as linear systems with Gaussian noise or robot navigation, which {{makes it difficult to}} understand the general principles behind <b>Kalman</b> <b>filtering.</b> In this paper, we first present the general statistical ideas behind <b>Kalman</b> <b>filtering</b> at a level accessible to anyone with a basic knowledge of probability theory and calculus, and then show how these abstract concepts can be applied to state estimation problems in linear systems. This separation of abstract concepts from applications should make it easier to apply <b>Kalman</b> <b>filtering</b> to other problems in computer systems. Comment: Added acknowledgements and fixed typo...|$|R
40|$|AbstractAiming at the {{characteristic}} of Ankang reservoir, the coupling of robustness and <b>kalman</b> <b>filtering</b> was firstly {{taken in the}} real-time co-correction model parameters estimation based on the improving Xin’anjiang models. The coupling of robustness and <b>kalman</b> <b>filtering</b> was {{used to make the}} dynamic estimation of AR model's error equation parameter, then compared with the outcome of the <b>kalman</b> <b>filtering.</b> The result shows that when hydrological data carries unusual errors, this algorithm could resist the harmful effects and has better tracking ability...|$|R
40|$|Abstract. In {{the active}} support control system, the {{sampling}} accuracy of force sensor directly affect the force control precision of the system, {{the surface of}} the primary mirror, and then affect the imaging quality of the optical system. Based on the <b>Kalman</b> <b>filtering,</b> this document introduces the force sensor signal filtering model of the active support system, verifies the validity of <b>Kalman</b> <b>filtering</b> to filtering the random noise signal via the <b>Kalman</b> <b>filtering</b> processing and analysis of the sampling of the active support system, realizes the high accuracy force of the system, which better the shape of the primary mirror...|$|R
25|$|In Dempster–Shafer theory, {{each state}} {{equation}} or observation {{is considered a}} special case of a linear belief function and the <b>Kalman</b> <b>filter</b> is a special case of combining linear belief functions on a join-tree or Markov tree. Additional approaches include belief filters which use Bayes or evidential updates to the state equations.|$|E
25|$|It {{follows from}} {{theory that the}} <b>Kalman</b> <b>filter</b> is the optimal linear filter in cases where a) the model {{perfectly}} matches the real system, b) the entering noise is white (uncorrelated) and c) the covariances of the noise are exactly known. Several methods for the noise covariance estimation have been proposed during past decades, including ALS, mentioned in the section above. After the covariances are estimated, {{it is useful to}} evaluate the performance of the filter; i.e., whether it is possible to improve the state estimation quality. If the <b>Kalman</b> <b>filter</b> works optimally, the innovation sequence (the output prediction error) is a white noise, therefore the whiteness property of the innovations measures filter performance. Several different methods can be used for this purpose. If the noise terms are non-Gaussian distributed, methods for assessing performance of the filter estimate, which use probability inequalities or large-sample theory, are known in the literature.|$|E
25|$|The <b>Kalman</b> <b>filter</b> uses a system's {{dynamics}} model (e.g., physical laws of motion), known {{control inputs}} to that system, and multiple sequential measurements (such as from sensors) {{to form an}} estimate of the system's varying quantities (its state) that is better than the estimate obtained by using only one measurement alone. As such, it is a common sensor fusion and data fusion algorithm.|$|E
40|$|Abstract. The {{application}} of distributed multi-sensor information fusion technology in accurate positioning of Underwater Vehicle {{was introduced in}} this paper. According to the system structure of Distributed multi-sensor in an AUV “T 1 ”, this article establishes the <b>Kalman</b> <b>filtering</b> mathematical model, accomplishes the fusion algorithm based on <b>Kalman</b> <b>filtering</b> and a numerical simulation. The experimental result shows that the {{application of}} fusion algorithm based on <b>Kalman</b> <b>filtering</b> can avoid the limitations of a single sensor, reduce its uncertainty impact and increase the confidence level of data...|$|R
40|$|This report {{presents}} {{some preliminary}} results on speech enhancement using <b>Kalman</b> <b>filtering</b> techniques {{for use with}} a speaker verification system. <b>Kalman</b> <b>filtering</b> is shown to improve hte performance of the dynamic time-warping distance measure {{in addition to the}} expected improvement in signal-to-noise ratio of the processed signal...|$|R
5000|$|... #Subtitle level 3: Generalized <b>filtering</b> and <b>Kalman</b> <b>filtering</b> ...|$|R
