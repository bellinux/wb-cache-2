4|10000|Public
30|$|Citizen science {{projects}} can {{be classified}} into different types depending on several factors. For example, Roy etÂ al. (2012) derived different clusters of citizen science projects based on <b>how</b> <b>they</b> <b>scored</b> on two dimensions. The first dimension accounted for the degree of mass participation (i.e. mass participation projects versus local monitoring projects), while the second dimension was interpreted as the degree of investment (i.e. investment of project managers, investment of background information and supporting material, and the time-investment of the participants). In this paper, we follow a similar thinking process in terms of classifying different types of citizen surveillance into a two-dimensional system. However, we specifically focus on the quantitative characteristics of the citizen-sourced data, {{because they are more}} relevant with respect to choosing an analysis method.|$|E
40|$|Understanding {{their own}} {{learning}} styles can assist students {{as they relate to}} one another and ultimately to their future clients. Purpose: The {{purpose of this study was}} to describe the preferred learning and personality styles of a convenience sample of Central Michigan University students enrolled in the following health-related professions: Athletic Training, Communication Disorders, Social Work, and Physician Assistant. Method: Students completed two self-administered online instruments used to measure learning styles, the VARK and the online version of the Keirsey Temperament Sorter II (KTS-II). Associations between VARK learning style scores and the online Keirsey Temperament Sorter II results were also examined. Results: Seventy-four percent of the students scored as Guardians (Sensing-Judging) based on the online KTS-II report and 62 % were multimodal learners on the online version of the VARK. Conclusion: This study confirmed previous findings that Guardian is the preferred temperament type on the MBTI/KTS-II for health professions students. Average scores on the VARK and the Keirsey did not differ between the various health-related disciplines; however, students scoring as Idealists (Intuition/Feeling) on the Keirsey had significantly higher Aural scores on the VARK when compared to those with Guardian temperaments. There was no significant difference found between Keirsey groups and <b>how</b> <b>they</b> <b>scored</b> on Vark-V (Visual), R/W (Read/Write), or K (Kinesthetic) learning style dimensions...|$|E
40|$|The {{purpose of}} this essay is to {{investigate}} different types of feedback {{and how they are}} used in schools, and to see which of them are preferred when it comes to error correction. Feedback is used in schools every day even though {{it is difficult to know}} if students really learn from it. Students tend to only glance briefly at the paper or test when it is returned and then throw it away. They are interested in <b>how</b> <b>they</b> <b>scored</b> but not really in how to improve their errors until next time. In this study, students wrote essays which were corrected with four different types of feedback and handed back to the students. The students got a chance to revise them and then the result was analyzed. The students were also given a questionnaire in order for me to find out what kind of feedback they liked the most and compare it to the result of the essay corrections. The different feedback types worked well with different students in general, although, underlining with description did not only work best, it was also chosen as the best type by most students. They seemed to think that this type was good for learning something from the feedback. Most students wanted to look for errors themselves instead of getting the correct answer from the teacher...|$|E
50|$|Reviews: This section had {{reviews for}} games {{released}} over {{during the previous}} month, or those available between the current and next issues. It had a front page explaining <b>how</b> <b>they</b> <b>score,</b> along with another contents section detailing {{the pages of the}} reviews. As well as UK releases, the magazine also reviewed the major Japanese and American releases and had a round-up of other games {{at the end of the}} section.|$|R
5000|$|Slavin (1995) {{enumerated}} {{three main}} concepts of STAD as team rewards, individual accountability and for equal opportunities for success [...] Team rewards are certificates or either rewards which are given if a STAD group achieves higher than predetermined level [...] In this way {{a spirit of}} positive competition is reinforced and all or none of the groups would be rewarded based on <b>how</b> <b>they</b> <b>score.</b> In terms of individual accountability, the individual learning {{of each of the}} group members determines the success of the terms.|$|R
50|$|According to Isabel Briggs Myers, a person's {{decision-making}} process depends {{to a significant}} degree on their cognitive style. Myers developed a set of four bi-polar dimensions, called the Myers-Briggs Type Indicator (MBTI). The terminal points on these dimensions are: thinking and feeling; extroversion and introversion; judgment and perception; and sensing and intuition. She claimed that a person's decision-making style correlates well with <b>how</b> <b>they</b> <b>score</b> on these four dimensions. For example, someone who scored near the thinking, extroversion, sensing, and judgment ends of the dimensions would {{tend to have a}} logical, analytical, objective, critical, and empirical decision-making style. However, some psychologists say that the MBTI lacks reliability and validity and is poorly constructed.|$|R
40|$|The {{number of}} {{performance}} assessment tasks has {{increased over the}} years because some constructs are best assessed in this manner. Though there are benefits to using performance tasks, there are also drawbacks. The problems with performance assessments include scoring time, scoring costs, and problems with human raters. One solution for overcoming the drawbacks of performance assessments {{is the use of}} automated scoring programs. There are several automated scoring programs designed to score essays and other constructed responses. Much research has been conducted on these programs by program developers; however, relatively little research has used external criteria to evaluate automated programs. ^ The {{purpose of this study was}} to evaluate two popular automated scoring programs. The automated scoring programs were evaluated with respect to several criteria: the percent of exact and adjacent agreements, kappas, correlations, differences in score distributions, discrepant scoring, analysis of variance, and generalizability theory. The scoring results from the two automated scoring programs were compared to the scores from operational scoring and an expert panel of judges. ^ The results indicated close similarity between the two scoring program regarding <b>how</b> <b>they</b> <b>scored</b> the essays. However, the results also revealed some subtle, but important, differences between the programs. One program exhibited higher correlations and agreement indices with both the operational and expert committee scores, although the magnitude of the different was small. Differences were also noted in the scores assigned to fake essays designed to trick the programs into providing a higher score. These results were consistent for both the full set of 500 scored essays and the subset of essays reviewed by the expert committee. Overall, both automated scoring programs did well judged on the criteria; however, one program did slightly better. The G-studies indicated that there were small differences among the raters and that the amount of error in the models was reduced as the number of human raters and automated scoring programs were increased. ^ In summary, results suggest automated scoring programs can approximate scores given by human raters, but they differ with respect to proximity to operational and expert scores, and their ability to identify dubious essays. ...|$|E
6000|$|... "We are {{not here}} to have a {{pleasant}} time," [...] said Mortimer, with a flash through his glasses. [...] "We are here to do our best for our papers. <b>How</b> can <b>they</b> <b>score</b> over each other {{if we do not}} do the same? If we all combine we might as well amalgamate with Reuter at once." ...|$|R
50|$|Adjusted {{to reflect}} the raising of the points scale (2007 and 2009), {{reduction}} of tournaments counted (2009) and removal of quality points (2006).Not an exact figure but a good approximation of <b>how</b> <b>they</b> would have <b>scored</b> under the current system.Original total in brackets.|$|R
5000|$|... 1 [...] "Best result" [...] {{is defined}} by goal {{difference}} between the two teams. How many goals Villa <b>score</b> and whether <b>they</b> keep a clean sheet affects which result is listed (when goal difference is the same e.g. 1-0 or 2-1). [...] 2 [...] "Worst result" [...] {{is defined by}} goal {{difference between the two}} teams. How many goals Villa concede and <b>how</b> many <b>they</b> <b>score</b> affects which result is listed (when goal difference is the same e.g. 0-1 or 1-2).|$|R
50|$|Here {{is a list}} of all of KF Tirana's Cup seasons from 1939 till end of {{most recent}} season. This list shows where they {{finished}} the season, how many ties won or lost, <b>how</b> many goals <b>they</b> <b>scored</b> and conceded, <b>how</b> many wins draws and losses they had throughout the season, goal difference, winning difference and number of matches played.|$|R
40|$|To {{determine}} whether a component is meeting its reliability requirement during production, acceptance sampling is employed in which selected units coming off the production line are subjected to additional environmental and/or destructive tests that are within the normal environment space to which the component {{is expected to be}} exposed throughout its life in the Stockpile. This report describes what these tests are and <b>how</b> <b>they</b> are <b>scored</b> for reliability purposes. The roles of screens, Engineering Use Only tests, and next assembly product acceptance testing are also discussed, along with both {{the advantages and disadvantages of}} environmental and destructive testing...|$|R
50|$|Another {{reason for}} Heisman's plan {{to run up}} the score was the {{practice}} among the sportswriters of the time to rank teams based upon <b>how</b> many points <b>they</b> <b>scored.</b> Since this statistic did {{not account for the}} strength or weakness of a team's opponent, Heisman disagreed with the amount of weight the writers tended to assign to it, and he may have unleashed his players on Cumberland to make his point.|$|R
30|$|The dataset {{consists}} of self-reported personalities, self-reported job tasks, and self-reported quality of job matches. Autor and Handel (forthcoming) discuss several issues {{with this kind}} of survey. Bias caused by the respondentsâ subjective answers is our main concern. First, bias can result from the abstract definitions of the variables, resulting in different interpretations among respondents. Second, respondents likely vary in <b>how</b> <b>they</b> distribute <b>scores.</b> For instance, some respondents will label a score as important, whereas others will label the same score as very important. Third, workers may over or underestimate their own skills, jobs tasks and job match, e.g. be âoverconfidentâ. This measurement error affects our results when workers in cities have different biases in their answers than workers in the countryside.|$|R
40|$|We {{investigate}} {{the implications of}} using different indicators to assess the sustainability performance of investment funds. In particular, we look into the environmental performance of Dutch government bond funds. We find that it does matter a lot which particular indicator is used. This suggests that funds should be very transparent and straightforward about their non-financial performance. We argue that basically they have three options. First, the industry {{comes up with a}} benchmark against which the responsibility of their investments is measured and reported by all funds. Second, the funds make very clear and transparent which particular aspects of sustainability they specifically target and <b>how</b> <b>they</b> keep <b>score.</b> Third, the dashboard approach where the funds report their performance on a well-defined set of indicators...|$|R
40|$|For most Americans, {{access to}} credit is an {{essential}} requirement for upward mobility and financial success. A favorable credit rating is necessary to purchase a home or car, {{to start a new}} business, to seek higher education, or to pursue other important goals. For many consumers, strong credit is also necessary to gain access to employment, rental housing, and essential services such as insurance. At present, however, individuals have very little control over <b>how</b> <b>they</b> are <b>scored</b> and have even less ability to contest inaccurate, biased, or unfair assessments of their credit. Traditional, automated credit-scoring tools raise longstanding concerns of accuracy and unfairness. The recent advent of new 2 Ì 2 big-data 2 Ì 2 credit-scoring products heightens these concerns...|$|R
50|$|Here {{is a list}} of all of KF Tiranas seasons from 1930 till {{most recent}} season. This list shows where they {{finished}} the season, <b>how</b> many goals <b>they</b> <b>scored</b> and conceded, <b>how</b> many wins draws and losses they had throughout the season, goal difference, winning difference, earned points and matches played. The list below also displays the results from three Second World War championships along period 1939-1942, however, as these championships are not officially recognized from AFA, results are not added in the total line.|$|R
50|$|The {{other type}} of levels are {{competition}} levels, which consist of three one-minute sessions, from which the player can only advance once they have won a medal, which also comes with a cash prize depending on which medal was won. At {{the end of each}} session, five judges score the round, with only the best three scores counting. The rating by the judges that a player receives in a competition is based on <b>how</b> much <b>they</b> <b>score,</b> variation of tricks, bails, and how much of the level they have used. The lowest score is then taken away {{at the very end of}} the competition, leaving the average of the other, higher two scores as the final result. There are three minute-long runs in total. Competition levels also contain hidden cash like the regular levels.|$|R
40|$|In {{response}} to questions raised about the 2 Ì 2 accuracy 2 Ì 2 of SF- 36 physical (PCS) and mental (MCS) component summary scores, particularly extremely high and low scores, we briefly comment on: <b>how</b> <b>they</b> were developed, <b>how</b> <b>they</b> are <b>scored,</b> the factor content of the eight SF- 36 subscales, cross-tabulations between item-level responses and extreme summary scores, and published and new tests of their empirical validity. Published cross-tabulations between SF- 36 items and PCS and MCS scores, reanalyses of public datasets (N = 5919), and preliminary results from the Medicare Health Outcomes Survey (HOS) (N = 172, 314) yielded little or no {{evidence in support of}} Taft 2 Ì 7 s hypothesis that extreme scores are an invalid artifact of some negative scoring weights. For example, in the HOS, those (N = 432) with 2 Ì 2 unexpected 2 Ì 2 PCS scores worse than 20 (which, according to Taft, indicate better mental health rather than worse physical health) were about 25...|$|R
5000|$|It {{is legal}} to meld certain special hands as your team's {{first and only}} meld. These are hands of exactly 14 cards which you can conceivably have after drawing your card for the turn. If a team plays a special hand, the play ends immediately; the team scores only the points for the special hand (there are no {{penalties}} for the cards in the other partner's hand). This is also the only time a player is allowed to not discard a card; even when going out, a player must otherwise have something to discard. There is considerable variation in what special hands are allowed and <b>how</b> <b>they</b> are <b>scored.</b> Among the most commonly accepted special hands are the following (these {{are the ones that}} were legal in the tournament version): ...|$|R
30|$|The third {{article is}} {{relevant}} {{to those who are}} exploring the topic of oral communication assessment. It reports how students used rubrics to understand their teacherâs expectations as well as <b>how</b> <b>they</b> used the <b>scoring</b> guide to assess their own performance. The fourth and final article, on the other hand, {{is relevant to}} those who are interested in the role of feedback. This article takes a different approach because it does not merely describe the comments given by language teachers, but it also compares the comments of language and non-language teachers.|$|R
50|$|Near {{the end of}} each show, a {{selection}} process occurs, during which Project Runway fashion designers choose which model they wish to work with for the week. All of the models stand in a runway lineup with Heidi Klum in the center, while the designers sit on the ground floor facing them. The models appear by wearing the same outfit (barefoot and a short black shift dress). The sequence by which designers select models is based upon <b>how</b> high <b>they</b> <b>scored</b> during the preceding episode's design competition as well as random pick from a bag: The winning designer has first pick, the runner-up selects second, the lowest-scoring designer picks last, etc. Because there is one more model than the number of designers {{at the beginning of the}} selection process, one model remains unpicked at the end, and will be sent home. Thus, the surviving designer with the lowest score during the previous week plays the most important role in determining which model will be eliminated.|$|R
25|$|These earlier methods had flaws {{that were}} easily exploitable. The average run-rate method took no {{account of how}} many wickets were lost by the team batting second, but simply {{reflected}} <b>how</b> quickly <b>they</b> were <b>scoring</b> when the match was interrupted. So if a team felt a rain stoppage was likely, they could attempt to force the scoring rate without regard for the corresponding highly likely loss of wickets, skewing the comparison with the first team. The most productive overs method also took no account of wickets lost by the team batting second, and effectively penalized the team batting second for good bowling, by ignoring their best overs in setting the revised target.|$|R
25|$|The 2220 {{defeat of}} Cumberland {{was the largest}} margin of victory in {{football}} history. Cumberland, a Presbyterian school in Lebanon, Tennessee, had discontinued its football program before the season but {{was not allowed to}} cancel its game against the Engineers. The fact that Cumberland's baseball team had crushed Georgia Tech earlier that year 220 (amidst allegations that Cumberland used professionals as ringers) probably accounted for Georgia Tech coach John Heisman's running up the score on the Bulldogs. (Heisman was also the Engineers' baseball coach.) Another possible reason for Heisman's plan to run up the score was the practice among the sportswriters of the time to rank teams based on <b>how</b> many points <b>they</b> <b>scored.</b> Since this statistic did not account for the strength or weakness of a team's opponent, Heisman disagreed with the amount of weight the writers tended to assign to it, and he may have unleashed his players on Cumberland to make his point.|$|R
40|$|Thesis (M. S., Chemistry) [...] California State University, Sacramento, 2011. When am I {{ever going}} to use this???? (Pleacher, 1998) Many {{students}} ask themselves this question throughout grade school, high school, and college during math class. A scientist knows the answer, but a non-scientist may feel that math classes are {{a waste of time}} (Angel and LaLonde, 1998). There exists a correlation between math and science; that is why those who struggle with math do not pursue the sciences. Through years of data, the strongest evidence in how a student will perform in their college chemistry class is <b>how</b> well <b>they</b> <b>scored</b> in their high school math courses and <b>how</b> <b>they</b> performed on the math portion of their SATs (Andrews and Andrews, 1979). Fifty percent of freshman chemistry students drop out or fail chemistry; these students switch to non-science majors or drop out of college altogether (Angel and LaLonde, 1998). Often times these dejected students pursue a liberal studies degree and in turn teach elementary school, teaching math. If these teachers never saw the connection between math and chemistry, <b>how</b> can <b>they</b> help their students understand when they are going to use the math they are learning? (Worthy, 1982) Something must be done to stop this cycle. Sources of Data: The practices and attitudes to math related chemistry questions by 376 science-major students enrolled in an undergraduate chemistry course at California State University, Sacramento, were characterized by an introductory math quiz and survey. An additional survey and a sequence of worksheets were administered throughout the course and responses to the worksheets and worksheet related exam questions were analyzed. Conclusions Reached: Students should have the option to complete mathematic worksheets that refresh their math knowledge and help them solverelated math questions on their chemistry exams. Students??? academic performance is enhanced by the use of worksheets that aid the practical application of mathematics to chemistry education. Chemistr...|$|R
40|$|Recently, oenological prejudices were {{challenged}} {{by the use of}} a points scoring system (from 50 to 100) to evaluate wine in a book now widely {{regarded as one of the}} most authoritative. On this scale, a 1981 Chateau Citran described as 'emaciated' scored 65, a 1983 Chateau Kirwan scored 85, and a 1982 Petrus 100. If the same approach were used for drugs used in ulcerative colitis to quantify an advance over conditions existing at the time of its introduction <b>how</b> would <b>they</b> <b>score?</b> Because <b>they</b> were the first available drugs in their class and clearly constituted major advances, corticosteroids and sulphasalazine both score 95, the score being limited by a high level of side effects. The new salicylates <b>score</b> 75, because <b>they</b> extend the benefits of sulphasalazine to a minority of patients but they have the potential to score 90 if increased dosing and greater effectiveness over sulphasalazine can be achieved. Salicylate enemas <b>score</b> 80, because <b>they</b> advance treatment over topical corticosteroids for patients with resistant distal disease, but the mode of delivery needs improvement. Steroid foams also score 80, particularly if the patient's vote is taken into account. Azathioprine's score cannot be calculated because there is doubt over its efficacy, but it is potentially 88 if it saves patients with difficult disease from colectomy. We can only guess what an oral non-absorbed steroid would score, but if response rates for relapse were substantially improved, or if corticosteroids could be used as effective maintenance treatment, it could be as high as 95. There are indications that we should 'watch this space'...|$|R
25|$|If a batsman {{has been}} {{dismissed}} {{in every single}} innings, then their total number of runs scored divided {{by the number of}} times they have been out gives exactly the average number of runs <b>they</b> <b>score</b> per innings. However, for a batsman with innings which have finished not out, this statistic is only an estimate of the average number of runs <b>they</b> <b>score</b> per innings â the true average number of runs <b>they</b> <b>score</b> per innings is unknown as it is not known <b>how</b> many runs <b>they</b> would have <b>scored</b> if <b>they</b> could have completed all their not out innings. If their scores have a geometric distribution then total number of runs scored divided by the number of times out is the maximum likelihood estimate of their true unknown average.|$|R
40|$|The International Network for Food and Obesity/non-communicable {{diseases}} Research, Monitoring and Action Support (INFORMAS) {{proposes to}} collect performance indicators on food policies, actions and environments related to obesity and non-communicable diseases. This paper reviews existing communications strategies used for performance indicators and proposes {{the approach to}} be taken for INFORMAS. Twenty-seven scoring and rating tools were identified in various fields of public health including alcohol, tobacco, physical activity, infant feeding and food environments. These were compared based on the types of indicators used and <b>how</b> <b>they</b> were quantified, <b>scoring</b> methods, presentation and the communication and reporting strategies used. There are several implications of these analyses for INFORMAS: the ratings/benchmarking approach is very commonly used, presumably {{because it is an}} effective way to communicate progress and stimulate action, although this has not been formally evaluated; the tools used must be trustworthy, pragmatic and policy-relevant; multiple channels of communication will be needed; communications need to be tailored and targeted to decision-makers; data and methods should be freely accessible. The proposed communications strategy for INFORMAS has been built around these lessons to ensure that INFORMAS 2 Ì 7 s outputs have the greatest chance of being used to improve food environments...|$|R
40|$|We test {{experimentally}} {{an explanation}} of over and under confidence as motivated by (perhaps unconscious) strategic concerns, and find compelling evidence supporting this hypothesis {{in the behavior of}} participants who send and respond to others' statements of confidence about <b>how</b> well <b>they</b> have <b>scored</b> on an IQ test. In two-player tournaments where the highest score wins, one is likely to enter at equilibrium when he knows that his stated confidence is higher than the other player's, but very unlikely when the reverse is true. Consistent with this behavior, stated confidence by males is inflated when deterrence is strategically optimal and is instead deflated by males and females when hustling (encouraging entry) is strategically optimal. This behavior is consistent with the equilibrium of the corresponding signaling game. Based on the theory of salient perturbations, we propose a strategic foundation of overconfidence. Since overconfident statements are used in familiar situations in which it is strategically effective, it may also occur in the absence of strategic benefits, provided the environment is similar...|$|R
40|$|Scores on the Massachusetts Teacher Tests {{of reading}} and writing are highly unreliable. The tests' margin of error is close to double to triple the range found on {{well-developed}} tests. A person retaking the MTT several times could have huge fluctuations in their scores even if their skill level did not change significantly. In fact, the 9 to 17 point margin of error calculated for the tests represents more than 10 percent of the grading scale (assumed to be 0 to 100). The large margin of error means there is both a high false-pass rate and a high false-failure rate. For example, a person who received a score of 72 on the writing test could have scored an 89 or a 55 {{simply because of the}} unreliability of the test. Since adults' reading and writing skills do not change a great deal over several months, this range of scores on the same test should not be possible. While this test is being touted as an accurate assessment of a person's fitness to be a teacher, one would expect the scores to accurately reflect a test-taker's verbal ability level. In addition to the large margin of error, the MTT contain questionable content that make them poor tools for measuring test-takers' reading and writing skills. The content and lack of correlation between the reading and writing scores reduces the meaningfulness, or validity, of the tests. The validity is affected not just by the content, but by a host of factors, such as the conditions under which tests were administered and <b>how</b> <b>they</b> were <b>scored.</b> Interviews with a small sample of test-takers confirmed published reports concerning problems with the content and administration...|$|R
50|$|Five {{questions}} with four multiple-choice answers were {{asked by the}} host. The players had 10 seconds to answer by pressing a number from 1-4 on a keypad in front of them. <b>They</b> <b>scored</b> points based on <b>how</b> fast <b>they</b> answered the question correctly, with a maximum of 1,000 points available. After five questions, the six players with the highest scores played round two and the other players were eliminated.|$|R
25|$|In cricket, a player's {{batting average}} {{is the total}} number of runs <b>they</b> have <b>scored</b> divided by the number of times they have been out. Since the number of runs a player <b>scores</b> and <b>how</b> often <b>they</b> get out are {{primarily}} measures of their own playing ability, and largely independent of their teammates, batting average is a good metric for an individual player's skill as a batsman. The number is also simple to interpret intuitively. If all the batsman's innings were completed (i.e. they were out every innings), this is the average number of runs <b>they</b> <b>score</b> per innings. If they did not complete all their innings (i.e. some innings they finished not out), this number is an estimate of the unknown average number of runs <b>they</b> <b>score</b> per innings. Batting average has been used to gauge cricket players' relative skills since the 18th century.|$|R
50|$|One of {{the major}} {{assumptions}} of obedience research is that the effect is caused only by the experimental conditions, and Thomas Blass' research contests this point, as in some cases participant factors involving personality could potentially influence the results.In one of Blass' reviews on obedience, he found that participant's personalities can impact <b>how</b> <b>they</b> respond to authority, as people that were high in authoritarian submission {{were more likely to}} obey. He replicated this finding in his own research, as in one of his experiments, he found that when watching portions of the original Milgram studies on film, participants placed less responsibility on those punishing the learner when <b>they</b> <b>scored</b> high on measures of authoritarianism.|$|R
50|$|Havant also {{achieved}} success from 2005-2008 {{when the}} club won {{back to back}} leagues titles, and once again found themselves competing in the England Hockey League Men's Premier Division. In the Men's National South Division 2005/2006 <b>they</b> <b>scored</b> 116 goals, in the Men's Division One 2006/2007 <b>they</b> <b>scored</b> 90, and in the Men's Premier Division 2007/2008 <b>they</b> <b>scored</b> 73.|$|R
6000|$|<b>How</b> <b>they</b> squirmed and <b>how</b> <b>they</b> squealed! [...] <b>How</b> <b>they</b> shouted for assistance! [...] <b>How</b> <b>they</b> fruitlessly appealed [...] To the shepherds in the distance! ...|$|R
6000|$|<b>How</b> <b>they</b> {{changed their}} boastful tune! <b>How</b> <b>they</b> hugged the vilified boat! <b>How</b> <b>they</b> wished {{they were in}} it, the braggarts! And <b>how</b> <b>they</b> all tingled with fear! ...|$|R
