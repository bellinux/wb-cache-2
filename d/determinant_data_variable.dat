0|6462|Public
30|$|The <b>data</b> <b>variables</b> are density ρ {{and flow}} ρυ in the KG, PW, Zhang and {{proposed}} models. Roe’s technique {{is used to}} linearize the Jacobian matrix A(G) by decomposing it into eigenvalues and eigenvectors. This {{is based on the}} realistic assumption that the <b>data</b> <b>variables,</b> eigenvalues and eigenvectors remain conserved for small changes in time and distance. This technique is widely employed because it is able to capture the effects of abrupt changes in the <b>data</b> <b>variables.</b>|$|R
5000|$|Every {{local area}} is {{classified}} {{using the same}} <b>data</b> <b>variables.</b>|$|R
40|$|A value-passing {{version of}} normed {{context-free}} processes is considered, where process behaviours {{depend on a}} global state of <b>data</b> <b>variables.</b> The problem of characterizing bisimilarity of such processes is posed. A solution of the formulated problem is presented for a restricted class of processes and possibilities of extending the result are discussed. The presented solution exploits a tableau decision method for pure, normed, context-free processes: based on a tableau, a system of implications is formulated, solution of which characterizes bisimulation equivalence {{for a pair of}} valuepassing processes. 1 Introduction We consider a value-passing version of normed context-free processes, where process behaviours depend on a global state of <b>data</b> <b>variables.</b> Accordingly, the semantics and bisimulation depend on valuations of <b>data</b> <b>variables.</b> In this work we search for a formula characterizing those valuations of <b>data</b> <b>variables</b> for which two given processes are bisimilar. We aim at extending [...] ...|$|R
5000|$|Type-specific <b>Data</b> (<b>variable)</b> : <b>Data</b> {{that belongs}} {{to this type of}} routing header.|$|R
40|$|The practice-based {{research}} network (PBRN) is {{a resource}} to recruit research participants; conduct developmental and pilot studies; and coordinate multicentre research, teaching, clinical care and quality assurance programs. It is a community–based laboratory for translational, clinical {{and health services}} research. The mining of clinical information systems of PBRNs {{can be used to}} monitor performance at the service unit level. However, are the routinely collected data of ePBRNs fit for the abovementioned purposes? We describe the establishment and governance of an ePBRN which included general practice and community health and hospital units, The general practice data quality was examined, using diabetes as the context, for completeness, correctness and consistency and assessed on its fitness for research, audit and quality assurance purposes. The quality of social <b>determinants</b> <b>data</b> was generally good while risk factors <b>data</b> were <b>variable.</b> Issues and strategies for improving data quality are discussed...|$|R
50|$|Wide, or unstacked data is {{presented}} with each different <b>data</b> <b>variable</b> {{in a separate}} column.|$|R
3000|$|In the <b>Data</b> <b>Variable</b> {{dropdown}} for the Y axis, select Major Cardiovascular Procedures (Avg medicare pmnt) [...]...|$|R
50|$|Such <b>data</b> <b>variables</b> are implicitly const, {{and must}} have an initializer which must be a {{constant}} expression.|$|R
5000|$|XPath {{access to}} <b>variable</b> <b>data</b> (XPath <b>variable</b> syntax $variable.part/location) ...|$|R
30|$|According to our <b>data</b> <b>variables</b> of tumor {{chronology}} and tumor biology have {{a similar}} impact {{on the presence of}} lymph node metastasis.|$|R
50|$|A single {{record in}} this table {{represents}} {{the subject of}} the prediction (e.g. a customer) and stores all <b>data</b> (<b>variables)</b> describing this subject.|$|R
30|$|While Nagel et al. have {{advanced}} {{the project in}} terms of temporal and aural dimensions, the use of 3 D scatterplots provides the base for the overall data representation. Scatterplots map three <b>data</b> <b>variables</b> to X, Y and Z coordinates to produce 3 D terrain-like visualizations that are described as ‘macro DV’. These data terrains are contrasted with ‘micro DV’, the mapping of other variables to geometric shapes aligned with the scatterplot. These shapes also have movement and dynamic colour properties that add additional layers of <b>data</b> <b>variables.</b> In discussion of their trials Nagel et al. report up to 10 quantifiable <b>data</b> <b>variables,</b> with three assigned to the macro DV (x, y, z coordinates) and the seven other variables that are mix of different shapes, color, orientation and sound. In conclusion, they report that VDM in VR does “help in discovering remarkable nonlinear data relations and substructures” [22].|$|R
3000|$|... [...]) and f(Gi[*]+[*] 1) and substituting e|Λ|e− 1 for [...] A(G_i+ 1 / 2), {{the updated}} <b>data</b> <b>variables,</b> ρ and ρυ, are then {{obtained}} at time n using (24).|$|R
30|$|This paper {{describes}} a dynamic approach to incorporate positional uncertainties of buried utilities into an uncertainty-aware, geospatial-AR system for real time visualization and proximity analysis. Uncertainties are modeled as probability bands (e.g. spatial bands with certain probabilities of enclosing the “true” location of utilities). Positional uncertainties are derived {{in real time}} by referring to its <b>determinant,</b> <b>data</b> lineage, the genesis and processes used to collect and interpret data.|$|R
50|$|Since complex {{numbers and}} vectors {{of up to}} three {{elements}} can be stored as a single value, each <b>data</b> <b>variable</b> occupies 37 bytes, enough for a type indicator and three floating-point numbers.|$|R
40|$|From {{number theory}} to string theory, {{analyzing}} algebraic relations in two variables still dominates how we view laws governing relations between quantities. An algebraic relation between two variables defines a nonsingular projective curve. Our understanding starts with moduli of curves. From, however, cryptography to Hamiltonian mechanics, we command complicated data through a key <b>data</b> <b>variable.</b> We’re human; {{we come to}} complicated issues through specific compelling interests. That <b>data</b> <b>variable</b> eventually drags us into deeper, less personal territory. Abel, Galois and Riemann knew that; though some versions of algebraic geometry from the late 1970 s lost it. A choice <b>data</b> <b>variable</b> (function to the Riemann sphere) to extract information brings the tool of finite group theory. Giving such relations structure, and calling for advanced tools and interpretations, {{is the study of}} their moduli — the main goal of the papers of this volume. Applications in this volume are to analyzing properties of the absolute Galois group GQ (Part I) and to describing systems of relations over a finite field (Part II). Such application...|$|R
3000|$|The {{other issue}} to {{consider}} is the representation of [...] "wfld" [...] <b>data</b> <b>variables.</b> As shown in Table 3, both the real and imaginary parts of [...] "wfld" [...] data have a wide range from [...]...|$|R
5000|$|<b>Data</b> (<b>variable)</b> [...] - [...] when Control bit C is set, {{this field}} {{contains}} an SSTP control message. Otherwise, the data field would contain {{a higher level}} protocol. At the moment, this can only be PPP.|$|R
40|$|Latent {{variable}} {{models can}} be used to probabilistically "fill-in" missing data entries. The variational autoencoder architecture (Kingma and Welling, 2014; Rezende et al., 2014) includes a "recognition" or "encoder" network that infers the latent <b>variables</b> given the <b>data</b> <b>variables.</b> However, {{it is not clear how}} to handle missing <b>data</b> <b>variables</b> in this network. We show how to calculate exactly the latent posterior distribution for the factor analysis (FA) model in the presence of missing data, and note that this solution exhibits a non-trivial dependence on the pattern of missingness. Experiments compare the effectiveness of various approaches to filling in the missing data. Comment: 6 pages, 1 figur...|$|R
5000|$|The {{namespace}} for function names {{is separate}} from the namespace for <b>data</b> <b>variables.</b> This is a key difference between Common Lisp and Scheme. For Common Lisp, operators that define names in the function namespace include , , , [...] and [...]|$|R
25|$|In {{the results}} of Statistics Canada's 2001 Canadian Census, white is one {{category}} in the population groups <b>data</b> <b>variable,</b> derived from <b>data</b> collected in question 19 ({{the results of}} this question are also used to derive the visible minority groups variable).|$|R
40|$|Imagine a user {{wanting to}} study {{hurricane}} events. This could involve searching and downloading multiple <b>data</b> <b>variables</b> from multiple <b>data</b> sets. The currently available services from the Goddard Earth Sciences Data and Information Services Center (GES DISC) only allow {{the user to}} select one data set at a time. The GES DISC started a Data List initiative, in order to enable users to easily select multiple <b>data</b> <b>variables.</b> A <b>Data</b> List {{is a collection of}} predefined or user-defined <b>data</b> <b>variables</b> from one or more archived data sets. Target users of Data Lists include science teams, individual science researchers, application users, and educational users. Data Lists are more than just data. Data Lists effectively provide users with a sophisticated integrated data and services package, including metadata, citation, documentation, visualization, and data-specific services, all available from one-stop shopping. Data Lists are created based on the software architecture of the GES DISC Unified User Interface (UUI). The Data List service is completely data-driven, and a Data List is treated just as any other data set. The predefined Data Lists, created by the experienced GES DISC science support team, should save a significant amount of time that users would otherwise have to spend...|$|R
5000|$|Payload <b>data</b> (<b>variable)</b> : The {{protected}} {{contents of}} the original IP packet, including any data used to protect the contents (e.g. an Initialisation Vector for the cryptographic algorithm). The type of content that was protected is indicated by the Next Header field.|$|R
30|$|Results of the {{statistical}} comparisons among selected variables at baseline and at the latest follow up showed a significant improvement of all parameters including proteinuria, C 3 and C 4 (Table  2). Then we evaluated laboratory <b>data</b> <b>variables</b> changes {{during the course of}} treatment.|$|R
40|$|Recent {{advances}} in logic programming {{have been successfully}} used to build practical verication toolsets, {{as evidenced by the}} XMC system. Thus far, XMC has supported value-passing process languages, but has been limited to using the propositional fragment of modal mucalculus as the property specication logic. In this paper, we explore the use of <b>data</b> <b>variables</b> in the property logic. In particular, we present valuepassing modal mu-calculus, its formal semantics and describe a natural implementation of this semantics as a logic program. Since logic programs naturally deal with variables and substitutions, such an implementation need not pay any additional price| either in terms of performance, or in complexity of implementation| for having the added exibility of <b>data</b> <b>variables</b> in the property logic. Our preliminary implementation supports this expectation. ...|$|R
50|$|Since 2001, the Millennium Project has {{initiated}} a project entitled the State of the Future Index, {{has been using}} a predictive methodology to foresee the future for global countries based on historical <b>data,</b> <b>variables</b> and indicators, such as GDP, annual population, literacy rates, population, and unemployment.|$|R
30|$|In this paper, Section 2 {{outlines}} the main hypotheses; Section 3 presents the <b>data,</b> <b>variables</b> and methods used; Sections 4 and 5  report {{and analyze the}} empirical findings including main tests and robustness tests. In Section 6, the main conclusions are made and policy recommendations are put forward.|$|R
40|$|Recent {{advances}} in logic programming {{have been successfully}} used to build practical verification toolsets, {{as evidenced by the}} XMC system. Thus far, XMC has supported value-passing process languages, but has been limited to using the propositional fragment of modal mucalculus as the property specification logic. In this paper, we explore the use of <b>data</b> <b>variables</b> in the property logic. In particular, we present valuepassing modal mu-calculus, its formal semantics and describe a natural implementation of this semantics as a logic program. Since logic programs naturally deal with variables and substitutions, such an implementation need not pay any additional price [...] - either in terms of performance, or in complexity of implementation [...] - for having the added flexibility of <b>data</b> <b>variables</b> in the property logic. Our preliminary implementation supports this expectation...|$|R
50|$|Following {{is a list}} of {{companies}} providing software and/or services for file merging, mail presorting and/or <b>data</b> cleansing for <b>variable</b> <b>data</b> printing.|$|R
5000|$|BSS segment (uninitialized static <b>data,</b> both <b>variables</b> and constants) ...|$|R
40|$|Abstract Background In 1999, an Utstein Template for Uniform Reporting of Data {{following}} Major Trauma was published. Few {{papers have}} since been published based on that template, reflecting a lack of international consensus on its feasibility and use. The aim of the present revision was to further develop the Utstein Template, particularly with a major {{reduction in the number}} of core <b>data</b> <b>variables</b> and the addition of more precise definitions of <b>data</b> <b>variables.</b> In addition, we wanted to define a set of inclusion and exclusion criteria that will facilitate uniform comparison of trauma cases. Methods Over a ten-month period, selected experts from major European trauma registries and organisations carried out an Utstein consensus process based on a modified nominal group technique. Results The expert panel concluded that a New Injury Severity Score > 15 should be used as a single inclusion criterion, and five exclusion criteria were also selected. Thirty-five precisely defined core <b>data</b> <b>variables</b> were agreed upon, with further division into core data for Predictive models, System Characteristic Descriptors and for Process Mapping. Conclusion Through a structured consensus process, the Utstein Template for Uniform Reporting of Data following Major Trauma has been revised. This revision will enhance national and international comparisons of trauma systems, and will form the basis for improved prediction models in trauma care. </p...|$|R
40|$|This {{research}} {{will focus on}} measuring the quality of educational services in the Business Administration program by measuring the gaps and its determinants. The study also focuses on measuring the so-called “Reality Gap ” which is the actual difference between the expected service and perceived service. In addition, the study aims at measuring the amount of expectations {{and the amount of}} perceptions as well as the quality <b>determinants.</b> <b>Data</b> has been collected through a model known as "Service Quality Model: " which is known as "SERVQUAL” which was distributed to a sample selection screened among graduate students in the MBA program...|$|R
40|$|Motivation: Model-based {{clustering}} {{has been}} widely used, e. g. in microarray data analysis. Since for high-dimensional <b>data</b> <b>variable</b> selection is necessary, several penalized model-based clustering methods have been proposed tørealize simultaneous variable selection and clustering. However, the existing methods all assume that the variables are independent {{with the use of}} diagonal covariance matrices...|$|R
40|$|THIS SUPPLEMENT {{provides}} added technical details {{related to}} the <b>data,</b> <b>variable</b> definitions, and estimation. The paper has two empirical components: estimation of quantile regression weighting schemes and robust inference on the quantile regression process for earnings equations. Both rely on Census microdata for 1980, 1990, and 2000. The original raw data {{are available from the}} Integrated Public Use Microdata Series (IPUMS) web site and our Stata extracts are available here. In addition to a description of the <b>data</b> and <b>variables,</b> this supplement includes all Stata and R (version 2. 0. 1) command files used to construct Figures 1 and 2, and Table I...|$|R
5000|$|... the {{necessity}} to automatically generate citations to <b>data</b> with <b>variable</b> granularity.|$|R
30|$|According to our <b>data,</b> <b>variables</b> of tumor {{chronology}} and tumor biology {{seem to have}} {{a similar}} impact on the presence of lymph node metastasis. Based on pathological tumor size, the presence of LVI, tumor grade, ER, PR and HER- 2, the presence of axillary lymph node metastasis can be predicted with an AUC of 0.74.|$|R
