36|304|Public
50|$|Transderivational search (often {{abbreviated}} to TDS) is a psychological and cybernetics term, meaning when a search is being conducted for a <b>fuzzy</b> <b>match</b> {{across a broad}} field. In computing the equivalent function can be performed using content-addressable memory.|$|E
5000|$|Variants of regexes can be {{used for}} working with text in natural language, when it is {{necessary}} to take into account possible typos and spelling variants. For example, the text [...] "Julius Caesar" [...] might be a <b>fuzzy</b> <b>match</b> for: ...|$|E
5000|$|In the 1990s, fuzzy {{matching}} {{began to take}} off as a prominent feature of TM tools, and despite some issues concerning the extra work involved in editing a <b>fuzzy</b> <b>match</b> [...] "proposal", {{it is still a}} popular subset of TM. It is currently a feature of most popular TM tools.|$|E
40|$|The <b>fuzzy</b> file block <b>matching</b> {{technique}} (<b>fuzzy</b> <b>matching</b> for short), {{was first}} proposed for opportunistic use of Content Addressable Storage. <b>Fuzzy</b> <b>matching</b> aims {{to increase the}} hit ratio in the content-addressable storage providers, and thus can improve the performance of underlying distributed file storage systems by potentially saving significant network bandwidth and reducing file transmission costs. <b>Fuzzy</b> <b>matching</b> employs shingling to represent the fuzzy hashing of file blocks for similarity detection, and error-correcting information to reconstruct the canonical content of a file block from some similar blocks. In this paper, we present the implementation details of <b>fuzzy</b> <b>matching</b> and a very basic evaluation of its performance. In particular, we show that <b>fuzzy</b> <b>matching</b> can recover new versions of GNU Emacs source from older versions. ...|$|R
40|$|The {{concept of}} <b>fuzzy</b> <b>matching</b> in {{translation}} memories {{can take place}} using linguistically aware or unaware methods, {{or a combination of}} both. We designed a ﬂexible and time-efficient framework which applies and combines linguistically unaware or aware metrics in the source and target language. We measure the correlation of <b>fuzzy</b> <b>matching</b> metric scores with the evaluation score of the suggested translation to ﬁnd out how well the usefulness of a suggestion can be predicted, and we measure the difference in recall between <b>fuzzy</b> <b>matching</b> metrics by looking at the improvements in mean TER as the match score decreases. We found that combinations of <b>fuzzy</b> <b>matching</b> metrics outperform single metrics and that the best-scoring combination is a non-linear combination of the different metrics we have tested. status: publishe...|$|R
40|$|Abstract—This paper {{proposes a}} new double-private {{protocol}} for <b>fuzzy</b> <b>matching</b> and -fuzzy matching. Many works {{have been done}} for private database search in which the keyword that a user inputs for the search is concealed to the database owner. In these database searches, the exactly matched data are returned to the user. <b>Fuzzy</b> <b>matching</b> has been proposed in which not exactly matched but nearly matched data are returned to the user. Then the condition to be matched is further relaxed by -fuzzy <b>matching.</b> In <b>fuzzy</b> <b>matching</b> and -fuzzy matching, a new security requirement, {{the security of the}} database can be considered. The database owner just answers the existence of a matched data without showing the matched data itself. This paper first formalizes the problem as the double-private -fuzzy matching. We show a naive protocol and an efficient protocol for double-private -fuzzy matching. Keywords—cryptographic protocols, database retrieval, <b>fuzzy</b> <b>matching,</b> -fuzzy matching, double-private matching I...|$|R
5000|$|Fuzzy match: When {{the match}} is not exact, it is a [...] "fuzzy" [...] match. Some systems assign {{percentages}} to {{these kinds of}} matches, in which case a <b>fuzzy</b> <b>match</b> is greater than 0% and less than 100%. Those figures are not comparable across systems unless the method of scoring is specified.|$|E
50|$|Users can insert fuzzy matches using a {{keyboard}} shortcut or using the mouse. OmegaT shows {{the degree of}} similarity in fuzzy matches using colours. OmegaT can also display the date, time {{and the name of}} the user who translated any given segment. Glossary matches can be inserted using the mouse. The user can choose to have the source text copied into the target text field, or to have the highest <b>fuzzy</b> <b>match</b> automatically inserted.|$|E
50|$|When {{an exact}} match cannot {{be found in}} the TM {{database}} for the text being translated, there is an option to search for a match that is less than exact; the translator sets the threshold of the <b>fuzzy</b> <b>match</b> to a percentage value less than 100%, and the database will then return any matches in its memory corresponding to that percentage. Its primary function is to assist the translator by speeding up the translation process; fuzzy matching is not designed to replace the human translator.|$|E
5000|$|In Context Exact matching, {{as well as}} exact and <b>fuzzy</b> <b>matching</b> ...|$|R
50|$|SmartList is {{the only}} mailing list manager that uses <b>fuzzy</b> <b>matching</b> to {{accommodate}} for typos and derived email addresses.|$|R
40|$|This thesis {{analyzes}} {{techniques of}} manipulation of accounting {{data for the}} purpose of fraud. It is further looking for methods, which could be capable of detecting these manipulations and it verifies the efficiency of the procedures already in use. A theoretical part studies method of financial analysis, statistical methods, Benford's tests, <b>fuzzy</b> <b>matching</b> and technologies of machine learning. Practical part verifies the methods of financial analysis, Benford's tests, algorithms for <b>fuzzy</b> <b>matching</b> and neural networks...|$|R
50|$|It {{includes}} {{three groups of}} files: a set of tools for indexing, a set of tools for searching, {{and a set of}} HTML files for building the user interface to access the search engine. ht://Dig works differently from most search engines as most engines use a two-step process, building an index and searching it. ht://Dig indexes pages in full, then processes the pages into a searchable form later using soundex and metaphone. ht://Dig also stores <b>fuzzy</b> <b>match</b> information instead of using a dynamic algorithm. At one time, over 500 organizations used ht://Dig to index sites they owned. Notable sites included Blizzard Entertainment, Greenpeace, and The Mozilla Foundation.|$|E
5000|$|This raises {{questions}} {{about the quality of the}} resulting translations. On occasions a translator is under pressure to deliver on time and is thus led to accept a <b>fuzzy</b> <b>match</b> proposal without checking its suitability and context. TM databases are built up by input from numerous different translators working on a variety of different texts, with a danger that sentences extracted from this word [...] "tapestry" [...] will be a stitched-together hodgepodge of styles, and the antithesis of the striven-after consistency - what some critics have dubbed [...] "sentence salad". The question of faith in the TM's proposals can be a problem when trying to strike a balance between a faster translation process and the quality of that translation. Nevertheless, fuzzy matching is still an important part of the translator's tool-kit.|$|E
40|$|In recent years, it is {{becoming}} more and more clear that the localisation industry does not have the necessary manpower to satisfy the increasing demand for high-quality translation. This has fuelled the search new and existing technologies that would increase translator throughput. As Translation Memory (TM) systems are the most commonly employed tool by translators, a number of enhancements are available to assist them in their job. One such enhancement would be to show the translator which parts of the sentence that needs to be translated match which parts of the <b>fuzzy</b> <b>match</b> suggested by the TM. For this information to be used, however, the translators have to carry it over to the TM translation themselves. In this paper, we present a novel methodology that can automatically detect and highlight the segments that need to be modified in a TM-­suggested translation. We base it on state-­of-the-art sub-­tree align- ment technology (Zhechev, 2010) that can produce aligned phrase-­based-­tree pairs from unannotated data. Our system operates in a three-­step process. First, the <b>fuzzy</b> <b>match</b> selected by the TM and its translation are aligned. This lets us know which segments of the source-­language sentence correspond to which segments in its translation. In the second step, the <b>fuzzy</b> <b>match</b> is aligned to the input sentence that is currently being translated. This tells us which parts of the input sentence are available in the <b>fuzzy</b> <b>match</b> and which still need to be translated. In the third step, the <b>fuzzy</b> <b>match</b> is used as an intermediary, through which the alignments between the input sentence and the TM translation are established. In this way, we can detect with precision the segments in the suggested translation that the translator needs to edit and highlight them appropriately to set them apart from the segments that are already good translations for parts of the input sentence. Additionally, we can show the alignments—as detected by our system—between the input and the translation, which will make it even easier for the translator to post-edit the TM suggestion. This alignment information can additionally be used to pre- translate the mismatched segments, further reducing the post-­editing load...|$|E
40|$|Name {{matching}} is {{a common}} requirement in modern business systems, wherein <b>fuzzy</b> <b>matching</b> techniques are employed to overcome variations between names. The purpose of this dissertation was {{the development of a}} framework, which is capable of implementing various <b>fuzzy</b> <b>matching</b> algorithms, while abstracting the name matching process away from external business systems. Through a study of existing <b>fuzzy</b> <b>matching</b> algorithms and frameworks, several design requirements were identified; the maintaining of name relationships, non-algorithm specific logic, abstraction of the matching process, user configured matching logic, consistent external interface and performance considerations. The deployment to a production environment and a series of tests, demonstrated that the framework fulfilled all but one of its design requirements, as certain algorithm implementations yielded excessive search times. The cause and remedy of this shortcoming were identified. Finally, based on an evaluation of the design‟s strengths and weaknesses, recommendations for future developments were suggested...|$|R
50|$|OmegaT shares many {{features}} with mainstream CAT tools. These include creating, importing and exporting translation memories, <b>fuzzy</b> <b>matching</b> from translation memories, glossary look-up, {{and reference}} and concordance searching.|$|R
40|$|We {{describe}} Amharic-English cross lingual {{information retrieval}} {{experiments in the}} adhoc bilingual tracs of the CLEF 2006. The query analysis is supported by morpho-logical analysis and part of speech tagging while we used different machine readable dictionaries for term lookup in the translation process. Out of dictionary terms were handled using <b>fuzzy</b> <b>matching</b> and Lucene[4] was used for indexing and searching. Four experiments that differed in terms of utilized fields in the topic set, <b>fuzzy</b> <b>matching,</b> and term weighting, were conducted. The results obtained are reported and discussed...|$|R
40|$|To ensure {{high data}} quality, data {{warehouses}} must validate and cleanse incoming data tuples from external sources. In many situations, clean tuples must match acceptable tuples in reference tables. For example, product name and description fields in a sales record from a distributor must match the pre-recorded name and description fields in a product reference relation. A significant challenge {{in such a}} scenario is to implement an efficient and accurate <b>fuzzy</b> <b>match</b> operation that can effectively clean an incoming tuple if it fails to match exactly with any tuple in the reference relation. In this paper, we propose a new similarity function which overcomes limitations of commonly used similarity functions, and develop an efficient <b>fuzzy</b> <b>match</b> algorithm. We demonstrate the effectiveness of our techniques by evaluating them on real datasets. 1...|$|E
40|$|Abstract—String {{similarity}} join {{that finds}} similar string pairs between two string sets {{is an essential}} operation in many applications, and has attracted significant attention recently in the database community. A significant challenge in similarity join is to implement an effective <b>fuzzy</b> <b>match</b> operation to find all similar string pairs which may not match exactly. In this paper, we propose a new similarity metrics, called “fuzzy token matching based similarity”, which extends token-based similarity functions (e. g., Jaccard similarity and Cosine similarity) by allowing <b>fuzzy</b> <b>match</b> between two tokens. We study the problem of similarity join using this new similarity metrics and present a signature-based method to address this problem. We propose new signature schemes and develop effective pruning techniques to improve the performance. Experimental results show that our approach achieves high efficiency and result quality, and significantly outperforms state-of-the-art methods. I...|$|E
40|$|In today's global marketplace, translators are {{responding}} to the current demand to produce fast and high-quality translations by using electronic tools to help them do their jobs, {{and one of the}} most promising tools that translators have at their disposal is translation memory (TM) software, a veritable database of previously translated material. Fuzzy matching [...] -where the TM system identifies a portion of the text that is similar to but not exactly the same as one stored in the database [...] -has become an integral feature of TM software; yet using this feature effectively remains a mystery to most translators. This is largely because translators have not been presented with any type of guidelines with regard to helping them identify an ideal setting for the <b>fuzzy</b> <b>match</b> value. The objective of this thesis is to provide translators with a better understanding of TM systems by exploring fuzzy matching in detail, and particularly by investigating factors such as the TM system selected, the category of text being processed, the working languages involved, and the degree of fuzziness of the match. Accordingly, a series of experiments have been designed and carried out to determine the influence that these four factors might have on the ideal <b>fuzzy</b> <b>match</b> setting. The results of these experiments show that these factors should indeed be taken into account when translators are selecting the <b>fuzzy</b> <b>match</b> value to be used with a TM system...|$|E
50|$|In {{translation}} work, translation segments {{are compared}} with translation units {{stored in the}} translation memory, and exact or <b>fuzzy</b> <b>matches</b> can be shown and inserted in the translated text.|$|R
50|$|DataMatch Enterprise {{provides}} <b>fuzzy</b> <b>matching</b> {{and record}} linkage services for companies of all sizes. The company recently rolled {{out a new}} integration with CRM service Salesforce, as well as address verification services.|$|R
40|$|In this paper, {{the task}} of parsing and {{matching}} inconsistent, poorly formed text data {{through the use of}} parser combinators and <b>fuzzy</b> <b>matching</b> is discussed. An object-oriented implementation of the parser combinator technique is used to allow for a relatively simple interface for adapting base parsers. For <b>matching</b> tasks, a <b>fuzzy</b> <b>matching</b> algorithm with Levenshtein distance calculations is implemented to match string pair, which are otherwise difficult to match due to the aforementioned irregularities and errors in one or both pair members. Used in concert, the two techniques allow parsing and matching operations to be performed which had previously only been done manually...|$|R
40|$|The paper {{describes}} an example-based parser for Chinese. Trees are retrieved from a treebank via a <b>fuzzy</b> <b>match.</b> Then tree and sentence are aligned. Subsequent structural adaptations handle unknown words, type shifting and metaphorical extentions of words. Derivational adaptations re-analyze awkward subtrees {{with the purpose}} to auto-correct badly matched trees and to insert deleted words, a strategy crucial for parsing long sentences. Experiments are presented in which dierent variants of this approach are tested...|$|E
40|$|New {{function}} group formation algorithm based on attribute value for space group target was presented, {{which had the}} ability to realize {{function group}} formation. The uncertainty of measurement space was mapped into the fuzzy attribute value space, and the uncertainty of measurement space was resolved by the <b>fuzzy</b> <b>match</b> mechanism. With lower calculation complexity less than O(n 2), it was more efficient to generate group formation for maneuvering target by simulation results. Key words: Maneuvering target, Function group formation, Situatio...|$|E
40|$|User uploads a new {{translation}} {{assignment in}} client (CAT-tool) • Document is uploaded to server and segmentized into sentences • N-grams from database are detected in each segment • 2 types of similarity calculations (bag-of-n-grams, cosine) on server: 1. Segments matched with all sentences in Staatblad (~TM <b>fuzzy</b> <b>match)</b> 2. Assignment’s similarity with all documents in Staatsblad • For identified n-grams: concordances retrieved from Staatsblad + meta-data {{of the document}} they occurred in. • Concordances are sorted based on the document similarity to current assignment (relevancy) and categorized by translation (disambiguation...|$|E
40|$|Semantic {{knowledge}} {{has been adopted}} recently for SMT preprocessing, decoding and evaluation, {{in order to be}} able to compare sentences based on their meaning rather than on mere lexical and syntactic similarity. Little attention has been paid to semantic knowledge in the context of integrating <b>fuzzy</b> <b>matches</b> from a translation memory with SMT. We present work in progress which focuses on semantics-based pretranslation before decoding in SMT. This involves applying <b>fuzzy</b> <b>matching</b> metrics based on lexical semantics and semantic roles, aligning parse trees based on semantic roles, and pretranslating matching source sentence parts using aligned tree nodes. status: publishe...|$|R
30|$|Following the {{big data}} {{analysis}} principle, QoE evaluation based on fuzzy clustering heuristic algorithm can obtain predictive score value and management information eventually, {{after the service}} analysis according to <b>fuzzy</b> <b>matching</b> and heuristic rules.|$|R
50|$|OmegaT is {{intended}} for professional translators. Its features include customisable segmentation using regular expressions, translation memory with <b>fuzzy</b> <b>matching</b> and match propagation, glossary matching, dictionary matching, translation memory and reference material searching, and inline spell-checking using Hunspell spelling dictionaries.|$|R
40|$|AbstractMatchmaking is {{considered}} {{as one of the}} crucial factors to ensure pervasive discovery of web services. Current matchmaking methods are inadequate to semantic information with machine understandable, therefore intelligent service discovery can not be carried on. In this paper, we use fuzzy linguistic variables to represent the vague or imprecise data at abstract level. The match method performs two levels, first level is capability match by inputs and outputs interfaces based on description logic reasoning, and the second level is the <b>fuzzy</b> <b>match</b> with linguistic variables, thus the more reasonable results will be presented to the users for selection...|$|E
40|$|We {{present a}} discriminative {{learning}} method {{to improve the}} consistency of translations in phrase-based Statistical Machine Translation (SMT) systems. Our method is inspired by Translation Memory (TM) systems which are widely used by human translators in industrial settings. We constrain the translation of an input sentence using the most similar ‘translation example ’ retrieved from the TM. Differently from previous research which used simple <b>fuzzy</b> <b>match</b> thresholds, these constraints are imposed using discriminative learning to optimise the translation performance. We observe that using this method can benefit the SMT system by not only producing consistent translations, but also improved translation outputs. We report a 0. 9 point improvement in terms of BLEU score on English–Chinese technical documents. ...|$|E
40|$|Today’s record {{matching}} infrastructure {{does not}} allow a flexible way to account for synonyms such as “Robert ” and “Bob ” which refer to the same name, and more general forms of string transformations such as abbreviations. We expand the problem of record matching to take such user-defined string transformations as input. These transformations coupled with an underlying similarity function are used to define the similarity between two strings. We demonstrate {{the effectiveness of this}} approach via a <b>fuzzy</b> <b>match</b> operation that is used to lookup an input record against a table of records, where we have an additional table of transformations as input. We demonstrate an improvement in record matching quality and efficient retrieval based on our index structure that is cognizant of transformations...|$|E
3000|$|... is the {{matching}} path length, and L {{is the actual}} driving length. We compare our proposed algorithm with the global matching algorithm based on weak Fréchet distance and the piecewise <b>fuzzy</b> <b>matching</b> algorithm over the running time and matching accuracy.|$|R
40|$|This paper {{presents}} {{a method for}} classifying the ancestry of Brazilian surnames based on historical sources. The information obtained forms the basis for applying <b>fuzzy</b> <b>matching</b> and machine learning classification algorithms to more than 46 million workers in 5 categories: Iberian, Italian, Japanese, German and East European. The vast majority (96. 7 %) of the single surnames were identified using a <b>fuzzy</b> <b>matching</b> and the rest using a method proposed by Cavnar and Trenkle (1994). A comparison {{of the results of}} the procedures with data on foreigners in the 1920 Census and with the geographic distribution of non-Iberian surnames underscores the accuracy of the procedure. The study shows that surname ancestry is associated with significant differences in wages and schooling...|$|R
50|$|Examples of {{technologies}} available to integrate information include deduplication, and string metrics which allow {{the detection of}} similar text in different data sources by <b>fuzzy</b> <b>matching.</b> A host of methods for these research areas are available such as those presented in the International Society of Information Fusion.|$|R
