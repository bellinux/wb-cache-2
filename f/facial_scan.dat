23|127|Public
5000|$|... #Caption: Cyberware Inc.'s <b>facial</b> <b>scan</b> {{technology}} was used with main characters and fully exploited on the Event Mode's high polygon models. Here character Gion Toji borrows actor Takashi Tsukamoto's physical appearance ...|$|E
50|$|Biometric {{authentication}} authenticates individuals {{by identifying}} their physiological or behavioral characteristic. The physiological features include {{but are not}} limited to fingerprint, hand geometry, retina scan, iris Scan, signature dynamics, keyboard dynamics, voice print, and <b>facial</b> <b>scan.</b> The most widely used biometric authentication nowadays is the fingerprint method.|$|E
50|$|The top-left {{corner of}} the {{passport}} card contains the biometric chip, which contains {{a copy of the}} information printed on the card, and a <b>facial</b> <b>scan</b> of the holder. To prevent unauthorised parties remotely accessing the information stored in the RFID biometric chip, the machine readable zone of the identity page must be scanned to unlock it. This safeguard is known as Basic Access Control.|$|E
40|$|Thesis (Master's) [...] University of Washington, 2013 Objective: To compare nasolabial {{measurements}} on nasal casts and <b>facial</b> <b>scans</b> in infants with non-syndromic clefts. Data: Two types of clinical records obtained {{prior to and}} post- presurgical: (1) digital scans of nasal casts (N = 35); (2) 3 dMD <b>facial</b> <b>scans</b> (N = 69); 34 of which had repeated <b>facial</b> <b>scans</b> on the same day. Main Outcome Measures: (1) columellar angle; (2) columella length on the noncleft or right side; (3) columella length on the cleft or left side; (4) nasal alar base width on the noncleft or right side; (5) nasal alar base width on the cleft or left side; (6) inter-endocanthal width; (7) nostril dome curvature. Results: There {{were no significant differences}} (p >. 05) between nasolabial measurements obtained from nasal casts and 3 dMD <b>facial</b> <b>scans.</b> Both records can be measured with good intra-rater reliabilities except the nasal alar base width and inter-endocanthal width (p <. 005). However, the discrepancies are not clinically significant. Reliability between two raters based on 20 casts and 20 <b>facial</b> <b>scans</b> is also good. Conclusions: The nasolabial measurements obtained from casts and 3 D <b>facial</b> <b>scans</b> are consistent, both of which show good intra- reliability and inter-rater reliability. These measurements are reproducible across repeated 3 D <b>facial</b> <b>scans</b> in infants with cleft. KEY WORDS: cleft, nose, stereophotogrammetry, cast, infant...|$|R
50|$|Actors Norman Reedus and Mads Mikkelsen will portray leading {{characters}} in the game, through motion capture, <b>facial</b> <b>scanning,</b> and vocal performance; director Guillermo del Toro will also contribute his likeness to another character through <b>facial</b> and body <b>scanning.</b> The game's title is {{a reference to the}} cetacean stranding phenomenon.|$|R
30|$|Mahmood et al. [59] {{proposed}} a matching method using nose region extraction {{to defend against}} large yaw changes (approximately 60 ° of yaw axis). In order to re-align the face to the frontal orientation, a pre-defined and pre-trained nose model is used. Face surfaces are represented by local shape descriptors. The effectiveness of this method has been evaluated in the GAVADB 3 D facial database, which includes both frontal and partially frontal <b>facial</b> <b>scans.</b> Using this method, the recognition accuracies for frontal face scans and partially frontal <b>facial</b> <b>scans</b> are 94 % and 90 % respectively.|$|R
50|$|The {{identity}} page of {{the passport}} booklet has been moved {{to the front of}} the passport and is now printed on a plastic card. This allows easier machine reading of the passport, as the official has to spend less time finding the identity page in the passport. The top-right corner of the passport booklet contains the biometric chip, which contains a copy of the information contained on the identity page, and a <b>facial</b> <b>scan</b> of the holder. To prevent unauthorised parties remotely accessing the information stored in the RFID biometric chip, the machine readable zone of the identity page must be scanned to unlock it. This safeguard is known as Basic Access Control.|$|E
5000|$|Accuracy is a {{major issue}} with Biometric Devices and a major reason why {{corporations}} and people are hesitant to implement them deeper into their working. Passwords are still extremely popular because a password is static in nature while Biometric Data can be subject to change (persons voice becoming heavier due to puberty, accidents to the face could lead to improper reading of <b>facial</b> <b>scan</b> data). When testing voice recognition as a substitute to pin based systems,Barclays reported [...] that their voice recognition system is 95 percent accurate- this statistic means that many of its customers voice might still not be recognised even when correct. This uncertanity revolving around the system could lead to slower adoption of biometric devices and continue reliance on traditional password based methods.|$|E
50|$|The {{introduction}} of the scheme was much debated, and various degrees of concern about the scheme were expressed by human rights lawyers, activists, security professionals and IT experts, as well as politicians. Many of the concerns focused on the databases underlying the identity cards rather than the cards themselves. The Act specified fifty categories of information that the National Identity Register could hold on each citizen, including up to 10 fingerprints, digitised <b>facial</b> <b>scan</b> and iris scan, current and past UK and overseas places of residence of all residents of the UK throughout their lives and indexes to other Government databases (including National Insurance Number) - which {{would allow them to}} be connected. The legislation on this resident register also said that any further information could be added.|$|E
5000|$|In {{the year}} 2000, Greg founded the [...] "Persona Foundation" [...] to further {{initiatives}} in human simulation, motion capture, 3D body and <b>facial</b> <b>scanning,</b> digital persona creation and custom platform development / operating system design for human simulation systems.|$|R
50|$|The {{game was}} {{developed}} by Psygnosis' external Chester Studio and Pompeii Studios over 1995-1997. The characters in the game were based on <b>facial</b> <b>scans</b> of staff at the studio. The Windows version supports 3D acceleration, but only using the Matrox Mystique and the Creative Labs 3D Blaster.|$|R
40|$|We {{present a}} method for {{quantifying}} and localising changes in two <b>facial</b> <b>scans</b> of the same person taken at two different time instants. The method is based on rigid registration and semantic feature extraction, followed by discrepancy computation. The proposed method combines the Landmark Transform (LT) method, which is applied on semantic feature points, and the Iterative Closest Point (ICP) algorithm, which is performed on semantic regions. Finally, {{the discrepancy between the}} two scans is computed using the Symmetric Hausdorff distance. Experimental results with both synthetic and real data show the effectiveness of the proposed method which has also been validated by an experienced clinical scientist. Moreover, the method is being used as support in clinical studies on a 3 D object database with more than 1000 <b>facial</b> <b>scans.</b> ...|$|R
5000|$|In {{order to}} {{identify}} a person, a security system has to compare personal characteristics with a database. A scan of a person's iris, fingerprint, face, or other distinguishing feature is made {{and a series of}} biometric points are drawn at key locations in the scan. In the case of a <b>facial</b> <b>scan,</b> biometric points might be placed at the tip of each ear lobe and in the corners of both eyes, for example. Measurements taken between all the (possibly hundreds of) points of a scan are compiled and result in a numerical [...] "score" [...] (which might be quite large), unique for every individual, yet which can quickly and easily be compared to the previously compiled scores of all the facial scans in the database to determine if there is a match.|$|E
40|$|Face {{recognition}} from 3 D shape data {{has been proposed}} {{as a method of}} biometric identification as a way of either supplementing or reinforcing a 2 D approach. This paper presents a 3 D face recognition system capable of recognizing the identity of an individual from a 3 D <b>facial</b> <b>scan</b> in any pose across the view-sphere, by suitably comparing it with a set of models (all in frontal pose) stored in a database. The system makes use of only 3 D shape data, ignoring textural information completely. Firstly, we propose a generic learning strategy using support vector regression [2] to estimate the approximate pose of a 3 D head. The support vector machine (SVM) is trained on range images in several poses belonging to only a small set of individuals and is able to coarsely estimate the pose of any unseen <b>facial</b> <b>scan.</b> Secondly, we propose a hierarchical twostep strategy to normalize a <b>facial</b> <b>scan</b> to a nearly frontal pose before performing any recognition. The first step consists of either a coarse normalization making use of facial features or the generic learning algorithm using the SVM. This is followed by an iterative technique to refine the alignment to the frontal pose, which is basically an improved form of the Iterated Closest Point Algorithm [8]. The latter step produces a residual error value, which {{can be used as a}} metric t...|$|E
30|$|In [90] on the {{application}} of biometric recognition in 3 D face recognition in real life, a new grid SIFT-like algorithm for registration-free 3 D face recognition is proposed under expression vatiations, occlusion, and pose changes. The principal curvature-based 3 D keypoint detection algorithm, which can repeatedly recognize the complementary position in the local curvature on a <b>facial</b> <b>scan.</b>|$|E
40|$|Basic {{components}} of the conventional prosthodontic diagnostic set-up workﬂow include dental cast models, full-mouth two-dimensional digital photographs, as well as selected intra- and extra-oral radiographs. This set-up provides a limited two-dimen-sional representation of the maxillofacial region and fails to depict the patient in full three dimensions, thereby limiting diagnosis and treatment planning. Novel three-dimensional (3 D) imaging technologies such as digital intra-oral scanning and cone beam computed tomography (CBCT) are becoming increasingly available in the dental ofﬁce. However, these technologies are limited in capturing the dentition and alveolar bone due to little regard to the soft tissue proﬁle. <b>Facial</b> <b>scanning</b> is a rapidly evolving technol-ogy {{with a wide range}} of applications in the ﬁelds of biomedical engineering, industrial design and 3 D animations. In dental medicine, the technology has its roots in orthodontics and orthognathic surgery and provides the basis for comprehensive 3 D mapping of the face for treatment planning and follow-up purposes. Recently, there has been increasing interest in applying <b>facial</b> <b>scanning</b> technology in prosthodontics and implant dentistry. The aim of this review is to shed some light on the evolution of <b>facial</b> <b>scanning</b> technology and to demonstrate the scanning principles, while providing some perspective on potential applications in prosthetic dentistry. An attempt is also made to discuss the accuracy and limitations of this novel technology, and to examine future trends...|$|R
30|$|This {{methodology}} thus provides higher accuracy {{with respect}} to laser scanning (Vivid 910 i, Minolta, Osaka, Japan; a method based on triangulation and widely used in the literature for 3 D <b>facial</b> <b>scans),</b> which has an accuracy of ± 0.38 and ± 0.31 mm in the X and Y directions, respectively, and ± 0.2 mm in the Z direction.|$|R
50|$|He also {{portrayed the}} {{character}} Shinji Mimura in the controversial film Battle Royale, {{along with this}} he has also portrayed the character Gion Toji in the video game Ryū ga Gotoku Kenzan! in both voice and likeness that was captured using <b>facial</b> <b>scanning</b> technology. He narrated the 2015 film Junk Story, which documents the life of musician hide.|$|R
30|$|The non-rigid method {{applies the}} {{deformation}} recovery algorithms to the 3 D <b>facial</b> <b>scan</b> {{to counteract the}} distortion caused by expression variations. Although a good recognition method {{can be found in}} both categories, the non-rigid method is more capable of handling 3 D face recognition in facial expression variations and can extract richer facial information [73]. In non-rigid classification, the recognition algorithms are divided into two categories: local methods and holistic methods.|$|E
30|$|All {{respiratory}} tract samples (plugged telescoping catheter, tracheal aspirate or bronchoalveolar fluid) performed for microbiological examination were analyzed. Galactomannan antigen (GM) detection in plasma and in bronchoalveolar lavage (BAL) fluid was {{performed at the}} discretion of the managing physician. An optical density ratio of 0.5 or greater for GM in serum and of 1.0 or greater for BAL fluid was considered positive. Chest CT scan and cerebral or <b>facial</b> <b>scan</b> were not routinely performed.|$|E
40|$|Objective: For {{the use of}} Cone Beam Computed Tomography (CBCT) in orthodontics, {{radiation}} exposure should be kept at a minimum for the patient. The {{radiation exposure}} {{is closely related to}} the size of the used field of view (FOV). It will be shown that the additional use of a radiation-free face scan the medium FOV (diameter 16 cm x height 16 cm) is sufficient for orthodontic diagnosis of all patients. Methods: For this work, existing CBCT data were evaluated by means of a planning software. 1, 000 patient records were anonymized, and sets of data according to sex (m/f) and age (≥ 18 / < 18 years) were created. For each of the resulting four CBCT data sets, or patient groups, an orthodontic diagnosis (FRS analysis) was carried out. The FRS-analysis was simulated using two different FOV sizes (medium and large FOV). In addition, a <b>facial</b> <b>scan</b> was simulated. Each FOV was moved in dorsal direction by the area of soft tissue detected in the face scan. Results: While all reference points necessary for FRS analysis can be captured by a large FOV. The medium FOV does not suffice detect the dorsal reference points in all male patients. This is also true for older patients compared with younger patients. However, 99 % of the reference points can be captured in all patient groups when a medium FOV is combined with a radiation-free face scan. There is no significant difference in the detection of reference points between a large FOV and a medium FOV in combination with a face scan. A medium FOV is also sufficient to capture the 4 th cervical vertebra in 100 % of patients under 18 years. Conclusion: Just as a large FOV, the combination of a medium FOV with a <b>facial</b> <b>scan</b> can capture all reference points of a cephalometric analysis to a sufficient degree in all patients, regardless of age and sex. Thus, by combining a medium FOV with a <b>facial</b> <b>scan</b> the radiation exposure of the patient can be reduced while a constant standard of diagnostic information can be maintained...|$|E
30|$|The use of {{three-dimensional}} (3 D) surface imaging {{is becoming}} more popular and accepted {{in the fields of}} Medicine and Dentistry. The present study aims to develop a technique to automatically localise and quantify soft-tissue asymmetry in adults using 3 D <b>facial</b> <b>scans.</b> This may be applied as a diagnostic tool to monitor growth and dynamic changes and to evaluate treatment outcomes.|$|R
40|$|Accuracy and {{precision}} of integumental linear dimensions in a three-dimensional facial imaging system Objective: A recently developed <b>facial</b> <b>scanning</b> method uses three-dimensional (3 D) surface imaging with a light-emitting diode. Such scanning enables surface {{data to be}} captured in high-resolution color and at relatively fast speeds. The {{purpose of this study}} was to evaluate the accuracy {{and precision}} of 3 D image...|$|R
40|$|A 3 D {{landmark}} {{detection method}} for 3 D <b>facial</b> <b>scans</b> is presented and thoroughly evaluated. The main {{contribution of the}} presented method is the automatic and pose-invariant detection of landmarks on 3 D <b>facial</b> <b>scans</b> under large yaw variations (that often result in missing facial data), and its robustness against large facial expressions. Three-dimensional information is exploited by using 3 D local shape descriptors to extract candidate landmark points. The shape descriptors include the shape index, a continuous map of principal curvature values of a 3 D object’s surface, and spin images, local descriptors of the object’s 3 D point distribution. The candidate landmarks are identified and labeled by matching them with a Facial Landmark Model (FLM) of facial anatomical landmarks. The presented method is extensively evaluated against a variety of 3 D facial databases and achieves state-of-the-art accuracy (4. 5 - 6. 3 mm mean landmark localization error), considerably outperforming previous methods, even when tested with the most challenging data...|$|R
40|$|Introduction: The {{increasingly}} {{widespread use}} of cone-beam computed tomography (CBCT) in orthodontics {{has given rise to}} vivid discussions about radiation doses, costs, and scan volumes (known as “field of view” or FoV). This study aimed to examine whether a CBCT scanner with a spherical FoV 75 mm in radius would capture all the landmarks needed for cephalometric treatment planning. Another goal was to investigate if optical facial scans, used in combination with a CBCT scan, could open the door to capturing additional landmarks not otherwise accessible. Other points of evaluation were the size requirement for a spherical FoV that would cover 95 % of all patients and how many landmarks are needed to optimize positioning of the spherical FoV. Methods. A total of 1, 003 anonymized DICOM datasets were selected for this retrospective study from the Mesantis® radiographic network. After graphic processing with InVivo 4. 0 (Anatomage Inc., San Jose, CA, USA), the datasets were imported into a specially developed software application and were aligned using anterior landmarks as reference. Based on 17 landmarks, two measurement series were conducted, simulating a CBCT scan either by itself or in combination with a <b>facial</b> <b>scan.</b> A total of 32, 758 coordinates thus acquired were checked for normal distribution, followed by presenting in tabular format the resultant frequencies at which the various landmarks were captured inside the defined FoV. A specially developed software application was used to calculate the centre of an ideal sphere defined by 17 landmarks, then calculating the combination of landmarks characterized by the closest proximity to the ideal sphere. Results. Landmarks in the dorsal region of the cranium were captured less frequently. Regardless of age and gender, the least frequently captured landmark was the porion, with relative frequencies ranging from 4. 01 % (males ≥ 18 years) to 83. 23 % (females < 18 years) based on CBCT scans alone. Using an additional <b>facial</b> <b>scan,</b> these frequencies ranged from 20. 94 % (males ≥ 18 years) to 93. 07 % (females < 18 years). Female patients under 18 offer the best chances of identifying all landmarks required. The reverse is true of adult men. Covering 95 % of all patients would require a FoV of 102. 35 ± 7. 29 mm in radius. The best reference points for optimal positioning of a spherical FoV are the porion (bilaterally) along with the soft-tissue pogonion and the nose tip. Conclusions. A CBCT scan with a spherical FoV 75 mm in radius cannot acceptably capture all of the landmarks needed for cephalometric diagnostics, whether used by itself of in combination with a <b>facial</b> <b>scan...</b>|$|E
40|$|A full-term {{baby girl}} {{weighing}} 2. 9 kg was born by normal delivery. The anomaly scan at 20 weeks (including a 3 D <b>facial</b> <b>scan)</b> was normal. She {{was born in}} good condition, but was noticed to have bilateral purple-coloured tense mobile, non-pulsatile masses below the medial canthus (figure 1). At 6 h of age, she had a cyanotic episode with airway obstruction soon after feeding. She underwent resuscita-tion, during which a naso-gastric tube was passed through each nostril, excluding choanal atresia. An ultra-sound scan confirmed bilateral cystic enlargement of the lacrimal ducts (14 mm), with some debris present. A diag-nosis of bilateral congenital dacryocystocele was made. Probing both cysts under local anaesthetic through the lacrimal punctums resulted in the release of mucoi...|$|E
40|$|International audienceA {{commonly}} accepted postulate is that {{facial expression}} recognition (FER) {{can be carried}} out by interpretation of facial action units (AUs) through high-level decision making rules. Meanwhile, most studies on AU-based FER simply detect AUs and do not map their AU detection results into expressions. In this paper, we propose to build a statistical AU space for the purpose of AU interpretation. Similarity scores from the previously proposed statistical feature models are used for defining the coordinate of an expression displayed on the <b>facial</b> <b>scan.</b> These scores are further fed to a SVM classifier to interpret expression into one of the six universal emotions. The preliminary results demonstrate the potential effectiveness of applying AU space for FER through AU interpretation...|$|E
30|$|The aim of {{the study}} was to define a {{standardized}} clinical-instrumental procedure to perform such <b>facial</b> <b>scanning</b> and mapping with the use of a specific 3 D photogrammetric methodology that allows the reconstruction of 3 D digital models of the face. Thus, with the aid of dedicated computer software, this allows quantitative and qualitative anthropometric evaluations of the surface characteristics of the facial soft tissue.|$|R
40|$|This paper {{presents}} {{a new approach}} for 3 D face modeling and recognition. Motivated by finding a representation that embodies a high power of discrimination between face classes, {{a new type of}} 3 D shape descriptors is suggested. We have developed a fully automatic system which uses an alignment algorithm to register 3 D <b>facial</b> <b>scans.</b> In addition, scalability in both time and space is achieved by converting 3 D <b>facial</b> <b>scans</b> into compact wavelet metadata. Our system consists in two phases. The first phase is called enrolment composed of 3 steps: data processing, alignment and metadata generating. The metadata generating step is powered by the use of Multi Library Wavelet Neural Networks (MLWNN). The second phase is called Authentication it starts with the calculation of depth distances between a probe and gallery 3 D face. A K-Nearest Neighbors (K-NN) technique is used for 3 D face classification. The results of this contribution are more interesting, in comparison with some others works, in term of recognition rate using the GavabDB 3 D facial database. 1...|$|R
40|$|Bury Art Museum surveys {{international}} {{contemporary artists}} working with light and time. “The poetic beauty of Grazia Toderi’s enchanting cityscales, heavenly visions of human nights; a new installation of ‘The Air That Held Them’, giant inflating heads created by UK collective Brass Art, reflecting the precise {{measurements of the}} artists’ heads taken from biomedical <b>facial</b> <b>scans</b> and a new neon commission by leading British poet and text artist, Tony Lopez, questions {{who we are and}} how we are defined. ...|$|R
40|$|Objective: To {{describe}} a new method for measuring facial swelling following orthognathic surgery using a 3 D laser scanning device. Design: Prospective clinical trial. Setting and Sample Population: University Dental Hospital, Wales College of Medicine, Biology Life and Health Sciences. Three subjects requiring bi-maxillary orthognathic surgery were recruited for the study. Experimental Variables: Laser-scanned {{images of the}} subjects were obtained under a reproducible and controlled environment with two Minolta Vivid 900 (Osaka, Japan) optical laser-scanning devices assembled as a stereo-pair. A set of left and right scanned images was taken for each subject and each scan took an average of 2. 5 s. 3 D laser scans were recorded over six time periods (T 1 – re-surgical scan, postoperatively: T 2 – 1 day, T 3 – 1 week, T 4 – 1 month, T 5 – 3 months and T 6 – 6 months). Outcome Measure: Facial scans from different time periods were overlaid onto the baseline (T 6) <b>facial</b> <b>scan</b> to determine the reduction and changes in swelling following orthognathic surgery. Results: The results showed that swelling could be accurately quantified following surgery. Furthermore, {{there was a significant}} reduction in the amount of swelling 1 month postoperatively. Furthermore, the facial morphology returned to approximately 90...|$|E
40|$|Abstract—The {{uncontrolled}} {{conditions of}} real-world biometric applications pose {{a great challenge}} to any face recognition approach. The unconstrained acquisition of data from uncooperative subjects may result in facial scans with significant pose variations along the yaw axis. Such pose variations can cause extensive occlusions, resulting in missing data. In this paper, a novel 3 D face recognition method is proposed that uses facial symmetry to handle pose variations. It employs an automatic landmark detector that estimates pose and detects occluded areas for each <b>facial</b> <b>scan.</b> Subsequently, an Annotated Face Model is registered and fitted to the scan. During fitting, facial symmetry is used to overcome the challenges of missing data. The result is a pose invariant geometry image. Unlike existing methods that require frontal scans, the proposed method performs comparisons among interpose scans using a wavelet-based biometric signature. It is suitable for real-world applications as it only requires half of the face to be visible to the sensor. The proposed method was evaluated using databases from the University of Notre Dame and the University of Houston that, {{to the best of}} our knowledge, include the most challenging pose variations publicly available. The average rank-one recognition rate of the proposed method in these databases was 83. 7 percent. Index Terms—Biometrics, face and gesture recognition, physically-based modeling. Ç...|$|E
40|$|Abstract. Facial feature {{extraction}} {{is important in}} many face-related applications, such as face alignment for recognition. We propose a multimodal scheme to integrate 3 D (range) and 2 D (intensity) information provided from a <b>facial</b> <b>scan</b> to extract the feature points. Given a face scan, the foreground is segmented from the background using the range map and the face area is detected using a real-time intensity-based algorithm. A robust nose tip locator is presented. A statistical 3 D feature location model is applied after aligning the model with the nose tip. The shape index response derived from the range map and the cornerness response from the intensity map are combined to determine {{the positions of the}} corners of the eyes and the mouth. Real-world data is subject to sensor noise, resulting in spurious feature points. We introduce a local quality metric to automatically reject the scan whose sensor noise is above a certain threshold. As a result, a fully automatic multimodal face recognition system is developed. Both qualitative and quantitative evaluations are conducted for the proposed {{feature extraction}} algorithm on a publicly available database, containing 946 facial scans of 267 subjects. This automatic feature extraction algorithm has been integrated in an automatic face recognition system. The identification performance on a database of 198 probe scans and 200 gallery subjects is close to that with manually labeled landmarks. ...|$|E
3000|$|... 3 D-TEC (3 D Twins Expression Challenge (3 D-TEC) Data Set) [49], this dataset {{contains}} 3 D <b>facial</b> <b>scans</b> of 107 {{pairs of}} twins, that is 214 people, {{each with a}} smile and a neutral expression for a total of 428 scans. Although this data set is ten times smaller than the FRGC v 2.0 data set, it is still very representative, because it includes twins with different expressions. This database will help promote the development of 3 D face recognition technology.|$|R
40|$|A seven metre-long balloon draws {{inspiration}} from classical images of Hypnos, {{the god of}} sleep, and the Surrealists, Brass Art’s work was made using a mean average of the artists’ faces taken from biomedical <b>facial</b> <b>scans.</b> The process converted living three-dimensional subjects into digital data, then into a two-dimensional pattern and finally into a single, three-dimensional inflatable sculpture. Conjuring journeys of the imagination in conjunction with real spaces {{is central to the}} three artists’ collaborative practice. ‘Trine’ means ‘threefold, or one third of 360 degrees’...|$|R
5000|$|The {{external}} {{muscles of}} the eye are conspicuously large and strong {{in relation to the}} small size and weight of the eyeball. It is frequently said that they are [...] "the strongest muscles for the job they have to do" [...] and are sometimes claimed to be [...] "100 times stronger than they need to be." [...] However, eye movements (particularly saccades used on <b>facial</b> <b>scanning</b> and reading) do require high speed movements, and eye muscles are exercised nightly during rapid eye movement sleep.|$|R
