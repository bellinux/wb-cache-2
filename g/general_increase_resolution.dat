0|10000|Public
40|$|Long-standing {{systematic}} model {{errors in}} both tropics and extratropics of the ECMWF model run at a horizontal resolution typical for climate models are investigated. Based on {{the hypothesis that}} the misrepresentation of unresolved scales contributes to the systematic model error, three model refinements aimed at their representation—fluctuating or deterministically—are investigated. <b>Increasing</b> horizontal <b>resolution</b> to explicitly simulate smaller-scale features, representing subgrid-scale fluctuations by a stochastic parameterization, and improving the deterministic physics parameterizations all lead to a decrease in the systematic bias of the Northern Hemispheric circulation. These refinements reduce the overly zonal flow and improve the model’s ability to capture the frequency of blocking. However, the model refinements differ greatly in their impact in the tropics. While improving the deterministic and introducing stochastic parameterizations reduces the systematic precipitation bias and improves the characteristics of convectively coupled waves and tropical variability in <b>general,</b> <b>increasing</b> horizontal <b>resolution</b> has little impact. The fact that different model refinements can lead to reductions in systematic model error is consistent with the hypothesis that unresolved scales play an important role. At the same time, this degeneracy of the response to different forcings can lead to compensating model errors. Hence, if one takes the view that stochastic parameterization should be an important element of next-generation climate models, if only to provide reliable estimates of model uncertainty, then a fundamental conclusion {{of this study is that}} stochasticity should be incorporated within the design of physical process parameterizations and improvements of the dynamical core and not added a posteriori...|$|R
40|$|In view of {{the growing}} {{interests}} in the explicit modeling of clouds and precipitation, the effects of varying vertical resolution and time-step sizes on the 72 -h explicit simulation of Hurricane Andrew (1992) are studied using the Pennsylvania State University/National Center for Atmospheric Research (PSU/NCAR) mesoscale model (i. e., MM 5) with the finest grid size of 6 km. It is shown that changing vertical resolution and time-step size has significant effects on hurricane intensity and inner-core cloud/precipitation, but little impact on the hurricane track. In <b>general,</b> <b>increasing</b> vertical <b>resolution</b> tends to produce a deeper storm with lower central pressure and stronger three-dimensional winds, and more precipitation. Similar effects, but to a less extent, occur when the time-step size is reduced. It is found that increasing the low-level vertical resolution is more efficient in intensifying a hurricane, whereas changing the upper-level vertical resolution has little impact on the hurricane intensity. Moreover, {{the use of a}} thicker surface layer tends to produce higher maximum surface winds. It is concluded that the use of higher vertical resolution, a thin surface layer, and smaller time-step sizes, along with higher horizontal resolution, is desirable to model more realistically the intensity and inner-core structures and evolution of tropical storms {{as well as the other}} convectively driven weather systems. Key words: hurricane intensity, vertical resolution, numerical weather prediction 1...|$|R
40|$|A {{professional}} project submitted in partial {{fulfillment of}} the requirements for the degree of Master of Water Resources (Hydroscience), Water Resources Program, University of New Mexico, August, 2002 Following the Cerro Grande Fire in 2000, stakeholders {{in the immediate vicinity}} became concerned with the hydrological ramifications from the change in the hydrologic system. Flooding is more prevalent after a high temperature forest fire burns through an area, due to the creation of hydrophobic soil conditions and loss of vegetative cover. The Cerro Grande Fire started as a controlled burn on Cerro Grande Mountain inside Bandelier National Park on May 4, 2000. This fire burned over 45, 000 acres. Much of the affected land sits on the edges of the Jemez Mountains, which drain into and through the Pajarito Plateau. With all the changes in the hydrologic system, a full-blown reevaluation of the floodplain derived from the 100 -yr 6 -hr design storm was needed. The hydrologic modeling for the floodplain analysis was done using GHEC-l, Haestad's graphical version of the United States Army Corp. of Engineers (US ACE) HEC-l. The hydraulic floodplain modeling was done using the Hydraulic Engineering Center's River Analysis System (HEC-RAS) linked with ArcView 3. 2 a. While assessing the revised model, the question of how differing data resolutions and cross sectional spacing would affect the final floodplain outcome was raised. It was thought that the modeling accuracy should <b>increase</b> with higher <b>resolution</b> data and more closely spaced cross sections. HEC-GeoRAS allowed us to retrieve elevational cross section data at a very high resolution without incurring exorbitant land surveying costs. After looking at four different data sets, there were slightly noticeable differences in the floodplain produced from linked GIS-HEC calculations. The differences were noticed through both visual inspections as well as by looking at average topwidths. In <b>general,</b> with <b>increased</b> <b>resolution</b> data the floodplain tended to be smaller from bank to bank. As for the cross sectional spacing differences, the closer the cross sections were spaced the more continuous the floodplain became...|$|R
40|$|The {{convergence}} of simulations from the Community Atmosphere Model with <b>increasing</b> <b>resolution</b> is determined in an aqua-planet context. Convergence {{as a function}} of scale is considered. Horizontal resolution (T 42 –T 340) and time step (40 – 5 min) are varied separately. The simulations are sensitive to both. Global averages do not necessarily converge with <b>increasing</b> <b>resolution.</b> The zonal average equatorial precipitation shows a strong sensitivity to time step. Parametrizations should be applied in a range of time steps where such sensitivity is not seen. The larger scales of the zonal average equatorial precipitation converge with <b>increasing</b> <b>resolution.</b> There is a mass shift from polar to equatorial regions with <b>increasing</b> <b>resolution</b> with no indication of convergence. The zonal average cloud fraction decreases with <b>increasing</b> <b>resolution</b> with no indication of convergence. Equatorial wave propagation characteristics converge with <b>increasing</b> <b>resolution,</b> however a relatively high truncation of T 170 is required to capture wavenumbers less than 16. Extremes are studied {{in the form of the}} probability density functions of precipitation. The largest half of the scales of the model converge for resolutions above T 85. 1...|$|R
5000|$|... to <b>increase</b> <b>resolution</b> in {{photoresists}} for {{cathode ray}} tubes (CRT) ...|$|R
30|$|Quantitative {{evaluation}} of scalability for big data (including {{hundreds of thousands}} of nodes) with <b>increased</b> <b>resolutions.</b>|$|R
30|$|In summary, Cabinet Tree {{is highly}} {{scalable}} with <b>increased</b> <b>resolutions</b> in both speed {{and percentage of}} visible nodes.|$|R
30|$|What {{resolution}} do we need? The {{development of}} new sensors {{has been driven by}} the need for <b>increased</b> <b>resolution.</b>|$|R
50|$|In {{addition}} {{three more}} levels (3, 4 and 5) at <b>increasing</b> <b>resolution</b> have been proposed, {{but not yet}} standardized.|$|R
40|$|<b>Increasing</b> the <b>resolution</b> of semblance-based {{velocity}} spectra, or semblance spectra, {{can improve}} the accuracy of normal moveout velocity estimates. The resolution of semblance spectra depends on the sensitivity of semblance to changes in velocity. By weighting terms in the semblance calculation that are more sensitive to changes in velocity, we can <b>increase</b> <b>resolution.</b> Our implementation of weighted semblance is a straightforward extension of conventional semblance. Somewhat surprisingly, we <b>increase</b> <b>resolution</b> by choosing a weighting function that minimizes semblance. Compared to conventional semblance, weighted semblance better distinguishes semblance peaks for interfering events. Key words: semblance resolution velocity analysis...|$|R
50|$|Tabular {{crystals}} tend to lie {{along the}} film's surface when coated and dried. This reduces scattering {{of light and}} <b>increases</b> <b>resolution.</b>|$|R
5000|$|To {{determine}} gravity-field anomalies with {{an accuracy}} of [...] (1 mGal). To <b>increase</b> <b>resolution,</b> the satellite flew in an unusually low orbit.|$|R
5000|$|It is not {{possible}} to use subpixel rendering to <b>increase</b> the <b>resolution</b> without creating colour fringes similar to those seen in classic [...] or [...] striped panels, but the <b>increased</b> <b>resolution</b> compensates it, in addition, their effective visible colour is reduced by the presence of [...] "colour-neutral" [...] white subpixels.|$|R
30|$|Where λo is {{the central}} {{wavelength}} of the light and Δλ is its spectral full width at half maximum (FWHM). Thus, if we increase BW of light used (using a source of shorter coherence length), we can <b>increase</b> axial <b>resolution.</b> The advantage of <b>increased</b> <b>resolution</b> is lost by the autocorrelation noise that covers required signals of the sample structure.|$|R
40|$|AbstractIn this paper, the adaptive, minimum {{variance}} (MV) beamformer {{is applied to}} ultrasound data. Due to near-field properties, {{the energy of the}} ultrasound data reduces towards the edges of the transducer. The influence of this near-field effect is demonstrated, and a method to reduce this influence is proposed. By reducing the number of active sensor elements, an <b>increased</b> <b>resolution</b> can be obtained with the MV beamformer. This observation is directly opposite the well-known relation between the spatial extent of the aperture and the achievable resolution. The investigations are based on Field II simulated data using a 128 -element transducer with a large spatial extent. The results show that an <b>increased</b> <b>resolution</b> can be obtained, when using only {{the central part of the}} transducer compared to using the entire spatial extent. Using the central 32 or 48 elements provides an <b>increased</b> <b>resolution</b> compared to using all 128 elements...|$|R
30|$|To {{evaluate}} scalability with <b>increased</b> <b>resolutions,</b> we use {{two large}} datasets (D Drive and C Drive 1 in Table 4) on 7 wide screens (640 × 360, 960 × 540, 1, 280 × 720, 1, 600 × 900, 1, 920 × 1, 080, 2, 560 × 1, 440 and 3, 840 × 2, 160). In this evaluation, {{we wish to}} find the trend {{of the percentage of}} visible nodes (among all the nodes) and the layout time (excluding the file reading, rendering and displaying time) with <b>increased</b> <b>resolutions.</b>|$|R
40|$|The goal of {{this project}} was to {{successfully}} demonstrate a double patterning technique using equipment available at the SMFL at RIT. Traditional methods of <b>increasing</b> <b>resolution</b> have been essentially exhausted; therefore new methods of <b>increasing</b> <b>resolution</b> are needed. One of these new methods is double patterning, which splits a dense pattern into two less dense patterns which are imaged in two steps, thereby reducing imaging constraints. Overall a proof of concept of the double patterning process was achieved. Imaging of 0. 5 μm drawn features was demonstrated, resulting in 0. 3 μm post-etch...|$|R
50|$|So {{what does}} this mean? It means that to <b>increase</b> <b>resolution</b> of two peaks on a chromatogram, {{one of the three}} terms of the {{equation}} need to be modified.|$|R
3000|$|..., even {{discontinuous}} solutions will be approximated with <b>increasing</b> <b>resolution.</b> Furthermore, {{in order}} to leverage the advantages of a sparse tensor approximation, a higher regularity of the solution will be required in any case.|$|R
50|$|In March 2016, Krome Studios re-released an PC remastered port of Ty the Tasmanian Tiger on Steam Early Access for the PC only, with <b>increased</b> <b>resolution</b> textures, and new lighting, {{shadow and}} {{reflection}} effects.|$|R
50|$|UHDTV {{potentially}} allows Rec. 2020, higher dynamic range, {{and higher}} frame rates {{to work on}} HD services without <b>increasing</b> <b>resolution</b> to 4K, providing improved quality without as high {{of an increase in}} bandwidth demand.|$|R
30|$|While {{looking at}} the {{recognition}} rate for each individual class in Figs. 8, 9, and 10 (c), all danger prediction rates are stable from medium to high resolution, except for outdoor stairs at the highest resolution (Fig. 8 (c)). In outdoor stairs at high resolution, some dangers can still be classified as warnings when the stairs start {{to appear in the}} lower sub-image. All warning prediction rates decrease with <b>increasing</b> <b>resolution.</b> The quality of the depth map affects the classification of warnings that tend to be predicted as dangers or safe. However, the safe prediction rate in indoor scenes gets higher with <b>increasing</b> <b>resolution</b> while it tends to decrease in outdoor scenes (Figs. 8, 10 (c)). This behaviour indicates the influence of the illumination and the texture. The outdoor reflection glare has a negative impact on the depth map extraction. The texture of indoor scenes is improved with <b>increasing</b> <b>resolution.</b> In any of the three groups, the classification between critical scenes and harmless places presents a very low false positive rate despite a slight increase at the lowest resolution.|$|R
50|$|Data fusion {{will always}} mean an {{increase}} in processing compared to a single radar. However it may be particularly computationally expensive if significant processing is involved in data fusion, such as attempts to <b>increase</b> <b>resolution.</b>|$|R
50|$|Display Stream Compression (DSC) uses a {{visually}} lossless low-latency algorithm {{based on}} predictive DPCM and YCoCg-R color space; it allows <b>increased</b> <b>resolutions</b> and color depths and reduced power consumption. Visually lossless compression is tested against ISO/IEC 29170-2 standard.|$|R
50|$|Adaptive multigrid {{exhibits}} adaptive mesh refinement, that is, it {{adjusts the}} grid as the computation proceeds, {{in a manner}} dependent upon the computation itself. The idea is to <b>increase</b> <b>resolution</b> of the grid only in regions of the solution where it is needed.|$|R
40|$|Optical {{fibers and}} fiber Bragg grating can improve using of {{standard}} laser interferometry methods in industry applications. Especially fiber Bragg gratings can improve frequency parameters of laser diodes in the laser interferometers. These parameters <b>increase</b> <b>resolution</b> and measurement {{range of the}} laser interferometer...|$|R
40|$|Display {{accessories}} <b>increase</b> <b>resolution</b> {{and flexibility}} of use. Toolmaker's microscope equipped with video monitor, auxiliary lighting, and high-resolution readout devices enables noncontacting measurements of tiny slots, indentations, and similar features on parts. Measures places {{difficult or impossible}} to reach by mechanical means...|$|R
40|$|The University of Bath’s Department of Mathematical Sciences {{is at the}} {{forefront}} of research in adaptivity. This is a sophisticated mathematical approach to automatically reducing computational mesh sizes at specific points of interest, <b>increasing</b> <b>resolution</b> while minimising any escalation in computing power...|$|R
50|$|Typically, {{magnification}} {{is related}} to scaling up visuals or images {{to be able to}} see more detail, <b>increasing</b> <b>resolution,</b> using microscope, printing techniques, or digital processing. In all cases, the magnification of the image does not change the perspective of the image.|$|R
50|$|The LARMOR neutron {{microscope}} is {{a planned}} microscope {{based on the}} principle of neutron scattering. It is named in honor of Joseph Larmor and the principle of larmor precession that will <b>increase</b> <b>resolution</b> and accuracy. It will be built at the ISIS facilities in Oxfordshire.|$|R
5000|$|... 3) Changing α is {{the most}} {{effective}} way of <b>increasing</b> <b>resolution.</b> This can be done by choosing a stationary phase that has a greater difference between k1' and k2'. It can also be done in L.C. by using pH to invoke secondary equilibria (if applicable).|$|R
40|$|A typical transoceanic {{submarine}} cable route survey includes {{a vast amount}} of information spanning thousands of kilometers, with additional data types and <b>increased</b> <b>resolution</b> near continental margins. Formerly, cable installers have requested paper charts. This information is static, and changes to routing can result in increased cost...|$|R
40|$|Device {{proposed}} to improve imaging of x rays. Features thin layer of oxide in virtual phase to increase quantum efficiency and depletion layer nearly as thick as epitaxial silicon layer to <b>increase</b> <b>resolution.</b> Applications include imaging spectrometers for x-ray astronomy, investigations of plasmas, and x-ray crystallography...|$|R
40|$|The {{main goal}} of this bachelor’s thesis is acquaint with method, which enable <b>increasing</b> <b>resolution</b> digital photos. Also realize {{individual}} interpolation method and Super-resolution by the help of programme Matlab and reference on estimation record. Discuss possibility using method super- resolution for imagery with medical modality...|$|R
40|$|We {{recently}} reported the excitation of autoionizing states in helium by positive-ion bombardment and their subsequent observation as fine {{structure in the}} energy spectrum of the emitted electrons. With somewhat <b>increased</b> <b>resolution</b> we have now observed additional levels in helium including parts of two series not previously reported...|$|R
50|$|Cancer research: Micro-MRI {{is often}} used to image the brain because of its ability to non-invasively {{penetrate}} the skull. Because of its high resolution, micro-MRI can also detect early small-sized tumors. Antibody-bound paramagnetic nanoparticles {{can also be used to}} <b>increase</b> <b>resolution</b> and to visualize molecular expression in the system.|$|R
