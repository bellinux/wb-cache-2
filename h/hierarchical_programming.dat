16|199|Public
50|$|In many {{programming}} taxonomies and syntax models (as well as fractals in mathematics), nested hierarchies, including Russian dolls, {{are also}} used to illustrate the properties of self-similarity and recursion. Recursion itself is included as a subset of <b>hierarchical</b> <b>programming,</b> and recursive thinking can be synonymous with a form of hierarchical thinking and logic.|$|E
30|$|The {{proposed}} technique can {{be extended}} to more complex <b>hierarchical</b> <b>programming</b> problems like multi-level quadratic fractional programming problems (ML-QFPPs), multi-level multi-objective programming problems (ML-MOPPs) etc. and related computer programs can also be constructed in MATLAB or other programming platforms.|$|E
40|$|This paper {{presents}} a novel method for enabling fast devel-opment and easy customization of interactive data-intensive web applications. Our approach {{is based on}} a high-level <b>hierarchical</b> <b>programming</b> model that results in both a very clean semantics of the application {{while at the same time}} cre-ating well-defined interfaces for customization of application components. A prototypical implementation of a conference management system shows the efficacy of our approach. Categories and Subject Descriptor...|$|E
40|$|AbstractWe {{investigate}} the defining power of stratified and <b>hierarchical</b> logic <b>programs.</b> As {{an example for}} the treatment of negative information in the context of these structured programs we also introduce a stratified and hierarchical closed-world assumption. Our analysis tries to relate the defining power of stratified and <b>hierarchical</b> <b>programs</b> (with and without an appropriate closed-world assumption) very precisely to notions and hierarchies in classical definability theory...|$|R
40|$|AbstractHierarchical Timing Language (HTL) is a {{coordination}} {{language for}} distributed, hard real-time applications. HTL is a hierarchical extension of Giotto and, like its predecessor, {{based on the}} logical execution time (LET) paradigm of real-time programming. Giotto is compiled into code for a virtual machine, called the Embedded Machine (or E machine). If HTL is targeted to the E machine, then the <b>hierarchical</b> <b>program</b> structure needs to be flattened; the flattening makes separate compilation difficult, and may result in E machine code of exponential size. In this paper, we propose a generalization of the E machine, which supports a <b>hierarchical</b> <b>program</b> structure at runtime through real-time trigger mechanisms that are arranged in a tree. We present the generalized E machine, and a modular compiler for HTL that generates code of linear size. The compiler may generate code for any part of a given HTL program separately in any order...|$|R
40|$|We have {{recently}} proposed a coordination language, called Hierarchical Timing Language (HTL), for distributed, hard real-time applications. HTL is a hierarchical extension of Giotto and, like its predecessor, {{based on the}} logical execution time (LET) paradigm of real-time programming. Giotto is compiled into code for a virtual machine, called the Embedded Machine (or E machine). If HTL is targeted to the E machine, the <b>hierarchical</b> <b>program</b> structure needs to be flattened which makes separate compilation difficult and may result in code of exponential size. In this paper, we propose a generalization of the E machine which supports a <b>hierarchical</b> <b>program</b> structure at runtime through real-time trigger mechanisms that are arranged in a tree. We present the generalized E machine, and a modular compiler for HTL that generates code of linear size. The compiler may generate code for any parts of a given HTL program separately in any order...|$|R
40|$|Abstract—Dataflow {{languages}} offer {{a natural}} means to express concurrency {{but are not}} a natural representation of the archi-tectural features of high-performance, distributed-memory com-puters. When used as the outermost language in a <b>hierarchical</b> <b>programming</b> model, dataflow is very effective at expressing the overall flow of a computation. In this work, we present strategies and techniques used by the Swift dataflow language to obtain good performance on extremely large computing systems. We also present multiple unique language features that offer practical utility and performance enhancements. I...|$|E
40|$|In {{development}} regions, {{the management}} of environmental quality and the regional planning of water supply and the disposal of residuals {{are closely related to}} the form of intraregional population distribution. In this paper a <b>hierarchical</b> <b>programming</b> model is presented of the optimum intraregional population distribution in relation to environmental quality and the economic cost of water supply and the disposal of residuals. The model is applied to the specific case of a suburban region of the Tokyo Metropolitan Region. The results show that the higher-order objective of environmental quality regulates the spatial allocation of disposal-of-residuals activities, and the lower-order objective of economic cost determines the form of intraregional population distribution. ...|$|E
40|$|The {{paper is}} {{a manifestation of}} the {{fundamental}} importance of the linear program with linear complementarity constraints (LPCC) in disjunctive and <b>hierarchical</b> <b>programming</b> as well as in some novel paradigms of mathematical programming. In addition to providing a unified framework for bilevel and inverse linear optimization, nonconvex piecewise linear programming, indefinite quadratic programs, quantile minimization, and ℓ 0 minimization, the LPCC provides a gateway to a mathematical program with equilibrium constraints, which itself is an important class of constrained optimization problems that has broad applications. We describe several approaches for the global resolution of the LPCC, including a logical Benders approach that can be applied to problems that may be infeasible or unbounded...|$|E
40|$|Recently, Hitzler and Seda {{showed how}} a domain-theoretic proof {{can be given}} of the fact that, for a locally <b>hierarchical</b> <b>program,</b> the single-step {{operator}} T P, defined in two-valued logic, has a unique fixed point. Their approach employed a construction which turned a ScottErshov domain into a generalized ultrametric space. Finally, a fixed-point theorem of PriessCrampe and Ribenboim was applied to T P to establish the result. In this paper, we extend these methods and results to the corresponding well-known single-step operators Φ P and Ψ P determined by P and defined, respectively, in three-valued and four-valued logics. AMS Subject Classification 2000 : Primary 68 N 17, Secondary 03 B 70, 03 G 10. Keywords: Fixed point, operator, many-valued logic, Scott-Ershov domain, locally <b>hierarchical</b> <b>program.</b> 1 Introduction A common approach to giving meaning or "semantics" to programming language constructs is to assign an operator to the construct and look for its fixed points. In t [...] ...|$|R
40|$|We {{investigate}} the defining power of stratified and <b>hierarchical</b> logic <b>programs.</b> As {{an example for}} the treatment of negative information in the context of these structured programs we also introduce a stratified and hierarchical closed-world assumption. Our analysis tries to relate the defining power of stratified and <b>hierarchical</b> <b>programs</b> (with and without an appropriate closed-world assumption) very precisely to notions and hierarchies in classical definability theory. Stratified and <b>hierarchical</b> logic <b>programs</b> are two well-known and typical candidates of what one may more generally denote as structured programs. In both cases {{we have to deal with}} normal logic programs which satisfy certain syntactic conditions with respect to the occurrence of negative literals. Recently they have gained a lot of importance in connection with the search for nice declarative semantics for logic programs and the treatment of negative information in logic programming (e. g., Lloyd [10]). Stratified programs were introduced into logic programming by Apt, Blair, and Walker [2] and van Gelder [17] not long ago. In mathematical logic, however, theories of this kind have been studied for more than 20 years under the general theme of iterated inductive definability. Indeed, stratified programs can be understood as systems for (finitely) iterated inductive definitions where the definition clauses are of very low logical complexity. The notion of <b>hierarchical</b> <b>program</b> (e. g., Clark [6], Shepherdson [15]), on the other hand, is motivated by database theory and tries to reflect the idea of iterated explicit definability by simple principles. From a conceptual point of view we are interested in the relationship between logic programming, inductive definability and equational definability. By making u [...] ...|$|R
40|$|Abstract. This paper {{addresses}} {{the problem of}} learning control skills from observation. In particular, we show how to infer a <b>hierarchical,</b> reactive <b>program</b> that reproduces and explains the observed actions of other agents, specifically the elements that are shared across multiple individuals. We infer these programs using a three-stage process that learns flat unordered rules, combines these rules into a classification hierarchy, and finally translates this structure into a <b>hierarchical</b> reactive <b>program.</b> The resulting program is concise and easy to understand, {{making it possible to}} view program induction as a practical technique for knowledge acquisition. ...|$|R
40|$|This {{thesis is}} {{concerned}} with the specification, compilation and corresponding temporal analysis of real-time stream processing applications that are executed on embedded multiprocessor systems. An example of such applications are software defined radio applications. These applications typically have real-time requirements in the form of throughput and latency constraints which result from communication with the environment. Modern stream processing applications also often have multiple operation modes and can process multiple streams at different rates. To efficiently utilize these multiprocessor systems, function-level parallelism has to be extracted from these applications by a multiprocessor compiler. The compiler must also derive a corresponding temporal analysis model which is used to verify that real-time constraints are satisfied. This ensures that the implementation is a refinement of the analysis model, meaning the analysis results are an upper bound on the actual temporal behavior. The temporal analysis model must be sufficiently expressive that any application that can be specified can be modeled and also analyzed. In this thesis we present a novel <b>hierarchical</b> <b>programming</b> language and compiler for the specification and compilation of real-time stream processing applications that satisfy the aforementioned requirements. The <b>hierarchical</b> <b>programming</b> language consists of parallel modules in which sequential modules are nested. Sequential modules contain sequential statements which can be for example while-loops. The use of modules enables component based design, thus the independent development and analysis of separate modules. The language also allows for the use of time in algorithms in the form of time-aware statements, e. g. time-out statements. From every specification a corresponding temporal analysis model is derived which is used to verify the real-time requirements automatically. However, the used temporal analysis models {{can also be used to}} automatically explore different optimizations opportunities and to make a trade-off between the throughput, latency and memory requirements of applications...|$|E
40|$|Today most {{systems in}} {{high-performance}} computing (HPC) feature a hierarchical hardware design: shared-memory nodes with several multi-core CPUs are connected via a network infrastructure. When parallelizing {{an application for}} these architectures it seems natural to employ a <b>hierarchical</b> <b>programming</b> model such as combining MPI and OpenMP. Nevertheless, there is the general lore that pure MPI outperforms the hybrid MPI/OpenMP approach. In this paper, we describe the hybrid MPI/OpenMP parallelization of IR 3 D (Incompressible Realistic 3 -D) code, a full-scale real-world application, which simulates the environmental effects {{on the evolution of}} vortices trailing behind control surfaces of underwater vehicles. We discuss performance, scalability and limitations of the pure MPI version of the code on a variety of hardware platforms and show how the hybrid approach can help to overcome certain limitations...|$|E
40|$|Abstract—In {{this note}} we propose two projects: (1) Creating a <b>hierarchical</b> <b>programming</b> model from current models, and (2) Extracting {{application}} primitives from the ” 13 dwarfs”. The first topic addresses {{the need for}} a unified and manageable framework for very large scale concurrent execution. This is the productivity part- less complexity will drive better mapping of algorithms to architecture; which will also contributes to better performance. The second topic focuses mostly on the processor and the node with the aim of laying the groundwork for software and silicon optimized kernels. While it is understood that applications primitives are outside the scope of IESP, the motivation for introducing it here {{is that it is a}} companion issue and that increasing the efficiency of each processor provides high return for science- at all levels of system size...|$|E
40|$|This paper {{describes}} the recently developed "genetic programming " paradigm which genetically breeds popu-lations of computer programs to solve problems. In ge-netic programming, {{the individuals in}} the population are <b>hierarchical</b> computer <b>programs</b> of various sizes and shapes. This paper also extends the genetic program-ming paradigm to a "co-evolution " algorithm which op-erates simultaneously on two populations of indepen-dently-acting <b>hierarchical</b> computer <b>programs</b> of various sizes and shapes. 1. INTRODUCTION AND OVERVIEW This paper {{describes the}} recently developed "genetic pro-gramming " paradigm which genetically breeds populations of computer programs to solve problems. In genetic pro...|$|R
40|$|To evolve {{structured}} programs we introduce H-PIPE, {{a hierarchical}} extension of Probabilistic Incremental Program Evolution (PIPE - Sa/lustowicz and Schmidhuber, 1997). Structure is induced by "hierarchical instructions" (HIs) limited to top-level, structuring program parts. "Skip nodes" (SNs) inspired by biology's introns (non-coding segments) allow for switching program parts on and off. In our experiments H-PIPE outperforms PIPE, and SNs facilitate synthesis of certain structured programs but not unstructured ones. We conclude that introns {{can be particularly}} useful {{in the presence of}} structural bias. Keywords: Probabilistic Incremental Program Evolution, Structured <b>Programs,</b> <b>Hierarchical</b> <b>Programs,</b> Introns, Non-Coding Segments. 1 Introduction and Previous Work Overview. <b>Hierarchical</b> Probabilistic Incremental <b>Program</b> Evolution (H-PIPE) is a novel method for synthesizing structured programs. It uses the PIPE paradigm (Sa/lustowicz and Schmidhuber, 1997) to iteratively generate succes [...] ...|$|R
40|$|To evolve {{structured}} programs we introduce H-PIPE, {{a hierarchical}} extension of Probabilistic Incremental Program Evolution (PIPE). Structure is induced by "hierarchical instructions" (HIs) limited to top-level, structuring program parts. "Skip nodes" (SNs) allow for switching program parts on and off. They facilitate synthesis of certain structured programs. In our experiments HPIPE outperforms PIPE: structural bias can speed up program synthesis. Keywords: Probabilistic Incremental Program Evolution, Structured <b>Programs,</b> <b>Hierarchical</b> <b>Programs,</b> Non-Coding Segments. 1 Introduction Overview. Automatic program synthesis {{is of interest}} because it addresses the problem of searching in general algorithm space as opposed to more limited search spaces like those of, say, feedforward neural networks. <b>Hierarchical</b> Probabilistic Incremental <b>Program</b> Evolution (H-PIPE) is a novel method for synthesizing structured programs. It uses the PIPE paradigm (Sa/lustowicz and Schmidhuber, 1997) to iterativ [...] ...|$|R
40|$|Targeting Outcomes of Programs (TOP) is a seven-step <b>hierarchical</b> <b>programming</b> {{model in}} which the program {{development}} and performance sides are mirror images of each other. It served as a framework to identify a simple method for targeting photographic events in nonformal education programs, indicating why, when, and how photographs {{would be useful to}} inform other evaluation strategies. In two case studies, photographs enhanced the formative story of a geoscience project being developed and tested, and contributed to the outcome narrative of a 10 -year partnership project between two universities. In both cases, TOP proved to be an efficient and easy-to-use framework. Using TOP in this fashion has the potential to help evaluators address challenges posed by the subjectivity of photography and possible biases of the photographer in the research process...|$|E
40|$|The work of {{engineering}} and business professionals includes making a series of decisions and optimizations. Real world decision making problems faced by decision makers (DM) involve multiple, usually conflicting, criteria. These multi-criteria decision making problems (MCDM) are usually complicated and large in scale. In strategic Maintenance planning, choices are made on where to focus time and effort, where to spend money. We consider a framework for strategic maintenance planning in a modern maintenance driven organization. Our focus is on a multi-stage framework in which the planning {{is divided into two}} stages, identifying an optimal set of possible actions and finding the optimal decision policy for these actions for each point in time {{as a function of the}} stochastically evolving system state. To this respect we consider the MCDM method of AHP (Analytical <b>hierarchical</b> <b>programming)</b> in a fuzzy environment, and Markov decision processes (MDP) ...|$|E
40|$|Apple Macintosh HyperCardR is a <b>hierarchical</b> <b>programming</b> environment, with {{linkages}} between visual data fields. CELLMATE is a public-domain hyperCard stack containing three graphic user templates: a report template {{modeled on the}} standard U. S. Government tissue consultation form, a quality assurance template, and a statistics template that automatically compiles data retrieved from the report files according to the specific search and organization instructions contained in the statistics “buttons”. Maneuvering through the stack is accomplished by user-initiated events (system messages) trapped by objects. Included features of the program include printout of reports and other stack cards; generation and printout of followup letters; and retrieval of cases by diagnosis, by submitting physician, or by patient. CELLMATE's functions can be expanded by scripting newly declared objects, permitting the user to customize quality assurance activities. CELLMATE is portable throughout Macintosh computers, and is a potential aid for automated quality assurance systems...|$|E
5000|$|Synthestra, an <b>hierarchical</b> MIDI {{sequencing}} <b>program</b> for Apple II (1986) ...|$|R
40|$|Abstract. Several {{important}} {{classes of}} normal logic programs, including the classes of acyclic, acceptable, and locally <b>hierarchical</b> <b>programs,</b> have the property thatevery {{program in the}} class has a unique twovalued supported model. In this paper, we call such classes unique supported model classes. We analyse and characterize these classes by means of operators on three-valued logics. Our studies will motivate the de nition of a larger unique supported model class which we call the class of-accessible programs. Finally, weshow that the class of-accessible programs is computationally adequate in that every partial recursive function can be implemented by such a program...|$|R
50|$|Dahl {{became a}} full {{professor}} at the University of Oslo in 1968 and was a gifted teacher as well as researcher. Here he worked on <b>Hierarchical</b> <b>Program</b> Structures, probably his most influential publication, which appeared co-authored with C.A.R. Hoare in the influential book Structured Programming of 1972 by Dahl, Edsger Dijkstra and Hoare, perhaps the best-known academic book concerning software in the 1970s. As his career progressed, Dahl became increasingly interested {{in the use of}} formal methods, to rigorously reason about object-orientation for example. His expertise ranged from the practical application of ideas to their formal mathematical underpinning to ensure the validity of the approach.|$|R
40|$|Dedication. It is {{our great}} {{pleasure}} to dedicate this work to Professor Richard W. Cottle {{on the occasion of}} his 75 th birthday in 2009. Professor Cottle is the father of the linear complementarity problem (LCP) [16]. The linear program with linear complementarity constraints (LPCC) treated in this paper is a natural extension of the LCP; our hope is that the LPCC will one day become as fundamental as the LCP, thereby continuing Professor Cottle’s legacy, bringing it to new heights, and extending its breadth. The paper is a manifestation of the fundamental importance of the linear program with linear complementarity constraints (LPCC) in disjunctive and <b>hierarchical</b> <b>programming</b> as well as in some novel paradigms of mathematical programming. In addition to providing a unified framework for bilevel and inverse linear optimization, nonconvex piecewise linear programming, indefinite quadratic programs, quantile minimization, and ℓ 0 minimization, the LPCC provides a gateway to a mathematical program with equilibrium constraints, which itself is an important class of constrained optimization problems that has broad applications. We describe several approaches for the global resolution of the LPCC, including a logical Benders approach that can be applied to problems that may be infeasible or unbounded...|$|E
40|$|Abstract In recent years, the {{application}} of high-performance and distributed computing in scientific practice has become increasingly wide-spread. Among the most widely available platforms to scientists are clusters, grids, and cloud systems. Such infrastructures currently are undergoing revolutionary change due to the integration of many-core technologies, providing orders-of-magnitude speed improvements for selected compute kernels. With high-performance and distributed computing systems thus becoming more heterogeneous and <b>hierarchical,</b> <b>programming</b> complexity is vastly increased. Further complexities arise because urgent desire for scalability, and issues including data distribution, software heterogeneity, and ad-hoc hardware availability, commonly force scientists into simultaneous use of multiple platforms (e. g. clusters, grids, and clouds used concurrently). A true computing jungle. In this chapter we explore the possibilities of enabling efficient and transparent use of Jungle Computing Systems in every-day scientific practice. To this end, we discuss the fundamental methodologies required for defining programming models that are tailored to {{the specific needs of}} scientific researchers. Importantly, we claim that many of these fundamental methodologies already exist today, as integrated in our Ibis high-performance distributed programming system. We also make a case for the urgent need for easy and efficient Jungle Computing in scientific practice, by exploring a set of state-of-the-art application domains. For one of these domains we present results obtained with Ibis on a real-world Jungle Computing System. The chapter concludes by exploring fundamental research questions to be investigated in the years to come...|$|E
40|$|AbstractTreatment {{planning}} for intensity modulated radiation therapy (IMRT) is challenging due {{to both the}} size of the computational problems (thousands of variables and constraints) and the multi-objective, imprecise nature of the goals. We apply <b>hierarchical</b> <b>programming</b> to IMRT treatment planning. In this formulation, treatment planning goals/objectives are ordered in an absolute hierarchy, and the problem is solved from the top-down such that more important goals are optimized in turn. After each objective is optimized, that objective function is converted into a constraint when optimizing lower-priority objectives. We also demonstrate the usefulness of a linear/quadratic formulation, including the use of mean-tail-dose (mean dose to the hottest fraction of a given structure), to facilitate computational efficiency. In contrast to the conventional use of dose-volume constraints (no more than x% volume of a structure should receive more than y dose), the mean-tail-dose formulation ensures convex feasibility spaces and convex objective functions. To widen the search space without seriously degrading higher priority goals, we allowed higher priority constraints to relax or ‘slip’ a clinically negligible amount during lower priority iterations. This method was developed and tuned for external beam prostate planning and subsequently tested using a suite of 10 patient datasets. In all cases, good dose distributions were generated without individual plan parameter adjustments. It was found that allowance for a small amount of ‘slip,’ especially in target dose homogeneity, often resulted in improved normal tissue dose burdens. Compared to the conventional IMRT treatment planning objective function formulation using a weighted linear sum of terms representing very different dosimetric goals, this method: (1) is completely automatic, requiring no user intervention, (2) ensures high-priority planning goals are not seriously degraded by lower-priority goals, and (3) ensures that lower priority, yet still important, normal tissue goals are separately pushed as far as possible without seriously impacting higher priority goals...|$|E
40|$|<b>Hierarchical</b> loyalty <b>programs</b> award {{elevated}} customer status (e. g., “elite membership”) {{to consumers}} who meet a predefined spending level. However, if a customer subsequently {{falls short of}} the required spending level, firms commonly revoke that status. The authors investigate the impact of such customer demotion on loyalty intentions toward the firm. Building on prospect theory and emotions theory, the authors hypothesize that changes in customer status have an asymmetric negative effect, such that {{the negative impact of}} customer demotion is stronger than the positive impact of status increases. An experimental scenario study provides evidence that loyalty intentions are indeed lower for demoted customers than for those who have never been awarded a preferred status, meaning that <b>hierarchical</b> loyalty <b>programs</b> can drive otherwise loyal customers away from a firm. A field study using proprietary sales data from a different industry context demonstrates the robustness of the negative impact of customer demotion. The authors test the extent to which design variables of <b>hierarchical</b> loyalty <b>programs</b> may attenuate the negative consequences of status demotions with a second experimental scenario study and present an analytical model that links status demotion to customer equity to aid managerial decision making...|$|R
5000|$|The {{plain text}} project {{description}} {{is written in}} a <b>hierarchical,</b> declarative <b>programming</b> language that requires one to think abstractly about the sequencing and constraints in the project, {{as well as the}} structure of the program itself. A typical project has the following sections: ...|$|R
40|$|Because of the {{possibility}} of floundering and infinite derivations, SLDNFresolution is, in general, not complete. The classical approach [17] to get a completeness result is to restrict the attention to normal programs P and normal goals G, such that P ∪ {G} is allowed and P is hierarchical. Unfortunately, the class of all normal programs and all normal goals meeting these requirements is not powerful enough to be of great practical importance. But after refining the concept of allowedness by taking modes [12] into account, we can broaden the notion of a <b>hierarchical</b> <b>program,</b> and thereby define a subclass of the class of normal programs and normal goals which is powerful enough to compute all primitive recursive functions without losing the completeness of SLDNF-resolution...|$|R
40|$|UnrestrictedWith recent {{technological}} advances, it {{has become}} possible to use reconfigurable hardware to accelerate scientific computing applications. There has been a resulting development of reconfigurable computers that have microprocessors, reconfigurable hardware, and high-performance interconnect. We address several aspects of accelerating scientific computing applications with reconfigurable hardware and reconfigurable computers.; Because there is no native support on reconfigurable hardware for the floating-point arithmetic needed by many scientific computing applications, we introduce a library of double-precision floating-point cores and analyze the effects on performance {{of the degree of}} pipelining and the implemented features of IEEE standard 754. Scientific computing applications may spend a large amount of time evaluating arithmetic expressions. Hence, we present area-efficient designs for arithmetic expression evaluation that hide the pipeline latencies of floating-point cores. These designs use at most two cores for each type of operator in the expression and have better area and throughput properties than designs generated by a state-of-the-art hardware compiler for FPGAs. Experiments show that for 64 - and 1024 -input expressions, area increases linearly with the number of types of operators.; Implementing a design on a reconfigurable computer can be difficult and is not guaranteed to give a speed-up. We thus formulate hierarchical architectural and performance models for reconfigurable computers that facilitate performance prediction early in the design process. The performance model has errors of 5 % to 13 % in our work in accelerating molecular dynamics. A <b>hierarchical</b> <b>programming</b> model for developing and modeling implementations of scientific computing applications on reconfigurable computers is also provided.; To demonstrate acceleration of a complete scientific computing application, we study molecular dynamics on reconfigurable computers. We investigate single-node, shifted-force simulations; single-node, particle-mesh-Ewald simulations; and multinode, shifted-force simulations. We attain 2 x to 3 x speed-ups over state-of-the-art microprocessors through a hardware/software approach in which the most intensive task executes on reconfigurable hardware {{and the rest of the}} tasks execute on the microprocessor. In the particle-mesh-Ewald simulation, we exploit parallelism between the microprocessor and the reconfigurable hardware. For the multi-node,shifted-force simulations, we show that a cluster of accelerated nodes has about the same performance as a cluster of twice as many unaccelerated nodes...|$|E
40|$|We explore in {{this paper}} the problem of {{generating}} <b>hierarchical</b> broadcast <b>programs</b> with the data access frequencies {{and the number of}} broadcast disks in a broadcast disk array given. Specifically, we first transform the problem of generating <b>hierarchical</b> broadcast <b>programs</b> into the one of constructing a channel allocation tree with variant-fanout. By exploiting the feature of tree generation with variantfanout, we develop a heuristic algorithm VF K to minimize the expected delay of data items in the broadcast program. Performance of these algorithms is analyzed. It is shown by our simulation results that by exploiting the feature of variant-fanout in constructing the channel allocation tree, the solution obtained by algorithm VF K is of very high quality and is in fact very close to the optimal one...|$|R
40|$|We analyse {{assignment}} {{problems in}} which not every agent {{is controlled by}} the central planner. The autonomous agents search for vacant tasks guided by their own preference orders defined over subsets of the available tasks. The goal of the central planner is to maximise the total value of the assignment, taking into account the behaviour of the uncontrolled agents. This setting can be found in numerous real-world situations, ranging from organisational economics to “crowdsourcing ” and disaster response. The problem faced by the central planner defines a mixed integer bilevel optimisation problem—a <b>hierarchical</b> <b>program</b> where the set of constraints contains a parametric optimisation problem, and which is generally hard to solve. We show that is can be reduced to a disjoint bilinear program, which is much more manageable computationally...|$|R
40|$|Safe state {{abstraction}} in {{reinforcement learning}} allows an agent to ignore aspects {{of its current}} state that are irrelevant to its current decision, and therefore speeds up dynamic programming and learning. This paper explores safe state abstraction in hierarchical reinforcement learning, where learned behaviors must conform to a given partial, <b>hierarchical</b> <b>program.</b> Unlike previous approaches to this problem, our methods yield significant state abstraction while maintaining hierarchical optimality, i. e., optimality among all policies consistent with the partial program. We show how to achieve this for a partial programming language that is essentially Lisp augmented with nondeterministic constructs. We demonstrate our methods on two variants of Dietterich's taxi domain, showing how state abstraction and hierarchical optimality result in faster learning of better policies and enable the transfer of learned skills from one problem to another...|$|R
50|$|SemmleCode {{builds on}} {{academic}} research on querying {{the source of}} software programs. The first such system was Linton's Omega system, where queries were phrased in QUEL. QUEL did not allow for recursion in queries, {{making it difficult to}} inspect <b>hierarchical</b> <b>program</b> structures such as the call graph. The next significant development was therefore the use of logic programming, which does allow such recursive queries, in the XL C++ Browser. The disadvantage of using a full logic programming language is however that {{it is very difficult to}} attain acceptable efficiency. The CodeQuest system, developed at the University of Oxford, was the first to exploit the observation that Datalog, a very restrictive version of logic programming, is in the sweet spot between expressive power and efficiency. The QL query language is an object-oriented version of Datalog.|$|R
40|$|AbstractAxon pathfinding {{relies on}} the ability of the growth cone to detect and {{interpret}} guidance cues and to modulate cytoskeletal changes in response to these signals. We report that the murine POU domain transcription factor Brn- 3. 2 regulates pathfinding in retinal ganglion cell (RGC) axons at multiple points along their pathways and the establishment of topographic order in the superior colliculus. Using representational difference analysis, we identified Brn- 3. 2 gene targets likely to act on axon guidance at the levels of transcription, cell–cell interaction, and signal transduction, including the actin-binding LIM domain protein abLIM. We present evidence that abLIM plays a crucial role in RGC axon pathfinding, sharing functional similarity with its C. elegans homolog, UNC- 115. Our findings provide insights into a Brn- 3. 2 -directed <b>hierarchical</b> <b>program</b> linking signaling events to cytoskeletal changes required for axon pathfinding...|$|R
