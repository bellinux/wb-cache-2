0|13|Public
5000|$|XDAIS or eXpressDsp Algorithm Interoperability Standard is a {{standard}} for algorithm development by Texas Instruments for the TMS320 DSP family. The standard was first introduced in 1999 and was created to facilitate integration of DSP algorithms into systems without <b>re-engineering</b> <b>cost.</b> The XDAIS standard address the issues of algorithm resource allocation and consumption on a DSP. Algorithms that comply with the standard are tested and awarded an [...] "eXpressDSP-compliant" [...] mark upon successful completion of the test ...|$|R
40|$|Recent {{advances}} in high performance computing architectures have presented a clear trend that future systems must include computers from different classes. It {{is conceivable that}} effective large scale computing in general must {{be done in a}} heterogenous distributed environment. The reported research seeks to build a generic virtual processor model on top of heterogeneous computing and communication devices. By using a specification based approach, we can effectively customize the available heterogeneous devices for every computer application. In this paper, we shall present the computational results of three field applications in scientific visualization, engineering simulation and financial simulation using a Scatter-And-Gather method (or virtual vector processing). To aid objective evaluation of the virtual processor model, we also include the program <b>re-engineering</b> <b>costs</b> for achieving such performances. Keywords: Distributed Heterogeneous Computing, Distributed Operating System. 1 [...] . ...|$|R
40|$|Corporations face {{mounting}} maintenance and <b>re-engineering</b> <b>costs</b> for large legacy systems. Evolving over several years, these systems embody substantial corporate knowledge, including requirements, design decisions, and business rules. Such knowledge is di cult to recover {{after many years}} of operation, evolution, and personnel change. To address this problem, software engineers are spending an ever-growing amount of e ort on program understanding and reverse engineering technologies. This article describes the scope and results of an on-going research project on program understanding undertaken by the IBM Software Solutions Toronto Laboratory Centre for Advanced Studies (CAS). The project involves, in addition to a team from CAS, ve research groups working cooperatively on complementary reverse engineering approaches. All groups are using the source code of SQL/DS (a multi-million line relational database system) as the reference legacy system. The article also discusses the approach adopted to integrate the various toolsets under a single reverse engineering environment...|$|R
40|$|This paper {{proposes a}} domain-oriented {{software}} process re-engineering method {{that allows for}} efficient software process modeling and cuts overall software development cost. This is achieved by use of a software synthesis shell that supports the development of program generators from input specification syntax and rewrite rules. Application of the proposed method {{to the development of}} a large scale "chain store management system" resulted in the development of a specification checker, two program generators, a specification document generator, and a test data generator. The overall development <b>cost,</b> including <b>re-engineering</b> <b>cost,</b> for this store management system has been reduced by 164 man-months. 1 Introduction Many software synthesis systems have been proposed in order to improve the productivity of software development, and some have succeeded in automating the programming phase [1] [8] as well as the design phase [3] [5] [6] by limiting the application domains. Although software s [...] ...|$|R
40|$|In a {{world where}} today’s {{technology}} is yesterday’s news, organisations will need empower their employees to be nimble and to become organisational change enablers {{in order to ensure}} the organisation has the ability to manage and adapt to the huge competitive pressures. These pressures are further exacerbated by the rapid evolution of technological advances and the rapid deconstruction of global boundaries. Continued process improvement projects, business process <b>re-engineering</b> and escalating <b>cost</b> reduction pressures are now the normal cognitive activities which occupy senior managers in their day-to-day routines...|$|R
40|$|There is an {{increasing}} request from the government to collect much revenue by way of taxes to face the increasing financial problems experienced by the country. So the department of Inland Revenue has to identify taxable activities which could not connect to as registered tax payers to collect additional tax. The registration process of new tax payers completely depends {{on the availability of}} tax-information. In such a situation the department has to have an enhanced tax-information collection system and an efficient way of handling tax-information. Many large governmental organizations that handle large collection of data seek to implement software systems to manage such data to gain cost benefits efficiency and accuracy, through input output process. Automation of Tax-Information Processing System does not require high equipment cost, but rather helps to ease the burden of over-staffing, high <b>re-engineering</b> <b>cost</b> confronted by among other government institutions. This project involves developing an automated tax-information system for the Department of Inland Revenue to monitor the information handling process and ensure its efficiency, quality and accuracy. This project report presents an approach to implement a user friendly interface with web-based system using an object oriented software approach. The need for such a system is satisfied by the waste of user's time, delay in the delivery of hand documents, mishandlings of data and improper maintenance of confidential of data seen in the manual system. Therefore, the main objective of this project is to deliver an alternative and cost effective solution for tax-information management process, using minimal resources within the available infrastructure. All new information will be stored on a Central Server which runs under windows platform. The automated system will distribute stored new tax-information to users in the branches in the Department. Then they will attend to manual processes on received data and they will upload the output of them to the system. The system will monitor the output and the progresses on the information distributed and send messages as necessity arises with the help of users in information monitoring branch called Information Branch. There is {{an increasing}} request from the government to collect much revenue by way of taxes to face the increasing financial problems experienced by the country. So the department of Inland Revenue has to identify taxable activities which could not connect to as registered tax payers to collect additional tax. The registration process of new tax payers completely depends on the availability of tax-information. In such a situation the department has to have an enhanced tax-information collection system and an efficient way of handling tax-information. Many large governmental organizations that handle large collection of data seek to implement software systems to manage such data to gain cost benefits efficiency and accuracy, through input output process. Automation of Tax-Information Processing System does not require high equipment cost, but rather helps to ease the burden of over-staffing, high <b>re-engineering</b> <b>cost</b> confronted by among other government institutions. This project involves developing an automated tax-information system for the Department of Inland Revenue to monitor the information handling process and ensure its efficiency, quality and accuracy. This project report presents an approach to implement a user friendly interface with web-based system using an object oriented software approach. The need for such a system is satisfied by the waste of user's time, delay in the delivery of hand documents, mishandlings of data and improper maintenance of confidential of data seen in the manual system. Therefore, the main objective of this project is to deliver an alternative and cost effective solution for tax-information management process, using minimal resources within the available infrastructure. All new information will be stored on a Central Server which runs under windows platform. The automated system will distribute stored new tax-information to users in the branches in the Department. Then they will attend to manual processes on received data and they will upload the output of them to the system. The system will monitor the output and the progresses on the information distributed and send messages as necessity arises with the help of users in information monitoring branch called Information Branch...|$|R
25|$|Although the C1 Corvette chassis and {{suspension}} design {{were derived}} from Chevrolet's full-size cars, the same basic design was continued through the 1962 model even after the full-size cars were completely redesigned for the 1955 model year. This {{was due to the}} combined factors of the relatively high <b>re-engineering</b> and re-tooling <b>costs</b> for this low-volume production vehicle, the continued potential for cancellation of the car, and the increased size and weight of the all-new suspension design for the full-size cars, which made it unsuitable for use in the lighter weight Corvette.|$|R
40|$|It {{is widely}} {{expected}} {{that a great}} deal of scholarly communication will move to an electronic format. This paper speculates about the impact this movement will have on the form of scholarly communication. In order to understand how journals might evolve, the paper begins {{with a look at the}} demand and supply for scholarly commutation today, as well as the first-copy costs of academic journals. Two other costs are then mentioned: archiving and yearly costs-per-article read. A discussion on re-engineering journal production and the impact of <b>re-engineering</b> on <b>costs</b> savings follows. Further savings of electronic distribution on shelf-space, monitoring, information searches, and supporting materials are then outlined. The paper concludes that when all academic publication is electronic: (1) publications will have much more general forms; (2) new filtering and refereeing mechanisms will be used; and (3) archiving and standardization will remain a problem. A model for electronic publishing is also presented. (Contains 12 references.) (AEF) Reproductions supplied by EDRS are the best that can be made from the original document...|$|R
40|$|Today, cloud {{computing}} – {{a result of}} combining existing technologies – is a popular paradigm that has brought many benefits for users and enterprises. Cloud computing fosters the provision and use of IT infrastructure, platforms, and applications of any kind {{in the form of}} services that are available on the Web. Expensive initial hardware and software investments are not necessary anymore as the resources can be acquired as a service from cloud providers with a pay-per-use pricing model. One aspect that cannot be overlooked in {{cloud computing}} is multi-tenancy. It is a property of a system where multiple customers, so-called tenants, transparently share the system's resources. It leverages economies of scale where users and cloud providers benefit from reduced costs, which is a result of higher system density and increased utilization rate of resources. This model surpasses the traditional methods of using single-tenant architecture and ASP model in which a single instance or server is provisioned solely for one customer. Customizability {{is an essential part of}} multi-tenant systems. Ideally cloud application vendors wish that every user would be satisfied with the standardized offering, but usually users have their own unique business needs. Customizability can be divided into configuration, which supports differentiation by pre-defined scope, and customization, which supports tenant's custom code. Software variations can be applied to user interface, business logic related workflows, underlying data and reporting utilities. Multi-tenancy shares a lot in common with software product line engineering. However, implementing multi-tenancy and supporting differentiation between tenants have to be carefully planned. Increased complexity may have an impact in maintenance <b>costs</b> and <b>re-engineering</b> <b>costs</b> can be significant. Goal of the thesis is to first examine the requirements for a multi-tenant application, and based on the research, to develop a prototype of a configuration management tool in order to solve the customization need produced by tenants' unique business requirements. The target environment consists of a new SaaS service called SignHero, which is a digital signature service suited for companies that want to shift their signing process to modern times. The scope includes three variability points: customizing the logo in the signing page, customizing the logo in the emails and saving a default workflow. The developed tool fulfills the requirements, and the main service was extended to apply the saved configurations. The implementation leaves many improvement possibilities related to customizability and cloud characteristics. Findings promote the fact that customizability has to be initially included in the product design...|$|R
40|$|Implementing {{effective}} {{cost management}} approaches has recently gained momentum due to intense competition and increasing customer demands. Moreover, effective cost management approaches {{have contributed to}} firms’ competitive advantage in relation to cost leadership strategy. Consequently, firms have implemented contemporary cost management systems, such as activity-based management, business process <b>re-engineering,</b> life-cycle <b>costing,</b> target costing, and theory of constraint (TOC), {{to enable them to}} become low-cost producers and compete effectively and sustain their performance. Furthermore, focusing on cost management to improve profitability has led to the integration of activity-based costing (ABC) and TOC. Therefore, the aim {{of this study is to}} review literature and discuss how integration of ABC and TOC can result in improved and sustained cost management. While these methods have different approaches in addressing cost management, treating them as complementary cost management approaches can result in improved cost management due to improved product costing, improved cost reporting, improved product-mix decisions, and improved cycle-time management. Improvement in cost management will then result in sustained cost management. Sustained cost management is further enhanced with the investment in information technology that supports cross-functional decision making to continue creating customer and shareholder value to remain competitive in the market...|$|R
40|$|This paper {{intends to}} present the {{opportunities}} emerging for the national economy, out of the financial crisis. In particular the management of those, which arise from the commercial real estate owned property sector, defined by the author as crisis heritage management. On one hand, as real estate property prices are subject of wide fluctuations, the longer possession of such assets can seriously impact the financial condition of the already shattered financial institutions, but on the on other - {{with the help of}} professional and proactive management, and the right kind of attitude by all the stakeholders, the heritage left out of the financial collapse, can not only help stabilize the system - bringing liquidity into it, but can also support its healthy corporate governance in the long-term. The properties themselves (business buildings, warehouses, retail-and-office spaces), being an object of optimization of maintenance <b>costs,</b> <b>re-engineering,</b> intensive marketing, {{as a result of the}} crisis, can serve as a solid base for number of new and profitable business and investment opportunities, described in the article, as a proof of the healing effect of the financial crisis and the second chance it gives. Comment: Presented at the 2013 Sofia Business School Master Classes in Global Risks Managemen...|$|R
40|$|Organizations in today’s {{business}} environment struggle {{on how to}} reduce operation cost in order to set prices that can be afforded by many customers while obtaining reasonable profit.   In order to reduce Operational Cost, service organizations have been working hard to identify techniques that facilitate business processes improvement for reduced Operational Cost. In so doing, the global literature indicates that service organizations adopt Business Process Re-engineering technique as a panacea of reducing Operational Cost. Despite a documented potentiality of Business Process Re-engineering technique, there are mixed empirical results, findings and conclusions regarding the effect of Business Process <b>Re-engineering</b> on Operational <b>Cost.</b> Therefore, this paper aimed at assessing and explaining effects of BPR on Operational Cost.   The study used cross-sectional survey design to investigate the effect of BPR on Operational Cost. Intensive literature review enabled the construction of structural measurement model, formulation of testable hypotheses and operationalization of constructs. In order to test the model and hypotheses, {{data were collected from}} ninety five (95) service organizations in Tanzania. Results of the study reveal that BPR and delivering speed have no direct effects on Operational Cost; they indirectly affect Operational Cost through the mediations of service quality. Therefore, BPR influences first both service quality and delivery speed in affecting Operational Cost of service organizations. It is now recommended that service organizations should use Business Process Re-engineering as panacea of reducing Operational Cost.    </p...|$|R

