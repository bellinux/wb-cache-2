6|50|Public
5000|$|... where Qr is {{the vector}} of queue {{backlogs}} {{at the beginning}} of frame r. In the special case when all frames are the same size and are normalized to 1 slot length, so that Tr = 1 for all r, the above minimization reduces to the standard drift-plus-penalty technique. This <b>frame-based</b> <b>method</b> can be used for constrained optimization of Markov decision problems (MDPs) and for other problems involving systems that experience renewals.|$|E
40|$|We present here {{progress}} on the Alvey MMI/ 134 project "Model based processing of radiological images". The radiological images {{we are dealing with}} are X-ray CT and NMR images of the head. Radiological interpretation of medical images obtained from any imaging modality, for example X-ray CT, relies on the fact that normal anatomy is predictable with respect to certain landmarks. The radiologist can then take into account variation between normal individuals and the effect of the imaging modality to create a flexible framework with fixed reference points to work from. We describe here a symbolic <b>frame-based</b> <b>method</b> of modelling 3 D anatomy which allows 2 D representations to be derived. This slice-wise representation is compatible with both the radiologist's view during interpretation an...|$|E
40|$|Abstract. Japanese {{relative}} clause constructions (RCC’s) {{are defined as}} being the NP’s of structure ‘S NP’, noting {{the lack of a}} relative pronoun or any other explicit form of noun-clause demarcation. Japanese {{relative clause}} modification should be classified into at least two major semantic types: case-slot gapping and head restrictive. However, these types for relative clause modification cannot apparently be distinguished. In this paper we propose a method of identifying a RCC’s type with a machine learning technique. The features used in our approach are not only rep-resenting RCC’s characteristics, but also automatically obtained from large corpora. The results we obtained from evaluation revealed that our method outperformed the traditional case <b>frame-based</b> <b>method,</b> and the features that we presented were effective in identifying RCC’s types. ...|$|E
40|$|In this paper, {{a method}} for the {{suppression}} of acoustic howling is developed, based on adaptive notch filters (ANF) with regularization (RANF). The method features three RANFs working in parallel to achieve frequency tracking, howling detection and suppression. The ANF-based approach to howling suppression introduces minimal processing delay and minimal complexity, in contrast to non-parametric <b>frame-based</b> <b>methods</b> featuring a non-parametric frequency analysis. Compared to existing ANF-based howling suppression methods, the proposed method allows for a more advanced howling detection such that tonal components in the source signal are not affected. The RANFs proposed in this paper are implemented in direct form and are updated using a gradient descent type algorithm. Results show that, under certain conditions, the level of suppression and sound quality are similar to what is obtained with <b>frame-based</b> <b>methods.</b> 1...|$|R
30|$|Various {{methods have}} been {{proposed}} {{to deal with the}} BGS problem, such as the statistical models: Gaussian mixture model (GMM) [3]. <b>Frame-based</b> <b>methods</b> consider spatial configurations as a significant cue for background modeling, such as eigen-background model [4]. In addition, a number of popular approaches have been developed that are not restricted to the above categories, such as artificial neural networks like self-organizing background subtraction (SOBS) [5] and local feature descriptors [2]. All of the abovementioned approaches and algorithms can be categorized as classic BGS methods that make overly restrictive assumptions on the background model.|$|R
40|$|AbstractFractal image {{compression}} {{is a relatively}} recent {{image compression}} method. Its extension to a sequence of motion images is important in video compression applications. There are two basic fractal compression methods, namely the cube-based and the <b>frame-based</b> <b>methods,</b> being commonly used in the industry. However there are advantages and disadvantages in both methods. This paper proposes a hybrid algorithm highlighting {{the advantages of the}} two methods in order to produce a good compression algorithm for video industry. Experimental results show the hybrid algorithm improves the compression ratio and the quality of decompressed images...|$|R
40|$|In this paper, {{we present}} a new {{approach}} to F 0 transformation, that can capture aspects of speaking style. Instead of using the traditional 5 ms frames as units in transformation, we propose a method that looks at longer phonological regions such as metrical feet. We automatically detect metrical feet in the source speech, and for each of source speaker’s feet, we find its phonological correspondence in target speech. We use a statistical phrase accent model to represent the F 0 contour, where a 4 -dimensional TILT representation is used for the F 0 is parameterized over each feet region for the source and target speakers. This forms the parallel data that is the training data for our transformation. We transform the phrase component using simple z-score mapping. We use a joint density Gaussian mixture model to transform the accent contours. Our transformation method generates F 0 contours that are significantly more correlated with the target speech than a baseline, <b>frame-based</b> <b>method...</b>|$|E
40|$|To {{improve the}} human-computer {{interaction}} (HCI) {{to be as}} good as human-human interaction, building an efficient approach for human emotion recognition is required. These emotions could be fused from several modalities such as facial expression, hand gesture, acoustic data, and biophysiological data. In this paper, we address the frame-based perception of the universal human facial expressions (happiness, surprise, anger, disgust, fear, and sadness), with the help of several geometrical features. Unlike many other geometry-based approaches, the <b>frame-based</b> <b>method</b> does not rely on prior knowledge of a person-specific neutral expression; this knowledge is gained through human intervention and not available in real scenarios. Additionally, we provide a method to investigate the performance of the geometry-based approaches under various facial point localization errors. From an evaluation on two public benchmark datasets, we have found that using eight facial points, we can achieve the state-of-the-art recognition rate. However, this state-of-the-art geometry-based approach exploits features derived from 68 facial points and requires prior knowledge of the person-specific neutral expression. The expression recognition rate using geometrical features is adversely affected by the errors in the facial point localization, especially for the expressions with subtle facial deformations...|$|E
3000|$|In general, the humming {{and music}} data are {{represented}} as magnitude values on a time axis. By using short time Fourier transform (STFT), the pitch (fundamental frequency) can be {{extracted from the}} humming and music data. Although the pitch value corresponds to musical notes (e.g., the pitch values 440 and 494 Hz represent the musical notes [...] "la" [...] and [...] "ti" [...] respectively [1]), there exist fluctuations in the pitch value caused by the errors in pitch extraction (tracking) due to background noise. To overcome these problems, the note-based method was introduced, where the pitch sequence is segmented into (musical) notes [2]. Since the notes have characteristics of discrete values (i.e., [...] "do", [...] "re", [...] "mi", etc.), the note-based method {{is similar to that}} representing continuous pitch values as quantized ones. Through representation as discrete values, fluctuation in the pitch value can be reduced, and the possibility of the existence of the same note in some period is increased. Thus, additional features such as the musical interval, duration, and tempo can be used in the note-based method [3 – 8]. However, inaccurate note segmentation from the pitch value can degrade the matching accuracy. Thus, the <b>frame-based</b> <b>method,</b> which uses the original pitch values as features, has also been studied [2, 9 – 12].|$|E
40|$|Effective and {{efficient}} representation of color features of multiple video frames or pictures is an im- portant yet challenging task for visual information management systems. Key <b>frame-based</b> <b>methods</b> {{to represent the}} color features {{of a group of}} frames (GoF) are highly dependent on the selection crite- rion of the representative frame(s), and may lead to unreliable results. In this paper, we present various histogram-based color descriptors to reliably capture and represent the color properties of multiple images or a GoF. One family of such descriptors, called alpha-trimmed average histograms, combine individual frame or image histograms using a specific filtering operation to generate robust color histograms that can eliminate the adverse effects of brightness/color variations, occlusion, and edit effects on the color representation. We show the efficacy of the alpha-trimmed average histograms for video segment retrieval applications, and illustrate how they consistently outperform key <b>frame-based</b> <b>methods.</b> Another color histogram descriptor that we introduce, called the intersection histogram, reflects the number of pixels of a given color that is common to all the frames in the GoF. We employ the intersection histogram to develop a fast {{and efficient}} algorithm for identification of the video segment to which a query frame belongs. The proposed color histogram descriptors have been included in the recently completed ISO standard MPEG- 7 after extensive evaluation experiments...|$|R
30|$|For {{matching}} methods, {{previous research}} on QBH was divided into bottom-up and top-down methods [13, 14]. In the bottom-up method [3 – 7, 9 – 11], the two waveforms of query humming and the target music file are locally compared. Based {{on the results of}} local matching, the optimal matching path is determined. In contrast, the global shapes of the two waveforms are compared in the top-down methods, and the local information of the waveform is also used to adjust the matching results of the global shape [2, 8, 12]. Based on this taxonomy (i.e., note-based and <b>frame-based</b> <b>methods,</b> bottom-up and top-down methods), previous studies can be classified as follows [13, 14].|$|R
40|$|For {{human action}} {{recognition}} methods, {{there is often}} a trade-off between classification accuracy and computa-tional efficiency. Methods that include 3 D information from multiple cameras are often computationally expensive and not suitable for real-time application. 2 D, <b>frame-based</b> <b>methods</b> are generally more efficient, but suffer from lower recognition accuracies. In this paper, we present a hybrid keypose-based method that operates in a multi-camera en-vironment, but uses only a single camera at a time. We learn, for each keypose, the relative utility of a particular viewpoint compared with switching to a different available camera in the network for future classification. On a bench-mark multi-camera action recognition dataset, our method outperforms approaches that incorporate all available cam-eras. 1...|$|R
40|$|AbstractFractal image {{compression}} {{is a relatively}} recent {{image compression}} method, which is simple to use and often leads to a high compression ratio. These advantages make it suitable for the situation of a single encoding and many decoding, as required in video on demand, archive compression, etc. There are two fundamental fractal compression methods, namely, the cube-based and the <b>frame-based</b> <b>methods,</b> being commonly studied. However, there are advantages and disadvantages in both methods. This paper gives {{an extension of the}} fundamental compression methods based on the concept of adaptive partition. Experimental results show that the algorithms based on adaptive partition may obtain a much higher compression ratio compared to algorithms based on fixed partition while maintaining the quality of decompressed images...|$|R
40|$|In {{this paper}} we {{describe}} our recent {{efforts to improve}} acousticphonetic modeling by developing sets of heterogeneous, phoneclass -specific measurements, and combining these diverse measurements into a probabilistic classification framework. We first describe a baseline classifier using homogeneous measurements. After comparing selected sub-tasks to known human performance, we define sets of phone-class-specific measurements which improve within-class classification performance. Subsequently, we combine these heterogeneous measurements into an overall context-independent classification framework. We report {{on a series of}} phonetic classification experiments using the TIMIT acoustic-phonetic corpus. Our overall framework achieves 79. 0 % accuracy on the NIST core test set. 1. INTRODUCTION Over the past several years, our group has pursued a segmentbased approach to speech recognition. One of the potential advantages of this approach over conventional <b>frame-based</b> <b>methods</b> is that it provides [...] ...|$|R
40|$|This paper {{investigates the}} use of Deep Bidirectional Long Short-Term Memory based Recurrent Neural Networks (DBLSTM-RNNs) for voice conversion. Temporal {{correlations}} across speech frames are not directly modeled in <b>frame-based</b> <b>methods</b> using conventional Deep Neural Networks (DNNs), which results in a limited quality of the converted speech. To improve the naturalness and continuity of the speech output in voice conversion, we propose a sequence-based conversion method using DBLSTM-RNNs to model not only the frame-wised relationship between the source and the target voice, but also the long-range context-dependencies in the acoustic trajectory. Experiments show that DBLSTM-RNNs outperform DNNs where Mean Opinion Scores are 3. 2 and 2. 3 respectively. Also, DBLSTM-RNNs without dynamic features have better performance than DNNs with dynamic features. Index Terms — voice conversion, bidirectional long short-term memory, recurrent neural networks, dynamic features 1...|$|R
40|$|Introduction: CT-guided, {{frameless}} radiosurgery (SRS) is {{an alternative}} treatment to traditional catheter-angiography targeted, <b>frame-based</b> <b>methods</b> for intracranial arteriovenous malformations (AVMs). Despite {{the widespread use of}} frameless radiosurgery for treating intracranial tumors, its use for treating AVM is not well described. Methods: Patients who completed a course of single fraction SRS at The University of North Carolina or Georgetown University between 4 / 1 / 2005 – 4 / 1 / 2011 with single fraction SRS and received at least one follow-up imaging study were included. All patients received pre-treatment planning with CTA ± MRA and were treated on the CyberKnife (Accuray) radiosurgery system. Patients were evaluated for changes in clinical symptoms and radiographic changes evaluated with MRI/MRA and catheter-angiography. Results: 26 patients, 15 male and 11 female, were included in the present study at a median age of 41 years (IQR, 26 - 55 years). The Spetzler Martin grades of the AVMs included seven Grade I, twelve Grade II, six Grade III, and one Grade IV with fourteen (54 %) of the patients having a pre-treatment hemorrhage. Median AVM nidal volume was 1. 62 cm 3 (IQR, 0. 57 - 8. 26 cm 3) and was treated with a median of 1900 cGy to the 80 % isodose line. At median follow-up of 25 months (IQR, 19 - 36 months), 15 patients had a complete closure of their AVM, 6 patients had a partial closure, and 5 patients were stable. Time since treatment {{was a significant predictor of}} response, with patients experience complete closure having on average 11 months more follow-up than patients with partial or no closure (p = 0. 03). One patient experienced a post-treatment hemorrage at 22 months. Conclusions: Frameless SRS can be targeted with non-invasive MRI/MRA and CTA imaging. Despite the difficulty of treating AVM without catheter angiography, early results with frameless, CT-guided SRS suggest that it can achieve similar results to <b>frame-based</b> <b>methods</b> at these time points...|$|R
40|$|In {{this paper}} the signal {{subspace}} approach for nonparametric speech enhancement is considered. Traditionally, the SVD (or the eigendecomposition) {{is used in}} <b>frame-based</b> <b>methods</b> to decompose the vector space of the noisy signal into a signal- and noise subspace [1, 2, 5]. Linear estimation of the clean signal from {{the information in the}} signal subspace is then performed using a set of nonparametric estimation criteria. In this paper, the rank-revealing ULV decomposition is used instead of the SVD, and we use recursive updating of the estimate instead of working in frames. An ULV formulation of three different estimation strategies is considered: Least Squares, Minimum Variance and Time Domain Constrained. Experiments indicate that the ULV-based algorithm is able to achieve the same quality of the reconstructed speech signal as the SVD-based method. 1 SIGNAL AND NOISE MODEL Let x = (x 1; x 2; ΔΔΔ; xm) T denote the noisy signal vector of m samples and assume that [...] ...|$|R
40|$|We {{address the}} problem of object {{recognition}} in egocen-tric videos, where a user arbitrarily moves a mobile cam-era around an unknown object. Using a video that cap-tures variation in an object’s appearance owing to cam-era motion (more viewpoints, scales, clutter and lighting conditions), can accumulate evidence and improve object recognition accuracy. Most previous work has taken a sin-gle image as input, or tackled a video simply by a collec-tion i. e. sum of frame-based recognition scores. In this pa-per, beyond frame-based recognition, we propose two novel set-of-sets representations of a video sequence for object recognition. We combine the techniques of bag of words for a set of data spatially distributed thus heterogeneous, and manifold for a set of data temporally smooth and homoge-neous, to construct the two proposed set-of-sets representa-tions. We also propose methods to perform matching for the two representations respectively. The representations and matching techniques are evaluated on our video-based ob-ject recognition datasets, which contain 830 videos of ten objects and four environmental variations. The experiments on the challenging new datasets show that our proposed so-lution significantly outperforms the traditional <b>frame-based</b> <b>methods.</b> 1...|$|R
40|$|This book gives a {{short but}} {{comprehensive}} {{overview of the}} field of spoken dialogue systems, outlining the issues involved in building and evaluating this type of system and making liberal use of techniques and examples {{from a wide range of}} implemented systems. It provides an excellent review of the research, with particularly relevant discussions of error handling and system evaluation, and is suitable both as an introduction to this research area and as a survey of current state-of-the-art techniques. The book is structured into seven chapters. Chapter 1 provides an introduction to the research area and briefly introduces the topics covered in the book. The end of the chapter consists of a list of links to tools and components that can be used for dialogue system development, which—although currently useful—seems likely to go out of date quickly. Chapter 2 addresses the task of dialogue management, beginning by describing simple graph- and <b>frame-based</b> <b>methods</b> for dialogue control, and continuing with a discussion of VoiceXML. The chapter ends with an extended discussion of recent work in statistical approaches to dialogue control and modeling. It is unfortunate that th...|$|R
40|$|BACKGROUND: Stereoelectroencephalography (SEEG) is an {{invasive}} diagnostic pro-cedure in epilepsy {{surgery that}} is usually implemented with <b>frame-based</b> <b>methods.</b> OBJECTIVE: To describe a new technique of frameless SEEG and report a prospective case series at a single center. METHODS: Image integration and planning of electrode trajectories were performed preoperatively on specialized software and exported to a Medtronic S 7 StealthStation. Trajectories were implemented by frameless stereotaxy using percutaneous drilling and bolt insertion. RESULTS: Twenty-two patients went this technique, with the insertion of 187 intra-cerebral electrodes. Of 187 electrodes, 175 accurately reached their neurophysiological target, as measured by postoperative computed tomography reconstruction and multimodal image integration with preoperative magnetic resonance imaging. Four electrodes failed to hit their target due to extradural deflection, and 3 were sub-sequently resited satisfactorily. Eight electrodes were off target by a mean of 3. 6 mm (range, 0. 9 - 6. 8 mm) due {{to a combination of}} errors in bolt trajectory implementation and bending of the electrode. There was 1 postoperative hemorrhage that was clinically asymptomatic and no postoperative infections. Sixteen patients were offered definitive cortical resections, and 6 patients were excluded from resective surgery. CONCLUSION: Frameless SEEG is a novel and safe method for implementing SEEG and is easily translated into clinical practice...|$|R
40|$|Though high {{redundancy}} rate of a tight frame {{can improve}} performance in applications, as the dimension increases, {{it also makes}} the computational cost skyrocket and the storage of frame coefficients increase exponentially. This seriously restricts the usefulness of such tight frames for problems in moderately high dimensions such as video processing in dimension three. Inspired by the directional tensor product complex tight framelets TP-CTF_m with m> 3 in [14, 18] and their impressive performance for image processing in [18, 30] {{in this paper we}} introduce a directional tensor product complex tight framelet TP-CTF^!_ 6 (called reduced TP-CTF_ 6) with low redundancy. Such TP-CTF_ 6 ^! is a particular example of tight framelet filter banks with mixed sampling factors. The TP-CTF^!_ 6 in d dimensions not only offers good directionality but also has the low redundancy rate 3 ^d- 1 / 2 ^d- 1 (e. g., the redundancy rates are 2, 22 / 3, 35 / 7, 51 / 3 and 725 / 31 for dimension d= 1, [...] ., 5, respectively). Moreover, our numerical experiments on image/video denoising and inpainting show that the performance using our proposed TP-CTF^!_ 6 is often comparable or sometimes better than several state-of-the-art <b>frame-based</b> <b>methods</b> which have much higher redundancy rates than that of TPCTF^!_ 6...|$|R
40|$|In this paper, {{we propose}} a novel Bayesian {{approach}} to modelling temporal transitions of facial expressions represented in a manifold, {{with the aim}} of dynamical facial expression recognition in image sequences. A generalised expression manifold is derived by embedding image data into a low dimensional subspace using Supervised Locality Preserving Projections. A Bayesian temporal model is formulated to capture the dynamic facial expression transition in the manifold. Our experimental results demonstrate the advantages gained from exploiting explicitly temporal information in expression image sequences resulting in both superior recognition rates and improved robustness against static <b>frame-based</b> recognition <b>methods.</b> ...|$|R
40|$|International audienceThis paper {{proposes a}} {{definition}} for articulatory {{as well as}} acoustic gestures along with a method to segment the measured articulatory trajectories and the acoustic waveform into gestures. Using an simultaneously recorded acoustic-articulatory database, the gestures are detected based on finding critical points in the utterance both in the acoustic and articulatory representations. The acoustic gestures are parameterized using 2 -D cepstral coefficients. The articulatory trajectories are essentially the horizontal and vertical movements of Electromagnetic Articulagraphy (EMA) coils placed on the tongue, jaw and lips along the midsagittal plane. The articulatory movements are parameterized using 2 D-DCT using the same transformation that is applied on the acoustics. The relationship between the detected acoustic and articulatory gestures {{in terms of the}} timing as well as the shape is studied. Acoustic-to-articulatory inversion is also performed using a GMM-based regression, in order to study this relationship further. The accuracy of predicting of the articulatory trajectories from the acoustic waveform are at par with state-of-the-art <b>frame-based</b> <b>methods</b> with dynamical constraints (with an average error of 1. 45 - 1. 55 mm for the two speakers in the database). In order to evaluate the acoustic-to-articulatory inversion in a more intuitive manner, a method based on the error in estimated critical points is suggested. Using this method, it was noted that the estimated articulatory trajectories using the acoustic-to-articulatory inversion methods were still not accurate enough to be within the perceptual tolerance of audio-visual asynchrony...|$|R
40|$|In {{this study}} we compare nine optical flow {{algorithms}} that locally measure the flow normal to edges according to accuracy and computation cost. In contrast to conventional, frame-based motion flow algorithms, our open-source implementations compute optical flow based on address-events from a neuromorphic Dynamic Vision Sensor (DVS). For this benchmarking we created a dataset of two synthesized and three real samples recorded from a 240 x 180 pixel Dynamic and Active-pixel Vision Sensor (DAVIS). This dataset contains events from the DVS as well as conventional frames to support testing state-of-the-art <b>frame-based</b> <b>methods.</b> We introduce a new source for the ground truth: In the special case that the perceived motion stems solely from a rotation of the vision sensor around its three camera axes, the true optical flow can be estimated using gyro data from the inertial measurement unit integrated with the DAVIS camera. This provides a ground-truth to which we can compare algorithms that measure optical flow by means of motion cues. An analysis of error sources led {{to the use of}} a refractory period, more accurate numerical derivatives and a Savitzky-Golay filter to achieve significant improvements in accuracy. Our pure Java implementations of two recently published algorithms reduce computational cost by up to 29 % compared to the original implementations. Two of the algorithms introduced in this paper further speed up processing by a factor of 10 compared with the original implementations, at equal or better accuracy. On a desktop PC, they run in real-time on dense natural input recorded by a DAVIS camera. In {{this study we}} compare nine optical flow algorithms that locally measure the flow normal to edges according to accuracy and computation cost. In contrast to conventional, frame-based motion flow algorithms, our open-source implementations compute optical flow based on address-events from a neuromorphic Dynamic Vision Sensor (DVS). For this benchmarking we created a dataset of two synthesized and three real samples recorded from a 240 x 180 pixel Dynamic and Active-pixel Vision Sensor (DAVIS). This dataset contains events from the DVS as well as conventional frames to support testing state-of-the-art <b>frame-based</b> <b>methods.</b> We introduce a new source for the ground truth: In the special case that the perceived motion stems solely from a rotation of the vision sensor around its three camera axes, the true optical flow can be estimated using gyro data from the inertial measurement unit integrated with the DAVIS camera. This provides a ground-truth to which we can compare algorithms that measure optical flow by means of motion cues. An analysis of error sources led to the use of a refractory period, more accurate numerical derivatives and a Savitzky-Golay filter to achieve significant improvements in accuracy. Our pure Java implementations of two recently published algorithms reduce computational cost by up to 29 % compared to the original implementations. Two of the algorithms introduced in this paper further speed up processing by a factor of 10 compared with the original implementations, at equal or better accuracy. On a desktop PC, they run in real-time on dense natural input recorded by a DAVIS camera...|$|R
40|$|Abstract — This letter {{considers}} the multicast scheduling {{problem for the}} case where the average rates of flows are known and a fixed frame size is applicable. We present a <b>frame-based</b> decomposition <b>method</b> for computing offline a recurring schedule that can guarantee the specified flow rates with minimum internal speedup, if any. We consider both the no-splitting case, where a multicast cell must be transferred to all its destinations in a single time slot, and the fanout-splitting case, where a multicast cell may take multiple time slots to transfer to all its destinations, transferring only to a subset of its destinations each time. I...|$|R
40|$|This {{extended}} abstract describes my {{submission to}} the QBSH (Query by Singing/Humming) task of MIREX (Music Information Retrieval Evaluation eXchange) 2008. The system {{takes advantage of}} note-based and <b>frame-based</b> matching <b>methods</b> to improve {{the accuracy of the}} Query by Singing/Humming system. First, Earth Mover’s Distance (EMD), which is note-based and much faster, is adopted to eliminate most unlikely candidates. Then, Dynamic Time Warping (DTW), which is frame-based and more accurate, is executed on these surviving candidates. Finally, a weighted voting fusion strategy is employed to fusion the result of the two similarity measurement, the final decision is the one with highest scores. KeyWords—Query by Humming/Singing System...|$|R
40|$|Three PRP-type direct search {{methods for}} {{unconstrained}} optimization are presented. The methods adopt {{three kinds of}} recently developed descent conjugate gradient methods {{and the idea of}} <b>frame-based</b> direct search <b>method.</b> Global convergence is shown for continuously differentiable functions. Data profile and performance profile are adopted to analyze the numerical experiments and the results show that the proposed methods are effective...|$|R
40|$|Abstract—This letter {{considers}} the multicast scheduling {{problem for the}} case where the average rates of flows are known and a fixed frame size is applicable. We present a <b>frame-based</b> decomposition <b>method</b> for computing offline a recurring schedule that can guarantee the specified flow rates with minimum internal speedup, if any. We consider both the no-splitting case, where a multicast cell must be transferred to all its destinations in a single time slot, and the fanout-splitting case, where a multicast cell may take multiple time slots to transfer to all its destinations, transferring only to a subset of its destinations each time. Index Terms—Multicast switching, high-performance switches, rate guarantees. Recently, Sundararajan et al. [4] extended the BvN decomposition approach to support multicast switching. This method retains the generality of the BvN approach in that it can support any flow rates specified as non-negative real numbers, but it also inherits the worst-case online memory requirement of the BvN approach {{and the need for}} online scheduling using PGPS. Our work is complementary in that it provides a simpler solution in cases where integer flow rates and a fixed frame size apply. To our knowledge, previous <b>frame-based</b> offline scheduling <b>methods</b> did not consider multicast switching. I...|$|R
40|$|A pitch detection/tracking {{strategy}} for solo bowed-string and wind musical instru-mental recordings is presented. To avoid the missing fundamental problem, we adopted the {{greatest common divisor}} method and modified it with a weighted-and-voting tech-nique that can reveal more information of strong partials in the target signal. Moreover, a <b>frame-based</b> correction <b>method</b> with consideration of the performing aspects of the in-struments is also proposed to emendate possible misjudgments in the transition from one note to the next note. Experimental {{results showed that the}} proposed strategy is superior to three popular methods for a pitch extraction/tracking task. The proposed method was also tested when the sound source is reverberant and the results were compared with oth-er methods, too...|$|R
40|$|<b>Frame-based</b> regularization <b>method</b> as {{one kind}} of {{sparsity}} representation method has been developed {{in recent years and}} has been proved to be an efficient method for CT image reconstruction. However, most of the developed CT image reconstruction methods are analysis-based frame methods. This paper proposes a novel frame-based balanced hybrid model with two sparse regularization terms for CT image reconstruction. We generalize the fast alternating direction method to solve the proposed model so that every subproblem can be easily solved. The numerical experiments suggest that the proposed hybrid balanced-based wavelet regularization scheme is efficient in terms of reducing the defined reconstruction root mean squared error and improving the signal to noise ratio in CT image reconstruction...|$|R
40|$|The {{design of}} {{advanced}} manufacturing systems entails a high {{flexibility in the}} system specification method, to allow for flexibility and efficiency in coping with the frequent design modifications. Object-oriented specification methods possess the necessary expressiveness and extensibility to allow for such flexibility. In order to obtain a declarative representation of the knowledge of objects, the semantic data model of the <b>frame-based</b> representation <b>method</b> is incorporated. This extended object-oriented model {{can be used for}} specifying system behaviors. Within this model, generic object types representing general concepts in manufacturing systems are identified. These generic object types can facilitate the specification of manufacturing systems by means of an object-oriented approach. The application of the model for system specification is illustrated with reference to a typical robotic FMC. link_to_subscribed_fulltex...|$|R
40|$|Abstract—A layered {{video object}} coding system is {{presented}} in this paper. The goal is to improve video coding efficiency by exploiting the layering of video and to support content-based functionality. These two objectives are accomplished using a sprite technique and an affine motion model on a per-object basis. Several novel algorithms {{have been developed for}} mask process-ing and coding, trajectory coding, sprite accretion and coding, locally affine motion compensation, error signal suppression, and image padding. Compared with conventional <b>frame-based</b> coding <b>methods,</b> better experimental results on both hybrid and natural scenes have been obtained using our coding scheme. We also demonstrate content-based functionality which can be easily achieved in our system. Index Terms — Affine motion model, image padding, layered video object coding, MPEG- 4, scalability, shape coding, sprite coding. I...|$|R
30|$|The last {{category}} involves <b>frame-based</b> and top-down <b>methods</b> [2, 12] {{as follows}} [13, 14]. Since linear scaling (LS) based matching cannot {{solve the problem}} of nonlinear alignment between the input humming and stored music data, the recursive alignment (RA) algorithm has been proposed [2] to solve the problem by attempting local matching recursively. Ryynanen et al. extracted the pitch vectors using a time window of fixed length and used the locality sensitive hashing (LSH) method for matching [12].|$|R
40|$|Abstract. According to the {{characteristics}} of AVS video data, a RTP encapsulation method based on frame type is proposed. When the video data is encapsulated by the RTP protocol, different types of video data such as sequence header, sequence end, I frame, P frame and B frame are encapsulated with different method. Under the limit of maximum transmission unit (MTU), sequence headers, sequence ends and I frames are encapsulated individually to reduce the packet length and protect the important data. While multiple P frames and B frames are encapsulated into one RTP packet to reduce the quantity of the RTP packets and decrease the overload of link. Simulation results show that, compared to the <b>frame-based</b> encapsulation <b>method,</b> the proposed method can reduce the packet loss rate of the video data effectively and {{improve the quality of}} video service...|$|R
40|$|International audienceWe {{present a}} new type of {{deformable}} model which combines the realism of physically based continuum mechanics models and the usability of <b>frame-based</b> skinning <b>methods,</b> allowing the interactive simulation of objects with heterogeneous material properties and complex geometries. The degrees of freedom are coordinate frames. In contrast with traditional skinning, frame positions are not scripted but move in reaction to internal body forces. The deformation gradient and its deriv- atives are computed at each sample point of a deformed object and used in the equations of Lagrangian mechanics to achieve physical realism. We introduce novel material-aware shape functions in place of the traditional radial basis functions used in meshless frameworks, allowing coarse deformation functions to efficiently resolve non-uniform stiffnesses. Complex models can thus be simulated at high frame rates using a small number of control nodes...|$|R
40|$|A natural {{language}} query interface for databases provides the user friendliness in retrieving the desired information by querying in a native {{natural language}}. Up to now, many natural language query interfaces for conventional databases have been developed. However, {{the field of}} natural language query interfaces for object-oriented databases which have recently started to emerge as the next-generation databases has become a new research area. This paper describes a processing technique to manipulate natural language representations of path expressions. From {{the fact that the}} path expression {{is one of the key}} features in the object-oriented data model, a <b>frame-based</b> decomposition <b>method</b> is proposed for efficient processing. 1 Introduction The objective of natural language interfaces is to take inputs in human language and extract from them something which is meaningful to a computer. A natural language query interface to a database system provides end users with a way to formulate que [...] ...|$|R
