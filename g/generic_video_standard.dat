0|3020|Public
40|$|This {{tutorial}} {{will present}} {{and discuss the}} main recent advances in standardized video coding technology, as being developed collaboratively by members of both the ITU-T VCEG and ISO/IEC MPEG organizations during the standardization of the new H. 264 /MPEG- 4 Advanced <b>Video</b> Coding (AVC) <b>standard.</b> Being designed as a <b>generic</b> <b>video</b> coding <b>standard</b> for {{a broad range of}} applications, H. 264 /MPEG- 4 AVC has already received an overwhelming amount of attention from industry. Application areas are ranging from videoconferencing over mobile TV and broadcasting of standard-/high-definition TV content up to very high-quality video applications such as professional digital video recording or digital cinema / large-screen digital imagery. The first part of the tutorial is devoted to the core technology of the H. 264 /MPEG- 4 AVC video coding layer, as specified in the 2003 version of the standard. We will focus on the key innovations such as given by enhanced motion-compensated prediction c apabilities, low-complexity integer transforms, content-adaptive in-loop deblocking filter, and enhanced entropy coding methods. We will then highlight the technical features of the so-called Fidelity Range Extensions (FRExt) of H. 264 /MPEG- 4 AVC addressing the specific needs of rapidly growing higher-fidelity video applications. Finally, we will provide an understanding of the basic concepts of the Scalable Video Coding (SVC) extensions, as the most recent and presently ongoing work for extending the capabilities of H. 264 /MPEG- 4 AVC. We will show how the present design of those SVC extensions supports the functionalities of spatial scalability, SNR scalability, and temporal scalability as well as their combinations in a maximally-consistent fashion relative to the current syntax and decoding process of H. 264 /MPEG- 4 AVC. This tutorial is intended for researchers, students and engineers who are interested in gaining an understanding of the recent advances in standardized video coding technology. Copy...|$|R
40|$|An {{overview}} of existing and upcoming 3 D <b>video</b> coding <b>standards</b> is given. Various different 3 D video formats are available, each with individual pros and cons. The 3 D video formats can be separated into two classes: video-only formats (such as stereo and multiview video) and depth-enhanced formats (such as video plus depth and multiview video plus depth). Since all these formats exist {{of at least}} two video sequences and possibly additional depth data, efficient compression is essential for the success of 3 D video applications and technologies. For the video-only formats the H. 264 family of coding standards already provides efficient and widely established compression algorithms: H. 264 /AVC simulcast, H. 264 /AVC stereo SEI message, and H. 264 /MVC. For the depth-enhanced formats standardized coding algorithms are currently being developed. New and specially adapted coding approaches are necessary, as the depth or disparity information included in these formats has significant ly different characteristics than video and is not displayed directly, but used for rendering. Motivated by evolving market needs, MPEG has started an activity to develop a <b>generic</b> 3 D <b>video</b> <b>standard</b> within the 3 DVC ad-hoc group. Key features of the standard are efficient and flexible compression of depth-enhanced 3 D video representations and decoupling of content creation and display requirements...|$|R
5000|$|Quick {{and simple}} utility to convert a <b>generic</b> <b>video</b> (avi, mpeg, mov, wmv, asf) to Xvid AVI ...|$|R
40|$|Video {{summarization}} enables {{convenient and}} efficient management of {{large volume of}} visual data. However, most existing summarization approaches are based on either the pixel domain information or conventional <b>video</b> compression <b>standards.</b> As the most recent and popular international <b>video</b> coding <b>standard,</b> H. 264 /AVC adopts a number of advanced techniques and brings not only opportunities but also challenges to video summarization. In this paper, we propose a real-time image storyboard generation algorithm for H. 264 /AVC compressed videos by using both compressed domain and pixel domain information jointly and adaptively. This algorithm extracts compressed domain information for visual content representation, video structuring and candidate representative frame selection. By fusing both compressed domain and pixel domain information, the redundancy in the candidate representative frames is further reduced. Our experimental {{results show that the}} proposed algorithm can efficiently produce image storyboards conforming to human interpretation of the essential content in <b>generic</b> <b>videos.</b> Department of Electronic and Information EngineeringRefereed conference pape...|$|R
50|$|<b>Video</b> <b>standards</b> {{converter}} is used so TV shows can {{be viewed}} in nations with different <b>video</b> <b>standards.</b>|$|R
40|$|We {{investigate}} the challenging issue of joint audio-visual analysis of <b>generic</b> <b>videos</b> targeting at concept detection. We extract a novel local representation, Audio-Visual Atom (AVA), which {{is defined as}} a region track associated with regional visual features and audio onset features. We develop a hierarchical algorithm to extract visual atoms from <b>generic</b> <b>videos,</b> and locate energy onsets from the corresponding soundtrack by time-frequency analysis. Audio atoms are extracted around energy onsets. Visual and audio atoms form AVAs, based on which discriminative audio-visual codebooks are constructed for concept detection. Experiments over Kodak’s consumer benchmark videos confirm the effectiveness of our approach...|$|R
50|$|Songs {{often include}} music videos when played, {{although}} only some songs contain dedicated videos. Some songs contain <b>generic</b> <b>videos</b> shared by multiple songs, {{and some of}} these have additional animated graphics overlaid atop them.|$|R
40|$|We {{introduce}} the challenge problem for <b>generic</b> <b>video</b> indexing to gain insight in intermediate steps that affect performance of multimedia analysis methods, {{while at the}} same time fostering repeatability of experiments. To arrive at a challenge problem, we provide a general scheme for the systematic examination of automated concept detection methods, by decomposing the <b>generic</b> <b>video</b> indexing problem into 2 unimodal analysis experiments, 2 multimodal analysis experiments, and 1 combined analysis experiment. For each experiment, we evaluate <b>generic</b> <b>video</b> indexing performance on 85 hours of international broadcast news data, from the TRECVID 2005 / 2006 benchmark, using a lexicon of 101 semantic concepts. By establishing a minimum performance on each experiment, the challenge problem allows for component-based optimization of the generic indexing issue, while simultaneously offering other researchers a reference for comparison during indexing methodology development. To stimulate further investigations in intermediate analysis steps that influence video indexing performance, the challenge offers to the research community a manually annotated concept lexicon, pre-computed low-level multimedia features, trained classifier models, and five experiments together with baseline performance, which are all available a...|$|R
50|$|Coding tree unit (CTU) is {{the basic}} {{processing}} unit of the High Efficiency Video Coding (HEVC) <b>video</b> <b>standard</b> and conceptually corresponds in structure to macroblock units {{that were used in}} several previous <b>video</b> <b>standards.</b> CTU is also referred to as largest coding unit (LCU).|$|R
50|$|The {{exact nature}} of the color frame {{sequence}} depends on the <b>video</b> <b>standard</b> being used. In {{the case of the}} three main composite <b>video</b> <b>standards,</b> PAL <b>video</b> has an 8-field (4 frame) color frame sequence, and NTSC and SECAM both have 4-field (2 frame) color frame sequences.|$|R
50|$|In {{countries}} {{that use the}} PAL or SECAM <b>video</b> <b>standards,</b> film destined for television is photographed at 25 frames per second. The PAL <b>video</b> <b>standard</b> broadcasts at 25 frames per second, so the transfer from film to video is simple; for every film frame, one video frame is captured.|$|R
50|$|The per-second {{frame rate}} of the PAL <b>video</b> <b>standard.</b>|$|R
5000|$|HD-MAC, {{a planned}} high-definition analog <b>video</b> <b>standard</b> in Europe ...|$|R
5000|$|STANAG 3350: Analogue <b>Video</b> <b>Standard</b> for Aircraft System Applications ...|$|R
5000|$|... #Subtitle level 2: Extensions to the {{composite}} <b>video</b> <b>standard</b> ...|$|R
5000|$|Configuration wizards are {{provided}} to automatically configure the web server to perform specific tasks, or run frameworks and applications. These provide support for: PHP through FastCGI, Ruby on Rails, ColdFusion, GlassFish, Django, Alfresco, GNU Mailman, [...]NET with Mono, rTorrent, Symfony, and Zend Engine, plus <b>generic</b> <b>Video</b> Streaming and uWSGI.|$|R
5000|$|RGBI output (RGB plus Intensity) {{compatible}} with IBM's CGA <b>video</b> <b>standard.</b>|$|R
500|$|HDMI {{uses the}} Consumer Electronics Association/Electronic Industries Alliance 861 standards. HDMI 1.0 to HDMI 1.2a uses the EIA/CEA-861-B <b>video</b> <b>standard,</b> HDMI 1.3 uses the CEA-861-D <b>video</b> <b>standard,</b> and HDMI 1.4 uses the CEA-861-E <b>video</b> <b>standard.</b> The CEA-861-E {{document}} defines [...] "video formats and waveforms; colorimetry and quantization; transport of compressed and uncompressed, {{as well as}} Linear Pulse Code Modulation (LPCM), audio; carriage of auxiliary data; and implementations of the <b>Video</b> Electronics <b>Standards</b> Association (VESA) Enhanced Extended Display Identification Data Standard (E-EDID)". [...] On July 15, 2013, the CEA announced the publication of CEA-861-F which is a standard {{that can be used}} by interfaces such as DVI, HDMI, and LVDS. CEA-861-F adds the ability to transmit several Ultra HD video formats and additional color spaces.|$|R
5000|$|Macroblock - The basic {{processing}} unit used in several previous <b>video</b> <b>standards</b> ...|$|R
5000|$|STANAG 3350 Analogue <b>Video</b> <b>Standard</b> (NATO {{military}} {{version of}} RS-343 RGB, now EIA-343A) ...|$|R
5000|$|... x262: A GPL-licensed {{implementation}} of the H.262 <b>video</b> <b>standard.</b> x262 is only an encoder.|$|R
5000|$|... x264: A GPL-licensed {{implementation}} of the H.264 <b>video</b> <b>standard.</b> x264 is only an encoder.|$|R
5000|$|... x265: A GPL-licensed {{implementation}} of the H.265 <b>video</b> <b>standard.</b> x265 is only an encoder.|$|R
50|$|VK is a helical scan analog {{recording}} videocassette format developed by Akai {{in the late}} 1970s, {{that is capable of}} recording and playing back black & white (and later color) video in either EIA (a.k.a. RS-170, the 525-line NTSC <b>video</b> <b>standard</b> for North America, Canada, Mexico, & Japan) and CCIR (the 625-line PAL <b>video</b> <b>standard</b> for Europe {{and other parts of the}} world).|$|R
5000|$|Audio <b>Video</b> <b>Standard</b> (a {{newly created}} audio/video format {{designed}} {{for use in the}} EVD standard) ...|$|R
50|$|<b>Video</b> <b>standards</b> {{converter}} is a video {{device that}} converts NTSC to PAL and/or PAL to NTSC.|$|R
5000|$|D1, D2, D3, D5, D9 (also {{known as}} Digital-S) — various SMPTE {{commercial}} digital <b>video</b> <b>standards</b> ...|$|R
5000|$|This {{generation}} of Quick Sync supports the H.264/MPEG-4 AVC, VC-1 and H.262/MPEG-2 Part 2 <b>video</b> <b>standards.</b>|$|R
40|$|AVS视频编码标准是中国第一个具有自主知识产权的数字视频编码技术标准，其编码效率与H. 264 /AVC相当，是MPEG- 2 的 2 ~ 3 倍。 2006 年 2 月，AVS视频编码标准正式被批准为国家标准，进入了产业化推广阶段。作为AVS视频产业链中最核心的部分，AVS视频编解码芯片的研究与设计对于AVS视频编码标准的推广起着极其重要的作用。据估计，未来十年我国解码芯片的年均需求量将达到 4000 多万片。因此，研究AVS视频解码器设计意义重大。 目前，软硬件协同设计方案已经逐渐成为了视频编解码器的主流解决方案。软硬件协同设计技术兼顾了软件的灵活性和硬件的高性能等特性，它使得复杂度极高的AVS视频解码器实现变得简 [...] . The AVS <b>video</b> coding <b>standard</b> is {{the first}} digital <b>video</b> coding <b>standard</b> of China with {{independent}} intellectual property rights. It achieves similar performance to H. 264 /AVC, and about 2 or 3 times than MPEG- 2. AVS <b>video</b> <b>standard</b> has been approved as the national standard in February 2006 in China. Now {{it is on the}} way of industrialization. In the industrial chain of AVS <b>video</b> coding <b>standard,</b> the [...] . 学位：工学硕士院系专业：信息科学与技术学院电子工程系_电路与系统学号： 2312008115317...|$|R
50|$|On May 19, 2017, ATSC {{released}} the <b>video</b> <b>standard</b> for ATSC 3.0 which includes support for HLG.|$|R
5000|$|IVC 9000-M (could {{record and}} {{playback}} video in the 655-line/48 field per second (24 frame/s) <b>video</b> <b>standard)</b> ...|$|R
40|$|In this proposal, highly {{integrated}} algorithm {{and corresponding}} hardware architecture for highly computational complexity of post-processing on multi-format video decoder will be developed, including error concealment and deblocking filter. First, for error concealment, error detection and error concealment algorithms {{and their respective}} hardware architecture suitable for the MPEG- 2 and H. 264 /AVC <b>video</b> <b>standards</b> will be presented. The proposed error detection algorithm will be applied to different <b>video</b> <b>standards.</b> In addition, a common framework of error concealment to achieve different <b>video</b> <b>standards</b> will also be presented. The proposed method will effectively solve the hardware unnecessary waste on different multi-format video integration platform. Secondly, for deblocking filters, this proposal will be applicable to the H. 264 /AVC, VC- 1, MPEG- 4 and MPEG- 2 to integrate the deblocking filters. For different <b>video</b> <b>standards,</b> the in-loop filtering and the post-loop filter will be integrated into a common architecture. Using this architecture, it will be suitable for different <b>video</b> <b>standard</b> decoder and will be implemented on hardware. In addition, the MPEG- 4 advanced deblocking filter will be developed in this proposal to improve the performance. The proposed hardware architecture will be implemented on hardware, and will be verified on the FPGA development platform. 本計畫主要針對多重視訊標準/格式解碼器中計算複雜度高的視訊解碼後處理技術提出整合度高的演算法及相對應之硬體架構，其中包含錯誤隱藏與區塊消除濾波器。首先，針對錯誤隱藏，本計畫將提出適用於MPEG- 2 與H. 264 /AVC視訊標準之錯誤偵測與錯誤隱藏演算法及其相對應之硬體架構。提出之錯誤偵測演算法將分別應用於不同之視訊標準上。另外本計畫將提出一個錯誤隱藏之共通架構以實現於不同視訊標準，此方法可以有效解決在不同視訊標準整合平台上之硬體不必要的浪費。其次，在區塊消除濾波器上，本計畫將提出適用於H. 264 /AVC、VC- 1 、MPEG- 4 與MPEG- 2 整合之區塊消除濾波器，針對不同視訊標準，將內迴路濾波器與後迴路濾波器整合成一共同架構，利用此架構可適用於不同視訊標準解碼器上，並實現於硬體。此外，亦將針對MPEG- 4 之區塊消除濾波器提出改良之適應性濾波器，預期可有效消除區塊效應。上述提出之硬體架構，將實現於硬體，並於FPGA開發平台上驗證...|$|R
5000|$|High Efficiency Video Coding (HEVC) — a <b>video</b> <b>standard</b> being {{developed}} by the ISO/IEC MPEG and ITU-T VCEG ...|$|R
40|$|Videos and {{multimedia}} are increasingly used to stimulate reminiscence in dementia care. However, {{they are also}} valuable in eliciting {{a wide range of}} language patterns that are not necessarily keyed to reminiscence about self. Low-technology, home-made <b>generic</b> and personalized <b>videos</b> were tested with 2 samples of persons with dementia, to increase engagement and support the retention of identity. Participants showed a slight, though not significant, preference for looking first at personalized videos and produced a wider range of conversational language topics and phrasal patterns in response to the <b>generic</b> <b>videos...</b>|$|R
5000|$|High Efficiency Video Coding (HEVC) - <b>Video</b> <b>standard</b> that {{supports}} 4K/8K UHDTV and resolutions up to 8192 × 4320 ...|$|R
5000|$|Presentation: Audio and <b>Video</b> <b>{{standard}}s</b> (to be determined), Ultra HD with High Definition {{and standard}} definition multicast, Immersive Audio ...|$|R
