18|4876|Public
25|$|With Oracle Solaris, the {{encryption}} capability in ZFS {{is embedded}} into the I/O pipeline. During writes, a block may be compressed, encrypted, checksummed and then deduplicated, in that order. The policy for encryption {{is set at}} the dataset level when datasets (file systems or ZVOLs) are created. The wrapping keys provided by the user/administrator can be changed at any time without taking the file system offline. The default behaviour is for the wrapping key to be inherited by any child data sets. The data encryption keys are randomly generated at dataset creation time. Only descendant datasets (snapshots and clones) share data encryption keys. A command {{to switch to a}} new <b>data</b> <b>encryption</b> <b>key</b> for the clone or at any time is provided—this does not re-encrypt already existing data, instead utilising an encrypted master-key mechanism.|$|E
5000|$|The group {{state that}} is stored in the group member are keys and key metadata. Conceptually, the group member's keys are {{structured}} {{in a set of}} 1:N relationships and often called a [...] "key ladder". The member has a credential such as an X.509 certificate that proves it is authorized to join one or more groups. The default group policy for the [...] "Private Authentication Key" [...] is a 2048-bit RSA key, but other policies are possible. Similarly, the default [...] "group key" [...] or [...] "Key Encrypting Key" [...] is a 128-bit AES key, but other policies are possible. Finally, the <b>data</b> <b>encryption</b> <b>key</b> is application-dependent but is commonly a 128-bit AES key. In some groups, a member can be a sender that generates a <b>data</b> <b>encryption</b> <b>key</b> and encrypts it with the key encrypting key. So long as the two share the group key for the same group, the sender can use that [...] "key encrypting key" [...] to encrypt the key(s) for the media files or streams that it serves.|$|E
50|$|With Oracle Solaris, the {{encryption}} capability in ZFS {{is embedded}} into the I/O pipeline. During writes, a block may be compressed, encrypted, checksummed and then deduplicated, in that order. The policy for encryption {{is set at}} the dataset level when datasets (file systems or ZVOLs) are created. The wrapping keys provided by the user/administrator can be changed at any time without taking the file system offline. The default behaviour is for the wrapping key to be inherited by any child data sets. The data encryption keys are randomly generated at dataset creation time. Only descendant datasets (snapshots and clones) share data encryption keys. A command {{to switch to a}} new <b>data</b> <b>encryption</b> <b>key</b> for the clone or at any time is provided—this does not re-encrypt already existing data, instead utilising an encrypted master-key mechanism.|$|E
5000|$|Symmetric {{master key}}: A {{symmetric}} master key {{is used to}} derive other symmetric <b>keys</b> (e.g., <b>data</b> <b>encryption</b> <b>keys,</b> key wrapping keys, or authentication keys) using symmetric cryptographic methods.|$|R
50|$|HSM {{are also}} {{deployed}} to manage Transparent <b>Data</b> <b>Encryption</b> <b>keys</b> for databases.|$|R
5000|$|Symmetric key {{agreement}} key: These symmetric {{keys are}} used to establish keys (e.g., <b>key</b> wrapping <b>keys,</b> <b>data</b> <b>encryption</b> <b>keys,</b> or MAC keys) and, optionally, other keying material (e.g., Initialization Vectors) using a symmetric key agreement algorithm.|$|R
3000|$|The {{retrieval}} {{stage is}} also the same as PKIS-I. Receiving the results (encrypted documents) from DS, GM decrypts them with <b>data</b> <b>encryption</b> <b>key</b> dk [...]...|$|E
40|$|With the {{increasing}} dependency of database for data storage, many sensitive data such as personal information data {{and credit card}} information data are being stored inside a database. These data is so valuable that it attracts unauthorized personnel to gain access for obtaining the data for further usage. Even though the network infrastructure nowadays is protected with different kind of security measures, there is none of them is able to block all the threats perfectly. Therefore, the data {{needs to be able}} to protect its confidentiality even though all measures have been failed. This is where the importance of cryptography in protecting the data confidentiality even the data is in the hands of the attacker. Cryptography can be implemented in different kind of methods to secure the database. The purpose of this study is to develop a cryptosystem that is able to implement cryptography to the data before storing them into the database. This implementation has been strengthened by introducing two approaches which are the classification of types of data using Key Family and the classification of <b>data</b> <b>encryption</b> <b>key</b> status according to the activation time. Key Family separates types of data such as personal information data and credit card information data. Both families use different <b>data</b> <b>encryption</b> <b>key</b> to encrypt and decrypt to limit the access of the attacker if one of the key is obtained. The state of <b>data</b> <b>encryption</b> <b>key</b> is determined by the activation date which the key which has the latest time will be activated and the old ones will be expired. This will prevent the key remains too long for encryption and decryption which poses risks for threats to break the key. This system is developed using Java programming language with the use of Java Cryptography Extension for the cryptography process. MySQL database is used as the protected database where all the data in the database is encrypted for protection. Finally, it is hope that this system can provide better security for data confidentiality and also become the last line defense of data towards the attack...|$|E
40|$|We {{introduce}} {{the notion of}} security effectiveness, illustrate its use {{in the context of}} cryptographic protocol analysis, and argue that it requires analysis of protocol property dependencies. We provide examples to show that, without dependency analysis, the use of some logics for cryptographic protocol analysis yields results that are inconsistent or unrealistic in practice. We identify several types of property dependencies whose use in protocol analysis methods can yield realistic analyses. Categories and Subject Descriptors: C. 2. 4 [Computer-Communication Networks]: General- Security and Protection, Distributed Systems; D. 4. 6 [Operating Systems]: Security and Protection - authentication, cryptographic controls; K. 6. 5 [Management of Computing and Information Systems]: Security and Protection - authentication; E. 3 [Data]: <b>Data</b> <b>Encryption.</b> <b>Key</b> Words and Phrases: Security effectiveness, cryptographic protocol, cryptographic assumption, logic, dependency, threat countermeasure. 1 Intr [...] ...|$|E
5000|$|Private static key {{agreement}} key: Private static key agreement {{keys are}} the private keys of asymmetric key pairs {{that are used}} to establish keys (e.g., <b>key</b> wrapping <b>keys,</b> <b>data</b> <b>encryption</b> <b>keys,</b> or MAC keys) and, optionally, other keying material (e.g., Initialization Vectors).|$|R
40|$|In {{this paper}} we propose a dual {{encryption}} protocol for scalable secure multicasting. Multicasting is a scalable solution for group communication. It howevel; poses several unique security problems. We use hierarchical subgrouping to achieve scalability. Third party hosts or members of the multicast group are designated as subgroup managers. They are responsible for secret key distribution and group membership management at the subgroup level. Unlike existing secure multicast protocols, our protocol need not trust the subgroup managers with the distribution of <b>data</b> <b>encryption</b> <b>keys.</b> The dual <b>encryption</b> protocol proposed in this paper distributes encrypted <b>data</b> <b>encryption</b> <b>keys</b> via subgroup managers. We also present a class$cation of the existing secure multicast protocols, compare their relative merits and show the advantages of our protocol...|$|R
50|$|Private ephemeral key {{agreement}} key: Private ephemeral key agreement {{keys are}} the private keys of asymmetric key pairs {{that are used}} only once to establish one or more keys (e.g., <b>key</b> wrapping <b>keys,</b> <b>data</b> <b>encryption</b> <b>keys,</b> or MAC keys) and, optionally, other keying material (e.g., Initialization Vectors).|$|R
40|$|We propose an {{approach}} for reasoning about message integrity protection in cryptographic protocols. The set of axioms presented herein relate design parameters and assumptions of message integrity protection mechanisms to generic message integrity threats. Comparison of threat properties derived using these axioms {{with the policy}} goals for integrity protection aids in assessing the strength (or lack thereof) of message integrity protection mechanisms. We provide examples to illustrate the use of our approach in examining the weaknesses of message integrity protection mechanisms, and also in suggesting modifications in their design parameters. Categories and Subject Descriptors: C. 2. 4 [Computer-Communication Networks]: General - Security and Protection, Distributed Systems; D. 4. 6 [Operating Systems]: Security and Protection - cryptographic controls; E. 3 [Data]: <b>Data</b> <b>Encryption.</b> <b>Key</b> Words and Phrases: Message integrity, integrity threshold, effective threshold, block membership, order, [...] ...|$|E
40|$|The {{success of}} the cloud {{database}} paradigm is strictly related to strong guarantees in terms of service availability, scalability and security, but also of data confidentiality. Any cloud provider assures the security and availability of its platform, while the implementation of scalable solutions to guarantee confidentiality of the information stored in cloud databases is an open problem left to the tenant. Existing solutions address some preliminary issues through SQL operations on encrypted data. We propose the first complete architecture that combines <b>data</b> <b>encryption,</b> <b>key</b> management, authentication and authorization solutions, and that addresses the issues related to typical threat scenarios for cloud database services. Formal models describe the proposed solutions for enforcing access control and for guaranteeing confidentiality of data and metadata. Experimental evaluations based on standard benchmarks and real Internet scenarios show that the proposed architecture satisfies also scalability and performance requirements...|$|E
40|$|Abstract—The {{success of}} the cloud {{database}} paradigm is strictly related to strong guarantees in terms of service availability, scalability and security, but also of data confidentiality. Any cloud provider assures the security and availability of its platform, while the implementation of scalable solutions to guarantee confidentiality of the information stored in cloud databases is an open problem left to the tenant. Existing solutions address some preliminary issues through SQL operations on encrypted data. We propose the first complete architecture that combines <b>data</b> <b>encryption,</b> <b>key</b> management, authentication and authorization solutions, and that addresses the issues related to typical threat scenarios for cloud database services. Formal models describe the proposed solutions for enforcing access control and for guaranteeing confidentiality of data and metadata. Experimental evaluations based on standard benchmarks and real Internet scenarios show that the proposed architecture satisfies also scalability and performance requirements. Index Terms—Database, confidentiality, encryption, access control Ç...|$|E
5000|$|Public key {{transport}} key: Public {{key transport}} keys are the public keys of asymmetric key pairs {{that are used}} to encrypt keys using a public key algorithm. These keys are used to establish keys (e.g., <b>key</b> wrapping <b>keys,</b> <b>data</b> <b>encryption</b> <b>keys</b> or MAC keys) and, optionally, other keying material (e.g., Initialization Vectors).|$|R
5000|$|Private key {{transport}} key: Private {{key transport}} keys are the private keys of asymmetric key pairs {{that are used}} to decrypt keys that have been encrypted with the associated public key using a public key algorithm. Key transport keys are usually used to establish keys (e.g., <b>key</b> wrapping <b>keys,</b> <b>data</b> <b>encryption</b> <b>keys</b> or MAC keys) and, optionally, other keying material (e.g., initialization vectors).|$|R
50|$|PKWARE {{released}} Smartcrypt, a {{data protection}} platform combining <b>encryption,</b> <b>data</b> discovery, and <b>encryption</b> <b>key</b> management, in 2016.|$|R
40|$|Abstract—Wirless sensor {{networks}} {{are becoming increasingly}} attactiv for military,wildlife monitoring and other applications. Usually the sensor nodes are deployed in a dangerous and untrusted area. Therefore,network security becomes very important. Key management is the core areas of the security. In this paper,we describe EPKM(Efficient and Practical Key Management Scheme),a key management protocol for the hierarchical wireless sensor networks. EPKM adopts the main idea of multiple keying mechanism which includes key establishment and updating procedures. It supports four types of keys for each node–an individual key shared with the gateway, a <b>data</b> <b>encryption</b> <b>key</b> shared with another node, a cluster key shared with the cluster head,and a global key that is initially preloaded by all the nodes. Compared to other key management schemes,our scheme used for establishing and updating these keys is efficient and practical as well as low storage and communication. Keywords-wireless sensor networks; key management; hierarchical I...|$|E
40|$|Abstract — Now a days, more {{attention}} is paid to reversible data hiding (RDH) in encrypted images, since it maintains the important property that the original cover can be losslessly recovered after embedded data is extracted while protecting the image content’s properly. All the existing methods embed data by reversibly vacating room from the encrypted images, which may be subject to some errors on data extraction and/or image recovery. This paper presents a novel method by reserving room before encryption with a traditional RDH algorithm which makes much easier for the data hider to reversibly embed data in the encrypted image. This method achieve the property of real reversibility, which means data extraction and image recovery are free of errors. The proposed method also uses an additional <b>data</b> <b>encryption</b> <b>key</b> for improving the security. Experiments show that this novel method can embed more than 10 times as large payloads for the same image quality as the previous methods...|$|E
40|$|Cloud {{database}} services {{assure the}} high availability and scalability, {{but there are}} many issues about data privacy and confidentiality. The online applications are also vulnerable to attack that gain access to the sensitive data as the attacker can easily exploit software bug. Hence the security and privacy of the sensitive data stored on the cloud is the biggest challenge today. Storing critical and sensitive data in the hands of cloud service provider will not guarantee the privacy of data. Several ways are available for storage services, but the data privacy and confidentiality solutions for cloud database are still in research. The data privacy and confidentiality can be maintained by combining encryption of data with SQL operations. The application that uses SQL database can be secured by using DD-PLAC architecture which provides confidentiality of the data stored on cloud. DD-PLAC (Distributed Database with Proxy-less architectures that store meta data in the cloud) architecture combines <b>data</b> <b>encryption,</b> <b>key</b> management and access control policies which addresses the issues related to typical threat for cloud database...|$|E
50|$|Now part of Gemalto {{and marketed}} under the SafeNet product brand, offerings include {{enterprise}} authentication, <b>data</b> <b>encryption,</b> and <b>key</b> management. SafeNet's software monetization products are now offered under Gemalto's Sentinel brand.|$|R
50|$|The <b>{{encryption}}</b> of <b>data</b> at rest {{should only}} include strong encryption {{methods such as}} AES or RSA. Encrypted data should remain encrypted when access controls such as usernames and password fail. Increasing encryption on multiple levels is recommended. Cryptography can be implemented on the database housing the data and on the physical storage where the databases are stored. <b>Data</b> <b>encryption</b> <b>keys</b> should be updated on a regular basis. <b>Encryption</b> <b>keys</b> should be stored separately from the data. Periodic auditing of sensitive data {{should be part of}} policy and should occur on scheduled occurrences. Finally, only store the minimum possible amount of sensitive data.|$|R
50|$|Cryptographic keys {{may also}} have keys that {{designate}} {{they can be used}} for long-term (static, archived) use or used for a single session (ephemeral). The latter generally applies to the use of an Ephemeral Key Agreement Key. Most other key types are designed to last for long crypto-periods from about one to two years. When a shorter crypto-period is designed different key types may be used, such as <b>Data</b> <b>Encryption</b> <b>keys,</b> Symmetric Authentication keys, Private Key-Transport keys, Key-Wrapping keys, Authorization keys or RNG keys.|$|R
40|$|Encryption and {{watermarking}} are complementary {{lines of}} defense in protecting multimedia content. Recent watermarking techniques have therefore been developed independent from encryption techniques. In this paper, we present a hybrid image protection scheme to establish a relation between the <b>data</b> <b>encryption</b> <b>key</b> and the watermark. Prepositioned secret sharing allows the reconstruction of different encryption keys by communicating different activating shares for the same prepositioned information. Each activating share {{is used by the}} receivers to generate a fresh content decryption key. In the proposed scheme, the activating share is used to carry copyright or usage rights data. The bit stream that represents this data is also embedded in the content as a visual watermark. When the encryption key needs to change, the data source generates a new activating share, and embeds the corresponding watermark into the multimedia stream. Before transmission, the composite stream is encrypted with the key constructed from the new activating share. Each receiver can decrypt the stream after reconstructing the same key, and extract the watermark from the image. Our presentation will include the application of the scheme to a test image, and a discussion on the data hiding capacity, watermark transparency, and robustness to common attacks...|$|E
40|$|Abstract. With the {{continuous}} {{expansion of the}} scale data storage, cloud storage technology for its high performance and low cost {{to get a lot}} of attention and support. However, the security issues of cloud storage data hinder its further promotion. For the current cloud storage applications of data stored encrypted, a cloud storage encryption scheme based on the separated key and encryption policy is proposed. By strengthening the <b>data</b> <b>encryption</b> <b>key</b> management and data encryption algorithm, the system achieves a more secure storage of data assurance in the technical level. Cloud storage encryption technology Encryption technology is the main storage data encryption security measures taken, but also the most used means confidentiality. Specific process is: First, the data is encrypted, then the data stored ciphertext to a storage device; in obtaining data, first remove the data ciphertext, and then use the decryption key for decryption. Common data encryption[1] modes include static data and dynamic data encryption mode encryption mode. Static data encryption mode refers to the user data is encrypted locally and then sent to the ciphertext cloud storage server. The advantages are: the user to save the decryption key, high degree of safety. Disadvantages are: client computing capability have higher requirements, and only th...|$|E
40|$|Abstract—In {{order to}} offer {{backward}} and forward secrecy for multicast applications (i. e., {{a new member}} cannot decrypt the multicast data sent before its joining and a former member cannot decrypt the data sent after its leaving), the <b>data</b> <b>encryption</b> <b>key</b> has to be changed whenever a user joins or leaves the system. Such a change {{has to be made}} known to all the current users. The bandwidth used for such re-key messaging can be high when the user pool is large. In this paper, we propose a distributed servers approach to minimize the overall system bandwidth (and complexity) by splitting the user pool into multiple groups each served by a (logical) server. After presenting an analytic model for the system based on a hierarchical key tree, we show that there is an optimal number of servers to achieve minimum system bandwidth. As the underlying user traffic fluctuates, we propose a simple dynamic scheme with low overhead where a physical server adaptively splits and merges its traffic into multiple groups each served by a logical server so as to minimize its total bandwidth. Our results show that a distributed servers approach is able to substantially reduce the total bandwidth required as compared with the traditional singleserver approach, especially for those applications with a large user pool, short holding time, and relatively low bandwidth of a data stream, as in the Internet stock quote applications. Index Terms—Distributed servers approach, key tree, multicast security, re-key messaging, split-and-merge scheme. I...|$|E
5000|$|Symmetric <b>data</b> <b>encryption</b> key: These <b>keys</b> {{are used}} with {{symmetric}} key algorithms to apply confidentiality protection to information.|$|R
50|$|In 1998, the Electronic Frontier Foundation, with {{assistance}} from the mailing list, built a $200,000 machine that could brute-force a <b>Data</b> <b>Encryption</b> Standard <b>key</b> in a few days. The project demonstrated that DES was, without question, insecure and obsolete, {{in sharp contrast to}} the US government's recommendation of the algorithm.|$|R
30|$|However, {{conventional}} encryption {{is incompatible}} with deduplication. Specifically, encrypting the same <b>data</b> with different <b>encryption</b> <b>keys</b> results into distinct ciphertexts corresponding to the same source data. Thus, it makes cross-user deduplication impossible.|$|R
40|$|In {{order to}} offer {{backward}} and forward secrecy for multicast applications (i. e., {{a new member}} cannot decrypt the multicast data sent before its joining and a former member cannot decrypt the data sent after its leaving), the <b>data</b> <b>encryption</b> <b>key</b> has to be changed whenever a user joins or leaves the system. Such a change {{has to be made}} known to all the current users. The bandwidth used for such re-key messaging can be high when the user pool is large. In this paper, we propose a distributed servers approach to minimize the overall system bandwidth (and complexity) by splitting the user pool into multiple groups each served by a (logical) server. After presenting an analytic model for the system based on a hierarchical key tree, we show that there is an optimal number of servers to achieve minimum system bandwidth. As the underlying user traffic fluctuates, we propose a simple dynamic scheme with low overhead where a physical server adaptively splits and merges its traffic into multiple groups each served by a logical server so as to minimize its total bandwidth. Our results show that a distributed servers approach is able to substantially reduce the total bandwidth required as compared with the traditional single-server approach, especially for those applications with a large user pool, short holding time, and relatively low bandwidth of a data stream, as in the Internet stock quote applications...|$|E
40|$|Multicast is an {{efficient}} technique for delivering data {{to a large}} group of users in multimedia applications such as the Internet stock quote, Internet radio, audio/music delivery, video surveillance, etc. Many of these applications require data confidentiality. One of the critical problem of data confidentiality is key management for backward and forward secrecy (i. e., a new member cannot decrypt the multicast data sent before its joining and a former member cannot decrypt the data sent after its leaving). In order to offer backward and forward secrecy for some multicast applications, <b>data</b> <b>encryption</b> <b>key</b> has to be changed whenever a user joins or leaves the system, and made known to the current users. The bandwidth used for such re-key messaging can be high when the user pool is large and the group is highly dynamic. In this thesis, we propose a distributed server approach to minimize the overall system bandwidth (and hence complexity) by splitting the user pool into multiple groups each served by a (logical) server. After presenting a simple model for the system based on a hierarchical key tree, we show that there is an optimal number of servers to achieve minimum system bandwidth. As the underlying user traffic fluctuates, we propose a simple dynamic scheme with low overhead in which the servers adaptively split and merge user groups according to user traffic to maintain such an optimum. Our results show that a distributed server approach is able to substantially reduce the total bandwidth required (by more than 30 %) as compared to the traditional single-server approach, especially for those applications with large user pool and short holding time, relatively low bandwidth of a data stream, and widely fluctuating user traffic (e. g., an Internet stock quote application) ...|$|E
30|$|The role of {{multicasting}} as a scalable {{solution for}} group communication in MANETs has {{ushered in the}} development of many group key management approaches. While those schemes normally focus on improving security and reducing the size of group keys, forward and backward confidential information should also be provided for multicast applications whenever a user joins or leaves the system. Kim et al. [7] developed a tree-based group key agreement scheme by using a binary tree infrastructure to compute and update a group key efficiently. That study also completed secure and distributed protocols by exploiting the group Diffie-Hellman (GDH) key exchange. Vasudevan and Sukumar [10] developed a scalable secure multicast algorithm by using a multiserver approach when the <b>data</b> <b>encryption</b> <b>key</b> (DEK) had to be changed. To minimize the rekeying cost, their schemes utilize the dynamic split and merge with a low overhead cost, where a physical server splits and merges its traffic into multiple groups, with each group served by a dedicated server. Wang et al. [11] developed a hybrid group key management scheme with a two-level structure where the group users are subdivided into clusters, subsequently reducing the rekeying cost as key updating. While developing a scheme that ensures key and data authenticity among group members, Chiang and Huang [12] demonstrated the data confidentiality of group messages with the properties of forward and backward confidential information. The group key is established collaboratively by combining the keys of all authenticated members, which assists in maintaining the communication and computation transparency among group members. Chaddoud et al. [13] divided group members into several operation units to perform microkey management. Compared with the logical key hierarchy (LKH), the above schemes can more significantly reduce the overload of the key server and provide more efficient key management for a secure wireless multicast. However, the above schemes lack efficient key management mechanisms for members to participate in or leave MANETs dynamically.|$|E
5000|$|In {{the last}} decade or so, file and {{directory}} encryption to tape is gradually given way to device-level encryption, with the encryption being performed by the tape drives instead of the system CPU. [...] With encryption-capable tape drives in the <b>data</b> center, <b>encryption</b> <b>keys</b> are managed and securely delivered to tape drives by dedicated key managers.|$|R
50|$|PEAPThis {{stands for}} Protected Extensible Authentication Protocol. This {{protocol}} {{allows for a}} secure transport of <b>data,</b> passwords, and <b>encryption</b> <b>keys</b> without the need of a certificate server. This was developed by Cisco, Microsoft, and RSA Security.|$|R
40|$|We present Keyed HIP (KHIP), a secure, {{hierarchical}} multicast routing protocol. We {{show that}} other shared-tree multic& routing protocols {{are subject to}} attacks against the multicast routing infrastructure that can isolate receivers or domains or introduce loops into {{the structure of the}} multicast routing tree. KHIP changes the multicast routing model so that only trusted members are able to join the multicast tree. This protects the multicast routing against attacks that could form branches to unauthorized receivers, prevents replay attacks and limits the effects of flooding attacks. Untrusted routers that are present on the path between trusted routers cannot change the routing and can mount no denialof-service attack stronger than simply dropping control messages. KHIP also provides a simple mechanism for distributing <b>data</b> <b>encryption</b> <b>keys</b> while adding little overhead to the protocol. ...|$|R
