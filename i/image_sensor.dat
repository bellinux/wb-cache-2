2493|2842|Public
5|$|Phase {{shifting}} interferometry overcomes {{these limitations}} by not relying on finding fringe centers, {{but rather by}} collecting intensity data from every point of the CCD <b>image</b> <b>sensor.</b> As seen in Fig.17, multiple interferograms (at least three) are analyzed with the reference optical surface shifted by a precise fraction of a wavelength between each exposure using a piezoelectric transducer (PZT). Alternatively, precise phase shifts can be introduced by modulating the laser frequency. The captured images are processed by a computer to calculate the optical wavefront errors. The precision and reproducibility of PSI is far greater than possible in static interferogram analysis, with measurement repeatabilities of a hundredth of a wavelength being routine. Phase shifting technology has been adapted {{to a variety of}} interferometer types such as Twyman-Green, Mach–Zehnder, laser Fizeau, and even common path configurations such as point diffraction and lateral shearing interferometers. More generally, phase shifting techniques can be adapted to almost any system that uses fringes for measurement, such as holographic and speckle interferometry.|$|E
5|$|The HTC One (codenamed and retroactively called M7) is a touchscreen-based Android {{smartphone}} designed, developed, {{and manufactured}} by HTC. The smartphone was unveiled on 19 February 2013 at press events in New York City and London and is HTC’s seventh flagship smartphone. It is {{the successor to}} the company’s 2012 flagship model, the One X—which was critically acclaimed, but commercially unsuccessful {{due in part to}} insufficient marketing efforts. To make the device stand out among its competition, the HTC One was developed with a major emphasis on unique hardware and software features; which included a unibody aluminum frame, a 1080p full-HD display, dual front-facing stereo speakers, a camera with a custom <b>image</b> <b>sensor</b> and the ability to automatically generate montages of media, an updated version of HTC’s Sense user experience, BlinkFeed—an aggregator of news and social network content, and an electronic program guide app with the ability to serve as a universal remote via an IR blaster located in the device’s power button.|$|E
5|$|The HTC One is {{equipped}} with a 4.0-megapixel rear-facing camera module that contains a custom <b>image</b> <b>sensor</b> marketed as UltraPixel, which is composed of pixels that are 2.0µm in size. Most high-end smartphones {{at the time of its}} release used 8- or 13-megapixel cameras with pixel sizes ranging from 1.4 to 1.0µm, both of which are considerably smaller in size than the pixels found in the One’s UltraPixel sensor. Although these smaller pixel sizes were typically necessary to ensure that the camera sensor did not compromise the design of the phone, there were concerns that this could result in a loss of dynamic range and sensitivity, and also result in poor performance in low-light environments. As such, HTC stated that its camera design with larger sensor pixels could notably increase overall image quality, especially in low-light environments. The camera also includes optical image stabilization, and is further enhanced by improvements to the Sense camera software and the ImageChip 2 image processor.|$|E
40|$|The {{increasing}} miniaturization {{and resolution}} of <b>image</b> <b>sensors</b> bring challenges to conventional optical {{elements such as}} spectral filters and polarizers, the properties of which are determined mainly by the materials used, including dye polymers. Recent developments in spectral filtering and optical manipulating techniques based on nanophotonics have opened up {{the possibility of an}} alternative method to control light spectrally and spatially. By integrating these technologies into <b>image</b> <b>sensors,</b> it will become possible to achieve high compactness, improved process compatibility, robust stability and tunable functionality. In this Review, recent representative achievements on nanophotonic <b>image</b> <b>sensors</b> are presented and analyzed including <b>image</b> <b>sensors</b> with nanophotonic color filters and polarizers, metamaterial-based THz <b>image</b> <b>sensors,</b> filter-free nanowire <b>image</b> <b>sensors</b> and nanostructured-based multispectral <b>image</b> <b>sensors.</b> This novel combination of cutting edge photonics research and well-developed commercial products may not only lead to an important application of nanophotonics but also offer great potential for next generation <b>image</b> <b>sensors</b> beyond Moore's Law expectations...|$|R
30|$|In recent years, <b>image</b> <b>sensors</b> have {{increased}} in quality and capability {{and at the same}} time decreased in price, making them desirous to include in small electronic devices and systems. However, these <b>image</b> <b>sensors</b> are difficult to interface with most commercial microcontrollers (MCUs) as these high-speed <b>image</b> <b>sensors</b> produce data at such a high rate that cannot be processed in real time. As a consequence, most high-speed <b>image</b> <b>sensors</b> are difficult to use in low-power and low-speed embedded systems. There is no buffering provided inside the <b>image</b> <b>sensors.</b> Most MCUs have limited internal memory space and may not be able to store a complete frame unless external memory is provided. Moreover, these <b>image</b> <b>sensors</b> send <b>image</b> data in a row-by-row fashion; as a result, the data cannot be accessed randomly; the first row must be read prior to the second row to avoid data loss. Many image processing algorithms, such as transform coding using the Discrete Cosine Transform (DCT) and pattern recognition for robotic vision, need to access pixel values in a random access fashion. Besides, a high-speed clock must be provided to operate the <b>image</b> <b>sensors</b> properly.|$|R
5000|$|Active-pixel <b>sensors</b> (APSs) are <b>image</b> <b>sensors.</b> Usually {{made in a}} {{complementary}} metal-oxide-semiconductor (CMOS) process, and also known as CMOS <b>image</b> <b>sensors,</b> APSs are commonly used in cell phone cameras, web cameras, and some DSLRs.|$|R
5|$|When {{a crystal}} is mounted and exposed to an intense beam of X-rays, it {{scatters}} the X-rays into {{a pattern of}} spots or reflections that can be observed on a screen behind the crystal. A similar pattern may be seen by shining a laser pointer at a compact disc. The relative intensities of these spots provide the information to determine the arrangement of molecules within the crystal in atomic detail. The intensities of these reflections may be recorded with photographic film, an area detector or with a charge-coupled device (CCD) <b>image</b> <b>sensor.</b> The peaks at small angles correspond to low-resolution data, whereas those at high angles represent high-resolution data; thus, an upper limit on the eventual resolution of the structure can be determined from the first few images. Some measures of diffraction quality can be determined at this point, such as the mosaicity of the crystal and its overall disorder, as observed in the peak widths. Some pathologies of the crystal that would render it unfit for solving the structure can also be diagnosed quickly at this point.|$|E
25|$|The {{digital camera}} is a camera that takes video or still photographs, {{digitally}} by recording images via an electronic <b>image</b> <b>sensor.</b> Steven Sasson {{as an engineer}} at Eastman Kodak invented and built the first digital camera using a CCD <b>image</b> <b>sensor</b> in 1975.|$|E
25|$|Currently {{available}} scanners typically use {{charge-coupled device}} (CCD) or contact <b>image</b> <b>sensor</b> (CIS) as the <b>image</b> <b>sensor,</b> whereas older drum scanners use a photomultiplier tube as the <b>image</b> <b>sensor.</b> Early color film scanners used a halogen lamp and a three-color filter wheel, so three exposures {{were needed to}} scan a single color image. Due to heating problems, the worst of them being the potential destruction of the scanned film, this technology was later replaced by non-heating light sources such as color LEDs.|$|E
30|$|Most native HD (720 p and 1080 p) <b>image</b> <b>sensors</b> such as OV 10131 from OmniVision [32] and MT 9 P 401 from Aptina [31] use the DVP interface. Some higher-resolution HD <b>image</b> <b>sensors</b> such as OV 9810 [32] use an {{additional}} interface, called the mobile industry processor interface (MIPI) {{along with the}} typical DVP interface. The data output bus DOUT is generally wider than 8 [*]bits in these HD <b>image</b> <b>sensors.</b>|$|R
40|$|The aim of {{this article}} is to guide <b>image</b> <b>sensors</b> {{designers}} to optimize the analog-to-digital conversion of pixel outputs. The most common ADCs topologies for <b>image</b> <b>sensors</b> are presented and discussed. The ADCs specific requirements for these sensors are analyzed and quantified. Finally, we present relevant recent contributions of specific ADCs for <b>image</b> <b>sensors</b> and we compare them using a novel FOM. © (2014) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use onlyPeer reviewe...|$|R
25|$|DSLR cameras {{often have}} <b>image</b> <b>sensors</b> of much larger size and often higher quality, {{offering}} lower noise, which {{is useful in}} low light. Although mirrorless digital cameras with APS-C and full frame sensors exist, most full frame and medium format sized <b>image</b> <b>sensors</b> are still seen in DSLR designs.|$|R
25|$|A CMOS <b>image</b> <b>sensor</b> (complementary metal-oxide semiconductor) is an <b>image</b> <b>sensor</b> {{consisting}} {{of an integrated}} circuit containing an array of pixel sensors, each pixel containing a photodetector and an active amplifier. Starting at the same point, they have to convert light into electrons by using the CMOS process. CMOS image sensors {{can be found in}} digital SLR cameras, embedded web-cams, video cameras, automotive safety systems, swallowable-pill cameras, toys and video games, and wireless video-security networks. The renowned American physicist and engineer Eric Fossum invented the CMOS <b>image</b> <b>sensor</b> while working at NASA's Jet Propulsion Laboratory in Pasadena, California. On January 28, 1994, Fossum filed U.S. patent #5,471,515, which was issued to him on November 28, 1995.|$|E
25|$|The Foveon X3 sensor is an <b>image</b> <b>sensor</b> {{for digital}} cameras, {{designed}} by Foveon, Inc. (now part of Sigma Corporation) and manufactured by Dongbu Electronics.|$|E
25|$|The {{camera is}} the image-forming device, and a {{photographic}} plate, photographic film or a silicon electronic <b>image</b> <b>sensor</b> is the capture medium. The respective recording medium {{can be the}} plate or film itself, or a digital magnetic or electronic memory.|$|E
40|$|Abstract: This paper {{presents}} {{the structure and}} the operational principle of CMOS <b>image</b> <b>sensors.</b> And then the reason is illuminated for producing dark current and black level of CMOS <b>image</b> <b>sensors.</b> It is necessary to calibrate dark current and black level to improve quality of CMOS <b>image</b> <b>sensors.</b> The dark current is corrected by optimizing pixel structure, perfecting technology, improving 6 layout, and correction double sample. But these ways do not calibrate black level. So, {{it is important to}} calibrate black level using black level calibration algorithm in the stage of image processing. 1...|$|R
40|$|Silicon imaging is {{a fast-growing}} {{area of the}} {{semiconductor}} industry. Its use in cell phone cameras is already well established, and emerging applications include web, security, automotive, and digital cinema cameras. High Performance Silicon Imaging covers the fundamentals of silicon <b>image</b> <b>sensors,</b> {{with a focus on}} existing performance issues and potential solutions. The book considers several applications for the technology. Part I includes a review of the fundamental principles of photosensing and the operational principles of silicon <b>image</b> <b>sensors.</b> It also focuses on charged coupled device (CCD) <b>image</b> <b>sensors</b> and metal-oxide-semiconductor (CMOS) <b>image</b> <b>sensors.</b> The performance issues considered include image quality, detector sensitivity, data-transfer rate, system level integration, rate of power consumption, and the potential for 3 D sensor development. Part II provides a detailed discussion of how CMOS technology {{can be used in a}} range of areas,including mobile devices, <b>image</b> <b>sensors</b> for automotive applications, highdefinition TV imaging, sensors for several forms of scientific imaging, space, and sensors for medical applications. High Performance Silicon Imaging is an excellent resource for both academics and engineers working in the optics, photonics, semiconductor and electronics industries...|$|R
40|$|This paper {{presents}} a novel motion compensation approach for stabilizing video sequences captured by CMOS <b>image</b> <b>sensors.</b> Although {{a number of}} papers have been dedicated to the compensation of shaky camera motions, most of them have focused on CCD <b>image</b> <b>sensors.</b> By relating the homography model to the characteristics of CMOS video sequences, we estimated the dominant motion in image sequences degraded by random shake, simultaneously estimating the distortion parameters of CMOS <b>image</b> <b>sensors.</b> Also, we considered the real-time applications with a fast linear-programming approach for the estimation of camera motion. Index Terms — CMOS, CCD, Digital video stabilization. 1...|$|R
25|$|The {{two primary}} types of HDR images are {{computer}} renderings and images resulting from merging multiple low-dynamic-range (LDR) or standard-dynamic-range (SDR) photographs. HDR images {{can also be}} acquired using special image sensors, such as an oversampled binary <b>image</b> <b>sensor.</b>|$|E
25|$|In 1986, the Kodak Microelectronics Technology Division {{developed}} a 1.3 MP CCD <b>image</b> <b>sensor,</b> the first {{with more than}} 1 million pixels. In 1987, this sensor was integrated with a Canon F-1 film SLR body at the Kodak Federal Systems Division to create the first DSLR camera. The digital back monitored the camera body battery current to sync the <b>image</b> <b>sensor</b> exposure to the film body shutter. Digital images were stored on a tethered hard drive and processed for histogram feedback to the user. This first camera was created for the U.S. Government, and was followed by several other models intended for government use, and eventually the first commercial DSLR, launched by Kodak in 1991.|$|E
25|$|Photography is the science, art, {{application}} {{and practice of}} creating durable images by recording light or other electromagnetic radiation, either electronically {{by means of an}} <b>image</b> <b>sensor,</b> or chemically by means of a light-sensitive material such as photographic film.|$|E
40|$|This paper {{presents}} {{the use of}} charge coupled device (abbreviated as CCD) linear <b>image</b> <b>sensors</b> in an optical tomographic instrumentation system used for sizing particles. Four CCD linear <b>image</b> <b>sensors</b> are configured around an octagonal shaped measurement section for a four projections system. The system consists of lighting system, data acquisition system and image reconstruction system. The measurement system is explained and uses four CCD linear <b>image</b> <b>sensors</b> consisting of 2048 pixels with a size of 14 micron by 14 micron. Hence, a high-resolution system is produced. Image reconstruction for the four-projection optical tomography system is generated using Matlab software...|$|R
40|$|An imaging {{arrangement}} {{including a}} multi-sensor {{for use in}} an x-ray examination apparatus is described that combines a plurality of partially overlapping sub-images, resulting in an increased effective sensor area when compared to a single sensor-image. Thus an imaging arrangement is provided suitable for imaging a large area output screen of an image intensifier by way of semiconductor <b>image</b> <b>sensors.</b> <b>Image</b> artifacts owing to variations in the alignment of the respective <b>image</b> <b>sensors</b> are corrected for by applying geometric transformation to respective electronic sub-image generated by the <b>image</b> <b>sensors.</b> The transformed electronic sub-images are assembled into a recombined image. Further image quality improvement is obtained by performing evening operations in overlapping regions of the transformed sub-images...|$|R
5000|$|Color filter array, {{mosaic of}} tiny color filters over color <b>image</b> <b>sensors</b> ...|$|R
25|$|These {{additional}} vector attributes can {{be captured}} optically {{through the use}} of microlenses at each pixel point within the 2-dimensional <b>image</b> <b>sensor.</b> Every pixel of the final image is actually a selection from each sub-array located under each microlens, as identified by a post-image capture focus algorithm.|$|E
25|$|In the Red Steel trailer {{shown at}} E3 2006, the Wii Remote {{featured}} a smaller circular shaped <b>image</b> <b>sensor,</b> {{as opposed to}} the larger opaque IR filters shown on other versions. In the initial teaser video that revealed the controller at Tokyo Game Show 2005, the 1 and 2 buttons were labeled X and Y, respectively.|$|E
25|$|DSLRs {{generally}} have greater cost, size, and weight. They also have louder operation, {{due to the}} SLR mirror mechanism. Sony's fixed mirror design manages to avoid this problem. However, that design has the disadvantage {{that some of the}} light received from the lens is diverted by the mirror and thus the <b>image</b> <b>sensor</b> receives about 30% less light compared with other DSLR designs.|$|E
40|$|The {{experiments}} {{of displacement}} damage effects on CMOS APS <b>image</b> <b>sensors</b> induced by neutron irradiation from {{a nuclear reactor}} are presented. The CMOS APS <b>image</b> <b>sensors</b> are manufactured in the standard 0. 35 μm CMOS technology. The flux of neutron beams was about 1. 33 × 108 n/cm 2 s. The three samples were exposed by 1 MeV neutron equivalent-fluence of 1 × 1011, 5 × 1011, and 1 × 1012 n/cm 2, respectively. The mean dark signal (KD), dark signal spike, dark signal non-uniformity (DSNU), noise (VN), saturation output signal voltage (VS), and dynamic range (DR) versus neutron fluence are investigated. The degradation mechanisms of CMOS APS <b>image</b> <b>sensors</b> are analyzed. The mean dark signal increase due to neutron displacement damage appears to be proportional to displacement damage dose. The dark images from CMOS APS <b>image</b> <b>sensors</b> irradiated by neutrons are presented to investigate the generation of dark signal spike...|$|R
40|$|Solution-processed phototransistors can {{substantially}} {{advance the}} performance of <b>image</b> <b>sensors.</b> Phototransistors exhibit large photoconductive gain and a sublinear responsivity to irradiance, which enables a logarithmic sensing of irradiance that is akin to the human eye and has a wider dynamic range than photodiode-based <b>image</b> <b>sensors.</b> Here, we present a novel solution-processed phototransistor composed of a heterostructure between a high-mobility organic semiconductor and an organic bulk heterojunction. The device efficiently integrates photogenerated charge {{during the period of}} a video frame then quickly discharges it, which significantly increases the signal-To-noise ratio compared with sampling photocurrent during readout. Phototransistor-based <b>image</b> <b>sensors</b> processed without photolithography on plastic substrates integrate charge with external quantum efficiencies above 100 % at 100 frames per second. In addition, the sublinear responsivity to irradiance of these devices enables a wide dynamic range of 103 dB at 30 frames per second, which is competitive with state-of-The-Art <b>image</b> <b>sensors...</b>|$|R
50|$|By the mid 1990s, digital <b>image</b> <b>sensors</b> and {{computers}} had improved tremendously, but still lacked the required pixel count and density for digital holography {{to be anything}} more than a curiosity. At the time, the market driving digital <b>image</b> <b>sensors</b> was primarily low-resolution video, and so those sensors provided only PAL, NTSC, or SECAM resolution. This suddenly changed {{at the beginning of the}} 21st century with the introduction of digital still image cameras, which drove demand for inexpensive high-pixel-count sensors. As of 2010, affordable <b>image</b> <b>sensors</b> can have up to 60 megapixels. In addition, the CD and DVD-player market has driven development of affordable diode lasers and optics.|$|R
25|$|Georges Cornuéjols and licensees of his patents (Brdi, Hymatom) {{introduced}} {{the principle of}} HDR video image, in 1986, by interposing a matricial LCD screen {{in front of the}} camera's <b>image</b> <b>sensor,</b> increasing the sensors dynamic by five stops. The concept of neighborhood tone mapping was applied to video cameras by a group from the Technion in Israel led by Dr. Oliver Hilsenrath and Prof. Y.Y.Zeevi who filed for a patent on this concept in 1988.|$|E
25|$|Digital imaging uses an {{electronic}} <b>image</b> <b>sensor</b> {{to record the}} image {{as a set of}} electronic data rather than as chemical changes on film. An important difference between digital and chemical photography is that chemical photography resists photo manipulation because it involves film and photographic paper, while digital imaging is a highly manipulative medium. This difference allows for a degree of image post-processing that is comparatively difficult in film-based photography and permits different communicative potentials and applications.|$|E
25|$|Focusing can be manual, by {{twisting}} {{the focus on}} the lens; or automatic, activated by pressing half-way on the shutter release or a dedicated AF button. To take an image, the mirror swings upwards {{in the direction of the}} arrow, the focal-plane shutter (3) opens, and the image is projected and captured on the <b>image</b> <b>sensor</b> (4), after which actions, the shutter closes, the mirror returns to the 45-degree angle, and the built in drive mechanism re-tensions the shutter for the next exposure.|$|E
50|$|Digital camera <b>image</b> <b>sensors</b> {{can also}} {{be subject to a}} form of {{reciprocity}} failure.|$|R
30|$|High-quality HDR capture using {{off-the-shelf}} <b>image</b> <b>sensors</b> can currently {{be performed}} with three distinct approaches.|$|R
5000|$|... #Caption: An OV7910 {{and three}} OV6920 <b>image</b> <b>sensors</b> — both types with {{composite}} video outputs.|$|R
