0|10000|Public
40|$|Databases and <b>database</b> {{technology}} <b>are</b> {{having a}} major impact on the growing use of computers. It {{is fair to say that}} <b>databases</b> <b>are</b> playing a critical role in almost all areas where computers are used, including business, engineering, medicine, law, education, and library science, to name a few. At Ball State University, <b>databases</b> <b>are</b> <b>very</b> widely <b>used</b> among faculty, staff, and students. The common commercial database management system (DBMS) used in the university is ORACLE. Due to the extensive use of the system and the availability and easy access to alternative systems such as RDB/VMS, a comparative research is in order. This thesis is a comprehensive comparison between the two systems. It covers the differences in design, SQL codings, and the use of host programming language such as FORTRAN. It concentrates on the differences in memory usage, execution time, as well as the CPU time needed to precompile, link, and run. Department of Computer ScienceThesis (M. S. ...|$|R
40|$|Abstract. Current {{solutions}} to integrating private data with public data have provided useful privacy metrics, such as relative information gain, {{that can be}} used to evaluate alternative approaches. Unfortunately, they have not addressed critical performance issues, especially when the public <b>database</b> <b>is</b> <b>very</b> large. The <b>use</b> of hashes and noise yields better performance than existing techniques, while still making it difficult for unauthorized entities to distinguish which data items truly exist in the private database. As we show here, the uncertainty introduced by collisions caused by hashing and the injection of noise can be leveraged to perform a privacy-preserving relational join operation between a massive public table and a relatively smaller private one. ...|$|R
40|$|Aim of this {{research}} is to draw up a proprietary BIM guideline to help buildings owners in managing their assets using BIM models in connection with databases, so to solve two recurring issues: a) many people in the maintenance and operation supply chain are unable to use or {{do not have access to}} BIM authoring tools; and b) difficulties in storing life cycle data in a BIM model. After analyzing the current maintenance management procedures and the documents management system of the client, the BIM adoption procedure has been planned. This consists of some steps: a) analysis of organizations requirements (OIRs) and of owner’s database of maintenance operations; b) setting up a Work Breakdown Structure (WBS) to identify building or system components; c) listing data required for each object in the WBS starting from what collected in point a) and using COBie guides as a background base; d) digitalization of all client information about building asset. The connection between high Level of Information BIM models and a database allows the client to manage complex activities like, for example, scheduling and recording maintenance operations, store and update technical documents (pictures, datasheets, warranties, etc.) and setting up automatic alerts for recurring control activities. Due to the extent of the topic, there is a great variety of stakeholders and professionals involved, so the guideline must be able to cope with different requirements, input and output, while keeping data updated and consistent. Many different scenarios have been analysed so to avoid ambiguity and personal users’ choices (in opposition to organization’s ones). The application of the developed procedures and tools has been made using Autodesk Revit and Microsoft Access because these are among the most used BIM and database software tools in Italy and because the connection between the BIM model and the <b>database</b> <b>is</b> <b>very</b> reliable when <b>using</b> these tools...|$|R
40|$|In {{recent years}} {{there has been}} a rapid {{transition}} to subscription of electronic resources and significant percentages of library budgets are allocated to electronic resources. Identifying and analyzing the benefits and costs of this new trend is therefore relevant. In this study we have considered the experiences of METU Library in utilizing electronic resources and provided a cost-benefit analysis of electronic resources based on the cost and usage statistics obtained from this library. The study examines the ScienceDirect, EbscoHost and Web of Science databases available within the METU electronic resources collection. In addition to the subscription cost statistics, non-subscription cost information obtained through interviews and surveys have been used in our analysis. Usage statistics of electronic information sources have been collected in accordance with the COUNTER standards and analyzed using various methods. The high usage of electronic resources in METU reduces the unit cost of databases. According to the 2004 data, the cost per usage for EbscoHost and Web of Science is $ 0. 3 $ 0. 2 respectively. These figures place METU below the average unit cost per use of all Anatolian University Libraries Consortium (ANKOS) members. Yet due to high subscription cost, the unit cost per use of ScienceDirect is relatively higher ($ 2. 3), even though the <b>database</b> <b>is</b> <b>used</b> <b>very</b> heavily at METU. This figure is above the average unit cost per use of all ANKOS members for the ScienceDirect database. Statistics show that a small number of ""core"" journals satisfy significant amount of use while the majority of journals are used rather infrequently. The results obtained from this study show that electronic resources cost, over the years, considerable amount of money for METU and their usage has also increased gradually. In general, it can be concluded that electronic resources are heavily utilized in METU in terms of overall usage. In order to maximize the benefits of electronic resources it is necessary to analyze cost and usage statistics in detail at both institutional and consortial levels, using various techniques. The results obtained from such studies can be used as guidelines for the development of collections of electronic resources, consortial agreements and user education programs...|$|R
3000|$|LBPHF and MR methods. Although {{the results}} of alone Zernike moment {{features}} in the Outex <b>database</b> <b>are</b> <b>very</b> outstanding, they <b>are</b> not stable compared with the proposed method because the results in the CUReT and KTH-TIPS <b>databases</b> <b>are</b> <b>very</b> bad. In addition, multiscale idea can further notably improve the recognition results.|$|R
50|$|One of the {{problems}} of knowledge-based machine translation systems is that it becomes impossible to create databases for domains larger than very specific areas. Another is that processing these <b>databases</b> <b>is</b> <b>very</b> computationally expensive.|$|R
50|$|Library {{has also}} {{installed}} 12 Bloomberg terminals. The specific features of Bloomberg <b>Database</b> <b>is</b> {{that it provides}} a range of Global Economic data and live changes for stocks Markets, Company Reports, Sector analysis, and future trends. Bloomberg <b>Database</b> <b>is</b> <b>very</b> useful for Research Analysis.|$|R
30|$|Brunei’s {{disaster}} information {{reported to}} regional and global disaster <b>databases</b> <b>is</b> <b>very</b> limited and scanty. Both a disaster {{information sharing system}} and disaster <b>database</b> <b>are</b> currently nonexistent, although the need to establish a systematic data-sharing procedure among relevant stakeholders has been recognized (Brunei Darussalam Government 2011 b).|$|R
40|$|Although the {{mathematical}} foundations of relational <b>databases</b> <b>are</b> <b>very</b> well established, {{the state of}} affairs for object-oriented <b>databases</b> <b>is</b> much less satisfactory. We propose a semantic foundation for object-oriented databases based on a simple logic of change called rewriting logic, and a language called MaudeLog {{that is based on}} that logic. Some key advantages of our approach include its logical nature, its simplicity without any need for higher-order features, the fact that dynamic aspects are directly addressed, the rigorous integration of user-definable algebraic data types within the framework, the existence of initial models, and the integration of query, update, and programming aspects within a single declarative language. 1 Introduction Although {{the mathematical}} foundations of relational <b>databases</b> <b>are</b> <b>very</b> well established, the state of affairs for object-oriented <b>databases</b> <b>is</b> much less satisfactory. This is unfortunate, because object-oriented databases seem to have impor [...] ...|$|R
40|$|We {{introduce}} a new algorithm for mining sequential patterns. Our algorithm is especially efficient when the sequential patterns in the <b>database</b> <b>are</b> <b>very</b> long. We {{introduce a}} novel depth-first search strategy that integrates a depth-first traversal of the search space with effective pruning mechanisms...|$|R
30|$|The {{selection}} of the appropriate <b>database</b> <b>is</b> <b>very</b> important in order to construct the VL-CSEVS. The MIT-BIH arrhythmia <b>database</b> <b>was</b> selected as the training set because it contains a large set of ECG beats and many different examples of cardiac pathologies. Then, VL-CSEVS having the unique patterns were generated by analyzing {{a huge number of}} the ECG segments obtained from this database.|$|R
3000|$|For the two datasets, each 3 D object {{belongs to}} a unique class among {{different}} semantic concepts with strong variations including human, airplane, chair, and so forth. For instance, the human class contains persons with different poses and appearances [...] "running, seating, walking, etc.", globally the two <b>databases</b> <b>are</b> <b>very</b> challenging.|$|R
40|$|The {{internet}} hosts {{different kind of}} services like email, ftp, video and database applications. As <b>databases</b> <b>are</b> <b>very</b> important for storing confidential information, it very important that networks provide the minimum requirement during a database transaction. The objective {{of this paper is}} to present a simulation study on importance of queuing mechanisms for a heavy database traffic. 2...|$|R
5000|$|Relational <b>databases</b> <b>are</b> <b>very</b> {{well suited}} to flat data layouts, where {{relationships}} between data is one or two levels deep. For example, an accounting database might need to look up all the line items for all the invoices for a given customer, a three-join query. Graph <b>databases</b> <b>are</b> aimed at datasets that contain many more links. They are especially {{well suited to}} social networking systems, where the [...] "friends" [...] relationship is essentially unbounded. These properties make graph databases naturally suited to types of searches that are increasingly common in online systems, and in big data environments. For this reason, graph <b>databases</b> <b>are</b> becoming <b>very</b> popular for large online systems like Facebook, Google, Twitter, and similar systems with deep links between records.|$|R
30|$|All {{experiments}} are {{conducted on the}} BOSSbase database ver. 1.01 [25] containing 10, 000 512 [*]×[*] 512 8 -bit grayscale images coming from eight different cameras. This <b>database</b> <b>is</b> <b>very</b> convenient for our purposes because it contains uncompressed images that serve as precovers for side-informed JPEG embedding. Also, the images can be compressed to any desirable quality factor for the JPEG domain.|$|R
50|$|The {{database}} of the Scottish Tartans Authority {{is a record}} of all known tartan designs. This <b>database</b> <b>is</b> <b>very</b> similar to, and was originally based on, the Register of All Publicly Known Tartans of the Scottish Tartans Society, but contains twice as many entries - about 6,000, accordingly the STA's website lists about only 3,500 different tartans as of 2004.|$|R
50|$|Jenipapo: it <b>is</b> <b>very</b> <b>used</b> to make liquor.|$|R
40|$|International audienceMedical imaging {{research}} {{deals with}} large, heterogeneous and fragmented amounts of medical images. The need for secure, federated and functional medical image <b>databases</b> <b>is</b> <b>very</b> strong within these research communities. This paper {{provides an overview}} of the different projects concerned with building medical image databases for medical imaging research. It also discusses the characteristics and requirements of this community and tries to determine to what extent existing solutions can answer these specific requirements...|$|R
40|$|Everyday an {{enormous}} amount of data is received and transmitted in a Data Warehouse. A Data Warehouse is a repository of organizations electronically stored data and can be considered as a set of materialized. When the query is imposed on data warehouse the result of the query has to be finding out from the large database. Hence the query response time <b>is</b> <b>very</b> large and performance response of <b>database</b> <b>is</b> <b>very</b> poor. Hence how to increase the query performance is a challenge in a data warehouse environment...|$|R
40|$|Content based image {{retrieval}} system is used to retrieve images which <b>are</b> <b>very</b> close to the image that is given as input by user. User can give any image in the database for which texture and colour calculations are performed using euclidean distance and quadratic distances respectively. This system is efficient when the <b>database</b> <b>is</b> <b>very</b> large and manual retrieval of images consume long time. <b>Database</b> <b>is</b> divided into parts,which belongs to same category for decreasing the computational time. Main objective {{of this paper is}} to retrieve an images using both the texture and colour features of an image and display optimum number of output...|$|R
30|$|The error {{distribution}} for those segments, displayed in Figure 3, shows {{the degree of}} difficulty of the audio segmentation task. On average, only 6.98 % of the segments in the testing <b>database</b> <b>are</b> <b>very</b> difficult. The rest of the segments were detected correctly at least by one detection system. Comparing this number with the final score from the winner system (30.22 %), we conclude {{that there is still}} a large margin to improve the audio segmentation performance.|$|R
30|$|Similar to the Shazam method, the {{variance}} and therefore, {{the standard deviation}} were calculated for the ORB results from Fig.  8. The Eqs. 10 and 11 were used to calculate {{the variance}} and standard deviation, respectively. The variance for the ORB method results was calculated to be 1113.58, and the standard deviation was calculated as 33.37. The standard deviation is large which means that the matches of the other songs in the <b>database</b> <b>were</b> <b>very</b> small.|$|R
40|$|This paper {{surveys the}} data {{structures}} that were proposed for efficient management of spatial data. These data structures were designed {{having in mind}} the types of queries asked on spatial data, which are usually proximity-based. It is thus essential to store together, in one sense or another, "nearby" objects. This condition is crucial for performance when the <b>databases</b> <b>are</b> <b>very</b> large [...] -which is almost always the case [...] -and data accesses require lengthy I/O operations...|$|R
40|$|Project (M. S., Computer Science) [...] California State University, Sacramento, 2009. Nowadays <b>database</b> {{management}} systems <b>are</b> {{the most crucial}} factors in managing and storing the data. Security enforcement in a <b>database</b> <b>is</b> <b>very</b> important {{to assure that the}} data stored is properly secured. Most of the <b>database</b> {{management systems}} <b>are</b> occupied with strong defense mechanisms. In addition to this, many academic researchers have been proposing solutions and mechanisms to improve security enforcement in database management systems. Understanding and Identifying of these new mechanisms and security features provided by <b>database</b> systems <b>are</b> <b>very</b> important. In this project, I surveyed the solutions proposed and implemented by academic researchers on Relational and Object-Oriented Databases. Also, I identified and illustrated a set of security features that can be utilized to enforce security using Oracle database management system. In conclusion, this project identified the solutions, mechanisms, and features {{that can be used to}} improve security enforcement in both Relational and Object-Oriented databases. Computer Scienc...|$|R
3000|$|... [...]. This {{singularity}} {{could be}} due to different zero line for the Dst calculation compared to the other years. Since the data is taken 50 years ago and the solar wind <b>database</b> <b>is</b> <b>very</b> little before, Dst zero lines in 1965 cannot easily be re-examined. If the singularity of the 1965 Dst value is due to such error, the Dst difference between the 1965 to 1974 decade and the following three decades (1975 to 2004) in Figure 1 a,e is significantly reduced.|$|R
30|$|For the Shazam method, the {{variance}} {{was determined to}} be 26500.38, and the standard deviation was 162.79. Similar to the Shazam method, {{the variance}} and therefore the standard deviation were calculated for the ORB results. The variance for the ORB method results {{was determined to be}} 1113.58, and the standard deviation was calculated as 33.37. The standard deviation for both methods was large which confirmed that the matches of the other songs in the <b>database</b> <b>were</b> <b>very</b> small compared to the actual match.|$|R
40|$|We {{introduce}} a new algorithm for mining sequential patterns. Our algorithm is especially e#cient when the sequential patterns in the <b>database</b> <b>are</b> <b>very</b> long. We {{introduce a}} novel depth-first search strategy that integrates a depth-first traversal of the search space with e#ective pruning mechanisms. Our implementation of the search strategy combines a vertical bitmap representation of the database with e#cient support counting. A salient feature of our algorithm is that it incrementally outputs new frequent itemsets in an online fashion...|$|R
40|$|The basic magic sets {{transformation}} algorithm for rewriting logical {{rules in}} deductive <b>databases</b> <b>is</b> <b>very</b> clear and straightforward. However, rules {{generated by the}} algorithm for answering queries are too many compared to the original rules. Therefore, {{it is useful to}} simplify the generated rules before they are evaluated. This paper reports the study on the effect of simplifying such rules from the aspect of computing time. It is concluded that the improvement as a result of simplification is quite significant...|$|R
40|$|Legislative <b>databases</b> <b>are</b> a {{well-established}} information {{source for the}} legal professional. However, the manual updating of the texts and their reference data or metadata that are necessary for an effective consultation of the <b>databases</b> <b>is</b> <b>very</b> expensive and does not always guarantee the correctness of the retrieved texts. A valuable solution to the maintenance problems of the <b>databases</b> <b>is</b> more automation in the lifecycle of legislation. This {{can be achieved by}} the official electronic publication of legislation including the texts (original and consolidated) and their reference data, and by incorporating intelligent techniques for drafting, indexing and hypertext linking. Such an approach would allow for an automated update of the texts and the reference data in the databases...|$|R
50|$|Guava: It is {{consumed}} fresh or as {{ice cream or}} juice. The greens (tips of guava branches) <b>are</b> <b>very</b> <b>used</b> as tea to combat childhood diarrhea.|$|R
5000|$|... #Caption: The deer <b>are</b> <b>very</b> <b>used</b> {{to people}} {{walking in the}} deer park and graze {{right up to the}} walls of the house itself, {{ignoring}} passing bipeds.|$|R
40|$|This thesis {{deals with}} pectins {{substances}} in food processing and pharmaceutical industry. Pectin <b>is</b> <b>very</b> <b>using</b> component in food processing products, mainly due to jelly and thickening ability. The thesis is dedicated plant cell wall, where is located pectin including other material component of plant cell wall. Further it is described structure of pectin, including his production and use in industry. The {{last part of}} the thesis is dedicated enzymatic degradation of plants origin materials. Pectin <b>is</b> <b>very</b> <b>using,</b> but its structure and biosynthesis is still not fully explored...|$|R
50|$|The clock code is {{a further}} method of visualising {{fractions}} of 60, since we <b>are</b> <b>very</b> <b>used</b> to expressing fractions of an hour (60 minutes) when telling the time.|$|R
50|$|Certain {{services}} {{offer to}} check telephone numbers alongside other personal details, gained from various public sources e.g. the Electoral roll {{and from the}} imprints left on by their activities, for examples from transactions made using credit cards. The advantage of a <b>database</b> check <b>is</b> that the lookup can <b>be</b> <b>very</b> quick (sub 1s), however no databases exist to cover all telephone subscriber lines internationally, with mobile telephones being particularly problematic to trace - especially Pay as you go (phone) (non contract) arrangements which often have no registered owner. Some <b>databases</b> <b>are</b> <b>very</b> detailed and can correlate telephone numbers with physical addresses, e-mail addresses, ownership and sometimes even personal details. Such detail can help with combating fraud as well as allowing greater understanding of a customer base.|$|R
40|$|AbstractThe way {{developers}} define architecture, execute architectural strategy, {{and record}} the results make a critical difference {{in the ability to}} deal with information and knowledge. In this context, integrating <b>databases</b> <b>is</b> <b>very</b> important indeed, but the different semantics they possibly have usually complicates administration. Therefore, recovering information through a common semantics becomes crucial in order to realise the full knowledge contained in the databases. In this paper, we describe and illustrate a proposal on the use of layered architectures to integrate knowledge from heterogeneous sources. We illustrate how the process might be facilitated by applying ontology-based comparisons as part of the components' behaviour...|$|R
40|$|We {{present a}} new {{algorithm}} for mining maximal frequent itemsets from a transactional <b>database.</b> Our algorithm <b>is</b> especially efficient when the itemsets in the <b>database</b> <b>are</b> <b>very</b> long. The search strategy of our algorithm integrates a depth-first traversal of the itemset lattice with effective pruning mechanisms. Our {{implementation of the}} search strategy combines a vertical bitmap representation of the database with an efficient relative bitmap compression schema. In a thorough experimental analysis of our algorithm on real data, we isolate {{the effect of the}} individual components of the algorithm. Our performance numbers show that our algorithm outperforms previous work by a factor of three to five. ...|$|R
