1108|10000|Public
5|$|The {{analysis}} above {{assumes that}} each key's hash is a random number {{independent of the}} <b>hashes</b> {{of all the other}} keys. This assumption is unrealistic for most applications of hashing.|$|E
5|$|Perl's text-handling {{capabilities}} can be {{used for}} generating SQL queries; arrays, <b>hashes,</b> and automatic memory management make it easy to collect and process the returned data. For example, in Tim Bunce's Perl DBI application programming interface (API), the arguments to the API can be the text of SQL queries; thus it is possible to program in multiple languages at the same time (e.g., for generating a Web page using HTML, JavaScript, and SQL in a here document). The use of Perl variable interpolation to programmatically customize each of the SQL queries, and the specification of Perl arrays or <b>hashes</b> as the structures to programmatically hold the resulting data sets from each SQL query, allows a high-level mechanism for handling large amounts of data for post-processing by a Perl subprogram.|$|E
5|$|Arrays {{can contain}} {{elements}} {{of any type}} that PHP can handle, including resources, objects, and other arrays. Order is preserved in lists of values and in <b>hashes</b> with both keys and values, and the two can be intermingled. PHP also supports strings, {{which can be used}} with single quotes, double quotes, nowdoc or heredoc syntax.|$|E
5000|$|... uint32_t jenkins_one_at_a_time_hash(const uint8_t* key, size_t length) { size_t i = 0; uint32_t <b>hash</b> = 0; while (i != length) { <b>hash</b> += keyi++; <b>hash</b> += <b>hash</b> << 10; <b>hash</b> ^= <b>hash</b> >> 6; } <b>hash</b> += <b>hash</b> << 3; <b>hash</b> ^= <b>hash</b> >> 11; <b>hash</b> += <b>hash</b> << 15; return hash;} ...|$|R
5000|$|... <b>hash</b> = 0 {{for each}} octet_of_data to be <b>hashed</b> <b>hash</b> = <b>hash</b> × FNV_prime <b>hash</b> = <b>hash</b> XOR octet_of_data return <b>hash</b> ...|$|R
50|$|Binary <b>hash</b> {{chains are}} {{commonly}} used in association with a <b>hash</b> tree. A Binary <b>hash</b> chain takes two <b>hash</b> values as inputs, concatenates them and applies a <b>hash</b> function to the result, thereby producing a third <b>hash</b> value.|$|R
5|$|Perl takes lists from Lisp, <b>hashes</b> ("associative arrays") from AWK, {{and regular}} {{expressions}} from sed. These simplify and facilitate many parsing, text-handling, and data-management tasks. Also shared with Lisp are the implicit {{return of the}} last value in a block, {{and the fact that}} all statements have a value, and thus are also expressions and can be used in larger expressions themselves.|$|E
5|$|The {{interpreter}} has an object-oriented architecture. All of {{the elements}} of the Perl language—scalars, arrays, <b>hashes,</b> coderefs, file handles—are represented in the interpreter by C structs. Operations on these structs are defined by a large collection of macros, typedefs, and functions; these constitute the Perl C API. The Perl API can be bewildering to the uninitiated, but its entry points follow a consistent naming scheme, which provides guidance to those who use it.|$|E
25|$|A client {{that does}} key pinning adds an extra step beyond the normal X.509 {{certificate}} validation: After obtaining the server's certificate {{in the standard}} way, the client checks the public key(s) in the server's certificate chain against a set of (<b>hashes</b> of) public keys for the server name. Typically the public key <b>hashes</b> are bundled with the application. For example, Google Chrome includes public key <b>hashes</b> for the *.google.com certificate that detected fraudulent certificates in 2011. (Chromium does not enforce the hardcoded key pins.) Since then, Mozilla has introduced public key pinning to its Firefox browser.|$|E
50|$|Multiplicative <b>hashing</b> is {{a simple}} type of <b>hash</b> {{function}} often used by teachers introducing students to <b>hash</b> tables. Multiplicative <b>hash</b> functions are simple and fast, but have higher collision rates in <b>hash</b> tables than more sophisticated <b>hash</b> functions.|$|R
5000|$|Murmur3_32(key, len, seed) // Note: In this version, all integer {{arithmetic}} {{is performed}} with unsigned 32 bit integers. // In {{the case of}} overflow, the result is constrained by the application of modulo [...] arithmetic. [...] c1 &larr; 0xcc9e2d51 c2 &larr; 0x1b873593 r1 &larr; 15 r2 &larr; 13 m &larr; 5 n &larr; 0xe6546b64 [...] <b>hash</b> &larr; seed [...] for each fourByteChunk of key k &larr; fourByteChunk [...] k &larr; k &times; c1 k &larr; (k ROL r1) k &larr; k &times; c2 [...] <b>hash</b> &larr; <b>hash</b> XOR k <b>hash</b> &larr; (<b>hash</b> ROL r2) <b>hash</b> &larr; <b>hash</b> &times; m + n [...] with any remainingBytesInKey remainingBytes &larr; SwapToLittleEndian(remainingBytesInKey) // Note: Endian swapping is only necessary on big-endian machines. // The purpose is to place the meaningful digits towards {{the low end of}} the value, // so that these digits have the greatest potential to affect the low range digits // in the subsequent multiplication. Consider that locating the meaningful digits // in the high range would produce a greater effect upon the high digits of the // multiplication, and notably, that such high digits are likely to be discarded // by the modulo arithmetic under overflow. We don't want that. [...] remainingBytes &larr; remainingBytes &times; c1 remainingBytes &larr; (remainingBytes ROL r1) remainingBytes &larr; remainingBytes &times; c2 [...] <b>hash</b> &larr; <b>hash</b> XOR remainingBytes [...] <b>hash</b> &larr; <b>hash</b> XOR len [...] <b>hash</b> &larr; <b>hash</b> XOR (<b>hash</b> >> 16) <b>hash</b> &larr; <b>hash</b> &times; 0x85ebca6b <b>hash</b> &larr; <b>hash</b> XOR (<b>hash</b> >> 13) <b>hash</b> &larr; <b>hash</b> &times; 0xc2b2ae35 <b>hash</b> &larr; <b>hash</b> XOR (<b>hash</b> >> 16) ...|$|R
50|$|Often, an {{additional}} <b>hash</b> of the <b>hash</b> list itself (a top <b>hash,</b> also called root <b>hash</b> or master <b>hash)</b> is used. Before downloading a file on a p2p network, {{in most cases}} the top <b>hash</b> is acquired from a trusted source, for instance a friend or a web site that is known to have good recommendations of files to download. When the top <b>hash</b> is available, the <b>hash</b> list can be received from any non-trusted source, like any peer in the p2p network. Then the received <b>hash</b> list is checked against the trusted top <b>hash,</b> and if the <b>hash</b> list is damaged or fake, another <b>hash</b> list from another source will be tried until the program finds one that matches the top <b>hash.</b>|$|R
25|$|These <b>hashes</b> {{are used}} on Direct Connect and G2 (Gnutella2), among others.|$|E
25|$|Supported by G2 (Gnutella2), such <b>hashes</b> are {{vulnerable}} to hash collision attacks.|$|E
25|$|Enhancement in the client's and server's {{ability to}} specify which <b>hashes</b> and {{signature}} algorithms they accept.|$|E
40|$|Abstract — Sensors {{and other}} small devices that {{periodically}} transmit relatively small packets of information motivate the study of <b>hash</b> chains with small domains and ranges. <b>Hash</b> chain based protocols work using deferred disclosure and it is often assumed their <b>hash</b> functions are one-way, hence essentially unbreakable. However small domains and ranges make <b>hash</b> functions much weaker. If a deterministic <b>hash</b> function’s domain and range are the same and both are very small, then {{it may not be}} possible for the <b>hash</b> function to be one-way. In fact, <b>hash</b> chains with size-constrained domains and ranges are likely to cycle quickly. This paper proposes a solution to this challenge- the general <b>hash</b> chain construction. A general <b>hash</b> chain uses several subsequent <b>hash</b> elements at once as input to produce each output <b>hash</b> element. General <b>hash</b> chains have the following properties: (1) repeated <b>hash</b> elements do not necessarily indicate cycles in the <b>hash</b> chain, (2) subsequent elements of these <b>hash</b> chains do not have exponentially diminishing ranges. This makes general <b>hash</b> chains alluring for devices with size constraints on their domains and ranges. I...|$|R
50|$|People {{who write}} {{complete}} <b>hash</b> table implementations choose a specific <b>hash</b> function—such as a Jenkins <b>hash</b> or Zobrist hashing—and independently choose a hash-table collision resolution scheme—such ascoalesced hashing,cuckoo <b>hashing,</b> orhopscotch <b>hashing.</b>|$|R
40|$|In this paper, {{we present}} a new {{construction}} for strong separating <b>hash</b> families by using hypergraphs and obtain some optimal separating <b>hash</b> families. We also improve some previously known bounds of separating <b>hash</b> families. Comment: <b>Hash</b> family, separating <b>hash</b> family, strong separating <b>hash</b> family, hypergrap...|$|R
25|$|Multiple {{files and}} their URNs, names and <b>hashes</b> in the Magnet link can be {{included}} {{by adding a}} count number preceded by a dot (".") to each link parameter.|$|E
25|$|Git uses SHA-1 <b>hashes</b> internally. Linus Torvalds {{has responded}} that the hash was mostly {{to guard against}} {{accidental}} corruption, and the security a cryptographically secure hash gives was just an accidental side effect, with the main security being signing elsewhere.|$|E
25|$|Kademlia is a {{distributed}} {{hash table}} for decentralized peer-to-peer computer networks designed by Petar Maymounkov and David Mazières in 2002. It specifies {{the structure of}} the network and the exchange of information through node lookups. Kademlia nodes communicate among themselves using UDP. A virtual or overlay network is formed by the participant nodes. Each node is identified by a number or node ID. The node ID serves not only as identification, but the Kademlia algorithm uses the node ID to locate values (usually file <b>hashes</b> or keywords). In fact, the node ID provides a direct map to file <b>hashes</b> and that node stores information on where to obtain the file or resource.|$|E
50|$|In {{the top of}} a <b>hash</b> tree {{there is}} a top <b>hash</b> (or root <b>hash</b> or master <b>hash).</b> Before {{downloading}} a file on a p2p network, in most cases the top <b>hash</b> is acquired from a trusted source, for instance a friend or a web site that is known to have good recommendations of files to download. When the top <b>hash</b> is available, the <b>hash</b> tree can be received from any non-trusted source, like any peer in the p2p network. Then, the received <b>hash</b> tree is checked against the trusted top <b>hash,</b> and if the <b>hash</b> tree is damaged or fake, another <b>hash</b> tree from another source will be tried until the program finds one that matches the top <b>hash.</b>|$|R
50|$|The {{problem of}} optimal static <b>hashing</b> was first solved in general by Fredman, Komlós and Szémeredi. In their 1984 paper, they detail a two-tiered <b>hash</b> table scheme {{in which each}} bucket of the (first-level) <b>hash</b> table {{corresponds}} to a separate second-level <b>hash</b> table. Keys are <b>hashed</b> twice—the first <b>hash</b> value maps to a certain bucket in the first-level <b>hash</b> table; the second <b>hash</b> value gives the position of that entry in that bucket's second-level <b>hash</b> table. The second-level table is guaranteed to be collision-free (i.e. perfect <b>hashing)</b> upon construction. Consequently, the look-up cost is guaranteed to be O(1) in the worst-case.|$|R
3000|$|Furthermore, we plan {{to explore}} the {{variations}} of the current FJLT <b>hashing.</b> Similar to the NMF-based <b>hashing</b> approach (referred as NMF-NMF-SQ <b>hashing</b> in [16]) where the <b>hash</b> {{is based on a}} two-stage application of NMF, we can modify the proposed FJLT <b>hashing</b> into a two-stage FJLT-based <b>hashing</b> approach by introducing a second stage of FJLT as follows. Treat the intermediate <b>hash</b> [...]...|$|R
25|$|The {{birthday}} {{problem in}} this more generic sense applies to hash functions: the expected number of N-bit <b>hashes</b> that can be generated before getting a collision is not 2N, but rather only 2N/2. This is exploited by birthday attacks on cryptographic hash functions and {{is the reason why}} a small number of collisions in a hash table are, for all practical purposes, inevitable.|$|E
25|$|In November 2014, {{phishing}} {{attacks on}} ICANN. Notably, administrative {{access to the}} Centralized Zone Data System was gained, allowing the attacker to get zone files, and data about users in the system, such as their real names, contact information, and salted <b>hashes</b> of their passwords. Access was also gained to ICANN's public Governmental Advisory Committee wiki, blog, and whois information portal.|$|E
25|$|Sometimes, if {{part of the}} {{software}} generating the CAPTCHA is client-side (the validation is done on a server but the text that the user is required to identify is rendered on the client side), then users can modify the client to display the un-rendered text. Some CAPTCHA systems use MD5 <b>hashes</b> stored client-side, which may leave the CAPTCHA vulnerable to a brute-force attack.|$|E
50|$|Double <b>hashing</b> is a {{computer}} programming technique used in <b>hash</b> tables to resolve <b>hash</b> collisions, in cases when two different values to be searched for produce the same <b>hash</b> key. It is a popular collision-resolution technique in open-addressed <b>hash</b> tables. Double <b>hashing</b> is implemented in many popular libraries.|$|R
30|$|<b>Hashing</b> time: calculating <b>hash</b> {{value is}} the main step of the query. The <b>hashing</b> time means the time {{consumed}} by applying <b>hash</b> functions.|$|R
40|$|This paper {{discusses}} a generalised incremental <b>hashing</b> {{scheme for}} explicit state model checkers. The <b>hashing</b> scheme has been implemented {{into the model}} checker Spin. The incremental <b>hashing</b> scheme works for Spin’s exhaustive and both approximate verification modes: bitstate <b>hashing</b> and <b>hash</b> compaction. An implementation is provided for 32 -bit and 64 -bit architectures. We performed extensive experiments on the BEEM benchmarks to compare the incremental <b>hash</b> functions against Spin’s traditional <b>hash</b> functions. In almost all cases, incremental <b>hashing</b> is faster than traditional <b>hashing.</b> The amount of performance gain depends on several factors, though. We conclude that incremental <b>hashing</b> performs best for the (64 -bits) Spin’s bitstate <b>hashing</b> mode, on models with large state vectors, and using a verifier, that is optimised by the C compiler...|$|R
25|$|Google combats child {{pornography}} through Gmail's servers {{in conjunction with}} the National Center for Missing & Exploited Children (NCMEC) to find children suffering abuse around the world. In collaboration with the NCMEC, Google creates a database of {{child pornography}} pictures. Each one of the images is given a unique numerical number known as a hash. Google then scans Gmail looking for the unique <b>hashes.</b> When suspicious images are located Google reports the incident to the authorities.|$|E
25|$|The free {{user account}} {{includes}} {{access to all}} the main features listed below. Registered Users are also able to send and receive private messages. In March 2012, the music website Last.fm was hacked and 43 million user accounts were exposed. Whilst Last.fm knew of an incident back in 2012, the scale of the hack was not known until the data was released publicly in September 2016. The breach included 37 million unique email addresses, usernames and passwords stored as unsalted MD5 <b>hashes.</b>|$|E
25|$|In Windows XP and later, {{there is}} no default local Data Recovery Agent and no {{requirement}} to have one. Setting SYSKEY to mode 2 or 3 (syskey typed in during bootup or stored on a floppy disk) will mitigate the risk of unauthorized decryption through the local Administrator account. This is because the local user's password <b>hashes,</b> stored in the SAM file, are encrypted with the Syskey, and the Syskey value is not available to an offline attacker who does not possess the Syskey passphrase/floppy.|$|E
3000|$|A <b>hash</b> {{function}}, {{also called}} a <b>hash</b> function or a <b>hash</b> function, {{is a public}} function that maps any long message to a shorter, fixed-length value as a qualifier, called a <b>hash</b> value, <b>hash</b> code, or message digest. A <b>hash</b> value {{is a function of}} all bits in a message, thus providing an error detection capability that alters the <b>hash</b> value by altering any bit or bits in the message. The definition of the <b>hash</b> function is given below: [...]...|$|R
40|$|Abstract — In this paper, a novel {{multimedia}} {{identification system}} based on quantum <b>hashing</b> is considered. Many traditional systems are based on binary <b>hash</b> which is obtained by encoding intermediate <b>hash</b> extracted from multimedia content. In the system considered, the intermediate <b>hash</b> values extracted from a query are encoded into quantum <b>hash</b> values by incorporating uncertainty in the binary <b>hash</b> values. For this, the intermediate <b>hash</b> difference between the query and its true-underlying content is considered as a random process. Then, the uncertainty {{is represented by the}} probability density estimate of the intermediate <b>hash</b> difference. The quantum <b>hashing</b> system is evaluated using both audio and video databases, and with marginal increment in computational cost, the quantum <b>hashing</b> system is shown to be more robust against various distortions than the binary <b>hashing</b> system using the same intermediate <b>hash</b> values...|$|R
40|$|International audienceMany multidimensional <b>hashing</b> schemes {{have been}} {{actively}} studied in recent years, providing efficient nearest neighbor search. Generally, we can distinguish several <b>hashing</b> families, such as learning based <b>hashing,</b> which provides better <b>hash</b> function selectivity by learning the dataset distribution. The spacial <b>hashing</b> family proposes a suitable partition of the multidimensional space, more adapted to data points distribution. In {{spite of the}} efficiency of multidimensional <b>hashing</b> techniques to solve the nearest neighbor search problem, these techniques suffer from scalabity issues. In this paper, we propose a novel <b>hashing</b> algorithm, named Cluster Based Data Oriented <b>Hashing,</b> that combines space <b>hashing</b> and learning based <b>hashing</b> techniques. The proposed approach applies first a clustering algorithm for structuring the multidimensional space into clusters. Then, in each cluster, a learning based <b>hashing</b> algorithm is applied by selecting an appropriate <b>hash</b> function that fits the data distribution. Experimental comparisons with standard Euclidean Locality Sensitive <b>Hashing</b> demonstrate {{the effectiveness of the}} proposed method for large dataset...|$|R
