491|312|Public
25|$|Metropolitan Kathmandu {{is divided}} into five sectors: the Central Sector, the East Sector, the North Sector, the City Core and the West Sector. For civic administration, the city is further divided into 35 {{administrative}} wards. The Council administers the Metropolitan area of Kathmandu city through its 177 elected representatives and 20 nominated members. It holds biannual meetings to review, process and approve the annual budget and make major policy decisions. The ward's profile documents for the 35 wards prepared by the Kathmandu Metropolitan Council is detailed and provides information for each ward on population, the structure and condition of houses, the type of roads, educational, health and financial institutions, entertainment facilities, parking space, security provisions, etc. It also includes lists of development projects completed, on-going and planned, along with <b>informative</b> <b>data</b> about the cultural heritage, festivals, historical sites and the local inhabitants. Ward 16 is the largest, with an area of 437.4ha; ward 26 is the smallest, with an area of 4ha.|$|E
50|$|Typically, {{normative}} is {{contrasted with}} informative (referring to the standard's descriptive, explanatory or positive content). <b>Informative</b> <b>data</b> is supplemental {{information such as}} additional guidance, supplemental recommendations, tutorials, commentary as well as background, history, development, and relationship with other elements. <b>Informative</b> <b>data</b> is not a requirement and doesn’t compel compliance.|$|E
50|$|Anas is {{a co-founder}} of BLINDSPOT, a {{socio-economic}} think tank, a group of concerned citizens voicing out {{the voice of the}} voiceless - presenting critical, <b>informative</b> <b>data</b> and facts often missed.|$|E
40|$|We {{present a}} method for {{discovering}} <b>informative</b> patterns from <b>data.</b> With this method, large databases {{can be reduced to}} only a few representative data entries. Our framework also encompasses methods for cleaning databases containing corrupted data. Both on-line and off-line algorithms are proposed and experimentally checked on databases of handwritten images. The generality of the framework makes it an attractive candidate for new applications in knowledge discovery. Keywords: knowledge discovery, machine learning, <b>informative</b> patterns, <b>data</b> cleaning, information gain. 4. ...|$|R
40|$|Master of Public HealthDepartment of Diagnostic Medicine and PathobiologyPatricia A. PayneAs {{ecological}} niche modeling (ENM) evolves {{as a tool}} in epidemiology and public health, refinement of occurrence data, and selection of the most appropriate and <b>informative</b> environmental <b>data</b> sets becomes increasingly important. In this report, a previous ENM analysis predicting the potential distribution of human monkeypox in Africa is reassessed using refined georeferencing criteria, and use of a more diverse set of environmental data, {{in order to identify}} environmental parameters contributing to monkeypox ecology. Significant environmental variables included annual precipitation, several temperature-related variables, net primary productivity, potential evaoptranspiration, solid moisture, soil pH, and two monthly NDVI variables. Our results emphasize the importance of selecting the most appropriate and <b>informative</b> environmental <b>data</b> for ENM analysis...|$|R
40|$|As ecologic niche {{modeling}} (ENM) evolves {{as a tool}} in spatial {{epidemiology and}} public health, selection of the most appropriate and <b>informative</b> environmental <b>data</b> sets becomes increasingly important. Here, we build on a previous ENM analysis of the potential distribution of human monkeypox in Africa by refining georeferencing criteria and using more-diverse environmental data to identify environmental parameters contributing to monkeypox distributional ecology. Significant environmental variables include annual precipitation, several temperature-related variables, primary productivity, evapotranspiration, soil moisture, and pH. The potential distribution identified with this set of variables was broader than that identified in previous analyses but does not include areas recently found to hold monkeypox in southern Sudan. Our results {{emphasize the importance of}} selecting the most appropriate and <b>informative</b> environmental <b>data</b> sets for ENM analyses in pathogen transmission mapping...|$|R
5000|$|System {{identification}} uses {{statistical methods}} to build mathematical models of dynamical systems from measured data. System identification {{also includes the}} optimal design of experiments for efficiently generating <b>informative</b> <b>data</b> for fitting such models.|$|E
50|$|The {{field of}} system {{identification}} uses statistical methods to build mathematical models of dynamical systems from measured data. System identification {{also includes the}} optimal design of experiments for efficiently generating <b>informative</b> <b>data</b> for fitting such models as well as model reduction.|$|E
5000|$|Statistical theory {{provides}} {{a guide to}} comparing methods of data collection, {{where the problem is}} to generate <b>informative</b> <b>data</b> using optimization and randomization while measuring and controlling for observational error. Optimization of data collection reduces the cost of data while satisfying statistical goals, while randomization allows reliable inferences. Statistical theory {{provides a}} basis for good data collection and the structuring of investigations in the topics of: ...|$|E
30|$|For the orientation, we {{have chosen}} {{inclinometer}} because the obtained data from this sensor are more <b>informative</b> and compass <b>data</b> are changing due to magnetic strength.|$|R
40|$|Maximum {{likelihood}} estimation in nite mixture distributions {{is typically}} approached as an incomplete data problem to allow {{application of the}} Expectation-Maximization (EM) algorithm. In its general formulation, the EM algorithm involves {{the notion of a}} complete data space, in which the observed measurements and incomplete data are embedded. An advantage is that many dicult estimation problems are facilitated when viewed in this way. One drawback is that the simultaneous update used by standard EM requires overly <b>informative</b> complete <b>data</b> spaces, which leads to slow convergence in some situations. In the incomplete data context, {{it has been shown that}} the use of less <b>informative</b> complete <b>data</b> spaces, or equivalently smaller missing data spaces, can lead to faster convergence without sacrifying simplicity. However, in the mixture case, little progress has been made in speeding up EM. In this paper we propose a component-wise EM for mixtures. It uses, at each iteration, the smallest ad [...] ...|$|R
30|$|The default of {{the bank}} is modeled as a totally {{unpredictable}} time τ calibrated to the bank CDS spread, which we view as the most reliable and <b>informative</b> credit <b>data</b> regarding anticipations of markets participants about future recapitalization, government intervention, etc. Assuming instantaneous liquidations upon defaults, the time horizon of the model is τ̅=τ∧ T, where T is the final maturity of the portfolio.|$|R
50|$|In {{practice}} , no progressive organisation {{can afford}} to remain stuck {{to any one of}} these value chains. In order to cover both market spaces (physical world and cyber world), organisations need to deploy their very best practices in both of these spaces to churn out the most <b>informative</b> <b>data,</b> which can further be used to improve the ongoing products/services or to develop some new product/service. Hence organisations today try to employ the combined value chain.|$|E
50|$|FORR {{does not}} have perfect {{knowledge}} of how to solve a problem, but instead learns from experience. Intelligent agents are not optimal, but make decisions based on only a subset of all possible good reasons and <b>informative</b> <b>data.</b> These agents can still be considered rational. This idea of bounded rationality was introduced by Herbert A. Simon, who along with Allen Newell developed the early foundations of the study of cognitive architectures and also inspired early architectures such as Soar and ACT-R.|$|E
50|$|Kinetic {{parameters}} are frequently determined from experimental data via nonlinear estimation. Sensitivity analysis {{can be used}} for optimal experimental design, e.g. determining initial conditions, measurement positions, and sampling time, to generate <b>informative</b> <b>data</b> which are critical to estimation accuracy. A great number of parameters in a complex model can be candidates for estimation but not all are estimable. Sensitivity analysis can be used to identify the influential parameters which can be determined from available data while screening out the unimportant ones. Sensitivity analysis {{can also be used to}} identify the redundant species and reactions allowing model reduction.|$|E
50|$|The {{historical}} background of Philippians is traditionally gathered from two main primary New Testament sources: <b>informative</b> internal <b>data</b> from the letter itself, and related information garnered {{from the rest}} of the New Testament Canon, especially from the Acts of the Apostles and the other Pauline Epistles. Other primary information is also derived from external historical sources related to the chronological connections between Paul's association with Philippi, its political and economical setting, and its social and religio-philosophical context.|$|R
30|$|This study {{provides}} preliminary {{evidence that a}} trial protocol with more complete details on the PRO endpoint may {{reduce the risk of}} avoidable missing PRO data. Poor compliance led to non-reporting of PROs for 2 RCTs, meaning that efforts invested into PRO data collection for these RCTs was wasted as the PRO data cannot possibly impact patient care. It also provides evidence that the reporting of PROs requires improvement, particularly reporting of the rates, reasons and impact of missing PRO data. Given that rates of avoidable and <b>informative</b> missing PRO <b>data</b> were quite high in this sample, clear reporting is crucial and should include a transparent discussion of generalisability concerns in light of avoidable and <b>informative</b> missing <b>data.</b> Investigators should refer to the forthcoming SPIRIT-PRO Extension [23] to develop PRO aspects of trial protocols with clear strategies to minimise the missing data, as well as the CONSORT-PRO guidance for reporting [20]. Such efforts will ensure high-quality PRO findings are accurately interpreted and can meaningfully impact patient care.|$|R
40|$|Motivation: Rapidly {{expanding}} repositories {{of highly}} <b>informative</b> genomic <b>data</b> have generated increasing interest in methods for protein function prediction and inference of biological networks. The successful application of {{supervised machine learning}} to these tasks requires a gold standard for protein function: a trusted set of correct examples, {{which can be used}} to assess performance through cross-validation or other statistical approaches. Since gene annotation is incomplete for even the best studied model organisms, the biological reliability of such evaluations may be called into question...|$|R
5000|$|A more <b>informative</b> <b>data</b> {{source is}} the organic microfossils of the Mount Cap formation, Mackenzie Mountains, Canada. This late Early Cambrian {{assemblage}} (...) consists of microscopic fragments of arthropods' cuticle, which is left behind when the rock is dissolved with hydrofluoric acid. The diversity of this assemblage {{is similar to}} that of modern crustacean faunas. Most interestingly, analysis of fragments of feeding machinery found in the formation shows that it was adapted to feed in a very precise and refined fashion. This contrasts with most other early Cambrian arthropods, which fed messily by shovelling anything they could get their feeding appendages on into their mouths. This sophisticated and specialised feeding machinery belonged to a large (about 30 cm) organism, and would have provided great potential for diversification; specialised feeding apparatus allows a number of different approaches to feeding and development, and creates a number of different approaches to avoid being eaten.|$|E
50|$|Kathmandu Municipal Corporation, {{abbreviated}} KMC, is {{the chief}} nodal agency for the administration of Kathmandu. The Municipality of Kathmandu was upgraded to incorporated in 1994.Metropolitan Kathmandu is divided into five sectors: the Central Sector, the East Sector, the North Sector, the City Core and the West Sector. For civic administration, the city is further divided into 35 administrative wards. The Council administers the Metropolitan area of Kathmandu city through its 177 elected representatives and 20 nominated members. It holds biannual meetings to review, process and approve the annual budget and make major policy decisions. The ward's profile documents for the 35 wards prepared by the Kathmandu Metropolitan Council is detailed and provides information for each ward on population, the structure and condition of houses, the type of roads, educational, health and financial institutions, entertainment facilities, parking space, security provisions, etc. It also includes lists of development projects completed, on-going and planned, along with <b>informative</b> <b>data</b> about the cultural heritage, festivals, historical sites and the local inhabitants. Ward 16 is the largest, with an area of 437.4 ha; ward 26 is the smallest, with an area of 4 ha.|$|E
5000|$|In her various {{research}} projects {{there is a}} strong consumer orientation that emphasizes the need to provide extensive protection to banking customers. Accordingly, she favors the side of imposing strict ethical rules on the banks and the financial institutions regarding the relationship with their customers. However, she warns against imposing too wide a responsibility on the financial institutions, and she aims for a balance between the interests of the parties, while acknowledging the importance of maintaining the stability of the banking and the financial system. One of her latest contributions is the imposition of a “duty of disclosure in the broad sense” on the banks. This duty includes not only providing <b>informative</b> <b>data</b> relating to a transaction, but also the duty to provide a broad explanation which includes a reference to all aspects of the transaction, as well as a duty to ensure - as far as possible - that the customer has indeed understood the nature of the transaction and agreed thereto. [...] She proposes expanding the “broad duty of disclosure” to apply to guarantors and mortgagors as well. Her approach has been adopted by the Supreme Court in various rulings.|$|E
40|$|A {{mathematical}} {{model has been}} developed for an enzymatic process with kinetically controlled synthesis. Model reduction and detailed system analysis have been undertaken to examine the main properties of this enzyme reaction system. Optimal experimental design (OED) is developed to obtain the experimental conditions that will generate the most <b>informative</b> measurement <b>data</b> for parameter estimation. Both single-input and multiple-inputs optimisation strategies have been investigated {{to determine the best}} intensity levels of control inputs. The results demonstrate that parameter estimation quality can be improved through proper model-based experimental design...|$|R
40|$|Mobile telephones, company ID badges, {{and similar}} common devices form a sensor network {{which can be}} used to map human activity, and {{especially}} human interactions. The most <b>informative</b> sensor <b>data</b> seem to be measurements of personto-person proximity, and statistics of vocalization and body movement measurements. Using this data to model individual behavior as a stochastic process allows prediction of future activity, with the greatest predictive power obtained by modeling the interactions between individual processes. Experiments show that between 40 % and 95 % of the variance in human behavior may be explained by such models...|$|R
40|$|A {{stochastic}} epidemic {{model is}} proposed which incorporates heterogeneity {{in the spread}} of a disease through a population. In particular, three factors are considered: the spatial location of an individual’s home and the household and school class to which the individual belongs. The model is applied to an extremely <b>informative</b> measles <b>data</b> set and the model is compared with nested models, which incorporate some, but not all, of the aforementioned factors. A reversible jump Markov chain Monte Carlo algorithm is then introduced which assists in selecting the most appropriate model to fit the data...|$|R
40|$|Incremental concept {{learning}} algorithms using backtracking have to store previous data. These {{data can be}} ordered by the "is more specific than " relation. Using this order only the most <b>informative</b> <b>data</b> have to be stored, and the less <b>informative</b> <b>data</b> can be discarded. Moreover, under certain conditions some data can be replaced by automatically generated, more <b>informative</b> <b>data.</b> We investigate some conditions for data to be discarded, independently of the chosen {{concept learning}} algorithm or concept representation language. Then an algorithm for discarding data {{is presented in the}} framework of Iterative Versionspaces, which is a depth-first algorithm computing versionspaces as introduced by Mitchell. We update the datastructures used in the Iterative Versionspaces algorithm, while preserving its most important properties. ...|$|E
40|$|This paper {{estimates}} transition matrices for {{the ratings}} on financial institutions, using an unusually <b>informative</b> <b>data</b> set. We {{show that the}} process of rating migration exhibits significant non-Markovian behavior, {{in the sense that the}} transition intensiFinancial institutions, macroeconomic variables, capitalization, supervision, transition intensities...|$|E
40|$|Traditionally: sample then compress/aggregation I i. e., average, mean of {{the data}} or {{transform}} the data in another domain (frequency, wavelet etc) I to save energy and storage by sampling all the data first and then discarding most of them? I How to aquire <b>informative</b> <b>data</b> efficiently? [4 / 29] Shuangjiang Li, Hairong Qi, AICIP Lab “Distributed Data Aggregation for Sparse Recovery in Wireless Sensor Networks. ” DCOSS 2013 Data aquisiton in WSNs Traditionally: sample then compress/aggregation I i. e., average, {{mean of the}} data or transform the data in another domain (frequency, wavelet etc) I to save energy and storage by sampling all the data first and then discarding most of them? I How to aquire <b>informative</b> <b>data</b> efficiently...|$|E
40|$|The paper {{studies the}} returns from enterprise-related {{continuous}} vocational training on individual earnings, unemployment probabilities, and other labour market indicators in East Germany after unification. It attempts {{to solve the}} intrinsic identification problem of such evaluation problems nonparametrically by using restrictions "produced" by unification {{as well as by}} using very <b>informative</b> panel <b>data</b> (GSOEP, 1990 - 1994). The estimation is performed with nonparametric methods taking account of the panel structure. The results suggest that there are no effects with respect to employment and unemployment probabilities, but that there are large and positive earnings effects. ...|$|R
40|$|Investigations {{related to}} the {{identification}} of the most significant indicators of blood hormones {{to solve the problem of}} diagnosis of children's health. The article investigated the characteristic of medical <b>data.</b> <b>Informative</b> parameters estimated using the Pareto diagrams. Results of the study and most informative indicators are presented in the article...|$|R
40|$|Despite {{extensive}} research and numerous publications biomarkers {{have yet to}} fulfill their promise as prognostic indicators that can be widely used {{in the care of}} patients with heart failure. Specific clinical applications need to be identified for <b>informative</b> analyses of <b>data</b> that emphasize the most directly applicable measures of predictive performance...|$|R
40|$|For {{some data}} sources, a voxel-based {{representation}} can provide much more <b>informative</b> <b>data</b> visualization than the surface-based representation of conventional computer graphics. For example, the image {{data from a}} 3 D Magnetic Resonance Image (MRI) scan consists of {{a wealth of information}} about internal structure, function, an...|$|E
40|$|For difference-in-differences (DD), the {{identification}} question in using {{three types of}} progres-sively more <b>informative</b> <b>data</b> is addressed: independent cross-sections, ‘mover ’ panels, and ‘no-mover ’ panels. Although DD identifies ‘the average effect on the treated’, its meaning and {{the identification}} conditions differ across the data types...|$|E
40|$|We {{describe}} the Edinburgh-Stanford approach to task 2 of the Pascal Challenge Evaluating Machine Learning for Information Extraction, 1 the active learning task. Active learning promises {{to reduce the}} cost of supervised training by requesting the most <b>informative</b> <b>data</b> points for human annotation. The literature contains a numbe...|$|E
40|$|This article {{deals with}} the {{investigation}} of "friend or foe" regime in the pattern recognition technology {{to solve the problem}} of determining the synthesis model algorithm of the input object in multilevel monitoring information systems for the system structure coordination according to the characteristics of the object primary <b>data</b> <b>informative</b> descriptions...|$|R
30|$|Notice {{that the}} {{accuracy}} of SE results presented in Fig.  4 and Table  2 is acceptable for engineering applications. But {{it is still possible}} that high-quality SE results are unavailable considering the limited redundancy of real-time measurements and the pseudo-measurements with low accuracy. In this case, two promising solutions could be taken to enhance the SE performance: ① data-driven state estimation [37], in which <b>informative</b> historical <b>data</b> is further taken advantage of to exploit its connection with the current states, and ② (optimal) placement of PMU units that can effectively increase the SE accuracy (even though the number of PMUs is limited).|$|R
40|$|International audienceThis paper {{presents}} a {{first attempt at}} obtaining a reusable and scalable model of buildings. To this end, a university building is first modeled using EnergyPlus, an energy simulation software. The EnergyPlus model is then validated using measured temperatures in the university building. In a second part, the EnergyPlus model is used to generate <b>informative</b> input/output <b>data</b> to perform system identification techniques: a black-box model of the building is obtained. Using simulation experiments, it is showed that {{the structure of the}} black-box model can be used to model the building at different scales: a thermal zone, a floor or the whole building...|$|R
