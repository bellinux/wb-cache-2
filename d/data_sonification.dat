111|47|Public
5000|$|Data-to-Music API, a {{browser-based}} JavaScript API for real-time <b>data</b> <b>sonification</b> ...|$|E
50|$|In his {{research}} at the ICST, Maeder is working on <b>data</b> <b>sonification</b> of ecophysiological and climatic processes and studying the acoustic and aesthetic requirements for making them perceptible. Maeder contextualises his scientific and artistic {{work in the fields}} of Acoustic and Soundscape Ecology.|$|E
50|$|In 1992, the International Community for Auditory Display (ICAD) {{was founded}} by Gregory Kramer as a forum for {{research}} on auditory display which includes <b>data</b> <b>sonification.</b> ICAD has since become a home for researchers from many different disciplines interested {{in the use of}} sound to convey information through its conference and peer-reviewed proceedings.|$|E
40|$|Sonifications must match {{listener}} expectancies about representing {{data with}} sound. Three experiments showed {{the utility of}} magnitude estimation for this. In Experiment 1, 67 undergraduates judged the sizes of visual stimuli and the temperature, pressure, velocity, size, or dollars they represented. Similarly, in Experiment 2, 132 listeners judged the pitch or tempo of sounds and the data they represented. In both experiments, polarity and scaling preference depended on the conceptual data dimension. In Experiment 3, 60 listeners matched auditory graphs to data created {{with the results of}} Experiment 2, providing initial validation of scaling slopes. Magnitude estimation is proposed as a design tool in the development of <b>data</b> <b>sonifications,</b> with the level of polarity preference agreement predicting mapping effectiveness...|$|R
40|$|Good {{astronomy}} pictures, {{like those}} of the HST, play an important and wellknown role in astronomy outreach, triggering curiosity and interest. This same aim can also be achieved by means of sounds. Here we present the use of astronomy-related sounds and <b>data</b> <b>sonifications</b> to be used in astronomy outreach. These sounds, which people are unlikely to hear in the normal course of things, are a good tool for stimulating interest when teaching astronomy. In our case, sounds are successfully used in ‘‘The sounds of science,’’ a weekend science-dissemination program heard on the principal national radio station, Radio Nacional de Espan˜a (RNE). But teachers can also easily make use of these sounds in the classroom, since only a simple cassette player is needed...|$|R
40|$|Presented at the 22 nd International Conference on Auditory Display (ICAD- 2016) This paper {{presents}} {{a brief description}} of surface electromyography (sEMG), what it can be used for, {{as well as some of}} the problems associated with visual displays of sEMG <b>data.</b> <b>Sonifications</b> of sEMG <b>data</b> have shown potential for certain applications in data monitoring and movement training, however there are still challenges related to the design of these sonifications that need to be addressed. Our previous research has shown that different sonification designs resulted in better listener performance for different sEMG evaluation tasks (e. g. identifying muscle activation time vs. muscle exertion level). Based on this finding, we speculated that sonifications may benefit from being designed to be task-specific, and that integrating a task analysis into the sonification design process may help sonification designers identify intuitive and meaningful sonification designs. This paper {{presents a}} brief introduction to what a task analysis is, provides an example of how a task analysis can be used to inform sonification design, and outlines future research into a task-analysis-based approach to sonification design...|$|R
5000|$|His first <b>data</b> <b>sonification</b> work {{to receive}} {{international}} press attention was 2014s [...] "One Year of Suicides in Japan on Piano", which the The Japan Times has called a [...] "provocative composition" [...] and Wired magazine has called [...] "a haunting piano score". The sonification of Japanese suicide data {{was followed by}} similar projects mapping American crime statistics.|$|E
5000|$|The {{principal}} investigator is James L. Burch of Southwest Research Institute, assisted {{by an international}} team of investigators, both instrument leads and theory and modeling experts. [...] The Project Scientist is Thomas E. Moore of Goddard Space Flight Center. [...] Education and public outreach is a key aspect of the mission, with student activities, <b>data</b> <b>sonification,</b> and planetarium shows being developed.|$|E
5000|$|Though many {{experiments}} with <b>data</b> <b>sonification</b> have been explored in forums {{such as the}} International Community for Auditory Display (ICAD), sonification faces many challenges to widespread use for presenting and analyzing data. For example, studies show it is difficult, but essential, to provide adequate context for interpreting sonifications of data. Many sonification attempts are coded from scratch {{due to the lack}} of a flexible tool for sonification research and data exploration ...|$|E
40|$|For {{people with}} visual impairments, sound is an {{important}} information channel. The traditional accommodation for visually impaired users to access data is to rely on screen readers to speak the data in tabular forms. While speech can accurately describe information, such data presentation tends to be long and hard to realize complex information. This is particularly true in exploratory data analysis in which users often need to examine the data from different aspects. Sonification, the use of non-speech sound, has shown to help data comprehension. Previous <b>data</b> <b>sonifications</b> focus on <b>data</b> to sound attribute mapping and typically lack support for task-oriented data interaction. This dissertation makes four contributions. (1) An Action-by-Design-Component (ADC) framework guides auditory interface designs for exploratory data analysis. The framework characterizes data interaction in the auditory mode {{as a set of}} Auditory Information Seeking Actions (AISA). It also discusses design considerations for a set of Design Components to support AISAs, contrasted with actions in visualizations. (2) Applying the framework to geo-referenced statistical data, I explore its design space. Through user evaluations, effective design options were identified and insights wer...|$|R
40|$|AbstractThe ATLAS Education & Outreach project has, {{over the}} years, {{developed}} a strong reputation for supporting innovation. Animated event displays, musical CDs, 3 d movies, 3 -storey murals, photo books, <b>data</b> <b>sonifications,</b> multi-media art installations, pub slams, masterclasses, documentaries, pop-up books, LEGO® models, and virtual visits {{are among the}} many diverse methods being exploited to communicate to the world the goals and accomplishments of the ATLAS Experiment at CERN. This variety of creativity and innovation does not pop out of a vacuum. It requires underlying motivation by the collaboration {{to communicate with the}} public; freedom and encouragement to do so in a creative manner; and a support structure for developing, implementing and promoting these activities. The ATLAS Outreach project has built this support structure on a well-defined communication plan, high-quality content, and effective delivery platforms. Most importantly, implementation of the program has been based on the effective engagement of the participating institutes and other key partners, not only to leverage modest human resources and funding, but also {{to take advantage of the}} rich imagination and inspiration of a diverse, global human collaboration. We present our current plan, on-going activities, and a few more fun innovations for the future...|$|R
40|$|Auditory {{display is}} an often underutilized {{interface}} modality for conveying {{information to a}} user. However, audio has previously proven effective {{in a variety of}} use cases for information presentation and is particularly effective when the user is unable to attend to a visual interface, whether from a disability or a temporary constraint such as vehicle operation. In addition to auditory representations of <b>data</b> (<b>sonifications),</b> audio {{can also be used to}} represent a list of commands or menu within an interface. This thesis presents a concept for auditory menus that minimizes responses/inputs by the user as well as the number of tactile controls necessary. Such types of menus therefore limit simultaneous manual interactions when the user is also engaged with another demanding motor task. This approach to auditory menu interaction is referred to as a push menu and can be thought of as an alternative to more conventional auditory menus, which are referred to as pull menus. Push menus present menus in an automated sequence during which the user recognizes the desired menu item and makes a selection within a selection interval. In contrast, pull menus require that the user navigate via a combination of multiple navigation inputs and item selections. In this thesis a general hypothesis is presented that predicts that a primary visual-motor task, such as operating a vehicle, will be less negatively impacted by the secondary task of auditory menu interaction when the menu is a push menu rather than a pull menu. Ph. D...|$|R
5000|$|Polli {{works with}} {{atmospheric}} scientists to develop systems for understanding storm and climate through sound. She began collaborating with atmospheric scientists on sound and <b>data</b> <b>sonification</b> projects in 1999, {{and has worked}} with NASA's Goddard Institute Climate Research Group in New York City and the National Center for Atmospheric Research. Her New York installation Atmospherics/Weather Works was a spatialized sonification that used highly detailed models to recreate the sound of two historic east coast storms: the presidents’ Day Snowstorm of 1979 and Hurricane Bob in 1991. In 2007/2008 she spent seven weeks in Antarctica on a National Science Foundation funded project, collaborating with artist Tia Kramer, who {{was working as a}} communications operator at McMurdo Station, and other scientists. The sounds she recorded there included water pouring off a glacier and wind whipping through the valleys. Heat and the Heartbeat of the City is a series of sonifications of actual and projected climate in Central Park. [...] N. (pronounced n-point), created in collaboration with Joe Gilmore, is a real-time multi-channel sonification and visualization of weather in the Arctic.|$|E
40|$|Today energy {{consumption}} {{is one of}} the biggest world wide issues. In order to start saving money on our energy bills, it is important to be aware of our {{energy consumption}}. Also to convey/inform the data effectively,the development of <b>data</b> <b>sonification</b> is needed. <b>Data</b> <b>sonification</b> is the representation of visual graphics of data using sound and it allows the listeners to get valuable and useful information from data by using their natural listening skills. This paper will describe how sonification is important to convey the energy consumption data and also careful design is required when integrating <b>data</b> <b>sonification.</b> DECO 1013 : Sound Design and Sonificatio...|$|E
40|$|It {{has been}} {{assumed that the}} much-needed {{development}} of <b>data</b> <b>sonification</b> software would occur from the adaptation of sound synthesis software, principally that developed for computer music. As the software demands of <b>data</b> <b>sonification</b> research grow, some limitations of this approach are becoming evident. This paper outlines an extendable software framework, called SoniPy, which attempts to redress some of those limitations. 1...|$|E
40|$|Visualization of high-dimensional {{or large}} {{geometric}} data sets is inherently difficult, so we {{experiment with the}} use of audio to display the shape and connectivity of these <b>data</b> sets. <b>Sonification</b> is used as both an addition to and a substitution for the visual display. We describe a new algorithm called wave traversal that provides a necessary intermediate step to sonification of the data; it produces an ordered sequence of subsets, called waves, that allows us to map the data to time. In this paper we focus in detail on the mathematics of wave traversal, in particular, how wave traversal {{can be used as a}} discrete Morse function...|$|R
40|$|The Sonification Application and Research Toolbox (SonART) is an {{open-source}} {{effort to}} develop a platform-independent collection of methods to map <b>data</b> to <b>sonification</b> parameters. A set of graphical user interface tools that will provide practical and intuitive utilities for experimentation and auditory display. SonART aims to provide publicly available, well-documented code that will be easily adapted to address {{a broad range of}} sonification needs. The effort will build upon the Synthesis ToolKit (STK) [1]. In this paper we describe SonART’s parameter engine framework, its interface to STK, and relevant recent developments in STK. We present an example of sonified stock market data to illustrate the principles of SonART. 1...|$|R
40|$|Sonification is {{a family}} of {{representational}} techniques {{under the umbrella of}} the more general term ‘auditory display’ for revealing information in data and communicating it in a non-speech aural form – sonification makes the inaudible audible. Sonification is not bound to any particular types of data and has been applied across a diverse range of domains. In all cases the purpose of sonification is to let people gain information about the phenomenon under investigation by listening to the <b>data.</b> Fundamentally, <b>sonification</b> is concerned with causation: the sounds we hear are caused by changes in data values sampled from some underlying phenomenon or domain of enquiry...|$|R
40|$|The {{submission}} {{is about}} {{the combination of the}} report of <b>Data</b> <b>sonification</b> about the data of birth rate, the max patch, one max patch photo, and sound outputThe submission {{is about the}} combination of the report of <b>Data</b> <b>sonification</b> about the data of birth rate, the max patch, one max patch photo, and sound outputDECO 1013 : Sound Design and Sonificatio...|$|E
40|$|In this work, {{we present}} sMax a {{multimodal}} toolkit for stock market <b>data</b> <b>sonification.</b> Unlike most research focusing their effort {{primarily on the}} sonification of single stock information, sMax provides an auditory display for the user to monitor parallel distributed data. sMax uses a set of Java and Max modules to map real time stock market information into recognizable musical patterns. One of the main design goals of the toolkit is to allow low-latency controls over real-time <b>data</b> <b>sonification.</b> Because of its object-oriented architecture, sMax can be easily extended by the user when additional functionality is required. The project outcomes range from the creation of art installations to auditory display for mobile computing devices. We present the theoretical background, {{and the structure of}} the program. 1...|$|E
40|$|Maximum temperature, minimum temperature, {{amount of}} rain fall and {{anomalies}} data of Sydney's daily weather conditions in September {{are used in}} sonification. Max Patch, data, supporting graphics, and extra relevant files are included. <b>Data</b> <b>Sonification</b> of daily weather of Sydney in September 2010. DECO 1013 : Sound Design and Sonificatio...|$|E
40|$|Presented at the 11 th International Conference on Auditory Display (ICAD 2005) This paper {{deals with}} the <b>sonification</b> of log <b>data</b> {{gathered}} during a field test of an innovative toilet system. These tests {{have been carried out}} in a day care center for multiple sclerosis patients in winter 2004 / 05 in the framework of the EU funded Friendly Rest Room project (FRR). For ethical reasons, no direct observational data are at hand to validate the design concept. We will show a way to solve this dilemma by sonification of the log <b>data.</b> This <b>sonification</b> must be designed in a way that enables the researcher to reconstruct the user's actions s/he could not directly observe...|$|R
40|$|This paper {{presents}} {{novel interaction}} modes for Model-Based Soni-fication (MBS) via a multi-touch interface. We first lay out {{details about the}} constructed multi-touch surface. This {{is followed by a}} description of the <b>Data</b> Sonogram <b>Sonification</b> Model and how it is implemented using the system. Modifications from the original sonification model such as the limited space scans are described and discussed with sonification examples. Videos showing exam-ples of interaction are provided for various data sets. Beyond Data Sonograms, the presented system provides a basis for the imple-mentation of known and novel sonification models. We discuss the available interaction modes with multi-touch surfaces and how these interactions can be profitably used to control spatial and non-spatial sonification models. 1...|$|R
40|$|Presented at the 21 st International Conference on Auditory Display (ICAD 2015), July 6 - 10, 2015, Graz, Styria, Austria. In this paper, we {{describe}} a sonification system that delivers instantaneous heart rate information to an athlete. The sonification system uses a textitPolar H 7 heart rate sensor {{to monitor the}} heart rate of the user. We describe the techniques used for the processing of the captured heart rate <b>data,</b> its <b>sonification</b> and {{the relevance of the}} feedback methods via both a subjective and objective analysis. Our tests prove the strength of having a method for the sonification of instantaneous heart rate. Our testing procedure also serves as a pointer for evaluation of the efficacy of sonification methods in general...|$|R
40|$|Presented at the 10 th International Conference on Auditory Display (ICAD 2004) In this work, {{we present}} sMax a {{multimodal}} toolkit for stock market <b>data</b> <b>sonification.</b> Unlike most research focusing their effort {{primarily on the}} sonification of single stock information, sMax provides an auditory display for the user to monitor parallel distributed data. sMax uses a set of Java and Max modules to map real time stock market information into recognizable musical patterns. One of the main design goals of the toolkit is to allow low-latency controls over real-time <b>data</b> <b>sonification.</b> Because of its object-oriented architecture, sMax can be easily extended by the user when additional functionality is required. The project outcomes range from the creation of art installations to auditory display for mobile computing devices. We present the theoretical background, {{and the structure of}} the program...|$|E
40|$|Presented at the 18 th International Conference on Auditory Display (ICAD 2012) on June 18 - 21, 2012 in Atlanta, Georgia. Reprinted by {{permission}} of the International Community for Auditory Display, [URL] disciplines are applying <b>data</b> <b>sonification,</b> and what synthesis tools are they using to make the sounds? These questions are basic to understanding the state of sonification today, but they are surprisingly difficult to answer. This short review attempts to fill this gap by distilling common patterns of <b>data</b> <b>sonification</b> research. We hope that this will complement other literature reviews and give potential and current sonification researchers a sense of {{what is happening in the}} ICAD community, show where there is room for new ventures, and where there is already a lot of active research to connect with. Additionally, we put ICAD in context of other academic publications...|$|E
40|$|As {{composer}} and producer of this 7 -track digital album (2011), I am exploring {{the field of}} <b>data</b> <b>sonification</b> in that digital audio technology is employed in the systemized translation of biological processes to sound design. As an example, Primal Sound (Track 1) - inspired by Rilke’s 1919 Ur-Geräusch – converts the contour of a coronal suture into musical data thereby “tricking the phonographic needle”. Other data sources include MRI brain scans, blood cell populations during my treatment for leukaemia, microbacterial DNA and tree-ring cycles. Each track involved collaboration with experts and institutions in the relevant field, in order to inform the compositional process, as documented in the accompanying 6, 000 word liner notes. The field of <b>data</b> <b>sonification</b> has found resurgence with recent developments in digital audio technology, compositional models and in its theoretical paradigms (e. g. Fernstrom 2009 and Walker & Nees 2011), and this project aims to explore this newly-found potential. Key questions: i) How can traditional and electronic composition, <b>data</b> <b>sonification</b> and collaboration with non-musician scientists most effectively interact? ii) How can one fulfill Hermann’s 4 criteria for sonification (Hermann 2008) and produce work that is engaging {{to a range of}} listeners, reflective of the biological process and informative to ‘standard’ compositional practice? iii) Can a work resulting from <b>data</b> <b>sonification</b> be useful beyond its philosophical underpinning, i. e. work as music, disassociated from its origin, and requiring no explanation? Compositional insights and developments include: i) Isologos – the large-scale composition derived from heterogenous translation of a single contour). ii) A complex colour/DNA ‘synaesthetic’ mapping system. iii) A ‘trajectory’ technique of deriving multiple data curves from 3 -dimensional structures. iv) The creation of works which engage a range of audiences internationally in sound installations, music and science conferences, and as autonomous pieces (used in TV, radio and film) divorced from an explanatory context. Key questions: i) How can traditional and electronic composition, <b>data</b> <b>sonification</b> and collaboration with non-musician scientists most effectively interact? ii) How can one fulfill Hermann’s 4 criteria for sonification (Hermann 2008) and produce work that is engaging to a range of listeners, reflective of the biological process and informative to ‘standard’ compositional practice? iii) Can a work resulting from <b>data</b> <b>sonification</b> be useful beyond its philosophical underpinning, i. e. work as music, disassociated from its origin, and requiring no explanation? Compositional insights and developments include: i) Isologos – the large-scale composition derived from heterogenous translation of a single contour). ii) A complex colour/DNA ‘synaesthetic’ mapping system. iii) A ‘trajectory’ technique of deriving multiple data curves from 3 -dimensional structures. iv) The creation of works which engage a range of audiences internationally in sound installations, music and science conferences, and as autonomous pieces (used in TV, radio and film) divorced from an explanatory context. THe entire album - with 6, 000 word liner notes - may be accessed here: [URL]...|$|E
40|$|Presented at the 8 th International Conference on Auditory Display (ICAD), Kyoto, Japan, July 2 - 5, 2002. The Sonification Application and Research Toolbox (SonART) is an {{open-source}} {{effort to}} develop a platform-independent collection of methods to map <b>data</b> to <b>sonification</b> parameters. A set of graphical user interface tools that will provide practical and intuitive utilities for experimentation and auditory display. SonART aims to provide publicly available, well-documented code that will be easily adapted to address {{a broad range of}} sonification needs. The effort will build upon the Synthesis ToolKit (STK) [1]. In this paper we describe SonART's parameter engine framework, its interface to STK, and relevant recent developments in STK. We present an example of sonified stock market data to illustrate the principles of SonART...|$|R
40|$|Many {{sonification}} techniques use acoustic attributes such as frequency, intensity, and timbre {{to represent}} different characteristics of multidimensional data. Here we demonstrate a perceptual interaction between changes in pitch and loudness, {{as well as}} perceived asymmetries in directional change. Three experiments show that changes in loudness can influence judgments of pitch change, changes in pitch can influence loudness change, and that increases in loudness are judged to change more than equivalent decreases. Within a sonification of stock market data, these characteristics created perceptual distortions in the data set. The results imply that in situations where precision is critical, caution should be exercised when using lower level acoustic dimensions such as frequency and intensity to represent multidimensional <b>data.</b> Keywords <b>Sonification,</b> Pitch, Loudness, Perceptual Interaction, Stock Marke...|$|R
40|$|Presented at the 16 th International Conference on Auditory Display (ICAD 2010) on June 9 - 15, 2010 in Washington, DC. This paper {{describes}} a composition/sonification project {{to be realized}} by faculty and students from the Electronic Production and Design department (EP/D) at Berklee College of Music in Boston. The goal of the project is compose music for a 30 - minute interdisciplinary-networked performance to be premiered in Boston, Lyon and Havana involving artists from each city. In the process, artists are examining new modes of expression {{and the construction of}} knowledge and artistic dialog. Kelly Snook, Ph. D. Astrophysicist, Division of Solar System Exploration, NASA Goddard Spaceflight Center is working with the group to choose scientific <b>data</b> for <b>sonification</b> including compelling new planetary science and solar system data...|$|R
40|$|This paper {{describes}} {{an investigation of}} using interactive sonification (non-speech sound) to present geo-referenced statistical data to vision-impaired users for problem solving and decision making. By working with vision-impaired users, the work will identify effective interaction and sound designs for geo-referenced data, and derive principles that can guide general interactive <b>data</b> <b>sonification</b> designs for auditory information seeking...|$|E
40|$|Three {{complementary}} {{methods are}} {{used to analyze the}} dynamics of multivariate EEG data obtained from a human listening to a piece of music. The analysis yields parameters for a <b>data</b> <b>sonification</b> that conserves temporal and frequency relationships as well as wave intensities of the data. Multiple events taking place on different time scales are combined to a polyrhythmic display in real time. 1...|$|E
40|$|The data {{collection}} has two purposes: One to create data for {{an examination of}} the efficiency and compatibility of Battery PV generators with power consumption requirements of outdoor festivals and events. The other to create a <b>data</b> <b>sonification</b> based multimedia project to display this data in a multimedia artspace. Dataset contains multiple graphs and tables and raw data files in digital form...|$|E
40|$|In this paper, we {{introduce}} space filling curves (SFC) as {{a useful}} possibility to organize <b>data</b> for <b>sonification.</b> First, we give a brief overview {{about the history of}} SFCs and their graphical construction. Then we focus on the mapping properties of SFCs from 2 D to one dimension. We present the acoustic results of an implementation of the described method, in which we took the Hilbert curve as one particular example of an SFC. The actual sonification program features different methods for real-time interaction. These methods take advantage of the particular properties of SFCs. We further discuss their restrictions, how they can be circumvented, and give an outlook to future applications, where we also make suggestions as to how the properties of SFCs can be combined with methods of data reduction...|$|R
40|$|Motivated by {{the need}} for a multi-platform, {{multipurpose}} toolkit for sonifying <b>data,</b> the <b>Sonification</b> Sandbox allows users to map data to multiple auditory parameters and add context using a graphical interface. The Sonification Sandbox is a cross-platform application authored in Java, using the Java Sound API to generate MIDI output. The software allows users to independently map several data sets to timbre, pitch, volume, and pan, with full control over the default, minimum, maximum, and polarity for each attribute. It is also possible to add context to the sonification using a percussive “click track ” or a constant, repeating, or notifying tone at the minimum, maximum, or mean of a given set of data. Applications for the Sonification Sandbox include auditory display for the blind, science and mathematics education, data exploration, and experimenting with the effectiveness of various sonification techniques and parameters. 1...|$|R
40|$|Presented at the 15 th International Conference on Auditory Display (ICAD 2009), Copenhagen, Denmark, May 18 - 22, 2009 This paper {{presents}} {{novel interaction}} modes for Model-Based Soni- fication (MBS) via a multi-touch interface. We first lay out {{details about the}} constructed multi-touch surface. This {{is followed by a}} description of the <b>Data</b> Sonogram <b>Sonification</b> Model and how it is implemented using the system. Modifications from the original sonification model such as the limited space scans are described and discussed with sonification examples. Videos showing exam- ples of interaction are provided for various data sets. Beyond Data Sonograms, the presented system provides a basis for the imple- mentation of known and novel sonification models. We discuss the available interaction modes with multi-touch surfaces and how these interactions can be profitably used to control spatial and non- spatial sonification models...|$|R
