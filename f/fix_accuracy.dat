10|183|Public
50|$|During WWII, the Royal Canadian Air Force {{constructed}} Canadian Forces Base Portage la Prairie {{in support}} of the British Commonwealth Air Training Plan. The station was controlled by the RCAF but used naval personnel as high-frequency direction finding operators. The station's priority was German U-boat traffic. This site and CFB Rivers located at Rivers, Manitoba helped to increase the <b>fix</b> <b>accuracy</b> immensely.|$|E
50|$|Elektra was {{updated version}} of the beam-based low-frequency radio range (LFR) used in the United States during the 1930s. This was further {{modified}} to create Sonne by electronically rotating the signal to create a series of beams sweeping across the sky. Using simple timing of the signal, the navigator could determine the angle to the station. Two such measurements then provided a radio <b>fix.</b> <b>Accuracy</b> and range were excellent, with fixes around ¼ of a degree being possible at 1,000 miles range.|$|E
50|$|The display was {{relatively}} small, which limited resolution, {{and thus the}} determination of the delay. A measurement accuracy of 1 microsecond was quoted, which resulted in an accuracy of {{the determination of the}} correct hyperbolic to about 150 meters, and when two such measurements were combined the resulting <b>fix</b> <b>accuracy</b> was around 210 m. At longer ranges, 350 miles for example, the error ellipse was about 6 miles by 1 mile. The maximum range was about 450 miles, although several long-range fixes were made under unusual circumstances.|$|E
40|$|This paper {{considers}} {{the problem of}} sequential point estimation and <b>fixed</b> <b>accuracy</b> confidence set procedures of parameters in a stochastic regression model with random coefficients. The sequential estimator proposed {{is based on the}} least-squares estimator and is shown to be risk efficient as the cost of estimation error tends to infinity. Furthermore, the proposed procedure for fixed-width confidence set is shown to be both asymptotically consistent and asymptotically efficient as the width approaches zero. Sequential estimation <b>Fixed</b> <b>accuracy</b> confidence set Asymptotic risk efficiency Stochastic regression model with random coefficients RCA model...|$|R
40|$|Released: 17 / 01 / 2013 General Changes: Added CCPACSWingSegment::GetChordPoint to {{internal}} API Added a simple cpacs data set for accuracy testing Added some accuracy tests for getPoint functions Added support for visual leak detector Changed UnitTesting? Framework to google-test Changed TIGL linking to static for unit tests Added coverage with gcov (gcc only) to project New API Functions: tiglWingGetIndex Returns the wing index given a wing UID tiglWingGetSegmentIndex Returns the segment index given a wing segment UID tiglWingGetComponentSegmentCount Returns {{the number of}} component segments for a specific wing (selected by wing index) tiglWingGetComponentSegmentIndex Translates component segment UID into component segment index tiglWingGetComponentSegmentUID Translates component segment index into component segment UID Fixes: <b>Fixed</b> tiglWingComponentSegmentPointGetSegmentEtaXsi <b>Fixed</b> <b>accuracy</b> of CCPACSWingComponentSegment::getPoint <b>Fixed</b> <b>accuracy</b> of CCPACSWingSegment::getEta <b>Fixed</b> memory management handling of tiglWingGetProfileName Fixed memory leaks in VTK export Fixed memory leak in CCPACSFuselages TIGLViewer: Menus are enabled/disabled depending on number of wings/fuselages Added close configuration menu entry improved view rotation with middle mouse butto...|$|R
40|$|It {{is known}} that one can solve semidefinite {{programs}} to within <b>fixed</b> <b>accuracy</b> in polynomial time using the ellipsoid method (under some assumptions). In this paper it is shown that {{the same holds true}} when one uses the short step, primal interior point method. The main idea of the proof is to employ Diophantine approximation at each iteration to bound the intermediate bit sizes of iterates...|$|R
40|$|In {{order to}} {{lengthen}} the usable time {{and evaluate the}} positioning accuracy of the GPS by means of two satellites, we made a measurement at three fixed stations in Japan with a GPS receiver connected with a high stable oscillator. The usable time became about four hours longer at each station. Positioning accuracy {{was influenced by the}} accuracy of navigation messages from each satellite, so that we should not use an inaccurate satellite for positioning. By avoiding an inaccurate satellite, we attained almost the same <b>fix</b> <b>accuracy</b> as the low level positioning with three satellites...|$|E
40|$|The Arctic Ice Dynamics Joint Experiment of 1975 - 1976 used data bouys in {{conjunction}} with tracking satellites to study the interaction of Arctic Sea ice with the environment, and, more specifically, to define the motion of ice on {{the perimeter of the}} area of interest and to measure surface barometeric pressure over the same area. Charts are presented, indicating the position of the buoy array along with a table detailing buoy characteristics. The position <b>fix</b> <b>accuracy</b> of RAMS (Random Access Measurement System) buoys is discussed together with position errors due to the along-track motion of the observing satellites. Polar satellite data collection and tracking efficiency is assessed together with satellite system flexibility concepts...|$|E
40|$|The {{experimental}} program described {{included an}} evaluation of every significant factor affecting the accuracy of position fixing by range measurements from geostationary satellites. The tone-code ranging technique was found to provide a precision of roughly 0. 1 n mi at mid-lattitudes with one range measurement at L-band and one at VHF. The factors which introduce bias errors were studied analytically and experimentally, and means of rectifying the bias errors were developed. An operational system at L-band {{may be expected to}} provide position <b>fix</b> <b>accuracy</b> of 0. 1 n mi over large regions of the earth. The ranging technique developed within this program is digital, and uses a single signalling waveform and a single modem for communications and ranging...|$|E
40|$|In this paper, we {{show that}} {{efficient}} separated sum-of-exponentials approximations can be constructed for the heat kernel in any dimension. In one space dimension, the heat kernel admits an approximation involving a number of terms that is of the order O((T/δ) ((1 /ϵ) +(T/δ))) for any x∈ and δ≤ t ≤ T, where ϵ is the desired precision. In all higher dimensions, the corresponding heat kernel admits an approximation involving only O(^ 2 (T/δ)) terms for <b>fixed</b> <b>accuracy</b> ϵ. These approximations {{can be used to}} accelerate integral equation-based methods for boundary value problems governed by the heat equation in complex geometry. The resulting algorithms are nearly optimal. For N_S points in the spatial discretization and N_T time steps, the cost is O(N_S N_T ^ 2 T/δ) in terms of both memory and CPU time for <b>fixed</b> <b>accuracy</b> ϵ. The algorithms can be parallelized in a straightforward manner. Several numerical examples are presented to illustrate the accuracy and stability of these approximations. Comment: 23 pages, 5 figures, 3 table...|$|R
40|$|When {{designing}} a two-alternative classifier, one ordinarily aims {{to maximize the}} classifier's ability to discriminate between members of the two classes. We describe a situation in a real-world business application of machine-learning prediction in which an additional constraint {{is placed on the}} nature of the solution: that the classifier achieve a specified correct acceptance or correct rejection rate (i. e., that it achieve a <b>fixed</b> <b>accuracy</b> on members of one class or the other) ...|$|R
40|$|We {{address the}} {{classical}} knapsack problem and a variant {{in which an}} upper bound is imposed {{on the number of}} items that can be selected. We show that appropriate combinations of rounding techniques yield novel and powerful ways of rounding. As an application of these techniques, we present a faster polynomial time approximation scheme requiring only linear storage, that computes an approximate solution of any <b>fixed</b> <b>accuracy</b> in linear time. This linear complexity bound gives a substantial improvement of the best previously known polynomial bound [2]...|$|R
40|$|This work {{investigates the}} {{problems}} of applying GSM location methods to solve transport problems. The work covers analysis of wide selection of location methods, and contemporary location platforms. The research in location platforms has shown that current LBS systems are not completely suitable for establishing relationship between transport and location data. It is shown that geocoding, and especially reverse geocoding is critical in applying location data to solve transport problems. After qualitative analysis of contemporary location methods in context of transport information, it is suggested, that improving existing Cell-ID, Cell-ID+TA, E-CGI methods by making them more geocoding friendly could improve location <b>fix</b> <b>accuracy</b> and time. An NWAD algorithm to automatically select the best location method in GSM/UMTS networks is suggested and developed into the system for automatic cell coverage area calculations...|$|E
40|$|This paper {{explores the}} use of {{terrestrial}} time of arrival (TOA) measurements to improve the initial Global Positioning System (GPS) location <b>fix</b> <b>accuracy.</b> First, we present a geometric approach when a GPS location fix and one TOA measurement are available. Then, a more general hybrid GPS/TOA method via the Weighted Least Square Estimator (WLSE) is proposed. To simplify the calculation, a closed-form solution based on the two-step Least Square approach is also designed. The Cramer-Rao Lower Bound (CRLB) is derived as a performance benchmark. Simulation results exhibit excellent performance of the proposed methods which attain the CRLB in different scenarios. The proposed methods work even if only one TOA measurement (in addition to a GPS location fix) is available and the corresponding accuracy improvement (compared with the initial GPS location fix) can {{be as much as}} 30 %...|$|E
40|$|December 13 - 14, 2006 Siam City Hotel, Bangkok, ThailandEffects of man-made, low-frequency sounds on the {{behavior}} of the dugong are discussed in this paper. We developed a monitoring system of power-driven vessel {{to assess the impact of}} man-made noise on dugongs. Ship navigation was monitored by questionnaire for boaters and visual observations from an anchored vessel. We used automatic under water sound monitoring systems for dugongs (AUSOMS-D) to record under water sound and to track ship navigations acoustically. The visual observations were performed for a total of 10 hours and 20 minutes and 72 ships were detected. The acoustic monitoring was conducted for over 81 hours and detected 258 ships. Shortest distance between the visual-observation platform and the power-driven vessels ranged from 18 to 500 m or more. We calculated the monitoring range of the system by comparing the result of the visual observation and the acoustic survey. The system detected 51. 4 % of noise-making ships within 500 meters from the observation platform, and 78. 1 %, 89. 5 %, and 100 % within 300, 200, and 100 meters, respectively. The ship navigation showed bimodal occurrence during 6 : 00 - 7 : 00 and during 15 : 00 - 17 : 00. We could position the sound source of ship sounds and draw the pathway of a ship by using AUSOMS-D. Based on this result, we calculated the position <b>fix</b> <b>accuracy</b> of ship sound, which was 17. 1 ± 8. 71 m. This study provided information on detailed techniques for tracking the noise-making vessels and will lead to tracking the vocalizing animal, such as the dugong...|$|E
30|$|During a {{recording}} {{the data is}} stored in an upload buffer by the upload manager. This buffer {{is sent to the}} server once every minute. At the moment, the recorded sensor data is platform specific. On iOS and Windows Phone, our system only records GPS data including the user’s heading, speed and the GPS <b>fix’s</b> <b>accuracy.</b> On Android however, the app also offers the option to record the number of Bluetooth devices in the phone’s vicinity. This data offers some valuable insights into the crowd density in the user’s direct proximity.|$|R
30|$|A major {{challenge}} in CS is its current limitation to fixed-rate compression preventing it from {{operating in a}} <b>fixed</b> <b>accuracy</b> mode. In other words, the compression ratio has to be chosen before performing an in situ compression {{and has to be}} the same for all computing processes in a parallel HPC application which correspond to the different subdomains in a distributed data field. If the data contains features expressed by large gradients in the field, the choice of the compression ratio might be low resulting in a poor reconstruction.|$|R
40|$|This SAND report {{documents}} {{the results of}} an LDRD project undertaken to study the accuracy of terrain-aided navigation coupled with highly accurate topographic maps. A revolutionary new mapping technology, interferometric synthetic aperture radar (IFSAR), has the ability to make terrain maps of extremely high accuracy and spatial resolution, more than an order of magnitude better than currently available DMA map products. Using a laser altimeter and the Sandia Labs Twin Otter Radar Testbed, <b>fix</b> <b>accuracies</b> of less than 3 meters CEP were obtained over urban and natural terrain regions...|$|R
40|$|Since various {{electronic}} navigation systems, {{have been developed}} as measuring instruments of the position at sea, the position measurements can be automatically made at all times regardless of the weather and in all {{the space of the}} world. These systemes provide not only the knowledge of the right location but also very usefull pieces of information about the fishing industry, the marine survey and the exploitation of the ocean. Under these circumstances, new systems have been developed by the requirements for extension of application and high accuracy, together with the improvement of the instruments. The {{purpose of this study is}} to develope a simple and convenient system for tracking the underwater object and for recording the movement of its location continuously. As the {{electronic navigation}} system makes automatic location possible, location can be established at all times and in a wide area on the sea. The position of this object measured on the ship strongly depends upon the accuracy of the ship loca-tion also determined by the navigation system. Therefore, various locating systems were examined on their systematic and accidental errors. In addition, the accracy of position, namely its allowable error which is demanded in the fishing industry was discussed for each individual type of industry. 1. Accuracy of location in the fishing industry The accuracy of location desired in the fishing industry can be classified under two large groups. One is the case of nektonic fishes and the other is that of benthonic fishes. In the former case, a rather crude accuracy of about a nautical mile (N. M.) can be permitted. On the contrary, a systematic error less than 0. 5 N. M. and then a very small accidental error is demanded in the latter case so as to obtain high reproducibility. Especially, a minute accuracy is desired for the trawl fishing and the crab basket fishing, because the trawl-net usually go up and down in the same region and the basket of crab must be deposited like a pin point. In marine research, an error of 1 N. M. is generally good enough for a marine survey, but the systematic error within 0. 1 N. M. and high reproducibility are needed for setting an artificial fishing reef. A severe accuracy of 0. 1 N. M. also desired in the research of the behavior and ecology of fishes. 2. Valuation of various navigation systems The accuracy of astronavigation in use so far is the same as those of Loran-A and the Omega systems. However, this system takes a long time to process data and cannot be used on cloudy days even in the daytime. In addition to this, its accuracy depends on the skill of an observer. Although the radar system and the﻿ early Loran-A and C systems had similar disadvantages, these systems have made continuous measurements possible with the aid of a computer-assisted automated receiver. The accidental error of the Decca navigator system, which is recognized as the most excellent one, is as small as 0. 01 to 0. 05 N. M., so that its reproducibility is high. In spite of this, it shoud be kept in mind that its systematic error varies in a narraw region near the coast because of influence of topography on the phase of radio wave. The Omega system covering all the world lacks precision, for its systematic error ranges from 2 to 5 N. M. The intermediate system between the above two is Loran-A, for which a mean error of 1. 0 N. M. is estimated. However, improved Loran-C has an excellent reproducibility because of a small error of 0. 1 to 0. 5 N. M. The satellite navigation system having two transmitting frequencies (NNSS) gives the accurate position in a systematic error of 10 m and an accidental error of several dozen m, although it has a disadvantage that the time interval till the next measurement reach about 1 or 2 hours by the latitude of the location. The Decca system and Loran-C are most adequate for the purpose of the detection and tracking of underwater objects, because these systems provide a minute <b>fix</b> <b>accuracy</b> with a small error. The errors acompanied with these systems were examined on the land base point and experimental region of the sea. As the result, the errors range from 0. 01 to 0. 03 N. M., so that the position can be determined within an error of less than 0. 05 N. M. by compensating for the systematic error of 0. 33 N. M. for the Decca and 0. 15 N. M. for Loran-C. 3. Construction of the tracking system and its problems (1) A transmitter-receiver unit with a transponder was applied in this study. Microphone A was attanched under water alongside of the ship and microphone B was situated at a distance of 100 m from the stern. The distance between microphone B and the stern was kept constant in order to form a base line between the two microphones. The length of this base line was measured by supersonic waves and its direction was adjusted to the ship's head. The location of the transponder C was determined from the distances of three sides AB, AC and CB. The latitude and longitude of this position was evaluated on the basis of the ship's position sensor. These data were recorded on the printer, and was tracked in detail and continuously by the aid of a plotter. (2) The direction of the base line agreed with the direction of the ship's head when the ship was moving straight. Under altering course, however, these directions were different because the towing rope extending from the stern to microphone B was in a curved line. Hence, the measured values of position C had large errors in the time from the beginning to the end of a altering. Since in a state like this the duration time of a altering depended on the velocity of the ship, and of the wind, and the wind direction, etc. We measured how long the rope continued to be curved when we altered 45 ° and 90 ° at a speed of 2 knots in the case where it was calm and where there was 7 m/s wind. In conclusion, the time could be successfully cut down provided that the altering course was perform ed about 30 % beyond the scheduled angle and then taken back to the intended direction. The duration time was about 2 minutes for the altering of 45 ° and about 3 minutes for 90 °. In addition,﻿ the speedup of the ship was also effective in reducing the duration time. (3) The direction of the base line varied corresponding to the yawing of the ship's head. However, the ship's head could be treated as constant despite the yawing, so long as the towing rope was kept in a straight line. While the ship was moving straight at a constant speed of 2 knots by an automatic steering, the angle between the point B and the fore and aft line of the ship was measured with an interval of 30 seconds by the repeater of gyrocompass. The amplitude of the yawing angle in calm condition was about 2 ° and its period was about 1. 5 to 2 minutes. Since the ship was drifted to the leeward by a transverse wind with a speed of 7 m/s, the towing rope was bent windward from the fixed point on the stern. Although the mean deviation angle was about 4 ° in the case of a due transverse wind, its standard deviation was smaller than in the case of a head wind, and the ship's head was kept slightly steady direction. On the whole, the yawing ranged from 2 to 3 ° and it was safe to say the rope continued to be in nearly straight line. Therefore, ± 2 to ± 3 ° of play was allowed in the direction of ship's head for computation of the transponder position. In the case of a yawing angle greater than this value, the direction of the base line was altered and the computed position had fairly large error. 4. Accuracy of the measured distance and position (1) Along the wharf the base line between microphones A and B was fixed, and the boat was moved several hundred meters from the wharf with spaces of about 100 m, from which transponder C was hung underwater. The boat was an-chored for the measurement each time. What we got was the calculated distance that was determined by the triangulation from the base line and its included angles. We also measured distance on the basis of the method described above. The differece between the calculated distance and the distance by actual measurement was compared and discussed. The mean values were 1. 2 m for AC line and 0. 1 m for BC line respectively and the standard deviations were ± 4. 6 m and ± 4. 7 m respectively. These values of standard deviation were only 1. 4 % of the full length. The standard deviation of the difference was also estimated at every 100 m distance of AC or BC. These values fell within the range from ± 2. 6 m to ± 5. 4 m, that is, they were rather stable, hardly depending on the full length. Therefore, the ratio of the standard deviation to the full length had best be classified at 100 m or 200 m intervals of the full length. (2) The deviation of the measured position was 0. 02 N. M. on the average, and only 0. 04 N. M. even in the case of longer than 500 m. As the deviations of the horizontal axis and the vertical axis components were 23. 9 m and 11. 1 m respectively, they formed an error ellipse with the major semiaxis on the horizontal axis. The accuracy of position C was simulated by changing the angle ACB and the distance between AC and CB. As a result, we found this angle should be larger than 10 ° in order to obtain a high accuracy, that is, the distance to the underwater object should be within the range of 2 ～ 4 times longer than the base line. We also found that the difference in length between AC and CB should be less than one-half of the base line, that is, the underwater object should be nearly on the perpendicular bisector of the base line. The farther point C gets, the more important this﻿ formation becomes. 5. Experiments in tracking (1) While moving the research vessel with the transponder fixed, we measured and compared the distances between AC and CB on the system, and at the same time measured the angles ACB and CAB with the sextants. The result showed an error distribution of point C scattered within about 0. 1 N. M., although point C had been expected to be fixed. The reason was that the location of ship was determined on the Decca system and an accidental error of 0. 01 ～ 0. 02 N. M. was attributed to this equipment. Another error was a systematic error due to the change of the ship's head. (2) Another experiment similar to the above was conducted; the motorboat with transponder C under the water moved in almost parallel with the ship, and, as in the former experiment, we made use of the measuring system and the sextants and we compared the results of both. The ratio of the deviation length to the full distance was nearly equal to the above case on the whole, although the values were somewhat larger in a small range of the full distance. The mean deviation was 19. 8 ± 17. 1 m (less than 0. 02 N. M.), which corresponded to the accidental error of the Decca system. (3) The tracks both of the ship in motion and the underwater object, which were plotted on a chart, were moor smooth by aid of the Decca system as a sensor of the ship's position than by aid of the Loran-C system. This was due to the dif-ference of their accidental errors. As the accidental error of the Decca system is smaller, the track of the underwater object determined on this system was closer to the real one. Since the line between the ship and the underwater object showed both the relative direction and the distance, we could tell how good the results were by observing its changing tendencies. It can be confirmed from the experiments described above that the position of the underwater object is successfully tracked by the present method with accuracy comparable to the accidental errors of the Decca or Loran-C systems. Since the present study is restricted to the measurements of the object moving horizontally, it is necessary to make a further study of the measurements of the depth of the object, the choice of the length of the base line and the measuring techniques in an altering condition in the future. 本システムはトランスポンダを用いた応答送信方式によるトラッキング装置と船位センサとして電波航法装置を組合せたものであるが,最大の特徴は送受波器の 1 個を曳航することにより長い基準線を採用したことである。そして水中物体の移動を追跡しながら,船位を基準として相対位置を記録,図示する。その位置の精度について,各種の実験を行なった。トランスポンダと測距装置の両者を固定して,測距精度と測位精度について評価を行なった。偏差の平均値は 5 m以下,その標準偏差は 4. 7 mで,トランスポンダまでの距離が増大しても偏差の変動幅はあまり変化せず,ほぼ一定している。実測位置の偏位は 500 m以上でも 0. 04 海里にすぎず,平均で 0. 02 海里以下である。さらにトランスポンダのみを固定した場合と,両者をほぼ平行に航走しながらの追跡測定の実験を行なった。固定したトランスポンダの位置には船位の誤差が含まれるから,その位置のプロットは 1 点に集中しないが,システムによる測位と六分儀による測位の差は大分部が 25 m以下にすぎなかった。両者航走中の距離の偏差や位置の偏位は,固定点での結果とほぼ同じかやや小さくなっている。偏位の平均値は 19. 8 ± 17. 1 m(0. 02 海里) で,この値はデッカ位置の不定誤差に相当する。実際の追跡では,船位センサとしてデッカシステムを用いた場合の方が,この不定誤差が少ないからなめらかな航跡となり,水中物体の実際の移動状況に近い形で描かれている。船位からの水中物体の方位線は船首方向を基準とするから,基準線の方向と船首方向(ジィイロコース) のずれが大きくなれば,隣合う方位線が交叉する。また,実測距離の偏差が大きくて著しい偏位を生じたときも同様に方位線が交叉する。以上の各実験の結果から,本システムの測位精度は,測定距離の誤差のほか,船位センサとして用いるデッカやロランCシステムの不定誤差にも左右される。たとえ不定誤差の補正ができても船位センサの最小単位以下の測定位置の偏位は除去できない。しかし方位線の変化状況から,水中物体の移動状況や測定位置の良否の推定は可能である。従って水中物体を広範囲にわたって自由に追跡するという所期の目的を充分に達し得るといえる。なお,精度向上のためには距離ACのC点における交角θが 10 °以 下にならぬように,すなわち,基準線の 2 ～ 4 倍程度の範囲で,水中物体の位置が基準線の垂直二等分線上の付近にプロットされるように操船しながら追跡すべきである...|$|E
40|$|This paper {{addresses}} {{the problem of}} the numerical computation of generalized Mittag-Leffler functions with two parameters, with applications in fractional calculus. The inversion of their Laplace transform is an effective tool in this direction; however, the choice of the integration contour is crucial. Here parabolic contours are investigated and combined with quadrature rules for the numerical integration. An in-depth error analysis is carried out to select suitable contour's parameters, depending on the parameters of the Mittag-Leffler function, in order to achieve any <b>fixed</b> <b>accuracy.</b> We present numerical experiments to validate theoretical results and some computational issues are discussed...|$|R
40|$|Given the {{continued}} integration of intermittent renewable generators in electrical power grids, connection overloads are of increasing concern for grid operators. The risk of an overload due to injection variability {{can be described}} mathematically as a barrier crossing probability of a function of a multidimensional stochastic process. Crude Monte Carlo is a well-known technique to estimate probabilities, {{but it may be}} computationally too intensive in this case as typical modern power grids rarely exhibit connection overloads. In this paper we derive an approximate rate function for the overload probability using results from large deviations theory. Based on this large deviations approximation, we design a rare event simulation technique called splitting to estimate overload probabilities more efficiently than Crude Monte Carlo simulation. We show on example power grids with up to eleven stochastic power injections that for a <b>fixed</b> <b>accuracy</b> Crude Monte Carlo would require tens to millions as many samples than the proposed splitting technique required. We investigate the balance between accuracy and workload of three numerical approximations of the importance function. We justify the workload increase of large deviations based splitting compared to a naive one based on merely the Euclidean distance to the rare event set: for a <b>fixed</b> <b>accuracy</b> naive splitting requires over 60 times as much CPU time as large deviation based splitting. In these examples naive splitting — unlike large deviations based splitting — requires even more CPU time than CMC simulation, illustrating its pitfall. ...|$|R
5000|$|Due to the <b>fixed</b> barrel, <b>accuracy</b> is {{well above}} average, {{on par with}} higher priced pistols [...] this weapon remains popular due to its low cost and lifetime, no {{questions}} asked warranty, and extremely rugged nature.|$|R
40|$|AbstractWe {{address the}} {{classical}} knapsack problem and a variant {{in which an}} upper bound is imposed {{on the number of}} items that can be selected. We show that appropriate combinations of rounding techniques yield novel and more powerful ways of rounding. Moreover, we present a linear-storage polynomial time approximation scheme (PTAS) and a fully polynomial time approximation scheme (FPTAS) that compute an approximate solution, of any <b>fixed</b> <b>accuracy,</b> in linear time. These linear complexity bounds give a substantial improvement of the best previously known polynomial bounds [A. Caprara, et al., Approximation algorithms for knapsack problems with cardinality constraints, European J. Oper. Res. 123 (2000) 333 – 345]...|$|R
40|$|We {{address the}} {{classical}} knapsack problem and a variant {{in which an}} upper bound is imposed {{on the number of}} items that can be selected. We show that appropriate combinations of rounding techniques yield novel and more powerful ways of rounding. Moreover, we present a linear-storage Polynomial Time Approximation Scheme (PTAS) and a Fully Polynomial Time Approximation Scheme (FPTAS) that compute an approximate solution, of any <b>fixed</b> <b>accuracy,</b> in linear time. These linear complexity bounds give a substantial improvement of the best previously known polynomial bounds [2]. Keywords Knapsack problems; approximation algorithms; arithmetic and geometric rounding; reduction; FPTAS; linear time approximation scheme; dynamic programming. 1...|$|R
40|$|Multiple fixes and {{additions}} since v. 1. 2. 2. [...] skip parameter added. Allows {{users to}} skip the trimming step when "trim" option is include. Syntax: [...] skip trim [...] only_coverage option added. Allows users to provide a chloroplast genome and reads to run the coverage analysis portion of Fast-Plast. [...] Coverage used by Fast-Plast is printed to log and summary files. [...] N's allowed in coverage and IR/SC identification from scaffolding. [...] Faster runs of afin after initial coverage analysis. [...] Minimum coverage for coverage analysis no longer defaulted as 0. Now estimated as 0. 25 of average coverage across plastome. [...] General bug <b>fixes</b> <b>accuracy.</b> [...] Subsampling option added to allow for faster completion...|$|R
40|$|AbstractSequential {{procedures}} are proposed {{to estimate the}} unknown mean vector of a multivariate linear process of the form Xt − μ = ∑∞j = 0 AjZt − j, where the Zt are i. i. d. (0, Σ) with unknown covariance matrix Σ. The proposed point estimation is asymptotically risk efficient {{in the sense of}} Starr (1966, Ann. Math. Statist. 37 1173 - 1185). The <b>fixed</b> <b>accuracy</b> confidence set procedure is asymptotically efficient with prescribed coverage probability in the sense of Chow and Robbins (1965, Ann. Math. Statist. 36 457 - 462). A random central limit theorem for this process, under a mild summability condition on the coefficient matrices Aj, is also obtained...|$|R
40|$|Abstract—In {{this paper}} {{we present a}} load {{balancing}} method for parallel simulation of accuracy adaptive transaction level models. In contrast to traditional <b>fixed</b> <b>accuracy</b> TLMs, timing accuracy of adaptive TLMs changes during simulation. This makes the computation and synchronization characteristics of the models variable, and practically prohibits the use of static load balancing. To deal with this issue, we present a light-weight load balancing method which takes advantage of, and can be easily incorporated with the simulation time synchronization scheme used in parallel TLM simulation. We have developed a highperformance parallel simulation kernel based on the proposed method, and our experiments using the developed kernel show {{the effectiveness of the}} proposed approach in a realistic scenario. I...|$|R
40|$|We {{study the}} problem of {{scheduling}} a set of n independent tasks on a fixed number of parallel processors, where the execution time of a task {{is a function of}} the subset of processors assigned to the task. We propose a fully polynomial approximation scheme that for any fixed > finds a preemptive schedule of length at most (1 +) times the optimum in O(n) time. We also discuss the non-preemptive variant of the problem, and present a polynomial approximation scheme that computes an approximate solution of any <b>fixed</b> <b>accuracy</b> in linear time. In terms of the running time, this linear complexity bound gives a substantial improvement of the best previously known polynomial bound [7]...|$|R
40|$|Sequential {{procedures}} are proposed {{to estimate the}} unknown mean vector of a multivariate linear process of the form Xt - [mu] = [summation operator][infinity]j = 0 AjZt - j, where the Zt are i. i. d. (0, [Sigma]) with unknown covariance matrix [Sigma]. The proposed point estimation is asymptotically risk efficient {{in the sense of}} Starr (1966, Ann. Math. Statist. 37 1173 - 1185). The <b>fixed</b> <b>accuracy</b> confidence set procedure is asymptotically efficient with prescribed coverage probability in the sense of Chow and Robbins (1965, Ann. Math. Statist. 36 457 - 462). A random central limit theorem for this process, under a mild summability condition on the coefficient matrices Aj, is also obtained. ...|$|R
40|$|Released: 17 / 01 / 2014 Changed API: Added {{argument}} for tiglWingGetReferenceArea {{to define the}} projection plane for reference area calculations General Changes: Support for parametric CST wing profiles Logging improvements. The console verbosity can now be set independent of file logging. New API functions: tiglWingGetMAC, computes the mead aerodynamic chord length and position (thanks to Arda!) Fixes: Fixed crash in case of missing wing and fuselage profiles <b>Fixed</b> <b>accuracy</b> errors in tiglWingSegmentPointGetComponentSegmentEtaXsi and tiglWingComponentSegmentPointGetSegmentEtaXsi Fixed a warning when including tigl. h Fixed numerical bug tiglWingComponentSegmentGetSegmentIntersection TiGLViewer: Improved dialog for displaying wing component segment points Added BRep export Fixed crash on some Linux systems with strange LANG settings Added dialog showing log history {{in case of an}} erro...|$|R
30|$|The test {{problems}} proposed at CEC′ 2005 {{are based}} on classical benchmark functions such as Sphere, Rosenbrock’s, Rastrigin’s, Ackley’s and Griewank’s function. They contain difficulties such as huge number of local minima, shifted global optimum, rotated domain, noise, global optimum outside the initialization range or within a very narrow basin, and a combination of different function properties (Suganthan et al. 2005). The function f_ 15, for example, is a composition of Rastrigin’s, Weierstrass, Griewank’s, Ackley’s and Sphere functions. The selected subset of the CEC′ 2005 test problems comprises those for which {{at least one of}} the thirteen algorithms (eleven EAs, the q-G and SD methods) was capable to achieve a <b>fixed</b> <b>accuracy</b> or a target function value defined in (Suganthan et al. 2005).|$|R
40|$|A mixed {{finite element}} {{formulation}} for efficiently computing the velocity field for fluid flows in porous media is presented. Raviart Thomas (RT 0) and Brezzi Douglas Marini (BDM 1) spaces of lowest order are considered and compared both on analytic and realistic test cases. The BDM 1 space {{proves to be}} preferable to the simpler RT 0 with respect to CPU time and memory storage, if a <b>fixed</b> <b>accuracy</b> is required. The related algebraic problem has been solved either using an Uzawalike method with ad-hoc preconditioners or solving a penalized Lagrangian. These two approaches are comparable with the well known hybridization technique. Moreover, the preconditioned Uzawa system shows good convergence properties yielding a constant number of iterations versus problem size...|$|R
40|$|We outline a {{strategy}} to compute the second-loop contribution to the cSW coefficient of the Sheikoleslami-Wohlert-Wilson fermion action by means of NSPT. We also present preliminary results for higher-order integrators for the Langevin evolution within NSPT. At <b>fixed</b> numerical <b>accuracy,</b> these integrators considerably reduce the required computer-time...|$|R
40|$|When {{dealing with}} modern big data sets, {{a very common}} theme is {{reducing}} the set through a random process. These generally work by making "many simple estimates" of the full data set, and then judging them as a whole. Perhaps magically, these "many simple estimates" can provide a very accurate and small representation of the large data set. The key tool in showing {{how many of these}} simple estimates are needed for a <b>fixed</b> <b>accuracy</b> trade-off is the Chernoff-Hoeffding inequality[Che 52,Hoe 63]. This document provides a simple form of this bound, and two examples of its use. Comment: Expository document hopefully at the level of an advanced undergrad or beginning graduate student. The update corrects a missing bound on a parameter in one form of the main theore...|$|R
40|$|International audienceWe {{present a}} new flexible, fast and {{accurate}} way to implement massiveneutrinos, warm dark matter {{and any other}} non-cold dark matter relics inBoltzmann codes. For whatever analytical or numerical form of the phase-spacedistribution function, the optimal sampling in momentum space compatible with agiven level of accuracy is automatically found by comparing quadrature methods. The perturbation integration is made even faster by switching to an approximateviscous fluid description inside the Hubble radius, which differs from previousapproximations discussed in the literature. When adding one massive neutrino tothe minimal cosmological model, CLASS becomes just 1. 5 times slower, instead ofabout 5 times in other codes (for <b>fixed</b> <b>accuracy</b> requirements). We illustratethe flexibility of our approach by considering {{a few examples of}} standard ornon-standard neutrinos, as well as warm dark matter models...|$|R
40|$|In {{the event}} of non {{availability}} of GPS/GLONASS satellite, Pseudolite only system has been proposed by many researchers. Pseudolite only system has constraint in placement of Pseudolite transmitters which leads to GDOP (Geometric Dilution of Precision) value very high for typical transmitter deployment scenarios. This high value of GDOP directly affects the position <b>fixing</b> <b>accuracy</b> and consequently pseudolite based system becomes unattractive for navigation systems where transmitter deployment constraint exists. In this paper a novel approach is proposed for mitigating the effect of high GDOP by combining pseudorange differencing and Ridge regression technique. The proposed approach is modeled and simulated for a typical scenario. The accuracy improvement by the proposed approach is validated with specially configured scenario using Inverted GPS without requiring Pseudolite transmitter and receiver hardware. </p...|$|R
