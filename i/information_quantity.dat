139|785|Public
50|$|Mathematically H {{may also}} be seen as an average information, taken over the message space, because when a certain message occurs with {{probability}} pi, the <b>information</b> <b>quantity</b> −log(pi) will be obtained.|$|E
50|$|In Information-Driven Business, Robert Hillard proposes an {{approach}} to comparing the two approaches {{based on the information}} needs of the business problem. The technique shows that normalized models hold far more information than their dimensional equivalents (even when the same fields are used in both models) but this extra information comes at the cost of usability. The technique measures <b>information</b> <b>quantity</b> in terms of information entropy and usability in terms of the Small Worlds data transformation measure.|$|E
50|$|As {{expressed}} by Shannon's equation for channel information capacity, the omnipresence of noise in information systems sets a minimum signal-to-noise ratio (shortened as S/N) requirement in a channel, even when adequate spectral bandwidth is available. Since the integral {{of the rate}} of information transfer with respect to time is <b>information</b> <b>quantity,</b> this requirement leads to a corresponding minimum energy per bit. The problem of sending any given amount of information across a channel can therefore be viewed in terms of sending sufficient Information-Carrying Energy (ICE). For this reason {{the concept of an}} ICE 'pipe' or 'conduit' is relevant and useful for examining existing systems.|$|E
5000|$|... #Subtitle level 2: Relation {{to other}} quantum <b>information</b> <b>quantities</b> ...|$|R
40|$|Abstract — The linear, binary, block codes with no equally likely probabilities for {{the binary}} symbols are analyzed. The {{encoding}} graph for systematic linear block codes is proposed. These codes {{are seen as}} sources with memory and the <b>information</b> <b>quantities</b> H(S,X), H(S), H(X), H(X|S), H(S|X), I(S,X) are derived. On the base of these quantities, the code performances are analyzed. Index Terms — <b>information</b> <b>quantities,</b> linear, block codes, sources with memory. I...|$|R
40|$|A {{fascinating}} {{research program}} in neurophysiology attempts {{to quantify the}} amount of information transmitted by single neurons. The claims that emerge from this research raise new philosophical questions about the nature of information. What kind of information is being quantified? Do the resulting quantities describe empirical magnitudes like those found elsewhere in the natural sciences? In this article, it is argued that neural <b>information</b> <b>quantities</b> have a relativisitic character that makes them distinct from the kinds of information typically discussed in the philosophical literature. It is also argued that despite this relativistic character, there are cases in which neural <b>information</b> <b>quantities</b> can be viewed as robustly objective empirical properties...|$|R
50|$|Grey {{relational}} analysis (GRA), {{also called}} Deng's Grey Incidence Analysis model, {{was developed by}} a Chinese Professor Julong Deng of Huazhong University of Science and Technology. It {{is one of the}} most widely used models of Grey system theory. GRA uses a specific concept of information. It defines situations with no information as black, and those with perfect information as white. However, neither of these idealized situations ever occurs in real world problems. In fact, situations between these extremes are described as being grey, hazy or fuzzy. Therefore, a grey system means that a system in which part of information is known and part of information is unknown. With this definition, <b>information</b> <b>quantity</b> and quality form a continuum from a total lack of information to complete information - from black through grey to white. Since uncertainty always exists, one is always somewhere in the middle, somewhere between the extremes, somewhere in the grey area.|$|E
5000|$|Propaganda thrives off of what {{individuals}} {{have in common}} with others to develop patterns of behavior and modify cultural opinions. Total propaganda recognizes that within a nation individuals should all have in common a standard of living, a culture, and an ideology.The need of an average standard of living is that people must be able to afford to buy a radio, TV, a newspaper, or go to the movies. It is mostly concerned with the densest mass which is made up of average men and not the very rich or very poor. Poor cannot do this therefore they cannot be subjected to integration propaganda because the immediate concerns of daily life absorb all their capacities and efforts. The poor can only be subjected to agitation propaganda, excited to the point of theft and murder. But they cannot be trained by propaganda, kept in hand, channeled, and oriented. More advanced propaganda can influence only a man who is not completely haunted by poverty, a man who can view things from a certain distance and be reasonably unconcerned about his daily bread, who therefore can take an interest in more general matters. [...] "For propaganda to be effective the propagandee must have a certain store of ideas and a number of conditioned reflexes that can only be acquired through peace of mind springing from relative security. The establishment of a mode of common life- all this leads {{to the creation of a}} type of normal man conveniently leads all men toward that norm via a multitude of paths. Propaganda's intent is to integrate people into the normal pattern prevailing in society bring about conformance to way of life. To sum up: The creation of normalcy in our society can take one of two shapes. It can be the result of scientific, psycho-sociological analysis based on statistics- that is the American type of normalcy. It can be ideological and doctrinaire- that is the Communist type. But the results are identical: such normalcy necessarily gives rise to propaganda that can reduce the individual to the pattern most useful to society." [...] "Information" [...] Is an essential element of propaganda, which must [...] "have reference to political or economic reality" [...] to be credible. In fact, no propaganda can work until the moment when a set of facts has become a problem in the eyes of those who constitute public opinion." [...] Education permits the dissemination of propaganda in that it enables people to consume information. Information is indistinguishable from propaganda in that information is an essential element of propaganda because for propaganda to succeed it must have reference to political or economic reality. Propaganda grafts itself onto an already existing reality through [...] "informed opinion". Where no informed opinion with regard to political or economic affairs propaganda cannot exist making it an indispensable aspect. Propaganda means nothing without preliminary information that provides the basis for propaganda, gives propaganda the means to operate, and generates the problems that propaganda exploits by pretending to offer solutions. It is through information that the individual is placed in a social context and learns to understand the reality of his own situation. Information allows us to evaluate our situation feel our own personal problems are a general social problem thus enabling propaganda to entice us into social and political action. Information is most effective when it is objective and broad because it creates a general picture. With <b>information</b> <b>quantity</b> is better than quality, the more political or economic facts believed to be mastered by an individual, the more sensitive their judgment is to propaganda. In fact, only in and through propaganda do the masses have access to political economy, politics, art, or literature. The more stereotypes in a culture, the easier it is to form public opinion, and the more an individual participates in that culture, the more susceptible he becomes to the manipulation of these symbols.|$|E
40|$|The {{problem of}} the {{directionality}} of genome evolution is studied. Based on the analysis of C-value paradox {{and the evolution of}} genome size we propose that the function-coding <b>information</b> <b>quantity</b> of a genome always grows in the course of evolution through sequence duplication, expansion of code, and gene transfer from outside. The function-coding <b>information</b> <b>quantity</b> of a genome consists of two parts, p-coding <b>information</b> <b>quantity</b> which encodes functional protein and n-coding <b>information</b> <b>quantity</b> which encodes other functional elements except amino acid sequence. The evidences on the evolutionary law about the function-coding <b>information</b> <b>quantity</b> are listed. The needs of function is the motive force for the expansion of coding <b>information</b> <b>quantity</b> and the <b>information</b> <b>quantity</b> expansion is the way to make functional innovation and extension for a species. So, the increase of coding <b>information</b> <b>quantity</b> of a genome {{is a measure of the}} acquired new function and it determines the directionality of genome evolution. Comment: 16 page...|$|E
50|$|One {{reason the}} quantum {{relative}} entropy is useful is that several other important quantum <b>information</b> <b>quantities</b> are special cases of it. Often, theorems are stated {{in terms of}} the quantum relative entropy, which lead to immediate corollaries concerning the other quantities. Below, we list some of these relations.|$|R
40|$|In {{this note}} we {{introduce}} purification {{for a pair}} (ρ,Φ), where ρ is a quantum state and Φ is a channel, which allows in particular {{a natural extension of}} the properties of related <b>information</b> <b>quantities</b> (such as mutual and coherent informations) to the channels with arbitrary input and output spaces. Comment: 4 pages, LATE...|$|R
40|$|The linear, binary, block codes with no equally likely probabilities for {{the binary}} symbols are analyzed. The {{encoding}} graph for systematic linear block codes is proposed. These codes {{are seen as}} sources with memory and the <b>information</b> <b>quantities</b> H(S,X), H(S), H(X), H(X|S), H(S|X), I(S,X) are derived. On the base of these quantities, the code performances are analyzed...|$|R
40|$|The {{paper is}} devoted to the problem of integer-valued {{estimating}} of <b>information</b> <b>quantity</b> in a pixel of digital image. The definition of an integer estimation of <b>information</b> <b>quantity</b> based on constructing of the certain binary hierarchy of pixel clusters is proposed. The methods for constructing hierarchies of clusters and generating of hierarchical sequences of image approximations that minimally differ from the image by a standard deviation are developed. Experimental results on integer-valued estimation of <b>information</b> <b>quantity</b> are compared with the results obtained by utilizing of the classical formulas. Comment: 11 pages, 4 figures, 1 definition, 5 formula...|$|E
40|$|The {{problem of}} the {{directionality}} of genome evolution is studied from the information-theoretic view. We propose that the function-coding <b>information</b> <b>quantity</b> of a genome always grows {{in the course of}} evolution through sequence duplication, expansion of code, and gene transfer between genomes. The function-coding <b>information</b> <b>quantity</b> of a genome consists of two parts, p-coding <b>information</b> <b>quantity</b> which encodes functional protein and n-coding <b>information</b> <b>quantity</b> which encodes other functional elements except amino acid sequence. The relation of the proposed law to the thermodynamic laws is indicated. The evolutionary trends of DNA sequences revealed by bioinformatics are investigated which afford further evidences on the evolutionary law. It is argued that the directionality of genome evolution comes from species competition adaptive to environment. An expression on the evolutionary rate of genome is proposed that the rate is a function of Darwin temperature (describing species competition) and fitness slope (describing adaptive landscape). Finally, the problem of directly experimental test on the evolutionary directionality is discussed briefly. Comment: 18 page...|$|E
40|$|In the 1960 s Professor Hu Guoding {{proposed}} {{a method of}} measuring information {{based on the idea}} that connotation and denotation of a concept satisfies inverse ratio rule. According to this information measure, firstly we put forward the <b>information</b> <b>quantity</b> for information systems and decision systems; then, we discuss the updating mechanism of <b>information</b> <b>quantity</b> for decision systems; finally, we give an attribute reduction algorithm for decision tables with dynamically varying attribute values...|$|E
40|$|We {{consider}} utility maximization {{problem for}} semi- martingale models depending on a random factor. We reduce initial maximization {{problem to the}} conditional one, given = u, which we solve using dual approach. For HARA utilities we con- sider <b>information</b> <b>quantities</b> like Kullback-Leibler <b>information</b> and Hellinger integrals, and corresponding information processes. As a particular case we study exponential Levy models depending on random factor. In that case the information processes are deter- ministic and this fact simplify very much indi erence price calcu- lus. Then we give the equations for indi erence prices. We show that indi erence price for seller and minus indi erence price for buyer are risk measures. Finally, we apply the results to Geo- metric Brownian motion case. Using identity in law technique we give the explicit expression for <b>information</b> <b>quantities.</b> Then, the previous formulas for indi erence price can be applied...|$|R
40|$|The {{information}} {{energy and}} information temperature are proposed as new quantum descriptors for {{the characterization of}} molecular systems. Ab initio and semiempirical (PM 3) procedures are used to create molecular probability fields on which the aforementioned <b>information</b> <b>quantities</b> are applied. The connection with other structural descriptors is discussed {{in the case of}} linear condensed aromatic rings and linear hydrocarbons with alternate double bonds...|$|R
40|$|Abstract. We {{consider}} utility maximization {{problem for}} semimartingale models depending on a random factor ξ. We reduce initial maximization {{problem to the}} conditional one, given ξ = u, which we solve using dual approach. For HARA utilities we consider <b>information</b> <b>quantities</b> like Kullback-Leibler <b>information</b> and Hellinger integrals, and corresponding information processes. As a particular case we study exponential Levy models depending on random factor. In that case the information processes are deterministic and this fact simplify very much indifference price calculus. Then we give the equations for indifference prices. We show that indifference price for seller and minus indifference price for buyer are risk measures. Finally, we apply the results to Geometric Brownian motion case. Using identity in law technique we give the explicit expression for <b>information</b> <b>quantities.</b> Then, the previous formulas for indifference price can be applied. Key words and phrases: utility maximisation, utility indifference price, semi-martingale, f-divergence minimal martingale measure, exponential Levy mode...|$|R
3000|$|We may {{sometimes}} {{be able to}} choose a link function so that the <b>information</b> <b>quantity</b> does not depend on θ [...].|$|E
40|$|Online reviews (ORs) are {{fostering}} {{the spread of}} Word-Of-Mouth in the online environment (e-WOM). The popularity of e-WOM is constantly growing among consumers who use them before buying a product/service. Therefore, {{it is important for}} marketers to understand the antecedents of e-WOM. In this paper we have used the elaboration likelihood model to investigate the antecedents of consumers' adoption of ORs for hedonic products. Drawing on this theory, we have measured the influence of information quality, <b>information</b> <b>quantity,</b> and products ranking on consumers' adoption of ORs. Predictions were tested by using regression analysis with data from 608 users of online travel reviews from different countries. Contrary to previous findings, this research shows that highly involved consumers are mainly influenced by peripheral cues, including the ranking of services/products but not by <b>information</b> <b>quantity.</b> Finally, the research shows that product ranking, and not <b>information</b> <b>quantity</b> or negative reviews, is a strong antecedent of e-WOM's adoption...|$|E
40|$|<b>Information</b> <b>quantity</b> {{subject is}} {{approached}} in this paperwork, considering the specific domain of nonconforming product management as information source. This work represents a case study. Raw data were gathered from a heavy industrial works company, information extraction and knowledge formation being considered herein. Involved method for <b>information</b> <b>quantity</b> estimation {{is based on}} Shannon entropy formula. Information and entropy spectrum are decomposed and analysed for extraction of specific information and knowledge-that formation. The result of the entropy analysis point out the information needed to be acquired by the involved organisation, this being presented as a specific knowledge type...|$|E
40|$|This paper {{presents}} a general information-theoretic approach for obtaining lower bounds on the num-ber of examples needed to PAC {{learn in the}} pres-ence of noise. This approach deals directly with the fundamental <b>information</b> <b>quantities,</b> avoiding a Bayesian analysis. The technique is applied to several different models, illustrating its generality and power. The resulting bounds add logarithmic factors to (or improve the constants in) previously known lower bounds. ...|$|R
40|$|We derive three {{fundamental}} decompositions on relevant <b>information</b> <b>quantities</b> in feedback systems. The feedback systems {{considered in}} this paper are only restricted to be causal in time domain and the channels are allowed {{to be subject to}} arbitrary distribution. These decompositions comprise the well-known mutual information and the directed information, and indicate a law of conservation of information flows in the closed-loop network. Comment: 10 pages, 1 figure. Seminar Repor...|$|R
40|$|AbstractThis paper {{presents}} a general information-theoretic approach for obtaining lower bounds {{on the number}} of examples required for Probably Approximately Correct (PAC) learning in the presence of noise. This approach deals directly with the fundamental <b>information</b> <b>quantities,</b> avoiding a Bayesian analysis. The technique is applied to several different models, illustrating its generality and power. The resulting bounds add logarithmic factors to (or improve the constants in) previously known lower bounds...|$|R
40|$|Vehicle-to-vehicle {{communication}} plays {{a significantly}} {{important role in}} implementing safe and efficient road traffic. When disseminating safety messages in the network, the <b>information</b> <b>quantity</b> on safety packets changes over time and space. However, most of existing protocols view each packet the same to disseminate, preventing vehicles from collecting more recent and precise safety information. Hence, an information quantity-based broadcast protocol is proposed in this paper to ensure the efficiency of safety messages dissemination. In particular, we propose the concept of emergency-degree to evaluate packets’ <b>information</b> <b>quantity.</b> Then we present EDCast, an emergency-degree-based broadcast protocol. EDCast differentiates each packet’s priority for accessing the channel based on its emergency-degree so as to provide vehicles with more safety information timely and accurately. In addition, an adaptive scheme is presented to ensure fast dissemination of messages in different network condition. We compare the performance of EDCast with those of three other representative protocols in a typical highway scenario. Simulation results indicate that EDCast achieves higher broadcast efficiency and less redundancy with less delivery delay. What we found demonstrates that it is feasible and necessary for incorporating <b>information</b> <b>quantity</b> of messages in designing an efficient safety message broadcast protocol...|$|E
40|$|The {{purpose of}} {{geometric}} matching is {{to extract the}} geometric transformation parameters between the corresponding images. It is widely used in photogrammetric mapping, deformation detection, and flying platform's posture analysis, etc. In this paper, a new image matching method which {{is different from the}} traditional features based image matching algorithm is proposed, it takes all the pixels of the corresponding images to participate the matching procedure and calculate the geometric parameters by least square criterion. The principle of the algorithm, including the gray corresponding equation, the <b>information</b> <b>quantity</b> inequation and procedure of least square solution are expressed. Particularly, the wavelet analysis for gray signal and calculating the <b>information</b> <b>quantity</b> by signal to noise ratio are discussed in detail. For verifying the theory and algorithm, a series of sequential images taking from a video camera mounted on a helicopter are selected for experiment. The results of two typical models according to the relative orientation elements model and parallax grid model are given, and the experimental results show that the proposed algorithm is feasible and effective. The comparison of APM with ordinary features based method by the <b>information</b> <b>quantity</b> inequation is given in the conclusion...|$|E
40|$|ISBN : 978 - 2 - 9532965 - 0 - 1 Spike train {{analysis}} generally {{focus on}} two purposes: (1) {{the estimate of}} the neuronal <b>information</b> <b>quantity,</b> and (2) the quantification of spikes or bursts synchronization. We introduce here a new multivariate index based on Lempel-Ziv complexity for spike train analysis. This index, called mutual Lempel-Ziv complexity (MLZC), can measure both spikes correlations and estimate the <b>information</b> <b>quantity</b> of spike trains (i. e. characterize the dynamic state). Using simulated spike trains from a Poisson process, we show that the MLZC is able to quantify spike correlations. In addition, using bursting activity generated by electrically coupled Hindmarsh-Rose neurons, the MLZC is able to quantify and characterize bursts synchronization, when classical measures fail...|$|E
40|$|Given a {{positive}} function f on (0,∞) and a non-zero real parameter θ, we consider a function I_f^θ(A,B,X) =Tr X^*(f(L_AR_B^- 1) R_B) ^θ(X) in three matrices A,B> 0 and X. In the literature θ=± 1 has been typical. The concept unifies various quantum <b>information</b> <b>quantities</b> such as quasi-entropy, monotone metrics, etc. We characterize joint convexity/concavity and monotonicity {{properties of the}} function I_f^θ, thus unifying some known results for various quantum quantities. Comment: 27 page...|$|R
5000|$|The {{comparisons}} made generally measure <b>information</b> theoretic <b>quantities</b> such as {{value of}} the mutual information function between two regions of the sequence.|$|R
50|$|In logistics, Pneuron {{provides}} real-time {{situational awareness}} across the diverse {{components of a}} highly outsourced supply chain. On both a scheduled and event-driven basis, Pneuron executes configured workflows to pull current inventory from both internal and partner/distributor systems to gather up-to-the minute inventory <b>information</b> (<b>quantities,</b> models) which allows an accurate valuation calculation. Further by analyzing trending and forecasted consumption, Pneuron triggers a replenishment order to various internal and distributor systems to avoid running out of stock.|$|R
40|$|This paper {{presents}} {{a model of}} information and political regime change. If enough citizens act against a regime, it is overthrown. Citizens are imperfectly informed about how hard this will be and the regime can, at a cost, engage in propaganda so that at face-value it seems hard. This coordination game with endogenous information manipulation has a unique equilibrium and the paper gives a complete analytic characterization of its comparative statics. If the quantity of information available to citizens is suciently high, then the regime {{has a better chance}} of surviving. However, an increase in the reliability of information can reduce the regime's chances. These two effects are always in tension: a regime benefits from an increase in <b>information</b> <b>quantity</b> if and only if an increase in information reliability reduces its chances. The model allows for two kinds of information revolutions. In the first, associated with radio and mass newspapers under the totalitarian regimes of the early twentieth century, an increase in <b>information</b> <b>quantity</b> coincides with a shift towards media institutions more accommodative of the regime and, in this sense, a decrease in information reliability. In this case, both effects help the regime. In the second kind, associated with diffuse technologies like modern social media, an increase in <b>information</b> <b>quantity</b> coincides with a shift towards sources of information less accommodative of the regime and an increase in information reliability. This makes the quantity and reliability effects work against each other. The model predicts that a given percentage increase in information reliability has exactly twice as large an effect on the regime's chances as the same percentage increase in <b>information</b> <b>quantity,</b> so, overall, an information revolution that leads to roughly equal-sized percentage increases in both these characteristics will reduce a regime's chances of surviving. global games; hidden actions; signal-jamming; propaganda; bias; media...|$|E
40|$|The {{study of}} minimum entropy {{of a natural}} {{language}} has been an interesting research subject. For English, great progress has been made, but few reports on other languages {{have been found in}} literature. Based on two hypotheses on the conservation of <b>information</b> <b>quantity,</b> we proposed a method which can be used to estimate the minimum entropy of characters in natural languages. With a large quantity of translation corpus, this method enables us to estimate the minimum entropy without calculating the probability. Besides, as the scale of translation corpus increases, the fluctuation of the ratio between character quantities in any two languages becomes negligible. In this paper, we apply this method to the study of two languages of a large character total — Japanese and Chinese. Minimum entropy, conservation of <b>information</b> <b>quantity,</b> natural language processing...|$|E
40|$|International audienceTexture {{adaptation}} is {{a challenging}} issue in tex-ture-based feature visualization. In order to visualize as more information as we can, {{this paper presents}} a texture adaptation technique for fuzzy feature visualization of 3 D vector field, taking into account <b>information</b> <b>quantity</b> carried by vector field and texture based on extended information entropy. Two definitions of information measurement for 3 D vector field and noise texture, MIE and RNIE, are proposed to quantitatively represent the information carried by them. A noise generation algorithm based on three principles derived from minimal differentia of MIE and RNIE is designed to obtain an approximately optimal distribution of noise fragments which shows more details than those used before. A discussion of results is included to demonstrate our algorithm {{which leads to a}} more reasonable visualization results based on fuzzy feature measurement and <b>information</b> <b>quantity...</b>|$|E
40|$|Abstract—The 3 -user {{discrete}} memoryless interference {{channel is}} considered in this paper. We provide a new inner bound (achievable rate region) to the capacity region for this channel. This inner bound {{is based on}} a new class of code ensembles based on asymptotically good nested linear codes. This achievable region is strictly superior to the straightforward extension of Han-Kobayashi rate region from the case of twousers to three-users. This rate region is characterized using single-letter <b>information</b> <b>quantities.</b> We consider examples to illustrate the rate region...|$|R
40|$|Abstract. The {{estimation}} of relevant <b>information</b> theoretical <b>quantities,</b> such as entropy, mutual information, and various divergences is computationally expensive in high dimensions. However, for this task, one may apply pairwise Euclidean distances of sample points, which suits random projection (RP) based low dimensional embeddings. The Johnson-Lindenstrauss (JL) lemma gives theoretical bound on {{the dimension of}} the low dimensional embedding. We adapt the RP technique for the {{estimation of}} <b>information</b> theoretical <b>quantities.</b> Intriguingly, we find that embeddings into extremely small dimensions, far below the bounds of the JL lemma, provide satisfactory estimates for the original task. We illustrate this in the Independent Subspace Analysis (ISA) task; we combine RP dimension reduction with a simple ensemble method. We gain considerable speed-up with the potential of real-time parallel estimation of high dimensional <b>information</b> theoretical <b>quantities.</b> Key words: independent subspace analysis, random projection, pairwise distances, information theoretical estimations...|$|R
25|$|Other {{important}} <b>information</b> theoretic <b>quantities</b> include Rényi entropy (a {{generalization of}} entropy), differential entropy (a generalization of <b>quantities</b> of <b>information</b> to continuous distributions), and the conditional mutual information.|$|R
