50|16|Public
2500|$|Computers usually use {{the method}} of {{complements}} to implement subtraction. Using complements for subtraction {{is closely related to}} using complements for representing negative numbers, since the combination allows all signs of operands and results; <b>direct</b> <b>subtraction</b> works with two's-complement numbers as well. Like addition, the advantage of using two's complement is the elimination of examining the signs of the operands to determine whether addition or subtraction is needed. For example, subtracting −5 from 15 is really adding 5 to 15, but this is hidden by the two's-complement representation: ...|$|E
5000|$|IBM 405 (photo): From the IBM Archives: Introduced in 1934, the 405 Alphabetical Accounting Machine was {{the basic}} {{bookkeeping}} and accounting machine marketed by IBM for many years. Important features were expanded adding capacity, greater flexibility of counter grouping, direct printing {{of the entire}} alphabet, <b>direct</b> <b>subtraction</b> and printing of either debit or credit balance from any counter. Commonly called the 405 [...] "tabulator," [...] this machine remained the flagship of IBM's product line until after World War II.|$|E
5000|$|Computers usually use {{the method}} of {{complements}} to implement subtraction. Using complements for subtraction {{is closely related to}} using complements for representing negative numbers, since the combination allows all signs of operands and results; <b>direct</b> <b>subtraction</b> works with two's-complement numbers as well. Like addition, the advantage of using two's complement is the elimination of examining the signs of the operands to determine whether addition or subtraction is needed. For example, subtracting −5 from 15 is really adding 5 to 15, but this is hidden by the two's-complement representation: ...|$|E
40|$|We {{present a}} simple {{subtraction}} procedure of GDDSC as {{a modification of}} the original DSC and GDRDA methods. Genetically <b>Directed</b> Differential <b>Subtraction</b> Chain (GDDSC) is a process by which highly related genomes are compared in order to isolate tags carrying the polymorphisms. |$|R
40|$|Background and aims. In periapical {{radiographic}} technique, {{the changes}} will be visible only after considerable deposition or resorption while digital subtraction technique visualizes slight density changes. This study was aimed to compare visualization of density changes in conventional periapical radiographs and digital subtraction technique with or without image enhancement. Materials and methods. Three dry human mandibles with unspecified age and gender were selected. Conventional periapical and direct digital radiographs {{were taken from the}} anterior, and right and left posterior regions by step-wise placement of aluminum plates until the image of the plate was clearly visible. The radiographs taken with the direct digital technique were subtracted from the first radiograph using Photoshop software. Three observers evaluated the radiographs and the digital subtraction images with or without image enhancement. The density was recorded in each radiograph in which the image of the aluminum plate was completely visible. Results. In all mandibles, the differences in diagnosis of density changes between the conventional periapical radiographic technique and the <b>direct</b> digital <b>subtraction</b> radiographic technique with or without image enhancement were statistically significant irrespective of the region under study (p< 0. 001). There {{were no significant differences in}} the diagnosis of density changes in all the three mandibles in the left and right posterior regions between the two radiographic techniques. However, the differences in the anterior region were statistically significant (p< 0. 001). Conclusion. <b>Direct</b> digital <b>subtraction</b> radiographic technique with or without image enhancement is a more efficacious technique in exhibiting minor density changes compared to conventional periapical radiographic techniqu...|$|R
40|$|International audienceThe {{finite-element method}} (FEM) {{is applied to}} solve the EEG forward problem. Two {{issues related to the}} {{implementation}} of this method are investigated. The first is the singularity due to the punctual dipole sources and the second is the numerical errors observed near the interface of different tissues. To deal with the singularity of the punctual dipole sources, three source modeling methods, namely, the <b>direct,</b> the <b>subtraction</b> and the Saint Venant's methods, are examined. To solve the problem of numerical instability near the interface of different tissues, a modification on the Saint Venant's method is introduced. The numerical results are compared with analytical solution {{in the case of the}} multilayer spherical head models. The advantages of the proposed method are highlighted...|$|R
40|$|We {{investigated}} {{the use of}} the subtraction by addition strategy, an important mental calculation strategy in children with different levels of mathematics achievement. In doing so we relied on Siegler’s cognitive psychological model of strategy change (Lemaire & Siegler, 1995), which defines strategy competencies in terms of four parameters (strategy repertoire, distribution, efficiency and selection), and the choice/no-choice method (Siegler & Lemaire, 1997), which is essentially characterized by offering items in two types of conditions (choice and no-choice). Participants were 63 11 - 12 -year-olds with varied mathematics achievement levels. They solved multi-digit subtraction problems in the number domain up to 1, 000 in one choice condition (choice between <b>direct</b> <b>subtraction</b> or subtraction by addition on each item) and two no-choice conditions (obligatory use of either <b>direct</b> <b>subtraction</b> or subtraction by addition on all items). We distinguished between two types of subtraction problems: problems with a small versus large difference between minuend and subtrahend. Although mathematics instruction only focused on applying <b>direct</b> <b>subtraction,</b> most children reported using subtraction by addition in the choice condition. Subtraction by addition was applied frequently and efficiently, particularly on small-difference problems. Children flexibly fitted their strategy choices to both numerical item characteristics and individual strategy speed characteristics. There were no differences in strategy use between the different mathematical achievement groups. These findings add to our theoretical understanding of children’s strategy acquisition and challenge current mathematics instruction practices that focus on <b>direct</b> <b>subtraction</b> for children of all levels of mathematics achievement. status: accepte...|$|E
40|$|In {{the last}} decades, variety and {{flexibility}} in children’s strategy use {{has become a}} major aim in mathematics education. For children with mathematical difficulties (MD), however, there remains discussion whether it is feasible to aim for strategy variety and flexibility. Some researchers, curriculum developers and policy makers advise to teach children with MD only one way of solving problems. In the domain of mental subtraction, for instance, children with MD are typically taught to always use a <b>direct</b> <b>subtraction</b> strategy to solve problems such as 52 & minus; 48. However, for problems with a relatively large subtrahend compared to the difference, subtraction by addition appears to be a more efficient strategy. In the present study, we focused on the spontaneous use of the subtraction by addition strategy in 27 children with MD, using non-verbal research methods. Results showed that children with MD flexibly switch between <b>direct</b> <b>subtraction</b> and subtraction by addition strategies based on the relative size of the subtrahend, similar to our previous work with typically developing children. Our findings are of great relevance for mathematics education as they challenge special education classroom practices that only focus on the routine mastery of the <b>direct</b> <b>subtraction</b> strategy, and on the routine mastery of mental calculation strategies in general. status: publishe...|$|E
40|$|Subtraction {{problems}} of the type M ! S = ? can be solved with various mental calculation strategies. We investigated fourth- to sixth-graders’ use of the subtraction by addition strategy, first by fitting regression models to the reaction times of 32 two-digit subtractions. These models represented three different strategy use patterns: the use of <b>direct</b> <b>subtraction,</b> subtraction by addition, and switching between the two strategies based on {{the magnitude of the}} subtrahend. Additionally, we compared performance on problems presented in two presentation formats, i. e., a subtraction format (81 ! 37 =.) and an addition format (37 +. = 81). Both methods converged to the conclusion that children of all three grades switched between <b>direct</b> <b>subtraction</b> and subtraction by addition based on the combination of two features of the subtrahend: If the subtrahend was smaller than the difference, <b>direct</b> <b>subtraction</b> was the dominant strategy; if the subtrahend was larger than the difference, subtraction by addition was mainly used. However, this performance pattern was only observed when the numerical distance between subtrahend and difference was large. These findings indicate that theoretical models of children’s strategy choices in subtraction should include the nature of the subtrahend as an important factor in strategy selection. status: publishe...|$|E
40|$|Estimations of prompt photon {{production}} at FAIR (Facility for Antiproton and Ion Research) energies using the extrapolation of existing data are presented. About 10 − 4 prompt γ with pt> 2 GeV/c per Au+Au central event at 25 AGeV are expected. With the planed beam intensity 10 9 /s, 1 % interaction rate and 10 % centrality, at CBM (Compressed Baryonic Matter) experiment one can expect prompt γ rate 100 /s. Predictions for direct photons by some generators (PYTHIA, UrQMD, RQMD, HSD, HIJING) are analyzed. One {{of the main}} sources of direct photons (due to meson scatterings πρ → πγ, ππ → ργ) is not implemented in the heavy-ion generators. Corresponding cross-sections for this source have been prepared for implementation into the HSD code. Main experimental methods to study <b>direct</b> photons (<b>subtraction</b> method, momentum correlations method and internal conversion method) are shortly reviewed. High intensity beam, good tracking and good e ± particle identification of the CBM detector favor to measure direct photons by all the methods. ...|$|R
40|$|The Virgo and A 1795 {{clusters}} of galaxies were re-observed by EUVE with in situ background measurements by pointing at small offsets. Earlier, a similar reobservational strategy {{applied to the}} cluster A 2199 revealed that the background radial profile was consistent with a flat distribution, and therefore the original method of extracting cluster EUV signals by the subtraction of an aymptotically determined background was valid. It is shown here that the same conclusions hold for the current sample. A model of the background was obtained from its known properties and the in situ measurements, and the subtracted cluster fluxes remain in agreement with those reported in our discovery papers. They are also consistent with results from the most conservative procedure of <b>direct</b> point-topoint <b>subtraction</b> of the in situ background and proper error propagation, which still preserves {{the existence of the}} EUV excess and its rising radial trend. We present evidence which argues against the soft excess as due to peculiarities in the line-of-sight Galactic absorption. The data appear to favor a thermal origin of the emission. 1...|$|R
40|$|Ultrasonic wavefield imaging, {{which refers}} to the {{measurement}} of wave motion on a 2 -D rectilinear grid resulting from a fixed source, has been previously applied to angle-beam shear wave propagation in simple plates with through-holes and far-surface notches [1]. In this prior work scattered waves were analyzed using baseline subtraction of wavefields acquired before and after a notch was introduced [2]. In practice, however, defects of interest often occur between bonded layers and it is generally not possible to record data from the same specimen in both the undamaged and damaged states, making <b>direct</b> baseline <b>subtraction</b> infeasible. This present work considers measurement of angle-beam waves in several bonded specimens with and without buried defects originating from fastener holes. The experimental methodology is explained, which includes specimen fabrication details and wavefield measurement methods. Data from fastener holes with and without simulated damage {{in the form of}} notches are compared, and techniques used to analyze differences are discussed. Despite unavoidable deviations from specimen-to-specimen caused by factors such as variations in bonding, transducer mounting, and fastener hole machining, it is shown that scattering from buried notches can be clearly visualized in the recorded wavefield data...|$|R
40|$|In {{the last}} decades, {{strategy}} variability and flexibility have become major aims in mathematics education. For children with mathematical learning disabilities (MLD) {{it is unclear}} whether the same goals can and should be set. Some researchers and policy makers advise to teach MLD children only one solution strategy, others advocate stimulating the flexible use of various strategies, as for typically developing children. To contribute to this debate, we compared the use of the subtraction by addition strategy to mentally solve two-digit subtractions in children with and without MLD. We used non-verbal research methods to infer strategy use patterns, and found that both groups of children switch between the traditionally taught <b>direct</b> <b>subtraction</b> strategy and subtraction by addition, based on the relative size of the subtrahend. These findings challenge typical special education classroom practices, which only focus on the routine mastery of the <b>direct</b> <b>subtraction</b> strategy. status: publishe...|$|E
40|$|Subtractions of {{the type}} M−S=? can be solved by various strategies, {{including}} subtraction by addition. In this study, we investigated children’s use of subtraction by addition by means of reaction time analyses. We presented 106 third to sixth graders with 32 large non-tie single-digit problems in both subtraction (12 − 9 =.) and addition format (9 +. = 12). We examined the fit of three regression models, which represented the consistent use of <b>direct</b> <b>subtraction,</b> of subtraction by addition and of flexibly switching between both strategies based on the relative size of the subtrahend. Findings revealed that children did not switch flexibly between the two strategies, as adults do, but that they rely on <b>direct</b> <b>subtraction</b> for problems presented in subtraction format and on subtraction by addition for problems in addition format. We end with the major theoretical, methodological and educational implications of these results. status: publishe...|$|E
40|$|This study {{examined}} adults' use of indirect addition and <b>direct</b> <b>subtraction</b> strategies on multi-digit subtractions {{in the number}} domain up to 1, 000. Seventy students who differed in their level of arithmetic ability solved multi-digit subtractions in one choice and two no-choice conditions. Against the background of recent findings in elementary subtraction, we manipulated {{the size of the}} subtrahend compared to the difference and only selected items with large distances between these two integers. Results revealed that adults frequently and efficiently apply indirect addition on multi-digit subtractions, yet adults with higher arithmetic ability performed more efficiently than those with lower arithmetic ability. In both groups, indirect addition was more efficient than <b>direct</b> <b>subtraction</b> both on subtractions with a subtrahend much larger than the difference (e. g., 713 695) and on subtractions with a subtrahend much smaller than the difference (e. g., 613 67). Unexpectedly, only adults with lower arithmetic ability fitted their strategy choices to their individual strategy performance skills. Results are interpreted in terms of mathematical and cognitive perspectives on strategy efficiency and adaptiveness. status: publishe...|$|E
40|$|The {{employment}} of superconductivity and other material properties at cryogenic temperatures to fabricate sensitive, low-drift, gravity gradiometer is described. The device yields {{a reduction of}} noise of four orders of magnitude over room temperature gradiometers, and <b>direct</b> summation and <b>subtraction</b> of signals from accelerometers in varying orientations are possible with superconducting circuitry. Additional circuits permit determination of the linear and angular acceleration vectors independent of the measurement of the gravity gradient tensor. A dewar flask capable of maintaining helium in a liquid state for a year's duration is under development by NASA, and a superconducting tensor gravity gradiometer for the NASA Geodynamics Program is intended for a LEO polar trajectory to measure the harmonic expansion coefficients of the earth's gravity field up to order 300...|$|R
40|$|Measuring {{small changes}} in {{refractive}} index can provide both sensitive and contactless information on molecule concentration or process conditions {{for a wide range}} of applications. However, refractive index measurements are easily perturbed by non-specific background signals, such as temperature changes or non-specific binding. Here, we present an optofluidic device for measuring refractive index with <b>direct</b> background <b>subtraction</b> within a single measurement. The device is comprised of two interdigitated arrays of nanofluidic channels designed to form an optical grating. Optical path differences between the two sets of channels can be measured directly via an intensity ratio within the diffraction pattern that forms when the grating is illuminated by a collimated laser beam. Our results show that no calibration or biasing is required if the unit cell of the grating is designed with an appropriate built-in asymmetry. In proof-of-concept experiments we attained a noise level equivalent to ∼ 10 (- 5) refractive index units (30 Hz sampling rate, 4 min measurement interval). Furthermore, we show that the accumulation of biomolecules on the surface of the nanochannels can be measured in real-time. Because of its simplicity and robustness, we expect that this inherently differential measurement concept will find many applications in ultra-low volume analytical systems, biosensors, and portable devices...|$|R
40|$|The {{investigation}} of memory function using functional {{magnetic resonance imaging}} (fMRI) is an expanding field of research. The aim {{of this study was to}} demonstrate brain-activity patterns related to a word-pair association task employing a whole-brain EPI sequence. Six right-handed, healthy male volunteers (mean age: 27. 5 years) took part in the study. fMRI was performed at a field strength of 1. 5 Tesla with 26 – 32 slices parallel to the AC-PC line, depending on individual brain size. Distributed brain regions were activated in episodic encoding and retrieval with similarities, but also (distinct) differences in activation patterns. Bilateral prefrontal cortical areas were involved when comparing encoding as well as retrieval to the reference condition (nonsense words). Furthermore, activation was observed in cerebellar areas during encoding, and activation in bilateral parietal areas (precuneus and inferior parietal cortex) was differentially more pronounced during retrieval. The activation of left dorsomedial thalamus during retrieval of high imagery-content word-pair associates may point to the role of this structure in episodic retrieval. The <b>direct</b> cognitive <b>subtraction</b> of encoding minus retrieval yielded a differentially larger left prefrontal activation. There was a differentially higher right prefrontal activation during retrieval than during encoding, underlining the proposed right/left asymmetry for episodic memory processes...|$|R
40|$|PosterIn {{the last}} decades {{flexible}} strategy use {{has become a major}} aim in mathematics education. For children with mathematical difficulties, however, there remains discussion whether the same goal has to be set. Some researchers and policy makers advise to teach only one way of solving problems to these children, while others stimulate the use of various strategies. In the domain of mental subtraction, the discussion is still vivid. <b>Direct</b> <b>subtraction</b> strategies are mainly taught, but problems with a very small difference (e. g., 52 − 48) can be efficiently solved with the subtraction by addition strategy (i. e., by determining how much needs {{to be added to the}} smaller number to get to the larger one). This strategy has hardly been explored in children with mathematical difficulties so far. With the present study, we aimed at getting more insight in the use of this strategy in these children. We presented 27 children from the final year of special education for children with learning disorders (Mage = 12 y 4 m; SD = 7 m) with 32 horizontally presented subtraction problems, which all required borrowing. Each problem was presented both in the traditional subtraction (e. g., 52 − 4 =?) and in its corresponding addition format (4 +?= 52). The problems were divided into four problem types, based on the combination of the magnitude of the subtrahend (S) compared to the difference (D) (S D) and the numerical distance between S and D (small or large). Small-distance problems were defined by S and D differing by less than 10, whereas in the large-distance problems S and D differed by at least 10 and either S or D was a one-digit number. We fitted the children’s mean reaction times of the 32 problems presented in subtraction format to three regression models, which modeled the use of <b>direct</b> <b>subtraction,</b> subtraction by addition, and the flexibly switching between both based on the magnitude of the subtrahend (Authors, in press). The model representing the flexible switch between <b>direct</b> <b>subtraction</b> and subtraction by addition provided the best fit to the data averaged over children, F(1, 30) = 45. 29, p <. 01, Rsq =. 60. Analyses at an individual level showed that this Switch-Model also provided the best fit for the individual data of most children. An additional repeated measures ANOVA with magnitude, numerical distance between S and D, and presentation format as within-subject factors showed that the magnitude of the subtrahend only affects strategy choice when the distance between subtrahend and difference was rather large (as in 71 − 2 and 71 − 69) and not when these two integers were close to each other (as in 75 − 36 or 75 − 39). These results reveal that children with mathematical difficulties switch between <b>direct</b> <b>subtraction</b> and subtraction by addition strategies based on the combination of magnitude and numerical distance, similar to typically developing children. Our findings are of great relevance for mathematics education as they challenge special education classroom practices that only focus on the routine mastery of the <b>direct</b> <b>subtraction</b> strategy, and on the routine mastery of mental calculation strategies in general. status: publishe...|$|E
40|$|ABSTRACT. The {{sensitivity}} to damage achievable by guided wave structural health monitoring systems {{is limited by}} the repeatability of recorded signals under normal operating conditions. <b>Direct</b> <b>subtraction</b> of reference signals leads to unacceptably high post-subtraction noise in the presence of modest temperature changes due to variations in reflections from benign structural features, hence temperature compensation is necessary. In this paper, various numerical compensation strategies are investigated. It is concluded that a combination of stretching and translating time-traces provides reasonable compensation performance for modest temperature changes...|$|E
30|$|The SISCOM {{technique}} {{consists of}} a digital subtraction of ictal and interictal perfusion SPECT scans, either by <b>direct</b> <b>subtraction</b> or preferably using more advanced statistical methods with a histogram-based cluster analysis {{that needs to be}} thresholded with a certain z-score (the number of relative standard deviations compared to no difference). In this statistical analysis, a threshold z-value of 2 is generally accepted in most publications [5, 11 – 14], but this threshold was arbitrarily selected mainly because of lack of hard endpoints (ground truth) and small sample sizes.|$|E
40|$|A new, {{simple and}} {{specific}} spectrophotometric method {{was developed and}} validated in accordance with ICH guidelines for the simultaneous estimation of Amlodipine (AML), Valsartan (VAL), and Hydrochlorothiazide (HCT) in their ternary mixture. In this method three techniques were used, namely, <b>direct</b> spectrophotometry, ratio <b>subtraction,</b> and isoabsorptive point. Amlodipine (AML) was first determined by direct spectrophotometry and then ratio subtraction was applied to remove the AML spectrum from the mixture spectrum. Hydrochlorothiazide (HCT) could then be determined directly without interference from Valsartan (VAL) which could be determined using the isoabsorptive point theory. The calibration curve is linear over the concentration ranges of 4 – 32, 4 – 44 and 6 – 20 [*]μg/mL for AML, VAL, and HCT, respectively. This method was tested by analyzing synthetic mixtures of the above drugs and was successfully applied to commercial pharmaceutical preparation of the drugs, where the standard deviation is < 2 in the assay of raw materials and tablets. The method was validated according to the ICH guidelines and accuracy, precision, repeatability, and robustness {{were found to be}} within the acceptable limits...|$|R
40|$|Quantification of {{hydroxide}} in aqueous solutions by Raman spectroscopy {{is complicated}} by the fact that the O-H stretching band of hydroxide is overlapped by the broad, symmetric O-H stretching band of water. This overlap is further {{complicated by the fact that}} the shape of the O-H stretching band of water is strongly influenced by the concentration of hydroxide. The O-H stretching band of water is believed to consist of five components that result from differing configurations of intramolecular hydrogen bonding. The Raman spectral region from 300 to 4, 450 cm{sup {minus} 1 } was investigated for NaOH solutions ranging in concentration from 0. 2 to 50 weight percent. At approximately 5 weight percent NaOH, a distinct shoulder appears on the high energy side of the O-H stretching band of water. As the NaOH concentration increases, this shoulder becomes a sharp distinct band at 3, 600 cm{sup {minus} 1 } which is still not resolved from the O-H stretching band of water. As the O-H stretching band of hydroxide increases, the O-H stretching band of water broadens and its contour becomes smoother. By curve fitting five Gaussian functions to the O-H stretching band of water, the asymmetric band due to hydroxide was extracted from the composite band of the NaOH solution. The curve fitting routine resulted in a linear relationship for the area of the hydroxide band in the concentration range from 5 to 50 weight percent NaOH. The uncertainty in the curve fitting at concentrations below 5 weight percent was too large to establish a reliable calibration curve. Below 5 weight percent NaOH, <b>direct</b> spectral <b>subtraction</b> of the water band from the NaOH solution band resulted in a linear relationship in the range of 5 down to 0. 2 weight percent NaOH. The peak shape obtained for the hydroxide band by the two different techniques was very similar. A comparison of the results obtained from peak fitting and spectral subtraction is presented...|$|R
5000|$|Since the {{earliest}} days of the telephone, the need for a unit in which to measure the transmission efficiency of telephone facilities has been recognized. The introduction of cable in 1896 afforded a stable basis for a convenient unit and the [...] "mile of standard" [...] cable came into general use shortly thereafter. This unit was employed up to 1923 when a new unit was adopted as being more suitable for modern telephone work. The new transmission unit is widely used among the foreign telephone organizations and recently it was termed the [...] "decibel" [...] at the suggestion of the International Advisory Committee on Long Distance Telephony.The decibel may be defined by the statement that two amounts of power differ by 1 decibel when they are in the ratio of 100.1 and any two amounts of power differ by N decibels when they are in the ratio of 10N(0.1). The number of transmission units expressing the ratio of any two powers is therefore ten times the common logarithm of that ratio. This method of designating the gain or loss of power in telephone circuits permits <b>direct</b> addition or <b>subtraction</b> of the units expressing the efficiency of different parts of the circuit...|$|R
30|$|For instance, 0.5 % of the {{enantiomer}} of the analyzed substance {{discussed in}} this paragraph was added in the last updated impurity profile. As expected, the titration value became 91.23 %, instead of 91.73 %, based on the “Kjeldahl” calculation. Of course and more easy is the <b>direct</b> <b>subtraction</b> of the 0.5 % of the enantiomer content from the 91.73 % titration value. In fact, this second way of calculation validates the 0.0055  mol of the enantiomer calculated by Mat-CHN, leading to the titration value obtained by the Kjeldahl approach.|$|E
40|$|This paper {{examines}} a time reversal beamforming imager {{for detecting}} early stage breast cancer tumors. We use numerical simulations and electromagnetic tissue experiments {{to validate the}} imager. Microwave radiation {{is known to be}} a potential diagnostic imaging tool for breast cancer detection that could complement the standard X-ray mammography. Electromagnetic radiation waves undergo multiple scattering due to the inhomogeneities of biological tissues. In this paper, we demonstrate that our proposed time reversal imager exploits successfully the multiple path electromagnetic scattering to achieve higher resolution and robustness than the <b>direct</b> <b>subtraction</b> beamforming imager. Index Terms — Time reversal, Electromagnetic radiation, Breast cancer detection, Beamformin...|$|E
40|$|Subtraction has two {{meanings}} and each meaning {{leads to the}} different strategies. The meaning of “taking away something” suggests a <b>direct</b> <b>subtraction,</b> while the meaning of “determining the difference between two numbers” {{is more likely to}} be modeled as indirect addition. Many prior researches found that the second meaning and second strategy rarely appeared in the mathematical textbooks and teacher explanations, including in Indonesia. Therefore, this study was conducted to contribute to the development of a local instruction theory for subtraction by designing instructional activities that can facilitate first grade of primary school students to develop a model in solving two digit numbers subtraction. Consequently, design research was chosen as an appropriate approach for achieving the research aim and Realistic Mathematics Education (RME) was used as a guide to design the lesson. This study involved 6 students in the pilot experiment, 31 students in the teaching experiment, and a first grade teacher of SDN 179 Palembang. The result of this study shows that the beads string could bridge students from the contextual problems (taking ginger candies and making grains bracelets) to the use of the empty number line. It also shows that the empty number line could promote students to use different strategies (<b>direct</b> <b>subtraction,</b> indirect addition, and indirect subtraction) in solving subtraction problems. Based on these findings, it is recommended to apply RME in the teaching learning process to make it more meaningful for students. ...|$|E
40|$|Optical code {{division}} multiple access system (OCDMA) has been gaining importance with increasing demands of high speed and large capacity for communication in optical networks. OCDMA system is totally asynchronous, that does not require any clock signals for synchronization in the network. Therefore, OCDMA provide a network that is simpler and offers the potential for scalability to higher levels of connectivity. OCDMA encoding /decoding process also provides a level of security directly implemented in the physical layer. Using OCDMA technique high spectral efficiency is achieved, hence fiber bandwidth is used very efficiently with throughput in excess of Tbit/s. Among several kinds of OCDMA systems, spectra amplitude coding (SAC) scheme attracts increasing interest because multiple access interference (MAI) can be eliminated and preserve the orthogonality between users in the system. This paper presents comparison of three important SAC-OCDMA detection techniques, namely- <b>Direct</b> detection, Complementary <b>subtraction</b> and AND subtraction. The design of encoder and decoder modules for SAC-OCDMA system used in this paper is based on Fiber Bragg Gratings (FBGs). Here conventional single mode fiber (SMF) is used as the transmission link and the performance metric studied is Quality factor (Q) in multiple access environments of various user systems for these three detection techniques. Finally Effect of increasing number of fiber distance on the direct detection technique using NRZ and RZ data formats have been studied. Simulated results show that AND subtraction technique gives better Quality-factor (Q) than the complementary subtractio...|$|R
40|$|Introduction: External root {{resorption}} {{refers to}} the loss of cementum and/or dentin from the rootof the teeth. 40 % mineral loss occur in conventional radiographies but digital subtractionradiography is capable of localizing a lesion with only 1 - 5 % mineral loss. This in vitro study aimedto determine the accuracy of digital subtraction radiography in diagnosis of simulated external rootresorption. Methods and Materials: Ten premolar teeth with clinically intact roots were used were fixed insuitable place between the X-ray tube and CCD sensor. Direct digital radiographs were obtainedbefore and after each lesion was created by 1 / 2, 1, 2, 4 and 6 round dental burs at facial andproximal surfaces; then digital subtraction images were obtained and observers evaluated all of theimages and sensitivity and specificity and accuracy were calculated. Results were compared by J 2 test. Results: The sensitivity of digital <b>subtraction</b> and <b>direct</b> digital methods in detecting proximaldefects were 97. 34 % and 93. 92 % respectively (p value = 0. 16). The sensitivity of digital subtractionand direct digital radiography in facial surfaces were 98 % and 92. 6 % respectively (p value = 0. 03). The specificity of <b>direct</b> digital and <b>subtraction</b> methods in proximal surfaces were 91. 92 %and 96. 52 % (p value = 0. 08) and in facial surfaces were 91. 92 % and 99. 26 % respectively (p value= 0. 002). The accuracy of digital subtraction radiography in detecting facial lesion wassignificantly superior to direct digital radiography. Conclusion: Digital subtraction radiography was superior to direct digital radiography indetecting small external root resorptive defects. Key words: External root resorption, Digital <b>subtraction</b> radiography, <b>Direct</b> digital radiograph...|$|R
40|$|The {{radiative}} {{response of}} the classical electron is commonly described by the Lorentz-Abraham-Dirac (LAD) equation. Dirac's derivation of this equation is based on energy and momentum conservation laws and on regularization of the field singularities and infinite energies of the point charge by subtraction of certain quantities: "We [...] . shall try to get over difficulties associated with the infinite energy of the process by a process of <b>direct</b> omission or <b>subtraction</b> of unwanted terms". To substantiate Dirac's approach and clarify the mass renormalization, we introduce the point charge as a limit of extended charges contracting to a point; the fulfillment of conservation laws follows from the relativistic covariant Lagrangian formulation of the problem. We derive the relativistic point charge dynamics described by the LAD equation from the extended charge dynamics in a localization limit by a method which {{can be viewed as}} a refinement of Dirac's approach in the spirit of Ehrenfest theorem. The model exhibits the mass renormalization as the cancellation of Coulomb energy with the Poincaré cohesive energy. The value of the renormalized mass is not postulated as an arbitrary constant, but is explicitly calculated. The analysis demonstrates that the local energy-momentum conservation laws yield dynamics of a point charge which involves three constants: mass, charge and radiative response coefficient θ. The value of θ depends on the composition of the adjacent potential which generates Poincaré forces. The classical value of the radiative response coefficient is singled out by the global requirement that the adjacent potential does not affect the radiated energy balance and affects only the local energy balance involved in the renormalization. Comment: More details are added in the introduction concerning similarities and differences between the original Dirac's approach and our treatment. Several typos are correcte...|$|R
40|$|We {{report on}} deep {{near-infrared}} F 125 W (J) and F 160 W (H) Hubble Space Telescope Wide Field Camera 3 {{images of the}} z= 6. 42 quasar J 1148 + 5251 to attempt to detect rest-frame near-ultraviolet emission from the host galaxy. These observations included contemporaneous observations of a nearby star of similar near-infrared colors to measure temporal variations in the telescope and instrument point spread function (PSF). We subtract the quasar point source using both this direct PSF and a model PSF. Using <b>direct</b> <b>subtraction,</b> we measure an upper limit for the quasar host galaxy of m_J> 22. 8, m_H> 23. 0 AB mag (2 sigma). After subtracting our best model PSF, we measure a limiting surface brightness from 0. 3 "- 0. 5 " radius of mu_J > 23. 5, mu_H > 23. 7 AB magarc (2 sigma). We test {{the ability of the}} model subtraction method to recover the host galaxy flux by simulating host galaxies with varying integrated magnitude, effective radius, and Sérsic index, and conducting the same analysis. These models indicate that the surface brightness limit (mu_J > 23. 5 AB magarc) corresponds to an integrated upper limit of m_J > 22 - 23 AB mag, consistent with the <b>direct</b> <b>subtraction</b> method. Combined with existing far-infrared observations, this gives an infrared excess log(IRX) > 1. 0 and corresponding ultraviolet spectral slope beta > - 1. 2 ± 0. 2. These values match those of most local luminous infrared galaxies, but are redder than those of almost all local star-forming galaxies and z 6 Lyman break galaxies. Comment: 6 pages, 4 figures, Accepted to ApJ...|$|E
40|$|A {{mathematical}} {{approach to}} the accurate correction of the blank when applying isotope dilution (ID) and reverse ID is presented. The manner in which blank correction is undertaken {{is critical to the}} quality of the final results. <b>Direct</b> <b>subtraction</b> of a procedural blank from the gross analyte concentration is only valid when the blank contributes to the primary ID process and not to the reverse ID process. When the blank contributes to both processes, typically only a fraction of this blank concentration should be subtracted. The approach developed here was illustrated and validated by the determination of MeHg in tuna fish using ID and reverse ID SPME GC-ICP-MS and an enriched Me 198 Hg spike. Despite a 150 -fold higher blank (equivalent to 7...|$|E
40|$|We further {{develop a}} new {{singular}} finite element method, the integrated singular basis function method (ISBFM), for the solution of Newtonian flow problems with stress singularities. The ISBFM {{is based on the}} <b>direct</b> <b>subtraction</b> of the leading local solution terms from the governing equations and boundary conditions of the original problem, followed by a double integration by parts applied to those integrals with singular contributions. The method is applied to the stick-slip and the die-swell problems and improves the accuracy of the numerical results in both cases. In the case of the die-swell problem it considerably accelerates the convergence of the free surface profile with mesh refinement. The advantages and disadvantages of the ISBFM when compared to other singular methods are also discussed...|$|E
40|$|One {{dimensional}} acousto-optic {{signal processing}} techniques are examined from the systems and functional viewpoint, and are then used as building blocks to synthesize multidimensional {{time and space}} integrating architectures. Time and space integrating signal processing systems are capable of performing 2 -dimensional linear transformations upon images or matrices, by sequentially entering rows of the image with a travelling wave acousto-optic Bragg cell. The travelling rows are frozen by a pulsed laser diode, and the stationary diffracted fields are spatially processed by an optical system. The successively transformed rows are sequentially multiplied by a time varying reference wavefront, and accumulated on a time integrating CCD detector array to complete the two dimensional processing. Long 1 -dimensional signals can also be linearly transformed by a time and space integrating system, by using a similar strategy upon a folded, or rastered, version of the high time bandwidth product signal. Small pieces of the long signal are slid into the system with an acousto-optic devices, and are spatially transformed over the device aperture. Then, successively transformed portions of the long signal are multiplied by a reference, and appropriately delayed and accumulated on a 2 -D CCD in order to perform multichannel time integrations in the orthogonal dimension. The desired high time bandwidth one dimensional linear transformation is represented in the folded coordinate space of the 2 -dimensional output detector. The operational characteristics of the principal active devices used in these time and space integrating systems are examined {{from the viewpoint of}} the system architect. The effects of the devices on the overall system operation are discussed, and device designs intended for application in a time and space integrating system operating environment are proposed. The final chapter is a detailed theoretical and experimental investigation into the particular operating characteristics of systems designed to perform a folded spectrum analysis of very high time bandwidth signals. This spectrum analysis problem has a shift variant transformation kernel, which can be broken down into a succession of smaller temporal and spatial sub transformations. The 1 -dimensional space integrating spectrum analysis operation performed by a lens is used to produce a coarse spectral channelization of the input signal, displayed as a one dimensional spatial profile. Each resolvable spectral channel is fine frequency analyzed by temporal integration, producing a resulting intensity variation of each channel in the orthogonal direction, thereby forming a folded representation of the desired high time bandwidth spectrum analysis. The information which is needed to perform the fine frequency analysis is carried on the optical phase, so interferometric techniques are employed in order to detect the phase and transform it to an optical intensity modulation. Various bias terms are produced on the detector by the interferometric detection operation, and techniques for removing the unwanted bias are investigated. These include spatial carrier encoding of the interferometric terms combined with bandpass filtering, and <b>direct</b> bias <b>subtraction</b> techniques...|$|R
40|$|This article {{discusses}} {{the characteristics of}} the indirect addition strategy (IA) in the domain of multi-digit subtraction. In two studies, adults' use of IA on three-digit subtractions with a small, medium, or large difference between the integers was analysed using the choice/no-choice method. Results from both studies indicate that adults spontaneously apply IA on three-digit subtractions, and use IA with the same frequency as <b>direct</b> <b>subtraction</b> (DS) strategies. Furthermore, IA resulted in faster responses - without any loss in accuracy - than DS. Finally, adults flexibly applied IA and DS strategies on the basis of task and individual strategy performance characteristics. Our results support theoretical models on adaptive strategy choices, and question instructional practices focusing on the routine mastery of only DS. status: publishe...|$|E
40|$|Abstract: We {{compute the}} NNLO QCD {{corrections}} for the hadroproduction {{of a pair}} of off-shell photons in the limit {{of a large number of}} quark flavors. We perform a reduction of the two-loop amplitude to master integrals and calculate the latter analytically as a Laurent series in the dimensional regulator using modern integra-tion methods. Real radiation corrections are evaluated numerically with a <b>direct</b> <b>subtraction</b> of infrared limits which we cast in a simple factorized form. The results presented here constitute a gauge invariant part of the full NNLO corrections but are not necessarily dominant. We view this calculation as a step towards a complete computation. Our partial corrections to the total cross-section are about 1 % − 3 % and vary with the virtuality of the two off-shell photons...|$|E
