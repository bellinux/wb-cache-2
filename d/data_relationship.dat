57|4343|Public
500|$|... {{abortion}} counseling {{materials in}} Alaska, Mississippi, Texas, West Virginia, and Kansas {{state that the}} <b>data</b> <b>relationship</b> between abortion and breast cancer are inconclusive, while Minnesota materials report no link. Similar legislation requiring notification has also been introduced in 14 other states. An editor for the American Journal of Public Health expressed concern that these bills propose warnings that {{do not agree with}} established scientific findings.|$|E
5000|$|Hyperion Master Data Management/Oracle <b>Data</b> <b>Relationship</b> Management ...|$|E
5000|$|Sample and <b>Data</b> <b>Relationship</b> Format [...] - [...] U. S. National Cancer Institute's wiki ...|$|E
5000|$|Identification of <b>data</b> <b>relationships</b> {{as part of}} data lineage {{analysis}} ...|$|R
25|$|Visual {{modification}} of PivotDiagrams by dragging data around levels, {{to restructure the}} <b>data</b> <b>relationships.</b>|$|R
5000|$|Composite Discovery {{to locate}} key {{entities}} and reveal hidden <b>data</b> <b>relationships</b> within enterprise <b>data</b> assets; ...|$|R
5000|$|<b>Data</b> <b>relationship</b> model, K Sonmez, LR Toll, PD Lincoln, PD Karp, US Patent 7,039,238, 2006 ...|$|E
50|$|The Sample and <b>Data</b> <b>Relationship</b> Format (SDRF) {{is part of}} the MAGE-TAB {{standard}} for communicating the resultsof microarray investigations, including all information required for MIAME compliance.|$|E
50|$|With {{the growth}} of the {{internet}} and mobile platforms, relationship marketing has continued to evolve as technology opens more collaborative and social communication channels. This includes tools for managing relationships with customers that goes beyond demographic and customer service <b>data.</b> <b>Relationship</b> marketing extends to include inbound marketing efforts, (a combination of search optimization and strategic content), PR, social media and application development.|$|E
5000|$|Twine {{combined}} {{features of}} forums, wikis, online databases and newsgroups and mined and store <b>data</b> <b>relationships</b> expressed using RDF statements.|$|R
50|$|DSDL {{defines a}} modular set of {{specifications}} for describing the document structures, data types, and <b>data</b> <b>relationships</b> in structured information resources.|$|R
50|$|Twine {{combined}} {{features of}} forums, wikis, online databases and newsgroups and employed intelligent software to automatically mine and store <b>data</b> <b>relationships</b> expressed using RDF statements.|$|R
5000|$|... {{abortion}} counseling {{materials in}} Alaska, Mississippi, Texas, West Virginia, and Kansas {{state that the}} <b>data</b> <b>relationship</b> between abortion and breast cancer are inconclusive, while Minnesota materials report no link. Similar legislation requiring notification has also been introduced in 14 other states. An editor for the American Journal of Public Health expressed concern that these bills propose warnings that {{do not agree with}} established scientific findings.|$|E
5000|$|... #Caption: Overview of data {{modeling}} context: Data model {{is based on}} Data, <b>Data</b> <b>relationship,</b> Data semantic and Data constraint. A data model provides the details of information to be stored, and is of primary use when the final product is the generation of computer software code for an application or the preparation of a functional specification to aid a computer software make-or-buy decision. The figure {{is an example of}} the interaction between process and data models.|$|E
40|$|Image mining [1] {{deals with}} {{extraction}} of implicit knowledge, image <b>data</b> <b>relationship</b> or other patterns not explicitly stored in images and uses ideas from computer vision, image processing, image retrieval, data mining, machine learning, databases and AI. The fundamental challenge in image mining {{is to determine}} how low-level, pixe...|$|E
5000|$|New in DoDAF V2.0. Articulates the <b>data</b> <b>relationships</b> and {{alignment}} {{structures in}} the architecture content for the capability and operational requirements, system engineering processes, and systems and services.|$|R
50|$|Top-down parsing is a {{strategy}} of analyzing unknown <b>data</b> <b>relationships</b> by hypothesizing general parse tree structures and then considering whether the known fundamental structures are compatible with the hypothesis. It occurs {{in the analysis of}} both natural languages and computer languages.|$|R
50|$|Though it {{had been}} thought to be an extinct species, a {{population}} of the plant was rediscovered in 1995, from which the somatic chromosome number and detailed chromosome morphology were presented. Using this karyological <b>data,</b> <b>relationships</b> between Allium rouyi and allied species were discussed.|$|R
30|$|Big data based {{credit scoring}} (BDCS) is to {{evaluate}} customer credit using massive data analytics for e-businesses. To {{cope with the}} challenges of big data in e-commerce, special <b>data</b> <b>relationship</b> discovery techniques are {{to be applied to}} reveal seemingly irrelevant datasets or data attributes to extend the information about specific customers for the credit scoring purpose.|$|E
40|$|Due {{to their}} growing complexity, it becomes {{extremely}} difficult to detect and isolate faults in complex systems. While large amount of monitoring data can be collected from such systems for fault analysis, one challenge is how to correlate the data effectively across distributed systems and observation time. Much of the internal monitoring data reacts to the volume of user requests accordingly when user requests flow through distributed systems. In this paper, we use Gaussian mixture models to characterize probabilistic correlation between flow-intensities measured at multiple points. A novel algorithm derived from Expectation-Maximization (EM) algorithm is proposed to learn the “likely ” boundary of normal <b>data</b> <b>relationship,</b> which is further used as an oracle in anomaly detection. Our recursive algorithm can adaptively estimate the boundary of dynamic <b>data</b> <b>relationship</b> and detect faults in real time. Our approach is tested {{in a real system}} with injected faults and the results demonstrate its feasibility. 1...|$|E
40|$|Large scale {{data set}} {{provides}} the better opportunity {{to find out}} much better <b>data</b> <b>relationship</b> {{in the area of}} business intelligence. In the paper, we implement our systems using Hadoop that has been popular to store and compute Big Data. However, {{it is not easy to}} write Hadoop Map Reduce code. Therefore, we use Hive and Hive QL codes to understand the relationships between ratings and the users ’ profiles for the different movies in the Movie Lens data set...|$|E
40|$|This {{site from}} SERC's Starting Point {{encourages}} {{the user to}} recognize relationships between modern GIS and traditional geoscience spatial analysis methods. Links to example GIS exercises and exercises and visualizations that emphasize spatial <b>data</b> <b>relationships</b> in geoscience are provided. Educational levels: Undergraduate lower division, Undergraduate upper division...|$|R
40|$|XML Schema Definition (XSD) is {{the logical}} schemas of an XML model, {{but there is}} no {{standard}} format for the conceptual schema of an XML model. Therefore, we propose an XML Tree Model (XTM) as an XML conceptual schema for representing data semantics in a diagram, and also as an XML data model validator for confirming the data semantics required by users. An XTM consists of hierarchical nodes representing all the elements, and the <b>data</b> <b>relationships</b> among elements within the XSD. A rule-based algorithm and an information capacity with pre-and post-conditions are developed as the methodology for reverse engineering. The proposed algorithm consists of two rules: General Information Transformation and Data Semantic Recovering to construct an XTM [...] Users can draw an XTM with <b>data</b> <b>relationships</b> among elements {{as a result of the}} reverse engineering...|$|R
40|$|This paper {{reports on}} the {{progress}} of an extension to a journal publishing system (OJS) to add RDF aggregation. The system is a lightweight open source repository solution with full CMS features for devolved publishing, a new semantic module is in development for enhanced navigation, searching and for content re-purposing. African Journals Online is used as the example live installation of the extended OJS. Further functionality is being developed to aggregate the large existing metadata resource as a RDF Store, which can be queried using RDQL, to uncover underlying <b>data</b> <b>relationships</b> expressed via formats such as FOAF, or for reuse via RSS. In order to preserve <b>data</b> <b>relationships</b> when harvesting the existing OAI:PMH interface now offers RDF format metadata and an extension of the set support within the OAI protocol has been prototyped...|$|R
40|$|Image mining is {{a process}} to find valid, useful, and {{understandable}} knowledge from large image sets or image databases. Image mining combines the areas of content-based image retrieval, image understanding, data mining and databases. Image mining deals with the extraction of knowledge, image <b>data</b> <b>relationship,</b> or other patterns not explicitly stored in the images. It uses methods from computer vision, image processing, image retrieval, data mining, machine learning, database, and artificial intelligence. Rule mining {{has been applied to}} large image databases. Image mining is more than just an extension of data mining to image domain...|$|E
40|$|Abstract — Image mining {{deals with}} the {{extraction}} of implicit knowledge, image <b>data</b> <b>relationship,</b> or other patterns not explicitly stored in the images. It {{is an extension of}} data mining to image domain. The main objective {{of this paper is to}} apply image mining in the domain of medical image processing using classification rule generated by metaheuristic algorithms. The parameters used in the metaheuristic algorithms are optimized using genetic algorithm with the aim of improving the accuracy by generating minimum number of rules in order to cover more patterns. Index Terms — Genetic Algorithm, Ant-Miner, Mammogram I...|$|E
40|$|GIS-based spatial {{analysis}} was combined with statistical analysis to process time varying water quality data. A data model {{was employed to}} manage the spatio-temporal data. The spatial data engine of ArcSDE was used to access the database. A <b>data</b> <b>relationship</b> model was developed to perform data communication between GIS and the statistical software. Visual Basic was used to construct links between all the software packages being implemented. This allows {{the combination of the}} spatial and temporal characteristics into the water quality mathematical analysis. Ten water quality parameters were selected from a water quality monitoring programme to validate the present approach. Department of Land Surveying and Geo-InformaticsDepartment of Civil and Environmental Engineerin...|$|E
5000|$|Termination: What {{happens when}} the <b>data</b> sharing <b>relationship</b> is ended? ...|$|R
40|$|When {{computer}} security violations are detected, computer forensic analysts attempting {{to determine the}} relevant causes and effects are forced to perform the tedious tasks of finding and preserving useful clues in large networks of operational machines. To augment a computer crime investigator 's efforts, the approach {{presented in this paper}} is an expert system with a decision tree that uses predetermined invariant relationships between redundant digital objects to detect semantic incongruities. By analyzing data from a host or network and searching for violations of known <b>data</b> <b>relationships,</b> particularly when an attacker is attempting to hide his presence, an attacker's unauthorized changes may be automatically identified. Examples of such invariant <b>data</b> <b>relationships</b> are provided, as are techniques to identify new, useful ones. By automatically identifying relevant evidence, experts can focus on the relevant files, users, times and other facts first...|$|R
40|$|Abstract. This paper {{reports on}} the {{progress}} of an extension to a journal publishing system (OJS) to add RDF aggregation. The system is a lightweight open source repository solution with full CMS features for devolved publishing, a new semantic module is in development for enhanced navigation, searching and for content re-purposing. African Journals Online is used as the example live installation of the extended OJS. Further functionality is being developed to aggregate the large existing metadata resource as a RDF Store, which can be queried using RDQL, to uncover underlying <b>data</b> <b>relationships</b> expressed via formats such as FOAF, or for reuse via RSS. In order to preserve <b>data</b> <b>relationships</b> when harvesting the existing OAI:PMH interface now offers RDF format metadata – and an extension of the set support within the OAI protocol has been prototyped. 1...|$|R
40|$|Research: – 2014 - 2015 : Entity summarizarion for RDF {{entities}} utilizing incremental hierarchical conceptual clustering {{to improve}} diversity. Predication similarity for document similarity and retrieval (NIH-NLM). Access control mechanisms for data exchange using knowledge representation and Semantic Web technologies (AFRL). – 2013 : Semantic matching of heterogeneous events. Applying Linked Data and Semantic Web technologies for the Materials Science domain (President’s Material Genome Initiative). – 2012 : Property alignment for Linked Open Data. Large scale LOD data analysis using Map-Reduce. Informativeness analysis on micro-blog content. – 2011 : Linked Open <b>Data</b> <b>Relationship</b> Identification. Partial and Causal relationships. – 2010 : Cloud computing techniques and specialized tools for NMR data processing...|$|E
30|$|Artificial neural {{networks}} (ANNs) {{can be considered}} as simplified computational structures that are inspired by observed process in natural networks of biological neurons in the brain. They are nonlinear mapping architectures based on the function of the human brain, therefore {{can be considered as}} powerful tools for modeling, especially when the underlying <b>data</b> <b>relationship</b> is unknown. A very important feature of these networks is their adaptive nature, where “learning by example” replaces “programming” in solving problems. In other words, in contrast to conventional methods, which are used to perform specific task, most {{neural networks}} are more versatile. This feature raises a very appealing computational model which can be applied to solve variety of problems.|$|E
40|$|Abstract. The {{design of}} data mining system in {{database}} is researched. Vast {{amounts of information}} contained in the database, and the data show the diversity of characteristics, resulting in lower efficiency of data mining in database, which database brought greater difficulties to information query. To avoid these shortcomings, database performance optimization method based on cloud computing is proposed. The model of cloud computing <b>data</b> <b>relationship</b> is established to describe the connection between related data inthe database, thus providing the basis for data query. The load state of data nodes is calculated to enable rapid information inquiryin the database. Experimental results show that using this algorithm to optimize data inquiry in database can improve the efficiency of informationinquiry indatabase effectively...|$|E
5000|$|The DataONE {{federation}} of data repositories uses BagIt as a serialization format for transporting data packages from data repositories to end users. These data packages consist of heterogeneous data {{objects that are}} collected in BagIt and linked by including an OAI-ORE compatible resource map in a standard location in the bag for describing <b>data</b> <b>relationships.</b>|$|R
5000|$|Data Descriptions: This {{component}} of the Enterprise Architecture identifies how data is maintained, accessed, and used. At a high level, agencies define the data and describe the <b>relationships</b> among <b>data</b> elements used in the agency's information systems. The <b>Data</b> Descriptions and <b>Relationships</b> component can include data models that describe the data underlying the business and information needs of the agency. Clearly representing the <b>data</b> and <b>data</b> <b>relationships</b> is important for identifying data that can be shared corporately, for minimizing redundancy, and for supporting new applications ...|$|R
50|$|Each row in a table has its {{own unique}} key. Rows in a table {{can be linked to}} rows in other tables by adding a column for the unique key of the linked row (such columns are known as foreign keys). Codd showed that <b>data</b> <b>relationships</b> of {{arbitrary}} complexity can be represented by a simple set of concepts.|$|R
