154|200|Public
30|$|Conclusion Acute renal <b>failure</b> <b>occurrence</b> in {{intensive}} care is a critical step with a very derogatory prognosis significance. A better understanding of its risk factors and prognosis is basic for more effective management.|$|E
40|$|Finite failure NHPP models {{proposed}} in the literature exhibit either constant, monotonic increasing or monotonic decreasing <b>failure</b> <b>occurrence</b> rates per fault, and are in-adequate to describe the failure process underlying cer-tain failure data sets. In this paper, we propose the log-logistic reliability growth model, which can capture the increasing=decreasing nature of the <b>failure</b> <b>occurrence</b> rate per fault. Equations to estimate {{the parameters of the}} exist-ing finite failure NHPP models, as well as the log-logistic model, based on failure data collected in the form of inter-failure times are developed. We also present an analysis of two data sets, where the underlying failure process could not be adequately described by the existing models, which motivated the development of the log-logistic model. ...|$|E
30|$|To {{describe}} the failure and repair {{process of the}} production systems we consider a failure distribution that has a constant failure and repair rate representing the exponential probability distribution. Some {{of the reasons for}} <b>failure</b> <b>occurrence</b> may be undetectable defects, abuse, low-safety factor, etc.|$|E
40|$|Most {{software}} reliability growth models specify the expected number of failures {{experienced as a}} function of testing effort or calendar time. However, there are approaches to model the development of intermediate factors driving <b>failure</b> <b>occurrences.</b> This paper starts out with presenting a model framework consisting of four consecutive relationships. It is shown that a differential equation representing this framework is a generalization of several finite failures category models. The relationships between the number of test cases executed and expected structural coverage, and between expected structural coverage and the expected number of <b>failure</b> <b>occurrences</b> are then explored further. A non-homogeneous Markov model allowing for partial redundancy in sampling code constructs is developed. The model bridges the gap between setups related to operational testing and systematic testing, respectively. Two extensions of the model considering the development of the number of <b>failure</b> <b>occurrences</b> are discussed. The paper concludes with showing that the extended models fit into the structure of the differential equation presented at the beginning, which permits further interpretation. [...] ...|$|R
40|$|International audienceOpen Source Software (OSS) {{products}} {{are widely used}} although a general consensus on their quality is far to be reached. Providing results on OSS reliability - as quality indicator - contributes to {{shed some light on}} this issue and allows organizations to make informed decisions in adopting OSS products or in releasing their own OSS. In this paper, we use a classical technique of Software Reliability Growth to model <b>failures</b> <b>occurrences</b> across versions. We have collected data from the bug tracking systems of three OSS products, Mozilla Firefox, OpenSuse and OpenOffice. org. Our analysis aims at determining and discussing patterns of <b>failure</b> <b>occurrences</b> in the three OSS products to be used to predict reliability behaviour of future releases. Our findings indicate that in the three cases, <b>failures</b> <b>occurrences</b> follow a predetermined pattern, which shows: a) an initial stage in which the community learns the new version b) after this first period a rapid increase of the failure detection rate until c) very few failures are left and the discovery of a new failure discovery is rare. This is the stage in which the version can be considered reliable...|$|R
40|$|Failure modes {{analysis}} and diagnostic architectures are very interesting aspects for plants based on PV panel. In fact, these plants {{are called to}} operate for many years. The monitoring of plant parameters and performances {{is a very important}} task that can be obtained by means a well-designed monitoring system. This approach allows to improve complex system maintenance policies and, at the same time, to achieve a reduction of unexpected <b>failure</b> <b>occurrences</b> in the most critical components...|$|R
40|$|The paper {{proposes a}} novel {{approach}} to service differentiation using both 'classical' QoS parameters and novel resilience-oriented QoR (Quality of Resilience) parameters. In this concept, two network states are defined, 'fully operational' and 'after failure', enabling the operators to define precisely the QoS guarantees before and after a <b>failure</b> <b>occurrence,</b> and to distribute Information about failure severity to a customer/user. As such, a combined QoS/QoR approach {{can be seen as}} a kind of an 'insurance' for the customer, i. e. sharing the risk of a <b>failure</b> <b>occurrence</b> and enabling selective treatment of Individual services. In the 'after failure' state, the failure is unverifiable for the user, and a service with a lower QoS guarantee Is provided at possibly reduced costs...|$|E
40|$|AbstractEvaluating and {{analyzing}} the {{risk in the}} mining industry is a new approach for improving the machinery performance. Reliability, safety, and maintenance management based on the risk analysis can enhance the overall availability and utilization of the mining technological systems. This study investigates the <b>failure</b> <b>occurrence</b> probability of the crushing and mixing bed hall department at Azarabadegan Khoy cement plant by using fault tree analysis (FTA) method. The results of the analysis in 200 h operating interval show that the probability of <b>failure</b> <b>occurrence</b> for crushing, conveyor systems, crushing and mixing bed hall department is 73, 64, and 95 percent respectively and the conveyor belt subsystem found as the most probable system for failure. Finally, maintenance {{as a method of}} control and prevent the occurrence of failure is proposed...|$|E
40|$|The {{ability of}} {{overcoming}} service interruptions, i. e., resilience, {{has always been}} an irremissible requirement for communication networks. Resilient schemes can either reserve in advance network spare resources (protection schemes) or found them upon <b>failure</b> <b>occurrence</b> (restoration schemes). While fixed protection schemes have been extensively used thus far in the telephone industry, the envisioned dynamic Optical Layer (OL) and the lack of flexibility proper of protection schemes are driving network designer to resort to restoration schemes. By dynamically looking for backup paths of spare wavelengths upon <b>failure</b> <b>occurrence,</b> restoration schemes have the potential to yield efficient and flexible resource reservation. However restoration schemes, generally, present long failure recovery time (i. e., the time required to restore the disrupted connections). This is mainly due to the heavy signaling that originates upon <b>failure</b> <b>occurrence.</b> In high capacity WDM networks, the presence of many connections concurrently seeking restoration exacerbates the above problem as, in existing restoration schemes, coordination among restoration attempts may further slow down the process completion. To exploit the flexibility of restoration schemes and decrease their failure recovery time and resource contention, the authors propose a class of fast and efficient path restoration schemes called Stochastic Preplanned Restoration (SPR) schemes. In the SPR schemes each active connection is associated with an agent resident at the connection master node. Communication between agent...|$|E
40|$|The growing {{computational}} {{and storage}} needs of several scientific applications mandate {{the deployment of}} extreme-scale parallel machines, such as IBM’s BlueGene/L which can accommodate as many as 128 K processors. One of the challenges when designing and deploying these systems in a production setting {{is the need to}} take <b>failure</b> <b>occurrences,</b> whether it be in the hardware or in the software, into account. Earlier work has shown that conventional runtime faulttolerant techniques such as periodic checkpointing are not effective to the emerging systems. Instead, the ability to predict <b>failure</b> <b>occurrences</b> can help develop more effective checkpointing strategies. Failure prediction has long been regarded as a challenging research problem, mainly {{due to the lack of}} realistic failure data from actual production systems. In this study, we have collected RAS event logs from BlueGene/L over a period of more than 100 days. We have investigated the characteristics of fatal failure events, as well as the correlation between fatal events and non-fatal events. Based on the observations, we have developed three simple yet effective failure prediction methods, which can predict around 80 % of the memory and network failures, and 47 % of the application I/O failures. ...|$|R
40|$|In {{fault-tolerant}} computing, dependability {{of systems}} is usually demonstrated by abstracting from failure probabilities (under simplifying assumptions on <b>failure</b> <b>occurrences).</b> In the specification framework FOCUS, we show under which conditions {{and to which}} extent this is sound: We use a specification language that is interpreted in the usual abstract model and in a probabilistic model. We give probability bounds showing the degree of faithfulness of the abstract model wrt. the probabilistic one. These include cases where the usual assumptions are not fulfilled. 1...|$|R
40|$|Physical asset {{management}} (PAM) is of increasing concern for companies in industry today. A key performance area of PAM is asset care plans (ACPs), which consist of maintenance {{strategies such as}} usage based maintenance (UBM) and condition based maintenance (CBM). Data obtained from the South African mining industry was modelled using a CBM prognostic model called the proportional hazards model (PHM). Results indicated that the developed model produced estimates that were reasonable representations of reality. These findings provide an exciting basis {{for the development of}} future Weibull PHMs that could result in huge maintenance cost savings and reduced <b>failure</b> <b>occurrences...</b>|$|R
40|$|This master’s {{thesis is}} focused on {{description}} and application of the FMEA method at the manufacturing company. The thesis is based on important steps such as introducing a knowledge database of all possible functions, failures, and countermeasures to minimize risks of a <b>failure</b> <b>occurrence</b> (detection, prevention), a failure assessment by Pareto analysis, and verification of the introduced template by a real project...|$|E
40|$|OBJECTIVES ANRS 139 TRIO {{trial was}} a phase II noncomparative trial that {{evaluated}} in highly experienced patients, {{a combination of}} raltegravir, etravirine and darunavir boosted with ritonavir. We analyzed emergence of resistant viruses {{at the time of}} virological failure and investigated the impact of baseline integrase polymorphisms on virological <b>failure</b> <b>occurrence.</b> METHODS Bulk sequencing of protease, reverse transcriptase and integrase genes was performed for 103 patients at baseline and 14 patients at the time of virological failure. Additionally, integrase clonal analyses were performed at baseline and at virological failure in patients with successful integrase gene amplification. Impact of baseline integrase polymorphisms on virological <b>failure</b> <b>occurrence</b> was analyzed using Fisher exact and Wilcoxon tests. RESULTS In the 14 failing patients median viral load at virological failure was 90 copies/ml (interquartile range = 60 - 783). Emergence of darunavir and etravirine resistance mutations was observed at virological failure in only one and three patients, respectively. Raltegravir resistance mutations were found neither at baseline nor at the time of virologic failure. Integrase clonal analyses showed neither the presence nor the selection of minority variants carrying raltegravir resistance mutations at baseline or at virological failure. No impact of baseline integrase polymorphisms was observed on virological failure either at week 24 or at week 48. CONCLUSION Virological failure occurred in a small proportion of patients with low viral load. No raltegravir resistance mutations were observed using bulk sequencing or clonal analyses, and darunavir and etravirine resistance-associated mutations were detected in only one and three patients, respectively at virological failure. No impact of baseline integrase polymorphism was observed on virological <b>failure</b> <b>occurrence...</b>|$|E
30|$|Sahin and Polatoglu (1996, 1998) {{offered a}} random {{distribution}} of products based on <b>failure</b> <b>occurrence</b> and {{variables related to}} the estimated costs. Murthy and Blischke (2005) studied the terms of warranty obligations of cost models and warranty models based on different platforms. St. John and Cassady (2010) considered a heterogeneous population of customers based on exponentially distributed failures to develop this study and {{form the basis of}} theoretical research.|$|E
40|$|An {{analysis}} of experimental tests and a literature {{survey of the}} issue revealed that the problems connected with assessment of costs and effectiveness of transport means repairs has a significant influence on their operation efficiency. Operating factors affecting the elements of technical objects cause negative changes in their features resulting in failures. The failures {{are referred to as}} events which significantly impair the vehicle operation efficiency, safety and reliability. On the basis of experimental tests concerning times of <b>failures</b> <b>occurrence,</b> {{it was found that the}} set of failures can be divided into subsets of primary and secondary failures. The tests results revealed that the most frequent cause of secondary <b>failures</b> <b>occurrence</b> was improperly performed primary repairs. Primary failures are not related to each other and they appear randomly. However, secondary failures are related to each other as their occurrence is conditioned by the primary failure and results from an inappropriate performance of the successive secondary failure. Basing on an {{analysis of}} the author’s own tests results, it was established that failures of transport means used in real transport systems are the effect of impact of various forcing factors. Some failures result from the natural wear of machine elements, whereas, other failures can be caused by inappropriate repair of the previous damage. Thus, there occur the so called secondary failures in a short period of time. In connection with this, high efficiency of the repair performance is of primary importance as it largely affects efficiency of transport task...|$|R
40|$|Cloud {{computing}} is {{an internet}} based paradigm which provide different computing services {{to millions of}} end users. Due to its complex distributed architecture and characteristics like dynamism and openness, it is always susceptible to faults and <b>failures.</b> <b>Occurrence</b> of faults in cloud delays the service delivery and consequently degrades the system performance. Therefore, an efficient and robust fault handling technique is always required to maintain the system reliability. Various fault handling techniques have been evolved through the years. This paper explains the various causes of faults and uncertainties and presents a brief survey on different fault handling approaches in cloud computing along with the techniques based on those approaches...|$|R
40|$|Analysis {{of failure}} modes and causes and {{diagnostic}} architectures are fundamental aspects for plants based on photovoltaic (PV) panel. In fact, for these plants, {{high level of}} reliability is {{necessary in order to}} operate, without failures, in the time taking into consideration also the typical lifetime of these plants. To this aim the monitoring of both plant parameters and plant performances is a very important task that can be obtained, as presented in this paper, by means of a well-designed diagnostic and monitoring system. This approach allows to improve complex system maintenance policies and, at the same time, to achieve a reduction of unexpected <b>failure</b> <b>occurrences</b> in the most critical components...|$|R
40|$|Abstract: To {{decrease}} {{the probability of}} severe accidents for the stream boiler, a kind of preventive maintenance named operational check based RCM (Reliabilty Centred Maintenance) is put forward to reduce the probability of multi-ply <b>failure</b> <b>occurrence</b> caused by the covert failure, which can reduce or hold back the occurrence of severe accident. The instance is given to describe {{the influence of the}} preventive maintenance named operational check for the occurrence probability of severe accident. The instance indicates that the occurrence probability of severe accident will greatly reduce, so this method is useful for machine management...|$|E
40|$|This {{paper has}} studied failure {{initiation}} {{of the root}} section of 60 m tall industrial steel chimney. Cracks that occurred in steel wall of the wind shield have significantly influenced integrity of the structure. Analytical and numerical analysis of <b>failure</b> <b>occurrence</b> was performed. Location of extreme stress values in the steel structure were identified numerically by finite element method. Identified locations coincided with {{the location of the}} cracks initiation. The results of analysis identified causes of the failure initiation and allowed expression of the recommendation for root redesign and further maintenance procedures...|$|E
40|$|Increasing cost {{pressure}} due to regulatory guidelines, changing topology of electrical power generation {{as well as}} ageing of equipment and very volatile load flows are the main challenges for {{transmission and distribution system}} operators. Minimizing the total cost and providing a high security of supply at the same time is the aim of system operators. An efficient asset management will help to achieve theses aims. The optimal usage of equipment as well as determining their maximal lifetime are essential aspects in this optimisation process. One of the basic requirements is a comprehensive knowledge about equipments, their type specific behaviour as well as the impact of maintenance strategies on minor and major failure occurrences. Modelling the type specific failure occurrences of high voltage circuit breakers is the objective of this dissertation. First, based on a comprehensive database of minor and major failures as well as empiric findings, the failure model in case of current maintenance actions will be developed and applied on a representative population of circuit breakers. The new type specific ageing models show clear advantages over the general bath tub curve approach. The minor to major failure model (m 2 M) developed in this thesis, enables the mapping between maintenance actions and failure occurrences for the first time. Based on a probabilistic approach the model describes the progression from a minor to a major failure. Here it is presumed, that due to deferred maintenance, the minor failure which is normally discovered is not remedied and can subsequently progress to a major failure. The estimated <b>failure</b> <b>occurrence</b> after the normal maintenance interval is exceeded as a superposition of the previously calculated <b>failure</b> <b>occurrence</b> (current maintenance activities) with additional major failures which occur as a result of minor failures. This modelling approach allows a prognosis for type specific failure occurrences in case of modified maintenance actions. Comprehensive analysis on real maintenance data demonstrates the applicability of this approach for circuit breakers as well as for other equipments. Hence, type specific models to predict the <b>failure</b> <b>occurrence</b> of high voltage circuit breakers are available for the first time...|$|E
40|$|Includes bibliographical {{references}} (pages 101 - 103). In {{order for}} an electronic telephone switching system to perform its functions without loss of credits and earnings from customers, accurate reliability should be predicted before system release. A methodology for making this prediction is developed {{within the context}} of a particular system (Time Division Switching System). A bottom-up approach was used for system reliability prediction with step-by-step methods from component or circuit pack level to board, block, subsystem, and system level. For important component or circuit pack level reliability, a suitable model selection method of <b>failure</b> <b>occurrences</b> is recommended along with its parameter estimation method using statistical analysis. For expensive board level reliability, a weak link identification method and a reliability improving method are recommended. For inexpensive block level reliability, its components or circuit packs reliability were calculated from a model that included part stress analysis. For software reliability prediction, a suitable model selection method of <b>failure</b> <b>occurrences</b> is recommended, along with maximum likelihood parameter estimation. An objective failure intensity set-up method based on system test cost and system operation cost is recommended along with a prediction method of additional testing time required before system release. It was verified that a Time Division Switching system satisfied the reliability recommended by the International Telegraph and Telephone Consult Committee. In addition, the percentages of hardware reliability and software reliability were predicted along with each subsystem reliability, unavailability, number of failures, down time, mean time to first failure, and failure intensity. M. S. (Master of Science...|$|R
40|$|Water {{mains failure}} {{studies have focused}} on failure {{clustering}} analysis which measures the spatial clustering of failures and failure factor analysis which quantifies the impact of various factors on <b>failure</b> <b>occurrences.</b> This study aims to enhance these two analyses by using a spatial analysis approach. The improvements include (1) initial global and multi-scale geographical statistics to measure the failure clustering, (2) refining quantitative relationships between failure factors and <b>failure</b> <b>occurrences</b> and (3) filling the research gap in subtropical regions by a Hong Kong case study. The global and multi-scale failure cluster measures are based on Moran's I and Ripley's K-statistic. Failure factors are analysed using descriptive statistics and regressions. Failures rates per unit pipe length were found highly clustered in space. The scale at which the failures are the most clustered was also identified. The failure factor analysis revealed quantitative relationships that were more detailed than previous studies, or specific for Hong Kong, between failure rate and four factors: pipe diameter, pipe age, material and temperature. The global failure cluster measure verifies the necessity for cluster analysis in identifying areas of high failure risk. The multi-scale measure suggests that it should be effective and economic to monitor areas of high failure risk if the area size is 1 - 1. 5 km in radius. The refined failure factor analysis can enhance the accuracy of failure risk prediction models and results in several failure control recommendations for Hong Kong and other subtropical cities. Department of Land Surveying and Geo-Informatic...|$|R
40|$|Purpose. To {{examine the}} {{operation}} of the automatic locomotive signaling system (ALS), to find out the influence of external factors on the devices operation {{and the quality of the}} code information derived from track circuit information, as well as to enable modeling of <b>failure</b> <b>occurrences</b> that may appear during operation. Methodology. To achieve this purpose, the main obstacles in ALS operation and the reasons for their occurrence were considered and the system structure principle was researched. The mathematical model for input equipment of the continuous automatic locomotive signaling system (ALS) with the number coding was developed. It was designed taking into account all the types of code signals “R”, “Y”, “RY” and equivalent scheme of replacing the filter with a frequency of 50 Hz. Findings. The operation of ALSN with a signal current frequency of 50 Hz was examined. The adequate mathematical model of input equipment of ALS with a frequency of 50 Hz was developed. Originality. The computer model of input equipment of ALS system in the environment of MATLAB+Simulink was developed. The results of the computer modeling on the outlet of the filter during delivering every type of code combination were given in the article. Practical value. With the use of developed mathematical model of ALS system operation we have an opportunity to study, research and determine behavior of the circuit during the normal operation mode and <b>failure</b> <b>occurrences.</b> Also there is a possibility to develop and apply different scheme decisions in modeling environment MATLAB+Simulink for reducing the influence of obstacles on the functional capability of ALS and to model the occurrence of possible difficulties...|$|R
40|$|International audienceThe {{objective}} {{of this paper is}} to assess the risks associated with LPG loading and especially the risks that could undergo the pump. The pump is substantial equipment that ensures and guarantees the LPG loading. A list of failure scenarios related to this equipment was conducted. The most relevance will be simulated. AnyLogic platform based on Multi-Agent Systems is used to assess the safety of this supply chain. This simulation allows the calculation of the criticality of each <b>failure</b> <b>occurrence</b> and specifies the status of the equipment (working, degraded, shutdown). The final goal is orienting responsible to the best assessment decisions...|$|E
40|$|Keywords-two-dimensional {{warranty}}, warranty costs, reliability, automotive application Abstract—The article {{deals with}} current problems of warranty costs in automotive applications. The two-dimensional warranty {{widely used in}} automotive industry is presented. The relationship between warranty costs and product reliability is also presented. The article analyses problems with estimation {{of a number of}} <b>failure</b> <b>occurrence</b> over a warranty period and estimation of costs related to repair failures. The mathematical model enables to predict warranty costs for two-dimensional warranty is presented. The article also deals with problems of estimation of an instant of warranty period expiration and demonstrates its estimation on an example of a vehicle...|$|E
40|$|National audienceThis article {{presents}} {{a method of}} diagnosis of avionics equipment based on the temporal correlation of events. A failure is detected thanks to the execution of built-in tests organised in test trees. The method proposed is based on two parameters: the temporal data coming from the test tree execution and the propagation time of failures. The temporal correlation window between the failure messages is obtained thanks {{to the analysis of}} the ways of failure propagation. The identification of this time window allows determining the degree of correlation between the different failure messages. The goal is to distinguish between single <b>failure</b> <b>occurrence</b> with propagation phenomenon, and multiple occurrences of failure...|$|E
40|$|Failure {{assessment}} {{encompasses the}} identification and characterization both of potential failure mechanisms in systems under development and of actual <b>failure</b> <b>occurrences</b> in operational systems. This paper presents several {{of the most widely}} used and useful techniques for failure assessment across the system lifecycle with an emphasis on the role of software. For each technique the paper describes its purpose and background, summarizes the process of performing the technique, and evaluates the technique’s strengths and limitations. The discussion provides lessons learned from practice, examples from spacecraft applications, and pointers to additional work in the field. The paper describes some of the tools that are available to help the practitioner select and implement failure assessment techniques and identifies likely future directions in failure assessment...|$|R
40|$|This {{paper has}} {{addressed}} {{one of the}} issues raised in this context, which is the dependable composition of Web services, i. e., understanding how fault tolerance should be addressed in the Web service architecture. While dependability in closed distributed systems is conveniently addressed by transactions when concerned with both concurrency control and <b>failure</b> <b>occurrences,</b> it can hardly rely on such a mechanism in an open environment. Our solution to this concern lies in forward error recovery that enables accounting for the specific of Web services and that leads to structure Web services-based systems in terms of co-operative actions. In particular, we are able to address dependable service composition in a way that neither undermines the Web service's autonomy nor increases their individual access latenc...|$|R
40|$|Semiconductor Industry (SI) {{is facing}} the {{challenge}} of short product life cycles due to increasing diversity in customer demands. As a result, it has transformed into a high-mix low-volume production line that requires sustainable production capacities. However, {{significant increase in the}} unscheduled equipment breakdowns, limits its success. It is observed that in a high-mix low-volume production, product commonality is inversely proportional to <b>failure</b> <b>occurrences</b> and number of corrective actions in each failure. This provides evidence of misdiagnosis for equipment failures and causes. Moreover, equipment {{is believed to be the}} only source for product quality drifts that increase the unscheduled breakdowns and result in unstable production capacities. In this paper, we propose two defense lines against increasing unscheduled equipment breakdowns due to misdiagnosis...|$|R
40|$|The aim of {{the study}} is to analyse and assess the water supply network failure {{frequency}} in last ten years, with particular emphasis on the last year of the analysis. The analysis is based on actual data obtained from the water company. The study contains the analysis of the network failure with division into used material, the type of network and place of <b>failure</b> <b>occurrence.</b> Also the failure rate was calculated. Continuous changes in the age and material structure of the water network cause the need for conducting failure frequency research because data on failure rate are the key indicators for operational policy of water supply systems...|$|E
40|$|The {{availability}} of the gas supply system safety concerns the crucial issue in gas infrastructure operation and management. In recent years, the observed development of gas supply system does not protect against the <b>failure</b> <b>occurrence</b> of the gas network. Gas network requires proper analysis of its functioning, as it forms a complex system. Gas companies are responsible for supplying gas to consumers in reliable and safe way. In the paper the approach to failure cost and losses assessment with implementation of clustering analysis was presented. Such comparison {{can be helpful in}} costs assessment in different distribution gas systems. The analysis, was based on the operational data obtained from the gas companies...|$|E
40|$|Maintenance of {{hospitality}} buildings {{is complex and}} dynamic as {{the performance of the}} engineering systems is subjected to sensitive users? requirements and high expectation of the top management for supporting the business. With detailed case studies drawn from a representative hotel, this paper presents the practices, work load and resource requirement for maintaining the engineering systems and the building. In?house and contracted?out maintenance, repair and retrofitting works are examined. Common failure modes and <b>failure</b> <b>occurrence</b> rates are reported. A concept of five strategic bases of maintenance is presented for the development of maintenance programmes. Performance indicators for measuring the effectiveness of maintenance are established for the hospitality engineering systems and applied in the hotel studied to illustrate the assessment of maintenance performance.; Maintenance {{of hospitality}} buildings is complex and dynamic as the performance of the engineering systems is subjected to sensitive users? requirements and high expectation of the top management for supporting the business. With detailed case studies drawn from a representative hotel, this paper presents the practices, work load and resource requirement for maintaining the engineering systems and the building. In?house and contracted?out maintenance, repair and retrofitting works are examined. Common failure modes and <b>failure</b> <b>occurrence</b> rates are reported. A concept of five strategic bases of maintenance is presented for the development of maintenance programmes. Performance indicators for measuring the effectiveness of maintenance are established for the hospitality engineering systems and applied in the hotel studied to illustrate the assessment of maintenance performance. Department of Building Services Engineerin...|$|E
40|$|We {{present the}} first {{large-scale}} analysis of failures in a data center network. Through our analysis, {{we seek to}} answer several fundamental questions: which devices/links are most unreliable, what causes failures, how do failures impact network traffic and how effective is network redundancy? We answer these questions using multiple data sources commonly collected by network operators. The key findings of our study are that (1) data center networks show high reliability, (2) commodity switches such as ToRs and AggS are highly reliable, (3) load balancers dominate in terms of <b>failure</b> <b>occurrences</b> with many short-lived software related faults, (4) failures have potential to cause loss of many small packets such as keep alive messages and ACKs, and (5) network redundancy is only 40 % effective in reducing the median impact of failure...|$|R
40|$|International audienceConsidering {{the great}} {{importance}} of sensor {{data in the}} study of environmental systems, efforts are focused on the validation problem. Although off-line sensor data validation is necessary for providing validated database to the end user, on-line failure detection and isolation (FDI) is essential for reliable system monitoring and management. Thus paper thus investigates the possibility of implementing on-line FDI techniques for monitoring an urban rain gauge network. A quantitative model-based approach is presented and the basis of a FDI scheme is described. Analytical middles between sensors are designed and involved in the generation of failure sensitive signals. These signals are the evaluated in order to detect <b>failure</b> <b>occurrences,</b> isolate the faulty sensors and generate alarms for monitoring operators. Results obtained with actual homogeneous rainfall data are provided as illustrations...|$|R
40|$|Start-up {{subsidies}} are a frequently employed policy instrument, {{the use of}} which is justified by alleged market failure resulting from positive external effects and capital market imperfections. This article investigates whether the allocation of subsidies reflects a policy focus on addressing these market <b>failure</b> <b>occurrences.</b> However, using survey data from the East German state of Thuringia, logistic regressions reveal a rather random subsidization of start-ups. Furthermore, propensity score matching suggests that subsidized start-ups would have survived and thrived in any case, an indication of deadweight losses of start-up subsidies. The analysis points to serious information problems arising when subsidies should be allocated to remedy market failure. Making the situation even more problematic is that failure to precisely target start-up subsidies is {{likely to result in}} market distortions and ineffectiveness. Start-ups, Subsidies, Subsidy allocation, Policy evaluation...|$|R
