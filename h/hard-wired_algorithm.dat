3|10|Public
40|$|Evolution of {{cooperation}} and competition can appear when multiple adaptive agents share a biological, social, or technological niche. In the present work we study how cooperation and competition emerge between autonomous agents that learn by reinforcement while using only their raw visual input as the state representation. In particular, we extend the Deep Q-Learning framework to multiagent environments to investigate the interaction between two learning agents in the well-known video game Pong. By manipulating the classical rewarding scheme of Pong we show how competitive and collaborative behaviors emerge. We also describe the progression from competitive to collaborative behavior when the incentive to cooperate is increased. Finally we show how learning by playing against another adaptive agent, instead of against a <b>hard-wired</b> <b>algorithm,</b> results in more robust strategies. The present work shows that Deep Q-Networks can become {{a useful tool for}} studying decentralized learning of multiagent systems coping with high-dimensional environments...|$|E
40|$|The {{field of}} Machine Vision is still {{dominated}} by classical imaging systems {{consisting of a}} camera attached to a PC. Especially very fast processes with high requirements on minimal latency or maximal refresh rate are increasingly starting to stretch such systems to their limits. Image sensors with integrated feature extraction – so-called ”Vision Chips” – already allow {{reducing the amount of}} data on chip compared to conventional imagers, thereby narrowing down the output to relevant data. Freely programmable systems are not restricted to the execution of a specific <b>hard-wired</b> <b>algorithm.</b> However, not least because of the necessary, but rather complex external circuitry, none of the proposed systems have so far been able to gain acceptance. This paper introduces an architecture of an Application-Specific Instruction Set Processor (ASIP) based control system, which can be directly incorporated into a System-on-Chip (SoC). The sensor’s functional units are integrated into the micro-controller as additional data path elements, making them directly accessible as part of the instruction set. Furthermore, a parameterizable input/output (IO) controller and an Serial Peripheral Interface(SPI) based configuration interface enable the system to be used widely self-sufficient with specific algorithms. The proposed control system has been integrated into a prototypical Vision Chip and has been successfully tested...|$|E
40|$|In this work, we {{describe}} and evaluate a grasping mechanism {{that does not}} make use of any specific object prior knowledge. The mechanism makes use of second-order relations between visually extracted multi–modal 3 D features provided by an early cognitive vision system. More specifically, the algorithm is based on two relations covering geometric information in terms of a co-planarity constraint as well as appearance based information in terms of co-occurrence of colour properties. We show that our algorithm, although making use of such rather simple constraints, is able to grasp objects with a reasonable success rate in rather complex environments (i. e., cluttered scenes with multiple objects). Moreover, we have embedded the algorithm within a cognitive system that allows for autonomous exploration and learning in different contexts. First, the system is able to perform long action sequences which, although the grasping attempts not being always successful, can recover from mistakes and more importantly, is able to evaluate the success of the grasps autonomously by haptic feedback (i. e., by a force torque sensor at the wrist and proprioceptive information about the distance of the gripper after a gasping attempt). Such labelled data is then used for improving the initially <b>hard-wired</b> <b>algorithm</b> by learning. Moreover, the grasping behaviour has been used in a cognitive system to trigger higher level processes such as object learning and learning of object specific grasping...|$|E
40|$|Weight {{modifications}} in traditional neural nets are computed by <b>hard-wired</b> <b>algorithms.</b> Without exception, all previous weight change algorithms have many specific limitations. Is it (in principle) possible to overcome limitations of <b>hard-wired</b> <b>algorithms</b> by allowing neural nets {{to run and}} improve their own weight change algorithms? This paper constructively demonstrates that the answer (in principle) is `yes'. I derive an initial gradient-based sequence learning algorithm for a `self-referential' recurrent network that can `speak' about its own weight matrix in terms of activations. It uses some of its input and output units for observing its own errors and for explicitly analyzing and modifying its own weight matrix, including {{those parts of the}} weight matrix responsible for analyzing and modifying the weight matrix. The result is the first `introspective' neural net with explicit potential control over all of its own adaptive parameters. A disadvantage of the algorithm is its high c [...] ...|$|R
40|$|At {{the input}} to the {{calorimeter}} {{part of the}} Level- 1 Trigger a Pre-Processor system performs the preprocessing of about 7200 analogue trigger-tower signals. The preprocessing includes digitisation, identification of the corresponding bunch-crossing in time (BCID), calibration of the transverse energy, rate monitoring, readout of raw trigger data, and high-speed data transmission to the following processors. The preprocessing {{of a large number}} of analogue signals requires a compact Pre-Processor system with fast <b>hard-wired</b> <b>algorithms</b> implemented in application-specific integrated circuits (ASICs). In this paper we present the tasks of the Pre-Processor, measurement results, and advanced technologies used for the preprocessing of about 7200 analogue signals...|$|R
40|$|Arrays {{of charge}} coupled devices or linear {{detector}} arrays simultaneously obtain spectral reflectance data of different wavelengths for a target area. Several accommodating a particular bandwidth, are individually {{associated with each}} array. Data from the arrays are read out in parallel and applied to a computer or microprocessor for processing. The microprocessor serves {{to analyze the data}} in real time and if possible, in accordance with <b>hard-wired</b> <b>algorithms.</b> The data are then displayed as an image on an appropriate display unit and also recorded for further use. The display system may be operationally connected to receive a terrain image such that the target area and the analyzed spectral reflectance data are superimposed and simultaneously displayed...|$|R
40|$|Usually weight {{changes in}} neural {{networks}} are exclusively caused by some <b>hard-wired</b> learning <b>algorithm</b> with many specific limitations. I {{show that it}} is in principle possible to let the network run and improve its own weight change algorithm (without significant theoretical limits). I derive an initial gradientbased supervised sequence learning algorithm for an `introspective' recurrent network that can `speak' about its own weight matrix in terms of activations. It uses special subsets of its input and output units for observing its own errors and for explicitly analyzing and manipulating all of its own weights, including those weights responsible for analyzing and manipulating weights. The result is the first `self-referential' neural network with explicit potential control over all adaptive parameters governing its behavior...|$|R
40|$|We examine {{emotional}} algorithms {{and their}} role in a fundamental dilemma that confronts human groups-whether actors should take care of 'me' (compete) or take care of 'we' (cooperate). We argue that human emotions, triggered in algorithmic fashion through four common, although culturally specified, mechanisms, powerfully direct humans to compete or cooperate. Drawing on evolutionary psychology, we first define and characterize these <b>hard-wired</b> emotional <b>algorithms,</b> presenting evidence for their independent influence. Their regulatory influence on human groups, however, can only be appreciated once we examine them as a system. We show how, as a system, these algorithms help explain the dynamic balance that members of human groups can (and often must) achieve between competition and cooperation. We derive three propositions regarding how these algorithms play out in groups. We suggest that understanding these dynamics can help leaders better manage cooperation and competition in organizational groups. Copyright © 2006 John Wiley & Sons, Ltd. ...|$|R
40|$|A {{user-friendly}} {{speech interface}} for car applications is highly needed for safety reasons. This paper will describe a speech interface VLSI designed for car environments, with speech recognition and speech compression/decompression functions. The chip has a heterogeneous architecture composed of ADC/DAC, DSP, RISC, hard-wired logic and peripheral circuits. The DSP not only executes acoustic analysis and output probability calculation of HMMs for speech recognition, but also does speech compression/decompression. On the other hand, the RISC {{works as a}} CPU of the whole chip and Viterbi decoder with an aid of <b>hard-wired</b> logic. An <b>algorithm</b> to recognize a mixed vocabulary of speaker-independent fixed words and speaker-dependent user-defined words in a seamless way is proposed. It is based on acoustic event HMMs which enable a template creation from one sample utterance. The proposed algorithm embedded in the chip is evaluated. Promising results of the algorithm for multiple languages are shown. 1...|$|R
40|$|This paper {{describes}} a generic speech synthesis system called CHATR {{which is being}} developed at ATR. CHATR is designed in a modular way so that module parameters and even which modules are actually used may be set and selected at runtime. Although some interdependencies exist between modules, CHATR offers a useful research tool in which functionally equivalent modules may be easily compared. It also acts as a simple system for those less interested in the internals of speech synthesis but just wish their computer to talk. Topic: speech synthesis, generic systems. Introduction There are many requirements for a speech synthesis system. In addition to high quality natural sounding speech output, the system should be flexible and not simply be <b>hard-wired</b> to particular <b>algorithms.</b> For example it should at least {{be the case that}} new words can be added to the lexicon. Other more general changes should also be possible e. g. specification of new intonational tunes, varying of output voices, [...] ...|$|R
40|$|One of {{the most}} {{striking}} feature of the cortex is its ability to wire itself. Understanding how the visual cortex wires up through development and how visual experience refines connections into adulthood is a key question for Neuroscience. While computational models of the visual cortex are becoming increasingly detailed, the question of how such architecture could self-organize through visual experience is often overlooked. Here we focus on the class of hierarchical feedforward models of the ventral stream of the visual cortex, which extend the classical simple-to-complex cells model by Hubel and Wiesel (1962) to extra-striate areas, and have been shown to account for a host of experimental data. Such models assume two functional classes of simple and complex cells with specific predictions about their respective wiring and resulting functionalities. In these networks, the issue of learning, especially for complex cells, is perhaps the least well understood. In fact, in most of these models, the connectivity between simple and complex cells is not learned butrather <b>hard-wired.</b> Several <b>algorithms</b> have been proposed for learning invariances at the complex cell level based on a trace rule to exploit the temporal continuity of sequences of natural images, but very few can learn from natural cluttered image sequences. Here we propose a new variant of the trace rule that only reinforces the synapses between the most active cells, and therefore can handle cluttered environments. The algorithm has so far been developed and tested at the level of V 1 -like simple and complex cells: we verified that Gabor-like simple cell selectivity could emerge from competitive Hebbian learning. In addition, we show how the modified trace rule allows the subsequent complex cells to learn to selectively pool over simple cells with the same preferred orientation but slightly different positions thus increasing their tolerance to the precise position of the stimulus within their receptive fields...|$|R
30|$|Compared to {{high-level}} parallelization, the low-level {{approach is}} more complicated to implement. In the best case, for the former one simply runs the serial code in parallel on the individual machines; when finished one collects and combines the results. For the latter, when doing the explicit coding one deals with local data portions of the global data array on the individual nodes of the cluster. Hence, one has {{to keep track of}} additional information: for example, given a distribution scheme, which portion of the global data is stored on which node of the cluster? Keeping the number of cluster nodes, the size and the dimensionality of the data arrays arbitrary implies a considerable complication for indexing purposes. By this, while implementing an application one has to take care of two non-trivial tasks. On the one hand, one must program the logic of distributing and collecting the data; i.e. the data handling. On the other hand, one must implement the application’s actual (abstract) algorithm. Those two tasks are conceptually completely different and therefore a mixture of implementations should be avoided. Otherwise there is the risk that features of an initial implementation—like the data distribution scheme—become <b>hard-wired</b> to the <b>algorithm,</b> inhibiting its further evolution. Thus it makes sense to insert a layer of abstraction between the algorithm code and the data distribution logic. Then the abstract algorithm can be written in a serial style from which all knowledge and methodology regarding the data distribution is encapsulated. This layer of abstraction is d 2 o.|$|R
40|$|Research on {{artificial}} {{neural networks}} (ANNs) {{has been carried}} out for more than five decades. A renewed interest appeared in the 80 's with the finding of powerful models like J. Hopfield's recurrent networks, T. Kohonen's self-organizing feature maps, and the back-propagation rule. At that time, there was no platform that was at the same time versatile enough for any ANN model to be implemented and fast enough to solve large problems. Super-computers were the sole exception to this rule, but were prohibitively expensive for most applications. However, both research scientists and application engineers clearly identified the need for such a computing power. This triggered many projects in the field. In parallel, research on multi-processor systems started during the 60 's. Systolic arrays have been proposed in 1979 as a means to fully exploit the possibilities of VLSI. Two previous theses, by F. Blayo and C. Lehmann, have studied the use of bi-dimensional systolic arrays for neural computation. At first, the presented system, called GENES, has been designed for the Hopfield model. Extensions to other ANNs have also been proposed. The goal of the present thesis is to study, design, build, and analyze an efficient accelerator for neural computation. In a first step, the GENES architecture has been extended towards generality and efficiency. This includes a thorough analysis of ANN models, of other neural computers, and of previous GENES implementations. The result of this work is the GENES IV integrated circuit, whose architecture has been co-designed by P. Ienne and the author. The main part of this thesis discusses the architecture, the design and the analysis of the MANTRA I machine, a neural computer based on a GENES IV array with up to 40 × 40 processing elements (PEs). The delta rule (and hence the Perceptron and Adaline rules), the back-propagation rule, the Hopfield model, and the Kohonen model can be implemented on this system. Although not a generic system, such a machine may be regarded as a multi-model neural computer. A prototype has been running for a year and is used daily by software designers. Several novel features distinguish the MANTRA I machine from other neural systems. First, it belongs to the few existing neural computers, contrary to the majority of implementations, which are specific to an application or to an algorithm. The machine does not <b>hard-wire</b> any <b>algorithm,</b> but provides the necessary primitives to implement the target models. This is a key feature for research, since several algorithms or versions of an algorithm can be tested on a problem. It is an important aspect for applications as well, because different ANN models are often cascaded to solve a problem. The GENES IV array — that is, the computing core of the MANTRA I machine — features synapse-level parallelism (i. e., one real or virtual PE is allocated per synapse or neural connection), while most other systems exploit only neuron-level parallelism (i. e., one PE per neuron). Hence, this system aims at a much finer parallelism grain and is well suited for massively parallel architectures. The problem size that can be computed by a neural accelerator should not be limited by the hardware (except for memory size). Therefore, it is essential to support time-sharing of PEs. On the MANTRA I machine, this is achieved by the concept of virtual arrays. Matrices are divided into sub-matrices that can be mapped onto the physical array, which is then time-shared among them. An efficient mechanism has been implemented to swap sub-matrices in background, while some other computation is performed. Since systolic arrays are pipelined systems, it is important to avoid emptying and re-filling them too often, {{in order to keep the}} hardware utilization rate high. Therefore, a systolic instruction flow has been implemented, so that each instruction follows the data for which it has been issued. Like any SIMD system, the MANTRA I machine is composed of a parallel or SIMD module and a control module. The SIMD module consists of the GENES IV array and a set of dedicated units designed for the computation that scales with the number of neurons and would poorly fit on a bi-dimensional array. A complex system of FIFOs and memories sustains the required input/output streams for the systolic array. The control module is a complete SISD system. Its tasks are (1) to control the SIMD module by dispatching instructions, (2) to manage data input and output, (3) to communicate with the external world, and (4) to perform data pre- and post-processing. The SIMD instructions are of the very long instruction word (VLIW) type. Synchronization between the two modules is achieved by an instruction FIFO. The performance of the MANTRA I machine has been analyzed using the delta rule. Measurements show that the sustained performance is very close to its peak value, as long as the problem fits in the memory banks connected to the GENES IV array. Experiments have also been run to investigate the impact of the constraints imposed by the hardware on the convergence of algorithms. Finally, the use of systolic arrays as neural accelerators is discussed in the light of the experience acquired with the GENES IV array and the MANTRA I machine. The weaknesses of the machine are analyzed, and several solutions are proposed to avoid them in a future design. A general discussion of the future of neural computers concludes this thesis...|$|R

