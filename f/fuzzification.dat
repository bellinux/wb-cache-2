666|11|Public
5000|$|... {{straightforward}} <b>fuzzification</b> {{during the}} sixties and seventies, ...|$|E
50|$|Representing <b>fuzzification,</b> fuzzy {{inference}} and defuzzification through multi-layers feed-forward connectionist networks.|$|E
5000|$|The {{evolution}} of the <b>fuzzification</b> of mathematical concepts {{can be broken down}} into three stages: ...|$|E
40|$|Images of fuzzy {{relations}} provide powerful {{access to}} <b>fuzzifications</b> of properties of and/or relationships between fuzzy sets. As an important example, images of fuzzy orderings canonically {{lead to a}} concept of ordering of fuzzy sets. This contribution studies in which way the partial (i. e. componentwise) monotonicity of an n-ary mapping transfers to its extension to fuzzy sets...|$|R
40|$|Abstract. Several <b>fuzzifications</b> {{of formal}} concept {{analysis}} {{have been proposed}} to deal with uncertainty or incomplete information. In this paper, {{we focus on the}} new paradigm of multi-adjoint concept lattices which embeds different fuzzy extensions of concept lattices, our main result being the representation theorem of this paradigm. As a consequence of this theorem, the representation theorems of the other paradigms can be proved more directly. Moreover, the multi-adjoint paradigm enriches the language providing greater flexibility to the user...|$|R
40|$|This {{paper is}} a {{contribution}} to the theoretical founda-tions of the theory of fuzzy dynamical systems. More precisely, we study relations between a given discrete dynamical system on the space X and its fuzzy counter-part- Zadeh’s extension defined on the space of fuzzy sets on X. We provide a short discussion and a brief survey of some recent results devoted to various (espe-cially chaotic) dynamical properties, a special attention is paid to <b>fuzzifications</b> on the space of fuzzy numbers, i. e., to fuzzy sets with connected α-cuts...|$|R
5000|$|Noisy, but {{the noise}} is non-stationary, they are modeled as an {{interval}} type-2 fuzzy set (this latter kind of <b>fuzzification</b> cannot {{be done in a}} type-1 FLS).|$|E
5000|$|Usually, a <b>fuzzification</b> of {{mathematical}} concepts {{is based on}} a generalization of these concepts from characteristic functions to membership functions. Let A and B be two fuzzy subsets of X. Intersection A ∩ B and union A ∪ B are defined as follows: (A ∩ B)(x) = min(A(x),B(x)), (A ∪ B)(x) = max(A(x),B(x)) for all x ∈ X. Instead of min and max one can use t-norm and t-conorm, respectively , for example, min(a,b) can be replaced by multiplication ab. A straightforward <b>fuzzification</b> is usually based on min and max operations because in this case more properties of traditional mathematics can be extended to the fuzzy case.|$|E
50|$|A similar {{generalization}} {{principle is}} used, for example, for <b>fuzzification</b> of the transitivity property. Let R be a fuzzy relation in X, i.e. R is a fuzzy subset of X×X. Then R is transitive if for all x,y,z in X, R(x,z) ≥ min(R(x,y),R(y,z)).|$|E
40|$|Several <b>fuzzifications</b> {{of formal}} concept {{analysis}} {{have been proposed}} to deal with uncertain information. In this paper, we focus on concept lattices under a multi-adjoint paradigm, which enriches the language providing greater flexibility to the user in that she can choose {{from a number of}} different connectives. Multi-adjoint concept lattices are shown to embed different fuzzy extensions of concept lattices found in the literature, the main results of the paper being the representation the-orem of this paradigm and the embedding of other well-known approaches...|$|R
40|$|We {{revisit the}} notion of fuzzy {{revealed}} preference, {{with the intention of}} using it in decision making. A decision making agent manages resources that are priced, and it has a certain wealth. We review proposed <b>fuzzifications</b> of preference relations. Although they are well founded, they cannot deal well with decision making under fuzzy constraints. We introduce the fuzzy budget set as a general model of fuzzy constraints on resources. We then show that a general condition for rationality, the fuzzy axiom of revealed preference should not be an axiom anymore, but just a statement that is true to a certain degree. We show how to calculate this degree of truth. We define a fuzzy utility function, and show how it can be maximised, subject to fuzzy budget constraints...|$|R
40|$|In this paper, {{we address}} {{some aspects of}} the {{extension}} problem for possibility measures: given the values that a (fuzzy) set mapping takes on a family of (fuzzy) sets, is it possible to extend this mapping to a possibility measure? This problem is shown to be equivalent to a special system of relational equations. When the family of sets considered is a (semi) partition, two important solutions are identified. It is shown that these solutions, and their <b>fuzzifications,</b> play a central part in the treatment of the more general extension problem. This role is shown to be even more conspicuous when the family of fuzzy sets considered is a T - (semi) partition, a notion introduced and studied {{for the first time in}} this paper. 1 Introduction Let us start by introducing a number of basic notions. We shall consider a nonempty set, or universe of discourse, X. A fuzzy set in X is a mapping from X to the real unit interval [0; 1]. The set of all fuzzy sets in X is denoted by F(X). A fuzzy set i [...] ...|$|R
5000|$|<b>Fuzzification</b> {{operations}} can map mathematical input values into fuzzy membership functions. And {{the opposite}} de-fuzzifying operations {{can be used}} to map a fuzzy output membership functions into a [...] "crisp" [...] output value that can be then used for decision or control purposes.|$|E
50|$|A neuro-fuzzy {{network is}} a fuzzy {{inference}} {{system in the}} body of an artificial neural network. Depending on the FIS type, several layers simulate the processes involved in a fuzzy inference-like <b>fuzzification,</b> inference, aggregation and defuzzification. Embedding an FIS in a general structure of an ANN has the benefit of using available ANN training methods to find the parameters of a fuzzy system.|$|E
5000|$|The [...] "POPFNN" [...] {{architecture}} is a five-layer neural network where the layers from 1 to 5 are called: input linguistic layer, condition layer, rule layer, consequent layer, output linguistic layer. The <b>fuzzification</b> of the inputs and the defuzzification of the outputs are respectively {{performed by the}} input linguistic and output linguistic layers while the fuzzy inference is collectively performed by the rule, condition and consequence layers.|$|E
40|$|There {{are much}} more {{publications}} in open literature {{on the topic of}} linguistic variables as compared with Computing With Words (CWW). This paper intends to change that situation by demonstrating the feasibility of a working system. In order to accomplish this goal, a very focused example of an insurance evaluation system, no matter how rudimentary, is presented. Lotfi A. Zadeh has persistently stressed the importance of CWW for a contemporary society and he is absolutely right on target. We have proceeded our project, taking the advantage of the previously established works of Chen, Hsieh and Wang, such as linguistic logic, uncertainty numbers modeling, <b>fuzzifications</b> and defuzzifications schemes, etc. Basically, the Linguistic Evaluating System (LES), consists of Linguistic Descriptions Evaluating Algorithm (LDEA), Linguistic Descriptions Base (LDB), and Fuzzy Knowledge Base (FKB). The previously published works on linguistic methodology and linguistic logic make it possible to develop our LDEA. This main algorithm intends to appraise the linguistic descriptions based upon the newly proposed preferred evaluation rules. In addition, the measuring evaluations of the linguistic descriptions, which have been based on the innovative combination of different IF-THEN fuzzy rules, which in term has been based upon the use of the linguistic distance measurements, reflected the preference of a humane expert. If then, only then, the desired user friendly applications of the essential thrust of risk assessment required for insurance industry has been finally realized. Linguistic variables, CWW, Computing With Words, natural language processing, risk assessments, insurance industry, linguistic logic, uncertain numbers, linguistic fuzzy numbers, linguistic modeling...|$|R
40|$|Thesis (Master) [...] İzmir Institute of Technology, Computer Engineering, İzmir, 2010 Includes bibliographical {{references}} (leaves: 44 - 45) Text in English; Abstract: Turkish and Englishx, 65 leavesA syllogism, {{also known}} as a rule of inference or logical appeals, is a formal logical scheme used to draw a conclusion from a set of premises. It is a form of deductive reasoning that conclusion inferred from the stated premises. The syllogistic system consists of systematically combined premises and conclusions to so called figures and moods. The syllogistic system is a theory for reasoning, developed by Aristotle, who is {{known as one of the}} most important contributors of the western thought and logic. Since Aristotle, philosophers and sociologists have successfully modelled human thought and reasoning with syllogistic structures. However, a major lack was that the mathematical properties of the whole syllogistic system could not be fully revealed by now. To be able to calculate any syllogistic property exactly, by using a single algorithm, could indeed facilitate modelling possibly any sort of consistent, inconsistent or approximate human reasoning. In this work generic <b>fuzzifications</b> of sample invalid syllogisms and formal proofs of their validity with set theoretic representations are presented. Furthermore, the study discuss the mapping of sample real-world statements onto those syllogisms and some relevant statistics about the results gained from the algorithm applied onto syllogisms. By using this syllogistic framework, it can be used in various fields that can uses syllogisms as inference mechanisms such as semantic web, object oriented programming and data mining reasoning processes...|$|R
40|$|As {{the most}} {{essential}} feature in problem solving and decision making by humans, uncertainty information occur frequently in business, scientific and engineering disciplines. The explosive growth and diverse forms of uncertainty information in the stored data have generated an urgent requirement for new techniques and tools that can intelligently and automatically assist us in eliciting valuable knowledge from raw data. The DCIFI is defined based on the Choquet extension of a signed fuzzy measure. A numerical calculation algorithm is implemented to derive the integration result of the DCIFI. A DCIFI regression model is designed to handle the regression problem where heterogeneous fuzzy data are involved. We propose a GA-based Double Optimization Algorithm (GDOA) to retrieve the internal coefficients of the DCIFI regression model. Besides that, A DCIFI projection classifier, which is capable of classifying heterogeneous fuzzy data efficiently and effectively, is established. We proposed a GA-based Classifier-learning Algorithm (GACA) to search the relevant internal parameters of the DCIFI projection classifier. Both the DCIFI regression model and projection classifier are very informative and powerful to deal with heterogeneous fuzzy data sets with strong interaction. Their performances are validated {{by a series of}} experiments both on synthetic and real data. (Abstract shortened by UMI.) This thesis is mainly devoted to a comprehensive investigation on innovative data mining methodologies which merge the advantages of nonlinear integral (Choquet integral) in the representation of nonlinear relationship and fuzzy set theory in the description of uncertainty existed in practical data bases. It proposes two <b>fuzzifications</b> on the classical Choquet integral, one is the Defuzzified Choquet Integral with Fuzzy-valued Integrand (DCIFI), and the other is the Fuzzified Choquet Integral with Fuzzy-valued Integrand (FCIFI). The DCIFI and the FCIFI are regarded as generalizations of Choquet integral since both of them allow their integrands to be fuzzy-valued. The difference lies in that the DCIFI has its integration result non-fuzzified while the FCIFI has its integration result fuzzified. Due to the different forms of integration results, the DCIFI and the FCIFI have their distinct theoretic analyses, implementation algorithms, and application scopes, respectively. by Rong Yang. "April 2005. "Advisers: Kwong-Sak Leung; Pheng-Ann Heng. Source: Dissertation Abstracts International, Volume: 67 - 01, Section: B, page: 0371. Thesis (Ph. D.) [...] Chinese University of Hong Kong, 2005. Includes bibliographical references (p. 187 - 199). Electronic reproduction. Hong Kong : Chinese University of Hong Kong, [2012] System requirements: Adobe Acrobat Reader. Available via World Wide Web. Electronic reproduction. [Ann Arbor, MI] : ProQuest Information and Learning, [200 -] System requirements: Adobe Acrobat Reader. Available via World Wide Web. Abstract in English and Chinese. School code: 1307...|$|R
5000|$|A very {{important}} generalization principle used in <b>fuzzification</b> of algebraic operations is a closure property. Let * be a binary operation on X. The closure property for a fuzzy subset A of X {{is that for}} all x,y ∈ X, A(x*y) ≥ min(A(x),A(y)). Let (G,*) be a group and A a fuzzy subset of G. Then A is a fuzzy subgroup of G if for all x,y in G, A(x*y&minus;1) ≥ min(A(x),A(y&minus;1)).|$|E
5000|$|This {{would be}} easy if the output truth values were exactly those {{obtained}} from <b>fuzzification</b> of a given number.Since, however, all output truth values are computed independently, in most cases they do not represent such a set of numbers.One has then to decide for a number that matches best the [...] "intention" [...] encoded in the truth value.For example, for several truth values of fan_speed, an actual speed must be found that best fits the computed truth values of the variables 'slow', 'medium' and so on.|$|E
50|$|The {{application}} of fuzzy set theory and fuzzy logic to biomedical subjects, clinical problems, and philosophical issues {{is one of}} Sadegh-Zadeh's main interests. Prominent among his achievements {{in this area is}} the reconstruction of biopolymers (such as nucleic acid chains DNA and RNA and polypeptide chains) as ordered fuzzy sets. This theory of fuzzy biopolymers has made biopolymers amenable to fuzzy set theory and logic and has proved very fruitful thereby to stimulate research interest in different teams. Other examples are (i) extensive {{application of}} fuzzy logic in his clinical praxiology and to problems of clinical decision-making; and (ii) <b>fuzzification</b> of deontics and ontology.|$|E
40|$|The ongoing global {{financial}} crisis has demonstrated {{the importance of}} a systemwide, or macroprudential, approach to safeguarding financial stability. An essential part of macroprudential oversight concerns the tasks of early identification and assessment of risks and vulnerabilities that eventually may lead to a systemic financial crisis. Thriving tools are crucial as they allow early policy actions to decrease or prevent further build-up of risks or to otherwise enhance the shock absorption capacity of the financial system. In the literature, three types of systemic risk can be identified: i) build-up of widespread imbalances, ii) exogenous aggregate shocks, and iii) contagion. Accordingly, the systemic risks are matched by three categories of analytical methods for decision support: i) early-warning, ii) macro stress-testing, and iii) contagion models. Stimulated by the prolonged {{global financial}} crisis, today's toolbox of analytical methods includes a wide range of innovative solutions to the two tasks of risk identification and risk assessment. Yet, the literature lacks a focus on the task of risk communication. This thesis discusses macroprudential oversight from the viewpoint of all three tasks: Within analytical tools for risk identification and risk assessment, the focus concerns a tight integration of means for risk communication. Data and dimension reduction methods, and their combinations, hold promise for representing multivariate data structures in easily understandable formats. The overall task of this thesis is to represent high-dimensional data concerning financial entities on lowdimensional displays. The low-dimensional representations have two subtasks: i) to function as a display for individual data concerning entities and their time series, and ii) to use the display as a basis to which additional information can be linked. The final nuance of the task is, however, set by the needs of the domain, data and methods. The following ve questions comprise subsequent steps addressed in the process of this thesis: 1. What are the needs for macroprudential oversight? 2. What form do macroprudential data take? 3. Which data and dimension reduction methods hold most promise for the task? 4. How should the methods be extended and enhanced for the task? 5. How should the methods and their extensions be applied to the task? Based upon the Self-Organizing Map (SOM), this thesis not only creates the Self-Organizing Financial Stability Map (SOFSM), but also lays out a general framework for mapping the state of financial stability. This thesis also introduces three extensions to the standard SOM for enhancing the visualization and extraction of information: i) <b>fuzzifications,</b> ii) transition probabilities, and iii) network analysis. Thus, the SOFSM functions as a display for risk identification, on top of which risk assessments can be illustrated. In addition, this thesis puts forward the Self-Organizing Time Map (SOTM) to provide means for visual dynamic clustering, which in the context of macroprudential oversight concerns the identification of cross-sectional changes in risks and vulnerabilities over time. Rather than automated analysis, the aim of visual means for identifying and assessing risks is to support disciplined and structured judgmental analysis based upon policymakers' experience and domain intelligence, as well as external risk communication...|$|R
40|$|Soft {{computing}} techniques {{differ from}} conventional (hard) computing, in that unlike hard computing, it is tolerant of imprecision, uncertainty, partial truth, and approximation. In effect, the {{role model for}} soft computing is the human mind {{and its ability to}} address day-to-day problems. The principal constituents of Soft Computing (SC) are Fuzzy Logic (FL), Evolutionary Computation (EC), Machine Learning (ML) and Artificial Neural Networks (ANNs). This thesis presents a generic hardware architecture for type-I and type-II standalone tunable Fuzzy Logic Controllers (FLCs) in Field Programmable Gate Array (FPGA). The designed FLC system can be remotely configured or tuned according to expert operated knowledge and deployed in different applications to replace traditional Proportional Integral Derivative (PID) controllers. This re-configurability is added as a feature to existing FLCs in literature. The FLC parameters which are needed for tuning purpose are mainly input range, output range, number of inputs, number of outputs, the parameters of the membership functions like slope and center points, and an If-Else rule base for the fuzzy inference process. Online tuning enables users to change these FLC parameters in real-time and eliminate repeated hardware programming whenever {{there is a need to}} change. Realization of these systems in real-time is difficult as the computational complexity increases exponentially with an increase in the number of inputs. Hence, the challenge lies in reducing the rule base significantly such that the inference time and the throughput time is perceivable for real-time applications. To achieve these objectives, Modified Rule Active 2 Overlap Membership Function (MRA 2 -OMF), Modified Rule Active 3 Overlap Membership Function (MRA 3 -OMF), Modified Rule Active 4 Overlap Membership Function (MRA 4 -OMF), and Genetic Algorithm (GA) base rule optimization methods are proposed and implemented. These methods reduce the effective rules without compromising system accuracy and improve the cycle time in terms of Fuzzy Logic Inferences Per Second (FLIPS). In the proposed system architecture, the FLC is segmented into three independent modules, fuzzifier, inference engine with rule base, and defuzzifier. Fuzzy systems employ fuzzifier to convert the real world crisp input into the fuzzy output. In type 2 fuzzy systems there are two <b>fuzzifications</b> happen simultaneously from upper and lower membership functions (UMF and LMF) with subtractions and divisions. Non-restoring, very high radix, and newton raphson approximation are most widely used division algorithms in hardware implementations. However, these prevalent methods have a cost of more latency. In order to overcome this problem, a successive approximation division algorithm based type 2 fuzzifier is introduced. It has been observed that successive approximation based fuzzifier computation is faster than the other type 2 fuzzifier. A hardware-software co-design is established on Virtex 5 LX 110 T FPGA board. The MATLAB Graphical User Interface (GUI) acquires the fuzzy (type 1 or type 2) parameters from users and a Universal Asynchronous Receiver/Transmitter (UART) is dedicated to data communication between the hardware and the fuzzy toolbox. This GUI is provided to initiate control, input, rule transfer, and then to observe the crisp output on the computer. A proposed method which can support canonical fuzzy IF-THEN rules, which includes special cases of the fuzzy rule base is included in Digital Fuzzy Logic Controller (DFLC) architecture. For this purpose, a mealy state machine is incorporated into the design. The proposed FLCs are implemented on Xilinx Virtex- 5 LX 110 T. DFLC peripheral integration with Micro-Blaze (MB) processor through Processor Logic Bus (PLB) is established for Intellectual Property (IP) core validation. The performance of the proposed systems are compared to Fuzzy Toolbox of MATLAB. Analysis of these designs is carried out by using Hardware-In-Loop (HIL) test to control various plant models in MATLAB/Simulink environments. ...|$|R
50|$|Linear partial {{information}} (LPI) is {{a method}} of making decisions based on insufficient or fuzzy information. LPI was introduced in 1970 by Polish - Swiss mathematician Edward Kofler (1911-2007) to simplify decision processes. Comparing to other methods the LPI-fuzziness is algorithmically simple and particularly in decision making, more practically oriented. Instead of an indicator function the decision maker linearizes any fuzziness by establishing of linear restrictions for fuzzy probability distributions or normalized weights. In the LPI-procedure the decision maker linearizes any fuzziness instead of applying a membership function. This {{can be done by}} establishing stochastic and non-stochastic LPI-relations. A mixed stochastic and non-stochastic <b>fuzzification</b> is often a basis for the LPI-procedure. By using the LPI-methods any fuzziness in any decision situation can be considered on the base of the linear fuzzy logic.|$|E
30|$|The {{proposed}} framework imposes no constraints regarding <b>fuzzification.</b> <b>Fuzzification</b> {{should be}} implemented as per established FIS conventions {{as described in}} “Fuzzy inference systems” section.|$|E
40|$|AbstractThe {{purpose of}} this paper is to present a <b>fuzzification</b> of {{probability}} theory, or more precisely to give a <b>fuzzification</b> of plausibility measures first introduced by Shafer in 1976. Although plausibility measures include probability measures as well as possibility measures, it is a typical result of this theory that only a <b>fuzzification</b> of possibility measures is attainable, while a <b>fuzzification</b> of probability measures seems to be impossible. Moreover with regard to fuzzy plausibility measures we specify a concept of mean values and entropies, which can be considered as a direct generalization of the classical notions of mean value and entropy based upon probability measures...|$|E
30|$|The <b>fuzzification</b> {{interface}} {{gets the}} values of input variables (e, Δe), performs a scale mapping to transfer the range of their values into corresponding universes of discourse, and performs the function of <b>fuzzification</b> to convert input (crisp) data into linguistic values.|$|E
30|$|Thus, given a fuzzy {{equivalence}} relation and a crisp point ‘a’, we can define (generate) a fuzzy set about the point ‘a’. This is called <b>fuzzification</b> and {{plays an important}} role in the design of fuzzy systems. We illustrates this <b>fuzzification</b> with the following algorithm.|$|E
40|$|Więcej informacji: [URL] {{influence}} of the scale of a fuzzy membership function used to fuzzify a histogram is analysand. It is shown that for a class of fuzzifying functions {{it is possible to}} indicate the limit for <b>fuzzification,</b> at which the mode of the histogram equals to the mean of the data accumulated in it. The <b>fuzzification</b> functions for which this appears are: the quadratic function for aperiodic histograms and the cosine square function for periodic ones. The scaled and clipped versions of these functions can be used to control the degree of <b>fuzzification</b> belonging to the interval [0; 1]. While the quadratic function is related to the widely known Huber-type clipped mean or the kernel function derived from the Epanechnikov kernel, the clipped cosine square seems to be less known. The indications for using strong or weak <b>fuzzification,</b> according to the value of the <b>fuzzification</b> degree, are justified by examples in two applications: classic Hough transform-based image registration and novel accumulation-based line detec tion. Typically, the weak <b>fuzzification</b> is recommended. The images used are related to simulation images from teleradiotherapy and to mammographic images. Ministerstwo Nauki i Szkolnictwa Wyższego, projekt 3 T 11 C 050 29, 2005 - 2008. Leszek Chmielewsk...|$|E
3000|$|... (k, l) {{defined as}} in section 3.1. The <b>fuzzification</b> {{parameter}} q[*]>[*] 1 controls the membership softness {{in the cost}} function and therefore controls the fuzziness of the generated TF masks. Section 4.1 describes the selection of an appropriate value for the <b>fuzzification</b> parameter in this BSS context.|$|E
40|$|Some {{possibilities}} of <b>fuzzification</b> of the von Neumann [...] Morgenstern solution of cooperative games with transferable utility (TU games) are briefly investigated. The <b>fuzzification</b> {{based on the}} transformation of individual fuzzy TU game into a fuzzy class of (deterministic) TU games with their own specific solutions is discussed...|$|E
30|$|Second layer: Neurons in {{the second}} layer perform <b>fuzzification.</b>|$|E
40|$|A {{family of}} <b>fuzzification</b> schemes is {{proposed}} {{that can be}} used to transform cardinality-based similarity measures for ordinary sets into similarity measures for fuzzy sets in a finite universe. These schemes are based on the Frank t-norm family and preserve transitivity in the <b>fuzzification</b> process. Keywords: Similarity measure; T-transitivity; Frank t-norm...|$|E
40|$|Introduction In this {{communication}} {{we propose}} two logically sound <b>fuzzification</b> and defuzzification techniques for implementing a credibility calculus {{on a set}} of propositional expressions. Both rely on a credibility evaluation domain using the rational interval [- 1, 1] where the sign carries a split truth/falseness denotation. The first technique implements the classic min and max operators where as the second technique implements Bochvar-like operators. Main interest in the communication is given to the concept of natural <b>fuzzification</b> of a propositional calculus. A formal definition is proposed and the demonstration that both <b>fuzzification</b> techniques indeed verify this definition is provided. 2 Logical <b>fuzzification</b> and polarization: an adjoint pair 2. 1 Introducing logical fuzziness Let P be a set of constants or ground propositions. Let, # denote respectively the contradiction, disjunction and conjunction operators. The set E of all well formulated finite expressions wi...|$|E
40|$|This paper {{describes}} the <b>fuzzification</b> and defuzzification {{process in the}} framework of hybrid systems comprising Fuzzy Cognitive Maps (FCMs) and Genetic Algorithms (GAs). More specifically, it provides a stepwise methodology for <b>fuzzification</b> and defuzzification aiming at both an improved approach of the human reasoning pattern and an increase of the decision-making potentials. The <b>fuzzification</b> process is primarily based on producing fuzzy information provided by a group of experts. Each concept is analyzed into trapezoidal membership functions of either fixed or variable widths, with these intervals labeled and stored for the defuzzification process later on, during which the levels are matched according to the membership functions of each concept. The defuzzification process is more complicated than the <b>fuzzification</b> one and consists of four basic iterative stages: The Iteration, the Max-Min Average Computation, the Categorization and, finally, the Realization Inference Stage. ...|$|E
30|$|The {{defuzzification}} unit which converts <b>fuzzification</b> quantity to {{the precise}} quantity.|$|E
