2|52|Public
40|$|Abstract. We {{present a}} proof-searching {{algorithm}} for the classical first order natural deduction calculus and prove its correctness. For any given task (if this task is indeed solvable), a searching algorithm terminates, either finding a corresponding natural deduction proof or giving {{a set of}} constraints, from which a counter-example can be extracted. Proofs of the properties which characterize correctness of the searching algorithm are given. Based on a fully automatic <b>goal-directed</b> <b>searching</b> procedure, our technique can be efficiently applied as an automatic reasoning tool in a deliberative decision making framework across various AI applications. ...|$|E
40|$|The hippocampal-entorhinal complex {{plays an}} {{essential}} role within the brain in spatial navigation, mapping a spatial path onto a sequence of cells that reaction potentials. During rest or sleep, these sequences are replayed in either reverse or forward temporal order; in some cases, novel sequences occur that may represent paths not yet taken, but connecting contiguous spatial locations. These sequences potentially {{play a role in}} the planning of future paths. In particular, mental exploration is needed to discover short-cuts or plan alternative routes. Hopeld proposed a two-dimensional planar attractor network as a substrate for the mental exploration. He extended the concept of a line attractor used for the ocular-motor apparatus, to a planar attractor that can memorize any spatial path and then recall this path in memory. Such a planar attractor contains an infinite number of fixed points for the dynamics, each fixed point corresponding to a spatial location. For symmetric connections in the network, the dynamics generally admits a Lyapunov energy function L. Movement through different fixed points is possible because of the continuous attractor structure. In this model, a key role is played by the evolution of a localized activation of the network, a "bump", that moves across this neural sheet that topographically represents space. For this to occur, the history of paths already taken is imprinted on the synaptic couplings between the neurons. Yet attractor dynamics would seem to preclude the bump from moving; hence, a mechanism that destabilizes the bump is required. The mechanism to destabilize such an activity bump and move it to other locations of the network involves an adaptation current that provides a form of delayed inhibition. Both a spin-glass and a graded-response approach are applied to investigating the dynamics of mental exploration mathematically. Simplifying the neural network proposed by Hopfield to a spin glass, I study the problem of recalling temporal sequences and explore an alternative proposal, that relies on storing the correlation of network activity across time, adding a sequence transition term to the classical instantaneous correlation term during the learning of the synaptic "adaptation current" is interpreted as a local field that can destabilize the equilibrium causing the bump to move. We can also combine the adaptation and transition term to show how the dynamics of exploration is affected. To obtain <b>goal-directed</b> <b>searching,</b> I introduce a weak external field associated with a rewarded location. We show how the bump trajectory then follows a suitable path to get to the target. For networks of graded-response neurons with weak external stimulation, amplitude equations known from pattern formation studies in bio-chemico- physical systems are developed. This allows me to predict the modes of network activity that can be selected by an external stimulus and how these modes evolve. Using perturbation theory and coarse graining, the dynamical equations for the evolution of the system are reduced from many sets of nonlinear integro-dierential equations for each neuron to a single macroscopic equation. This equation, in particular close to the transition to pattern formation, takes the form of the Landau Ginzburg equation. The parameters for the connections between the neurons are shown to be related to the parameters of the Landau-Ginzburg equation that governs the bump of activity. The role of adaptation within this approximation is studied, which leads to the discovery that the macroscopic dynamical equation for the system has the same structure of the coupled equations used to describe the propagation of the electrical activity within one single neuron as given by the Fitzhugh-Nagumo equations...|$|E
40|$|In complex {{games with}} a high {{branching}} factor, global alphabeta search is computationally infeasible. One way to overcome this problem is by using selective <b>goal-directed</b> <b>search</b> algorithms. These <b>goal-directed</b> <b>searches</b> can use relevancy zones to determine which part of the board influences the goal. In this paper, we propose a general method that uses these relevancy zones for searching for compound goals. A compound goal is constructed from less complex atomic goals, using the standard connectives. In contrast to other approaches that treat goals separately in the search phase, compound goal search obtains exact results. status: publishe...|$|R
40|$|In {{this paper}} we present VOCUS: a robust {{computational}} attention system for <b>goal-directed</b> <b>search.</b> A standard bottom-up architecture is extended by a top-down component, enabling the weighting of features depending on previously learned weights. The weights {{are derived from}} both target (excitation) and background properties (inhibition). A single system is used for bottom-up saliency computations, learning of feature weights, and <b>goal-directed</b> <b>search.</b> Detailed performance results for artificial and real-world images are presented, showing that a target is typically among the first 3 focused regions. VOCUS represents a robust and time-saving front-end for object recognition since by selecting regions of interest it significantly reduces the amount of data to be processed by a recognition system...|$|R
40|$|We {{consider}} {{the problem of}} proof search in an expressive authorization logic that contains a “says ” modality and an ordering on principals. After {{a description of the}} proof system for the logic, we identify two fragments that admit complete goal-directed and saturating proof search strategies. A smaller fragment is then presented, which supports both <b>goal-directed</b> and saturating <b>search,</b> and has a sound and complete translation to first-order logic. We conclude with a brief description of our implementation of <b>goal-directed</b> <b>search.</b> This work was supported partially by the iCAST project sponsored by the National Science Council...|$|R
40|$|This paper {{describes}} {{the design and}} initial evaluation of a technology being developed for document use. It uses interactive visualization of paragraph level metadata to allow rapid <b>goal-directed</b> <b>search</b> and navigation within documents. An experimental evaluation of a prototype's performance on representative work tasks is described. Quantitative analysis finds that the prototype does not increase performance. However, qualitative {{analysis of the data}} suggests that there is room for performance improvements and has inspired design changes to realize this potentia...|$|R
40|$|In {{the last}} lecture {{we saw that}} it is {{difficult}} to identify subcomputations in pure forward chaining. By comparison, in functional programming calling a function naturally gives rise to a subcomputation that is given some arguments and returns a result. In logic programming, the same is true if we compute using backward chaining instead of forward chaining. As we will see, it has other problems, so sometimes we will want to use backward chaining and sometimes forward chaining, and some problems benefit from a combination of these. Today, we will discuss pure backward chaining. The idea of backward chaining for the Horn fragment of logic goes back to Kowalski and Colmerauer (see [Kow 88] for a recounting of its beginning). A more general notion was introduced as uniform proofs [MNPS 91], which was based on the negative fragment of intuitionistic higher-order logic. A proof-theoretic introduction and many further discussions and references can be found in a set of lecture notes [Pfe 06]. 1 Negative Atoms and <b>Goal-Directed</b> <b>Search</b> Backward chaining characteristically performs <b>goal-directed</b> <b>search.</b> We recall an earlier example: a, a ⊸ b, b ⊸ c → c When all atoms are positive, we can only focus on a ⊸ b. When all atoms are negative we can only focus on b ⊸ c. In other words, the only applicable clause is one whose conclusion matches the right-hand side of the sequent. LECTURE NOTES MARCH 26, 2012 Backward Chaining L 17. 2 One of the first questions should be which fragment of linear logic maintains this property. When we are focused on the left on a clause D, we should eventually come to a negative atom (which must match the succedent of the sequent), and not a positive proposition. In this process we spawn goals G, in right focus, which should decompose far enough that we eventually reach a negative atom, rather than stopping at a positive proposition which would not provide at atom for <b>goal-directed</b> <b>search.</b> ...|$|R
40|$|Nearly {{four hundred}} {{non-routine}} organizational decisions were investigated to discover search approaches [...] determining {{the frequency of}} use and success of each search approach uncovered. A 'search approach' {{is made up of}} a direction and a means to uncover solution ideas. Direction indicates desired results and it can be either implicit or explicit, with an explicit direction offering either a problem or a goal-like target. Solutions can be uncovered by opportunity, bargaining, and chance as well as by rational approaches. Defining a search approach as a direction coupled with a means of search, search approaches were linked with indicators of success, measured by the decision's adoption, value and timeliness, noting frequency. A rational, <b>goal-directed,</b> <b>search</b> approach was more apt to produce successful outcomes. Bargaining with stakeholders to uncover solutions was always combined some of the search approaches in this study, and this merger improved the prospects of success. Searches with an opportunistic or chance (emergent opportunity) features and rational searches with a problem target were more apt to produce unsuccessful outcomes. The means used {{to come up with a}} solution had less bearing on success than did the type of direction, with <b>goal-directed</b> <b>searches</b> leading to the best outcomes. Each search approach is discussed to reveal best practices and to offer suggestions to improve practice...|$|R
40|$|A {{significant}} {{trend in}} buying behaviour is consumer information search on the Internet and subsequent purchase online. However, conversion rate from search to purchase has been lower than anticipated leaving marketers and academicians to contemplate {{how best to}} turn browsers into buyers. A move in this direction entails a more thorough understanding of ongoing <b>search</b> and <b>goal-directed</b> <b>search</b> online. In this study, we examine a causal link between ongoing search/browsing and goal-directed/ pre-purchase search which {{has yet to be}} tested in empirical research in offline and online environments. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Abstract: Knowledge Management {{recently}} has become popular in enterprises hoping {{to achieve a}} competitive advantage. Describing information by metadata allows for performing detailed queries uniformly over information items from different information sources and enables <b>goal-directed</b> <b>search</b> and automatic provision of relevant information. As the manual acquisition of metadata is very costly, support for this task is desired. This work presents two metadata extractors {{for the creation of}} metadata. The first applies Instance-Based Learning for the adoption of metadata from similar objects. The second extracts information by applying regular expressions. Both extractors have been integrated into the metadata generation framework of the KnowWork system and have been evaluated in experiments on two real-world data sets from the engineering domain...|$|R
40|$|This paper {{describes}} {{the design and}} initial evaluation of a technology being developed for document use. It uses interactive visualisation of paragraph level metadata to allow rapid <b>goal-directed</b> <b>search</b> and navigation within documents. An experimental evaluation of a prototypes performance on representative work tasks is described. Qualitative {{analysis of the data}} suggests that there is substantial room for performance improvements, and has inspired design changes to realise this potential. Quantitative analysis proved inadequate to detect a numerical advantage due to the sample size restrictions inherent when doing academic research in a corporate setting. The problems of empirical evaluation in a corporate setting are discussed. A new approach to robust quantitative evaluation is proposed...|$|R
40|$|Exploration is an {{activity}} that people undertake to broaden their knowledge on a certain topic. In contrast to regular search, which is typically aimed at obtaining a specific answer to a specific question, exploratory search should give a more complete overview of a topic. Further it should enable the discovery of related aspects, such as people, places, times and locations. Exploration demands more time, effort and creativity from the user, but rewards the user with deeper knowledge. Therefore, users need to be stimulated to bring exploration in regular <b>goal-directed</b> <b>search</b> activities. In this paper we present a user study in which we investigate different kinds of exploratory behavior and goals, as well as different kinds of visualizations to support exploration. Categories and Subject Descriptor...|$|R
40|$|In {{this paper}} we report about ongoing {{research}} on navigation assistance in virtual environments. Our {{aim is to}} {{contribute to the development of}} forms of navigation assistance that enable non-professional visitors of a virtual environment to find their way without previous training. The environment used in this research is a virtual theatre that models a real world music theatre. This virtual theatre can be used for exploration as well as for transactions and <b>goal-directed</b> <b>search</b> for information. We first present some design principles for navigation assistance in virtual environments and some design criteria for assistance by personal agents. Subsequently we describe how these principles and criteria have been implemented in our experimental virtual theatre environment. Finally we give an overview of future research plans...|$|R
40|$|In {{this work}} we propose a new error-correction framework, called CoRé, which uses counterexamples, or bug traces, {{generated}} in verification to automatically correct errors in digital designs. CoRé {{is powered by}} two innovative resynthesis techniques, <b>Goal-Directed</b> <b>Search</b> (GDS) and Entropy-Guided Search (EGS), which modify the functionality of internal circuit’s nodes to match the desired specification. We evaluate our solution to designs and errors arising during combinational equivalencechecking, as well as simulation-based verification of digital systems. Compared with previously proposed techniques, CoRé is more powerful in that: (1) it can fix {{a broader range of}} error types because it does not rely on specific error models; (2) it derives the correct functionality from simulation vectors, hence not requiring golden netlists; and (3) it can be applied to a range of verification flows, including formal and simulation-based...|$|R
40|$|Abstract. Computing a {{shortest}} path from one node {{to another in}} a directed graph is a very common task in practice. This problem is classically solved by Dijkstra’s algorithm. Many techniques are known to speed up this algorithm heuristically, while optimality of the solution can still be guaranteed. In most studies, such techniques are considered individually. The focus of our work is the combination of speed-up techniques for Dijkstra’s algorithm. We consider all possible combinations of four known techniques, namely <b>goal-directed</b> <b>search,</b> bi-directed search, multilevel approach, and shortest-path bounding boxes, and show how these can be implemented. In an extensive experimental study we compare the performance of different combinations and analyze how the techniques harmonize when applied jointly. Several real-world graphs from road maps and public transport and two types of generated random graphs are taken into account. ...|$|R
40|$|Route {{planning}} in large scale time-dependent road networks {{is an important}} practical application of the shortest paths problem that greatly benefits from speedup techniques. In this paper we extend a two-level hierarchical approach for pointto-point shortest paths computations to the time-dependent case. This method, also known as core routing in the literature for static graphs, consists {{in the selection of}} a small subnetwork where most of the computations can be carried out, thus reducing the search space. We combine this approach with bidirectional <b>goal-directed</b> <b>search</b> in order to obtain an algorithm capable of finding shortest paths in a matter of milliseconds on continental sized networks. Moreover, we tackle the dynamic scenario where the piecewise linear functions that we use to model time-dependent arc costs are not fixed, but can have their coefficients updated requiring only a small computational effort...|$|R
40|$|A proof-theoretic {{characterization}} of logical languages that form suitable bases for Prolog-like programming languages is provided. This characterization {{is based on}} the principle that the declarative meaning of a logic program, provided by provability in a logical system, should coincide with its operational meaning, provided by interpreting logical connectives as simple and fixed search instructions. The operational semantics is formalized by the identification of a class of cut-free sequent proofs called uniform proofs. A uniform proof is one that can be found by a <b>goal-directed</b> <b>search</b> that respects the interpretation of the logical connectives as search instructions. The concept of a uniform proof is used to define the notion of an abstract logic programming language, and it is shown that first-order and higher-order Horn clauses with classical provability are examples of such a language. Horn clauses are then generalized to hereditary Harrop formulas and it is shown that first- [...] ...|$|R
40|$|Emerging {{database}} application domains demand {{not only}} new functionality but also high performance. To satisfy these two requirements, the Volcano project provides efficient, extensible tools for query and request processing, particularly for object-oriented and scientific database systems. One of these tools {{is a new}} optimizer generator. Data model, logical algebra, physical algebra, and optimi-zation rules are translated by the optimizer generalor into optimizer source code. Compared with our earlier EX-ODUS optimizer generator prototype, the search engine is more extensible and powerful; it provides effective support for non-trivial cost models and for physical properties such as sort order. At the same time, {{it is much more}} efficient as it combines dynamic programming, which until now had been used only for relational select-project-join optimization, with <b>goal-directed</b> <b>search</b> and branch-and-bound pruning. Compared with other rule-based optimi-zation systems, it provides complete data model indepen-dence and more natural extensibility. 1...|$|R
40|$|In recent work, {{we showed}} how to {{implement}} tactic-style theorem proving in Twelf [2]. Tactics and tacticals are a mechanism {{used in a}} variety of theorem provers such as LCF [5], HOL [4], and Coq [8]. They provide exible control for <b>goal-directed</b> proof <b>search.</b> Tactics provide the basic search procedures, while tacticals are used to compose tactics in various ways to form mor...|$|R
40|$|Abstract — In {{this work}} we propose a resynthesis framework, called CoRé, that {{automatically}} corrects errors in digital designs. The framework {{is based on}} a simulation-based abstraction technique and performs error correction through two innovative circuit resynthesis solutions: Distinguishing-Power <b>Search</b> (DPS) and <b>Goal-Directed</b> <b>Search</b> (GDS), which modify the functionality of a circuit’s internal nodes to match the correct behavior. In addition, we propose a compact encoding of resynthesis information, called Pairs of Bits to be Distinguished (PBDs), which is a key enabler for our resynthesis techniques. Compared with previous solutions, CoRé is more powerful in that: (1) it can fix a broader range of error types because it is not bounded by specific error models; (2) it derives the correct functionality from simulation vectors, without requiring golden netlists; and (3) it can be applied with a broad range of verification flows, including formal and simulation-based. Index Terms — Error correction, error diagnosis, logic synthesis I...|$|R
40|$|The constructivist 2 ̆ 7 s {{theory and}} its {{application}} to information retrieval from the Internet was reviewed. The main aim {{of the study was}} to devise and test an approach with which the most relevant information could be easily and efficiently extracted from the Internet. The impact of a judicious choice of the keywords to retrieve information, according to the particular approach to be implemented as well as the importance of speed reading as an additional technique to improve information retrieval, was compared and critically analyzed. The study was based on information retrieval from www. google. com and www. images. google. com and focused on real-life examples and <b>goal-directed</b> <b>searches.</b> After a careful selection, the criteria used for evaluation were factors such as data quality, accuracy, integrity, and speed of retrieval. These factors helped to determine how useful the constructivist theory could be in information retrieval if it was to be applied in combination with speed reading and traditional approaches...|$|R
40|$|Visual {{attention}} mechanisms allow {{humans to}} extract relevant and important information from raw input percepts. Many applications in robotics and computer vision have modeled human visual attention mechanisms using a bottom-up data centric approach. In contrast, recent studies in cognitive science highlight {{advantages of a}} top-down approach to the attention mechanisms, especially in applications involving <b>goal-directed</b> <b>search.</b> In this paper, we propose a top-down approach for extracting salient objects/regions of space. The top-down methodology first isolates different objects in an unorganized point cloud, and compares each object for uniqueness. A measure of saliency using the properties of geodesic distance on the object’s surface is defined. Our method works on 3 D point cloud data, and identifies salient objects of high curvature and unique silhouette. These being the most unique features of a scene, are robust to clutter, occlusions and view point changes. We provide {{the details of the}} proposed method and initial experimental results...|$|R
40|$|Activities {{are located}} behaviors, taking time, {{conceived}} as socially meaningful, and usually involving interaction with tools and the environment. In modeling human cognition {{as a form}} of problem solving (<b>goal-directed</b> <b>search</b> and operator sequencing), cognitive science researchers have not adequately studied "off-task" activities (e. g., waiting), non-intellectual motives (e. g., hunger), sustaining a goal state (e. g., playful interaction), and coupled perceptual-motor dynamics (e. g., following someone). These aspects of human behavior have been considered in bits and pieces in past research, identified as scripts, human factors, behavior settings, ensemble, flow experience, and situated action. More broadly, activity theory provides a comprehensive framework relating motives, goals, and operations. This paper ties these ideas together, using examples from work life in a Canadian High Arctic research station. The emphasis is on simulating human behavior as it naturally occurs, such that "working" is understood as an aspect of living. The result is a synthesis of previously unrelated analytic perspectives and a broader appreciation of the nature of human cognition. Simulating activities in this comprehensive way is useful for understanding work practice, promoting learning, and designing better tools, including human-robot systems...|$|R
40|$|In this lecture {{we return}} to the view that a logic program is defined by a {{collection}} of inference rules for atomic propositions. But we now base the operational semantics on reasoning forward from facts, which are initially given as rules with no premisses. Every rule application potentially adds new facts. Whenever no more new facts can be generated we say forward reasoning saturates and we can answer questions about truth by examining the saturated database of facts. We illustrate bottom-up logic programming with several programs, including graph reachability, CKY parsing, and liveness analysis. 20. 1 Bottom-Up Inference We now return the very origins of logic programming as an operational interpretation of inference rules defining atomic predicates. As a reminder, consider the definition of even. even(z) evz even(N) even(s(s(N))) evss This works very well on queries such as even(s(s(s(s(z))))) (which succeeds) and even(s(s(s(z)))) (which fails). In fact, the operational reading of this program under <b>goal-directed</b> <b>search</b> constitutes a decision procedure for ground queries even(n). This specification makes little sense under an alternative interpretation where we eagerly apply the inference rules in the forward direction, from the premisses to the conclusion, until no new facts can be deduced. Th...|$|R
40|$|Uniform Proofs as a Foundation for Logic Programming A proof-theoretic {{characterization}} of logical languages that form suitable bases for Prolog-like programming languages is provided. This characterization {{is based on}} the principle that the declarative meaning of a logic program, provided by provability in a logical system, should coincide with its operational meaning, provided by interpreting logical connectives as simple and fixed search instructions. The operational semantics is formalized by the identification of a class of cut-free sequent proofs called uniform proofs. A uniform proof is one that can be found by a <b>goal-directed</b> <b>search</b> that respects the interpretation of the logical connectives as search instructions. The concept of a uniform proof is used to define the notion of an abstract logic programming language, and it is shown that first-order and higher-order Horn clauses with classical provability are examples of such a language. Horn clauses are then generalized to hereditary Harrop formulas and it is shown that first-order and higher-order versions of this new class of formulas are also abstract logic programming languages if the inference rules are those of either intuitionistic or minimal logic. The programming language significance of the various generalizations to first-order Horn clauses is briefl...|$|R
40|$|We {{argue that}} a logic {{programming}} language with a higher-order intuitionistic logic as its foundation can be used both to naturally specify and implement theorem provers. The language extends traditional logic programming languages by replacing first-order terms with simply-typed λ-terms, replacing first-order unification with higher-order unification, and allowing implication and universal quantification in queries and the bodies of clauses. Inference rules {{for a variety of}} proof systems can be naturally specified in this language. The higher-order features of the language contribute to a concise specification of provisos concerning variable occurrences in formulas and the discharge of assumptions present in many proof systems. In addition, abstraction in meta-terms allows the construction of terms representing object level proofs which capture the notions of abstractions found in many proof systems. The operational interpretations of the connectives of the language provide a set of basic search operations which describe <b>goal-directed</b> <b>search</b> for proofs. To emphasize the generality of the meta-language, we compare it to another general specification language: the Logical Framework (LF). We describe a translation which compiles a specification of a logic in LF to a set of formulas of our meta-language, an...|$|R
40|$|Recognizing {{the need}} to support both {{goal-directed}} and experiential behaviour in online shopping environments {{as a means of}} facilitating flow, this paper reports results from an exploratory study that investigates consumer preferences for Web-based product information display across browsing and searching tasks. Thirty-one participants performed two online shopping tasks (one searching and one browsing in nature) on predetermined e-tailing sites and were asked to evaluate the display of product information on these sites in helping them carry out these tasks. Results suggest three things: 1) information such as pricing, product description, retailer selection, retailer advice, and a good interface design are required in both tasks; 2) searching requires more detailed product information; and 3) browsing places greater emphasis on information about the retailer. Based on these findings, a theoretical framework for Web-based product information display is presented. With respect to the design of Web retailing sites, the study’s results imply {{the need to}} focus not only on <b>goal-directed</b> <b>search,</b> but also on non-directed browsing tasks as well. It is argued that adapting the design of e-tailing sites to the unique information display requirements of search and browse tasks could help promote more compelling online shopping experiences for consumers...|$|R
40|$|Speeding up multi-criteria {{search in}} real {{timetable}} information systems remains {{a challenge in}} spite of impressive progress achieved in recent years for related problems in road networks. Our goal is to perform multi-criteria range queries, that is, to find all Pareto-optimal connections with respect to travel time and number of transfers within a given start time interval. This problem can be modeled as a path search problem in a time- and event-dependent graph. In this paper, we investigate two key speed-up techniques for a multi-criteria variant of textscDijkstra 2 ̆ 7 s algorithm [...] - arc flags and contraction [...] - which seem to be strong candidates for railway networks, too. We describe in detail how these two techniques have to be adapted for a multi-criteria scenario and explain why we can expect only marginal speed-ups (compared to observations in road networks) from a direct implementation. Based on these insights we extend traditional arc-flags to emphtime-period flags and introduce emphroute contraction {{as a substitute for}} node contraction. A computational study on real queries demonstrates that these techniques combined with <b>goal-directed</b> <b>search</b> lead to a speed-up of factor 13. 08 over the baseline variant for range queries for a full day...|$|R
40|$|Abstract. We {{describe}} a sound, complete, and terminating procedure for <b>goal-directed</b> proof <b>search</b> in BL G sf, an expressive fragment of a recently presented access control logic, BLsf. BL G sf is more expressive {{than many other}} Datalog-based access control logics that also have very efficient decision procedures, and it finds proofs of authorization quickly in practice. We also extend BL G sf’s proof search procedure to find missing credentials when a requested authorization does not hold and discuss an implementation of our techniques in {{an extension of the}} Unix file synchronization program rsync. ...|$|R
40|$|This paper explores <b>goal-directed</b> proof <b>search</b> in first-order {{multi-modal}} logic. The {{key issue}} is {{to design a}} proof system that respects the modularity and locality of assumptions of many modal logics. By forcing ambiguities to be considered independently, modular disjunctions in particular {{can be used to}} construct efficiently executable specifications in reasoning tasks involving partial information that otherwise might require prohibitive search. To achieve this behavior requires prior proof-theoretic justifications of logic programming to be extended, strengthened, and combined with proof-theoretic analyses of modal deduction in a novel wa...|$|R
40|$|AbstractMiller, D., G. Nadathur, F. Pfenning and A. Scedrov, Uniform proofs as a {{foundation}} for logic programming, Annals of Pure and Applied Logic 51 (1991) 125 – 157. A proof-theoretic characterization of logical languages that form suitable bases for Prolog-like programming languages is provided. This characterization is based on the principle that the declarative meaning of a logic program, provided by provability in a logical system, should coincide with its operational meaning, provided by interpreting logical connectives as simple and fixed search instructions. The operational semantics is formalized by the identification of a class of cut-free sequent proofs called uniform proofs. A uniform proof is one that can be found by a <b>goal-directed</b> <b>search</b> that respects the interpretation of the logical connectives as search instructions. The concept of a uniform proof is used to define the notion of an abstract logic programming language, and it is shown that first-order and higher-order Horn clauses with classical provability are examples of such a language. Horn clauses are then generalized to hereditary Harrop formulas and it is shown that first-order and higher-order versions of this new class of formulas are also abstract logic programming languages if the inference rules are those of either intuitionistic or minimal logic. The programming language significance of the various generalizations to first-order Horn clauses is briefly discussed...|$|R
40|$|There is an {{increasing}} amount of structure on the Web {{as a result of}} modern Web languages, user tagging and annotation, and emerg- ing robust NLP tools. These meaningful, semantic, annotations hold the promise to significantly enhance information access, by enhancing the depth of analysis of today’s systems. Currently, we have only started exploring the possibilities and only begin to un- derstand how these valuable semantic cues can be put to fruitful use. Unleashing the potential of semantic annotations requires us to think outside the box, by combining the insights of natural lan- guage processing (NLP) to go beyond bags of words, the insights of databases (DB) to use structure efficiently even when aggregating over millions of records, the insights of information retrieval (IR) in effective <b>goal-directed</b> <b>search</b> and evaluation, and the insights of knowledge management (KM) to get grips on the greater whole. The Workshop aims to bring together researchers from these dif- ferent disciplines and work together on one of the greatest chal- lenges in the years to come. The desired result of the workshop will be concrete insight into the potential of semantic annotations, and in concrete steps to take this research forward; synchronize related research happening in NLP, DB, IR, and KM, in ways that combine the strengths of each discipline; and have a lively, interactive work- shop were everyone contributes and that inspires attendees to think “outside the box. ...|$|R
40|$|Navigational path {{planning}} is a classical problem in robotics. Traditional approaches use <b>goal-directed</b> heuristic <b>search</b> of problem spaces defined by spatial {{models of the}} navigation world. Case-based reasoning offers an alternative approach. In the Router project, we have combined the case-based method with the model-based method. Since Router is a multistrategy system, it provides an experimental testbed to study some of the hypotheses of case-based reasoning. In this paper, we report {{on a set of}} experiments that examine four hypotheses: (i) the case-based method more efficient than the model-based method, (il) the case-based method produces plans of quality equal to those produced by the model-based method, (iii) th...|$|R
40|$|Abstract <b>Goal-directed</b> proof <b>search</b> in first-order logic uses meta-{{variables}} {{to delay}} the choice of witnesses; substitutions for such variables are produced when closing proof-tree branches, using first-order unific-ation or a theory-specific background reasoner. This paper investigates a generalisation of such mechanisms whereby theory-specific constraints are produced instead of substitutions. In order to design modular proof-search procedures over such mechanisms, we provide a sequent calcu-lus with meta-variables, which manipulates such constraints abstractly. Proving soundness and completeness of the calculus leads to an axiomat-isation that identifies {{the conditions under which}} abstract constraints can be generated and propagated in the same way unifiers usually are. We then extract from our abstract framework a component interface and a specification for concrete implementations of background reasoners. ...|$|R
40|$|In {{recent years}} a huge {{research}} {{effort has been}} devoted to making information on the Web more accessible. One strand concentrates on semantics (the meaning of data); within this is work on data description (via metadata) and research to develop tools for presenting and accessing information through metadata visualisation. The book where this chapter appears is a collection exploring the emerging field bringing research on information visualisation together with research towards realising the ‘semantic web’ (Berners-Lee, 1998 - 1999). This invited chapter concerns how the visualisation of metadata at paragraph level can support <b>goal-directed</b> <b>searches</b> within documents. It describes a novel approach to document visualisation, claims are supported through an account of how a functional taxonomy of paragraph-level tags (semantic metadata) can be generated via systematic empirical methods. An interactive tool for document visualisation (GridVis), developed by Weiss-Lijn, which realises the proposals is described; there is extensive discussion of user testing and formal, quantitative evaluation of system performance and how findings from these sources provided the rationale for the novel features of the visualisation tool. The chapter sets GridVis in the context of related pioneering attempts to visualise other document properties and to support goal-directed navigation within documents. The research reported contributes to the agenda for realising the semantic web, although it can apply to any electronic documents. The work was initially motivated by the needs of large organisations to better exploit information ‘stored’ in documents. The empirical aspects of the work were made possible through collaboration and sponsorship from JSainsbury plc; the principal funding was via a postgraduate training partnership award from the DTI and EPSRC. Early developments for this work were widely disseminated as was a method for testing based on theoretical ‘best case’ performance devised to support this work but widely applicable to information visualisation tools...|$|R
40|$|ABSTRACT. In {{this paper}} {{we focus on}} theorem proving for {{conditional}} logics. First, we give {{a detailed description of}} CondLean, a theorem prover for some standard conditional logics. CondLean is a SICStus Prolog implementation of some labeled sequent calculi for conditional logics recently introduced. It is inspired to the so called “lean ” methodology, even if it does not fit this style in a rigorous manner. CondLean also comprises a graphical interface written in Java. Furthermore, we introduce a <b>goal-directed</b> proof <b>search</b> mechanism, derived from the above mentioned sequent calculi based on the notion of uniform proofs. Finally, we describe GOALDUCK, a simple SICStus Prolog implementation of the goal-directed calculus mentioned here above. Both the programs CondLean and GOALDUCK, together with their source code, are available for free download at...|$|R
