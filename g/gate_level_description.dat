13|3739|Public
50|$|In {{a typical}} design flow, an FPGA {{application}} developer will simulate the design at multiple stages throughout the design process. Initially the RTL description in VHDL or Verilog is simulated by creating test benches {{to simulate the}} system and observe results. Then, after the synthesis engine has mapped the design to a netlist, the netlist is translated to a <b>gate</b> <b>level</b> <b>description</b> where simulation is repeated to confirm the synthesis proceeded without errors. Finally the design is {{laid out in the}} FPGA at which point propagation delays can be added and the simulation run again with these values back-annotated onto the netlist.|$|E
40|$|Abstract. We {{consider}} {{the possibilities of}} supplementing or expanding a particular realization test having a purpose to enhance test quality for detecting various defects. We suggest complementing the existing test suites of the IP core with sensitive adjacent patterns. Then the suitable test patterns for the synthesized gate level implementation have to be selected {{on the base of}} the fault simulation. Our experiments prove that such a complement would enhance the test quality for any synthesized IP core <b>gate</b> <b>level</b> <b>description.</b> We believe that the practice of sensitive adjacent patterns is a very cheap way to adopt test patterns for the re-synthesized <b>gate</b> <b>level</b> <b>description</b> of IP core, because the fault simulation is not so critical task as a test generation. 1. Indroduction System-on-a-chip (SoC) design is built on automatic topology synthesis according to behavioural descriptions of components. Such descriptions together with technological libraries are initial data for automatic topology synthesis. Due to considerable complexity the SoC test is performed by testing separate components. Components tests and defects unde...|$|E
40|$|The action system {{framework}} is a formalism which can model asynchronous (quasi) delay-insensitive circuits. It is expressive {{enough to give}} both high level specification of the circuit and its implementation up to the gate level. A derivation of the <b>gate</b> <b>level</b> <b>description</b> from the specification {{is based on the}} Refinement Calculus. In the paper we present the handshaking expansion as a refinement of action systems and thus prove correctness of the transformation...|$|E
30|$|Methods to {{estimate}} the power consumption based on <b>gate</b> <b>level</b> <b>descriptions</b> of microprocessors or micro controller cores have been proposed in literature. The main advantage of such methods with respect to transistor-level simulation approaches is that the simulation is event-driven and {{takes place in a}} discrete time domain, leading to a considerable reduction of the computational complexity, without a significant loss of accuracy [2].|$|R
40|$|A novel FPGA {{design flow}} {{combined}} with automated hierarchical {{test pattern generation}} was developed and experimented on a real FPGA circuit for telecommunication. A hierarchical test generator for digital systems described in VHDL is presented. Both, register-transfer (RT) and <b>gate</b> <b>level</b> <b>descriptions</b> are used. Decision diagrams are exploited as a uniform model for describing systems at both levels. The method combines bottom-up and top-down approaches to make hierarchical test generation more efficient. It combines RT level deterministic test planning with gatelevel local test generation based on deterministic approach at the bottom-up working mode or on random approach at the top-town working mode. Experimental results have shown the advantages of using structural tests generated by ATPG compared to using functional test sequences created by designer...|$|R
40|$|Abstract: A {{hierarchical}} test generation {{approach for}} digital systems which uses register-transfer (RT) and <b>gate</b> <b>level</b> system <b>descriptions</b> is presented. The proposed test generator implements novel fault simulation and test generation approaches based on alternative graph models. A uniform fault model and uniform simulation and decision procedures are used at both levels. Experimental results showing {{the efficiency of}} the approach are provided. 1...|$|R
40|$|Logic {{synthesis}} {{is a novel}} {{architectural concept}} used for converting a high level description of logic circuit into optimized <b>gate</b> <b>level</b> <b>description.</b> The method ranges from transforming a RTL description to producing an optimized netlist. Logic minimization {{plays an important role}} in optimization of logic synthesis. This optimization is done through the function minimization through different existing methods. The existing work on function minimization has resulted into many algorithms. In the proposed work, we form the basis for our synthesis engines vide detailed performance analysis and insight into the various minimization algorithms proposed erstwhile, and apply them on some real example circuit. We plan to propose our own algorithm as well for enhanced performance...|$|E
40|$|The authors {{propose a}} new {{approach}} to the problem of estimating the average power consumption of a CMOS combinational circuit which is based on neural models. Given the <b>gate</b> <b>level</b> <b>description</b> of a circuit, they build the corresponding Hopfield neural network, store it, calculate the energy dissipated by the network and, finally, derive the power dissipated by the original circuit. All the operations above are executed in the symbolic domain, that is algebraic decision diagrams are used to represent and manipulate the graph specification of the neural network modelling the circuit. The approach is viable and computationally efficient. In addition, it produces power estimates which are, on average, as accurate as the ones computed by state-of-the-art power analysis tool...|$|E
40|$|In {{this paper}} we {{address the problem of}} {{computing}} silent paths in an Finite State Machine (FSM). These paths are characterized by no observable activity under constant inputs, and can be used for a variety of applications, from verification, to synthesis, to simulation. First, we describe a new approach to compute the Timed Transition Relation of an FSM. Then, we concentrate on applying the methodology to simulation of reactive behaviors. In this field, we automatically extract a BDD-based behavioral model from the RT or <b>Gate</b> <b>Level</b> <b>description.</b> The behavioral model is able to "jump" in time and to avoid the simulation of internal events. Finally, we discuss a set of promising experimental results in a simulation environment under the Ptolemy simulator...|$|E
40|$|An open design framework, {{which allows}} mixing {{asynchronous}} and synchronous circuit styles, is presented. It {{is based on}} the development of a tool called "CHP/sub 2 /VHDL" which automatically translates CSP-like specifications (Communicating Sequential Processes) into VHDL programs. This work follows two main motivations: (i) to provide the asynchronous circuit designers with a powerful execution/simulation framework mixing high-level CSP descriptions, HDL programs and <b>gate</b> <b>level</b> <b>descriptions,</b> (ii) to give to synchronous designers familiar with existing HDL-based top-down design flows, the opportunity to include clockless circuits in their designs. An extension of the CHP language proposed by A. J. Martin (1990) is presented and its simulation-oriented features are discussed. The "CHP/sub 2 /VHDL" translator and its software environment are then described. Finally, a significant design experiment is considered to illustrate the efficiency of the design framework...|$|R
40|$|Process Algebras are a {{suitable}} formalism both for system-level description and for ATPG with formal verification techniques. A functional fault model for System-Level descriptions is presented and experimental data are reported. The contributions {{of this paper}} are {{the definition of a}} general-purpose fault model for concurrently evolving processes and the implementation of a test pattern generation procedure, as a variant of the testing equivalence proof. A complete test system is implemented, allowing to describe systems, describe faults and generate test patterns whithin the same environment. 1. Introduction As technological advancements allow to integrate on a chip what in the near past was considered a complex system, hardware designers are confronted with systemlevel issues, rather than with the more familiar registertransfer or <b>gate</b> <b>levels.</b> <b>Description,</b> validation, synthesis, verification, and testing at system-level must respond to new demands, such as dealing with the sy [...] ...|$|R
40|$|A {{hierarchical}} test generation {{approach to}} digital circuits, which uses Register-Transfer (RT) and <b>gate</b> <b>level</b> model <b>descriptions,</b> is presented. The proposed test generator implements a novel test generation technique based on Decision Diagram (DD) models. Uniform modeling procedures are used on both levels, {{as well as}} for datapath and control parts. Experimental results show that the method offers better performance than other state-of-the-art test generators for sequential circuits [1, 2, 3]...|$|R
40|$|Abstract â€“ In this paper, {{we present}} a method for {{diagnosing}} gate delay faults in synchronous sequential circuits. This method is an outgrowth of our previous work on delay fault diagnosis in combinational circuits, and is therefore based on a path tracing algorithm appropriate for sequential circuits. Input data for diagnosis are (1) the <b>gate</b> <b>level</b> <b>description</b> of the circuit, (2) the set of test sequences, and (3) the set of failing patterns and failing outputs provided by the tester. Output data are a set of potential fault locations. In order to correctly interpret the tester results, and avoid multiple fault effects and selfâ€“masking problems during diagnostic processing, each test sequence is considered under different combinations of slow and fast clock cycles (slow clock test methodology). Experimental results are given to show the feasibility, reliability and efficiency of the diagnosis method. 1...|$|E
40|$|This paper {{describes}} {{the use of}} model-based diagnosis for locating bugs in hardware designs. We restrict our view to hardware designs written in {{a subset of the}} commonly used hardware description language VHDL. This subset includes all synthesizeable (register transfer level) programs. This are programs which can be automatically converted into a <b>gate</b> <b>level</b> <b>description</b> without changing their behavior. Therefore almost all VHDL programs are elements of this subset. We show the conversion of VHDL programs into a logical representation. Take this representation and apply model-based diagnosis. The resulting diagnoses are mapped back to the VHDL code fragments of the original program explaining misbehaviors. Finally, we specify some rules optimizing the obtained results. We further present some arguments showing that the proposed debugging technique scales up to large designs. Introduction Since hardware designs continue to become larger and more complex the verification t [...] ...|$|E
40|$|This paper {{describes}} how a formal semantics {{for a computer}} hardware design and description language may be embedded in a proof system. An abstraction of ELLA 1, its formal structured operational semantics and the underlying semantic model are introduced. The Lambda 2 proof system, the embedding of the semantics and some results are discussed. Some examples are shown, and other approaches are briefly surveyed. 1 Introduction As circuits are getting larger and more complex, circuit design is becoming more difficult. The need to describe and document designs {{has led to the}} development of computer hardware design and description languages (CHDDLs) such as ELLA [Com 90] and VHDL [Ins 88]. Using these languages, a circuit may be described at all stages of its design, from the high level specification down to the <b>gate</b> <b>level</b> <b>description.</b> Traditionally simulators have been used to test designs at various levels. It is now impossible to fully test a design by simulation alone. Circuits are [...] ...|$|E
40|$|The paper {{describes}} an environment for an Internetbased co-operation {{in the field}} of design and test of digital systems. A VLSI design flow is combined with an Internet-based hierarchical automated test pattern generation (ATPG). A novel hierarchical ATPG driven by testability measures is presented. Both, the register-transfer (RT) and the <b>gate</b> <b>level</b> <b>descriptions</b> are used, and decision diagrams are exploited as a uniform model for describing systems at both levels, for calculating testability measures and for test generation. The ATPG and testability analyzer can be run at geographically different places under the virtual environment MOSCITO. The interfaces between the integrated tools and also the commercial design tools were developed and implemented. The functionality of the integrated design and test system was verified in several co-operative experiments over Internet by partners in different geographical sites. The experimental results have shown the advantages of using structural tests generated by ATPG compared to using functional test sequences created by designers. ...|$|R
40|$|ABSTRACT: A {{hierarchical}} test generation {{approach for}} digital systems which uses register-transfer (RT) and <b>gate</b> <b>level</b> system <b>descriptions</b> is presented. Decision diagrams {{are used as}} a uniform model for describing structures, functions, as well as faults and fault propagation modes in a wide class of digital circuits at different representation levels. The test generator presented {{is based on a}} top-down approach and uses a novel method for combining deterministic and random techniques. Experimental results show high efficiency in using the presented test generator...|$|R
40|$|A {{hierarchical}} test generation {{approach for}} digital systems which uses register-transfer (RT) and <b>gate</b> <b>level</b> system <b>descriptions</b> is presented. Decision diagrams are exploited as a uniform model for describing systems at different representation levels. The method combines bottom-up and top-down approaches to make hierarchical test generation more efficient by a synergism of deterministic and random low level techniques. It combines register transfer level deterministic test planning with gate-level local test generation based on deterministic approach at the bottom-up working mode and pseudorandom approach at the top-town working mode. Experimental results of using both modes of test generation are included which show high {{efficiency of the}} presented hybrid approach to test generation for sequential digital systems...|$|R
40|$|A {{method is}} {{presented}} that automatically synthesizes gated [...] clocks in synchronous static CMOS circuits to reduce power dissipation. This synthesis is {{performed on the}} <b>gate</b> <b>level</b> <b>description</b> of the circuit. The boolean behavior of the inputs of the flip [...] flops is determined by examining the network. This behavior is represented in ROBDD's. Analysis of these equations results in the condition for which flip [...] flops {{do not need to}} be clocked. Flip [...] flops are grouped in so called hold domains, and clocked by a gated [...] clock signal. Power reductions of up to 29 % are found. There is only a small area overhead (less than 8 %). Testability of the resulting design is taken care of. 1. Introduction Due to the continuously decreasing feature sizes and the increasing clock frequencies on integrated digital circuits, power dissipation is growing to be one of the major concerns during the design of an integrated circuit. Examples of this phenomenon are for instance the DEC Alpha chip (dissipating 30 [...] ...|$|E
40|$|Abstract â€” Considering {{the full}} scan {{benchmark}} circuit, {{in which the}} undetectable single stuck-at faults, tends to cluster in certain areas. This indicates that certain areas may remain uncovered by a test set for single stuck-at faults. The extension to the set of target faults aimed at providing a better coverage of the circuit {{in the presence of}} undetectable single stuck-at fault. The extended set of target faults consists of double stuck-at faults that include an undetectable fault as one of their components. The other component is a detectable fault adjacent to the undetectable fault. Test sets that contain several different tests for each fault (n-detection test sets) are expected to increase the likelihood of detecting defects associated with the sites of target faults. This phenomenon is discerned from the <b>gate</b> <b>level</b> <b>description</b> of the circuit, and it is independent of layout parameters. In addition, the clustering is based on the gate level, and remains valid for any layout of the circuit. The fault simulation and test generation for the extended set of target faults is simulated using modelsim along with that the test set compaction is achieved by reseeding method. Index Terms â€” Benchmark circuits, fault simulation, stuck-at faults, test quality, unresolved faults. ...|$|E
40|$|In {{this paper}} a {{practical}} methodology for formally verifying RISC cores is presented. Using a hierarchical model which reflects the abstraction levels used by designers of real RISC processors, proofs between neighboring levels are performed for simplifying the verification process. The proofs are performed {{by showing that}} each instruction is executed correctly by the pipelined machine {{with respect to the}} semantics of the instruction set architecture. During this proof, temporal abstractions are used to find correspondences between the various levels of abstractions. Additionally, lower level implementational details such as, multi-phased clocks and <b>gate</b> <b>level</b> <b>descriptions</b> of the final implementation, are accounted for. The overall correctness proof is managed in two complementary steps, namely, pipeline data and pipeline control correctness. In the former, we show that the cumulative effect of pipeline suboperations yields the data semantics of architecture instructions. While in the latter, we are concerned with interferences (conflicts) between the different instructions and suboperations in the pipeline. We have developed a set of parametrized proof scripts which highly automate the different proof tasks. In addition, the pipeline control proof is constructive, {{in the sense that the}} conditions under which the pipeline conflicts occur are automatically generated and explicitly stated thus aiding the user in its removal. All developed specifications and proof scripts are kept general, so that the methodology could be applied for a wide range of RISC cores (e. g. those used in embedded systems). In this paper, the described formalization and proof strategies are illustrated via the DLX RISC processor...|$|R
40|$|Post-silicon {{validation}} is {{an essential}} step in the de-sign flow, which is needed {{to demonstrate that the}} imple-mented circuit meets its intended behavior. Due to lack of in-system controllability and observability, design-for-debug hardware is employed to aid post-silicon validation. A number of solutions have been proposed to implement the design-for-debug hardware, as well as to analyze the debug data that is acquired. Although the design entry is done at the register-transfer level, the existing approaches to aid post-silicon validation rely primarily on the information ex-tracted from the <b>gate</b> <b>level</b> circuit <b>descriptions.</b> We antic-ipate that, as the design complexity continues to grow, ex-tracting and processing circuit information at this level will become increasingly difficult. In this paper, we briefly sum-marize the known art and discuss some possible directions of investigation that can utilize high-level circuit descrip-tions to augment the existing solutions. 1...|$|R
40|$|This paper {{presents}} {{a method for}} the automatic validation of the timing behavior of RT and <b>gate</b> <b>level</b> VHDL <b>descriptions.</b> Using a machine-readable timing specification, we automatically create a VHDL testbench for the stimuli generation and the validation of the expected responses. We have developed a VHDL package using linear programming algorithms to compute a valid set of stimuli. The model responses are checked dynamically subject to the model outputs. A graphical interface is used to specify and validate a timing diagram [...] 1. IC design using VHDL Today an ASIC or FPGA designer starts from a verbal, textual or graphical specification to develop a synthesizeable RT level VHDL model. The functional validation of this model is done using a VHDL simulator. Therefore the designer has to create a consistent set of input stimuli. [...] VHDL RTL description of a DRAM Entity Modul is Port (not_RAS IN std_logic not_CAS IN std_logic A IN std_logic_vector 0 to 8) not_WE IN std_logic not_OE IN [...] ...|$|R
40|$|COMSIM is a fault {{simulator}} for combinational circuits {{which can}} efficiently handle various <b>gate</b> <b>level</b> fault models. Stuck-at faults, function conversions, bridging faults, transition faults {{as well as}} multiple faults of all types and faults with additional fault detection conditions, can be simulated in one pass. This offers a practical approach to solve {{the conflict between the}} accuracy of fault modeling, which usually requires a low <b>level</b> circuit <b>description,</b> and the desired performance of the simulation tools, which forbids the use of a low <b>level</b> <b>description.</b> In a preprocessing step which has to be performed only once for a given cell library, the effects of realistic faults are investigated for each gate type. These fault effects are mapped onto <b>gate</b> <b>level</b> faults and stored in a fault library. The specification of a corresponding <b>gate</b> <b>level</b> fault is almost always possible due to the wide variety of <b>gate</b> <b>level</b> fault models which can be simulated by COMSIM. Simulation results are given which demonstrate the practicability and the advantages of library-based fault modeling. The experimental results show that COMSIM can efficiently handle non-classical faults on the <b>gate</b> <b>level...</b>|$|R
40|$|An Efficient analog {{to digital}} {{interface}} (TDC/DTC) is presented. In particular, we explore time-based techniques for data conversion, which can potentially achieve significant reductions in power consumption while keeping silicon chip {{area will be}} very small. On {{the basis of a}} generic mixed-signal system the scaling difficulties of analog and mixed-signal circuits based on a signal representation in the voltage domain are discussed for nanometer CMOS technologies. Easy to control and seamlessly embedded, were also low latency occur. Mainly applicant for LDPC implementation which is used for error correcting and image processing will be done. In <b>gate</b> <b>level</b> verilog hardware <b>description</b> language used for coding digital circuits using tool Xilinx ISE 10. 1 i and target family Spartan 3 E,Device XC 3 S 500, speed- 5,package:FG 320. The synthesized for the proposed digital circuits. Keywordsâ€”low density parity-check (LDPC), time-to-digital converter (TDC), Binary-search time-to digital converter (BS-TDC), low power 1...|$|R
40|$|Due to the {{increasing}} complexity of modern circuit design, verification has become the major bottleneck of the entire design process. Most efforts are to verify the correctness of the initial Register-Transfer <b>Level</b> (RTL) <b>descriptions</b> written in Hardware Description Language (HDL). Major drawback of high level design methodologies such as RTL {{can be seen in}} the following facts. First, they lack of sufficiently precise fault models - compared to sophisticated models available for low <b>level</b> <b>description</b> <b>levels</b> such as logic <b>gate</b> <b>level.</b> Second, since the structure of a design changes significantly with every logic synthesis run, testability analysis is typically performed only after final logic synthesis. So in this paper, we detect the stuck-at fault using the concept of textio...|$|R
40|$|In this work, we have formalized and {{verified}} {{a hardware}} {{implementation of the}} Table-Driven algorithm for the floating-point exponential function. We have used a hierarchical approach enabling the verification of this function from the <b>gate</b> <b>level</b> implementation up to a behavioral specification adapted from the high <b>level</b> algorithmic <b>description</b> written by Harrison [3]...|$|R
40|$|A two-step {{approach}} {{is used to}} increase the accuracy of fault modeling without sacrificing the efficiency of fault simulation and test pattern generation on the <b>gate</b> <b>level.</b> First, low level faults are mapped onto the <b>gate</b> <b>level</b> and a data base with <b>gate</b> <b>level</b> faults is created. In a second step, fault simulation is performed using this data base. A <b>gate</b> <b>level</b> fault simulator has been modified to perform the simulations. This paper describes the first step and presents a method which maps low <b>level</b> faults onto <b>gate</b> <b>level</b> faults. Existing <b>gate</b> <b>level</b> fault models are extended and new <b>gate</b> <b>level</b> fault models are introduced. In order to demonstrate the feasibility of the approach electrical level shorts and opens have been mapped onto <b>gate</b> <b>level</b> faults for two typical CMOS libraries. For these libraries all shorts and opens can be described accurately by <b>gate</b> <b>level</b> faults. 1...|$|R
40|$|NUMBER OF PAGES: xii+ 607 Methods {{allowing}} a designer to perform early dependability analyses aim either at classifying the faults {{according to their}} main potential effect, or at analyzing more in depth the error propagation paths in the circuit. In the two cases, these methods can be applied at several <b>description</b> <b>levels,</b> starting from the behavioral level down to the <b>gate</b> <b>level</b> with back annotation data. This paper compares results obtained at RT and <b>gate</b> <b>levels.</b> The advantages of combining an error propagation path analysis and a classification are also discussed...|$|R
50|$|There are {{elevators}} between {{ground level}} and the ticket <b>gate</b> <b>level</b> and between the ticket <b>gate</b> <b>level</b> and platform level. There are also escalators between the ticket <b>gate</b> <b>level</b> and platform level. Along with multifunction toilets, these facilities are meant to make the station barrier free.|$|R
40|$|Many {{integrated}} circuits of today contain {{a very large}} number of transistors, over 1 million in some designs. The aim is to design a low power high performance sequencer and program counter, analyze and simulate at <b>gate</b> and layout <b>levels.</b> High <b>level</b> <b>description</b> language to be used to construct layout of program counter and sequencer...|$|R
40|$|The same circuit may be {{described}} at algorithmic, behavioral or <b>gate</b> <b>level.</b> Test generation is usually performed for every level separately. We introduce a test generation approach based on test selection {{by means of}} simulation at algorithmic <b>level</b> of circuit <b>description.</b> The generated test {{could be applied to}} VHDL behavioral level as test bench. This test shows high fault coverage at equivalent <b>gate</b> <b>level.</b> The test selection procedure relies on the model of input stuck-at faults transmissions to output. The application of test frames allows sequential circuits to consider like combinational ones. The proposed method is implemented in the test generation program that is available on the Internet as freeware. The experiment shows efficiency of the proposed method. ...|$|R
40|$|The {{purpose of}} this thesis is to study the {{methodology}} of behavioral synthesis and evaluate its usefulness compared to Register Transfer Level (RTL) synthesis. Custom IC design uses high-powered synthesis tools. Engineers have traditionally used RTL <b>level</b> <b>descriptions</b> of their circuits as input to these synthesis tools. As new Behavioral Synthesis tools are becoming more powerful, the option to describe their circuitry in a higher and more abstract level is becoming a more feasible option. Describing circuitry {{at a higher level}} has many advantages. It is easier to make architecture changes and higher <b>level</b> <b>descriptions</b> generally have significantly less lines of code and faster development times. To study behavioral synthesis a tri-linear interpolation algorithm is used. An RTL style and two different behavioral styles are used. Each are compared for area, power consumption, synthesis time, code length and throughput. The design is simulated before and after synthesis to verify the accuracy of the design using VHDL. Behavioral Compiler from Synopsys will be used to synthesize the design from VHDL to the <b>gate</b> <b>level.</b> It was found that behavioral synthesis can produce results nearly as good as an RTL described circuit. The results were generally 20 % - 30 % worse for this implementation using behavioral synthesis...|$|R
40|$|Delay {{fault testing}} and at-speed testing {{are widely used}} to verify the timing of {{synchronous}} digital ICâ€™s. The importance of these techniques is still growing because of the relevant ICâ€™s parameters uncertainties which characterize the current technologies. In order to drive this process, several fault models and test generation techniques have been developed that target different trade-offs between accuracy and efficiency. The largest fraction of these approaches is based upon <b>gate</b> <b>level</b> <b>descriptions</b> of the circuit. In case the basic building blocks are more complex than logic gates and their implementation is not known, functional level approaches have been proposed. For instance, {{this is the case}} for look-up tables based Field Programmable Gate Arrays (FPGAs) and it may be a perspective for deep submicron circuits that exploit logic bricks as basic building blocks. This class of circuits has been referred to as macro or module based. In this context, the main activities performed during the tree years of my PhD are related to the timing failures problems in module-based CMOS VLSI circuits. The attention to module-based (or block-based) circuits follows the current VLSI physical design trends that attempt to limit the parametric failures due to the scaling of technology toward nanometric feature sizes. In such technologies, in fact, the traditional design paradigms that are based on small (i. e <b>gate</b> <b>level)</b> cells may produce high levels of variability, thus resulting in parametric defects. The use of highly regular cell structures, called logic bricks has been proposed to solve these problems thus increasing the yield of VLSI circuits. A brick comprises a logic function created from a small set of logic primitives that are mapped on to a micro-regular fabric. Such logic function is typically more complex that those implemented in traditional VLSI libraries. Field Programmable Gate Array (FPGA) technology also exploits a module based design approach. Unlike logic bricks, FPGAs are completely programmable, because they are based on look up tables (a n-bit LUT can accomplish every n-bit function), but the drawback is related to the implementation of the LUT, that is unknown to designer and not optimized for regularity. In this scenario, the delay fault testing became a big issue, since {{it is very difficult to}} study a circuit built using modules whose implementation in not known, either for technological and for intellectual property reasons. Moreover, the aggressive timing policies used in todayâ€™s ICs make the need for delay fault testing more relevant. The main PhD activity, that will be explained in detail in this thesis, is related to a new method that we propose to generate test vectors for path delay faults in circuits based on modules. In particular, we consider the single path delay fault model in combinational circuits or in (enhanced) full-scan ones that are composed of functional blocks whose implementation is not known. In such circuits a path fault is detected by suitable conditions so that a test pair is able to propagate a transition through the path under test, in order to detect a path delay fault. In order to identify such conditions, we introduced a new signal representation that enables the use of boolean differential calculus. Also, additional conditions to prevent invalidation of tests by hazards have been identified. We suppose that the dynamic behavior of the block is modeled using input delays such as in the timing arc delay model. We target simple combinational blocks such as logic bricks, that are expected to present up to 8 - 10 inputs and a low logic depth. The used method is scalable, to generate conditions for path delay fault tests also at <b>gate</b> <b>level.</b> In order to assess the feasibility of the proposed approach, I realized a software, written in C/C++, that permits to find out robust and non-robust test pairs, starting from the BLIF description of a module based circuit. Such a software uses a BDD description of the blocksâ€™ functions on which we apply Boolean Differences to obtain local sensitization conditions at module level. Since there are circuits whose BDD structure may be very large and it may be inefficient (in some cases also infeasible) to treat it, we translate functions obtained at macros level to a CNF description. After that, a SAT solver generates the test pairs at circuit level starting from the conjunction of all the CNF functions. The software tool was used to verify the proposed approach on a set of benchmarks (both combinational or full-scan) from ITCâ€™ 99 and ISCASâ€™ 85 sets. Such benchmarks allowed to show the feasibility of the proposed approach, although they are not fully representative of the target circuits for which the method was developed. Another significant work, carried out during my PhD period, also deal with testing of macro-based circuits, but it concerns specifically logic bricks. In particular, a method for high quality functional fault simulation and test generation for such circuits was conceived and a software tool that implements it was developed. For both the approaches, results showed the feasibility of them, but also highlighted possibilities to improve and extend the work done...|$|R
40|$|Software-based {{self-testing}} is {{a promising}} approach for {{the testing of}} processor cores which are embedded inside a System-on-a-Chip (SoC), as it can apply test vectors in functional mode using its instruction set. This paper presents a software-based self-testing methodology for delay fault testing. Delay faults will affect the circuit functionality only when it can be activated in functional mode. A systematic approach for the generation of test vectors, which are applicable in functional mode, is presented. A graph theoretic model (represented by IE-Graph) is developed in order to model the datapath. A finite state machine model {{is used for the}} controller. These models are used for constraint extraction under which a test can be applied in functional mode. This approach uses instruction set architecture, RT <b>level</b> <b>description</b> along with <b>gate</b> <b>level</b> netlist for test generation. [URL]...|$|R
40|$|This paper {{introduces}} and evaluates functional fault {{models for}} {{test pattern generation}} of sequential circuits at the finite state machine level. Evaluation of the proposed fault models against their <b>gate</b> <b>level</b> fault coverage on multi-level implementations is presented. The relationships between functional and <b>gate</b> <b>level</b> fault coverage are discussed...|$|R
