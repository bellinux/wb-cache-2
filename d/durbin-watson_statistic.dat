90|11|Public
5|$|Von Neumann made {{fundamental}} {{contributions to}} mathematical statistics. In 1941, he derived the exact {{distribution of the}} ratio of the mean square of successive differences to the sample variance for independent and identically normally distributed variables. This ratio was applied to the residuals from regression models and is commonly known as the <b>Durbin–Watson</b> <b>statistic</b> for testing the null hypothesis that the errors are serially independent against the alternative that they follow a stationary first order autoregression.|$|E
25|$|If the <b>Durbin–Watson</b> <b>statistic</b> {{indicates}} {{the presence of}} serial correlation of the residuals, this can be remedied by using the Cochrane–Orcutt procedure.|$|E
25|$|<b>Durbin–Watson</b> <b>statistic</b> tests {{whether there}} is any {{evidence}} of serial correlation between the residuals. As a rule of thumb, the value smaller than 2 will be an evidence of positive correlation.|$|E
25|$|Mathematica: the <b>Durbin–Watson</b> (d) <b>statistic</b> is {{included}} {{as an option}} in the LinearModelFit function.|$|R
40|$|This paper shows {{a simple}} method for {{approximating}} the exact {{distribution of the}} <b>Durbin-Watson</b> test <b>statistic</b> for first-order autocorrelation in a nonlinear model. The proposed approximate nonlinear Durbin-Watson test has good size and power when compared to alternatives. Copyright 1992 by MIT Press. ...|$|R
40|$|The saddlepoint {{approximation}} as {{developed by}} Daniels [3] {{is an extremely}} accurate method for approximating probability distributions. Econometric and statistical applications of the technique to densities of statistics of interest are often hindered by the requirements of explicit knowledge of the c. g. f. {{and the need to}} obtain an analytical solution to the saddlepoint defining equation. In this paper, we show the conditions under which any approximation to the saddlepoint is justified and suggest a convenient solution. We illustrate with an approximate saddlepoint expansion of the <b>Durbin-Watson</b> test <b>statistic.</b> ...|$|R
25|$|It is {{important}} to note that the <b>Durbin–Watson</b> <b>statistic,</b> while displayed by many regression analysis programs, is not applicable in certain situations. For instance, when lagged dependent variables are included in the explanatory variables, then it is inappropriate to use this test. Durbin's h-test (see below) or likelihood ratio tests, that are valid in large samples, should be used.|$|E
25|$|In {{statistic}}s, the <b>Durbin–Watson</b> <b>statistic</b> is a {{test statistic}} used to detect the presence of autocorrelation (a relationship between values separated from each other by a given time lag) in the residuals (prediction errors) from a regression analysis. It is named after James Durbin and Geoffrey Watson. The small sample distribution of this ratio was derived by John von Neumann (von Neumann, 1941). Durbin and Watson (1950, 1951) applied this statistic to the residuals from least squares regressions, and developed bounds tests for the null hypothesis that the errors are serially uncorrelated against the alternative that they follow a first order autoregressive process. Later, John Denis Sargan and Alok Bhargava developed several von Neumann–Durbin–Watson type test statistics for the null hypothesis that the errors on a regression model follow a process with a unit root against the alternative hypothesis that the errors follow a stationary first order autoregression (Sargan and Bhargava, 1983). Note that the distribution of this test statistic {{does not depend on}} the estimated regression coefficients and the variance of the errors.|$|E
2500|$|... {{using the}} <b>Durbin–Watson</b> <b>statistic</b> d and the {{estimated}} variance ...|$|E
40|$|Abstract. It {{is shown}} that the lower and upper {{critical}} values of the <b>Durbin-Watson</b> (&w) <b>statistic</b> are asymptotically {{the same for the}} analysis based on M-estimators as for the classical least squares analysis. Moreover, the paper offers a possibility to make an idea when the asymptotics may start to work. Considering the B-robust optimal $-function, we demonstrate that the differences between the precise critical values of Durbin-Watson statistics evaluated for residuals cor-responding to the M-estimate and critical values which were found by Durbin and Watson for the least squares analysis are rather small evcn for moderate sample size...|$|R
40|$|A test {{is given}} for testing for lag h {{autocorrelation}} of residuals from a full-rank normal errors ~gression model. This test {{is based on}} the normalized uniform (NU) residuals obtained from conditional probability integral transformations (CPIT). The exact distribution theory of these values permits the evaluation of the significance level for this test for any regression model. The test can also be applied to sets of NU residuais obtained from different regression regimes such as for data sequences obtained from measurements from a manufacturing process subject to an automated compensating action. Some limited power comparisons are made with the <b>Durbin-Watson</b> (D-W) <b>statistic</b> for a one-sample simple linear regression model, and for this case the new NU test has power somewhat less than the exact D-W statistic, but much better than the D-W bounds test. Percentage points are given for tests for lags 1 through 6 and formulas are given that will treat all cases. A technique is suggested for distinguishing test significance due to one form of model misspecification from significance due to serial correlation...|$|R
40|$|The {{classical}} {{autocorrelation coefficient}} estimator {{in the time}} series context is very sensitive {{to the presence of}} outlying measurements in the data. This paper proposes several new robust estimators of the autocorrelation coefficient. First, we consider an autoregressive process of the first order AR(1) to be observed. Robust estimators of the autocorrelation coefficient are proposed in a straightforward way based on robust regression. Further, we consider the task of robust estimation of the autocorrelation coefficient of residuals of linear regression. The task is connected to verifying the assumption of independence of residuals and robust estimators of the autocorrelation coefficient are defined based on the <b>Durbin-Watson</b> test <b>statistic</b> for robust regression. The main result is obtained for the implicitly weighted autocorrelation coefficient with small weights assigned to outlying measurements. This estimator is based on the least weighted squares regression and we exploit its asymptotic properties to derive an asymptotic test that the autocorrelation coefficient is equal to 0. Finally, we illustrate different estimators on real economic data, which reveal the advantage of the approach based on the least weighted squares regression. The estimator turns out to be resistant against the presence of outlying measurements...|$|R
2500|$|The <b>Durbin–Watson</b> <b>statistic</b> {{is biased}} for {{autoregressive moving average}} models, so that {{autocorrelation}} is underestimated. But for large samples one can easily compute the unbiased normally distributed h-statistic: ...|$|E
2500|$|... where T is {{the number}} of observations. Note that if one has a lengthy sample, then this can be linearly mapped to the Pearson {{correlation}} of the time-series data with its lags. [...] Since d is approximately equal to 2(1−r), where r is the sample autocorrelation of the residuals, d=2 indicates no autocorrelation. The value of d always lies between 0 and 4. If the <b>Durbin–Watson</b> <b>statistic</b> is substantially less than 2, there is evidence of positive serial correlation. As a rough rule of thumb, if Durbin–Watson is less than 1.0, there may be cause for alarm. Small values of d indicate successive error terms are, on average, close in value to one another, or positively correlated. If d>2, successive error terms are, on average, much different in value from one another, i.e., negatively correlated. In regressions, this can imply an underestimation of the level of statistical significance.|$|E
5000|$|... {{using the}} <b>Durbin-Watson</b> <b>statistic</b> d and the {{estimated}} variance ...|$|E
40|$|Autocorrelated {{errors are}} {{recognized}} as potentially troublesome in regression analysis. Because of the computational problems encountered, however, few economists have estimated equations under the assumption of autocorrelated errors. Recently, relatively economical procedures {{have been developed for}} estimating equations containing autocorrelated errors. In this study, one of these procedures-autoregressive least squares (A. L. S.) -is applied to equations describing the behavior of various economic agents, by using different unit observation periods-year, quarter and month. Some of the results have been published elsewhere; some are published here. In addition to presenting some results of autoregressive error estimation, this report summarizes experience with the use of AL. S. Some equations presented here were estimated by a simultaneous equations method under the assumption of autocorrelated errors. The results of four different tests for autocorrelation in errors were compared: <b>Durbin-Watson</b> d <b>statistic,</b> Theil-Nagar d, Hart-von Neumann ratio and A. L. S. Essentially, the Theil-Nagar d test classes as significant those values of d that are significant or inconclusive in the Durbin-Watson test. The Theil-Nagard yielded evidence of autocorrelated errors most frequently; A. L. S., second most frequently; Hart-von Neumann ratio, third most frequently; and Durbin-Watson test, least frequently. The proportions of the equations in which each test provided significant evidence of autocorrelated errors are: Theil-Nagard, 66 percent; autoregressive least squares, 51 percent; Hart-von Neumann ratio, 37 percent; Durbin-Watson test, 26 percent...|$|R
40|$|In {{this paper}} we {{evaluate}} {{the performance of}} three methods for testing {{the existence of a}} unit root in a time series, when the models under consideration in the null hypothesis do not display autocorrelation in the error term. In such cases, simple versions of the Dickey-Fuller test should be used as the most appropriate ones instead of the known augmented Dickey-Fuller or Phillips-Perron tests. Through Monte Carlo simulations we show that, apart from a few cases, testing the existence of a unit root we obtain actual type I error and power very close to their nominal levels. Additionally, when the random walk null hypothesis is true, by gradually increasing the sample size, we observe that p-values for the drift in the unrestricted model fluctuate at low levels with small variance and the <b>Durbin-Watson</b> (DW) <b>statistic</b> is approaching 2 in both the unrestricted and restricted models. If however, the null hypothesis of a random walk is false, taking a larger sample, the DW statistic in the restricted model starts to deviate from 2 while in the unrestricted model it continues to approach 2. It is also shown that the probability not to reject that the errors are uncorrelated, when they are indeed not correlated, is higher when the DW test is applied at 1 % nominal level of significance...|$|R
40|$|Sugar {{is one of}} the {{strategic}} goods in the basket of households in each country and it {{plays an important role in}} supplying the required energy. On the other hand, it {{is one of the}} goods, which Iranian government is about to change its subsidy strategies. To design useful sugar subsidy strategies, it is necessary to know sugar position in the basket of households and be familiar with households' sugar demand or consumption behavior. This research estimates sugar demand for Iranian households by using time series of 1984 - 2008, which is taken from central bank of Iran. In this paper, first independent and dependent variables of household sugar demand model are chosen based on the literature review and theory of demand. Then, sugar demand is estimated by OLS technique and linear regression. The preliminary statistical observations such as <b>Durbin-Watson,</b> F <b>statistic</b> and R 2 indicate that the regression is admissible. The results seem plausible and consistent with theory and show that sugar demand in Iranian households is associated with household expenditure, relative sugar price, family size and indicate that demand of sugar is affected during the war time. The results also show the income elasticity is 0. 8 and price elasticity is - 0. 2 which means sugar is essential good for Iranian households and is inelastic to price...|$|R
5000|$|... #Subtitle level 2: Computing and {{interpreting}} the <b>Durbin-Watson</b> <b>statistic</b> ...|$|E
50|$|If the <b>Durbin-Watson</b> <b>statistic</b> {{indicates}} {{the presence of}} serial correlation of the residuals, this can be remedied by using the Cochrane-Orcutt procedure.|$|E
5000|$|The <b>Durbin-Watson</b> <b>statistic</b> {{is biased}} for {{autoregressive moving average}} models, so that {{autocorrelation}} is underestimated. But for large samples one can easily compute the unbiased normally distributed h-statistic: ...|$|E
30|$|Eq.  2 {{uses the}} results of Eq.  1 for {{estimating}} occupation-specific wages in each of 63  industrial sectors. A potential of 3402 wages are estimated accordingly. However, not all occupation and industry combinations exist: taking 2010 as base year, only 75 % of all possible combinations report employment. The corresponding regressions are estimated using ordinary least squares. The estimated parameters are evaluated against the R 2 (greater than 0.90), <b>Durbin-Watson</b> test <b>statistic</b> (between − 1 and 1), and the p-value (below or at 0.05). In total, {{it was possible to}} identify wage responsiveness in 1.513 occupation-specific industry wages which means that roughly 30 thousand employees are wage-sensitive in an econometric sense. Nonetheless, there exist some cases for which no conclusions about the existence of an industry-specific penalty or mark-up can be made, because either the coefficient of the industry-specific labour productivity is insignificant or the regression is subject to autocorrelation. In these 28 % of the cases a default option is used, using the OF wage to update the industry specific OF wages. A similar approach is used for the estimation of Eq.  3, where in cases of autocorrelation or insignificance of the wage relation by default the relative inputs of occupations is kept constant. Therefore, not in all cases changes in the labour supply transmit a change in wages and likewise not all wage changes induce a change in the occupational structure of the industry. For the estimation of Eq.  4, firstly, the distribution of formally trained workers by 54 training OF over the exercised OF is calculated for each age, sex and qualification group for the years 2005 to 2011 using Microcensus data. Table  1 shows the aggregate distribution, the so-called flexibility matrix, for the year 2011 for the summarized 20  MOF, where the dark cells highlight the percentage of stayers. Overall, we can see that some groups of persons as distinguished by training OF are more concentrated on fewer exercised OF than others. MOF  20 ‘teaching occupations’ is a classic example of high concentration.|$|R
50|$|Serial {{correlation}} of the residuals can indicate model misspecification, {{and can be}} checked for with the <b>Durbin-Watson</b> <b>statistic.</b> The problem of heteroskedasticity can be checked for in any of several ways.|$|E
5000|$|<b>Durbin-Watson</b> <b>statistic</b> tests {{whether there}} is any {{evidence}} of serial correlation between the residuals. As a rule of thumb, the value smaller than 2 will be an evidence of positive correlation.|$|E
50|$|The test is {{more general}} than the <b>Durbin-Watson</b> <b>statistic</b> (or Durbin's h statistic), {{which is only}} valid for {{nonstochastic}} regressors and for testing {{the possibility of a}} first-order autoregressive model (e.g. AR(1)) for the regression errors. The BG test has none of these restrictions, and is statistically more powerful than Durbin's h statistic.|$|E
50|$|It is {{important}} to note that the <b>Durbin-Watson</b> <b>statistic,</b> while displayed by many regression analysis programs, is not applicable in certain situations. For instance, when lagged dependent variables are included in the explanatory variables, then it is inappropriate to use this test. Durbin's h-test (see below) or likelihood ratio tests, that are valid in large samples, should be used.|$|E
50|$|Watson {{developed}} the <b>Durbin-Watson</b> <b>statistic</b> for detecting autocorrelation with James Durbin of the London School of Economics in 1950.Watson was {{especially interested in}} applications of statistics. He used statistical methods to support the theory of continental drift. He estimated {{the size of the}} penguin population in Antarctica, and the effect of repealing the motorcycle helmet law in the United States.|$|E
50|$|Bhargava {{received}} his Ph.D. in econometrics from the London School of Economics {{under the supervision}} of John Denis Sargan in 1982. His thesis (The Theory of the <b>Durbin-Watson</b> <b>Statistic</b> with special reference to the Specification of Models in Levels as against in Differences) led to many tests for unit roots that were used in co-integration analyses. Bhargava also worked on econometric methods for longitudinal ("panel") data.|$|E
50|$|Von Neumann made {{fundamental}} {{contributions to}} mathematical statistics. In 1941, he derived the exact {{distribution of the}} ratio of the mean square of successive differences to the sample variance for independent and identically normally distributed variables. This ratio was applied to the residuals from regression models and is commonly known as the <b>Durbin-Watson</b> <b>statistic</b> for testing the null hypothesis that the errors are serially independent against the alternative that they follow a stationary first order autoregression.|$|E
5000|$|If it {{is found}} via the <b>Durbin-Watson</b> <b>statistic</b> that the error term is {{serially}} correlated over time, then standard statistical inference as normally applied to regressions is invalid because standard errors are estimated with bias. To avoid this problem, the residuals must be modeled. If the process generating the residuals {{is found to be}} a stationary first-order autoregressive structure, , with the errors {} being white noise, then the Cochrane-Orcutt procedure can be used to transform the model by taking a quasi-difference: ...|$|E
5000|$|The {{traditional}} {{test for}} the presence of first-order autocorrelation is the <b>Durbin-Watson</b> <b>statistic</b> or, if the explanatory variables include a lagged dependent variable, Durbin's h statistic. The Durbin-Watson can be linearly mapped however to the Pearson correlation between values and their lags. [...] A more flexible test, covering autocorrelation of higher orders and applicable whether or not the regressors include lags of the dependent variable, is the Breusch-Godfrey test. This involves an auxiliary regression, wherein the residuals obtained from estimating the model of interest are regressed on (a) the original regressors and (b) k lags of the residuals, where k is the order of the test. The simplest version of the test statistic from thisauxiliary regression is TR2, where T is the sample size and R2 is the coefficient of determination. Under the null hypothesis of no autocorrelation, this statistic isasymptotically distributed as [...] with k degrees of freedom.|$|E
5000|$|... where T is {{the number}} of observations. Note that if one has a lengthy sample, then this can be linearly mapped to the Pearson {{correlation}} of the time-series data with its lags. [...] Since d is approximately equal to 2(1 − r), where r is the sample autocorrelation of the residuals, d = 2 indicates no autocorrelation. The value of d always lies between 0 and 4. If the <b>Durbin-Watson</b> <b>statistic</b> is substantially less than 2, there is evidence of positive serial correlation. As a rough rule of thumb, if Durbin-Watson is less than 1.0, there may be cause for alarm. Small values of d indicate successive error terms are, on average, close in value to one another, or positively correlated. If d > 2, successive error terms are, on average, much different in value from one another, i.e., negatively correlated. In regressions, this can imply an underestimation of the level of statistical significance.|$|E
50|$|In {{statistic}}s, the <b>Durbin-Watson</b> <b>statistic</b> is a {{test statistic}} used to detect the presence of autocorrelation (a relationship between values separated from each other by a given time lag) in the residuals (prediction errors) from a regression analysis. It is named after James Durbin and Geoffrey Watson. The small sample distribution of this ratio was derived by John von Neumann (von Neumann, 1941). Durbin and Watson (1950, 1951) applied this statistic to the residuals from least squares regressions, and developed bounds tests for the null hypothesis that the errors are serially uncorrelated against the alternative that they follow a first order autoregressive process. Later, John Denis Sargan and Alok Bhargava developed several von Neumann-Durbin-Watson type test statistics for the null hypothesis that the errors on a regression model follow a process with a unit root against the alternative hypothesis that the errors follow a stationary first order autoregression (Sargan and Bhargava, 1983). Note that the distribution of this test statistic {{does not depend on}} the estimated regression coefficients and the variance of the errors.|$|E
5000|$|Yule (1936) and Granger and Newbold (1974) {{were the}} first to draw {{attention}} to the problem of spurious correlation and find solutions on how to address it in time series analysis. Given two completely unrelated but integrated (non-stationary) time series, the regression analysis of one on the other will tend to produce an apparently statistically significant relationship and thus a researcher might falsely believe to have found evidence of a true relationship between these variables. Ordinary least squares will no longer be consistent and commonly used test-statistics will be non-valid. In particular, Monte Carlo simulations show that one will get a very high R squared, very high individual t-statistic and a low <b>Durbin-Watson</b> <b>statistic.</b> Technically speaking, Phillips (1986) proved that parameter estimates will not converge in probability, the intercept will diverge and the slope will have a non-degenerate distribution as the sample size increases. However, there might a common stochastic trend to both series that a researcher is genuinely interested in because it reflects a long-run relationship between these variables. Because of the stochastic nature of the trend it is not possible to break up integrated series into a deterministic (predictable) trend and a stationary series containing deviations from trend. Even in deterministically detrended random walks walks spurious correlations will eventually emerge. Thus detrending doesn't solve the estimation problem. In order to still use the [...] Box-Jenkins approach, one could difference the series and then estimate models such as ARIMA, given that many commonly used time series (e.g. in economics) appear to be stationary in first differences. Forecasts from such a model will still reflect cycles and seasonality that are present in the data. However, any information about long-run adjustments that the data in levels may contain is omitted and longer term forecasts will be unreliable. This lead Sargan (1964) to develop the ECM methodology, which retains the level information.|$|E
40|$|A wide {{literature}} {{is available on}} the asymptotic behavior of the <b>Durbin-Watson</b> <b>statistic</b> for autoregressive models. However, it is impossible to find results on the <b>Durbin-Watson</b> <b>statistic</b> for autoregressive models with adaptive control. Our purpose is to fill the gap by establishing the asymptotic behavior of the Durbin Watson statistic for ARX models in adaptive tracking. On the one hand, we show the almost sure convergence as well as the asymptotic normality of the least squares estimators of the unknown parameters of the ARX models. On the other hand, we establish the almost sure convergence of the <b>Durbin-Watson</b> <b>statistic</b> and its asymptotic normality. Finally, we propose a bilateral statistical test for residual autocorrelation in adaptive tracking...|$|E
40|$|We {{propose a}} new {{statistical}} {{test for the}} residual autocorrelation in ARX adaptive tracking. The introduction of a persistent excitation in the adaptive tracking control allows us to build a bilateral statistical test based on the well-known <b>Durbin-Watson</b> <b>statistic.</b> We establish the almost sure convergence and the asymptotic normality for the <b>Durbin-Watson</b> <b>statistic</b> leading to a powerful serial correlation test. Numerical experiments illustrate the good performances of our statistical test procedure...|$|E
