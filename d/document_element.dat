31|500|Public
5000|$|Whitespace {{outside of}} the <b>document</b> <b>element</b> and within start and end tags is {{normalized}} ...|$|E
5000|$|... and [...] {{methods that}} are called {{at the start}} and end of a <b>document</b> <b>element.</b>|$|E
5000|$|... text nodes {{representing}} the text {{found between the}} start and end tags of a <b>document</b> <b>element.</b>|$|E
40|$|Abstract. In this paper, {{we propose}} a {{preference}} framework for information retrieval {{in which the}} user and the system administrator are enabled to express preference annotations on search keywords and <b>document</b> <b>elements,</b> respectively. Our framework is flexible and allows expressing preferences such as “A is infinitely more preferred than B, ” which we capture by using hyperreal numbers. Due to the widespread of XML as a standard for representing documents, we consider XML documents in this paper and propose a consistent preferential weighting scheme for nested <b>document</b> <b>elements.</b> We show how to naturally incorporate preferences on search keywords and <b>document</b> <b>elements</b> into an IR ranking process using the well-known TF-IDF ranking measure. ...|$|R
50|$|The {{concept of}} merging static <b>document</b> <b>elements</b> and {{variable}} <b>document</b> <b>elements</b> predates the term and has seen various implementations ranging from simple desktop 'mail merge', to complex mainframe {{applications in the}} financial and banking industry. In the past, the term VDP has been most closely associated with digital printing machines. However, {{in recent years the}} application of this technology has spread to web pages, emails, and mobile messaging.|$|R
50|$|CSS Animations is a {{proposed}} module for Cascading Style Sheets {{that allows the}} animation of HTML <b>document</b> <b>elements</b> using CSS.|$|R
5000|$|... {{method that}} is called with the text data {{contents}} contained between the start and end tags of an XML <b>document</b> <b>element.</b>|$|E
50|$|The RDFa {{metadata}} {{is embedded}} as an XHTML attribute of the <b>document</b> <b>element,</b> generally the XHTML tag. The annotation syntax provided by RDFa {{can be used}} to express RDF statements in XHTML documents.|$|E
50|$|An editor {{can be made}} {{smart enough}} to track the {{location}} of each token, permitting new, longer tokens to replace existing, shorter tokens by merely addressing the new token in separate memory outside that used to store the original document. Likewise, when reordering the <b>document,</b> <b>element</b> text {{does not need to}} be copied; only the LCs need to be updated. When a complete, contiguous XML document is needed, such as when saving it, the disparate parts can be reassembled into a new, contiguous document.|$|E
5000|$|Syntax {{highlighting}} ("font lock"): {{combinations of}} fonts and colors, termed [...] "faces," [...] that differentiate between <b>document</b> <b>elements</b> such as keywords and comments.|$|R
40|$|We {{present in}} this paper a method for {{document}} layout analysis based on identifying the function of <b>document</b> <b>elements</b> (what they do). This approach is orthogonal and complementary to the traditional view based on the form of <b>document</b> <b>elements</b> (how they are constructed). One key advantage of such functional knowledge is that the functions of some <b>document</b> <b>elements</b> are very stable from document to document and over time. Relying on the stability of such functions, the method is not impacted by layout variability, a key issue in logical document analysis and is thus very robust and versatile. The method starts the recognition process by using functional knowledge and uses in a second step formal knowledge {{as a source of}} feedback in order to correct some errors. This allows the method to adapt to specific documents by using formal specificities...|$|R
40|$|International audienceWe {{consider}} the Structured Information Retrieval task which consists in ranking nested textual units {{according to their}} relevance for a given query, {{in a collection of}} structured documents. We propose to improve the performance of a baseline Information Retrieval system by using a learning ranking algorithm which operates on scores computed from <b>document</b> <b>elements</b> and from their local structural context. This model is trained to optimize a Ranking Loss criterion using a training set of annotated examples composed of queries and relevance judgments on a subset of the <b>document</b> <b>elements.</b> The model can produce a ranked list of <b>documents</b> <b>elements</b> which fulfills a given information need expressed in the query. We analyze the performance of our algorithm on the INEX collection and compare it to a baseline model which is an adaptation of Okapi to Structured Information Retrieval...|$|R
5000|$|The {{fact that}} it created {{structured}} documents enabled Interleaf to add its Active Document capabilities in the early 1990s. Just as JavaScript enables contemporary software developers to add functionality and [...] "intelligence" [...] to Web documents, Interleaf used LISP to enable document authors and engineers to enhance its authoring electronic publishing systems. Any <b>document</b> <b>element</b> could be given new [...] "methods" [...] (capabilities), and could respond {{to changes in the}} content or structure of the document itself. Typical applications included documents that automatically generated and updated charts based upon data expressed in the document, pages that altered themselves based on data accessed from databases or other sources, and systems that dynamically created pages to guide users through complex processes such as filling out insurance forms.|$|E
5000|$|Web markup {{languages}} such as XML and HTML treat whitespace characters specially, including space characters, for programmers' convenience. One or {{more space}} characters read by conforming display-time processors of those markup languages are collapsed to 0 or 1 space, {{depending on their}} semantic context. For example, double (or more) spaces within text are collapsed to a single space, and spaces which appear {{on either side of}} the [...] "" [...] that separates an attribute name from its value have no effect on the interpretation of the <b>document.</b> <b>Element</b> end tags can contain trailing spaces, and empty-element tags in XML can contain spaces before the [...] "". In these languages, unnecessary white space increases the file size, and so may slow network transfers. On the other hand, unnecessary white space can also inconspicuously mark code, similar to, but less obvious than comments in code. This can be desirable to prove an infringement of license or copyright that was committed by copying and pasting.|$|E
40|$|We propose {{simplifying}} {{the editing}} of structured documents that conform to Backus-Naur Form (BNF) grammars, by exposing and {{operating on the}} grammar itself. We introduce an original grammar view that supports browsing and editing of structured documents and is coordinated with the document view. The grammar view presents <b>document</b> <b>element</b> types in context to better support document editing. Both shading and font size scaling are {{used to create a}} focus area in the grammar view making it more scalable for larger grammars. We present an implementation of a grammar view for XML documents, in our XML editor, Xeena for Schema...|$|E
40|$|As {{more and}} more {{structured}} documents, such as SGML or XML documents become available on the Web, {{there is a growing}} demand to develop effective structured document retrieval which exploits both content and hierarchical structure of documents and return <b>document</b> <b>elements</b> with appropriate granularity. Previous work on partial retrieval of structured document has limited applications due to the requirement of structured queries and restriction on sliding along the document structure according to queries. In this paper, we put forward a method for flexible element retrieval which can get relevant <b>document</b> <b>elements</b> with arbitrary granularity against natural language queries. The proposed techniques constitute a novel hierarchical index propagation and pruning mechanism and an algorithm of ranking <b>document</b> <b>elements</b> based on the hierarchical index. The experimental results show that our method significantly outperforms other existing methods. Our method also shows robustness to the long-standing problems of text length normalization and threshold setting in structured document retrieval...|$|R
50|$|Along with {{conversion}} to almost all popular document formats, Aspose.Words product family supports documents rendering, printing, reporting, mail merge and advanced formatting for any <b>document</b> <b>elements</b> using <b>document</b> object model.|$|R
40|$|International audienceStandard Information Retrieval (IR) metrics are {{not well}} suited for new {{paradigms}} like XML or Web IR in which retrievable information units are <b>document</b> <b>elements</b> and/or sets of related documents. Part of the problem stems from the classical hypotheses on the user models: They do {{not take into account}} the structural or logical context of <b>document</b> <b>elements</b> or the possibility of navigation between units. This article proposes an explicit and formal user model that encompasses a large variety of user behaviors. Based on this model, we extend the probabilistic precision-recall metric to deal with the new IR paradigms...|$|R
40|$|Abstract — WebKB is {{a public}} domain {{knowledge}} annotation toolkit allowing indices of any <b>Document</b> <b>Element</b> (DE) on the WWW to be built using annotations in a Knowledge Representation (KR) language: Conceptual Graphs. The language permits the semantic content and relationships to other DEs to be described precisely. Search can be initiated remotely, via a WWW-browser and/or other software. WebKB enables the document generation using inferences within the knowledge engine to assemble DEs. Additionally, the knowledge base provides an alternate index through which both query and direct hyper-link navigation can occur. This paper describes {{some of the key}} features of the toolkit and its approach to knowledge indexation. I...|$|E
40|$|Much {{research}} {{has been carried out}} in order to man-age structured documents such aa SGML documents and to provide powerful query facilities which exploit document structures as well as document contents. In order to perform structure queries efficiently in a structured document management system, an index struc-ture which supports fast <b>document</b> <b>element</b> access must be provided. However, there has been little research on the index structures for structured documents. In this paper, we propose various kinds of new inverted indexing schemes and signature file schemes for eficient structure query processing. We evaluate the storage re-quirements and disk access times of our schemes and present the analytical and experiment al results...|$|E
40|$|In this paper, {{we first}} show how in CGKAT, our {{knowledge}} acquisition tool, any <b>document</b> <b>element</b> and its semantics may be represented using the Conceptual Graphs formalism (Sowa, 1984) and a structured document editor. Then, we study {{the kinds of}} hypertext links that may be set between documents elements and concepts or relations {{of the knowledge base}} (such links enables the use of search techniques on the KB for finding information within the documents). In a second part, we detail the top-level ontologies (for concepts and relations) proposed by CGKAT and its exploitation of a semantically structured dictionary for guiding knowledge representation and easing its later reuse. ...|$|E
5000|$|Each XML {{document}} has {{exactly one}} single root element. It encloses {{all the other}} elements and is therefore the sole parent element {{to all the other}} elements. ROOT elements are also called <b>document</b> <b>elements.</b>|$|R
5000|$|The term variable-data {{publishing}} {{was likely}} {{an offshoot of}} the term [...] "variable-data printing", first introduced to the printing industry by Frank Romano, Professor Emeritus, School of Print Media, at the College of Imaging Arts and Sciences at Rochester Institute of Technology. However, the concept of merging static <b>document</b> <b>elements</b> and variable <b>document</b> <b>elements</b> predates the term and has seen various implementations ranging from simple desktop 'mail merge', to complex mainframe applications in the financial and banking industry. In the past, the term VDP has been most closely associated with digital printing machines. However, in the past 3 years the application of this technology has spread to web pages, emails, and mobile messaging.|$|R
40|$|This paper {{proposes a}} new method for {{document}} transformation using OCR to generate various XML documents from printed documents. The proposed method adopts a hierarchical transformation strategy {{based on a}} pivot XML <b>document.</b> Firstly, <b>document</b> <b>elements</b> such as title, authors, abstract, headings, paragraphs, lists, captions, tables and figures are extracted from document images. Secondly, the hierarchical structure of <b>document</b> <b>elements</b> is extracted and is described using a DOM tree. Thirdly, this document structure is converted into a pivot XML document described as an XHTML document by an XML parser. Finally, this pivot XML document is transformed into the target XML document by the XML parser with XSLT scripts or specific programs. Experimental results show the method is effective in transforming printed documents to various XML documents...|$|R
40|$|This paper {{explores the}} {{possibility}} of using a modified Expectation-Maximization algorithm to estimate parameters for a simple hierarchical generative model for XML retrieval. The generative model for an XML element is estimated by linearly interpolating statistical language models estimated from the text of the element, the parent element, the <b>document</b> <b>element,</b> and its children elements. We heuristically modify EM to allow the incorporation of negative examples, then attempt to maximize the likelihood of the relevant components while minimizing the likelihood of non-relevant components found in training data. The technique for incorporation of negative examples provide an e#ective algorithm to estimate the parameters in the linear combination mentioned...|$|E
40|$|A {{document}} analysis method {{based on a}} structural model nf document elements and pages is described. byout analysis for generic dmumcnt elements and logical structure analyaia For upecific documents are integrated in a consistent way. Each category of <b>document</b> <b>element</b> {{is defined as a}} "class". Each definitien of class consists of a definition type. classes of subordinate elernenLq with logicnl labels and geometric con-atraints among them. Classes of specific pages can be defined as well as classes of elements. Class definitions form a net-work whose nodes correspond to element classes and whom links correspond to elementrsubordinate reIations. The rec-ognition process storb from the most primitive element class, and traverses the network to find elements satisfying geo-metric constraints in the definition. It progresses sequen...|$|E
40|$|It is {{difficult}} to view multipage, high resolution documents on devices with small displays. As a solution, we introduce a Multimedia Thumbnail representation, which {{can be seen as}} a multimedia clip that provides an automated guided tour through a document. Multimedia Thumbnails are automatically generated by taking a document image as input and first performing visual and audible information analysis on the document to determine salient document elements. Next, the time and information attributes for each <b>document</b> <b>element</b> are computed by taking into account the display and application constraints. An optimization routine, given a time constraint, selects elements to be included in the Multimedia Thumbnail. Last, the selected elements are synthesized into animated images and audio to create the final multimedia representation. 1...|$|E
50|$|Since VTDs {{refer to}} <b>document</b> <b>{{elements}}</b> by their offsets, {{changes to the}} length of elements occurring earlier in a document require adjustments to VTDs referring to all later elements. However, those adjustments are integer additions, albeit to many integers in multiple tables, so they are quick.|$|R
40|$|In {{order to}} {{facilitate}} your authoring process, ICE 2001 provides you with a professional MS Word document template, containing predefined styles for all your <b>document</b> <b>elements.</b> Using these styles will keep your effort to prepare an excellent page layout to a minimum and will ensure a smooth editing of the conference proceedings...|$|R
50|$|Like most Japanese {{historical}} epics, the Taiheikis tendencies towards {{drama and}} exaggeration are acknowledged, but {{the text is}} regarded as remaining mostly accurate. It is the primary source {{on many of the}} warriors and battles of this period, and also <b>documents</b> <b>elements</b> of the fall of the powerful and historically important Hōjō clan.|$|R
40|$|The American Mathematical Society {{has been}} {{involved}} in the development of TEX from the beginning and began using it for journal production ten years ago; we now produce nearly all of our publications (a couple of dozen journals and book series) with TEX, using AMS-developed macro packages. One of the goals set for a major overhaul of the primary in-house macro package, begun in 1992, was to make revisions to the visual design of a given publication easier. In the new version of the macro package the design specifications for a particular <b>document</b> <b>element</b> (such as an article title) are not embedded in TEX code, but are entered into an element specs template that is comparatively easy to read and modify, and that corresponds more directly to traditional book design specs (e. g., vertical spacing is expected to be given in base-to-base terms) ...|$|E
40|$|WebKB is {{a public}} domain {{knowledge}} annotation toolkit allowing indices of any <b>Document</b> <b>Element</b> (DE) on the WWW to be built using annotations in a Knowledge Representation (KR) language: Conceptual Graphs. The language permits the semantic content and relationships to other DEs to be described precisely. Search can be initiated remotely, via a WWW-browser and/or other software. WebKB enables the document generation using inferences within the knowledge engine to assemble DEs. Additionally, the knowledge base provides an alternate index through which both query and direct hyper-link navigation can occur. This paper describes {{some of the key}} features of the toolkit and its approach to knowledge indexation. I. INTRODUCTION WebKB [13] {{is a public}} domain knowledge annotation toolkit sharing many design principles with WWW-based public annotation tools, e. g. ComMentor [18] and HyperNews [9], and WWW-based traders, e. g. AlephWeb [17], NetRepository [10] and AI-trader [16]. Despite similariti [...] ...|$|E
40|$|Due to the wide-spread {{use of the}} WWW, many {{institutions}} are using HTML to encode their documents for hypertext presentation. However, HTML is not always suitable for long-term document storage. Hypermedia/Time-based Structuring Language (HyTime) is designed for the long-term and presentation-independent storage of hypertext documents. Because of the close relationship both HTML and HyTime have with Standard Generalized Markup Language (SGML), HyTime-encoded documents can easily be translated into HTML. This paper discusses the issues involved in such translations. (IDREF). An ID attribute gives its element a unique name within the document. An IDREF attribute has as its value the ID of some other element in the document, thus representing {{a reference to the}} element. The third primary construct of SGML is the entity. One of the most important uses of the entity is to enable the inclusion of external files in any format, even non-text, in a <b>document</b> <b>element.</b> Together these construct [...] ...|$|E
5000|$|... {{introduction}} to fine-tune the <b>documents</b> dynamic <b>elements</b> - [...] "Actions", such as: ...|$|R
40|$|Abstract. The {{characteristics}} of lists, forms and tables are compared {{from the perspective}} of layout and indexing. Examples of ambiguous <b>document</b> <b>elements</b> reveal barriers to interpreting them. As a common denominator, the collection of facts in lists, forms, and tables all constitute first-order logic theories and can be represented as machine-queriable relations in a relational database...|$|R
5000|$|... content: the XUL <b>document(s),</b> whose <b>elements</b> {{define the}} layout of the user {{interface}} ...|$|R
