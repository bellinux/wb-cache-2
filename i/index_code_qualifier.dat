0|1613|Public
50|$|Key <b>Code</b> <b>Qualifier</b> is an error-code {{returned}} by a SCSI device.|$|R
5000|$|Q - {{additional}} sense <b>code</b> <b>qualifier</b> (ASCQ) - 8 bits, (byte 13 of Fixed sense data format) ...|$|R
40|$|Abstract—An <b>index</b> <b>coding</b> {{scheme in}} which the source transmits binary symbols over a {{wireless}} fading channel is considered. <b>Index</b> <b>codes</b> with the transmitter using minimum number of transmissions are known as optimal <b>index</b> <b>codes.</b> Different optimal <b>index</b> <b>codes</b> give different performances in terms of probability of error in a fading environment and this also varies from receiver to receiver. In this paper we deal with optimal <b>index</b> <b>codes</b> which minimizes the maximum probability of error among all the receivers. We identify a criterion for optimal <b>index</b> <b>codes</b> that minimizes the maximum probability of error among all the receivers. For a special class of <b>index</b> <b>coding</b> problems, we give an algorithm to identify optimal <b>index</b> <b>codes</b> which minimize the maximum error probability. We illustrate our techniques and claims with simulation results leading to conclude that a careful choice among the optimal <b>index</b> <b>codes</b> will give a considerable gain in fading channels. <b>Index</b> Terms—Index <b>coding,</b> side information, fading broadcast channels. I...|$|R
40|$|An <b>index</b> <b>coding</b> {{scheme in}} which the source (transmitter) transmits binary symbols over a {{wireless}} fading channel is considered. <b>Index</b> <b>codes</b> with the transmitter using minimum number of transmissions are known as optimal <b>index</b> <b>codes.</b> Different optimal <b>index</b> <b>codes</b> give different performances in terms of probability of error in a fading environment and this also varies from receiver to receiver. In this paper we deal with optimal <b>index</b> <b>codes</b> which minimizes the maximum probability of error among all the receivers. We identify a criterion for optimal <b>index</b> <b>codes</b> that minimizes the maximum probability of error among all the receivers. For a special class of <b>index</b> <b>coding</b> problems, we give an algorithm to identify optimal <b>index</b> <b>codes</b> which minimize the maximum error probability. We illustrate our techniques and claims with simulation results leading to conclude that a careful choice among the optimal <b>index</b> <b>codes</b> will give a considerable gain in fading channels...|$|R
40|$|Abstract—This paper studies {{a special}} class of {{multicast}} <b>index</b> <b>coding</b> problems where a sender transmits messages to multiple receivers, each with some side information. Here, each receiver knows a unique message a priori, {{and there is}} no restriction on how many messages each receiver requests from the sender. For this class of multicast <b>index</b> <b>coding</b> problems, we obtain the optimal <b>index</b> <b>code,</b> which has the shortest codelength for which the sender needs to send in order for all receivers to obtain their (respective) requested messages. This is the first class of <b>index</b> <b>coding</b> problems where the optimal <b>index</b> <b>codes</b> are found. In addition, linear <b>index</b> <b>codes</b> are shown to be optimal for this class of <b>index</b> <b>coding</b> problems. I...|$|R
40|$|In this paper, we generalize the {{well-known}} <b>index</b> <b>coding</b> problem {{to exploit the}} structure in the source-data to improve system throughput. In many applications, the {{data to be transmitted}} may lie (or can be well approximated) in a low-dimensional subspace. We exploit this low-dimensional structure of the data using an algebraic framework to solve the <b>index</b> <b>coding</b> problem (referred to as subspace-aware <b>index</b> <b>coding)</b> as opposed to the traditional <b>index</b> <b>coding</b> problem which is subspace-unaware. Also, we propose an efficient algorithm based on the alternating minimization approach to obtain near optimal <b>index</b> <b>codes</b> for both subspace-aware and -unaware cases. Our simulations indicate that under certain conditions, a significant throughput gain (about 90 %) can be achieved by subspace-aware <b>index</b> <b>codes</b> over conventional subspace-unaware <b>index</b> <b>codes...</b>|$|R
40|$|In this paper, new <b>index</b> <b>coding</b> {{problems}} are studied, where each receiver has erroneous side information. Although side information {{is a crucial}} part of <b>index</b> <b>coding,</b> the existence of erroneous side information has not yet been considered. We study an <b>index</b> <b>code</b> with receivers that have erroneous side information symbols in the error-free broadcast channel, which is called an <b>index</b> <b>code</b> with side information errors (ICSIE). The encoding and decoding procedures of the ICSIE are proposed, based on the syndrome decoding. Then, we derive the bounds on the optimal codelength of the proposed <b>index</b> <b>code</b> with erroneous side information. Furthermore, we introduce a special graph for the proposed <b>index</b> <b>coding</b> problem, called a δ_s-cycle whose properties {{are similar to those of}} the cycle in the conventional <b>index</b> <b>coding</b> problem. Properties of the ICSIE are also discussed in the δ_s-cycle and clique. Finally, the proposed ICSIE is generalized to an <b>index</b> <b>code</b> for the scenario having both additive channel errors and side information errors, called a generalized error correcting <b>index</b> <b>code</b> (GECIC) ...|$|R
40|$|In this paper, noisy <b>index</b> <b>coding</b> {{problems}} over AWGN channel are considered. For a given <b>index</b> <b>coding</b> {{problem and}} a chosen scalar linear <b>index</b> <b>code</b> of length N, we proppse to transmit the N <b>index</b> <b>coded</b> bits {{as a single}} signal from a 2 (N) -PSK constellation. By transmitting the <b>index</b> <b>coded</b> bits in this way, there is an N/ 2 - fold reduction in the required bandwidth. Also, by transmitting the <b>index</b> <b>coded</b> bits as a PSK signal, receivers with side information satisfying certain conditions get coding gain relative to a receiver with no side information. This coding gain obtained by the receivers is due to proper utilization of their side information and hence is called ``PSK side information coding gain (PSK-SICG) ''. We state and prove a necessary and sufficient condition for a receiver to get PSK-SICG. An algorithm to map the <b>index</b> <b>coded</b> bits to PSK signal set such that the PSK-SICG obtained is maximized for the receiver with maximum side information is given. Further, we show that if <b>index</b> <b>coded</b> bits are transmitted as a PSK signal, {{it is not always}} necessary to minimize the length of <b>index</b> <b>code</b> used as there are <b>index</b> <b>coding</b> problems where use of a longer <b>index</b> <b>code</b> will give a better performance in terms of probability of error...|$|R
40|$|The <b>index</b> <b>coding</b> {{problem has}} been {{generalized}} recently to accommodate receivers which demand functions of messages and which possess functions of messages. The connections between <b>index</b> <b>coding</b> and matroid theory have been well studied in the recent past. <b>Index</b> <b>coding</b> solutions were first connected to multi linear representation of matroids. For vector linear <b>index</b> <b>codes</b> discrete polymatroids which {{can be viewed as}} a generalization of the matroids was used. It was shown that a vector linear solution to an <b>index</b> <b>coding</b> problem exists if and only if there exists a representable discrete polymatroid satisfying certain conditions. In this work we explore the connections between generalized <b>index</b> <b>coding</b> and discrete polymatroids. The conditions that needs to be satisfied by a representable discrete polymatroid for a generalized <b>index</b> <b>coding</b> problem to have a vector linear solution is established. From a discrete polymatroid we construct an <b>index</b> <b>coding</b> problem with coded side information and shows that if the <b>index</b> <b>coding</b> problem has a certain optimal length solution then the discrete polymatroid satisfies certain properties. From a matroid we construct a similar generalized <b>index</b> <b>coding</b> problem and shows that the <b>index</b> <b>coding</b> problem has a binary scalar linear solution of optimal length if and only if the matroid is binary representable. Comment: Expanded version of a paper accepted in ISIT 2017. 13 pages with 6 table...|$|R
40|$|This paper studies {{a special}} class of {{multicast}} <b>index</b> <b>coding</b> problems where a sender transmits messages to multiple receivers, each with some side information. Here, each receiver knows a unique message a priori, {{and there is}} no restriction on how many messages each receiver requests from the sender. For this class of multicast <b>index</b> <b>coding</b> problems, we obtain the optimal <b>index</b> <b>code,</b> which has the shortest codelength for which the sender needs to send in order for all receivers to obtain their (respective) requested messages. This is the first class of <b>index</b> <b>coding</b> problems where the optimal <b>index</b> <b>codes</b> are found. In addition, linear <b>index</b> <b>codes</b> are shown to be optimal for this class of <b>index</b> <b>coding</b> problems. Comment: Author's final version (to be presented at ICC 2012...|$|R
40|$|The {{connection}} between <b>index</b> <b>coding</b> and matroid theory {{have been well}} studied in the recent past. El Rouayheb et al. established a {{connection between}} multi linear representation of matroids and wireless <b>index</b> <b>coding.</b> Muralidharan and Rajan showed that a vector linear solution to an <b>index</b> <b>coding</b> problem exists {{if and only if}} there exists a representable discrete polymatroid satisfying certain conditions. Recently <b>index</b> <b>coding</b> with erroneous transmission was considered by Dau et al [...] Error correcting <b>index</b> <b>codes</b> in which all receivers are able to correct a fixed number of errors was studied. In this paper we consider a more general scenario in which each receiver is able to correct a desired number of errors, calling such <b>index</b> <b>codes</b> differential error correcting <b>index</b> <b>codes.</b> We show that vector linear differential error correcting <b>index</b> <b>code</b> exists if and only if there exists a representable discrete polymatroid satisfying certain conditionsComment: arXiv admin note: substantial text overlap with arXiv: 1501. 0506...|$|R
40|$|The {{symmetric}} {{capacity for}} <b>index</b> <b>coding</b> problems with K messages and K receivers, each demanding a unique message (Single Unicast <b>Index</b> <b>Coding</b> Problem) and having symmetric (with respect to receiver index), neighboring and consecutive side information (SUICP-SNC) {{have been reported}} by Maleki, Cadambe and Jafar. For these <b>index</b> <b>coding</b> problems, assuming that the transmissions are error prone, we present optimal length error-correcting <b>index</b> <b>codes</b> for all one-sided SUICP-SNC problems and for some cases of two-sided SUICP-SNC problems. We also discuss construction for these optimal Error Correcting <b>Index</b> <b>Codes...</b>|$|R
40|$|<b>Index</b> <b>coding</b> {{is often}} studied with the {{assumption}} that a single source has all the messages requested by the receivers. We refer to this as centralized <b>index</b> <b>coding.</b> In contrast, this paper focuses on distributed <b>index</b> <b>coding</b> and addresses the following question: How does the availability of messages at distributed sources (storage nodes) affect the solutions and achievable rates of <b>index</b> <b>coding?</b> An extension to the work of Arbabjolfaei et al. in ISIT 2013 is presented when distributed sources communicate via a semi-deterministic multiple access channel (MAC) to simultaneous receivers. A numbers of examples are discussed that show the effect of message distribution and redundancy across the network on achievable rates of <b>index</b> <b>coding</b> and motivate future research on designing practical network storage codes that offer high <b>index</b> <b>coding</b> rates...|$|R
40|$|This paper {{deals with}} scalar linear <b>index</b> <b>codes</b> for {{canonical}} multiple unicast <b>index</b> <b>coding</b> problems {{where there is}} a source with K messages and there are K receivers each wanting a unique message and having symmetric (with respect to the receiver index) antidotes (side information). Optimal scalar linear <b>index</b> <b>codes</b> for several such instances of this class of problems have been reported in MRRarXiv. These codes can be viewed as special cases of the symmetric unicast <b>index</b> <b>coding</b> problems discussed in MCJ. In this paper a lifting construction is given which constructs a sequence of multiple unicast index problems starting from a given multiple unicast <b>index</b> <b>coding</b> problem. Also, it is shown that if an optimal scalar linear <b>index</b> <b>code</b> is known for the problem given starting problem then optimal scalar linear <b>index</b> <b>codes</b> can be obtained from the known code for all the problems arising from the proposed lifting construction. For several of the known classes of multiple unicast problems our construction is used to obtain several sequences of multiple unicast problem with optimal scalar linear <b>index</b> <b>codes.</b> Comment: 9 pages. arXiv admin note: text overlap with arXiv: 1510. 0543...|$|R
40|$|We {{present a}} novel upper {{bound for the}} optimal <b>index</b> <b>coding</b> rate. Our bound uses a graph theoretic {{quantity}} called the local chromatic number. We show how a good local coloring {{can be used to}} create a good <b>index</b> <b>code.</b> The local coloring is used as an alignment guide to assign <b>index</b> <b>coding</b> vectors from a general position MDS code. We further show that a natural LP relaxation yields an even stronger <b>index</b> <b>code.</b> Our bounds provably outperform {{the state of the art}} on <b>index</b> <b>coding</b> but at most by a constant factor. Comment: 14 Pages, 3 Figures; A conference version submitted to ISIT 2013; typos correcte...|$|R
40|$|We {{show that}} the network <b>coding</b> and <b>index</b> <b>coding</b> {{problems}} are equivalent. This equivalence holds in the general setting which includes linear and non-linear codes. Specifically, we present a reduction that maps a network coding instance to an <b>index</b> <b>coding</b> instance while preserving feasibility, i. e., the network coding instance has a feasible solution {{if and only if}} the corresponding <b>index</b> <b>coding</b> instance is feasible. In addition, we show that one can determine the capacity region of a given network coding instance with colocated sources by studying the capacity region of a corresponding <b>index</b> <b>coding</b> instance. Previous connections between network and <b>index</b> <b>coding</b> were restricted to the linear case...|$|R
40|$|The <b>index</b> <b>coding</b> {{problem is}} a {{fundamental}} transmission problem arising in content distribution and wireless networks. Traditional approach {{to solve this problem}} is to find heuristic/ approximation minimum clique partition solution on an appropriately mapped graph of the <b>index</b> <b>coding</b> problem. In this paper we study <b>index</b> <b>code</b> for unicast data flow for which we propose updated clique <b>index</b> <b>coding</b> (UCIC) scheme, UCIC piggybacks additional information in the coded symbol such that an unsatisfied client can update its cache. We show that UCIC has higher coding gain than previously proposed <b>index</b> <b>coding</b> schemes, and it is optimal for those instances where <b>index</b> <b>code</b> of minimum length is known. Comment: This paper has been accepted for publication in the 39 th IEEE Conference on Local Computer Networks (LCN) to be held in Edmonton, Canada, Sep. 8 - 11, 201...|$|R
40|$|Abstract-The <b>index</b> <b>coding</b> problem {{involves}} a sender with K messages to be transmitted across a broadcast channel, {{and a set}} of receivers each of which demands a subset of the K messages while having prior knowledge of a different subset as side information. We consider the specific instance of noisy <b>index</b> <b>coding</b> where the broadcast channel is Gaussian and every receiver demands all the messages from the source. We construct lattice <b>index</b> <b>codes</b> for this channel by encoding the K messages individually using K modulo lattice constellations and transmitting their sum modulo a shaping lattice. We introduce a design metric called side information gain that measures the advantage of a code in utilizing the side information at the receivers, and hence its quality as an <b>index</b> <b>code.</b> Based on the Chinese remainder theorem, we then construct lattice <b>index</b> <b>codes</b> for the Gaussian broadcast channel. Among all lattice <b>index</b> <b>codes</b> constructed using any densest lattice of a given dimension, our codes achieve the maximum side information gain. Index Terms-Chinese remainder theorem, Gaussian broadcast channel, <b>index</b> <b>coding,</b> lattice codes, side information. I...|$|R
40|$|This paper {{deals with}} vector linear <b>index</b> <b>codes</b> for {{multiple}} unieast <b>index</b> <b>coding</b> problems {{where there is}} a source with K messages and there are K receivers each wanting a unique message and having symmetrie (with respect to the receiver index) two-sided antidotes (side information). Starting from a given multiple unieast <b>index</b> <b>coding</b> problem with K messages and symmetrie one-sided antidotes for which a scalar linear <b>index</b> <b>code</b> (sic) is known, we give a construction procedure whieh constructs a sequence (indexed by m) of multiple unicast <b>index</b> <b>coding</b> problems with symmetrie two-sided antidotes (for the same source) for all of whieh a vector linear code ((m)) is obtained from (sic). Also, it is shown that if (sic) is optimal then ((m)) is also optimal for all m. To our knowledge, this is the first paper whieh gives a method to construct a sequence of optimal vector linear <b>index</b> <b>codes...</b>|$|R
40|$|This {{document}} proposes {{several new}} additional sense code and additional sense <b>code</b> <b>qualifiers</b> defined for use within SMC- 3. Both the sense code description and usage within SMC- 3 are presented. Once agreement is reached within the SMC- 3 working group for this proposal, a corresponding proposal for th...|$|R
5000|$|Tele{{communications}} Center Specialist (teletype) - Tape Ape - (72B w/D1 designator), Radio Teletype (RTTY) w/Morse <b>Code</b> <b>qualifier</b> (05C), Cryptanalysis/Cryptanalytic Technician (crippies),(98B), communications traffic analysts (98C), voice intercept operators (Monterey-Marys)(98G) non-communications intercept/analysts (98J - {{radar and}} telemetry) electronic cryptographic maintenance technicians(32F-G, and 33S), and Specialized Teletypewriter Equipment Repairman (31J B3).|$|R
40|$|In <b>Index</b> <b>coding</b> {{there is}} a single sender with {{multiple}} messages and multiple receivers each wanting a different set of messages and knowing a different set of messages a priori. The <b>Index</b> <b>Coding</b> problem is to identify the minimum number of transmissions (optimal length) to be made so that all receivers can decode their wanted messages using the transmitted symbols and their respective prior information and also the codes with optimal length. Recently it was shown that different optimal length codes perform differently in a wireless channel. Towards identifying the best optimal length <b>index</b> <b>code</b> one needs to know the number of optimal length <b>index</b> <b>codes.</b> In this paper we present results on the number of optimal length <b>index</b> <b>codes</b> making use of the representation of an <b>index</b> <b>coding</b> problem by an equivalent network code. We give the minimum number of codes possible with the optimal length. This is done using a simpler algebraic formulation of the problem compared to the approach of Koetter and Medard...|$|R
40|$|Abstract—We propose <b>index</b> <b>codes,</b> {{based on}} multidimensional QAM constellations, for the Gaussian {{broadcast}} channel, where every receiver demands all the {{messages from the}} source. The effi-ciency with which an <b>index</b> <b>code</b> exploits receiver side information in this broadcast channel is characterised by a code design metric called side information gain. The known <b>index</b> <b>codes</b> for this broadcast channel enjoy large side information gains, but do not encode all the source messages at the same rate, and do not admit message sizes that are powers of two. The <b>index</b> <b>codes</b> proposed in this letter, {{which are based on}} linear codes over integer rings, overcome both these drawbacks and yet provide large values of side information gain. With the aid of a computer search, we obtain QAM <b>index</b> <b>codes</b> for encoding up to 5 messages with message sizes 2 m, m ≤ 6. We also present the simulated performance of a new 16 -QAM <b>index</b> <b>code,</b> concatenated with an off-the-shelf LDPC code, which is observed to operate within 4. 3 dB of the broadcast channel capacity. Index Terms—Codes over rings, Gaussian broadcast, <b>index</b> <b>coding,</b> quadrature amplitude modulation, side information. I...|$|R
40|$|In {{contrast}} to the network coding problem wherein the sinks in a network demand subsets of the source messages, in a network computation problem the sinks demand functions of the source messages. Similarly, in the functional <b>index</b> <b>coding</b> problem, the side information and demands of the clients include disjoint sets of functions of the information messages held by the transmitter instead of disjoint subsets of the messages, {{as is the case}} in the conventional <b>index</b> <b>coding</b> problem. It is known that any network coding problem can be transformed into an <b>index</b> <b>coding</b> problem and vice versa. In this work, we establish a similar relationship between network computation problems and a class of functional <b>index</b> <b>coding</b> problems, viz., those in which only the demands of the clients include functions of messages. We show that any network computation problem can be converted into a functional <b>index</b> <b>coding</b> problem wherein some clients demand functions of messages and vice versa. We prove that a solution for a network computation problem exists if and only if a functional <b>index</b> <b>code</b> (of a specific length determined by the network computation problem) for a suitably constructed functional <b>index</b> <b>coding</b> problem exists. And, that a functional <b>index</b> <b>coding</b> problem admits a solution of a specified length if and only if a suitably constructed network computation problem admits a solution. Comment: 3 figures, 7 tables and 9 page...|$|R
40|$|A sender {{wishes to}} {{broadcast}} an n character word x in F^n (for a field F) to n receivers R_ 1, [...] .,R_n. Every receiver has some side information on x {{consisting of a}} subset of the characters of x. The side information of the receivers is represented by a graph G on n vertices in which i,j is an edge if R_i knows x_j. In the <b>index</b> <b>coding</b> problem the goal is to encode x using a minimum number of characters in F in a way that enables every R_i to retrieve the ith character x_i using the encoded message and the side information. An <b>index</b> <b>code</b> is linear if the encoding is linear, and in this case the minimum possible length is known to be equal to a graph parameter called minrank (Bar-Yossef et al., FOCS' 06). Several bounds on the minimum length of an <b>index</b> <b>code</b> for side information graphs G were shown in the study of <b>index</b> <b>coding.</b> However, the minimum length of an <b>index</b> <b>code</b> for the random graph G(n,p) is far from being understood. In this paper we initiate the study of the typical minimum length of a linear <b>index</b> <b>code</b> for G(n,p) over a field F. First, we prove that for every constant size field F and a constant p, the minimum length of a linear <b>index</b> <b>code</b> for G(n,p) over F is almost surely Omega(√(n)). Second, we introduce and study the following two restricted models of index coding: 1. A locally decodable <b>index</b> <b>code</b> is an <b>index</b> <b>code</b> in which the receivers are allowed to query at most q characters from the encoded message. 2. A low density <b>index</b> <b>code</b> is a linear <b>index</b> <b>code</b> in which every character of the word x affects at most q characters in the encoded message. Equivalently, it is a linear code whose generator matrix has at most q nonzero entries in each row. Comment: 16 page...|$|R
40|$|Abstract—In this paper, linear binary <b>index</b> <b>coding</b> is con-sidered. It {{is shown}} that the minimum clique-cover {{heuristic}} algorithm can provide {{an efficient way to}} solving linear binary <b>index</b> <b>coding</b> problems. Based on the least difference greedy (LDG) clique-cover algorithm, an existing minimum clique-cover algorithm for <b>index</b> <b>coding,</b> proposed by Birk and Kol [1], [2], we develop an extended LDG algorithm by considering a transpose <b>index</b> <b>coding</b> model and cycle detection in the side information graph. Numerical results show that the proposed algorithm considerably outperforms the conventional LDG algorithm {{in terms of the number}} of transmissions. I...|$|R
40|$|The {{distributed}} <b>index</b> <b>coding</b> {{problem is}} studied, whereby multiple messages are stored at different servers to be broadcast to receivers with side information. First, the existing composite coding scheme is enhanced for the centralized (single-server) <b>index</b> <b>coding</b> problem, {{which is then}} merged with fractional partitioning of servers to yield a new coding scheme for distributed <b>index</b> <b>coding.</b> New outer bounds on the capacity region are also established. For 213 out of 218 non-isomorphic distributed <b>index</b> <b>coding</b> problems with four messages the achievable sum-rate of the proposed distributed composite coding scheme matches the outer bound, thus establishing the sum-capacity for these problems...|$|R
40|$|This paper {{proposes a}} novel {{achievable}} scheme for the index problem and applies {{it to the}} caching problem. <b>Index</b> <b>coding</b> and caching are noiseless broadcast channel problems where receivers have message side information. In the <b>index</b> <b>coding</b> problem the side information sets are fixed, while in the caching problem the side information sets correspond the cache contents, which are {{under the control of}} the system designer. The proposed <b>index</b> <b>coding</b> scheme, based on distributed source coding and non-unique decoding,is shown to strictly enlarge the rate region achievable by composite <b>coding.</b> The novel <b>index</b> <b>coding</b> scheme applied to the caching problem is then shown to match an outer bound (previously proposed by the authors and also based on known results for the <b>index</b> <b>coding</b> problem) under the assumption of uncoded cache placement/prefetching. Comment: ITA 201...|$|R
40|$|An <b>index</b> <b>coding</b> problem {{arises when}} there is a single source with a number of {{messages}} and multiple receivers each wanting a subset of messages and knowing a different set of messages a priori. The noiseless <b>Index</b> <b>Coding</b> Problem is to identify the minimum number of transmissions (optimal length) to be made by the source through noiseless channels so that all receivers can decode their wanted messages using the transmitted symbols and their respective prior information. Recently, it is shown that different optimal length codes perform differently in a noisy channel. Towards identifying the best optimal length <b>index</b> <b>code</b> one needs to know the number of optimal length <b>index</b> <b>codes.</b> In this paper we present results on the number of optimal length <b>index</b> <b>codes</b> making use of the representation of an <b>index</b> <b>coding</b> problem by an equivalent network code. Our formulation results in matrices of smaller sizes compared to the approach of Kotter and Medard. Our formulation leads to a lower bound on the minimum number of optimal length codes possible for all unicast <b>index</b> <b>coding</b> problems which is met with equality for several special cases of the unicast <b>index</b> <b>coding</b> problem. A method to identify the optimal length codes which lead to minimum-maximum probability of error is also presented. Comment: Part of the content appears in Proceedings of IEEE International Symposium on Information Theory, (ISIT 2015), Hong Kong, 14 - 19 June 2015, pp. 1044 - 104...|$|R
40|$|An <b>index</b> <b>coding</b> (IC) problem {{consisting}} of a server and multiple receivers with different side-information and demand sets can be equivalently represented using a fitting matrix. A scalar linear <b>index</b> <b>code</b> to a given IC problem is a matrix representing the transmitted linear combinations of the message symbols. The length of an <b>index</b> <b>code</b> is then the number of transmissions (or equivalently, the number of rows in the <b>index</b> <b>code).</b> An IC problem I_ext is called an extension of another IC problem I if the fitting matrix of I is a submatrix of the fitting matrix of I_ext. We first present a straightforward m-order extension I_ext of an IC problem I for which an <b>index</b> <b>code</b> is obtained by concatenating m copies of an <b>index</b> <b>code</b> of I. The length of the codes {{is the same for}} both I and I_ext, and if the <b>index</b> <b>code</b> for I has optimal length then so does the extended code for I_ext. More generally, an extended IC problem of I having the same optimal length as I {{is said to be a}} rank-invariant extension of I. We then focus on 2 -order rank-invariant extensions of I, and present constructions of such extensions based on involutory permutation matrices...|$|R
40|$|The <b>index</b> <b>coding</b> {{problem is}} studied from an {{interference}} alignment perspective providing new results {{as well as}} new insights into, and generalizations of, previously known results. An equivalence is established between the capacity of multiple unicast <b>index</b> <b>coding</b> (where each message is desired by exactly one receiver), and groupcast <b>index</b> <b>coding</b> (where a message can be desired by multiple receivers), which settles the heretofore open question of insufficiency of linear codes for the multiple unicast <b>index</b> <b>coding</b> problem by equivalence with groupcast settings, where this question has previously been answered. Necessary and sufficient conditions for the achievability of rate half per message in the <b>index</b> <b>coding</b> problem are shown to be a natural consequence of interference alignment constraints, and generalizations to feasibility of rate 1 /(L+ 1) per message when each destination desires at least L messages, are similarly obtained. Finally, capacity optimal solutions are presented to a series of symmetric <b>index</b> <b>coding</b> problems inspired by the local connectivity and local interference characteristics of wireless networks. The solutions are based on vector linear coding. © 1963 - 2012 IEEE...|$|R
40|$|Abstract—A {{problem of}} <b>index</b> <b>coding</b> with side {{information}} was first considered by Birk and Kol in 1998. In this study, a gener-alization of <b>index</b> <b>coding</b> scheme, where transmitted symbols {{are subject to}} errors, is studied. Error-correcting methods for such a scheme, and their parameters, are investigated. In particular, the following question is discussed: given the side information hypergraph of <b>index</b> <b>coding</b> scheme and the maximal number of erroneous symbols, what is the shortest length of a linear <b>index</b> <b>code,</b> such that every receiver is able to recover the required information? This question {{turns out to be}} a generalization of the problem of finding a shortest length error-correcting code with a prescribed error-correcting capability in the classical coding theory. The Singleton bound and two other bounds, referred to as the-bound and the-bound, for the optimal length of a linear error-correcting <b>index</b> <b>code</b> (ECIC) are established. For larg...|$|R
40|$|In {{this paper}} we {{consider}} noisy <b>index</b> <b>coding</b> problem over AWGN channel. We give an algorithm {{to map the}} <b>index</b> <b>coded</b> bits to appropriate sized PSK symbols such that for the given <b>index</b> <b>code,</b> in general, the receiver with large amount of side information will gain in probability of error performance compared to the ones with lesser amount, depending upon the <b>index</b> <b>code</b> used. We call this the PSK side information coding gain. Also, we show that receivers with large amount of side information obtain this coding gain {{in addition to the}} bandwidth gain whereas receivers with lesser amount of side information trade off this coding gain with bandwidth gain. Moreover, in general, the difference between the best and worst performance among the receivers is shown to be proportional to the length of the <b>index</b> <b>code</b> employed. Comment: 11 pages and 12 figures. Few tables have been include...|$|R
40|$|In {{this paper}} we define {{critical}} graphs as minimal graphs that support a given set of {{rates for the}} <b>index</b> <b>coding</b> problem, and study them for both the one-shot and asymptotic setups. For the case of equal rates, we find the critical graph with minimum number of edges for both one-shot and asymptotic cases. For the general case of possibly distinct rates, we show that for one-shot and asymptotic linear <b>index</b> <b>coding,</b> as well as asymptotic non-linear <b>index</b> <b>coding,</b> each critical graph is a union of disjoint strongly connected subgraphs (USCS). On the other hand, we identify a non-USCS critical graph for a one-shot non-linear <b>index</b> <b>coding</b> problem. Next, we identify a few graph structures that are critical. We also generalize some of our results to the groupcast problem. In addition, we show that the capacity region of the <b>index</b> <b>coding</b> is additive for union of disjoint graphs...|$|R
50|$|When {{the target}} returns a Check Condition in {{response}} to a command it is indicating that it has entered a contingent allegiance condition. This means that an error occurred when it attempted to execute a SCSI command. The initiator usually then issues a SCSI Request Sense command in order to obtain a Key <b>Code</b> <b>Qualifier</b> (KCQ) from the target.|$|R
40|$|Abstract—In this paper, <b>index</b> <b>coding</b> {{problems}} {{in which the}} number (m) of receivers is larger than that (n) of data are considered. Unlike {{the case that the}} two numbers are same (n = m), <b>index</b> <b>coding</b> problems with n ≤ m are more general and hard to handle. To circumvent this difficulty, problems with n < m are approached via corresponding problems with n = m. It is shown that in certain cases, the symmetric capacity and <b>code</b> construction for <b>index</b> <b>coding</b> problems with n < m can be obtained from the existing symmetric capacity result and <b>codes</b> for <b>index</b> <b>coding</b> problems with n = m. Such cases include cases with n < m ≤ 5. I...|$|R
