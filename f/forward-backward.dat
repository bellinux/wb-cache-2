3715|0|Public
25|$|The {{degrees of}} freedom in planar motion can be easily {{demonstrated}} using a computer mouse. The {{degrees of freedom}} are: left-right, <b>forward-backward</b> and the rotation about the vertical axis.|$|E
25|$|The Sensor Bar is {{required}} when the Wii Remote is controlling up-down, left-right motion of a cursor or reticle on the TV screen {{to point to}} menu options or objects such as enemies in first-person shooters. Because the Sensor Bar also allows the Wii Remote to calculate {{the distance between the}} Wii Remote and the Sensor Bar, the Wii Remote can also control slow <b>forward-backward</b> motion of an object in a 3-dimensional game. Rapid <b>forward-backward</b> motion, such as punching in a boxing game, is controlled by the acceleration sensors. Using these acceleration sensors (acting as tilt sensors), the Wii Remote can also control rotation of a cursor or other objects.|$|E
25|$|The ball mouse has two freely {{rotating}} rollers. These {{are located}} 90 degrees apart. One roller detects the <b>forward–backward</b> {{motion of the}} mouse and other the left–right motion. Opposite the two rollers is a third one (white, in the photo, at 45 degrees) that is spring-loaded to push the ball against the other two rollers. Each roller is on the same shaft as an encoder wheel that has slotted edges; the slots interrupt infrared light beams to generate electrical pulses that represent wheel movement. Each wheel's disc has a pair of light beams, located so that a given beam becomes interrupted or again starts to pass light freely when the other beam of the pair is about halfway between changes.|$|E
25|$|In {{a typical}} {{rectangular}} listening room, the hard, parallel {{surfaces of the}} walls, floor and ceiling cause primary acoustic resonance nodes {{in each of the}} three dimensions: left-right, up-down and <b>forward-backward.</b> Furthermore, there are more complex resonance modes involving three, four, five and even all six boundary surfaces combining to create standing waves. Low frequencies excite these modes the most, since long wavelengths are not much affected by furniture compositions or placement. The mode spacing is critical, especially in small and medium size rooms like recording studios, home theaters and broadcast studios. The proximity of the loudspeakers to room boundaries affects how strongly the resonances are excited as well as affecting the relative strength at each frequency. The location of the listener is critical, too, as a position near a boundary can have a great effect on the perceived balance of frequencies. This is because standing wave patterns are most easily heard in these locations and at lower frequencies, below the Schroeder frequency– typically around 200–300Hz, depending on room size.|$|E
2500|$|The Inside-Outside {{algorithm}} is an analogue of the <b>Forward-Backward</b> algorithm. It computes the total probability of all derivations {{that are consistent}} with a given sequence, based on some PCFG. [...] This is equivalent to the probability of the PCFG generating the sequence, and is intuitively a measure of how consistent the sequence is with the given grammar. The Inside-Outside {{algorithm is}} used in model parametrization to estimate prior frequencies observed from training sequences in the case of RNAs.|$|E
5000|$|The <b>forward-backward</b> least-squares estimators {{treat the}} [...] {{process as a}} {{regression}} problem and solves that problem using <b>forward-backward</b> method. They are competitive with the Burg estimators.|$|E
50|$|The term <b>forward-backward</b> {{algorithm}} {{is also used}} to refer to any algorithm belonging to the general class of algorithms that operate on sequence models in a <b>forward-backward</b> manner. In this sense, the descriptions in the remainder of this article refer but to one specific instance of this class.|$|E
5000|$|... <b>forward-backward</b> {{greedy search}} and exact methods using {{branch-and-bound}} techniques, ...|$|E
5000|$|... #Subtitle level 3: Proof by Cauchy using <b>forward-backward</b> {{induction}} ...|$|E
5000|$|Interpolation {{functions}} - Flat <b>forward-backward,</b> linear, and cubic spline interpolation.|$|E
50|$|The <b>forward-backward</b> {{algorithm}} is an efficient method for computing the smoothed values for all hidden state variables.|$|E
5000|$|... #Caption: The {{result of}} {{applying}} the both, the Forward Euler method {{as well as}} the <b>Forward-Backward</b> Euler method [...] and [...]|$|E
5000|$|... #Caption: A {{right-handed}} Cartesian coordinate system, {{illustrating the}} x (right-left), y (<b>forward-backward)</b> and z (up-down) axes {{relative to a}} human being.|$|E
50|$|Proximal {{gradient}} methods, {{also called}} <b>forward-backward</b> splitting, are optimization methods useful for minimizing functions with a convex and differentiable component, and a convex potentially non-differentiable component.|$|E
5000|$|... where R is the {{covariance}} matrix, and [...] is the 2D complex-conjugate transpose of the Fourier vector. The computation of {{this equation}} over all frequencies is time-consuming. It is {{seen that the}} <b>forward-backward</b> Capon estimator yields better estimation than the forward-only classical capon approach. The main reason behind this {{is that while the}} <b>forward-backward</b> Capon uses both the forward and backward data vectors to obtain the estimate of the covariance matrix, the forward-only Capon uses only the forward data vectors to estimate the covariance matrix.|$|E
50|$|HMM {{is closely}} related to an earlier work on the optimal {{nonlinear}} filtering problem by Ruslan L. Stratonovich, who was the first to describe the <b>forward-backward</b> procedure.|$|E
5000|$|The <b>forward-backward</b> {{algorithm}} is an [...] inference algorithm for hidden Markov models which computes the posterior marginals of all hidden state variables given {{a sequence of}} observations/emissions , i.e. it computes, for all hidden state variables , the distribution [...] This inference task is usually called smoothing. The algorithm makes use {{of the principle of}} dynamic programming to compute efficiently the values that are required to obtain the posterior marginal distributions in two passes. The first pass goes forward in time while the second goes backward in time; hence the name <b>forward-backward</b> algorithm.|$|E
50|$|The {{degrees of}} freedom in planar motion can be easily {{demonstrated}} using a computer mouse. The {{degrees of freedom}} are: left-right, <b>forward-backward</b> and the rotation about the vertical axis.|$|E
5000|$|... 2. <b>Forward-{{backward}}</b> algorithmThe {{forward backward}} algorithm helped as an algorithm for tracking {{the states in}} the markov chain. And this also was used the algorithm of GDL like generality ...|$|E
50|$|The {{following}} description {{will use}} matrices of probability values rather than probability distributions, although {{in general the}} <b>forward-backward</b> algorithm {{can be applied to}} continuous as well as discrete probability models.|$|E
5000|$|A <b>forward-backward</b> {{asymmetry}} {{is defined}} as AFB=(NF-NB)/(NF+NB), where NF {{is the number of}} events in which some particular final-state particle is moving [...] "forward" [...] with respect to some chosen direction (e.g., a final-state electron moving {{in the same direction as}} the initial-state electron beam in electron-positron collisions), while NB is the number of events with the final-state particle moving [...] "backward". <b>Forward-backward</b> asymmetries were used by the LEP experiments to measure the difference in the interaction strength of the Z boson between left-handed and right-handed fermions, which provides a precision measurement of the weak mixing angle.|$|E
50|$|BCJR equalizer: {{uses the}} BCJR {{algorithm}} (also called the <b>Forward-backward</b> algorithm) {{to find the}} maximum a posteriori (MAP) solution. Its goal is to minimize {{the probability that a}} given bit was incorrectly estimated.|$|E
50|$|The <b>forward-backward</b> {{algorithm}} {{can be used}} to {{find the}} most likely state for any point in time. It cannot, however, be used to find the most likely sequence of states (see Viterbi algorithm).|$|E
5000|$|If {{the graph}} is a chain or a tree, message passing {{algorithms}} yield exact solutions. The algorithms {{used in these}} cases are analogous to the <b>forward-backward</b> and Viterbi algorithm for the case of HMMs.|$|E
5000|$|... where [...] is the {{projection}} onto the set C. Convergence is guaranteed when [...] This is again {{a special case}} of projected gradient descent (which is a special case of the <b>forward-backward</b> algorithm) as discussed in.|$|E
50|$|The Sensor Bar is {{required}} when the Wii Remote is controlling up-down, left-right motion of a cursor or reticle on the TV screen {{to point to}} menu options or objects such as enemies in first-person shooters. Because the Sensor Bar also allows the Wii Remote to calculate {{the distance between the}} Wii Remote and the Sensor Bar, the Wii Remote can also control slow <b>forward-backward</b> motion of an object in a 3-dimensional game. Rapid <b>forward-backward</b> motion, such as punching in a boxing game, is controlled by the acceleration sensors. Using these acceleration sensors (acting as tilt sensors), the Wii Remote can also control rotation of a cursor or other objects.|$|E
50|$|The {{production}} of Z bosons through the Drell-Yan process affords {{the opportunity to}} study the couplings of the Z boson to quarks. The main observable is the <b>forward-backward</b> asymmetry in the angular distribution of the two leptons in their center-of-mass frame.|$|E
50|$|In {{electrical}} engineering, computer science, statistical computing and bioinformatics, the Baum-Welch {{algorithm is}} used to find the unknown parameters of a hidden Markov model (HMM). It makes use of the <b>forward-backward</b> algorithm and is named for Leonard E. Baum and Lloyd R. Welch.|$|E
50|$|These {{are also}} called happy joints. Oval shaped condyle of one bone fits into {{elliptical}} cavity of other bone. These joints allow biaxial movements i.e. <b>forward-backward</b> and {{side to side}} but not rotation. Radiocarpal joint and Metacarpo-phalangeal joint are examples of condyloid joint.|$|E
50|$|Blumrich {{proposed}} a wheel that {{is capable of}} rotating not only in the <b>forward-backward</b> direction, but also sideways, based on his interpretation of the description in Ezekiel, and patented it. The wheel is now known as Omni wheel, and it is used in special applications.|$|E
5000|$|An {{enhancement}} to {{the general}} <b>forward-backward</b> algorithm, called the Island algorithm, trades smaller memory usage for longer running time, taking [...] time and [...] memory. On a computer with an unlimited number of processors, this {{can be reduced to}} [...] total time, while still taking only [...] memory.|$|E
50|$|Gradient descent can be {{extended}} to handle constraints by includinga projection onto the set of constraints. This method isonly feasible when the projection is efficiently computable on a computer. Under suitable assumptions,this method converges. This method is a specific case of the <b>forward-backward</b> algorithm for monotone inclusions (which includes convex programming and variational inequalities).|$|E
50|$|A blocked Gibbs sampler groups {{two or more}} {{variables}} {{together and}} samples from their joint distribution conditioned on all other variables, rather than sampling from each one individually. For example, in a hidden Markov model, a blocked Gibbs sampler might sample from all the latent variables making up the Markov chain in one go, using the <b>forward-backward</b> algorithm.|$|E
5000|$|Measuring the <b>forward-backward</b> {{asymmetry}} of the muon pair in the flavour changing {{neutral current}} Bd → K* μ+ μ− decay. Such a flavour changing neutral current cannot occur at tree-level in the Standard Model of Particle Physics, and only occurs through box and loop Feynman diagrams; {{properties of the}} decay can be strongly modified by new Physics.|$|E
5000|$|Vogel et. al {{developed}} an approach featuring lexical translation probabilities and relative alignment by mapping {{the problem to}} a Hidden Markov model. The states and observations represent the source and target words respectively. The transition probabilities model the alignment probabilities. In training the translation and alignment probabilities {{can be obtained from}} [...] and [...] in the <b>Forward-backward</b> algorithm.|$|E
50|$|Another {{advantage}} of MEMMs versus HMMs and conditional random fields (CRFs) is that training can be considerably more efficient. In HMMs and CRFs, {{one needs to}} use some version of the <b>forward-backward</b> algorithm as an inner loop in training. However, in MEMMs, estimating {{the parameters of the}} maximum-entropy distributions used for the transition probabilities can be done for each transition distribution in isolation.|$|E
