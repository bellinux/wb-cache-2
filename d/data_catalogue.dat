102|732|Public
5000|$|... #Caption: Trans Canada Trail. B.C. section. Data sourced {{from the}} Government of British Columbia <b>data</b> <b>catalogue.</b>|$|E
50|$|Environment Agency {{provides}} Open {{data are}} through its Spatial <b>Data</b> <b>Catalogue.</b> Lidar and other survey datasets {{are also available}} through its Survey Open Data web portal.|$|E
50|$|Its {{metadata}} catalogue {{is built}} {{on the basis of}} international standards such as Dublin Core, the <b>data</b> <b>catalogue</b> vocabulary DCAT and the asset description metadata schema ADMS.|$|E
40|$|International audienceOpening {{public sector}} {{information}} has recently become {{a trend in}} many countries around the world. Online government <b>data</b> <b>catalogues</b> with national, regional or local scope act as one-stop data portals providing descriptions of available government datasets. These catalogues though remain isolated. Potential benefits from federating geographically overlapping or thematically complementary catalogues are not realized. We propose an RDF Schema vocabulary as an interchange format among <b>data</b> <b>catalogues</b> and {{as a way of}} bringing them into the Web of Linked Data, where they can enjoy interoperability among themselves and with other deployed datasets. The vocabulary's design was informed by a survey of seven <b>data</b> <b>catalogues</b> from five different countries, and has been verified by unifying four <b>data</b> <b>catalogues</b> to allow cross-catalogue queries and browsing...|$|R
50|$|The European Public Sector Information (PSI) Platform {{maintains}} {{a list of}} PSI <b>data</b> <b>catalogues</b> provided by governments and providing direct access to data.|$|R
50|$|OpenDataMonitor, which {{provides}} users with an online monitoring and analytics platform for open data in Europe. It will provide insights into open data availability and publishing platforms by developing and delivering an analysis and visualisation platform that harvests and analyses multilingual metadata from local, {{regional and national}} <b>data</b> <b>catalogues.</b>|$|R
5000|$|DBK (Data Catalogue/ Datenbestandskatalog) - Approximately 5,000 {{studies can}} be searched and ordered via the <b>Data</b> <b>Catalogue</b> /Datenbestandskatalog. These are {{available}} for usage in secondary analyses or as reference for own surveys.|$|E
50|$|There {{are many}} means of {{aggregating}} {{information to be}} displayed in a SharePoint Dashboard. Some common methods include Application Programming Interface (API), Business Connectivity Service/Business <b>Data</b> <b>Catalogue,</b> Microsoft Excel, and Open Database Connectivity (ODBC).|$|E
50|$|As of March 2016, data {{presented}} at the City of Toronto's open <b>data</b> <b>catalogue,</b> includes over 200 data sets such as Festivals and Events, Licensed Child Care Centers, Priority Investment Neighbourhoods, Wellbeing Neighbourhood index and transportation data.|$|E
30|$|Arrival {{times for}} both S and SKS phases and the event hypocentres {{have been taken}} from the {{reprocessing}} of data reported to international agencies. Each event has been relocated, including depth phase information, and later phases re-associated using the improved locations to provide a set of travel times whose variance is significantly reduced compared with the original <b>data</b> <b>catalogues.</b>|$|R
40|$|The {{ability to}} extract {{knowledge}} from very large <b>data</b> <b>catalogues</b> resulting from sky surveys or from deep wide elds, observed at various wavelength ranges, {{is a critical}} task {{in the context of}} the future Virtual Observatories. Based on CDS experience, we will try to draw a few lessons for strategies to be adopted when mining very large data sets...|$|R
50|$|The Defense Manpower Data Center (DMDC) serves {{under the}} Office of the Secretary of Defense to collate {{personnel}}, manpower, training, financial, {{and other data}} for the Department of Defense. This <b>data</b> <b>catalogues</b> the history of personnel {{in the military and}} their family for purposes of healthcare, retirement funding and other administrative needs. It has offices in Seaside, California and Alexandria, Virginia.|$|R
50|$|The portal {{is built}} using open source {{solutions}} {{such as the}} Drupal content management system and CKAN, the <b>data</b> <b>catalogue</b> software developed by the Open Knowledge Foundation. It uses Virtuoso as an RDF database and has a SPARQL endpoint.|$|E
50|$|POLPAN {{data and}} {{documentation}} from the waves 1988, 1993, 1998, and 2003 {{are available for}} download in various formats from the <b>data</b> <b>catalogue</b> at GESIS - Leibniz Institute for the Social Sciences and from the Polish Social Data Archive. The latter archive also contains 2008 POLPAN wave data and documentation.|$|E
50|$|The Comprehensive Knowledge Archive Network (CKAN) is {{a web-based}} open source {{management}} {{system for the}} storage and distribution of open data. Being initially inspired by the package management capabilities of Linux, CKAN has developed into a powerful <b>data</b> <b>catalogue</b> system that is mainly used by public institutions seeking to share their data with the general public.|$|E
50|$|Many of {{the future}} {{challenges}} of pathogenomics begin with handling and {{making sense of the}} large influx of data that now is available to the research community. Mining the data for useful information proves to be applicable to many facets of epidemiology. bioinformatics approaches are providing much of the power for rapidly mining, organising, analyzing, visualizing and annotating the <b>data</b> <b>catalogued</b> in databases.|$|R
40|$|ATLAS Distributed Data Management (DDM) {{service is}} {{developed}} for data transfer between ATLAS sites and for <b>data</b> <b>cataloguing.</b> The <b>Data</b> Management Software (SW) {{is based on}} DQ 2 and end-users tools (aka dq 2 _get package). In this paper we {{address the issue of}} DDM day-by-day operation, DDM operations team organization, roles and responsibilities of Tier- 1 s and Tier- 2 s DDM coordinators...|$|R
40|$|Tectonically regionalized {{variations}} in {{the temperature of the}} upper 400 km of the Earth's mantle are estimated from analysis of global seismic travel-time <b>data</b> <b>catalogued</b> by the International Seismological Centre (ISC). Seismic parameter profiles are determined from estimates of P and S velocities obtained by tau inversion, and summary phase diagrams for the olivine and pyroxene- garnet subsystems are constructed in conjunction with a thermodynamic potential formulation...|$|R
50|$|The Archive {{hosts and}} manages the UK Data Service, which {{provides}} free research access to over 6,000 social science data sets, including quantitative data and qualitative {{data from a}} wide range of disciplines. Access to the <b>data</b> <b>catalogue,</b> including online documentation such as questionnaires, is completely open. The Archive removes data access barriers wherever possible, however registration is required to download data where there are disclosure risks.|$|E
50|$|Among {{the best}} known of more than 400 {{e-government}} applications are FinanzOnline, E-Finanz, federal budget accounting and personnel management, Electronic customs application service (eCustoms), Business Service Portal (usp.gv.at), Commercial and Land Register, Austrian Federal electronic filing system (ELAK), administrative procedures information platform for citizens (HELP.gv.at), Austrian open <b>data</b> <b>catalogue</b> (data.gv.at), student union elections (E-Voting), Biometric passport, Austrian Health Portal (gesundheit.gv.at), Austrian personalised access portal (portal.at) and Electronic health filing system (ELGA).|$|E
50|$|Access to the <b>data</b> <b>catalogue,</b> {{documentation}} and guides are available free of charge. Registration {{is required to}} download data, and its use is subject to licensing requirements specified by data owners. Most data are available under a standard End User Licence, but data are available along a spectrum ranging from 'open' to 'secure'. The latter requires specific approval and training to ensure the appropriate level of security for highly detailed and sensitive data.|$|E
5000|$|CKAN's {{codebase}} {{is maintained}} by Open Knowledge International. The system is used {{both as a}} public platform on Datahub and in various government <b>data</b> <b>catalogues,</b> such as the UK's data.gov.uk, the Dutch National Data Register, the United States government's Data.gov and the Australian government's [...] "Gov 2.0". The state government of South Australia also makes government data freely {{available to the public}} on the CKAN platform.|$|R
40|$|RefDB is the CMS Monte Carlo Reference Database. It is {{used for}} {{recording}} and managing all details of physics simulation, reconstruction and analysis requests, for coordinating task assignments to world-wide distributed Regional Centers, Grid-enabled or not, and trace their progress rate. RefDB is also the central database that the workflow-planner contacts {{in order to get}} task instructions. It is automatically and asynchronously updated with book-keeping run summaries. Finally it is the end-user interface to <b>data</b> <b>catalogues.</b> 1...|$|R
40|$|This {{article is}} about the GEOeBIZ project which wants to improve {{business}} opportunities in geomarketing for small and medium enterprises. The project's central hypothesis is that spatial data infrastructures will move from <b>data</b> <b>catalogues</b> to federated platforms {{for the development of}} low cost and low risk applications. To complement the data-retrieval services of the Open GeoSpatial Consortium the project will design, implement and apply both, visual analysis services for geomarketing and ebusiness services for commercial exploitation. The article proposes a framework and services for visual analysis...|$|R
5000|$|The city's {{planning}} department has, {{over the}} past five years, steadilyproduced enough municipal data to warrant a Time magazine article on open-government. Nanaimo has been dubbed 'the capital of Google Earth'. Working directly with Google, the city fed it a wealth of information about its buildings, property lines, utilities and streets. The result is earth.nanaimo.ca, a wealth of city data viewed through the Google Earth 3D mapping program. Their Open <b>Data</b> <b>Catalogue</b> is available at http://data.nanaimo.ca/ ...|$|E
5000|$|CSES {{data are}} {{available}} publicly and are free of charge. Data releases are non-proprietary - in other words the data are {{made available to the}} public without preferential or advance access to anyone. Data is available in multiple formats including for common statistical packages like STATA, SPSS, SAS and R. The data can be downloaded from the CSES website [...] as well as via the GESIS <b>data</b> <b>catalogue.</b> The GESIS online analysis tool ZACAT can furthermore be used to browse and explore the dataset.|$|E
50|$|All {{results of}} WISDOM Phase I and Phase II are stored and {{distributed}} to WISDOM partners using the WISDOM Information System, which comprises {{data and information}} from the fields of hydrology, sociology, information technology, and earth observation. Data models and concepts for storing such kind of data within spatial databases have been developed and implemented in the WISDOM Prototype. Different aspects of data are represented in these models. Ontologies describing spatial-, thematic-, and temporal reference aspects have been implemented allowing a semantic enrichment of the datasets and with that enable fast data retrieval by meaningful search attributes as e.g. finding all data in a specific administrative unit belonging to a specific theme. The models represent geometrical aspects of data and allow for efficient management of either raster- or vector data. Additionally, nonspatial data like sensor measurements or census data {{are related to the}} spatial reference objects. The data model further describes styling aspects of spatial datasets using Styled Layer Descriptions as also Web Mapping Service (WMS) layer specifications. This allows for a dynamic retrieval of rendered maps of requested spatial datasets from the data management system. Furthermore, meta data descriptions of spatial data are modelled based on the ISO19115 standard. These are then used in a meta <b>data</b> <b>catalogue</b> system as also in the warehouse of the WISDOM Information System.|$|E
40|$|The {{general purpose}} of the present paper is to {{summarize}} the state-of-the-art of historical earthquake knowledge and research in the Iberian Peninsula, giving an account of the main references, the historical developments and the present situation of earthquake catalogues. The most representative historical works for compiling earthquake <b>data</b> (<b>catalogues)</b> up to 1985 are referred together with those of more recent investigations carried out in Spain and Portugal for the period 1985 - 2003. Existing databases on historical seismicity are presented, mentioning the most important achievements in relation to quality of information...|$|R
50|$|In {{the last}} 30 years, {{it has been}} {{possible}} to routinely calculate focal mechanisms from teleseismic <b>data.</b> <b>Catalogues</b> of events with calculated focal mechanisms are now available online, such as the searchable catalogue from the NEIC. As focal mechanisms give two potential active fault plane orientations, other evidence is required to interpret the origin of an individual event. Although only available for a restricted time period, in areas of moderate to intense seismicity there is probably sufficient data to characterise the type of seismicity in an area, if not all the active structures.|$|R
5000|$|Original <b>catalogue</b> <b>data,</b> 1953-1985, 109293 objects (alternative {{reference}} is Mermilliod, 1987) ...|$|R
5000|$|Vril Dox, upon {{losing control}} of his L.E.G.I.O.N. robots is forced to flee and is {{followed}} to Earth {{by a team of}} bounty hunters (one of which turns out to be Amon Hakk, an ex-member of Vril's original team). He finds Supergirl and has her heat vision encrypt a file onto a cd. Brainiac Five of the Legion of Super-Heroes had contacted his ancestor and told him to do so. Upon uploading the disc, Brainiac Five contacts Vril directly and offers him the entire <b>data</b> <b>catalogue</b> on the Legion of Super-Heroes in order for Vril to set up a new team and to guarantee the survival of the Brainiac lineage into the 31st century. Instead of using the heroes, Vril Dox decides to use the data of their villains. The Omega Men are also seen fleeing from attacking L.E.G.I.O.N. robots. Vril manipulates Hakk into shooting the other bounty hunter. He seizes a device that was used to control Tribulus (a giant simian beast strongly resembling Validus of the Fatal Five) and implants the device into his own head. Vril gains control over Tribulus and they take the bounty hunter ship as their new headquarters. [...] Vril finds the next member of the team, Wildstar, old and sick and convinces her that he can heal her. After luring her onto his ship he shoots her with an energy gun, leaving her in an energy form and trapped in a containment suit. Wildstar contemplates killing Vril, but instead helps him escape her home planet {{and the two of them}} hunt down Strata and Bounder. Strata tries to convince Wildstar that she will be turned on soon enough if she stays with someone like Vril Dox. The Omega Men discover a secret plot involving Starro.|$|E
40|$|In Germany the {{environmental}} <b>data</b> <b>catalogue</b> {{was designed as}} a meta information system for retrieving environ-mental information held by public authorities. It is providing its user with information about who is having which information at what location. In this paper we discuss some issues concerning the implementation of the environ-mental <b>data</b> <b>catalogue</b> at public authorities and the management of data quality. 1...|$|E
40|$|The Arctic Permafrost Geospatial Centre (APGC) is {{designed}} as a web interface showcasing high level projects with permafrost focus and providing an entry point for their geospatial product dissemination needs. At the core of APGC we will establish two services for data discovery: an Open Access <b>Data</b> <b>Catalogue</b> and an Open Access WebGIS Application (Fig. 1). The APGC <b>Data</b> <b>Catalogue</b> will allow searching for project-specific geospatial data by tags, keywords, data type and format, licence type, or geographically, provides a data preview figure, localizes the dataset on a zoom- and pan-capable basemap, displays a variety of metadata, and links to a permanent DOI-based archival link at the PANGAEA data repository (Figs. 2 and 3). The APGC <b>Data</b> <b>Catalogue</b> {{will be based on}} the open source CKAN <b>data</b> <b>catalogue</b> architecture, allowing geospatial data categorization associated with defined projects based on metadata standards. The <b>Data</b> <b>Catalogue</b> will contain all final products of projects that will be featured here, for example the ERC PETA-CARB project and the IPA Action Group on Yedoma ice-rich permafrost. The WebGIS Application will rely on OGC-standardized Web Mapping Services (WMS) and Web Feature Service (WFS) technologies for data display and visualization. The WMS/WFS services are provided through the <b>Data</b> <b>Catalogue.</b> We are further evaluating the possibility to load external WMS/WFS services in the WebGIS Application. Legends will provide information on data attributes, and pop-up menus will provide information on metadata and a link to the archive location for a dataset. The WebGIS Application will provide a platform independent and visually interactive platform for displaying both raster and vector geospatial data from the project. Independently, we will provide an Access-Restricted FTP Service at AWI which will be available to project team members and defined users for rapid and easy sharing of validation data and for testing new versions of project datasets. ...|$|E
5000|$|Z39.83: NISO Circulation Interchange Protocol (NCIP) for library <b>catalogue</b> <b>data</b> {{exchange}} ...|$|R
40|$|Geospatial {{information}} systems provide a unique {{frame of reference}} to bring together a large and diverse set of data {{from a variety of}} sources. However, automating this process remains a challenge since: 1) data (particularly from sensors) is error prone and ambiguous, 2) analysis and visualization tools typically expect clean (or exact) data, and 3) it is difficult to describe how different data types and modalities relate to each other. In this paper we describe a data integration approach that can help address some of these challenges. Specifically we propose a light weight ontology for an Information Space Model (ISM). The ISM is designed to support functionality that lies between <b>data</b> <b>catalogues</b> and domain ontologies. Similar to <b>data</b> <b>catalogues,</b> the ISM provides metadata for data discovery across multiple, heterogeneous (often legacy) data sources e. g. maps servers, satellite images, social networks, geospatial blogs. Similar to domain ontologies, the ISM describes the functional relationship between these systems with respect to entities relevant to an application e. g. venues, actors and activities. We suggest a minimal set of ISM objects, and attributes for describing data sources and sensors relevant to data integration. We present a number of statistical relational learning techniques to represent and leverage the combination of deterministic and probabilistic dependencies found within the ISM. We demonstrate how the ISM provides a flexible language for data integration where unknown or ambiguous relationships can be mitigated...|$|R
40|$|Brief {{presentation}} {{about the}} J-PLUS EDR data access web portal ([URL] where the different services available to retrieve images and <b>catalogues</b> <b>data</b> have been presented. J-PLUS Early Data Release (EDR) archive includes {{two types of}} data: images and dual and single <b>catalogue</b> <b>data</b> which include parameters measured from images. J-PLUS web portal offers <b>catalogue</b> <b>data</b> and images through several different online data access tools or services each suited to a particular need. The different services offered are: 	Coverage map 	Sky navigator 	Object visualization 	Image search 	Cone search 	Object list search 	Virtual observatory services: 	 		Simple Cone Search 		Simple Image Access Protocol 		Simple Spectral Access Protocol 		Table Access Protoco...|$|R
