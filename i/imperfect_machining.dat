0|20|Public
40|$|Extensive Tracking Studies {{have been}} {{performed}} for a realistic model of the LHC at the injection energy of 450 GeV. The underlying model contains all static multipole magnet errors and linear imperfections. The <b>imperfect</b> <b>machines</b> are corrected using control room techniques. The paper gives estimates for the dynamic aperture for 60 different realizations of errors for the versions 4. To get a better picture of the dynamics the emittance ratios are varied to sample a large fraction of the phase space. Phase space averaged apertures are compared with averages over different <b>imperfect</b> <b>machines</b> for selected emittance ratios. Lastly it is checked if the reduced systematic a 4 and b 4 multipolar components of the main bending magnets remain an important aperture limitation...|$|R
40|$|A new optics with phase {{advances}} m x a 131 and m y a 90 in the arc cells {{has been}} proposed for LEP. This note summarises the main results from the optics evaluation procedure that is now routinely applied to new LEP optics. This includes {{the study of the}} orbits, optics and dynamic apertures of an ensemble of <b>imperfect</b> <b>machines</b> with corrections similar to those applied in operation. It provides predictions of performance and results of measurements that can be done when the optics is commissioned. The results show that the dynamic aperture of this optics is much smaller than necessary for high-energy operation of LEP. A modification of the sextupole configuration to reduce the detuning with amplitude does not help. Introduction To evaluate the potential performance of a new optics for LEP, it is necessary to perform calculations of orbits, optics, beam parameters and dynamic apertures on an ensemble of <b>imperfect</b> <b>machines.</b> Over the last few years, a standard procedure has evolved for [...] ...|$|R
40|$|A new physics optics with phase {{advances}} P x 102 # and P y 90 # in the arc cells {{was recently}} tested in LEP. This note summarises the main {{results from the}} optics evaluation procedure that is now routinely applied to new LEP optics. This includes {{the study of the}} orbits, optics and dynamic apertures of an ensemble of <b>imperfect</b> <b>machines</b> with corrections similar to those applied in Introduction To evaluate the potential performance of a new optics for LEP, it is necessary to perform calculations of orbits, optics, beam parameters and dynamic apertures on an ensemble of <b>imperfect</b> <b>machines.</b> Over the last few years, a standard procedure has evolved for this purpose. For the present note, it has been applied to a "squeezed" (102, 90) optics at 91. 5 GeV. This optics is very similar to the optics that was subsequently tested in operation (the differences are discussed in Section 1. 2). The procedure followed is briefly outlined in the following subsection. Full technical details of the methods an [...] ...|$|R
40|$|In 1998 LEP will be run {{using an}} optics with phase {{advances}} P x 102 # and P y 90 # in the arc cells. This note summarises the main {{results from the}} optics evaluation procedure that is now routinely applied to new LEP optics. This includes {{the study of the}} orbits, optics and dynamic apertures of an ensemble of <b>imperfect</b> <b>machines</b> with corrections similar to those applied in operation. It provides predictions of performance and results of measurements that can be done when the optics is commissioned. A single SF sextupole family is used in order to provide a baseline for comparison of the effects of re-cabling the sextupoles. This will be treated in a subsequent note. 1 Introduction To evaluate the potential performance of a new optics for LEP, it is necessary to perform calculations of orbits, optics, beam parameters and dynamic apertures on an ensemble of <b>imperfect</b> <b>machines.</b> Over the last few years, a standard procedure has evolved for this purpose. For the present note, it has been ap [...] ...|$|R
25|$|Margaret Cavendish, a seventeenth-century aristocrat, {{took part}} {{in some of the}} most {{important}} scientific debates of that time. She was however, not inducted into the English Royal Society, although she was once allowed to attend a meeting. She wrote a number of works on scientific matters, including Observations upon Experimental Philosophy (1666) and Grounds of Natural Philosophy. In these works she was especially critical of the growing belief that humans, through science, were the masters of nature. The 1666 work attempted to heighten female interest in science. The observations provided a critique of the experimental science of Bacon and criticized microscopes as <b>imperfect</b> <b>machines.</b>|$|R
40|$|A new optics with phase {{advances}} of 131 Â° and 90 Â° in the arc cells hasbeen proposed for LEP. This note summarises the main results from theoptics evaluation procedure {{that is now}} routinely applied to new LEPoptics. This includes {{the study of the}} orbits, optics and dynamicapertures of an ensemble of <b>imperfect</b> <b>machines</b> with corrections similarto those applied in operation. It provides predictions of performanceand results of measurements that can be done when the optics iscommissioned. The results show that the dynamic aperture of this optics is muchsmaller than necessary for high-energy operation of LEP. A modificationof the sextupole configuration to reduce the detuning with amplitudedoes not help...|$|R
50|$|Margaret Cavendish, a seventeenth-century aristocrat, {{took part}} {{in some of the}} most {{important}} scientific debates of that time. She was however, not inducted into the English Royal Society, although she was once allowed to attend a meeting. She wrote a number of works on scientific matters, including Observations upon Experimental Philosophy (1666) and Grounds of Natural Philosophy. In these works she was especially critical of the growing belief that humans, through science, were the masters of nature. The 1666 work attempted to heighten female interest in science. The observations provided a critique of the experimental science of Bacon and criticized microscopes as <b>imperfect</b> <b>machines.</b>|$|R
40|$|In 1998 LEP {{will run}} using an optics with phase {{advances}} u_x= 102 o and u_y= 90 o in the arc cells. This note summarises the main {{results from the}} optics evaluation procedure that is now routinely applied to new LEP optics. This includes {{the study of the}} orbits, optics and dynamic aperture of an ensemble of <b>imperfect</b> <b>machines</b> with corrections similar to those applied in operation. It provides predictio ns of performance and results of measurements that can be done when the optics is ommissioned. A single SF sextupole family is used in order to provide a baseline for comparison of the effects or re-c abling the sextupoles. This will be treated in a subsequent note...|$|R
40|$|Over the two-decade {{lifetime}} of the LEP project, techniques {{for evaluating the}} quality of optical configurations have evolved considerably to exploit the growth in computer power and improved modelling of single-particle dynamics. These developments have culminated in a highly automated Monte-Carlo evaluation process whose stages include the generation of an ensemble of <b>imperfect</b> <b>machines,</b> simulation of the operational correction procedures, correlation studies of the optical functions and parameters of (both) beams, 4 -dimensional dynamic aperture scans and tracking with quantum fluctuations to determine the beam core distribution. We outline the process, with examples, and explain why each step is necessary to realistically capture essential physics affecting performance. The mechanisms determining the vertical emittance, radial beam distribution and dynamic aperture are especially important. As a storage ring in which an unusual variety of optics have been tested, LEP provides a valuable test case for the predictive power of the methodology...|$|R
40|$|International audienceWe {{consider}} a project investment problem, where {{a set of}} projects and an overall budget are given. For each project, a piecewise linear profit function is known which describes the profit obtained if a specific amount is invested into this project. The objective {{is to determine the}} amount invested into each project such that the overall budget is not exceeded and the total profit is maximized. For this problem, a graphical algorithm (GrA) is presented which is based on the same Bellman equations as the best known dynamic programming algorithm (DPA) but the GrA has several advantages in comparison with the DPA. Based on this GrA, a fully-polynomial time approximation scheme is proposed having the best known running time. The idea of the GrA presented {{can also be used to}} solve some similar scheduling or lot-sizing problems in a more effective way, e. g., the related problem of finding lot-sizes and sequencing several products on a single <b>imperfect</b> <b>machine...</b>|$|R
40|$|LEP's optical {{configurations}} {{are subjected}} to a lengthy evaluation procedure which tries to model the <b>imperfect</b> <b>machine</b> with the conditions and corrections applied in operation. The physical effects distinguishing the candidate optics for operation at the highest energies will be very briefly summarised. Attention {{will be given to}} the origins of the vertical beam size as revealed by quantum tracking. 1 INTRODUCTION In comparison with other e + e storage rings, the number of optical configurations considered for LEP {{in recent years has been}} extraordinary. Most machines stick with minor variations of a single optics for the whole of their operating life. The diversity of the LEP optics reflects the wide range of operating conditions (beam energies in particular) and the lengths we have gone to in order to maximise performance in each of them. Ideally, the process of choosing between various options should culminate in thorough experimental tests of theoretical predictions. These sho [...] ...|$|R
40|$|We {{present a}} {{detection}} scheme which using imperfect detectors, and <b>imperfect</b> quantum copying <b>machines</b> (which entangle the copies), {{allows one to}} extract more information from an incoming signal, than with the imperfect detectors alone. Comment: 4 pages, 2 figures, REVTeX, {{to be published in}} Phys. Rev. ...|$|R
40|$|We {{identify}} {{problems with}} the Penn Treebank that render it <b>imperfect</b> for syntaxbased <b>machine</b> translation and propose methods of relabeling the syntax trees to improve translation quality. We develop a system incorporating a handful of relabeling strategies that yields a statistically significant improvement of 2. 3 BLEU points over a baseline syntax-based system...|$|R
6000|$|All matter {{likely to}} be found {{beneath the surface of the}} earth in that part of the country had been experimented upon by Clewe, and nothing had {{resisted}} the penetrating and illuminating influence of his ray--well called Artesian ray, for it was intended to bore into the bowels of the earth. After making many minor trials of the force and powers of his light, Roland Clewe had undertaken the construction of a massive apparatus, by which he believed a ray could be generated which, little by little, perhaps foot by foot, would penetrate into the earth and light up everything between the farthest point it had attained and the lenses of his machine. That is to say, he hoped to produce a long hole of light about three feet in diameter and as deep as it was possible to make it descend, in which he could see all the various strata and deposits of which the earth is composed. How far he could send down this piercing cylinder of light he did not allow himself to consider. With a small and <b>imperfect</b> <b>machine</b> he had seen several feet into the ground; with a great and powerful apparatus, such as he was now constructing, why should he not look down below the deepest point to which man's knowledge had ever reached? Down so far that he must follow his descending light with a telescope; down, down until he had discovered the hidden secrets of the earth! ...|$|R
40|$|We have, {{within the}} last years, {{witnessed}} horrifying tragedies within the transportation domain. Planes fall down, trains crash, boats sink, and car accidents {{are one of the}} most frequent causes of death throughout the world. What is more, technology seems also to fail in settings that are more mundane. In his book "the trouble with computers: Usefulness, usability, and productivity", T. K. Landauer shows that the productivity has, within the western world, decreased by about 50 % from the period 1950 - 1973 to the period from 1973 to 1993, and claims that this effect is mostly due to the introduction of technology. Even closer to home, technology is still anxiety provoking for most people. One of many everyday observations to support this fact can be seen at the airports. Have you wondered why most people line up, even for hours, without daring to go near the automatic check-in machines? What has become of the grandiose promises from the heydays of artificial intelligence? What happened to the mind-machines of Newell and Simon? Where is HAL 9000 ? The distance between the massive technology positivism observed in the west, and the contemporary role of technology in the society, is, I believe, one of the largest paradoxes of our time. What is particularly interesting to note, is that the parody of the AI of the 60 s, seems to be recycled every now and again, both within entertainment, the financial world, and within academia. At the turn of the century, we have seen the popularity of movies like The Matrix, we have seen high hopes become sober reality at NASDAQ, and the reductionism of Newell and Simon is alive and well, in disguise of the magic buzzword connectionism. Universities around the world are now buying MRI – scanners on the thousands. We are, yet again (!), on the verge of discovering the mysteries of the mind. The slogan "Vorsprung Durch Technic" used by Audi displays something that lies deep within the western mind, namely the tendency to define ourselves and our culture in terms the inherent qualities of technology; precision, logic, rationality, reliability, punctuality, determination and power. Technology is, in many respects, the totem of the western culture. Maybe this thesis should have been about Techno-Totemism. But it is not. This thesis, on the other hand, attempts to explore what technology might have looked like, had it not been for techno-totemism, i. e. the prevailing idea within western culture and sciences, that humans are literally machines. This notion makes engineers design technological products as if humans actually were <b>machines,</b> or worse <b>imperfect</b> <b>machines.</b> The <b>imperfect</b> <b>machine</b> metaphor leads directly to the notion of "human error", which is often used in a particularly stupid fashion. In this work I lean, on the contrary, on aspects of human cognition that are not machine-like whatsoever, and advocate a change in design focus, from an emphasis on technology to an emphasis on ecology. I have attempted to present my programme positively; that is, to give indications on how, in practical, real life settings, such an approach might be carried out. At certain points, however, it has been necessary to point out the difference of my approach from the traditional cognitive-based Human Factors tradition, to make my points explicit. I apologize to cognitivists and human factors specialists for occasionally making a straw man of their theory. There are many excellent contributions made by these traditions, which are not reflected in this thesis. dr. polit. dr. polit...|$|R
40|$|Abstract:- The {{safety of}} quantum {{cryptography}} {{relies on the}} no-cloning theorem. In secret quantum communications, an eavesdropper cannot clone the sent qubits perfectly, however the best eavesdropping attacks for quantum cryptography are based on <b>imperfect</b> cloning <b>machines.</b> The eavesdropper’s physically allowed quantum evolutions on the sent qubit {{can be described in}} terms of the quantum state’s geometry. We use a fundamentally new computational geometrical method to analyze the informational theoretical impacts of cloning activity on the quantum channel. Our method uses Delaunay tessellation and convex hull calculation, with respect to quantum relative entropy as distance measure. The security analysis is focused on the four state (BB 84) and Six state quantum cryptography protocols. The proposed geometrical method can be used to analyze efficiently the informational theoretical impacts of physically allowed quantum cloning transformations...|$|R
60|$|And {{while the}} {{emergent}} New Republic is deciding {{to provide for}} the swarming inferiority of the Abyss, and developing the morality and educational system of the future, in this fashion, it will be attacking that mass of irresponsible property that is so unavoidable and so threatening under present conditions. The attack will, of course, be made along lines that the developing science of economics will trace in the days immediately before us. A scheme of death duties and of heavy graduated taxes upon irresponsible incomes, with, perhaps, in addition, a system of terminable liability for borrowers, will probably suffice to control the growth of this creditor elephantiasis. The detailed contrivances are for the specialist to make. If {{there is such a thing}} as bitterness in the public acts of the New Republicans, it will probably be found in the measures that will be directed against those who are parasitic, or who attempt to be parasitic, upon the social body, either by means of gambling, by manipulating the medium of exchange, or by such interventions upon legitimate transactions as, for example, the legal trade union in Great Britain contrives in the case of house property and land. Simply because he fails more often than he succeeds, there is still a disposition among sentimental people to regard the gambler or the speculator as rather a dashing, adventurous sort of person, and to contrast his picturesque gallantry with the sober certainties of honest men. The men of the New Republic will be obtuse to the glamour of such romance; they will regard the gambler simply as a mean creature who hangs about the social body in the hope of getting something for nothing, who runs risks to filch the possessions of other men, exactly as a thief does. They will put the two on a footing, and the generous gambler, like the kindly drunkard, in the face of their effectual provision for his little weakness, will cease to complain that his worst enemy is himself. And, in dealing with speculation, the New Republic will have the power of an assured faith and purpose, and the resources of an economic science that is as yet only in its infancy. In such matters the New Republic will entertain no superstition of laissez faire. Money and credit are as much human contrivances as bicycles, and as liable to expansion and modification as any other sort of prevalent but <b>imperfect</b> <b>machine.</b>|$|R
40|$|Abstract:- In secret quantum {{communications}} {{the best}} eavesdropping attacks on quantum cryptography {{are based on}} <b>imperfect</b> cloning <b>machines.</b> The incoherent attack, based on quantum cloning, {{is the most common}} eavesdropping strategy. Using a probe, the eavesdropper imperfectly clones the sender’s quantum state which keeps one copy and sends the other. The physically allowed transformations of Eve’s quantum cloner on Bob’s qubit can be described in terms of Completely Positive (CP), trace preserving maps. The map of the quantum cloner compresses the Bloch-ball, as an affine map. This affine map has to be a complete positive, trace preserving map, which shrinks the Bloch ball. The effects of a quantum cloner can be given in tetrahedron representation. In this paper we show a new, quantum information theoretical representation of eavesdropping detection, focused on the Four-state (BB 84) and Six-state quantum cryptography protocols. We use a fundamentally new computational geometrical method to analyze the informational theoretical impacts of cloning activity on the quantum channel. The proposed algorithm uses Delaunay tessellation and convex hull calculation on the Bloch sphere, with respect to quantum relative entropy as distance measure. The improved core-set approach can be used to analyze efficiently the informational theoretical impacts of physically allowed quantum cloning attacks...|$|R
40|$|In {{this thesis}} it is first {{presented}} how robust control {{can be used}} to give AC motor drive systems competitive dynamic performance under parameter variations. These variations are common to all AC machines, and are a result of temperature change in the <b>machine,</b> and <b>imperfect</b> <b>machine</b> models. This robust control is, however, dependent on sensor operation {{in the sense that the}} rotor position is needed in the control loop. Elimination of this control loop has been for many years, and still is, a main research area of AC machines control systems. An integrated PWM modulator and sampler unit has been developed and tested. The sampler unit is able to give current and voltage measurements with a reduced noise component. It is further used to give the true derivative of currents and voltages in the machine and the power converter, as an average over a PWM period, and as separate values for all states of the power converter. In this way, it can give measurements of the currents as well as the derivative of the currents, at the start and at the end of a single power inverter state. This gave a large degree of freedom in parameter and state identi_cation during uninterrupted operation of the induction machine. The special measurement scheme of the system achieved three main goals: By avoiding the time frame where the transistors commutate and the noise in the measurement of the current is large, filtering of the current measurement is no longer needed. The true derivative of the current in the machine is can be measured with far less noise components. This was extended to give any separate derivative in all three switching states of the power converter. Using the computational resources of the FPGA, more advanced information was supplied to the control system, in order to facilitate sensorless operation, with low computational demands on the DSP.   As shown in the papers, this extra information was first used to estimate some of the states of the machine, in some or all of the speed regions of the machine. The information was then combined to increase the dynamic performance of the sensorless operation of induction machines using the DTC algorithm, even under temperature variations. The scope of this thesis is to develop and test strategies for improving the performance of motor drive systems, when subjected to parameter variations in the machine. First, this is performed by modifying the controller towards a more robust controller, while later a special sampler is developed, in order to estimate machine parameters on-line. This development is shown in the following papers:  In the first paper, a complete motor drive system is built, and an H 1 current controller is implemented, instead of a previously designed PI controller with decoupling. The results show that this controller is able to perform similar to a classical PI-controller, even when subjected to parameter variations, at the cost of increased computational demands. The second paper presents a form of robust decoupling for a PI-controller as an alternative to the higher-order H 1 controller from the first paper. Although there is no speed input to the decoupling network, rotor position feedback from a resolver is still needed for the FOC to work correctly. The special sampler is introduced in the third paper. Here the sampler is used to estimate the rotor ux angle, based on measurements of the derivative of the machine currents in speci_c parts of the PWM-period. The estimator shows good performance. The estimation principle is based on measurements during the zero-period of the inverter, though. This gives poor performance in the upper speed region, when the zero-period 1 of the inverter is small or non-existent. In the fourth paper, the zero-state as well as the two active states of the inverter are used to estimate the rotor speed in a machine. This gives the opportunity of estimating machine parameters in the whole speed region, except around standstill, and the results show good performance, both static and dynamic. A combination of the DTC-algorithm and the sampler is presented in paper 5. Here, the sampler is used with a di_erent scheme to estimate the stator resistance, which a_ects the torque and speed estimation. The tests show that the sampler correctly identi_es the change in stator resistance and in this way makes it possible to achieve constant torque and speed, using the DTC-algorithm, even under stator resistance change. The overall contribution to knowledge in this thesis is that a machine control system can be made less dependent on parameter variations during operations of the machine, without interfering with the operation of the power inverter. This can be done by carefully designing the controller, or in the case of sensorless operation, by means of the specialized sampler developed as a part of the work presented.   1 The zero-period refer to the state where all the lower switches in the switching matrix are in the same state, and all the upper switches are in the same state, but opposite to the lower switches, connecting the outputs of the power converter either to the high or low potential of the DC-bus. PhD i elektronteknikkPhD in Electrical Engineerin...|$|R
30|$|This study {{explores the}} optimal {{production}} run {{time for a}} producer–retailer integrated economic manufacturing quantity (EMQ) model with rework failures, random machine breakdown, and a discontinuous inventory issuing policy. The EMQ model employed mathematical techniques to balance the production setup cost and inventory holding cost in a production cycle to derive the most economic manufacturing quantity that minimizes the long-run average production–inventory costs per unit time (Taft 1918; Wagner and Whitin 1958; Nahmias 2009). The classic EMQ model implicitly assumes that production equipment is in perfect condition and all items produced are of perfect quality. However, in real manufacturing environments, due to process deterioration or other uncontrollable factors, both production of items of <b>imperfect</b> quality and <b>machine</b> breakdown are inevitable. Unsurprisingly, many studies {{have been carried out}} to enhance the classic EMQ model by addressing issues of imperfect product quality and random machine breakdowns (Barlow and Proschan 1965; Shih 1980; Bielecki and Kumar 1988; Grosfeld-Nir and Gerchak 2002; Inderfurth et al. 2006; Hishamuddin et al. 2014; Chiu and Chang 2014; Lin et al. 2014; Wu et al. 2014; Khedlekar et al. 2014; Pal et al. 2015; Ocampo 2015; Chiu et al. 2015 a, b, c). Henig and Gerchak (1990) conducted a comprehensive analysis of a general periodic review production/inventory model with variable yield. Groenevelt et al. (1992) proposed two production control policies to cope with machine breakdown. The first policy considers that the production of an interrupted lot will not be resumed after a breakdown (i.e., the no resumption or NR policy), while the second assumes that the production of an interrupted lot resumed immediately after production is restored and if the current on-hand inventory is below a certain threshold level (i.e., the abort-resume or AR policy). Wee (1993) proposed an economic production policy for deteriorating items with partial back-ordering. Two numerical examples were used to illustrate this proposed theory, and the computational results indicated that the policy led to a lower cost. Gopalan and Kannan (1994) examined a two-stage transfer-line production system with inspection and rework. Transient state characteristics were analyzed for the system, subject to an initial buffer of infinite capacity, inspection at both inter- and end-stages, and rework. A stochastic model was developed to study the system, and as a result, some explicit analytical expressions of system characteristics were revealed. Moinzadeh and Aggarwal (1997) investigated a production–inventory system with random disruptions. They proposed an (s, S) policy for the system in which the time between breakdowns is exponential, restoration times are constant, and excess demand is backordered. A procedure for deriving optimal values from the policy was developed, and the system parameters that minimize the expected total cost per unit time were examined. Jabal Ameli et al. (2008) proposed a multi-objective integer linear programming approach for cell formation problems with alternative process routings and machine reliability issues. Their study aimed to simultaneously minimize total cost and maximize system reliability. Unlike the traditional reliability evaluation approaches, the approach used in their study was to model machine unreliability in terms of cost and time-based effects. Using the e-constraint method as an optimization tool for multi-objective programming, a numerical example was provided to demonstrate the capability of the proposed model to evaluate various effects of reliability issues. Chiu et al. (2009) studied the optimal production run time in an EMQ model with imperfect rework and Poisson machine breakdowns under the abort/resume (A/R) control policy. In their proposed system, a random defective rate is assumed and all defective items are reworked at the end of regular production, and there exists a certain percentage of rework failures. The system is subject to random breakdowns and the A/R inventory control policy is adopted when breakdowns occur. Mathematical modeling was used, and theorems related to conditional convexity and bounds of optimal production run times were proposed and proved in their study. A recursive searching algorithm was developed to locate the optimal run time that minimizes the expected production–inventory costs.|$|R

