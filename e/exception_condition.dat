20|147|Public
2500|$|Ultimately, {{the purpose}} of {{distinct}} operating modes for the CPU is to provide hardware protection against accidental or deliberate corruption of the system environment (and corresponding breaches of system security) by software. Only [...] "trusted" [...] portions of system software are allowed to execute in the unrestricted environment of kernel mode, and then, in paradigmatic designs, only when absolutely necessary. All other software executes {{in one or more}} user modes. If a processor generates a fault or <b>exception</b> <b>condition</b> in a user mode, in most cases system stability is unaffected; if a processor generates a fault or <b>exception</b> <b>condition</b> in kernel mode, most operating systems will halt the system with an unrecoverable error. When a hierarchy of modes exists (ring-based security), faults and exceptions at one privilege level may destabilize only the higher-numbered privilege levels. Thus, a fault in Ring 0 (the kernel mode with the highest privilege) will crash the entire system, but a fault in Ring 2 will only affect rings 3 and beyond and Ring 2 itself, at most.|$|E
5000|$|Error and <b>exception</b> <b>condition</b> {{values or}} types that can occur, and their {{meanings}} ...|$|E
50|$|NaNs are not {{necessarily}} generated in all the above cases. If an operation can produce an <b>exception</b> <b>condition</b> and traps are not masked then the operation will cause a trap instead. If an operand is a quiet NaN, and there isn't also a signaling NaN operand, {{then there is no}} <b>exception</b> <b>condition</b> and the result is a quiet NaN. Explicit assignments will not cause an exception even for signaling NaNs.|$|E
40|$|Abstract—The exception-handling {{mechanism}} {{has been}} widely adopted to deal with <b>exception</b> <b>conditions</b> that may arise during program executions. To produce high-quality programs, developers are expected to handle these <b>exception</b> <b>conditions</b> and take necessary recovery or resource-releasing actions. Failing to handle these <b>exception</b> <b>conditions</b> can lead to not only performance degradation, but also critical issues. Developers can write formal specifications to capture expected exceptionhandling behavior, and then apply tools to automatically analyze program code for detecting specification violations. However, in practice, developers rarely write formal specifications. To address this issue, mining techniques {{have been used to}} mine common exception-handling behavior out of program code. In this paper, we discuss challenges and achievements in precisely specifying and mining formal exception-handling specifications, as tackled by our previous work. Our key insight is that expected exception-handling behavior may be “conditional ” or may need to accommodate “exceptional ” cases. I...|$|R
50|$|Event Management, {{as defined}} by ITIL, is the process that {{monitors}} all events that occur through the IT infrastructure. It allows for normal operation and also detects and escalates <b>exception</b> <b>conditions.</b>|$|R
40|$|One of {{the major}} costs in a {{software}} project is the construction of test-data. This paper outlines a generalised test-case data generation framework based on optimisation techniques. The framework can incorporate a number of testing criteria, for both functional and non-functional properties. Application of the optimisation framework to testing specification failures and <b>exception</b> <b>conditions</b> is illustrated. The results {{of a number of}} small case studies are presented and show the efficiency and effectiveness of this dynamic optimisation-base approach to generating test-data. 1. 1 Keywords Automatic test-case generation, software testing, formal specifications, <b>exception</b> <b>conditions,</b> optimisation techniques, simulated annealing. ...|$|R
5000|$|Programming {{languages}} implement various mitigation methods {{against an}} accidental overflow: Ada, Seed7 (and certain variants of functional languages), trigger an <b>exception</b> <b>condition</b> on overflow, while Python (since 2.4) seamlessly converts internal {{representation of the}} number to match its growth, eventually representing it as [...] - whose ability is only limited by the available memory.|$|E
50|$|When {{a program}} was running in 'problem state', using a privileged {{instruction}} or an invalid memory address {{would cause the}} hardware to raise an <b>exception</b> <b>condition.</b> By trapping these conditions, CP could simulate the appropriate behavior, e.g. performing I/O or paging operations. A guest operating system, which would run in 'supervisor state' on a bare machine, was run in 'problem state' under CP.|$|E
5000|$|Ultimately, {{the purpose}} of {{distinct}} operating modes for the CPU is to provide hardware protection against accidental or deliberate corruption of the system environment (and corresponding breaches of system security) by software. Only [...] "trusted" [...] portions of system software are allowed to execute in the unrestricted environment of kernel mode, and then, in paradigmatic designs, only when absolutely necessary. All other software executes {{in one or more}} user modes. If a processor generates a fault or <b>exception</b> <b>condition</b> in a user mode, in most cases system stability is unaffected; if a processor generates a fault or <b>exception</b> <b>condition</b> in kernel mode, most operating systems will halt the system with an unrecoverable error. When a hierarchy of modes exists (ring-based security), faults and exceptions at one privilege level may destabilize only the higher-numbered privilege levels. Thus, a fault in Ring 0 (the kernel mode with the highest privilege) will crash the entire system, but a fault in Ring 2 will only affect rings 3 and beyond and Ring 2 itself, at most.|$|E
5000|$|The PL/I design {{principles}} {{were retained}} and withstood this major extension comprising several new data types, new statements and statement options, new <b>exception</b> <b>conditions,</b> and new organisations of program source. The resulting {{language is a}} compatible super-set of the PL/I Standard and of the earlier IBM compilers. Major topics added to PL/I were: ...|$|R
5000|$|Put {{commands}} {{first in}} warnings and cautions, with the <b>exception</b> of <b>conditions</b> ...|$|R
50|$|A VisualCron job {{consists}} of six elements: triggers, tasks, notifications, time <b>exceptions,</b> <b>conditions,</b> and timeouts. Like the Windows Task Scheduler, VisualCron allows user to bind several options for each job. The program provides {{the set of}} triggers and task types that the administrator can choose among; after the job is run, the user-configured notification is issued. The built-in tasks include file operations, SQL queries, system restart, and executing user-defined macros.|$|R
50|$|One {{of the key}} aspect {{that allows}} this {{compatibility}} is to define that unused fields are to be set to a predetermined value (usually 0) - and that using another value leads to an <b>exception</b> <b>condition</b> being recognized. When the interface is modified, this unused field can then be used to alter the interface contract. A well formed program can then still produce the expected result even when executing on an implementation of the new interface.|$|E
5000|$|... # THE PRODUCT INFORMATION FILE# THE PRICE INFORMATION FILE# THE CUSTOMER INFORMATION FILE# THE ORDER FILE# THE PICKING INSTRUCTIONS FILE# THE DELIVERY NOTIFICATION FILE# THE DELIVERY CONFIRMATION FILE# THE INVOICE FILE# THE CREDIT NOTE FILE# THE STATEMENT/REMITTANCE DETAILS FILE# THE UPLIFT INSTRUCTION FILE# THE UPLIFT CONFIRMATION FILE# THE STOCK SNAPSHOT FILE# THE STOCK ADJUSTMENT FILE# THE AVAILABILITY REPORT FILE # THE GENERAL COMMUNICATIONS FILE# THE COMPLEX ORDER FILE# THE ACKNOWLEDGEMENT OF ORDER FILE# THE PRODUCT PLANNING REPORT FILE# THE PAYMENT ORDER FILE# THE DEBIT ADVICE FILE# THE CREDIT ADVICE FILE# THE <b>EXCEPTION</b> <b>CONDITION</b> FILE# THE LOCATION PLANNING REPORT FILE# THE UTILITY BILL FILE ...|$|E
5000|$|SSI {{benefits}} are not paid solely to US citizens, {{but may also}} be paid to aliens legally residing in the United States. [...] Conversely, citizens may find themselves ineligible {{because they do not}} currently reside within the United States; exceptions apply for children of military parent(s) who were born overseas, were disabled or became blind overseas, or first applied for benefits overseas and for students studying abroad who were eligible for SSI in the month prior to leaving the US, whose absence will be for less than 1 year, and who are studying to enhance their ability to perform substantial gainful activity, sponsored by an educational institution in the US, and would not be available to the individual in the US. [...] Several restrictions apply to the eligibility of aliens however. These include being in a [...] "qualified alien" [...] category and meeting an <b>exception</b> <b>condition.</b>|$|E
40|$|Programming {{languages}} such as Java and C++ provide exception-handling constructs {{to handle}} <b>exception</b> <b>conditions.</b> Applications {{are expected to}} handle these <b>exception</b> <b>conditions</b> and take necessary recovery actions such as releasing opened database connections. However, exceptionhandling rules that describe these necessary recovery actions are often not available in practice. To address this issue, we develop a novel approach that mines exceptionhandling rules as sequence association rules of the form “(FC 1 c [...] . FC n c) ∧ FCa ⇒ (FC 1 e [...] . FC m e) ”. This rule describes that function call FCa should {{be followed by a}} sequence of function calls (FC 1 e [...] . FC m e) when FCa is preceded by a sequence of function calls (FC 1 c [...] . FC n c). Such form of rules is required to characterize common exceptionhandling rules. We show the usefulness of these mined rules by applying them on five real-world applications (including 285 KLOC) to detect violations in our evaluation. Our empirical results show that our approach mines 294 real exception-handling rules in these five applications and also detects 160 defects, where 87 defects are new defects that are not found by a previous related approach. ...|$|R
50|$|George 1 was {{a simple}} batch {{processing}} system, Job descriptions were read from cards or paper tape which controlled the loading and running of programs, either loaded from cards or paper tape or magnetic tape. The job control language allowed definition of the peripherals and files to be used and handling of <b>exception</b> <b>conditions.</b> The job description would be checked for errors before the job was run. George used the trusted program facilities provided by executive to run the user programs.|$|R
40|$|Abstract. Several {{researchers}} are using evolutionary search methods {{to search for}} test data with which to test a program. The fitness or cost function depends on the test goal but almost invariably {{an important component of}} the cost function is an estimate of the cost of satisfying a predicate expression as might occur in branches, <b>exception</b> <b>conditions,</b> etc. This paper reviews the commonly used cost functions and points out some deficiencies. Alternative cost functions are proposed to overcome these deficiencies. The evidence from an experiment is that they are more reliable. ...|$|R
5000|$|Additionally, {{buffering}} stores until retirement allows processors to speculatively execute store {{instructions that}} follow an instruction that may produce an exception (such as {{a load of}} a bad address, divide by zero, etc.) or a conditional branch instruction whose direction (taken or not taken) is not yet known. If the exception-producing instruction has not executed or the branch direction was predicted incorrectly, the processor will have fetched and executed instructions on a [...] "wrong path." [...] These instructions {{should not have been}} executed at all; the <b>exception</b> <b>condition</b> should have occurred before any of the speculative instructions executed, or the branch should have gone the other direction and caused different instructions to be fetched and executed. The processor must [...] "throw away" [...] any results from the bad-path, speculatively-executed instructions when it discovers the exception or branch misprediction. The complication for stores is that any stores on the bad or mispredicted path should not have committed their values to the memory system; if the stores had committed their values, {{it would be impossible to}} [...] "throw away" [...] the commit, and the memory state of the machine would be corrupted by data from a store instruction that should not have executed.|$|E
40|$|V;rriablc {{precision}} {{logic is}} concerned with probh. 'ms (ff reaoning with incomplete information md under time constrdnts. It offers mechanisms for hmdhng trade-offs between the precision of ixffcrcnces mid the computatiomd cihcicncy tff deriving them. Of the two mapects of precision, the specificity of conclusions mid the certainty (ff bclicf in them, we address here primarily thc latter, md mnploy censored production rules as m underlying reprcsentation md cmnputation nhanism. Such les e created by augmenting ordim production nles witli l <b>exception</b> <b>condition,</b> d e written the t}rm if A then B unless C, where C is the <b>exception</b> <b>condition...</b>|$|E
40|$|One of {{the major}} costs in a {{software}} project is the construction of test-data. This paper outlines a generalised test-case data generation framework based on optimisation techniques. This framework can incorporate a number of testing criteria unifying both functional and non-function testing. Application of the optimisation based approach are given for worst-case execution time, specification conformance, structural coverage and <b>exception</b> <b>condition</b> testing. The results {{of a number of}} small example case studies are presented and show the efficacy of the approach. ...|$|E
50|$|The Rail Pass {{is valid}} on almost {{all forms of}} {{transportation}} (train, bus and ferry) operated by the companies of the JR Group. However, there are <b>exceptions</b> and <b>conditions</b> of use of the Rail Pass.|$|R
40|$|Business {{processes}} in open environments often involve multiple organizations. Effectively modeling and enacting such {{processes in}}volves understanding the protocols that occur {{within and across}} such organizations and the interplay between the protocols and the structures of the organizations. This is especially {{so as to make}} the processes robust under <b>exception</b> <b>conditions.</b> This paper proposes commitments as the unifying abstraction for modeling organizations and protocols. It introduces the notion of facets of commitments to provide a principled basis for managing commitments in organizations. Further, this paper studies a form of gray-box modeling where the structure of organizations may be made partially visible externally to improve system resilience. 1...|$|R
50|$|In test-driven development, {{each new}} feature begins with writing a test. Write {{a test that}} defines a {{function}} or improvements of a function, which should be very succinct. To write a test, the developer must clearly understand the feature's specification and requirements. The developer can accomplish this through use cases and user stories to cover the requirements and <b>exception</b> <b>conditions,</b> and can write the test in whatever testing framework is appropriate to the software environment. It could be {{a modified version of}} an existing test. This is a differentiating feature of test-driven development versus writing unit tests after the code is written: it makes the developer focus on the requirements before writing the code, a subtle but important difference.|$|R
40|$|This paper {{presents}} the results of a three year research program to develop an automated test-data generation framework to support the testing of safety-critical software systems. The generality of the framework comes from the exploitation of domain independent search techniques, allowing new test criteria to be addressed by constructing functions that quantify the suitability of test-data against the test-criteria. The paper presents four applications of the framework — specification falsification testing, structural testing, <b>exception</b> <b>condition</b> testing and worst-case execution time testing. The results of three industrial scale case-studies are also presented to show that the framework offers useful support in the development safety-critical software systems. ...|$|E
40|$|This paper proposes and {{analyses}} {{the performance of}} a finite buffer point-to-multipoint selective repeat (SR) protocol with accumulative acknowledgment. The proposed strategy is based on three key ideas. The first is the use of accumulative acknowledgments {{in order to reduce the}} required processing overhead and implementation complexity. The second and third aim at improving the throughput efficiency: to make the most of the selective repeat recovery procedure and to process and store all messages correctly received during an <b>exception</b> <b>condition.</b> The proposed strategy performs very well under a wide range of conditions, being more efficient than all known point-to-multipoint GB(N) strategies, for low bit error rates...|$|E
40|$|Variable {{precision}} {{logic is}} concerned with problems of reasoning with incomplete information and under time constraints. It offers mechanisms for handling trade-offs between the precision of inferences and the computational efficiency of deriving them. Of the two aspects of precision, the specificity of conclusions and the certainty of belief in them, we address here primarily the latter, and employ censored production rules as an underlying representational and computational mechanism. Such rules are created by augmenting ordinary production rules with an <b>exception</b> <b>condition</b> and are written in the form if A then D unless C, where C is the <b>exception</b> <b>condition.</b> From a control viewpoint, censored production rules are intended for situations in which the implication A {arrow} B holds frequently and the assertion C holds rarely. Systems using censored production rules are free to ignore the exception conditions, when time is a premium. Given more time, the exception conditions are examined, lending credibility to initial, high-speed answers, or changing them. Such logical systems therefore exhibit variable certainty of conclusions, reflecting variable investments of computational resources in conducting reasoning. From a logical viewpoint, the unless operator between B and C acts as the exclusive-or operator. From an expository viewpoint, the if A then B part of the censored production rule expresses an important information (e. g., a causal relationship), while the unless C part acts only as a switch that changes the polarity of B to ??hen C holds. Expositive properties are captured quantitatively by augmenting censored rules with two parameters that indicate the certainty of the implication if A then B. Parameter 6 is the certainty when the truth value C is unknown, and 7 is the certainty when C {{is known to be}} false...|$|E
5000|$|Parasoft Jtest uses runtime error {{detection}} to expose defects such as race <b>conditions,</b> <b>exceptions,</b> resource & memory leaks, and security attack vulnerabilities.|$|R
40|$|The {{following}} analysis {{focuses on}} the prospects for implementation of the first directive (racial and ethnic discrimination) with a particular emphasis on {{issues related to the}} legal position of third country nationals, who, although specifically addressed in the directive are at the same time subject to vague <b>exception,</b> <b>conditions,</b> and caveats [...] . The goal of the first section is to show how policy issues were gradually being redefined and renegotiated across borders and levels of government over a fifteen year period beginning in 1985. The goal of the second section is to employ the empirical examination of the first section to analyze the post-Amsterdam policy jam at the intersection of race, nationality, and citizenship. I'll conclude by speculating, in light of this analysis, on prospects for effective implementation of the new anti-race discrimination directive (deadline, July 2003) ...|$|R
40|$|Current Floating-point divisor {{architectures}} {{have low}} frequency, larger area and high latency in nature. With advent of more graphic, scientific and medical applications, floating point dividers have become indispensable and increasingly important. However, {{most of these}} modern applications need higher frequency or low latency of operations with minimal area occupancy. In this work, highly optimized pipelined architecture of an IEEE- 754 standard double precision floating point divider is designed to achieve high frequency on FPGAs. By using secondary clock to perform mantissa division the overall latency of the divisor is reduced to 30 clock cycles, i. e. 52 % less compared to conventional divisors. This design is mapped onto a Virtex- 6 FPGA and an operating frequency of 452. 69 MHz is achieved. The proposed design also handles all the IEEE specified four rounding modes, overflow, underflow and various <b>exception</b> <b>conditions...</b>|$|R
40|$|One of {{the major}} costs in a {{software}} project is the construction of test-data. This paper outlines a generalised test-case data generation framework based on optimisation techniques. This framework can incorporate a number of testing criteria unifying both functional and non-function testing. Application of the optimisation based approach are given for worst-case execution time, specification conformance, structural coverage and <b>exception</b> <b>condition</b> testing. The results {{of a number of}} small example case Software testing is an expensive process, typically consuming at least 50 % of the total costs involved in developing software [1]. Automation of the testing process is desirable both to reduce the development costs and also {{to improve the quality of}} (or at least confidence in) software. While automation of the testing process – the maintenance and execution of tests – is becoming commercially wide spread, th...|$|E
40|$|The Oklahoma {{manual of}} legal blank forms : being a {{collection}} of the most approved short forms, for conveyancing, executive, judicial, election, probate, municipal, and contract blanks and office books : adapted to the <b>exception</b> <b>condition</b> and present needs of Oklahoma Territory, and for use therein, by lawyers, public officers, and people / prepared by an expert, upon authority. Topeka, Kan. : The Hall & O'Donald Litho. Co. [c 1890]": p. [995]- 1021 "Explanatory" signed: Le Grand Byington, compilerParts 1 - 3 have various pagingsI. Treaties, United States laws, proclamation of the President, and such of the Nebraska General statutes as are in force in the territory {{by virtue of the}} Organic Act of Congress : approved April 30, 1890 [...] II. Code of civil procedure [...] III. Criminal code [...] IV. AppendixMode of access: Internet...|$|E
40|$|An {{investigation}} {{was made of}} the characteristics of computer programming languages intended for the implementation of provably correct programs and of the characteristics of programs written in these languages. It was discovered that potential run time exceptions and the necessity of providing a rigorously correct implementation of exception handlers so dominate the potential control paths of programs written in verifiable languages that the usual code optimization techniques are ineffective. It was further discovered that the call intensive control structures of these programs, necessitated by verification constraints, also thwart optimization and lead to inefficient code. It is shown that theorems can be derived at potential exception sites which, if true, guarantee that the <b>exception</b> <b>condition</b> will never arise permitting removal of the exception path from the program's flow graph. These theorems are proved using the automatic theorem prover {{which is part of the}} program verification [...] ...|$|E
40|$|This {{case study}} {{concerns}} the specification and validation of a Security Policy Model (SPM) for an electronic network. The network {{is intended to}} provide processing and transmission services for electronic messages, including sensitive and classified material, over distributed sites and supporting multiple levels of security classification. The SPM is formally specified in VDM-SL and validated by showing that the model is mathematically consistent and satisfies certain security properties. Rigorous proofs are provided. In addition, the case study illustrates some new techniques concerning proof obligations for <b>exception</b> <b>conditions</b> in VDM-SL. 1 Introduction 1. 1 Background and Context This chapter describes the specification and validation of a formal Security Policy Model (SPM) for an electronic-message processing and transmission service. The SPM is a distillation of the important security requirements of the software system that provides the service. The SPM described here is [...] ...|$|R
50|$|<b>Exceptions</b> to this <b>condition</b> are, however, not infrequent: {{the left}} may {{be larger than}} the right or the two may be almost equal in size.|$|R
5000|$|Runtime error {{detection}} - Monitoring an application {{the execution of}} automated or manual tests to expose problems such as race <b>conditions,</b> <b>exceptions,</b> and resource leaks.|$|R
