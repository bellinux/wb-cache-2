1|42|Public
5000|$|The {{behavior}} of a trusted system is often characterized {{in terms of a}} mathematical model - which may be more or less rigorous, depending upon applicable operational and administrative constraints - that {{takes the form of a}} finite state machine (FSM) with state criteria; state transition constraints; a set of [...] "operations" [...] that correspond to state transitions (usually, but not necessarily, one); and a <b>descriptive</b> <b>top-level</b> <b>specification,</b> or DTLS, entailing a user-perceptible interface (e.g., an API, a set of system calls UNIX or system exits mainframe), each element of which engenders one or more model operations.|$|E
5000|$|Formal {{design and}} {{verification}} techniques including a formal <b>top-level</b> <b>specification</b> ...|$|R
40|$|This paper {{presents}} {{parts of}} the SECREDS project which aims {{to bridge the gap}} between system modeling and implementation using a high-level programming language. Within SECREDS secure applications are developed top down starting with a <b>top-level</b> <b>specification.</b> <b>Top-level</b> <b>specifications</b> are given by our computational model and application-specific security policies are specified using our security requirement logic. To implement a <b>top-level</b> <b>specification</b> we developed a high-level programming language called INSEL + offering language concepts well adapted to our underlying model. We will present main features of INSEL + focusing on access control aspects and we will outline some guidelines to support the systematic implementation of a given <b>top-level</b> <b>specification</b> preserving specified security properties. Keywords Access Control, Security Policy, Programming Language 1 INTRODUCTION The issue of developing secure applications is still a great challenge. Secure applications should be [...] ...|$|R
40|$|The VIPER {{microprocessor}} chip is partitioned {{into four}} levels of abstractions. At the highest level, VIPER is described with decreasingly abstract sets of functions in LCF-LSM. At {{the lowest level}} are the gate-level models in proprietary CAD languages. The block-level and gate-level specifications are also given in the ELLA simulation language. Among VIPER's deficiencies are {{the fact that there}} is no notion of external events in the <b>top-level</b> <b>specification,</b> and it is impossible to use the <b>top-level</b> <b>specifications</b> to prove abstract properties of programs running on VIPER computers. There is no complete proof that the gate-level <b>specifications</b> implement the <b>top-level</b> <b>specifications.</b> Cohn's proof that the major-state machine correctly implements the <b>top-level</b> <b>specifications</b> has no formal connection with any of the other proof attempts. None of the latter address resetting the machine, memory timeout, forced error, or single step modes...|$|R
5000|$|Security Testing {{automatically}} generates test-case {{from the}} formal <b>top-level</b> <b>specification</b> or formal lower-level specifications.|$|R
40|$|Government. The {{verification}} of a bit-slice ALU {{has been accomplished}} using a mechanical theorem prover. This ALU has an n-bit design specification, which has been verified to implement its <b>top-level</b> <b>specification.</b> The ALU and <b>top-level</b> <b>specifications</b> were written in the Boyer-Moore logic. The verification was carried out {{with the aid of}} Boyer-Moore theorem prover in a hierarchical fashion. 1 1...|$|R
40|$|The {{verification}} of a bit-slice ALU {{has been accomplished}} using a mechanical theorem prover. This ALU has an n-bit design specification, which has been verified to implement its <b>top-level</b> <b>specification.</b> The ALU and <b>top-level</b> <b>specifications</b> were written in the Boyer-Moore logic. The verification was carried out {{with the aid of}} Boyer-Moore theorem prover in a hierarchical fashion. 1 1. Introduction The {{verification of}} a bit-slice ALU design has been accomplished {{with the aid of a}} mechanical theorem prover. This ALU, used in the FM 8502 microprocessor [Hunt 89], has been proved to implement the FM 8501 abstract ALU specification which precisely describes the operation of the FM 8501 ALU in terms of natural numbers, integers, and bit vectors. This verification was accomplished in two steps: one, verifying that the FM 8501 ALU implements its abstract specification, and two, verifying that the results computed by the FM 8502 bit-slice ALU exactly match the results computed by the FM 8501 ALU. T [...] ...|$|R
40|$|We {{describe}} the specification {{of the formal}} security policy model and formal <b>top-level</b> <b>specification</b> for the Least Privilege Separation Kernel (LPSK) in Alloy, a relatively new modelling language and analysis tool. The {{state of the art}} for the formal verification of secure software requires representation of an abstract model, and one or more refinements (to the model), in a formal specification language. These specifications are then examined for self-consistency with their properties, as well as for consistency between levels of abstraction, all of which can be time consuming, and costly. Alloy provides a simple, intuitive logic framework, in contrast to many other formal languages that are intended to support general-purpose mathematics. In order to determine whether Alloy can improve the efficiency and effectiveness of the verification of secure computer systems, we used it to specify portions of the LPSK formal security policy model and formal <b>top-level</b> <b>specification,</b> and utilized the Alloy Analyzer to examine the consistency of the specifications. The security-critical system elements and predicates for security properties were defined in terms of a state model, and system operations were represented as state transitions. While Alloy does not support induction or proofs, {{it can be used to}} find counter examples in a small scope of state transitions. We conclude that Alloy has few limitations and is suitable, as measured by utility and ease of use, to include in the toolbox for rapid high-assurance system development. The primary concern with using Alloy for industrial, versus academic, security verification is the scalability of the Alloy Analyzer with respect to the state-space of the security model and formal <b>top-level</b> <b>specification.</b> For real system verification, Alloy must support a much larger scope. We found that the translation of an existing informal LPSK security policy model to Alloy provided insight for making the model clearer. It is also apparent that Alloy allows for the beginner to formal system verification to quickly climb its learning curve...|$|R
40|$|Abstract The {{semantic}} {{architecture of}} CML consists of conventions, dictionaries and units. The conventions conform to a <b>top-level</b> <b>specification</b> and each convention can constrain compliant documents through machine-processing (validation). Dictionaries conform to a dictionary specification which also imposes machine validation on the dictionaries. Each dictionary {{can also be}} used to validate data in a CML document, and provide human-readable descriptions. An additional set of conventions and dictionaries are used to support scientific units. All conventions, dictionaries and dictionary elements are identifiable and addressable through unique URIs. </p...|$|R
40|$|Abstract: We {{describe}} the specification {{of the formal}} security policy model and formal <b>top-level</b> <b>specification</b> for the Least Privilege Separation Kernel (LPSK) in Alloy, a relatively new modeling language and analysis tool. The {{state of the art}} for the formal verification of secure software requires representation of an abstract model, and one or more refinements (to the model), in a formal specification language. These specifications are then examined for self-consistency with their properties, as well as for consistency between levels of abstraction, all of which can be time consuming, and costly. Alloy provides a simple, intuitive logic framework, in contrast to many other formal languages that are intended to support general-purpose mathematics. In order to determine whether Alloy can improve the efficiency and effectiveness of the verification of secure computer systems, we used it to specify portions of the LPSK formal security policy model and formal <b>top-level</b> <b>specification,</b> and utilized the Alloy Analyzer to examine the consistency of the specifications. The security-critical system elements and predicates for security properties were defined in terms of a state model, and system operations were represented as state transitions. While Alloy does not support induction or proofs, {{it can be used to}} find counter examples in a small scope of state transitions. We conclude that Alloy has few limitations and is suitable, as measured by utility and eas...|$|R
40|$|A {{real-time}} high-performance and fault-tolerant FPGA-based hardware architecture for {{the processing}} of synthetic aperture radar (SAR) images has been developed for advanced spaceborne radar imaging systems. In this paper, we present the integrated design approach, from <b>top-level</b> algorithm <b>specifications,</b> system architectures, design methodology, functional verification, performance validation, down to hardware design and implementation...|$|R
40|$|We {{present a}} {{real-time}} high-performance and fault-tolerant FPGA-based hardware architecture for {{the processing of}} synthetic aperture radar (SAR) images in future spaceborne system. In particular, we will discuss the integrated design approach, from <b>top-level</b> algorithm <b>specifications</b> and system requirements, design methodology, functional verification and performance validation, down to hardware design and implementation...|$|R
40|$|Formal {{methods for}} {{software}} verification and refinement almost all involve verification conditions. These are predicate calculus formulae generated, often automatically, {{from the program}} under development; proving the verification conditions establishes the correctness of the development. Surprisingly, {{it is possible to}} reverse the process and generate an implementation from the verification conditions, together with the <b>top-level</b> <b>specification.</b> The code generation algorithm presented here has polynomial complexity. Two versions of this algorithm are presented, both based on a form of Hoare logic, which is used rather than, say, refinement calculus because of its simplicity. The feasibility of generating code from the verification conditions establishes their significance as an independent summary of the program and its correctness argument. The result also justifies investigation into a new method of program development, logical refinement, in which the verification conditions are w [...] ...|$|R
40|$|Productivity is {{of major}} {{economic}} {{significance in the}} current competitive global market. Due to growing costs and globalization of the marketplace, improvements in productivity require {{the creation of a}} reliable design through concurrent systems analysis in the shortest possible time. This is particularly important for designing complex engineering systems such as aircraft, automobiles and ships. The Robust Concept Exploration Method (RCEM) embodies a systematic approach {{that can be used to}} enhance design productivity by both increasing design knowledge in the early stages of designs and maintaining design freedom throughout the design process. Given the overall design requirements and the systems analysis packages with high fidelities, the RCEM is used to evaluate quickly the design alternatives and to develop comprehensive, robust, flexible, and modifiable <b>top-level</b> <b>specifications.</b> Central to the RCEM is the integration of robust design techniques, Suh's design axioms, and the Respon [...] ...|$|R
40|$|Abstract- A {{real-time}} high-performance and fault-tolerant FPGA-based hardware architecture for {{the processing}} of synthetic aperture radar (SAR) images has been developed for advanced spaceborne radar imaging systems. In this paper, we present the integrated design approach, from <b>top-level</b> algorithm <b>specifications,</b> system architectures, design methodology, functional verification, performance ‘i validation, down to hardware design and implementation. I...|$|R
40|$|Formally {{refining}} a real-time specification to an implementation is {{only possible}} when the specification allows for all physical limitations, and timing and signal errors {{inherent in the}} implementation. Allowing for such implementation-specific details in a <b>top-level</b> <b>specification</b> can, however, obscure the desired functionality and complicate analysis. Furthermore, such an approach assumes the specifier has {{an understanding of the}} physical limitations and errors of the implementation which may not yet have been developed. As an alternative, we propose introducing a notion of realisation into the formal development process. Realisation is an approach to specification development which allows errors and physical limitations to be introduced. It also allows properties of the new specification to be derived from those proved for the original. 1 Introduction Several formal notations have been developed for the specification and refinement of real-time systems [19, 15, 16, 3, 13, 12]. To [...] ...|$|R
40|$|In {{the early}} stages of design of complex systems, it is {{necessary}} to explore the design space to determine a suitable range for specifications and identify feasible starting points for design. Thus, a robust concept exploration method have been developed to improve the efficiency and effectiveness of the process of identifying suitable starting points for the design of complex systems. Using this method, quality concepts (robustness) are introduced into the choice of the initial specifications for design. The Concept exploration is implemented by integrating the Response Surface Method, robust design techniques and the compromise Decision Support Problem. The proposed approach is demonstrated to determining <b>top-level</b> <b>specifications</b> for airframe geometry and the propulsion system for the High Speed Civil Transport aircraft. The focus in this paper is on illustrating the approach rather than on the results per se. Word Count: 6986. Key words: Concept exploration, robust design, specifi [...] ...|$|R
40|$|This {{article was}} {{published}} online in the journal, Software Engineering Journal [© IEEE]. It {{is also available}} at: [URL] Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists, or to reuse any copyrighted component of this work in other works must {{be obtained from the}} IEEE. Temporal logic techniques have been proposed as a way of achieving a very natural transition from informal requirements to a formal specification of the requirements. The paper presents a case study of a real-life system developed using such techniques. Both a <b>top-level</b> <b>specification</b> and implementation semantics are given in temporal logic. In particular, the progression from statements in English to temporal logic is highlighted. A correctness proof that the implemented system satisfies the specification has been produced...|$|R
40|$|The {{issue of}} {{developing}} complex secure systems {{is still a}} great challenge. We claim that {{in contrast to the}} well known bottom-up oriented approaches secure concurrent systems should be developed top-down starting with a formal <b>top-level</b> <b>specification.</b> A framework for developing secure systems is needed, which offers means to specify security requirements adapted to the specific demands of application areas. In addition, an appropriate security model is needed to formally describe the behavior and the security properties of systems. We will present a uniform framework which is appropriate to match security policies to application needs. Secure concurrent systems are modeled with two different levels of abstraction. The action model provides a sound and fine-grained basis to formalize security properties of the system. In order to ease system modeling we introduce the object security model by systematically coarsening the action model. In addition to our security model we will present a [...] ...|$|R
50|$|The <b>top-level</b> <b>specification</b> is a Stream X-Machine {{describing}} the main user {{interaction with the}} system. For example, the word processor will exist {{in a number of}} states, in which keystrokes and commands will have different effects. Suppose that this word processor exists in the states {Writing, Selecting, Filing, Editing}. We expect the word processor to start in the initial Writing state, but to move to the Selecting state if either the mouse is dragged, or the shift-key is held down. Once the selection is established, it should return to the Writing state. Likewise, if a menu option is chosen, this should enter the Editing or Filing state. In these states, certain keystrokes may have different meanings. The word processor eventually returns to the Writing state, when any menu command has finished. This state machine is designed and labelled informally with the various actions that cause it to change state.|$|R
50|$|Brands {{have also}} applied {{to get their}} brand as a <b>top-level</b> domain. <b>Specification</b> 13 is an {{addendum}} to the registry contract that describes specific provisions to brands to run their Top Level Domain in a closed fashion. 517 applications to qualify to Spec 13 were made to ICANN, 36 requests were rejected by ICANN or withdrawn by the applicant, 4 are pending review.|$|R
40|$|AA The initial {{operations}} concept expresses information about system objectives, and defines the system users, system interfaces, and operational performance constraints. We {{have developed a}} prototype expert system which has established the feasibility of automating a scenario-driven methodology for deriving <b>top-level</b> <b>specifications</b> and preliminary designs for user data systems. This scenario-driven methodology uses an initial design, an {{initial operations}} concept, and user scenarios {{as the starting point}} for system definition. The top-level initial design is a functional description of the system {{in the form of an}} annotated data flow diagram. The initial operations concept expresses informationabout system objectives, and defines the system users, system interfaces, and operational performance constraints. The user scenarios are detailed time-lined descriptions of user activities, developed by prospective end users. These scenarios, along with the initial design and operations concept, are analyzed and iterated by the expert system to form a consistent set. The resulting User Scenario-Operation Set plays a key role in the development of requirements and system tests...|$|R
40|$|This paper {{presents}} a novel formal {{development of a}} non-trivial parallel program: Simpson's implementation of asynchronous communication mechanisms (ACMs). Although the correctness of the " 4 -slot algorithm " has been shown elsewhere, earlier developments {{are by no means}} intuitive. The aims of this paper include both the presentation of an understandable (yet formal) design history and the establishment of another way of "splitting (software) atoms". Using the "fiction of atomicity " as an aid to understanding the initial steps of development, the <b>top-level</b> <b>specification</b> is developed to code. The rely-guarantee approach is, here, combined with notions of read/write frames and "phased " specifications; the atomicity assumptions implied by rely/guarantee conditions are realised by clever choice of data representation. The development method herein is compared with other approaches [...] in a spirit of cooperation [...] as the authors believe that constructive comparison elucidates many of the finer points in the " 4 -slot " specification/development and of parallel programs in general...|$|R
40|$|The goal of {{this paper}} is the correct {{derivation}} of an implementation of a steam boiler control system. Using a mixed formalism that is presented in [Hoo 94 b] in which programs and assertional specifications are combined within a unified framework, we refine its <b>top-level</b> <b>specification</b> in a top-down manner. Having the formalism defined in the PVS specification language, the interactive proof checker of PVS is used to check the correctness of each refinement step, thereby guaranteeing the correctness of the resulting program. 1 Introduction We aim at a specification of a steam boiler control system [Abr 94], a typical example of a hybrid system. A hybrid system is a mixture of discrete and continuous components, such as program controlled digital computers and continuous processes [GNRR 93]. The intention is to design a real-time control program that keeps the water level inside a steam boiler between certain critical values Min and Max. The level is influenced by outflow in the form of [...] ...|$|R
40|$|RIGHTS : This {{article is}} {{licensed}} under the BioMed Central licence at [URL] {{which is similar}} to the 'Creative Commons Attribution Licence'. In brief you may : copy, distribute, and display the work; make derivative works; or make commercial use of the work - under the following conditions: the original author must be given credit; for any reuse or distribution, it must be made clear to others what the license terms of this work are. Abstract The semantic architecture of CML consists of conventions, dictionaries and units. The conventions conform to a <b>top-level</b> <b>specification</b> and each convention can constrain compliant documents through machine-processing (validation). Dictionaries conform to a dictionary specification which also imposes machine validation on the dictionaries. Each dictionary {{can also be used to}} validate data in a CML document, and provide human-readable descriptions. An additional set of conventions and dictionaries are used to support scientific units. All conventions, dictionaries and dictionary elements are identifiable and addressable through unique URIs. Peer Reviewe...|$|R
40|$|Driven by {{increasing}} complexity and reliability demands, the Japanese Aerospace Exploration Agency (JAXA) in 2004 commissioned development of ELEGANT, a complete SpecC-based environment for electronic system-level (ESL) design {{of space and}} satellite electronics. As integral part of ELEGANT, the Center for Embedded Computer System (CECS) has developed and supplied the SER tool set. Following a Specify-Explore-Refine methodology, SER supports system-level design space exploration, interactive platform development and automatic model refinement and model generation. The SER engine has been successfully integrated into ELEGANT. With SER at its core, ELEGANT provides a seamless tool chain for modeling verification and synthesis from <b>top-level</b> <b>specification</b> down to embedded HW/SW implementation. ELEGANT and SER have been succesfully delivered to JAXA and its suppliers. Tools are currently being deployed in companies like NEC Toshiba Space Systems. Evaluation results prove the feasibility of the approach for design space exploratoin, rapid virtual prototyping and system synthesis resulting in tremendous productivity and reliability gains. In addition, ELEGANT has been commercialized for general market availability. The SER component has been licensed to InterDesign Technologies, Inc. (IDT) and it is available from, sold and supported by IDT...|$|R
40|$|We have {{developed}} a stack of semantics for a high-level C-like language and low-level assembly code, which has been carefully crafted to support the pervasive verification of system software. It can handle mixed-language implementations and concurrently operating devices, and permits the transferral of properties to the target architecture while obeying its resource restrictions. We demonstrate the applicability of our framework by proving the correct virtualization of user memory in our microkernel, which implements demand paging. This verification target {{is of particular interest}} because it has a relatively simple <b>top-level</b> <b>specification</b> and it exercises all parts of our semantics stack. At the bottom level a disk driver written in assembly implements page transfers via a swap disk. A page-fault handler written in C uses the driver to implement the paging algorithm. It guarantees that a step of the currently executing user can be simulated at the architecture level. Besides the mere theoretical and technical difficulties the project also bore the social challenge to manage the large verification effort, spread over many sites and people, concurrently contributing to and maintaining a common theory corpus. We share our experiences and elaborate on lessons learned...|$|R
40|$|Integrity, security, {{and safety}} are desired {{properties}} of database systems destined {{for use in}} critical applications. These properties are desirable because they determine a system`s credibility. However, demonstrating that a system does, in fact, preserve these properties when implemented is a difficult task. The difficulty depends on {{the complexity of the}} associated design. The authors explore architectural paradigms that have been demonstrated to reduce system complexity and, thus, reduce the cost associated with certifying that the above properties are present in the final implementation. The approach is based on the tenet that the design is divided into multiple layers. The critical functions and data make up the bottom layer, where the requirements for integrity, security, and safety are most rigid. Certification is dependent on the use of formal methods to specify and analyze the system. Appropriate formal methods are required to support certification that multiple properties are present in the final implementation. These methods must assure a rigid mapping from the <b>top-level</b> <b>specification</b> down through the implementation details. Application of a layered architecture reduces the scope of the design that must be formally specified and analyzed. This paper describes a generic, layered architecture and a formal model for specification and analysis of complex systems that require rigid integrity security, and safety properties...|$|R
40|$|A {{major problem}} in verifying the {{security}} of code is that the code’s large size makes it much too costly to verify in its entirety. This paper describes a novel and practical approach to verifying the security of code which substantially reduces the cost of verification. In this approach, a compact security model containing only information needed to reason about the security properties of interest is constructed and the security properties are represented formally {{in terms of the}} model. To reduce the cost of verification, the code to be verified is partitioned into three categories and only the first category, which is less than 10 percent of the code in our application, requires formal verification. The proof of the other two categories is relatively trivial. Our approach was developed to support a Common Criteria evaluation of the separation kernel of an embedded software system. This paper describes 1) our techniques and theory for verifying the kernel code and 2) the artifacts produced, that is, a <b>Top-Level</b> <b>Specification</b> (TLS), a formal statement of the security property, a mechanized proof that the TLS satisfies the property, the partitioning of the code, and a demonstration that the code conforms to the TLS. This paper also presents the formal basis for the argument that the kernel code conforms to the TLS and consequently satisfies the security property...|$|R
40|$|Programmable Logic Controllers (PLC) and its {{programming}} standard IEC 61131 - 3 {{are widely}} used in embedded systems for the industrial automa-tion domain. We propose a framework for the formal treatment of PLC based on the IEC 61131 - 3 standard. A PLC system description typically combines code written in different languages that are defined in IEC 61131 - 3. For the <b>top-level</b> <b>specification</b> we regard the Sequential Function Charts (SFC) language, a graphical high-level language that allows to describe the main control-flow of the system. In addition to this, we describe the Instruction List (IL) language – an assembly like language – and two other graphical languages: Ladder Diagrams (LD) and Function Block Diagrams (FBD). IL, LD, and FBD are used to describe more low level structures of a PLC. We formalize the semantics of these languages and describe and prove relations between them. Formalization and associated proofs are carried out using the proof assistant Coq. In addition to this, we present work on a tool for automatically generating SFC representations from a graphical description – the IL and LD languages can be handled in Coq directly – and its usage for verification purposes. We sketch possible usages of our formal framework, and present an example application for a PLC in a project demonstrator and prove safety properties. ...|$|R
5000|$|The vRS was the <b>top-level</b> and quickest <b>specification</b> {{and used}} a 1.8-litre straight-4 {{turbocharged}} engine which produced [...] Škoda made {{a limited number of}} 100 WRC Replica Cars worldwide in 2002. These differ from normal vRS Octavias, as they are produced in white, have rally decals and have additional accessories as standard (such as ESP, xenon lights, heated front seats).|$|R
40|$|This paper {{presents}} AiResearch {{experience to}} date in using the NASA/Boeing Application Generator (AG) to develop real-time control systems for the Carbon Dioxide Removal Assembly (CDRA) in Work Package 01. The AG provides an integrated design and development tool encompassing: system analysis, modeling, control law design, simulation, code generation, real-time hardware-in-the-loop simulation and operation, and documentation. This allows rapid interactive prototyping of real-time control systems in a single, integrated, environment. Advantages and disadvantages of using the AG for real-time control system development will be addressed, with the CDRA specification to delivery cycle serving {{as a basis for}} discussion. Suggestions for improving the AG are offered and observations on its potential as a <b>top-level</b> system <b>specification</b> tool are made...|$|R
40|$|The paper {{presents}} a RFDSCA automated synthesis procedure. This algorithm determines several RFDSCA circuits from the <b>top-level</b> system <b>specifications</b> {{all with the}} same maximum performance. The genetic synthesis tool optimizes a fitness function proportional to the RFDSCA quality factor and uses the epsiv-concept and maximin sorting scheme to achieve a set of solutions well distributed along a non-dominated front. To confirm {{the results of the}} algorithm, three RFDSCAs were simulated in SpectreRF {{and one of them was}} implemented and tested. The design used a 0. 25 mum BiCMOS process. All the results (synthesized, simulated and measured) are very close, which indicate that the genetic synthesis method is a very useful tool to design optimum performance RFDSCAs...|$|R
40|$|Design {{capability}} indices {{provide a}} metric {{to assess the}} capability {{of a family of}} designs, represented by a range of <b>top-level</b> design <b>specifications,</b> to satisfy a ranged set of design requirements. Design capability indices can be used to manage design freedom {{in the early stages of}} the design process when design requirements for a system may be uncertain. To illustrate the use of design capability indices, the design of a family of General Aviation aircraft is presented: design capability indices are used to simultaneously design a family of three aircraft around a two, a four, and a six seater configuration. The results are compared against two of our previous studies. 1 PROBLEM OVERVIEW There are many sources of variability in the early stage...|$|R
40|$|This paper {{describes}} the <b>top-level</b> requirements and <b>specifications</b> of the CMS Computing Model, {{and the associated}} costs. It was prepared primarily for the LHCC review of Computing Resources of January 2005 but will {{also be used as}} input to the CMS and LCG Computing TDR’s, due for submission in the Summer of 2005. The primary focus is the first year of LHC physics running but approximate estimates of the cost evolution are also given...|$|R
40|$|For robust design it is {{desirable}} to allow the design requirements to vary within a certain range rather than setting point targets. This is particularly important {{during the early stages}} of design when {{little is known about the}} system and its requirements. Toward this end, design capability indices are developed in this paper to assess the capability of a family of designs, represented by a range of <b>top-level</b> design <b>specifications,</b> to satisfy a ranged set of design requirements. Design capability indices are based on process capability indices from statistical process control and provide a single objective, alternate approach to the use of Taguchi's signal-to- noise ratio which is often used for robust design. Successful implementation of design capability indices ensures that a family of designs conforms to a given ranged set of design requirements. To demonstrate an application and the usefulness of design capability indices, the design of a solar powered irrigation system is presented. Our focus in this paper is on the development and implementation of design capability indices as an alternate approach to the use of the signal-to-noise ratio and not on the results of the example problem, per se...|$|R
