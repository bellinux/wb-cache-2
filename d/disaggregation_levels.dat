14|49|Public
50|$|HBEFA (the {{so-called}} “public version”) {{is available}} for download for everyone (chargeable at a fee of 250 EUR for new users). This public version allows users to view emission factors at different <b>disaggregation</b> <b>levels.</b> For selected experts participating {{in the development of}} HBEFA an extended version with additional features (referred to as “expert version”) is available.|$|E
40|$|For poverty {{monitoring}} and evaluation, one needs poverty estimates at the different <b>disaggregation</b> <b>levels.</b> The prediction of poverty trend is also {{of interest for}} policy makers as well as researchers. This paper presents a method â {{that is based on}} a small area estimation method of Elbers et al. (2003) â to project a map of disaggregated poverty measures in the future. This method is applied to project a poverty map in rural Vietnam for the year 2008 using the 2006 Rural, Agricultural and Fishery Census and the 2004 and 2006 Vietnam Household Living Standard Surveys. Poverty measurement Poverty projection Poverty mapping Vietnam...|$|E
40|$|WP 02 / 1999; The aim of {{this paper}} is an {{analysis}} of the technology transfers from Cnr Institutes of Turin Research Area to the subjects that could get benefits in the 1995 -' 97 period. Using the Cnr final budget, two statistical <b>disaggregation</b> <b>levels</b> were applied on the basis of data contained in internal documents of the Institutes to find out actions and subject's typologies. From this analysis of this period a substantial growth in self-financing of the Institutes was found; this is mostly due to an increase in calibration and testing activities, homologation of farm machinery and research activity under contracts with European Community and public administration...|$|E
40|$|The aim of {{this paper}} is to assess {{inflation}} forecasting acurracy over the short-term horizon using Consumer Price Index (CPI) disaggregated data. That is, aggregating forecasts is compared with aggregate forecasting. In particular, three questions are addressed: i) one should bottom-up or not, ii) how bottom one should go and iii) how one should model at the bottom. In contrast with the literature, di erent levels of data dis-aggregation are allowed, namely a higher <b>disaggregation</b> <b>level</b> than the one considered up to now. Moreover, both univariate and multivariate models are considered, such as SARIMA and SARIMAX models with dynamic common factors. An out-of-sample forecast comparison (up to twelve months ahead) is done using Portuguese CPI dataset. Aggregating the forecasts seems to be better than aggregate forecasting up to a five-months ahead horizon. Moreover, this improvement increases with the <b>disaggregation</b> <b>level</b> and the multivariate modelling outperforms the univariate one in the very short-run. ...|$|R
40|$|This paper {{provides}} an empirical {{investigation of the}} cohesion versus growth tradeoff on European regions at a fine geographical <b>disaggregation</b> <b>level.</b> We use data on gdp per capita at the nuts 3 level for 1980 - 2000 to estimate the influence of income dispersion within nuts 1 on their economic growth. There is strong evidence that greater spatial disparities foster growth, at least for Northern regions. Classification JEL : R 11. ...|$|R
40|$|Very {{preliminary}} draft This paper provides an empirical {{investigation of the}} cohesion versus growth tradeoff on European regions at a fine geographical <b>disaggregation</b> <b>level.</b> We use data on gdp per capita at the NUTS 3 level for 1980 - 2000 to estimate the influence of income dispersion within NUTS 1 on their economic growth. There is strong evidence that greater spatial disparities foster growth, at least for Northern regions. Finally, an increase in market potential, as expected, has an unambiguous positive impact on local growth...|$|R
30|$|All {{these models}} {{have the same}} energy {{calculation}} engine which is the BREDEM (Building Research Establishment Domestic Energy Model) modified to varying degrees. The <b>disaggregation</b> <b>levels</b> vary significantly amongst the seven models. The transparency of models in terms of data sources and model structures is recognised by most authors as a crucial issue for the future deployment of the models. Furthermore, no access is available to the raw input data and core calculation algorithms of almost all the models, including the modified BREDEM-type modules (Kavgic et al. 2010; Natarajan and Levermore 2007). Except for EEP all other models, these tools lack {{the ability to be}} used by stakeholders for implementation of policy or initiatives.|$|E
40|$|This paper {{analyses}} {{the impact}} of human capital composition on regional catch-up for Spain over the period 1960 – 1997. Empirical evidence shows that human capital has a non-linear impact on convergence at both NUTS- 2 and NUTS- 3 geographical <b>disaggregation</b> <b>levels.</b> Tertiary ducation drives regional catch-up, while the accumulation of non-technical education slows down this convergence. When one controls for the development stage of the regions, strong complementarities seem to arise between different types of skills. When closer to the frontier, the complementarities between tertiary education and secondary/vocational training drive the convergence process, while {{the impact of}} intermediate education is weak for regions at lower development stages. JRC. J. 2 -Knowledge for Growt...|$|E
40|$|International audienceIn {{this paper}} we analyze {{the impact of}} human capital {{composition}} on regional economic catch-up for Spain over the period 1960 - 1997. Empirical evidence shows that human capital has a non-linear impact on convergence at both NUTS 2 and NUTS 3 geographical <b>disaggregation</b> <b>levels.</b> Tertiary education drives regional catch-up while the accumulation of non-technical education slows down this convergence. When we control for the development stage of the regions, strong complementarities seem to arise between different types of skills. Closer to the frontier, tertiary education and secondary/vocational training drive the convergence process while the impact of intermediate education is weak for regions at lower development stages. Results are robust to different specifications and when we tackle endogeneity by applying efficient two-step system-GMM estimators and correcting for small sample biases...|$|E
30|$|Although the ESWB are {{compelling}} {{from the}} country coverage point of view, the number of observations per country is usually small. Typically between 1200 and 1800 establishments are interviewed in large economies, 360 in medium-sized economies and 150 in small economies. While representative pictures of the aggregates can be computed by using the provided population weights, the dataset is somehow limited to construct representative measures at a high <b>disaggregation</b> <b>level.</b> This is why we take the country-level regressions as our preferred specifications, and carry out some country-(broadly defined) sector analysis as a robustness exercise.|$|R
40|$|This paper {{presents}} the model GreenMod and an application regarding {{the impacts of}} the carbon taxes on the three Belgian regions (Brussels, Flanders and Wallonia). GreenMod is a modelling platform for regional and sectoral analysis for energy and environmental issues. The current version is a recursively dynamic CGE model with imperfect competition, increasing returns to scale, and a detailed <b>disaggregation</b> <b>level</b> of the households, the firms, and the government. We decide that carbon taxes alone are not sufficient in achieving the Kyoto targets at both regional and federal levels. Furthermore, our results indicate that carbon taxes have an adverse effect on income distribution...|$|R
40|$|We built a model analyzing, through {{cross-section}} estimation methods, {{the influence}} of spatial effects in the conditional product convergence in the parishes’ economies of mainland Portugal between 1991 and 2001 (the last year with data available for this spatial <b>disaggregation</b> <b>level).</b> Taking into account the estimation results, it is stated {{that there are not}} indications of convergence (the population is in the littoral of Portugal) and {{it can be seen that}} spatial spillover effects, spatial lag (capturing spatial autocorrelation through a spatially lagged dependent variable) and spatial error (capturing spatial autocorrelation through a spatially lagged error term) condition the convergence of product of Portuguese parishes in the period under consideration. ...|$|R
30|$|In addition, Table 8 permits an {{explicit}} comparison between estimates of model (11) estimated at the bank-loan level and {{estimates of the}} same coefficients on a bank-industry sample. The estimates in the top panel—obtained in a sample that matches banks and firms—are remarkably {{similar to those in}} the bottom panel—obtained in a sample that matches banks and industries sample. The robustness of the estimates across <b>disaggregation</b> <b>levels</b> and estimation methods confirms that banks exposed to real estate developers {{at the beginning of the}} boom shifted inward their credit supply curve, holding borrower’s quality constant. More generally, the invariance of results across samples does suggest that bank-industry data goes a long way in detecting bank balance sheet effects. This is an important result, as bank-level data is typically the only information available in countries that lack comprehensive credit registers.|$|E
40|$|CGEMs {{are one of}} {{the most}} {{potentially}} powerful tools for simulating policies. However, a major restriction they face is them needing a huge number of parameters that are not always available, and even at times impossible to obtain. When CGEMs are applied to trade, Armington elasticities of substitution are one of those key sets. The common practice among CGEMs builders has been to impose these values, either at will or by using those stemming from other existing research. There is general consensus, however, that econometrically estimated parameters for each case study would substantially improve the robustness of results. Unfortunately, most of the so obtained elasticities are considered underestimates of both the real and theoretically expected parameters. This gave rise to a growing concern on the eventual role played by methodological and empirical issues in this matter. There are some findings that have generated a quite general consensus among researchers, related to the type of datasets used; the <b>disaggregation</b> <b>levels</b> at which goods are defined and the origins of imported varieties are considered; the frequency of data; among others. ...|$|E
40|$|This paper {{analyzes}} {{the changes in}} the energy consumption of the service sector in France over the period 1995 - 2006, using the logarithmic mean Divisia index I (LMDI I) decomposition method. The analysis is carried out at various <b>disaggregation</b> <b>levels</b> to highlight the specifics of each sub-sector and end-use according to their respective determinants. The results show that in this period the economic growth of the service sector was the main factor that led to the increase in total energy consumption. Structure, productivity, substitution and intensity effects restricted this growth, but with limited effect. By analyzing each end-use, this paper enables a more precise understanding of the impact of these factors. The activity effect was the main determinant of the increase in energy consumption for all end-uses except for air conditioning, for which the equipment rate effect was the main factor. Structural changes in the service sector primarily impacted energy consumption for space heating and cooking. Improvements in productivity limited the growth of energy consumption for all end-uses except for cooking. Finally, energy efficiency improvements mainly affected space-heating energy use. Energy demand Service sector Decomposition analysis...|$|E
40|$|Hierarchical aggregation/disaggregation of {{time series}} {{in order to}} make {{forecasts}} is a frequent challenge in business and econometric scenarios. This work presents a novel approach for selecting an adequate time series <b>disaggregation</b> <b>level</b> {{as a starting point for}} making forecasts. The methodology combines qualitative criteria - such as business resources and decision environment - and quantitative criteria - such as information quality and forecastability - in a multicriteria decision making task which is addressed through the analytic hierarchy process (AHP) technique. Results from a study case in a subscription business model company show the usefulness of combining AHP and time series forecasting techniques and the importance of multicriteria decision-making in the task of selecting an adequate aggregation/disaggregation level...|$|R
40|$|This paper {{provides}} detailed {{empirical evidence}} on the scope of mismatch in Germany in the past decade, using a comprehensive administrative data set that allows for <b>disaggregation</b> at the <b>levels</b> of industry, occupation and region. The findings suggest that regional mismatch did not {{play an important role}} in explaining movements of aggregate unemployment. Across industries and occupations, there was a decrease in mismatch unemployment from over 5 percent to below 4 percent (on the highest <b>disaggregation</b> <b>level),</b> whereas the share of mismatch unemployment (across industries and occupations) within total unemployment remains almost unchanged between 2000 and 2010. Concluding, mismatch unemployment fell but the Hartz reforms did not reduce mismatch overproportionally compared with search frictions, in line with the fact that reallocation across occupations appears not to have been eased. In diesem Papier wird das Ausma der Mismatch-Arbeitslosigkeit mittels eines umfangreichen administrativen Datensatzes, durch welchen Industrien, Berufe und Regionen in unterschiedlichen Disaggregationsstufen analysiert werden k 6 nnen, quantifiziert. Regionaler Mismatch spielt eine untergeordnete Rolle f die Entwicklung der Arbeitslosenquote in Deutschland. Auf Industrie- und Berufsebene kann festgestellt werden, dass die Mismatch-Arbeitslosenquote von 5...|$|R
40|$|The aim of {{this paper}} is to assess {{inflation}} forecast acurracy over the short-term horizon, using Consumer Price Index (CPI) disaggregated data, through a bottom-up approach. That is, aggregating forecasts is compared with aggregate forecasting. A new dimension to the question of to bottom-up or not is introduced by considering different <b>levels</b> of data <b>disaggregation,</b> namely a higher <b>disaggregation</b> <b>level</b> than the one considered up to now. This raises modelling issues that one has to cope with. In particular, it is suggested the use of a new strand of models, the Factor-Augmented SARIMA models. Considering as case-study the Por-tuguese one, we find an inverse relationship between the forecast horizon and the amount of information underlying the forecast, when minimizing the RMSFE...|$|R
30|$|The {{convergence}} {{debate was}} started by Abramovitz (1986), Baumol (1986), Dollar and Wolff (1988), Dollar (1993), Barro and Sala i Martin (1992), Quah (1993, 1996), O’Leary (1997) and Doyle and O’Leary (1999), and has continued ever since. Most of the studies on this issue have tested the convergence separately between countries, regions and industries and have reached different conclusions. For example, some studies found {{a greater degree of}} convergence at the aggregate (country) level than at the disaggregate (regions and industry) level, while others have found the opposite. For instance, Sondermann (2014) found no convergence at the aggregate level but did find strong evidence of convergence at the disaggregate level for some sectors. Conversely, Bernard and Jones (1996) found convergence at the aggregate level but not at the disaggregate. Furthermore, the results of productivity convergence at different <b>disaggregation</b> <b>levels</b> of sectors and NUTS (Nomenclature of Units for Territorial Statistics) also differ from one study to another. 4 The speed of convergence could also be different because of heterogeneity in labour productivity at different levels of aggregation. For example, in the case of EU economies, regions are more integrated than countries and industries. Therefore, one can expect to find a different speed of convergence across countries, regions and industries. Since there are a much larger number of regional borders than a number of national borders in EU economies, this might be the reason for having different speeds of convergence across different levels. Therefore, the current study will extend the analysis of productivity convergence at all three levels: countries, regions and industry simultaneously.|$|E
40|$|The Multiplicative Discrete Random Cascade (MDRC) {{class of}} model {{is used to}} {{temporally}} disaggregate rainfall volumes through multiplying the volumes by random weights, which is repeated through multiple <b>disaggregation</b> <b>levels.</b> The model development involves the identification of probability density functions from which to sample the weights. The parameters of the probability density functions {{are known to be}} dependent on the rainfall volume. This paper characterises the volume dependency over the scarcely observed extreme ranges of rainfall, introducing the concept of volume-bounded MDRC models. Probable maximum precipitation (PMP) estimates are used to define theoretically-based points and asymptotes to which the observation-based estimates of the MDRC model parameters are extrapolated. Alternative models are tested using a case study of rainfall data from Brisbane, Australia covering the period 1908 to 2015. The results show that moving from a baseline model with constant parameters to incorporating the volume dependency of the parameters is essential for acceptable performance in terms of the frequency and magnitude of modelled extremes. As well as providing better estimates of parameters at each disaggregation level, the volume dependency provides an in-built bias correction when moving from one level to the next. A further, relatively small performance gain is obtained by extrapolating the observed dependency to the theoretically-based bounds. The volume dependency of the parameters is found to be reasonably time-scaleable, providing opportunity for advances in the generalisation of MDRC models. Sensitivity analysis shows that the subjectivities and uncertainties in the modelling procedure have mixed effects on the performance. A principal uncertainty, to which the results are sensitive, is the PMP estimate. Therefore, in applications of the bounded approach, the PMP should ideally be described by a probability distribution function...|$|E
40|$|We {{previously}} {{developed a}} spatially explicit, individual-based model (IBM) evaluating the bio-economic efficiency of fishing vessel movements between regions {{according to the}} catching and targeting of different species based on the most recent high resolution spatial fishery data. The main purpose was to test the effects of alternative fishing effort allocation scenarios related to fuel consumption, energy efficiency (value per litre of fuel), sustainable fish stock harvesting, and profitability of the fisheries. The assumption here was constant underlying resource availability. Now, an advanced version couples the vessel model to selected size-based population models and considers the underlying resource dynamics in the distribution and density patterns of the targeted stocks for the cases of Danish and German vessels harvesting the North Sea and Baltic fish stocks. The stochastic fishing process includes direct and local depletion by stock that is specific to the vessel catching power, which {{is proportional to the}} encountered size-based population on the visited ground and is based on stock assessment and research survey data. The impact of the potential fishing effort displacement by vessels on the fish stocks, with resulting fishing mortality, and the vessels’ economic consequences are evaluated on high spatial and seasonal <b>disaggregation</b> <b>levels</b> by simulating different individual choices of vessel speed, fishing grounds and ports. All tested scenarios led to increased overall energy efficiency, except for the fishing closures that increased fuel consumption and costs for most of the vessels due to increased travel distance. On an individual scale, the simulations led to gains and losses due to either the technical interactions between vessels exploiting the same stocks or to the alteration of individual fishing patterns. We demonstrate that integrating the spatial activity of vessels and local fish stock abundance dynamics allow for interactions and more realistic predictions of fishermen behaviour, revenues and stock abundance...|$|E
40|$|This study analyses, through {{cross-section}} estimation methods, {{the influence}} of spatial effects in the conditional product convergence in the parishes' economies of mainland Portugal between 1991 and 2001 (the last year with data available for this spatial <b>disaggregation</b> <b>level).</b> To analyse the data, Moran's I statistics is considered, and it is stated that product is subject to positive spatial autocorrelation (product develops {{in a similar manner}} to product in neighbouring regions). Taking into account the estimation results, it is stated that there are not indications of convergence (the population is in the littoral of Portugal) and {{it can be seen that}} spatial spillover effects, spatial lag (capturing spatial autocorrelation through a spatially lagged dependent variable) and spatial error (capturing spatial autocorrelation through a spatially lagged error term) condition the convergence of product of Portuguese parishes in the period under consideration (1) (Martinho, 2011) ...|$|R
40|$|Abstract: Armington elasticities {{are a key}} {{parameter}} {{in applied}} general equilibrium models, more so in those models used to analyze free trade agreements and other trade related issues. However, frequently only educated guesses, or extrapolated figures, are used to run the models, and Mexico {{has not been an}} exception. In this paper, given {{the quantity and quality of}} available data from the Mexican Statistics Institute, we consider the Maximum Entropy approach to be a suitable tool to estimate such elasticities for Mexico. Using annual time series from 1988 to 2004, we estimate the Armington elasticities using the 72 Activities <b>disaggregation</b> <b>level</b> of the System of National Accounts of Mexico (SNAM). Specifically, we use three main model specifications to estimate short run and long run elasticities. The first model is just the simplest regression in levels, while the second one is a partial adjustment model, and the third one an error correction mechanism model...|$|R
40|$|This paper {{provides}} an empirical {{investigation of the}} cohesion versus growth tradeoff on European regions at a fine geographical <b>disaggregation</b> <b>level.</b> We use data on gdp per capita at the NUTS 3 level for 1980 - 2000 to estimate the influence of income dispersion within NUTS 1 on their economic growth. We analyze {{the existence of the}} tradeoff using Redding and Venables'(2004) approach. From a simple new economic geography model in which we add a technological externality in order to allow for local growth, we derive an estimable equation linking the level of factor prices in a region to the level of inequalities inside that region, as well as the region's access to markets. Our results show a positive relation between the gdp per capita growth rate of a region and the change in the level of inequalities inside the region. Finally, an increase in market potential, as expected, has an unambiguous positive impact on local growth...|$|R
40|$|DaCoTA was a Collaborative Project {{under the}} European Seventh Framework Programme that {{aimed to develop}} tools and methodologies to support road safety policy and further extend and enhance the European Road Safety Observatory (ERSO). One of the Work Packages in DaCoTA, WP 6, focused on the {{usefulness}} and feasibility of applying the Naturalistic Driving method for collecting comparable information about the road safety level in EU Member States and its development over time. The current Deliverable was prepared in this framework and gives {{an overview of the}} aspects {{to be taken into account}} when implementing ND research for monitoring purposes. Naturalistic Driving (ND) Naturalistic Driving (ND) can be defined as “A study undertaken to provide insight into driver behaviour during every day trips by recording details of the driver, the vehicle and the surroundings through unobtrusive data gathering equipment and without experimental control”. Typically, in an ND study passenger cars, preferably the subjects' own cars, are equipped with several small cameras and sensors. These devices continuously and inconspicuously register vehicle manoeuvres (like speed, acceleration/deceleration, direction, location), driver behaviour (like eye, head and hand manoeuvres), and external conditions (like road, traffic and weather characteristics). ND for monitoring purposes ND data can, among other things, be used to establish how often drivers routinely are exposed to or engaged in certain situations/behaviours that are known to increase the risk of a crash. This includes monitoring safety-relevant behaviour (Safety Performance Indicators - SPIs) and mobility (Risk Exposure Data — RED). An important reason for monitoring road safety and comparing road safety levels and their developments over time in different countries is benchmarking. It allows countries to determine their relative position in comparison to other selected countries, to understand differences and find ways and get motivated to improve their position. Obviously, monitoring road safety also allow countries to evaluate their own road safety policy and road safety targets. ND is considered a promising approach for collecting reliable and comparable information about various RED and SPIs, as well as several relevant context variables. The main advantage of the ND approach for monitoring purposes as compared to the more traditional SPI data collection methods, such as road-side surveys and questionnaires, is that ND ensures continuous, automatic and standardized data collection. Provided that similar data acquisition systems and methods are applied in all participating cars, this approach substantially increases international comparability and level of detail. Though the current Deliverable is purely focused on road safety and exposure data, the collected data will also be useful for other transport areas, in particular eco-driving and traffic management. Three data collection scenarios Depending on the variable of interest, ND data collection needs different technologies ranging from simple and relatively cheap data acquisition systems to more sophisticated systems with several sensors as well as several videos covering the inside of the car and various directions outside the car. By combining the RED and SPIs of interest and the technological requirements for collecting that type of data, we distinguish three scenarios to collect meaningful data within reasonable limits of cost and complexity. It is recommended to start off with Scenario 1 : a low-cost simple, off-the-shelf simple data acquisition system (e. g. an OBD GPS tracker or a Smart Phone) and a limited number of additional sensors, measuring: * Vehicle kilometres * Person kilometres * Number of trips * Time in traffic * Speed * Seat belt use * Light use In a later stage, additional SPIs and network characteristics could be added successively (Scenario 2), including: * Time headway * Acceleration * Lane departures * Inappropriate speed * Signal use * Junction type SPIs that would need continuous external and/or internal video recordings do not seem to be feasible in the short term, because this results in huge amounts of data and very high costs for the related data transfer and data coding. That means that the SPIs like fatigue, inattention, distraction and the (proper) use of child restraints can currently not be monitored by means of ND research. Technical developments may allow reconsideration of this conclusion in due time. Furthermore, it is recommended to equip a limited number of cars also with an event-triggered video in order to monitor numbers of near crashes as yet another relevant SPI (Scenario 3). As a very useful side product, this effort will provide data that can be used to further specify and refine the quantitative and qualitative relationship between near crashes and real crashes. Study design and organisational issues In principle, the techniques and procedures for ND data collection, data transfer, data storage and data analysis are available and not too complicated. In order to get reliable information, a fairly large sample is needed. The exact size of the sample depends on the variation in behaviour in the population and the required level of precision of the results. Assuming that the sample is drawn in a cleverly stratified way, resulting in a number of mutually exclusive and homogeneous subgroups (e. g. based on gender and age), a sample of around 10, 000 drivers per country seems to be required for RED such as the annual amount of vehicle kilometres. This number is usually independent of the size of the population of car drivers in a country. Only if the sample size is larger than 10 % of the population, a correction is applicable. It is recommended to collect data throughout the year on a continuous basis and to follow each individual in the sample for one year, applying a rotating scheme of 50 % per 6 months. Analyses are best performed at a national level, applying a series of definitions on variables and <b>disaggregation</b> <b>levels</b> and following fixed analysis protocols. It could be considered to identify a limited number of ‘core’ variables (SPIs/RED) to be analysed at a central/ERSO level to ensure exact comparability. Participation in ND research is per definition on a voluntary basis and experiences in the USA and Europe have shown that it is requires special attention to find sufficient suitable participants, especially if there are strict sample stratification requirements. In addition, there are legal and ethical issues involved in ND research, in particular in the area of privacy and data protection. Exploring Scenario 4 In parallel to the implementation of the previous three scenarios, it is recommended to start exploring the possibility of a Scenario 4 now, i. e. a scenario where relevant data is extracted directly from the vehicle via CAN-bus, OBD, and other trip and travel data collected automatically by the vehicle. In theory, that way a lot of relevant information is already available with no or little additional costs; in practice, however, the information is not generally accessible nor comparable between car makes and models. So, this is a scenario that cannot be realised overnight. One of the first steps, in consultation with the car manufacturers, is an elaboration of the requirements for this data: what is available, what is needed, what is technically feasible. A central role for the EC Since harmonisation and international comparability of data are the key reason for this effort, there is a central role for the European Commission in initiating this task and taking the lead from here, most likely within the ERSO framework. A stepwise approach is recommended, including successively: 1. Creating support and finding budget by presenting the case to the relevant road safety bodies at European and Member State level, explaining the need for harmonised, comparable international data, the ND approach, and its added value. 2. Preparing a detailed description of / handbook for all practical implementation aspects, including the functional specifications of data collection equipment, participant selection, data transfer and storage, as well as definitions of variables, <b>disaggregation</b> <b>levels</b> and analyses. 3. Identifying the relevant national organisations which will be responsible for national data collection and pre-analyses, and fine-tuning data collection procedures (including legal aspects) and variable definitions in consultation with them. 4. Developing and equipping a database at EU level and defining the required (pre-analysed aggregated) data to be provided by the Member States as well as the procedures and time schedule, in consultation with the relevant national organisations. 5. Setting up European-wide communication strategies to guarantee maximum dissemination and use of the collected data. 6. Setting up one year national pilots in at least four Member States, well spread of Europe (North, West, South, East). 7. Adapting procedures and definitions, based on the pilot experiences. 8. Successive implementation of Scenario 1 in additional Member States. Parallel to steps 6 and 7, Scenario 2 (additional SPIs/RED) and 3 (monitoring nearcrashes) can be elaborated, piloted and implemented, applying a similar stepwise process. From the very beginning, the EC is advised to initiate discussions with the car manufacturers, using existing discussion platforms, with the aim to explore longer term possibilities of Scenario 4, i. e. the scenario where relevant data is extracted directly from the vehicle. (Author/publisher...|$|E
40|$|WP 6 of DaCoTA, Driver Behaviour Monitoring through Naturalistic Driving, {{focuses on}} the {{usefulness}} and feasibility of applying the Naturalistic Driving method for monitoring {{within the framework of}} ERSO. The aim is to continuously collect comparable information about the road safety level in EU Member States and its development over time. Naturalistic Driving methods are intended to gather data that represent the behaviour of the population of drivers in its basic state. Naturalistic Driving (ND) study can be defined as: ‘A study undertaken to provide insight in driver behaviour during every day trips by recording details of the driver, the vehicle and the surroundings through unobtrusive data gathering equipment and without experimental control’ Typically, in an ND study passenger cars are equipped with small sensors. These devices continuously and inconspicuously register vehicle manoeuvres (like speed, acceleration/deceleration, direction, location), driver behaviour (like eye, head and hand manoeuvres), and external conditions (like road, traffic and weather characteristics). ND for monitoring purposes ND data can be used to establish how often drivers routinely are exposed to or engaged in certain situations/behaviours that are known to increase the risk of a crash. This includes monitoring safety-relevant behaviour (Safety Performance Indicators - SPIs) and mobility (Risk Exposure Data — RED). Benchmarking is an important reason for monitoring road safety and comparing road safety levels and their developments over time. It allows countries to determine their relative position in comparison to other countries, to understand differences and find ways and get motivated to improve their position. Obviously, monitoring road safety also allow countries to evaluate their own road safety policy and road safety targets. ND is considered a promising approach for collecting reliable and comparable information about various RED and SPIs, as well as several relevant context variables. The main advantage of the ND approach for monitoring as compared to the more traditional SPI data collection methods, such as road-side surveys and questionnaires, is that ND ensures continuous, automatic and standardized data collection. This approach substantially increases international comparability and level of detail. Though the current Deliverable is purely focused on road safety and exposure data, the collected data will also be useful for other transport areas, in particular eco-driving and traffic management. Three data collection scenarios Depending on the variable of interest, ND data collection needs different technologies ranging from simple data acquisition systems to more sophisticated systems with several sensors and several videos. By combining the RED and SPIs of interest and the technological requirements for collecting that type of data, we distinguish three scenarios to collect meaningful data within reasonable limits of cost and complexity. It is recommended to start off with Scenario 1 : a low-cost simple, off-the-shelf simple data acquisition system (e. g. an OBD GPS tracker or a Smart Phone) and a limited number of additional sensors, basically measuring RED and speed. At a later stage, successively additional sensors could be added to measure more advanced SPIs and network characteristics (Scenario 2). SPIs that would need continuous video recordings {{do not seem to be}} feasible for monitoring purposes, because of huge amounts of data and high costs of data transfer and coding. That means that the SPIs like fatigue, inattention and distraction can currently not be monitored by means of ND research. Technical developments may allow reconsideration of this conclusion in due time. It is recommended to equip a limited number of cars also with an event-triggered video in order to monitor numbers of near crashes as yet another relevant SPI (Scenario 3). Study design and organisational issues In principle, the techniques and procedures for ND data collection, transfer, storage and analysis are available and not too complicated. In order to get reliable information, a fairly large sample is needed. The exact size of the sample depends on the variation in behaviour in the population and the required level of precision of the results. Assuming that the sample is drawn in a cleverly stratified way a sample of around 10, 000 drivers per country seems to be required for RED such as the annual mobility. This sample size is independent of the size of the country. Only if the sample size is larger than 10 % of the population, a correction is applicable. Participation in ND research is per definition on a voluntary basis and past experiences have shown that it requires special attention to find sufficient suitable participants. There are legal and ethical issues involved in ND research, in particular in the areas of privacy and data protection. Exploring Scenario 4 In parallel to the implementation of the previous three scenarios, it is recommended to start exploring the possibility of a Scenario 4 now, i. e. a scenario where relevant data is extracted directly from systems built-in by the vehicle manufacturers. In theory, that way a lot of relevant information is already available with no or few additional costs; in practice, however, the information is not generally accessible nor comparable between car makes. So this is a scenario that cannot be realised overnight. One of the first steps, in consultation with the car manufacturers, is an elaboration of the requirements for this data: what is available, what is needed, what is feasible. A central role for the EC Since harmonisation and international comparability of data are the key reason for this effort, there is a central role for the European Commission in initiating this task and taking the lead from here, most likely within the ERSO framework. A stepwise approach is recommended, including successively: 1. Creating support and finding budget by presenting the case to the relevant road safety bodies at European and Member State level, explaining the need for harmonised, comparable international data, the ND approach, and its added value. 2. Preparing a detailed description of all practical implementation aspects, including the functional specifications of data collection equipment, participant selection, data transfer and storage, definitions of variables, <b>disaggregation</b> <b>levels</b> and analyses. 3. Identifying the relevant national organisations, responsible for national data collection and pre-analyses, and fine-tuning data collection procedures (including legal aspects) and variable definitions in consultation with them. 4. Developing and equipping a database at EU level and defining the required data to be provided and the procedures and time schedule, in consultation with the relevant national organisations. 5. Setting up European-wide communication strategies to guarantee maximum dissemination and use of the collected data. 6. Setting up one year national pilots in at least four Member States. 7. Adapting procedures and definitions, based on the pilot experiences. 8. Successive implementation of Scenario 1 in additional Member States. Parallel to steps 6 and 7, Scenario 2 (additional SPIs/RED) and 3 (monitoring nearcrashes) can be elaborated, piloted and implemented, applying a similar stepwise process. From the very beginning, the EC is advised to initiate discussions with the car manufacturers, using existing discussion platforms, with the aim to explore longer term possibilities of Scenario 4, i. e. the scenario where relevant data is extracted directly from the vehicle. (Author/publisher...|$|E
40|$|The aim of {{this study}} is to produce {{sensible}} forecasts for a number of combinations of classes such as age/gender, transport mode, road type, rush hour or not, and accident severity. The Mobility Explorer imposes a number of conditions which the traffic safety component has to satisfy. One of these conditions is the development of forecasts for combinations of classes of road users or traffic. The study started by investigating the <b>disaggregation</b> <b>level</b> made possible by the data. Attention has been paid to the reliability of the results. This has been done: (1) by comparing the observed numbers with the forecasted figures; and (2) by computing confidence intervals (a measure of reliability) for the forecasts, assuming the correctness of the applied model. Finally, it is described how to improve the measure of reliability: (i) by incorporating knowledge about the uncertainty in the mobility information; and (ii) by estimating the deviance of the used model from the 'true' model...|$|R
40|$|A dynamic energy-economic CGE {{model is}} used to analyse how {{sensitive}} simulation results are to alternative values assumed by several types of elasticity of substitution. Substitutability in the energy mix is analysed by {{taking into account the}} nest structure of the CGE model in the energy module. Input substitutability in the production function is tested for the relationship between capital and energy in different manufacturing sectors. The simulation exercise reveals that the model produces highly differentiated results when different sets of elasticity parameters are adopted. A reduction in the flexibility of energy substitution possibilities makes abatement efforts more expensive at the general level. Moreover, this restriction generates changes in the distribution of costs associated with abatement efforts across regions. The direct implication derived from this work is that in order to use CGE forecasting models to predict the costs and feasibility of climate policies, they must be integrated with empirically estimated behavioural parameters at the highest possible <b>disaggregation</b> <b>level.</b> sensitivity analysis; CGE model; elasticity of substitution; climate polic...|$|R
40|$|Recent {{research}} has analysed whether existing transportation networks affect interregional {{trade in goods}} in a spatial econometric model approach (LeSage and Polasek, 2008; Alamá-Sabater et al, 2012). Nonetheless, {{to the best of}} our knowledge, the previous research that has taken this approach does not deal with highly disaggregated regional trade data by disentangling the role of different types of transportation networks. This paper aims to cover this gap in the existing literature. In order to proxy the structure of the transportation network, data for trade flows between Spanish provinces (NUTS 3) 1 in the year 2007 are obtained, as well as data about the characteristics of the logistics platforms in each region. Previously, Alamá-Sabater et al (2012) provided evidence about the role of the location of logistics platforms in satisfying existing demand for transport structures at NUTS 2 spatial <b>disaggregation</b> <b>level,</b> as spatial and transportation network dependence plays a significant role in interregional trade flows. However, these authors only focused on the number and area of logistics platforms in each region to proxy the logistics facilities in contiguous regions...|$|R
40|$|<b>Disaggregation</b> at system <b>level</b> Integration at chip level Optical {{interconnection}} at shorter reach Electronics-photonics convergence Cost, {{energy and}} bandwidth density Architecture, components, programming Make it happen or end {{the information age}} © 2011 Scuola Superiore Sant’AnnaExample of application...|$|R
40|$|International audienceFreight {{statistics}} {{are at the}} core of many studies in the field of industrial ecology because they depict the physical inter-dependencies of territories and allow to link worldwide productions and consumptions,. Recent studies have been increasingly focusing on subnational scales, often relying on domestic freight data. In this perspective, this article analyses the uncertainties of the French domestic road freight survey, road being by far the most common mode of transport in the country. Based on a statistical analysis of the survey, we propose a model to estimate the uncertainty of any given domestic road transport flow. We also assess uncertainty reduction when averaging the flows over several years, and obtain for instance a 30 % reduction for a 3 -year average. We then study the impact of the uncertainties on regional material flow studies such as the Economy-Wide Material Flow Analysis of the Bourgogne region. Overall the case studies advocate for a systematic assessment of freight uncertainties, as neither the <b>disaggregation</b> <b>level</b> nor the quantities traded are good enough predictors. This justifies the need for an easy-to-implement estimation model. Finally, basic comparison with the German and Swedish surveys tend to indicate that the main conclusions presented in this article are likely to be valid in other European countries...|$|R
40|$|In this task, {{research}} is mostly finalised to analyse how EU {{policies have been}} distributed across space. Here, the main focus is on Common Agricultural Policy (CAP) expenditure. The same territorial detail adopted in previous tasks is used (i. e., NUTS 3 level). By analysing CAP expenditure at such a territorial <b>disaggregation</b> <b>level,</b> this work has specifically concentrated on rural, agricultural and environmental policies. Actually, specific CAP measures are directly aimed at tackling those issues. CAP also accounts for {{a large share of}} overall EU funds, and it represents one of major drivers of EU spatial development. The methodology of analysis is based on the reconstruction of allocation of EU funds across EU- 27 NUTS 3 regions. First, an exploratory analysis of the spatial allocation of CAP expenditure across Europe is assessed. Spatial allocation of CAP expenditure is considered by disentangling specific measures as well (e. g., Pillar One and Pillar Two expenditure, Direct Payment and Market Intervention Measures, Pillar Two 9 ̆ 2 s Axes 8 ̆ 5). Both absolute expenditure levels and expenditure intensity are computed here. Then, through a simple statistical analysis, the correlation between CAP expenditure at NUTS 3 level and regional features, in terms of both rurality and agricultural activity, is assessed...|$|R
40|$|This study investigates {{whether the}} current lack of {{structure}} of internal control weakness disclosures (a narrative about {{the reliability of}} the financial reporting system) leads nonprofessional investors to make differential investment decisions. Using the non-accelerated filer (smaller public company) setting, where nonprofessional investors are likely to consume unaudited internal control reports in their investing judgments and decisions, I examine two facets of internal control disclosure formats: presentation salience and disaggregation of material weaknesses. A 2 x 2 between-participants behavioral experiment was conducted with internal control presentation salience (bulleted vs. in-text) and <b>disaggregation</b> <b>level</b> (a single material weakness vs. a combination of multiple control deficiencies that is a material weakness). I find that nonprofessional investors reward companies that disclose internal control weaknesses more saliently. The results also indicate that disaggregation interacts with salience in that it increases the effect of salience on investing judgments such that salient (stealth) disclosure of a combination of control deficiencies is viewed more positively (negatively) than salient (stealth) disclosure of a material weakness. These findings are contrary to Rennekamp (2012) who finds that processing fluency in bad news leads to more negative investment judgements. Additional analyses indicated that the results related to management trust and credibility are consistent with prior literature. The findings contribute to academia and practice by shedding light on the importance that needs to be placed on the presentation format of internal control disclosures...|$|R
40|$|The {{automotive}} industry {{is one of}} the most important sectors for Polish total exports and imports in terms of value, as well as the factor of trade intensity trade. The paper is aimed at verifying the hypothesis according to which the sector covered in this research does not strengthen the capital intensity of Polish exports and fosters international division of labour between centres and semi-peripheries. Thus, the issues raised here are considered in the context of the middle income trap. The author analysed trade streams in Polish exports and imports through the changes in their structure, evolution of revealed comparative advantages (RCA), import penetration (IMP), revealed advantages in trade (RTA), trade balance and the level of intra-industry trade (IIT) together with an attempt to distinguish the shares of vertical and horizontal exchange. For the purpose of the research, data at the 4 - and 6 -digit <b>disaggregation</b> <b>level</b> of the Harmonised System were used. As a middle income country Poland is still an attractive location for foreign investments of multinational companies. However, it may preserve the developmental gap. This may be proven by the structure of the trade in the sector covered: cars and parts and accessories of motor vehicles are the most dominant sections, which is consistent with the level of revealed comparatives advantages and revealed advantages in trade. What is also worth noticing are the trade relations with Germany, where one can easily identify a technological dependency...|$|R
40|$|Although, {{by working}} {{to push the}} limits of the gaze, {{photography}} indirectly contributes to stimulating new paths for the garden, the elusive complexity of the garden reciprocally defies capture by the photograph. Landscape is a key concept for photography and for gardens. Referring to the hypertextuality made possible by new modes of computer communication, the notion of hyperlandscape suggests a gaze that examines the transience and apparent insignificance of things to extract new paths for creativity. When we plunge into the ubiquitous media, we are confronted with the growing <b>disaggregation</b> of <b>levels</b> of the reality; as with the hyperlink, something insignificant can open up to a universe...|$|R
40|$|This paper {{presents}} a comparative analysis of methods used in European countries to assess buildings’ condition. The following methods were compared: a Portuguese method to assess buildings condition, an English housing {{health and safety}} rating system, a French method to assess buildings that may be declared inhabitable, a Dutch standard about buildings condition assessment and the assessment methods developed within the European projects EPIQR & TOBUS. The comparative analysis included three tasks. First, each of the methods was described separately. Then, the main features of the methods were compared. Finally, some guidelines to improve the Portuguese method were drawn. The main differences of the methods are the objectives {{and scope of the}} assessment, the <b>disaggregation</b> <b>level</b> of the global assessment, the calculation formula used to aggregate partial assessments, the type final results obtained and the tools developed for their implementation. The main similarities are that the assessment is carried out mainly by visual inspection, the condition of the building is assessed by a systematic analysis of the entire building divided into functional elements, the severity of defects is the assessment criterion used, weighting coefficients are used to determine the importance of each partial assessment in the final result and surveyors need specific training. The recommendations about the Portuguese method are to maintain the present assessment model, to carry out the training courses of surveyors, to create a complementary tool for the diagnosis of the causes of defects and to develop a computer program to support surveyors during inspections. OTB ResearchOTB Research Institute for the Built Environmen...|$|R
