6|10000|Public
50|$|Finally, if {{the code}} had an {{asterisk}} next to it, a final FAC would {{be drawn to}} check for error. This was done by comparing the error range on the FAC to the <b>error</b> <b>rating</b> of the fielder. For example, if the fielder's <b>error</b> <b>rating</b> was E2 and the <b>error</b> <b>rating</b> on the FAC was F8 to F10, {{then there would be}} no error.|$|E
5000|$|The {{following}} table shows all the Qumran-related {{samples that}} were tested by Zurich (Z), Tucson (T) and Libby (L). The column headed [...] "14C Age" [...] provides a raw age before 1950 for each sample tested. This represents the ideal {{date for the}} amount of 14C measured for the sample. However, as the quantity of 14 absorbed by all life fluctuates from year to year, the figure must be calibrated based on known fluctuation. This calibrated range of dates is represented in the last column, given with a 2-sigma <b>error</b> <b>rating,</b> which means at 95% confidence. With the exception of the first text from Wadi-ed-Daliyeh, the texts in the table below are only those from the caves around Qumran. The table orders them chronologically, based on 14C age.|$|E
40|$|This {{research}} {{focuses on}} the data quality control methods for evaluating the performance of Weigh-In-Motion (WIM) systems on Oregon highways. This research identifies and develops a new methodology and algorithm to explore the accuracy of each station 2 ̆ 7 s weight and spacing data at a corridor level, and further implements the Statistical Process Control (SPC) method, finite mixture model, axle spacing <b>error</b> <b>rating</b> method, and data flag method in published research to examine the soundness of WIM systems. This research employs the historical WIM data to analyze sensor health and compares the evaluation results of the methods. The results suggest the new triangulation method identified most possible WIM malfunctions that other methods sensed, and this method unprecedentedly monitors the process behavior with controls of time and meteorological variables. The SPC method appeared superior in differentiating between sensor noises and sensor errors or drifts, but it drew wrong conclusions when accurate WIM data reference was absent. The axle spacing <b>error</b> <b>rating</b> method cannot check the essential weight data in special cases, but reliable loop sensor evaluation results were arrived at by employing this multiple linear regression model. The results of the data flag method and the finite mixed model results were not accurate, thus they {{could be used as}} additional tools to complement the data quality evaluation results. Overall, these data quality analysis results are the valuable sources for examining the early detection of system malfunctions, sensor drift, etc., and allow the WIM operators to correct the situation on time before large amounts of measurement are lost...|$|E
40|$|A bit <b>error</b> <b>rate</b> test on a {{transceiver}} is {{accelerated by}} adding a phase offset to data phase encoding and decoding in the transceiver and by mapping bit <b>error</b> <b>rate</b> test results from an elevated <b>error</b> <b>rate</b> condition to a normal <b>error</b> <b>rate</b> condition for the transceiver. The elevated <b>error</b> <b>rate</b> is accomplished by adjusting the phase of the phase encoder and decoder with {{the value of the}} phase offset so that the encoded data transmission signal is not as robust against noise as it normally would be. Noise {{in the form of an}} interference signal is introduced during the transmission, and the bit <b>error</b> <b>rate</b> is measured after the receiver has decoded the signal. The bit <b>error</b> <b>rate</b> (BER) data with an elevated propensity for error is mapped against bit <b>error</b> <b>rate</b> data for normal operations. A mapping function is built to map BERE (bit <b>error</b> <b>rate</b> elevated) data�data from the elevated <b>error</b> <b>rate</b> condition for data encoding, to BERN (normal bit <b>error</b> <b>rate)</b> data�data from the normal <b>error</b> <b>rate</b> condition for data encoding. The BERE data is mapped to BERN data using the mapping function so that the BER performance of the transceiver may be measured using far fewer test sequences of digital bits. Georgia Institute Of Technolog...|$|R
40|$|In {{spite of}} the {{excellent}} bit <b>error</b> <b>rate</b> performance of the original turbo-code, simulations indicate that this code yields relatively poor frame <b>error</b> <b>rate</b> performance. In this paper we show that "primitive" turbo-codes and "asymmetric" turbocodes provides both good bit <b>error</b> <b>rate</b> and frame <b>error</b> <b>rate</b> performance...|$|R
5000|$|In {{communication}} systems with very low uncorrected bit <b>error</b> <b>rates,</b> such as modern fiber optic transmission systems, or systems with higher low-level <b>error</b> <b>rates</b> that are corrected using {{large amounts of}} forward error correction, errored seconds are often a better measure of the effective user-visible <b>error</b> <b>rate</b> than the raw bit <b>error</b> <b>rate.</b>|$|R
40|$|Abstract: Cognitive errors (CE) {{and coping}} {{strategies}} (CS) {{are the focus}} of most cognitive-behavioral treatments for in-carcerated child molesters. Several studies have reported differences in CEs and CSs between child molesters and con-trols. However, the vast majority of these studies assessed cognitive errors and coping using questionnaires, which are known to present a number of important limitations. This pilot study aimed to compare the CEs and CSs of N = 17 incar-cerated child abusers and N = 12 controls using observer-rated methods, namely the Cognitive <b>Error</b> <b>Rating</b> Scale (CERS; Drapeau et al., 2005) and the Coping Action Pattern Rating Scale (CAPRS; Perry, Drapeau, & Dunkley, 2005). Results showed that child molesters presented more cognitive errors, in particular positive selective abstraction, and lower coping functioning, such as escape strategies. Treatment and research implications, including the use of observer-rated methods, are discussed...|$|E
30|$|Determining if Twitter {{data can}} indeed detect ILI {{epidemics}} by accurately estimating CDC ILI values {{was done on}} a weekly basis on a national level and a regional level (where region 2 is presented by the authors). For the national estimation they trained their method using 1 million of the tweets from October 1, 2009 - May 20, 2010 throughout the United States, with the objective being CDC’s ILI values throughout the nation. Leave-one-out cross-validation was used to determine the accuracy of the model. The results found for the national level were quite accurate, scoring an average error of 0.28 % {{with a standard deviation of}} 0.23 %. In order to estimate the ILI levels in a particular region, with the goal being real-time prediction (as again, the CDC has a 1 to 2 week delay), they took the tweets that had geolocation information and fit these tweets to CDC region ILI readings from 9 of the 10 regions in order to construct the model to determine the results for last region (region 2). The authors argue that perhaps the smaller amount of tweets containing the geolocation information could have generated the slightly higher <b>error</b> <b>rating</b> of 0.37 % with a standard deviation of 0.26 %.|$|E
5000|$|... {{where is}} the Bayes <b>error</b> <b>rate</b> (which is the minimal <b>error</b> <b>rate</b> possible), [...] is the k-NN <b>error</b> <b>rate,</b> and [...] {{is the number of}} classes in the problem. For [...] and as the Bayesian <b>error</b> <b>rate</b> [...] {{approaches}} zero, this limit reduces to [...] "not more than twice the Bayesian error rate".|$|R
30|$|According to the {{empirical}} results (Tables  6, 7, 8), the prediction {{accuracy of the}} LASSO–NN model is 88.96  % (Type I <b>error</b> <b>rate</b> is 12.22  %; Type II <b>error</b> <b>rate</b> is 7.50  %), the prediction accuracy of the LASSO–CART model is 88.75  % (Type I <b>error</b> <b>rate</b> is 13.61  %; Type II <b>error</b> <b>rate</b> is 14.17  %), and the prediction accuracy of the LASSO–SVM model is 89.79  % (Type I <b>error</b> <b>rate</b> is 10.00  %; Type II <b>error</b> <b>rate</b> is 15.83  %). Our comparison follows that of Kirkos et al. (2007 a, b), Tasi and Huang (2010) and Chen et al. (2014). We not only focus on the hit ratio of the models, but also consider the Type I error and Type II <b>error</b> <b>rates.</b>|$|R
40|$|In {{multiple}} testing scenarios, {{typically the}} sign of a parameter is inferred when its estimate exceeds some significance threshold in absolute value. Typically, the significance threshold is chosen to control the experimentwise type I <b>error</b> <b>rate,</b> family-wise type I <b>error</b> <b>rate</b> or the false discovery rate. However, controlling these <b>error</b> <b>rates</b> does not explicitly control the sign <b>error</b> <b>rate.</b> In this paper, we propose two procedures for adaptively selecting an experimentwise significance threshold in order to control the sign <b>error</b> <b>rate.</b> The first controls the sign <b>error</b> <b>rate</b> conservatively, without any distributional assumptions on the parameters of interest. The second is an empirical Bayes procedure, and achieves optimal performance asymptotically when a model for the distribution of the parameters is correctly specified. We also discuss an adaptive procedure to minimize the sign <b>error</b> <b>rate</b> when the experimentwise type I <b>error</b> <b>rate</b> is held fixed. Comment: 19 pages, 4 figure...|$|R
40|$|AbstractRecent work on robust <b>error</b> <b>rate</b> {{estimation}} {{in classification}} analysis is summarized. First, the perspective for the <b>error</b> <b>rate</b> estimation problem is established, and the parameters that {{are referred to}} as <b>error</b> <b>rates</b> are described. Next, the bases for comparison of <b>error</b> <b>rate</b> estimators are reviewed and a mean-square error criterion recommended. Then several approaches to robust <b>error</b> <b>rate</b> estimation are introduced. Finally, recommendations for applications based on available evaluations of robust estimators are made, and important unresolved issues are identified...|$|R
5000|$|Total <b>Error</b> <b>Rate</b> = ((INF + IF)/ (C + INF + IF)) * 100%Not Corrected <b>Error</b> <b>Rate</b> = (INF/ (C + INF + IF)) * 100%Corrected <b>Error</b> <b>Rate</b> = (IF/ (C + INF + IF)) * 100% ...|$|R
40|$|Machine {{learning}} algorithms induce classifiers {{that depend}} on the training set and hyperparameters {{and there is a}} need for statistical testing for (i) assessing the expected <b>error</b> <b>rate</b> of a classifier, and (ii) comparing the expected <b>error</b> <b>rates</b> of two classifiers. We review interval estimation and hypothesis testing and discuss three tests for <b>error</b> <b>rate</b> assessment and four tests for <b>error</b> <b>rate</b> comparison. ...|$|R
40|$|The Student-Newman-Kuels {{procedure}} {{is a well-known}} step-down multiple comparisons procedure with critical values based on the Studentized range distribution. The False Discovery Rate is a Type I <b>error</b> <b>rate</b> for multiple comparisons, intermediate in stringency to the weak familywise <b>error</b> <b>rate</b> (experimentwise <b>error</b> <b>rate)</b> and the strong familywise <b>error</b> <b>rate.</b> We show that SNK controls FDR. Multiple comparisons Simultaneous inference SNK FDR...|$|R
40|$|Abstract—Due to high complexity, the low-complexity Gaussian-assumption bit <b>error</b> <b>rate</b> or {{the upper}} bound and lower bound of BER is usually used in CDMA systems in stead {{of the real}} bit <b>error</b> <b>rate.</b> In this paper, we propose a low-complexity {{approximate}} bit <b>error</b> <b>rate</b> formula which is closer to real bit <b>error</b> <b>rate</b> than the Gaussian-assumption bit <b>error</b> <b>rate</b> in CDMA systems. At {{the end of the}} paper, we apply our formula to the MC-CDMA system with a slowly fading flat channel to verify our formula...|$|R
50|$|As {{the size}} of {{training}} data set approaches infinity, the one nearest neighbour classifier guarantees an <b>error</b> <b>rate</b> of no worse than twice the Bayes <b>error</b> <b>rate</b> (the minimum achievable <b>error</b> <b>rate</b> given {{the distribution of the}} data).|$|R
30|$|In case of [2], {{the average}} {{estimation}} <b>error</b> <b>rate</b> was 3 %, so our assumed estimation <b>error</b> <b>rate</b> {{was higher than}} 3 %. Similarly, for [10, 12], the estimation rate was assumed based on their average estimation <b>error</b> <b>rate.</b>|$|R
50|$|Two {{performance}} measures give quality characteristics of an ARQ-M link. These are <b>error</b> <b>rate</b> and throughput. Residual errors can {{be due to}} transpositions of the symbol elements or double errors. The chances that this happens is about 100 to 1000 times less than for a working unprotected link. A log graph of residual <b>error</b> <b>rate</b> against raw <b>error</b> <b>rate</b> shows a steeper line with slope 2 intercepting at 100% errors. If the unprotected 5 unit code had an <b>error</b> <b>rate</b> of 1%, the ARQ-M protected code <b>error</b> <b>rate</b> is 0.0025%.|$|R
40|$|Abstract. This paper {{proposes a}} method for {{reducing}} the Bit <b>Error</b> <b>Rate</b> (BER), Frame <b>Error</b> <b>Rate</b> (FER) in OFDM system using Spatial Multiplexing. Spatial multiplexing is a transmission technique in MIMO wireless communication to transmit independent and separately encoded data signals {{from each of the}} multiple transmits antennas. For different Modulation techniques to calculate the <b>Error</b> <b>rate</b> for OFDM system. Finally compare the performance using Data <b>Rate</b> and <b>Error</b> <b>Rate...</b>|$|R
30|$|Type I errors may {{not have}} serious {{consequences}} when compared to Type II errors. If the auditor wrongly classifies a GC firm as healthy, then he/she can be sued. If an auditor issues a wrong audit report due to his/her misjudgment, then this will affect not only the enterprise and stakeholders, but also many investors. Moreover, the CPA may be sued. The costs for Type II errors are thus rather severe. We have developed three GCD prediction models. In the LASSO–NN model, the Type I <b>error</b> <b>rate</b> is 12.22  % and the Type II <b>error</b> <b>rate</b> is 7.50  %; in the LASSO–CART model, the Type I <b>error</b> <b>rate</b> is 13.61  % and the Type II <b>error</b> <b>rate</b> is 14.17  %; and in the LASSO–SVM model, the Type I <b>error</b> <b>rate</b> is 10.00  % and the Type II <b>error</b> <b>rate</b> is 15.83  %. These <b>error</b> <b>rates</b> are all lower than 20  %, especially in the LASSO–NN model where the Type II <b>error</b> <b>rate</b> is only 7.50  %. This is a key contribution of this paper.|$|R
40|$|Abstract—Many {{real-world}} data mining applications need varying cost for {{different types of}} classification errors and thus call for cost-sensitive classification algorithms. Existing algorithms for cost-sensitive classification are successful in terms of minimizing the cost, but {{can result in a}} high <b>error</b> <b>rate</b> as the trade-off. The high <b>error</b> <b>rate</b> holds back the practical use of those algorithms. In this paper, we propose a novel cost-sensitive classification methodology that takes both the cost and the <b>error</b> <b>rate</b> into account. The methodology, called soft cost-sensitive classification, is established from a multicriteria optimization problem of the cost and the <b>error</b> <b>rate,</b> and can be viewed as regularizing cost-sensitive classification with the <b>error</b> <b>rate.</b> The simple methodology allows immediate improvements of existing cost-sensitive classification algorithms. Experiments on the benchmark and the {{real-world data}} sets show that our proposed methodology indeed achieves lower test <b>error</b> <b>rates</b> and similar (sometimes lower) test costs than existing cost-sensitive classification algorithms. We also demonstrate that the methodology can be extended for considering the weighted <b>error</b> <b>rate</b> instead of the original <b>error</b> <b>rate.</b> This extension is useful for tackling unbalanced classification problems...|$|R
40|$|We explore discriminative {{training}} of HMM parameters that directly minimizes the expected <b>error</b> <b>rate.</b> In discriminative training one {{is interested in}} training a system to minimize a desired error function, like word <b>error</b> <b>rate,</b> phone <b>error</b> <b>rate,</b> or frame <b>error</b> <b>rate.</b> We review a recent method (McAllester, Hazan and Keshet, 2010), which introduces an analytic expression for the gradient of the expected error-rate. The analytic expression leads to a perceptron-like update rule, which is adapted here for {{training of}} HMMs in an online fashion. While the proposed method can work with any type of the error function used in speech recognition, we evaluated it on phoneme recognition of TIMIT, when the desired error function used for training was frame <b>error</b> <b>rate.</b> Except for the case of GMM with a single mixture per state, the proposed update rule provides lower <b>error</b> <b>rates,</b> {{both in terms of}} frame <b>error</b> <b>rate</b> and phone <b>error</b> <b>rate,</b> than other approaches, including MCE and large margin. Index Terms: hidden Markov models, online learning, direct error minimization, discriminative training, automatic speech recognition, minimum phone error, minimum frame error 1...|$|R
40|$|The {{apparent}} <b>error</b> <b>rate</b> is {{a commonly}} used estimator {{of the actual}} <b>error</b> <b>rate</b> in discrimi-nant analysis. In this study the asymptotic bias of the apparent <b>error</b> <b>rate</b> is derived {{in the context of}} two multivariate normal populations with unknown different means and unknown common covariance matrix. From the derived expansion a correction term is available for reducing the bias of the apparent <b>error</b> <b>rate</b> from the first to the second order with respect to the reciprocals of the initial sample sizes. Also, some previously unanswered questions on inequalities between the average apparent, the optimal, and the average actual <b>error</b> <b>rates</b> are solved. Some key words: Bias of apparent <b>error</b> rate; <b>Error</b> <b>rates,</b> optimal, actual and apparent; Inequalities between error rates; Linear discriminant function. 1...|$|R
40|$|Abstract Background We {{investigated}} {{the influence of}} genotyping errors on the type I <b>error</b> <b>rate</b> and empirical power of two haplotype based association methods applied to candidate regions. We compared {{the performance of the}} Mantel Statistic Using Haplotype Sharing and the haplotype frequency based score test with that of the Armitage trend test. Our study is based on 1000 replication of simulated case-control data settings with 500 cases and 500 controls, respectively. One of the examined markers was set to be the disease locus with a simulated odds ratio of 3. Differential and non-differential genotyping errors were introduced following a misclassification model with varying mean <b>error</b> <b>rates</b> per locus in the range of 0. 2 % to 15. 6 %. Results We found that the type I <b>error</b> <b>rate</b> of all three test statistics hold the nominal significance level in the presence of nondifferential genotyping errors and low <b>error</b> <b>rates.</b> For high and differential <b>error</b> <b>rates,</b> the type I <b>error</b> <b>rate</b> of all three test statistics was inflated, even when genetic markers not in Hardy-Weinberg Equilibrium were removed. The empirical power of all three association test statistics remained high at around 89 % to 94 % when genotyping <b>error</b> <b>rates</b> were low, but decreased to 48 % to 80 % for high and nondifferential genotyping <b>error</b> <b>rates.</b> Conclusion Currently realistic genotyping <b>error</b> <b>rates</b> for candidate gene analysis (mean <b>error</b> <b>rate</b> per locus of 0. 2 %) pose no significant problem for the type I <b>error</b> <b>rate</b> as well as the power of all three investigated test statistics. </p...|$|R
50|$|New Reno {{performs}} {{as well as}} SACK at low packet <b>error</b> <b>rates,</b> and substantially outperforms Reno at high <b>error</b> <b>rates.</b>|$|R
30|$|The {{performance}} of the G 2 P conversion system was expressed in two average <b>error</b> <b>rates</b> (over the fivefold): average <b>error</b> <b>rate</b> of phonemes (PER) and average <b>error</b> <b>rate</b> of words (WER). The following figures summarize the results obtained using n-grams with n between 2 and 8.|$|R
30|$|One of the {{effective}} techniques {{to reduce the}} <b>error</b> <b>rate</b> in memories is through ECC. As described in “PRAM reliability” and “STT-RAM reliability” sections, raw <b>error</b> <b>rate</b> of MLC PRAM and STT-RAM can significantly be reduced using circuit-level techniques. For instance, the <b>error</b> <b>rate</b> of MLC PRAM {{can be reduced to}} 10 – 4 by adjusting Rth(10, 00) and the <b>error</b> <b>rate</b> of STT-RAM can be reduced to 10 – 5 by voltage boosting and/or write pulse width adjustment.|$|R
40|$|In {{order to}} scientifically {{demonstrate}} a measurable <b>error</b> <b>rate</b> {{in the operation}} of forensic imaging tools, any technology used must be empirically verified. A methodology is introduced to provide for measuring software logical imaging <b>error</b> <b>rates</b> on an Android tablet. This study observed no <b>error</b> <b>rate</b> in four of five tools tested, yet some measurable rate did exist for one tool. Additionally it was found that forensic imaging tools may have <b>error</b> <b>rates</b> comparable to other file transfer tools. ...|$|R
50|$|Most {{telecommunication}} systems use a fixed channel code {{designed to}} tolerate the expected worst-case bit <b>error</b> <b>rate,</b> and then fail to work at all if the bit <b>error</b> <b>rate</b> is ever worse.However, some systems adapt to the given channel error conditions: some instances of hybrid automatic repeat-request use a fixed FEC method {{as long as the}} FEC can handle the <b>error</b> <b>rate,</b> then switch to ARQ when the <b>error</b> <b>rate</b> gets too high;adaptive modulation and coding uses a variety of FEC rates, adding more error-correction bits per packet when there are higher <b>error</b> <b>rates</b> in the channel, or taking them out when they are not needed.|$|R
50|$|In 2011, an <b>error</b> <b>rate</b> of 0.27 percent, {{improving}} on {{the previous}} best result, was reported by researchers using a similar system of neural networks. In 2013, an approach based on regularization of neural networks using DropConnect has been claimed to achieve a 0.21 percent <b>error</b> <b>rate.</b> Recently, the single convolutional neural network best performance was 0.31 percent <b>error</b> <b>rate.</b> Currently, the best performance of a single convolutional neural network trained in 74 epochs on the expanded training data is 0.27 percent <b>error</b> <b>rate.</b> Also, the Parallel Computing Center (Khmelnitskiy, Ukraine) obtained an ensemble of only 5 convolutional neural networks which performs on MNIST at 0.21 percent <b>error</b> <b>rate.</b>|$|R
50|$|In statistics, per-comparison <b>error</b> <b>rate</b> (PCER) is the {{probability}} of a Type I error {{in the absence of any}} multiple hypothesis testing correction. This is a liberal <b>error</b> <b>rate</b> relative to the false discovery <b>rate</b> and familywise <b>error</b> <b>rate,</b> in that it is always less than or equal to those rates.|$|R
5000|$|Since the {{carriers}} are independent, the overall bit <b>error</b> <b>rate</b> {{is the same}} as the per-carrier <b>error</b> <b>rate,</b> just like BPSK and QPSK: ...|$|R
5000|$|... #Caption: Progress in machine {{classification}} of images--------------------------The <b>error</b> <b>rate</b> of AI by year. Red line - the <b>error</b> <b>rate</b> of a trained human ...|$|R
40|$|AbstractThe {{problem of}} {{estimating}} the <b>error</b> <b>rates</b> of a sample-based {{rule on the}} basis of the same sample used in its construction is considered. The apparent <b>error</b> <b>rate</b> is an obvious nonparametric estimate of the conditional <b>error</b> <b>rate</b> of a sample rule, but unfortunately it provides too optimistic an assessment. Attention is focussed on the formation of improved estimates, mainly through appropriate bias correction of the apparent <b>error</b> <b>rate.</b> In this respect the role of the bootstrap, a computer-based methodology, is highlighted...|$|R
40|$|Abstract—In this paper, we derive exact {{closed form}} bit <b>error</b> <b>rate</b> (BER) or symbol <b>error</b> <b>rate</b> (SER) {{expressions}} for orthogonal frequency division multiplexing (OFDM) systems with carrier frequency offset (CFO). We consider {{the performance of}} an OFDM system subject to CFO error in additive white Gaussian noise (AWGN), frequency flat and frequency selective Rayleigh fading channels. The BER / SER performances of BPSK and QPSK modulation schemes are analyzed for AWGN and frequency-flat Rayleigh fading channels while BPSK is considered for frequency-selective Rayleigh fading channels. Our results can easily be reduced to the respective analytical <b>error</b> <b>rate</b> expressions for the OFDM systems without CFO error. Furthermore, the simulation results are provided to verify {{the accuracy of the}} new <b>error</b> <b>rate</b> expressions. Index Terms—Bit <b>error</b> <b>rate</b> (BER), frequency offset, frequency selective fading, orthogonal frequency division multiplexing (OFDM), Rayleigh fading, symbol <b>error</b> <b>rate</b> (SER). I...|$|R
