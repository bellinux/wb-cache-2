3|76|Public
50|$|Vacuum-assisted breast biopsy (VAB) is a {{minimally}} invasive procedure (Biopsy) {{to help in the}} diagnosis of breast cancer. VAB is characterized by single insertion, acquisition of contiguous and larger tissue samples, and <b>directional</b> <b>sample</b> capability. It also offers 10x the tissue of core needle biopsy.|$|E
40|$|An {{important}} step of modeling spatially-referenced data is appropriately specifying the second order {{properties of the}} random field. A scientist developing a model for spatial data {{has a number of}} options regarding the nature of the dependence between observations. One of these options is deciding whether or not the dependence between observations depends on direction, or, in other words, whether or not the spatial covariance function is isotropic. Isotropy implies that spatial dependence is a function of only the distance and not the direction of the spatial separation between sampling locations. A researcher may use graphical techniques, such as <b>directional</b> <b>sample</b> semivariograms, to determine whether an assumption of isotropy holds. These graphical diagnostics can be difficult to assess, subject to personal interpretation, and potentially misleading as they typically do not include a measure of uncertainty. In order to escape these issues, a hypothesis test of the assumption of isotropy may be more desirable. To avoid specification of the covariance function, a number of nonparametric tests of isotropy have been developed using both the spatial and spectral representations of random fields. Several of these nonparametric tests are implemented in the R package spTest, available on CRAN. We demonstrate how graphical techniques and the hypothesis tests programmed in spTest can be used in practice to assess isotropy properties. Comment: 18 pages, 7 figure...|$|E
40|$|An {{important}} aspect of modeling spatially-referenced data is appropriately specifying the covariance function of the random field. A practitioner working with spatial data is presented a number of choices regarding {{the structure of the}} dependence between observations. One of these choices is determining whether or not an isotropic covariance function is appropriate. Isotropy implies that spatial dependence does not depend on the direction of the spatial separation between sampling locations. Misspecification of isotropy properties (directional dependence) can lead to misleading inferences, e. g., inaccurate predictions and parameter estimates. A researcher may use graphical diagnostics, such as <b>directional</b> <b>sample</b> variograms, to decide whether the assumption of isotropy is reasonable. These graphical techniques can be difficult to assess, open to subjective interpretations, and misleading. Hypothesis tests of the assumption of isotropy may be more desirable. To this end, a number of tests of directional dependence have been developed using both the spatial and spectral representations of random fields. We provide an overview of nonparametric methods available to test the hypotheses of isotropy and symmetry in spatial data. We summarize test properties, discuss important considerations and recommendations in choosing and implementing a test, compare several of the methods via a simulation study, and propose a number of open research questions. Several of the reviewed methods can be implemented in R using our package spTest, available on CRAN. Comment: 22 pages, 6 figures, 9 tables, appendi...|$|E
5000|$|Failure {{probability}} (Reliability analysis): approximation (FORM), simulation (Monte Carlo, LHS, <b>Directional</b> <b>sampling)</b> ...|$|R
40|$|Based on an average-derivative {{method and}} {{optimization}} techniques, a 27 -point scheme for a 3 D frequency-domain scalar wave equation is developed. Compared to the rotated-coordinate approach, the average-derivative optimal method {{is not only}} concise but also applies to equal and unequal <b>directional</b> <b>sampling</b> intervals. The resulting 27 -point scheme uses a 27 -point operator to approximate spatial derivatives and the mass acceleration term. The coefficients are determined by minimizing phase velocity dispersion errors and the resultant optimal coefficients depend on ratios of <b>directional</b> <b>sampling</b> intervals. Compared to the classical 7 -point scheme, the number of grid points per shortest wavelength is reduced from approximately 13 to approx-imately 4 by this 27 -point optimal scheme for equal <b>directional</b> <b>sampling</b> intervals and unequal <b>directional</b> <b>sampling</b> intervals as well. Two numerical examples are pre-sented to demonstrate the theoretical analysis. The average-derivative algorithm is also extended to a 3 D frequency-domain viscous scalar wave equation...|$|R
40|$|In {{this paper}} an {{adaptive}} procedure is presented DARS: <b>Directional</b> <b>Sampling,</b> {{combined with an}} interactive response surface. This method makes structural reliability computations feasible without pre-knowledge the probabilistic behaviour even for cases with many stochastic variables and a low probability of failure...|$|R
40|$|ABSTRACT: A {{methodology}} {{is presented}} {{for determining the}} probability of dikes failing due to uplifting and piping using <b>directional</b> <b>sampling.</b> The study concerns one dike section in the lower river area of The Netherlands. For this dike section, {{the three most important}} random quantities are: the North-Sea water level, the river Rhine discharge, and the critical head in the event of uplifting and piping. Dike failure due to uplifting and piping is defined as the event in which the resistance (the critical head) drops below the stress (the outer water level, a combination of both sea level and river discharge, minus the inner water level). Since the critical head is correlated over the length of a dike, the spatial variation and correlation is modelled using a Markovian dependency structure. Three-dimensional <b>directional</b> <b>sampling</b> {{on the basis of the}} polar coordinates of the sea water level, the river discharge, and the critical head is used to determine the failure probability. ...|$|R
40|$|The {{principles}} of cloud droplet size retrieval via Polarization and Directionality of the Earth's Reflectance (POLDER) requires that clouds be horizontally homogeneous. The retrieval is performed by combining all measurements {{from an area}} of 150 km × 150 km to compensate for POLDER's insufficient <b>directional</b> <b>sampling.</b> Using POLDER-like data simulated with the RT 3 model, we investigate the impact of cloud horizontal inhomogeneity and <b>directional</b> <b>sampling</b> on the retrieval and analyze which spatial resolution is potentially accessible from the measurements. Case {{studies show that the}} sub-grid-scale variability in droplet effective radius (CDR) can significantly reduce valid retrievals and introduce small biases to the CDR (~ 1. 5 μm) and effective variance (EV) estimates. Nevertheless, the sub-grid-scale variations in EV and cloud optical thickness (COT) only influence the EV retrievals and not the CDR estimate. In the <b>directional</b> <b>sampling</b> cases studied, the retrieval using limited observations is accurate and is largely free of random noise. Several improvements have been made to the original POLDER droplet size retrieval. For example, measurements in the primary rainbow region (137 – 145 °) are used to ensure retrievals of large droplet (> 15 μm) and to reduce the uncertainties caused by cloud heterogeneity. We apply the improved method using the POLDER global L 1 B data from June 2008, and the new CDR results are compared with the operational CDRs. The comparison shows that the operational CDRs tend to be underestimated for large droplets because the cloudbow oscillations in the scattering angle region of 145 – 165 ° are weak for cloud fields with CDR > 15 μm. Finally, a sub-grid-scale retrieval case demonstrates that a higher resolution, e. g., 42 km × 42 km, can be used when inverting cloud droplet size distribution parameters from POLDER measurements...|$|R
40|$|The paper {{describes}} two {{well known}} but adapted methods for calculating {{the probability of}} failure of structures. First the First Order Reliability Method (FORM) is described using an adapted response surface. Secondly the <b>Directional</b> <b>Sampling</b> (DS) procedure is described using truncated stochastic distributions. Both methods are implemented in the Finite Element Method (FEM) code DIANA of TNO. The two methods have been applied for calculating the probability of failure of steel structures. Three examples are presented...|$|R
40|$|In {{engineering}} science the modeling and numerical analysis of complex systems and relations {{plays an important}} role. In order to realize such an investigation, for example a stochastic analysis, in a reasonable computational time, approximation procedure have been developed. A very famous approach is the response surface method, where the relation between input and output quantities is represented for example by global polynomials or local interpolation schemes as Moving Least Squares (MLS). In recent years artificial neural networks (ANN) have been applied as well for such purposes. Recently an adaptive response surface approach for reliability analyses was proposed, which is very efficient concerning the number of expensive limit state function evaluations. Due to the applied simplex interpolation the procedure is limited to small dimensions. In this paper this approach is extended for larger dimensions using combined ANN and MLS response surfaces for evaluating the adaptation criterion with only one set of joined limit state points. As adaptation criterion a combination by using the maximum difference in the conditional probabilities of failure and the maximum difference in the approximated radii is applied. Compared to response surfaces on <b>directional</b> <b>samples</b> or to plain <b>directional</b> <b>sampling</b> the failure probability can be estimated with a much smaller number of limit state points...|$|R
40|$|AbstractConcerning {{the issue}} of high-dimensions and low-failure probabilities {{including}} implicit and highly nonlinear limit state function, reliability analysis based on the <b>directional</b> importance <b>sampling</b> {{in combination with the}} radial basis function (RBF) neural network is used, and the RBF neural network based on first-order reliability method (FORM) is to approximate the unknown implicit limit state functions and calculate the most probable point (MPP) with iterative algorithm. For good efficiency, based on the ideas that <b>directional</b> <b>sampling</b> reduces dimensionality and importance sampling focuses on the domain contributing to failure probability, the joint probability density function of importance sampling is constructed, and the sampling center is moved to MPP to ensure that more random sample points draw belong to the failure domain and the simulation efficiency is improved. Then the numerical example of initiating explosive devices for rocket booster explosive bolts demonstrates the applicability, versatility and accuracy of the approach compared with other reliability simulation algorithm...|$|R
50|$|The {{primary purpose}} of these {{instruments}} is to monitor clouds and to measure the thermal emission of the Earth. These sensors have proven useful {{for a number of}} other applications, however, including the surveillance of land surfaces, ocean state, aerosols, etc. AVHRR data are particularly relevant to study climate change and environmental degradation because of the comparatively long records of data already accumulated (over 20 years). The main difficulty associated with these investigations is to properly deal with the many limitations of these instruments, especially in the early period (sensor calibration, orbital drift, limited spectral and <b>directional</b> <b>sampling,</b> etc.).|$|R
40|$|AbstractComputing system {{reliability}} when system components are correlated presents a challenge because it usually requires solving multi-fold integrals numerically, {{which is generally}} infeasible due to the computational cost. In Dutch flood defense reliability modeling, an efficient method for computing the failure probability {{of a system of}} correlated components – referred to here as the Equivalent Planes method – was developed and has been applied in national flood risk analysis. The accuracy of the method has never been thoroughly tested, and the method is absent in the literature; this paper addresses both of these shortcomings. The method is described in detail, including an in-depth discussion about the source of error. A suite of system configurations were defined to test the error in the Equivalent Planes method, with a focus on extreme cases to capture the upper bound of the error. The ‘exact’ {{system reliability}} was computed analytically for the special case of equi-correlated components, and otherwise using Monte-Carlo <b>directional</b> <b>sampling.</b> We found that errors in the system failure probability estimates were low {{for a wide range of}} system configurations, and became more substantial for large systems with highly-correlated components. In the most extreme cases we tested, the error remained within three times the true failure probability. We provided an example of how one can determine if such error is tolerable in their particular application. We also show the computational advantage of using the Equivalent Planes method; large systems with small failure probabilities which take over 17 h for Monte Carlo <b>directional</b> <b>sampling</b> were computed with the Equivalent Planes in less than one second...|$|R
40|$|A {{mapping of}} unit vectors onto a 5 D {{hypersphere}} {{is used to}} model and partition ODFs from HARDI data. This mapping {{has a number of}} useful and interesting properties and we make a link to interpretation of the second order spherical harmonic decompositions of HARDI data. The paper presents the working theory and experiments of using a von Mises-Fisher mixture model for <b>directional</b> <b>samples.</b> The MLE of the second moment of the HvMF pdf can also be related to fractional anisotropy. We perform error analysis of the estimation scheme in single and multi-fibre regions and then show how a penalised-likelihood model selection method can be employed to differentiate single and multiple fibre regions. ...|$|R
40|$|Computing system {{reliability}} when system components are correlated presents a challenge because it usually requires solving multi-fold integrals numerically, {{which is generally}} infeasible due to the computational cost. In Dutch flood defense reliability modeling, an efficient method for computing the failure probability {{of a system of}} correlated components – referred to here as the Equivalent Planes method – was developed and has been applied in national flood risk analysis. The accuracy of the method has never been thoroughly tested, and the method is absent in the literature; this paper addresses both of these shortcomings. The method is described in detail, including an in-depth discussion about the source of error. A suite of system configurations were defined to test the error in the Equivalent Planes method, with a focus on extreme cases to capture the upper bound of the error. The ‘exact’ {{system reliability}} was computed analytically for the special case of equi-correlated components, and otherwise using Monte-Carlo <b>directional</b> <b>sampling.</b> We found that errors in the system failure probability estimates were low {{for a wide range of}} system configurations, and became more substantial for large systems with highly-correlated components. In the most extreme cases we tested, the error remained within three times the true failure probability. We provided an example of how one can determine if such error is tolerable in their particular application. We also show the computational advantage of using the Equivalent Planes method; large systems with small failure probabilities which take over 17 h for Monte Carlo <b>directional</b> <b>sampling</b> were computed with the Equivalent Planes in less than one second. Hydraulic EngineeringCivil Engineering and Geoscience...|$|R
40|$|Most {{reliability}} {{methods are}} applicable only for relatively simple structural systems with analytically formulated limit state functions {{and a few}} random variables. The combination of these standard reliability methods with structural analysis based on physically and geometrically non-linear Finite Element calculations leads to large computation times. In {{order to reduce the}} calculation time special methods like response surface techniques and advanced Monte Carlo methods may be used. The paper will review a number of these methods on items like accuracy, calculation time and required pre-knowledge. It turns out that an intelligent combination of an adaptive <b>Directional</b> <b>Sampling</b> Procedure and the Response Surface methods (DARS) offers a calculation scheme that makes probabilistic methods suitable for the design of every day as well as special structure...|$|R
40|$|Accurate {{analysis}} of orientations of linear elements from polyphase populations involves computing statistics (mean, standard deviation) of each sub-population, which needs previous {{identification of the}} polymodal character and separation of sub-samples. The procedure here proposed for a regional study involves: (a) distinguishing polyphase from monophase samples; (b) characterizing mean and deviation of clearly monophase populations; (c) separating poliphase samples into sub-samples using density diagrams in equal-area projection and standard deviation values; (d) applying a correspondence test based upon the 95 % confidence cone, {{as well as an}} equality F-test for <b>directional</b> <b>samples,</b> by comparison with monophase reference samples. An example of application of this procedure to pressure-solution lineations in carbonate pebbles of the Aliaga Tertiary basin (Teruel, Iberian Chain) is show...|$|R
40|$|Satellite {{measurements}} {{are subject to}} a wide range of uncertainties due to their temporal, spatial, and <b>directional</b> <b>sampling</b> characteristics. An information-theory approach is suggested to examine the nonuniform temporal sampling of ERB measurements. The information (i. e., its entropy or uncertainty) before and after the measurements is determined, and information gain (IG) is defined as a reduction in the uncertainties involved. A stochastic model for the diurnal outgoing flux variations that affect the ERB is developed. Using Gaussian distributions for the a priori and measured radiant exitance fields, the IG is obtained by computing the a posteriori covariance. The IG for the monthly outgoing flux measurements is examined for different orbital parameters and orbital tracks, using the Earth Observing System orbital parameters as specific examples. Variations in IG due to changes in the orbit's inclination angle and the initial ascending node local time are investigated...|$|R
40|$|A finite {{spherical cavity}} {{expansion}} technique is developed {{to simulate the}} loading on projectiles penetrating geologic media. Damaged Mohr-Coulomb plasticity models and general pressure-dependent damaged plasticity models are used with incompressible kinematics to approximate {{a wide range of}} targets. The finite cavity expansion approximation together with <b>directional</b> <b>sampling</b> reasonably captures near surface and layering effects without resort to ad hoc or empirical correction factors. The Mohr-Coulomb models are integrated exactly to provide a very efficient loading algorithm for use with conventional implicit or explicit finite element structural analysis. The more general constitutive model requires numerical integration and leads to a more computationally intensive procedure. However, subcycling is easily implemented with the numerical integration and thus an efficient loading method is readily achieved even for large complex simulations using explicit finite element analysis. The utility of the finite cavity expansion approach is demonstrated by comparison of simulations to measured test data from projectiles penetrating rock and soil targets...|$|R
30|$|The IMA angular {{coverage}} {{is not only}} limited, it is potentially strongly biased as {{the orientation of the}} three-axis stabilized platform is determined by the needs of the on-board cameras and other instruments designed to study the surface and atmosphere of Mars. The orientation is therefore neither evenly nor randomly distributed. The <b>directional</b> <b>sampling</b> problem is further emphasized by the low energy ion data, below 50 eV, which does not have entrance deflection scanning and is thus two-dimensional. Things are further {{complicated by the fact that}} the space environment around Mars is not symmetric, it shows clear asymmetry relative to the direction of the solar wind electric field (Dubinin et al., 2006; Fedorov et al., 2006; Barabash et al., 2007; Nilsson et al., 2010). The crustal fields have a very uneven distribution between the hemispheres (Acuna et al., 1998; Connerney et al., 2001), which may also bias data if these are important for the ion distributions around Mars and the ion outflow.|$|R
40|$|In {{this study}} a new local and {{likewise}} global response surface method is proposed. Lengths and angles of the limit state check point vectors {{are being used}} only without any additional geometrical conditions. The so called weighted radii interpolation of convex and concave failure surfaces is intended to provide reasonably accurate estimates of failure probabilities while maintaining computational efficiency. These are especially suitable for the reliability analysis of complex structures, because global polynomial approximation procedures are not sufficiently flexible. They always need a predefined number of limit state support points in unimportant directions {{in order to avoid}} any approximation problems. Moreover, the maximum number of limit state check points is limited, too. This is achieved by a combination of random search strategies (based on the adaptive <b>directional</b> <b>sampling</b> approach) as well as deterministic search refinement in combination with local and global interpolation schemes. A numerical example shows application possibilities in the context of geometrically and materially nonlinear static analysis...|$|R
40|$|Abstract. Material {{recognition}} applications use typically color texture-based features; {{however, the}} underlying measurements are in several application fields unavailable or too expensive (e. g., {{due to a}} limited resolution in remote sensing). Therefore, bidirectional reflectance mea-surements are used, i. e., dependent on both illumination and viewing directions. But even measurement of such BRDF data is very time- and resources-demanding. In this paper we use dependency-aware feature se-lection method to identify very sparse set of the most discriminative bidi-rectional reflectance samples that can reliably distinguish between three types of materials from BRDF database – fabric, wood, and leather. We conclude that ten gray-scale samples primarily at high illumination and viewing elevations are sufficient to identify type of material with accuracy over 96 %. We analyze estimated placement of the bidirectional samples for discrimination between different types of materials. The stability of such <b>directional</b> <b>samples</b> is very high as was verified by an additional leave-one-out classification experiment. We consider this work a step towards automatic method of material classification based on several reflectance measurements only...|$|R
40|$|Leaf Area Index (LAI) {{is a key}} {{structural}} and functional biophysical variable of the vegetated surfaces which is important in quantifying evapotranspiration rates and the energy exchange of terrestrial vegetation. Remote sensing offers a method of providing estimates of LAI through {{the analysis of the}} Bidirectional Reflectance Distribution Function (BRDF), an angular-dependent surface response. High-resolution, multi-angular and hyperspectral image data from PROBA/CHRIS (Project On-Board Autonomy/ Compact High Resolution Imaging Spectrometer) are used to estimate LAI. The retrieval of LAI is accomplished using the 1 D turbid-medium canopy reflectance model, SAIL, coupled with the leaf reflectance model, PROSPECT REDUX. Look-up-tables are generated using scene-specific parameters required to invert the physically based model. Two experiments are performed to examine the contribution of multispectral versus hyperspectral reflectances (nadir direction) and single-look versus multi-look hyperspectral reflectances in deriving the LAI. Image data of the calibration/validation site at Chilbolton, Hampshire, UK are used for the inversion. In addition, ground measurements of LAI are compared with the retrieved LAI estimates. Retrieved LAI estimates using various spectral and <b>directional</b> <b>sampling</b> suggest that the spectro-directional reflectances from CHRIS provides more accurate results than their lower-resolution counterparts such as single-look and multispectral reflectances...|$|R
40|$|The Dutch {{design codes}} for the dikes with {{retaining}} walls rely on Finite Element Analysis (FEM) {{in combination with}} partial safety factors. However, {{this can lead to}} conservative designs. For this reason, in this study, a reliability analysis is carried out with FEM calculations aiming to demonstrate the feasibility of reliability analysis for a dike with an anchored sheet pile wall modelled in the 2 D FEM, Plaxis. Sensitivity and reliability analyses were carried out and enabled by coupling the uncertainty package, OpenTURNS and Plaxis. The most relevant (ultimate) limit states concern the anchor, the sheet pile wall, the soil body failure (global instability) and finally the system. The case was used to investigate the applicability of the First Order Reliability Method (FORM) and <b>Directional</b> <b>Sampling</b> (DS) to analysing these limit states. The final goal is to estimate the probability of failure and identify the most important soil properties that affect the behaviour of each component and the system as a whole. The results of this research can be used to assess and optimize the current design procedure for dikes with retaining walls. Hydraulic Structures and Flood Ris...|$|R
40|$|Acquiring and {{representing}} the 4 D space of rays {{in the world}} (the light field) is important for many computer vision and graphics applications. Yet, light field acquisition is costly due to their high dimensionality. Existing approaches either capture the 4 D space explicitly, or involve an errorsensitive depth estimation process. This paper argues that the fundamental difference between different acquisition and rendering techniques {{is a difference between}} prior assumptions on the light field. We use the previously reported dimensionality gap in the 4 D light field spectrum to propose a new light field prior. The new prior is a Gaussian assigning a non-zero variance mostly to a 3 D subset of entries. Since there is only a lowdimensional subset of entries with non-zero variance, we can reduce the complexity of the acquisition process and render the 4 D light field from 3 D measurement sets. Moreover, the Gaussian nature of the prior leads to linear and depth invariant reconstruction algorithms. We use the new prior to render the 4 D light field from a 3 D focal stack sequence and to interpolate sparse <b>directional</b> <b>samples</b> and aliased spatial measurements. In all cases the algorithm reduces to a simple spatially invariant deconvolution which does not involve depth estimation. 1...|$|R
30|$|To {{investigate}} {{the hypothesis that}} N 2 amplitudes would be greater (more negative) in response to “NoGo” than to “Go” stimuli presentations, <b>directional</b> paired <b>samples</b> t tests were performed. Due to artifact, eight participants were excluded from this analysis, leaving n of 37. As expected, N 2 amplitudes were significantly greater (more negative) in response to “NoGo” stimuli (M[*]=[*]−[*] 7.136 microvolts, SD[*]=[*] 4.0364) than in response to “Go” stimuli (M[*]=[*]−[*] 6.118 microvolts, SD[*]=[*] 3.379), t(36)[*]=[*] 1.886, p[*]=[*] 0.0335, 90 % CI [. 106, 1.929]. This finding supports the hypothesis that “NoGo” N 2 amplitudes would be more negative than “Go” N 2 amplitudes.|$|R
50|$|Lumia Storyteller (previously Nokia Storyteller) was a scrapbooking app Windows and Windows Phone that {{displays}} {{photos and}} videos {{taken on a}} Lumia device {{in the manner of}} a story, it integrates with Here maps to show where every individual photograph and video clip has been taken, and if its recorded on the Nokia Lumia 1520 it allows audiophiles that can capture <b>directional</b> stereo <b>samples.</b> In September 2015 Microsoft announced that they would discontinue Lumia Storyteller and its associated online service on October 30, 2015 as some of its features would be implemented in the Windows 10 Photos app.|$|R
40|$|A {{portable}} wind-sensitive <b>directional</b> air <b>sampler</b> {{has been}} developed {{as part of an}} air pollution source identification system. The system is designed to identify sources of air pollution based on the directional collection of field air samples and their analysis for TSP and trace element characteristics. Sources can be identified by analyzing the data on the basis of pattern recognition concepts. Functional testing of a prototype sampler is described; all items exhibited performance and life sufficient to carry out field performance test operations. Life testing of the wind direction sensor and the directional porting valves, which are critical to reliable operation, was emphasized with successful results...|$|R
40|$|New {{bandwidth}} selectors for kernel density estimation with {{directional data}} {{are presented in}} this work. These selectors are based on asymptotic and exact error expressions for the kernel density estimator combined with mixtures of von Mises distributions. The performance of the proposed selectors is investigated in a simulation study and compared with other existing rules for a large variety of <b>directional</b> scenarios, <b>sample</b> sizes and dimensions. The selector based on the exact error expression {{turns out to have}} the best behaviour of the studied selectors for almost all the situations. This selector is illustrated with real data for the circular and spherical cases. Comment: 26 pages, 4 figures, 8 table...|$|R
40|$|Magnetic {{shape memory}} {{materials}} can deform by some percent via twin boundary motion {{under the influence}} of a magnetic field. This effect is well documented for single crystals of Ni-Mn-Ga alloys with compositions around Ni 2 MnGa. It is demonstrated that this effect can be achieved in textured polycrystalline samples as well, which can be produced much more efficient than single crystals. <b>Directional</b> solidified <b>samples</b> were subjected to thermal and thermo-mechanical treatment in order to adjust structure and microstructure. A shape change larger than 1 % was achieved in a Ni 5 oMn 29 Ga 2 i alloy by applying a magnetic field at room temperature...|$|R
40|$|Key words: robust design optimization, {{robustness}} evaluation, reliability analysis, fluid-structure interaction, surrogate models, {{adaptive design}} of experiment, impor-tance <b>sampling,</b> <b>directional</b> <b>sampling</b> Abstract. Since the engineering of turbo machines began {{the improvement of}} spe-cific physical behaviour, especially the efficiency, {{has been one of}} the key issues. However, improvement of the efficiency of a turbo engine, is hard to archive using a conventional deterministic optimization, since the geometry is not perfect and many other parameters vary in the real approach. In contrast, stochastic design optimization is a methodology that enables the solving of optimization problems which model the effects of uncertainty in manufac-turing, design configuration and environment, in which robustness and reliability are explicit optimization goals. Therein, a coupling of stochastic and optimization prob-lems implies high computational efforts, whereby the calculation of the stochastic constraints represents the main effort. In view of this fact, an industrially relevant algorithm should satisfy the conditions of precision, robustness and efficiency. In this paper an efficient approach is presented to assist reducing the number of design evaluations necessary, in particular the number of nonlinear fluid-structure interaction analyses. In combination with a robust estimation of the safety level within the iteration and a final precise reliability analysis, the method presented is particularly suitable for solving reliability-based structural design optimization problems with ever-changing failure probabilities of the nominal designs. The applicability for real case applications is demonstrated through the example of a radial compressor, with a very high degree of complexity and a large number of design parameters and random variables. ...|$|R
40|$|Figure 1 : Wavelength-dependent {{subsurface}} scattering with single wavelength sampling (left) and our proposed method (right). The lower image halves are rendered with 4 paths per pixel, {{and the upper}} halves are rendered with 1024. For both sample counts, the hero wavelength images took only 3. 5 % longer than the single wavelength ones. We present a spectral rendering technique that offers a compelling set of advantages over existing approaches. The key idea is to propagate energy along paths for a small, constant number of changing wavelengths. The first of these, the hero wavelength, is randomly sampled for each path, and all <b>directional</b> <b>sampling</b> is solely based on it. The additional wavelengths are placed at equal distances from the hero wavelength, so that all path wavelengths together always evenly cover the visible range. A related technique, spectral multiple importance sampling, was already introduced a few years ago. We propose a simplified and optimised version of this approach which is easier to implement, has good performance character-istics, and is actually {{more powerful than the}} original method. Our proposed method is also superior to techniques which use a static spectral representation, as it does not suffer from any inherent representation bias. We demonstrate the performance of our method in several application areas that are of critical importance for production work, such as fidelity of colour reproduction, sub-surface scattering, dispersion and volumetric effects. We also discuss how to couple our proposed approach with several technologies that are important in current production systems, such as photon maps, bidirectional path tracing, environment maps, and participating media...|$|R
40|$|This paper aims {{to assess}} the role of Cu on Al-Si-Mg alloys, {{in a range of}} 0 - 5 wt%, qualitatively on microstructure, defect formation, in terms of porosity, and {{strength}} in the as-cast conditions. The ternary system of Al - Si - Mg, using the A 356 alloy as a base material, were cast using the gradient solidification technique; applying three different solidifica tion rates to produce <b>directional</b> solidified <b>samples</b> with a variety of microstructure coarsenesses. Microstructural ob servations reveal that as the Cu levels in the alloys are increased, the amounts of intermetallic compounds as well as the Cu concentration in the α -Al matrix are increased. Furthermore, the level of porosity is unaffected and the tensile strength is improved at the expense of ductility. </p...|$|R
40|$|The {{proportion}} {{of air pollution}} control (APC) residue in fugitive dust from the active cell of a hazardous waste landfill has been quantified using multi-element analytical data in combination with directional information about the dust samples collected. Passive sampling gauges (DustScan®) were deployed at {{the periphery of the}} cell, and samples were collected at fortnightly intervals. They were scanned for dust coverage and direction, and sub-samples were digested using HF and HNO 3 prior to analysis for a range of metals using ICPAES. Dust samples were initially categorised on the basis of direction and distance with respect to the active cell, and overall colour. Independent graphical manipulation of the elemental data revealed separate dust populations with several demonstrably different inter-element ratios. These populations accord well with the initial dust characterisation, and consequent designation as “APC” and “background” has been confirmed by chemical comparison with grab samples from the active cell, the landfill clay and the topsoil cap. As well as allowing confident graphical discrimination between APC and background dusts, the technique provides datasets amenable to multivariate statistics. Principal component analysis followed by partial least-squares regression provides a rigorous way of investigating correlations within the data and predicting the explicable variance resulting from chosen end members. Element loadings on the first two components essentially confirm the results of the intuitive graphical approach. APC and clay/soil grab samples are successful signatures for PLS, for complementary sample groups. On the basis of both the intuitive and the statistical data handling, distinctive elemental ratios characteristic of APC and background dusts can be paired in order to define binary mixing trajectories, and thus quantify APC proportion in any individual sample. In one of the sampling intervals under consideration, some 65 % APC was recorded close to the active cell margin, decreasing rapidly with dust fall out to 30 % within a few hundred metres. This trial study indicates the potential of combining <b>directional</b> <b>sampling</b> with sensitive multi-element analysis to quantify fugitive dust from landfill and other facilities in the waste and industrial sectors...|$|R
40|$|Wepresent {{five new}} {{variance}} reduction techniques applicable toMonte Carlo simulations of radiative transfer in the atmosphere: detector <b>directional</b> importance <b>sampling,</b> n-tuple local estimate, prediction-based splitting and Russian roulette, and circumsolar virtual importance sampling. With {{this set of}} methods {{it is possible to}} simulate remote sensing instruments accurately and quickly. In contrast to all other known techniques used to accelerate Monte Carlo simulations in cloudy atmospheres – except for two methods limited to narrow angle lidars – the presented methods do not make any approximations, and hence do not bias the result. Nevertheless, these methods converge as quickly as any of the biasing acceleration techniques, and the probability distribution of the simulation results is almost perfectly normal. The presented variance reduction techniques have been implemented into the Monte Carlo code MYSTIC (‘‘Monte Carlo code for the physically correct tracing of photons in cloudy atmospheres’’) in order to validate the techniques...|$|R
40|$|A tunable local {{oscillator}} with a tunable circuit that includes a resonator and a transistor as an active element for oscillation. Tuning of the circuit is achieved with an externally applied dc bias across coupled lines on the resonator. Preferably the resonator is a high temperature superconductor microstrip ring resonator with integral coupled lines formed over a thin film ferroelectric material. A <b>directional</b> coupler <b>samples</b> {{the output of the}} oscillator which is fed into a diplexer for determining whether the oscillator is performing at a desired frequency. The high-pass and lowpass outputs of the diplexer are connected to diodes respectively for inputting the sampled signals into a differential operational amplifier. The amplifier compares the sampled signals and emits an output signal if {{there is a difference between}} the resonant and crossover frequencies. Based on the sampled signal, a bias supplied to the ring resonator is either increased or decreased for raising or lowering the resonant frequency by decreasing or increasing, respectively, the dielectric constant of the ferroelectric...|$|R
