14|80|Public
40|$|Writing {{concurrent}} {{programs in}} languages that lack explicit support for concurrency {{can often be}} awkward and difficult. Haskell’s monads provide a way to explicitly specify sequence and effects in a functional language, and monadic combinators allow composition of monadic actions, for example via parallelism and choice – two core aspects of Communicating Sequential Processes (CSP). We show how {{the use of these}} combinators, and being able to express processes as first-class types (monadic actions) allow for easy and <b>elegant</b> <b>programming</b> of process-oriented concurrency in a new CSP library for Haskell: Communicating Haskell Processes...|$|E
40|$|Middleboxes {{are heavily}} {{used in the}} Internet to process the network tra c for a speci c purpose. As there is no open standards, these {{proprietary}} boxes are expensive and di - cult to upgrade. In this paper, we present a programmable platform for middleboxes called FlowOS to run on commod- ity hardware. It provides an <b>elegant</b> <b>programming</b> model for writing ow processing software, which hides the complexi- ties of low-level packet processing, process synchronisation, and inter-process communication. We show that FlowOS itself does not add any signi cant overhead to ows by pre- senting some preliminary test results. Peer reviewe...|$|E
40|$|Logic {{programming}} {{is one of}} a batch of new-generation tools derived from the field of artificial intelligence and presenting new challenges and opportunities to those concerned with managing and processing data. This paper is a review of the underlying theory of logic programming, demonstrating how simple spatial problems may be expressed in the language of logic and then transformed into a syntax suitable for automated theorem proving. The implementation of automated theorem proving as a general purpose logic programming language is illustrated by means of PROLOG and examples of PROLOG applications are drawn from the literature. Logic {{programming is}} presented both as an <b>elegant</b> <b>programming</b> language and also as a modelling framework with strong theoretical roots offering a fresh approach to the formulation and solution of spatial problems. Pointers are offered to its potential applications in this field. ...|$|E
25|$|Unfortunately {{there may}} be a {{tradeoff}} between goodness (speed) and elegance (compactness)—an <b>elegant</b> <b>program</b> may take more steps to complete a computation than one less elegant. An example that uses Euclid's algorithm appears below.|$|R
40|$|Jensen et al. {{present a}} simple and <b>elegant</b> <b>program</b> model, within a {{specification}} and verification framework for checking control flow based security properties by model checking techniques. We generalise this model and framework to allow for compositional specification and verification of security properties of multi-application programs. The framework contains a program model for multi-application programs, and a temporal logic to specify security properties about such programs...|$|R
40|$|CuPit- 2 is a {{programming}} language specifically designed to express neural network learning algorithms. It provides most of the flexibility of general-purpose languages like C/C ++, but results in much clearer and more <b>elegant</b> <b>programs</b> due to higher expressiveness, in particular for algorithms that change the network topology dynamically (constructive algorithms, pruning algorithms). Furthermore, CuPit- 2 programs can be compiled into efficient code for parallel machines; no changes are required in the source program. This article presents {{a description of the}} language constructs and reports performance results for an implementation of CuPit- 2 on symmetric multiprocessors (SMPs) ...|$|R
40|$|The {{major part}} of environments for {{parallel}} programming in distributed systems either neglects load distribution support or realizes load distribution by the trivial task farming paradigm. This paper presents new language concepts {{for the support of}} application integrated load distribution. In addition to the task farming approach, the system can also dynamically migrate objects. Active objects and passive objects are combined to a very flexible and <b>elegant</b> <b>programming</b> model. Specific tasks for initialization and migration are used to realize efficient and portable load distribution mechanisms. The paper describes the new programming model and presents language constructs realizing this model. The language constructs are an extension of the parallel and distributed programming language ParMod-C. A program example shows the usage of the new language constructs and demonstrates easy implementation of load distribution using the new concept. 1 Introduction Environments for parallel progr [...] ...|$|E
40|$|Proof {{assistants and}} the {{programming}} languages that implement them {{need to deal}} with a range of expressions that involve bindings. Many mature proof assistants have been extended with various packages and libraries so that bindings are addressed using various techniques (e. g., de Bruijn numerals and nominal logic). I argue here, however, that bindings are such an intimate aspect of the structure of expressions that they should be accounted for directly in the under-lying programming language support for proof assistants. High-level and semantically <b>elegant</b> <b>programming</b> language support can be found in rather old and familiar concepts. In particular, Church’s Simple Theory of Types has long ago provided answers to how bindings interact with logical connectives and quantifiers. Similarly, the proof search interpretation of Gentzen’s proof theory provides a rich model of computation that supports bindings. I outline several principles for dealing computationally with bindings that follow from their treatments in quantificational logic and sequent calculus. I also briefly describe some implementations of these principles that have helped to validate their effectiveness as computational principles. 1 Mechanization of meta theor...|$|E
40|$|International audienceIn {{functional}} reactive programming (FRP), system {{inputs and}} outputs are generally modeled as functions over continuous time (behaviors) whose future values are governed by sudden changes (events). In this approach, discrete events are embedded into piece-wise continuous behaviors. In the field of reactive music system programming, we develop an orthogonal approach that seems to better fit our need. Much like piano keys can be played and combined both in sequence and in parallel, we model system {{inputs and outputs}} as spatio-temporal combinations {{of what we call}} temporal values: continuous functions over time whose domain lays between two events: a start and a stop event. Various high level data types and program constructs can then be derived from such a model. They are shown to satisfy robust algebraic and category theoretic properties. Altogether, this eventually provides a simple, robust and <b>elegant</b> <b>programming</b> front-end, temporal tile programming, for reading, memorizing, stretching, combining and transforming flows of inputs into flows of outputs. Although at its infancy, the resulting approach has been experimentally validated for reactive and real-time music system programming...|$|E
40|$|Agent {{programming}} languages for rational agents {{provide an}} action selection mechanism based on practical reasoning. In the GOAL programming language agents derive {{their choice of}} action from their beliefs and goals. These high-level, common sense concepts allow for the specification of <b>elegant</b> <b>programs</b> {{for a variety of}} tasks. Rational agents however are expected to optimize their performance and the common sense concepts of beliefs and goals do not always provide the right tools for the specification of such behaviour. We explore some extensions of agent programming, more specific of the GOAL agent programming language, with simple heuristic techniques to allow agents to generate near-optimal behaviour...|$|R
40|$|Abstract. As {{software}} {{tends to}} be increasingly concurrent, the paradigm of message passing is becoming more prominent in computing. The language Erlang offers an intuitive and industry-tested implementation of process-oriented programming, combining pattern-matching with message mailboxes, resulting in concise, <b>elegant</b> <b>programs.</b> However, it lacks a successful static verification mechanism that ensures safety and determinism of communications with respect to well-defined specifications. We present a session typing system for a featherweight Erlang calculus that encompasses the main communication abilities of the language. In this system, structured types are used to govern the interaction of Erlang processes, ensuring that their behaviour is safe {{with respect to a}} defined protocol. The expected properties of subject reduction and type safety are established. ...|$|R
40|$|The Targeted Jobs Tax Credit (TJTC) is a {{representative}} redistributive incentive. Initially, proponents saw TJTC as an <b>elegant</b> <b>program,</b> efficiently promoting labor market behavior that would solve the employment problems of many disadvantaged job seekers. However, interest groups distorted the credit into a windfall for businesses that hire {{large numbers of}} low wage workers. The policy theories incorporated into TJTC, which emphasized continual program reform and minimized program management by public administrators, provided a setting conducive to interest group distortion. Because few representatives of the disadvantaged participated in the oversight process, special interests undermined TJTC being reformed through empirical evaluation. This experience indicates that without {{major changes in the}} policy process, narrowly targeted rzdistributive policies should be avoided. ...|$|R
40|$|The {{closely related}} {{research}} areas management of semistructured data and languages for querying the Web have recently attracted {{a lot of}} interest. We argue that languages supporting deduction and object-orientation (dood languages) are particularly suited in this context: Objectorientation provides a exible common data model for combining information from heterogeneous sources and for handling partial information. Techniques for navigating in object-oriented databases {{can be applied to}} semistructured databases as well, since the latter may be viewed as (very simple) instances of the former. Deductive rules provide a powerful framework for expressing complex queries in a high-level, declarative programming style. We elaborate on the management of semistructured data and show how reachability queries involving general path expressions and the extraction of data paths in the presence of cyclic data can be handled. We then propose a formal model for querying structure and contents of Web data and present its declarative semantics. A main advantage of our approach is that it brings together the above-mentioned issues in a uni ed, formal framework and|using the Florid system|supports rapid prototyping and experimenting with all these features. Concrete examples illustrate the concise and <b>elegant</b> <b>programming</b> style supported by Florid and substantiate the above-mentioned claims...|$|E
40|$|We present Jabberwocky, {{a social}} {{computing}} stack {{that consists of}} three components: a human and machine resource management system called Dormouse, a parallel programming framework for human and machine computation called ManReduce, and a high-level programming language on top of ManReduce called Dog. Dormouse is designed to enable cross-platform programming languages for social computation, so, for example, programs written for Mechanical Turk can also run on other crowdsourcing platforms. Dormouse also enables a programmer to easily combine crowdsourcing platforms or create new ones. Further, machines and people are both first-class citizens in Dormouse, allowing for natural parallelization and control flows for {{a broad range of}} data-intensive applications. And finally and importantly, Dormouse includes notions of real identity, heterogeneity, and social structure. We show that the unique properties of Dormouse enable <b>elegant</b> <b>programming</b> models for complex and useful problems, and we propose two such frameworks. ManReduce is a framework for combining human and machine computation into an intuitive parallel data flow that goes beyond existing frameworks in several important ways, such as enabling functions on arbitrary communication graphs between human and machine clusters. And Dog is a high-level procedural language written on top of ManReduce that focuses on expressivity and reuse. We explore two applications written in Dog: bootstrapping product recommendations without purchase data, and expert labeling of medical images. ACM Classification: H 5. 2 [Information interfaces and presentation]...|$|E
40|$|I {{wrote this}} book to help teach LISP to {{students}} in a course on data structures. Consequently it contains a careful description of the data structures manipulated by LISP functions. These data structures and others, notably hash tables, are also used in constructing a LISP interpreter. I wish to acknowledge the help of readers in shaping and debugging this material. The study of LISP, coupled with the study of a LISP interpreter intended for exhibition, is of special interest to students {{in the areas of}} programming languages and computer architecture as well as data structures. Indeed, I hope this book will be useful to students in all areas of computer science, and I also hope it will be useful to autodidacts, professional programmers, and computer enthusiasts {{in a wide variety of}} fields. This book is intended to be accessible to a wide range of interested readers from high school students through professional programmers. I would very much like to see students use this book to help them understand LISP interpreters, and thus understand the concepts involved in building an interpreter for any language. The best way to proceed is to compile and run the C LISP interpreter, and then experiment by modifying it in various ways. Finally, I hope this book can help all who use it develop an aesthetic appreciation of this <b>elegant</b> <b>programming</b> language...|$|E
40|$|Why did {{a magician}} become a mathematician? How can a person see in four dimensions? What does a {{mathematical}} proof {{have in common}} with a Picasso portrait? This <b>elegant</b> <b>program</b> brings to life the human dimension of mathematics through lively interviews with Freeman Dyson, David Mumford, Ingrid Daubechies, Persi Diaconis, Michael Freedman, Fan Chung Graham, Kate Okikiolu, Jennifer Tour Chayes, Peter Sarnak, Steven Strogatz, and seven other mathematicians. These captivating luminaries vividly communicate the excitement and wonder that fuel their work as they explore the world through its patterns, shapes, motions, and probabilities. Computer animations and analogies drawn from the visual arts are incorporated, to maximize accessibility to the fascinating concepts discussed. A Wendy Conquest/Bob Drake/Dan Rockmore Production. (51 minutes...|$|R
5000|$|The ZX81 version {{received}} a positive review from Popular Computing Weekly. As quoted on the packaging for the later ZX Spectrum version, they stated [...] "No words can {{do justice to}} this most <b>elegant</b> of <b>programs</b> ... You will not see a better computer game till Psion produce one for the Spectrum".|$|R
40|$|Abstract. Higher-order {{abstract}} syntax (HOAS) {{refers to the}} technique of representing variables of an object-language using variables of a meta-language. The standard first-order alternatives force the programmer to deal with superficial concerns such as substitutions, whose implementation is often routine, tedious, and error-prone. In this paper, we describe the underlying calculus of Delphin. Delphin is a fully implemented functional-programming language supporting reasoning over higher-order encodings and dependent types, while maintaining the benefits of HOAS. More specifically, just as representations utilizing HOAS free the programmer from concerns of handling explicit contexts and substitutions, our system permits programming over such encodings without making these constructs explicit, leading to concise and <b>elegant</b> <b>programs.</b> To this end our system distinguishes bindings of variables intended for instantiation from those that will remain uninstantiated, utilizing a variation of Miller and Tiu’s ∇-quantifier [1]. ...|$|R
40|$|Software {{maintenance}} {{is a complex}} and costly process. Previous {{research has shown that}} software restructuring techniques can be used to reduce the overall time and cost required to perform software maintenance. This research builds on a visualization technique called the star diagram that can help a programmer understand and manipulate the overall structure of a program. The star diagram uses a tree-like graphical representation to display the definition of a variable and its uses throughout the program. It has been proven to work successfully on small programs written in a simple, <b>elegant</b> <b>programming</b> language. However, as the number of references of a global variable increases, the arms in the original star diagram grow longer and wider, increasingly becoming less effective in promoting the understanding of the structure. In addition, the original star diagram does not allow the user to modify the visualization without restructuring the actual source code. This research uses simple elision techniques to deal with the scalability of a star diagram and provide the flexibility of planning a restructuring without modifying the program. For a software restructuring tool to help lower maintenance costs on large, modern systems, it must work on a widely used programming language such as C. This research provides numerous extensions to the original star diagram to work specifically with the C language grammar. Our work presents a simple visualization method for understanding and planning the restructuring of data abstractions in large systems written in the C programming language...|$|E
40|$|These Lecture Notes {{refer to}} the {{examples}} and illustrations proposed in the book A Guide to Modern Econometrics by Marno Verbeek (4 th and 3 rd editions). The source codes here described are written in the R language (R Development Core Team, 2012) (R version 2. 15. 1 was used). Subjects are presented in the course Computational Laboratory for Economics held at Università Cattolica del Sacro Cuore, Graduate Program Economics. The course runs in parallel with the course Empirical Economics where the methodological background is assessed. Attention was paid {{in order to obtain}} results first according to their mathematical structure, and then by using appropriate built-in R functions, anyway searching for an efficient and <b>elegant</b> <b>programming</b> style. The reader is assumed to possess the basic knowledge of R. An introduction to R by Longhow Lam, available on [URL] may represent a good reference. Chapters from 2 to 10 recall the contents of Verbeek's Guide. Appendix A 1 describes how to read data from text, Stata and EViews files, which are the formats used by Verbeek on his book website, where data sets are available. Appendix B contains results for examples which were present on the 3 rd edition of Verbeek's Guide. Some companion materials to these Lecture Notes can be downloaded from the booksite www. educatt. it/libri/materiali. I warmly thank Diego Zappa and Giuseppe Boari for having read parts of the manuscript. I wish to thank Stefano Iacus for his short course on an efficient and advanced use of R, and Achim Zeileis, Giovanni Millo and Yves Croissant for having improved their libraries lmtest and plm in order to properly fit some problems here presented...|$|E
40|$|These notes refer {{mainly to}} the {{examples}} and illustrations proposed in the book A Guide to Modern Econometrics by Marno Verbeek (4 th and 3 rd editions). The source codes here described are written in the R language (R Development Core Team 2016) (R version 3. 2. 4 was used). Subjects were initially presented in the course Computational Laboratory for Economics held at Università Cattolica del Sacro Cuore, Graduate Program Economics. The course ran in parallel with the course Empirical Economics where the methodological background were assessed. Attention is paid {{in order to obtain}} results first according to their mathematical structure, and then by using appropriate built-in R functions, always aiming at achieving an efficient and <b>elegant</b> <b>programming</b> style. The reader is assumed to possess the basic knowledge of R. In Chapter 1 some simulation results on the distribution properties of the sample mean are shown. Chapters from 2 to 10 reproduce results of examples and illustrations of Verbeek’s Guide. Appendix A 1 describes how to read data from text, Stata, EViews and Microsoft Excel files. Appendix B contains results for examples which were present on the 3 rd edition of Verbeek’s Guide. Detailed methodological presentations are given on the geometric interpretation of the linear model and OLS, on multicollinearity problems and their detection, on the assessment of distributional hypotheses (Chapter 2), on the interpretation of coefficients in linear regression model with logarithmic transformation of the outcome or of explanatory variables (Chapter 3), on the application of the GMM (Chapter 5), on the interpretation of marginal effects for logit and probit models and of odds ratio for logit models (Chapter 7) and on the classical presentation of stochastic processes (Chapter 8) ...|$|E
40|$|Non-strict {{evaluation}} {{improves the}} expressive power of functional languages {{at the expense}} of an apparent loss of efficiency. In this paper we give examples of this expressive power, taking as an example an interactive functional program and describing the programming techniques depending on non-strict evaluation which improved its design. Implementation methods for non-strict languages have delivered poor performance precisely when such programming techniques have been used. This need not be the case, however, and {{in the second part of}} the paper we describe Tim, a method of implementing non-strict languages for which the penalty for using lazy evaluation is very small. 1 Introduction Effort in the functional programming community is today divided into two main activities: making efficient implementations of functional languages and exploiting the expressive power of these languages by writing <b>elegant</b> <b>programs.</b> To a large extent these activities are carried out by separate groups of p [...] ...|$|R
40|$|CuPit- 2 is a {{special-purpose}} {{programming language}} designed for expressing dynamic neural network learning algorithms. It provides {{most of the}} flexibility of general-purpose languages such as C or C ++, but is more expressive. It allows writing much clearer and more <b>elegant</b> <b>programs,</b> in particular for algorithms that change the network topology dynamically (constructive algorithms, pruning algorithms). In contrast to other languages, CuPit- 2 programs can be compiled into efficient code for parallel machines without any changes in the source program, thus providing an easy start for using parallel platforms. This article analyzes {{the circumstances under which}} the CuPit- 2 approach is the most useful one, presents a description of most language constructs and reports performance results for CuPit- 2 on symmetric multiprocessors (SMPs). It concludes that in many cases CuPit- 2 is a good basis for neural learning algorithm research on small-scale parallel machines. Keywords: neural networks [...] ...|$|R
40|$|Logical {{frameworks}} are languages used {{to represent}} information. In this dissertation we present the Delphin programming language, which is a functional programming syntax and dependent types. Higher-order abstract syntax, or HOAS, refers to the technique of representing variables of an object language using variables of a metalanguage, which leads to more concise and elegant encodings than first-order alternatives. Dependent types allow one to represent complex data (such as derivations in various logics) and enforce more properties of programs than possible using only simple types. Delphin {{is not only a}} useful programming language but also a useful system for formalizing proofs as total functions express proofs that the input entails the output. Just as representations using HOAS free the programmer from concerns of handling explicit contexts and substitutions, our system permits computation and reasoning over such encodings without making these constructs explicit, leading to concise and <b>elegant</b> <b>programs.</b> Delphin is a two-level system distinguishing functions use...|$|R
40|$|The {{prevalence}} of chip multiprocessor opens opportunities of running data-parallel applications originally in clusters {{on a single}} machine with many cores. MapReduce, a simple and <b>elegant</b> <b>programming</b> model to program large scale clusters, has recently {{been shown to be}} a promising alternative to harness the multicore platform. The differences such as memory hierarchy and communication patterns between clusters and multicore platforms raise new challenges to design and implement an efficient MapReduce system on multicore. This paper argues that it is more efficient for Map-Reduce to iteratively process small chunks of data in turn than processing a large chunk of data at one time on shared memory multicore platforms. Based on the argument, we extend the general MapReduce programming model with “tiling strategy”, called Tiled-MapReduce (TMR). TMR partitions a large MapReduce job into a number of small sub-jobs and iteratively processes one subjob at a time with efficient use of resources; TMR finally merges the results of all sub-jobs for output. Based on Tiled-MapReduce, we design and implement several optimizing techniques targeting multicore, including the reuse of input and intermediate data structure among sub-jobs, a NUCA/NUMA-aware scheduler, and pipelining a sub-job’s reduce phase with the successive sub-job’s map phase, to optimize the memory, cache and CPU resources accordingly. We have implemented a prototype of Tiled-MapReduce based on Phoenix, an already highly optimized MapReduce runtime for shared memory multiprocessors. The prototype, namely Ostrich, runs on an Intel machine with 16 cores. Experiments on four different types of benchmarks show that Ostrich saves up to 85 % memory, causes less cache misses and makes more efficient uses of CPU cores, resulting in a speedup ranging from 1. 2 X to 3. 3 X...|$|E
40|$|Java is {{for sure}} {{the most popular}} {{programming}} language today. Its popularity {{is based on the}} portability of the code and on the <b>elegant</b> <b>programming</b> framework provided by the language: built in garbage collection and multi-threaded support, easy Internet application development through socket streams, and last but not least familiar syntax. Even if a lot of work has already been done related to Java Virtual Machines (JVMs) and a large number of Java applications are already available, few of these have penetrated the DSP world. Our work aims to bridge this gap between DSP architectures and Java. Such a connection would open the DSP world to a much larger class of consumers, a place now occupied by general-purpose processors. The two main research directions we see in improving the performance of a JVM for DSP architectures are: (1) writing a Java bytecode Just-In-Time compiler optimized for a specific DSP platform, and (2), taking advantage of the available parallelism present in DSP multi-processor architectures. Our work focuses on the last issue. We propose a distributed JVM designed for a multi-processor DSP architecture. Due to the unavailability of the hardware at the moment, we have implemented our ideas on a network of general-purpose processors, emulating the topology of the quad-processor DSP board constructed by Innovative DSP. We emulate the I/O channels connecting the processors through TCP sockets and interrupts with Unix signals. All the protocols use a constant number of messages, making it possible to estimate the costs of all distributed actions. In this document we show the design and test results obtained with DISK. While a distributed JVM architecture may not prove to be an exciting project for highly-specialized DSP processors (such as TI's TMS 320 family), we believe that this work may be successfully applied to multiprocessor architectures based on RISC processors enhanced with signal processing capabilities (such as the new ARM 9 E processor). Other projects are working on porting Java to this class of processors. On top of this we provide a Java parallel-processing platform that binds the power of Java distributed computing with signal processing. ...|$|E
40|$|Submission to the Special Issue on ”Simulation of Artificial Neural Networks” for the Systems Analysis Modelling Simulation (SAMS) journal CuPit- 2 is a {{special-purpose}} {{programming language}} designed for expressing dynamic neural network learning algorithms. It provides {{most of the}} flexibility of general-purpose languages such as C or C ++, but is more expressive. It allows writing much clearer and more <b>elegant</b> <b>programs,</b> in particular for algorithms that change the network topology dynamically (constructive algorithms, pruning algorithms). In contrast to other languages, CuPit- 2 programs can be compiled into efficient code for parallel machines without any changes in the source program, thus providing an easy start for using parallel platforms. This article analyzes {{the circumstances under which}} the CuPit- 2 approach is the most useful one, presents a description of most language constructs and reports performance results for CuPit- 2 on symmetric multiprocessors (SMPs). It concludes that in many cases CuPit- 2 is a good basis for neural learning algorithm research on small-scale parallel machines...|$|R
40|$|A {{new kind}} of metaobject protocol, that {{controls}} the compilation of programs, allows users {{to participate in the}} compilation in a principled and modular way. Such a compiler makes it possible to program in a high-level language and still maintain control over crucial implementation issues. This result is that a number of simple and <b>elegant</b> Scheme <b>programs</b> can be compiled as efficiently {{as if they had been}} written with special purpose primitives. ...|$|R
40|$|This {{paper is}} based on the {{tutorial}} given as part of the tutorial programme of CLIMA-VI. The tutorial aimed at giving an overview of the various features available in Jason, a multi-agent systems development platform that {{is based on}} an interpreter for an extended version of AgentSpeak. The BDI architecture is the best known and most studied architecture for cognitive agents, and AgentSpeak is an <b>elegant,</b> logic-based <b>programming</b> language inspired by the BDI architecture...|$|R
40|$|This is {{a conference}} paper. There {{is little doubt}} that design work {{provides}} a natural focus for Information Technology (IT) activities and that both profile components of National Curriculum Technology are intended to be centred upon real applications and real situations. Despite a plethora of computer software applications which might be considered relevant in the context of Design and Technology work, few are rarely designed {{to meet the needs of}} pupil learners and so it is not surprising that few are used effectively. If IT is to become an effective tool in education, there is an urgent need to consider how pupils and students learn through interaction with computer media, and ways in which the teacher’s role might be developed. These issues are quite different from, but no less important than, those considered by the software engineer, who is predominantly concerned with providing <b>elegant</b> <b>program</b> code and sophisticated program facilities. This paper discusses how these two sets of, often contradictory, matters may be corporately considered to provide more effective software design. In particular, it considers how research, development and evaluation, concerned with computer applications, might take more effective account of educationalists’ views, teachers’ requirements and pupils’ needs...|$|R
40|$|The {{conciseness}} conjecture is {{a longstanding}} notion {{in computer science}} that programming languages with more built-in operators, that is more expressive languages with larger semantics, produce smaller programs on average. Chaitin defines the related concept of an <b>elegant</b> <b>program</b> such {{that there is no}} smaller program in some language which, when run, produces the same output. This thesis investigates the conciseness conjecture in an empirical manner. Influenced by the concept of <b>elegant</b> <b>programs,</b> we investigate several models of computation, and implement a set of functions in each programming model. The programming models are Turing Machines, λ-Calculus, SKI, RASP, RASP 2, and RASP 3. The information content of the programs and models are measured as characters. They are compared to investigate hypotheses relating to how the mean program size changes as the size of the semantics change, and how the relationship of mean program sizes between two models compares to that between the sizes of their semantics. We show that the amount of information present in models of the same paradigm, or model family, is a good indication of relative expressivity and average program size. Models that contain more information in their semantics have smaller average programs for the set of tested functions. In contrast, the relative expressiveness of models from differing paradigms, is not indicated by their relative information contents. RASP and Turing Machines have been implemented as Field Programmable Gate Array (FPGA) circuits to investigate hardware analogues of the hypotheses above. Namely that the amount of information in the semantics for a model directly influences the size of the corresponding circuit, and that the relationship of mean circuit sizes between models is comparable to the relationship of mean program sizes. We show that the number of components in the circuits that realise the semantics and programs of the models correlates with the information required to implement the semantics and program of a model. However, the number of components to implement a program in a circuit for one model does not relate to the number of components implementing the same program in another model. This is in contrast to the more abstract implementations of the programs. Information is a computational resource and therefore follows the rules of Blum’s axioms. These axioms and the speedup theorem are used to obtain an alternate proof of the undecidability of elegance. This work is a step towards unifying the formal notion of expressiveness with the notion of algorithmic information theory and exposes a number of interesting research directions. A start has been made on integrating the results of the thesis with the formal framework for the expressiveness of programming languages...|$|R
40|$|Abstract. Constraint Handling Rules (CHR) is an <b>elegant,</b> {{high-level}} <b>programming</b> language {{based on}} multi-headed, forward chaining rules. A distinguishing feature of CHR are propagation rules. To avoid trivial non-termination, CHR implementations ensure a CHR rule is applied at most once {{with the same}} combination of constraints by maintaining a so-called propagation history. The performance impact of this history is often significant. We introduce two optimizations to reduce or even eliminate this overhead, and evaluate their implementation in two stateof-the-art CHR systems. ...|$|R
40|$|AbstractWe {{investigate}} the changing {{relationship between the}} small research community of theoretical computer scientists and the much larger community of computer users, in particular, the technology transfer {{problem of how to}} exploit theoretical insights that can lead to better products. Our recommendation can be summarized in four points: 1 The computing community is impressed by usable tools and by little else. Although a powerful theorem or ån elegant algorithm may be a useful tool for a fellow theoretician, by and large, the only tools directly usable by the general computing community are systems. No systems, no impact! 2 System development means programming-in-the-large, but the algorithms research community so far has learned only how to program in-the-small. 3 Algorithm researchers must enshrine their algorithms not merely in individual <b>elegant</b> <b>programs,</b> but collectively in useful application packages aimed at some identifiable user group. 4 Since the development of software systems easily turns into a full-time activity that requires different skills from those of algorithms research, we must strive to develop techniques that lets a small group of algorithm researchers develop simply structured, open-ended systems whose kernel can be implemented with an effort of the order of 1 man-year. Low-complexity systems is the goal...|$|R
40|$|Constraint Handling Rules (CHR) is an <b>elegant,</b> {{high-level}} <b>programming</b> language {{based on}} multi-headed, forward chaining rules. To ensure CHR propagation rules are applied at most once {{with the same}} combination of constraints, CHR implementations maintain a so-called propagation history. The performance impact of this history can be significant. We introduce several optimizations that, {{for the majority of}} CHR rules, eliminate this overhead. We formally prove their correctness, and evaluate their implementation in two state-of-the-art CHR systems. This extended report contains complete formal proofs of all theoretical results. nrpages: 19 status: publishe...|$|R
40|$|Abstract—Recent work shows a {{tendency}} to use programming languages specific to the social aspects of multi-agent systems, for example in programming norms that agents ought to follow. In this paper, we introduce a simple and <b>elegant</b> normative <b>programming</b> language called NPL and show its operational semantics. We then define a particular class of NPL programs that are suitable for programming Organisation Management Infrastructures (OMI) for MOISE, defining a Normative Organisation Programming Language (NOPL). We show how MOISE’s Organisation Modelling Language can be translated into NOPL, and briefly describe how this all has been implemented {{on top of an}} artifact-based OMI for MOISE. I...|$|R
40|$|In this paper, we {{investigate}} a unified linear transceiver design with mean-square-error (MSE) as the objective function {{for a wide}} range of wireless systems. The unified design is based on an <b>elegant</b> mathematical <b>programming</b> technology namely quadratic matrix programming (QMP). It is revealed that for different wireless systems such as multi-cell coordination systems, multi-user MIMO systems, MIMO cognitive radio systems, amplify-and-forward MIMO relaying systems, the MSE minimization beamforming design problems can always be solved by solving a number of QMP problems. A comprehensive framework on how to solve QMP problems is also given. © 2012 IEEE. published_or_final_versio...|$|R
