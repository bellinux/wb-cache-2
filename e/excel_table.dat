29|111|Public
5000|$|... an <b>excel</b> <b>table</b> {{with data}} on {{emissions}} and materials depletion (more than 3000 substances), see [...] - an <b>excel</b> <b>table</b> on products and processes, based on LCIs of Ecoinvent, Idemat, and Agri Footprint (more than 10,000 lines), see ...|$|E
50|$|The latest SENSE ranking, as all {{previous}} rankings, {{is based on}} the subjective assessment of publisher's standing by prominent Dutch and international scientists. Their <b>EXCEL</b> <b>Table</b> is available from the SENSE website.|$|E
40|$|S 1 File {{includes}} the incorrect {{data in the}} “Data S 3 GREP model classifier ” tab and in Column F (GREP prediction) of the “Data S 4 in-vivo data ” tab, which are from another model not dis-cussed in this paper. Please see the corrected S 1 File here. The authors confirm that all results and figures in the original work remain unaffected by this error and correspond to the updated supplementary data in this correction. Supporting Information S 1 File. Supplementary data tables: In-vitro results. <b>Excel</b> <b>table</b> showing for each line the IC 50, Amax, experimental sensitivity call, MAS 5 gene expression value, 2 -gene prediction, and GREPDR 5 prediction for all genes used in the GREP model. All genes. <b>Excel</b> <b>table</b> showing dif-ferential analysis of all genes with DR 5 Nb 1 -tetra sensitivity calls. GREP model classifier. <b>Excel</b> <b>table</b> showing coefficients for ratios used in the GREPDR 5 model. In-vivo data. <b>Excel</b> <b>table</b> showing for each primary tumor xenograft model, the T/C, sensitivity call, GREP prediction and gene expression for all genes used in the GREP model. (XLSX...|$|E
5000|$|... <b>excel</b> <b>tables</b> on www.ecocostsvalue.com, tab data (look-up {{tables for}} {{designers}} and engineers): ...|$|R
2500|$|... (Data {{from the}} Register on 1 January 2006) and [...] <b>Excel</b> <b>tables</b> about name and surname {{distribution}} {{by age and}} province, from the Instituto Nacional de Estadística (Spain).|$|R
50|$|Jedox ODBO XMLA is a {{complementary}} Jedox component. This standard interface {{can be used}} by all ODBO-enabled Windows clients, e.g. Microsoft <b>Excel</b> Pivot <b>tables</b> or XMLA based web-service consumers to access and visualize Jedox data. Communication between Jedox and <b>Excel</b> Pivot <b>tables</b> is handled through the MDX query language for OLAP databases.|$|R
30|$|The Principal Investigator {{explained}} the rating procedure, 3 {{and then the}} two experienced raters received an audio CD with 100 extracts and electronic rating forms. They independently rated the samples at home and returned their rating results on an <b>Excel</b> <b>table</b> within 10  days.|$|E
40|$|This bachelor’s thesis {{describes}} {{development of}} an application, {{that can be used}} to generate reports from information system Ucetnictvi, specifically Flat register, in the form of a Microsoft <b>Excel</b> <b>table.</b> It outlines the process of development in the Microsoft Visual C# Express IDE and highlights the benefits of its usage...|$|E
30|$|Data {{obtained}} {{were organized}} in an <b>Excel</b> <b>table</b> (Microsoft Office Excel, Redmond, WA, USA) and {{were subjected to}} the SigmaPlot software (SigmaPlot, San Jose, CA, USA) version 12.0. The Shapiro-Wilk test was applied to verify wheter data presented normal distribution. As they did not, the Mann-Whitney test was used. For all statistical analyses, a 5 % significance level was adopted.|$|E
50|$|Since 2004/2005 the LSG {{has used}} a system utilising PHP and MySQL {{in order for}} {{reservation}} of the ICT rooms via the internet. This system replaces the previous one of MS <b>Excel</b> <b>tables,</b> and was developed by students of the LSG themselves, {{on the basis of}} the GPL. This system is also used by the Käthe-Kollwitz-Gymnasium.|$|R
40|$|The dataset {{contains}} input information used {{to prepare}} exposure maps for 37 European {{countries and territories}} from 1870 to 2020. It includes baseline land cover/use map and population map, and <b>Excel</b> <b>tables</b> with national or regional-level data on the environment, population and economy. Inofrmation on currencies and inflation {{can be used to}} convert nominal value of natural hazard-related losses to present-value euro...|$|R
40|$|The {{main goal}} of this thesis is to design and {{implement}} an information system for a language school, which will replace the existing data processing in Microsoft <b>Excel</b> <b>tables.</b> The system will work with language school's data like courses, translation, staff, books, customers and makes management work easier. The most of the processes will be accelerated or automated. It will also notify management for upcoming translations' deadlines or employees' ending contracts. ...|$|R
30|$|In MS Excel, all columns were deleted {{except those}} needed for {{subsequent}} calculations and {{to rejoin the}} <b>Excel</b> <b>table</b> to the Fire Frequency shapefile, these being RECNO 1, RECNO 2, YEAR, and SEASON. The column YEAR had been created from FIREYEAR within ArcGIS 9.0. This converted fire-years (e.g., of the form 1988 / 89) to single years (e. g., of the form 1988), by dropping {{the second part of}} the fire-year, which enabled simple arithmetic to calculate fire return intervals in the next stage of the process.|$|E
40|$|Abstract − IMEKO World Congress is {{gathering}} of {{experts in the}} field of metrology. More than 500 abstracts have been received during last year and even more people have registered for attending it. Huge number of applications required usage of modern technologies including Internet as a backbone for communication and interaction among participants and organisers. From one <b>excel</b> <b>table</b> we developed powerful web based application that can handle more than 5000 records thus enabling us to overcome difficulties that faced us during organisation of the congress. In this paper we describe how Croatian Metrology Society dealt with the challenge of organising IMEKO World Congress. We discuss about technologies used to attain multi user environment and accessibility of data t...|$|E
40|$|Abstract:- Platform {{independent}} Java {{application to}} support interaction between an instructor, teaching assistants {{and students in}} a traditional on-campus course is developed. The TSI (teacher-student interaction) application includes a specialized Web server, an ordinary Web server, a mailer and a simple database. The HTTP protocol is used for all communications. Both teachers and students employ Web browsers to access the TSI server. Students have possibilities to check their personal data (scores and comments), to download educational materials, to upload files and to communicate to the instructor or teaching assistants. The instructor and teaching assistants can upload <b>Excel</b> <b>table</b> containing student personal records, send personal e-mail messages to students, upload educational materials etc. Two-year use of the TSI system demonstrates {{that it is a}} helpful tool for improving communication between students and teachers in a traditional course...|$|E
5000|$|Nieto {{considered}} {{himself as a}} nerd in school. He preferred studying for examinations a week before because cramming does not work for him. He admitted being a [...] "teacher's pet" [...] in school, even until college. [...] Aside from studying, Nieto also has interest in sports such as tennis (his favorite), judo (which he <b>excels),</b> <b>table</b> tennis, badminton, and basketball (which in another interview he said he dislikes).|$|R
40|$|Can I {{have that}} in Excel? " This is a request that makes many of us shudder. Now your boss has {{discovered}} <b>Excel</b> pivot <b>tables.</b> Unfortunately, he has not discovered how to make them. So you get to extract the data, massage the data, put the data into Excel, and then spend hours rebuilding pivot tables every time the corporate data are refreshed. In this workshop, you learn to be the armchair quarterback and build pivot tables without leaving the comfort of your SAS ® environment. In this workshop, you learn the basics of <b>Excel</b> pivot <b>tables</b> and, {{through a series of}} exercises, you learn how to augment basic pivot <b>tables</b> first in <b>Excel,</b> and then using SAS. No prior knowledge of <b>Excel</b> pivot <b>tables</b> is required...|$|R
5000|$|Save as <b>Excel</b> Pivot <b>Table</b> {{has been}} deprecated; {{the ability to}} save {{directly}} into a Pivot Table is no longer available.|$|R
40|$|Protein {{methylation}} {{has recently}} {{emerged as an}} abundant and important posttranslational modification, affecting many cellular functions including transcription and translation. The budding yeast Saccharomyces cerevisiae has become an important model organism for studying methylation reactions and the enzymes responsible for catalyzing the reaction (methyltransferases). Generally, either unfractionated lysates from cells grown under fermentation or specific protein substrates of well-characterized methyltransferases have been investigated for protein methylation. As a result of this, the methylation state of proteins inside the mitochondria remains largely unknown. The goal of this dissertation was two-fold: 1.) determine the experimental requirements for thoroughly identifying the methylation state of proteins in yeast mitochondria and 2.) identify methylated proteins in mitochondria {{that may have been}} previously overlooked. 	Only one example in the scientific literature has investigated the global level of protein methylation in the mitochondria of any organism and only two proteins in the yeast mitochondria are known to be methylated. I set out to determine mitochondrial protein methylation by detecting differences between wild type and methyltransferase gene deletion yeast strains using a combination of commonly used biochemical and molecular biology assays. When I found that these methods were ill-suited for identification of mitochondrial protein methylation, I turned to mass spectrometry approaches. 	From my initial mass spectrometric analyses of proteolytic digests of yeast proteins, I learned that it was not sufficient to simply rely on computer algorithms to identify novel methylated peptides. It is important to use isotopic labeling to validate the mass shifts that occur as a result of methylation on identified peptides. This led me to use to adapt heavy methyl stable isotope labeling with amino acids in cell culture (SILAC) for use in yeast with my identification of a strain better suited for these experiments. From this approach, I have been able to curate a list of proteins comprising the mitochondrial methyl proteome. Using this method, I have also compared the cytosolic methyl proteome between yeast cells grown under fermentative or respiratory conditions. 	I conclude with future directions for the work included in this dissertation. The functional implications of the mitochondrial methylation reactions have yet to be discovered and the methyltransferases responsible remain to be identified. 	This dissertation contains three supplemental Excel spreadsheets. These materials are available on ProQuest. com. The first supplemental <b>Excel</b> <b>table</b> is an expanded version of Table 2 - 1 with a list of the known and putative methyltransferases in yeast, their confirmed and predicted substrate type, the substrate and residue methylated if known, and descriptions of the methyltransferase. The second <b>Excel</b> <b>table</b> contains data from nine separate mass spectrometry experiments, attempting to identify the methylation state of mitochondrial ribosomal proteins from wild type and methyltransferase gene deletion strains, including peptides identified and descriptions. The third supplemental <b>Excel</b> <b>table</b> contains the peptides identified as methylated in cytosol isolated from fermenting and respiring yeast cells...|$|E
40|$|Abstract. A simple course {{management}} tool (CMT) {{has been}} developed using Java and Web technologies. The Java application runs on any computer and supports interaction between an instructor, teaching assistants and students. It provides graphical user interface and includes a Web server, a mailer and a simple database. The HTTP protocol is used for all communications. Both teachers and students employ Web browsers to access the CMT server. Students have possibilities to check their personal data (scores and comments), to download educational materials, to upload files and to communicate to the instructor or teaching assistants. The instructor and teaching assistants can upload <b>Excel</b> <b>table</b> containing student personal records, send personal e-mail messages to students, upload educational materials etc. Several-year use of the CMT demonstrates {{that it is a}} helpful tool for improving communication between students and teachers. Main difference of the presented CMT from available course management system is in simplicity of its learning, installation and support...|$|E
40|$|Compact {{elliptical}} galaxies form a rare {{class of}} stellar system (~ 30 presently known) characterized by high stellar densities and small sizes and often harboring metal-rich stars. They {{were thought to}} form through tidal stripping of massive progenitors, until two isolated objects were discovered where massive galaxies performing the stripping could not be identified. By mining astronomical survey data, we have now found 195 compact elliptical galaxies in all types of environment. They all share similar dynamical and stellar population properties. Dynamical analysis for nonisolated galaxies demonstrates the feasibility of their ejection from host clusters and groups by three-body encounters, which is in agreement with numerical simulations. Hence, isolated compact elliptical and isolated quiescent dwarf galaxies are tidally stripped systems that ran away from their hosts. Comment: Published in Science, 8 pages, 7 figures, 1 table including the supplementary information section; MS <b>Excel</b> <b>table</b> with the list of galaxies is available here [URL]...|$|E
50|$|This project {{seeks to}} ensure that {{statistics}} are comparable, as far as possible, between countries and over time. This is done using similar definitions of variables in each country/year and applying consistent methods of data processing. In this way SEDLAC allows users to monitor the trends in poverty and other distributional and social indicators in the region. The dataset {{is available in the}} form of brief reports, charts and electronic <b>Excel</b> <b>tables</b> with information for each country/year. In addition, the website visitor can carry out dynamic searches online in the official website.|$|R
5000|$|In {{another room}} are located {{the remains of}} War 70: {{remnants}} of weapons, rifles, Yatagan, gun bullets, wheeled carts, running boards, found in Tajy and Boquerón, existing companies Umbu Island. It raises the curiosity of visitors a bed of iron, artistically worked, which belonged to Juanita Pesoa. And in the courtroom, which was supposed Marshal Lopez when she hosted the Intendant of the Army, <b>Excel</b> <b>tables</b> in oil signed by the painter Bartolome Martinez. In several paintings are scenes of bloody battles in some others women delivering their jewellery to Marshal, and portraits of Paraguayan hero, Madama Lynch and Pancha Garmendia.|$|R
5000|$|... #Caption: <b>ExCeL</b> London hosting <b>table</b> tennis {{events at}} the 2012 Summer Olympics.|$|R
40|$|This paper {{describes}} {{the evolution of}} the SAS ® programming of a report used in employee evaluations by a government agency. The data is taken from a survey seeking customers ’ opinion of the service they received from the agency. We entered the data into a SAS dataset and developed a ranking for each employee. The agency requires the final report to be in Excel. When we began processing the report, the programming was written in SAS Version 6. The report was derived from a CROSSTAB output. LST file and typed into an <b>Excel</b> <b>table.</b> With SAS Version 8, we were able to output the CROSSTAB table into an Excel file using ODS. Although the results were in Excel, they still required much editing. Thus, the first two versions were both time consuming and error prone. To resolve these issues, we changed the SAS programming and used PROC REPORT and ODS statements. This last evolution of SAS programming allows us to produce the report in nearly final format and with a lower potential for introducing error...|$|E
40|$|AbstractOne of {{the water}} {{treatment}} process used is Actiflo system, utilized {{the concept of a}} pre-determined amount of microsand concentration to expedite flocs settling by mixing a chemical known as microsand into the treatment. A high cost in chemical due to excessive amount of microsand consumption to treat water. The need of additional microsand is due to high volume of unwanted debris being pumped from water intake plant into Water Treatment Plant (WTP), resulting frequent equipment breakdown and inefficient microsand recirculation. This leads to microsand wastage and higher maintenance cost. Pareto Diagram method is used to determine and solve higher chemical cost consumption due to frequent equipment problem. Bernoulli's Principle is used to obtain optimum mesh size of debris strainer. The strainer designed using CATIA V 5 software. Data collected before and after implementing the strainer to analyze the result of microsand concentration and consumption. A comparison and analysis of chemical and maintenance cost explained using Microsoft Office <b>Excel</b> <b>table</b> and graph. The results showed that the new debris strainer design has improved by 33 % of microsand cost and 80 % on maintenance cost...|$|E
40|$|A {{review of}} star {{formation}} in the Rho Ophiuchi molecular complex is presented, with particular emphasis on studies of the main cloud, L 1688, since 1991. Recent photometric and parallax measurements of stars in the Upper Scorpius subgroup of the Sco-Cen OB association suggest a distance for the cloud between 120 and 140 parsecs. Star formation is ongoing in the dense cores of L 1688 with a median age for young stellar objects of 0. 3 Myr. The surface population {{appears to have a}} median age of 2 - 5 Myr and merges with low mass stars in the Upper Scorpius subgroup. Making use of the most recent X-ray and infrared photometric surveys and spectroscopic surveys of L 1688, we compile a list of over 300 association members with counterparts in the 2 MASS catalog. Membership criteria, such as lithium absorption, X-ray emission, and infrared excess, cover the full range of evolutionary states for young stellar objects. Spectral energy distributions are classified for many association members using infrared photometry obtained from the Spitzer Space Telescope. Comment: 30 pages, 9 figures, 4 tables, 1 <b>EXCEL</b> <b>table,</b> accepted for publication in the Handbook of Star Forming Regions, 2008, Astronomical Society of the Pacific, ed. Bo Reipurt...|$|E
5000|$|The Novell OpenOffice.org team, led by Michael Meeks, {{managed to}} create {{reasonably}} solid support for VBA macros in Microsoft Excel documents, {{and a new}} spreadsheet feature called [...] "Data Pilot" [...] which offers compatibility with Microsoft <b>Excel</b> Pivot <b>Tables</b> [...]|$|R
40|$|Historical censuses have an {{enormous}} potential for research. In order to fully use this potential harmonization of these censuses is essential. During the last decades enormous efforts have been undertaken in digitizing the published aggregated outcomes of the Dutch historical censuses (1795 - 1971). Although the accessibility has been improved enormously, we {{have to cope with}} hundreds of heterogeneous and disconnected <b>Excel</b> <b>tables.</b> As a result the census is still for the most part an untapped source of information. We describe the main harmonization challenges of the census and how we work towards one harmonized dataset. We propose a specific approach and model in creating an interlinked census dataset in the Semantic Web using the Resource Description Framework technology...|$|R
40|$|The {{traditional}} way to analyze stocks and portfolios within {{the area of}} finance have been restricted to Sharpe and Markovitz. The Omega function and its properties enlighten the field of finance and differs from the {{traditional way}}s {{when it comes to}} the volatility of the stocks. The Omega function, the Sharpe performance criteria and mean-variance model by Markovitz will be used. All calculations are done in Matlab and the data sheets are <b>excel</b> <b>tables.</b> The aim of this thesis is to investigate the nordic small cap market by using the Omega function, Sharpe performance criteria and the mean variance model by Markovitz. In order to to see how the purposed methods differs...|$|R
40|$|Arterial {{hypertension}} {{is one of}} {{the main}} risk factors as to the development of cardiovascular and renal disease and reaches a great part of the Brazilian population. The objectives of this study are: describe the profile of hypertension people and identify their knowledge about the disease. This is a descriptive research and has started in November 2005, in a Health Unit in the city of Curitiba and it was authorized by the ethical committee of the institution involved in. It is part of the sample 46 active users enrolled on the hypertension programme aged between 18 e 65 years old. The data were collected at the users’ house by the application of a semi-structured recorded interview. The data were tabulated by an <b>Excel</b> <b>table.</b> The sample consists of 70 % of women, who had an increase of arterial pressure in a 41 to 50 age range. 39 % of the sample has related co-morbidity, predominating the Melitus Diabetes. The average pressure level of 47 % of the population is over 110 mmHg. It was verified that 78 % of the sample don’t have knowledge about hypertension. This deficit contributes as not to adhere to long term treatment and to early appearance of hypertension complications...|$|E
40|$|The British Geological Survey (BGS) has {{conducted}} {{a survey of the}} building stones and roofing slates in 172 buildings that lie within, and face onto, the Townscape Heritage Initiative (THI) area in Falkirk town centre. The survey was commissioned by Falkirk Council and was conducted by the BGS Building Stone Team in January and February 2013. This report describes the outcomes of the survey. The report also has sections describing a brief assessment of historical quarrying activity in the Falkirk area and the results of stone matching for all the different building stones and slates recorded during the survey. The survey results are presented in this report as a set of maps, but the ‘raw’ survey data have been delivered independently of this report in a Microsoft <b>Excel</b> <b>table</b> and in a shape file suitable for GIS applications. A folder of digital images of the surveyed building elevations has also been delivered independently of this report. Twenty different building stones were recorded in the THI area: thirteen are buff sandstone, two are orange sandstone, one is limestone, and four are granite. All of the buff sandstones were sourced from Carboniferous strata that were laid down between 350 and 300 million years ago. Seven come from quarries in the Midland Valley of Scotland and six are from northern England...|$|E
40|$|A muffler {{is a part}} of {{the exhaust}} system on an {{automobile}} that plays a vital role. It needs to have modes that are located away from the frequencies that the engine operates at, whether the engine be idling or running at the maximum amount of revolutions per second. The purpose of the design project performed was to determine which modes are very high and may affect the automobile adversely while in operation. A muffler that affects an automobile in a negative way is one that causes noise or discomfort while the car engine is running. In order to determine the modes most at risk of adversely affecting an automobile, an impact test was conducted. Research was performed prior to the test to determine which frequencies to look for modes at. It was determined to conduct the experiment so data from 0 Hz to 1000 Hz could be collected. The force was caused manually by a hammer with a hard head. After collecting the data, the transfer functions were plotted using Matlab. To ensure correct analyzation, the transfer function equivalent graphs were also plotted. The data was put into an <b>Excel</b> <b>table</b> and analyzed. Six points on the muffler were chosen, after looking at the data, and determined to be under damped. Therefore, our design study suggests to increase the mass, increase the damping, or provide a negative stiffness to make the muffler more damped and to lower the modes of the transfe...|$|E
40|$|Historical censuses are {{the richest}} source of {{statistical}} data about a nation’s past. These censuses include valuable {{data about the}} population characteristics, housing information and socio-economic data. Not only are they taken consistently over time, in our case for almost two centuries, they also cover the entire nation geographically. The challenges of using these data for studies over time and space are well known, documented and shared by many projects focusing on the harmonization of historical census data. Napoleonic influences during the Batavian Republic {{were responsible for the}} first versions of the historical Dutch censuses. Starting with a general enumeration in 1795, over thirty years later the first official census was introduced in Netherlands and continued until 1971 in its traditional ‘door to door’ form. To make this valuable source of data better accessible and available for study, digitization effort where undertaken which resulted in the creation of thousands of scans representing the original census books. These images were later transcribed to <b>Excel</b> <b>tables</b> making them computer processable, but not solving the problem of harmonization. To solve this problem we apply Semantic Web technologies, more specifically the Resource Description Framework (RDF) and propose a specific (three tier) model to harmonize the Dutch historical censuses. We convert the data in RDF {{in such a way that}} we preserve all the peculiarities and hierarchies of the original tables. In other words, we provide a one to one representations of the <b>Excel</b> <b>tables</b> in RDF. Although now available and in one system (instead of having over two thousands heterogeneous Excel files) the data still has to be harmonized in order to allow comparisons across time and space. We acknowledge that even when using machine readable formats and Semantic Web technologies, the data still has to be formally defined by ‘expert users’, i. e. the historians working with the data. However, even for these users this is not a straightforward task. As we cannot claim to know upfront the ‘best’ harmonization model we recognize the need for a flexible approach which allow the users to build and test their harmonizations in a very efficient process, especially when dealing with only aggregated data. Current literature does not provide enough insights in the practice of data harmonization when dealing with aggregated census data. We have created a multilevel ‘flexible’ workflow, consisting of a set of specific harmonization practices. We do all of these transformation in RDF while not compromising the underlying sources. Being able to provide direct links from the harmonized results to the original <b>Excel</b> <b>tables</b> and images is a key requirement of our model...|$|R
50|$|Starting in October 2008, Palo {{supports}} XML for Analysis and MultiDimensional eXpressions (MDX) APIs for connectivity, and OLE DB for OLAP interface {{which allows}} standard <b>Excel</b> pivot <b>tables</b> {{to serve as}} a client tool.Starting September 2011, Palo supports SDX dialect of LINQ.|$|R
40|$|Abstract. In the paper, some {{difficulties}} and their solutions, about drawings, detailed drawings and CNC data output based on three-dimensional solid model for {{various forms of}} rural residence structures, are discussed. The complex spatial relationships and construction details can be shown directly, accurately and completely in drawings software system based on 3 D solid model. Therefore, drawings and detailed drawings can be drawn and labeled automatically by projecting and hiding with the extracted geometric information of particular entities. Further more, in the software system, Manufacture information of components and parts in the 3 D Solid model can be extracted and CNC data can be outputted with according to the required format, such as: the binary data, <b>Excel</b> <b>tables,</b> and so on...|$|R
