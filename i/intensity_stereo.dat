20|14|Public
50|$|As with MP3, Ogg Vorbis stereo files can employ either L/R stereo or joint stereo. When using joint stereo, both M/S {{stereo and}} <b>intensity</b> <b>stereo</b> methods may be used. As opposed to MP3 where M/S stereo (when used) is applied before quantization, an Ogg Vorbis encoder applies M/S stereo to samples in the {{frequency}} domain after quantization, making application of M/S stereo a lossless step. After this step, any frequency area {{can be converted to}} <b>intensity</b> <b>stereo</b> by removing the corresponding part of the M/S signal's side channel. Ogg Vorbis' floor function will take care of the required left-right panning.|$|E
50|$|Note: {{although}} possible, {{the resulting}} quality is {{much worse than}} typicalfor this bitrate. So for normal 64 kbit/s AAC LC a bandwidth of 14-16 kHz isachieved by using <b>intensity</b> <b>stereo</b> and reduced NMRs. This degrades audible qualityless than transmitting 6 kHz bandwidth with perfect quality.|$|E
50|$|This form {{of joint}} stereo uses a {{technique}} known as joint frequency encoding, which functions {{on the principle of}} sound localization. Human hearing is predominantly less acute at perceiving the direction of certain audio frequencies. By exploiting this characteristic, <b>intensity</b> <b>stereo</b> coding can reduce the data rate of an audio stream with little or no perceived change in apparent quality.|$|E
40|$|The Azimuth Discrimination and Resynthesis {{algorithm}} (ADRess) {{has been}} shown to produce high quality sound source separation results for <b>intensity</b> panned <b>stereo</b> recordings. There are however, artifacts such as phasiness which become apparent in the separated signals under certain conditions. This is largely {{due to the fact that}} only the magnitude spectra for the separated sources are estimated. Each source is then resynthesised using the phase information obtained from the original mixture. This paper describes the nature and origin of the associated artifacts and proposes alternative techniques for resynthesising the separated signals. A comparison of each technque is then presented...|$|R
40|$|This paper {{describes}} a statistical integration algorithm for color, motion and stereo disparity, and introduces a realtime stereo {{system that can}} tell us where and what objects are moving. Regarding the integration algorithm, motion estimation and depth estimation are simultaneously performed by a clustering process based on motion, stereo disparity, color, and pixel position. As {{a result of the}} clustering, an image is decomposed into region fragments. Each fragment is characterized by distribution parameters of spatiotemporal <b>intensity</b> gradients, <b>stereo</b> difference, color and pixel positions. Motion vectors and stereo disparities for each fragment are obtained from those distribution parameters. The real-time stereo system can view the objects with the distribution parameters over frames. The implementation shows that we can utilize the proposed algorithm in real-time applications such as surveillance and human computer interaction...|$|R
40|$|Systems of coupled, {{non-linear}} diffusion equations {{are proposed}} as a computational tool for grouping. Grouping tasks {{are divided into}} two classes - local and bilocal - and for each a prototypical set of equations is presented. It is shown how different cues {{can be used for}} grouping given these two blueprints plus cue-specific specialisations. Results are shown for <b>intensity,</b> texture orientation, <b>stereo</b> disparity, optical flow, mirror symmetry, and regular textures. The proposed equations are particularly well suited for parallel implementations. They also show some interesting analogies with basic architectural characteristics of the cortex. status: publishe...|$|R
50|$|More specifically, the {{dominance}} of inter-aural time differences (ITD) for sound localization by humans is only present for lower frequencies. That leaves inter-aural amplitude differences (IAD) as the dominant location indicator for higher frequencies. The idea of <b>intensity</b> <b>stereo</b> coding is to merge the lower spectrum into just one channel (thus reducing overall differences between channels) and to transmit a little side information about how to pan certain frequency regions to recover the IAD cues.|$|E
50|$|An AAC HE v2 {{bitstream}} {{is obtained}} by downmixing the stereo audio to mono at the encoder along with 2-3 kbit/s of side info (the Parametric Stereo information) {{in order to}} describe the spatial <b>intensity</b> <b>stereo</b> generation and ambience regeneration at the decoder. By having the Parametric Stereo side info along with the mono audio stream, the decoder (player) can regenerate a faithful spatial approximation of the original stereo panorama at very low bitrates.|$|E
50|$|In {{addition}} to Layer II's intensity encoded joint stereo, MP3 can use middle/side (mid/side, m/s, MS, matrixed) joint stereo. With mid/side stereo, certain frequency ranges of both channels are merged {{into a single}} (middle, mid, L+R) mono channel, while the sound difference between {{the left and right}} channels is stored as a separate (side, L-R) channel. Unlike <b>intensity</b> <b>stereo,</b> this process does not discard any audio information. When combined with quantization, however, it can exaggerate artifacts.|$|E
40|$|Abstract—Complex visual {{processes}} such as visual attention {{are often}} computationally too expensive to allow real-time im-plementation on a single computer. To solve this problem we study distributed computer architectures that enable us to divide complex tasks into several smaller problems. In this paper we demonstrate how to implement distributed visual attention system on a humanoid robot to achieve real-time operation at relatively high resolutions and frame rates. We start from a popular theory of bottom-up visual attention that assumes that information across various modalities {{is used for the}} early encoding of visual information. Our system uses five different modalities including color, <b>intensity,</b> edges, <b>stereo,</b> and motion. We show how to distribute the attention processing on a computer cluster and study the issues arising on such systems. The system was fully implemented on a workstation cluster comprised of eight PCs. It was used to drive the gaze of a humanoid head towards potential regions of interest. Index Terms—Visual attention, distributed computing, hu-manoid heads. I...|$|R
40|$|This paper {{discusses}} {{a method}} for stereo image coding. We assume stereo images that try to imitate the human visual system, i. e. the two camera planes must be coplanar. First we apply an <b>intensity</b> based <b>stereo</b> algorithm using cooperative bidirectional matching with a hierarchical multilevel structure that returns depth field and occlusion information. This information {{can be used to}} estimate the disparity of pixels from one image to the other one. On the one hand one might use the full depth information to be able to generate synthetic virtual views, on the other hand, if one is only interested in transferring the stereo image pair, one can divide the image into objects of similar depth and code these like in MPEG- 4. Similar to objects in image sequences, the object of the second stereo image can be predicted by applying a translation to each object. 1 Introduction For future telecommunication technologies a highly effective interpersonal information exchange is foreseen [...] . ...|$|R
40|$|Here {{we present}} a {{technique}} for automatic classification of seafloor data collected during the 2012 HABCAMV 4 cruises led by NOAA, UNH and WHOI a federally funded long term project part of the annual NOAA seascallop’s survey. This project will analyze a unique data set that includes simultaneously collected data such as: Hi-resolution multi-beam (digital bathymetry and backscatter <b>intensity)</b> Seafloor <b>stereo</b> image data (e. g. species and substrate) Environmental parameters (e. g. temperature, salinity, water turbidity) The analysis {{will be based on}} an unsupervised spatial clustering (K-means) of a combination of several predictors like morphological features (curvature, rugosity, fractal index, surface area) and backscatter intensity. The final results will be validated by analyzing the identified classes with a randomly selected subset of underwater photographs for each class. The seafloor classification map produced is then used as a preliminary 2 ̆ 2 habitat classification 2 ̆ 2 for further classification. It can be reused to define selection-criteria for the underwater images used by automatic classifier or by manual image annotator tools. Results from this project will also help to define new survey track-lines prior to and during HABCAM surveys...|$|R
50|$|For {{the channel}} {{coupling}} CELT may use M/S stereo or <b>intensity</b> <b>stereo.</b> Blocks {{can be described}} independent from adjacent frames (Intra-frame); for example to enable a decoder to jump into a running stream. With transform codecs so-called pre-echo artifacts can get audible, because the quantisation error of sharp, energy-heavy sounds (transients) can spread over the entire DCT block and the transient doesn't mask them backward in {{time as well as}} forward. With CELT each block can be further divided to thwart such artifacts.|$|E
50|$|The idea is {{to merge}} a given {{frequency}} range of multiple sound channels together so that the resulting encoding will preserve the sound information of that range not as a bundle of separate channels but as one homogeneous data stream. This will destroy the original channel separation permanently, as the information cannot be accurately reconstructed, but will greatly lessen the amount of required storage space. Only some forms of joint stereo use the joint frequency encoding technique, such as <b>intensity</b> <b>stereo</b> coding.|$|E
5000|$|M/S stereo coding {{transforms}} {{the left and}} right channels into a mid channel and a side channel. The mid channel is the sum of {{the left and right}} channels, or [...] The side channel is the difference of the left and right channels, or [...] Unlike <b>intensity</b> <b>stereo</b> coding, M/S coding is a special case of transform coding, and retains the audio perfectly without introducing artifacts. Lossless codecs such as FLAC or Monkey's Audio use M/S stereo coding because of this characteristic.|$|E
40|$|Correpondence {{is often}} {{considered}} the crucial problem in binocular stereopsis. It consists {{in finding the}} images of the same object in the two half [...] images of a stereogram. With correspondence solved, depth can be determined by triangulation. However, half [...] images differ {{in a number of other}} ways as well, which might be useful for depth perception without involving correspondence. Using <b>intensity</b> [...] based <b>stereo</b> and disparity [...] evoked vergence as examples, I will show that in these cases interocular correlation is a more likely mechanism than the purely geometrical notion of correspondence. In conclusion, a task [...] oriented view of stereopsis is presented. Correlation subserves relatively simple tasks such as depth ordering or vergence control, whereas correspondence is needed for fine depth resolution and figure [...] ground segmentation (camouflage breaking) ...|$|R
40|$|Results are {{presented}} which show {{the application of}} GOES stereoscopy to the investigation of hurricanes and tornadic thunderstorms. Stereo cloud top height contour maps were constructed to observe the structural evolution of two hurricanes, Frederic on September 12, 1979 and Allen on August 8, 1980, and a tornadic thunderstorm complex over Oklahoma on May 2 - 3, 1979. Stereo height contours of Hurricane Allen reveal a very intense and symmetric storm with a circular shaped central dense overcast with an average height of 16. 5 km. Contours of Hurricane Frederic reveal a preferred region for convection with an explosive exhaust tower attaining a maximum height of 17. 8 km. Also presented is a technique for estimating tropical cyclone <b>intensity</b> using GOES <b>stereo</b> height and IR temperature information. Results indicate vertical motions ranging from 4. 4 m/s for a moderate storm to 7. 7 m/s for an intense storm...|$|R
40|$|Integration {{of several}} vision modules {{is likely to}} be one of the keys to the power and {{robustness}} of the human visual system. The problem of integrating early vision cues is also emerging as a central problem in current computer vision research. In this paper we suggest that integration is best performed at the location of discontinuities in early processes, such as discontinuities in image brightness, depth, motion, texture and color. Coupled Markov Random Field models, based on Bayes estimation techiques, can be used to combine vision modalities with their discontinuities. These models generate algorithms that map naturally onto parallel fine-grained architectures such as the Connection Machine. We derive a scheme to integrate <b>intensity</b> edges with <b>stereo</b> depth and motion field information and show results on synthetic and natural images. The use of intensity edges to integrate other visual cues and to help discover discontinuities emerges as a general and powerful principle...|$|R
5000|$|Layer II {{can also}} {{optionally}} use <b>intensity</b> <b>stereo</b> coding, {{a form of}} joint stereo. This means that the frequencies above 6 kHz of both channels are combined/down-mixed into one single (mono) channel, but the [...] "side channel" [...] information on the relative intensity (volume, amplitude) of each channel is preserved and encoded into the bitstream separately. On playback, the single channel is played through left and right speakers, with the intensity information applied to each channel to give the illusion of stereo sound. This perceptual trick is known as stereo irrelevancy. This can allow further reduction of the audio bitrate without much perceivable loss of fidelity, but is generally not used with higher bitrates as it does not provide very high quality (transparent) audio.|$|E
30|$|MPEG- 1 audio coding [1, 2] (including {{the popular}} Layer III {{also known as}} MP 3 audio coding), MPEG- 2 AAC (advanced audio coding) [3 – 5], and Dolby AC- 3 [6, 7] are some {{well-known}} audio coding methods for stereo and multichannel audio content. These methods mainly exploit the masking property of the human auditory system for shaping the quantization noise {{so that it will}} be inaudible. In addition to reducing the intrachannel redundancies and irrelevancies, these methods also include algorithms for exploring the interchannel redundancies, irrelevancies, more specifically mid/side coding [8], for frequencies below 2 [*]kHz, and <b>intensity</b> <b>stereo</b> coding [9] above 2 [*]kHz. M/S codes the sum and difference signals instead of the actual channels, operating in an approximate Karhunen-Loeve (K-L transform) manner. <b>Intensity</b> <b>stereo</b> is based on coding only the sum signal of the channels, as well as the time envelopes for each channel as side information, given that these envelopes are adequate for synthesizing the spatial image at the decoder. A useful introduction to several technologies for the more general area of audio compression can be found in [10]. More recently, exact KLT methods have been derived (e.g., [11]), while <b>intensity</b> <b>stereo</b> has been generalized for the entire frequency spectrum by MPEG Surround [12].|$|E
40|$|When coding several signals {{which are}} not {{dependent}} on each other, selection of the suitable coding type {{is dependent on the}} degree of similarity. According to one aspect of the invention, the degree of similarity is determined by coding one of the signals first using the <b>intensity</b> <b>stereo</b> process and then decoding it {{in order to create a}} signal containing a coding error, whereupon the latter and the related non-coded signal are transformed into the frequency range. Within the frequency range, the actually audible spectral component, the signal bearing the coding error and the related signal not containing any coding error are selected or evaluated using a masking threshold which is determined by a psycho-acoustic calculation. If the degree of similarity is high, an <b>intensity</b> <b>stereo</b> coding is performed, whereas in the opposite case, the channels are coded separately...|$|E
40|$|This paper {{presents}} a multilevel algorithm for straight line extraction and matching from <b>stereo</b> <b>intensity</b> images based on fuzzy strategies. The {{ultimate goal of}} our work is to find 3 D landmarks represented {{in the form of}} straight lines. In this method line extracting not only uses the information of current level but also considers the lines extracted at the coarser level. The idea is similar to multi-scale edge focusing, except that a fuzzy evaluation procedure is carried out to control the quality of a line candidate. This paper also proposes a new matching strategy based on fuzzysets, where various matching constraints can be effectively combined and some matching information from the coarser level is also considered. This method needs only one-step matching and avoids inadequate overstrong constraints, so that reliable unique line matches can be achieved with a relatively small cost. 1 Introduction As a part of a vision system for helping blind people to recognize some importa [...] ...|$|R
40|$|We propose Stereo Direct Sparse Odometry (Stereo DSO) as a novel {{method for}} highly {{accurate}} real-time visual odometry estimation of large-scale environments from stereo cameras. It jointly optimizes {{for all the}} model parameters within the active window, including the intrinsic/extrinsic camera parameters of all keyframes and the depth values of all selected pixels. In particular, we propose a novel approach to integrate constraints from static stereo into the bundle adjustment pipeline of temporal multi-view stereo. Real-time optimization is realized by sampling pixels uniformly from image regions with sufficient <b>intensity</b> gradient. Fixed-baseline <b>stereo</b> resolves scale drift. It also reduces the sensitivities to large optical flow and to rolling shutter effect which are known shortcomings of direct image alignment methods. Quantitative evaluation demonstrates that the proposed Stereo DSO outperforms existing state-of-the-art visual odometry methods both in terms of tracking accuracy and robustness. Moreover, our method delivers a more precise metric 3 D reconstruction than previous dense/semi-dense direct approaches while providing a higher reconstruction density than feature-based methods. Comment: ICCV 201...|$|R
40|$|Abstract: Conventional {{approaches}} to recovering depth from gray-level imagery have involved obtaining {{two or more}} images, applying an "interest " operator, and solv-ing the correspondence problem. Unfortunately, the computational complexity involved in feature extraction and solving the correspondence problem makes existing techniques unattractive for many real-world robotic ap-plications. By approaching the problem from more of an engineering perspective, we have developed a new depth recovery technique that completely avoids thecomputa-tionally intensive steps of feature selection and corre-spondence required by conventional approaches. The In-tensity Gradient Analysis technique (IGA) is a depth recovery algorithm that exploits {{the properties of the}} MCSO (moving camera, stationary objects) scenario. Depth values are obtained by analyzing temporal inten-sity gradients arising from the optic flow field induced by known camera motion. In doing so, IGA avoids the fea-ture extraction a d correspondence steps of conventional approaches and is therefore very fast. A detailed descrip-tion of the algorithm isprovided along with experimental results from complex laboratory scenes. Key Words: depth recovery, <b>intensity</b> gradient, motion <b>stereo,</b> optic flow, stereopsi...|$|R
40|$|The coding {{method has}} the stereo audio {{spectral}} values grouped into scale factor bands (28), with formation of sections each containing {{at least one}} scale factor band. The audio spectral values are coded within each section using a coding table selected {{from a number of}} coding tables. Each coding table is identified by a coding table number transmitted alongside the coded stereo audio spectral values. An additional coding table number is transmitted for an <b>intensity</b> <b>stereo</b> coding method, or an adaptive Huffman coding method for the stereo audio spectral values. ADVANTAGE - Provides compression of audio digital signals without quality degradation...|$|E
40|$|Vision {{researchers}} have advocated {{the integration of}} vision modules. However, generic system integration issues for recovering 3 D information have not been adequately addressed in the literature. We propose a unified Bayesian integration framework for interactions among the vision modules to obtain a complete 3 D reconstruction {{from a pair of}} <b>intensity</b> (<b>stereo)</b> images. We integrate perceptual grouping, stereo, shape from shading, and shape from texture modules under the proposed framework and demonstrate that the integrated system recovers the depth and surface orientation information more reliably than the individual modules for different synthetic and real images...|$|E
30|$|Since most audio {{material}} {{is produced in}} stereo, an efficient coding tool should also exploit the redundancies and irrelevancies of both channels simultaneously. Since it is not straightforward to use standard stereo coding tools like mid/side stereo [51] and <b>intensity</b> <b>stereo</b> [52] in conjunction with parametric coding, and since the aim also {{was to develop a}} general stereo coding tool for low bit rates, the novel Parametric Stereo (PS) tool was developed where the stereo image is coded on the basis of spatial cues. The PS tool as standardized in MPEG was developed in 2003 and primarily aimed to enhance the performance of SSC and HE-AAC at low bit rates.|$|E
40|$|We {{present a}} method to recover the {{reflectance}} of objects and the parameters of multiple lights illuminating the scene using a 3 D image acquired by a depth sensor and a <b>stereo</b> <b>intensity</b> pair. The methodology has three components: the object geometric model, the surface reflection properties and the light source parameters. In the simpler case, we allow calibration of the point light sources using a Lambertian sphere; this can be used subsequently to estimate the surface reflection properties of an object with known geometry, acquired by an active sensor and represented as a triangulation mesh. However, the main contribution of the thesis is to remove the need for pre-calibration, and estimate the light source parameters, the diffuse and specular surface reflection parameters and the surface geometry from image data alone. By adapting a welldetermined iterative regression process on the illumination equation, a Gaussian Subtraction (GS) algorithm is used to separate the diffuse and specular components of the surface reflectance across the object surface. Then, the locations and intensities of the several light sources are recovered. We demonstrate the approach on both synthetic and real data acquired {{from a series of}} objects of reasonable complexity, using up to three light sources. No pre-calibration of the surfaces or of the light positions is necessary. For evaluation, we compare the results to ground truth when available, but also render these objects in dynamic X 3 DNRML format for a subjective comparison. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Detection {{of objects}} of {{interest}} is a fundamental problem in computer vision. Foreign object detection (FOD) is to detect the objects that {{are not expected to}} be appear in certain area. For this task, we need to first detect the position of foreign objects, and then compute the distance to the foreign objects to judge whether the objects are within the dangerous zone or not. The three principle sources of difficulty in performing this task are: a) the huge number of foreign objects categories, b) the calculation of distance using camera(s), and c) the real-time system running performance. Most state-of-art detectors focus on one type or one class of objects. To the best of our knowledge, there is no single solution that focuses on a set of multiple foreign objects detection in an integrated manner. In some cases, multiple detectors can operate simultaneously to detect objects of interest in a given input. This is not efficient. The goal of our research is to focus on detection of a set of objects identified as foreign object in an integrated and efficient manner. We design a multi-class detector. Our approach is to use a coarse-tofine strategy in which we divide the complicated space into finer and finer sub-spaces. For this purpose, data-driven clustering algorithm is implemented to gather similar foreign objects samples, and then an extended vector boosting algorithm is developed to train our multi-class classifier. The purpose of the extended vector boosting algorithm is to separate all foreign objects from background. For the task of estimation of the distance to the foreign objects, we design a look-up table which is based on the area of the detected foreign objects. Furthermore, we design a FOD framework. Our approach is to use stereo matching algorithm to get the disparity information based on <b>intensity</b> images from <b>stereo</b> cameras, and then using the camera model to retrieve the distance information. The distance calculated using disparity is more accurate than using the distance look-up table. We calculate the initial distance map when no objects are in the scene. Block of interest (BOI) is the area where distance is smaller than the corresponding area in the initial distance map. For the purpose of detecting foreign objects, we use flood fill method along with noise suppression method to combine adjacent BOI with higher confidence level. The foreign object detection prototype system has been implemented and evaluated on a number of test sets under real working scenarios. The experimental results show that our algorithm and framework are efficient and robust...|$|R
40|$|The same program {{heard on}} DAB at 128 kbit/s and 192 kbit/s has been {{compared}} with a high quality FM stereo signal. The result from informal listening tests {{is that there are}} audible impairments in the stereo imaging of high-frequency instruments, and in particular hi-hats at 128 kbit/s. Some examples of songs where this effect can be heard are given. The effect can be explained by spectral analysis of the output of a DAB radio which shows that at 128 kbit/s, 3 kHz is used as the switch frequency for the <b>intensity</b> <b>stereo</b> coding of the MPEG-I layer 2 encoder, effectively removing most signal differences above this frequency. This degradation cannot be heard in a good quality FM stereo signal...|$|E
40|$|Traditional MDCT-based perceptual audio coding schemes employ mid/side and <b>intensity</b> <b>stereo</b> {{techniques}} to allow efficient joint coding {{of the two}} channels of a stereophonic signal. These techniques, however, provide only little coding gain for critical stereo signals characterized by spectral components with a distinct level or phase difference between the channels. To overcome this deficiency, we propose an extension to the mid/side coding paradigm that utilizes complex-valued inter-channel linear prediction in the MDCT spectral domain. The required imaginary spectrum (MDST) is calculated in a computationally efficient manner without additional algorithmic delay. A formal listening test conducted {{in the course of}} the ISO/MPEG standardization of the unified speech and audio codec USAC illustrates that the proposed stereo prediction approach provides significant improvements in coding efficiency and shows that at 96 kb/s, excellent quality can be obtained even for critical signals...|$|E
40|$|We present {{preliminary}} results confirming {{the importance of}} radiometric calibration in multicamera applications. We review systematic and random noise in the video sensor (camera/frame grabber). The manifestation of background noise in dark images, and fixed pattern noise in flat fields are illustrated. Through a flat-field correction of an uniform <b>intensity</b> <b>stereo</b> image pair an improvement of 26 % to 59 % in stereo matching is demonstrated. 1 Introduction The need of methodology for characterization of vision algorithms has been recognized [7]. When multiple sensors are used in applications requiring hard performance guarantees, correcting for errors and obtaining objective confidence measures for {{the uncertainty of the}} results cannot be neglected. Empirical tests, validation, and analysis of robustness of existing systems are necessary [18]. The use of vision algorithms with physically different sensors, necessitates the evaluation of the performance of the algorithms given the param [...] ...|$|E
40|$|The ISO/MPEG phases 1 and 2 audio {{compression}} is receiving {{a wide range}} of applications. In the encoding process of MPEG, the psychoacoustic model exploits audio irrelevancy which is the key role to achieve high compression ratio without losing audio quality. However, the Fourier transform (FT) which has been used by the two psychoacoustic models suggested in standard draft requires high computational complexity which leads to high hardware and software cost for real-time applications. This paper presents a new design named the hybrid filter bank to replace the FT. The hybrid filter bank can be integrated with the psychoacoustic models and provides a much lower complexity than the FT. Also, this paper shows that the hybrid filter is more suitable for the stereo coding and hence can provide a better quality for the <b>intensity</b> <b>stereo</b> coding, which is the key technology for the MPEG 1 to achieve near transparent quality lower than 96 x 2 Kbits for two stereo channels...|$|E
40|$|The {{description}} {{refers to}} a process for the reduction of data for the transmission and/or storage of digital signals of several dependent channels. The dependence of the signals in the channels, for example in a left and a right stereo channel, {{can be used for}} additional data reduction. Known processes such as middle/side coding or the <b>intensity</b> <b>stereo</b> process lead to perceivable interference in the case of poor signal composition. The process according to the invention avoids such interference by performing a coding of the channels only if there is sufficient spectral similarity of the signals in the two channels. Furthermore, an additional data reduction can be achieved using a process according to the invention {{by the fact that the}} associated spectral values are set to zero in those frequency bands in which the spectral energy of a channel does not exceed a preset fraction of the total spectral energy. Since the process is independent of the specific internal structure of the coding process, it can be used in many applications...|$|E

