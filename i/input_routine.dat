10|79|Public
50|$|Machine code {{programs}} {{are written in}} an octal/decimal representation exemplified in the Example Program above, and loaded by a rudimentary assembler known as the Translation <b>Input</b> <b>Routine.</b> It has no symbolic addressing facilities, but instead allows the source to be broken into blocks which can be manually relocated {{to allow for the}} expansion or contraction of a previous block in development. There is also an Autocode for simple programming tasks, allowing faster program development without the need for a knowledge of machine code. This has no formula translation facilities and requires all calculations to be reduced to a series of assignments with no more than a single operator on the right hand side.|$|E
40|$|Keyword {{directed}} {{free format}} <b>input</b> <b>routine,</b> {{which has been}} used in large neutronics codes, is described. The routine also sets up variable dimension addresses for use with side entry calls. In addition, as a program debugging aid, a labelled printer dump facility is provided. The suite of routines has been used on IBM 360 computers...|$|E
40|$|The {{development}} and validation {{of a new}} altimeter wind speed model will be presented. This algorithm provides a direct mapping of TOPEX-measured backscatter and significant wave height to 10 m wind speed. A large scatterometer/altimeter crossover data set was assembled to develop the routine and several large ancillary data sets have been assembled for validation purposes. Validation results suggest that this two <b>input</b> <b>routine</b> provides marginal, yet measurable improvements over the standard single-parameter MCW algorithm...|$|E
5000|$|The PMD 85-2 {{introduced}} some {{improvements in}} BASIC, some in <b>input</b> <b>routines</b> (for instance, key autorepeat), {{a much more}} ergonomic keyboard (but much less mechanically reliable) and also terminal mode. Some of the changes caused it to be not completely backward compatible.|$|R
5000|$|The default BIOS {{keyboard}} routines simply ignore SysRq {{and return}} without taking action. So did the MS-DOS <b>input</b> <b>routines.</b> [...] The keyboard routines in libraries supplied with many high-level languages followed suit. Although {{it is still}} included on most PC keyboards manufactured, and though it is used by some debugging software, the key is of no use {{for the vast majority}} of users.|$|R
50|$|The OpenGL Utility Toolkit (GLUT) is {{a library}} of {{utilities}} for OpenGL programs, which primarily perform system-level I/O with the host operating system. Functions performed include window definition, window control, and monitoring of keyboard and mouse <b>input.</b> <b>Routines</b> for drawing a number of geometric primitives (both in solid and wireframe mode) are also provided, including cubes, spheres and the Utah teapot. GLUT also has some limited support for creating pop-up menus.|$|R
40|$|Computer Programming and Computer Systems imparts a "reading knowledge? of {{computer}} systems. This book describes {{the aspects of}} machine-language programming, monitor systems, computer hardware, and advanced programming that every thorough programmer should be acquainted with. This text discusses the automatic electronic digital computers, symbolic language, Reverse Polish Notation, and Fortran into assembly language. The routine for reading blocked tapes, dimension statements in subroutines, general-purpose <b>input</b> <b>routine,</b> and efficient use of memory are also elaborated. This publication is inte...|$|E
40|$|An <b>input</b> <b>routine</b> {{has been}} {{designed}} for use with FORTRAN or SAP coded programs which are to be executed on an IBM 704 digital computer. All input to be processed by the routine is punched on IBM cards as declarative statements of the arithmetic type resembling the FORTRAN language. The routine is 850 words in length. It is capable of loading fixed- or floating-point numbers, octal numbers, and alphabetic words, and of performing simple arithmetic as indicated on input cards. Provisions have been made for rapid loading of arrays of numbers in consecutive memory locations...|$|E
40|$|Abstract Background Apollo, a genome {{annotation}} viewer and editor, {{has become a}} widely used {{genome annotation}} and visualization tool for distributed genome annotation projects. When using Apollo for annotation, database updates are carried out by uploading intermediate annotation files into the respective database. This non-direct database upload is laborious and evokes problems of data synchronicity. Results To overcome these limitations we extended the Apollo data adapter with a generic, configurable web service client that is able to retrieve annotation data in a GAME-XML-formatted string and {{pass it on to}} Apollo's internal <b>input</b> <b>routine.</b> Conclusion This Apollo web service adapter, Apollo 2 Go, simplifies the data exchange in distributed projects and aims to render the annotation process more comfortable. The Apollo 2 Go software is freely available from ftp://ftpmips. gsf. de/plants/apollo_webservice. </p...|$|E
40|$|This talk {{gives an}} {{overview}} of the collaborative featrues of JuSER and it's sister systems. After a short introduction of the publications database and the institutional repository, and why they should interact, the main topic are the private collections, known in Jülich as institute collections, and how they {{can be used in a}} scientific publication workflow. <b>Input</b> <b>routines</b> are outlined with a special emphasise on the possiblity to import data. Finally a short introduction to groups and baskets is given...|$|R
50|$|Logical {{cohesion}}: Logical cohesion is when {{parts of}} a module are grouped because they are logically categorized {{to do the same}} thing even though they are different by nature (e.g. grouping all mouse and keyboard <b>input</b> handling <b>routines).</b>|$|R
2500|$|Although MythDevelopers {{worked to}} update The Fallen Lords and Soulblighter to newer {{operating}} systems on both Mac and PC, fix bugs, and create unofficial patches to enhance both the games {{themselves and the}} mapmaking tools, their initial focus was on the bug-ridden release versions of The Wolf Age, which had problems running on both Windows XP and OS X. Upon getting the code for The Wolf Age, they discovered they [...] "couldn't even build a usable app. We had to rewrite the Mac <b>input</b> <b>routines</b> before we could even make an app." [...] They were also given access to the source code for [...] "BurgerLib", a proprietary development library created by Bill Heineman, lead developer on the Mac version of the game. Additionally, they developed their own library, dubbed the Myth Core Library, which provided networking, <b>input</b> <b>routines,</b> and other low-level functions. This enabled MythDevelopers to avoid the necessity of licensing any external libraries, and instead allowed them to develop everything in-house. This was part of their deal with Take-Two, as they couldn't incorporate anything into the games which they {{would be unable to}} give Take-Two the rights to should the company ever ask for the source code back; all modifications remained the intellectual property of Take-Two, who were free to use them in a future commercial version of Myth, if they ever wanted to re-release an upgraded version of {{one or more of the}} games, or incorporate the modifications into the development of a new Myth game.|$|R
40|$|A high {{input of}} {{pesticides}} in farming {{has led to}} a growing The farmer expects specialized expertise from plant proteccontamination of ground and surface water in Europe. To tion experts regarding decisions about treatment, treatment improve this situation, the farmers have to reduce the input of selection and the time of its application. Certain cultures are pesticides to a minimum, which gives as good economic more succeptible to various pathogenic agents than others. In returns, as well as high <b>input</b> <b>routine</b> sprays, if the application corn, the insects can be disregarded, however, weeds can of pesticides will be optimized. Important conditions are cause existential damage. Insects are significant for rape, cropmanagement to avoid diseases and country wide plant whereas fungus agents must be closely observed in grain disease control. Due to the personnel and technical situation, stock. The fungus diseases found in grains will serve as an these demands cannot be met. To improve this po [...] ...|$|E
40|$|Forty years ago, the PC- 1, {{parametron}} computer 1, {{was born}} at Professor Hidetosi Takahasi's Laboratory. The logical elements of the PC- 1 were parametrons, which supported majority logic. The memory system operated in a two frequency read/write scheme. The word selection mechanism applied error correcting code to decrease the number of elements. Most of the hardware technologies were created by Eiichi Goto. We studied the EDSAC computer precisely, however we developed our own architecture and programming system based upon our own philosophy. The machine instruction set was chosen to ease programming. The normal teletype on the market was employed, leaving the burden of code conversion tasks to software, which seemed to us to have had almost infinite abilities. However, the real memory capacity was indeed very small, which forced us to invent a clever way to implement things. In this paper, after introducing {{the functions of the}} initial <b>input</b> <b>routine</b> R 0, examples of (i) code conversion t [...] ...|$|E
40|$|This paper {{describes}} greatly enhanced {{version of}} the computer program SPECTRAN, which was initially presented in Paper No. 96 -RA 104. 01, at the A&WMA 89 th Annual Meeting in June 1996. The program has had three basic upgrades since that time. The first is provision of an option to use either batch-mode input from previously prepared data files or a {open_quotes}user-friendly{close_quotes} interactive <b>input</b> <b>routine.</b> The latter is primarily for first-time users and those having only one, or very few, spectra to process. The second improvement is the synthesis of 1 / 12 octave-band spectra from 1 / 3 octave-band spectra, with {open_quotes}tone correction,{close_quotes} {{in a manner similar}} to that used in the original {{version of the}} program. The third fundamental improvement is addition of a unique new capability to synthesize classic {open_quotes}critical-band{close_quotes} spectra from 1 / 3 octave-band input spectra. Critical-band spectra are also termed {open_quotes}equivalent-rectangular-bandwidth (ERB) {close_quotes} and {open_quotes}equal-contribution-to-speech (ECS) {close_quotes} spectra...|$|E
40|$|We {{introduce}} the logical story behind file input in ACL 2 {{and discuss the}} types of theorems that can be proven about filereading operations. We develop a low level library for reasoning about the primitive <b>input</b> <b>routines.</b> We then develop a representation for Unicode text, and implement efficient functions to translate our representation {{to and from the}} UTF- 8 encoding scheme. We introduce an efficient function to read UTF- 8 -encoded files, and prove that when files are well formed, the function produces valid Unicode text which corresponds to the contents of the file. We find exhaustive testing to be a useful technique for proving many theorems in this work. We show how ACL 2 can be directed to prove a theorem by exhaustive testing...|$|R
40|$|Transient Analysis of Linear Circuits Using Constraint Logic Programming By Archana Shankar, David R. Gilbert, Michael B. Jampel This report {{describes}} {{the design of}} a transient analysis program for linear circuits and its implementation in a Constraint Logic Programming language. CLP(R) was chosen to be the implementation language as it is designed to be efficient in handling real numbers. We have defined a circuit definition language(CDL) to input the circuit topology to the program. The transient analysis program parses the CDL into a network graph, analyses the semantic correctness of the network graph and then performs the actual transient analysis of a given circuit. There is also a library to implement the abstract data type of matrices, plus <b>input</b> <b>routines</b> to read the CDL file, and output routines to display the results to the user. The test results show that the program is at least 97 % accurate when run at two decimal places. We have compared the performance of our program with [...] ...|$|R
40|$|The LANDSAT-geographic {{information}} system (GIS) interface must summarize {{the results of}} the LANDSAT classification over the same cells that serve as geographic referencing units for the GIS, and output these summaries on a cell-by-cell basis in a form that is readable by the <b>input</b> <b>routines</b> of the GIS. The ZONAL interface for cell-oriented systems consists of two primary programs. The PIXCEL program scans the grid of cells and outputs a channel of pixels. Each pixel contains not the reflectance values but the identifier of the cell in which the center of the pixel is located. This file of pixelized cells along with the results of a pixel-by-pixel classification of the scene produced by the LANDSAT analysis system are input to the CELSUM program which then outputs a cell-by-cell summary formatted according to the requirements of the host GIS. Cross-correlation of the LANDSAT layer with the other layers in the data base is accomplished with the analysis and display facilities of the GIS...|$|R
40|$|Analysis of the multi-nerve impulses {{by means}} of {{electrophysiological}} method has become {{important to understand the}} parallel information processing in the nervous system. We have previously reported the multi-impulse analyzing system by using the microcomputer (MEK 6800 D-II) and additional electronic circuits. Impulses from two nerve cells or more were classified according to their amplitude. That was executed by machine language program. The system operated sufficiently to analyze the impulses recorded in nerve bundle from mechanoreceptors on the crayfish antennule. However, there were a few problems in the system. The one was a slight time lag of the peak discriminator which detected the peak time of an impulse and triggered A-D converter. The other was flicker of realtime display caused by sequential time sharing between data <b>input</b> <b>routine</b> and display one. Those problems are improved in the present new system. The former is overcome by using the peak hold circuit in place of the peak discriminator, and the latter by introducing the interrupt technique when both impulse height and interspike interval are gotten into the microcomputer. An additional microcomputer (CBM) which can execute BASIC program is connected with the previous one in order to supply the lack of programing flexibility on the machine language system. The connection between those two microcomputer consists of a control line and 8 -bit bidirectional data bus. By using the only one control line, the program for data transfer is made as simple as possible. Then, the new system is made to reconcile processing speed in machine language system and flexibility in BASIC system. Furthermore, CBM 3032 have an input-output port based on the standard IEEE 488 bus. A X-Y plotter (WX 4671) is connected with this port through an interface circuit. All of the experimental result can be printed out by the plotter. The present multi-impulse analyzing system possesses sufficient accuracy and flexibility. The system can be used not only in our electrophysiological experiment but also in one of another nervous system...|$|E
30|$|Master–slave {{control is}} widely {{employed}} in robot manipulation. In most cases, the joystick or the keyboard is the <b>routine</b> <b>input</b> device for the robot master–slave control system. The system {{presented in this}} paper is shown in Figure  1.|$|R
25|$|MythDevelopers {{used this}} {{material}} {{to improve and}} further develop the games. Although their initial focus was on the bug-ridden release version of The Wolf Age, they also worked to update {{the first two games}} to newer operating systems on both Mac and PC, fix bugs, and create unofficial patches to enhance both the games themselves and the mapmaking tools. They also developed their own library, dubbed the Myth Core Library, which provided networking, <b>input</b> <b>routines,</b> and other low-level functions. This enabled MythDevelopers to avoid the necessity of licensing any external libraries, and instead allowed them to develop everything in-house. This was part of their deal with Take-Two, as they couldn't incorporate anything into the games which they would be unable to give Take-Two the rights to should the company ever ask for the source code back; all modifications remained the intellectual property of Take-Two, who were free to use them in a future commercial version of Myth, if they ever wanted to re-release an upgraded version of {{one or more of the}} games, or incorporate the modifications into the development of a new Myth game.|$|R
50|$|Within the Eiffel {{software}} development method and language, the terms argument and parameter have distinct uses established by convention. The term argument is used exclusively {{in reference to}} a <b>routine's</b> <b>inputs,</b> and the term parameter is used exclusively in type parameterization for generic classes.|$|R
40|$|Globally {{distributed}} crossovers of altimeter and scatterometer observations clearly {{demonstrate that}} ocean altimeter backscatter correlates {{with both the}} near-surface wind speed and the sea state. Satellite data from TOPEX/Poseidon and NSCAT are used to develop an empirical altimeter wind speed model that attenuates the sea-state signature and improves upon the present operational altimeter wind model. The inversion is defined using a multilayer perceptron neural network with altimeter-derived backscatter and significant wave height as inputs. Comparisons between this new model and past single <b>input</b> <b>routines</b> indicates that the rms wind error is reduced by 10 %– 15 % {{in tandem with the}} lowering of wind error residuals dependent on the sea state. Both model intercomparison and validation of the new routine are detailed, including the use of large independent data compilations that include the SeaWinds and ERS scatterometers, ECMWF wind fields, and buoy measurements. The model provides consistent improvement against these varied sources with a wind-independent bias below 0. 3 m s− 1. The continuous form of the defined function, along with the global data used in its derivation, suggest an algorithm suitable for operational application to Ku-band altimeters. Further model improvement through wave height inclusion is limited due to an inherent multivaluedness between any single realization of the altimeter measurement pair [σo, HS] and observed near-surface winds. This ambiguity indicates that HS is a limited proxy for variable gravity wave properties that impact upon altimeter backscatter...|$|R
40|$|Coastal {{pollution}} {{due to high}} inputs {{of organic}} matter is easy to detect and monitor {{it is much more}} difficult in the case of sporadic low-level <b>inputs.</b> Full <b>routine</b> water-quality surveys of large stretches of coastline are time-consuming and expensive. The present study evaluates the suitability of using rocky shore community structure as such an indicator in the Maltese Islands. The rocky shore communities at Xaghra, which is 1. 3 km south of Malta’s main sewage outfall were sampled. The peculiarities found in these communities suggest that rocky shore biotic assemblages may be useful indicators of low-level sewage pollution, at least under local conditions. peer-reviewe...|$|R
5000|$|It will {{be assumed}} that the Xm have been {{computed}} by solving the relevant equations and are available as an <b>input</b> to our <b>routine.</b> Although g is in principle a two dimensional matrix, it can be computed in a column by column fashion starting from the leftmost column. The routine uses a single column vector C to represent the current column of g.|$|R
50|$|The basic VELA {{carries a}} single 4KB EPROM (ISL1 or ISL1*) which {{contains}} the basic <b>input</b> and output <b>routines</b> that handle the keyboard input and 8-digit LED display output together with seventeen user selectable programs {{which range from}} a 4-channel digital volt meter to a random event monitor {{which could be used}} with a Geiger Counter Probe to measure and log radiation levels from a source material.|$|R
5000|$|MODULE E1 (MAIN = CTRL) =BEGINFORWARD ROUTINE CTRL, STEP;ROUTINE CTRL =!+! This <b>routine</b> <b>inputs</b> a value, {{operates}} on it, and! then outputs the result.!- BEGIN EXTERNAL <b>ROUTINE</b> GETNUM, ! <b>Input</b> a number from terminal PUTNUM; ! Output a number to terminal LOCAL X, ! Storage for input value Y; ! Storage for output value GETNUM(X); Y = STEP(.X); PUTNUM(.Y) END;ROUTINE STEP(A) =!+! This routine adds 1 to the given value.!- (.A+1);ENDELUDOM ...|$|R
40|$|Energy ” {{models for}} {{continuous}} domains {{can be applied}} to many problems, but often suffer from high computational expense in training, due to the need to repeatedly minimize the energy function to high accuracy. This paper considers a modified setting, where the model is trained in terms of results after optimization is truncated to a fixed number of iterations. We derive “backpropagating ” versions of gradient descent, heavy-ball and LBFGS. These are simple to use, as they require as <b>input</b> only <b>routines</b> to compute the gradient of the energy with respect to the domain and parameters. Experimental results on denoising and image labeling problems show that learning with truncated optimization greatly reduces computational expense compared to “full ” fitting. ...|$|R
40|$|In this study, {{survey and}} {{interview}} data from four high technology industrial sectors in northern Florida {{are used to}} examine the effect of several establishment and organizational characteristics on the strength of intrastate linkages both of sophisticated and of <b>routine</b> <b>inputs.</b> The empirical findings show that local linkages of Florida's high technology industries are generally weak, and are most local mainly among small, locally owned, research and development-intensive establishments. ...|$|R
40|$|The {{purpose of}} this paper is to {{demonstrate}} how to process multiple <b>input</b> files and <b>routine</b> programs with one click through the use of two macros. These macros combined with the %INCLUDE statement, CALL SYMPUT, and SCAN functions in a control program will eliminate updating various %LET statements, and physically opening, running, and closing each program. Most people who process data for routine operations will appreciate this solution...|$|R
30|$|Cryptography is a {{fundamental}} part of any modern computing system, but unlikely to be the weakest component in its attack surface. Networking protocols, <b>input</b> parsing <b>routines</b> and even interface code with cryptographic mechanisms are components {{much more likely to}} be vulnerable to exploitation. However, a successful attack on cryptographic security properties is usually disastrous due to the risk concentrated in cryptographic primitives. For example, violations of confidentiality may cause massive data breaches involving sensitive information. Adversarial interference on communication integrity may allow command injection attacks that deviate from the specified behavior. Availability is crucial to keep the system accessible by legitimate users and to guarantee continuous service provisioning, thus cryptographic mechanisms must also be lightweight to minimize potential for abuse by attackers.|$|R
40|$|CARLOS- 3 D is a {{three-dimensional}} scattering code which was developed under {{the sponsorship of}} the Electromagnetic Code Consortium, and is currently used by over 80 aerospace companies and government agencies. The code has been extensively validated and runs on both serial workstations and parallel super computers such as the Intel Paragon. CARLOS- 3 D is {{a three-dimensional}} surface integral equation scattering code based on a Galerkin method of moments formulation employing Rao- Wilton-Glisson roof-top basis for triangular faceted surfaces. Fully arbitrary 3 D geometries composed of multiple conducting and homogeneous bulk dielectric materials can be modeled. This presentation describes some of the extensions to the CARLOS- 3 D code, and how the operator structure of the code facilitated these improvements. Body of revolution (BOR) and two-dimensional geometries were incorporated by simply including new <b>input</b> <b>routines,</b> and the appropriate Galerkin matrix operator routines. Some additional modifications were required in the combined field integral equation matrix generation routine due to the symmetric nature of the BOR and 2 D operators. Quadrilateral patched surfaces with linear roof-top basis functions were also implemented in the same manner. Quadrilateral facets and triangular facets {{can be used in}} combination to more efficiently model geometries with both large smooth surfaces and surfaces with fine detail such as gaps and cracks. Since the parallel implementation in CARLOS- 3 D is at high level, these changes were independent of the computer platform being used. This approach minimizes code maintenance, while providing capabilities with little additional effort. Results are presented showing the performance and accuracy of the code for some large scattering problems. Comparisons between triangular faceted and quadrilateral faceted geometry representations will be shown for some complex scatterers...|$|R
40|$|The Symmetrical List Processor SLIP; {{developed}} by Professor Joseph Weizenbaum of MIT, was implemented with considerable modifications and additions on the University of Cape Town computer. A package to perform automated analytical differentiation (DERIV) was developed using SLIP. Basic simplification techniques {{as well as}} convenient <b>input</b> and output <b>routines</b> were included. The package was tested extensively and a rough comparison drawn with the abilities of various computer languages and programs which include the same facility as TIERIV...|$|R
40|$|The {{history of}} the {{development}} of the NASTRAN computer program, a general purpose finite element code for structural analysis, is described. The need for research programs to improve analysis of structures, and the writing of a computer program to give numerical solutions for shell behavior, were the impetus for the program design. The use of finite elements to obtain engineering solutions was introduced. The architecture, solution structure, DMAP language, decomposition technique for banded matrices with active columns, general purpose plotter, engineering data <b>inputs,</b> elastic element <b>routines,</b> programmer manuals, of NASTRAN's system design are described...|$|R
50|$|When {{magnetic}} media publishing became widely available, a US Navy petty officer, Paul Lohnes, ported Sargon to the TRS-80, altering the graphics, <b>input,</b> and housekeeping <b>routines</b> but leaving the Spracklen's chess-playing algorithm intact. Paul consulted with the Spracklens, who were both living in San Diego at the time, {{to make the}} TRS-80 version an instant success {{with the help of}} Hayden Book's newly established software division: Hayden Software. Paul was not involved in further refinements to the TRS-80 version due to his reassignment to sea duty shortly after signing the deal with Hayden Software.|$|R
40|$|We apply an {{understanding}} of what computers do to study how computerization alters job skill demands. We argue that computer capital (1) substitutes for workers in performing cognitive and manual tasks that can be accomplished by following explicit rules; and (2) complements workers in performing nonroutine problem-solving and complex communications tasks. Provided that these tasks are imperfect substitutes, our model implies measurable changes in the composition of job tasks, which we explore using representative data on task input for 1960 to 1998. We find that within industries, occupations, and education groups, computerization is associated with reduced labor <b>input</b> of <b>routine</b> manual and routine cognitive tasks and increased labor input of nonroutine cognitive tasks. Translating task shifts into education demand, the model can explain 60 percent of the estimated relative demand shift favoring college labor during 1970 to 1998. Task changes within nominally identical occupations account for almost half of this impact. © 2001 the President and Fellows of Harvard College and the Massachusetts Institute of Technology...|$|R
