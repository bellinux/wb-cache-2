157|4812|Public
2500|$|... 197A - Adaptive Recursive Interpolated <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation</b> (ARIDPCM) Compression Algorithm For The National Imagery Transmission Format Standard ...|$|E
5000|$|G.726 is a {{waveform}} speech coder {{which uses}} Adaptive <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation</b> (ADPCM) ...|$|E
5000|$|Adaptive <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation</b> (ADPCM), former ITU-T G.721, 32 kbit/s used in STE secure {{telephone}} ...|$|E
30|$|Zero-motion-based H. 264 denoted as H. 264 0 -mv is {{employed}} in our scheme {{to meet the}} demands of low-complexity encoding. Zero-motion-based H. 264 means that only the previous frame is used as the referenced frame for the inter-coding with motion searching region set to zero, which is therefore similar to the <b>differential</b> <b>pulse</b> <b>coding</b> <b>modulation</b> (DPCM). Because DPCM exploits the temporal correlation between adjacent frames, zero-motion-based H. 264 normally outperforms the intra-frame coding in term of rate-distortion performance. With no motion estimation at the encoder, its encoding process is greatly simplified. Typically, in our experiments, the encoding time of zero-motion-based H. 264 inter-coding is always shorter than that of the intra-frame in H. 264 JM 9.0 program.|$|R
40|$|A joint {{source channel}} coding scheme for error {{resilient}} image transmission is proposed. A practical image coder {{was introduced in}} [1] using modified <b>Differential</b> <b>Pulse</b> <b>Coded</b> <b>Modulation</b> (DPCM) codec with multi-rate processing and adaptive entropy coding. In this paper the residual redundancy of the prediction error image is exploited by using turbo codes for both data compression and er-ror protection. In the paper we deal with robust transmission of the source over a BSC channel, but {{the results can be}} easily extended for non binary channels. Note also that simple modification of the quantizer allows for progressive transmission and successive refinement of information. With properly chosen rate and punctur-ing, the system is able to approach the limit theoretically attainable and to outperform the separated approach that consists on the con-catenation of the system in [1] and the best turbo codes for the same spectral efficiency. 1...|$|R
40|$|Image {{and audio}} data are {{examples}} of domains in which DPCM (<b>Differential</b> <b>Pulse</b> <b>Coded</b> <b>Modulation)</b> is an effective method for removing much of the linear correlation between data samples. However, most simple DPCM schemes cannot simultaneously cater for smooth signals, noisy signals, and discontinuities such as edges in images. To overcome this, many adaptive DPCM schemes have been proposed, including median predictors, gradient-based switching predictors and gradient-based blending predictors. In this paper we generalize the idea of blending predictors, and describe a powerful technique for creating locally adaptive compound predictors. The result is a prediction scheme which works well over a range of data types froms smooth to noisy, and requires very few tunable parameters. We apply this scheme to greyscale image data, colour image data, and audio data, and compare results {{with some of the}} current best adaptive DPCM predictors. 1 Introduction Image and audio data {{are examples of}} dom [...] ...|$|R
5000|$|... 197A - Adaptive Recursive Interpolated <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation</b> (ARIDPCM) Compression Algorithm For The National Imagery Transmission Format Standard ...|$|E
5000|$|G.726 - 40, 32, 24, 16 kbit/s Adaptive <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation</b> (ADPCM). Corresponding ANSI-C code is {{available}} in the G.726 module of the ITU-T G.191 Software Tools Library.|$|E
5000|$|G.723 {{withdrawn}} - Extensions of Recommendation G.721 adaptive <b>differential</b> <b>pulse</b> <b>code</b> <b>modulation</b> to 24 and 40 kbit/s {{for digital}} circuit multiplication equipment application. The {{content of the}} 1988 edition of ITU-T G.723 is now covered by ITU-T G.726.|$|E
40|$|The {{modified}} <b>Differential</b> <b>Pulse</b> <b>Coded</b> <b>Modulation</b> (DPCM) codec with multi-rate processing {{has been}} shown to able to code source with monotonically decreasing spectrum efficiently at low bit rates [1]. A practical image coder is designed based on this approach. Two dimensional DPCM is used along with decimation and interpolation {{to reduce the number of}} transmitted samples. The decimation rate depends on the signal spectrum and the bit rate. Further bit rate reduction is achieved through adaptive entropy coding. Wiener filter is appended in the decoder for minimizing distortion caused by quantization noise. The decimation filter can be implemented using simple IIR filters. The necessary side information is low. Simulation results show that the coder is able to give good compression performance at low bit rates which is superior to conventional DPCM codec and JPEG. Subjective quality can be as good as JPEG 2000. While at very low bit rates the proposed codec is able to retain certain image characteristics better than JPEG 2000. 1...|$|R
40|$|In this dissertation, an {{adaptive}} block truncation coding (ABTC) scheme suit-able for highly-parallel software implementation is proposed. ABTC {{is one of}} extended schemes of the original block truncation coding (BTC), but it introduces a new classifi-cation approach for adaptive <b>coding</b> and <b>differential</b> <b>pulse</b> <b>coding</b> <b>modulation</b> (DPCM). Furthermore, its highly-parallel data-driven software implementation is discussed to realize real-time video applications on small and low-power ubiquitous devices. In the proposed ABTC scheme, two optimal threshold values are introduced to identify a luminance block image as uniform block, normal block, or pattern block. One is the sample first absolute central moment (AM), which denotes the dispersion from the mean value in a 4 x 4 pixel block; another is the mean of absolute errors (MAE) between the original pixel values and their decoded data in every block image, which is computed with the simplified absolute moment block truncation coding (SAMBTC). In order to achieve a better trade-off between the image quality and computational complexity, different coding approaches are employed to compress/decompress three sorts of block images. Moreover, to improve the compression efficiency, DPCM is utilized to remov...|$|R
40|$|With the {{advancement}} of computer graphics in the recent years, {{an increasing number of}} pictures, video and 3 D content is generated by synthesis processing rather than acquired with capture devices such as cameras or scanners. Several techniques have been developed for compression of discrete (i. e. piece-wise planar) 3 D models, in the form of 3 D polygonal meshes. However, no important attempt has been made to compress the smooth surfaces of artificially generated 3 D models, that are most often represented as parametric surfaces, of which Non-Uniform Rational B-Spline (NURBS) is a popular form. This paper presents a method for compressing NURBS 3 D models with a small and controllable loss. The scheme uses a <b>differential</b> <b>pulse</b> <b>coded</b> <b>modulation</b> (DPCM) coder with different predictors for knot values and control points, coupled with a uniform scalar quantizer, followed by a bitplane arithmetic entropy coder. The multiplicity of knots is preserved by the use of a multiplicity map. The rate-distortion characteristics of the proposed scheme are evaluated on various models. When compared to MPEG- 4 [8, 9] and Touma-Gotsman [19] compressed triangular meshes, the proposed scheme achieves more than five times better compression, for equivalent L 2 error and much better visual quality. Key words: B-Spline, NURBS, compression, 3 D model, coding, triangular mes...|$|R
50|$|Smacker audio {{is one of}} {{the audio}} formats {{that can be used in}} the Smacker container. For compression, <b>Differential</b> <b>pulse</b> <b>code</b> <b>modulation</b> (DPCM) is used. The {{difference}} between two successive samples is compressed using Huffman coding. The Huffman tables are adapted once per audio frame.|$|E
50|$|NICAM {{sampling}} is not standard PCM sampling, as commonly employed {{with the}} Compact Disc {{or at the}} codec level in MP3, AAC or Ogg audio devices. NICAM sampling more closely resembles Adaptive <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation,</b> or A-law companding with an extended, rapidly modifiable dynamic range.|$|E
50|$|G.723 is an ITU-T {{standard}} speech codec using {{extensions of}} G.721 providing voice quality covering 300 Hz to 3400 Hz using Adaptive <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation</b> (ADPCM) to 24 and 40 kbit/s for digital circuit multiplication equipment (DCME) applications. The standard G.723 is obsolete {{and has been}} superseded by G.726.|$|E
40|$|This paper {{presents}} an efficient and fast encoding of still images using {{feedforward neural network}} technique for codebook search. The image to be coded is first clustered into a small subset of neighboring images and then the neural network-based encoder is used {{to find the best}} matching code sequences in the codebook. This subset is then used as a candidate set and an exhaustive search is then performed within this subset to find an optimal code sequence which minimizes the perceptual error between coded and decoded images. In this work, a generic codebook is developed using non-causal <b>Differential</b> <b>Pulse</b> <b>Coded</b> <b>Modulation</b> (DPCM) with residual mean removal and vector quantization using Linde, Buzo and Gray (LBG) method. The codebook is analyzed to identify a pattern in the codebook. This pattern is used to train a neural network to obtain the approximate index of the pattern in the codebook. Then, an extensive search is done around this approximate position identified by the neural network to obtain the nearest neighbor of the pattern. Since the candidate set is usually much smaller that the whole code book, there is a substantial saving in codebook search time for coding an image as compared to the traditional method using full codebook search by LBG algorithm...|$|R
40|$|Two personalised {{instantaneous}} speech playback {{devices were}} designed and developed Both centred upon the memory efficiency advantages of Adaptive <b>Differential</b> <b>Pulse</b> <b>Coded</b> <b>Modulation</b> (ADPCM). One system is handheld and offers 64 seconds of speech. The second system hasdictionary of 230 four second phrases and is PC based. Medical Assessment: The problem of communication for the vocally handicapped is of grave concern. The communication aids currently available {{for this group}} of society include text-to-speech synthesizers and portable LPC coders (ref. 1 & 2). The use of these devices is restrictive due to poor quality speech and the use normally of a mid atlantic accent. Some offer good quality speech although are somewhat restrictive in use (ref. 3). The non-vocal physically handicapped also have few systems available to them for communication. The seventy of their disabilities normally limits their use such systems. Following {{a study conducted by}} the National Medical Rehabilitation Centre it became evident that a syntheziser system would have to preserve quality accent and sex. Also apparent from this study was the fact that full text-to-speech was not required by the majority of potential users but instead short well spoken phrases. Cost also had a bearing on the communication aid prescribed. A...|$|R
40|$|The {{purpose of}} this thesis {{was to develop a}} low {{complexity}} image compression algorithm for Wireless Sensor Networks (WSN). The main constraints in a WSN node are limited processing power, memory allocation, and battery life. The goal of this thesis was to develop an image compression algorithm that would thrive under this constraint environment. The main focus was to minimize the complexity of the algorithm by taking advantage of the spatial correlation found in Bayer images. The algorithm employs line based 1 -D Discrete Wavelet Packets Transform of Bayer images. In addition the image compression method includes the application of a third-order <b>Differential</b> <b>Pulse</b> <b>Coded</b> <b>Modulation,</b> and entropy <b>coding.</b> The generation of the prediction values for a third order DPCM were generated based on statistical data of a set of six Kodak true color images. In addition, the probability density function of every subband was obtained and used to design the Huffman tables used for entropy coding. ^ The proposed algorithm was able to produce comparable PSNR and compression ratio compared to a direct implementation of the JPEG algorithm to a Bayer image. In addition it was found that applying the JPEG algorithm with a very low quality factor does not preserve the color information in the image. ...|$|R
50|$|Sub-band coding is {{used for}} example in the G.722 codec. It uses {{sub-band}} adaptive <b>differential</b> <b>pulse</b> <b>code</b> <b>modulation</b> (SB-ADPCM) within a bit rate of 64 kbit/s. In the SB-ADPCM technique, the frequency band is split into two sub-bands (higher and lower) and the signals in each sub-band are encoded using ADPCM.|$|E
50|$|Communication systems: {{amplitude}} and {{angle modulation}} and demodulation systems, spectral {{analysis of these}} operations, superheterodyne receivers; elements of hardware, realizations of analog communication systems; signal-to-noise ratio (SNR) calculations for amplitude modulation (AM) and frequency modulation (FM) for low noise conditions. Digital communication systems: pulse code modulation (PCM), <b>differential</b> <b>pulse</b> <b>code</b> <b>modulation</b> (DPCM), delta modulation (DM); digital modulation schemes-amplitude, phase and frequency shift keying schemes (ASK, PSK, FSK), matched filter receivers, bandwidth consideration and probability of error calculations for these schemes.|$|E
5000|$|Similar {{to other}} ADPCM (Adaptive <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation)</b> formats, Dialogic ADPCM {{compresses}} audio data {{into a series}} of 4-bit samples. The original Dialogic ADPCM paper (linked to below) does not specify or mention a recording or playback frequency; it may be at the implementer discretion. However, traditionally, files commonly have a sampling rate of 6000 or 8000 samples per second, but 8000 samples per second (8000 Hz) is more common. 8000 Hz matches the sampling rate used in G.711 voice systems such as DS1.|$|E
40|$|The {{need for}} {{efficient}} joint source-channel coding (JSCC) is growing as new multimedia services are introduced in commercial wireless communication systems. An {{important component of}} practical JSCC schemes is a distortion model that can predict the quality of compressed digital multimedia such as images and videos. The usual approach in the JSCC literature for quantifying the distortion due to quantization and channel errors is to estimate it for each image using the statistics of the image for a given {{signal to noise ratio}} (SNR). This is not an efficient approach in the design of real-time systems because of the computational complexity. A more useful and practical approach would be to design JSCC techniques that minimize average distortion for a large set of images based on some distortion model rather than carrying out per-image optimizations. However, models for estimating average distortion due to quantization and channel bit errors in a combined fashion for a large set of images are not available for practical image or video coding standards employing entropy coding and differential coding. This paper presents a statistical model for estimating the distortion introduced in progressive JPEG compressed images due to quantization and channel bit errors in a joint manner. Statistical modelling of important compression techniques such as Huffman <b>coding,</b> <b>differential</b> <b>pulse</b> <b>coding</b> <b>modulation</b> (DPCM), an...|$|R
40|$|With recent {{progress}} in computing, algorithmics and telecommunications, 3 D models are increasingly used in various multimedia applications. Examples include visualization, gaming, entertainment and virtual reality. In the multimedia domain 3 D {{models have been}} traditionally represented as polygonal meshes. This piecewise planar representation {{can be thought of}} as the analogy of bitmap images for 3 D surfaces. As bitmap images, they enjoy great flexibility and are particularly well suited to describing information captured from the real world, through, for instance, scanning processes. They suffer, however, from the same shortcomings, namely limited resolution and large storage size. The compression of polygonal meshes has been a very active field of research in the last decade and rather efficient compression algorithms have been proposed in the literature that greatly mitigate the high storage costs. However, such a low level description of a 3 D shape has a bounded performance. More efficient compression should be reachable through the use of higher level primitives. This idea has been explored to a great extent in the context of model based coding of visual information. In such an approach, when compressing the visual information a higher level representation (e. g., 3 D model of a talking head) is obtained through analysis methods. This can be seen as an inverse projection problem. Once this task is fullled, the resulting parameters of the model are coded instead of the original information. It is believed that if the analysis module is efficient enough, the total cost of coding (in a rate distortion sense) will be greatly reduced. The relatively poor performance and high complexity of currently available analysis methods (except for specific cases where a priori knowledge about the nature of the objects is available), has refrained a large deployment of coding techniques based on such an approach. Progress in computer graphics has however changed this situation. In fact, nowadays, an increasing number of pictures, video and 3 D content are generated by synthesis processing rather than coming from a capture device such as a camera or a scanner. This means that the underlying model in the synthesis stage can be used for their efficient coding without the need for a complex analysis module. In other words it would be a mistake to attempt to compress a low level description (e. g., a polygonal mesh) when a higher level one is available from the synthesis process (e. g., a parametric surface). This is, however, what is usually done in the multimedia domain, where higher level 3 D model descriptions are converted to polygonal meshes, if anything by the lack of standard coded formats for the former. On a parallel but related path, the way we consume audio-visual information is changing. As opposed to recent past and a large part of today's applications, interactivity is becoming a key element in the way we consume information. In the context of interest in this dissertation, this means that when coding visual information (an image or a video for instance), previously obvious considerations such as decision on sampling parameters are not so obvious anymore. In fact, as in an interactive environment the effective display resolution can be controlled by the user through zooming, there is no clear optimal setting for the sampling period. This means that because of interactivity, the representation used to code the scene should allow the display of objects in a variety of resolutions, and ideally up to infinity. One way to resolve this problem would be by extensive over-sampling. But this approach is unrealistic and too expensive to implement in many situations. The alternative would be to use a resolution independent representation. In the realm of 3 D modeling, such representations are usually available when the models are created by an artist on a computer. The scope of this dissertation is precisely the compression of 3 D models in higher level forms. The direct coding in such a form should yield improved rate-distortion performance while providing a large degree of resolution independence. There has not been, so far, any major attempt to efficiently compress these representations, such as parametric surfaces. This thesis proposes a solution to overcome this gap. A variety of higher level 3 D representations exist, of which parametric surfaces are a popular choice among designers. Within parametric surfaces, Non-Uniform Rational B-Splines (NURBS) enjoy great popularity as a wide range of NURBS based modeling tools are readily available. Recently, NURBS has been included in the Virtual Reality Modeling Language (VRML) and its next generation descendant eXtensible 3 D (X 3 D). The nice properties of NURBS and their widespread use has lead us to choose them as the form we use for the coded representation. The primary goal of this dissertation is the definition of a system for coding 3 D NURBS models with guaranteed distortion. The basis of the system is entropy <b>coded</b> <b>differential</b> <b>pulse</b> <b>coded</b> <b>modulation</b> (DPCM). In the case of NURBS, guaranteeing the distortion is not trivial, as some of its parameters (e. g., knots) have a complicated influence on the overall surface distortion. To this end, a detailed distortion analysis is performed. In particular, previously unknown relations between the distortion of knots and the resulting surface distortion are demonstrated. Compression efficiency is pursued at every stage and simple yet efficient entropy coder realizations are defined. The special case of degenerate and closed surfaces with duplicate control points is addressed and an efficient yet simple coding is proposed to compress the duplicate relationships. Encoder aspects are also analyzed. Optimal predictors are found that perform well across a wide class of models. Simplification techniques are also considered for improved compression efficiency at negligible distortion cost. Transmission over error prone channels is also considered and an error resilient extension defined. The data stream is partitioned by independently coding small groups of surfaces and inserting the necessary resynchronization markers. Simple strategies for achieving the desired level of protection are proposed. The same extension also serves the purpose of random access and on-the-fly reordering of the data stream...|$|R
40|$|Calibration curves for the Apollo 16 command {{service module}} <b>pulse</b> <b>code</b> <b>modulation</b> {{downlink}} and onboard display are presented. Subjects discussed are: (1) measurement calibration curve format, (2) measurement identification, (3) multi-mode calibration data summary, (4) <b>pulse</b> <b>code</b> <b>modulation</b> bilevel events listing, and (5) calibration curves for instrumentation downlink and meter link...|$|R
50|$|Lossless JPEG is {{actually}} a mode of operation of JPEG. This mode exists because the discrete cosine transform (DCT) based form cannot guarantee that encoder input would exactly match decoder output. Unlike the lossy mode {{which is based on}} the DCT, the lossless coding process employs a simple predictive coding model called <b>differential</b> <b>pulse</b> <b>code</b> <b>modulation</b> (DPCM). This is a model in which predictions of the sample values are estimated from the neighboring samples that are already coded in the image. Most predictors take the average of the samples immediately above and {{to the left of the}} target sample. DPCM encodes the differences between the predicted samples instead of encoding each sample independently. The differences from one sample to the next are usually close to zero. A typical DPCM encoder is displayed in Fig.1. The block in the figure acts as a storage of the current sample which will later be a previous sample.|$|E
40|$|<b>Differential</b> <b>pulse</b> <b>code</b> <b>modulation</b> (DPCM) and its signal -{{adaptive}} derivative, {{the adaptive}} <b>differential</b> <b>pulse</b> <b>code</b> <b>modulation</b> (ADPCM), are well-known schemes for coding {{of images and}} video [1, 2]. We present a novel low-complexity scheme for adaptive <b>differential</b> <b>pulse</b> <b>code</b> <b>modulation</b> of color video using a set of two-level quantizers which are switched adaptively on a block-by-block basis. The quantizers are designed by statistical optimization with a new design criterion that borrows from DPCM, block truncation coding (BTC) and vector quantization (VQ). Coding results show that our scheme has a better performance than other lowcomplexity schemes. At 2 bit/pixel, it performs more than 2. 0 dB better in peak signal-to-noise ratio than DPCM and up to 3. 5 dB better than BTC. Possible applications include VLSI implementations and real-time compression for video transmission over local area networks. 1. ADAPTIVE <b>DIFFERENTIAL</b> <b>PULSE</b> <b>CODE</b> <b>MODULATION</b> (ADPCM) The principle of DPCM (Different [...] ...|$|E
40|$|This project {{investigates the}} signal {{compression}} potential and signal-to-noise ratios for audio signal based on four different source-coding techniques. They are the Fast Fourier Transform with Huffman Coding, Discrete Wavelet Transform with Huffman Coding, <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation,</b> and Delta Modulation...|$|E
5000|$|Alec Harley Reeves, Electronics engineer, {{inventor}} of <b>Pulse</b> <b>code</b> <b>modulation</b> ...|$|R
5000|$|The first {{transmission}} of speech by <b>pulse</b> <b>code</b> <b>modulation</b> (PCM) ...|$|R
5000|$|Equivalent <b>pulse</b> <b>code</b> <b>modulation</b> noise, {{measure of}} noise by {{comparing}} to PCM quantization noise ...|$|R
40|$|The semiannual {{report is}} included. Topics covered include communication, {{information}} science, data compression, remote sensing, color mapped images, robust coding scheme for packet video, recursively indexed <b>differential</b> <b>pulse</b> <b>code</b> <b>modulation,</b> image compression technique {{for use on}} token ring networks, and joint source/channel coder design...|$|E
40|$|Adaptive <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation,</b> or ADPCM, is {{a digital}} {{compression}} technique used mainly for speech compression in telecommunications. ADPCM is a waveform codec {{that can also}} be used to code other signals than speech, such as music or sound effects. ADPCM is simpler than advanced low bit-rate voic...|$|E
40|$|The {{study is}} related to {{lossless}} compression of greyscale images. The goal {{of the study was}} to combine two techniques of lossless image compression, i. e. Integer Wavelet Transform and <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation</b> to attain better compression ratio. This is an experimental study, where we implemented Integer Wavelet Transform, <b>Differential</b> <b>Pulse</b> <b>Code</b> <b>Modulation</b> and an optimized predictor model using Genetic Algorithm. This study gives encouraging results for greyscale images. We achieved a better compression ration in term of entropy for experiments involving quadrant of transformed image and using optimized predictor coefficients from Genetic Algorithm. In an other set of experiments involving whole image, results are encouraging and opens up many areas for further research work like implementing Integer Wavelet Transform on multiple levels and finding optimized predictor at local levels...|$|E
25|$|Alec Harley Reeves, {{electronics}} engineer, {{inventor of}} <b>Pulse</b> <b>code</b> <b>modulation,</b> {{was born here}} in 1902.|$|R
5000|$|Robustness {{similar to}} <b>pulse</b> <b>code</b> <b>modulation</b> (PCM) with packet loss concealment, like the ITU-T G.711 ...|$|R
40|$|An illustrative {{embodiment}} of the invention includes apparatus which simultaneously produces both direct delta <b>modulation</b> and <b>pulse</b> <b>code</b> <b>modulation.</b> An input signal, after amplification, is supplied to a window comparator which supplies a polarity control signal to gate the output of a clock to the appropriate input of a binary up-down counter. The control signals provide direct delta modulation while the up-down counter output provides <b>pulse</b> <b>code</b> <b>modulation...</b>|$|R
