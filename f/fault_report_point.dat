0|2629|Public
50|$|This {{concept is}} {{applicable}} to mission critical systems that incorporate active redundancy and <b>fault</b> <b>reporting.</b> It is also applicable to non-mission critical systems that lack redundancy and <b>fault</b> <b>reporting.</b>|$|R
50|$|<b>Fault</b> <b>reporting</b> {{eliminates}} {{maintenance costs}} associated manual diagnostic testing.|$|R
50|$|This {{concept is}} related to {{condition-based}} maintenance and <b>fault</b> <b>reporting.</b>|$|R
5000|$|... less {{reliable}} than equipment with <b>fault</b> <b>reporting</b> associated with CBM ...|$|R
5000|$|Checking any <b>fault</b> <b>reports</b> {{to limit}} {{possible}} hardware problems prior to test ...|$|R
50|$|All modern {{computers}} {{provide the}} following when an existing feature is enabled via <b>fault</b> <b>reporting.</b>|$|R
50|$|<b>Fault</b> <b>reporting</b> is a {{maintenance}} concept that increases operational availability and that reduces operating cost through three mechanisms.|$|R
50|$|Active {{redundancy}} can {{be integrated}} with <b>fault</b> <b>reporting</b> to reduce down time to a few minutes per year.|$|R
40|$|Analysis {{techniques}} from safety-critical development, such as PHA or HazOp, {{shall be}} used on DAIM, a system used at IME for starting, delivering and finishing master thesis. Documents to be analyzed are from the specification and design phase of the system development. The results obtained from using these techniques shall be compared with existing <b>fault</b> <b>reports</b> with actual <b>faults</b> as have been discovered in the system. These <b>fault</b> <b>reports</b> shall also be treated and analyzed...|$|R
5000|$|Diagnostic {{down time}} is {{required}} to identify {{the amount of time}} spent perform maintenance when <b>fault</b> <b>reporting</b> does not support condition-based maintenance.|$|R
50|$|As another example, {{enabling}} <b>fault</b> <b>reporting</b> for Internet network packet delivery failure {{will increase}} network loading when {{the network is}} already busy, and that will cause total network outage.|$|R
5000|$|In Australia, {{there are}} {{numerous}} satirical news websites including The Shovel, The Betoota Advocate, The (Un)Australian, The <b>Fault</b> <b>Report,</b> The Sauce and The Tunnel Presents. The Shovel mainly satirizes the Australian political and social culture and The Betoota Advocate satirizes the political right and Australian journalism. In February 2015, The Betoota Advocate shot to fame after the publication's editor's sneaked in to the media scrum outside Parliament House in Canberra during a leadership spill motion and managed to interview some of Australia's most high-profile media personalities and politicians, posing as legitimate journalists. The fallout from The Betoota Advocate stunt {{has led to a}} security increase surrounding parliamentary media and screening of all crew. The <b>Fault</b> <b>Report</b> [...] was established in 2014 and also has a political editorial focus. British-born Australian author John Birmingham once described The <b>Fault</b> <b>Report</b> as, [...] "Like The Onion. But with Vegemite", on his blog Cheeseburger Gothic. The Tunnel Presents, which has been online since June 2011, is by Brisbane-based satire writing team The Tunnel and has political and social satire stories with a Queensland focus.|$|R
50|$|<b>Fault</b> <b>reporting</b> is {{localised}} {{and system}} failure is generally only uncovered {{as a consequence}} of customer complaint. The fixed telecommunications network consists {{of a wide variety of}} mostly old technologies, some of which are obsolete.|$|R
50|$|Other {{kinds of}} <b>fault</b> <b>reporting</b> {{involves}} painting green, yellow, and red zones onto temperature gages, pressure gages, flow gages, vibration sensors, strain gages, and similar sensors. Remote viewing {{can be implemented}} using a video camera.|$|R
40|$|The {{traditional}} Automatic Test Equipment (ATE) {{systems are}} insufficient {{to cope with}} the challenges of testing more and more complex avionics systems. In this study, we propose a general method for module automatic testing in the avionics test platform based on PXI bus. We apply virtual instrument technology to realize the automatic testing and the <b>fault</b> <b>reporting</b> of signal performance. Taking the avionics bus ARINC 429 as an example, we introduce the architecture of automatic test system as well as the implementation of algorithms in Lab VIEW. The comprehensive experiments show the proposed method can effectively accomplish the automatic testing and <b>fault</b> <b>reporting</b> of signal performance. It greatly improves the generality and reliability of ATE in avionics systems...|$|R
40|$|A good {{interaction}} between public administrations and citizens is imperative in modern smart cities. Semantic web technologies can aid in achieving such a goal. We present a smart urban <b>fault</b> <b>reporting</b> web platform to help citizens in reporting common urban problems, such as street faults, potholes or broken street lights, {{and to support}} the local public administration in responding and fixing those problems quickly. The tool {{is based on a}} semantic data model designed for the city, which integrates several distinct data sources, opportunely re-engineered to meet the principles of the Semantic Web and linked open data. The platform supports the whole process of road maintenance, from the <b>fault</b> <b>reporting</b> to the management of maintenance activities. The integration of multiple data sources enables increasing interoperability and heterogeneous information retrieval, thus favoring the development of effective smart urban <b>fault</b> <b>reporting</b> services. Our platform was evaluated in a real case study: a complete urban reporting and road maintenance system has been developed for the municipality of Catania. Our approach is completely generalizable and can be adopted by and customized for other cities. The final goal is to stimulate smart maintenance services in the "cities of the future"...|$|R
40|$|Abstract. Improving {{software}} processes {{relies on}} the ability to analyze previous projects and derive which parts of the process that should be focused on for improvement. All software projects encounter software faults during development and have to put much effort into locating and fixing these. A lot of information is produced when handling <b>faults,</b> through <b>fault</b> <b>reports.</b> This paper reports a study of <b>fault</b> <b>reports</b> from industrial projects, where we seek a better understanding of faults that have been reported during development and how this may affect the quality of the system. We investigated the fault profiles of five business-critical industrial projects by data mining to explore if there were significant trends in the way faults appear in these systems. We wanted to see if any types of faults dominate, and whether some types of <b>faults</b> were <b>reported</b> as being more severe than others. Our findings show that one specific fault type is generally dominant across reports from all projects, and that some fault types are rated as more severe than others. From this we could propose that the organization studied should increase effort in the design phase in order to improve software quality. ...|$|R
25|$|Maintenance on the ICE trains {{is carried}} out in special ICE {{workshops}} located in Basel, Berlin, Cologne, Dortmund, Frankfurt, Hamburg, Leipzig and Munich. The train is worked upon at up to four levels {{at a time and}} <b>fault</b> <b>reports</b> are sent to the workshops in advance by the on-board computer system to keep maintenance time at a minimum.|$|R
40|$|International audienceWe {{consider}} {{a group of}} players who perform tasks repeatedly. The players are nodes of a communication network and observe their neighbors' actions. Players have partial knowledge of the network and only know their set of neighbors. We study the existence of protocols for fault reporting: whenever a player chooses a faulty action, the communication protocol starts and the output publicly reveals {{the identity of the}} faulty player. We consider two setups. In the first one, players do not share authentication keys. We show that existence of a protocol for <b>fault</b> <b>reporting</b> is equivalent to the 2 -vertex-connectedness of the network: no single vertex deletion disconnects the graph. In the second setup, we allow players to share authentication keys. We show that existence of a distribution of the keys and of a protocol for <b>fault</b> <b>reporting</b> is equivalent to the 2 -edge-connectedness of the network: no single edge deletion disconnects the graph. We give applications to the implementation of socially optimal outcomes in repeated games...|$|R
40|$|Abstract. Faults {{introduced}} into systems during development are costly to fix, and especially so for business-critical systems. These systems are developed using common development practices, but have high requirements for dependability. This paper reports {{on an ongoing}} investigation of <b>fault</b> <b>reports</b> from Norwegian IT companies, where {{the aim is to}} seek a better understanding on faults that have been found during development and how this may affect the quality of the system. Our objective in this paper is to investigate the fault profiles of four business-critical commercial projects to explore if there are differences in the way faults appear in different systems. We have conducted an empirical study by collecting <b>fault</b> <b>reports</b> from several industrial projects, comparing findings from projects where components and reuse have been core strategies with more traditional development projects. Findings show that some specific fault types are generally dominant across reports from all projects, and that some fault types are rated as more severe than others. 1...|$|R
40|$|In this master thesis we have {{analyzed}} the software system DAIM, {{which is a}} web-based delivery system used at NTNU in connection with master theses and master students, with respect to software faults. Based on the documentation from the design stage of the DAIM project we have performed a technique called Preliminary Hazard Analysis (PHA), which is an analysis technique from safety-critical development. The results from this analysis have been compared with existing <b>fault</b> <b>reports</b> containing actual <b>faults</b> discovered in the system. Some of the intention behind our work has been to find if hazards identified with PHA {{can be related to}} actual faults found in the <b>fault</b> <b>reports.</b> In [17] it is stated that correcting software faults in later phases of the software development is much more expensive than in earlier phases and we have performed the PHA to see if some of the faults could have been avoided. We found that there were some connections between some of the faults and hazards identified, but the results were not entirely as expected. In our previous work we did a similar kind of analysis as we have done in this work regarding the analysis of <b>fault</b> <b>reports</b> and we have compared the results from our previous work with some of the results that we have obtained from this work to see how the distribution of fault types varies between the projects. The results showed that there were several differences between the projects, but some similarities were also discovered. </p...|$|R
40|$|Universal voltage, power-factor-corrected {{power supply}} • Very low inrush current • 100 watts x 4 {{channels}} in 1 U chassis • Built-in load monitoring • Remote <b>fault</b> <b>reporting</b> and redundancy switching • Optional 4 channel 70 / 100 volt transformers in 1 U chassis • Adjustable high-pass filters and remote level controllable • Advanced dynamics control adjusts for sensitivity setting, load Z and temperatur...|$|R
50|$|In network {{management}}, {{fault management}} is {{the set of}} functions that detect, isolate, and correct malfunctions in a telecommunications network, compensate for environmental changes, and include maintaining and examining error logs, accepting and acting on error detection notifications, tracing and identifying faults, carrying out sequences of diagnostics tests, correcting <b>faults,</b> <b>reporting</b> error conditions, and localizing and tracing faults by examining and manipulating database information.|$|R
50|$|The {{historic}} AN/UYK-43 architecture includes active redundancy. It includes multiple processors, multiple memory banks, {{and multiple}} input-output devices with interfaces for multiple disk drives. Power-on self test firmware incorporates features that reconfigure software loading {{in order to}} bypass failure. This allows it to run in degraded mode with failed processors, failed memory, failed disk drives, and failed input/output devices. Remote status boards perform <b>fault</b> <b>reporting.</b>|$|R
40|$|A rule-based, {{system-level}} {{fault detection}} and diagnostic (FDD) method for HVAC systems was developed. It functions as an interface between multiple, equipment-specific FDD tools and a human operator. The method resolves and prioritizes conflicting <b>fault</b> <b>reports</b> from equipment-specific FDD tools, performs FDD {{at the system}} level, and presents an integrated view of an HVAC system’s fault status to an operator. A simulation study to test and evaluate the method was conducted...|$|R
5000|$|... #Subtitle level 3: Warning, Advice and <b>Reporting</b> <b>Points</b> (WARPs) ...|$|R
50|$|Another media <b>report</b> <b>pointed</b> at Dokumacılar, an ISIL-linked {{terrorist}} group.|$|R
50|$|<b>Report</b> <b>points</b> out 474 {{instances}} of involuntary disappearances since 2006.|$|R
40|$|A {{system-level}} {{fault detection}} and diagnostic (FDD) method for heating, ventilation, {{and air conditioning}} (HVAC) systems was developed. It functions as an interface between multiple, equipment-specific FDD tools and a human operator. The method resolves conflicting <b>fault</b> <b>reports</b> from equipment-specific FDD tools, performs FDD at the system level, and presents an integrated view of an HVAC system’s fault status to an operator. A simulation study to test and evaluate the method was conducted...|$|R
50|$|<b>Fault</b> <b>reporting</b> is an {{optional}} feature {{that can be}} forwarded to remote displays using simple configuration setting in all modern computing equipment. The system level of reporting that is appropriate for Condition Based Maintenance are critical, alert, and emergency, which indicate software termination due to failure. Specific failure reporting, like interface failure, can be integrated into applications linked with these reporting systems. There is no development cost if these are incorporated into designs.|$|R
5000|$|Preferred <b>reporting</b> <b>points</b> (magenta flag with name), on easily {{identified}} features; and ...|$|R
5000|$|... #Caption: The <b>reported</b> <b>point</b> {{where the}} ship was last {{observed}} by coastal radar ...|$|R
50|$|EESL is {{successfully}} {{implementing the}} energy efficiency schemes like UJALA (Unnat Jyoti by Affordable LEDs for All), Street Light National Programme (SLNP), National Energy Efficient fan distribution programme, Efficient Buildings programme. EESL is also implementing the world’s largest Agricultural Demand Side Management programme (AgDSM) wherein the Energy Efficient Pumpsets (EEPS) with Smart control Panel are being distributed to farmers free of cost. Smart control panels would enable facilities like remote (Mobile based) start/ Stop, <b>fault</b> <b>report</b> by SMS, etc.|$|R
30|$|The MapReduce P 2 P {{framework}} {{can also}} be applied to distributed computing applications, especially applications running on P 2 P networks. These applications process large amount of data on distributed workstations on the Internet. We apply this framework to improve the computation component of DisCaRia, a distributed case-based reasoning (CBR) system for resolving faults in network and communication systems [28, 29, 30, 31, 32, 33]. DisCaRia takes advantage of P 2 P technology to extend the conventional CBR systems [3], thus exploring problem solving knowledge resources in distributed environments, such as expert communities, ticket tracking systems (TTSs), forums and archives. Each peer contains an independent CBR component and exploits knowledge resources in parallel; the system therefore enhances the performance of managing huge datasets on various peers {{and the quality of}} various output solutions. The main disadvantage of DisCaRia is high computation cost and low efficiency of the computation component as the size of fault datasets increases. Note that <b>fault</b> <b>reports</b> contain several symptoms, error messages, distinct keywords, etc. MapReduce operations can deal with this problem by processing a large number of <b>fault</b> <b>reports</b> on various peers quickly and efficiently.|$|R
40|$|This {{thesis is}} a {{feasibility}} study {{for a more}} comprehensive work at Process Automation (PA) ABB, Västerås. The business units this work is focusing on are Mining and Crane Systems with the mission to map their quality processes within supply collaboration, acceptance control and data such as their supplier’s fault frequency. This thesis was initiated because of an internal audit where these business units at PA received remarks on their long term quality development and that they didn’t calculated supplier faults. To evaluate these business units and to find {{the root causes of}} these problems, the involved staff was interviewed and their internal documentation database was examined. The work method that is used in this thesis is ABB’s 4 Q and it’s practiced in quality development projects at ABB. The thesis report is also structured after 4 Q. From the interviews could the conclusion be made that the remarks from the internal audit was correct, but that the business units had different root causes to their problems. It was made clear that Mining had problems with <b>reporting</b> <b>faults</b> found at site. It’s not possible to calculate metrics, that global ABB determined shall be used, if the occurring <b>faults</b> aren’t <b>reported.</b> A plausible root cause to why there are insufficient <b>faults</b> <b>reported</b> is that the business units’ decision-making authority haven’t succeed to reach out with enough information to the staff {{about the importance of the}} process. It has led to a staff that isn’t aware of the real usefulness of <b>fault</b> <b>reporting.</b> Even the 100 k SEK guideline showed to be a root cause to the problem. This guideline hampers the possibility to collect relevant data and goes against ABB’s regulations to generate statistics. It makes it impossible to monitor field failure rates (fault at site) when minor fault are ignored because of the guideline. Crane Systems have on the contrary a functioning <b>fault</b> <b>reporting</b> process, but their shortage is in the generating of statistics. Even though the business unit has enough data to calculate and monitor their supplier’s error rate in the forms of lots accepted and PPM, are the statistics not communicated further. The statistics are neither reported internally within the organization, to the supplier or to central ABB. Both product and system managers generate their own statistics for their specific responsibility areas and needs, which mean that the general picture gets lost and the suppliers total fault frequency can’t be found. Summarized are these deficiencies leading to poor feedback to the suppliers about their delivered quality, and consequently makes it hard for the suppliers to know what to improve...|$|R
50|$|In 14% {{of deaths}} {{there was a}} {{regulator}} <b>fault</b> <b>reported,</b> and in 1% the regulator was misused. Subsequent testing of the regulators showed {{that most of the}} problems were caused by leaks resulting in inhalation of salt water, but in some cases there was excessive breathing resistance following a mechanical dysfunction. In a few cases the regulator failed catastrophically, or the hose burst. The difficulty of breathing from the regulator was often aggravated by other factors such as panic, exhaustion or badly adjusted buoyancy.|$|R
