0|155|Public
40|$|Bondlab {{has been}} set up as a {{platform}} independent toolbox in Matlab for mechatronic systems design. Powerful data structure constructs and object oriented facilities of the latest Matlab release are used to <b>guarantee</b> <b>code</b> transparency and maintenance efficiency. In order to retain fast execution of the code the classical vectorization of critical parts is still necessary...|$|R
40|$|Real {{parallel}} applications find little {{benefits from}} code portability {{that does not}} guarantee acceptable efficiency. In this paper, we describe the new features of a framework that allows the development of Single Program Multiple Data (SPMD) applications adaptable to different distributed-memory machines, varying from traditional parallel computers to networks of workstations. Special programming primitives providing indirect accesses to the platform and data domain <b>guarantee</b> <b>code</b> portability and open the way to runtime optimizations carried out by a scheduler and a runtime support...|$|R
50|$|The Trusted Execution Environment (TEE) is {{a secure}} {{area of the}} main processor. It <b>guarantees</b> <b>code</b> and data loaded inside to be {{protected}} with respect to confidentiality and integrity. The TEE as an isolated execution environment provides security features such as isolated execution, integrity of Trusted Applications along with confidentiality of their assets. In general terms, the TEE offers an execution space that provides {{a higher level of}} security than a rich mobile operating system (mobile OS) and more functionality than a 'secure element' (SE).|$|R
5000|$|Corruption. Government {{ministers and}} civil {{servants}} {{are bound to}} uphold the highest ethical standards, and standards of probity are <b>guaranteed</b> through <b>codes</b> of conduct and declarations of interest. However, the selling process could lack transparency, allowing the purchaser and civil servants controlling the sale to gain personally.|$|R
50|$|The {{original}} Java memory model, {{developed in}} 1995, was widely perceived as broken, preventing many runtime optimizations and not providing strong enough <b>guarantees</b> for <b>code</b> safety. It was updated through the Java Community Process, as Java Specification Request 133 (JSR-133), which took effect in 2004, for Tiger (Java 5.0).|$|R
5000|$|Non-characters. The {{consortium}} <b>guarantees</b> certain <b>code</b> points {{will never}} be assigned a character and calls these non-character code points. The last two code points of each plane (ending in FE and FF [...] ) are such code points. There are a few others interspersed throughout the Basic Multilingual Plane, the first plane.|$|R
40|$|Real {{parallel}} applications find little {{benefits from}} code portability {{that does not}} guarantee acceptable efficiency. In this paper, we describe the new features of a framework that allows the development of Single Program Multiple Data (SPMD) applications adaptable to different distributed-memory machines, varying from traditional parallel computers to networks of workstations. Special programming primitives providing indirect accesses to the platform and data domain <b>guarantee</b> <b>code</b> portability and open the way to runtime optimizations carried out by a scheduler and a runtime support. 1 Introduction The SPMD paradigm is the most widely adopted model for a large class of problems. However, this programming paradigm does not facilitate portability because it requires {{the choice of a}} specific domain decomposition, and the insertion of communications and parallel primitives in a decomposition dependent way. If we want a parallel application to be portable with efficiency (perfor- mance [...] ...|$|R
50|$|After data collection, the {{hospital}} staff transfers the data into a data base which is accessible over the website http://www.nutritionday.org. An individual <b>code</b> <b>guarantees</b> anonymity of participants.|$|R
40|$|Mobile code {{distribution}} {{relies on}} digital signatures to <b>guarantee</b> <b>code</b> authenticity. Unfortunately, standard signature schemes {{are not well}} suited for use in conjunction with program transformation techniques, such as aspect-oriented programming. With these techniques, code development is performed in sequence by multiple teams of programmers. This is fundamentally different from traditional single-developer/ single-user models, where users can verify end-to-end (i. e., developer-to-user) authenticity of the code using digital signatures. To address this limitation, we introduce FLEX, a flexible code authentication framework for mobile applications. FLEX allows semi-trusted intermediaries to modify mobile code without invalidating the developer's signature, {{as long as the}} modification complies with a "contract" issued by the developer. We introduce formal definitions for secure code modification, and show that our instantiation of FLEX is secure under these definitions. Although FLEX can be instantiated using any language, we design AMJ - a novel programming language that supports code annotations - and implement a FLEX prototype based on our new language...|$|R
40|$|Security (TLS) {{protocols}} {{have become}} the security backbone of the Web and Internet today. Many systems including mobile and desktop applications are protected by SSL/TLS protocols against network attacks. However, many vulnerabilities caused by incorrect use of SSL/TLS APIs have been uncovered in recent years. Such vulnerabilities, {{many of which are}} caused due to poor API design and inexperience of application developers, often lead to confidential data leakage or man-in-the-middle attacks. In this paper, to <b>guarantee</b> <b>code</b> quality and logic correctness of SSL/TLS applications, we design and implement SSLINT, a scalable, automated, static analysis system for detecting incorrect use of SSL/TLS APIs. SSLINT is capable of performing automatic logic verification with high efficiency and good accuracy. To demonstrate it, we apply SSLINT {{to one of the most}} popular Linux distributions – Ubuntu. We find 27 previously unknown SSL/TLS vulnerabilities in Ubuntu applications, most of which are also distributed with other Linux distributions. I...|$|R
40|$|The {{interaction}} between software systems {{by means of}} mobile code is a powerful and truly effective method, particularly useful for installing and executing code dynamically. However, for this mechanism to be applicable safely, especially in industrial or critical applications, techniques that <b>guarantee</b> foreign <b>code</b> execution safety for the consumer or host will be necessary. Of course, tool support for automating, at least partially, the application of these techniques is essential. The importance of <b>guarantee</b> <b>code</b> execution safety originates numerous active research lines, among which Proof-Carrying Code (PCC) {{is one of the}} most successful. One of the problems to overcome for the PCC industrial use is to obtain lineal methods of safeness certification and verification. A framework for the generation and execution of safe mobile code based on PCC together with techniques for static analysis of control and data-flow, called PCC-SA, was developed later by the authors. The results of the group that allowed proving the hypothesis that the PCC-SA complexity in practice is lineal respect to the input programs length, as for certification as for verification processes are also presented. To achieve this, a C-program family, whose elements are referred to as lineally annotative, is defined. Parameters statically measured over their source code determine whether a program belongs to this family or not. Different properties of this family are demonstrated in this work, which allows formally showing that for all the programs of this family, the PCC-SA presents a lineal behavior. The parameters required for a large sample of programs keeping of standard packages, are calculated. This calculation finally determines that all the programs of the sample are lineally annotative, which validates the hypothesis previously stated...|$|R
40|$|The bus {{between the}} System on Chip (SoC) and the {{external}} memory {{is one of}} the weakest points of computing systems because an adversary can easily probe this bus in order to read private data, to retrieve software code (data confidentiality concern) or to inject data (data integrity concern). The conventional way to provide data confidentiality and integrity is to implement a dedicated hardware engine for each security service. Being secured, this approach prevents parallelizability of the underlying computations. In this paper, we introduce the concept of Added Redundancy Explicit Authentication (AREA) at the block level and we describe a Parallelized Encryption and Integrity Checking Engine (PE-ICE) based on this concept. PE-ICE has been designed to provide an effective solution to ensure both security services while allowing for full parallelization on processor read and write operations and optimizing the hardware resources. Compared to standard encryption which provides only confidentiality, we show that PE-ICE additionally <b>guarantees</b> <b>code</b> and data integrity for less than 4 % of run-time performance overhead and at no additional hardware cost...|$|R
50|$|In {{contrast}} to classical block codes that often specify an error-detecting or error-correcting ability, many modern block codes such as LDPC <b>codes</b> lack such <b>guarantees.</b> Instead, modern <b>codes</b> are evaluated {{in terms of}} their bit error rates.|$|R
3000|$|Yet, {{when all}} SIRLs have been terminated, the {{proposed}} decoder architecture {{still does not}} <b>guarantee</b> all SW <b>coded</b> bit-planes have been decoded properly. Therefore, similar to[23], additional SIRLs are added. These supplemental SIRLs, that is, the SIRL [...]...|$|R
40|$|MCNPX is a Fortran 90 Monte Carlo {{radiation}} transport {{computer code}} that transports all particles at all energies. It is a superset of MCNP 4 C 3, and has many capabilities beyond MCNP 4 C 3. These capabilities are summarized {{along with their}} quality <b>guarantee</b> and <b>code</b> availability. Then the user interface changes from MCNP are described. Finally, the n. ew capabilities of the latest version, MCNPX 2. 5. c, are documented. Future plans and references are also provided...|$|R
50|$|Code signing is {{the process}} of {{digitally}} signing executables and scripts to confirm the software author and <b>guarantee</b> that the <b>code</b> has not been altered or corrupted since it was signed. The process employs the use of a cryptographic hash to validate authenticity and integrity.|$|R
40|$|Abstract. Standard {{class-based}} inheritance mechanisms, {{which are}} often used to implement distributed systems, {{do not seem to}} scale well to a distributed context with mobility. In this paper, a mixin-based approach is proposed for structuring mobile object-oriented code and it is shown to fit in the dynamic and open nature of a mobile code scenario. We introduce MoMi (Mobile Mixins), a coordination language for mobile processes that communicate and exchange object-oriented code in a distributed context. MoMi is equipped with a type system, based on polymorphism by subtyping, in order to <b>guarantee</b> safe <b>code</b> communications. ...|$|R
3000|$|... {{where the}} {{projection}} <b>guarantees</b> that the <b>codes</b> satisfy the nonnegative constraints C 6 and the definition by {{parts of the}} function of the codes is due to constraint C 8. Notice that the bisection method can also be used in this case to compute the optimum code allocation, n [...]...|$|R
40|$|In {{the context}} of the Lagrange approach, used in {{numerical}} simulations of two-phase flow, the discrete elements that constitute the dispersed phase are tracked through the fluctuating fluid field by solving their equations of motion. It has been shown previously [Laín, S., & Göz, M. F. (2000). Instabilities in numerical simulations of dispersed two-phase flow. Mechanical Research Communication 27, 475; Laín, S., & Göz, M. F. (2001). Numerical instabilities in bubble tracking in two-phase flow simulations. International Journal of Bifurcation and Chaos, 11 (4), 1169] that widely used discretization methods for integrating the particle equation of motion in bubbly flows may lead to artificial instabilities and, eventually, yield spurious oscillations and chaotic behavior via period-doubling bifurcations. The {{purpose of this paper is}} the extension of these previous investigations to consider dispersed two-phase flow laden with solid particles, which can be heavier or lighter than the fluid in which they are immersed. As a result, the numerical techniques applied to integrate the particle or bubble equation of motion are quite stable in the case of heavy particles but must be used very carefully when applied to the tracking of bubbles or light solid particles in a fluid. In addition, sound criteria are established for choosing optimal time steps to simultaneously avoid numerical instabilities and <b>guarantee</b> <b>code</b> efficiency, in contrast to the usual but naive trial and error approach. © 2004 Elsevier Ltd. All rights reserved. Peer Reviewe...|$|R
40|$|Abstract—String {{data has}} {{traditionally}} been difficult for test data generation tools to generate. Of particular concern are strings that conform to a given grammar, since coverage of grammar productions does not <b>guarantee</b> high <b>code</b> coverage or fault-finding ability. We address this problem by deriving Java classes from the grammatical categories in the grammar, and then using a collection of deterministic and metaheuristic techniques to generate strings from them. We compare the code coverage of these techniques and the standard conformance test suites for the grammars. We conclude that the various techniques have complementary strengths, {{and that they can}} be usefully used in combination. Keywords-Software testing; string data generation; metaheuristic algorithms; structural code coverage; I...|$|R
40|$|Region Of Interest (ROI) coding is a {{prominent}} feature of some image coding systems aimed to prioritize {{specific areas of}} the image {{through the construction of}} a codestream that, decoded at increasing bit-rates, recovers the ROI first and with higher quality {{than the rest of the}} image. JPEG 2000 is a wavelet-based coding system that is supported in the Digital Imaging and Communications in Medicine (DICOM) standard. Among other features, JPEG 2000 provides lossy-to-lossless compression and ROI coding, which are especially relevant to the medical community. But, due to JPEG 2000 supported ROI <b>coding</b> methods that <b>guarantee</b> lossless <b>coding</b> are not designed to achieve a high degree of accuracy to prioritize ROIs, they have not been incorporated in the medical community. - This paper introduces a ROI coding method that is able to prioritize multiple ROIs at different priorities, <b>guaranteeing</b> lossy-to-lossless <b>coding.</b> The proposed ROI Coding Through Component Prioritization (ROITCOP) method uses techniques of rate-distortion optimization combined with a simple yet effective strategy of ROI allocation that employs the multi-component support of JPEG 2000 codestream. The main insight in ROITCOP is the allocation of each ROI to an component. Experimental results indicate that this ROI allocation strategy does not penalize coding performance whilst achieving an unprecedented degree of accuracy to delimit ROIs. - The proposed ROITCOP method maintains JPEG 2000 compliance, thus easing its use in medical centers to share images. This paper analyzes in detail the use of ROITCOP to mammographies, where the ROIs are identified by computer-aided diagnosis. Extensive experimental tests using various ROI coding methods suggest that ROITCOP achieves enhanced coding performanc...|$|R
50|$|In October 2005 the Economist Intelligence Unit {{reported}} that Anvil's claim to Mutoshi was being disputed by Chemaf, an Indian-based company that operates the Etoile copper and cobalt mine.Chemaf, which apparently had strong political {{connections in the}} DRC, claimed it acquired the rights to Mutoshi in a 2003 deal with Emiko. The case {{was seen as an}} important test of the Mining <b>Code's</b> <b>guarantee</b> that the courts will uphold property rights.|$|R
30|$|This paper {{presents}} a class-based fair code allocation (CFCA) protocol to support fairness, rate and delay <b>guarantees</b> while allocating <b>codes</b> with low reassignment overhead in WCDMA. CFCA includes three algorithms: class-based code placement (CBP), class-based code replacement (CBR), and {{dynamic bandwidth allocation}} (DBA). Algorithm 1 aims to assign each flow a code whose affinity-mate codes can be easily assigned later to the flow in case of stringent delay requirements or poor channel conditions. If the affinity-mate codes of a code are not available, then Algorithm 2 is invoked to assign an appropriate code to the flow that requires a higher-rate code due to poor channel conditions. Both CBP and CBR also undertake {{reducing the number of}} code reassignments while eliminating code blocking. Although the existing bandwidth allocation algorithms address rate allocation only without considering code placements and reassignments, Algorithm DBA (see Algorithm 3) enables rate allocation, code allocation and reassignment to interact with each other in order to provide fairness, delay and rate <b>guarantees</b> with low <b>code</b> reassignment overhead.|$|R
40|$|It is {{inherently}} difficult for static analyses to make precise decisions about dynamic features of modern object-oriented languages. This {{makes it more}} difficult to apply optimizations aggressively. This thesis introduces the D. U. P. O. framework to facilitate the use of dynamic analyses to enable performance optimizations. Since dynamic analyses cannot <b>guarantee</b> complete <b>code</b> coverage, a two part strategy is employed: unit tests are used as a de facto specification, and the programmer provides final verification. The interaction can be kept at a minimum by using the rich information provided by a dynamic analysis. Object inlining is discussed as an example instance of the framework. National Science FoundationComputer ScienceMastersUniversity of New Mexico. Dept. of Computer ScienceStefanovic, DarkoDiwan, AmerBridges, Patrick G...|$|R
40|$|Nowadays many-core {{computing}} platforms {{are widely}} adopted {{as a viable}} solution to accelerate compute-intensive workloads at different scales, from low-cost devices to HPC nodes. It is well established that heterogeneous platforms including a general-purpose host processor and a parallel programmable accelerator {{have the potential to}} dramatically increase the peak performance/Watt of computing architectures. However the adoption of these platforms further complicates application development, whereas it is widely acknowledged that software development is a critical activity for the platform design. The introduction of parallel architectures raises the need for programming paradigms capable of effectively leveraging an increasing number of processors, from two to thousands. In this scenario the study of optimization techniques to program parallel accelerators is paramount for two main objectives: first, improving performance and energy efficiency of the platform, which are key metrics for both embedded and HPC systems; second, enforcing software engineering practices with the aim to <b>guarantee</b> <b>code</b> quality and reduce software costs. This thesis presents a set of techniques that have been studied and designed to achieve these objectives overcoming the current state-of-the-art. As a first contribution, we discuss the use of OpenMP tasking as a general-purpose programming model to support the execution of diverse workloads, and we introduce a set of runtime-level techniques to support fine-grain tasks on high-end many-core accelerators (devices with a power consumption greater than 10 W). Then we focus our attention on embedded computer vision (CV), with the aim to show how to achieve best performance by exploiting the characteristics of a specific application domain. To further reduce the power consumption of parallel accelerators beyond the current technological limits, we describe an approach based on the principles of approximate computing, which implies modification to the program semantics and proper hardware support at the architectural level...|$|R
30|$|Broadcasting {{nature of}} {{wireless}} communications {{makes it possible}} to apply opportunistic network coding (OPNC) by overhearing transmitted packets from a source to sink nodes. However, it is difficult to apply network coding to the topology of multiple relay and sink nodes. We propose to use relay node selection, which finds a proper node for network coding since the OPNC alone in the topology of multiple relays and sink nodes cannot <b>guarantee</b> network <b>coding</b> gain. The proposed system is a novel combination of wireless network coding and relay selection. In this paper, with the consideration of channel state and potential network coding gain, we propose several relay node selection techniques that have performance gain over the conventional OPNC and the conventional channel-based selection algorithm in terms of average system throughput.|$|R
40|$|We {{propose a}} {{security}} model for open multi-agent systems. Given a user-defined task T, we generate {{a group of}} mobile agents which realise a common functionality that solves T. Those agents cooperate {{with each other and}} build an autonomous community. Using a scheme for secure distributed computations, this community is able to perform secure computations without requiring interaction with a trusted party. To get some formal security guarantees we incorporate Canetti's model for secure multi-party computations (see [6]) into the agent setting. Canetti's model assumes stationary parties and so does not cover the agents' migration process. But we will present a solution to this. Thus, we yield <b>guarantees</b> for <b>code,</b> data and execution integrity, data privacy and prevention from malicious routing. Key Words: Distributed Computations, Security Model, MultiAgent Systems 1...|$|R
40|$|Software {{testing is}} a very time {{consuming}} process of software development life cycle. The software tester has to think a lot before he generates any test cases. Even after generating the test cases {{there is no proof}} that those test cases can actually uncover all the bugs and there is no <b>guarantee</b> of <b>code</b> coverage. The cost of bug also increases drastically as the software is being developed. Hence this paper tries to reduce the stress of testers as well as reduce the cost of bugs by early detection of bugs by implementing mutation testing strategy with new mutation operators introduces in this paper. This will evaluate the quality of test cases and the tester can modify his test cases based on the mutation score generated in order to improve his test cases...|$|R
50|$|The {{temporary}} reassignment {{of country}} code cs (Serbia and Montenegro) until its split into rs and me (Serbia and Montenegro, respectively) {{led to some}} controversies about the stability of ISO 3166-1 country codes, resulting in a second edition of ISO 3166-1 in 2007 with a <b>guarantee</b> that retired <b>codes</b> will not be reassigned for at least 50 years, and the replacement of RFC 3066 by RFC 4646 for country codes used in language tags in 2006.|$|R
5000|$|In {{the field}} of data compression, Shannon-Fano coding, named after Claude Shannon and Robert Fano, is a {{technique}} for constructing a prefix code based {{on a set of}} symbols and their probabilities (estimated or measured). It is suboptimal {{in the sense that it}} does not achieve the lowest possible expected code word length like Huffman coding; however unlike Huffman <b>coding,</b> it does <b>guarantee</b> that all <b>code</b> word lengths are within one bit of their theoretical ideal [...]|$|R
40|$|Formal {{verification}} enables {{developers to}} provide {{safety and security}} <b>guarantees</b> about their <b>code.</b> A modular verification approach supports the verification of different pieces of an application in separation. VeriFast is an annotation-based verifier for C source code that implements symbolic linking to support modular verification. This report describes the process of symbolic linking and the unsoundness introduced by the C preprocessor. Moreover it contains a detailed formalization of our solution and a proof of its correctness. nrpages: 32 status: publishe...|$|R
5000|$|Winning {{positions}} in the mathematical game of Mogul: a position in Mogul is a row of 24 coins. Each turn consists of flipping from one to seven coins such that the leftmost of the flipped coins goes from head to tail. The losing positions are those with no legal move. If heads are interpreted as 1 and tails as 0 then moving to a codeword from the extended binary Golay <b>code</b> <b>guarantees</b> {{it will be possible}} to force a win.|$|R
40|$|The paper {{deal with}} a deep {{analysis}} and application of object-oriented methodologies for the design process of industrial machine controllers. The process pass thought the phases of (1) conceptual model development of the software artifacts, and (2) model code deployment for the automation system target, which is in general a Programmable Logic Controller (PLC) compliant with the international standard IEC 61131 - 3 for programming languages. The paper describes a design pattern for the software conceptual model deployment, with a particular emphasis on practical requirements enforced by PLC of different brands. In fact, IEC 61131 - 3 compliance provides a common ``look-and-feel'' for programming languages, but does not <b>guarantee</b> straightforward <b>code</b> portability between different PLC vendors. The paper has a great focus on applications and provides an example, based on a generic flow-pack machine, to better explain the proposed methodology...|$|R
40|$|In {{this paper}} {{we deal with}} k-arch graphs, a {{superclass}} of trees and k-trees. We give a recursive function {{counting the number of}} labeled k-arch graphs. Our result relies on a generalization of the well-known Prüfer code for labeled trees. In order to <b>guarantee</b> the generalized <b>code</b> to be a bijection, we characterize the valid code strings. A previous attempt at counting the number of labeled k-arch graphs was made by Lamathe. We point out an error in his work, and prove it by giving a counterexample...|$|R
40|$|This paper {{studies the}} problem of {{register}} allocation and scheduling for Dual-LoadExecute (DLE) architectures. These are architectures which can execute an ALU instruction and two memory transfer operations (load/store) in a single instruction cycle. DLE architectures are extensively used {{in the design of}} Digital Signal Processors (DSPs) like the Motorola 56000, Analog Devices ADSP- 2100, and NEC ¯PD 77016. This work proves the existence of an efficient O(n) expression tree code generation algorithm for DLE architectures which have homogeneous register sets. The algorithm is an extension of the Sethi-Ullman algorithm, and produces <b>guaranteed</b> optimal <b>code</b> for a large number of expression trees in the program. The experimental results, using the NEC ¯PD 77016 as the target processor, show the efficacy of the approach. 1 Introduction Digital Signal Processors (DSPs) are receiving increased attention recently due to their role in the design of modern embedded systems like video cards, ce [...] ...|$|R
30|$|Our {{previous}} proposal [6] {{introduced the}} spreading slotted Aloha {{to replace the}} conventional slotted Aloha random access scheme. Unlike the conventional slotted Aloha scheme, the spreading slotted Aloha does not assume that the (partial or full) collision occurs between two or more packets (coming from different orientation nodes) will destroy these packets. This is because these packets is spreaded with a unique pseudorandom code signature assigned to the users owning these packets. The uniqueness of these <b>codes</b> <b>guarantee</b> that only overlapped packets which spreaded with the same code will be destroyed.|$|R
