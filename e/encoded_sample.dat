1|170|Public
40|$|In a {{previous}} published work, the lowest entropy for lossless encoding {{of the standard}} image "Lena" {{is found to be}} 5. 311 bpp [3]. In this paper, we design an optimal filter using the Hybrid method approach that will give lower entropy of 4. 198 bpp for the same image and with saving in computation complexity and <b>encoded</b> <b>sample</b> of 32 % and 20 %, respectively than that in [3]. © 2003 IEEE. The Institute of Electrical and Electronics Engineers (IEEE), IEEE Circuits and Systems Society (CAS), University of Sharjah (UOS), Etisalat College of Engineering (ECE), Emirates Telecommunications Corporation (ETISALAT...|$|E
40|$|Ten <b>encoded</b> grape <b>samples</b> from 2006 {{were taken}} from a {{long-term}} field trial on the comparison of different organic and conventional production systems at Geisenheim, Germany. The samples were examined with the picture forming methods biocrystallization according to Pfeiffer, capillary dynamolysis according to Wala and circular chromatography according to Pfeiffer. The pictures of the <b>encoded</b> <b>samples</b> were i. differentiated and ii characterised. Two <b>encoded</b> <b>samples</b> {{of each of the}} five production methods ‘conventional’, ‘bio-organic’, ‘bio-dynamic without horn silica’,‘bio-dynamic with three horn silica applications’ and ‘bio-dynamic with four horn silica applications’ were clearly differentiated with highest accuracy, i. e. 100...|$|R
50|$|In addition, some {{wideband}} codecs may use {{a higher}} audio bit depth of 16-bits to <b>encode</b> <b>samples,</b> also resulting {{in much better}} voice quality.|$|R
50|$|As {{there is}} no header, {{compatible}} audio players require information from the user that would normally be stored in a header, such as the <b>encoding,</b> <b>sample</b> rate, number of bits used per sample, {{and the number of}} channels.|$|R
30|$|Then, {{the buffer}} is shifted. Two rows leave the buffer and two new ones enter into it, keeping the last {{previous}} row, as {{in case of}} columns. All the above operations continue until all the input <b>encoded</b> <b>samples</b> are decoded.|$|R
40|$|An {{audio decoder}} decodes a bit stream of encoded audio data, wherein the bit stream of encoded audio data {{represents}} {{a sequence of}} audio sample values and comprises a plurality of frames, wherein each frame includes associated <b>encoded</b> audio <b>sample</b> values. The audio decoder comprises a determiner configured {{to determine whether a}} frame of the encoded audio data is a special frame comprising <b>encoded</b> audio <b>sample</b> values associated with the special frame and additional information, wherein the additional information comprise <b>encoded</b> audio <b>sample</b> values of a number of frames preceding the special frame, wherein the <b>encoded</b> audio <b>sample</b> values of the preceding frames are encoded using the same codec configuration as the special frame, wherein the number of preceding frames is sufficient to initialize the decoder {{to be in a position}} to decode the audio sample values associated with the special frame if the special frame is the first frame upon start-up of the decoder. The decoder comprises an initializer configured to initialize the decoder, wherein initializing the decoder comprises decoding the <b>encoded</b> audio <b>sample</b> values included in the additional information before decoding the <b>encoded</b> audio <b>sample</b> values associated with the special frame...|$|R
30|$|In each cycle, {{two columns}} of <b>encoded</b> <b>samples</b> leave the decoder and another two enter into it, keeping the last {{previous}} column, considering that it contains the necessary PCM samples to decode {{the next set}} of 4 pixels. This process is carried out iteratively until all samples of the three rows from the buffer have been decoded.|$|R
40|$|An {{audio encoder}} (100) for <b>encoding</b> audio <b>samples,</b> {{comprising}} a first time domain aliasing introducing encoder (110) for <b>encoding</b> audio <b>samples</b> {{in a first}} encoding domain, the first time domain aliasing introducing encoder (110) having a first framing rule, a start window and a stop window. The audio encoder (100) further comprises a second encoder (120) for <b>encoding</b> <b>samples</b> in a second encoding domain, the second encoder (120) having a different second framing rule.; The audio encoder (100) further comprises a controller (130) switching from the first encoder (110) to the second encoder (120) in response to characteristic of the audio samples, and for modifying the second framing rule in response to switching from the first encoder (110) to the second encoder (120) or for modifying the start window or the stop window of the first encoder (110), wherein the second framing rule remains unmodified...|$|R
40|$|Ten <b>encoded</b> rocket <b>samples</b> from 2009 {{were taken}} from a field trial on the {{comparison}} of nitrogen supply and different organic and conventional production systems at Hennef, Germany. The samples were examined with the image forming methods biocrystallization according to Pfeiffer, capillary dynamolysis according to Wala and circular chromatography according to Pfeiffer. The images of the <b>encoded</b> <b>samples</b> were a) characterised and b) assigned to experimental factors. The factors investigated were i) nitrogen supply, ii) fertilizer type, and iii) horn silica application. The ten samples were assigned 100 % correctly to low and high N supply, to mineral fertilization and manure fertilization and to with or without horn silica application...|$|R
5000|$|... // <b>Encode</b> <b>samples</b> into pulse-density {{modulation}} // using a first-order sigma-delta modulator [...] function pdm(real0..s x, real qe = 0) // initial running {{error is}} zero var int0..s y [...] for n from 0 to s if xn >= qe yn := 1 else yn := -1 qe := yn - xn + qe [...] return y, qe // return output and running error ...|$|R
5000|$|DataFormat: format used to <b>encode</b> the <b>sampled</b> data - {{examples}} include Offset Binary and Binary Coded Decimal ...|$|R
40|$|Abstract—Predictive {{quantization}} is {{a simple}} and effective method for encoding slowly-varying signals that is widely used in speech and audio coding. It has been known qualitatively that leaving correlation in the <b>encoded</b> <b>samples</b> can lead to improved estimation at the decoder when <b>encoded</b> <b>samples</b> are subject to erasure. However, performance estimation in this case has required Monte Carlo simulation. Provided here is a novel method for efficiently computing the mean-squared error performance of a predictive quantization system with erasures via a convex optimization with linear matrix inequality constraints. The method is based on jump linear system modeling and applies to any autoregressive moving average (ARMA) signal source and any erasure channel described by an aperiodic and irreducible Markov chain. In addition to this quantification for a given encoder filter, a method is presented to design the encoder filter to minimize the reconstruction error. Optimization of the encoder filter is a nonconvex problem, but {{we are able to}} parameterize with a single scalar a set of encoder filters that yield low MSE. The design method reduces the prediction gain in the filter, leaving the redundancy in the signal for robustness. This illuminates the basic tradeoff between compression and robustness. Index Terms—Differential pulse code modulation, erasure channels, joint source-channel coding, linear matrix inequalities. I...|$|R
5000|$|... #Subtitle level 2: Multiple sub-nyquist <b>sampling</b> <b>Encoding</b> system (MUSE) ...|$|R
5000|$|Multiple sub-Nyquist <b>sampling</b> <b>encoding</b> (MUSE), {{an early}} high-definition video system ...|$|R
30|$|In such a way, {{samples in}} the first half of the track will show traces of double <b>encoding,</b> while <b>samples</b> in the second half will not, due to the induced {{misalignment}} of the quantization pattern.|$|R
5000|$|... low bitrate <b>encoding</b> with halved <b>sampling</b> rate (MPEG-1 Layer 1/2/3 LSF - [...] "Low Sampling Frequencies") ...|$|R
5000|$|Fourth {{generation}} NVENC implements HEVC Main10 10-bit hardware encoding. It also doubles the encoding {{performance of}} 4K H.264 & HEVC {{when compared to}} previous generation NVENC. It supports HEVC 8K, 4:4:4 chroma subsampling, lossless <b>encoding,</b> and <b>sample</b> adaptive offset (SAO).|$|R
40|$|International audienceThe {{concept of}} {{citation}} implies a decontextualization and an incorporation, with {{different degrees of}} accuracy and expliciteness. In a practical perspective, representing this incorporation with markup means aligning or combining the logics of two texts. It also requires to take {{pay special attention to}} the explicitness of the encoding and the disambiguisation of implicit information, to permit for example comparative extractions for intertextuality studies. A great deal of flexibility and a global view of what’s available in the encoding scheme is thus needed. The talk will give a synthetic view of the main mechanisms offered by TEI guidelines. The examples used will be taken from <b>encoding</b> <b>samples</b> realized {{in the context of the}} Biblindex project...|$|R
40|$|Quantitative protein {{profiling}} is {{an essential}} part of pro-teomics and requires new technologies that accurately, reproducibly, and comprehensively identify and quantify the proteins contained in biological samples. We describe a new strategy for quantitative protein profiling that is based on the separation of proteins labeled with isotope-coded affinity tag reagents by two-dimensional gel elec-trophoresis and their identification and quantification by mass spectrometry. The method is based on the obser-vation that proteins labeled with isotopically different iso-tope-coded affinity tag reagents precisely co-migrate during two-dimensional gel electrophoresis and that therefore two or more isotopically <b>encoded</b> <b>samples</b> can be separated concurrently in the same gel. By analyzing changes in the proteome of yeast (Saccharomyces cer...|$|R
40|$|Low delay speech coding at 16 kbits/sec has {{received}} {{a tremendous amount of}} attention. One recently proposed scheme that offers excellent performance with buffering delays less than 5 msec is Trellis Coded Quantization (TCQ). The primary objective of this thesis is to evaluate the performance of TCQ in the presence of channel errors. When feedback-free encoding circuits are employed, error propagation is not a serious problem. For <b>encoding</b> <b>sampled</b> speech, segmental signal-to-noise ratios in excess of 20 dB are obtained. Performance comparisons are made using a fixed predictor and four different adaptive predictors for both error-free and noisy channels. Informal listening tests reveal that the reconstructed speech is of "near toll quality" and is almost indistinguishable from the original speech...|$|R
40|$|Abstract. This work {{presents}} {{a method for}} multiresolution mesh extraction with important mathematical properties. The generated mesh re{{presents a}} regular surface from 3 D Euclidian space. The input surface may be specified either implicitly or directly as a volumetric object. The method applies simplification operations to obtain a low resolution initial mesh and applies refinement operations to obtain a multiresolution representation from initial mesh. These combined operations provide nice properties to the mesh. In several areas like medical visualization, geosciences and others, mesh extraction is crucial for many applications. In these areas, initial data may be represented as a volume data that <b>encodes</b> <b>samples</b> of a function over a grid. Each function value defines an iso-surface inside the volume tha...|$|R
40|$|Abstract. In {{view of the}} {{backward}} {{situation in}} technology of the prepayment intelligent water-meter. The paper presents the new method of water-meter word wheel’s numeral recognition and the design of intelligent water-meter based on TM card and its management system. TM-card technology is introduced into prepayment intelligent water-meter, the structure of hardware and realization of software in the control system of Intelligent TM-card water-meter is given, including introducing the method of <b>encoding</b> <b>sampling</b> and recognition, and the circuit design of every part, and the design of embedded software. The realization of charge management system is detailed introduced. The prototypical experiment and the actual application indicates that the intelligent water-meter system based on TM card has some advantage of perfect function, exact measurement and reliable communication. 1...|$|R
5000|$|... low bitrate <b>encoding</b> with halved <b>sampling</b> rate (MPEG-1 Layer 1/2/3 LSF - a.k.a. MPEG-2 LSF - [...] "Low Sampling Frequencies") ...|$|R
40|$|Compressed sensing (CS) aims to {{reconstruct}} signals and images from significantly fewer measurements than were traditionally thought necessary. Magnetic resonance imaging (MRI) {{is an essential}} medical imaging tool with an inherently slow data acquisition process. Applying CS to MRI offers potentially significant scan time reductions, with benefits for patients and health care economics. MRI obeys two key requirements for successful application of CS: 1) medical imagery is naturally compressible by sparse coding in an appropriate transform domain (e. g., by wavelet transform), and 2) MRI scanners naturally acquire <b>encoded</b> <b>samples,</b> rather than direct pixel samples (e. g., in spatial-frequency encoding). In this article we review the requirements for successful CS, describe their natural fit to MRI, and then give examples of four interesting applications of CS in MRI. We emphasiz...|$|R
40|$|The Electrocardiogram {{signals are}} a very {{valuable}} source of data for physicians in diagnosing heart abnormalities. In this paper, we present an efficient technique for compression of electrocardiogram (ECG) signals. A new thresholding method based on the three level of quantization is proposed for <b>encoding</b> <b>samples</b> using an Embedded Zero-tree Wavelet (EZW) and Huffman algorithms. The modified encoding algorithm allows an optimal data compression for a target bit rate and appeared superior to other wavelet-based ECG coders. Also, to improve {{the efficiency of the}} proposed method we propose to use different types of wavelet and compare their performances for compression of the ECG signals. Experimental results show that the proposed method has a good performance and less complexity for compression of ECG database from MIT-BIH database different types of wavelet transform...|$|R
50|$|In the 1990s, Pioneer {{and others}} {{produced}} {{a small number}} of a high-definition video player models, which employed multiple sub-Nyquist <b>sampling</b> <b>encoding</b> (MUSE) technology.|$|R
40|$|By {{combined}} {{application of}} the three picture forming methods biocrystallization ac-cording to Pfeiffer, capillary dynamolisis according to Wala and circular chromatogra-phy according to Pfeiffer <b>encoded</b> food <b>samples</b> from different production systems have been repeatedly differentiated and identified by Dr. Ursula Graf. In the present study we tested whether by using the combined three picture forming methods en-coded food samples from different production systems could also be differentiated and identified in a different laboratory by another trained person. Ten <b>encoded</b> wheat <b>samples</b> each from 2000 and 2005 harvests {{were taken from the}} long-term DOK- trial in Oberwil/Switzerland and examined with the pictomorphological methods. The wheat samples derived from the production systems ‘bio-dynamic’, ‘bio-organic’, ‘unfertil-ized’, ‘mineral fertilization’ and ‘conventional’ (mineral fertilization combined with ma-nure application) could be differentiated and identified, with partial differentiation and identification of the two production systems ‘bio-dynamic’ and ‘bio-organic’...|$|R
40|$|A novel {{scheme for}} perceptual coding of audio for robust and {{real-time}} communication is designed and analyzed. As {{an alternative to}} PCM, DPCM, and more general noise-shaping converters, we propose to use psychoacoustically optimized noise-shaping quantizers based on the moving-horizon principle. In moving-horizon quantization, a few samples look-ahead is allowed at the encoder, which {{makes it possible to}} better shape the quantization noise and thereby reduce the resulting distortion over what is possible with conventional noise-shaping techniques. It is first shown that significant gains over linear PCM can be obtained without introducing a delay and without requiring postprocessing at the decoder, i. e., the <b>encoded</b> <b>samples</b> can be stored as, e. g., 16 -bit linear PCM on CD-ROMs, and played out on standards-compliant CD players. We then show that multiple-description coding can be combined with moving-horizon quantization in order to combat possible erasures on the wireless link without introducing additional delays...|$|R
40|$|We {{describe}} {{the development of}} a formal language for expressing qualitative spatial knowledge. The language is intended as a practical tool for knowledge representation and has been designed with the particular aim of encoding the qualitative spatial information found in an introductory college level biology textbook. We have taken a corpus-driven approach in which we first identify the requirements by analysing the sentences in the book, design the vocabulary, and then check its adequacy by applying it to model the sentences containing spatial knowledge. Our technical solution extends the well-known Region Connection Calculus with predicates for referring to surfaces, cavities and different forms of containment. We illustrate the application of this vocabulary in <b>encoding</b> <b>sample</b> sentences from the book, and give empirical results regarding the correspondence between the defined relations of our formal theory and the actual usage of vocabulary pertaining to ‘surrounding’, ‘enclosure’ and ‘containment’ in the textbook...|$|R
40|$|Magnetic {{resonance}} imaging systems {{are sensitive to}} heating: hot spots {{can lead to a}} degradation of the image quality and system failure. Gradient coils are required to produce highly uniform and fast switching magnetic fields in order to spatially <b>encode</b> <b>samples</b> within a volume. When optimizing for heating and power loss there is a tradeoff for ideal magnetic performance. This paper investigates an automatic design procedure for gradient coil cooling systems which allows a strict relation between gradient coil design, performed through different criteria power and energy oriented, and its optimal cooling layout. Power and energy optimized split gradient coils are both cooled using an optimized layout based on a Dijkstra 2 ̆ 7 s algorithm approach. Both systems see a large reduction in temperature values allowing the magnetically optimized coil to be used despite its increased power loss. This method can help ensure gradient coils can be optimized primarily for magnetic performance while keeping excess heating under control...|$|R
40|$|Abstract—A novel {{scheme for}} perceptual coding of audio for robust and {{real-time}} communication is designed and analyzed. As {{an alternative to}} PCM, DPCM, and more general noise-shaping converters, we propose to use psychoacoustically op-timized noise-shaping quantizers based on the moving-horizon principle. In moving-horizon quantization, a few samples look-ahead is allowed at the encoder, which {{makes it possible to}} better shape the quantization noise and thereby reduce the resulting distortion over what is possible with conventional noise-shaping techniques. It is first shown that significant gains over linear PCM can be obtained without introducing a delay and without requiring post-processing at the decoder, i. e., the <b>encoded</b> <b>samples</b> can be stored as e. g., 16 -bit linear PCM on CD-ROMs, and played out on standards-compliant CD players. We then show that multiple-description coding can be combined with moving-horizon quantization in order to combat possible erasures on the wireless link without introducing additional delays. Index Terms—Low delay source coding, multiple-description coding, moving horizon quantization, perceptual audio coding I...|$|R
40|$|This letter {{reports the}} {{production}} and optical polarimetric verification of codes based on thin-film technology for security applications. Because thin-film structures display distinctive polarization signatures, this data is used to authenticate the message <b>encoded.</b> <b>Samples</b> are analyzed using an imaging ellipsometer able to measure the 16 components of the Mueller matrix. As a result, {{the behavior of the}} thin-film under polarized light becomes completely characterized. This information is utilized to distinguish among true and false codes by means of correlation. Without the imaging optics the components of the Mueller matrix become noise-like distributions and, consequently, the message encoded is no longer available. Then, a set of Stokes vectors are generated numerically for any polarization state of the illuminating beam and thus, machine learning techniques can be used to perform classification. We show that successful authentication is possible using the knearest neighbors algorithm in thin-films codes that have been anisotropically phase-encoded with pseudorandom phase code...|$|R
5000|$|The {{main steps}} of {{lossless}} operation mode are depicted in Fig.2. In the process, the predictor combines {{up to three}} neighboring samples at A, B, and C shown in Fig.3 {{in order to produce}} a prediction of the sample value at the position labeled by X. The three neighboring samples must be already <b>encoded</b> <b>samples.</b> Any one of the predictors shown in the table below can be used to estimate the sample located at X. Any one of the eight predictors listed in the table can be used. Note that selections 1, 2, and 3 are one-dimensional predictors and selections 4, 5, 6, and 7 are two-dimensional predictors. The first selection value in the table, zero, is only used for differential coding in the hierarchical mode of operation.Once all the samples are predicted, the differences between the samples can be obtained and entropy-coded in a lossless fashion using Huffman coding or arithmetic coding.|$|R
50|$|A truetone or realtone is a ringtone {{which has}} been <b>encoded</b> with a <b>sampled</b> audio format such as MP3, AAC, or WMA. It is also {{referred}} to as a mastertone.|$|R
50|$|The {{container}} is {{a modified}} version of AVI. The video format is a variant of Motion JPEG, with fixed rather than variable quantisation tables. The audio format is a variant of IMA ADPCM, where the first 8 bytes of each frame are origin (16 bits), index (16 bits) and number of <b>encoded</b> 16-bit <b>samples</b> (32 bits); all known AMV files run sound at 22050 samples/second.|$|R
40|$|A finite-State vector {{quantizer}} is a finite-state {{machine that}} {{can be viewed as}} a collection of memoryless full-searched vector quantizers, where each input vector is encoded using a vector quantizer associated with the current encoder state; the current state and codeword selected determine the next encoder state [1]. In [1], the state codebooks are unstructured. In addition, it is assumed that all the state codebooks have the same cardinality leading to a fixed-rate system. In this paper, we present two variable-rate variations of the system in [1]. In the first system we let the state codebook sizes be different for different states. In the second system along with the flexibility of having different codebook sizes for different states, we use pruned tree-structured vector quantizers [2] as the state quantizers. For <b>encoding</b> <b>samples</b> speech data, both of these schemes perform significantly better than the scheme in [1]. The second system gives the best performance of all. Performance improvements of up to 4. 25 dB at the rate of 5 / 8 bits per sample are obtained...|$|R
