1300|111|Public
50|$|This {{problem is}} {{analogous}} to <b>deblurring</b> in the image processing domain.|$|E
5000|$|... image {{denoising}} and <b>deblurring</b> with [...] and [...] with [...] {{a motion}} blur or Gaussian blur, ...|$|E
5000|$|Best Student Paper: Discriminative Non-blind <b>Deblurring,</b> Uwe Schmidt, Carsten Rother, Sebastian Nowozin, Jeremy Jancsary, and Stefan Roth ...|$|E
30|$|Separated BI-RL {{with these}} {{overlapped}} rectangular blocks produces 256 <b>deblurred</b> block images and combines 256 <b>deblurred</b> block images of size 30 × 30, after cutting out required amount of rows and columns from 256 <b>deblurred</b> block images, {{to the final}} image (Fig. 17 a). Figure 17 b {{can be obtained by}} a similar procedure.|$|R
5000|$|... #Caption: From left: Original image, blurred image, image <b>deblurred</b> using Wiener deconvolution.|$|R
40|$|In this paper, we give a {{framework}} to <b>deblur</b> the blurry frame {{in a video}} clip. Two kinds of motion blurring effects can be removed in the video, one is the blurring effect caused by hand shaking, {{the other is the}} blurring effect caused by a fast moving object. For the blurring caused by hand shaking, PSF is estimated by comparing the stable area in blurry frame and non-blurry frame, so the Richardson-Lucy algorithm can restore the blurry frame by non-blind deconvolution. We also propose {{a framework}} to <b>deblur</b> the motion blurring objects which move fast in the video. The background is reconstructed by the algorithm in each frame, so an accurate matte of blurry object can be extracted to <b>deblur</b> the moving object by alpha matting. Results show our method is effective...|$|R
50|$|This is {{controlling}} photographic illumination in {{a structured}} fashion, then processing the captured images,to create new images. The applications include image-based relighting, image enhancement, image <b>deblurring,</b> geometry/material recovery and so forth.|$|E
50|$|In {{order to}} {{identify}} {{the size of the}} blur (needed to decode depth information) in the captured image, two approaches can be used: 1) <b>deblurring</b> the captured image with different blurs, or 2) learning some linear filters that identify the type of blur.|$|E
50|$|This is {{capture of}} {{optically}} coded images, followed by computational decoding to produce new images.Coded aperture imaging was mainly applied in astronomy or X-ray imaging {{to boost the}} image quality. Instead of a single pin-hole, a pinhole pattern is applied in imaging, and deconvolution is performed to recover the image. In coded exposure imaging, the on/off state of the shutter is coded to modify the kernel of motion blur. In this way motion <b>deblurring</b> becomes a well-conditioned problem. Similarly, in a lens based coded aperture, the aperture can be modified by inserting a broadband mask. Thus, out of focus <b>deblurring</b> becomes a well-conditioned problem. The coded aperture can also improve the quality in light field acquisition using Hadamard transform optics.|$|E
40|$|Guiding gaze using near-peripheral vision {{improves}} gaze-contingent-display efficiency {{by reducing}} display response latency. We propose {{a new approach}} for controlling exploration of static displays through near-peripheral stimuli, and report results of an evaluation of its effectiveness. 10 participants viewed full screen displays of 60 blurred pictures (Gaussian filtering). As soon as a fixation (first strategy) or a gaze sample (second strategy) was detected next to the current stimulus, the area surrounding it was <b>deblurred.</b> An image was totally <b>deblurred</b> when all stimuli had thus attracted the user's gaze. Stimuli are blinking <b>deblurred</b> circles (radius: 1 deg visual angle). They appear in predefined positions on the screen, one at a time. For each picture, successive stimulus positions on the screen reproduce observed gaze patterns. The current stimulus is visible only if the visual angle between its position {{on the screen and}} the position of the user's current fixation is superior to 8 deg (to avoid users noticing it) and inferior to 14 deg. (near-periphery upper limit). Eye movements are detected through an ASL-H 6 eye-tracker (120 Hz). Stimulus saliency is estimated, for each picture and stimulus, from contrast ratio and sum of squared differences between blurred and <b>deblurred</b> area around the stimulus...|$|R
40|$|International audienceVideo {{camera is}} now {{commonly}} used and demand of capturing a single frame from video sequence is increasing. Since resolution of video camera is usually lower than digital camera and video data usually contains a many motion blur in the sequence, simple frame capture can produce only low quality image; image restoration technique is inevitably required. In this paper, we propose {{a method to}} restore a sharp and high-resolution image from a video sequence by motion <b>deblur</b> for each frame followed by super-resolution technique. Since the frame-rate of the video camera is high and variance of feature appearance in successive frames and motion of feature points are usually small, we can still estimate scene geometries from video data with blur. Therefore, by using such geometric information, we first apply motion <b>deblur</b> for each frame, and then, super-resolve the images from the <b>deblurred</b> image set. For better result, we also propose an adaptive super-resolution technique considering different defocus blur effects dependent on depth. Experimental results are shown to prove {{the strength of our}} method...|$|R
40|$|A countless {{number of}} {{photographs}} are taken every day, and in-evitably {{many of those}} suffer from some sort of blurring. A program that {{would be able to}} take a blurred image and restore the photograph back to its original, <b>deblurred</b> form would be invaluable. Anyone from law enforcement trying to read a blurred license plate on a getaway car to a family attempting to refine their grandfather?s smile would find such a piece of software useful. In my implementation I attempt to <b>deblur</b> images suffering from simple types of motion blur using the alternate domains granted by the use of Fourier transformations and a basic understanding of image deconvolution...|$|R
50|$|By {{imposing}} a signal domain constraint of finite extent support and positivity over the finite region of support, the constrained iterative deconvolution solution can be guaranteed to converge. Such a signal domain constraint can be realistically imposed for {{many cases of}} practical use. For example, {{in the case of}} image <b>deblurring,</b> the blur kernel can be assumed to have a positive impulse response over a finite region of support.|$|E
50|$|Spectral regularization is {{any of a}} {{class of}} regularization {{techniques}} used in machine learning to control the impact of noise and prevent overfitting. Spectral regularization {{can be used in}} a broad range of applications, from <b>deblurring</b> images to classifying emails into a spam folder and a non-spam folder. For instance, in the email classification example, spectral regularization can be used to reduce the impact of noise and prevent overfitting when a machine learning system is being trained on a labeled set of emails to learn how to tell a spam and a non-spam email apart.|$|E
50|$|The {{objective}} of image restoration techniques {{is to reduce}} noise and recover resolution loss. Image processing techniques are performed either in the image domain or the frequency domain. The most straightforward and a conventional technique for image restoration is deconvolution, which is performed in the frequency domain and after computing the Fourier transform of both the image and the PSF and undo the resolution loss caused by the blurring factors. This deconvolution technique, because of its direct inversion of the PSF which typically has poor matrix condition number, amplifies noise and creates an imperfect deblurred image. Also, conventionally the blurring process {{is assumed to be}} shift-invariant. Hence more sophisticated techniques, such as regularized <b>deblurring,</b> have been developed to offer robust recovery under different types of noises and blurring functions.|$|E
40|$|International audienceThe {{purpose is}} to propose an {{improved}} method for inverse boundary value problems. This method is presented on a model problem. It introduces a higher order problem. BEM numerical simulations highlight the efficiency, the improved accuracy, the robustness to noisy data of this new approach, {{as well as its}} ability to <b>deblur</b> noisy data...|$|R
40|$|AbstractGaussian blur is {{frequently}} used {{to model the}} degradation of images or signals. We will show how to clean the blurred image. We shall obtain exact formulas. To achieve this goal, we will make use of some formulas from the theory of basic hypergeometric series. We will also show how to <b>deblur</b> images blurred by a modified Gaussian blur...|$|R
30|$|Stefan Harmeling et al. [17] are {{the first}} to propose a blind {{deconvolution}} algorithm for astronomical imaging working in online mode. Instead of minimizing the total overall cost function for all blurry images, they just minimized the cost function for one image at each time and the current <b>deblurred</b> image was used as the initial estimate for the next time recursively. Thus, the <b>deblurred</b> image was refined gradually along with the image capturing. Hirsch et al. [18] extended the online blind deconvolution algorithm by incorporating super-resolution. The different information contained in different LR images results from blurring with different blur kernels. Both online blind deconvolution (OBD) and its SR extension (OBDSR) get the HR image estimate by minimizing an auxiliary function rather than minimizing the cost function directly to avoid image overfitting, while sometimes the strategy failed, especially when the noise of LR images is large.|$|R
50|$|<b>Deblurring</b> is {{the process}} of {{removing}} blurring artifacts from images, such as blur caused by defocus aberration or motion blur. The blur is typically modeled as the convolution of a (sometimes space- or time-varying) point spread function with a hypothetical sharp input image, where both the sharp input image (which is to be recovered) and the point spread function are unknown. This is an example of an inverse problem. In almost all cases, there is insufficient information in the blurred image to uniquely determine a plausible original image, making it an ill-posed problem. In addition the blurred image contains additional noise which complicates the task of determining the original image. This is generally solved by the use of a regularization term to attempt to eliminate implausible solutions. This problem is analogous to echo removal in the signal processing domain. Nevertheless, when coherent beam is used for imaging, the point spread function can be modeled mathematically. As the figure on the right illustrates, by proper deconvolution of the point spread function and the image, the resolution can be enhanced several times.|$|E
30|$|Note {{that since}} OSEM {{combines}} <b>deblurring</b> with reconstruction in a maximum-likelihood framework, its <b>deblurring</b> performance is somewhat different and {{more complicated than}} that of the simplistic 1 D <b>deblurring</b> operator discussed above [3],[4].|$|E
40|$|Blur removal is an {{important}} problem in signal and image processing. In this article, we formulate the <b>deblurring</b> problem within a wavelet framework and design a methodology to find <b>deblurring</b> filters. Using these <b>deblurring</b> filters, we derive an iterative <b>deblurring</b> algorithm and prove its convergence. Simulation results are reported to illustrate the proposed framework and methodology. © 2004 Wiley Periodicals, Inc. link_to_subscribed_fulltex...|$|E
40|$|Abstract This paper {{presents}} a novel Coprime Blurred Pair (CBP) model for visual data-hiding for security in camera surveillance. While most previous approaches {{have focused on}} completely encrypting the video stream, we introduce a spatial encryption scheme by blurring the image/video contents to create a CBP. Our goal is to obscure detail in public video streams by blur-ring while allowing behavior to be recognized and to quickly <b>deblur</b> the stream so that details are available if behavior is recognized as suspicious. We create a CBP by blurring the same latent image with two unknown kernels. The two kernels are coprime when mapped to bivariate polynomials in the z domain. To <b>deblur</b> the CBP we first use the coprime constraint to approximate the kernels and sample the bivariate CBP polynomials in one dimension on the unit circle. At each sample point, we factor the 1 D polynomial pair and compose the results into a 2 D kernel matrix. Finally, we compute the inverse Fast Fourier Transform (FFT) of the kernel matrices to recover the coprime kernels and then the la-tent video stream. It is therefore only possible to <b>deblur</b> the video stream if a user has access to both streams. To improve the practicability of our algorithm, we im-plement our algorithm using a graphics processing unit (GPU) to decrypt the blurred video streams in real-time, and extensive experimental results demonstrate that our new scheme can effectively protect sensitiv...|$|R
40|$|Abstract We {{propose a}} method for {{reducing}} out-of-focus blur caused by projector projection. We estimate the Point-Spread-Function (PSF) in the image projected onto the screen by using a camera that captures the projector screen. According to the estimated PSF, the original image is pre-corrected, so that the projected image can be <b>deblurred.</b> Experimental results show proposed method can reduce out-of-focus projection blur...|$|R
40|$|With controlled-source seismic {{interferometry}} {{we aim to}} redatum {{sources to}} downhole receiver locations without requiring a velocity model. Interferometry is generally based on a source integral over cross-correlation (CC) pairs of full, perturbed (time-gated), or decomposed wavefields. We {{provide an overview of}} ghosts, multiples, and spatial blurring effects that can occur for different types of interferometry. We show that replacing cross-correlation by multidimensional deconvolution (MDD) can deghost, demultiple, and <b>deblur</b> retrieved data. We derive and analyze MDD for perturbed and decomposed wavefields. An interferometric point spread function (PSF) is introduced that can be obtained directly from downhole data. Ghosts, multiples, and blurring effects that may populate the retrieved gathers can be locally diagnosed with the PSF. MDD of perturbed fields can remove ghosts and <b>deblur</b> retrieved data, but it leaves particular multiples in place. To remove all overburden-related effects, MDD of decomposed fields should be applied. Applied Geophysics and PetrophysicsCivil Engineering and Geoscience...|$|R
40|$|We {{propose a}} sparse {{representation}} based blind image <b>deblurring</b> method. The proposed method exploits the sparsity property of natural images, by {{assuming that the}} patches from the natural images can be sparsely represented by an over-complete dictionary. By incorporating this prior into the <b>deblurring</b> process, we can effectively regularize the illposed inverse problem and alleviate the undesirable ring effect which is usually suffered by conventional <b>deblurring</b> methods. Experimental results compared with state-of-theart blind <b>deblurring</b> method demonstrate {{the effectiveness of the}} proposed method. Index Terms — blind image <b>deblurring,</b> deconvolution, sparse representation 1...|$|E
40|$|Abstract — In {{recent years}} sparse {{representation}} model (SRM) based image <b>deblurring</b> approaches have shown promising image <b>deblurring</b> results. However, {{since most of}} the current SRMs don’t utilize the spatial correlations between the nonzero sparse coefficients, the SRM-based image <b>deblurring</b> methods often fail to faithfully recover sharp image edges. In this paper, a structured SRM is employed to exploit the local and nonlocal spatial correlation between the sparse codes. The connection between the structured SRM and the low-rank approximation model has also been exploited. An effective image <b>deblurring</b> algorithm using the patch-based structured SRM is then proposed. Experimental results demonstrate the improvements of the proposed <b>deblurring</b> method over current state-of-the-art image <b>deblurring</b> methods. I...|$|E
40|$|Abstract—Although spatial <b>deblurring</b> is {{relatively}} well understood by {{assuming that the}} blur kernel is shift invariant, motion blur is not so when we attempt to deconvolve on a frame-by-frame basis: this is because, in general, videos include complex, multilayer transitions. Indeed, we face an exceedingly difficult problem in motion <b>deblurring</b> of a single frame when the scene contains motion occlusions. Instead of <b>deblurring</b> video frames individually, a fully 3 -D <b>deblurring</b> method is proposed in this paper to reduce motion blur from a single motion-blurred video to produce a high-resolution video in both space and time. Unlike other existing approaches, the proposed <b>deblurring</b> kernel is free from knowledge of the local motions. Most importantly, due to its inherent locally adaptive nature, the 3 -D <b>deblurring</b> is capable of automatically <b>deblurring</b> the portions of the sequence, which are motion blurred, without segmentation and without adversely affecting {{the rest of the}} spatiotemporal domain, where such blur is not present. Our method is a two-step approach; first we upscale the input video in space and time without explicit estimates of local motions, and then perform 3 -D <b>deblurring</b> to obtain the restored sequence. Index Terms—Inverse filtering, sharpening and <b>deblurring.</b> I...|$|E
40|$|Astronomical {{images taken}} by {{ground-based}} telescopes suffer degradation due to atmospheric turbulence. This degradation can be tackled by costly hardware-based approaches such as adaptive optics, or by sophisticated software-based {{methods such as}} lucky imaging, speckle imaging, or multi-frame deconvolution. Software-based methods process a sequence of images to reconstruct a <b>deblurred</b> high-quality image. However, existing approaches are limited in one or several aspects: (i) they process all images in batch mode, which for thousands of images is prohibitive; (ii) they do not reconstruct a super-resolved image, even though an image sequence often contains enough information; (iii) {{they are unable to}} deal with saturated pixels; and (iv) they are usually non-blind, i. e., they assume the blur kernels to be known. In this paper we present a new method for multi-frame deconvolution called online blind deconvolution (OBD) that overcomes all these limitations simultaneously. Encouraging results on simulated and real astronomical images demonstrate that OBD yields <b>deblurred</b> images of comparable and often better quality than existing approaches...|$|R
40|$|Abstract: In image {{processing}} edge detection {{is an essential}} topic. We propose a new method for a simple edge detection and fast computation using fuzzy logic rule. We compare proposed edge detector to other existing edge detectors such as sobel edge detector, canny edge detector, and prewit edge detector. In addition it also <b>deblurred</b> the images efficiently and effectively. We present a new image <b>deblurred</b> method: wavelet image threshold de blurring. In these wavelet coefficients of an image that related to an image’s edges are primarily detected by wavelet edge detection. The detected wavelet coefficients will then be saving from de blurring; therefore we set a de blurring thresholds based on the blurring variances without disturbing of image edge. Proposed work can save image’s edges from noise and step up the PSNR up to 1 - 2 db. If we combine both image de blurring and edge detection of image. We {{can get rid of}} commonly used de blurred methods and also can detect image effectively &efficiently...|$|R
40|$|This paper {{presents}} a novel Coprime Blurred Pair (CBP) model for visual data-hiding for security in camera surveillance. While most previous approaches {{have focused on}} completely encrypting the video stream, we introduce a spatial encryption scheme by blurring the image/video contents to create a CBP. Our goal is to obscure detail in public video streams by blurring while allowing behavior to be recognized and to quickly <b>deblur</b> the stream so that details are available if behavior is recognized as suspicious. We create a CBP by blurring the same latent image with two unknown kernels. The two kernels are coprime when mapped to bivariate polynomials in the z domain. To <b>deblur</b> the CBP we first use the coprime constraint to approximate the kernels and sample the bivariate CBP polynomials in one dimension on the unit circle. At each sample point, we factor the 1 D polynomial pair and compose the results into a 2 D kernel matrix. Finally, we compute the inverse Fast Fourier Transform (FFT) of the kernel matrices to recover the coprime kernels and then the latent video stream. It is therefore only possible to <b>deblur</b> the video stream if a user has access to both streams. To improve the practicability of our algorithm, we implement our algorithm using a graphics processing unit (GPU) to decrypt the blurred video streams in real-time, and extensive experimental results demonstrate that our new scheme can effectively protect sensitive identity information in surveillance videos and faithfully reconstruct the unblurred video stream when two blurred sequences are available...|$|R
40|$|The goal {{of video}} <b>deblurring</b> {{is to remove}} the blurrness from blurry videos caused due to camera shake and object motion during exposure. Video <b>deblurring</b> is {{performed}} by monitoring videos spatial and temporal changes during video sequences. While most existing algorithms are able to deblur the videos well in controlled environment,they usually fail {{in the presence of}} significant variation of the object’s motion. There is still a need of better a algorithm for <b>deblurring</b> the videos in an effective manner. We propose a efficient video <b>deblurring</b> technique to handle the blurs due to shaky camera and complex motion blurs due to moving objects. A brief survey of different video <b>deblurring</b> methods available in the literature including analysis and comparative study of different techniques used for <b>deblurring</b> has been done...|$|E
40|$|Although spatial <b>deblurring</b> is {{relatively}} well-understood by {{assuming that the}} blur kernel is shiftinvariant, motion blur is not so when we attempt to deconvolve this motion blur on a frame-by-frame basis: this is because, in general, videos include complex, multi-layer transitions. Indeed, we face an exceedingly difficult problem in motion <b>deblurring</b> of a single frame when the scene contains motion occlusions. Instead of <b>deblurring</b> video frames individually, a fully 3 -D <b>deblurring</b> method is proposed in this paper to reduce motion blur from a single motion-blurred video to produce a high resolution video in both space and time. The blur kernel is free from explicit knowledge of local motions unlike other existing motion-based <b>deblurring</b> approaches. Most importantly, due to its inherent locally adaptive nature, the 3 -D <b>deblurring</b> is capable of automatically <b>deblurring</b> the portions of the sequence which are motion blurred, without segmentation, and without adversely affecting {{the rest of the}} spatiotemporal domain where such blur is not present. Our proposed approach is a two-step approach; first we upscale the input video in space and time without explicit estimates of local motions and then perform 3 -D <b>deblurring</b> to obtain the restored sequence...|$|E
30|$|This section mainly {{focuses on}} the image <b>deblurring</b> problems, which has {{received}} a lot of attention in recent years. Until now, some researchers have proposed many novel algorithms for this problem based on different <b>deblurring</b> models; for examples, see [26]. Now, by Corollary  5.2, we can consider the image <b>deblurring</b> problem.|$|E
40|$|Usually {{we assume}} that the central nervous system {{preserves}} temporal sequences. Here we show that moving objects—in the context of behaviour often dangerous ones—are seen with a shorter latency than stationary (flashed) objects. In addition moving objects are <b>deblurred.</b> Two mechanisms contribute to this functional specialisation: cue-induced visual focal attention and metacontrast. Under unnatural conditions these mechanisms lead to an optical illusion first described by Fröhlich [Fröhlich, F...|$|R
40|$|We {{address the}} problem of {{restoring}} a high-quality image from an observed image sequence strongly distorted by atmospheric turbulence. A novel algorithm is proposed in this paper to reduce geometric distortion as well as space-and-time-varying blur due to strong turbulence. By considering a suitable energy functional, our algorithm first obtains a sharp reference image and a subsampled image sequence containing sharp and mildly distorted image frames with respect to the reference image. The subsampled image sequence is then stabilized by applying the Robust Principal Component Analysis (RPCA) on the deformation fields between image frames and warping the image frames by a quasiconformal map associated with the low-rank part of the deformation matrix. After image frames are registered to the reference image, the low-rank part of them are <b>deblurred</b> via a blind deconvolution, and the <b>deblurred</b> frames are then fused with the enhanced sparse part. Experiments have been carried out on both synthetic and real turbulence-distorted video. Results demonstrate that our method is effective in alleviating distortions and blur, restoring image details and enhancing visual quality. Comment: 21 pages, 24 figure...|$|R
5000|$|Any {{blurred image}} {{can be given}} as input to blind {{deconvolution}} algorithm, it can <b>deblur</b> the image, but essential condition for working of this algorithm must not be violated as discussed above. In the first example (picture of shapes),recovered image was very fine, exactly similar to original image because L< K+N. In the second example,(picture of a girl), L> K+N , so essential condition is violated, hence recovered image is far different from original image.|$|R
