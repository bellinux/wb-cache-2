24|10000|Public
40|$|A {{system for}} {{analyzing}} {{a plurality of}} samples (202) containing a dispersion {{of one or more}} incompletely miscible components in a continuous fluid phase comprises a vial receptacle located at a first location, an <b>image</b> <b>capturing</b> <b>device</b> (102) directed at the first location, a light source (112) directed at the first location, and a programmable processor (124) operatively coupled to the <b>image</b> <b>capturing</b> <b>device</b> and configured to detect a behavior in a captured image of a sample. The programmable processor defines regions of interest in a captured image, generates an intensity profile for each region of interest, and detects the behavior based on the intensity profile. The programmable processor defines the regions of interest by detecting a sample boundary in a captured image and defining a region within the sample boundary. The programmable processor detects behavior by calculating a Laplacian or a derivative of the intensity profile for the region...|$|E
40|$|The {{objective}} of this experiment was to build a mobile structure that could take digital pictures simultaneously with live observation to record pigs’ behavior. The digital pen <b>image</b> <b>capturing</b> <b>device</b> specifications (position in pen, height and camera angle) {{were based on the}} dimensions of the nursery pens at Lauren Christian Swine Research Center at the Iowa State University Bilsland Memorial Farm, near Madrid, IA where an approachability experiment was to be conducted. The nursery pen dimensions were 1. 5 m wide by 2. 1 m length and the ceiling height was 2. 6 m. The digital pen <b>image</b> <b>capturing</b> <b>device</b> had a steel base that held a 1. 6 m tall PVC pipe and {{at the top of the}} pipe a PVC T held a tripod head that secured the digital camera. The definition of successfully capturing the nursery pen was a digital image that included four sticky notes that would be positioned in each corner of the pen. Each sticky note measured 7. 6 cm length by 7. 6 cm width. Three device positions (left, right and center back), three device heights (1. 5 m, 1. 8 m, and 2. 1 m) and a continuum of tripod head angles (ranging from 0 to 60 degrees were tested. The final specifications for the digital pen <b>image</b> <b>capturing</b> <b>device</b> was: a height of 1. 8 m, a tripod head angle of 35 degrees and a back right corner position...|$|E
40|$|The {{invention}} {{concerns a}} method and an arrangement for controlling means (24, 26), themselves controlled by processors, for three-dimensional transfer of information by motion detection using an <b>image</b> <b>capturing</b> <b>device</b> (20). Features {{of an object}} (10) are detected and transferred to line and point correspondences, which are used for controlling means (22, 26) to perform rotational and translational motion. QC 20150127 (Patent not in force) </p...|$|E
5000|$|Different {{spectral}} sensitivities of {{the human}} eye and of an <b>image</b> <b>capture</b> <b>device</b> (e.g. a camera).|$|R
50|$|The QX5 Computer Microscope is a Digital Blue {{product and}} {{upgraded}} the QX3 with multiple improvements, including a 640x480 <b>image</b> <b>capture</b> <b>device</b> and brighter light source.|$|R
50|$|The {{transilluminator}} apparatus {{may also}} contain <b>image</b> <b>capture</b> <b>devices,</b> {{such as a}} digital or polaroid camera, that allow {{an image of the}} gel to be taken or printed.|$|R
40|$|DE 102006060716 A 1 UPAB: 20080721 NOVELTY - The method {{involves}} {{introducing a}} high-contrast picture mark in a visible manner {{in a picture}} of a scene. The picture is taken by an <b>image</b> <b>capturing</b> <b>device.</b> A contrast area picture mark is selected from a circular area pattern, defined by a circular surface, which is divided into point-symmetrically formed four quadrant regions in relation to center of a circle. Two quadrants, which are identical in the visual appearance, face the center of the circle. Other two adjacent quadrants are arranged in a peripheral direction of the circle are lifted from each other in a contrasting manner. USE - Method for picture mark-supported image evaluation. ADVANTAGE - The method involves introducing a high-contrast picture mark in a visible manner in {{a picture of a}} scene, where the picture is taken by an <b>image</b> <b>capturing</b> <b>device,</b> and contrast area picture mark is selected from a circular area pattern, thus enables an automatic and interactive measurement using one type of picture mark...|$|E
40|$|In this paper, {{we present}} a no-reference blur metric for images and video. The blur metric {{is based on the}} {{analysis}} of the spread of the edges in an image. Its perceptual significance is validated through subjective experiments. The novel metric is near real-time, has low computational complexity and is shown to perform well over a range of image content. Potential applications include optimization of source coding, network resource management and autofocus of an <b>image</b> <b>capturing</b> <b>device...</b>|$|E
40|$|In {{this paper}} we present {{the design of}} an <b>image</b> <b>capturing</b> <b>device</b> for persons with aphasia. The early {{concepts}} were validated with one speech therapist and the usability of the camera was tested with one aphasic person. Our semi-autonomous hand-held camera, tapered to meet specific interaction and ergonomic needs of expressive aphasics. This camera is able to capture daily experiences by creating photographs that receives significant, automatically added tags. We present the design case study with early evaluation results by proxy users...|$|E
40|$|This paper {{describes}} {{the design and}} performance of an <b>image</b> <b>capture</b> simulator. The general model underlying the simulator assumes that the <b>image</b> <b>capture</b> <b>device</b> contains multiple classes of sensors with different spectral sensitivities and that each sensor responds in a known way to irradiance over most of its operating range. The input to the simulator {{is a set of}} narrow-band images of the scene taken with a custom-designed hyperspectral camera system. The parameters for the simulator are the number of sensor classes, the sensor spectral sensitivities, the noise statistics and number of quantization levels for each sensor class, the spatial arrangement of the sensors and the exposure duration. The output of the simulator is the raw image data that would have been acquired by the simulated <b>image</b> <b>capture</b> <b>device...</b>|$|R
40|$|This paper {{describes}} (a) {{models for}} digital cameras, (b) the calibration of the spectral response {{of a camera}} and (c) the performance of an <b>image</b> <b>capture</b> simulator. The general model underlying the simulator assumes that the <b>image</b> <b>capture</b> <b>device</b> contains multiple classes of sensors with different spectral sensitivities and that each sensor responds in a known way to light intensity over most of its operating range. The input to the simulator {{is a set of}} narrow-band images of the scene taken with a custom-designed hyperspectral camera system [1]. The parameters for the simulator are: the number of sensor classes; the sensor spectral sensitivities; the noise statistics and number of quantization levels for each sensor class; the spatial arrangement of the sensors; and the exposure duration. The output of the simulator is the raw image data that would have been acquired by the simulated <b>image</b> <b>capture</b> <b>device.</b> To test the simulator, we acquired images of the same scene both with the hyperspectral camera [1] and with a calibrated Kodak DCS- 200 digital color camera. We used the simulator to predict the DCS- 200 output from the hyperspectral data. The agreement between simulated and acquired images validated the <b>image</b> <b>capture</b> response model, the spectral calibrations, and our simulator implementation. We believe the simulator will provide a useful tool for understanding the effect of varying the design parameters of an <b>image</b> <b>capture</b> <b>device...</b>|$|R
5000|$|... iNo Mobile {{launched}} iNo ONE, the world's first non-camera smartphone in 2012, {{catering to}} {{the small group of}} people that works in sensitive environment where <b>image</b> <b>capturing</b> <b>devices</b> are strictly not allowed. The iNo Mobile was approved by the Singapore military for use in sensitive areas.|$|R
40|$|Devices {{have become}} {{increasingly}} more interconnected to their surroundings {{over the last few}} years. The introduction of Bluetooth is likely to further accelerate this trend. With Bluetooth's bandwidth and expected low price, many devices will likely be fitted with Bluetooth chips and thus enable more devices to exchange data. This master thesis aims at connecting a Personal Digital Assistant to an ARM Thumb microcontroller over Bluetooth. To the ARM Thumb shall an <b>image</b> <b>capturing</b> <b>device</b> be interfaced and the captured images shall be sent over Bluetooth to the Personal Digital Assistant which shall display them...|$|E
40|$|Abstract: Ubi-Com {{has emerged}} as an {{exciting}} new paradigm to provide intelligent computig and communications at anytime and anywhere. But, In order to take the advantages of such services, {{it is important that}} intelligent security framework be suitable for Ubi-Com. In this paper, we propose privacy and access control scheme by surveillance which is one of core security technologies for ubiquitous hybrid intelligent security framework. In this scheme, the device information and the signature information can be added to the image data obtained by the <b>image</b> <b>capturing</b> <b>device</b> to maintain security of the image data and use the image data as digital proof when a specific event is generated...|$|E
40|$|A {{system for}} {{analyzing}} fabric surface appearance includes a feed mechanism {{for running a}} fabric over a crest including a frame for holding the fabric bent to form a crest, an <b>image</b> <b>capturing</b> <b>device</b> for capturing profile images of the fabric surface at the crest, and a computer system for manipulating the images. The computer system produces a three-dimensional representation of the fabric surface and identifies characteristics in the three-dimensional representation. The information is compared to reference data to identify a grade for the fabric. Institute of Textiles and ClothingUS 6728593; US 6728593 B 2; US 6728593 B 2; US 6, 728, 593; US 6, 728, 593 B 2; 6728593; Appl. No. 10 / 162, 696 U...|$|E
50|$|Beginning with Windows XP Service Pack 1, generic USB 2.0 Enhanced Host Controller Interface {{drivers are}} included. Windows XP also adds support for USB device classes such as Bluetooth, USB video device class, imaging (still <b>image</b> <b>capture</b> <b>device</b> class) and Media Transfer Protocol with Windows Media Player 10.|$|R
40|$|The present {{invention}} {{relates to}} a method and a device for video processing intended to generate images comprising motion blur. The invention relates more {{specifically to the}} domain of animation and video effects and {{can be applied to}} synthesis images or images generated by an <b>image</b> <b>capture</b> <b>device</b> equipped with a digital shutter...|$|R
50|$|It {{is further}} {{standardized}} for USB by the USB Implementers Forum as the still <b>image</b> <b>capture</b> <b>device</b> class. USB is the default network transport media for PTP devices. USB PTP {{is a common}} alternative to the USB mass-storage device class (USB MSC), as a digital camera connection protocol. Some cameras support both modes.|$|R
40|$|With the {{advancement}} in <b>image</b> <b>capturing</b> <b>device,</b> the image data been generated at high volume. If images are analyzed properly, they can reveal useful {{information to the}} human users. Content based image retrieval {{address the problem of}} retrieving images relevant to the user needs from image databases on the basis of low-level visual features that can be derived from the images. Grouping images into meaningful categories to reveal useful information is a challenging and important problem. We apply the algorithm to content-based image retrieval and compare its performance with that of the k-means clustering algorithm. Unlike the k-means algorithm, our algorithm optimizes on both intra-cluster and inter-cluster similarity measures. It has three passes and each pass has the same time complexity as an iteration in the k-means algorithm. Our experiments on a bench mark image data set reveal that our algorithm improves on the recall at the cost of precision...|$|E
40|$|Abstract — With the {{advancement}} in <b>image</b> <b>capturing</b> <b>device,</b> the image data been generated at high volume. If images are analyzed properly, they can reveal useful {{information to the}} human users. Content based image retrieval {{address the problem of}} retrieving images relevant to the user needs from image databases on the basis of low-level visual features that can be derived from the images. Grouping images into meaningful categories to reveal useful information is a challenging and important problem. We apply the algorithm to content-based image retrieval and compare its performance with that of the k-means clustering algorithm. Unlike the k-means algorithm, our algorithm optimizes on both intra-cluster and intercluster similarity measures. It has three passes and each pass has the same time complexity as an iteration in the k-means algorithm. Our experiments on a bench mark image data set reveal that our algorithm improves on the recall at the cost of precision. Keywords-; Content based image Retreival System, clustering, k-means algorithm, medical image retrieval I...|$|E
40|$|With the {{advancement}} in <b>image</b> <b>capturing</b> <b>device,</b> the image data been generated at high volume. If images are analyzed properly, they can reveal useful {{information to the}} human users. Content based image retrieval {{address the problem of}} retrieving images relevant to the user needs from image databases on the basis of low-level visual features that can be derived from the images. Grouping images into meaningful categories to reveal useful information is a challenging and important problem. Clustering is a data mining technique to group a set of unsupervised data based on the conceptual clustering principal: maximizing the intraclass similarity and minimizing the interclass similarity. Proposed framework focuses on color as feature. Color Moment and Block Truncation Coding (BTC) are used to extract features for image dataset. Experimental study using K-Means clustering algorithm is conducted to group the image dataset into various clusters. Comment: " International Journal of Computer Science Issues, IJCSI, Volume 4, Issue 2, pp 31 - 35, September 2009...|$|E
30|$|GoPro Inc., a US-American {{producer}} of high-tech action cameras, is currently expanding into foreign markets. The company (formerly known as Woodman Labs) {{was founded in}} 2002 by Nick Woodman {{with the purpose of}} producing <b>image</b> <b>capture</b> <b>devices</b> for athletes and extreme sport enthusiasts. The analysis of the deal has been performed in July-October 2015.|$|R
50|$|Certain <b>image</b> <b>capturing</b> <b>devices</b> {{are capable}} of {{producing}} images through materials that are opaque to visible light, including clothing. These devices form images by using electromagnetic radiation outside the visible range. Infrared and terahertz-wave cameras {{are capable of}} creating images through clothing, though these images differ from what would be created with visible light.|$|R
50|$|Advances in {{microprocessor}} technology {{paved the}} way for the development and marketing of charge-coupled devices (CCDs) for use in a wide range of <b>image</b> <b>capture</b> <b>devices</b> and gradually displaced the use of analog film and tape in photography and videography towards the end of the 20th century. The computing power necessary to process digital <b>image</b> <b>capture</b> also allowed computer-generated digital images to achieve a level of refinement close to photorealism.|$|R
40|$|Most {{energy saving}} {{applications}} of advanced fenestration systems (solar blinds, novel types of glazing and daylight redirecting devices) require a precise {{knowledge of their}} directional light transmission features. These photometric properties can be described by a Bi-directional Transmission Distribution Function (BTDF) whose experimental assessment requires appropriate equipment. A novel bi-directional transmission photogoniometer, based on digital imaging techniques, was designed and set up for that purpose. The apparatus takes advantage of a modern video <b>image</b> <b>capturing</b> <b>device</b> (CCD digital camera) {{as well as of}} powerful image analysis software (pattern recognition) to considerably reduce the scanning time of a BTDF measurement, in comparison to existing devices that use a conventional approach (mobile photometer). A detailed calibration and validation procedure was used to obtain optimal experimental accuracy for the device during the assessment of BTDF data. It included a spectral, a photometric and a geometrical calibration of the digital video system, as well as several additional corrections, leading to an overall relative accuracy better than 11 % for BTD...|$|E
40|$|The Socio-Spatial History Recorder system {{provides}} a one-stop single-user action solution to creating, tagging, geo-coding, archiving, sharing and streaming of digital artifacts. Users of this solution {{will no longer}} need to perform intermediary actions to edit, prepare, and publish their digital artifacts to the Internet or their social networks. For example, in the case of digital still images, this system offers a one-click solution to sharing a digital artifact. An user can shoot a picture, geo-code the picture, display the picture in a mapping application, and share it with another user all by one and only one shutter click on the digital still <b>image</b> <b>capturing</b> <b>device.</b> Social sharing rules and rights can be set up in advance or dynamically configured and the digital artifacts can be encrypted if desired or required. Practical uses of this system in the social domain include unobtrusive social sharing of digital artifacts embedded in their rich interactional contexts. Practical uses are also in application domains that require or would benefit from unobtrusive collection of rich ecological data without disrupting and/or interrupting the user's primary activity cycle...|$|E
40|$|Research team headPublisher研究種目 : 基盤研究(B) 研究期間 : 2010 ～ 2013 課題番号 : 22320028 研究分野 : 人文学 科研費の分科・細目 : 哲学・美術史日本刀の学術的価値を明確にするためには、その表面形態解析が不可欠である。これまで表面形態解析は刀剣研究者に依存しており、刀剣研究者がいう日本刀表面形態の特徴を刀剣愛好家が視覚的に理解することは困難であった。本研究では株式会社リコーと、従来の日本刀鑑識法を踏襲した多色拡散撮像装置を共同開発し、日本刀 100 口のデジタル画像を作成した。その結果を解析し、日本刀五大流派の地鉄の特徴をまとめた資料集を作成した。併せて、研究成果の一部を平成 23 年度「名物刀剣」展、平成 25 年度「清麿」展で公開し、日本刀の地鉄の美とその変遷を一般に認識させるよう努めた。 In {{order to}} clarify the {{academic}} value of Japanese swords, the analysis of their surface morphology should be essential, which has been solely depending on the observations by the Japanese swords researchers. Therefore, it has been difficult for the Japanese sword fans to visually understand its surface morphology characteristics only by the researcher's descriptions. In this research, digital images of 100 swords were taken by the polychromatic diffuse reflection <b>image</b> <b>capturing</b> <b>device</b> developed in conjunction with Ricoh Co.,Ltd. The obtained results were analyzed and the surface morphology characteristics of the swords belonging to five sword schools in Japan were summarized in a source book. In addition, {{a part of the}} results were introduced in special exhibitions of "Meibutsu Treasured Japanese Swords" in 2011 and "Kiyomaro" in 2013. A great effort has been also made for sword fans to understand the beauty in surface morphology of the Japanese swords through these activities...|$|E
50|$|Instead of X-ray film, digital {{radiography}} uses a digital <b>image</b> <b>capture</b> <b>device.</b> This gives advantages of immediate image preview and availability; elimination of costly film processing steps; a wider dynamic range, {{which makes it}} more forgiving for over- and under-exposure; {{as well as the}} ability to apply special image processing techniques that enhance overall display quality of the image.|$|R
40|$|In a {{world where}} digital {{photography}} is almost ubiquitous, the size of <b>image</b> <b>capturing</b> <b>devices</b> and their lenses limit their capabilities to achieve shallower depths of field for aesthetic purposes. This work proposes a novel approach to simulate this effect using the color and depth images from a 3 D camera. Comparative tests yielded results {{similar to those of}} a regular lens...|$|R
40|$|Spectral based {{color image}} editing systems include methods for {{generating}} spectral representations of surfaces and illuminants from input signals of <b>image</b> <b>capture</b> <b>devices</b> (such as digital cameras and scanners), edi/illg spectral representations of surfaces and illuminants in a scene, and transforming spectral representations of surfaces and illuminants to output signals of image devices (such as CRT and LCD displays and color printers) ...|$|R
40|$|Recently, aerial {{photography}} with {{unmanned aerial vehicle}} (UAV) {{system uses}} UAV and remote controls through connections of ground control system using bandwidth of about 430 MHz radio Frequency (RF) modem. However, as mentioned earlier, existing method of using RF modem has limitations in long distance communication. The Smart Camera equipments’s LTE (long-term evolution), Bluetooth, and Wi-Fi to implement UAV that uses developed UAV communication module system carried out the close aerial photogrammetry with the automatic shooting. Automatic shooting system is an <b>image</b> <b>capturing</b> <b>device</b> for the drones in the area’s that needs image capturing and software for loading a smart camera and managing it. This system is composed of automatic shooting using the sensor of smart camera and shooting catalog management which manages filmed images and information. Processing UAV imagery module used Open Drone Map. This study examined the feasibility of using the Smart Camera as the payload for a photogrammetric UAV system. The open soure tools used for generating Android, OpenCV (Open Computer Vision), RTKLIB, Open Drone Map...|$|E
40|$|With the {{advancement}} in <b>image</b> <b>capturing</b> <b>device,</b> the image data has been generated at high volume. If images are analyzed properly, {{they can give}} useful information to the users. Content based image retrieval retrieves images relevant to the user needs from the image databases {{on the basis of}} low-level visual features that can be derived from the images. Grouping images into meaningful categories to reveal useful information is a challenging and important problem. Block Truncation Coding is used to extract features for image dataset and K-Means clustering algorithm is conducted to group the image dataset into various clusters. objects of interest, that have some similarity along a dimension of interest, are kept close while the objects that differ from each other, are kept further apart. The dimension of interest is defined based on the application. In case of images, they maybe color, texture and shape etc. In color image clustering, the dimension used is color feature. Image clustering consists of two steps the former is feature extraction and second part is grouping. For each image in a database, a feature vector capturing certain essential properties of the image is computed and stored in a feature base. Clustering algorithm is applied over this extracted feature to form the group...|$|E
40|$|Background. Microscopes are omnipresent {{throughout}} {{the field of}} biological research. With microscopes one can see in detail {{what is going on}} at the cellular level in tissues. Though it is a ubiquitous tool, the limitation is that with high magnification there is a small field of view. It is often advantageous to see an entire sample at high magnification. Over the years technological advancements in optics have helped to provide solutions to this limitation of microscopes by creating the so-called dedicated “slide scanners” which can provide a “whole slide digital image. ” These scanners can provide seamless, large-field-of-view, high resolution image of entire tissue section. The only disadvantage of such complete slide imaging system is its outrageous cost, thereby hindering their practical use by most laboratories, especially in developing and low resource countries. Methods. In a quest for their substitute, we tried commonly used image editing software Adobe Photoshop along with a basic <b>image</b> <b>capturing</b> <b>device</b> attached to a trinocular microscope to create a digital pathology slide. Results. The seamless image created using Adobe Photoshop maintained its diagnostic quality. Conclusion. With time and effort photomicrographs obtained from a basic camera-microscope set up can be combined and merged in Adobe Photoshop to create a whole slide digital image of practically usable quality at a negligible cost...|$|E
40|$|Here we {{describe}} {{a system for}} personal and professional management and analysis of bio-medical <b>images</b> <b>captured</b> using off-the-shelf, consumer-grade imaging devices such as scanners, digital cameras, cellphones, webcams and tablet PCs. Specifically, {{we describe}} an implementation of this system for the analysis, monitoring and tracking of conditions and features of human feet using a flatbed scanner as the <b>image</b> <b>capture</b> <b>device</b> and a custom-designed set of algorithms and software to manage and analyze the acquired data...|$|R
40|$|In this paper, {{we present}} a near {{infrared}} (NIR) image based face recognition system. Firstly, we describe a design of NIR <b>image</b> <b>capture</b> <b>device</b> which minimizes influence of environmental lighting on face images. Both face and facial feature localization and face recognition are performed using local features with AdaBoost learning. An evaluation in real-world user scenario shows that the system achieves excellent accuracy, speed and usability. 1...|$|R
50|$|Since {{digital signage}} content may be {{frequently}} updated using the control software, {{and also because}} of the interactive abilities available through the accompanying employment of real-world interfaces such as embedded touch screens, movement detection and <b>image</b> <b>capture</b> <b>devices</b> which enable these forms of signage to understand who and how users are interacting with them, they are gaining acceptance as an alternative to static signage.|$|R
