4|4493|Public
40|$|In this paper, a fast {{geometric}} rectification {{method for}} space-borne SAR (Synthetic Aperture Radar) digital image in slant range with no ground control point is introduced, {{which is based}} on the imaging principle of SAR and the law of geometric distortion in slant range image. The main idea is at first to resample a slant range SAR image to a <b>ground</b> <b>range</b> <b>image</b> with a definite ground spacing because the ground spacing corresponding to each pixel in slant is different caused by the different view angle. The coordinate system of the resampled image can be recognized as a plane rectangular coordinate system formed by the flight direction and the ground range direction. For the plain areas, the <b>ground</b> <b>range</b> <b>image</b> can be transformed into the image in a projected geographic coordinate system by four corner points whose ground coordinates can be calculated by the imaging equation. The rectified image is obtained with high accuracy; While for the areas with fluctuation topography, a higher precision rectification can be made based on the <b>ground</b> <b>range</b> <b>image</b> for it maintains the information of the original SAR slant range image(ground range and flight height) ...|$|E
40|$|International audienceIn {{this paper}} we present an {{approach}} for automatic analysis of urban acessibility using 3 D point clouds. Our approach {{is based on}} range images and it consists in two main steps: urban objects segmentation and curbs detection. Both of them are required for accessibility diagnosis and itinerary planning. Our method automatically segments facades and urban objects using two hypotheses: facades are the highest vertical structures in the scene and objects are bumps on the ground on the range image. The segmentation result is used to build an urban obstacle map. After that, the gradient is computed on the <b>ground</b> <b>range</b> <b>image.</b> Curb candidates are selected using height and geodesic features. Then, nearby curbs are reconnected using Bézier curves. Finally, accessibility is defined based on geometrical features and accessibility standards. Our methodology is tested on two MLS databases from Paris (France) and Enschede (The Netherlands). Our experiments show that our method has good detection rates, is fast and presents few false alarms. Our method outperforms other works {{reported in the literature}} on the same databases...|$|E
40|$|Intercomparison of {{backscatter}} {{collected by}} SAR sensors at heterogeneous radar look angles {{gives rise to}} highly variable ground areas being associated with each pixel location within a radar geometry (slant or <b>ground</b> <b>range)</b> <b>image.</b> Many elements within a digital elevation model (in map geometry) can be mapped to a single location in the radar image (range / Doppler coordinates). An image simulation technique uses a faceted high resolution elevation model to integrate all backscatter returned to each range and Doppler location in the radar image (incorporating knowledge of local radar shadow). Modelling the imaging process in this manner, a map of illuminated area is produced in radar geometry, and used to normalize the true backscatter returned by the radar sensor. Although radar shadow must be considered specially, no extraordinary treatment is required of layover regions, as they are correctly accounted for by integration of the illuminated area. The image simulation approach improves on the conventional consideration of 2 D incidence angles, as the 3 D configuration defining the illuminated area (in both the range and azimuth dimensions) is captured. RADARSAT images acquired over Switzerland are used to demonstrate the benefit of such normalization for thematic interpretation. A high resolution digital elevation model (DEM) with 25 m pixel spacing is used as input to the image simulation. The deterioration of the normalization with progressively poorer input DEMs is studied empirically to gauge the required DEM resolution for acceptable normalization of images acquired over pre-alpine topography...|$|E
40|$|The chirp scaling SAR {{processing}} {{algorithm is}} both accurate and efficient. Successful implementation requires proper {{selection of the}} interval of output samples, which {{is a function of}} the chirp interval, signal sampling rate, and signal bandwidth. Analysis indicates that for both airborne and spaceborne SAR applications in the slant range domain a linear chirp scaling is sufficient. To perform nonlinear interpolation process such as to output <b>ground</b> <b>range</b> SAR <b>images,</b> one can use a nonlinear chirp scaling interpolator presented in this paper...|$|R
40|$|Abstract [...] Stereo {{algorithms}} {{suffer from}} the lack of local surface texture due to smoothness of depth constraint, or local miss-matches in disparity estimates. Thus, most stereo methods only provide a coarse depth map which can be associated with a low pass image of the depth map. On the other hand, shape from shading algorithms generally produce better estimates of local surface areas, but some of them have problems with variable albedo and spherical surfaces. Thus, shape from shading methods produce better detailed depth information, and can be associated with the high pass image of the depth map. In order to compute a better depth map, we present a method for integrating the high frequncy information from the shape from shading and the low frequency information from stereo. The proposed algorithm is very simple, takes about 0. 7 s for a 128 x 128 image on a Sun SparcStation- 1, is non-iterative, and requires very little adjustment of parameters. The results obtained with a variety of synthetic and real images are discussed. The quality of depth obtained by integrating shading and stereo is compared with the <b>ground</b> truth (<b>range</b> <b>image)</b> using height error measure, and improvement ranging from 30 to 50 % over stereo, and from 65 to 98 % over shading is demonstrated. Shape from shading Shape from stere...|$|R
40|$|In {{this paper}} we analyze sampled high {{dimensional}} data with the NEB method from a <b>range</b> <b>image</b> database. Select a large {{random sample of}} log-valued, high contrast, normalized, 8 × 8 <b>range</b> <b>image</b> patches from the Brown database. We make a density estimator and we establish 1 -dimensional cell complexes from the <b>range</b> <b>image</b> patch data. We find topological properties of 8 × 8 <b>range</b> <b>image</b> patches, prove that there exist two types of subsets of 8 × 8 <b>range</b> <b>image</b> patches modelled as a circle...|$|R
40|$|Abstract In {{order to}} realize more precise {{geometrical}} models of existing buildings, <b>range</b> <b>images</b> {{are used to}} represent the geometrical information of the façades of existing buildings. First, the <b>range</b> <b>images</b> of existing buildings are acquired using laser scanners mounted on a data acquisition vehicle which runs along the street. After removing obstacles, edge detection based segmentation and histogram are used to locate the vertical patterns from the <b>range</b> <b>image</b> of the buildings. Then by matching the patterns from the <b>range</b> <b>image</b> with that from a digital map using a pattern matching algorithm based on dynamic programming, the <b>range</b> <b>image</b> corresponding to the façade of a building can be determined. Precise geometrical information of the façade of the buildings {{can be obtained from}} its corresponding <b>range</b> <b>image...</b>|$|R
40|$|Abstract. Automatic {{registration}} of <b>range</b> <b>images</b> {{is a fundamental}} problem in 3 D modeling of free-from objects. Various feature matching algorithms have been proposed for this purpose. However, these algorithms suffer from various limitations mainly related to their applicability, efficiency, robustness to resolution, and the discriminating capability of the used feature representation. We present a novel feature matching algorithm for automatic pairwise {{registration of}} <b>range</b> <b>images</b> which overcomes these limitations. Our algorithm uses a novel tensor representation which represents semi-local 3 D surface patches of a <b>range</b> <b>image</b> by third order tensors. Multiple tensors are used to represent each <b>range</b> <b>image.</b> Tensors of two <b>range</b> <b>images</b> are matched to identify correspondences between them. Correspondences are verified and then used for pairwise registration of the <b>range</b> <b>images.</b> Experimental results show that our algorithm is accurate and efficient. Moreover, it is robust to {{the resolution of the}} <b>range</b> <b>images,</b> the number of tensors per view, the required amount of overlap, and noise. Comparisons with the spin image representation revealed that our representation has more discriminating capabilities and performs better at a low resolution of the <b>range</b> <b>images...</b>|$|R
40|$|An {{adaptive}} <b>range</b> <b>image</b> {{coding algorithm}} for the geometry compression of large-scale 3 D point clouds (LS 3 DPCs) is proposed in this work. A terrestrial laser scanner generates an LS 3 DPC {{by measuring the}} radial distances of objects in a real world scene, which can be mapped into a <b>range</b> <b>image.</b> In general, the <b>range</b> <b>image</b> exhibits different characteristics from an ordinary luminance or color image, and thus the conventional image coding techniques are not suitable for the <b>range</b> <b>image</b> coding. We propose a hybrid <b>range</b> <b>image</b> coding algorithm, which predicts the radial distance of each pixel using previously encoded neighbors adaptively {{in one of three}} coordinate domains: <b>range</b> <b>image</b> domain, height image domain, and 3 D domain. We first partition an input <b>range</b> <b>image</b> into blocks of various sizes. For each block, we apply multiple prediction modes in the three domains and compute their rate-distortion costs. Then, we perform the prediction of all pixels using the optimal mode and encode the resulting prediction residuals. Experimental results show that the proposed algorithm provides significantly better compression performance on various <b>range</b> <b>images</b> than the conventional image or video coding techniquesclose 0...|$|R
40|$|In {{order to}} realize 3 D {{modeling}} and refinement of buildings {{in a digital}} 2 D residential map using <b>range</b> <b>images</b> of the streets, we match <b>range</b> <b>images</b> of streets with the digital map. After pattern lines of the <b>range</b> <b>images</b> are determined using edge detection and depth analysis, they are matched with pattern lines of the digital map using a pattern matching algorithm based on dynamic programming. The <b>range</b> <b>images</b> of every building can be extracted and linked with the corresponding building data in the residential map according to the matching result. 3 D modeling and refinement of the buildings in the 2 D residential digital map can be realized using their <b>range</b> <b>images.</b> 2. Matching <b>Range</b> <b>Images</b> of Streets with a Digital Map A <b>range</b> <b>image</b> of a street contains buildings and something else, such as trees, cars, electrical posts, and pedestrians. An example of a <b>range</b> <b>image</b> of streets {{is shown in figure}} 1. The image was taken by a line scan type laser scanner mounted on a vehicle. The laser scanner scanned buildings vertically when the vehicle moved on the road in front of the buildings. 1...|$|R
40|$|Abstract [...] This paper proposes and {{describes}} a hierarchical self-organizing neural network for <b>range</b> <b>image</b> segmentation. The multilayer self-organizing feature map (MLSOFM), {{which is an}} extension of the traditional (singlelayer) self-organizing feature map (SOFM) is seen to alleviate the shortcomings of the latter in the context of <b>range</b> <b>image</b> segmentation. The problem of <b>range</b> <b>image</b> segmentation is formulated as one of vector quantization and is mapped onto the MLSOFM. The MLSOFM combines the ideas of self-organization and topographic mapping with those ofmultiscale image segmentation. Experimental results using real <b>range</b> <b>images</b> are presented. Keywords [...] <b>Range</b> <b>image</b> segmentation, Self-organizing feature map, Neural networks, Computer vision. 1...|$|R
40|$|Abstract− − <b>Range</b> <b>images</b> have a {{key role}} for sur-face mapping in robot {{navigation}} and control. The robot control system can easily identify objects and obstacles by manipulating <b>range</b> <b>images,</b> however most of these <b>range</b> <b>images</b> are acquired in perspec-tive projection, thus object position may be incorrect due to distortion caused by the perspective effect. This paper proposes an easy and efficient way to acquire <b>range</b> <b>images,</b> with a single CCD camera in conjunction with laser stripes and afterwards these <b>range</b> <b>images</b> are orthorectified {{to turn out to}} sur-face maps. These orthorectified <b>range</b> <b>images</b> are very useful for biped and quadruped robots, orien-tating them when navigating among obstacles while robot manipulators can use them to find objects by setting up their joints and picking tools. Keywords− − rangefinder; robot control; vision system; laser stripes; orthorectification. I...|$|R
40|$|We {{present a}} new method for {{registration}} of <b>range</b> <b>images,</b> {{which is based}} on the results we obtain from the segmentation process. We need two <b>range</b> <b>images</b> segmented into regions, each of them modeled by a paramteric model and the approximation of the transformation between the two <b>range</b> <b>images.</b> Then two sets of corresponding points, one from each <b>range</b> <b>image,</b> are chosen and the transformation between them is computed to further refine the initial approximation of the transformation. The novelty is how we obtain the a corresponding points for the original set of points from the <b>range</b> <b>image.</b> Namely, to obtain them we project set of points from the first <b>range</b> <b>image</b> onto geometric parametric models that were recovered in the second <b>range</b> <b>image</b> and viceversa. This way we obtain two sets of corresponding points. Then we compute the transformation between the two sets. Few iterations are required to improve the initial approximation of the transformation. The results have shown a significant improvement in precision of the registration in comparison with traditional approaches...|$|R
40|$|<b>Range</b> <b>image</b> {{registration}} {{is a fundamental}} research topic for 3 D object modeling and recognition. In this paper, we propose an accurate and robust algorithm for pairwise and multi-view <b>range</b> <b>image</b> registration. We first extract a set of Rotational Projection Statistics (RoPS) features {{from a pair of}} <b>range</b> <b>images,</b> and perform feature matching between them. The two <b>range</b> <b>images</b> are then registered using a transformation estimation method and a variant of the Iterative Closest Point (ICP) algorithm. Based on the pairwise registration algorithm, we propose a shape growing based multi-view registration algorithm. The seed shape is initialized with a selected <b>range</b> <b>image</b> and then sequentially updated by performing pairwise registration between itself and the input <b>range</b> <b>images.</b> All input <b>range</b> <b>images</b> are iteratively registered during the shape growing process. Extensive experiments were conducted to test the performance of our algorithm. The proposed pairwise registration algorithm is accurate, and robust to small overlaps, noise and varying mesh resolutions. The proposed multi-view registration algorithm is also very accurate. Rigorous comparisons with the state-of-the-art show the superiority of our algorithm...|$|R
40|$|This paper {{presents}} a powerful {{variant of the}} ICP (Iterative Closest Point) algorithm for registering <b>range</b> <b>images</b> using a probability field. The probability field (p-field) represents the probability distribution of the surface position. By capitalizing on {{the properties of the}} <b>range</b> <b>image,</b> fast construction, compact representation, and efficient query of the p-field can be achieved. Different sensor models are supported by the p-field according to the properties of the <b>range</b> <b>image.</b> <b>Range</b> <b>images</b> can be precisely aligned by maximizing the probability of overlapping surfaces via the p-field...|$|R
40|$|Over-segmentation', `under-segmentation', `good results' {{and similar}} {{subjective}} terms appear {{frequently in the}} literature on <b>range</b> <b>image</b> segmentation. However, even though the need for standardized segmentation error metrics has been long recognized, no formal methodology for evaluating a <b>range</b> <b>image</b> segmentation has appeared. This paper describes a framework in which to carry out such an evaluation. With this framework, a more rigorous and objective comparison of <b>range</b> <b>image</b> segmentation techniques can be performed. We have developed many key issues, including a formal definition of the <b>range</b> <b>image</b> segmentation problem, a comprehensive data set to use in evaluation, a method for creating ground truths, and a set of formally defined metrics to classify segmentation results against ground truths. 1 Introduction This paper describes a methodology to compare <b>range</b> <b>image</b> segmentation techniques. As early as 1988, at the NSF <b>Range</b> <b>Image</b> Understanding Workshop, the community recognized the [...] ...|$|R
40|$|This paper {{describes}} a probabilistic method of aligning and merging <b>range</b> <b>images.</b> We formulate these issues as problems of estimating the maximum likelihood. By examining the error distribution {{of a range}} finder, we model it as a normal distribution {{along the line of}} sight. To align <b>range</b> <b>images,</b> our method estimates the parameters based on the Expectation Maximization (EM) approach. By assuming the error model, the algorithm is implemented {{as an extension of the}} Iterative Closest Point (ICP) method. For merging <b>range</b> <b>images,</b> our method computes the signed distances by finding the distances of maximum likelihood. Since our proposed method uses multiple correspondences for each vertex of the <b>range</b> <b>images,</b> errors after aligning and merging <b>range</b> <b>images</b> are less than those of earlier methods that use one-to-one correspondences. Finally, we tested and validated the efficiency of our method by simulation and on real <b>range</b> <b>images.</b> 1...|$|R
40|$|A {{mechanism}} for <b>range</b> <b>image</b> integration without image registration A mechanism is introduced that automatically integrates multi-view <b>range</b> <b>images</b> without registering the images. The mechanism {{is based on}} a reference double-frame that acts as the coordinate system of the scene. A single-view <b>range</b> <b>image</b> of a scene is obtained by sweeping a laser line over the scene by hand and analyzing the acquired light stripes. <b>Range</b> <b>images</b> captured from different views of the scene will be in the coordinate system of the double-frame, and thus, will automatically integrate without further processing. 1...|$|R
40|$|A novel {{method for}} {{integrating}} multiple <b>range</b> <b>images</b> in a multi-view stereo imaging system is presented here. Due to self-occlusion an individual <b>range</b> <b>image</b> provides {{only a partial}} model of an object surface. Therefore multiple <b>range</b> <b>images</b> from differing viewpoints must be captured and merged to extend the surface area that can be captured. In our approach <b>range</b> <b>images</b> are decomposed into subset patches and then evaluated in a "confidence competition". Redundant patches are removed whilst winning patches are merged to complete a single plausible mesh that represents the acquired object surface...|$|R
40|$|Automatic and {{accurate}} <b>range</b> <b>image</b> registration {{is often a}} prerequisite step for <b>range</b> <b>image</b> analysis and interpretation. Due to occlusion, appearance and disappearance of points in different images, outliers inevitably occur. In this case, various techniques to eliminate and model outliers have been proposed for accurate <b>range</b> <b>image</b> registration. The objective {{of this paper is}} to experimentally investigate which of the outlier elimination and modelling is more effective for the evaluation of possible correspondences established, so that a deep insight into how advanced <b>range</b> <b>image</b> registration algorithms will be developed can be obtained. The experimental results based on both synthetic data and real images show that the outlier modelling often outperforms the outlier elimination in the sense of producing more accurate and robust <b>range</b> <b>image</b> registration results. ...|$|R
40|$|In {{this paper}} we present yet another {{reconstruction}} technique which generates a 3 D closed triangular mesh from an unregistered <b>range</b> <b>image</b> by deforming discretely an initial triangular mesh. Combining {{the advantages of}} the previous work on a deformable model and on a function-graph model, our algorithm avoids not only holes in the reconstructed surfaces, but also self-intersections as well. Keywords: Deformable models, <b>range</b> <b>image,</b> 3 D closed mesh reconstruction. 1 Introduction Despite a variety of published work, the 3 D reconstruction from a set of <b>range</b> <b>images</b> is still a challenging and important problem for vision community. Since no single <b>range</b> <b>image</b> suf- ces to describe completely the surface of an object, additional methods were devised either to register multiple <b>range</b> <b>images</b> before surface model creation [10, 2] or to " multiple meshes reconstructed from unregistered <b>range</b> <b>images</b> [7]. In this context we may classify the known reconstruction techniques into three sche [...] ...|$|R
40|$|Liu, Yonghuai, Liu, Honghai, Li, Longzhuang, Wei, Baogang. Accurate <b>Range</b> <b>Image</b> Registration: Eliminating or Modelling Outliers. Proceedings of 12 th IEEE Conference on Emerging Technologies and Factory Automation, 2007, pp. 1316 - 1323. Sponsorship: IEEEAutomatic and {{accurate}} <b>range</b> <b>image</b> registration {{is often a}} prerequisite step for <b>range</b> <b>image</b> analysis and interpretation. Due to occlusion, appearance and disappearance of points in different images, outliers inevitably occur. In this case, various techniques to eliminate and model outliers have been proposed for accurate <b>range</b> <b>image</b> registration. The objective {{of this paper is}} to experimentally investigate which of the outlier elimination and modelling is more effective for the evaluation of possible correspondences established, so that a deep insight into how advanced <b>range</b> <b>image</b> registration algorithms will be developed can be obtained. The experimental results based on both synthetic data and real images show that the outlier modelling often outperforms the outlier elimination in the sense of producing more accurate and robust <b>range</b> <b>image</b> registration results. preprintpreprin...|$|R
40|$|Range finder {{devices are}} quite useful {{to measure the}} {{geometry}} of real-world objects. However, the reconstruction of large and complicated objects often requires the acquisition of multiple <b>range</b> <b>images</b> showing different views of the object. With our reconstruction method, the relative orientations of all <b>range</b> <b>images</b> are determined via simultaneous registration of all <b>range</b> <b>images.</b> The registration process {{is based on a}} least-squares approach where a distance metric between the overlapping <b>range</b> <b>images</b> is minimized. Registration errors are not accumulated, and it is even possible to reconstruct large objects from an arbitrary number of small <b>range</b> <b>images.</b> A resolution hierarchy accelerates the registration substantially. In order to exploit redundancies, the overlapping surfaces are optimally adapted to each other. The processed <b>range</b> <b>images</b> are converted to a signed distance function, which is {{based on the idea that}} no part of the object can lie between the scanner and the measured su rface in any view. According to the signed distance function an intermediate volumetric model is sculptured out and polygnalized with isosurface techniques. The accuracy of the generated mesh is improved by moving its vertices onto the surface implicitly defined bt the registered <b>range</b> <b>images...</b>|$|R
40|$|This paper {{presents}} a <b>range</b> <b>image</b> refinement technique for generating accurate 3 D computer models of real objects. <b>Range</b> <b>images</b> {{obtained from a}} stereo-vision system typically experience geometric distortions on reconstructed 3 D surfaces due to the inherent stereo matching problems such as occlusions or mismatchings. This paper introduces a <b>range</b> <b>image</b> refinement technique to correct such erroneous ranges by employing epipolar geometry of a multiview modeling system and the visual hull of an object. After registering multiple <b>range</b> <b>images</b> into a common coordinate system, we first determine if a 3 D point in a <b>range</b> <b>image</b> is erroneous, by measuring registration of the point with its correspondences in other <b>range</b> <b>images.</b> The correspondences are determined on 3 D contours which are inverseprojections of epipolar lines in other 2 D silhouette <b>images.</b> Then the <b>range</b> of the point is refined onto the object’s surface, if it is erroneous. We employ two techniques to search the correspondences fast. In case {{that there is no}} correspondence for an erroneous point, we refine the point onto the visual hull of the object. We show that refined <b>range</b> <b>images</b> yield better geometric structures in reconstructed 3 D models...|$|R
40|$|Abstract. In {{this paper}} a robust method is {{presented}} to classify and estimate an objects pose from a real time <b>range</b> <b>image</b> and a low dimensional model. The model is made from a <b>range</b> <b>image</b> training set which is reduced dimensionally by a nonlinear manifold learning method named Local Linear Embedding (LLE). New <b>range</b> <b>images</b> are then projected to this model giving the low dimensional coordinates of the object pose in an efficient manner. The <b>range</b> <b>images</b> are acquired by {{a state of the}} art SwissRanger SR- 3000 camera making the projection process work in real-time. ...|$|R
40|$|Abstract. This paper {{introduces}} a stereo vision system to automatically generate 3 D models of real objects. 3 D model generation {{is based on}} the merging of multiview <b>range</b> <b>images</b> obtained from a digital stereo camera. Stereo images obtained from the camera are rectified, and a correlation-based stereo matching technique reconstructs <b>range</b> <b>images</b> from them. A turntable stage is also employed to obtain multiple <b>range</b> <b>images</b> of the objects. To register <b>range</b> <b>images</b> into a common coordinate system automatically, we introduce and calibrate a turntable coordinate system with respect to the camera coordinate system. After the registration of multiview <b>range</b> <b>images,</b> a 3 D model is reconstructed using a volumetric integration technique. Error analysis on turntable calibration and 3 D model reconstruction shows the accuracy of our 3 D modeling system...|$|R
40|$|In this paper, we {{describe}} the method for aligning multiple <b>range</b> <b>images</b> given by a range finder. Especially we will use <b>range</b> <b>images</b> of {{inside and outside of}} buildings which contain many planar structures. In our method for registration of <b>range</b> <b>images,</b> we consider not only 3 D positions of range data but normal vectors of planes in the scene in order to refine the ICP (Iterative Closest Point) algorithm. First, we extract planes of <b>range</b> <b>images</b> in order to calculate normal vectors of planes in the scene. Then, we estimate the motion parameters that are composed of a rotation matrix and a translation vector using our refined ICP algorithm. We present results that demonstrate our approach’s ability to align <b>range</b> <b>images</b> more accurately and faster than the standard ICP algorithm. 1...|$|R
40|$|The {{fundamental}} {{assumption of}} 3 D videos using depth-image-based rendering is the full availability of <b>range</b> <b>images</b> at video rate. In this work we alleviate this hard demand {{and assume that}} only limited resources of <b>range</b> <b>images</b> are available, i. e. corresponding <b>range</b> <b>images</b> exist for some, but not all, color images of the monoscopic video stream. We propose to synthesize the missing <b>range</b> <b>images</b> between two consecutive <b>range</b> <b>images.</b> Experiments on real videos have demonstrated very encouraging results. Especially, one 3 D video was generated from a 2 D video without any sensory 3 D data available at all. In a quality evaluation using an autostereoscopic 3 D display the test viewers have attested similar 3 D video quality for our synthesis technique and rendering based on depth ground truth. © 2006 IEEE...|$|R
40|$|Abstract. Despite the {{ubiquitous}} use of <b>range</b> <b>images</b> in various com-puter vision applications, {{little has been}} investigated about the size vari-ation of the local geometric structures captured in the <b>range</b> <b>images.</b> In this paper, we show that, through canonical geometric scale-space anal-ysis, this geometric scale-variability embedded in a <b>range</b> <b>image</b> can be exploited as {{a rich source of}} discriminative information regarding the captured geometry. We extend previous work on geometric scale-space analysis of 3 D models to analyze the scale-variability of a <b>range</b> <b>image</b> and to detect scale-dependent 3 D features – geometric features with their inherent scales. We derive novel local 3 D shape descriptors that encode the local shape information within the inherent support region of each feature. We show that the resulting set of scale-dependent local shape descriptors can be used in an efficient hierarchical registration algorithm for aligning <b>range</b> <b>images</b> with the same global scale. We also show that local 3 D shape descriptors invariant to the scale variation can be de-rived and used to align <b>range</b> <b>images</b> with significantly different global scales. Finally, we demonstrate that the scale-dependent/invariant local 3 D shape descriptors can even be used to fully automatically register multiple sets of <b>range</b> <b>images</b> with varying global scales corresponding to multiple objects. ...|$|R
40|$|An {{efficient}} algorithm for extracting planar and curved surface patches that express distinctive {{parts of the}} objects contained in a given <b>range</b> <b>image</b> is pre-sented. The proposed technique does not directly segment the <b>range</b> <b>image</b> but a triangular approximation of it obtained through a fast adaptive randomized sam-pling algorithm. This intermediate representation allows to avoid the processing of all the individual points of the <b>range</b> <b>image</b> in the segmentation phase. 1...|$|R
40|$|Abstract—This paper {{presents}} an efficient technique for gener-ating adaptive triangular meshes from <b>range</b> <b>images.</b> The algo-rithm {{consists of two}} stages. First, a user-defined number of points is adaptively sampled from the given <b>range</b> <b>image.</b> Those points are chosen by {{taking into account the}} surface shapes represented in the <b>range</b> <b>image</b> {{in such a way that}} points tend to group in areas of high curvature and to disperse in low-variation regions. This selection process is done through a noniterative, inherently par-allel algorithm in order to gain efficiency. Once the image has been subsampled, the second stage applies a two and one half-dimen-sional Delaunay triangulation to obtain an initial triangular mesh. To favor the preservation of surface and orientation discontinuities (jump and crease edges) present in the original <b>range</b> <b>image,</b> the aforementioned triangular mesh is iteratively modified by applying an efficient edge flipping technique. Results with real <b>range</b> <b>images</b> show accurate triangular approximations of the given range im-ages with low processing times. Index Terms—Adaptive triangular meshes, discontinuity-pre-serving triangulation, <b>range</b> <b>images,</b> three-dimensional (3 -D) shape representation and recovery. I...|$|R
40|$|Abstract—Previous {{performance}} evaluation of <b>range</b> <b>image</b> segmentation algorithms has depended on manual tuning of algorithm parameters, and has lacked {{a basis for}} {{a test of the}} significance of differences between algorithms. We present an automated framework for evaluating the performance of <b>range</b> <b>image</b> segmentation algorithms. Automated tuning of algorithm parameters in this framework results in performance as good as that previously obtained with careful manual tuning by the algorithm developers. Use of multiple training and test sets of images provides the basis for a test of the significance of performance differences between algorithms. The framework implementation includes <b>range</b> <b>images,</b> <b>ground</b> truth overlays, program source code, and shell scripts. This framework should a) make it possible to objectively and reliably compare the performance of <b>range</b> <b>image</b> segmentation algorithms; b) allow informed experimental feedback for the design of improved segmentation algorithms. The framework is demonstrated using <b>range</b> <b>images,</b> but in principle it could be used to evaluate region segmentation algorithms for any type of image. Index Terms—Performance evaluation, <b>range</b> <b>image</b> segmentation, region segmentation. I...|$|R
40|$|Machine vision using image {{processing}} of traditional intensity images is in wide spread use. In many situations environmental conditions or object colours or shades cannot be controlled, leading to difficulties in correctly processing {{the images and}} requiring complicated processing algorithms. Many of these complications can be avoided by using <b>range</b> <b>image</b> data, instead of intensity data. This is because <b>range</b> <b>image</b> data represents the physical properties of object location and shape, practically independently of object colour or shading. The advantages of <b>range</b> <b>image</b> processing are presented, along with three example applications that show how robust machine vision results can be obtained with relatively simple <b>range</b> <b>image</b> processing in real-time applications...|$|R
40|$|In this paper, {{we present}} an {{approach}} for {{the reconstruction of}} work pieces and designer models from multiple <b>range</b> <b>images.</b> The <b>range</b> <b>images</b> are acquired with a 3 D <b>range</b> <b>image</b> scanner. Due to occlusions and self-occlusions appearing naturally in <b>range</b> <b>images,</b> a work piece has to be scanned from several directions for the reconstruction process. Then, all acquired range views are combined to build a CAD-model of the object. The idea is that {{every part of the}} surface should be visible in at least one view. The reconstruction process is divided into the steps registration, volume sculpturing and generation of an accurate polygonal representation...|$|R
40|$|This paper {{presents}} a technique for lossy compression of dense <b>range</b> <b>images.</b> Two separate compression schemes are applied. The first scheme (geometric compression) reduces redundant geometric information by generating an adaptive 3 D triangular mesh that approximates the shapes {{present in the}} original <b>range</b> <b>image.</b> Geometric compression is used for obtaining an efficient representation of the <b>range</b> <b>image</b> that allows further processing. The second compression scheme (topological compression) encodes the connectivity information contained in the triangular mesh. Topological compression is used for generating a compact representation suitable to be stored or transmitted. Both compression schemes avoid costly iterative optimization algorithms. Results with real <b>range</b> <b>images</b> are presented. 1...|$|R
40|$|Previous {{works on}} <b>range</b> <b>image</b> {{segmentation}} concentrate on surface patches {{that can be}} well represented by certain mathematical functions. In this paper we consider the more qualitative segmentation problem of decomposing a <b>range</b> <b>image</b> into convex parts/objects. An edge-based approach is proposed which uses an adaptive contour closure algorithm {{in conjunction with a}} global convexity test. Experimental results on two <b>range</b> <b>image</b> sets are reported to demonstrate the performance of our convex decomposition technique. ...|$|R
