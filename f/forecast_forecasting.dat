5|2368|Public
40|$|Abstract This {{paper will}} discuss some {{resource}} allocation methods that can tolerate forecast errors under the Budget-Based management infrastructure, BBQ, {{which is designed}} to offer end-to-end QoS assurance for All-IP networks. BBQ takes pre-planning approach to forecast incoming traffic based on historic statistics and allocates link resources accordingly. Traffic forecast may not be perfectly accurate due to traffic fluctuation and imperfect <b>forecast.</b> <b>Forecasting</b> errors may lead to poor resource allocation. We have designed some mechanisms that can compensate forecasting errors and thus may reduce performance degradation accordingly...|$|E
40|$|Scientific {{writing is}} {{intended}} to simplify decision-makers in predicting the volume of sales, bymaking a computer program to facilitate the calculations so that results {{would be expected to}} bemore quickly and accurately. Another aim {{to be able to see}} the opportunities that exist incompanies that can take into account the condition of the company to be able to develop moreadvanced again. The result is that the intelligence of elected experience and a good theory will provide the basicsis best to conduct the sales <b>forecast.</b> <b>Forecasting</b> by using the least square method using theassumption that what happens in the future no matter what happened in the past, state variablesmust be fixed for futur...|$|E
40|$|To {{address the}} {{question}} of whether the sex differential in mortality will in the future rise, fall, or stay the same, this study uses the relative smoking prevalence among males and females to forecast future changes in relative smoking-attributed mortality. Data on 21 high income nations from 1975 to 2000 and a lag between smoking prevalence and mortality allow forecasts up to 2020. Averaged across nations, the results reveal narrowing of measures of the sex differential in smoking mortality. However, continued widening of the differential in non-smoking mortality would counter narrowing due to smoking and lead to future increases in the female advantage overall, particularly in nations at late stages of the cigarette epidemic (such as the United States and the United Kingdom) where narrowing of the smoking differential has already begun to slow. <b>forecast,</b> <b>forecasting,</b> mortality, sex differences, smoking...|$|E
5000|$|Added {{document}} types for Collaborative planning, <b>forecasting,</b> and replenishment: Exception Criteria, Exception Notification, <b>Forecast,</b> <b>Forecast</b> Revision, Item Information Request, Prior Information Notice, Trade Item Location Profile ...|$|R
5000|$|Consensus <b>forecast,</b> {{also known}} as {{combining}} <b>forecasts,</b> <b>forecast</b> averaging or model averaging (in econometrics and statistics) and committee machines, ensemble averaging or expert aggregation (in machine learning) ...|$|R
40|$|The {{expected}} error variance of a combined <b>forecast</b> is necessarily {{lower than that}} of an individual <b>forecast,</b> but in practice there may be considerable variation around these expected values. This paper introduces a measure of the benefit from combining, the probability of a reduction in error variance, which recognizes this problem. The measure is applied to data on the <b>forecasts</b> and <b>forecasting</b> methods of a panel of U. S. economists to determine how the benefits of combining vary with the number of <b>forecasts</b> combined, and with the diversity in theories and techniques among the component <b>forecasts.</b> <b>forecasting,</b> combined <b>forecasts...</b>|$|R
40|$|In {{this paper}} we perform a {{comparative}} study of the forecasting properties of the about 30 alternative leading indicators for Germany using the growth rates of German real GDP. In addition to them, we have constructed a diffusion index based on the principal component analysis and including 145 component series that reflect all the facets of German economy. We use the post-unification data which cover years from 1991 through 2004. Using a battery of statistical tests we detect a structural break in the growth rates that occurs {{in the first half}} of 2001. Our results suggest that the forecasting ability of the leading indicators has been rather good in the pre-break period with our diffusion index showing the superior forecasting accuracy but the forecasting performance of all alternative indicators has significantly deteriorated in the post-break period, i. e. in 2001 - 2004. None of the leading indicator models was able to predict and accommodate the structural break in the growth rates of the time series under scrutiny. This finding confirms the widespread impression among the practitioners that the state of German economy in the recent years became much more difficult to <b>forecast.</b> <b>Forecasting</b> real GDP, diffusion index, leading indicators, PcGets...|$|E
40|$|This paper {{gives an}} {{overview}} of some issues related to market aluation, focusing on the developments on the New York equity markets. The 42. 4 p. c. fall in the S&P 500 price index between 24 March 2000 - when it reached its all-time high - and 31 December 2002 is situated {{in a very long}} term perspective. It then appears that some bear markets were more pronounced in the past but that the bull market preceding the 2000 - 2002 bear market had been particularly long and impressive in extent. Given this sharp correction, we will discuss whether the S&P 500 was correctly valued at the end of 2002. To this e d, we make use of valuation indicators defined as the ratio of the price to a fundamental. The fundamentals considered here are, according to the discount dividend model, annual earnings and, according to Q-theory, net worth. In December 2002, price-earnings (P/E) still showed a significant overvaluation of equity prices when compared to the historical average over the 1871 - 2002 period but, since July 2002, the overvaluation has not been significant in the case of Q. The evidence is even more mixed when the comparison is made, for each valuation indicator, with their average over the last 10 years. Simulations based on VAR models for P/E and Q were carried out to check whether, on two occasions, the S&P 500 in real terms climbed to a level perceived as irrational given past experience, implying that a correction had to be expected. These occasions were the so-called 1929 and 2000 bubbles. The models showed that, {{at some point in time}} before the peak in (real) stock prices was reached, the real S&P 500 exceeded the upper band of the 95 p. c. confidence intervals during both periods. For each of them, the Q model showed earlier and more persistent signals of significant overvaluation of stock prices than for the P/E model. Finally, in December 2002, both models indicated that the stock price had come back largely within the confidence interval. financial markets, stock prices, stock market, usa, united states, econometrics, time-series models, <b>forecast,</b> <b>forecasting...</b>|$|E
30|$|The above {{citations}} make {{it clear}} that when the aim is on air pollution <b>forecasting,</b> any <b>forecast</b> model ought to be better than the pure persistence <b>forecast</b> (i.e. <b>forecasting</b> for tomorrow what occurred today).|$|R
40|$|This study investigates four {{properties}} of earnings <b>forecasts</b> made by financial analysts {{to determine if}} systematic differences in these properties exists failing and healthy firms. The four properties are: The level of <b>forecasts,</b> <b>forecast</b> error, <b>forecast</b> bias, and <b>forecast</b> dispersion. Measures reflecting the four properties are used in models to distinguish failing and healthy firms and predict future bankruptcy. Results indicate that measures developed from analysts <b>forecasts</b> of future earnings can be exploited to distinguish failing from healthy firmsPrepared for: Chief of Naval Research, Arlington, VA. supported by the Foundation Research Program of the Naval Postgraduate School. [URL]...|$|R
40|$|This study {{investigated}} the magnitude of <b>forecast</b> improvements resulting from correction of inefficiencies in USDA cotton <b>forecasts</b> over 1999 / 00 to 2008 / 09 marketing years. The aspects of <b>forecast</b> performance {{included in this study}} were 1) bias and trends in bias, 2) correlation between <b>forecast</b> error and <b>forecast</b> level, 3) autocorrelation in <b>forecast</b> errors, 4) correlation in <b>forecast</b> revisions. Overall {{the results of this study}} demonstrated that some corrections of <b>forecast</b> inefficiencies, such as correction of correlation of error with <b>forecast</b> levels and correlation of error with previous year’s error resulted in consistent improvement of USDA cotton <b>forecasts,</b> while correction for correlation in <b>forecast</b> revisions did not benefit the <b>forecasts.</b> Correction for bias yielded mixed results likely because USDA has already been applying those corrections to some of the categories and thus our analysis resulted in over-correcting. The framework developed in this study can be used by USDA and other agencies to monitor and improve the performance of their <b>forecasts.</b> Commodity, <b>Forecast</b> evaluation, Fixed-event <b>forecasts,</b> Government <b>forecasting,</b> <b>Forecast</b> improvement, Agribusiness, Demand and Price Analysis, E 37, E 3, Q 13,...|$|R
50|$|During the eighties, {{the number}} of {{students}} enrolled in post-secondary studies once again exceeded the <b>forecasts.</b> <b>Forecast</b> for 1986 was 100,000 students in the colleges - actual number: 160,000. In the universities - forecast: 90,000 student, and the actual number of enrollments were 115,000.|$|R
40|$|In {{this paper}} we use multi-horizon {{evaluation}} techniques to produce monthly inflation <b>forecasts</b> {{for up to}} twelve months ahead. The <b>forecasts</b> are based on individual seasonal time series models that consider both, deterministic and stochastic seasonality, and on disaggregated Consumer Price Index (CPI) data. After selecting the best <b>forecasting</b> model for each index, we compare the individual <b>forecasts</b> to <b>forecasts</b> produced using two methods that aggregate hierarchical time series, the bottom-up method and an optimal combination approach. Applying these techniques to 16 indices of the Mexican CPI, {{we find that the}} best <b>forecasts</b> for headline inflation are able to compete with those taken from surveys of experts. Aggregated <b>forecasts</b> Bottom-up <b>forecasting</b> <b>Forecast</b> combination Hierarchical time series Inflation targeting Seasonal unit roots...|$|R
50|$|Tropical cyclone <b>forecasting</b> is {{the science}} of <b>forecasting</b> where a {{tropical}} cyclone's center, and its effects, {{are expected to be}} {{at some point in the}} future. There are several elements to tropical cyclone forecasting: track <b>forecasting,</b> intensity <b>forecasting,</b> rainfall <b>forecasting,</b> storm surge, tornado, and seasonal <b>forecasting.</b> While skill is increasing in regard to track <b>forecasting,</b> intensity <b>forecasting</b> skill remains nearly unchanged over the past several years. Seasonal <b>forecasting</b> began in the 1980s in the Atlantic basin and has spread into other basins in the years since.|$|R
50|$|In {{statistics}} and management science, a tracking signal monitors any <b>forecasts</b> {{that have been}} made in comparison with actuals, and warns when there are unexpected departures of the outcomes from the <b>forecasts.</b> <b>Forecasts</b> can relate to sales, inventory, or anything pertaining to an organization’s future demand.|$|R
50|$|TV Climatempo is a Brazilian TV channel specialising in weather <b>forecasts.</b> <b>Forecasts</b> {{are shown}} {{for more than}} 100 cities there is a five-day <b>forecast</b> for the capital. At {{the bottom of the}} screen, there is {{up-to-date}} information on what is happening in other cities, such as the relative humidity.|$|R
500|$|Tropical cyclone <b>forecasting</b> is {{the science}} of <b>forecasting</b> where a {{tropical}} cyclone's center, and its effects, {{are expected to be}} {{at some point in the}} future. [...] There are several elements to tropical cyclone forecasting: [...] track <b>forecasting,</b> intensity <b>forecasting,</b> rainfall <b>forecasting,</b> storm surge, tornado, and seasonal <b>forecasting.</b> [...] While skill is increasing in regard to track <b>forecasting,</b> intensity <b>forecasting</b> skill remains nearly unchanged over the past several years. [...] Seasonal <b>forecasting</b> began in the 1980s in the Atlantic basin and has spread into other basins in the years since.|$|R
5000|$|An Introduction to Econometric <b>Forecasting</b> and <b>Forecasting</b> Models (1980) ...|$|R
40|$|I {{investigate}} whether management earnings <b>forecasts</b> fully reflect {{the implications of}} accruals for future earnings. I find that managers overestimate accrual persistence in range <b>forecasts</b> but not in point <b>forecasts</b> and that managers' accrual-related <b>forecast</b> bias in range <b>forecasts</b> increases with <b>forecast</b> range and <b>forecast</b> horizon. My results suggest that managers overestimate accrual persistence when faced with greater difficulty <b>forecasting</b> earnings. Moreover, I find that managers' accrual-related <b>forecast</b> bias in range <b>forecasts</b> is somewhat affected by managerial opportunism and fear of litigation. Finally, I find accrual mispricing for firms issuing range <b>forecasts</b> but not for firms issuing point <b>forecasts.</b> Accruals Persistence Management <b>forecasts</b> <b>Forecast</b> errors...|$|R
40|$|Abstract- This paper {{contains}} {{short term}} monthly <b>forecasts</b> {{of crude oil}} prices using compumetric methods. Compumetric <b>forecasting</b> methods are ones that use computers to identify the underlying model that produces the <b>forecast.</b> Typically, <b>forecasting</b> models are designed or specified by humans rather than machines. Compumetric methods are applied to determine whether models they provide produce reliable <b>forecasts.</b> <b>Forecasts</b> produced by two compumetric methods – genetic programming and artificial neural networks – are compared and evaluated relative to a random walk type of prediction. The results suggest that genetic programming has advantage over random walk predictions while the neural network <b>forecast</b> proved inferior. ...|$|R
40|$|This paper {{compares the}} {{performance}} of different <b>forecasting</b> models of California house prices. Multivariate, theory-driven models are able to outperform a theoretical time series models across a battery of <b>forecast</b> comparison measures. Error correction models were best able to predict the {{turning point in the}} housing market, whereas univariate models were not. Similarly, even after the turning point occurred, error correction models were still able to outperform univariate models based on MSFE, bias, and <b>forecast</b> encompassing statistics and tests. These results highlight the importance of incorporating theoretical economic relationships into empirical <b>forecasting</b> models. house prices, <b>forecasting,</b> <b>forecast</b> comparison, <b>forecast</b> encompassing...|$|R
5000|$|... 1969: [...] "New {{organizational}} {{forms for}} <b>forecasting.</b> Technological <b>Forecasting,</b> 1(2), 151-161.|$|R
30|$|Because {{there are}} three outcome classes, {{there are three}} such figures. Figure 3 shows the results when an arrest for a violent crime is <b>forecasted.</b> <b>Forecasting</b> {{importance}} for each predictor is shown. For example, {{when the number of}} prison misconduct charges is shuffled, accuracy declines approximately 4 percentage points (e.g., from 60 % accurate to 56 % accurate).|$|R
40|$|The Australian Bureau of Meteorology has a {{requirement}} for complex and evolving systems to manage its weather <b>forecasting,</b> monitoring and alerts. This paper describes an agent-based system that monitors in real time the current terminal area <b>forecasts</b> (<b>forecasts</b> for areas around airports) and alerts forecasters to inconsistencies between these and observations obtained from automatic weather station data...|$|R
40|$|The {{purpose of}} this {{research}} is to <b>forecast</b> the number of hotel’s guests in Demak using Support Vector Regression. Support Vector Regression (SVR) is method used for <b>forecasting.</b> <b>Forecasting</b> the number of hotel’s guests in Demak using SVR produce good accuracy for <b>forecasting</b> the training and testing data. <b>Forecasting</b> for the training data generate MAPE value of 10. 2806...|$|R
40|$|We {{develop a}} system that {{provides}} model-based <b>forecasts</b> for inflation in Norway. <b>Forecasts</b> are recursively evaluated from 1999 to 2008. The performance of the models over this period is then used to derive weights {{that are used to}} combine the <b>forecasts.</b> Our results indicate that model combination improves upon the point <b>forecasts</b> from individual models. Furthermore, when comparing the whole <b>forecasting</b> period; model combination outperforms Norges Banks own point <b>forecast</b> for inflation at the <b>forecast</b> horizon up to a year. By using a suite of models we allow for a greater range of modelling techniques and data {{to be used in the}} <b>forecasting</b> process. <b>Forecasting,</b> <b>forecast</b> combination...|$|R
40|$|Judgement based <b>forecasts</b> {{are widely}} used in {{practice}} either alone or in conjunction with computer prepared <b>forecasts.</b> This study empirically examines the improvement in accuracy which can be gained from combining judgemental <b>forecasts,</b> either with other judgemental or with quantitatively derived <b>forecasts.</b> Two judgemental <b>forecasting</b> approaches are used by each of two different groups in a laboratory setting to give four sets of judgemental <b>forecasts</b> for the 68 monthly time series of the M-competition. These are combined either with each other or with <b>forecasts</b> from deseasonalised single exponential smoothing. Combined <b>forecasts</b> {{are found to be}} more accurate than single <b>forecasts</b> with the greatest benefit realised at short <b>forecast</b> horizons and for easier (as opposed to harder) <b>forecast</b> series. Averaging was observed to be a far better way of combining judgemental <b>forecasts</b> than a judgemental, nonsystematic combination. combining <b>forecasts,</b> judgemental <b>forecasting,</b> <b>forecasting</b> accuracy, extrapolation...|$|R
50|$|As {{mentioned}} in the introduction, the purpose of teletraffic theory is to reduce cost in telecommunications networks. An important tool in achieving this goal is <b>forecasting.</b> <b>Forecasting</b> allows network operators to calculate the potential cost of a new network / service for a given QoS during the planning and design stage, thereby ensuring that costs are kept to a minimum.|$|R
50|$|Foresight publishes peer-reviewed {{articles}} {{written by}} academics and business forecasters on topics including design {{and management of}} <b>forecasting</b> processes, <b>forecasting</b> models, integrating <b>forecasting</b> into business planning, sales <b>forecasting,</b> prediction markets, reviews of <b>forecasting</b> tools and books, sales and operations planning (S&OP), improving <b>forecasting</b> accuracy, and demand <b>forecasting.</b>|$|R
40|$|This study {{examines}} {{the ability of}} economists to <b>forecast</b> ten major economic series. The {{data for this study}} were provided by J. A. Livingston of the Philadelphia Inquirer, who since 1947 has collected <b>forecasts</b> for the upcoming 6 and 12 months. The results reveal that, in general, for the period from 1947 through 1978, the economists in Livingston's sample did not produce efficient <b>forecasts</b> and were not able to outperform simple statistical models. It should be noted, however, that a substantial and consistent improvement in <b>forecasting</b> performance by economists in Livingston's sample did occur over this same period. These results contain important information for managers who use macro-economic consensus <b>forecasts.</b> consensus <b>forecasts,</b> macro-economic variables, efficient <b>forecasts,</b> <b>forecast</b> errors...|$|R
40|$|Abstract: This article {{reviews the}} common used <b>forecast</b> error {{measurements}}. All error measurements have been {{joined in the}} seven groups: absolute <b>forecasting</b> errors, measures based on percentage errors, symmetric errors, measures based on relative errors, scaled errors, relative measures and other error measures. The formulas are presented and drawbacks are discussed for every accuracy measurements. To reduce the impact of outliers, an Integral Normalized Mean Square Error have been proposed. Due {{to the fact that}} each error measure has the disadvantages that can lead to inaccurate evaluation of the <b>forecasting</b> results, it is impossible to choose only one measure, the recommendations for selecting the appropriate error measurements are given. Key words: <b>Forecasting</b> <b>Forecast</b> accuracy <b>Forecast</b> error measurements (m...|$|R
40|$|Density <b>forecasts</b> {{have become}} {{important}} in finance {{and play a}} key role in modern risk management. Using a flexible density <b>forecast</b> evaluation framework that extends the Berkowitz likelihood ratio test this paper evaluates in- and out-of-sample density <b>forecasts</b> of daily returns on the DAX, ATX and S&P 500 stock market indices from models of financial returns that are currently widely used in the financial industry. The results indicate that GARCH-t models produce good in-sample <b>forecasts.</b> No model considered in this study delivers fully acceptable out-of-sample <b>forecasts.</b> The empirical findings emphasize that proper distributional assumptions combined with an adequate specification of relevant conditional higher moments are necessary to obtain good density <b>forecasts.</b> Density <b>forecasting,</b> <b>forecast</b> evaluation, risk management, GARCH models,...|$|R
40|$|The {{economic}} <b>forecasts</b> for Germany in {{the period}} 2001 to 2003 grossly missed reality. Forecasters estimated an average annual growth rate of 1. 6 per cent, but real GDP actually grew by only 0. 3 per cent per annum. In 2003 the real GDP in Germany even shrank by 0. 1 per cent. Forecasters tend to be generally optimistic. The analysis of the <b>forecasts</b> in the years 1995 to 2004 shows nevertheless that they were for the most years fairly accurate. In addition, the article gives several arguments which may explain <b>forecast</b> errors: data revisions, unpredictable events, behavioural and political feedback and imitation behaviour of forecasters. <b>Forecasting,</b> <b>Forecast</b> evaluation, <b>Forecast</b> error, Business cycles, Germany...|$|R
50|$|On Foxtel and Austar digital services, an {{interactive}} weather service is available. It provides local weather information, such as current conditions, marine and surf reports, dam information, 28-day rain <b>forecast,</b> capital city <b>forecast</b> and <b>forecasts</b> for the user's postcode. It {{also provides a}} state radar, national satellite and national lightning tracker.|$|R
40|$|Volatility is an {{important}} variable in financial <b>forecasting.</b> <b>Forecasting</b> volatility requires a development of a suitable model for it. In this paper, we examine different time series models for volatility modelling. Specifically, we will study the use of recurrent mixture density networks, GARCH and EGARCH models to model volatility. In addition, we demonstrate the impact of different factors on the accuracy and completeness {{of each of these}} models...|$|R
40|$|This paper {{studies the}} error in <b>forecasting</b> a dynamic time series with a {{deterministic}} component. We show {{that when the}} data are strongly serially correlated, <b>forecasts</b> based on a model which detrends the data before estimating the dynamic parameters are much less precise than those based on an autoregression that includes the deterministic components. The local asymptotic distribution of the <b>forecast</b> errors under the two-step procedure exhibits bimodality, and the <b>forecasts</b> are conditionally median biased {{in a direction that}} depends on the order of the deterministic trend function. We explore the conditions under which feasible GLS detrending can lead to <b>forecast</b> error reduction. The finite sample properties of OLS and feasible GLS <b>forecasts</b> are compared with <b>forecasts</b> based on unit root pretesting. The procedures are applied to fifteen macroeconomic time series to obtain real time <b>forecasts.</b> <b>Forecasts</b> based on feasible GLS detrending tend to be more efficient than <b>forecasts</b> based on OLS detrending. Regardless of the detrending method, unit root pretests often improve <b>forecasts.</b> <b>forecasting,</b> trends, unit root, GLS detrending...|$|R
