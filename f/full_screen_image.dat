5|2232|Public
50|$|With every {{character}} you complete the arcade mode with {{you will receive}} a <b>full</b> <b>screen</b> <b>image</b> portraying your character as Cinderella alongside Ichiro. These can be viewed in the options menu.|$|E
50|$|There {{is also a}} {{separate}} story mode in which you as Ichiro go around the Imperial Theatre (similar to the FREE mode in the Sakura Wars games) along with your chosen partner playing random games of Columns against {{the other members of}} the Troupe. Just like the arcade mode, when completing the story mode, you are given a special <b>full</b> <b>screen</b> <b>image</b> of the character you completed the story with, which can be viewed in the option menu.|$|E
5000|$|From 1946 to 1951 the 7JP4 was {{a common}} CRT (Picture Tube or Kinescope) used in lower priced {{televisions}} sold in the United States. These television were popular for portable carry around and small table top sets. These smaller sets were direct view electrostatic deflection designs. This required an extremely large amount of voltage to produce an image across the full display screen. In 1946, RCA influenced manufacturers (with royalty free circuit designs) to move toward electromagnetic deflection type televisions. Electromagnetic deflection uses varying magnetic fields to produce a <b>full</b> <b>screen</b> <b>image.</b> Horizontal and vertical electromagnets are placed at the picture tube neck, called the [...] "yoke". This method allowed the image to be viewed on larger screens. The first heavily mass-produced large picture tube to use this newer method of deflection was RCA's 10BP4, introduced in 1946. Soon after electrostatic picture tubes and the television electronic design would be completely replaced.|$|E
5000|$|International Match Day is an {{improved}} version of Match Day published in 1985 for ZX Spectrum 128KB. It {{takes advantage of}} the extra memory available to provide better sound and some <b>full</b> <b>screen</b> <b>images.</b>|$|R
50|$|Only <b>full</b> <b>screen</b> <b>images</b> were {{supported}} and the program's main flaw was {{an inability to}} view the entirety of an image while working on it. A copy adapted for use with a mouse was bundled with the official mouse addon.|$|R
50|$|Many {{journals}} {{have adopted}} the JCBs guidelines on image manipulation in their instructions to authors, {{but only a few}} are enforcing them with <b>full</b> <b>screening</b> of all <b>images</b> for evidence of manipulation.|$|R
30|$|By default, {{the image}} {{recognition}} engine {{will use the}} <b>full</b> <b>screen</b> <b>image</b> as input for recognition. If the Object of Interest is far away and thus becomes too small in the camera view, a <b>full</b> <b>screen</b> <b>image</b> may include a lot of background which is not relevant to the Object of Interest. In this case image cropping can be enabled, displaying a green rectangle in which the app user can place the Object of Interest.|$|E
40|$|We {{propose a}} {{formalisation}} of visual languages which allows a uniform approach to satisfying {{the needs of}} pattern recognition, image generation, and visual reasoning faced in visual human-computer communication. Such needs comprise managing the <b>full</b> <b>screen</b> <b>image</b> as seen on the computer display, handling interpretation of icons even when ambiguous, or generating multiple representations to convey one same meaning as required by different users for diverse tasks. We also formalise the way the machine associates a computational meaning with an image (including the whole screen image), and conversely, the way it generates an image on the screen from a computation. A definition of visual sentence as interpreted image is proposed, and the visual language {{is viewed as a}} set of visual sentences in a user-computer dialogue. Examples of how the proposed formalism is suitable for ambiguity control and multiple representations of meanings are provide...|$|E
40|$|Software {{documentation}} for {{the novice}} user typically {{must try to}} achieve at least three goals: to support basic knowledge and skills development; to prevent or support the handling of mistakes, and to support the joint handling of manual, input device and screen. This paper concentrates on the latter goal. Novice users often experience split-attention problem due {{to the need to}} (almost) simultaneously attend to different media. Existing research indicates that split-attention problems can be prevented or reduced by the presence of <b>screen</b> <b>images</b> in the manual. Research is yet unclear about the optimal design of these pictures. This study examines three design styles. Forty-eight novice users received one of the three manual based on these styles. The manuals were an introduction to Windows 95. The users of the most successful manual needed 25 % less training time and had a 60 % better retention. The most important characteristics of the design style of this manual were its use of <b>full</b> <b>screen</b> <b>images</b> (instead of partial ones) and a two-column lay-out in which the instructions and <b>screen</b> <b>images</b> were presented side-by-side in a left-to-right reading order. The discussion focuses on the tension that exists between theory and practice. Special attention is given to the contributions of a taxonomy of <b>screen</b> <b>images</b> and cognitive load theory...|$|R
50|$|The {{style of}} the images {{produced}} by Poag were unusual {{in terms of their}} geometric qualities. Appearing to repeat seamlessly along all four edges, PROPAGANDA images became attractive for use in 3D modeling, and particularly for use as desktop wallpaper, in that limitations in graphics hardware at the time often prevented users from using <b>full</b> <b>screen</b> 24-bit <b>images.</b> Using smaller, tileable images for desktop backgrounds helped keep memory utilization to a minimum, while still allowing early Linux desktops to be visually appealing.|$|R
5000|$|The LOE is a {{patented}} [...] {{optical waveguide}} that {{makes use of}} multiple partial reflectors embedded in a single substrate to reflect a virtual image into {{the eye of the}} wearer. Specifically, the image is coupled into the LOE by a [...] "Pod" [...] (micro-display projector) that sits {{at the edge of the}} waveguide—in an eyeglass configuration, this is embedded in the temple of the glasses. The image travels through total internal reflection to the multiple array of partial reflectors and are reflected to the eye. While each partial reflector shows only a portion of the image, the optics are such that the wearer sees the combined array and perceives it as a single uniform image projected at infinity. The transparent display enables a virtual image to be seamlessly overlaid over the wearer's real world view. This is especially true when the source image comprises a black background with light color wording or symbology being displayed. Black is essentially see-through color, while lighter colored objects, symbols or characters appear to float in the wearer's line of sight. Conversely, <b>full</b> <b>screen</b> <b>images</b> like documents, internet pages, movies which are typically brighter colors can be displayed to look like a large virtual image floating a few meter's away from the wearer.|$|R
40|$|Our {{project is}} {{designed}} to offer flexibility, easy expandability and high performance. We use standard personal computer hardware to run our multithreaded software. A frame grabber card is used to capture video signals from medical imaging systems. A modular, user-defined process chain performs arbitrary manipulations on the image data. The graphical user interface offers configuration options and displays the processed image in either window or <b>full</b> <b>screen</b> mode. <b>Image</b> source and processing routines are encapsulated in dynamic library modules for easy functionality extension without recompilation of the entire software framework. Documented template modules for sources and processing steps {{are part of the}} software’s source code. ...|$|R
40|$|Plenoptic cameras, {{constructed}} with internal microlens arrays, capture both spatial and angular information, i. e., the full four-dimensional radiance, of a scene. The design of traditional plenoptic cameras assumes that each microlens image is completely defocused {{with respect to}} the image created by the main camera lens. As a result, only a single pixel in the final image is rendered from each microlens image, resulting in disappointingly low resolution. A recently developed alternative approach based on the focused plenoptic camera uses the microlens array as an imaging system focused on the image plane of the main camera lens. The flexible spatio-angular tradeoff that becomes available with this design enables rendering of final images with significantly higher resolution than those from traditional plenoptic cameras. In this paper we analyze the focused plenoptic camera in optical phase space and present a series of rendering algorithms for producing high-quality high-resolution images. We also present our GPU-based implementations of these algorithms, which are able to render <b>full</b> <b>screen</b> refocused <b>images</b> in real time. a...|$|R
40|$|Imaging {{technology}} is highly important in today’s medical environments. It provides information {{upon which the}} accuracy of the diagnosis and consequently the wellbeing of the patient rely. Increasing the quality and significance of medical image data is therefore one the aims of scientific research and development. We introduce an integrated hardware and software framework for real time image processing in medical environments, which we call RealTimeFrame. Our project is designed to offer flexibility, easy expandability and high performance. We use standard personal computer hardware to run our multithreaded software. A frame grabber card is used to capture video signals from medical imaging systems. A modular, user-defined process chain performs arbitrary manipulations on the image data. The graphical user interface offers configuration options and displays the processed image in either window or <b>full</b> <b>screen</b> mode. <b>Image</b> source and processing routines are encapsulated in dynamic library modules for easy functionality extension without recompilation of the entire software framework. Documented template modules for sources and processing steps are part of the software’s source code. </p...|$|R
40|$|The {{technological}} pluralism is {{an important}} challenge of the twenty-first century. A template is a computer document which has a basic format. It can be used many different times. A template is also a system that helps the source to arrange information on a computerscreen. Most web pages on web sites are based on template which is a file {{that serves as a}} starting point for a new document. The television templates also consist of interesting page transitions, easy-to-use content management systems, drop down menus, photo galleries, custom fonts, <b>full</b> <b>screen</b> background <b>images,</b> contact us forms, Google maps, social networking icons, rollover effects, photo galleries and so on. The users can click the link, and the item content displays within the context of its associated Portal Template. The portal templates for items are created through the same wizard that is used for creating Portal Templates for pages. The television templates are designed to deliver video but are equally suitable for photos or other multimedia. The television templates also offer a thoughtful arrangement of elements and color, fonts, effects, style, and layout to your plain slides via our templates. The television news channels adopt the new innovative customization of TV template evaluated by channels. The television templates facilitate better understanding and appreciation of the product and project requirements among the audience. The television templates basically include website templates, flash templates, e-commerce templates, Facebook templates, responsive templates and other templates which include amazing features...|$|R
40|$|The {{described}} {{project is}} an iPhone application {{to control a}} robot using the accelerometer and the touch screen of the mobile device. The iPhone and the robot are connected over WiFi. The application interface displays <b>full</b> <b>screen</b> real time <b>images</b> coming from the robot vision system, allowing remote driving of the robot. We implemented 2 different driving modes and interactions: the first one fully exploits the accelerometer to move the robot forward and backward and to change direction, the second one uses the interface buttons for forward and backward movements, while the accelerometer is used only to change direction. In both driving modes {{there is the possibility}} to control the robot's mechanical arm to take and release an object through two touchscreen buttons. We carried on several user tests in order to validate and enhance our design. In fact, based on the test results, we could improve the interface as well as the driving experience (e. g. we could tune the correct power to drive the gearmotors of the robot {{as a function of the}} device inclination and the pressing duration of the interface controls). Users that tested the final version could smoothly drive the robot along a route with obstacles. © 2012 Authors...|$|R
5000|$|<b>Full</b> <b>screen</b> support, with {{automatic}} text and images resizing to fit <b>full</b> <b>screen.</b>|$|R
50|$|<b>Full</b> <b>Screen</b> Picture Caller ID - See <b>FULL</b> <b>SCREEN</b> profile {{pictures}} & status messages as caller ID {{every time}} you make or receive a call.|$|R
50|$|Video card RAM is {{necessary}} to keep the entire <b>screen</b> <b>image</b> in memory. The CPU sends its data to the video card. The video processor forms {{a picture of the}} <b>screen</b> <b>image</b> and stores it in the frame buffer. This picture is a large bitmap. It is used to continually update the <b>screen</b> <b>image.</b>|$|R
5000|$|The green [...] "zoom" [...] {{button on}} windows {{now has a}} {{different}} function in applications that support <b>full</b> <b>screen</b> mode. Instead of simply enlarging the window, the button now enters <b>full</b> <b>screen</b> mode, eliminating the <b>full</b> <b>screen</b> button at the top right corner of windows that has been present since Mac OS X Lion. However, holding the Option key (⌥) while clicking the zoom button or double-clicking on the window chrome continues to invoke the original behavior.|$|R
40|$|Abstract In this paper, a {{weighted}} value wrinkle detection method is suggested {{based on the}} analysis on the entire facial features such as face contour, face size, eyes and ears. Firstly, the main facial elements are detected with AAM method entirely from the input <b>screen</b> <b>images.</b> Such elements {{are mainly composed of}} shape-based and appearance methods. These are used for learning the facial model and for matching the face from new <b>screen</b> <b>images</b> based on the learned models. Secondly, the face and background are separated in the <b>screen</b> <b>image.</b> Four points with the biggest possibilities for wrinkling are selected from the face and high wrinkle weighted values are assigned to them. Finally, the wrinkles are detected by applying Canny edge algorithm for the interested points of weighted value. The suggested algorithm adopts various <b>screen</b> <b>images</b> for experiment. The experiments display the excellent results of face and wrinkle detection in the most of the <b>screen</b> <b>images...</b>|$|R
50|$|In 3D {{rendering}} {{applications such}} as video games, common <b>full</b> <b>screen</b> effects include color filters, depth of field, and <b>full</b> <b>screen</b> bloom. A color filter, for example, may desaturate an image or convert it to grayscale. These effects are usually achieved via GPU shaders.|$|R
40|$|In this paper, {{we propose}} {{a simple and}} {{effective}} scheme for <b>screen</b> <b>image</b> scaling, targeting at real-time applications like remote desktop and screen sharing. To balance visual quality and complexity, we build our scheme upon bilinear interpolation and devise a content adaptive post-processing method. Our scheme keeps the text/graphics regions of <b>screen</b> <b>images</b> as sharp as the original while avoiding magnifying noise and artifacts in the picture regions. Further, the involved operations are quite suitable for hardware acceleration. When implemented on commodity GPUs, our scheme achieves a frame rate more than 300 fps, which is fast enough for practical use. Index Terms — <b>Screen</b> <b>image,</b> image scaling, GPU 1...|$|R
50|$|Microsoft Magnifier, an {{accessibility}} utility for {{low vision}} users has been dramatically improved. Magnifier now supports the <b>full</b> <b>screen</b> zoom feature, whereas previous Windows versions had the Magnifier {{attached to the}} top of the screen in a dock layout. The new <b>full</b> <b>screen</b> feature is enabled by default, however, it requires Windows Aero for the advantage of the <b>full</b> <b>screen</b> zoom feature. If Windows is set to the Windows 7 Basic, Windows Classic, or High Contrast themes, Magnifier will still function like it did in Windows Vista and earlier.|$|R
5000|$|Internet kiosk : <b>Full</b> <b>screen,</b> toolbar management, white/blacklist management.|$|R
5000|$|Improve permissions UI {{related to}} <b>full</b> <b>screen</b> {{keyboard}} access ...|$|R
5000|$|Aspect ratio: 16:9, Widescreen - Aspect Ratio 4:3, <b>Full</b> <b>Screen</b> ...|$|R
5000|$|... #Caption: Open-Sankoré 1.4 {{running on}} Windows 7 in <b>full</b> <b>screen</b> ...|$|R
50|$|It also {{includes}} <b>full</b> <b>screen</b> mode, which only displays the text.|$|R
5000|$|... 2004: Paramount (<b>Full</b> <b>Screen</b> Collection), Region 1 DVD, November 30, 2004 ...|$|R
5000|$|Split <b>screen</b> and <b>full</b> <b>screen</b> modes {{for easy}} {{navigation}} and viewing ...|$|R
50|$|There {{are three}} page layouts: Book, <b>Full</b> <b>Screen,</b> and Scroll. In Book or <b>Full</b> <b>Screen</b> layout, pages are turned by tapping or {{dragging}} the page, animated {{to imitate the}} appearance of a paper book. In Scroll, there is no page turning, and the book appears as continuous text, read vertically like a web browser.|$|R
5000|$|Framebuffer - the {{computer}} memory used to store a <b>screen</b> <b>image</b> ...|$|R
50|$|The game {{takes place}} in a <b>full</b> <b>screen,</b> <b>full</b> motion video, first-person perspective, and the player has to move quickly to launch {{missiles}} at enemy aircraft.|$|R
5|$|In 1983, it was {{released}} on LaserDisc by MGM in <b>full</b> <b>screen.</b>|$|R
5000|$|... "Single + Swiping" [...] - TV Docu-series (<b>Full</b> <b>Screen</b> Media Network) (2016) ...|$|R
