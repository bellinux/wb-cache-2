10000|2064|Public
5|$|Grid {{computing}} is {{the most}} distributed form of parallel computing. It makes use of computers communicating over the Internet {{to work on a}} given problem. Because of the low bandwidth and extremely high latency available on the Internet, <b>distributed</b> <b>computing</b> typically deals only with embarrassingly parallel problems. Many <b>distributed</b> <b>computing</b> applications have been created, of which SETI@home and Folding@home are the best-known examples.|$|E
5|$|When used together, these {{features}} allow for assembling a complex <b>distributed</b> <b>computing</b> environment by reusing the existing hierarchical name system.|$|E
5|$|Xgrid is a {{proprietary}} program and <b>distributed</b> <b>computing</b> protocol {{developed by the}} Advanced Computation Group subdivision of Apple Inc that allows networked computers {{to contribute to a}} single task.|$|E
3000|$|... “A horizontal, {{system-level}} {{architecture that}} <b>distributes</b> <b>computing,</b> storage, control and networking functions {{closer to the}} users along a cloud-to-thing continuum”.|$|R
500|$|There {{are several}} <b>distributed</b> <b>computed</b> {{projects}} which have study areas {{similar to those}} of Rosetta@home, but differ in their research approach: ...|$|R
50|$|Recently, IBM {{has been}} {{exploring}} ways to <b>distribute</b> <b>computing</b> power more efficiently by mimicking the distributional {{properties of the}} human brain.|$|R
5|$|In 2007, Guinness World Records {{recognized}} Folding@home as {{the most}} powerful <b>distributed</b> <b>computing</b> network. As of September 30, 2014, the project has 107,708 active CPU cores and 63,977 active GPUs for a total of 40.190 x86 petaFLOPS (19.282 native petaFLOPS). At the same time, the combined efforts of all <b>distributed</b> <b>computing</b> projects under BOINC totals 7.924 petaFLOPS. In November 2012, Folding@home updated its accounting of FLOPS, especially for GPUs, and now reports the number of active processor cores and physical processors. Using the Markov state model method, Folding@home achieves strong scaling across its user base and gains a linear speedup for every added processor. This network allows Folding@home to do work that was formerly impractical computationally.|$|E
5|$|Watson uses IBM's DeepQA {{software}} and the Apache UIMA (Unstructured Information Management Architecture) framework. The system {{was written in}} various languages, including Java, C++, and Prolog, and runs on the SUSE Linux Enterprise Server 11 operating system using the Apache Hadoop framework to provide <b>distributed</b> <b>computing.</b>|$|E
5|$|Folding@home {{uses the}} Cosm {{software}} libraries for networking. Folding@home was launched on October1, 2000, {{and was the}} first <b>distributed</b> <b>computing</b> project aimed at bio-molecular systems. Its first client was a screensaver, which would run while the computer was not otherwise in use. In 2004, the Pande lab collaborated with David P. Anderson to test a supplemental client on the open-source BOINC framework. This client was released to closed beta in April 2005; however, the method became unworkable and was shelved in June 2006.|$|E
5000|$|There {{are several}} <b>distributed</b> <b>computed</b> {{projects}} which have study areas {{similar to those}} of Rosetta@home, but differ in their research approach: ...|$|R
50|$|This edition is the Developer Edition which {{includes}} TaveRNA. The TaveRNA Project aims {{to provide a}} language and software tools to facilitate easy use of workflow and <b>distributed</b> <b>compute</b> technology.|$|R
50|$|By {{partitioning}} {{input data}} and using parallelizable skeletons to process partitions the interpreter can exploit data parallelism {{even if the}} integrated tools are single-threaded. Workflows can be executed also in <b>distributed</b> <b>compute</b> environments.|$|R
5|$|In March 2002, Google cofounder Sergey Brin {{launched}} Google Compute as an add-on for the Google Toolbar. Although {{limited in}} function and scope, it increased participation in Folding@home from 10,000, {{up to about}} 30,000 active CPUs. The program ended in October 2005, {{in favor of the}} official Folding@home clients, and is no longer available for the Toolbar. Folding@home also gained participants from Genome@home, another <b>distributed</b> <b>computing</b> project from the Pande lab and a sister project to Folding@home. The goal of Genome@home was protein design and associated applications. Following its official conclusion in March 2004, users were asked to donate computing power to Folding@home instead.|$|E
5|$|In November 2006, first-generation {{symmetric}} multiprocessing (SMP) clients were publicly released for open beta testing, {{referred to as}} SMP1. These clients used Message Passing Interface (MPI) communication protocols for parallel processing, as {{at that time the}} GROMACS cores were not designed to be used with multiple threads. This was the first time a <b>distributed</b> <b>computing</b> project had used MPI. Although the clients performed well in Unix-based operating systems such as Linux and macOS, they were troublesome under Windows. On January24, 2010, SMP2, the second generation of the SMP clients and the successor to SMP1, was released as an open beta and replaced the complex MPI with a more reliable thread-based implementation.|$|E
5|$|Of all {{the major}} <b>distributed</b> <b>computing</b> {{projects}} involved in protein research, Folding@home {{is the only one}} not using the BOINC platform. Both Rosetta@home and Folding@home study protein misfolding diseases such as Alzheimer's disease, but Folding@home does so much more exclusively. Folding@home almost exclusively uses all-atom molecular dynamics models to understand how and why proteins fold (or potentially misfold, and subsequently aggregate to cause diseases). In other words, Folding@home's strength is modeling the process of protein folding, while Rosetta@home's strength is computing protein design and predicting protein structure and docking.|$|E
5000|$|HPE Helion CloudSystem, an {{integrated}} Infrastructure-as-a-Service and Platform-as-a-Service offering combining HPE Helion OpenStack and HPE Helion Stackato with HPE Proliant server hardware {{based on a}} particular use-case, such as <b>distributed</b> <b>compute</b> or <b>distributed</b> object storage. CloudSystem 10 launched in September 2016.|$|R
30|$|Qian He {{was born}} in 1979. He {{received}} his PhD in Beijing University of Posts and Telecommunications, Beijing, China, in 2011. He is currently a professor at Guilin University of Electronic Technology. His research interests lie in network security and <b>distribute</b> <b>computing.</b>|$|R
5000|$|The Terascale Open-source Resource and QUEue Manager (TORQUE) is a {{distributed}} resource manager providing {{control over}} batch jobs and <b>distributed</b> <b>compute</b> nodes. TORQUE can integrate with the non-commercial Maui Cluster Scheduler or the commercial Moab Workload Manager to improve overall utilization, scheduling and administration on a cluster.|$|R
5|$|Parallel {{computing}} {{is closely}} related to concurrent computing—they are frequently used together, and often conflated, though the two are distinct: it is possible to have parallelism without concurrency (such as bit-level parallelism), and concurrency without parallelism (such as multitasking by time-sharing on a single-core CPU). In parallel computing, a computational task is typically broken down in several, often many, very similar subtasks that can be processed independently and whose results are combined afterwards, upon completion. In contrast, in concurrent computing, the various processes often do not address related tasks; when they do, as is typical in <b>distributed</b> <b>computing,</b> the separate tasks may have a varied nature and often require some inter-process communication during execution.|$|E
5|$|Portal 2 is a first-person puzzle-platform {{video game}} {{developed}} {{and published by}} Valve Corporation. It is the sequel to Portal (2007) and was released on April 19, 2011 for Microsoft Windows, OS X, Linux, PlayStation 3, and Xbox 360. The retail versions of the game were published by Electronic Arts, while online distribution of the PC versions is handled by Valve's content delivery service Steam. Portal 2 was announced in March 2010, following a week-long alternate reality game based on new patches to the original game. Before the game's release on Steam, the company released the Potato Sack, a second multi-week alternate reality game, involving 13 independently developed titles which culminated in a <b>distributed</b> <b>computing</b> spoof to release Portal 2 several hours early.|$|E
5|$|Rosetta@home is a <b>distributed</b> <b>computing</b> project {{aimed at}} protein {{structure}} prediction {{and is one}} of the most accurate tertiary structure predictors. The conformational states from Rosetta's software can be used to initialize a Markov state model as starting points for Folding@home simulations. Conversely, structure prediction algorithms can be improved from thermodynamic and kinetic models and the sampling aspects of protein folding simulations. As Rosetta only tries to predict the final folded state, and not how folding proceeds, Rosetta@home and Folding@home are complementary and address very different molecular questions.|$|E
5000|$|... the {{integration}} of <b>distributed,</b> heterogeneous <b>computing</b> environments, and ...|$|R
40|$|<b>Distributed</b> {{adaptive}} <b>computing</b> systems (ACS) allow {{developers to}} design applications using multiple programmable devices. The ACS API, an API created for <b>distributed</b> adaptive <b>computing,</b> gives developers {{the ability to}} design scalable ACS systems in a cluster networking environment for large applications. One such application, found {{in the field of}} bioinformatics, is the DNA sequence alignment problem. This thesis presents a runtime reconfigurable FPGA implementation of the Smith-Waterman similarity comparison algorithm. Additionally, this thesis presents tools designed for the ACS API that assist developers creating applications in a heterogeneous <b>distributed</b> adaptive <b>computing</b> environment...|$|R
40|$|Python {{interface}} to the Xenon middleware library, v. 2. 0. Xenon {{provides a}} simple programming interface to various pieces of software {{that can be}} used to access <b>distributed</b> <b>compute</b> and storage resources. Underneath it uses GRPC, to connect to the Xenon-GRPC service. We've taken care to mirror the original Java API in this Python module as much as possible...|$|R
5|$|Rosetta@home is a <b>distributed</b> <b>computing</b> {{project for}} protein {{structure}} prediction on the Berkeley Open Infrastructure for Network Computing (BOINC) platform, {{run by the}} Baker laboratory at the University of Washington. Rosetta@home aims to predict protein–protein docking and design new proteins {{with the help of}} about sixty thousand active volunteered computers processing at over 210 teraFLOPS on average as of July 29, 2016. Foldit, a Rosetta@Home videogame, aims to reach these goals with a crowdsourcing approach. Though much of the project is oriented toward basic research to improve the accuracy and robustness of proteomics methods, Rosetta@home also does applied research on malaria, Alzheimer's disease, and other pathologies.|$|E
5|$|Similarly {{to other}} <b>distributed</b> <b>{{computing}}</b> projects, Folding@home quantitatively assesses user computing {{contributions to the}} project through a credit system. All units from a given protein project have uniform base credit, which is determined by benchmarking one or more work units from that project on an official reference machine before the project is released. Each user receives these base points for completing every work unit, though {{through the use of}} a passkey they can receive added bonus points for reliably and rapidly completing units which are more demanding computationally or have a greater scientific priority. Users may also receive credit for their work by clients on multiple machines. This point system attempts to align awarded credit with the value of the scientific results.|$|E
5|$|The {{project has}} pioneered {{the use of}} {{graphics}} processing units (GPUs), PlayStation3s, Message Passing Interface (used for computing on multi-core processors), and some Sony Xperia smartphones for <b>distributed</b> <b>computing</b> and scientific research. The project uses statistical simulation methodology that is a paradigm shift from traditional computing methods. As part of the client–server model network architecture, the volunteered machines each receive pieces of a simulation (work units), complete them, and return them to the project's database servers, where the units are compiled into an overall simulation. Volunteers can track their contributions on the Folding@home website, which makes volunteers' participation competitive and encourages long-term involvement.|$|E
40|$|<b>Distributed</b> object <b>computing</b> {{forms the}} basis for nextgeneration {{application}} middleware. At the heart of <b>distributed</b> object <b>computing</b> are Object Request Brokers (ORBs), which automate many tedious and error-prone distributed programming tasks. This article presents {{a case study of}} key design patterns needed to develop ORBs that can be dynamically configured and evolved for specific application requirements and system characteristics...|$|R
5000|$|The ACE ORB - a CORBA {{implementation}} {{from the}} <b>Distributed</b> Object <b>Computing</b> (DOC) Group ...|$|R
50|$|BURP also {{refers to}} the {{volunteer}} and grid computing software BOINC, because BURP needs BOINC in order to <b>distribute</b> <b>computing</b> task among their users. BURP is free software distributed under the GNU General Public License V3 licence. Because BURP is {{used to refer to}} both BOINC project and BURP back-end software, some confusion can arise when talking about other services running the BURP software.|$|R
5|$|Xgrid's {{original}} concept can {{be traced}} back to Zilla.app, found in the OPENSTEP operating system, created by NeXT in the late 1980s. Zilla was the first <b>distributed</b> <b>computing</b> program released on an end-user operating system and which used the idle screen-saver motif, a design feature since found in widely used projects such as Seti@Home and Distributed.net. Zilla won the national Computerworld Smithsonian Award (Science Category) in 1991 for ease of use and good design. Apple acquired Zilla, along with the rest of NeXT, in 1997 and later used Zilla as inspiration for Xgrid. The first beta version of Xgrid was released in January 2004.|$|E
5|$|Folding@home (FAH or F@h) is a <b>distributed</b> <b>computing</b> {{project for}} disease {{research}} that simulates protein folding, computational drug design, {{and other types}} of molecular dynamics. The project uses the idle processing resources of thousands of personal computers owned by volunteers who have installed the software on their systems. Its main purpose is to determine the mechanisms of protein folding, which is the process by which proteins reach their final three-dimensional structure, and to examine the causes of protein misfolding. This is of significant academic interest with major implications for medical research into Alzheimer's disease, Huntington's disease, and many forms of cancer, among other diseases. To a lesser extent, Folding@home also tries to predict a protein's final structure and determine how other molecules may interact with it, which has applications in drug design. Folding@home is developed and operated by the Pande Laboratory at Stanford University, under the direction of Prof. Vijay Pande, and is shared by various scientific institutions and research laboratories across the world.|$|E
5|$|More {{than half}} of all known cancers involve {{mutations}} of p53, a tumor suppressor protein present in every cell which regulates the cell cycle and signals for cell death in the event of damage to DNA. Specific mutations in p53 can disrupt these functions, allowing an abnormal cell to continue growing unchecked, resulting in the development of tumors. Analysis of these mutations helps explain the root causes of p53-related cancers. In 2004, Folding@home was used to perform the first molecular dynamics study of the refolding of p53's protein dimer in an all-atom simulation of water. The simulation's results agreed with experimental observations and gave insights into the refolding of the dimer that were formerly unobtainable. This was the first peer reviewed publication on cancer from a <b>distributed</b> <b>computing</b> project. The following year, Folding@home powered a new method to identify the amino acids crucial for the stability of a given protein, which was then used to study mutations of p53. The method was reasonably successful in identifying cancer-promoting mutations and determined the effects of specific mutations which could not otherwise be measured experimentally.|$|E
40|$|Grid {{computing}} provides {{new techniques}} to solve for numerous complex problems. It is an inevitable trend {{to implement the}} <b>distributed</b> parallel <b>computing</b> of large-scale problems with the grid. This paper presents two implementations for <b>distributed</b> parallel <b>computing</b> on Globus Toolkit, a wide-used grid environment. The first implementation, Loosely Coupled Parallel Services is used to achieve the large-scale parallel computing that {{can be broken down}} into independent sub-jobs by using the corresponding implementation framework, and the second implementation, Grid MPI Parallel Program is able to deal with specialized applications, which can’t easily be split up into numerous independent chunks, by using the proposed implementation framework. We make a beneficial attempt to implement <b>distributed</b> parallel <b>computing</b> on grid computing environments...|$|R
50|$|The {{mission of}} the ACME Center for Research in Wireless Communication (ARWiC) is to conductd {{research}} in networking (core, wireless, sensors), mobile and pervasive <b>computing,</b> <b>distributed</b> and grid <b>computing,</b> cellular networks, and social networks.|$|R
40|$|The {{scheduling}} problem in <b>distributed</b> data-intensive <b>computing</b> environments {{has been an}} active research topic due to immense practical applications. In this paper, we model the {{scheduling problem}} for work-Flow applications in <b>distributed</b> Data-intensive <b>computing</b> environments (FDSP) and make an attempt to formulate and solve the problem using a particle swarm optimization approach. We illustrate the algorithm performance and trace its feasibility and effectiveness {{with the help of}} an example. 1...|$|R
