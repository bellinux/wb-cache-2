0|2459|Public
40|$|Coordinated {{orienting}} movements can be accurately performed without direct sensory control. Ocular saccades, for instance, {{have been}} shown to be reprogrammed after target disappearance when an intervening eye movement is electrically triggered before the saccade onset. Saccadic eye movements can also be executed toward memorized targets, even when the subject has been passively moved in darkness. Two hypotheses have been proposed to account for this goal-invariance property: either (i) the goal is reconstructed and memorized in the stable frame of reference linked to the environment ("allocentric, coordinates") or (ii) the goal is selected and memorized in the sensors-related maps ("egocentric coordinates") and is continuously updated by efferent copies of the motor commands. In this paper, we shall describe a formal neural network based on this second hypothesis. The results of the simulation show that target position can be memorized and accurately updated in a topologically ordered map, using a velocity-signal feedback. Moreover, this network has been submitted to a simple learning procedure by using the <b>intermittent</b> <b>visual</b> recurring afferent <b>signal</b> as the teaching signal. A similar mechanism could be involved in control of limb movement...|$|R
40|$|One- and two-way {{communication}} with digital compressed <b>visual</b> <b>signals</b> {{is now an}} integral part of the daily life of millions. Such commonplace use has been realized by decades of advances in <b>visual</b> <b>signal</b> compression. The design of effective, efficient compression and transmission strategies for <b>visual</b> <b>signals</b> may benefit from proper incorporation of human visual system (HVS) characteristics. This paper overviews psychophysics and engineering associated with the communication of <b>visual</b> <b>signals.</b> It presents a short history of advances in perceptual <b>visual</b> <b>signal</b> compression, and describes perceptual models and how they are embedded into systems for compression and transmission, both with and without current compression standards...|$|R
40|$|The {{application}} of various orthogonal transformations to communication was investigated, with particular {{emphasis placed on}} speech and <b>visual</b> <b>signal</b> processing. The fundamentals of the one- and two-dimensional orthogonal transforms and their application to speech and <b>visual</b> <b>signals</b> are treated in detail...|$|R
40|$|The {{effects of}} signal {{modality}} on duration classification in college students were studied with the duration bisection task. When auditory and <b>visual</b> <b>signals</b> {{were presented in}} the same test session and shared common anchor durations, <b>visual</b> <b>signals</b> were classified as shorter than equivalent duration auditory signals. This occurred when auditory and <b>visual</b> <b>signals</b> were presented sequentially in the same test session and when presented simultaneously but asynchronously. Presentation of a single modality signal within a test session, or both modalities but with different anchor durations {{did not result in}} classification differences. The authors posit a model in which auditory and <b>visual</b> <b>signals</b> drive an internal clock at different rates. The clock rate difference is due to an attentional effect on the mode switch and is revealed only when the memories for the short and long anchor durations consist of a mix of contributions from accumulations generated by both the fast auditory and slower visual clock rates. When this occurs auditory signals seem longer than <b>visual</b> <b>signals</b> relative to the composite memory representation...|$|R
3000|$|... aIn this article, {{we simply}} denote [...] "retrieval and {{recommendation}}" [...] as recommendation hereafter. bIn this article, video sequences {{are defined as}} data that contain only <b>visual</b> <b>signals,</b> and video contents are defined as data that contain both <b>visual</b> <b>signals</b> and audio signals. cIn this section, we assume that [...]...|$|R
5000|$|... #Caption: The {{earliest}} {{communication with}} aircraft was by <b>visual</b> <b>signalling</b> ...|$|R
5000|$|Cathode-ray tubes (CRT) - {{converts}} electrical <b>signals</b> into <b>visual</b> <b>signals</b> ...|$|R
5000|$|... #Subtitle level 3: <b>Visual</b> <b>signals</b> {{of status}} and rival {{assessments}} ...|$|R
40|$|Abstract Background Several {{experimental}} studies in stroke patients suggest that mirror therapy and various virtual reality programs facilitate motor rehabilitation. However, {{the underlying mechanisms}} for these therapeutic effects have not been previously described. Objectives We attempted to delineate the changes in corticospinal excitability when individuals were asked to exercise their upper extremity using a real mirror and virtual mirror. Moreover, we attempted to delineate the role of visual modulation within the virtual environment that affected corticospinal excitability in healthy subjects and stroke patients. Methods A total of 18 healthy subjects and 18 hemiplegic patients were enrolled into the study. Motor evoked potential (MEP) s from transcranial magnetic stimulation were recorded in the flexor carpi radialis of the non-dominant or affected upper extremity using three different conditions: (A) relaxation; (B) real mirror; and (C) virtual mirror. Moreover, we compared the MEPs from the virtual mirror paradigm using continuous <b>visual</b> feedback or <b>intermittent</b> <b>visual</b> feedback. Results The rates of amplitude increment and latency decrement of MEPs in both groups were higher during the virtual mirror task than during the real mirror. In healthy subjects and stroke patients, the virtual mirror task with <b>intermittent</b> <b>visual</b> feedback significantly facilitated corticospinal excitability of MEPs compared with continuous visual feedback. Conclusion Corticospinal excitability was facilitated {{to a greater extent}} in the virtual mirror paradigm than in the real mirror and in <b>intermittent</b> <b>visual</b> feedback than in the continuous visual feedback, in both groups. This provides neurophysiological evidence supporting the application of the virtual mirror paradigm using various visual modulation technologies to upper extremity rehabilitation in stroke patients. </p...|$|R
50|$|Split sound system: Actually {{there are}} two {{parallel}} transmitters one for aural and one for <b>visual</b> <b>signal.</b> The two signals are combined at the output via a high power combiner. In addition to a combiner, this system requires separate mixer and amplifiers for aural and <b>visual</b> <b>signals.</b> This is the system used in most high power applications.|$|R
40|$|Nonverbal {{communication}} {{plays an}} important role in social interactions. However, most nonverbal communication relies on <b>visual</b> <b>signals</b> such as eye contact, head nods, facial expressions and body gestures. <b>Visual</b> nonverbal <b>signals</b> are inaccessible for the blind and hardly accessible for low vision individuals. In this paper, we present a qualitative study on nonverbal signals for the blind in face-to-face communication and problems they met due to the lack of <b>visual</b> <b>signals.</b> We interviewed 20 blind and low vision participants and collected qualitative data for the further analysis. Our results show that auditory and tactile signals are two major nonverbal signals that blind participants sense in face-to-face communication. They seldom sense positive feelings from <b>visual</b> <b>signals</b> in a conversation and they tend to have an indirect and fuzzy understanding of eyes and eye gestures. Furthermore, we discuss how our findings can be relevant for design: the sighted conversation partner’s <b>visual</b> <b>signals</b> with positive meanings need to be detected to help the blind perceive the signal and feel more confident and engaged in face-to-face communication. 1...|$|R
50|$|Signal stations: A {{small number}} of {{traditional}} <b>visual</b> <b>signal</b> stations remain in operation.|$|R
25|$|E Company, {{the signal}} company trained in radio, telephone, telegraph, buzzers, and <b>visual</b> <b>signalling.</b>|$|R
5000|$|Radio, <b>Visual</b> <b>Signal,</b> and Recognition Signal Service Division. Commanded by Kapt. z. S. Lucan ...|$|R
40|$|Abstract—This {{contribution}} {{deals with}} the testing and selection of methods and algorithms for the automatic video image (or <b>visual</b> <b>signal)</b> segmentation. The aim of this work has been to select a reliable and fast method for <b>visual</b> <b>signal</b> segmentation, {{which can be used}} in the system for audio-visual automatic TV broadcast transcription. Keywords-visual signal segmentation, shot change detection, audio-vsual TV broadcast processing I...|$|R
50|$|Information may {{be communicated}} on fires in many forms. Radios, vocals, <b>visual</b> <b>signals</b> such as {{flagging}} and mirrors, literature {{such as an}} IAP or incident action plan, whistles and mobile touch-screen computer terminals are some examples.The USFS <b>Visual</b> <b>Signal</b> Code system provides symbols used to communicate from ground to air, while aircraft may use wing tilting, motor gunning or circling to communicate air-to-ground.|$|R
40|$|Abstract: While quality {{assessment}} is essen-tial for testing, optimizing, benchmarking, moni-toring, and inspecting related systems and ser-vices, it also plays {{an essential role}} in the de-sign of virtually all <b>visual</b> <b>signal</b> processing and communication algorithms, as well as var-ious related decision-making processes. In this paper, we first provide an overview of recently derived {{quality assessment}} approaches for trad-itional <b>visual</b> <b>signals</b> (i. e., 2 D images/videos), with highlights for new trends (such as mach-ine learning approaches). On the other hand, with the ongoing development of devices and multimedia services, newly emerged <b>visual</b> <b>signals</b> (e. g., mobile/ 3 D videos) {{are becoming more and more}} popular. This work focuses on recent progresses of quality metrics, which have been reviewed for the newly emerged forms of <b>visual</b> <b>signals,</b> which include scalable and mobile videos, High Dynamic Range (HDR) images, image segmentation results, 3 D im-ages/videos, and retargeted images. Key words: objective quality assessment; 2 D images and videos; human perception; newly emerged visual signals; Human Visual System I...|$|R
40|$|Learning {{to escape}} {{aversive}} stimuli and effectively predicting {{the consequences of}} different cues provides animals with an increased chance of survival. Discriminative avoidance conditioning affords the opportunity to examine these specific behaviors. The present experiment investigated {{the influence of a}} <b>visual</b> <b>signal</b> on an auditory discriminative active avoidance conditioning task. Building on the work of Gabriel and colleagues (Freeman et al., 1997; Poremba and Gabriel, 1997, 1999), originally conducted in rabbits, an adaptation of the discriminative active avoidance paradigm was implemented using male rats. Animals were trained to avoid a signaled shock (US) by spinning a small wheel during an auditory cue, the positive conditioned stimulus (CS+). A second auditory cue signaled the absence of shock, the negative conditioned stimulus (CS-). A <b>visual</b> safety <b>signal</b> was added following a correct response to the CS+ (successful avoidance of the shock). Three groups were formed based on experience with the visual safety signal: animals that never had training with the <b>visual</b> <b>signal,</b> animals that had the <b>visual</b> <b>signal</b> added during their training, and animals that began training with the <b>visual</b> <b>signal.</b> Animals trained with the <b>visual</b> safety <b>signal</b> showed a {{decrease in the number of}} days need to learn the task and the percentage of animals that learned the task increased. These results suggest that a <b>visual</b> safety <b>signal</b> enhances learning during an auditory discriminative avoidance conditioning task. This task will be used to expand exploration of the active avoidance neural circuitry and investigate the circuitry underlying the <b>visual</b> safety <b>signal...</b>|$|R
50|$|Light and {{repetitive}} <b>visual</b> <b>signals</b> can induce epileptic seizures. Vection {{and motion}} sickness can also occur.|$|R
5000|$|Aircraft {{marshalling}} is <b>visual</b> <b>signalling</b> between {{ground personnel}} and pilots on an airport, aircraft carrier or helipad.|$|R
50|$|Doorbells for hearing-impaired {{people use}} <b>visual</b> <b>signaling</b> devices — {{typically}} light bulbs — rather than audible signaling devices.|$|R
50|$|Noise {{also allows}} neurons to detect weak <b>visual</b> <b>signals</b> by {{processing}} {{the level of}} contrast of the image.|$|R
5000|$|The {{main steps}} of <b>visual</b> <b>signal</b> {{from the scene}} to {{receiver}} screen (for terrestrial broadcasting) are as follows: ...|$|R
40|$|A {{temporal}} two-interval forced-choice {{paradigm is}} {{used to evaluate the}} relative strength of the <b>visual</b> <b>signals</b> conveyed by the eyes and the mouth in happy and fearful facial expressions.   Stimuli were black and white images of faces with a neutral, happy or fearful expression.   The happy and fearful <b>visual</b> <b>signals</b> were conveyed by the eyes, the mouth or by the whole face. A range of signal strengths (0 - 100...|$|R
40|$|The {{fluorescence}} of many {{marine organisms}} is a visually compelling phenomenon. Descriptions {{of the phenomenon}} have at times been accompanied by suggestions of a visual function, but with minimal supporting evidence. It is possible to make quantitative estimates of the contribution of fluorescence emission to a <b>visual</b> <b>signal</b> under arbitrary illumination conditions. This analysis can help in deciding whether further research into a visual function is warranted, or whether the fluorescence is an interesting epiphenomenon associated with biomaterials that are present for other purposes. This paper describes the concepts associated with <b>visual</b> <b>signals</b> consisting of both reflected and fluoresced light, and methods for determining the underlying optical properties and using that information to model <b>visual</b> <b>signal</b> under environmentally relevant illumination conditions...|$|R
50|$|The craft have <b>visual</b> <b>signaling</b> devices (flashing blue lights) and siren (electromechanic wail, {{also known}} as whistle or Hi-Lo).|$|R
5000|$|... signal books, {{containing}} {{audio and}} <b>visual</b> <b>signals</b> for ship-to-ship and ship-to-shore use, {{as well as}} details of French lighthouses ...|$|R
40|$|The {{study of}} animal {{communication}} systems {{is an important}} step towards gaining greater understanding of the processes influencing diversification because signals often {{play an important role in}} mate choice and can lead to reproductive isolation. Signal evolution can be influenced by a diversity of factors such as biophysical constraints on the emitter, the signalling environment, or selection to avoid heterospecific matings. Furthermore, because signals can be costly to produce, trade-offs may exist between different types of signals. Here, we apply phylogenetic comparative analyses to study the evolution of acoustic and <b>visual</b> <b>signals</b> in Asian barbets, a clade of non-Passerine, forest-dependent birds. Our results suggest that evolution of acoustic and <b>visual</b> <b>signals</b> in barbets is influenced by diverse factors, such as morphology and signalling environment, suggesting a potential effect of sensory drive. We found no trade-offs between <b>visual</b> and acoustic <b>signals.</b> Quite to the contrary, more colourful species sing significantly longer songs. Song characteristics presented distinct patterns of evolution. Song frequency diverged early on and the rate of evolution of this trait appears to be constrained by body size. On the other hand, characteristics associated with length of the song presented evidence for more recent divergence. Finally, our results indicate that there is a spatial component to the evolution of <b>visual</b> <b>signals,</b> and that <b>visual</b> <b>signals</b> are more divergent between closely related taxa than acoustic <b>signals.</b> Hence, <b>visual</b> <b>signals</b> in these species could play a role in speciation or reinforcement of reproductive isolation following secondary contacts. © 2013 European Society For Evolutionary Biology. Peer Reviewe...|$|R
5000|$|<b>Visual</b> <b>signals</b> where light goes {{more or less}} {{directly}} from the source to the human eye, to convey a message or meaning ...|$|R
40|$|The {{coloration}} {{of flowers}} {{is due to}} the wavelength-selective absorption by pigments of light backscattered by structures inside the petals. We investigated the optical properties of flowers using (micro) spectrophotometry and anatomical methods. To assess the contribution of different structures to the overall <b>visual</b> <b>signal</b> of flowers, we used an optical model, where a petal is considered as a stack of differently pigmented and structured layers and we interpreted the <b>visual</b> <b>signals</b> of the model petals with insect vision models. We show that the reflectance depends, in addition to the pigmentation, on the petal's thickness and the inhomogeneity of its interior. We find large between-species differences in floral pigments, pigment concentration and localization, as well as floral interior structure. The fractions of reflected and transmitted light are remarkably similar between the studied species, suggesting common selective pressures of pollinator visual systems. Our optical model highlights that pigment localization crucially determines the efficiency of pigmentary filtering and thereby the chromatic contrast and saturation of the <b>visual</b> <b>signal.</b> The strongest <b>visual</b> <b>signal</b> occurs with deposition of pigments only on the side of viewing. Our systematic approach and optical modelling open new perspectives on the virtues of flower colour...|$|R
40|$|The {{courtship}} {{behavior of}} male Schizocosa uetzi wolf spiders incorporates both <b>visual</b> and seismic <b>signals</b> into a multimodal display. These two signals {{have been shown}} to interact in such a manner that the seismic signal alters a female’s response to the <b>visual</b> <b>signal,</b> leading to a putative increased importance of <b>visual</b> <b>signaling</b> {{in the presence of a}} seismic signal. Experiments leading to this attention-focusing hypothesis relied in part on the video playback technique, eliciting the question of its significance under more biologically relevant conditions. Here, we directly examine female mate choice of males with differing <b>visual</b> <b>signals</b> (foreleg pigmentation) both in the presence and absence of a seismic courtship signal. We first quantified the natural variation of male foreleg pigmentation within a population of S. uetzi. The proportion of the tibia covered in pigmentation was found to be positively correlated with male weight, suggesting that this signal may convey reliable information about male size. <b>Visual</b> <b>signals</b> of live males were then manipulated into two treatments: black and brown male foreleg tibias, representing the extreme ends of the natural variation found. The seismic signaling environment was also manipulated into two treatments: seismic signal present and absent. Mating frequency was higher in the presence of a seismic signal than in its absence, but there was no interaction between the seismic and <b>visual</b> <b>signaling</b> treatments. Females mated with black and brown males equally whether a seismic signal was present or absent. This study suggests that inexperienced females do not distinguish between males of different manipulated foreleg pigmentations in mate-choice decisions, even when in the presence of a seismic courtship signal...|$|R
50|$|Magnetovision images may be {{used for}} data fusion with <b>visual</b> <b>signal.</b> This creates new {{possibility}} of presentation of magnetic field distribution for further analyses.|$|R
25|$|The Mirabilis jalapa flower {{contains}} violet, fluorescent betacyanins and yellow, fluorescent betaxanthins. Under white light, {{parts of}} the flower containing only betaxanthins appear yellow, but in areas where both betaxanthins and betacyanins are present, the visible fluorescence of the flower is faded due to internal light-filtering mechanisms. Fluorescence was previously suggested {{to play a role}} in pollinator attraction, however, it was later found that the <b>visual</b> <b>signal</b> by fluorescence is negligible compared to the <b>visual</b> <b>signal</b> of light reflected by the flower.|$|R
40|$|Choice between {{signaled}} and unsignaled response-independent food schedules {{was assessed}} in three experiments using a commitment procedure. In Experiment 1, subjects tested with a 5 -s <b>visual</b> <b>signal</b> consistently {{changed from the}} signaled to the unsignaled schedule. Changing from the unsignaled to the signaled schedule was observed only occasionally and only at low levels. The same outcome was observed in Experiment 2 with different types of <b>visual</b> <b>signals</b> and with different stimulus combinations identifying the signal period, the signal-absent period, and the unsignaled schedule. In Experiment 3 the <b>visual</b> <b>signal</b> was replaced with an auditory signal for four of the subjects tested in Experiment 2. The subjects then changed from the unsignaled to the signaled schedule or showed a substantial reduction in choice for the unsignaled schedule. The data were assessed using a conditioned-reinforcement interpretation of choice...|$|R
2500|$|Retracting the chromatophores {{reveals the}} iridophores and leucophores beneath them, thereby {{allowing}} cuttlefish to use another modality of <b>visual</b> <b>signalling</b> {{brought about by}} structural coloration.|$|R
50|$|Redeye bass (Micropterus coosae) and midland water snakes (Nerodia sipedon pleuralis) {{respond to}} {{acoustic}} and <b>visual</b> <b>signals</b> in male tricolor shiners (Cyprinella trichroistia) when detecting prey.|$|R
