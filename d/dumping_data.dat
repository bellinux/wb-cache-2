6|207|Public
40|$|The Belgian {{coastal zone}} is shallow, well mixed {{and has a}} high {{hydrodynamic}} energy. In the coastal zone a turbidity maximum occurs, {{which is responsible for}} high dredging amounts. Every year about 10 x 10 (6) ton dry matter (TDM) is dredged for the maintenance of the harbours and the navigation channels. After dumping the matter is transported in suspension. The amount of maintenance dredging works is depending on the local hydrodynamic conditions and of the natural sediment transport as well as the amount and frequency of the dumping and dredging works. In order to estimate the efficiency of the dumping sites the natural cohesive sediment transport has to be known. Numerical models can be used to simulate this natural sediment transport. The uncertainties or variability of the sediment transport measurement data are high, in contrast with the dredging and <b>dumping</b> <b>data,</b> which are well known. The natural sediment transport is partly formed by the continuous erosion and deposition during a tide, a neap-spring cycle and during storms. This article will focus on the results of numerical simulations of the sediment transport. In particular the natural sediment transport of mud, the effect of dumping of dredged matter and the efficiency of the dumping sites will be discussed. This discussion is preceded by an overview of the physical situation (hydrodynamics, sediment transport, dredging and <b>dumping</b> <b>data)</b> and a description of the numerical models used (hydrodynamic model, wave model and sediment transport model) ...|$|E
30|$|Given {{the rapid}} growth in the demand of cloud {{computing}} [1, 2] and cloud data, there is an increasing demand in storing, processing and a retrieving large amount of data in a cloud cluster. The data can be either stored to a cloud network such as scientific data (i.e. Climate modeling, Fusion, Bioinformatics…etc) or use the cloud network for data-intensive tasks such as collecting experimental data, <b>dumping</b> <b>data</b> on parallel storage systems, run large scale simulations…etc. Cloud computing is an emerging technology used to deliver different types of resources known as services over the internet. Cluster computing [3 – 7] {{is a set of}} stand-alone computers connected together to form a single computing resource [8, 9]. This improves the performance and availability of a cloud cluster as compared to a single computer.|$|E
40|$|Don’t Trash Nevada {{website traffic}} remains strong despite no {{separate}} marketing. • Project Manager Douglas Joslin attended a by-invitation-only presentation for environmental groups on May 17, 2007 to discuss marketing opportunities with BTDT Enterprises, Inc. • Mr. Joslin {{is working with}} the Clark County School District on elementary educational programs. • The Anti-Litter Team has started work on a GIS database for littering and <b>dumping</b> <b>data</b> with the GIS Team. The two Teams met twice this quarter to discuss strategy. • Republic Services’ sponsored Don’t Trash Nevada advertisements, which have begun to run in local newspapers. • More than 350 people have taken the on-line anti-litter and dumping pledge. • Mr. Joslin presented at the Summerlin Earthfaire on April 21, 2007. • Mr. Joslin and the Team have started working with the Las Vegas Natural History Museum. The Anti-Litter Team is conceptualizing an exhibit on litter prevention. • Five volunteer clean-ups took place this quarter. • The Team placed three dumpsters and 20 roll-offs on public lands this quarter. • Anti-Litter Team received a certificate of appreciation from the Take Pride in America program. • One alternative work force clean up was conducted this quarter...|$|E
50|$|One of {{the uses}} of UUIDs in Solaris (using Open Software Foundation implementation) is {{identification}} of a running operating system instance {{for the purpose of}} pairing crash <b>dump</b> <b>data</b> with Fault Management Event in the case of kernel panic.|$|R
40|$|We re-analyze proton beam <b>dump</b> <b>data</b> {{taken at}} the U 70 {{accelerator}} at IHEP Serpukhov with the ν-calorimeter I experiment in 1989 to set mass-coupling limits for dark gauge forces. The corresponding data {{have been used for}} axion and light Higgs particle searches in Refs. before. We determine new mass and coupling exclusion bounds for dark gauge bosons. Comment: 10 pages, 6 figures, 1 style fil...|$|R
50|$|In September 2012 a {{group of}} hackers {{associated}} with hacking collective Anonymous and the sub-meme #antisec (also written as AntiSec) published the UDID records of 1,000,000 Apple iPhones and claimed that they possessed 12 million such records. Announcements of the hack claim that the source was a hacked FBI agent; however an independent forensic researcher and BlueToad later claimed that the <b>dumped</b> <b>data</b> came from BlueToad's intranet.|$|R
40|$|When Italian law {{enforcement}} investigates illegal environmental <b>dumping,</b> <b>data</b> {{must be carefully}} compiled, analyzed, and validated in order to successfully prosecute the parties responsible. Investigators {{must be able to}} produce a validated data-set construction using recognized scientific methods such as random sampling. Chemical/physical analysis, photographs and/or other data with significant details must conclusively demonstrate the pollution source and causal connection between the pollution and observed environmental damage. Authorized officers appointed by the Prosecutor Office to exercise their functions under technical consultant supervision have extensive powers of investigation in relation to illegal dumping. There are a number of investigation tasks that can be carried out at both the place the waste was dumped ('on-site') and in the office/lab to catch and deal with offenders. This paper introduces the use of advanced technologies (special aerial platforms, innovative application of thermography and advanced software tools) and new methods and procedures to detect and fight this illegal activity. This is the first known use of these methods in both the fields of environmental research and {{law enforcement}}. This paper provides an example of where law enforcement and university research teams can collaborate on developing enhanced environmental protection methods. The proposed procedures, techniques and technologies, were tested and validated in environmental police actions directed by the Italian Prosecutor Office and allowed us to understand the forensic value of the environmental enginee...|$|E
40|$|This work {{investigates the}} role and {{importance}} {{of some of the}} key aspects of QoS planning, provisioning, monitoring and optimisation (QoS Management) for UMTS Terrestrial Radio Access (UTRA) FDD networks {{within the framework of the}} 3 rd Generation Partnership Project (3 GPP). Firstly, the differences between Quality of end user Experience (QoE) and Quality of Service (QoS) are explained. This is followed by a review of 3 GPP requirements for QoS concept and architecture. Then all models and the main assumptions in this dissertation are presented. Based on these, original QoS mechanisms in the radio access network domain, means and methods for QoS provisioning, planning, monitoring and "optimisation" are discussed. Simulation results showed substantial spectral efficiency gains provided by service (or user) differentiation in UTRAN by means of priorities and differentiated parameter settings. When appropriately configured, the proposed QoS mechanisms can greatly reduce the need for bandwidth. Performance results proved also the proposed virtual time simulator to be an appropriate tool for service driven WCDMA radio interface dimensioning and detailed radio network planning. It is also shown that measuring QoS performance by a proper classification of counters (and or gauges), based on a particular subset of radio access bearer attributes, is a promising technique for assessing performances of service applications through WCDMA networks. With this new method there is no need to trace upper layer protocols at different interfaces or <b>dumping</b> <b>data</b> in mobile terminals. The proposed metrics allow operators to measure the bandwidth required for robust statistical reliability, to assess and exploit statistical sharing of resources, to configure QoS functions effectively, and to monitor QoE. The application of the proposed technique is not limited to the WCDMA Radio Network Subsystem (RNS), yet it can be deployed in any radio access and packet core network supporting mapping of performance indicators onto a particular subset of QoS attributes. Finally, in order to maximise the performance of the available services in UTRAN, at a given QoE, simulation results showed clear needs for the network administrator to adapt the parameter settings to diverse input application traffic conditions and the proposed genetic approach to be an appropriate solution space search algorithm for this purpose. reviewe...|$|E
50|$|On 1 November 2011 a major {{update to}} version 2 of the API was released. This new release dropped support for XML, data is always {{returned}} in JSON format, however the monthly <b>data</b> <b>dumps</b> of new <b>data</b> are only provided in XML format.|$|R
40|$|The Remote Maintenance Monitoring System (RMMS) {{provides}} automated {{support for}} the maintenance and repair of ModComp computer systems used in the Launch Processing System (LPS) at Kennedy Space Center. RMMS supports manual and automated diagnosis of intermittent hardware failures, providing an efficient means for accessing and analyzing the data generated by catastrophic failure recovery procedures. This paper describes the design and functionality of the user interface for interactive analysis of memory <b>dump</b> <b>data,</b> relating it to the underlying declarative representation of memory dumps...|$|R
5000|$|The {{problem of}} data {{proliferation}} is affecting {{all areas of}} commerce {{as the result of}} the availability of relatively inexpensive data storage devices. This has made it very easy to <b>dump</b> <b>data</b> into secondary storage immediately after its window of usability has passed. This masks problems that could gravely affect the profitability of businesses and the efficient functioning of health services, police and security forces, local and national governments, and many other types of organizations. Data proliferation is problematic for several reasons: ...|$|R
40|$|I am so {{old that}} Post-Mortem is a {{well-known}} technique for debugging programs. And so old that when I started teaching as an assistant, pedagogy did not exist - we were just "thrown into the deep {{end of the pool}} and told to swim". So it seemed obvious to me to turn Post-Mortem into a pedagogical technique for debugging and improving my teaching. To first <b>dump</b> <b>data</b> about what happened and then analyze that data to find out why it happened and what actions to take to remove the problem...|$|R
5000|$|In 2008, Unlockitfree {{produced}} a sub site which steps through the NSS process for Windows users. The final {{step of the}} website is to upload the <b>data</b> <b>dumped</b> from NSS into Unlockitfree. If the steps were followed successfully, the server would parse the <b>data</b> <b>dump</b> file and identify the Security code for the device.|$|R
40|$|Overview of Data This dataset is a <b>data</b> <b>dump</b> {{containing}} <b>data</b> from June 2008 to March 2013. Note that Stack Overflow originated only in June 2008. Therefore, this dump {{includes all}} the questions and answers on Stack Overflow until March 2013. Stack Overflow provides <b>data</b> <b>dumps</b> of all user generated data, including questions asked with the list of answers, the accepted answer per question, up/down votes, favourite counts, post score, comments, and anonymized user reputation. Stack Overflow allows users to tag discussions and has a reputation-based mechanism to rank users based on their active participation and contributions. Attribute Information Attribute info the datasets are in xml format including questions and answers for the following topics: * CSS * CSS-mobile * HTML 5 * HTML 5 -mobile * JavaScript * Javascript-mobil...|$|R
30|$|We applied our {{algorithm}} {{to a real}} dataset {{to detect}} network intrusions. Detecting intrusions is a typical data streaming problem, since {{it is essential to}} identify the event while it is happening. In our experiments we used the KDD-CUP’ 99 ([URL] intrusion detection dataset which consists of 2  weeks of raw TCP <b>dump</b> <b>data.</b> This dataset is related to a local area network simulating a true Air Force environment with occasional attacks. Variables collected for each connection include the duration of the connection, the number of bytes transmitted from source to destination (and viceversa), the number of failed login attempts, etc. We applied our algorithm to the 34 variables that are declared to be continuous.|$|R
40|$|AbstractWe re-analyze {{published}} proton beam <b>dump</b> <b>data</b> {{taken at}} the U 70 accelerator at IHEP Serpukhov with the ν-calorimeter I experiment in 1989 to set mass-coupling limits for dark gauge forces. The corresponding data {{have been used for}} axion and light Higgs particle searches in Refs. [1, 2] before. More recently, limits on dark gauge forces have been derived from this data set, considering a dark photon production from π 0 -decay [3]. Here we determine extended mass and coupling exclusion bounds for dark gauge bosons ranging to masses mγ′ of 624  MeV at admixture parameters ε≃ 10 − 6 considering high-energy Bremsstrahlung of the γ′-boson off the initial proton beam and different detection mechanisms...|$|R
50|$|CORE {{data can}} be {{accessed}} through an API or downloaded as a pre-processed and semantically enriched <b>data</b> <b>dump.</b>|$|R
50|$|He {{has hosted}} {{a number of}} <b>data</b> <b>dumps</b> {{including}} those associated with Hacking Team, Ashley Madison, and Patreon.|$|R
50|$|In computing, a hex dump is a {{hexadecimal}} view (on {{screen or}} paper) of computer data, from RAM {{or from a}} file or storage device. Looking at a hex <b>dump</b> of <b>data</b> is commonly done {{as a part of}} debugging, or of reverse engineering.|$|R
50|$|CORE <b>Data</b> <b>Dumps,</b> {{enables the}} {{accessibility}} of the data aggregated from repositories by CORE and allows their further manipulation.|$|R
50|$|A 2017 <b>data</b> <b>dump</b> {{suggests}} Cellebrite {{sold its}} data extraction products to Turkey, the United Arab Emirates and Russia.|$|R
40|$|It 2 ̆ 7 s {{known as}} the annual 2 ̆ 7 {{political}} donations <b>data</b> <b>dump</b> 2 ̆ 7, when the Australian Electoral Commission reveals who gave what to whom last financial year. For the Australian voter, of course, this horse has bolted: when we cast our ballots at the federal election in August, we {{were still in the}} dark as to the source of the parties 2 ̆ 7 campaign funds and the size of individual contributions. Even with the <b>dumped</b> <b>data,</b> much information remains obscured because only donations above 11, 200 in value have to be disclosed. But the new stats do suggest that the electoral funding arms race continues apace, since both party returns show that both the ALP and the Liberals went deeper into debt in 2009 - 10. Containing the spiralling cost of campaigning could perhaps be the one thing that would unite the major parties in reforming the system - but capping donations or campaign expenditure isn 2 ̆ 7 t everyone 2 ̆ 7 s cup of tea.   Guests Andrew NortonResearch Fellow, Centre for Independent Studies Graeme OrrAssociate Professor of Law, University of Queenslan...|$|R
50|$|In Unix-like {{operating}} systems, {{one means}} of inter-process communication is through signals. When an executing unit (process or thread) receives {{a signal from}} the OS, it should react in some way defined by the datasheet and the conventional meaning of this signal (i.e. by <b>dumping</b> its <b>data,</b> stopping execution, synchronizing something...).|$|R
40|$|This paper puts {{forward a}} {{framework}} for investigating Free and Open Source Software (F/OSS) developers activities in both source code and mailing lists repositories. We used <b>data</b> <b>dumps</b> of fourteen projects from the FLOSSMetrics (FM) retrieval system. Our intentions are (i) to present a possible methodology, its advantages and disadvantages which can benefit future researchers using {{some aspects of the}} FM retrieval system’s <b>data</b> <b>dumps,</b> and (ii) discuss our initial research results on the contributions developers make to both coding and lists activities...|$|R
40|$|The drastic {{increase}} in the data requirements of scientific applications combined with an increasing trend towards collaborative research {{has resulted in the}} need to transfer large amounts of data among the participating sites. The heterogeneous nature of the storage systems employed by the different sites makes transfer of data among them a difficult problem. The general tendency has been to either use simple scripts which require human intervention to deal with failures, or <b>dump</b> <b>data</b> to tapes and mail them. We introduce a method to build and operate data-pipelines between mass-storage systems lacking a common interface. This method can be applied easily and efficiently to transfer data between various mass storage systems. It does not need any human intervention during transfers, and it can recover automatically from various kinds of storage system, network, and software failures, guaranteeing completion of the transfers...|$|R
30|$|The {{special edition}} of NFC AMS system can make a backup file in SD card. Of course, it can restore from the <b>data</b> <b>dumped</b> file.|$|R
40|$|Integrating the {{information}} from SAS DICTIONARY tables into programming helps create dynamic and efficient scripts to manage data sets. The {{purpose of this paper}} is to provide such techniques for generating dynamic code from SAS DICTIONARY tables. The author uses three macros to demonstrate how DICTIONARY tables-driven code is dynamically constructed via three approaches: SQL select into macro-variable method, call execute method, and generate-and-include an external file method. These macros manage all data sets at the library level: capitalize all character <b>data,</b> <b>dump</b> all <b>data</b> into an excel file, and query all character data with certain length. Using the basic techniques discussed in the paper, SAS programmers can develop their own dynamic scripts to accomplish other tasks...|$|R
50|$|Watchdog.net - Combines various {{data sources}} into a unified interface. APIs and <b>data</b> <b>dumps</b> for everything. Free software. Also {{provides}} tools {{to get involved}} with politics.|$|R
50|$|The Commission on Elections chairman, Andres Bautista {{said that}} he was told that no {{confidential}} information was leaked, saying the breach would not affect the election body's preparation for the 2016 elections. The commission also emphasized that the database on its website is accessible to the public and no sensitive information is hosted on the website. It said that the results website that the election body is planning will be hosted in a different website with a different and better set of security measures. It further added that the database might be fake saying that no biometrics date were compromised by the hackers as opposed to Trend Micro's findings. COMELEC also noted that Trend Micro accessed the <b>dumped</b> <b>data</b> by hackers on its investigation and said that it has no capability of validating the data since it had no access to its original database.|$|R
50|$|However, {{if one has}} {{a working}} system, it is far easier to <b>dump</b> the ROM <b>data</b> to tape, disk, etc. and {{transfer}} the data file to one's target machine.|$|R
40|$|Reviews basic {{phenomena}} in accretion and erosion. A review of historical {{data on the}} past behaviour of the beach with hindcasting of some wave data from meteorological records. Preliminary measurements, currents, wave refractions, littoral drift and sand grading. Various possible measures for mitigating erosion are discussed. Recommends trials of stock piling and offshore <b>dumping.</b> Further <b>data</b> collection and analysis recommended...|$|R
40|$|The {{electromagnetic}} calorimeter of the CMS {{experiment is}} designed to reach excellent energy resolution, essential for the discovery of narrow electromagnetic resonances, such as the Standard Model decay H→γγ. The non uniformity of the individual channels directly contributes to the calorimeter energy resolution. While the final performance will be achieved with in situ calibration exploiting physics events, a good performance at start-up is already offered by the result of pre-calibration procedures involving test beam data, exposure to cosmic rays and laboratory measurements of the crystal light yield and photodetector gains. During the CMS commissioning phase, muons from cosmic rays and from beam dumps were used to validate the calibrations. In particular, the measurement of the muon momentum by the tracking system allow to check {{the validity of the}} energy scale defined on a 120 GeV electron beam down to the energy released by a minimum ionising particle. Muons from beam <b>dump</b> <b>data</b> are used to improve the intercalibration of the ECAL endcaps...|$|R
50|$|On 21 October, {{announced}} a <b>dump</b> of <b>data</b> related {{to law enforcement}} {{in support of the}} Occupy Wall Street and Occupy movement. The <b>dump</b> including <b>data</b> taken from the International Association of Chiefs of Police, Boston Police Patrolmen's Association, and the Sheriff's office of Baldwin County, Alabama. A number of police websites virtually hosted together also had their content replaced with an anti-police rap video. The dump 600 megabytes of information including membership rosters, internal documents, and social security numbers from the International Association of Chiefs of Police; nearly 1000 names, ranks, addresses, phone numbers, and social security numbers of police officers in Jefferson County, Alabama and Birmingham, Alabama; 1000 names and passwords of members of the Boston Police Patrolmen's Association; and the financial information and client list of web developer and marketing company Matrix Group, a business with several law enforcement clients. AntiSec claimed that at least 40 law enforcement related websites were included in the attack.|$|R
5000|$|Haskell: In Haskell, {{serialization}} {{is supported}} for types that {{are members of}} the Read and Show type classes. Every type that {{is a member of the}} [...] type class defines a function that will extract the data from the string representation of the <b>dumped</b> <b>data.</b> The [...] type class, in turn, contains the [...] function from which a string representation of the object can be generated. The programmer need not define the functions explicitly—merely declaring a type to be deriving Read or deriving Show, or both, can make the compiler generate the appropriate functions for many cases (but not all: function types, for example, cannot automatically derive Show or Read). The auto-generated instance for Show also produces valid source code, so the same Haskell value can be generated by running the code produced by show in, for example, a Haskell interpreter. For more efficient serialization, there are haskell libraries that allow high-speed serialization in binary format, e.g. binary.|$|R
50|$|After {{completion}} of commissioning, MetOp-B <b>dumps</b> recorded global <b>data</b> {{stored in the}} onboard solid state recorder (SSR) over McMurdo (as well as Svalbard) and MetOp-A only dumps its SSR over Svalbard.|$|R
50|$|Players are test {{subjects}} for Abstergo Industries who relive {{the lives of}} other {{test subjects}}' ancestors through the DDS (<b>Data</b> <b>Dump</b> Scanner) {{as opposed to the}} Animus. These ancestors are Assassins.|$|R
