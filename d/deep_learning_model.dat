200|10000|Public
50|$|Ryan is {{currently}} developing an AI <b>deep</b> <b>learning</b> <b>model</b> of the Sunflower process to empower entrepreneurs.|$|E
50|$|A deep Q-network (DQN) {{is a type}} of <b>deep</b> <b>learning</b> <b>model</b> that {{combines}} a deep CNN with Q-learning, a form of reinforcement learning. Unlike earlier reinforcement learning agents, DQNs can learn directly from high-dimensional sensory inputs.|$|E
5000|$|WaveNet {{is a deep}} {{neural network}} for {{generating}} raw audio created by researchers at London-based artificial intelligence firm DeepMind. The technique, outlined in a paper in September 2016, [...] is able to generate realistic-sounding human-like voices by sampling real human speech and directly modelling waveforms. Tests with US-based English and Mandarin, reportedly showed that the system outperforms the best existing Text-to-Speech systems from Google, although it is still less convincing than actual human speech. WaveNet’s ability to generate raw waveforms means that it can model any kind of audio, including music. Canada-based start-up Lyrebird offers similar technology, but {{is based on a}} different <b>deep</b> <b>learning</b> <b>model.</b>|$|E
30|$|Recently, <b>deep</b> <b>learning</b> {{paradigms}} {{have received}} considerable research attention. <b>Deep</b> <b>learning</b> <b>models</b> have multiple layers {{that can be}} trained using either supervised or unsupervised training approaches [9, 10]. In recent studies, <b>deep</b> <b>learning</b> <b>models</b> have achieved competitive results compared to the classical <b>learning</b> <b>models</b> in brain tumour diagnosis and tumour image classification [11, 12]. In addition, <b>deep</b> <b>learning</b> <b>models</b> like convolutional neural networks (CNNs) have improved the field of object detection and classification in different applications [13, 14]. As a <b>deep</b> <b>learning</b> paradigm, CNNs [15] {{have been used to}} extract high-level features from raw image data [16].|$|R
30|$|<b>Deep</b> <b>learning</b> <b>models</b> have {{recently}} gained attention by the researchers. The deployment of <b>deep</b> <b>learning</b> <b>models</b> for big data reduction is potential research direction {{that can be}} pursued in future. The <b>deep</b> <b>learning</b> <b>models</b> are initially developed from certain data and gradually evolve with uncertain data to effectively reduce big data streams. However, the increasing computational complexities of operating in uncertain big data environments and optimization of <b>learning</b> <b>models</b> to discover patterns from maximum data are the issues that can be further investigated [84].|$|R
40|$|Neural {{networks}} {{are one of}} the most popular approaches for many natural language processing tasks such as sentiment analysis. They often outperform traditional machine <b>learning</b> <b>models</b> and achieve the state-of-art results on most tasks. However, many existing <b>deep</b> <b>learning</b> <b>models</b> are complex, difficult to train and provide a limited improvement over simpler methods. We propose a simple, robust and powerful model for sentiment classification. This <b>model</b> outperforms many <b>deep</b> <b>learning</b> <b>models</b> and achieves comparable results to other <b>deep</b> <b>learning</b> <b>models</b> with complex architectures on sentiment analysis datasets. We publish the code online. Comment: 4 page...|$|R
30|$|The {{output matrix}} of the <b>deep</b> <b>learning</b> <b>model</b> is the {{extracted}} iris feature.|$|E
30|$|We {{present an}} {{efficient}} approach to training a <b>deep</b> <b>learning</b> <b>model</b> with an imbalanced dataset.|$|E
3000|$|Performing {{iris image}} {{acquisition}} on the decryption side, inputting into the trained <b>deep</b> <b>learning</b> <b>model,</b> and realizing iris feature vector extraction V 2; [...]...|$|E
30|$|Recently, <b>deep</b> <b>learning</b> <b>models</b> {{have been}} {{famous for their}} ability to learn feature {{representations}} from the input data. <b>Deep</b> <b>learning</b> networks use a layered, hierarchical structure to learn increasingly abstract feature representations from the data. <b>Deep</b> <b>learning</b> architectures learn simple, low-level features from the data and build complex high-level features in a hierarchy fashion. <b>Deep</b> <b>learning</b> technologies have demonstrated revolutionary performance in several areas, e.g., visual object recognition, human action recognition, natural language processing, object tracking, image restoration, denoising, segmentation tasks, audio classification and brain–computer interaction. In recent years, <b>deep</b> <b>learning</b> <b>models</b> specially convolutional neural network (CNN) have demonstrated excellent performance in the field of medical imaging, i.e., segmentation, detection, registration and classification [4]. For neuroimaging data, <b>deep</b> <b>learning</b> <b>models</b> can discover the latent or hidden representation and efficiently capture the disease-related pathologies. So, recently researchers have started using <b>deep</b> <b>learning</b> <b>models</b> for AD and other brain disease diagnosis.|$|R
40|$|In {{this paper}} we present DeepLearningKit - an open source {{framework}} that supports using pretrained <b>deep</b> <b>learning</b> <b>models</b> (convolutional neural networks) for iOS, OS X and tvOS. DeepLearningKit is developed in Metal {{in order to}} utilize the GPU efficiently and Swift for integration with applications, e. g. iOS-based mobile apps on iPhone/iPad, tvOS-based apps for the big screen, or OS X desktop applications. The goal is to support using <b>deep</b> <b>learning</b> <b>models</b> trained with popular frameworks such as Caffe, Torch, TensorFlow, Theano, Pylearn, Deeplearning 4 J and Mocha. Given the massive GPU resources and time required to train <b>Deep</b> <b>Learning</b> <b>models</b> we suggest an App Store like model to distribute and download pretrained and reusable <b>Deep</b> <b>Learning</b> <b>models.</b> Comment: 9 pages, 12 figures, open source documentation and code at deeplearningkit. org and github. com/deeplearningki...|$|R
40|$|Exponential {{growth in}} Electronic Healthcare Records (EHR) has {{resulted}} in new opportunities and urgent needs for discovery of meaningful data-driven representations and patterns of diseases in Computational Phenotyping research. <b>Deep</b> <b>Learning</b> <b>models</b> have shown superior performance for robust prediction in computational phenotyping tasks, but suffer from the issue of model interpretability which is crucial for clinicians involved in decision-making. In this paper, we introduce a novel knowledge-distillation approach called Interpretable Mimic Learning, to learn interpretable phenotype features for making robust prediction while mimicking the performance of <b>deep</b> <b>learning</b> <b>models.</b> Our framework uses Gradient Boosting Trees to learn interpretable features from <b>deep</b> <b>learning</b> <b>models</b> such as Stacked Denoising Autoencoder and Long Short-Term Memory. Exhaustive experiments on a real-world clinical time-series dataset show that our method obtains similar or better performance than the <b>deep</b> <b>learning</b> <b>models,</b> and it provides interpretable phenotypes for clinical decision making...|$|R
30|$|Figures  11 and 12 corroborate {{the earlier}} {{observation}} that the <b>deep</b> <b>learning</b> <b>model</b> predicts better compared {{to most of the}} relative permeability models used in reservoir modelling software. It is important to note here that the empirical models (Figs.  9, 10) have a problem of generalization especially as every reservoir is unique. Again, the assumptions associated with their formulation might not be practically true in all cases but this reservoir uniqueness or generalization is captured by the <b>deep</b> <b>learning</b> <b>model</b> bearing in mind that it will perform even better as more real-time data are added to the training set.|$|E
3000|$|The {{encryption}} side collects {{the iris}} image and inputs the trained <b>deep</b> <b>learning</b> <b>model</b> {{to extract the}} feature vector V. The dimension of the feature vector V 1 can be adjusted according to the adopted image encryption algorithm; [...]...|$|E
40|$|In current {{upscaling}} of in situ {{surface soil}} moisture practices, commonly used novel statistical or machine learning-based regression models combined with remote sensing data show some advantages in accurately capturing the satellite footprint scale of specific local or regional surface soil moisture. However, {{the performance of}} most models is largely determined {{by the size of}} the training data and the limited generalization ability to accomplish correlation extraction in regression models, which are unsuitable for larger scale practices. In this paper, a <b>deep</b> <b>learning</b> <b>model</b> was proposed to estimate soil moisture on a national scale. The <b>deep</b> <b>learning</b> <b>model</b> has the advantage of representing nonlinearities and modeling complex relationships from large-scale data. To illustrate the <b>deep</b> <b>learning</b> <b>model</b> for soil moisture estimation, the croplands of China were selected as the study area, and four years of Visible Infrared Imaging Radiometer Suite (VIIRS) raw data records (RDR) were used as input parameters, then the models were trained and soil moisture estimates were obtained. Results demonstrate that the estimated models captured the complex relationship between the remote sensing variables and in situ surface soil moisture with an adjusted coefficient of determination of R ¯ 2 = 0. 9875 and a root mean square error (RMSE) of 0. 0084 in China. These results were more accurate than the Soil Moisture Active Passive (SMAP) active radar soil moisture products and the Global Land data assimilation system (GLDAS) 0 – 10 cm depth soil moisture data. Our study suggests that <b>deep</b> <b>learning</b> <b>model</b> have potential for operational applications of upscaling in situ surface soil moisture data at the national scale...|$|E
5000|$|ConvNetJS - Javascript {{library for}} {{training}} <b>deep</b> <b>learning</b> <b>models</b> entirely {{in a web}} browser ...|$|R
30|$|The trained <b>deep</b> <b>learning</b> <b>models</b> are {{available}} on reasonable request sent to the corresponding author.|$|R
30|$|Big Data {{encompasses}} {{a lot of}} things from medicine, genomic and biological data to call center. To handle huge volumes of input associated with Big Data, large-scale <b>Deep</b> <b>Learning</b> <b>models</b> are desirable. They can illustrate the optimal number of model parameters and overcome the challenges of <b>Deep</b> <b>Learning</b> for Big Data analysis. There are other Big Data problems like domain adaption and streaming data that large-scale <b>Deep</b> <b>Learning</b> <b>models</b> for Big Data need to handle.|$|R
30|$|In the {{spectrogram}} domain, “local” {{refers to}} the concept of locality in time-frequency bins, and, with the <b>deep</b> <b>learning</b> <b>model</b> described in the previous subsection as the starting point, we approach this in two different ways: outside the model and with a model that integrates local characterization.|$|E
40|$|In this chapter, we show two discoveries {{learned from}} the {{application}} of deep learning methods {{to the problem of}} classifying mammogram exams containing multi-view images and segmentation maps of breast lesions (i. e., masses and micro-calcifications). We first demonstrate the efficacy of pre-training a <b>deep</b> <b>learning</b> <b>model</b> using extremely large computer vision training sets, and then fine-tuning this same model for the classification of mammogram exams. We also show that the multi-view mammograms and segmentation maps {{do not need to be}} registered in order to produce accurate classification results using the fine-tuned <b>deep</b> <b>learning</b> <b>model</b> above. In particular, we take a <b>deep</b> <b>learning</b> <b>model</b> pre-trained to identify ImageNet classes from real images, and fine-tune it with cranio-caudal (CC) and medio-lateral oblique (MLO) mammography views of a single breast and their respective mass and micro-calcification segmentation maps in order to estimate the patient's risk of developing breast cancer. This methodology is tested on two publicly available datasets (InBreast and DDSM), and we show that our approach produces a volume under ROC surface of over 0. 9 and an area under ROC curve (for a 2 -class problem: benign and malignant) of over 0. 9. These results show that our method can produce state-of-the-art classification results using a new comprehensive way of tackling medical image analysis problems. © 2017 Elsevier Inc. All rights reserved...|$|E
30|$|Variety {{is one of}} {{the other}} {{characteristics}} of Big Data, which focuses on the variation of the input domains and data types in Big Data so the problem of domain adoption is another issue that Deep Learning in Big Data analysis need to overcome. There are some studies including [86, 87] that mainly focus on domain adoption during the learning process. Glorot et al. [86] illustrate that Deep Learning can find intermediate data representations in a hierarchical learning manner and this representation can be used for other domains. Chopra et al. [87] propose a new <b>Deep</b> <b>Learning</b> <b>model</b> for domain adoption. Their new proposed <b>Deep</b> <b>Learning</b> <b>model</b> considers information available from the distribution shift between the train and test data. Our paper mainly focuses on information retrieval so in the following section, we summarize Deep Learning in sentiment analysis.|$|E
5000|$|DSSTNE (Deep Scalable Sparse Tensor Network Engine) - Amazon {{developed}} {{library for}} building <b>deep</b> <b>learning</b> <b>models</b> ...|$|R
40|$|<b>Deep</b> <b>learning</b> <b>models</b> (aka <b>Deep</b> Neural Networks) have {{revolutionized}} many fields including computer vision, {{natural language}} processing, speech recognition, {{and is being}} increasingly used in clinical healthcare applications. However, few works exist which have benchmarked {{the performance of the}} <b>deep</b> <b>learning</b> <b>models</b> with respect to the state-of-the-art machine <b>learning</b> <b>models</b> and prognostic scoring systems on publicly available healthcare datasets. In this paper, we present the benchmarking results for several clinical prediction tasks such as mortality prediction, length of stay prediction, and ICD- 9 code group prediction using <b>Deep</b> <b>Learning</b> <b>models,</b> ensemble of machine <b>learning</b> <b>models</b> (Super Learner algorithm), SAPS II and SOFA scores. We used the Medical Information Mart for Intensive Care III (MIMIC-III) (v 1. 4) publicly available dataset, which includes all patients admitted to an ICU at the Beth Israel Deaconess Medical Center from 2001 to 2012, for the benchmarking tasks. Our results show that <b>deep</b> <b>learning</b> <b>models</b> consistently outperform all the other approaches especially when the `raw' clinical time series data is used as input features to the models. Comment: Submitted to Journal of Biomedical Informatics (JBI). First two authors have equal contribution...|$|R
50|$|Apache MXNet is a lean, flexible, and ultra-scalable <b>deep</b> <b>learning</b> {{framework}} that supports {{state of the}} art in <b>deep</b> <b>learning</b> <b>models,</b> including convolutional neural networks (CNNs) and long short-term memory networks (LSTMs).|$|R
30|$|The <b>deep</b> <b>{{learning}}</b> <b>model</b> for {{feature learning}} of the iris uses CNN, and the dataset contains 400 images of irises in total, 10 types, 40 images per class. The CNN structure uses a five-layer network layer, the convolution process is a 5 [*]×[*] 5 convolution filter, and the sampling layer is a 2 [*]×[*] 2 pooling filter.|$|E
40|$|In {{a recent}} decade, ImageNet {{has become the}} most notable and {{powerful}} benchmark database in computer vision and machine learning community. As ImageNet has emerged as a representative benchmark for evaluating the performance of novel deep learning models, its evaluation tends to include only quantitative measures such as error rate, rather than qualitative analysis. Thus, there are few studies that analyze the failure cases of deep learning models in ImageNet, though there are numerous works analyzing the networks themselves and visualizing them. In this abstract, we qualitatively analyze the failure cases of ImageNet classification results from recent <b>deep</b> <b>learning</b> <b>model,</b> and categorize these cases according to the certain image patterns. Through this failure analysis, we believe that it can be discovered what the final challenges are in ImageNet database, which the current <b>deep</b> <b>learning</b> <b>model</b> is still vulnerable to. Comment: Poster presented at CVPR 2017 Scene Understanding Worksho...|$|E
30|$|The {{remainder}} {{of this paper is}} organized as follows. Section 2 introduces relevant works, <b>deep</b> <b>learning</b> <b>model.</b> In Section 3, a classification framework is introduced, and every individual part of the proposed framework is depicted in detail by some mathematical explanations. In Section 4, some results together with relevant analyses and discussions are reported. At last, the conclusions are summarized.|$|E
30|$|Large-scale <b>Deep</b> <b>Learning</b> <b>models</b> {{are quite}} suited to handle massive volumes of input {{associated}} with Big Data, and {{as demonstrated in}} the above works they are also better at learning complex data patterns from large volumes of data. Determining the optimal number of model parameters in such large-scale models and improving their computational practicality pose challenges in <b>Deep</b> <b>Learning</b> for Big Data Analytics. In addition {{to the problem of}} handling massive volumes of data, large-scale <b>Deep</b> <b>Learning</b> <b>models</b> for Big Data Analytics also have to contend with other Big Data problems, such as domain adaptation (see next section) and streaming data. This lends to the need for further innovations in large-scale <b>models</b> for <b>Deep</b> <b>Learning</b> algorithms and architectures.|$|R
40|$|This paper {{considers}} security risks {{buried in}} the data processing pipeline in common <b>deep</b> <b>learning</b> applications. <b>Deep</b> <b>learning</b> <b>models</b> usually assume a fixed scale for their training and input data. To allow <b>deep</b> <b>learning</b> applications to handle {{a wide range of}} input data, popular frameworks, such as Caffe, TensorFlow, and Torch, all provide data scaling functions to resize input to the dimensions used by <b>deep</b> <b>learning</b> <b>models.</b> Image scaling algorithms are intended to preserve the visual features of an image after scaling. However, common image scaling algorithms are not designed to handle human crafted images. Attackers can make the scaling outputs look dramatically different from the corresponding input images. This paper presents a downscaling attack that targets the data scaling process in <b>deep</b> <b>learning</b> applications. By carefully crafting input data that mismatches with the dimension used by <b>deep</b> <b>learning</b> <b>models,</b> attackers can create deceiving effects. A <b>deep</b> <b>learning</b> application effectively consumes data that {{are not the same as}} those presented to users. The visual inconsistency enables practical evasion and data poisoning attacks to <b>deep</b> <b>learning</b> applications. This paper presents proof-of-concept attack samples to popular deep-learning-based image classification applications. To address the downscaling attacks, the paper also suggests multiple potential mitigation strategies...|$|R
40|$|Recently, <b>deep</b> <b>learning</b> {{techniques}} have enjoyed success in various multimedia applications, such as image classification and multi-modal data analysis. Large <b>deep</b> <b>learning</b> <b>models</b> are developed for learning rich representations of complex data. There are two challenges to overcome before <b>deep</b> <b>learning</b> can be widely adopted in multimedia and other applications. One is usability, namely {{the implementation of}} different models and training algorithms must be done by non-experts without much effort especially when the model is large and complex. The other is scalability, that is the <b>deep</b> <b>learning</b> system {{must be able to}} provision for a huge demand of computing resources for training large models with massive datasets. To address these two challenges, in this paper, we design a distributed <b>deep</b> <b>learning</b> platform called SINGA which has an intuitive programming model based on the common layer abstraction of <b>deep</b> <b>learning</b> <b>models.</b> Good scalability is achieved through flexible distributed training architecture and specific optimization techniques. SINGA runs on GPUs as well as on CPUs, and we show that it outperforms many other state-of-the-art <b>deep</b> <b>learning</b> systems. Our experience with developing and training <b>deep</b> <b>learning</b> <b>models</b> for real-life multimedia applications in SINGA shows that the platform is both usable and scalable. Comment: submitted to TOMM (under review...|$|R
30|$|To learn better {{representations}} and abstractions, one can {{use some}} supervised data in training the <b>Deep</b> <b>Learning</b> <b>model.</b> Ranzato et al. [36] present a study in which parameters of the <b>Deep</b> <b>Learning</b> <b>model</b> are learnt based on both supervised and unsupervised data. The advantages of such a strategy are {{that there is no}} need to completely label a large collection of data (as some unlabeled data is expected) and that the model has some prior knowledge (via the supervised data) to capture relevant class/label information in the data. In other words, the model is required to learn data representations that produce good reconstructions of the input in addition to providing good predictions of document class labels. The authors show that for learning compact representations, Deep Learning models are better than shallow learning models. The compact representations are efficient because they require fewer computations when used in indexing, and in addition, also need less storage capacity.|$|E
40|$|With the {{development}} of Internet of Everything such as Internet of Things, Internet of People, and Industrial Internet, big data is being generated. Clustering is a widely used technique for big data analytics and mining. However, most of current algorithms are not effective to cluster heterogeneous data which is prevalent in big data. In this paper, we propose a high-order CFS algorithm (HOCFS) to cluster heterogeneous data by combining the CFS clustering algorithm and the dropout <b>deep</b> <b>learning</b> <b>model,</b> whose functionality rests on three pillars: (i) an adaptive dropout <b>deep</b> <b>learning</b> <b>model</b> to learn features from each type of data, (ii) a feature tensor model to capture the correlations of heterogeneous data, and (iii) a tensor distance-based high-order CFS algorithm to cluster heterogeneous data. Furthermore, we verify our proposed algorithm on different datasets, by comparison with other two clustering schemes, that is, HOPCM and CFS. Results confirm {{the effectiveness of the}} proposed algorithm in clustering heterogeneous data...|$|E
40|$|International Classification of Diseases(ICD) is an {{authoritative}} health care classification system of different diseases and conditions for clinical and management purposes. Considering the complicated and dedicated process to assign correct codes to each patient admission based on overall diagnosis, we propose a hierarchical <b>deep</b> <b>learning</b> <b>model</b> with attention mechanism which can automatically assign ICD diagnostic codes given written diagnosis. We utilize character-aware neural language models to generate hidden representations of written diagnosis descriptions and ICD codes, and design an attention mechanism {{to address the}} mismatch between the numbers of descriptions and corresponding codes. Our experimental results show the strong potential of automated ICD coding from diagnosis descriptions. Our best model achieves 0. 53 and 0. 90 of F 1 score and area under curve of receiver operating characteristic respectively. The result outperforms those achieved using character-unaware encoding method or without attention mechanism. It indicates that our proposed <b>deep</b> <b>learning</b> <b>model</b> can code automatically in a reasonable way and {{provide a framework for}} computer-auxiliary ICD coding...|$|E
30|$|Currently, <b>deep</b> <b>learning</b> <b>models</b> are of {{considerable}} research importance. <b>Deep</b> <b>learning</b> methods provide high efficiency {{and the ability}} to process numerous MRIs from databases [35]. This study focuses on CNNs, which have gained popularity among researchers for object recognition and biological image segmentation.|$|R
40|$|While <b>deep</b> <b>learning</b> <b>models</b> have {{achieved}} state-of-the-art accuracies for many prediction tasks, understanding these models remains a challenge. Despite the recent {{interest in developing}} visual tools to help users interpret <b>deep</b> <b>learning</b> <b>models,</b> the complexity and wide variety of models deployed in industry, and the large-scale datasets that they used, pose unique design challenges that are inadequately addressed by existing work. Through participatory design sessions with over 15 researchers and engineers at Facebook, we have developed, deployed, and iteratively improved ActiVis, an interactive visualization system for interpreting large-scale <b>deep</b> <b>learning</b> <b>models</b> and results. By tightly integrating multiple coordinated views, such as a computation graph overview of the model architecture, and a neuron activation view for pattern discovery and comparison, users can explore complex deep neural network models at both the instance- and subset-level. ActiVis has been deployed on Facebook's machine learning platform. We present case studies with Facebook researchers and engineers, and usage scenarios of how ActiVis may work with different models. Comment: Will be presented at IEEE VAST 2017 and published in IEEE Transactions on Visualization and Computer Graphics, 24 (1...|$|R
40|$|<b>Deep</b> <b>learning</b> <b>models</b> are {{currently}} being applied in several areas with great success. However, their application {{for the analysis of}} high-throughput sequencing data remains a challenge for the research community {{due to the fact that}} this family of models are known to work very well in big datasets with lots of samples available, just the opposite scenario typically found in biomedical areas. In this work, a first approximation on the use of <b>deep</b> <b>learning</b> for the analysis of RNA-Seq gene expression profiles data is provided. Three public cancer-related databases are analyzed using a regularized linear model (standard LASSO) as baseline <b>model,</b> and two <b>deep</b> <b>learning</b> <b>models</b> that differ on the feature selection technique used prior to the application of a deep neural net model. The results indicate that a straightforward application of deep nets implementations available in public scientific tools and under the conditions described within this work is not enough to outperform simpler models like LASSO. Therefore, smarter and more complex ways that incorporate prior biological knowledge into the estimation procedure of <b>deep</b> <b>learning</b> <b>models</b> may be necessary in order to obtain better results in terms of predictive performance. Universidad de Málaga. Campus de Excelencia Internacional Andalucía Tech...|$|R
