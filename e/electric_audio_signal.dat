1|5686|Public
5000|$|An [...] "effects chain" [...] or [...] "signal chain" [...] {{is formed}} by {{connecting}} {{two or more}} stompboxes. Effect chains are typically created between the guitar and the amp or between the preamplifier ("preamp") and the power amp. When a pedal is off or inactive, the <b>electric</b> <b>audio</b> <b>signal</b> coming into the pedal diverts onto a bypass, an unaltered [...] "dry" [...] signal that continues on to other effects down the chain. In this way, a musician can combine effects within a chain {{in a variety of}} ways without having to reconnect boxes during a performance. A [...] "controller" [...] or [...] "effects management system" [...] lets the musician create multiple effect chains, so they can select one or several chains by tapping a single switch. The switches are usually organized in a row or a simple grid.To preserve the clarity of the tone, it is most common to put compression, wah and overdrive pedals at the start of the chain; modulation (chorus, flanger, phase shifter) in the middle; and time-based units (delay/echo, reverb) at the end. When using many effects, unwanted noise and hum can be introduced into the sound. Some performers use a noise gate pedal at the end of a chain to reduce unwanted noise and hum introduced by overdrive units or vintage gear.|$|E
40|$|An input <b>audio</b> <b>signal</b> {{having an}} input {{temporal}} envelope is converted into an output <b>audio</b> <b>signal</b> having an output temporal envelope. The input temporal envelope of the input <b>audio</b> <b>signal</b> is characterized. The input <b>audio</b> <b>signal</b> is processed {{to generate a}} processed <b>audio</b> <b>signal,</b> wherein the processing de-correlates the input <b>audio</b> <b>signal.</b> The processed <b>audio</b> <b>signal</b> is adjusted based on the characterized input temporal envelope to generate the output <b>audio</b> <b>signal,</b> wherein the output temporal envelope substantially matches the input temporal envelope...|$|R
40|$|An audio {{enhancement}} {{device in}} accordance with the present invention comprises an extraction circuit (210) for extracting a first <b>audio</b> <b>signal</b> from a first input signaland a second <b>audio</b> <b>signal</b> from a second input signal, and extracting inter-channel parameters from atleast a part of the first <b>audio</b> <b>signal</b> and at least a part of the second <b>audio</b> <b>signal,</b> a processing circuit for processing (230) the first <b>audio</b> <b>signal</b> and the second audio 5 signalinto processed <b>audio</b> <b>signals,</b> and a re-instating circuit for re-instating (240) the inter- channel parameters into the processed <b>audio</b> <b>signals</b> resulting in a first output <b>audio</b> <b>signal</b> and a second output <b>audio</b> <b>signal...</b>|$|R
40|$|An audio {{processing}} arrangement (200) comprises {{a plurality}} of audio sources (101, 102) generating input <b>audio</b> <b>signals,</b> a processing circuit (110) for deriving processed <b>audio</b> <b>signals</b> from the input <b>audio</b> <b>signals,</b> a combining circuit (120) for deriving a combined audio signalfrom the processed <b>audio</b> <b>signals,</b> and a control circuit (130) for controlling the processing circuit {{in order to maximize}} a power measure of the combined <b>audio</b> <b>signal</b> and for limiting a function of gains of the processed <b>audio</b> <b>signals</b> to a predetermined value. In accordance with the present invention, the audio processing arrangement (200) comprises a pre-processing circuit (140) for deriving pre-processed <b>audio</b> <b>signals</b> from the input <b>audio</b> <b>signals</b> to minimize a cross-correlation of interferences comprised in the input <b>audio</b> <b>signals.</b> The pre-processed signals are provided to the processing circuit (110) instead of the input <b>audio</b> <b>signals...</b>|$|R
40|$|WO 200280415 A UPAB: 20021129 NOVELTY - The method {{involves}} estimating (13) an <b>audio</b> <b>signal</b> {{specific characteristic}} of the <b>audio</b> <b>signal</b> indicating {{a measure of the}} energy of the inserted information, pre-processing (12) the signal based on the estimated characteristic to influence the energy and obtain a pre-processed <b>audio</b> <b>signal</b> and extracting (16) the information from the pre-processed <b>audio</b> <b>signal.</b> DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: an arrangement for detecting information inserted into an <b>audio</b> <b>signal,</b> an arrangement for inserting information into an <b>audio</b> <b>signal</b> and a method of inserting information into an <b>audio</b> <b>signal.</b> USE - For determining information with energy inserted into <b>audio</b> <b>signal.</b> ADVANTAGE - Enables secure determination of information inserted into an <b>audio</b> <b>signal</b> without reducing the data rate of the inserted information significantly...|$|R
40|$|WO 2008049587 A 1 UPAB: 20080620 NOVELTY - A {{compression}} unit (110) performs {{lossy compression}} of original representation of <b>audio</b> <b>signal</b> for obtaining compressed representation of <b>audio</b> <b>signal.</b> A {{difference between the}} compressed representation of <b>audio</b> <b>signal</b> and original representation of <b>audio</b> <b>signal</b> is calculated to obtain a discrimination representation (122). The ambient signal (132) is generated based on discrimination representation. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are included for the following: (1) multi-channel <b>audio</b> <b>signal</b> deriving apparatus; (2) ambient signal generation method; (3) multi-channel <b>audio</b> <b>signal</b> derivation method; (4) ambient signal generation program; and (5) multi-channel <b>audio</b> <b>signal</b> deriving program. USE - Apparatus for generating ambient <b>signal</b> from <b>audio</b> <b>signal</b> for upmixing mono <b>audio</b> <b>signals</b> recorded on DVD for playback on multi-channel system. ADVANTAGE - Prevents the introduction of synthetic audio effects to the ambient signal hence the ambient signal is free from reverberation...|$|R
40|$|A {{device for}} {{processing}} an <b>audio</b> <b>signal,</b> wherein the device comprises a detection unit adapted for detecting a widening {{state of the}} <b>audio</b> <b>signal,</b> and a widening modification unit adapted for modifying a widening characteristic of the <b>audio</b> <b>signal</b> depending on the detected widening state of the <b>audio</b> <b>signal...</b>|$|R
40|$|An {{apparatus}} {{for enhancing}} an <b>audio</b> <b>signal</b> comprises a signal processor for processing the <b>audio</b> <b>signal</b> {{in order to}} reduce or eliminate transient and tonal portions of the processed signal and a decorrelator for generating a first decorrelated signal and a second decorrelated signal from the processed signal. The apparatus further comprises a combiner for weightedly combining the first and the second decorrelated <b>signal</b> and the <b>audio</b> <b>signal</b> or a signal derived from the <b>audio</b> <b>signal</b> by coherence enhancement using time variant weighting factors and to obtain a two-channel <b>audio</b> <b>signal.</b> The apparatus further comprises a controller for controlling the time variant weighting factors by analyzing the <b>audio</b> <b>signal</b> so that different portions of the <b>audio</b> <b>signal</b> are multiplied by different weighting factors and the two-channel <b>audio</b> <b>signal</b> has a time variant degree of decorrelation...|$|R
40|$|An {{audio encoder}} for {{encoding}} an <b>audio</b> <b>signal,</b> comprises: a first encoding processor (600) for encoding a first <b>audio</b> <b>signal</b> portion in a frequency domain, wherein the first encoding processor (600) comprises: a time frequency converter (602) for converting the first <b>audio</b> <b>signal</b> portion into a frequency domain representation having spectral lines up {{to a maximum}} frequency of the first <b>audio</b> <b>signal</b> portion; an analyzer (604) for analyzing the frequency domain representation up to the maximum frequency to determine first spectral portions to be encoded with a first spectral resolution and second spectral regions to be encoded with a second spectral resolution, the second spectral resolution being lower than the first spectral resolution; a spectral encoder (606) for encoding the first spectral portions with the first spectral resolution and for encoding the second spectral portions with the second spectral resolution; a second encoding processor (610) for encoding a second different <b>audio</b> <b>signal</b> portion in the time domain; a controller (620) configured for analyzing the <b>audio</b> <b>signal</b> and for determining, which portion of the <b>audio</b> <b>signal</b> is the first <b>audio</b> <b>signal</b> portion encoded in the frequency domain and which portion of the <b>audio</b> <b>signal</b> is the second <b>audio</b> <b>signal</b> portion encoded in the time domain; and an encoded signal former (630) for forming an encoded <b>audio</b> <b>signal</b> comprising a first encoded signal portion for the first <b>audio</b> <b>signal</b> portion and a second encoded signal portion for the second <b>audio</b> <b>signal</b> portion...|$|R
40|$|DE 10129239 C UPAB: 20021204 NOVELTY - The water-marking method embeds a water-mark in an <b>audio</b> <b>signal</b> by {{providing}} a spectral representation of the <b>audio</b> <b>signal</b> and a spectral representation of the water-mark signal, the latter processed in dependence on the psychoacoustic masking threshold of the <b>audio</b> <b>signal,</b> to allow the water-mark signal to be combined with the <b>audio</b> <b>signal</b> without being audibly perceived. DETAILED DESCRIPTION - An INDEPENDENT CLAIM for a device for embedding a water-mark <b>signal</b> in an <b>audio</b> <b>signal</b> is also included. USE - The method is used for embedding a water-mark <b>signal</b> in an <b>audio</b> <b>signal.</b> ADVANTAGE - The method allows the water-mark signal to be embedded in the <b>audio</b> <b>signal</b> without being audibly perceived...|$|R
30|$|We {{will only}} {{consider}} tonal <b>audio</b> <b>signals,</b> that is, signals having a continuous spectrum containing {{a finite number}} of dominant frequency components. In this way, the majority of <b>audio</b> <b>signals</b> is covered, except for the class of percussive sounds. The performance of the different LP models described below will be evaluated for three types of audio signals: synthetic <b>audio</b> <b>signals</b> consisting of a sum of harmonic sinusoids in white noise, true monophonic <b>audio</b> <b>signals,</b> and true polyphonic <b>audio</b> <b>signals.</b>|$|R
50|$|An <b>audio</b> <b>signal</b> is a {{representation}} of sound, typically as an electrical voltage. <b>Audio</b> <b>signals</b> have frequencies in the audio frequency range of roughly 20 to 20,000 Hz (the limits of human hearing). <b>Audio</b> <b>signals</b> may be synthesized directly, or may originate at a transducer such as a microphone, musical instrument pickup, phonograph cartridge, or tape head. Loudspeakers or headphones convert an electrical <b>audio</b> <b>signal</b> into sound. Digital representations of <b>audio</b> <b>signals</b> exist {{in a variety of}} formats.|$|R
40|$|An {{efficient}} encoded {{representation of}} a first and a second input <b>audio</b> <b>signal</b> can be derived using correlation information indicating a correlation {{between the first and}} the second input <b>audio</b> <b>signals,</b> when a signal characterization information, indicating at least a first or a second, different characteristic of the input <b>audio</b> <b>signal</b> is additionally considered. Phase information indicating a phase relation between the first and the second input <b>audio</b> <b>signals</b> is derived, when the input <b>audio</b> <b>signals</b> have the first characteristic. The phase information and a correlation measure are included into the encoded representation when the input <b>audio</b> <b>signals</b> have the first characteristic, and only the correlation information is included into the encoded representation when the input <b>audio</b> <b>signals</b> have the second characteristic...|$|R
40|$|Algorithms exist {{which will}} perform {{independent}} transformations on frequency or duration of a digital <b>audio</b> <b>signal.</b> These processes have different results {{different types of}} <b>audio</b> <b>signals.</b> A comparative study of granular and phase vocoder algorithms, implementation, and their respective effects on <b>audio</b> <b>signals</b> was made to determine which algorithm is best suited to {{a particular type of}} <b>audio</b> <b>signal...</b>|$|R
40|$|An Audio decoder for {{decoding}} a multi-audio-object <b>signal</b> {{having an}} <b>audio</b> <b>signal</b> {{of a first}} type and an <b>audio</b> <b>signal</b> of a second type encoded therein is described, the multi-audio-object signal consisting of a downmix signal (56) and side information (58), the side information comprising level information (60) of the <b>audio</b> <b>signal</b> of the first type and the <b>audio</b> <b>signal</b> of the second type in a first predetermined time/frequency resolution (42), and a residual signal (62) specifying residual level values in a second predetermined time/frequency resolution, the audio decoder comprising means (52) for computing prediction coefficients (64) based on the level information (60);; and means (54) for up-mixing the downmix signal (56) based on the prediction coefficients (64) and the residual signal (62) to obtain a first up-mix <b>audio</b> <b>signal</b> approximating the <b>audio</b> <b>signal</b> of the first type and/or a second up-mix <b>audio</b> <b>signal</b> approximating the <b>audio</b> <b>signal</b> of the second type...|$|R
40|$|WO 2009100876 A 1 UPAB: 20090902 NOVELTY - The device has a {{fingerprint}} calculator (304) computing {{a fingerprint}} per block of an <b>audio</b> <b>signal</b> (114) according to block allocation information (302) {{to obtain a}} sequence of test-audio signal-fingerprints (306). A fingerprint extractor (308) extracts a sequence of reference-audio signal-fingerprints from reference <b>audio</b> <b>signal</b> fingerprint information of multi-channel expansion data (132). A fingerprint correlator (312) correlates the two sequences to obtain a correlation result. A compensator (316) controls a time offset between the expansion data and the <b>audio</b> <b>signal</b> based on the result. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (1) a method for synchronizing multi-channel expansion data with an <b>audio</b> <b>signal</b> (2) a device for processing an <b>audio</b> <b>signal</b> (3) a method for processing an <b>audio</b> <b>signal</b> (4) a computer program with a program core for executing a method for processing an <b>audio</b> <b>signal.</b> USE - Device for synchronizing multi-channel expansion data with an <b>audio</b> <b>signal</b> e. g. mono-downmix, stereo-downmix and monophonic <b>audio</b> <b>signal,</b> according to MPEG- 4 standard. ADVANTAGE - The compensator controls the time offset between the multi-channel expansion data and the <b>audio</b> <b>signal</b> based on the correlation result, thus reducing or eliminating the time offset between the multi-channel expansion data and the <b>audio</b> <b>signal,</b> and hence achieving an accurate synchronization by the block-based printing technology in an efficient and reliable manner, while obtaining a multi-channel reconstruction with high quality. The fingerprints represent a better and efficient characteristic for the <b>audio</b> <b>signal...</b>|$|R
50|$|<b>Audio</b> <b>signal</b> {{processing}} is {{the electronic}} manipulation of <b>audio</b> <b>signals</b> using analog and digital signal processing.|$|R
40|$|The thesis {{deals with}} {{negative}} influences of <b>audio</b> <b>signals</b> {{in the environment}} and the impact of the signals on human in psychological and physiological point of view. The origins of such <b>audio</b> <b>signals</b> as well as protection from their negative effects are considered. The thesis includes an overview study of standards and basic literature. Selected <b>audio</b> <b>signals</b> are presented using a program for negative <b>audio</b> <b>signal</b> analysis...|$|R
40|$|Abstract. This paper {{presents}} {{a system of}} <b>audio</b> <b>signal</b> processing based on FPGA,the system uses audio codec chip LM 4550 to A/D transform and D/A transform the input analog <b>audio</b> <b>signal</b> and output digital <b>audio</b> <b>signal.</b> Using FPGA as the high speed signal processor to realize volume adjustment and audio effect control,so it can output different style music. Meantime, the system designs a FFT computing module and control system of VGA display interface,to compute the digital <b>audio</b> <b>signal</b> which is A/D transformed,and real-time display the frequency spectrum of <b>audio</b> <b>signal</b> on VGA...|$|R
40|$|For a {{bandwidth}} {{extension of}} an <b>audio</b> <b>signal,</b> in a <b>signal</b> spreader the <b>audio</b> <b>signal</b> is temporally spread by a spread factor greater than 1. The temporally spread <b>audio</b> <b>signal</b> is then supplied to a demicator to decimate the temporally spread version by a decimation factor matched {{to the spread}} factor. The band generated by this decimation operation is extracted and distorted, and finally combined with the <b>audio</b> <b>signal</b> to obtain a bandwidth extended <b>audio</b> <b>signal.</b> A phase vocoder in the filterbank implementation or transformation implementation {{may be used for}} signal spreading...|$|R
40|$|We {{present a}} method for {{automatically}} equalizing music and <b>audio</b> <b>signals</b> based on information extracted from the signal. The main goal is to enhance the perceived audio quality especially if the sound quality of the <b>audio</b> <b>signal</b> is unsatisfactory. This method is based only on information contained within the <b>audio</b> <b>signal,</b> thus no further informa-tion is needed about recording conditions and equipment. The method adapts the equalizing {{in such a way}} that it re-duces the self-masking within an <b>audio</b> <b>signal,</b> in this way increasing the audibility of the information contained in the <b>audio</b> <b>signal.</b> Assuming that <b>audio</b> quality increases with the audibility of information within the <b>audio</b> <b>signal,</b> this approach will lead to an improved audio quality. ...|$|R
40|$|An {{apparatus}} (100) {{for providing}} direction information {{based on a}} reproduced <b>audio</b> <b>signal</b> with an embedded watermark is provided. The apparatus (100) comprises a signal processor (110), which is adapted to process at least two received watermarked <b>audio</b> <b>signals</b> recorded by at least two audio receivers at different spatial positions. The signal processor (110) is adapted to process the received watermarked <b>audio</b> <b>signals</b> to obtain a receiver-specific information for each received watermarked <b>audio</b> <b>signal.</b> The receiver-specific information depends on the embedded watermarks embedded in the received watermarked <b>audio</b> <b>signals.</b> Moreover, the apparatus comprises a direction information provider (120) for providing direction information based on the receiver-specific information for each received watermarked <b>audio</b> <b>signal...</b>|$|R
50|$|<b>Audio</b> <b>signal</b> flow is {{the path}} an <b>audio</b> <b>signal</b> takes from source to output. The concept of <b>audio</b> <b>signal</b> flow {{is closely related}} to the concept of audio gain staging; each {{component}} in the signal flow {{can be thought of as}} a gain stage.|$|R
40|$|The <b>audio</b> <b>signal</b> coding method {{involves}} {{transforming the}} <b>audio</b> <b>signal</b> into a frequency range, {{in order to}} provide a number of spectral values. A prediction method is used to provide spectral residual values, with subsequent detection of the noise regions for the residual values and noise substitution. The information for the noise regions and the noise substitutions is inserted in the side information of the coded <b>audio</b> <b>signal,</b> e. g. via a bit stream multiplexer (208), with corresponding extraction of this information at the <b>audio</b> <b>signal</b> reception point. USE - For coded <b>audio</b> <b>signal</b> transmission. ADVANTAGE - Enhances coding efficiency...|$|R
3000|$|We {{have tested}} the above {{presented}} scheme with <b>audio</b> <b>signals.</b> Since <b>audio</b> <b>signals</b> are nonstationary and the whitening filter [...]...|$|R
40|$|An <b>audio</b> <b>signal</b> {{processing}} device includes a signal supply for supplying coded <b>audio</b> <b>signal</b> {{over more than}} one input channel and, per input channel, over separate frequency sub-bands domain sub-channels. Further filters are used to decode and synthesize the <b>audio</b> <b>signals</b> over the total frequency domain. Sub-band combination circuits are used for supplying respective input channels to the same sub-band combination circuit the signals from the same sub-band frequency domain <b>audio</b> <b>signals...</b>|$|R
3000|$|... âˆ’ 1 are {{the power}} {{spectrum}} of the original SWB <b>audio</b> <b>signals</b> and extended SWB <b>audio</b> <b>signals</b> at the previous frame.|$|R
40|$|Rapid {{increase}} in data transmission over internet results in emphasis on information security. Audio steganography {{is used for}} secure transmission of secret data with <b>audio</b> <b>signal</b> as the carrier. In the proposed method, cover audio file is transformed from space domain to wavelet domain using lifting scheme, leading to secure data hiding. Text message is encrypted using dynamic encryption algorithm. Cipher text is then hidden in wavelet coefficients of cover <b>audio</b> <b>signal.</b> Signal to Noise Ratio (SNR) and Squared Pearson Correlation Coefficient (SPCC) values are computed to judge {{the quality of the}} stego <b>audio</b> <b>signal.</b> Results show that stego <b>audio</b> <b>signal</b> is perceptually indistinguishable from the cover <b>audio</b> <b>signal.</b> Stego <b>audio</b> <b>signal</b> is robust even in presence of external noise. Proposed method provides secure and least error data extraction. ...|$|R
40|$|An {{apparatus}} for manipulating an <b>audio</b> <b>signal</b> comprising {{a transient}} event comprises a transient signal replacer configured {{to replace a}} transient signal portion, comprising the transient event of the <b>audio</b> <b>signal,</b> with a replacement signal portion adapted to signal energy characteristics {{of one or more}} non-transient signal portions of the <b>audio</b> <b>signal,</b> or to signal energy characteristics of the transient signal portion, to obtain a transient-reduced <b>audio</b> <b>signal.</b> The apparatus also comprises a signal processor configured to process the transient-reduced <b>audio</b> <b>signal</b> to obtain a processed version of the transient-reduced audio signal.; The apparatus also comprises a transient-signal-re-inserter configured to combine the processed version of the transient-reduced <b>audio</b> <b>signal</b> with a transient signal representing, in an original or processed form, a transient content of the transient signal portion...|$|R
3000|$|The first {{condition}} {{prevents the}} singularities in the <b>audio</b> <b>signal</b> that extremely deteriorate the audio quality. The second condition {{requires that the}} <b>audio</b> <b>signal</b> remains in the same length as the original signal within a given time span. The threshold [...] T [...] determines {{the quality of the}} <b>audio</b> <b>signal.</b> The larger the threshold, the worse the <b>audio</b> <b>signal</b> quality would be. Usually the threshold can be selected based on the specific quality requirement and application scenario.|$|R
40|$|In many {{applications}} of <b>audio</b> <b>signal</b> processing modeling {{of the signal}} is required. The most commonly used approach for <b>audio</b> <b>signal</b> modeling is to assume the <b>audio</b> <b>signal</b> as an (autoregressive) AR-process where the <b>audio</b> <b>signal</b> is locally stationary over {{a relatively short time}} interval. In this case the <b>audio</b> <b>signal</b> can be modeled with an all-pole IIR (infinite impulse response) filter, which leads to LPC (linear predictive coding) where the current input sample is predicted by a linear combination of past samples of the input signal. However, in practice the relatively short time interval (i. e. a frame) where the signal is stationary will vary significantly in the <b>audio</b> <b>signal</b> data stream. Also the information content of the frames will show considerable variation. For a proper modeling of an <b>audio</b> <b>signal</b> it is essential that a suitable frame size and appropriate number of model parameters is used instead of a constant frame size and model order. In this paper we present an adaptive frame-by-frame technique for modeling <b>audio</b> <b>signals,</b> which automatically adjusts the optimal modeling frame size and the optimal number of model parameters for each frame...|$|R
40|$|An {{apparatus}} {{for processing}} an <b>audio</b> <b>signal</b> to focus an acoustic signal by {{an arrangement of}} a plurality of loudspeakers comprises a frequency analyzer, a signal processor and a signal output interface. The acoustic signal {{is based on the}} <b>audio</b> <b>signal.</b> The frequency analyzer is configured to determine a fundamental frequency in a frequency spectrum of the <b>audio</b> <b>signal</b> depending on a geometry parameter of the arrangement of the plurality of loudspeakers. The signal processor is configured to adapt an overtone of the fundamental frequency to obtain the processed <b>audio</b> <b>signal</b> and the signal output interface is configured to output the processed <b>audio</b> <b>signal</b> to the plurality of loudspeakers...|$|R
40|$|This article {{describes}} {{an approach to}} the problem of upmixing one-channel <b>audio</b> <b>signals</b> for multi-channel reproduction. The proposed method separates an ambient <b>signal</b> from an <b>audio</b> <b>signal</b> by computing the difference between the <b>audio</b> <b>signal</b> and a suitable approximation of the <b>audio</b> <b>signal</b> in the time-frequency domain. The approximation is derived by means of Non-negative Matrix Factorization minimizing the Kullback-Leibler divergence. A surround <b>audio</b> <b>signal</b> is generated by feeding the separated ambient signal into the rear channels. Results of extensive listening tests confirm the listeners' preference of the upmixed audio compared to unprocessed audio and competing upmix algorithms when played back on a 5. 0 system...|$|R
40|$|WO 2009100875 A 1 UPAB: 20090902 NOVELTY - The device has a block {{formation}} {{device for}} dividing <b>audio</b> <b>signals</b> into successive blocks of scanned values. A finger press-calculator is provided for calculating finger values {{for each of}} successive blocks, and a finger print correlator is provided for comparing fingerprint values. A device is provided for assigning binary values i. e. bits, when the fingerprint value of one of blocks is larger/smaller than the fingerprint value of the other block, respectively. A finger press-reprocessor is provided for outputting information about a sequence of binary values as a fingerprint for the signal. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (1) a method for calculating a finger print of an <b>audio</b> <b>signal</b> (2) a device for synchronizing multiple channel amplification data with an <b>audio</b> <b>signal</b> (3) a device for characterizing test-audiosignals (4) a method for synchronizing multiple channel amplification data with an <b>audio</b> <b>signal</b> (5) a method for characterizing test-audiosignals (6) a computer program with a program code for implementing the methods. USE - Device for calculating a fingerprint of an <b>audio</b> <b>signal</b> e. g. stereo downmix audio-signal, monophonic <b>audio</b> <b>signal</b> and mono-downmix <b>audio</b> <b>signal.</b> ADVANTAGE - The binary values are assigned, when the fingerprint value of one of blocks is larger or smaller than the fingerprint value of the other block, respectively, and information about the sequence of binary values is outputted as the fingerprint for the <b>audio</b> <b>signal,</b> thus calculating the fingerprint of the <b>audio</b> <b>signal</b> in an efficient manner. The individual bit is delivered to the finger print information during one-bit quantization, and the <b>audio</b> <b>signal</b> {{is represented by the}} simple bit-sequence, thus implementing fast, efficient and sudden accurate correlation of the <b>audio</b> <b>signal</b> with the test-bit sequence without requiring 8 -bit quantization or 16 -bit quantization...|$|R
40|$|US 2006075884 A UPAB: 20060510 NOVELTY - The device has a {{provider}} providing a time/spectral representation of an <b>audio</b> <b>signal.</b> A scaler scales the time/spectral representation using curves of equal volume reflecting a human volume perception {{in order to}} obtain a perception-related time/spectral representation. A key determinater (308) determines a melody of the <b>audio</b> <b>signal</b> {{on the basis of the}} perception-related time/spectral representation. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (A) a method for extracting a melody underlying an <b>audio</b> <b>signal</b> (B) a computer program having a program code to perform melody extraction method. USE - Used for extracting a melody of an <b>audio</b> <b>signal,</b> used for the generation of ring tones for mobile telephones from any <b>audio</b> <b>signal,</b> like e. g. singing, humming, whistling or the like. ADVANTAGE - The key determinater determines the melody of the <b>audio</b> <b>signal</b> on the basis of the perception-related time/spectral representation, thus efficiently generating ring tones e. g. polyphonic ring tone, from the <b>audio</b> <b>signal</b> at a reduced cost in a simple manner...|$|R
40|$|An {{audio encoder}} for {{encoding}} an <b>audio</b> <b>signal</b> includes an impulse extractor (10) for extracting an impulse-like portion from the <b>audio</b> <b>signal.</b> This impulse-like portion is encoded and forwarded to an output interface (22). Furthermore, the audio encoder includes a signal encoder (16) which encodes a residual signal {{derived from the}} original <b>audio</b> <b>signal</b> so that the impulse-like portion is reduced or eliminated in the residual <b>audio</b> <b>signal.</b> The output interface (22) forwards both, the encoded signals, i. e., the encoded impulse signal (12) and the encoded residual signal (20) for transmission or storage. On the decoder-side, both signal portions are separately decoded and then combined to obtain a decoded <b>audio</b> <b>signal...</b>|$|R
