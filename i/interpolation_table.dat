9|75|Public
40|$|AbstractSome {{recurrence}} {{relations between}} adjacent {{elements in the}} rational Hermite <b>interpolation</b> <b>table</b> are proved. This enables us to derive two methods for calculating the coefficients of the rational Hermite interpolants. These methods are generalizations of known algorithms for classical Padé approximations...|$|E
40|$|The cernox™ sensor is {{delivered}} with a 3 -point resistance versus temperature cal-ibration that permits {{the construction of}} an individual <b>interpolation</b> <b>table</b> by using the data in the CERN thermometer database. For instance at the 4. 2 K point, the individual calibration and the manufacturer data are within +/- 0. 1 K for 99. 39 % of a sample population of about 5700 sensors. Preliminary results also indicate that accuracies of 0. 1 K and 1 K can be obtained below respectively 5 K and 77 K...|$|E
40|$|This paper {{describes}} an efficient Monte Carlo algorithm for choosing {{a new direction}} of a photon after a scattering interaction. The algorithm chooses a scattering angle by linear interpolation in a table of the inverse cumulative scattering probability. A Legendre expansion of the phase function {{makes it easy to}} apply Clenshaw's algorithm to build the <b>interpolation</b> <b>table.</b> The points in the table are close enough together that linear interpolation is accurate. With a table of 100, 000 entries, we can keep the absolute and relative errors in matching the probability distribution below 10 (exp - 5) ...|$|E
2500|$|... c. 1000 BC– Simple {{fractions}} {{used by the}} Egyptians. However, only unit fractions {{are used}} (i.e., those with 1 as the numerator) and <b>interpolation</b> <b>tables</b> are used to approximate {{the values of the}} other fractions.|$|R
40|$|Shown in {{this paper}} is the {{efficiency}} of a smoothing cubic spline approximation for temperature response curves (TRC) of wide range silicon diode thermometers (SDTs). The offered calculation algorithm allows to describe TRC with a high accuracy and receive the <b>interpolation</b> <b>tables</b> with any temperature step. It allows essentially to expand SDT field of application...|$|R
40|$|A {{simplified}} biokinetic {{model for}} 137 Cs has six parameters representing transfer of material {{to and from}} various compart-ments. Using a Bayesian analysis, the joint probability distribution of these six parameters is determined empirically for two cases with {{quite a lot of}} bioassay data. The distribution is found to be a multivariate log-normal. Correlations between differ-ent parameters are obtained. The method utilises a fairly large number of pre-determined forward biokinetic calculations, whose results are stored in <b>interpolation</b> <b>tables.</b> Four different methods to sample the multidimensional parameter space with a limited number of samples are investigated: random, stratified, Latin Hypercube sampling with a uniform distribution of parameters and importance sampling using a lognormal distribution that approximates the posterior distribution. The import-ance sampling method gives much smaller sampling uncertainty. No sampling method-dependent differences are perceptible for the uniform distribution methods...|$|R
40|$|We generalize {{our earlier}} results on {{rational}} interpolation which were given in Van Barel and Bultheel (this journal, 1990) for the scalar case and in Bultheel and Van Barel (1990) for the vector case {{when all the}} interpolation points coincide, {{to the case of}} vector data given at arbitrary points that may coincide or not. This is the vector-valued Newton-Pade problem. We give a recursive algorithm which has the important advantage over other algorithms that overcome a singularity in the <b>interpolation</b> <b>table,</b> not even in the nonnormal vector case. It also generates all the information needed to give all solutions of the problem. status: publishe...|$|E
40|$|AbstractWe generalize {{our earlier}} results on {{rational}} interpolation which were given in Van Barel and Bultheel (this journal, 1990) for the scalar case and in Bultheel and Van Barel (1990) for the vector case {{when all the}} interpolation points coincide, {{to the case of}} vector data given at arbitrary points that may coincide or not. This is the vector-valued Newton-Padé problem. We give a recursive algorithm which has the important advantage over other algorithms that we do not need a reordering of the given interpolation data to overcome a singularity in the <b>interpolation</b> <b>table,</b> not even in the nonnormal vector case. It also generates all the information needed to give all solutions of the problem...|$|E
40|$|Uncontrolled {{exploitation}} of groundwater {{in many parts}} of the world has led to a sharp drop in groundwater levels. In this study, changes in Ardabil plain groundwater level were studied using geographic information system (GIS). For this purpose, the <b>interpolation</b> <b>table</b> method was used, the intrinsic data as table data of piezo metric wells was used. In order to implement the model, the Majol Geoestatical in geographic information system software was used. The data entered as regions into the geographic information system, and then done for the entire zoning area, due to zoning 8 models, the IDW, GPI, RBF, LPI, KO, KS, KU and EBK in geostatical extension were evaluated. The ordinary kriging method (KO) with the lowest RMSE, was determined as the most accurate one, and finally, as the ultimate method for zoning and map providing for the changes in groundwater levels drop of the region. The results of classification showed that the biggest drop of about 40 meters was in the areas close to the southeastern parts of the study region and in other areas, little changes were observed, this rate of the change and decline in some parts of the desert like southern regions is very tangible and specified...|$|E
40|$|Dryden {{real-time}} flight simulators {{encompass the}} simulation of {{pulse code modulation}} (PCM) telemetry signals. This paper presents a new method whereby the calibration polynomial (from first to sixth order), representing the conversion from counts to engineering units (EU), is numerically inverted in real time. The result is less than one-count error for valid EU inputs. The Newton-Raphson method is used to numerically invert the polynomial. A reverse linear interpolation between the EU limits is used to obtain an initial value for the desired telemetry count. The method presented here is not new. What is new is how classical numerical techniques are optimized {{to take advantage of}} modem computer power to perform the desired calculations in real time. This technique makes the method simple to understand and implement. There are no <b>interpolation</b> <b>tables</b> to store in memory as in traditional methods. The NASA F- 15 simulation converts and transmits over 1000 parameters at 80 times/sec. This paper presents algorithm development, FORTRAN code, and performance results...|$|R
50|$|Gupta {{addressed}} {{since the}} late 1960s {{with the history of}} mathematics, especially the development of Indian trigonometry. Among them his works on Paramesvara and his approximation of the sine function and Govindasvamin and his <b>interpolation</b> of sine <b>tables</b> are notably significant.|$|R
30|$|The {{aircraft}} performance software VarMission {{developed at}} the DLR Institute of Propulsion Technology was employed to calculate fuel consumption and CO 2 -emissions of each flight in the flight schedules. VarMission is written in Microsoft Visual Basic for Applications (VBA). A Microsoft Access database contains aircraft and engine data. For this study, the tool uses aircraft models from the EUROCONTROL Base of Aircraft Data (BADA) [10]. This database contains information on 91 aircraft types including most large airliners. Aircraft for which no data are available can be represented by models with similar characteristics. In order {{to speed up the}} calculation process, <b>interpolation</b> <b>tables</b> produced by VarMission for all aircraft models were used in this study, which contain pre-calculated flight mission protocols for different ranges and payloads as well as the fuel burn along these profiles. Using these look-up tables in combination with interpolation methods, fuel burn and emissions can be calculated for each flight in the flight schedules. Fuel burn and emissions calculations based on BADA data have a history of being used for global emission inventories (e. g. the FAA’s SAGE inventories) and can be considered a standard for such applications [12].|$|R
40|$|Abstract. The dyadic Green’s {{function}} in multi-layer structures for Maxwell equations {{is a key}} component for the integral equation method, but time consuming to calculate. A novel algorithm, the Fast Interpolation and Filtering Algorithm (FIFA), for the calculation of the dyadic Green’s {{function in}} multi-layer structures is proposed in this paper. We discuss in specific details, ready for use in practical calculations of scattering in layer media, how to apply FIFA to calculate various components of the dyadic Green’s function. The algorithm is based on two techniques: interpolation of Green’s function both in the spectral domain and spatial domain, and low pass filter window based acceleration. Compared to the popular Complex Image Method (CIM), FIFA provides the same speed and overcomes several difficulties associated with CIM while being more general and robust. Specifically, there are no limitations on the frequency range, the number of layers in the structure {{and the type of}} Green’s functions to be calculated, and moreover, no need to extract surface wave poles from the spectral form of the Green’s function. Numerical results are given to demonstrate the efficiency and robustness of the proposed method. Key words: Fast interpolation and filtering algorithm (FIFA); complex image method (CIM); low pass filter window (LPFW); <b>interpolation</b> <b>table</b> (IT); electromagnetic (EM). ...|$|E
40|$|Lecture {{notes in}} pure and applied mathematics, vol. 199 Given a {{modified}} PC fraction with approximants A_n/B_n {{there exists a}} unique pair (L_ 0,L_∞) of formal power series at 0 and ∞ such that A_{ 2 m}/B_{ 2 m} is the weak (m,m) two-point Padé approximant to L_ 0 of order m+ 1 and to L_∞ of order m, while A_{ 2 m+ 1 }/B_{ 2 m+ 1 } is the weak (m,m) two-point Padé approximant to L_∞ of order m and to L_∞ of order m+ 1. The canonical denominators of the even contraction of the modified PC fraction (which is a modified T fraction) are orthogonal Laurent polynomials obtained from the basis { 1, 1 /z,z, 1 /z^ 2,z^ 2, [...] . }, while the canonical denominators of the odd contractions of the modified PC fraction (which is a modified M fraction) are orthogonal Laurent polynomials obtained from the basis { 1,z, 1 /z,z^ 2, 1 /z^ 2, [...] . }. An analogous situation arises when the pair of power series (L_ 0,L_∞) is replaced by Newton series determined by a general <b>interpolation</b> <b>table</b> of points on the real line, the modified PC fraction and its contractions are replaced by appropriate analogous continued fractions, and orthogonal Laurent polynomials are replaced by orthogonal rational functions with poles in the set of interpolation points. In this paper an investigation of these relationships is carried out. status: publishe...|$|E
40|$|This thesis {{developed}} a specific information architecture to serve complex physiological information models and {{a means of}} delivering these models {{in a manner that}} allows interactive and distributed use. By redesign of existing models for distributed use, the HOP architecture provides general access across the Internet; the methods are replicable with many different types of physiological models that produce a variety of results. The concepts and software developed can be reusable by public domain. This thesis defines and explains the complete architecture for the user interface, the model encapsulation, and the communication layer between the client and server and database by developing several common examples. Using the equivalent of interactive browsers to access remote models and display the results, the HOP architecture is built up using platform-independent technology such as CORBA, Java and XML. The existing physiological models are first encapsulated by a suitable software language respect to the legacy models. Then CORBA IDL-XML interfaces are built accordingly as a broker interface connecting user interfaces to encapsulating interfaces. Therefore, the standard user interfaces on the browsers are easily built to access these models through the CORBA ORB and the encapsulating interfaces. This interface software is capable of interpreting and displaying very high-level descriptors and model output such that the amount of data required to be transmitted over the Internet is reduced. Two example models using HOP architecture are given in detail in this thesis. A 5 D <b>interpolation</b> <b>table</b> was created for the cardiovascular model. by Shixin Zhang. Thesis (S. M.) [...] Massachusetts Institute of Technology, Dept. of Mechanical Engineering, 2001. Includes bibliographical references (p. 64 - 66) ...|$|E
40|$|International Telemetering Conference Proceedings / October 26 - 29, 1998 / Town & Country Resort Hotel and Convention Center, San Diego, CaliforniaDryden {{real-time}} flight simulators {{encompass the}} simulation of {{pulse code modulation}} (PCM) telemetry signals. This paper presents a new method whereby the calibration polynomial (from first to sixth order), representing the conversion from counts to engineering units (EU), is numerically inverted in real time. The result is less than onecount error for valid EU inputs. The Newton-Raphson method is used to numerically invert the polynomial. A reverse linear interpolation between the EU limits is used to obtain an initial value for the desired telemetry count. The method presented here is not new. What is new is how classical numerical techniques are optimized {{to take advantage of}} modern computer power to perform the desired calculations in real time. This technique makes the method simple to understand and implement. There are no <b>interpolation</b> <b>tables</b> to store in memory as in traditional methods. The NASA F- 15 simulation converts and transmits over 1000 parameters at 80 times/sec. This paper presents algorithm development, FORTRAN code, and performance results...|$|R
50|$|Starting {{with known}} special cases, the {{calculation}} of logarithms and trigonometric functions can be performed by looking up numbers in a mathematical table, and interpolating between known cases. For small enough differences, this linear operation was accurate enough for use in navigation and astronomy in the Age of Exploration. The uses of interpolation have thrived in the past 500 years: by the twentieth century Leslie Comrie and W.J. Eckert systematized the use of <b>interpolation</b> in <b>tables</b> of numbers for punch card calculation.|$|R
40|$|International audienceIn this paper, {{a memory}} polynomial/linear <b>interpolation</b> look-up <b>table</b> (MP/LILUT) method based on direct {{learning}} architecture is proposed for linearizing a Power Amplifier (PA) with nonlinear memory effects. This method combines the MP technique with linear interpolation LUT technique. Thanks to the linear interpolation LUT technique, the proposed method can achieve {{a good performance}} with a small table size and low complexity. We compare its performances with three other techniques under noisy conditions, particularly with the technique based on indirect learning architecture. Simulation results validate the performances of the proposed method...|$|R
40|$|Inertial Confinement Fusion {{is based}} on the idea of imploding a target (filled with {{deuterium}} and tritium gas) in an attempt to release energy in the form of neutrons. To understand and predict target behavior during the fusion process, it is necessary to produce accurate simulations of the implosion. The equation of state (EOS) f o m an indispensable part of these simulations. In this project several available EOS, both tabular and analytic, were compared. Also, the concept of <b>interpolation</b> from <b>tables</b> as an alternative to using analytic expressions was considered and the accuracy of various interpolation methods was evaluated. I...|$|R
2500|$|Before {{the advent}} of {{powerful}} personal computers, it was common to estimate the correlated color temperature by way of <b>interpolation</b> from look-up <b>tables</b> and charts. The most famous such method is Robertson's, who {{took advantage of the}} relatively even spacing of the mired scale (see above) to calculate the CCT Tc using linear interpolation of the isotherm's mired values: ...|$|R
40|$|In {{the last}} few decades, the amount of space debris has {{dramatically}} increased, and this trend {{is expected to continue}} in the near future. Thus, there is a real risk that two objects in space orbiting about the Earth might collide. Consequently, an effective method for the detection of collisions is required in order to systematically prevent the creation of new space debris, or to study the evolution of the population of space debris after a collision occurs. This research is focused on objects orbiting in the exosphere - in low Earth orbits (LEOs) - because in the past decades these have produced the most serious damage. The methodology proposed in this paper consists of reducing the number of possible pairs of pieces of space debris into a shortlist of possible pairs at real risk of collision, using a filter sequence. This method is achieved by the following two procedures. First, an <b>interpolation</b> ephemerides <b>table</b> is built to compute the state of all the objects at several instants of time. Secondly, using the <b>interpolation</b> ephemerides <b>table,</b> the number of pairs at risk of collision is reduced by three filters. The first two filters are based on the geometry of the orbits and try to exclude pairs not undergoing orbit crossings, while the third filter searches for a time of coincidence. As a result, we have designed a powerful tool {{that can be used to}} avoid collisions between pieces of space debris...|$|R
40|$|Electron {{cyclotron}} resonant scattering features (CRSFs) {{are observed}} as absorption-like {{lines in the}} spectra of X-ray pulsars. A significant fraction of the computing time for Monte Carlo simulations of these quantum mechanical features is spent on the calculation of the mean free path for each individual photon before scattering, since it involves a complex numerical integration over the scattering cross section and the (thermal) velocity distribution of the scattering electrons. We aim to numerically calculate <b>interpolation</b> <b>tables</b> {{which can be used}} in CRSF simulations to sample the mean free path of the scattering photon and the momentum of the scattering electron. The tables also contain all the information required for sampling the scattering electron's final spin. The tables were calculated using an adaptive Simpson integration scheme. The energy and angle grids were refined until a prescribed accuracy is reached. The tables are used by our simulation code to produce artificial CRSF spectra. The electron momenta sampled during these simulations were analyzed and justified using theoretically determined boundaries. We present a complete set of tables suited for mean free path calculations of Monte Carlo simulations of the cyclotron scattering process for conditions expected in typical X-ray pulsar accretion columns (0. 01 <B/B_{crit}<= 0. 12, where B_{crit}= 4. 413 x 10 ^{ 13 } G and 3 keV<=kT< 15 keV). The sampling of the tables is chosen such that the results have an estimated relative error of at most 1 / 15 for all points in the grid. The tables are available online at [URL] A&A, in pres...|$|R
30|$|Equal {{receive antenna}} trajectory: {{in order to}} {{maintain}} a constant Doppler spread, the rotation speed has to be divided by the <b>interpolation</b> factor (see <b>Table</b> 1). Therefore, as it is shown in Figure 4, the trajectory of the receive antenna during the transmission of one LTE subframe does not vary when changing the interpolation factor and antenna velocity as long as the emulated speed is the same.|$|R
40|$|Context. Electron {{cyclotron}} resonant scattering features (CRSFs) {{are observed}} as absorption-like {{lines in the}} spectra of X-ray pulsars. A significant fraction of the computing time for Monte Carlo simulations of these quantum mechanical features is spent on the calculation of the mean free path for each individual photon before scattering, since it involves a complex numerical integration over the scattering cross section and the (thermal) velocity distribution of the scattering electrons. Aims. We aim to numerically calculate <b>interpolation</b> <b>tables</b> {{which can be used}} in CRSF simulations to sample the mean free path of the scattering photon and the momentum of the scattering electron. The tables also contain all the information required for sampling the scattering electron’s final spin. Methods. The tables were calculated using an adaptive Simpson integration scheme. The energy and angle grids were refined until a prescribed accuracy is reached. The tables are used by our simulation code to produce artificial CRSF spectra. The electron momenta sampled during these simulations were analyzed and justified using theoretically determined boundaries. Results. We present a complete set of tables suited for mean free path calculations of Monte Carlo simulations of the cyclotron scattering process for conditions expected in typical X-ray pulsar accretion columns (0. 01 ≤ B/B_(crit) ≤ 0. 12, where B_(crit) = 4. 413 × 10 ^(13) G, and 3 keV ≤ k_BT ≤ 15 keV). The sampling of the tables is chosen such that the results have an estimated relative error of at most 1 / 15 for all points in the grid. The tables are available online (see link in footnote, page 1) ...|$|R
40|$|Subroutine WETAIR calculates {{properties}} {{at nearly}} 1, 500 K and 4, 500 atmospheres. Necessary inputs are assigned values of combinations of density, pressure, temperature, and entropy. <b>Interpolation</b> of property <b>tables</b> obtains dry {{air and water}} (steam) properties, and simple mixing laws calculate properties of air/water mixture. WETAIR is used to test gas turbine engines and components operating in relatively humid air. Program is written in SFTRAN and FORTRAN...|$|R
50|$|While the {{original}} DIGDAT {{program has been}} left relatively untouched, {{there has been a}} new front-end created that will allow the user to name the input file with something more significant than FOR005.DAT. The new input file format allows the user to place comments in the input file. There have also been hooks placed in the DIGDAT that allow for alternate outputs in addition to {{the original}} output format, which is 132 columns wide and slightly user abusive if you intend to import the data into another application. There is a graphical representation of the aircraft output in AC3D, as well as data table output in XML for the JSBSim and FlightGear projects, as well as a free-format LFI (Linear Function <b>Interpolation)</b> data <b>table</b> file.|$|R
40|$|The {{introduction}} of the CNC-technology for the grinding of non-circular forms has improved accuracy and productivity in comparison with copy grinding. Especially the considerably reduced start-up time when changing over to new camforms is favourable to the trend towards greater variety of workpieces. The <b>table</b> <b>interpolation</b> {{discussed in this article}} is an open interface for the determination of geometry and speed. Via this interface the user's know-how can directly flow into the NC-machining...|$|R
50|$|While at the LSHTM, Hilda Woods {{published}} {{papers on}} respiratory disease (Woods, 1927, 1928a), scarlet fever and diphtheria (Woods, 1928b), {{as well as}} a methodological paper (Woods, 1929) that compared analytic and graphical methods for <b>interpolation</b> in life <b>tables.</b> In Greenwood's Divisional report for 1933, Woods' last year at the LSHTM, he described Dr. Hilda M Woods’“Epidemiological Study of Scarlet Fever in England and Wales since 1900”, as the Division’s most important paper.|$|R
40|$|Modern {{analytical}} device models {{become more and}} more complicated and expensive to evaluate in circuit simulation. <b>Interpolation</b> based <b>table</b> look-up device models become increasingly important for fast circuit simulation. Traditional table model trades accuracy for speed and is only used in fast-Spice simulators but not good enough for prime-time Spice simulators such as SPECTRE. We propose a novel table model technology that uses high-order essentially non-oscillatory (ENO) polynomial interpolation in multidimensions to guarantee smoothness in multi-dimensions and high accuracy in approximating i v�q v curves. An efficient transfinite blending technique for the reconstruction of multi-dimensional <b>tables</b> is used. <b>Interpolation</b> stencil is adaptively determined by automatic accuracy control. The method has been proved to be superior to traditional ones and successfully applied in Spectre and Ultrasim for simulating digital, analog, RF, and mixed-signal circuits. 1...|$|R
40|$|Abstract: FPGA-based {{acceleration}} of molecular dynamics simulations (MD) {{has been the}} subject of several recent studies. Here we report on an implementation that we believe to be the first to combine a high-level of FPGA-specific design, systematically determined precision, hardware support for complex force models, and support for simulations of over 250 K particles. The target system consists of a standard PC with a 2004 -era COTS FPGA board. There are several innovations: new microarchitectures for several major components, including the cell list processor and the off-chip memory controller; a novel arithmetic mode; and restructurings of algorithms, e. g., multigrid, to map efficiently to FPGA resources. Extensive experimentation was required to optimize precision, interpolation order, <b>interpolation</b> mode, <b>table</b> sizes, and simulation quality. We obtain a substantial speed-up over a highly tuned production MD code. ...|$|R
40|$|A {{variety of}} {{events such as}} gamma-ray bursts and supernovae may ex-pose the Earth to an {{increased}} flux of high-energy cosmic rays, with poten-tially important effects on the biosphere. Existing atmospheric chemistry soft-ware {{does not have the}} capability of incorporating the effects of substantial cosmic ray flux above 10 GeV. An atmospheric code, the NASA-Goddard Space Flight Center two-dimensional (latitude, altitude) time-dependent at-mospheric model (NGSFC), is used to study atmospheric chemistry changes. We have created a table that, {{with the use of the}} NGSFC code, can be used to simulate the effects of high energy cosmic rays (10 GeV- 1 PeV) ionizing the atmosphere. By <b>interpolation,</b> the <b>table</b> can be used to generate values for other uses which depend upon atmospheric energy deposition by ensembles of high-energy cosmic rays. We discuss the table, its use, weaknesses, and strengths. ...|$|R
40|$|This paper {{describes}} {{a strategy to}} develop an energy management system (EMS) for a charge-sustaining power-split hybrid electric vehicle. This kind of hybrid electric vehicles (HEVs) benefit from the advantages of both parallel and series architecture. However, it gets relatively more complicated to manage power flow between the battery and the engine optimally. The applied strategy in this paper is based on nonlinear model predictive control approach. First of all, an appropriate control-oriented model which was accurate enough and simple was derived. Towards utilization of this controller in real-time, the problem was solved off-line for a vast area of reference signals and initial conditions and stored the computed manipulated variables inside look-up tables. Look-up tables take a little amount of memory. Also, the computational load dramatically decreased, because to find required manipulated variables the controller just needed a simple <b>interpolation</b> between <b>tables...</b>|$|R
40|$|The RELAP 5 - 3 D {{computer}} {{program has been}} improved for analysis of supercritical-pressure, light-water-cooled reactors. Several code modifications were implemented to correct code execution failures. Changes {{were made to the}} steam table generation, steam <b>table</b> <b>interpolation,</b> metastable states, interfacial heat transfer coefficients, and transport properties (viscosity and thermal conductivity). The code modifications now allow the code to run slow transients above the critical pressure as well as blowdown transients (modified Edwards pipe and modified existing pressurized water reactor model) that pass near the critical point...|$|R
40|$|The {{reduction}} of the cumbersome operations of multiplication, division, and powering to addition, subtraction and multiplication {{is what makes the}} Logarithmic Number System (LNS) attractive. Addition and subtraction, though, are the bottleneck of every LNS circuit, for which there are implementation techniques that tradeoff area, latency and accuracy. This paper reviews the methods of <b>interpolation,</b> multipartite <b>tables</b> and cotransformation for LNS addition and subtraction, but special focus is given on a novel version of cotransformation, for which a new special case is identified. Synthesis results compare an already published Hardware Description Language (HDL) library for LNS arithmetic that uses only multipartite tables or 2 nd-order interpolation against a variation of the same library combined with cotransformation. Exhaustive simulation and a graphics example illustrate that the proposed library has smaller area requirements and is more accurate than the earlier library, at the cost of an increase in the latency of the hardware...|$|R
40|$|We {{propose the}} 2 ̆ 2 minvar 2 ̆ 2 {{algorithm}} for computing continuous, continuously invertible, piecewise linear (PL) approximations of color space transformations {{that can serve}} as functional replacements wherever look-up tables are presently used. After motivating the importance of invertible approximants in color space management applications, we review the parameterization and computational implementation of PL functions as representing one useful instance of this notion. Finally, we describe the present version of the minvar algorithm and compare the approximations it yields with standard industrial practice — <b>interpolation</b> of look-up <b>table</b> data...|$|R
40|$|Color space transformations are {{frequently}} used in image processing, graphics, and visualization applications. In many cases, these transformations are complex nonlinear functions, which prohibits {{their use in}} time-critical applications. In this paper, we present a new approach called Minimax Approximations for Color-space Transformations (MACT). We demonstrate MACT on three commonly used color space transformations. Extensive experiments on a large and diverse image set and comparisons with well-known multidimensional lookup <b>table</b> <b>interpolation</b> methods show that MACT achieves an excellent balance among four criteria: ease of implementation, memory usage, accuracy, and computational speed. ...|$|R
