19|1311|Public
40|$|This is {{the second}} year that our group participates in TREC’s Web track. Our {{experiments}} focused on the Topic distillation task. Our main goal was to experiment with the <b>Knowledge</b> <b>Agent</b> (KA) technology [1], previously developed at our Lab, for this particular task. The <b>knowledge</b> <b>agent</b> approach was designed to enhance Web search results by utilizing domain knowledge. We first describe the generic KA approach an...|$|E
40|$|A {{group of}} {{concepts}} and {{reflections on the}} category knowledge and the knowledge management, their advantages, objectives and essential tools are set forth. Also, the relationships with other management tools {{as well as the}} role of <b>knowledge</b> <b>agent</b> and the qualities of the information professionals to perform this function are also stated...|$|E
40|$|The KnowMore project aims at {{providing}} {{active support}} to humans working on knowledge-intensive tasks. To this end the knowledge {{available in the}} modeled business processes or their incarnations in specific workows shall {{be used to improve}} information handling. We present a representation formalism for knowledge-intensive tasks and the specification of its object-oriented realization. An operational semantics is sketched by specifying the basic functionality of the <b>Knowledge</b> <b>Agent</b> which works on the knowledge intensive task representation. The <b>Knowledge</b> <b>Agent</b> uses a meta-level description of all information sources available in the Organizational Memory. We discuss the main dimensions that such a description scheme must be designed along, namely information content, structure, and context. On top of relational database management systems, we basically realize deductive object-oriented modeling with a comfortable annotation facility. The concrete knowledge descriptions are obtained by co [...] ...|$|E
5000|$|Explorations in Information Space: <b>Knowledge,</b> <b>Agents</b> and Organization, co-authored with Ian C. MacMillan and Kyeong Seok Han, Oxford: Oxford University Press, (2007).|$|R
30|$|From {{the results}} of the study, new lines of {{research}} could be found: new <b>knowledge</b> <b>agents</b> trends in networking, comparative studies among national and international networks, among others.|$|R
5000|$|... b. “Customers” of such record {{services}} will be not only other electronic health record systems but also other middleware services such as security components, workflow systems, alerting and decision support services and other medical <b>knowledge</b> <b>agents.</b>|$|R
40|$|In {{this short}} paper we present OCL {{knowledge}} representation for interface constraints using a framework known as MDKR. The semantics of OCL [1, 2] are visualised and {{represented in the}} form of set-relationship diagram and is finally embedded with knowledge semantics. Using these semantics we have developed a formal correctness notation [3] for relationship between interfaces of web pages. Keywords: OCL, <b>Knowledge</b> <b>Agent.</b> 1...|$|E
40|$|This paper {{presents}} the Diamond Tool for knowledge management. The main objective of its specification and implementation {{was to create}} a universal and easily extendable tool for efficient work with knowledge. One of its extensions is the eTrium technology. The principal idea behind this technology is to represent explicitly the knowledge used by the information system by means of a <b>knowledge</b> <b>agent</b> built on the Diamond Tool- in contrary to current approaches, where knowledge is present implicitly (in a disintegrated form) in the program code, the database structure and internal regulations of the firm. Explicit representation of knowledge and the method of work with knowledge that is sug gested in this article, allows to build information systems of much higher quality in lesser time. Equally important is also the possibility of automatic or semi-automatic verification of knowledge managed by the <b>knowledge</b> <b>agent.</b> The paper shows how this can change the way applications are created and what it can be used for. Several commercial projects has already been implemented in the Diamond Tool- by means of the eTrium technology...|$|E
40|$|In this paper, we {{introduce}} a Dynamic Hypermedia System (DHS) for distributed design image databases {{that can provide}} simple and flexible user access capabilities based on perceptional link, so called Uansei link method. As a proof of concept, we have developed a prototype system incorporating the DHS model. Dubbed the Textile Design Image Database System, this database aids designers using apparel CAD systems in different locations, collaborating or working separately, {{in the design of}} clothes, including kimonos. Our purpose has been to create a database that will allow each designer to make the best use of his or her creativity and originality-his or her “style and sensitivity to beauty, ” or Kansei in Japanese. In our DHS, Metanodes are defined as abstract nodes and Metalinks are defined as flexible Kansei links respectively. Metanodes and Metalinks are combined to organize a dynamic hypermedia space from which users can easily retrieve desired design image objects by querying a <b>knowledge</b> <b>agent.</b> The <b>knowledge</b> <b>agent,</b> utilizing the knowledge-base, sets up links from Kansei word objects provided by the user to suitable design image objects among the multimedia databases distributed over the network. The <b>knowledge</b> <b>agent</b> also performs query conversion of individual users ’ subjective Kansei (unique, subjective use of Kansei words) into objective Kansei words using each users ’ individual “user model. ” These objective Kansei words are then converted to equivalent color values. Color value is the means by which all stored design images are characterized. This dynamic linking of Kansei word objects to equivalent design images allows individual users ’ Kansei to influence the retrieval process. The sophisticated andsexible CAD Systems of the future will require multimedia database systems with cooperative supporting capabilities similar to those of our Kansei system. ...|$|E
40|$|The paper studies {{problems}} of satisfiability, decidability and admissibility of inference rules, conceptions of <b>knowledge</b> and <b>agent's</b> <b>knowledge</b> in non-transitive temporal linear logic LTL(Past,m). We find algorithms solving mentioned problems, justify {{our approach to}} consider linear non-transitive time with several examples. Main, most complicated, technical new result is decidability of LTL(Past,m) w. r. t. admissible rules. We discuss several ways to formalize conceptions of <b>knowledge</b> and <b>agent's</b> <b>knowledge</b> within given approach in non-transitive linear logic with models directed to past. Comment: arXiv admin note: text overlap with arXiv: 1405. 055...|$|R
40|$|AbstractIn {{order to}} {{understand}} basic mechanisms of so-called Knowledge Ecosystems, the paper presents a study for modelling the emergence and diffusion of knowledge in regards to environmental conditions. The text gives an outline for the description of Knowledge Ecosystems by integrating 1) models for environmental dynamics based on resources and attractiveness, and 2) models for knowledge dynamics based on the behaviors and processes of <b>knowledge</b> <b>agents</b> (innovators) and agencies. As key methods, the work employs Cellular Automata for the modelling of knowledge environments, as well as agent models for the simulation of <b>knowledge</b> <b>agents</b> (innovators). The paper presents preliminary results of the ongoing study, including a first version of both scopes integrated into one descriptive system...|$|R
5000|$|Customer service <b>agent</b> <b>knowledge</b> base: Allows <b>agents</b> to type in a customer’s {{question}} and guide {{them with a}} response ...|$|R
40|$|The KnowMore project aims at {{providing}} {{active support}} to humans working on knowledge-intensive tasks. To this end the knowledge {{available in the}} modeled business processes or their incarnations in specific workflows shall {{be used to improve}} information handling. We present a representation formalism for knowledge-intensive tasks and the specification of its object-oriented realization. An operational semantics is sketched by specifying the basic functionality of the <b>Knowledge</b> <b>Agent</b> which works on the knowledge intensive task representation. The <b>Knowledge</b> <b>Agent</b> uses a meta-level description of all information sources available in the Organizational Memory. We discuss the main dimensions that such a description scheme must be designed along, namely information content, structure, and context. On top of relational database management systems, we basically realize deductive object- oriented modeling with a comfortable annotation facility. The concrete knowledge descriptions are obtained by configuring the generic formalism with ontologies which describe the required modeling dimensions. To support the access to documents, data, and formal knowledge in an Organizational Memory an integrated domain ontology and thesaurus is proposed which can be constructed semi-automatically by combining document-analysis and knowledge engineering methods. Thereby the costs for up-front knowledge engineering and the need to consult domain experts can be considerably reduced. We present an automatic thesaurus generation tool and show how it can be applied to build and enhance an integrated ontology /thesaurus. A first evaluation shows that the proposed method does indeed facilitate knowledge acquisition and maintenance of an organizational memory...|$|E
40|$|Knowledge {{management}} {{is a relatively}} new academic discipline. Currently, the major studies are in the areas of knowledge transformation and taxonomy. Although many researchers stress that knowledge activists play an essential role in activating the knowledge process, the study of individual behaviour in organisations is neglected. In this paper, we conceptualise the <b>Knowledge</b> <b>Agent</b> Theory (KAT) as a living system and explain its autopoietic characteristics. An empirical study of the organisations that supply stochastic demand products shows that their open work environment and free-thinking atmosphere enable knowledge agents to widen their self-referential and self-observing capacities, which encourages them to activate the knowledge process. Institute of Textiles and ClothingDepartment of Industrial and Systems Engineerin...|$|E
40|$|Faced {{with the}} immensity of new {{biological}} data spurred by the Human Genome Project, bio-ontologies have been generated to provide models of biological concepts to form a semantic framework. Such a semantic framework {{can be used to}} underpin a knowledge management (KM) mechanism to facilitate effective knowledge storage, sharing, and communication across computers for biological research. With regards to DNA sequences, the research process usually starts when biologists acquire new sequences. We propose a knowledge organization mechanism using fuzzy measure similarity with Gene Ontology (GO) to assist researchers by alleviating the difficulties of parsing through an immense amount of data and providing insight into how various organisms function. Based on particular evolving ontologies, a value-added knowledge base and semantic-based <b>knowledge</b> <b>agent</b> were established to return precise results tailored for the user...|$|E
30|$|Although Bayesian {{models are}} elegant and tractable, they assume agents act always rationally [74] and make strong {{assumptions}} on the <b>knowledge</b> <b>agents</b> have about posterior probabilities [49]. However, Bayesian models provide an important benchmark, not necessarily {{due to their}} accuracy but because they give an important reference point with which other models can be compared [35].|$|R
40|$|A {{blackboard}} {{approach is}} presented for {{the selection of}} grinding conditions. The <b>knowledge</b> <b>agents</b> consist of case-based reasoning, neural network reasoning and rule-based reasoning. Case-based reasoning is employed as the main problem-solving agent to select combinations of the grinding wheel and values of control parameters. Rule-based reasoning is employed where relevant data have not yet accumulated in the case base. A neural network is employed to select a grinding wheel if required. The operator has ultimate control over the wheel or the values of control parameters selected. The blackboard approach combines {{the strengths of the}} different <b>knowledge</b> <b>agents</b> to generate hybrid solutions and overcomes the limitations of any single approach. The system works as expected and demonstrates the potential of using artificial intelligence for selection of grinding conditions, as well as the capability to develop a powerful database by learning from experience...|$|R
50|$|The {{knowledge}} level {{refers to the}} <b>knowledge</b> an <b>agent</b> has about its world.|$|R
40|$|Given a {{sufficiently}} large database, {{it is usually}} possible to derive many different hypotheses about the data. Therefore, an important problem in data mining is which hypothesis to select, or, more specifically, how to define a criterion that best articulates {{the requirements of the}} given task domain. This paper presents an approach to this problem, in which a <b>knowledge</b> <b>agent</b> seeks descriptions that optimize a problem-oriented description quality measure. The proposed measure flexibly combines two criteria characterizing descriptions, completeness and consistency gain, into a single numerical measure of description quality Q(w). It is shown that by modifying the parameter w in Q(w), the proposed description quality specializes to different measures described in the literature. The Q(w) measure has been implemented in the AQ 18 learning system, and compared to several other methods, such as Information Gain, PROMISE, CN 2, IREP and RIPPER. A general measure of description utility can be [...] ...|$|E
40|$|A tuple space based object {{oriented}} model for knowledge base representation and interpretation is presented. An architecture for managing distributed knowledge agents is then implemented within the model. The general model {{is based upon}} a database implementation of a tuple space. Objects are then defined as an additional layer upon the database. The tuple space {{may or may not}} be distributed depending upon the database implementation. A language for representing knowledge and inference strategy is defined whose implementation takes advantage of the tuple space. The general model may then be instantiated in many different forms, each of which may be a distinct <b>knowledge</b> <b>agent.</b> Knowledge agents may communicate using tuple space mechanisms as in the LINDA model as well as using more well known message passing mechanisms. An implementation of the model is presented describing strategies used to keep inference tractable without giving up expressivity. An example applied to a power management and distribution network for Space Station Freedom is given...|$|E
40|$|Abstract. The <b>Knowledge</b> <b>Agent</b> Mediation Language (KNAML) is {{designed}} for use in multi-agent reasoning systems. Like conceptual graphs, KNAML represents knowledge using concepts, relations, and graphs. Concepts and relations are linked to form graphs, and graphs may be nested within other graphs. Additional constructs are used to support distributed reasoning and ontological concision. KNAML treats ontologies as knowledge domains that happen {{to be of the}} ontology domain. It uses an ontology of ontologies to define the concept and relation types available in an ontology. KNAML knowledge resources are modular to facilitate rapid development and efficient inter-agent processing. KNAML supports ontological specification of an extensible set of knowledge modalities, such as workflows, decision trees, and graphs that reflect the processing specializations of various knowledge agents and supports multi-modal knowledge authoring. Implemented in Java, KNAML supports subsumption, unification, and binding operations required by the host multi-agent system to carry out knowledge discovery and synthesis. ...|$|E
40|$|This {{paper is}} {{organized}} around three questions: (1) is knowledge a necessary entity in Agent Systems? (2) What {{is the problem}} for individual <b>knowledge</b> intensive <b>agents</b> to cooperate? (3) Provide a possible methodology for design and implement a <b>knowledge</b> intensive <b>agent.</b> <b>Knowledge</b> {{is considered to be}} only emerging during the process when agents coordinate, but not an individually possessed entity by some researchers. Some other researchers consider knowledge as a starting point, a given entity {{that is part of the}} notion of an intelligent agent, and focus on knowledge acquisition, inference and communication. The paper will first have a discussion on this topic from an angle of Activity Theory. Then we have a discussion of the ontology sharing problems in MultiAgent Systems (MAS), based on the Distributed Collective Memory. Finally we introduce a methodology to build a <b>knowledge</b> intensive <b>agent</b> system...|$|R
40|$|Abstract:- Reinforcement {{learning}} {{is applied to}} various fields such as robotics and mechatronics control. The reinforcement {{learning is}} an efficient method to control in unknown environment. This paper discusses a new reinforcement learning algorithm {{which is based on}} Genetic Algorithm and has a hierarchical evolutionary mechanism. The proposed learning algorithm introduces new adaptive action value tables and it enables sharing <b>knowledge</b> among <b>agents</b> effectively. Regarding sharing <b>knowledge</b> among <b>agents,</b> the <b>knowledge</b> is inherited not only across the generations, but also in one generation. As a result, the proposed algorithm achieves effective learning, and realizes robustness learning. Computational simulations using the pong simulator which executes table tennis prove the effectiveness of the proposed algorithm. Key-Words:- Q-Learning, Genetic Algorithm, Sharing <b>knowledge</b> among <b>agents,</b> Robustness of learning...|$|R
5000|$|Individual update：Update {{the private}} <b>knowledge</b> of <b>agent</b> , {{normally}} replace [...] by [...] Some Monte Carlo types {{might also be}} considered.|$|R
40|$|The University of Edinburgh and {{research}} sponsors are authorised to reproduce and distribute reprints and on-line copies for their purposes notwithstanding any copyright annotation hereon. The views and conclusions contained herein are the author’s and shouldn’t {{be interpreted as}} necessarily representing the official policies or endorsements, either expressed or implied, of other parties. We describe a collaborative problem solving architecture driven by semantic based workflow orchestration and constraint solving. These technologies are based on shared ontologies that allow two systems of very different natures to communicate, perform specialised tasks and achieve common goals. We {{give an account of}} our approach for the workflow assisted collaboration with a specialised <b>knowledge</b> <b>agent.</b> In this case, a system with constraint solving capabilities. We found that systems built with Semantic Web based technologies are useful for collaboration and are easier to add additional specialised capabilities. However, much care must be exercised before correct semantics may be exchanged and collaborations occur smoothly...|$|E
40|$|The {{technical}} {{obstacles to}} {{development of the}} Knowledge Web are formidable. A {{solution to this problem}} will include an intelligent agent technology capable of serving limited collections of information resources. It will also provide a scalable infrastructure wherein agents can perform effectively. The prototype architecture uses intelligent software agents to locate relevant knowledge elements and synthesize those elements to produce a usable solution. Individual agents are implemented using <b>knowledge</b> <b>agent</b> shells. These shells are reusable entities tailored to manage specific kinds of information, such as databases, models, and expert systems. Agents utilize managed ontologies and perform knowledge-based reasoning to service information requests. Requests are submitted to the agents via the services of a higher-level entity known as a metaagent. Meta-agents provide administrative oversight of the problem-solving process, marshalling resources and driving agent interaction towards a solution. The Knowledge Web thus combines centralized ontology-driven agent mediation with decentralized knowledge operations. This combination provides a flexible infrastructure capable of exploiting a variety of distributed knowledge sources while serving a heterogeneous and dynamic user population. Keywords: conceptual graphs diagnosis knowledge representation multi-agent systems ontologie...|$|E
40|$|When {{an agent}} acts {{contrary}} to his, all-things-considered, best judgment {{while he is}} able to do the best he acts akratically. Socrates for the first time posed the problem. He believed that akrasia is impossible since nobody can act wrong intentionally or waiver the best. But it sometimes seems that people commit evil intentionally; the reason, according to Socrates, is that they count the action in question as good due to their ignorance. Equating the good and pleasant, Socrates declares that the claim that "reason is sometimes overcome by passion" is baseless. Socrates knows nothing more powerful than knowledge. But Aristotle is known to be a defender of possibility of akrasia. He distinguishes between actualized and suspended <b>knowledge.</b> <b>Agent</b> with suspended knowledge may know related universals but particulars, or he may know both, but his knowledge is superficial like an asleep, insane or a drunken man. It is only the suspended knowledge that might be acted contrary to. It is not comprehensible that an agent equipped with actualized knowledge slips. This paper tries to show that, despite the opinion of some scholars, Aristotle's standpoint is very close to that of Socrates...|$|E
40|$|In this research, we conceptualize {{organizational}} {{learning as}} {{a manifestation of}} the collective learning behavior of <b>knowledge</b> <b>agents</b> in an organization. In a coalition or community of practice, each member possesses partial but complementary knowledge, so that only the team working together as a whole has the full body of knowledge. Organizational learning is exhibited as the change of organizational processes for accomplishing tasks through the collaborative work of members of a coalition...|$|R
40|$|In {{this paper}} we {{introduce}} Epistemic Strategy Logic (ESL), {{an extension of}} Strategy Logic with modal operators for individual knowledge. This enhanced framework allows us to represent explicitly and to reason about the <b>knowledge</b> <b>agents</b> have {{of their own and}} other agents' strategies. We provide a semantics to ESL in terms of epistemic concurrent game models, and consider the corresponding model checking problem. We show that the complexity of model checking ESL is not worse than (non-epistemic) Strategy Logi...|$|R
5000|$|Analysis and Implementation of the Game Arimaa and Appendix Bthesis by Christ-Jan Cox (Universiteit Maastricht, Institute for <b>Knowledge</b> and <b>Agent</b> Technology), Mar 2006 ...|$|R
40|$|A {{healthy diet}} and {{lifestyle}} {{are the most}} effective approaches to prevent disease. Good eating habits are central to a healthy lifestyle. When a person eats {{too much or too}} little on a continual basis, the risk of disease will increase. Therefore, developing healthy and balanced eating habits is essential to disease prevention. This paper proposes an ontology-based multi-agents (OMAS), including a personal <b>knowledge</b> <b>agent,</b> a fuzzy inference agent, and a semantic generation agent, for evaluating the health of diets. Using the proposed approach, domain experts can create nutritional facts for common Taiwanese foods. Next, the users are requested to input foods eaten. Finally, the food ontology and personal profile ontology are constructed by domain experts. Fuzzy markup language (FML) is used to describe the knowledge base and rule base of the OMAS. Additionally, web ontology language (OWL) is employed to describe the food ontology and personal profile ontology. Finally, the OMAS semantically analyzes dietary status for users based on the pre-constructed ontology and fuzzy inference results. Using the generated semantic analysis, people can obtain health information about what they eat, which can lead to a healthy lifestyle and healthy diet. Experimental results show that the proposed approach works effectively and diet health status can be provided as a reference to promote healthy living. © Springer-Verlag 2010...|$|E
40|$|The essay {{proposes to}} re-orient feminist debates on {{epistemology}} towards the care-security nexus as a pathway that can plausibly provide an integral {{understanding of a}} human-centred and eco-minded security. Seeing "gender" in binary terms tends to produce an understanding of "care" as "female" and "security" as "male". Care, when free from the constraints of gender as a binary construct, {{can play an important}} role in revealing the depth of ethical-political concerns and help expand the understanding of security. By revisiting the concept of care present in the two feminist innovations [...] situated knowledge and knowledge production as quilting [...] the essay shows that there are gains to be made in bridging existing rifts between feminist knowledge networks and beyond. The concept of situated knowledge gives significance to care as self-reflexivity [...] an ongoing process and a multifaceted nature of experience in the relation between the knower and the known. Knowledge production as quilting displaces the image of the solitary <b>knowledge</b> <b>agent</b> and provides a flexible approach to epistemology less constrained by teleological assumptions, appealing instead to interdisciplinary and inter-cultural cooperation. Both aspects of feminist epistemology are conducive to address the care-security nexus as an open and dynamic phenomenon, for which a successful inclusion of distinctive insights from different disciplines and cultural frameworks of knowledge would be a gain...|$|E
40|$|This talk {{proposes a}} logic for {{reasoning}} about (multi-agent) epistemic probability models, and for epistemic probabilistic model checking. Epistemic probability models are multi-agent Kripke models that assign to each agent an equivalence relation on worlds and an equivalence relation on lotteries over worlds, where a lottery over (finite) world set W {{is a function}} from W to the positive rational numbers. Uncertainty about probability is modelled as equivalence of lotteries. The difference with the usual approach is that probability is linked to knowledge rather than belief, and that “agent a knows that ϕ ” is equated with “agent a assigns probability 1 to ϕ. ” To motivate our approach, we formulate and prove a Certainty Theorem, stating that certainty in an epistemic probability model M corresponds to knowledge in the epistemic model that results when all lottery information gets erased from M. It follows immediately from this that the certainty operator in epistemic probability logic is an S 5 operator. If there is time, the talk will also introduce PRODEMO, a model checker for epistemic probability logic {{that can be used}} to keep track of information flow about aleatory acts among multiple agents. Probability as a function of degree of information Dans les choses qui ne sont que vraisemblables, la différence des données que chaque homme a sur elles, est une des causes principales de la diversite ́ des opinions que l’on voit régner sur les mêmes objects. Laplace [Lap 14] Relation between Probability and <b>Knowledge</b> <b>Agent</b> a knows ϕ iff the probability a assigns to ϕ equals 1. Let Paϕ be the probability that agent a assigns to ϕ...|$|E
40|$|Mobile agent systems incur {{resource}} overheads as they {{acquire and}} maintain knowledge about their network environment. This paper presents a technique that, for a speci#c set of cases, optimises network resource consumption through dynamic selection of agent interaction protocols. This process {{is made possible}} through learning {{on the part of}} static <b>knowledge</b> <b>agents,</b> which can then predict the likely length of a given search procedure. It is these predications combined with information about the network environment that allow quantitative comparison between di#erent search protocols...|$|R
40|$|We {{argue that}} rather than {{representing}} an <b>agent's</b> <b>knowledge</b> {{as a collection of}} formulas, and then doing theorem proving to see if a given formula follows from an <b>agent's</b> <b>knowledge</b> base, it may be more useful to represent this knowledge by a semantic model, and then do model checking to see if the given formula is true in that model. We discuss how to construct a model that represents an <b>agent's</b> <b>knowledge</b> {{in a number of different}} contexts, and then consider how to approach the model-checking problem...|$|R
40|$|The area of 'Knowledge Management` {{is closely}} related to CSCW as it {{involves}} collaboration in various ways. In this paper we outline our ideas for using collaborative filtering as one element of a knowledge management service in the project Campiello. We also detail what different types of agents we envision for the knowledge management and collaboration service in Campiello and briefly present the current status of the <b>Knowledge</b> <b>Agents</b> Platform which we build for supporting the development and the operation of this agent set...|$|R
