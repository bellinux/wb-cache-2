577|1017|Public
25|$|Consider this 8x8 <b>grayscale</b> <b>image</b> {{of capital}} letter A.|$|E
500|$|In 2015, {{in honor}} of the release of All-New, All-Different Marvel comics line and to pay homage to classic and {{contemporary}} hip hop albums, Marvel released variant covers inspired by these albums. One of them was variant cover of The Mighty Thor comics, based on Madvillainy cover. It used <b>grayscale</b> <b>image</b> of Jane Foster's face behind the metal mask, with a picture of Mjolnir in a small orange square on top right corner and [...] "THE MIGHTY THOR" [...] text in pixelated font on top left.|$|E
50|$|Consider this 8x8 <b>grayscale</b> <b>image</b> {{of capital}} letter A.|$|E
50|$|<b>Grayscale</b> <b>images</b> are {{distinct}} from one-bit bi-tonal black-and-white images, {{which in the}} context of computer imaging are images with only two colors, black and white (also called bilevel or binary <b>images).</b> <b>Grayscale</b> <b>images</b> have many shades of gray in between.|$|R
40|$|Red-green-blue (RGB) {{channels}} of RGB digital photographs were loaded with luminosity-adjusted R, G, and completely white <b>grayscale</b> <b>images,</b> respectively (RGwhtB method), or R, G, and R + G (RGB yellow) <b>grayscale</b> <b>images,</b> respectively (RGrgbyB method), {{to adjust the}} brightness of the entire area of multi-temporally acquired color digital photographs of a rice canopy. From the RGwhtB or RGrgbyB pseudocolor image, cyan, magenta, CMYK yellow, black, L*, a*, and b* <b>grayscale</b> <b>images</b> were prepared. Using these <b>grayscale</b> <b>images</b> and R, G, and RGB yellow <b>grayscale</b> <b>images,</b> the luminosity-adjusted pixels of the canopy photographs were statistically clustered. With the RGrgbyB and the RGwhtB methods, seven and five major color clusters were given, respectively. The RGrgbyB method showed clear differences among three rice growth stages, and the vegetative stage was further divided into two substages. The RGwhtB method could not clearly discriminate between the second vegetative and midseason stages. The relative advantages of the RGrgbyB method were attributed to the R, G, B, magenta, yellow, L*, and a* <b>grayscale</b> <b>images</b> that contained richer information to show the colorimetrical differences among objects than those of the RGwhtB method. The comparison of rice canopy colors at different time points was enabled by the pseudocolor imaging method...|$|R
30|$|A set of <b>grayscale</b> <b>images</b> {{is used to}} {{demonstrate}} {{the performance of the}} proposed algorithm. The images include the standard 8 -bit <b>grayscale</b> <b>images</b> of Lena, Barbara, and an infrared image. The hardware platform of the experiment is a desktop computer with 3.2  GHz CPU and 4  G RAM.|$|R
5000|$|IFS {{representation}} can {{be extended}} to a <b>grayscale</b> <b>image</b> by considering the image's graph as a subset of [...] For a <b>grayscale</b> <b>image</b> u(x,y), consider the setS = {(x,y,u(x,y))}. Then similar to the binary case, S is described by an IFS using a set of contraction mappings ƒ1,...,ƒN, but in , ...|$|E
5000|$|... #Caption: A <b>grayscale</b> <b>image</b> {{represented}} in 1 bit black-and-white space with dithering ...|$|E
5000|$|... 1985: VIEW 1220 - A 2nd generation, <b>grayscale</b> <b>image,</b> machine vision-based CMM ...|$|E
5000|$|Image colorization, where {{color is}} {{automatically}} added to <b>grayscale</b> <b>images.</b>|$|R
40|$|Based {{on a set}} of {{morphological}} distances computed {{between the}} <b>grayscale</b> <b>images</b> (spatial fields) of similar size specifications, the ratios of selected morphological distances, and the ratios of areas of infima and suprema of <b>grayscale</b> <b>images,</b> a new metric to quantify the degree of similarity between the <b>grayscale</b> <b>images</b> is proposed. We denote the two spatial fields (<b>grayscale</b> <b>images),</b> respectively, with fi and fj, and the infima and suprema of these spatial fields with (fi ∧ fj) and (fi ⋁ fj). The three morphology-based distances include: 1) dilation distance d(fi, fj); 2) erosion distance e(fi, fj); and 3) median-based distance MN(fi, fj). By employing these parameters, which play vital role in construction of parameter-specific interaction matrices, we provide a metric to designate every possible pair of images that can be considered out of a database consisting of a huge number of images. We demonstrate the whole approach on: 1) synthetic spatial fields; 2) a set of 12 similar-sized <b>grayscale</b> <b>images</b> representing cloud-top temperatures of a specific region for 12 different time instants; and 3) four spatial elevation fields to rank possible pairs of images...|$|R
40|$|The {{utility of}} digital stereo optic disc images for {{glaucoma}} {{was assessed by}} comparing primary digital stereo images to 35 -mm slides and scanned and <b>grayscale</b> <b>images.</b> Whereas color seemingly adds little to stereo <b>grayscale</b> <b>images,</b> digital images are useful for evaluating the optic disc in stereo and should allow the application of advanced image processing techniques...|$|R
5000|$|In {{the digital}} realm, {{there can be}} any number of {{conventional}} primary colors making up an image; a channel {{in this case is}} extended to be the <b>grayscale</b> <b>image</b> based on any such conventional primary color. By extension, a channel is any <b>grayscale</b> <b>image</b> the same size with the [...] "proper" [...] image, and associated with it.|$|E
5000|$|The {{marketing}} <b>grayscale</b> <b>image</b> for {{the fragrance}} is a [...] "ripped male torso." ...|$|E
5000|$|... #Caption: CIELAB {{lightness}} preserved, with a* and b* stripped, {{to make a}} <b>grayscale</b> <b>image</b> ...|$|E
50|$|Perestroika Girls, using <b>grayscale</b> <b>images</b> on 8-bit hardware, {{is similar}} to Taito's Super Qix.|$|R
40|$|In this paper, {{we propose}} {{a method for}} {{steganalysis}} of <b>grayscale</b> <b>images</b> using both spatial and Gabor features. The basis of our work is to use Gabor filter coefficients and statistics of the graylevel co-occurrence matrix of images to train a support vector machine. We show that this feature set works well in steganalysis of <b>grayscale</b> <b>images</b> steganographied by LSB matching and S-tools...|$|R
50|$|Compression {{efficiency}} {{increases with}} higher image complexity and color depth, compared to simple <b>grayscale</b> <b>images.</b>|$|R
5000|$|... #Caption: <b>Grayscale</b> <b>image</b> of van de Velde's oil {{painting}} of the action, based on the previous sketch ...|$|E
5000|$|... 1985: VIEW 720 - A 2nd generation, general-purpose, <b>grayscale</b> <b>image,</b> {{machine vision}} system for shop floor use ...|$|E
50|$|Color {{digital images}} {{are made of}} pixels, and pixels are made of {{combinations}} of primary colors represented {{by a series of}} code. A channel in this context is the <b>grayscale</b> <b>image</b> of the same size as a color image, made of just one of these primary colors. For instance, an image from a standard digital camera will have a red, green and blue channel. A <b>grayscale</b> <b>image</b> has just one channel.|$|E
30|$|Step 1 : Transfer the four-color {{images to}} the {{corresponding}} <b>grayscale</b> <b>images</b> using color-to-grayscale image processing.|$|R
40|$|Image {{colorization}} adds {{color to}} <b>grayscale</b> <b>images.</b> It not only increases the visual appeal of <b>grayscale</b> <b>images,</b> but also enriches {{the information contained}} in scientific images that lack color information. Most existing methods of colorization require laborious user interaction for scribbles or image segmentation. To eliminate the need for human labor, we develop an automatic image colorization method using epitome. Built upon a generative graphical model, epitome is a condensed image appearance and shape model which also proves to be an effective summary of color information for the colorization task. We train the epitome from the reference images and perform inference in the epitome to colorize <b>grayscale</b> <b>images,</b> rendering better colorization results than previous method in our experiments...|$|R
3000|$|Hereafter, the {{enhanced}} four <b>grayscale</b> <b>images</b> F_i^" [...] (x,y) [...] {{and the corresponding}} histograms can be achieved.|$|R
5000|$|... #Caption: Fourier {{transform}} modulus (diffraction pattern) of the <b>grayscale</b> <b>image</b> shown being reconstructed {{at the top}} of the page.|$|E
5000|$|... #Caption: Iterations 0, 100, 200, 300 and 400 in the difference-map {{reconstruction}} of a <b>grayscale</b> <b>image</b> from its Fourier transform modulus ...|$|E
5000|$|Homomorphic Filtering can be {{used for}} {{improving}} the appearance of a <b>grayscale</b> <b>image</b> by simultaneous intensity range compression (illustration) and contrast enhancement (reflection).|$|E
3000|$|The {{stereo camera}} {{provides}} {{a pair of}} <b>grayscale</b> <b>images</b> (left and right) and a corresponding disparity map. Below, I [...]...|$|R
30|$|In the {{training}} of the SVM, HOG features were extracted from {{the training}} <b>images</b> (converted into <b>grayscale</b> <b>images),</b> and the SVM was trained using the HOG features. In the testing of the SVM, the identification of arrangement patterns was performed by inputting HOG features extracted from the testing <b>images</b> (converted into <b>grayscale</b> <b>images)</b> into the trained SVM. Table  1 shows identification accuracy. The proposed method shows higher accuracy than the baseline method.|$|R
40|$|Self-Organizing Maps are {{commonly}} used for unsupervised learning purposes. This paper {{is dedicated to the}} certain modification of SOM called SOMN (Self-Organizing Mixture Networks) used as a mechanism for representing <b>grayscale</b> digital <b>images.</b> Any <b>grayscale</b> digital <b>image</b> regarded as a distribution function can be approximated by the corresponding Gaussian mixture. In this paper, the use of SOMN is proposed in order to obtain such approximations for input <b>grayscale</b> <b>images</b> in unsupervised manner...|$|R
5000|$|... {{histogram}}Counts is a 256-element histogram of a <b>grayscale</b> <b>image</b> different gray-levels (typical for 8-bit images). {{level is}} the threshold for the image (double).|$|E
50|$|Thresholding is the {{simplest}} method of image segmentation. From a <b>grayscale</b> <b>image,</b> thresholding {{can be used}} to create binary images (Shapiro, et al. 2001:83).|$|E
5000|$|It {{represents}} motion {{sequence in}} a compact manner. In this case, the silhouette sequence is condensed into a <b>grayscale</b> <b>image,</b> where dominant motion information is preserved.|$|E
3000|$|... and f: Ω→R be color (n = 3) and <b>grayscale</b> <b>images,</b> respectively, {{and they}} are defined on domain of Ω→R [...]...|$|R
40|$|Considered as {{topographic}} reliefs, <b>grayscale</b> <b>images</b> can be decomposed into {{a number}} of peaks that can be stored in the data structure of a tree. This decomposition is called the peak analysis of <b>grayscale</b> <b>images</b> in this paper. Its mathematical definition and its fast algorithm based on the watershed transform are both presented. Due to its intuitive definition, there is a wide range of applications for the peak analysis. One of them was to measure the quantum dots in the AFM photos...|$|R
5000|$|Print {{each of the}} <b>grayscale</b> <b>images</b> (Cyan, Magenta, Yellow, and Black) onto inkjet {{transparency}} film {{in black}} and white. (Thin images work better than dense ones.) ...|$|R
