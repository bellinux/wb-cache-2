85|45|Public
5000|$|It {{is assumed}} that {{preferences}} are similar for <b>expert</b> <b>listeners</b> and naive listeners and thus results of <b>expert</b> <b>listeners</b> are also predictive for consumers. In agreement with this assumption Schinkel-Bielefeld et al. [...] found no differences in the rank order between <b>expert</b> <b>listeners</b> and untrained listeners when using test signals containing only timbre and no spatial artifacts. However, Rumsey et al. [...] showed that for signals containing spatial artifacts, <b>expert</b> <b>listeners</b> weigh spatial artifacts slightly stronger than untrained listeners, who primarily focus on timbre artifacts.|$|E
5000|$|Both, MUSHRA and ITU BS.1116 tests {{call for}} trained <b>expert</b> <b>listeners</b> {{who know what}} typical {{artifacts}} sound like {{and where they are}} likely to occur. <b>Expert</b> <b>listeners</b> also have a better internalization of the rating scale which leads to a better retest reliability than untrained listeners. Thus, fewer listeners are needed to achieve significant results.|$|E
50|$|<b>Expert</b> <b>listeners</b> will detect {{also the}} {{influences}} of Slavic, Jewish, and Arabic.|$|E
40|$|The timbral {{elements}} in music analysis of have hitherto resisted systematic analysis {{due to the}} lack of tools to objectify them. This is increasingly important as modern composers exploit new acoustic resources. In this study a range of digital tools were applied to the analysis of acousmatic music, including scoring, analysis and modelling techniques. These tools are described and applied to a seminal acousmatic musical piece such that the outputs of computer models of perception can be compared to the <b>expert</b> <b>listener’s</b> analysis...|$|R
40|$|We {{investigate}} explicit segment duration {{models in}} addressing the problem of fragmentation in musical audio segmentation. The resulting probabilistic models are optimised using Markov Chain Monte Carlo methods; in particular, we introduce a modification to Wolff's algorithm to make it applicable to a segment classification model with an arbitrary duration prior. We apply this to a collection of pop songs, and show experimentally that the generated segmentations suffer much less from fragmentation than those produced by segmentation algorithms based on clustering, and are closer to an <b>expert</b> <b>listener's</b> annotations, as evaluated by two different performance measures...|$|R
50|$|Doctor Strangelove: a {{copyright}} infringing relationship <b>expert</b> that gives <b>listeners</b> generally completely irrelevant advice for love.|$|R
5000|$|In {{addition}} to this, {{it has been}} shown that <b>expert</b> <b>listeners</b> make more use of the possibility to listen to smaller sections of the signals under test repeatedly and compare more between the signals under test and the reference. This can be seen as a shift from preference rating to audio quality rating, which means rating the differences between the signal under test and the uncompressed original, which is the actual goal of a MUSHRA-test.|$|E
40|$|This study {{investigated}} the inter-rater and intra-rater reliability of ratings in evaluating voice quality change of a patient using a paired comparison method with a seven-point equal appearing interval scale. Thirty-one naïve listeners, who had no prior perceptual training, and three <b>expert</b> <b>listeners,</b> who had {{at least five years}} experience in perceptual voice evaluation, completed a perceptual rating task using the paired comparison method. Results showed that <b>expert</b> <b>listeners</b> achieved a moderate inter-rater reliability (ICC = 0. 529) and naïve listeners achieved a fair inter-rater reliability (ICC = 0. 347). Intra-rater reliability for <b>expert</b> <b>listeners</b> was significantly higher than naïve listeners (U = 10. 0, z = - 2. 22, p <. 05, r = − 0. 380). The findings indicated that paired comparison method could be a reliable method for <b>expert</b> <b>listeners</b> in detecting perceptual voice quality change. However, naïve listeners who had no previous perceptual training, may not give as reliable ratings using paired comparison method. published_or_final_versionSpeech and Hearing SciencesBachelorBachelor of Science in Speech and Hearing Science...|$|E
40|$|The {{purpose of}} this study was to further {{investigate}} the effects of articulation errors on perceptual ratings of nasality in speakers with repaired cleft palates, specifically looking at the effect of varying magnitudes of articulation errors and education on perception of nasality. A group of <b>expert</b> <b>listeners,</b> speech-language pathologists with significant clinical experience in the area of cleft palate and resonance disorders, first rated the articulatory proficiency and nasality of a number of utterances produced by children with repaired cleft palates, on separate 6 -point scales. Their ratings were then used to categorize stimuli into a three-by-three matrix (mild, moderate, severe) using articulation deficit and nasality as the two dimensions of interest. Untrained listeners (undergraduates and graduate students in a speech-language pathology training program) were then asked to rate the level of nasality on a 1 (normal) to 6 (severe) scale. Listener group ratings were compared to each other and to the <b>expert</b> <b>listeners.</b> Significant differences (p= 0. 004) were found between the undergraduate and graduate students 2 ̆ 7 ratings when compared to the <b>expert</b> <b>listeners.</b> Graduates, had lower inter- and intra-rater reliability compared to the undergraduates. For both undergraduates and graduates, the difference between their ratings and those of the <b>expert</b> <b>listeners</b> was significantly lower for stimuli with mild articulation errors compared to those with moderate (p 3 ̆c 0. 0001) and severe (p 3 ̆c 0. 0001) articulation errors. No significant differences (p= 0. 416) were found between difference scores for stimuli with moderate versus severe articulation errors. The results were interpreted to suggest that the magnitude, and perhaps type, of articulation errors affects perceived nasality, and that there are group differences between perceptual nasality ratings. These findings support the importance of articulation therapy for children with repaired cleft palates to both decrease articulation errors and decrease perceived nasality. Further, this study highlights the need for including awareness of this interaction in the training of speech-language pathologists in order for the “gold standard” of perceptual judgements to remain a valid and reliable measure...|$|E
50|$|Death, Sex + Money is an interview-style podcast {{hosted by}} Anna Sale that {{discusses}} personal dilemmas. The podcast launched in May 2014 and {{is produced by}} WNYC Studios. The podcast features celebrities, <b>experts</b> and <b>listeners</b> on topics of finance, grief, love and relationships.|$|R
40|$|Computer {{models for}} {{determining}} key boundaries are important tools for computer analysis of music, computational modeling of music cognition, content-based categorization and retrieval of music information and automatic generating of expressive performance. This paper proposes a Boundary Search Algorithm (BSA) for determining points of modulation {{in a piece}} of music using a geometric model for tonality called the Spiral Array. For a given number of key changes, the computational complexity of the algorithm is polynomial in the number of pitchevents. We present and discuss computational results for two selections from J. S. Bach's "A Little Notebook for Anna Magdalena". Comparisons between the choices of an <b>expert</b> <b>listener</b> and the algorithm indicates that in human cognition, a dynamic interplay exists between memory and presentknowledge, thus maximizing the opportunity for the information to coalesce into meaningful patterns. ...|$|R
40|$|Abstract: Background. A {{pneumatic}} artificial {{sound source}} incorporated {{in a regular}} tracheoesophageal shunt valve may improve alaryngeal voice quality. Methods. In 20 laryngectomees categorized for sex and pharyngoesophageal segment tonicity, a prototype sound-pro-ducing voice prosthesis (SPVP) is evaluated {{for a brief period}} and compared with their regular tracheoesophageal shunt speech. Results. Perceptual voice evaluation by an <b>expert</b> <b>listener</b> and acoustical analysis demonstrate a uniform rise of vocal pitch when using the SPVP. Female laryngectomees with an atonic pharyngoesophageal segment gain vocal strength with the SPVP. Exerted tracheal pressure and airflow rate are equivalent to those required for regular tracheoesophageal shunt valves. However, communicative suitability and speech intelligibility deteriorate by the SPVP for most patients. Tracheal phlegm clogging the SPVP is a hindrance for most patients. Conclusions. The SPVP raises vocal pitch. Female laryngec-tomees with an atonic or severely hypotonic pharyngoesopha-geal segment can benefit from a stronger voice with the SPVP...|$|R
40|$|A radio speech {{corpus of}} 9 mn has been prosodically {{marked by a}} phonetician expert, and non <b>expert</b> <b>listeners.</b> this corpus {{is large enough to}} train and test an {{automatic}} boundary spotting system, namely a time delay neural network fed with F 0 values, vowels and pseudo-syllable durations. Results validate both prosodic marking and automatic spotting of prosodic events. Comment: 4 page...|$|E
30|$|The {{limitations}} of perceptual speech evaluation by experts are seen when {{the results of}} the different experts, given in Table 3, are compared to each other. Although the experts' evaluations show a good correlation, their mean scores vary considerably between different <b>expert</b> <b>listeners</b> [24]. Previous studies even yielded more variability for linear ratings of laryngectomees' speech [25]. These findings support the need for objective and automatic speech evaluation.|$|E
40|$|In sociolinguistics, {{language}} variation in vowel sounds is typically studied using phonetic transcription. Phonetic transcription {{is carried out}} by <b>expert</b> <b>listeners,</b> {{who are capable of}} perceptually separating (socio-) linguistic variation from anatomical/physiological speaker-related characteristics. However, phonetic transcription is a very laborious task and its reliability is questionable. In phonetics, vowel normalization procedures were designed to separate linguistic variation from anatomical/physiological variation in acoustic measurements. In this thesis, it is evaluated whether vowel normalization procedures are suitable for use in sociolinguistics, for studying {{language variation}} in vowels. It is described how 12 procedures for vowel normalization were compared. This comparison consists of two parts. First, the procedures were evaluated in the acoustic domain by applying them to acoustic (formant and fundamental frequency) measurements of a database of vowels pronounced by 160 Dutch teachers from the Netherlands and Flanders. The procedures were evaluated on how well they preserved (socio-) linguistic variation and minimized anatomical/physiological variation. Second, the normalization procedures were compared in a perceptual-acoustic comparison; a comparison with perceptual judgments made by <b>expert</b> <b>listeners.</b> The normalization procedures were applied to the acoustic measurements of vowel tokens from 20 of the 160 Dutch teachers. These tokens were also judged by <b>expert</b> <b>listeners</b> on their perceived (socio-) linguistic characteristics, i. e., tongue height, tongue position, and lip rounding in a listening experiment. Next, the transformed acoustic measurements were compared to the perceptual judgments using linear regression analysis, to evaluate how well the output of the normalization procedures modeled the perceived (socio-) linguistic characteristics of the vowel tokens. These two comparisons of the 12 normalization procedures show that procedures that incorparate information (e. g., the mean or standard deviation of the formant measurements) about other vowels produced by a speaker are most succesful in the acoustic evaluation {{as well as in the}} perceptual-acoustic compariso...|$|E
40|$|I am {{conducting}} a Grounded Theory study into measuring opinions of urban soundscapes. Participants {{are given a}} small portable recording device and asked to keep a sound diary for two weeks. At {{the end of the}} two weeks, they are given a 60 -minute interview about their experiences. The methodology is designed to give people time to think about soundscapes on their own terms, recording what is important to them, rather than using a researcher-selected environment and vocabulary. Early data suggests people listen in a multitude of ways that challenge existing ideas of modes of listening, care more about work and home environments than public places, and that the role and importance of soundscape is both quantitatively and qualitatively different in varying environments. I also question the idea of what an <b>expert</b> <b>listener</b> is, with examples of various ways participants have demonstrated very high aural acuity without any acoustics, sound engineering or musical background, for instance. ...|$|R
40|$|In this study, Hidden Markov Models (HMMs) {{were used}} to {{evaluate}} pronunciation. Native and non-native speakers were asked to pronounce ten Dutch words. Each word was subsequently evaluated by an <b>expert</b> <b>listener.</b> Her main task was to decide whether a word was spoken by a native or a non-native speaker. For each word type, two versions of prototype HMMs were defined: one to be trained on tokens produced by a single native speaker, and another to be trained on tokens produced {{by a group of}} native speakers. For testing the different types of HMM, forced recognition was performed using native and non-native judged tokens. We expected that recognition with multispeaker HMMs would allow a more effective discrimination between native and non-native tokens than recognition with single-speaker models. A comparison of Equal Error Rates partly confirmed this hypothesis. INTRODUCTION This paper describes an experiment in which Hidden Markov Models (HMMs) were applied for the evaluation of pronunci [...] ...|$|R
40|$|International audiencePrevious {{studies on}} the pitch of long-duration vibrato tones have {{typically}} used synthesised frequency modulated tones to assess the perceived pitch in relation to its mean fundamental frequency. In this study a listening test was conducted with <b>expert</b> <b>listener</b> subjects matching recorded vibrato tones sung by professional singers using a method of adjustment within a free response paradigm as employed by van Besouw et al. 2009. Tones from recordings by 16 singers {{were used in the}} test, 8 of whom were employed at the Royal Opera House, Covent Garden, and the remaining singers specialised in Early Music Performance. A previous study in the vibrato usage by these singers shows a noticeable difference in the use of vibrato between these performance groups, particularly in extent, throughout long tones (Daffern, 2008). The impact of these differences in vibrato will be assessed in terms of the perception of pitch in long tones as performed by the two groups of singers, and the effectiveness of using real recordings to assess listener perception of vibrato tones will be discussed...|$|R
40|$|To {{determine}} the perceptual importance {{of differences in}} noise characteristics, a sample of pathological voices was modeled using analysis by synthesis techniques. Spectral characteristics of noise were varied to create different synthetic versions of each voice sample. <b>Expert</b> <b>listeners</b> compared each synthetic stimulus to the original voice sample. The perceptual importance of differences in how vocal noise is synthesized will be discussed, as will the relative contributions of jitter, shimmer, and aspiration noise in modeling pathological phonation...|$|E
40|$|In {{this paper}} the {{performance}} of an automatic transcription tool is evaluated. The transcription tool is a Continuous Speech Recognizer (CSR) running in forced recognition mode. For evaluation {{the performance of}} the CSR was compared to that of nine <b>expert</b> <b>listeners.</b> Both man and the machine carried out exactly the same task: deciding whether a segment was present or not in 467 cases. It turned out that {{the performance of the}} CSR is comparable to that of the experts. 1...|$|E
40|$|There {{is lack of}} {{agreement}} {{on the extent to}} which infants vocalizations are influenced by the sounds of the ambient language. In this experiment, 5 <b>expert</b> <b>listeners</b> were asked to discern ambient language effects on babbled vocalizations produced by American and Swedish 12 and 18 -month-olds. Listener responses revealed considerable individual variability among children in both age groups; whereas about half of the 18 -monthers were correctly recognized with respect to ambient language, most but not all 12 -monthers produce...|$|E
40|$|From {{monologue}} to dialogue; Radio {{and reform}} in Indonesia analyses how radio journalism {{since the late}} 1990 s has been shaped by and contributed to Reformasi, or the ambition of democratizing Indonesian politics, economy and society. The book examines ideas and practices such as independent journalism, peace journalism, meta-journalism, virtual interactivity, talk-back radio and community radio, which have all been designed to renew audience interest in media and societal affairs. It pays special attention to radio programmes that enable hosts, <b>experts,</b> <b>listeners</b> and other participants to discuss and negotiate the very rules and boundaries of Indonesia’s newly acquired media freedom. The author argues that these contemporary programmes provide dialogic alternatives to the official New Order discourse dominated by monologism. Edwin Jurriëns is Lecturer in Indonesian Language and Culture at the University of New South Wales, Canberra, Australia. He is author of Cultural travel and migrancy; The artistic representation of globalization in the electronic media of West Java (KITLV, 2004) and co-editor of Cosmopatriots; On distant belongings and close encounters (Rodopi, 200...|$|R
40|$|MuSA. RT is a {{collaborative}} research project integrating real-time music processing and contentbased graphical rendering in interactive immersive environments. 3. Project Role in Support of IMSC Strategic Plan The main {{outcome of this}} project {{is the development of}} systems for real-time analysis and interactive visualization of tonal patterns in music. From a project design and implementation point of view, MuSA. RT is an experiment in complex, cross-disciplinary multi-modal real-time system integration that serves as a model for larger scale integration experiments. 4. Discussion of Methodology Used A defining feature of tonal music is the unfolding of pitch structures over time. Real-time tracking of tonal patterns in music has widespread applications in music analysis, information retrieval, performance analysis and expression synthesis. Each piece of music consists of a sequential arrangement of notes that generates pitch structures over time. An <b>expert</b> <b>listener</b> is able to ascertain the keys and harmonic patterns traversed over time. But a novice or a computer would benefit greatly from a geometric model that can provide visual cues and numeric quantifying of these tonal properties...|$|R
2500|$|In {{the late}} 1970s, Levitin {{consulted}} for M Sound as an <b>expert</b> <b>listener</b> assisting {{in the design}} of the first commercial satellite and subwoofer loudspeaker systems, an early version of which were used by Steely Dan for mixing their album Pretzel Logic (1974). [...] Following that, he worked at A Broun Sound in San Rafael, California, building speaker cabinets for The Grateful Dead, for whom he later worked as a consulting record producer. [...] Levitin was one of the golden ears used in the first Dolby AC audio compression tests, a precursor to MP3 audio compression. From 1984–1988, he worked as Director and then Vice President of A for 415 Records in San Francisco, becoming President of the label in 1989 before the label was sold to Sony Music. [...] Notable achievements during that time included producing the punk classic Here Come the Cops by The Afflicted (named among the Top 10 records of 1985 by GQ magazine); engineering records by Jonathan Richman and the Modern Lovers, Santana, and the Grateful Dead; and producing tracks for Blue Öyster Cult, the soundtrack to Repo Man (1984), and others. Two highlights of his tenure in A were discovering the band The Big Race (which later became the well-known soundtrack band Pray for Rain); and for having had the chance to, but not signing M.C. Hammer.|$|R
40|$|Audio quality {{evaluation}} for audio material of intermediate and high quality requires <b>expert</b> <b>listeners.</b> In comparison to non-experts, {{these are not}} only more critical in their ratings, but also employ different strategies in their evaluation. In particular they concentrate on shorter sections of the audio signal and compare more to the reference than inexperienced listeners. We created a listener training for detecting coding artifacts in multi-channel audio {{quality evaluation}}. Our training is targeted at listeners without technical background. For this training, <b>expert</b> <b>listeners</b> commented on smaller sections of an audio signal they focused on in the listening test and provided {{a description of the}} artifacts they perceived. The non-expert listeners participating in the training were provided with general advice for helpful strategies in MUSHRA tests (Multi Stimulus Tests with Hidden Reference and Anchor), with the comments on specific sections of the stimulus by the experts, and with feedback after rating. Listener's performance improved {{in the course of the}} training session. Afterwards they performed the same test without the training material and a further test with different items. Performance did not decrease in these tests, showing that they could transfer what they had learned to other stimuli. After the training they also set more loops and compared more to the reference...|$|E
40|$|International audienceSix male music theatre singers were {{recorded}} in three different voice qualities: legit and two types of belt (‘chesty’ and ‘twangy’), on two vowels ([e] and [ɔ]), at four increasing pitches in the upper limit of each singer’s belt range (~ 250 - 440 Hz). The audio signal, the electroglottographic (EGG) signal and the vocal tract impedance were all measured simultaneously. Voice samples were analyzed and then evaluated perceptually by sixteen <b>expert</b> <b>listeners.</b> The three qualities were produced with significant differences at the physiological, acoustical and perceptual levels: Singers produced belt qualities with a higher EGG contact quotient (CQEGG) and greater contacting speed quotient (Qcs), greater sound pressure level (SPL) and energy above 1 kHz (alpha ratio), and with higher frequencies {{of the first two}} vocal tract resonances (fR 1, fR 2), especially in the upper pitch range when compared to legit. Singers produced the chesty belt quality with higher CQEGG, Qcs and SPL values and lower alpha ratios over the whole belt range, and with higher fR 1 at the higher pitch range when compared to twangy belt. Consistent tuning of fR 1 to the second voice harmonic (2 f 0) was observed in all three qualities and for both vowels. <b>Expert</b> <b>listeners</b> tended to identify all qualities based on the same acoustical and physiological variations as those observed in the singers’ intended qualities...|$|E
40|$|In this article, {{we address}} the issue of using a {{continuous}} speech recognition tool to obtain phonetic or phonological representations of speech. Two experiments were carried out in which the performance of a continuous speech recognizer (CSR) was compared to the performance of <b>expert</b> <b>listeners</b> in a task of judging whether a number of prespecified phones had been realized in an utterance. In the first experiment, nine <b>expert</b> <b>listeners</b> and the CSR carried out exactly the same task: deciding whether a segment was present or not in 467 cases. In the second experiment, we expanded on the first experiment by focusing on two phonological processes: schwa-deletion and schwa-insertion. The results of these experiments show that significant differences in performance were found between the CSR and the listeners, but also between individual listeners. Although some of these differences appeared to be statistically significant, their magnitude is such that they may very well be acceptable depending on what the transcriptions are needed for. In other words, although the CSR is not infallible, it makes it possible to explore large datasets, which might outweigh the errors introduced by the mistakes the CSR makes. For these reasons, we can conclude that the CSR can be used instead of a listener to carry out this type of task: deciding whether a phone is present or not...|$|E
40|$|GROOVE IS A SENSATION OF MOVEMENT OR WANTing to {{move when}} {{we listen to}} certain types of music; it {{is central to the}} {{appreciation}} of many styles such as Jazz, Funk, Latin, and many more. To better understand the mechanisms that lead to the sensation of groove, we explore the relationship between groove and systematic microtiming deviations. Manifested as small, intentional deviations in timing, systematic microtiming is widely considered within the music community to be a critical component of music performances that groove. To investigate the effect of microtiming on the perception of groove we synthesized typical rhythm patterns for Jazz, Funk, and Samba with idiomatic microtiming deviation patterns for each style. The magnitude of the deviations was parametrically varied from nil to about double the natural level. In two experiments, untrained <b>listeners</b> and <b>experts</b> listened to all combinations of same and different music and microtiming style and magnitude combinations, and rated liking, groove, naturalness, and speed. Contrary to a common and frequently expressed belief in the literature, systematic microtiming led to decreased groove ratings, as well as liking and naturalness, {{with the exception of the}} simple short-long shuffle Jazz pattern. A comparison of the ratings between the two listener groups revealed this effect to be stronger for the <b>expert</b> <b>listener</b> group than for the untrained listeners, suggesting that musical expertise plays an important role in the perception and appreciation of micro timing in rhythmic patterns...|$|R
40|$|The {{training}} of listening skills in higher music {{education is a}} central part of the aural training discipline, often called aural analysis or structural hearing. Listening here refers to active, conscious attention paid to the music and its elements through the combination of perceptual and cognitive skills, and understanding. Theories about listening suggest various categories and types of listeners and of listening, mainly along the analytical-emotional spectrum. How do professional musicians react when actively listening to music? What is typical in their ways of listening? What are the links between listening and academic aural analysis? In this study, I interviewed eight professional musicians, seven orchestral musicians and one orchestral conductor, focusing on their ways of listening to music and how this might be related to their profession. As a starting point for the interview, an excerpt from an orchestral piece unknown to the participants was played, which evoked a great variety of reactions, both emotional and analytical. The most typical and dominant way of listening was critical listening, a professional way of listening, valuing the quality of the performance and the performers’ ability. Academic aural training listening was also evident, but to a smaller degree. They also reported that the frequency of their deliberate music listening was strongly reduced, both in live concerts and listening without any purpose, and the importance of silence was strongly emphasized. Keywords: <b>expert</b> <b>listener,</b> analytical-, emotional- and critical listening, valuing, aural training, aural analysi...|$|R
40|$|Objective: To {{improve the}} voice quality of female laryngectomees and/or laryngectomees with a {{hypotonic}} pharyngoesophageal (PE) segment {{by means of}} a pneumatic artificial source of voice incorporated in a regular tracheoesophageal (TE) shunt valve. Study Design: Experimental, randomized, crossover trial. Methods: The new sound source consists of a single silicone lip, which performs an oscillatory movement driven by expired pulmonary air flowing along the outward-striking lip through the TE shunt valve. A prototype of this pneumatic sound source is evaluated in vitro and in six laryngectomees, In vivo evaluation includes speech rate, maximal phonation time, perceptual voice evaluation of read-aloud prose by an <b>expert</b> <b>listener,</b> speech intelligibility measurements with 12 listeners, and self-assessment by the patients. Moreover, extensive acoustical and aerodynamic in vivo registrations are performed using a newly developed data acquisition system. Results: The current prototype seems beneficial in female laryngectomees with a hypotonic PE segment only, For them the sound-producing voice prosthesis improves voice quality and increases the average pitch of voice, without decreasing intelligibility or necessitating other pressure and airflow rates than regular TE shunt speech. Pitch regulation of this prosthetic voice is possible, yet limited. Conclusions: The mechanism is feasible and does not result in unacceptable airflow resistance. For this new mechanism of alaryngeal voice to become an established technique for postlaryngectomy voice restoration, a voice suitably pitched for male laryngectomees has to be generated and {{a large part of the}} melodic and dynamic range of the sound source has to be attainable within physiological airflow rates...|$|R
40|$|The {{present study}} investigates {{the effect of}} a change in syntactic-like musical {{function}} on event-related brain potentials (ERPs). Eight-chord piano sequences were presented to musically expert and novice listeners. Instructed to watch a movie and to ignore the musical sequences, the participants had to react when a chord was played with a different instrument than the piano. Participants were not informed that the relevant manipulation was the musical function of the last chord (target) of the sequences. The target chord acted either as a syntactically stable tonic chord (i. e., a C major chord in the key of C major) or as a less syntactically stable subdominant chord (i. e., a C major chord in the key of G major). The critical aspect of the results related to the impact such a manipulation had on the ERPs. An N 5 -like frontal negative component was found to be larger for subdominant than for tonic chords and attained significance only in musically <b>expert</b> <b>listeners.</b> These findings suggest that the subdominant chord is more difficult to integrate with the previous context than the tonic chord (as indexing by the observed N 5) and that the processing of a small change in musical function occurs in an automatic way in musically <b>expert</b> <b>listeners.</b> The present results are discussed in relation to previous studies investigating harmonic violations with ERPs...|$|E
40|$|Scientific {{research}} on how people perceive or experience and/or understand the acoustic environment as a whole (i. e., soundscape) is still in development. In order to predict how people would perceive an acoustic environment, it is central to identify its underlying acoustic properties. This was {{the purpose of the}} present study. Three successive experiments were conducted. With the aid of 30 university students, the first experiment mapped the underlying dimensions of perceived similarity among 50 acoustic environments, using a visual sorting task of their spectrograms. Three dimensions were identified: (1) Distinguishable-Indistinguishable sound sources, (2) Background-Foreground sounds, and (3) Intrusive-Smooth sound sources. The second experiment was aimed to validate the results from Experiment 1 by a listening experiment. However, a majority of the 10 <b>expert</b> <b>listeners</b> involved in Experiment 2 used a qualitatively different approach than the 30 university students in Experiment 1. A third experiment was conducted in which 10 more <b>expert</b> <b>listeners</b> performed the same task as per Experiment 2, with spliced audio signals. Nevertheless, Experiment 3 provided a statistically significantly worse result than Experiment 2. These results suggest that information about the meaning of the recorded sounds could be retrieved in the spectrograms, and that the meaning of the sounds may be captured with the aid of holistic features of the acoustic environment, but such features are still unexplored and further in-depth research is needed in this field...|$|E
40|$|The average {{pitch of}} 68 news {{broadcasters}} (34 female / 34 male speakers) was evaluated by 6 <b>expert</b> <b>listeners.</b> Additionally, the average fundamental frequency for all samples was analyzed {{by means of}} a series of standard pitch detection algorithms. The results show a strong correlation of acoustic mean and auditory median values for male voices, whereas the auditory mean values female voices are slightly higher than their acoustic counterparts. Vice versa interlistener reliability is higher for the evaluation of fe-male speakers, whereas listeners report more difficulties in rating for male speaking voices. Index Terms: average speaking pitch, auditory measurement, speaking fundamental frequency, gender...|$|E
2500|$|McCartney's {{vocal and}} {{acoustic}} guitar, {{together with a}} string quartet, essentially made for the first solo performance of the band. It remains popular today with more than 2,200 cover versions {{and is one of}} the most covered songs in the history of recorded music. [...] "Yesterday" [...] was voted the best song of the 20th century in a 1999 BBC Radio 2 poll of music <b>experts</b> and <b>listeners</b> and was also voted the No. 1 pop song of all time by MTV and Rolling Stone magazine the following year. In 1997, the song was inducted into the Grammy Hall of Fame. Broadcast Music Incorporated (BMI) asserts that it was performed over seven million times in the 20th century.|$|R
40|$|A robust {{language}} learning system, {{designed to help}} students practice a foreign language along with a machine tutor, must provide meaningful feedback to users by isolating and localizing their pronunciation errors. This paper presents a new technique for automatic syllable stress detection that is tailored for language-learning purposes. Our method, which uses basic prosodic features and others related to the fundamental frequency slope and RMS energy range, {{is at least as}} accurate as an <b>expert</b> human <b>listener,</b> but requires no human supervision other than a pre-defined dictionary of expected lexical stress patterns for all words in the system’s vocabulary. Optimal feature choices exhibited an 87 - 89 % accuracy compared with human-tagged stress labels, exceeding the inter-human agreement commonly held to be about 80 %. 1...|$|R
40|$|SRI International is {{currently}} {{involved in the}} development of a new generation of software systems for automatic scoring of pronunciation as part of the Voice Interactive Language Training System (VILTS) project. This paper describes the goals of the VILTS system, the speech corpus, and the algorithm development. The automatic grading system uses SRI's Decipher^TM continuous speech recognition system [1] to generate phonetic segmentations that are used to produce pronunciation scores at the end of each lesson. The scores produced by the system are similar to those of <b>expert</b> human <b>listeners.</b> Unlike previous approaches in which models were built for specific sentences or phrases, we present a new family of algorithms designed to perform well even when knowledge of the exact text to be used is not available. 1. INTRODUCTION Computer-aided language instruction has been evolving from simple systems with exercises based on text and static pictures to more advanced systems that accept user [...] ...|$|R
