268|2826|Public
2500|$|Static storage {{duration}} objects are initialized in two phases. First, [...] "static initialization" [...] is performed, {{and only after}} all static initialization is performed, [...] "dynamic initialization" [...] is performed. [...] In static initialization, all objects are first initialized with zeros; after that, all objects that have a constant initialization phase are initialized with the constant expression (i.e. variables initialized with a literal or constexpr). Though it is not specified in the standard, the static initialization phase can be completed at compile time and saved in the <b>data</b> <b>partition</b> of the executable. [...] Dynamic initialization involves all object initialization done via a constructor or function call (unless the function is marked with constexpr, in C++11). The dynamic initialization order {{is defined as the}} order of declaration within the compilation unit (i.e. the same file). No guarantees are provided about the order of initialization between compilation units.|$|E
50|$|Linux {{used the}} same {{partition}} type GUID for basic <b>data</b> <b>partition</b> as Windows prior to introduction of a Linux specific <b>Data</b> <b>Partition</b> GUID 0FC63DAF-8483-4772-8E79-3D69D8477DE4.|$|E
5000|$|Microsoft {{defines the}} type-specific {{attributes}} for basic <b>data</b> <b>partition</b> as: ...|$|E
40|$|This paper {{presents}} performance {{results of}} a new <b>data</b> <b>partitioning</b> technique: snake <b>partitioning,</b> a <b>data</b> decomposition technique than can be derived at compile-time. Snake partitioning is suitable for multidimensional arrays with restricted affine references. The technique derives the <b>data</b> <b>partitioning</b> of these arrays and an execution order that exploits locality in loops. Experiments that compare {{the performance of the}} snake <b>data</b> <b>partitioning</b> against traditional <b>data</b> <b>partitioning</b> techniques like row, column and blocks are presented...|$|R
40|$|The {{performance}} of a parallel program depends largely on its <b>data</b> <b>partitions.</b> So a good <b>data</b> <b>partitioning</b> scheme is the need of the time. However {{it is very difficult}} to arrive at a good solution as the number of possible <b>data</b> <b>partitions</b> for a given real life program is exponential in the size of the program. We present a heuristic technique for automatic <b>data</b> <b>partitioning</b> for HPF. Our approach is based on Genetic Algorithms and is very simple, yet very efficient to quickly find appropriate <b>data</b> <b>partitions</b> even for large programs with large number of alternatives for data distribution. It makes use of both static as well as dynamic data distribution with the main aim of reducing the overall execution time of the entire program...|$|R
40|$|<b>Data</b> <b>partitioning</b> is {{important}} in many aspects, such as computational, load distribution, inter-process communication, load and data overhead considering different applications. In this paper, overhead due to <b>data</b> <b>partitioning</b> is discussed and two algorithms are proposed: Almost Square Tiles (AST) and Almost Square Tiles wit...|$|R
50|$|The system scales {{horizontally}} as newer {{machines are}} added, with no downtime to applications. Other elasticity operations include <b>data</b> <b>partition</b> assignment, reassignment and splitting.|$|E
5000|$|A {{separate}} {{instance of}} snort logs the full content of all network packets {{to the local}} disk (this typically requires a large separate <b>data</b> <b>partition)</b> ...|$|E
50|$|In Microsoft {{operating}} systems, {{when using}} basic disk partitioned with GUID Partition Table (GPT) layout, a basic <b>data</b> <b>partition</b> (BDP) is any partition identified with Globally Unique Identifier (GUID) of EBD0A0A2-B9E5-4433-87C0-68B6B72699C7.|$|E
40|$|In {{this work}} we compare non-scalable video coding with <b>data</b> <b>partitioning</b> using H. 264 /AVC under similar {{application}} and channel constraints for conversational applications over mobile channels. For both systems optimized rate allocation and network feedback has been applied. From the experimental results {{it is observed}} that based on the average PSNR the non-scalable system outperforms the <b>data</b> <b>partitioning</b> system. However, with the <b>data</b> <b>partitioning</b> system the percentage of entirely lost frames can be lowered, and the probability of poor quality decoded video can be reduced. 1...|$|R
5000|$|... #Subtitle level 3: Horizontal <b>data</b> <b>partitioning</b> (auto-sharding) ...|$|R
40|$|AbstractFuzzy C-Means (FCM) {{and hard}} {{clustering}} {{are the most}} common tools for <b>data</b> <b>partitioning.</b> However, the presence of noisy observations in the <b>data</b> being <b>partitioned</b> may render these clustering algorithms unreliable. In this paper, we introduce a robust noise-rejection clustering algorithm based on a combination of techniques that treat the FCM pitfalls with an outliers exclusion criterion. Unlike the traditional FCM, the proposed clustering tool provides much efficient <b>data</b> <b>partitioning</b> capabilities in the presence of noise and outliers. At the conclusion of the theoretical development, we validate the effectiveness of the proposed noise-rejection <b>data</b> <b>partitioning</b> tool through various comparison studies with existing noise-rejection clustering approaches in the literature...|$|R
50|$|A Basic <b>Data</b> <b>Partition</b> can be {{formatted}} {{with any}} filesystem format, although most commonly BDPs are formatted with the NTFS, exFAT, or FAT32 filesystem formats. To programatically determine which filesystem format a BDP contains, Microsoft specifies {{that one should}} inspect the BIOS Parameter Block that is contained in the BDP's Volume Boot Record.|$|E
50|$|According to Microsoft, {{the basic}} <b>data</b> <b>partition</b> is the {{equivalent}} to master boot record (MBR) partition types 0x06 (FAT16B), 0x07 (NTFS or exFAT), and 0x0B (FAT32). In practice, it is equivalent to 0x01 (FAT12), 0x04 (FAT16), 0x0C (FAT32 with logical block addressing), and 0x0E (FAT16 with logical block addressing) types as well.|$|E
50|$|When a Microsoft {{operating}} system converts a GPT-partitioned basic disk to a dynamic disk, all BDPs are combined and {{converted to a}} single Logical Disk Manager <b>data</b> <b>partition</b> identified with GUID AF9B60A0-1431-4F62-BC68-3311714A69AD. This {{is analogous to the}} conversion from partition types 0x01, 0x04, 0x06, 0x07, 0x0B, 0x0C, and 0x0E to partition type 0x42 on MBR partitioned disks.|$|E
3000|$|The {{extended}} and baseline profiles of H. 264 {{are designed for}} video communications applications. The <b>data</b> <b>partitioning</b> mechanism is not available in the [...] "baseline" [...] profile; however, it is upported in the [...] "extended" [...] profile. Therefore, the solutions based on DP are only applicable to the extended profile. <b>Data</b> <b>partitioning</b> is an important feature that allows a network-aware video encoder to achieve higher-performance levels in a network that provides unequal error protection or quality of service. We examine the video communication techniques based on <b>data</b> <b>partitioning</b> in this work.|$|R
40|$|Mining {{association}} rules {{refers to}} extracting useful knowledge from large databases. Algo-rithms {{of this technique}} are both data and computation-intensive, which make grid platforms very attractive for them. However, to exploit these platforms, new <b>data</b> <b>partitioning</b> features are required where the specificities of both association rule mining technique and grids {{must be taken into}} consideration. In this paper, we propose a novel <b>data</b> <b>partitioning</b> approach for distributed association rule mining algorithms {{in the context of a}} grid computing environment. We conduct exper-iments using the French research grid ”Grid’ 5000 ”. Experimental results confirm that our <b>data</b> <b>partitioning</b> approach is very sufficient for balancing the load when homogeneous clus-ters are used. For heterogeneous clusters, the proposed <b>data</b> <b>partitioning</b> approach constitute the preprocessing phase of the process of dynamic load balancing of distributed association rule mining...|$|R
40|$|This paper {{presents}} performance {{results of}} a new <b>data</b> <b>partitioning</b> technique: snake <b>partitioning,</b> a <b>data</b> decomposition technique than can be derived at compile-time. Snake partitioning is suitable for multidimensional arrays with restricted affine references. The technique derives the <b>data</b> <b>partitioning</b> of these arrays and an execution order that exploits locality in loops. Experiments that compare {{the performance of the}} snake <b>data</b> <b>partitioning</b> against traditional <b>data</b> <b>partitioning</b> techniques like row, column and blocks are presented. 1 Introduction Two issues involved in writing programs for distributed-memory machines are to identify the available parallelism in the program and to implement the program on the target architecture such that the parallelism is exploited. During the past decade the programmer was responsible for identifying the opportunities for parallelism and deciding on the best implementation that exploited such parallelism. Programming in this manner is not an easy [...] ...|$|R
5000|$|Due to <b>data</b> <b>partition,</b> x {{cannot be}} {{accessed}} directly from B. However, functionality is not limited, and a transaction running on B still can issue a write or read request of x (not common). This request is {{communicated to the}} transaction's local sub-transaction on A (which is generated, if does not exist already) which issues this request to the local data manager on A.|$|E
5000|$|A MemSQL cluster can be {{configured}} in [...] "High Availability" [...] mode, {{where every}} <b>data</b> <b>partition</b> is automatically created with master and slave versions on two separate leaf nodes. In High Availability mode, aggregators send transactions {{to the master}} partitions, which then send logs to the slave partitions. In {{the event of an}} unexpected master failure, the slave partitions take over as master partitions in a fully online operation.|$|E
5000|$|The <b>data</b> <b>partition</b> (x on A; y on B) is {{important}} since without it, for example, x {{can be accessed}} directly from B. If a transaction [...] is running on B concurrently with [...] and [...] and directly writes x, then, without a distributed lock manager the read-lock for x held by [...] on A is not visible on B and cannot block the write of [...] (or signal a materialized conflict for a non-blocking CO variant; see below). Thus serializability can be violated.|$|E
30|$|The fftw-distributor uses {{routines}} {{from the}} pyFFTW [8, 22] package [8] for the <b>data</b> <b>partitioning.</b>|$|R
5000|$|Global motion {{compensation}} and <b>Data</b> <b>Partitioning</b> are not supported for MPEG-4 Part 2.|$|R
30|$|Video {{streaming}} over IEEE 802.11 networks attracted {{much research}} interest. The authors of [11 – 13] proposed mechanisms to transport H. 264 and MPEG- 4 over IEEE 802.11 e/a networks. However, their mechanisms {{are based on}} hybrid coordination function controlled channel access (HCCA) [14]. HCCA is a polling-based channel access mechanism which is different from contention-based EDCA used in WAVE. Furthermore, these mechanisms are only suitable for scalable video streams. Ksentini et al. [10] proposed a cross-layer architecture for H. 264 over IEEE 802.11 e. They utilized a specific feature of H. 264 <b>data</b> <b>partitioning</b> (defined in the extended profile of H. 264 standard). In their work, the bitstreaming of a frame is classified into three <b>data</b> <b>partitions</b> with different importance levels. The <b>data</b> <b>partitions</b> are delivered by different access categories (ACs) in IEEE 802.11 e MAC. However, they only dealt with the different importance of <b>data</b> <b>partitions</b> within a frame, {{and they did not}} distinguish the importance between different video frame-types.|$|R
5000|$|Static storage {{duration}} objects are initialized in two phases. First, [...] "static initialization" [...] is performed, {{and only after}} all static initialization is performed, [...] "dynamic initialization" [...] is performed. In static initialization, all objects are first initialized with zeros; after that, all objects that have a constant initialization phase are initialized with the constant expression (i.e. variables initialized with a literal or [...] ). Though it is not specified in the standard, the static initialization phase can be completed at compile time and saved in the <b>data</b> <b>partition</b> of the executable. Dynamic initialization involves all object initialization done via a constructor or function call (unless the function is marked with , in C++11). The dynamic initialization order {{is defined as the}} order of declaration within the compilation unit (i.e. the same file). No guarantees are provided about the order of initialization between compilation units.|$|E
5000|$|The LifeDrive was a Palm OS-based {{handheld}} {{personal digital}} assistant device that was produced by PalmOne, a former incarnation of Palm, Inc. The device was PalmOne's first and only foray into the [...] "Mobile Manager" [...] device category. As its name suggests, Palm intended the LifeDrive {{to be capable of}} providing all the capabilities and data storage space that a user could possibly need {{during the course of the}} day, including contacts, calendar, music, images, video, and applications. At the time of release, the 4-gigabyte capacity that was chosen for this task could not be achieved using the flash memory used by most PDAs, while keeping the cost of the device low enough for consumer purchase. For this reason, a 4 GB microdrive hard disk drive was selected for the task. It featured a separate <b>data</b> <b>partition</b> that could be used as a portable disk drive. The LifeDrive featured Bluetooth and Wi-Fi connectivity, the first Palm handheld to feature both. The device came pre-loaded with eReader, Documents To Go, and WiFile software.|$|E
50|$|Disks {{with large}} {{capacities}} (over 2 TB) used on servers {{may have a}} larger fast cache memory, but this cache may be backed up by a frontal (hidden) SSD, so no space is needed in the MSR area of the physical disk for fast recovery in case of power failure or when using dynamic power management. For PCs preinstalled with a single SSD, the OEM recovery partition is usually at end of disk (this allows this OEM partition to be backed up to an external DVD or USB drive and then deleted from the SSD, for extending the main <b>data</b> <b>partition</b> over it after the OEM backup has been done without having to move all sectors on the SSD; during this operation, the small MSR partition may be temporarily used as a scratch area for recovery in case of unexpected failure of the conversion such as battery/power failure). Finally some security tools may add their own data or software components in the MSR for checking the system integrity at boot time. Some UEFI boot tools may also use the MSR as a temporary scratch area. In summary, the actual usage {{and content of the}} MSR is very device-specific and invisible to normal application software or to the Windows API, through which the MSR partition is not exposed as a mountable volume (it contains no standard filesystem).|$|E
40|$|While <b>data</b> <b>partitioning</b> in {{conjunction}} with unequal error pro-tection provides superb error resiliency, insufficient video qual-ity when only the base partition is available prevents its wide de-ployment in high-quality video applications. In this work. we de-velop a new scheme for <b>data</b> <b>partitioning</b> of motion-compensated DCT coded video in an operational rate-distortion context. Unlike the conventional <b>data</b> <b>partitioning</b> scheme which adapts the DCT break points at slice or video packet level, our new partitioning al-gorithm adapts the partitioning points at as low as the DCT block level with virtually no overhead using backward adaptation. hence produces superior video quality over the conventional data part-tioning scheme. Simulation results show that significant PSNR gain can he achieved using the new algorithm. I...|$|R
3000|$|... are {{strongly}} coupled, iff {{they have the}} same input <b>data</b> <b>partitioning</b> for their satisfiability valuation, i.e., [...]...|$|R
40|$|In {{order to}} be able to better cope with packet loss, H. 264 /AVC, besides {{offering}} superior coding efficiency, also comes with a number of error resilience tools. The goal of these tools is to enable the decoding of a bitstream containing encoded video, even when parts of it are missing. On top of that, the visual quality of the decoded video should remain as high as possible. In this paper, we will discuss and evaluate one of these tools, in particular the <b>data</b> <b>partitioning</b> tool. Experimental results will show that using <b>data</b> <b>partitioning</b> can significantly improve the quality of a video sequence when packet loss occurs. However, this is only possible if the channel used for transmitting the video allows selective protection of the different <b>data</b> <b>partitions.</b> In the most extreme case, an increase in PSNR of up to 9. 77 dB can be achieved. This paper will also show that the overhead caused by using <b>data</b> <b>partitioning</b> is acceptable. In terms of bit rate, the overhead amounts to approximately 13 bytes per slice. In general, this is less than 1 % of the total bit rate. On top of that, using constrained intra prediction, which is required to fully exploit <b>data</b> <b>partitioning,</b> causes a decrease in quality of about 0. 5 dB for high quality video and between I and 2 dB for low quality video...|$|R
30|$|The hash join {{algorithm}} proceeds in two phases: the build {{phase and}} the probe phase. In the build phase, a hash {{table of the}} dynamic <b>data</b> <b>partition</b> (small data) is built. In the probe phase, the algorithm scans the static <b>data</b> <b>partition</b> and finds its relevant dynamic data by looking in the hash table.|$|E
40|$|In {{recent years}} {{companies}} in various industries tended to outsource {{part of their}} R&D services to a professional third party to save their costs and speed up new product development. In light of customer retention, a customer's response to the R&D service has great impact {{on the possibility of}} reusing the service from the same service provider. Realizing how customers respond has become a critical issue for a R&D service provider, such as PIDC (Plastic Industry Development Center). Besides, if PIDC know their buyer's loyalty tendency and propensity to switch to other providers, it can implement adequate relationships management policy with limited marketing resources. The independent variables, including effective communication, trust, satisfaction, commitment, and customer's cultural market orientation, are used to predict buyer's response. The predictive performance of models, neural network, decision tree, linear regression, logistic regression and discriminant analysis, are compared. In the prediction of buyer's response, neural network is a better predictive model than other models. Finally, we suggest that PIDC use the neural network model as their predictive model to manage its relationship marketing policies effectively and efficiently. ACKNOWLEDGEMENTS	i ABSTRACT	ii TABLE OF CONTENTS	iii LISTS OF TABLES	vi LIST OF FIGURE	vii CHAPTERⅠ INTRODUCTION	 1 1. 1 Research Background and Motivation	 1 1. 2 Research Questions	 4 1. 3 Research Objectives	 4 1. 4 Thesis Organization	 5 CHAPTERⅡ LITERATURE REVIEW	 6 2. 1 The Target Variables	 6 2. 1. 1 Buyer's Loyalty	 6 2. 1. 2. Buyer's Propensity to Switch to Other Providers	 6 2. 2 The Prediction of Buyer's Response in the Literature	 7 2. 2. 1 Buyer's Cultural Market Orientation	 8 2. 2. 2 Effective Communication between Buyers and the Service Provider	 9 2. 2. 3 Trust	 9 2. 2. 4 Satisfaction with the Service Provider	 10 2. 2. 5 Commitment to the Relationship	 10 2. 3 The Antecedents of Buyer's Response	 11 2. 3. 1 Buyer's Cultural Market Orientation Effects on Buyer's Response	 11 2. 3. 2 Effective Communication Effects on Buyer's Response	 12 2. 3. 3 Trust Effects on Buyer's Response	 13 2. 3. 4 Satisfaction with the Service Provider Effects on Buyer's Response	 14 2. 3. 5 Commitment to the Relationship Effects on Buyer's Response	 15 2. 4 The Predicting Model of Buyer's Response	 16 CHAPTERⅢ RESEARCH METHOD	 18 3. 1 Research Variables Definition	 18 3. 2 Sampling Plan	 20 3. 3 Surveyed Sample Profiling	 21 3. 4 Measurement Validation	 22 3. 4. 1 Reliability Analysis	 22 3. 4. 2 Validation Analysis	 24 3. 5 Introduction to Models Used	 25 3. 5. 1 Neural Network Model (NN) 	 25 3. 5. 2 Decision Tree Model (DT) 	 26 3. 5. 3 Linear Regression Model (RE) 	 27 3. 5. 4 Logistic Regression Model (LR) 	 27 3. 5. 5 Discriminant Analysis (DC) 	 28 CHAPTERⅣ MODEL DEVELOPMENT AND	 29 DATA ANALYSIS	 29 4. 1. The Processes of the SAS Program	 30 4. 1. 1. Neural Network Model (NN) 	 30 4. 1. 2. Decision Tree Model (DT) 	 30 4. 1. 3. Linear Regression Model (RE) 	 31 4. 1. 4. Logistic Regression Model (LR) 	 31 4. 1. 5. Discriminant Analysis Model (DC) 	 31 4. 2. Buyer's Response Using Continuous Variables	 32 4. 3. Buyer's Response Using Categorical Variables	 38 4. 4. Why Both Target Variables as Buyer's Response	 44 CHAPTERⅤ DISCUSSION	 45 5. 1. Managerial Implications	 47 5. 2. Research Limitation and Future Research Directions	 47 REFERENCES	 49 APPENDICES	 56 Appendix 1. The Questionnaire	 56 Appendix 2. The Predictive Performance of Buyer's Loyalty Using Continuous Variable among Three Models	 59 Appendix 2. 1 The <b>Data</b> <b>Partition</b> of 75 %- 25 % of Both Data Sets	 59 Appendix 2. 2 The <b>Data</b> <b>Partition</b> of 80 %- 20 % of Both Data Sets	 60 Appendix 2. 3 The <b>Data</b> <b>Partition</b> of 85 %- 15 % of Both Data Sets	 61 Appendix 2. 4 The <b>Data</b> <b>Partition</b> of 90 %- 10 % of Both Data Sets	 62 Appendix 3. The Predictive Performance of Buyer's Propensity to Switch to Other Providers Using Continuous Variable among Three Models	 63 Appendix 3. 1 The <b>Data</b> <b>Partition</b> of 75 %- 25 % of Both Data Sets	 63 Appendix 3. 2 The <b>Data</b> <b>Partition</b> of 80 %- 20 % of Both Data Sets	 64 Appendix 3. 3 The <b>Data</b> <b>Partition</b> of 85 %- 15 % of Both Data Sets	 65 Appendix 3. 4 The <b>Data</b> <b>Partition</b> of 90 %- 10 % of Both Data Sets	 66 Appendix 4. The Predictive Performance of Buyer's Loyalty Using Categorical Variable among Four Models	 67 Appendix 4. 1 The <b>Data</b> <b>Partition</b> of 75 %- 25 % of Both Data Sets	 67 Appendix 4. 2 The <b>Data</b> <b>Partition</b> of 80 %- 20 % of Both Data Sets	 68 Appendix 4. 3 The <b>Data</b> <b>Partition</b> of 85 %- 15 % of Both Data Sets	 69 Appendix 4. 4 The <b>Data</b> <b>Partition</b> of 90 %- 10 % of Both Data Sets	 70 Appendix 5. The Predictive Performance of Buyer's Propensity to Switch to Other Providers Using Categorical Variable among Four Models	 71 Appendix 5. 1 The <b>Data</b> <b>Partition</b> of 75 %- 25 % of Both Data Sets	 71 Appendix 5. 2 The <b>Data</b> <b>Partition</b> of 80 %- 20 % of Both Data Sets	 72 Appendix 5. 3 The <b>Data</b> <b>Partition</b> of 85 %- 15 % of Both Data Sets	 73 Appendix 5. 4 The <b>Data</b> <b>Partition</b> of 90 %- 10 % of Both Data Sets	 7...|$|E
40|$|Abstract: Clustering is a {{partition}} of data {{into a group}} of similar or dissimilar data points and each group {{is a set of}} data points called clusters. Clustering is an unsupervised learning with no predefined class label for the data points. Clustering is considered an important tool for data mining. Clustering has many applications such as pattern recognition, image processing, market analysis, World Wide Web and many others. Categorical data are groups of categories and each value represents some category. The problem of clustering categorical data is solved by the use of the cluster ensemble approach, but this technique generates a final <b>data</b> <b>partition</b> with imperfect information. The ensemble-information matrix that is the binary cluster association matrix content presents only cluster-data point relations with many entries being left unknown and which decrease the quality of the whole <b>data</b> <b>partition.</b> To avoid the degradation of the final <b>data</b> <b>partition,</b> a new approach of link-based is presented which includes the refined cluster association matrix. It maintains cluster to cluster relation and helps to improve quality of the final <b>data</b> <b>partition</b> result by determining the unknown entries through measuring similarity between clusters in an ensemble. The cluster ensemble combines multiple data partitions from different clustering algorithms into a single clustering solution to improve the robustness, accuracy and quality of the clustering result. Index Terms- Clustering, categorical, link-based, ensembl...|$|E
40|$|Abstract. The {{performance}} of OLAP queries {{can be improved}} drastically if the warehouse data is properly selected and indexed. The problems of selecting and materializing views and indexing data have been studied extensively in the data warehousing environment. On the other hand, <b>data</b> <b>partitioning</b> can also greatly increase the {{performance of}} queries. <b>Data</b> <b>partitioning</b> has advantage over data selection and indexing since the former one does not require additional storage requirement. In this paper, we show that it is beneficial to integrate the <b>data</b> <b>partitioning</b> and indexing (join indexes) techniques for improving the performance of data warehousing queries. We present a data warehouse tuning strategy, called PartJoin, that decomposes the fact and dimension tables of a star schema and then selects join indexes. This solution takes advantage of these two techniques, i. e., <b>data</b> <b>partitioning</b> and indexing. Finally, we present {{the results of an}} experimental evaluation that demonstrates the effectiveness of our strategy in reducing the query processing cost and providing an economical utilisation of the storage space. ...|$|R
40|$|Abstract. The {{vision of}} the Semantic Web is {{becoming}} a reality with billions of RDF triples being distributed over multiple queryable endpoints (e. g. Linked Data). Although {{there has been a}} body of work on RDF triples persistent storage, it seems that, considering reasoning dependent queries, the problem of providing an efficient, in terms of performance, scalability and <b>data</b> redundancy, <b>partitioning</b> of the <b>data</b> is still open. In regards to recent <b>data</b> <b>partitioning</b> studies, it seems reasonable to think that <b>data</b> <b>partitioning</b> should be guided considering several directions (e. g. ontology, data, application queries). This paper proposes several contributions: describe an overview of what a roadmap for <b>data</b> <b>partitioning</b> for RDF <b>data</b> efficient and persistent storage should contain, present some preliminary results and analysis on the particular case of ontology-guided (property hierarchy) partitioning and finally introduce a set of semantic query rewriting rules to support querying RDF data needing OWL inferences. ...|$|R
40|$|Source-coded <b>data</b> <b>partitioning</b> of a {{compressed}} video stream protects more important data, {{reducing the risk}} of error corruption in wireless networks. However, because the <b>data</b> <b>partitions</b> of a video slice are each assigned to different network packets, in congestion-prone networks the increased number of packets per slice and their size disparity may increase the packet loss rate from buffer overflows. This paper recommends packet-size dependent scheduling as a relatively simple way of alleviating the problem, which problem remains real whenever there is an adverse distribution of packet sizes entering an access network. The paper also contributes an analysis of partition and packet sizes as a prelude to scheduling regimes. Index Terms — broadband wireless, access network congestion, <b>data</b> <b>partitioning,</b> multimedia networking, packet schedulin...|$|R
