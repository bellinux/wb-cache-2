0|16|Public
40|$|The CICT Program's Space Communications (SC) Project is {{responsible}} for developing technologies that deliver data quickly between Earth and space, and directly to users. To achieve this ambitious goal. the SC Project is providing technologies for building the Space Internet, which will require <b>back-bone</b> <b>networks</b> that pass data from one infrastructure to another. These infrastructures include the Earth-based wide-area and local-area networks. NASAs Tracking and Data Relay Satellite System (TDRSS) that provides links between low-earth orbiting spacecraft, and the ground planetary networks, and the Deep Space Network (DSN) ...|$|R
40|$|These authors contributed {{equally to}} this work. Networks are getting {{larger and more}} complex; yet adminis-trators rely on {{rudimentary}} tools such as ping and tracer-oute to debug problems. We propose an automated and sys-tematic approach for testing and debugging networks called “Automatic Test Packet Generation ” (ATPG). ATPG reads router configurations and generates a device-independent model. The model is used to generate a minimum set of test packets to (minimally) exercise every link in the network or (maxi-mally) exercise every rule in the network. Test packets are sent periodically and detected failures trigger a separate mech-anism to localize the fault. ATPG can detect both func-tional (e. g., incorrect firewall rule) and performance prob-lems (e. g., congested queue). ATPG complements but goes beyond earlier work in static checking (which cannot detect liveness or performance faults) or fault localization (which only localize faults given liveness results). We describe our prototype ATPG implementation and re-sults on two real-world data sets: Stanford University’s <b>back-bone</b> <b>network</b> and Internet 2. We find that {{a small number of}} test packets suffices to test all rules in these networks: For example 4000 packets can cover all rules in Stanford <b>back-bone</b> <b>network</b> while 54 is enough to cover all links. Sending 4000 test packets 10 times per second consumes less than 1 % of link capacity. ATPG code and the data sets are pub-licly available [6]. 1...|$|R
40|$|Abstract: – This {{paper is}} {{dedicated}} to on-going research activities {{in the field of}} wireless metropolitan and wide area networks with Quality-of-Service (QoS) guarantees. We focus on self-organizing systems, so-called adhoc networks, which can operate without any wired infrastructure (e. g. cellular base stations) – except for some interface points providing interconnectivity to other networks like the Public Switched Telephone Network (PSTN) or the Internet. Obviously, the lack of a wired <b>back-bone</b> <b>network</b> implicates that routing, signalling and other management functions must be handled completely over the air in a self-organizing manner. Key-Words: – Adhoc Networking, Radio Resource Management, Synchronization, IEEE 802. 11...|$|R
40|$|Abstract: A Mixed Line Rate (MLR) {{optical network}} {{is a good}} {{candidate}} for a core <b>back-bone</b> <b>network</b> because of its ability to provide diverse line rates to effectively accommodate traffic demands with heterogeneous bandwidth requirements. Because of the deleterious ef-fects of physical impairments, there is a maximum transmission reach for optical sig-nals before they have to be regenerated. Being expensive devices, regenerators are expected to be sparsely located and used in such a net-work, called a translucent optical network. In this paper, we consider the Grooming, Routing, and Wavelength Assignment (GRWA) prob-lem so that the Quality of Transmission (QoT) for connections is satisfied, and the net-work-level performance metric of blocking probability is minimized. Cross-layer heuris-tics to effectively allocate the sparse regen-erators in MLR networks are developed, and extensive simulation results are presented to demonstrate their effectiveness. Key words: MLR optical networks; transmis-sion reach; cross-layer RWA; QoT-awareness; regenerators I...|$|R
40|$|The {{tremendous}} {{growth of}} Internet traffic has created increasing demand on high capacity optical communications networks. The optical transmission networks offer improved possibilities {{for dealing with}} ever growing demands on transmission bandwidth and system capacity. In the last 20 years, the optical transmission networks have {{become one of the}} most important part in the telecommunication hierarchy, whose seamless integration with conventional network applications and services forces a further development and a broader deployment of optical networks in all telecommunication areas. Making a classification of different optical transmission networks, it can be distinguished between Access, Metro and Core (or <b>back-bone)</b> <b>networks.</b> This is the most convenient network classification made to the transmission distance or network diameter. Access networks as the base of the telecommunication hierarchy, are characterized by the interaction between numerous different network technologies based on different transmission media e. g. wire, wireless or fiber. These networks possess a small tota...|$|R
40|$|Abstract — How are future {{communication}} {{networks to}} cope with everincreasing traffic demands? Currently, data (e. g. IP packets) handled in the <b>back-bone</b> <b>network</b> is transported optically, yet is switched electronically. Being a demanding and power-consuming process, current switches are becoming the bottleneck in the network. More recent techniques, such as Optical Packet Switching (OPS) and Optical Burst Switching (OBS), can alleviate this problem. In the research community’s search for effective architectures, understanding the functioning of optical buffers is crucial. My PhD research focuses on the analysis and performance evaluation of optical buffers. Extensive use of probability generating functions allows to incorporate several environment aspects in a single stochastic model. Results elucidate the behaviour of a specific switch implementation, and lead to optimal constellations of the involved design parameters. Further research aims at results for (i) traffic assumptions that are less stringent and (ii) switch architectures of higher complexity. Keywords—fiber delay lines; optical buffers; stochastic modelling I...|$|R
40|$|Mobile ad hoc {{networks}} (MANETs) {{consist of}} a collection of wireless mobile nodes which dynamically exchange data among themselves without the reliance on a fixed base station or a wired <b>back-bone</b> <b>network.</b> Multipath routing allows the establishment of multiple paths between a single source and single destination node. It is typically proposed in order to increase the reliability of data transmission (i. e., fault tolerance) or to provide load balancing. To avoid frequent route discovery, various multipath routing protocol has been proposed based on the existing single path routing protocol in ad hoc networks. Ad hoc On-demand Multipath Distance Vector (AOMDV) is one of extension to the well-studied Ad hoc On Distance Vector (AODV). Security {{has become one of the}} major issues for data communication over MANET. Different from the past work on the designs of cryptography algorithms and system infrastructures, we will propose a multipath routing algorithm that could randomize delivery paths for data transmission as well as use cryptographically secured traffic load...|$|R
40|$|In this paper, {{we propose}} an {{experimental}} environment {{which can be}} accessed by remote users, where they can select their preferred operating system, and they can use the Power Controllable systems with full permission to access them. The goal of the proposed systems is to provide an experimental environment for the users to join the international experiment that needs high bandwidth network. In order to do that, we provide high performance systems that is directly connected to <b>back-bone</b> <b>network,</b> and we also provide the ability of users to install any application on various operating system. In addition, we provide the ability to keep continuing the system environment of users in shared system environment. We will show how the proposed systems are useful for the users {{in terms of the}} user-efficiency to utilize the environment and the response time for the set-up time. This new proposed environments will provide a new experimental method for the scientists who works fo...|$|R
40|$|Confronted {{with the}} {{generalization}} of monitoring in operational networks, researchers have proposed place-ment algorithms {{that can help}} ISPs deploy their monitor-ing infrastructure in a cost effective way, while maximiz-ing the benefits of their infrastructure. However, a static placement of monitors cannot be op-timal given the short-term and long-term variations in traffic due to re-routing events, anomalies and the nor-mal network evolution. In addition, most ISPs already deploy router embedded monitoring functionalities. De-spite some limitations (inherent to {{being part of a}} router), these monitoring tools give greater visibility on the net-work traffic but raise the question on how to configure a network-wide monitoring infrastructure that may contain hundreds of monitoring points. Therefore, we reformulate the placement problem as follows: Given a network where all links can be mon-itored, which monitors should be activated and which sampling rate should be set on these monitors in order to achieve a given measurement task with high accuracy and low resource consumption? We provide a formula-tion of the problem, an optimal algorithm to solve it, and we study its feasibility and performance on a real <b>back-bone</b> <b>network.</b> ...|$|R
40|$|Today, {{with the}} {{development}} of optical network, espe-cially access network, monolithic integrated optoelec-tronic device plays a very important role because of its potential low cost and high yield[1]. However, compared with electronic integrated device, optoelectronic inte-grated device is more complex and hard to fabricate. So far, many different integrated optoelectronic devices with distributed feedback (DFB) laser have been reported as DFB laser’s high performance and stability[2 – 4]. Actually, discrete DFB laser has been applied in <b>back-bone</b> <b>network</b> for many years. So, DFB-based integrated optoelectronic devices {{are one of the most}} interesting devices for researchers. Two typical devices using DFB laser array are monolithic DFB laser array with multi-mode interface (MMI) combiner or with arrayed wave-guide gratings (AWGs). Although AWG is powerful especially in the case of lager channel number, it is large and hard to fabricate with high performance. So it is just suitable for high-end application such as opti-cal line terminal. Although the performance of MMI is relatively lower, it is smaller with larger tolerance which means high yield, low cost, and suitable for optical network unit. However, the threshold current of the DFB laser is often larger than discrete commercial chip as different regions in the device are often hard Fabrication of low threshold current monolithic DFB laser with an MMI combine...|$|R
40|$|Bandwidth {{management}} and optimization are very critical to any organization especially universities and research organizations. This work {{is aimed at}} {{the development of a}} policy- based bandwidth scheme for ABU Zaria (as a case study). ABU Zaria currently has a fibre-based STM- 1 links leased from Glo – I, thus providing the university with a full duplex bandwidth of 155 Mbps. The university has a student – staff population of about 40000 currently and a fibre ring <b>back-bone</b> <b>network</b> linking the three campuses at Samaru, Shika and Kongo. The work involved collection and analysis of traffic data over a 90 -day period using Packet Sniffer, {{for the development of the}} policy- based strategies for bandwidth optimization. Simulation of the effect of the policies on a segment of the network was carried out using the GNS 3 and validation of results of the simulation was done on a small network. The results showed as improvement in bandwidth utilization from 3. 9 Mbps to 2. 9 Mbps thus saving 1. 0 Mbps in bandwidth when the developed policies were implemented. This is an indication that when implemented on the live network there will be better management of the bandwidth. [2] General Terms Policy based- bandwidth management implementation, Design a model, simulated in a GNS 3...|$|R
40|$|This paper {{presents}} an efficient {{strategy for the}} optimal network redesign with a biconnectivity-oriented topology (both edge and vertex biconnected). It helps re-designing existing networks or generating new networks consider-ing practically relevant constraints (such as leased lines with long running contracts to remain, maximum number of ports per device) typically found in these phases. The proposed strategy is composed of Reduction, Augmentation, and Fine-Tuning Reduction. Empirical tests using several IP network topologies showed the robustness and applica-bility of the method. Its application to other optical <b>back-bone</b> (or access) <b>network</b> redesign problems is possible...|$|R
40|$|A {{wireless}} Ad-hoc {{sensor network}} {{consists of a}} number of sensors spread across a geographical area as a collec-tion of sensors that form an ad-hoc wireless network. Sen-sors are very tiny devices that their primary function is to sense the target, convert the signal into a suitable data for-mat, and pass on the data to a command node. These sen-sor nodes are very heavily constrained in processing power, and have a limited energy supply. Since energy is such a scarce resource, several algorithms have been developed at the routing and MAC layers to utilize energy efficiently and extend the lifetime of the network. First layer of the sensor networks is the infrastructure layer and there is no <b>back-bone</b> for these <b>networks.</b> In this paper, we propose a vir-tual backbone for these networks and we measure the net-work lifetime and survivability as the performance evalua-tion metrics of the proposed model. 1...|$|R
40|$|Abstract- The sensors can {{be grouped}} into {{clusters}} and the mini sensors use a high energy {{to communicate with each}} other. Every cluster is equipped with a source node which acts as the central gateway for that cluster. In this paper we treat the communication among the smart nodes in the ad hoc mode where we propose to minimize the energy conservation of the nodes by increasing the cooperativeness. Directional antenna doesn't overhear the nodes outside its own arc of coverage and allows simultaneous communication without interference. This additionally helps to reduce power depletion of nodes. First layer of the sensor networks is the infrastructure layer and there is no <b>back-bone</b> for these <b>networks.</b> In this paper, we propose a frame-work model for cluster based cooperative networks and we measure the network lifetime and survivability as the performance evaluation metrics of the proposed model...|$|R
40|$|Adjustment-free {{clock and}} data {{recovery}} for 2. 488 -Gbit/s SONET applications {{is provided by}} a 1. 77 W, 3. 453. 45 -mm 2 chip implemented in a 25 -GHz fT silicon bipolar process. The chip has an on-chip VCO and operates from 2 to 3 Gbits/s over process, voltage, and temperature variations with a single off-chip filter capacitor. For network monitoring, a highly reliable loss-of-signal detector is provided. For good mechanical, thermal, and RF performance, a custom package was developed using HP’s fine-line hybrid process. SONET 2. 488 -Gbit/s transmission and switching systems, <b>network</b> <b>back-bones,</b> and video transmission are among the many applications benefiting from inexpensive and robust clock and data recovery circuits. Clock and data recovery circuits are used in high-speed communications systems, typically long-span, single-mode fiber-optic links. Their job is to regenerate clean clock and data signals from arbitrary scrambled data inputs that have been corrupted by jitter and intersymbol interference. To provide highly reliable clock and data recovery for 2. 488 -Gbit/s SONET data transmission, the HP CDR 2500 clock and data recovery circuit has been developed. Previous commercial solutions for this application have required multiple chips and GaAs processes. 1 The CDR 2500 was designed in HP’s 25 -GHz fT silicon bipolar process, 2 and incorporates several new circuit ideas developed at HP Laboratories, namely an arbitrary-data phase detector, a reliable loss-of-lock detector, and a monolithic wide-range VCO circuit. Building on techniques developed for the HP G-Link data communications chipset, 3 the CDR 2500 has been optimized for telecommunications needs. The major differences between these two applications are how the data is coded fo...|$|R
40|$|The {{continuous}} {{expansion of}} multimedia terminals, like smart-phones, besides {{the introduction of}} new multimedia services, like the high-definition streaming television, determines a constant increase in the demand of high-speed connectivity. This scenario requires a permanent update of the data capacity in local access networks. Nevertheless, a proper capacity upgrades plan, with new optical links deployment, has required for <b>back-bone</b> optical <b>networks</b> in order to avoid possible networks congestions. Such effect has theoretically forecast as probable in actual networks within next few tenths years, particularly in US if some network segments will reach their saturation. Nowadays, the most promising technology for future optical communication networks has proven to be coherent detection. Rather than intensity modulation direct detection systems, such solution enables to implement new multilevel transmission systems, allowing a more efficient use of the optical transmission bandwidth. These novel coherent optical communication systems have been made possible thanks to the availability of high-speed (gigabit-per-second) analog and digital opto-/electronic devices. Such new devices have allowed the introduction of real-time digital signal processing (DSP) in coherent receivers, so overcoming the practical limitations that were experienced in coherent optical system experiments in the early 1990 s. In this thesis, four main topics have been investigated to assess the feasibility and behaviour of spectrally efficient multichannel coherent optical communication systems for the highest data channel capacity in ultra-long-haul links. More in details, Nyquist filtered multilevel optical modulation formats (QPSK, 8 QAM and 16 QAM) have been investigated as candidates for the efficient transmission of information (toward the Shannon limit). Wavelength division multiplexed (WDM) systems assembled with these modulation formats have proven to support high spectral efficiency for data transmission over distances ranging from 3000 ~km to 10000 ~km. Besides the report of state-of-the-art transmission experiments, some practical and theoretical limitations have been discussed to motivate choices for laboratory experimental solutions as well as devices characteristics, DSP parameters, etc. The introduction of a novel mathematical model, accounting for non-linear interference (NLI) accumulations in optical lines optimized for systems based on coherent detection, has required an experimental validation through ad-hoc Nyquist-WDM transmission experiments. Reliability of the NLI model in performance predictions, enables to derive analytical expressions of transmission quantities as: the Figure of Merit of optical fibers, the non-linear channel capacity, etc. Furthermore, a simulative study to investigate the potentiality of a digital back-propagation (DBP) technique has been performed. The application of a digital non-linear compensation technique to data of a Nyquist-WDM transmission experiment has been carried out. Such analysis confirmed a loss in efficiency of DBP based on single channel processing to improve transmission distance in ultra-dense WDM systems as Nyquist-WDM. Finally, a simulative study about the polarization dependent loss (PDL) impact on system performances has been reported. Results from this analysis have justified the introduction in the DSP of the coherent receiver algorithms for the continuous channel parameters monitor. This DSP upgrade allowed to improve and speed-up laboratory measurements. The thesis is organized as follows: in the first chapter, it is reported a brief review of motivations, advantages and drawbacks in reintroducing coherent detection based systems in optical networks. Thereafter, novel DSP-based coherent optical systems are briefly introduced with some references about DSP algorithms reported in Appendix A. Theoretical foundations about the application of Nyquist theory to achieve ultra-dense WDM systems are reported in the second chapter. Chapters three to six have been dedicated to separately report each of the four investigated topics mentioned above. The final chapter contains a conclusive analysis, and it has followed by a reference bibliography and a complete list of the papers published within the three-year PhD period (2010 - 2012...|$|R

