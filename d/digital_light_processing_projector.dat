9|731|Public
25|$|In electronics, {{a remote}} control is a {{component}} of an electronic device used to operate the device wirelessly from a distance. For example, in consumer electronics, {{a remote control}} {{can be used to}} operate devices such as a television set, DVD player, or other home appliance, from a short distance. A remote control is primarily a convenience feature for the user, and can allow operation of devices that are out of convenient reach for direct operation of controls. In some cases, remote controls allow a person to operate a device that they otherwise {{would not be able to}} reach, as when a garage door opener is triggered from outside or when a <b>Digital</b> <b>Light</b> <b>Processing</b> <b>projector</b> that is mounted on a high ceiling is controlled by a person from the floor level.|$|E
40|$|This paper {{deals with}} stereolithographic 3 D {{printing}} (SLA). It describes both {{upper and lower}} lighting design and shows the differences between laser light and DLP (<b>Digital</b> <b>Light</b> <b>Processing)</b> <b>projector.</b> Another part {{is to find the}} dependence between the time of exposure and the thickness of the layer also known as material profile on the DETAX, gray. So another work and further experiments can be done using this material. These experiments are performed on Way 2 production's SolFlex 650 SLA printer. For ease of use with this printer, parameters affecting print time have been identified and a model is then found to calculate the total print time...|$|E
40|$|We report {{terahertz}} coded-aperture imaging using photo-induced reconfigurable aperture arrays on a silicon wafer. The coded aperture {{was implemented}} using programmable illumination from a commercially available <b>digital</b> <b>light</b> <b>processing</b> <b>projector.</b> At 590 GHz, {{each of the}} array element apertures can be optically turned on and off with a modulation depth of 20 dB and a modulation rate of ~ 1. 3 KHz. Prototype demonstrations of 4 by 4 coded-aperture imaging using Hadamard coding have been performed and this technique has been successfully applied to mapping THz beams by using a 6 by 6 aperture array at 590 GHz. The imaging results agree closely with theoretical calculations based on Gaussian beam transformation, demonstrating that this technique is promising for realizing real-time and low-cost terahertz cameras for many applications. The reported approach provides a simple but powerful means to visualize THz beams, which is highly desired in quasi-optical system alignment, quantum-cascade laser design and characterization, and THz antenna characterization. Comment: 12 pages, 5 figure...|$|E
50|$|Modern day <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projectors</b> {{commonly}} use color wheels {{to generate}} color images, typically running at {{a multiple of}} the video frame rate.|$|R
30|$|The height {{estimating}} {{function is}} very important for three-dimensional (3 -D) measurement systems based on a <b>digital</b> <b>light</b> <b>processing</b> (DLP) <b>projector</b> and a camera. Sinusoidal fringe patterns of the projector are projected onto an object, and the phase of the measuring point is calculated from the camera image. Generally, the least-squares method (LSM) and look-up table(LUT) method are typically used to obtain the phase-to-height relationship.|$|R
50|$|<b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projectors</b> use {{an array}} of tiny (16 μm²) electrostatically-actuated mirrors {{selectively}} reflecting a light source to create an image. Many low-end DLP systems also use a color wheel to provide a sequential color image, a feature that was common on many early color television systems before the shadow mask CRT provided a practical method for producing a simultaneous color image.|$|R
40|$|Lithographic {{processing}} {{has been}} the key technology responsible for the rapid advances in microelectronics, but is typically not accessible to undergraduates. We have developed a maskless photolithographic system that can be assembled from a consumer projector and a trinocular microscope. This system allows students to design and print custom patterns into photoresist in less than 30 min, without using a clean room, a mask facility, or a chrome-etch bath. Students can create and evaluate patterns, make changes to their design, or add additional layers of aligned patterns in a single laboratory session. The rapid turnaround time and low cost of ownership is useful for low-resolution (∼ 10 [*]μm) prototyping. Photoresist is spun in a modified food processor and baked on a standard hot plate. Mating pieces were machined from aluminum. Only the <b>digital</b> <b>light</b> <b>processing</b> <b>projector</b> and food processor are modified, so the microscope, camera, and computer need not be dedicated to the system. The entire system can be assembled for less than $ 5000...|$|E
40|$|This paper {{presents}} a 3 D small-field imaging system {{by using the}} color fringe projection technique to measure the small objects having large slopes and/or discontinuous surface. A stereo microscope is used to generate a small-field projecting field and to capture the deformed fringe patterns on the measured small objects, respectively. Three fringe sets having the optimum fringe numbers are coded into one major color channel to generate color fringe patterns having the maximum fringe contrast of the captured fringe images. Through one channel of the stereo microscope, a DLP (<b>Digital</b> <b>Light</b> <b>Processing)</b> <b>projector</b> projects these generated color fringe pattern images onto the measured objects surface. From another channel, the fringe patterns are deformed {{with regard to the}} object surface and captured by a color CCD camera. The absolute phase of each pixel can be calculated from the captured fringe patterns by using the optimum three-fringe numbers selection method. Experimental results on measuring 3 D shape of small objects show the accuracy and availability of the developed 3 D imaging system...|$|E
40|$|Abstract. We {{describe}} a high-resolution, real-time 3 -D shape measure-ment {{system based on}} a digital fringe projection and phase-shifting tech-nique. It utilizes a single-chip <b>digital</b> <b>light</b> <b>processing</b> <b>projector</b> to project computer-generated fringe patterns onto the object, and a high-speed CCD camera synchronized with the projector to acquire the fringe im-ages at a frame rate of 120 frames/s. A color CCD camera {{is also used to}} capture images for texture mapping. Based on a three-step phase-shifting technique, each frame of the 3 -D shape is reconstructed using three consecutive fringe images. Therefore the 3 -D data acquisition speed of the system is 40 frames/s. With this system, together with the fast three-step phase-shifting algorithm and parallel processing software we developed, high-resolution, real-time 3 -D shape measurement is re-alized at a frame rate of up to 40 frames/s and a resolution of 532 500 points per frame. © 2006 Society of Photo-Optical Instrumentation Engineers. DOI: 10. 1117 / 1. 2402128 Subject terms: High resolution; real time; 3 -D shape measurement; metrology; phase measurement; phase-shifting; structured light; range scanning. Paper 060119 received Feb. 16, 2006; accepted for publication May 11, 2006; published online Dec. 13, 2006. ...|$|E
5000|$|One use of {{the term}} [...] "display resolution" [...] applies to fixed-pixel-array {{displays}} such as plasma display panels (PDP), liquid-crystal displays (LCD), <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projectors,</b> OLED displays, and similar technologies, and is simply the physical number of columns and rows of pixels creating the display (e.g. 1920 × 1080). A consequence of having a fixed-grid display is that, for multi-format video inputs, all displays need a [...] "scaling engine" [...] (a digital video processor that includes a memory array) to match the incoming picture format to the display.|$|R
5000|$|The {{screen door}} effect on <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projectors</b> can be mitigated by {{deliberately}} setting the projected image {{slightly out of}} focus, which blurs the boundaries of each pixel to its neighbor. This minimizes the effect by filling the black pixel perimeters with adjacent light. Some older LCD projectors have a more noticeable screen door effect than first generation DLP projectors. [...] Newer DLP chip designs promise closer spacing of the mirror elements which would reduce this effect; however, some space is still required along one edge of the mirror to provide a control circuit pathway. Use of Dolgoff's depixelization method could also produce a DLP projector without noticeable pixelation.|$|R
40|$|The device has a {{container}} (1) for retaining a liquid polymeric component material (3). An optical transparent disk (5) is arranged opposite to an outer surface (6) of a roller (2) and formed transparent to an electromagnetic radiation of exposure units (7, 7 a, 7 b). The transparent disk exhibits a {{distance to the}} outer surface, where the distance increases from a minimum initial value in a circumferential direction of the roller. The units form exposure stations along the circumferential direction, where the radiation is directed into the material in the stations through the transparent disk. The exposure units are designed as <b>digital</b> <b>light</b> <b>processing</b> (DLP) <b>projectors.</b> An independent claim is also included for a method for manufacturing components...|$|R
40|$|The DMD (Digital Micromirror Device) has an {{important}} future in both ground and space based multi-object spectrometers. A series of laboratory measurements have been performed to determine the scattered light properties of a DMD. The DMD under test had a 17 m pitch and 1 m gap between adjacent mirrors. Prior characterization of this device has focused on its use in DLP (TI <b>Digital</b> <b>Light</b> <b>Processing)</b> <b>projector</b> applications in which a whole pixel is illuminated by a uniform collimated source. The purpose of performing these measurements {{is to determine the}} limiting signal to noise ratio when utilizing the DMD as a slit mask in a spectrometer. The DMD pixel was determined to scatter more around the pixel edge and central via, indicating the importance of matching the telescope point spread function to the DMD. Also, the generation of DMD tested here was determined to have a significant mirror curvature. A maximum contrast ratio was determined at several wavelengths. Further measurements are underway on a newer generation DMD device, which has a smaller mirror pitch and likely different scatter characteristics. A previously constructed instrument, RITMOS (RIT Multi-Object Spectrometer) will be used to validate these scatter models and signal to noise ratio predications through imaging a star field...|$|E
40|$|One {{may wish}} to use {{computer}} graphics images to carry out road visibility studies but most display devices still have a limited dynamic range. In driving scenes, the human visual system may be presented with a large illumination range. Our visual system copes with the vast illumination range through adaptation. It works {{as a set of}} different band pass filters which all together make up the Contrast Sensitivity Function. Visual adaptation depends on the spatial frequency filtering characteristics. In this paper, we propose a tone mapping algorithm to compress the luminance dynamic range while reproducing the overall impression of contrast and preserving the driver’s performance. To characterize the effects of local adaptation, we decompose the luminance image into a Laplacian pyramid and process the levels separately. We want the contrast perception to remain the same after the tone mapping operator has been applied. In road visibility, the Visibility Level is used as a performance index for the contrast perception. To assess our algorithm, we carried out a psychophysical experiment. We compared the visual performance of a number of observers measured when he stared at a reference scene, and when he stared at the image of this reference scene, processed by a Tone Mapping operator and displayed on a calibrated Liquid Crystal Display monitor (LCD). The reference scene is a High Dynamic Luminance image projected by a calibrated <b>Digital</b> <b>Light</b> <b>Processing</b> <b>projector</b> (DLP). The maximum luminance displayed by the DLP is 500 cd. m − 2 whereas the maximum of luminance that can be displayed by the LCD is 167 cd. m − 2. We measured the observers ’ visual performance with a Landolt Ring. These measures were made for 8 contrast values between the ring and the background. The break in the ring was displayed during 100 ms and we ask the subjects to indicate its position. We obtained a better preservation of the contrast perception around the perception threshold with our algorithm than with the 2 others we used for comparison...|$|E
40|$|AbstractNon-contact {{structured}} light system which utilizes a liquid crystal display (LCD) or <b>digital</b> <b>light</b> <b>processing</b> (DLP) <b>projector</b> is widely used in 3 -D surface profile measurement. In such fringe projection profilometry, the digital fringe projection and phase-shifting technique is employed. Although the accurate phase-shifting patterns is generated by a computer and projected by the LCD or DLP projector, the phase measurement error still exists and the error will affect the surface profile measurement results. In this paper, {{the causes of the}} phase error are analyzed and the subsequent error corrections are introduced when the color-encoded digital fringe projection (CFP) technique is used to retrieve the phase value. Experimental works are also carried out to verify the effectiveness of the proposed method...|$|R
40|$|We have {{analyzed}} {{different approaches}} to calibrating 4 -segment <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projectors</b> {{from the perspective of}} an end-user. A modification is introduced to Wyble and Rosen’s 1, 2 model that improves its prediction of tristimulus values (XYZ) as a function of input RGB. Tests also show that Tamura, Tsumura, and Miyake’s Masking model, which was originally introduced to compensate for channel interaction in LCD monitors, performs as well as the improved Wyble-Rosen model in the forward direction (RGB to XYZ). For predicting RGB values given XYZ input data (backward direction); however, we find that the Masking model is more accurate. All the models considered in this paper involve only basic look-up tables and matrix multiplication and as a result are computationally efficient. 1...|$|R
40|$|This conference {{paper is}} {{available}} {{here with the}} kind permission of the Solar Energy Society. A commercial <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projector</b> has been utilised for compressed sensing current mapping of photovoltaic (PV) devices. Through the projector, the necessary patterns are projected to apply compressive sampling for measurement acquisition. The reconstruction of the current map is achieved by an optimisation algorithm. The main advantage of this method is that measurement time is significantly reduced, compared to conventional LBIC measurement systems. This is achieved mainly by acquiring fewer measurements than a raster scan would need. Initial current maps of cells and modules have been acquired, showing the feasibility of the method. The issues of such a system have been investigated and its potential for fast and simple current mapping of PV modules is demonstrated...|$|R
50|$|Simple Eidophors {{produced}} black-and-white images. Later {{units used}} a color wheel (equivalent {{to the color}} television standard CBS tried {{to bring to the}} market against RCA/NBC's FCC-approved NTSC system, and today's DLP projection system) to produce red, green, and blue fields. The last models produced used separate red, green, and blue units in a single case. The Eidophor was eighty times brighter than CRT projectors of the time. The last Eidophors were able to project colour images of up to 18 metres in width. Advances in projection television technology in the 1990s brought {{about the end of the}} Eidophor. The new devices were smaller and cheaper and produced comparable results. Current technologies include the Liquid Crystal Display (LCD) and <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projectors,</b> both of which produce superior results from easily portable devices.|$|R
5000|$|Digital media {{playback}} of high-resolution 2K files {{has at least}} a 20-year history. Early video data storage units (RAIDs) fed custom frame buffer systems with large memories. In early digital video units, content was usually restricted to several minutes of material. Transfer of content between remote locations was slow and had limited capacity. It {{was not until the}} late 1990s that feature-length films could be sent over the [...] "wire" [...] (Internet or dedicated fiber links). On October 23, 1998, <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projector</b> technology was publicly demonstrated with the release of The Last Broadcast, the first feature-length movie, shot, edited and distributed digitally. In conjunction with Texas Instruments, the movie was publicly demonstrated in five theaters across the United States (Philadelphia, Portland (Oregon), Minneapolis, Providence, and Orlando).|$|R
40|$|National Natural Science Foundation of China [61308073]; Science and Technology Commission of Shanghai Municipality [15 JC 1403500]Face {{recognition}} {{technology has}} great prospects for practical applications. Three-dimensional (3 D) human faces {{are becoming more}} and more important in consideration of the limits of two-dimensional face recognition. We propose an active binocular setup to obtain a 3 D colorful human face using the band-limited binary patterns (BBLP) method. Two grayscale cameras capture the BBLP projected onto the target of human face by a <b>digital</b> <b>light</b> <b>processing</b> (DLP) <b>projector</b> synchronously. Then, a color camera captures a colorful image of the human face. The benefit of this system is that the 3 D colorful human face can be obtained easily with an improved temporal correlation algorithm and the precalibration results between three cameras. The experimental results demonstrated the robustness, easy operation, and the high speed of this 3 D imaging setup...|$|R
5000|$|... 1932 he {{received}} {{a call to the}} ETH Zurich, where he became professor and founded the Institute for Technical Physics. He developed and patented the Eidophor technique of displaying television pictures the size of cinema screens. Dr. Edgar Gretener, his chief assistant at the ETH, was project leader for the development of Eidophor. This project was transferred to a company founded by Gretener, which later became Gretag AG. After years of development, Eidophor achieved commercial success until Liquid Crystal Display LCD (another invention with important Swiss contributors) and <b>Digital</b> <b>Light</b> <b>Processing</b> DLP video <b>projectors</b> became available.|$|R
40|$|A {{number of}} {{projects}} within the computer graphics, computer vision, and human-computer interaction communities have recognized the value of using projected structured light patterns {{for the purposes of}} doing range finding, location dependent data delivery, projector adaptation, or object discovery and tracking. However, most of the work exploring these concepts has relied on visible structured light patterns resulting in a caustic visual experience. In this work, we present the first design and implementation of a high-resolution, scalable, general purpose invisible near-infrared projector that can be manufactured in a practical manner. This approach is compatible with simultaneous visible light projection and integrates well with future <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projector</b> designs – {{the most common type of}} projectors today. By unifying both the visible and non-visible pattern projection into a single device, we can greatly simply the implementation and execution of interactive projection systems. Additionally, we can inherently provide location discovery and tracking capabilities that are unattainable using other approaches...|$|R
40|$|We {{introduce}} {{a method to}} imperceptibly embed arbitrary binary patterns into ordinary color images displayed by unmodified off-the-shelf <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projectors.</b> The encoded images are visible only to cameras synchronized with the projectors and exposed for a short interval, while the original images appear only minimally degraded to the human eye. To achieve this goal, we analyze and exploit the micro-mirror modulation pattern used by the projection technology to generate intensity levels for each pixel and color channel. Our real-time embedding process maps the user’s original color image values to the nearest values whose camera-perceived intensities are the ones desired by the binary image to be embedded. The color differences caused by this mapping process are compensated by error-diffusion dithering. The non-intrusive nature of our novel approach allows simultaneous (immersive) display and acquisition under controlled lighting conditions, as defined on a pixel level by the binary patterns. We therefore introduce structured light techniques into human-inhabited mixed and augmented reality environments, where they previously often were too intrusive. 1...|$|R
40|$|<b>Digital</b> <b>light</b> <b>processing</b> (DLP) <b>projectors</b> {{have been}} widely {{utilized}} to project digital structured-light patterns in 3 D imaging systems. In order to obtain accurate 3 D shape data, {{it is important to}} calibrate DLP projectors to obtain the internal parameters. The existing projector calibration methods have complicated procedures or low accuracy of the obtained parameters. This paper presents a novel method to accurately calibrate a DLP projector by using an optical coaxial camera. The optical coaxial geometry is realized by a plate beam splitter, so the DLP projector can be treated as a true inverse camera. A plate having discrete markers on the surface is used to calibrate the projector. The corresponding projector pixel coordinate of each marker on the plate is determined by projecting vertical and horizontal sinusoidal fringe patterns on the plate surface and calculating the absolute phase. The internal parameters of the DLP projector are obtained by the corresponding point pair between the projector pixel coordinate and the world coordinate of discrete markers. Experimental results show that the proposed method can accurately calibrate the internal parameters of a DLP projector...|$|R
40|$|Abstract. Active vision {{techniques}} use programmable light sources, such as projectors, whose intensities can {{be controlled}} over space and time. We present a broad framework for fast active vision using <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projectors.</b> The <b>digital</b> micromirror array (DMD) in a DLP projector is capable of switching mirrors “on ” and “off ” at high speeds (10 6 /s). An off-the-shelf DLP projector, however, effectively operates at much lower rates (30 - 60 Hz) by emitting smaller intensities that are integrated over time by a sensor (eye or camera) to produce the desired brightness value. Our key idea is to exploit this “temporal dithering ” of illumination, as observed by a high-speed camera. The dithering encodes each brightness value uniquely and {{may be used in}} conjunction with virtually any active vision technique. We apply our approach to five well-known problems: (a) structured light-based range finding, (b) photometric stereo, (c) illumination de-multiplexing, (d) high frequency preserving motion-blur and (e) separation of direct and global scene components, achieving significant speedups in performance. In all our methods, the projector receives a single image as input whereas the camera acquires a sequence of frames. ...|$|R
40|$|In this work, we recover {{fast moving}} scenes by {{exploiting}} the high-speed illumination “dithering” of cheap and easily available <b>digital</b> <b>light</b> <b>processing</b> (DLP) <b>projectors.</b> We first show how to reverse-engineer the temporal dithering for off-the-shelf projectors, using a high-speed camera. DLP dithering can produce temporal patterns {{commonly used in}} active vision techniques. Since the dithering occurs {{at a very high}} framerate, such illumination-based methods can be “sped up” for fast scenes. We demonstrate this with three applications, each of which only requires a single slide to be displayed by the DLP projector. The quality of the result is determined by the camera frame-rate available to the user. Pairing a high-speed camera and a DLP projector, we demonstrate structured light reconstruction at 100 Hz. With the same camera and three or more DLP projectors, we show photometric stereo and demultiplexing applications at 300 Hz. Finally, with a real-time (60 Hz) or still camera, we show that DLP illumination acts as a very fast flash, allowing strobe photography of high-speed scenes. We discuss, in depth, some characteristics of the temporal dithering with a case study o...|$|R
40|$|This {{paper was}} {{published}} in Optics Express and is made available as an electronic reprint {{with the permission of}} the Optical Society of America. The paper {{can be found at the}} following URL on the OSA website: [URL] Systematic or multiple reproduction or distribution to multiple locations via electronic or other means is prohibited and is subject to penalties under law. We report optical modulation of continuous terahertz (THz) wave in the frequency range of 570 - 600 GHz using photo-induced reconfigurable patterns on a silicon wafer. The patterns were implemented using programmable illumination from a commercially-available <b>digital</b> <b>light</b> <b>processing</b> (DLP) <b>projector.</b> A modulation depth of 20 dB at 585 GHz has been demonstrated. Modulation speed measurement shows a 3 -dB bandwidth of 1. 3 kHz which is primarily limited by the DLP system. A photo-induced polarizer with tunable polarization angle has been demonstrated, showing a 3 -dB extinction ratio. Reconfigurable aperture-arrays (4 x 4 pixels) have been attempted for room-temperature coded-aperture imaging using a single Schottky diode detector at 585 GHz. We envision that this technique will provide a simple but powerful means to realize a variety of cost-effective reconfigurable quasi-optical THz circuits and components...|$|R
40|$|Personal {{use of this}} {{material}} is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing {{this material}} for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. The Compressed Sensing (CS) sampling theory has been combined with the Light Beam Induced Current (LBIC) method, to produce an alternative current mapping technique for photovoltaic (PV) devices. Compressive sampling of photocurrent is experimentally implemented using a Digital Micro-mirror Device (DMD). The main advantage of this new method for current mapping is that measurement time can be significantly reduced compared to conventional LBIC measurement systems. This is achieved mainly by acquiring fewer measurements than a raster scan would need and by utilizing the fast response of the micro-mirror array. Two different experimental layouts are considered in this work. The first is a small area optical set-up based on a single wavelength laser source. The second layout utilizes a commercial <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projector</b> through which compressive sampling is applied. Experimental results with both experimental schemes demonstrate that current maps can be produced with less than 50 % of the measurements a standard LBIC system would need. The ability to acquire current maps of individual cells in encapsulated modules is also highlighted. The advantages and drawbacks of the method are presented and its potential to significantly reduce measurement time of current mapping of PV cells and modules is indicated...|$|R
40|$|Stereoscopic 3 D {{displays}} {{are able}} to provide an added sense of depth compared to traditional displays by sending slightly different images to each eye. Although stereoscopic displays can provide a more immersive viewing experience, existing methods have drawbacks that can detract from image quality and cause perceptual artifacts. In this thesis I investigate perceptual artifacts associated with displays, and propose novel techniques that can improve viewing experience compared to existing methods. Chapter 1 presents a broad introduction to {{the various types of}} artifacts that can occur in displays, including motion artifacts, depth distortion, flicker, and color breakup. In Chapter 2, I describe a novel display technique, "spatiotemporal interlacing," that combines spatial and temporal interlacing. I demonstrate using psychophysics that this method provides a better viewing experience than existing methods, and I present a computational model that confirms the psychophysical data. In Chapter 3, I present an investigation of perceptual artifacts on a high-frame-rate (240 Hz) temporally interlaced OLED display. The high frame rate of this display allows for several unique driving modes. I investigated the perceptual consequences of these driving modes, characterizing the display in terms of motion, depth distortion, flicker, spatial resolution, and luminance. I demonstrate how one's selection of viewing mode can tailor the viewing experience depending on the goals of viewer. Chapter 4 discusses the phenomenon of color breakup, a perceptual artifact that occurs in displays that present colors sequentially in time, such as <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projectors.</b> I discuss a novel psychometric procedure to measure the artifact, and a way to model the saliency of the artifact based on known spatiotemporal properties of the human visual system. I also propose a method for reducing color breakup...|$|R
40|$|Appearance {{of objects}} in {{captured}} images and videos not only relies on objects themselves, but also significantly depends on imaging sensors and illuminations. Therefore, investigating how light emitted from light source interacts with objects and sensors {{has been an important}} task for a variety of applications in computer vision field. It is well known that light spans in a wide wavelength range, thus this interaction should be analyzed in spectral domain. However, it is hard to carry out the analysis because dominating equipments usually provide RGB 3 values only which are far from enough for spectral information estimation in the visible wavelength range. To deal with this problem, we present a framework for estimating spectral information of objects, cameras and illumination in this thesis. First, we show a system to recover spectral reflectance of objects with high temporal resolution. Spectral reflectance offers intrinsic characteristics of objects that are independent of illuminations and sensors. This direct representation about the objects is useful for solving many computer vision problems. However, existing methods for spectral reflectance recovery are limited either by their low temporal resolution or requirement for special hardware. To remove these limitations, we present a novel system for spectral reflectance recovery by exploiting the unique color-forming mechanism of <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) <b>projectors.</b> DLP projectors use color wheels which are composed of several color segments and rotate quickly to produce desired light. We make effective use of this mechanism and show that a DLP projector {{can be used as a}} light source with spectrally distinct illuminations when we capture scenes'appearance under the projector's irradiation by a high-speed camera. Our imaging system is built on easily available devices and capable of conducting spectral measurements at 100 Hz. Based on the measurements obtained by our system, spectral reflectance of the scene is recovered using a linear approximation of surface reflectance. We carefully evaluate the accuracy of our system and demonstrate its effectiveness by spectral relighting of dynamic scenes with fast-moving objects. Then, we use fluorescence to estimate camera spectral sensitivity under unknown illuminations. Camera spectral sensitivity is an indispensable factor for various color-based computer vision tasks. Though several methods have been proposed to estimate it, their applications are all severely restricted by the requirement for a known illumination spectrum. In this thesis, we present a single-image estimation method using fluorescence with no requirement for a known illumination spectrum. Under different illuminations, the spectral distributions of fluorescence emitted from the same material remain unchanged up to a certain scale. Thus, a camera's response to the fluorescence would have the same chromaticity. Making use of this chromaticity invariance, the camera spectral sensitivity can be estimated under an arbitrary illumination whose spectrum is unknown. Through extensive experiments, we proved that our method is accurate under different illuminations. Finally, based on the estimated camera spectral sensitivity, we show how to recover spectra of daylights with high accuracy. Making use the estimated camera spectral sensitivities and daylight spectra, color correction problems can be solved. Results show that images after the correction match the target images well. 報告番号: 甲 28466; 学位授与年月日: 2012 - 03 - 22; 学位の種別: 課程博士; 学位の種類: 博士(情報理工学); 学位記番号:; 研究科・専攻: 情報理工学系研究科電子情報学専...|$|R
40|$|The {{technique}} of generating sinusoidal fringe patterns by defocusing the binary dithering patterns has improved the measurement speed of Phase-Shifting Method to be super-fast,for the binary patterns can be projected by DLP(Digital <b>Light</b> <b>Processing)</b> <b>projector</b> {{at the rate}} of KHz. This projector defocu [...] ...|$|R
50|$|Today, TI {{is made up}} of four divisions: analog products, {{embedded}} processors (EP), <b>digital</b> <b>light</b> <b>processing</b> (DLP), {{and educational}} technology (ET).|$|R
5000|$|A {{lifeboat}} simulator, with a five-metre-radius cylindrical visualisation {{screen with}} <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP), {{was provided by}} Antycip Simulation UK of Oxfordshire.|$|R
50|$|Other technologies, such as <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) {{and liquid}} crystal on silicon (LCOS) are also {{becoming}} more popular in modestly priced video projection.|$|R
50|$|This {{method is}} similar in {{principle}} to field-sequential color system by CBS and other sequential color methods such as used in <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP).|$|R
5000|$|Module makers (e.g., Jabil/Sypro <b>Digital</b> <b>Light</b> <b>Processing</b> (DLP) with LED, 3M Liquid crystal on silicon (LCoS) with LED, Explay LCoS with laser, AAXA Technologies with LCoS engine) ...|$|R
