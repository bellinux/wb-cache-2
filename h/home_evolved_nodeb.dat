5|109|Public
40|$|Abstract: The {{specification}} of the <b>Home</b> <b>Evolved</b> <b>NodeB</b> (Home-eNB), {{which is a}} small base station designed for use in residential or small business environment, is currently ongoing in 3 GPP LTE (Long Term Evolution) systems. One of the key requirements for its feasibility in the LTE system is the mobility management in the deployment of the numerous Home-eNBs and other 3 GPP network. In this paper, we overview the characteristic of Home-eNB and also describe the mobility management issues and the related approaches in 3 GPP LTE based Home-eNB systems. Keywords: Home-eNB, 3 GPP LTE (Long Term Evolution), Mobility Management 1...|$|E
30|$|A {{femtocell}} can {{be easily}} set up without any centralized coordination, but simply enabling a low-power and small-range radio base station, which {{is referred to as}} <b>home</b> <b>evolved</b> <b>NodeB</b> (HeNB). Such a device has plug-and-play capabilities, is connected to the core network through a DSL line, and operates in the spectrum licensed for cellular systems[8]. The uncoordinated nature of femtocell deployment poses novel and interesting challenges on radio resource management (RRM). In fact, classical approaches already adopted in 3 G systems to face frequency planning, interference coordination, radio resource scheduling, and access policies could be not useful anymore in HetNet scenarios.|$|E
40|$|Long Term Evolution (LTE) system, User Equipments (UEs) have {{to measure}} system {{information}} of target cells, {{if the target}} cells are Closed Subscriber Group (CSG) cells. <b>Home</b> <b>evolved</b> <b>NodeB</b> (HeNB) in the LTE femtocell is CSG cell. Femtocell is one of promising cellular network technologies to enhance both of cell coverage and capacity. This paper introduces six measurement methods of system information in the 3 GPP LTE system. And, we also analyzed performance of the proposed measurement methods in aspect of service interruption time and measurement delay. We {{find out that the}} autonomous and parallel method shows the smallest measurement delay and the methods which use small gaps have small service interruption time. Keywords-LTE; Femtocell; System Information Measuremen...|$|E
30|$|To improve QoS and {{throughput}} {{performance for}} the users, two-tier heterogeneous networks (HetNets) are considered [3]. These networks have conventional eNBs in the first tier, overlaid with low-power LTE-Advanced (LTE-A) femtocells. In LTE-A, femtocells are {{commonly referred to as}} <b>home</b> <b>evolved</b> <b>NodeBs</b> (HeNBs). A recent study shows that 114 million mobile users will be accessing mobile networks through HeNBs by 2014 [4]. In HetNets that are composed of eNB and HeNB environments, two classes of users are considered. Users who are connected to eNB are called macro users (MUE), while those connected to HeNBs are referred as femto users (FUE). In two-tier HetNets, the HeNBs have the advantages of small form factor, low cost, and smaller coverage. These advantages support reuse of the same licensed band multiple times within the second tier of the HetNets. That is, the employment of HeNB improves QoS for users, spectral efficiency, and hence the capacity of the overall network. However, the use of the same frequency bands between MUE and FUE leads to several kinds of co-channel interference. The major interference scenario involves downlink (DL) interference from HeNBs to MUEs.|$|R
30|$|Femto-cells {{consist of}} user-deployed <b>Home</b> <b>Evolved</b> <b>NodeBs</b> (HeNBs) that promise {{substantial}} gains in system spectral efficiency, coverage, and data rates {{due to an}} enhanced reuse of radio resources. However, reusing radio resources in an uncoordinated, random fashion introduces potentially destructive interference to the system, both, in the femto and macro layers. An especially critical scenario is a closed-access femto-cell, cochannel deployed with a macro-cell, which imposes strong downlink interference to nearby macro user equipments (UEs) that {{are not permitted to}} hand over to the femto-cell. In order to maintain reliable service of macro-cells, it is imperative to mitigate the destructive femto-cell to macro-cell interference. The contribution in this paper focuses on mitigating downlink femto-cell to macro-cell interference through dynamic resource partitioning, in the way that HeNBs are denied access to downlink resources that are assigned to macro UEs in their vicinity. By doing so, interference to the most vulnerable macro UEs is effectively controlled at the expense of a modest degradation in femto-cell capacity. The necessary signaling is conveyed through downlink high interference indicator (DL-HII) messages over the wired backbone. Extensive system level simulations demonstrate that by using resource partitioning, for a sacrifice of 4 % of overall femto downlink capacity, macro UEs exposed to high HeNB interference experience a tenfold boost in capacity.|$|R
3000|$|The {{vehicles}} and <b>evolved</b> <b>NodeB</b> (eNB) broadcast signaling {{to indicate the}} existing of themselves via control channel periodically; [...]...|$|R
40|$|Femtocell {{networks}} that use <b>Home</b> <b>evolved</b> <b>NodeB</b> (HeNB) and existing networks for backhaul connectivity can fulfill the upcoming demand for high data rates in wireless communication systems {{as well as}} extend the coverage area. In this paper we seem handover between femtocell and macrocell as a heterogeneous handover and apply the Host Identity Protocol (HIP) with Media Independent Handover (MIH) to achieve handover execution. It considers handover parameters for, including interference, velocity, RSS and quality of service (QoS) level. We propose a new handover strategy based on HIP between the femtocell and the macrocell for LTE (Long Term Evolution) -based networks in hybrid access mode. This strategy can avoid unnecessary handovers and can reduce handover failure. </span...|$|E
40|$|The {{conventional}} mobile networks {{consists of}} macrocells or Evolved NodeB (eNB) which provide good coverage but reduces bandwidth {{available for a}} given area. The problem of coverage and lim- itation of bandwidth in a mobile network system is solved by using femtocells or <b>Home</b> <b>Evolved</b> <b>NodeB</b> (HeNB). In this thesis various handover scenarios have been considered for a LTE network having both femtocells (HeNB) and macrocells (eNB). Three handover scenarios: hand-in, hand-out and inter- femtocell and two dierent handover strategies: reactive and proactive handover are considered and analyzed. The mobility of the User Equipment (UE) has also been taken into consideration to achieve an optimal handover procedure. An algorithm has been proposed, {{which is used to}} dynamically decide upon the handover policy to be used based on the UE mobility and signal strength from the various available cells. The signaling and latency in handovers is studied using X 2 interface between macrocells and femtocells. The proposed algorithm has been studied using the NS- 3 simulator...|$|E
30|$|The LTE {{system is}} mainly {{composed}} by two parts: the air interface, i.e., the evolved-universal terrestrial {{radio access network}} (E-UTRAN), and the packet switched core network, known as Evolved Packet Core. From the network side, the <b>evolved</b> <b>NodeB</b> (eNB) is the only node of the E-UTRAN {{and it is in}} charge of providing network connectivity through the air interface to all user equipments (UEs) in the cell, according to the classic cellular network paradigm.|$|R
30|$|In [7 – 9], {{the authors}} propose the TDD {{underlay}} concept. Owing to the asymmetric nature of traffic [10], {{one of the}} frequency division duplex (FDD) bands (the underloaded one) can be split in time such that the HeNB transmits and receives information from its associated UE in a time division duplex (TDD) fashion. This proposal, while making efficient utilization of unused resources, still encounters a bottleneck, because typically, {{the link between the}} HeNB and its femto UEs is much stronger than that between the <b>evolved</b> <b>NodeB</b> (eNB) and the macro UE.|$|R
30|$|Relaying is an {{appealing}} technology that {{was introduced in}} LTE-A to provide seamless connection and high achievable data rates to the users located in the cell-edge or in coverage holes[1, 2]. Relay nodes (RN) are low power <b>evolved</b> <b>NodeB</b> (eNB) which, when deployed in the macro cell, improve the signal quality between the user equipment (UE) and eNB by dividing the radio link into two hops: the so-called backhaul link between the RN and the eNB, which in this context, {{is referred to as}} the Donor eNB (DeNB), and the so-called access link between the RN and the UE[3].|$|R
30|$|Conventional {{cellular}} systems use {{a planned}} homogeneous macrocell-based network architecture where the macrocells, i.e., <b>evolved</b> <b>NodeBs</b> or eNBs, {{provide services to}} the users in the network. In a homogeneous environment, the eNBs have the same transmit power levels, antenna patterns, receiver noise floors, and backhaul connectivity. This allows the network to offer a similar quality of service (QoS) to the user equipment (UE) across all cells [1, 2]. However, such a deployment is not suitable for cell-edge users because they have weak received signal power from the base stations (BSs). This degrades the QoS and throughput performance of the users.|$|R
40|$|When <b>evolved</b> <b>NodeB</b> (eNB) {{flexible}} functional split {{is implemented}} in Cloud-Radio Access Network (Cloud-RAN) 5 G systems, fronthaul connectivity between the virtualized functions must be always guaranteed. This study proposes {{the utilization of}} Software Defined Networking (SDN) to control mobile fronthaul. In particular, this study investigates {{the ability of the}} SDN-based control of reconfiguring the fronthaul to maintain virtualized network function connectivity when cell and optical access turn into sleep mode (off mode) for energy efficiency purposes. The experiments in two federated testbeds show that, upon cell and optical access turning on and off, the fronthaul reconfiguration time is limited to few tens of milliseconds...|$|R
30|$|The FiWi domain {{consists}} of the OLT (located at the CO), the powerless passive splitter/combiner, and hybrid optical-wireless units at the fronthaul. Hybrid optical-wireless units are {{the evolution of the}} integration of the traditional ONU, which terminates the PON by providing optical interface to the final users (realizing the Fiber To The x—FTTx paradigm), and the BS which can be a traditional 4 G BS (a WiMAX BS or an LTE <b>evolved</b> <b>NodeB)</b> or a 5 G cloud radio access network (C-RAN) BS with remote radio head (RRH). In the former case, various integration methods of the ONU and BS can be applied such as independent, hybrid, combined, unified, and microwave over fiber (MoF) architecture [34].|$|R
40|$|With {{the rapid}} growth of mobile communications, {{deployment}} and maintenance of cellular mobile networks {{are becoming more and more}} complex, time consuming, and expensive. In order to meet the requirements of network operators and service providers, the telecommunication industry and international standardization bodies have recently paid intensive attention to the research and development of self-organizing networks. In this article we first introduce both the market and technological perspectives for SONs. Then we focus on the self-configuration procedure and illustrate a self-booting mechanism for a newly added <b>evolved</b> <b>NodeB</b> without a dedicated backhaul interface. Finally, mobility load balancing as one of the most important selfoptimization issues for Long Term Evolution networks is discussed, and a distributed MLB algorithm with low handover cost is proposed and evaluated...|$|R
40|$|AbstractIn Long Term Evolution-Advanced (LTE-A) and Worldwide {{interoperability}} for microwave access (WiMAX) systems, {{the coverage}} area, signal strength and transmission quality {{are affected by}} white Gaussian noise, shadowing, wireless interference etc. This effect can be decreased by using more number of <b>evolved</b> <b>NodeBs</b> (eNB), but problem is that eNBs are expensive and it will increase network cost. Relay Stations (RS) are less expensive than eNBs, hence we go for RS deployment instead of eNBs. Thus this paper proposes a cost effective deployment of RSs using dynamic cost based deployment of RS (DCDR) approach. This approach first analyse the impact parameters and then finds the dynamic weighting and network cost for different deployment combination. Simulation result shows that DCDR approach gives a cost effective solution for the deployment of RSs...|$|R
30|$|One primary {{research}} {{trend of}} WNV is Long Term Evolution (LTE) air interface virtualization, where multiple VOs share resource {{on the air}} interface [4]. Gudipati et al. [5] proposes logically abstracting multiple LTE eNodeB (<b>evolved</b> <b>NodeB)</b> as one virtual big base station. Hence, all the resource elements can be conceptually thought of as three-dimensional resource grid with time, frequency, and space. Li et al. [6] promotes replacing LTE eNodeBs with remote radio units (RRUs) {{in order to achieve}} complete virtualization. Thus the distributed control units can be replaced by a central controller, which maintains a global view of the radio access network (RAN). Yang et al. [7] refractors the LTE control plane as software-defined to enhance classified user traffic quality of service (QoS). The network performance is therefore improved due to the additional flexibility provided to user service.|$|R
40|$|With the {{increasing}} complexity of current networks, it became evident {{the need for}} Self-Organizing Networks (SON), which aims to automate most of the associated radio planning and optimization tasks. Within SON, this paper aims to optimize the Neighbour Cell List (NCL) for Long Term Evolution (LTE) <b>evolved</b> <b>NodeBs</b> (eNBs). An algorithm composed by three decisions were were developed: distance-based, Radio Frequency (RF) measurement-based and Handover (HO) stats-based. The distance-based decision, proposes a new NCL taking account the eNB location and interference tiers, based in the quadrants method. The last two algorithms consider signal strength measurements and HO statistics, respectively; they also define a ranking to each eNB and neighbour relation addition/removal based on user defined constraints. The algorithms were developed and implemented over an already existent radio network optimization professional tool. Several case studies were produced using real data from a Portuguese LTE mobile operator. © 2014 IEEE...|$|R
40|$|With picocells {{deployed}} in the coverage of a macrocell in heterogeneous networks (HetNets), the macrocell <b>evolved</b> <b>NodeB</b> (MeNB) may receive interference signals from the picocell users, which results in more severe co-channel interference (CCI) problem in the uplink. In this paper, the spatial uplink interference coordination is investigated in multiple antenna systems, according to which the receiver coding matrix is generated by MeNB to mitigate the CCI from picocell users. Two interference coordination (IC) schemes are proposed based on whether the receiver coding matrix is full rank or not, named as full coding (IC-FC) and part coding (IC-PC), respectively. The application of the proposed schemes is discussed in single picocell and multiple picocell scenarios. The CCI can be totally canceled in single picocell scenario, and an algorithm is developed in multiple picocell networks to mitigate the most severely interfering picocell. Link level and system level simulations are applied, and it is shown that significant performance gain is achieved by our proposed schemes over traditional IC receivers...|$|R
40|$|International audienceEmerging {{multimedia}} {{services are}} spreading significantly {{thanks to the}} availability of high speed wireless networks. Network operators are facing the challenges to accommodate these services (e. g. Skype, interactive gaming, and other multimedia applications) with high user satisfaction. This paper presents a Quality of Experience (QoE) driven approach to allocate the radio resources in Long Term Evolution (LTE) wireless networks, {{in order to get}} higher user satisfaction. The main objective is to enhance the user experience while using the multimedia services such as VoIP, by jointly considering the user QoE and available wireless radio resources in the LTE-Advanced (LTE-A) network. Specifically, we propose a new downlink scheduling algorithm known as “QoE Scheme” for multimedia VoIP service in LTE-A networks. The main advantage of the proposed QoE Scheme is its measurement of user satisfaction and its feedback mechanism to the scheduler at <b>evolving</b> <b>NodeB</b> (eNodeB) {{in order to make the}} scheduling decisio...|$|R
40|$|With the {{development}} of mobile internet service, long-term evolution (LTE) system was proposed in the third generation partnership project (3 GPP) to provide higher data rates and frequency efficiency. Since the year of 2010, 113 LTE networks have been commercially deployed worldwide, {{and most of the}} networks are based on frequency division duplexing (FDD). In this paper, measurement methods of four MIMO transmission modes (TMs) in time division-LTE (TD-LTE) are studied and analyzed. Link level simulation is carried out to evaluate the downlink throughput for different signal-to-noise ratios and parameter settings. Furthermore, indoor and field tests are also presented in the paper to investigate how real-world propagation affects the capacity and the error performance of MIMO transmission scheme. For the indoor test, radio channel emulators are applied to generate realistic wireless fading channel, while in the field trials, a live TD-LTE experiment cellular network is built, which contains several <b>evolved</b> <b>nodeBs</b> (eNBs) and a precommercial user equipment (UE). It is shown from both simulation and tests results that MIMO deployment gives a substantial performance improvement compared with the third generation wireless networks...|$|R
40|$|We {{investigate}} {{the problem of}} energy-efficient dynamic spectrum access (DSA) in a cognitive Third Generation Partnership Project (3 GPP) long-term evolution (LTE) network based on IEEE 802. 22 architecture. In this architecture, the network resources are allocated to the end-users and the <b>evolved</b> <b>NodeBs</b> (eNBs) by the spectrum manager (SM) using some optimal resource allocation strategy. In particular, we propose to assign the bandwidth and transmission power to the uplink and downlink of LTE system so that the total transmission power is minimized subject to capacity constraints, queue stability constraints, and some integer restrictions on the bandwidth. To find the buffer occupancy in the system, we use modified Shannon expression which depends on signal-to-noise ratio (SNR) and modulation and coding scheme (MCS). Unlike previous works, the proposed resource allocation algorithm is derived based on realistic assumptions, such as discrete spectrum resources, relation between transmission rate, MCS and the channel quality. Performance of the algorithm is evaluated using simulations in OPNET environment. The algorithm shows consistent performance improvement when compared with other relevant resource allocation techniques...|$|R
40|$|Abstract—The Long Term Evolution (LTE) {{standard}} specifies the Discontinuous Reception Mechanism (DRX) {{mechanism for}} saving {{power at the}} User Equipment (UE). Here, a UE switches off its RF circuitry {{when there are no}} packets to be transmitted or received. The existing DRX algorithms use static operational parameters that are determined by the <b>evolved</b> <b>nodeB</b> (eNB) {{at the start of a}} UE’s session. During the switch-off period, packets destined to the UE are buffered in the eNB leading to higher packet latency. This paper presents two adaptive algorithms to dynamically adjust the DRX parameters, in order to reduce both energy consumption and the extra delay incurred. The algorithms use application Quality-of-Service and channel quality information to adjust the DRX parameters. ns 3 -based simulation performance studies show that the algorithms are able to reduce packet delay compared to static DRX by up to 60 %, 60 % and 75 % and reduce energy consumption by up to 75 %, 43 % and 90 % for video streaming, VoIP and bursty data applications respectively. I...|$|R
40|$|Carrier-grade Wireless Local Area Network (WLAN) is {{becoming}} an important complementary system to cellular networks for Mobile Network Operators (MNOs). Network controlled access network selection between cellular and WLAN is an essential functionality to optimize network performance and user experience. Automated configuration and optimisation of the network selection mechanism is of utmost importance in the emerging complex heterogeneous networks. In this article, we present and evaluate a Self-Organizing Network (SON) scheme for optimizing autonomously the access network selection between the Long Term Evolution (LTE) and WLAN systems. The adopted access network selection mechanism uses the standard LTE Received Reference Signal Power (RSRP) measurements available at the User Equipment (UE) {{and a set of}} simple rules based on network-provided RSRP thresholds. The proposed SON mechanism is using the LTE cell load estimated at the <b>evolved</b> <b>NodeB</b> (eNB) to update the RSRP thresholds in order to achieve the best load balancing in the network. Simulation results in a realistic network highlight the benefits of the proposed SON mechanism and possible further improvements...|$|R
5000|$|... 3GPP TS 33.320: Security of Home Node B (HNB) / <b>Home</b> <b>evolved</b> Node B (HeNB) ...|$|R
30|$|Long-term {{evolution}} (LTE) {{refers to}} a new high-performance air interface in the third Generation Partnership Project (3 GPP). 3 GPP LTE is a purely packet-switched radio access telecommunication technology, providing excellent service for 4 G networks at high data rate and low latency. The 3 GPP was launched in December 1998 [1] and boosted to 380 member companies by 2011 [2]. The aim of 3 GPP is {{to meet the needs}} on fast data transport media as well as high voice capacity. The requirements of the next-generation networks targeted by LTE are peak throughput of 100 Mbps or more for downlink and 50 Mbps for uplink, respectively [3]. Besides higher bit rate and lower latency, power saving of user equipment (UE) is another important issue with LTE [4]. The LTE physical layer employs advanced technologies including orthogonal frequency division multiple access (OFDMA) and multiple input multiple output (MIMO) to transmit both data and control data between <b>evolved</b> <b>NodeB</b> (eNodeB) and the UE. OFDMA is employed for downlink, and a special implementation of OFDMA called single-carrier frequency division multiple access (SC-FDMA) is employed for uplink in LTE with the aim of saving power [5, 6].|$|R
40|$|Multimedia and data-based {{services}} {{experienced a}} nonstopping {{growth over the}} last few years. People are continuously on the move using devices to access multimedia contents or other data-based services. Due to this, railway companies are showing a great interest in deploying broadband mobile wireless networks in high-speed-trains with the aim of supporting both passenger services provisioning as well as automatic train control and signaling. Nowadays, the most widely used technology for communications between trains and the railway infrastructure is GSM for Railways (GSM-R); however, it has limited capabilities to support such advanced services. Due to its success in the mass market, Long Term Evolution (LTE) seems to be the best candidate to substitute GSM-R. In this paper, we experimentally characterize the downlink between an LTE <b>Evolved</b> <b>NodeB</b> (eNodeB) and a high-speed train in a commercial high-speed line. We consider two links: the one between the eNodeB and the antennas placed outdoors on the train roof, and the direct link between the eNodeB and a receiver inside the train. Such a characterization consists in assessing the path loss, the Signal to Noise Ratio, the K-Factor, the Power Delay Profile, the delay spread, and the Doppler Power Spectral Density...|$|R
40|$|In this paper, we {{introduce}} {{a novel approach}} for optimal resource allocation from multiple carriers for users with elastic and inelastic traffic in fourth generation long term evolution (4 G-LTE) system. In our model, we use logarithmic and sigmoidal-like utility functions to represent the user applications running on different user equipments (UE) s. We use utility proportional fairness policy, where the fairness among users is in utility percentage of the application running on the mobile station. Our objective is to allocate the resources to the users optimally from multiple carriers. In addition, every user subscribing for the mobile service is guaranteed to have a minimum quality-of-service (QoS) with a priority criterion. Our rate allocation algorithm selects the carrier or multiple carriers that provide the minimum price for the needed resources. We prove that the novel resource allocation optimization problem with joint carrier aggregation is convex and therefore the optimal solution is tractable. We present a distributed algorithm to allocate the resources optimally from multiple <b>evolved</b> <b>NodeBs</b> (eNodeB) s. Finally, we present simulation results {{for the performance of}} our rate allocation algorithm. Comment: Computing, Networking and Communications (ICNC), 2015 International Conference o...|$|R
40|$|In 3 GPP the {{architecture}} of a New Radio Access Network (New RAN) has been defined where the <b>evolved</b> <b>NodeB</b> (eNB) functions can be split between a Distributed Unit (DU) and Central Unit (CU). Furthermore, in the virtual RAN (VRAN) approach, such functions can be virtualized (e. g., in simple terms, deployed in virtual machines). Based on the split type, different performance in terms of capacity and latency are requested to the network (i. e., fronthaul) connecting DU and CU. This study experimentally evaluates, in the 5 G segment of the Advanced Research on NetwOrking (ARNO) testbed (ARNO- 5 G), the fronthaul latency requirements specified by Standard Developing Organizations (SDO) (3 GPP in this specific case). Moreover it evaluates how much virtualization impacts the fronthaul latency budget for the the Option 7 - 1 functional split. The obtained results show that, in the considered Option 7 - 1 functional split, the fronthaul latency requirements are about 250 us but they depend on the radio channel bandwidth {{and the number of}} the connected UEs. Finally virtualization further decreases the latency budget. Comment: publication rights achieved typos fixe...|$|R
40|$|This paper {{presents}} a novel calibration method that equalizes the impulse responses {{of all the}} Radio Frequency (RF) modules of an antenna array system operating in Long-Term Evolution (LTE) <b>evolved</b> <b>NodeB</b> (eNB). The proposed technique utilizes the Zadoff-Chu (Z-C) sequence of the Primary Synchronization Signal (PSS) and Sounding Reference Signal (SRS) that are available in every LTE data frame for downlink and uplink, respectively, for estimating and compensating {{the differences in the}} impulse responses among the RF modules. The proposed calibration method is suitable for wide bandwidth signal environments of LTE because it equalizes the impulse response of each RF module, which is ultimately equivalent to compensate the phase and amplitude differences among RF modules for the entire frequency band. In addition, the proposed method is applicable while the target eNB is transmitting or receiving a data stream. From various experimental tests obtained from a test-bed implemented with 2 RF modules, it has been verified that the proposed method provides a reliable calibration for Release 10 Time Division Duplex (TDD) LTE signals. Phase errors after the calibration in our test-bed {{have been found to be}} about 2. 418 ° and 2. 983 ° for downlink and uplink, respectively...|$|R
40|$|We {{propose a}} dynamic {{resource}} allocation algorithm for device-to-device (D 2 D) communication underlying a Long Term Evolution Advanced (LTE-A) network with reinforcement learning (RL) applied for unlicensed channel allocation. In a considered system, the inband and outband resources are assigned by the LTE <b>evolved</b> <b>NodeB</b> (eNB) to different device pairs to maximize the network utility subject to the target signal-to-interference-and-noise ratio (SINR) constraints. Because {{of the absence of}} an established control link between the unlicensed and cellular radio interfaces, the eNB cannot acquire any information about the quality and availability of unlicensed channels. As a result, a considered problem becomes a stochastic optimization problem that can be dealt with by deploying a learning theory (to estimate the random unlicensed channel environment). Consequently, we formulate the outband D 2 D access as a dynamic single-player game in which the player (eNB) estimates its possible strategy and expected utility for all of its actions based only on its own local observations using a joint utility and strategy estimation based reinforcement learning (JUSTE-RL) with regret algorithm. A proposed approach for resource allocation demonstrates near-optimal performance after a small number of RL iterations and surpasses the other comparable methods in terms of energy efficiency and throughput maximization...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe increasingly {{important role of}} Long Term Evolution (LTE) has increased security concerns among the service provider and end users and made security of the network even more indispensable. In this thesis, the LTE specifications are examined, and several security vulnerabilities of LTE mechanisms, in particular those that exist within the Layer 2 protocol of the LTE network, are identified. Among these mechanisms, the power control mechanism for LTE is further explored. The unprotected power control signal together with the Cell Radio Network Temporary Identifier (CRNTI) can be exploited to trick the victim User Equipment (UE) to transmit {{at a much higher}} than required power, which introduces significant inter-cell interference to adjacent base stations, <b>evolved</b> <b>NodeB</b> (eNodeB). The ways that an attacker can maliciously manipulate the control field of the power control mechanism are demonstrated. The effectiveness of such attack is evaluated with respect to the victim UEs and the adjacent eNodeBs. The impacts include reduction of battery lifespan of victim UE to 33 % of the original battery lifetime and reduction in reverse channel signal-to-interference ratio (SIR) of adjacent eNodeB by 3. 4 dB causing a decrease in throughput of 37 %. Defence Science & Technologies Agenc...|$|R
50|$|As {{many new}} styles of <b>homes</b> <b>evolved,</b> Ferger Place {{remained}} a getaway from the changing society and stayed true to its classic, post-Victorian style. Houses included porches, open rooms, high ceilings, and multiple windows.|$|R
30|$|Device-to-device (D 2 D) communication-enabled {{cellular}} networks allow cellular {{devices to}} directly {{communicate with each}} other without any <b>evolved</b> <b>NodeB</b> (eNB). D 2 D communication aims to improve the spectral efficiency and increases the overall system capacity. For future mobile networks, intelligent radio resource allocation and power control schemes are required to accommodate the increasing number of cellular devices and their growing demand of data traffic. In this paper, a combined resource allocation and power control scheme for D 2 D communication is proposed. In the proposed scheme, D 2 D communication reuses the uplink (UL) resources of conventional cellular user equipments (CUEs); therefore, we have adopted single-carrier frequency division multiple access (SC-FDMA) as UL transmission scheme. The proposed scheme uses fractional frequency reuse (FFR)-based architecture to efficiently allocate the resources and mitigate the interference between CUEs and D 2 D user equipments (DUEs). In order to guarantee the user fairness, the proposed scheme uses the well-known proportional fair (PF) scheduling algorithm for resource allocation. We have also proposed an intelligent power control scheme which provides equal opportunity to both CUEs and DUEs to achieve a certain minimum signal-to-interference and noise ratio (SINR) value. The performance evaluation results show that the proposed scheme significantly improves the overall cell capacity and achieves low peak-to-average power ratio (PAPR).|$|R
40|$|In this paper, we {{introduce}} {{an approach}} for application-aware resource block scheduling of elastic and inelastic adaptive real-time traffic in fourth generation Long Term Evolution (LTE) systems. The users {{are assigned to}} resource blocks. A transmission may use multiple resource blocks scheduled over frequency and time. In our model, we use logarithmic and sigmoidal-like utility functions to represent the users applications running on different user equipments (UE) s. We present an optimal problem with utility proportional fairness policy, where the fairness among users is in utility percentage (i. e user satisfaction with the service) of the corresponding applications. Our objective is to allocate the resources to the users with priority given to the adaptive real-time application users. In addition, a minimum resource allocation for users with elastic and inelastic traffic should be guaranteed. Every user subscribing for the mobile service should have a minimum quality-of-service (QoS) with a priority criterion. We prove that our scheduling policy exists and achieves the maximum. Therefore the optimal solution is tractable. We present a centralized scheduling algorithm to allocate <b>evolved</b> <b>NodeB</b> (eNodeB) resources optimally with a priority criterion. Finally, we present simulation results {{for the performance of}} our scheduling algorithm and compare our results with conventional proportional fairness approaches. The results show that the user satisfaction is higher with our proposed method. Comment: 5 page...|$|R
40|$|This paper {{investigates the}} problem of {{resource}} allocation for device-to-device (D 2 D) communication in a ThirdGeneration Partnership Project (3 GPP) Long-Term Evolution Advanced (LTE-A) network. The users in the network can operate either in a traditional cellular mode, communicating with each other via the <b>evolved</b> <b>NodeB</b> (eNB), or in a D 2 D mode, communicating with each other without traversing the eNB. In the considered model, the D 2 D users and cellular users share the same radio resources. Particularly, each resource block (RB) within the available bandwidth can be occupied by one cellular and several D 2 D users. Hence, {{the problem of}} interference management is crucial for effective performance of such a network. The twofold aim of the proposed algorithm is to 1) mitigate the interference between cellular and D 2 D users and 2) improve the overall user-perceived quality of service (QoS). To control the interference, for each user, we define a certain target interference level and constrain the interference from the other users to stay below this level. The corresponding optimization problem maximizes the QoS of the users by minimizing {{the size of the}} buffers of user equipments (UEs). The performance of the algorithm has been evaluated by using the OPNET-based simulations. The algorithm shows improved performance in terms of mean packet end-to-end delay and loss for UEs when compared to other relevant schemes...|$|R
