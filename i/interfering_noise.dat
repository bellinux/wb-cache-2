122|169|Public
2500|$|In 1945, {{as the war}} {{was coming}} to an end, the NDRC was issuing a summary of {{technical}} reports as a last step prior to its eventual closing down. Inside the volume on fire control, a special essay titled Data Smoothing and Prediction in Fire-Control Systems, coauthored by Shannon, Ralph Beebe Blackman, and Hendrik Wade Bode, formally treated the problem of smoothing the data in fire-control by analogy with [...] "the problem of separating a signal from <b>interfering</b> <b>noise</b> in communications systems." [...] In other words, it modeled the problem in terms of data and signal processing and thus heralded the coming of the Information Age.|$|E
5000|$|The {{cocktail}} party effect works best as a [...] effect, which requires hearing with both ears. People {{with only one}} functioning ear seem much more distracted by <b>interfering</b> <b>noise</b> than people with two typical ears.|$|E
5000|$|... where [...] is the space-time {{snapshot}} statistic for the [...] range cell {{under the}} interference only hypothesis, [...] For SMI, the interference covariance matrix for the [...] range cell {{consisting of the}} statistics from <b>interfering</b> <b>noise,</b> clutter, and jammers is estimated as follows: ...|$|E
50|$|Using array signal processing, the {{temporal}} and spatial properties (or parameters) of the impinging signals <b>interfered</b> by <b>noise</b> and hidden in the data collected by the sensor array can be estimated and revealed. This is known as parameter estimation.|$|R
50|$|Absolute and {{difference}} thresholds are sometimes considered similar in principle {{because there is}} always background <b>noise</b> <b>interfering</b> with our ability to detect stimuli.|$|R
5000|$|In Macs without dual {{beamforming}} microphones (pre-2012), background <b>noise</b> <b>interferes</b> with recognition, {{and limits}} {{the usefulness of}} the [...] "listening continuously" [...] option.|$|R
5000|$|Some of the {{challenges}} that Weinberg faced with Haile’s programming involved being able to distinguish between different, simultaneous sounds. Initially, analysis algorithms were unable to pick out softer and more subtle notes amidst louder sounds. Also, the inability to filter out ambient noise prevented Haile from working properly. After {{a considerable amount of}} adjusting, the filters and input hardware were tuned to differentiate between various volumes of music while ignoring <b>interfering</b> <b>noise.</b>|$|E
5000|$|The {{auditory}} {{system can}} extract {{the sound of}} a desired sound source out of <b>interfering</b> <b>noise.</b> So the auditory system can concentrate on only one speaker if other speakers are also talking (the cocktail party effect). With the help of the cocktail party effect sound from interfering directions is perceived attenuated compared to the sound from the desired direction. The auditory system can increase the signal-to-noise ratio by up to 15 dB, which means that interfering sound is perceived to be attenuated to half (or less) of its actual loudness.|$|E
5000|$|In 1945, {{as the war}} {{was coming}} to an end, the NDRC was issuing a summary of {{technical}} reports as a last step prior to its eventual closing down. Inside the volume on fire control, a special essay titled Data Smoothing and Prediction in Fire-Control Systems, coauthored by Shannon, Ralph Beebe Blackman, and Hendrik Wade Bode, formally treated the problem of smoothing the data in fire-control by analogy with [...] "the problem of separating a signal from <b>interfering</b> <b>noise</b> in communications systems." [...] In other words, it modeled the problem in terms of data and signal processing and thus heralded the coming of the Information Age.|$|E
40|$|In this paper, a multi-stream {{paradigm}} is {{proposed to improve}} the performance of automatic speech recognition (ASR) systems {{in the presence of}} highly <b>interfering</b> car <b>noise.</b> It was found that combining the classical MFCCs with some auditory-based acoustic distinctive cues and the main formant frequencies of a speech signal using a multi-stream paradigm leads to an improvement in the recognition performance in noisy car environments...|$|R
40|$|Cochlear implant {{users have}} limited ability to {{understand}} speech in noisy conditions. Signal processing methods {{to address this issue}} that use multiple microphones typically use beamforming to perform noise reduction. However, the effectiveness of the beamformer is diminished as the number of <b>interfering</b> <b>noises</b> increases and the acoustic environment becomes more diffuse. A multi-microphone noise reduction algorithm that aims to address this issue is presented in this study. The algorithm uses spatial filtering to estimate the signal-to-noise ratio (SNR) and attenuates time-frequency elements that have poor SNR. The algorithm was evaluated by measuring intelligibility of speech embedded in 4 -talker babble where the interfering talkers were spatially separated and changed location during the test. Twelve cochlear implant users took part in the evaluation, which demonstrated a significant mean improvement of 4. 6 dB (standard error 0. 4, P < 0. 001) in speech reception threshold compared to an adaptive beamformer. The results suggest that a substantial improvement in performance can be gained for cochlear implant users in noisy environments where the noise is spatially separated from the target speech. Restricted Access: Metadata Onl...|$|R
40|$|Speech de-noising {{algorithms}} often {{suffer from}} introduction of artifacts, either by removal {{of parts of}} the speech signal, or imperfect noise reduction causing the remaining noise to sound unnatural and disturbing. This contribution proposes to spatially distribute monaural noisy speech signals based on single-channel source separation, {{in order to improve}} the perceived speech quality. Stereo up-mixing is utilized on the estimated speech and noise sources instead of simply suppressing the noise. This paper investigates the case of non-negative matrix factorization (NMF) speech enhancement applied to high levels of non-stationary noise. NMF-based and spectral subtraction speech enhancement algorithms are evaluated in a listening test in terms of speech intelligibility, presence of <b>interfering</b> <b>noises</b> and overall quality with respect to the unprocessed signal. In the result, the listening test provides evidence for superior noise reduction by NMF, yet also a drop in perceived speech quality that is not covered by the employed set of common objective metrics. However, stereo up-mixing of NMF-separated speech and noise delivers high subjective noise reduction while preserving the perceived speech quality. 1...|$|R
50|$|Balanced lines {{work because}} the <b>interfering</b> <b>noise</b> from the {{surrounding}} environment is induced into both wires equally. By measuring {{the difference between the}} two wires at the receiving end, the original signal is recovered while the noise is cancelled. Any inequality in the noise induced in each wire is an imbalance and will result in the noise not being fully cancelled. One requirement for balance is that both wires are an equal distance from the noise source. This is often achieved by placing the wires as close together as possible and twisting them together. Another requirement is that the impedance to ground (or to whichever reference point is being used by the difference detector) is the same for both conductors at all points along the length of the line. If one wire has a higher impedance to ground it will tend to have a higher noise induced, destroying the balance.|$|E
40|$|The robust {{localization}} {{of speech}} sources {{is required for}} a wide range of applications, among them hearing aids and teleconferencing systems. This chapter focuses on binaural approaches to estimate the spatial position of multiple competing speakers in adverse acoustic scenarios by only exploiting the signals reaching both ears. A set of experiments is conducted to systematically evaluate the impact of reverberation and <b>interfering</b> <b>noise</b> on speaker-localization performance. In particular, the spatial distribution of the <b>interfering</b> <b>noise</b> has a considerable effect on speaker-localization performance, being most detrimental if the noise field contains strong directional components. In these conditions, <b>interfering</b> <b>noise</b> might be erroneously classified as a speaker position. This observation highlights the necessity to combine the localization stage with a decision about the underlying source type in order to enable a robust localization of speakers in noisy environments...|$|E
3000|$|..., we {{have used}} the {{anechoic}} HRTFs, also from [32]. This corresponds to the early reflections being treated as <b>interfering</b> <b>noise</b> but yields a realistic implementation since the real acoustic path is generally not known.|$|E
30|$|Attack (4) Noising: While {{digital images}} are {{transmitted}} on the Internet, {{they may be}} <b>interfered</b> with Gaussian <b>noise.</b> Here, the additive Gaussian noise with a zero mean value and the variance value 0.01 {{is applied to the}} cover image.|$|R
40|$|International audienceAn {{investigation}} {{was performed to}} develop a real-time automatic health monitoring technique for the identification and prediction of the location and the force magnitude of foreign object impact on composite structures with distributed sensor network. In the smart ensemble impact identification (EII) technique proposed, it consists of four sequential procedures, which are the sensor signal preprocessing (SSP), the forward system modeling (FSM), the inverse model operator (IMO) and the impact positioning. Subsequently, in our experimental cases, we considered the disturbed factor ― random <b>interfering</b> <b>noises,</b> and added the cantilever support condition into our experimental tests of a CFRP plate structure, meanwhile, we also used the small balls with the different materials and masses as the impactors. However under the various impact situations and external noise environment, the predictions for the accuracy of impact forces and locations using the EII technique were validated, and the evaluated errors all fell well within the satisfactory limited range, and also interpreted the EII technique that is competent to reconstruct precisely the input-force signal due to stochastic impact event and estimate the impact location effectively in complex practical environment...|$|R
40|$|Multiple sound signals, such as {{speech and}} <b>interfering</b> <b>noises,</b> can be fairly well separated, localized, and {{interpreted}} by human listeners with normal binaural hearing. The computational model presented here, based on earlier cochlear modeling work, {{is a first}} step at ap-proaching human levels of performance on the localization and separa-tion tasks. This combination of cochlear and binaural models, imple-mented as real-time algorithms, could provide the front end for a robust sound interpretation system such as a speech recognizer. The cochlear model used is basically a bandpass filterbank with frequency channels corresponding to places on the basilar membrane; filter outputs are half-wave rectified and amplitude-compressed, maintaining fine time resolution. In the binaural model, outputs of corresponding frequency channels from the two ears are combined by cross-correlation. Peaks in the short-time cross-correlation functions are then interpreted as direction. With appropriate preprocessing, the correlation peaks in-tegrate cues based on signal phase, envelope modulation, onset time, and loudness. Based on peaks in the correlation functions, sources can be recognized, localized, and tracked. Through quickly varying gains, sound fragments are separated into streams representing different sources. Preliminary tests of the algorithms are very encouraging. 1...|$|R
40|$|The {{aim of the}} {{experiments}} described within this thesis was to measure binaural temporal and spectral resolution. Previous investigations that have studied temporal resolution (e. g. Bernstein et al., 2001) assumed that <b>interfering</b> <b>noise</b> dilutes delayed noise within the temporal window. The first two experiments described in this thesis have validated the dilution concept for correlated <b>interfering</b> <b>noise,</b> but not for uncorrelated <b>interfering</b> <b>noise,</b> the presence of which has a more detrimental effect than interfering correlated noise. The study by Bernstein et al. (2001) suggested that the equivalent rectangular bandwidth (ERD) of the binaural temporal window is considerably smaller than estimates made in previous studies (e. g. Kollmeier and Gilkey, 1990; Culling and Summerfield, 1998). The results from {{the experiments}} in this thesis disagree with those of Bernstein et al., and suggest that several factors led to their findings, including lack {{of control over the}} coherence of the stimulus due to the use of a detection task, the short duration of their stimuli, and the use of diotic <b>interfering</b> <b>noise.</b> The ERD of the binaural temporal window was found to range from 110 - 349 ms across listeners, a finding consistent with binaural sluggishness. In the frequency domain, a study by Sondhi and Guttman (1966) that investigated the frequency selectivity of the binaural system found evidence suggesting that binaural auditory filters are substantially wider than monaural auditory filters. Conversely, Kohlrausch (1988) measured auditory filters that were comparable to monaural filters. The results from the experiment conducted in this thesis found that binaural auditory filters are substantially wider than monaural auditory filters. Best fits were found to be 2 -parameter asymmetric Gaussian filters with an ERB that ranged from 99 - 198 Hz at a centre frequency (CF) of 250 Hz, 138 - 215 Hz at a CF of 500 Hz, and 229 - 285 Hz at a CF of 750 Hz...|$|E
40|$|We {{present a}} {{technique}} for denoising speech using nonnegative matrix factorization (NMF) {{in combination with}} statistical speech and noise models. We compare our new technique to standard NMF and to a state-of-the-art Wiener filter implementation and show improvements in speech quality {{across a range of}} <b>interfering</b> <b>noise</b> types...|$|E
40|$|Speech {{reception}} is poor for {{cochlear implant}} recipients in listen-ing environments with <b>interfering</b> <b>noise.</b> This study investigates the speech understanding provided in <b>interfering</b> <b>noise</b> by a cod-ing strategy {{based on the}} sparse approximation algorithm match-ing pursuit (MP) and additionally proposes two modifications to the strategy. The levels of spectral {{information provided by the}} MP strategy and the modified MP strategy are compared to that of continuous interleaved sampling (CIS) and a strategy based on the ideal binary mask (IBM) using vocoded speech and the normalized covariance metric (NCM). We demonstrate objective intelligibility improvements in quiet, and total and partial objective intelligibility restoration in steady-state and fluctuating noise, respectively. Index Terms — Cochlear implant, speech coding, sparse cod-ing, matching pursuit (MP), continuous interleaved sampling (CIS), normalized covariance metric (NCM) 1...|$|E
40|$|Small {{vocabulary}} isolated word {{speech recognition}} {{can be implemented}} on relative small hardware. Although the recognition problem {{is more or less}} solved in noise-free situations, the general application is hindered because of the dramatic decrease of performance in noisy environments, especially for hands-free applications. In this paper a binaural front-end for speech recognition is presented. This binaural model, whichwas originally developed at Ruhr-Universityof Bochum in Germany, allows for an effective reduction of <b>interfering</b> <b>noises</b> of any kind. Besides stationary noises also concurrent speech signals can be suppressed. The original model was designed as a precise computer model of the human binaural auditory system and can explain a varietyof psycho-acoustical phenomenon. Besides those abilities the model offers sharp directional selectivity which is superior to those obtained with directional microphones. We simplified this sophisticated model by adapting it to the specific task and use the peak position and the peak level of the binaural activity pattern for each frequency band as a parameter for pattern matching. The performance was evaluated in the form of recognition rates for a variety of difference noisy environments. The results show that the binaural front-end leads to a significant improvement in recognition rates corresponding to an enhancement of over 20 dB in SNR in most cases...|$|R
30|$|We {{implement}} a human-robot ensemble system as {{an application of}} our beat-tracking method. The robot plays its instrument according to the guitar beat and tempo. The task is challenging because the robot fan and motor <b>noise</b> <b>interfere</b> with the guitar's sound. All of our experiments are conducted in the situation with the robot.|$|R
40|$|Noise {{reduction}} algorithms {{have been}} proposed which imitate aspects of the binaural processing in the hearing system. Based on a two-channel input, it is theoretically possible to cancel one <b>interfering</b> directional <b>noise</b> source {{at a time and}} to cancel reverberation based on coherence measures. In practice, however, no significant increase in speech intelligibility was found in complex environments (diffuse noise, reverberation). Therefore, a localization algorithm is introduced, which uses a statistical description of the binaural signal differences in order to increase the robustness of sound localization in noisy environments. Possible noise reduction schemes based on this localization algorithm are discussed...|$|R
40|$|This paper {{describes}} an improved complementary beamforming microphone array {{based on the}} new noise adaptation algorithm. Complementary beamforming is based on two types of beamformers designed to obtain complementary directivity patterns with respect to each other. In this system, during a pause in the target speech, two directivity patterns of the beamformers are adapted to the noise directions of arrival so that the expectation values of each noise power spectrum are minimized in the array output. Using this technique, we can realize the directional nulls for each noise even {{when the number of}} sound sources exceeds that of microphones. To evaluate the effectiveness, speech enhancement experiments and speech recognition experiments are performed based on computer simulations with a two-element array and three sound sources under various noise conditions. In comparison with the conventional adaptive beamformer and the conventional spectral subtraction method cascaded with the adaptive beamformer, it is shown that(1) the proposed array improves the signal-to-noise ratio(SNR) of degraded speech by more than 6 dB when the <b>interfering</b> <b>noise</b> is two speakers with the input SNR of below 0 dB, (2) the proposed array improves the SNR by about 2 dB when the <b>interfering</b> <b>noise</b> is bubble noise, and(3) an improvement in the recognition rate of more than 18 % is obtained when the <b>interfering</b> <b>noise</b> is two speakers or two overlapped signals of some speakers under the condition that the input SNR is 10 dB...|$|E
40|$|Differences in arrival {{times of}} {{acoustic}} waves at multiple sensors permit the computation of source location. The computation depends upon delay estimation between sensor pairs. In severe acoustic environments, the estimates are degraded by reverberation and <b>interfering</b> <b>noise,</b> and some estimates are poor, constituting outlier. This report describes a computational method for outlier elimination {{to improve the}} accuracy of source location...|$|E
40|$|While speaker {{identification}} {{performance has}} improved {{dramatically over the}} past years, the presence of <b>interfering</b> <b>noise</b> and the variety of channel conditions pose a major obstacle. Particularly the mismatch between training and test condition leads to severe performance degradations. In this paper we explored several approaches to compensation {{for the effects of}} reverberation including compensation using linear post-filtering and frame-base score competition. 1...|$|E
40|$|Visual evoked {{potentials}} (VEPs) {{were recorded}} in 12 adult participants {{as a function of}} the temporal frequency of a phase-reversed checkerboard, with or without a simultaneously presented white noise. During the VEP recordings also the pulse rate was measured. VEP amplitude changed as function of temporal frequency, but it was not affected by noise. Pulse rate was stable during the session without noise, but it increased during the white noise stimulation at high temporal frequencies. Heart acceleration might be associated to conditions when processing at low levels of visual sensitivity (high temporal frequencies) is furthermore disturbed by <b>interfering</b> stimulation (<b>noise)</b> ...|$|R
40|$|International audienceWhen {{listening}} to speech in everyday-life situations, our cognitive system must often cope with signal instabilities such as sudden breaks, mispronunciations, <b>interfering</b> <b>noises</b> or reverberations potentially causing disruptions at the acoustic/phonetic interface and preventing efficient lexical access and semantic integration. The physiological mechanisms allowing listeners to react instantaneously to such fast and unexpected perturbations {{in order to}} maintain intelligibility of the delivered message are still partly unknown. The present electroencephalography (EEG) study aimed at investigating the cortical responses to real-time detection of a sudden acoustic/phonetic change occurring in connected speech and how these mechanisms interfere with semantic integration. Participants listened to sentences in which final words could contain signal reversals along the temporal dimension (time-reversed speech) of varying durations and could have either a low- or high-cloze probability within sentence context. Results revealed that early detection of the acoustic/phonetic change elicited a fronto-central negativity shortly after the onset of the manipulation that matched the spatio-temporal features of the Mismatch Negativity (MMN) recorded in the same participants during an oddball paradigm. Time reversal also affected late event-related potentials (ERPs) reflecting semantic expectancies (N 400) differently when words were predictable or not from the sentence context. These findings are discussed in the context of brain signatures to transient acoustic/phonetic variations in speech. They contribute {{to a better understanding of}} natural speech comprehension as they show that acoustic/phonetic information and semantic knowledge strongly interact under adverse conditions...|$|R
40|$|Electromagnetic {{information}} leakage {{from computer}} displays was first demonstrated {{to the general}} public by van Eck in 1985. Nearby eavesdroppers can pick up compromising emanations from computer hardware with directional antennas and wideband receivers. The basic phenomenon is easily demonstrated with modified TV sets. However, to separate practically readable text shown on modern high-resolution displays from <b>interfering</b> background <b>noise,</b> special digital wideband signal-processing systems are needed. Thanks to Moore’s law, access to such hardware is no longer restricted to well-funded spies, but has come within the reach of amateurs. The problem is not restricted to cathode-ray tubes; some contemporary flat-panel systems are at least as vulnerable...|$|R
40|$|The {{applications}} of emotion recognition in consumer electronics are increasing day by day. However the accuracy {{and stability of}} the decisions made by appliances largely depends on the efficient recognition of these emotions. The performance may degrade drastically due to <b>interfering</b> <b>noise.</b> This paper proposes a method which may improve the accuracy significantly. Results have confirmed that this system may help to improve the recognition results...|$|E
40|$|Cross-spectrum {{analysis}} is a commonly-used technique {{for the detection}} of phase and amplitude noise of a signal in the presence of <b>interfering</b> <b>noise.</b> It extracts the desired correlated noise from two time series in the presence of uncorrelated <b>interfering</b> <b>noise.</b> Recently, we demonstrated that the phase-inversion (anti-correlation) effect due to AM noise leakage can cause complete or partial collapse of the cross-spectral function. In this paper, we discuss the newly discovered effect of anti-correlated thermal noise that originates from the common-mode power divider (splitter), an essential component in a cross-spectrum noise measurement system. We studied this effect for different power splitters and discuss its influence on the measurement of thermal-noise limited oscillators. An oscillator whose thermal noise is primarily set by the 50 ohm source resistance is referred to as a thermally-limited oscillator. We provide theory, simulation and experimental results. In addition, we expand this study to reveal how the presence of ferrite-isolators and amplifiers at the output ports of the power splitters can affect the oscillator noise measurements. Finally, we discuss a possible solution to overcome this problem...|$|E
40|$|A spoken {{dialogue}} {{system is}} demanded as a user-friendly human-machine interface {{that does not}} require any special skills in its manipulation. Speech has advantageous features: they are hands-free and eyes-free, i. e., one can use speech while doing other tasks. For effective utilization of the features, it is desirable that the system can be used even when the user stands away from the microphone or the user’s speech is uttered interrupting the output sound of the system (response sound). The problem in satisfying such demands is the degradation of automatic speech recognition (ASR) because of feedback of response sound and observation of <b>interfering</b> <b>noise</b> due to other sound than the user’s speech. Since current ASR systems are sensitive to noise, a noise reduction method is indispensable. In elimination of the response sound and the <b>interfering</b> <b>noise,</b> an acoustic echo canceller (AEC) and an adaptive beamformer (ABF) are generally used, respectively. In each of the methods, a filter is adapted to eliminate its target noise based on the minimum-mean-squared-error criterion. Thus, when thei...|$|E
6000|$|For the rest, this of {{suspending}} our Mayor {{does seem}} a mistimed measure. By ill chance, {{it came out}} precisely {{on the day of}} that famous Baiser de l'amourette, or miraculous reconciliatory Delilah-Kiss, which we spoke of long ago. Which Delilah-Kiss was thereby quite hindered of effect. For now his Majesty has to write, almost that same night, asking a reconciled Assembly for advice! The reconciled Assembly will not advise; will not interfere. The King confirms the suspension; then perhaps, but not till then will the Assembly <b>interfere,</b> the <b>noise</b> of Patriot Paris getting loud. Whereby your Delilah-Kiss, such was the destiny of Parliament First, becomes a Philistine Battle! ...|$|R
40|$|The {{design of}} a digital {{decimation}} and channel selection filter is presented. The filter was designed to process the output from a modulator clocked at 64 MHz suppress-ing the out of band quantization <b>noise,</b> <b>interfering</b> channels and operating as a matched filter. Polyphase half-band struc-tures with canonic signed-digit representation and carry-save adders were used to minimize the power consumption. 1...|$|R
3000|$|... {{includes}} the spreading gain if SINR is measured after despreading of the signal. We {{also note that}} in HSDPA downlink transmission is carried out over the whole bandwidth and users are separated in each cell by spreading codes. The wideband interference from adjacent cells is white noise-like and by applying wideband transmit beamforming weights selected by an <b>interfered</b> user the <b>noise</b> level can be decreased.|$|R
