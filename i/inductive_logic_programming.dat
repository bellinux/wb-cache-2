1187|10000|Public
25|$|<b>Inductive</b> <b>logic</b> <b>programming</b> is {{concerned}} with generalizing positive and negative examples {{in the context of}} background knowledge: machine learning of logic programs. Recent work in this area, combining logic programming, learning and probability, has given rise to the new field of statistical relational learning and probabilistic <b>inductive</b> <b>logic</b> <b>programming.</b>|$|E
25|$|Atramentov, A., Leiva, H., and Honavar, V. (2003). A Multi-Relational Decision Tree Learning Algorithm– Implementation and Experiments.. In: Proceedings of the Thirteenth International Conference on <b>Inductive</b> <b>Logic</b> <b>Programming.</b> Berlin: Springer-Verlag.|$|E
25|$|Logic is {{used for}} {{knowledge}} representation and problem solving, {{but it can be}} applied to other problems as well. For example, the satplan algorithm uses logic for planning and <b>inductive</b> <b>logic</b> <b>programming</b> is a method for learning.|$|E
40|$|Abstract: The limit {{behaviors}} of an <b>inductive</b> <b>logic</b> <b>program</b> {{should be an}} important research topic {{which has not been}} explored. An <b>inductive</b> <b>logic</b> <b>program</b> is convergent if given an increasing sequence of example sets, the <b>inductive</b> <b>logic</b> <b>program</b> should produce a corresponding sequence of the Horn <b>logic</b> <b>programs</b> which has the settheoretic limit; limit-correct if the limit of the produced sequence of the Horn <b>logic</b> <b>programs</b> is correct with respect to the limit of the sequence of the example sets. We will show by examples that there exist incremental learning algorithms which are not limit-correct in some cases. A priority order is defined on the literals, and the prioritized version of the learning algorithm is proposed such that the prioritized version is limit-correct with respect to any increasing infinite sequence {Ek} of the positive literal sets...|$|R
40|$|The limit {{behavior}} of <b>inductive</b> <b>logic</b> <b>programs</b> {{has not been}} explored, but when considering incremental or online inductive learning algorithms which usually run ongoingly, such {{behavior of}} the programs {{should be taken into}} account. An example is given to show that some inductive learning algorithm may not be correct in the long run if the limit behavior is not considered. An <b>inductive</b> <b>logic</b> <b>program</b> is convergent if given an increasing sequence of example sets, the program produces a corresponding sequence of the Horn <b>logic</b> <b>programs</b> which has the set-theoretic limit, and is limit-correct if the limit of the produced sequence of the Horn <b>logic</b> <b>programs</b> is correct with respect to the limit of the sequence of the example sets. It is shown that the GOLEM system is not limit-correct. Finally, a limit-correct <b>inductive</b> <b>logic</b> system, called the prioritized GOLEM system, is proposed as a solution. Comment: 9 pages. Welcome any comments to kexu@nlsde. buaa. edu. c...|$|R
40|$|Abstract: The limit {{behavior}} of <b>inductive</b> <b>logic</b> <b>programs</b> {{has not been}} explored, but when considering incremental or online inductive learning algorithms which usually run ongoingly, such {{behavior of}} the programs {{should be taken into}} account. An example is given to show that some inductive learning algorithm may not be correc...|$|R
50|$|<b>Inductive</b> <b>logic</b> <b>programming</b> is {{concerned}} with generalizing positive and negative examples {{in the context of}} background knowledge: machine learning of logic programs. Recent work in this area, combining logic programming, learning and probability, has given rise to the new field of statistical relational learning and probabilistic <b>inductive</b> <b>logic</b> <b>programming.</b>|$|E
50|$|He {{worked on}} a Robot Scientist {{together}} with Ross D. King {{that is capable of}} combining <b>Inductive</b> <b>Logic</b> <b>Programming</b> with active learning. His present work concentrates on the development of Meta-Interpretive Learning, a new form of <b>Inductive</b> <b>Logic</b> <b>Programming</b> which supports predicate invention and learning of recursive programs.|$|E
5000|$|<b>Inductive</b> <b>logic</b> <b>programming</b> is {{particularly}} useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting. Shapiro built its first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from {{positive and negative}} examples. The term <b>Inductive</b> <b>Logic</b> <b>Programming</b> was first introduced in a paper by Stephen Muggleton in 1991. Muggleton also founded the annual international conference on <b>Inductive</b> <b>Logic</b> <b>Programming,</b> introduced the theoretical ideas of Predicate Invention, Inverse resolution, and Inverse entailment,. Muggleton implemented Inverse entailment first in the PROGOL system. The term [...] "inductive" [...] here refers to philosophical (i.e. suggesting a theory to explain observed facts) rather than mathematical (i.e. proving a property for all members of a well-ordered set) induction.|$|E
40|$|Traditionally logic was {{considered}} as having two branches: deductive and inductive. However {{the development of}} the subject from Frege (1879) up to about 1970 brought about a divergence between deductive and <b>inductive</b> <b>logic.</b> It is argued in this paper that developments in artificial intelligence in the last twenty or so years (particularly <b>logic</b> <b>programming</b> and machine learning) have created a new framework for logic in which deductive and <b>inductive</b> <b>logic</b> can, once again, be treated as similar branches of the same discipline. Keywords: deductive <b>logic,</b> <b>inductive</b> <b>logic,</b> <b>logic</b> <b>programming,</b> machine learning, PROLOG 1 Introduction The aim {{of this paper is to}} explore some consequences for the philosophy of logic and the philosophy of science of advances in artificial intelligence (AI) made in the last twenty or so years. Let me begin by listing some of these advances. I will describe the philosophically relevant aspects of these developments in more detail later. As far as the philosophy o [...] ...|$|R
40|$|Research {{evaluation}} {{should take}} into account the intended scholarly and non-scholarly audiences of the research output. This holds too for research infrastructures, which often aim at serving a large variety of audiences. With research and research infrastructures moving to the web, new possibilities are emerging for evaluation metrics. This paper proposes a feasible indicator for measuring the scope of audiences who use web-based e-infrastructures, as well as the frequency of use. In order to apply this indicator, a method is needed for classifying visitors to e-infrastructures into relevant user categories. The paper proposes such a method, based on an <b>inductive</b> <b>logic</b> <b>program</b> and a Bayesian classifier. The method is tested, showing that the visitors are efficiently classified with 90 % accuracy into the selected categories. Consequently, the method can be used to evaluate the use of the e-infrastructure within and outside academia. © 2012 Duin et al...|$|R
40|$|This paper {{presents}} {{an approach to}} <b>inductive</b> synthesis of <b>logic</b> <b>programs</b> from examples using problem decomposition and problem reduction principles. This {{is in contrast to}} the prevailing <b>logic</b> <b>program</b> induction paradigm, which relies on generalization of programs from examples. The problem reduction is accomplished as a constrained top-down search process, which eventually is to reach trivial problems...|$|R
5000|$|Brian Milch, and Stuart J. Russell: First-Order Probabilistic Languages: Into the Unknown, <b>Inductive</b> <b>Logic</b> <b>Programming,</b> volume 4455 of Lecture Notes in Computer Science, page 10-24. Springer, 2006 ...|$|E
5000|$|Plotkin's [...] "relative least general {{generalization}} (rlgg)" [...] {{approach to}} <b>inductive</b> <b>logic</b> <b>programming</b> shall {{be used to}} obtain a suggestion about how to formally define the daughter relation [...]|$|E
50|$|Uplift {{modeling}} {{has been}} recently extended and incorporated into diverse machine learning algorithms, like <b>Inductive</b> <b>Logic</b> <b>Programming,</b> Bayesian Network, Statistical relational learning, Support Vector Machines, Survival Analysis and Ensemble learning.|$|E
40|$|Abstract. In {{this paper}} we present {{the theory and}} {{practice}} of co-logic programming (co-LP for brevity), a paradigm that combines both <b>inductive</b> and coinductive <b>logic</b> <b>programming.</b> Co-LP is a natural generalization of <b>logic</b> <b>programming</b> and coinductive <b>logic</b> <b>programming,</b> which in turn generalizes other extensions of <b>logic</b> <b>programming,</b> such as infinite trees, lazy predicates, and concurrent communicating predicates. Co-LP has applications to rational trees, verifying infinitary properties, lazy evaluation, concurrent LP, model checking, bisimilarity proofs, etc. ...|$|R
40|$|This paper {{discusses}} the generalization of definite Horn programs beyond the ordering of logical implication. Since the seminal paper on generalization of clauses based on ` subsumption, {{there are various}} extensions in this area. Especially in <b>inductive</b> <b>logic</b> programming(ILP), people are using various methods that approximate logical implication, such as inverse resolution(IR), relative least general generalization(RLGG), and inverse implication(II), to generalize clauses. However, the logical implication {{is not the most}} desirable form of generalization. A program is more general than another program {{does not necessarily mean that}} the former should logically imply the latter. Instead, a more natural notion of generalization is the set inclusion ordering on the success set of <b>logic</b> <b>programs.</b> We observe that this kind of generalization relation is especially useful for <b>inductive</b> synthesis of <b>logic</b> <b>programs.</b> In this paper, we first define an ordering between <b>logic</b> <b>programs</b> which is strict [...] ...|$|R
40|$|In this work, we {{consider}} {{the extension of the}} <b>Inductive</b> Functional <b>Logic</b> <b>Programming</b> (IFLP) framework in order to learn functions in an incremental way. In general, incremental learning is necessary when the number of examples is in nite, very large or presented one by one. We have implemented this extension in the FLIP system, an implementation of the IFLP framework. Several examples of programs which have been induced indicate that our extension pays o in practice. An experimental study of some parameters which aect this eciency is performed and some applications for programming practice are illustrated, especially small classi cation problems and data-mining of semi-structured data...|$|R
5000|$|<b>Inductive</b> <b>logic</b> <b>programming</b> is a {{means of}} {{constructing}} theory that implies a condition. Plotkin's [...] "relative least general generalization (rlgg)" [...] approach constructs the simplest generalization consistent with the condition.|$|E
50|$|His {{early work}} on {{relational}} learning helped to the lay {{the foundations for}} the field of <b>Inductive</b> <b>Logic</b> <b>Programming</b> (ILP). With Donald Michie, he also did pioneering work in Behavioural Cloning.|$|E
5000|$|Atramentov, A., Leiva, H., and Honavar, V. (2003). A Multi-Relational Decision Tree Learning Algorithm - Implementation and Experiments.. In: Proceedings of the Thirteenth International Conference on <b>Inductive</b> <b>Logic</b> <b>Programming.</b> Berlin: Springer-Verlag.|$|E
40|$|Reasoning {{about the}} past is of {{fundamental}} importance in several applications in computer science and artificial intelligence, including reactive systems and planning. In this paper we propose efficient temporal knowledge representation algorithms to reason about and implement past time logical operators in neural-symbolic systems. We do so by extending models of the Connectionist <b>Inductive</b> Learning and <b>Logic</b> <b>Programming</b> System with past operators. This contributes towards integrated learning and reasoning systems considering temporal aspects. We validate the effectiveness of our approach by means of case studies. ...|$|R
40|$|Abstract. We are {{interested}} in inducing equational theories from facts. Our current, limited prototype that implements <b>inductive</b> equational <b>logic</b> <b>programming</b> using evolutionary techniques shows good convergence behavior for small problems but relatively poor convergence for larger problems. Therefore we {{are concerned with the}} design of our genetic operators. We chose to study the evolutionary population dynamics of our system through a set of experiments and compare it to the theoretical behavior predicted by Fisher’s Fundamental Theorem of Natural Selection {{in order to determine the}} quality of our genetic operators. The evolutionary population dynamics of our system behaves as predicted by Fisher’s Theorem and therefore we conclude that the design of our genetic operators is appropriate and that the poor convergence behavior in larger problems is due to limitations of the prototype. ...|$|R
40|$|We develop two {{applications}} of middle-out reasoning in <b>inductive</b> proofs: <b>Logic</b> <b>program</b> synthesis and {{the selection of}} induction schemes. Middle-out reasoning as part of proof planning was first suggested by Bundy et al [Bundy et al 90 a]. Middle-out reasoning uses variables to represent unknown terms and formulae. Unification instantiates the variables in the subsequent planning, while proof planning provides the necessary search control. Middle-out reasoning is used for synthesis by planning the verification of an unknown <b>logic</b> program: The <b>program</b> body is represented with a meta-variable. The planning results both in an instantiation of the program body and {{a plan for the}} verification of that program. If the plan executes successfully, the synthesized program is partially correct and complete. Middle-out reasoning is also used to select induction schemes. Finding an appropriate induction scheme during synthesis is difficult, because the recursion of the program, which is un [...] ...|$|R
5000|$|Plotkin {{used his}} {{algorithm}} {{to compute the}} [...] "relative least general generalization (rlgg)" [...] of two clause sets in first-order logic, which was {{the basis of the}} Golem approach to <b>inductive</b> <b>logic</b> <b>programming.</b>|$|E
50|$|Logic is {{used for}} {{knowledge}} representation and problem solving, {{but it can be}} applied to other problems as well. For example, the satplan algorithm uses logic for planning and <b>inductive</b> <b>logic</b> <b>programming</b> is a method for learning.|$|E
5000|$|<b>Inductive</b> <b>Logic</b> <b>Programming</b> {{system is}} a program that takes as an input logic {{theories}} [...] and outputs a correct hypothesis [...] wrt theories [...] An algorithm of an ILP system consists of two parts: hypothesis search and hypothesis selection. First a hypothesis is searched with an <b>inductive</b> <b>logic</b> <b>programming</b> procedure, then {{a subset of the}} found hypotheses (in most systems one hypothesis) is chosen by a selection algorithm. A selection algorithm scores each of the found hypotheses and returns the ones with the highest score. An example of score function include minimal compression length where a hypothesis with a lowest Kolmogorov complexity has the highest score and is returned. An ILP system is complete iff for any input logic theories [...] any correct hypothesis [...] wrt to these input theories can be found with its hypothesis search procedure.|$|E
40|$|This paper {{presents}} the Connectionist <b>Inductive</b> Learning and <b>Logic</b> <b>Programming</b> System (C-IL²P). C-IL²P {{is a new}} massively parallel computational model based on a feedforward Artificial Neural Network that integrates inductive learning from examples and background knowledge, with deductive learning from <b>Logic</b> <b>Programming.</b> Starting with the background knowledge represented by a propositional <b>logic</b> <b>program,</b> a translation algorithm is applied generating a neural network that can be trained with examples. The results obtained with this refined network {{can be explained by}} extracting a revised <b>logic</b> <b>program</b> from it. Moreover, the neural network computes the stable model of the <b>logic</b> <b>program</b> inserted in it as background knowledge, or learned with the examples, thus functioning as a parallel system for <b>Logic</b> <b>Programming.</b> We have successfully applied C-IL 2 Ptotwo real-world problems of computational biology, specifically DNA sequence analyses. Comparisons with the results obtained by some of the main neural, symbolic, and hybrid inductive learning systems, using the same domain knowledge, show the effectiveness of C-IL²P...|$|R
40|$|Computational grids {{are some}} of the largest {{computer}} systems in existence today. Unfortunately they are also, in many cases, the least reliable. This research examines the use of redundancy with permutation as a method of improving reliability in computational grid applications. Three primary avenues are explored - development of a new redundancy model, the Replication and Permutation Paradigm (RPP) for computational grids, development of grid simulation software for testing RPP against other redundancy methods and, finally, running a program on a live grid using RPP. An important part of RPP involves distributing data and tasks across the grid in Latin Square fashion. Two theorems and subsequent proofs regarding Latin Squares are developed. The theorems describe the changing position of symbols between the rows of a standard Latin Square. When a symbol is missing because a column is removed the theorems provide a basis for determining the next row and column where the missing symbol can be found. Interesting in their own right, the theorems have implications for redundancy. In terms of the redundancy model, the theorems allow one to state the maximum makespan in the face of missing computational hosts when using Latin Square redundancy. The simulator software was developed and used to compare different data and task distribution schemes on a simulated grid. The software clearly showed the advantage of running RPP, which resulted in faster completion times in the face of computational host failures. The Latin Square method also fails gracefully in that jobs complete with massive node failure while increasing makespan. Finally an <b>Inductive</b> <b>Logic</b> <b>Program</b> (ILP) for pharmacophore search was executed, using a Latin Square redundancy methodology, on a Condor grid in the Dahlem Lab at the University of Louisville Speed School of Engineering. All jobs completed, {{even in the face of}} large numbers of randomly generated computational host failures...|$|R
40|$|Abstract. This {{extended}} abstract discusses various {{approaches to}} the constraining of Partially Observable Markov Decision Processes (POMDPs) using social norms and logical assertions in a dynamic logic framework. Whereas the exploitation of synergies among formal logic {{on the one hand}} and stochastic approaches and machine learning on the other is gaining significantly increasing interest since several years, most of the respective approaches fall into the category of relational learning in the widest sense, including <b>inductive</b> (stochastic) <b>logic</b> <b>programming.</b> In contrast, the use of formal knowledge (including knowledge about social norms) for the provision of hard constraints and prior knowledge for some stochastic learning or modeling task is much less frequently approached. Although we do not propose directly implementable technical solutions, it is hoped that this work is a useful contribution to a discussion about the usefulness and feasibility of approaches from norm research and formal logic in the context of stochastic behavioral models, and vice versa...|$|R
50|$|Golem is an <b>inductive</b> <b>logic</b> <b>programming</b> {{algorithm}} {{developed by}} Stephen Muggleton and Feng. It uses the technique relative least general generalization proposed by Gordon Plotkin. Therefore, only positive examples are {{used and the}} search is bottom-up.Negative examples {{can be used to}} reduce the size of the hypothesis by deleting useless literals from the body clause.|$|E
5000|$|Progol is Stephen Muggleton's {{implementation}} of <b>Inductive</b> <b>Logic</b> <b>Programming</b> used {{in computer science}} that combines [...] "Inverse Entailment" [...] with [...] "general-to-specific search" [...] through a refinement graph. [...] "Inverse Entailment" [...] is used with mode declarations to derive the most-specific clause within the mode language which entails a given example. This clause is used to guide a refinement-graph search.|$|E
5000|$|The {{advent of}} logic {{programming}} {{brought a new}} elan but also a new direction in the early 1980s, especially due to the MIS system of Shapiro eventually spawning the new field of <b>inductive</b> <b>logic</b> <b>programming</b> (ILP). The early works of Plotkin, and his [...] "relative least general generalization (rlgg)", had an enormous impact in <b>inductive</b> <b>logic</b> <b>programming.</b> Most of ILP work addresses a wider class of problems, as the focus is not only on recursive logic programs but on machine learning of symbolic hypotheses from logical representations. However, there were some encouraging results on learning recursive Prolog programs such as quicksort from examples together with suitable background knowledge, for example with GOLEM. But again, after initial success, the community got disappointed by limited progress about the induction of recursive programs with ILP less and less focusing on recursive programs and leaning more and more towards a machine learning setting with applications in relational data mining and knowledge discovery.|$|E
40|$|Abstract. dialogs (Dialogue-based <b>Inductive</b> and Abductive <b>LOGic</b> <b>program</b> Synthesizer) is a schema-guided {{synthesizer}} of recursive logic programs; {{it takes}} the initiative and queries a (possibly computationally naive) specier for evidence in her/his conceptual language. The specier must know the answers to such simple queries, because otherwise s/he wouldn't even feel {{the need for the}} synthesized program. dialogs can be used by any learner (including itself) that detects, or merely conjectures, the necessity of invention of a new predicate. Due to its foundation on a powerful codication of a -theory " (by means of the template and constraints of a divide-and-conquer schema), dialogs needs very little evidence and is very fast. ...|$|R
40|$|Refinement {{operators}} are exploited {{to change in}} an automated way incorrect clauses of a <b>logic</b> <b>program.</b> In this paper, we present four refinement operators for Datalogprogramsand demonstrate {{that all of them}} meet the properties of local finiteness, properness, and completeness (ideality). Such {{operators are}} based on the quasi-ordering induced upon a set of clauses by the generalization model of q-subsumption under object identity. This model of generalization, as well as the four refinement operators have been implemented in a system for theory revision that proved effective in the area of electronic document classification. 1. Introduction In a logic framework for the <b>inductive</b> synthesis of <b>logic</b> <b>programs,</b> a fundamental problem is the definition of locally finite, proper, and complete (ideal) refinement operators. Indeed, when the aim is to develop incrementally a <b>logic</b> <b>program,</b> that should be correct with respect to its intended model {{at the end of the}} development process, it become [...] ...|$|R
40|$|Integrity {{constraints}} {{are useful}} for the specification of deductive databases, {{as well as for}} <b>inductive</b> and abductive <b>logic</b> <b>programs.</b> Verifying integrity constraints upon updates is a major efficiency bottleneck and specialised methods have been developed to speedup this task. They can however still incur a considerable overhead. In this paper we propose a solution to this problem by using partial evaluation to precompile the integrity checking for certain update patterns. The idea being, {{that a lot of the}} integrity checking can already be performed given an update pattern without knowing the actual, concrete update. In order to achieve the pre-compilation, we write the specialised integrity checking as a meta-interpreter in <b>logic</b> <b>programming.</b> This meta-interpreter incorporates the knowledge that the integrity constraints were not violated prior to a given update and uses a technique to lift the ground representation to the non-ground one for resolution. By partially evaluating this me [...] ...|$|R
