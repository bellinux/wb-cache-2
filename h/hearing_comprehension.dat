7|17|Public
50|$|Profound {{unilateral}} {{hearing loss}} or single-sided deafness, SSD, makes <b>hearing</b> <b>comprehension</b> very difficult. With speech and background noise {{presented at the}} same level, persons with unilateral deafness were found to hear only about 30-35% of the conversation. A person with SSD needs to make more effort whencommunicating with others. When a patient can hear from only one ear, and there are limited possibilities {{to compensate for the}} handicap, e.g., changing listening position, group discussions and dynamic listening situations become difficult. Individuals with profound unilateral hearing loss are often perceived as socially awkward due to constant attempts to maximize hearing leading to socially unique body language and mannerisms.|$|E
40|$|This {{postgraduate}} thesis {{deals with}} connections between movement {{and knowledge of}} English language with pupils in the 4 th grade of primary school. In the theoretical part there are described the aims of early learning of a foreign language, definitions of movement and different classifications of movement. The role of movement in child development, the role of moves in the foreign language and their functions are also described. I defined the non-verbal communication and non-verbal means of communication which {{play an important role}} in understanding messages in mother tongue and especially in a foreign language. I also presented the aims of movement in the curriculum for the foreign language. I focused on the influence of performing of words, latest researches and findings. In the empirical part the results of the research on connections between the frequency of movement activities and the knowledge of English language with pupils of the 4 th class of primary school are presented. 239 pupils from Slovenia participated in the research. Pupils solved a specially designed questionnaire and also solved a test about their knowledge of English language: Cambridge English Young Learners Tests - Movers which tested reading and <b>hearing</b> <b>comprehension</b> of English language. I conducted a semi-structured interview with randomly selected pupils. The results show that the majority of pupils is aware of the movements during the classes. There are also statistically relevant differences in knowledge of English language between the pupils who claim they move during English classes and those who do not. The test showed that the level of the measured language competences, especially reading and <b>hearing</b> <b>comprehension,</b> is high. During classes the pupils move fairly regularly but there was no connection between the frequency of the movement and the knowledge of English language. It can be concluded that movement influences the pupil’s knowledge of English but the mere quantity of movement in the classroom does not have such an influence. Movement activities are also one of those activities which are more popular with the pupils, especially songs and games which include movement. It can be concluded that with a foreign language movement essentially influences on retention and better results...|$|E
40|$|Analyze the {{progress}} of hearing and language {{in a group of}} children with cerebral palsy (CP) who have received cochlear implants (CI) and compare their progress in the clinical and functional domains. This is a prospective transdisciplinary study developed within a tertiary referral center, with a group of nine cochlear-implanted children with CP, two- to seven-year-old. The assessments undertaken included audiological, language, and communication assessments complemented by the assessment of functional abilities and the level of independence as evaluated by the Pediatric Evaluation of Disability Inventory (PEDI) and Gross Motor Function Classification System (GMFCS). The outcomes varied, as two children achieved <b>hearing</b> <b>comprehension</b> in open-set evaluations. These children presented the same type of CP, athetosis, but with different functional skills and GMFCS levels. Only one of the subjects had any spoken language at the single-word level. A holistic view of change and development is central to understanding progress made in children with CP who received cochlear implants (CI). The functional evaluation of these children with CP is a useful tool for monitoring their progress and measuring their outcomes with CI...|$|E
50|$|SSD also {{negatively}} affects <b>hearing</b> and <b>comprehension</b> {{by making}} it impossible for the patient to determine the direction, distance and movement of sound sources. In an evaluation using the Speech, Spatial and Qualities of Hearing Scale (SSQ) questionnaire, SSD results in a greater handicap than subjects with a hearing loss in both ears.|$|R
25|$|In {{order to}} {{understand}} linguistic intelligence, {{it is important to}} understand the mechanisms that control speech and language. These mechanisms can be broken down into four major groups: speech generation (talking), speech <b>comprehension</b> (<b>hearing),</b> writing generation (writing), and writing comprehension (reading).|$|R
50|$|Auditory {{phonetics}} is {{a branch}} of phonetics concerned with the <b>hearing,</b> acquisition and <b>comprehension</b> of phonetic sounds of words of a language. As articulatory phonetics explores the methods of sound production, auditory phonetics explores the methods of reception—the ear to the brain, and those processes.|$|R
40|$|The work aims {{to assess}} the {{abilities}} of reading and writing in dyslexic and normal children through the following tests: Sentence Reading Comprehension Test (SRCT), of Sentence <b>Hearing</b> <b>Comprehension</b> Test (SHCT), of Picture-Print Writing Test (PPWT 1. 1 -Writing), of Picture-Print Matching Test (PPMT 1. 1 - Choice) and Word Reading Competence Test (WRCT). 10 dyslexic children and 10 controls composed the sample. Significant differences was founded in performance of dyslexics in TTWT 1. 1 -Writing, TTWT 1. 1 - Choice and WRCT, with inferior performance {{in relation to the}} controls. Pearson's correlations show that children with good performance in WRCT also had good performance in TTWT 1. 1 -Writing. The execution time of SRCT was raised in the group of dyslexics, but the number of rightness if kept in the average of the control group. These results allows {{to assess the}} effectiveness of the methods of evaluation, education and intervention of the pertaining to school tasks in dyslexics, therefore some dyslexics can have equal or superior performance to the one of the reading good children in case that she has the time necessary and enough to carry through its tasks...|$|E
40|$|The {{aim of this}} {{bachelor}} {{thesis is}} to create didactic guidance according {{to the principles of}} Marie Montessori, who would support verbal development at children suffering from dysphasia. Data collected during analysis will be used to support decision which domains the guidance should be focused on. The guidance will be then created so it meets Montessori pedagogy requirements and will be shown to parents afterward. A qualitative survey is selected to achieve the objectives set. Results of practical part consist of multiple tools enhancing evaluation of the object size (big smaller - the smallest, small bigger - the biggest), colours, prepositions (above, bellow, in, besides, in between) and <b>hearing</b> <b>comprehension.</b> It is recommended to work with tools in predefined order and to begin with colours rather than with prepositions. All tools are motive active and built in three versions. Testing subjects worked with tools systematically, could focus on the task and finish the task successfully. Their performance was influenced by repeating activities and tools attractiveness as well as tediousness and surrounding environment. In conclusion, the investigation proved that verbal development at subjects suffering from dysphasia can be enhanced using Montessori tools...|$|E
40|$|Reduced {{hearing acuity}} {{is among the}} most {{prevalent}} of chronic medical conditions among older adults. An experiment is reported in which comprehension of spoken sentences was tested for older adults with good hearing acuity or with a mild-to-moderate hearing loss, and young adults with age-normal <b>hearing.</b> <b>Comprehension</b> was measured by participants’ ability to determine of the agent of an action in sentences that expressed this relation with a syntactically less complex subject-relative construction or a syntactically more complex object-relative construction. Agency determination was further challenged by inserting a prepositional phrase into sentences between the person performing an action and the action being performed. As a control, prepositional phrases of equivalent length were also inserted into sentences in a non-disruptive position. Effects on sentence comprehension of age, hearing acuity, prepositional phrase placement and sound level of stimulus presentations appeared only for comprehension of sentences with the more syntactically complex object-relative structures. Working memory as tested by reading span scores accounted for a significant amount of the variance in comprehension accuracy. Once working memory capacity and hearing acuity were taken into account, chronological age among the older adults contributed no further variance to comprehension accuracy. Results are discussed in terms of the positive and negative effects of sensory-cognitive interactions in comprehension of spoken sentences and lend support to a framework in which domain-general executive resources, notably verbal working memory, play a role in both linguistic and perceptual processing...|$|E
40|$|Handy Stories to Read and Sign takes a bilingual, fun {{approach}} to help beginning readers, deaf and <b>hearing,</b> improve their <b>comprehension</b> of both English and American Sign Language (ASL). Charmingly illustrated, the five stories presented here increase in complexity as the children’s vocabulary and reading skills increase {{during the school}} year. Introductions to each story explain to parents and teachers the elements emphasized, such as providing helpful information on how the formation of certain signs creates ASL rhymes...|$|R
40|$|In this paper, I {{investigate}} clause linkages in the Oceanic language Whitesands (ISO: TNP). Whitesands, {{like its}} sister languages {{of the southern}} Vanuatu sub-group, uses a switch reference system called the Echo Subject (ES) (Lynch 2001 : 177, Crowley 2002 : 201). I present results from a response time-based experiment that targets the comprehension of typical and non-typical forms of the switch reference system. The m- ‘ES’ inflection is typically used when two adjacent predicates have identical reference for the subject. The m- replaces the person agreement and tense operators in the second clause. In (1) the m- indicates co-reference of {{the subject of the}} predicate with the subject of the preceding predicate with no other tense or person operators present. If the subjects are different in each clause, such as (2), full inflection — both person agreement and tense — is required on both predicates (even if there is no overt nominal reference). (1) t-am-ø-uven apaha iVila kani m-ø-uven apaha itehi 3 -PST-SG-go LOC Port. Vila and ES-SG-go LOC saltwater He went to Port Vila and went to the beach. fn 2 _ 29 (2) t-am-ø-ek kapiel apiapwei kani t-us nelma-n 3 -PST-SG-touch stone hot and 3 SG. NPST-bite hand- 3 SG He touched a hot stone and it burnt him (lit. it bit his hand). fn 2 _ 49 However, in the Whitesands corpus it is clear that a simple “antecedent equals subject” rule does not always hold for Echo Subject clauses and that a notion of discourse topic might be a potential antecedent alternative (see Reesink (1983) for a similar claim in non-Austronesian languages). For example, there are topic chains that use the Echo Subject for continual reference whilst skipping immediately adjacent non-topical subjects. Further, there are forms where the Echo Subject prefix combines previously distinct arguments into a single argument slot. The experiment presented here was designed to test <b>hearer</b> <b>comprehension</b> of the Echo Subject system. In particular, it aims to answer two questions. Firstly, what is the relative ordering of canonicity of the different Echo Subject forms? That is, are some antecedent types more or less default OR is there evidence to posit a single syntactic or pragmatic class that is the antecedent for the Echo Subject clauses? It seems there are differences in response times and accuracy within the different conditions suggesting a hierarchy of preferred antecedents for Echo Subject clauses. Secondly, is the Echo Subject system more or less inferential than alternative referential systems? In particular, what is the pragmatic loading compared to when there is fully specified verb agreement. We see that in same subject contexts a fully inflected predicate (which is grammatical) results in longer response times. This suggests that additional pragmatic inference is required for non-Echo Subject clauses in these same subject configurations...|$|R
40|$|The use of sign {{language}} by the deaf, though {{a means of}} providing access to knowledge, offers some specific difficulties on reading/writing due to the impossibility on acquiring the written code of the official spoken language. Taking into account that some oral cues favor textual cohesion, the question this paper is mainly concerned with is whether the use of oral cues in writing favors comprehension as well. The aim {{of this research was}} to offer written texts produced by the deaf to the non deaf to see how the text was understood by these speakers. Some written fragments contained two or more oral cues, some with just one cue or with no cues produced by the deaf and some texts produced by the non deaf were offered to university hearing students who were asked to score the texts by means of levels of comprehension. The results showed that the answers favored the texts produced by the non deaf people followed by those with more than two oral cues produced by the deaf; the texts that offered difficulty for comprehension were those with no oral cues produced by the deaf. This paper suggests that the oral cues bring cohesion to the texts produced by the deaf thus favoring the <b>hearer</b> text <b>comprehension.</b>   Keywords: deafness; oral cues; writing; text cohesion...|$|R
40|$|In {{the recent}} years, foreign {{language}} learning has become a compulsory subject in the first triad of primary school. Lessons are taught {{in accordance with the}} learner's development and interests and their knowledge is assessed in a descriptive manner. A descriptive mark is based on how well a pupil meets knowledge standards in accordance with the English language syllabus. In order to assess pupils successfully, the process of teaching should motivate pupils for learning while the process of assessing should give relevant results of pupils' knowledge. Pupils should be motivated to participate in activities which involve assessment, they should also feel well throughout the process and the teachers should test what they teach. The description of the pupil's achievement and the descriptive mark itself are a complex problem for some of the teachers, especially for those who haven't gone through the process of descriptive assessment yet. The results of an evaluation research are described in the practical part of this master's thesis which was carried out among a group of second graders (28 pupils). On the basis of the theoretical knowledge and practical experience, various methods of assessment were introduced into practice, with the aim to provide a realistic picture of the pupils' knowledge. They were organized and carried out in a student-friendly way while they also followed all the principles of assessment: validity, reliability, objectivity, sensitivity and economy. Possible assessment techniques were described and tested young learners' listening and <b>hearing</b> <b>comprehension</b> and their speaking and communication skills. Furthermore an evaluation of the process and its possible improvements can guide the teachers of English to young pupils to reflect on their practical experience, while different forms of assessment which are shown and tested in this master's thesis may be introduced into their lessons. ...|$|E
40|$|The term Auditory Neuropathy {{was coined}} by Starr et al. in 1996 to label a {{peculiar}} hearing disorder due to poor synchronization of neural {{activity in the}} cochlear nerve. Since selective Inner Hair Cells loss or defects of the synapse between these cells and the cochlear nerve can lead to similar signs and symptoms, the condition is now referred to as Auditory Neuropathy/ Auditory Dys-synchrony. The condition reveals itself {{through a series of}} paradoxical findings distinguishing it from the usual cochlear <b>hearing</b> losses. Speech <b>comprehension</b> scores are typically poorer than those predicted from the audiograms. Auditory Brainstem Responses (including wave I) cannot be obtained to supra-threshold clicks and Outer Hair Cell responses (Cochlear Microphonic potential and/or Oto-Acoustic Emissions) are preserved despite threshold values associated with the abolition of the Oto-Acoustic Emissions in usual cochlear hearing losses. Estimations of prevalence in the population with confirmed Hearing Loss range from 4 to 11 %. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
50|$|Hearing {{aids are}} devices that work {{to improve the}} <b>hearing</b> and speech <b>comprehension</b> of those with hearing loss. It works by {{magnifying}} the sound vibrations in the ear so that one can understand {{what is being said}} around them. The use of this technological device {{may or may not have}} an effect on one's sociability. Some people feel as if they cannot live without one because they say it is the only thing that keeps them engaged with the public. Conversely, there are many people who choose not to wear their hearing aids for a multitude of reasons. The vast majority of these reasons stem from either poor performance of the aid, in which the user notices more amplification of background noises instead of the sounds they intended, or from issues with comfort, care, or maintenance of the device; financial factors have also been reported. A comparatively small fraction of people choose not to wear hearing aids due to aesthetic concerns and/or stigma around wearing the device.|$|R
40|$|The speech {{reception}} threshold (SRT) {{is routinely}} measured in the laboratory to assess speech understanding in noise, but is often reported to be a poor predictor of performance in real world listening situations. The overall goal of this work is to determine whether introducing realistic aspects to speech tests can better capture individual differences and ultimately produce more relevant performance measures. We examined the psychometric effects of (a) transplanting a standard sentence-in-noise test into a simulated reverberant cafeteria environment, and (b) moving from sentence recall to a new ongoing speech comprehension task. Participants included normal hearers and hearing-impaired listeners (who were tested with and without their hearing aids). SRTs in the cafeteria environment were significantly correlated with standard SRTs, but were poorer overall and more sensitive to <b>hearing</b> loss. The <b>comprehension</b> task, despite having very different demands to sentence recall, produced similar SRTs under these conditions. The benefit of hearing aids was weakly correlated across the two listening environments and the two listening tasks. These manipulations promise to be useful {{for the creation of}} realistic laboratory tests that are engaging and challenging, yet controlled enough to be useful for psychophysical experiments. 6 page(s...|$|R
40|$|Children with hearing {{impairment}} (HI) show disorders in syntax and morphology. The {{question is whether}} and how these disorders are connected to problems in the auditory domain. The aim {{of this paper is}} to examine whether moderate to severe hearing loss at a young age affects the ability of German-speaking orally trained children to understand and produce sentences. We focused on sentence structures that are derived by syntactic movement, which have been identified as a sensitive marker for syntactic impairment in other languages and in other populations with syntactic impairment. Therefore, our study tested subject and object relatives, subject and object Wh-questions, passive sentences, and topicalized sentences, as well as sentences with verb movement to second sentential position. We tested 19 HI children aged 9; 5 – 13; 6 and compared their performance with <b>hearing</b> children using <b>comprehension</b> tasks of sentence-picture matching and sentence repetition tasks. For the comprehension tasks, we included HI children who passed an auditory discrimination task; for the sentence repetition tasks, we selected children who passed a screening task of simple sentence repetition without lip-reading; this made sure that they could perceive the words in the tests, so that we could test their grammatical abilities. The results clearly showed that most of the participants with HI had considerable difficulties in the comprehension and repetition of sentences with syntactic movement: they had significant difficulties understanding object relatives, Wh-questions, and topicalized sentences, and in the repetition of object who and which questions and subject relatives, as well as in sentences with verb movement to second sentential position. Repetition of passives was only problematic for some children. Object relatives were still difficult at this age for both HI and hearing children. An additional important outcome of the study is that not all sentence structures are impaired—passive structures were not problematic for most of the HI childre...|$|R
40|$|The aim of {{the present}} thesis was to explore reading {{comprehension}} and narration {{in children and adolescents}} with different degrees of hearing impairment (HI). In Study I, reading comprehension was investigated in 16 children with cochlear implants (CI), aged 7 - 13 years. Over 60 % of the investigated children performed at the level of their <b>hearing</b> peers. Reading <b>comprehension</b> was better than expected taking the participants poor phonological skills into consideration. The association between reading comprehension and working memory capacity was robust. Study II was a methodological study, where narrative writing (picture-elicited) was studied using keystroke-logging, which was found to be a valid method for children with typical language developing and NH of 10 years of age and above. The analyses of narratives from 27 children aged 8 - 12 years, showed several relations between the writing process and the writing product. In Study III, the process and the product in written narration was explored in 18 participants with CI, aged 11 - 19. When comparing their performance to that of participants with NH, the most prominent difference was that the children and adolescents with CI were less linguistically mature. This was illustrated by a much higher proportion of content words (less function words). Regarding older participants, although they wrote as fast, they used significantly more pause time than participants with NH. In study IV, spoken, as well as written narration was investigated in 20 participants with HI and HA, 10 - 18 years old. The main finding was that they were less lexically varied than participants with NH. Narration and reading comprehension are important skills for academic success and social inclusion. This thesis clearly indicates that many individuals with HI who are over the age of 10 years clearly lag behind their age peers in complex language activities...|$|R
40|$|Persons with deafblindness {{experience}} {{difficulties in}} daily life and they experience service to sometimes barrier. The overall aim of this thesis is therefore to discover, evaluate and explain: 1. mechanisms that might have impact on participation restrictions {{for people who have}} visual and hearing impairment i. e. deafblindness and 2. mechanisms that might barrier service to these people. Service is used as an umbrella term for health care, education and certain service for persons with disabilities. Materials from multiple sources have been used: literature (Study I No 96 papers). Interviews (Study I and V) with 32 and 3 adults with deafblindness respectively. Questionnaires (Study II and III) : answered by 33 and 34 adults and youth with deafblindness. Patient records (Study IV and V) : records from 9 and 3 adult females with USH I respectively. Materials mostly retrospectively cover the period from 2005 and about 40 – 50 years. Both quantitative and qualitative methods were used. International Classification of Functioning, Disability and Health (ICF) were consequently used as a framework to describe as well as a tool to analyze mechanisms. Further, the Ecological approach, Disability as a laminated system and Life course approach were used in order to evaluate and explain mechanisms. The conclusions that can be drawn from an ecological, laminated and life course approach are: Participation restrictions for people with deafblindness are far-reaching and are embedded in a complex process of interaction between the person with deafblindness and the environment. Services entail systematical barriers. In order to improve service it is extremely important to understand the role of participation restrictions in deafblindness. Primary activity limitation is to not see and <b>hear</b> enough for <b>comprehension.</b> Hence, not taking part in the visible and audible world is primary participation restriction. Performing activities without basic information includes risk. One important aspect of deafblindness is exposure. Persons with deafblindness require rehabilitation in a life perspective. In order to increase people’s participation and protection requirement of individually adapted support and assistive devices is necessary. ICF and the UN convention support service alterations...|$|R
40|$|AbstractObjectiveMany {{tinnitus}} patients {{complain about}} difficulties regarding speech comprehension. In {{spite of the}} high clinical relevance {{little is known about}} underlying mechanisms and predisposing factors. Here, we performed an exploratory investigation in a large sample of tinnitus patients to (1) estimate the prevalence of speech comprehension difficulties among tinnitus patients, to (2) compare subjective reports of speech comprehension difficulties with objective measurements in a standardized speech comprehension test and to (3) explore underlying mechanisms by analyzing the relationship between speech comprehension difficulties and peripheral hearing function (pure tone audiogram), as well as with co-morbid hyperacusis as a central auditory processing disorder. Subjects and MethodsSpeech comprehension was assessed in 361 tinnitus patients presenting between 07 / 2012 and 08 / 2014 at the Interdisciplinary Tinnitus Clinic at the University of Regensburg. The assessment included standard audiological assessment (pure tone audiometry, tinnitus pitch and loudness matching), the Goettingen sentence test (in quiet) for speech audiometric evaluation, two questions about hyperacusis, and two questions about speech comprehension in quiet and noisy environments (How would you rate your ability to understand speech?; How would you rate your ability to follow a conversation when multiple people are speaking simultaneously?). Results Subjectively reported speech comprehension deficits are frequent among tinnitus patients, especially in noisy environments (cocktail party situation). 74. 2 % of all investigated patients showed disturbed speech comprehension (indicated by values above 21. 5 dB SPL in the Goettingen sentence test). Subjective speech comprehension complaints (both in general and in noisy environment) were correlated with hearing level and with audiologically-assessed speech comprehension ability. In contrast, co-morbid hyperacusis was only correlated with speech comprehension difficulties in noisy environments, but not with speech comprehension difficulties in general. ConclusionSpeech comprehension deficits are frequent among tinnitus patients. Whereas speech comprehension deficits in quiet environments are primarily due to peripheral <b>hearing</b> loss, speech <b>comprehension</b> deficits in noisy environments are related to both peripheral hearing loss and dysfunctional central auditory processing. Disturbed speech comprehension in noisy environments might be modulated by central inhibitory deficit. In addition, attentional and cognitive aspects may play a role...|$|R
40|$|Digital filters {{suitable}} for hearing aid application on low power perspective {{have been developed}} and implemented in FPGA in this dissertation. Hearing aids are primarily meant for improving <b>hearing</b> and speech <b>comprehensions.</b> Digital <b>hearing</b> aids score over their analog counterparts. This happens as digital hearing aids provide flexible gain besides facilitating feedback reduction and noise elimination. Recent advances in DSP and Microelectronics {{have led to the}} development of superior digital hearing aids. Many researchers have investigated several algorithms {{suitable for}} hearing aid application that demands low noise, feedback cancellation, echo cancellation, etc., however the toughest challenge is the implementation. Furthermore, the additional constraints are power and area. The device must consume as minimum power as possible to support extended battery life and should be as small as possible for increased portability. In this thesis we have made an attempt to investigate possible digital filter algorithms those are hardware configurable on low power view point. Suitability of decimation filter for hearing aid application is investigated. In this dissertation decimation filter is implemented using ‘Distributed Arithmetic’ approach. While designing this filter, it is observed that, comb-half band FIR-FIR filter design uses less hardware compared to the comb-FIR-FIR filter design. The power consumption is also less in case of comb-half band FIR-FIR filter design compared to the comb-FIR-FIR filter. This filter is implemented in Virtex-II pro board from Xilinx and the resource estimator from the system generator is used to estimate the resources. However ‘Distributed Arithmetic’ is highly serial in nature and its latency is high; power consumption found is not very low in this type of filter implementation. So we have proceeded for ‘Adaptive Hearing Aid’ using Booth-Wallace tree multiplier. This algorithm is also implemented in FPGA and power calculation of the whole system is done using Xilinx Xpower analyser. It is observed that power consumed by the hearing aid with Booth-Wallace tree multiplier is less than the hearing aid using Booth multiplier (about 25...|$|R
40|$|The {{quality of}} the {{professional}} training of foreign language teachers presupposes high level of their listening competence. However, in non-authentic language environment developing proficiency in listening is recognized as a difficult task. Therefore, Ukrainian methodologists are in search of new ways to improve listening skills of pre-service teachers. The {{purpose of this article}} is to explore recent research into psycho-linguistic issues and analyse the grounds for the development of listening competence by means of fiction audiobooks. This paper therefore deals with the analysis of cognitive processes and psychological mechanisms, listening stages (motivational, analytically-synthetic, executive and controlling). It goes on to focus on artistic perception and its mechanisms and the information processing mechanisms. Since fiction is an art of words, specific features of listening to audiobooks are primarily related to the category of art. It is revealed that at all levels of the structure of an artistic text (genre, plot, structure) there are some authors guidelines which guide, direct attention and activate apperception. The typical benchmarks of audiobooks that help to activate apperception (genre, cover, title, sample, summary, reviews, author / narrator, volume, rating etc.) have been determined. It has been found that listening to an audiobook should result into its "projection" in the recipients mind. The "projection" may be materialized through a secondary text. It is concluded that the mechanisms of listening to fiction audiobooks are: 1) mental processes (perception, thinking, memory, attention); 2) psychological mechanisms (speech <b>hearing,</b> articulation, anticipation, <b>comprehension,</b> working memory); 3) mechanisms of artistic perception (emotions and feelings, imagination, apperception, figurative and associative thinking); 4) information processing mechanisms (mechanism of equivalent replacements, transcoding, compression, expansion, transformation). Thus, the following prerequisites for developing listening competence of future teachers have been singled out: 1) interests of students, motivating factors should be considered; 2) students must be taught to analyze, synthesize and process information while listening 3) psychological mechanisms should be developed; 4) apperception should be activated before listening; 5) students should be able to share their “projection” of the audiobook...|$|R
40|$|Imitation and {{language}} processing are closely connected. According to the Ease of Language Understanding (ELU) model (Ronnberg et al., 2013) pre-existing mental representation of lexical items facilitates language understanding. Thus, imitation of manual gestures {{is likely to}} be enhanced by experience of sign language. We tested this by eliciting imitation of manual gestures from deaf and hard-of-hearing (DHH) signing and hearing non-signing children at a similar level of language and cognitive development. We predicted that the DHH signing children would be better at imitating gestures lexicalized in their own sign language (Swedish Sign Language, SSL) than unfamiliar British Sign Language (BSL) signs, and that both groups would be better at imitating lexical signs (SSL and BSL) than non-signs. We also predicted that the hearing non-signing children would perform worse than DHH signing children with all types of gestures the first time (T 1) we elicited imitation, but that the performance gap between groups would be reduced when imitation was elicited a second time (T 2). Finally, we predicted that imitation performance on both occasions would be associated with linguistic skills, especially in the manual modality. A split-plot repeated measures ANOVA demonstrated that DHH signers imitated manual gestures with greater precision than non-signing children when imitation was elicited the second but not the first time. Manual gestures were easier to imitate for both groups when they were lexicalized than when they were not; but {{there was no difference in}} performance between familiar and unfamiliar gestures. For both groups, language skills at T 1 predicted imitation at T 2. Specifically, for DHH children, word reading skills, comprehension and phonological awareness of sign language predicted imitation at T 2. For the <b>hearing</b> participants, language <b>comprehension</b> predicted imitation at T 2, even after the effects of working memory capacity and motor skills were taken into account. These results demonstrate that experience of sign language enhances the ability to imitate manual gestures once representations have been established, and suggest that the inherent motor patterns of lexical manual gestures are better suited for representation than those of non-signs. This set of findings prompts a developmental version of the ELU model, D-ELU. Funding Agencies|Swedish Research Council for Health, Working Life and Welfare [2008 - 0846]</p...|$|R

