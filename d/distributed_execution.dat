547|356|Public
5000|$|Support <b>distributed</b> <b>execution</b> {{environment}} (distributed test bed) ...|$|E
5000|$|Virtual synchrony, a <b>distributed</b> <b>execution</b> {{model for}} {{event-driven}} programming ...|$|E
5000|$|Cloud2Sim leverages Hazelcast as a <b>distributed</b> <b>execution</b> {{framework}} for CloudSim cloud simulations.|$|E
40|$|International audienceWe {{describe}} {{in this paper}} a Parallel Observable virtual Machine (POM), which provides a homogeneous interface upon the communication kernels of parallel architectures. POM was designed {{so as to be}} ported easily and eciently on numerous parallel platforms. It provides sophisticated features for observing <b>distributed</b> <b>executions...</b>|$|R
50|$|The XenoServer {{platform}} is {{a network of}} XenoServers meant to support <b>distributed</b> code <b>execution</b> services.|$|R
5000|$|Vinton Cerf et al., System for <b>Distributed</b> Task <b>Execution</b> June 3, 2003, U.S. Patent 6,574,628 ...|$|R
5000|$|Cloud2Sim leverages Infinispan for its <b>distributed</b> <b>execution</b> of MapReduce {{workflows}} and simulations.|$|E
5000|$|Cloud2Sim extends CloudSim {{to execute}} on {{multiple}} distributed servers, by leveraging Hazelcast <b>distributed</b> <b>execution</b> framework.|$|E
50|$|Hazelcast is {{also used}} in academia and {{research}} {{as a framework for}} <b>distributed</b> <b>execution</b> and storage.|$|E
40|$|With the {{emergence}} of global market and virtual enterprises, coordination of business processes in dispersed organizations by <b>distributed</b> workflow <b>execution</b> will take on more importance. At the same time, grid workflow is now been regarded as a fundamental service in grid environment. In this paper we give a real life example to see how distributed workflow technology {{can be used in}} virtual enterprises in grid environment. We propose a novel <b>distributed</b> workflow <b>execution</b> architecture, and we also address the key technologies in implementing this architecture, i. e., the procedure of <b>distributed</b> process <b>execution</b> and the model partition method. With the real life example we demonstrate how to use the proposed method to support <b>distributed</b> workflow <b>execution</b> inside virtual enterprises. Our method can be used in many scenarios such as service oriented computing and the grid, to serve as the process management platform. We also stress that future research should focus on making further investigations on the model partition policy, i. e., how to partition the model and allocate task to different sites to improve the overall system performance...|$|R
40|$|Designing and {{implementing}} a visual debugger for distributed programs {{is a significant}} challenge. Distributed applications are often large and frequently exhibit {{a high degree of}} complexity. Consequently, a debugger must address problems of complexity and scale in at least two ways. First, appropriate user interfaces should allow a user to manage the vast amount of information typically obtained from <b>distributed</b> <b>executions.</b> Second, the tool itself, in handling this information, should be implemented efficiently, providing a user with reasonable response times for interactive use. Our research efforts, concentrating on these problems, have {{led to the development of}} Poet, a tool for the collection and presentation of event-based traces of <b>distributed</b> <b>executions.</b> Poet makes as few assumptions as possible about characteristics that must be possessed by all target environments. Information describing each target environment is placed in configuration files, allowing a single set of Poet executables to be used for all target environments. Comparing Poet's performance to XPVM, the standard visualization tool for PVM executions, reveals that this target-system independence does not impose a performance penalty...|$|R
40|$|Traces are dynamic {{instruction}} sequences {{constructed and}} cached by hardware. A microarchitecture organized around traces {{is presented as}} a means for efficiently executing many instructions per cycle. Trace processors exploit both control flow and data flow hierarchy to overcome complexity and architectural limitations of conventional superscalar processors by (1) <b>distributing</b> <b>execution</b> resources based on trace boundaries and (2) applying control and data prediction at the trace level rather than individual branches or instructions. Three set...|$|R
5000|$|... ∂u∂u {{exploits}} Hazelcast as its <b>distributed</b> <b>execution</b> {{framework for}} near duplicate detection in enterprise data solutions.|$|E
5000|$|... 2012 Derek Murray (University of Cambridge), for {{his thesis}} A <b>Distributed</b> <b>Execution</b> Engine Supporting Data-Dependent Control Flow ...|$|E
50|$|NonStop SQL is {{designed}} to run effectively on parallel computers, adding functionality for distributed data, <b>distributed</b> <b>execution,</b> and distributed transactions.|$|E
40|$|Abstract. We examine {{provenance}} in {{the context}} of a <b>distributed</b> job <b>execution</b> system. It is crucial to capture provenance information during the execution of a job in a distributed environment because often this information is lost once the job has finished. In this paper we discuss the type of information that is available within a <b>distributed</b> job <b>execution</b> system, how to capture such information, and what the burdens on the user and system are when such information is captured. We identify what we think is the key data that must be captured and discuss the collection of provenance in the Quill++ project of Condor. Our conclusion is that it is possible to capture important provenance information in a <b>distributed</b> job <b>execution</b> system with relatively little intrusion on the user or the system. ...|$|R
40|$|Signal, a {{synchronous}} and data-flow oriented langage, {{allows the}} user to design safe real-time applications. Its compiler uses a single formalism called "Synchronized Data-Flow Graphs" all along the conception chain from specification to proof and verification. We show how this formalism can be kept on until distributed code generation. The implementation described here, called synchronous distribution, respects the semantics of Signal. We finally show the limits of SDFGs and conclude on the necessity of another model describing dynamic behaviours of <b>distributed</b> <b>executions...</b>|$|R
40|$|The p 2 d 2 {{project at}} NAS {{has built a}} {{debugger}} for applications running on heterogeneous computational grids. It employs a client-server architecture to simplify the implementation. Its user interface {{has been designed to}} provide process control and state examination functions on a computation containing a large number of processes. It can find processes participating in distributed computations even when those processes were not created under debugger control. These process identification techniques work both on conventional <b>distributed</b> <b>executions</b> as well as those on a computational grid...|$|R
5000|$|MEDIator {{data sharing}} {{synchronization}} platform for medical image archives leverages Infinispan as its distributed in-memory storage, {{as well as}} <b>distributed</b> <b>execution</b> framework.|$|E
50|$|Muskel also {{provides}} non-functional {{features such as}} Quality of Service (QoS); security between task pool and interpreters; and resource discovery, load balancing, and fault tolerance when interfaced with Java / Jini Parallel Framework (JJPF), a <b>distributed</b> <b>execution</b> framework. Muskel {{also provides}} support for combining structured with unstructured programming and recent research has addressed extensibility.|$|E
50|$|Grid Engine is {{typically}} {{used on a}} computer farm or high-performance computing (HPC) cluster and is responsible for accepting, scheduling, dispatching, and managing the remote and <b>distributed</b> <b>execution</b> {{of large numbers of}} standalone, parallel or interactive user jobs. It also manages and schedules the allocation of distributed resources such as processors, memory, disk space, and software licenses.|$|E
5000|$|Other {{stronger}} consistency models like sequential {{consistency and}} linearizability have downsides such as: they {{take too long}} and require more space; {{also in terms of}} implementation, they are unattainable in some situations. Due to those reasons, causal consistency was proposed in the nineties [...] as a weaker consistency model in order to improve the performance and gain in efficiency when defining the semantics of memory accesses in shared memory models. In causality, <b>distributed</b> <b>executions</b> are represented as partial orders based on Lamport's concept of potential causality.|$|R
40|$|Abstract. Efficient {{business}} {{workflow management}} in large-scale areas is in great demand. However, current business workflow management systems are short of <b>distributed</b> workflow <b>execution</b> support. In our paper, we design {{and implement a}} distributed framework called PeerODE for Apache ODE (Orchestration Director Engine) [1], an open-sourced business workflow engine. PeerODE presents a scalable approach to P 2 P business process execution. The scheduling experiment on PeerODE shows that the framework handles the <b>distributed</b> business process <b>execution</b> effectively...|$|R
50|$|Swift is an implicitly {{parallel}} programming language that allows writing scripts that <b>distribute</b> program <b>execution</b> across <b>distributed</b> computing resources, including clusters, clouds, grids, and supercomputers. Swift implementations are open-source software under the Apache License, version 2.0.|$|R
5000|$|JoCaml is {{the first}} {{language}} where the join-pattern was implemented. Indeed, at the beginning all the different implementation was compiled with the JoCaml Compiler. JoCaml language {{is an extension of}} the OCaml language. It extends OCaml with support for concurrency and synchronization, the <b>distributed</b> <b>execution</b> of programs, and the dynamic relocation of active program fragments during execution ...|$|E
5000|$|In 2010, the {{research}} project [...] "Stratosphere: Information Management on the Cloud" [...] (funded by the German Research Foundation (DFG)) was {{started as a}} collaboration of Technical University Berlin, Humboldt-Universität zu Berlin, and Hasso-Plattner-Institut Potsdam. Flink started from a fork of Stratosphere’s <b>distributed</b> <b>execution</b> engine and it became an Apache Incubator project in March 2014. In December 2014, Flink was accepted as an Apache top-level project.|$|E
50|$|In 2016 Google {{donated the}} core SDK {{as well as}} the {{implementation}} of a local runner, and a set of IOs (data connectors) to access Google Cloud Platform data services to the Apache Software Foundation. Other companies and members of the community have contributed runners for existing <b>distributed</b> <b>execution</b> platforms, as well as new IOs to integrate the Beam Runners with existing Databases, Key-Value stores and Message systems. Additionally new DSLs have been proposed to support specific domain needs on top of the Beam Model.|$|E
40|$|Abstract. After {{over thirty}} years of {{distributed}} computing, debugging distributed applications is still regarded as a difficult task. While {{it could be argued}} that this condition stems from the complexity of <b>distributed</b> <b>executions,</b> the fast pace of evolution witnessed with distributed computing technologies has also played its role by shortening the life-span of many useful debugging tools. In this paper we present an extensible Eclipse-based tool which brings distributed threads and symbolic debuggers together, resulting in a simple and useful debugging aid. This extensible tool is based on a technique that is supported by elements that are common to synchronous-call middleware implementations, making it a suitable candidate for surviving technology evolution. ...|$|R
50|$|Manages native {{supported}} integrated NOSQL {{data storage}} Sphinx (c) search index and <b>Distributed</b> Remote Command <b>Execution.</b>|$|R
40|$|Abstract—A stable {{property}} {{continues to}} hold in an execution once it becomes true. Detecting arbitrary stable properties efficiently in <b>distributed</b> <b>executions</b> is still an open problem. The known algorithms for detecting arbitrary stable properties and snapshot algorithms used to detect such stable properties suffer from drawbacks such as the following: They incur the overhead {{of a large number}} of messages per global snapshot, or alter application message headers, or use inhibition, or use the execution history, or assume a strong property such as causal delivery of messages in the system. We solve the problem of detecting an arbitrary stable property efficiently under the following assumptions: P 1) The application messages should not be modified, not even by timestamps o...|$|R
5000|$|The quasi-opportunistic {{paradigm}} aims {{to overcome}} this by achieving {{more control over the}} assignment of tasks to distributed resources and the use of pre-negotiated scenarios for the availability of systems within the network. Quasi-opportunistic <b>distributed</b> <b>execution</b> of demanding parallel computing software in grids focuses on the implementation of grid-wise allocation agreements, co-allocation subsystems, communication topology-aware allocation mechanisms, fault tolerant message passing libraries and data pre-conditioning. In this approach, fault tolerant message passing is essential to abstractly shield against the failures of the underlying resources.|$|E
50|$|Opa {{consists}} of a web server, a database and <b>distributed</b> <b>execution</b> engine. Code written in Opa is compiled to JavaScript using Node.js on the server side and to JavaScript using jQuery for cross-browser compatibility on the client side.The advantage of the approach compared to certain Rich Internet Application (RIA) platforms is that users {{are not required to}} install a plugin in their browser. Opa shares motivations with web frameworks, but takes a different approach.Its designers assert that this helps Opa to avoid many security issues, like SQL injections or cross-site scripting (XSS) attacks.|$|E
50|$|Quasi-opportunistic {{supercomputing}} {{is a form}} of {{distributed computing}} whereby the “super virtual computer” of many networked geographically disperse computers performs computing tasks that demand huge processing power. Quasi-opportunistic supercomputing aims to provide a higher quality of service than opportunistic grid computing by achieving more control over the assignment of tasks to distributed resources and the use of intelligence about the availability and reliability of individual systems within the supercomputing network. However, quasi-opportunistic <b>distributed</b> <b>execution</b> of demanding parallel computing software in grids should be achieved through implementation of grid-wise allocation agreements, co-allocation subsystems, communication topology-aware allocation mechanisms, fault tolerant message passing libraries and data pre-conditioning.|$|E
40|$|Abstract. Recording {{on-the-fly}} global {{states of}} <b>distributed</b> <b>executions</b> {{is an important}} paradigm when one is interested in analysing, testing, or verifying properties associated with these executions. Since Chandy and Lamport's seminal paper on this topic, this problem is called the snapshot problem. Unfortunately, the lack of both a globally shared memory and a global clock in a distributed system, added {{to the fact that}} transfer delays in these systems are finite but unpredictable, makes this problem non-trivial. This paper first discusses issues which have to be addressed to compute distributed snapshots in a consistent way. Then several algorithms which determine on-the-fly such snapshots are presented for several types of networks (according to the properties of their communication channels, namely, FIFO, non-FIFO, and causal delivery). 1...|$|R
40|$|This report proposes {{an on-line}} {{compression}} algorithm for <b>distributed</b> <b>executions.</b> An execution is decomposed into atomic communication patterns. Events are clustered together {{according to the}} following policy: the initial partial order structure is preserved, and valid global states are detected {{in order to find}} a coherent global state if a site fails. Two versions of the algorithm have been developed. The first version is online and centralized and does not depend on execution order of any concurrent events. Moreover, if clusters are bounded in size, the memory size needed for infinite executions is also bounded. The second version is distributed and is done by piggybacking subset of sites knowledge into messages: under certain conditions, size of piggybacked messages is bounded and the algorithm can be effectively implemented...|$|R
40|$|This paper studies message {{communication}} modes in <b>distributed</b> <b>executions.</b> It establishes a simple, hierarchical and homogeneous characterization of logically instantaneous, causally ordered and first-in-first-out communications. It is {{shown that a}} distributed computation obeys one of the previous communication modes iff a communication graph of messages does not include a cycle. This characterization {{plays a key role}} when one is interested in understanding asynchronous distributed computations. Further the homogeneity of our characterization contributes to get a better comprehension of concepts and relations that rule communication modes of distributed computations; this is a crucial point to develop new communication protocols by adding software layers over an existing one. Finally, such a graph-based approach shows some unity in the characterization of deadlock, concurrency control, memory consistency and communication modes...|$|R
