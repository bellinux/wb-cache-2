260|268|Public
2500|$|... added {{tasks that}} were from new areas of studies in {{computational}} semantics, viz., Coreference, Elipsis, <b>Keyphrase</b> Extraction, Noun Compounds and Textual Entailment.|$|E
5000|$|In English and {{all other}} {{languages}} the core intent or desire is identified and become the corner-stone of the <b>keyphrase</b> Intent segmentation. Core product/service, idea, action & or thought anchor the <b>keyphrase.</b>|$|E
5000|$|A <b>keyphrase</b> {{extractor}} might select [...] "Army Corps of Engineers", [...] "President Bush", [...] "New Orleans", and [...] "defective flood-control pumps" [...] as keyphrases. These {{are pulled}} {{directly from the}} text. In contrast, an abstractive <b>keyphrase</b> system would somehow internalize the content and generate keyphrases that do {{not appear in the}} text, but more closely resemble what a human might produce, such as [...] "political negligence" [...] or [...] "inadequate protection from floods". Abstraction requires a deep understanding of the text, which makes it difficult for a computer system.Keyphrases have many applications. They can enable document browsing by providing a short summary, improve information retrieval (if documents have keyphrases assigned, a user could search by <b>keyphrase</b> to produce more reliable hits than a full-text search), and be employed in generating index entries for a large text corpus.|$|E
40|$|<b>Keyphrases</b> provide {{semantic}} metadata that summarize and characterize documents. This paper describes Kea, an algorithm for automatically extracting <b>keyphrases</b> from text. Kea identifies candidate <b>keyphrases</b> using lexical methods, calculates feature {{values for}} each candidate, {{and uses a}} machine -learning algorithm to predict which candidates are good <b>keyphrases.</b> The machine learning scheme first builds a prediction model using training documents with known <b>keyphrases,</b> and then uses the model to find <b>keyphrases</b> in new documents. We use a large test corpus to evaluate Kea's effectiveness {{in terms of how}} many author-assigned <b>keyphrases</b> are correctly identified. The system is simple, robust, and publicly available. INTRODUCTION <b>Keyphrases</b> provide a brief summary of a document's contents. As large document collections such as digital libraries become widespread, the value of such summary information increases. Keywords and <b>keyphrases</b> 1 are particularly useful because they can be interprete [...] ...|$|R
40|$|This paper {{presents}} a novel system E 3 for extracting <b>keyphrases</b> from news {{content for the}} purpose of offering the news audience a broad overview of news events, with especially high content volume. Given an input query, E 3 extracts <b>keyphrases</b> and enrich them by tagging, ranking and finding role for frequently associated <b>keyphrases.</b> Also, E 3 finds the novelty and activeness of <b>keyphrases</b> using news publication date, to identify the most interesting and informative <b>keyphrases...</b>|$|R
40|$|Abstract. Many {{academic}} {{journals and}} conferences require that each paper {{will include a}} list of <b>keyphrases.</b> These <b>keyphrases</b> provide general information about the contents and the topics of the articles. <b>Keyphrases</b> may save pre-cious time for tasks such as filtering, summarization and categorization. In this paper, we investigate automatic extraction and learning of <b>keyphrases</b> from scientific articles written in English. Firstly, we introduce several base-line extraction methods. Then, we integrate them using different machine learning methods. Results achieved on a collection of 161 scientific articles in different domains are comparable {{to the state of}} art. ...|$|R
50|$|This general formula allows {{that the}} total word count will be {{unaffected}} if the <b>key(phrase)</b> is indeed a single term, so it acts as the original formula.|$|E
5000|$|Density = ( [...] Nkr / ( [...] Tkn -( [...] Nkr * ( [...] Nwp-1 [...] ) [...] ) [...] ) [...] ) * 100.where Nwp = {{the number}} of terms in the <b>keyphrase.</b>|$|E
50|$|Like <b>keyphrase</b> extraction, {{document}} summarization aims {{to identify}} {{the essence of a}} text. The only real difference is that now we are dealing with larger text units—whole sentences instead of words and phrases.|$|E
40|$|In pseudo-relevance feedback, the two {{key factors}} {{affecting}} the retrieval performance most {{are the source}} from which expansion terms are generated and the method of ranking those expansion terms. In this paper, we present a novel unsupervised query expansion technique that utilizes <b>keyphrases</b> and POS phrase categorization. The <b>keyphrases</b> are extracted from the retrieved documents and weighted with an algorithm based on information gain and co-occurrence of phrases. The selected <b>keyphrases</b> are translated into Disjunctive Normal Form (DNF) based on the POS phrase categorization technique for better query refomulation. Furthermore, we study whether ontologies such as WordNet and MeSH improve the retrieval performance {{in conjunction with the}} <b>keyphrases.</b> We test our techniques on TREC 5, 6, and 7 as well as a MEDLINE collection. The experimental results show that the use of <b>keyphrases</b> with POS phrase categorization produces the best average precision...|$|R
40|$|Many {{academic}} journals {{ask their}} authors {{to provide a}} list of about five to fifteen key words, {{to appear on the}} first page of each article. Since these key words are often phrases of two or more words, we prefer to call them <b>keyphrases.</b> There is a surprisingly wide variety of tasks for which <b>keyphrases</b> are useful, as we discuss in this paper. Recent commercial software, such as Microsoft's Word 97 and Verity's Search 97, includes algorithms that automatically extract <b>keyphrases</b> from documents. 1 In this paper, we approach the problem of automatically extracting <b>keyphrases</b> from text as a supervised learning task. We treat a document as a set of phrases, which the learning algorithm must learn to classify as positive or negative examples of <b>keyphrases.</b> Our first set of experiments applies the C 4. 5 decision tree induction algorithm to this learning task. The second set of experiments applies the GenEx algorithm to the task. We developed the GenEx algorithm specifically for this task. Th [...] ...|$|R
40|$|Abstract. <b>Keyphrases</b> {{extracted}} from articles are beneficial in helping people boost brows-ing speed, but unfortunately <b>keyphrases</b> are rarely available for news articles {{due to the}} high expense of labor and time for manual annotation. This paper proposes a practical approach to extracting <b>keyphrases</b> for Chinese news articles using the TextRank and query log knowl-edge. Previous work is word based, while our approach uses phrase as its basic element. We generate phrases by employing several statistical criteria with the huge amount of queries as a training corpus. We use TextRank, a graph-based learning algorithm, for extracting <b>keyphrases</b> from Chinese news articles. In addition, two instructive features, lengths and positions of phrases, are incorporated into the TextRank model. Experimental results demon-strate that our methods improve the performance significantly...|$|R
5000|$|... 'Keywords' (kr) that {{consist of}} several words artificially inflate the {{total word count}} of the dissertation. The purest {{mathematical}} representation should adjust the total word count (Tkn) lower by removing the excess <b>key(phrase)</b> word counts from the total: ...|$|E
5000|$|Another <b>keyphrase</b> {{extraction}} {{algorithm is}} TextRank. While supervised methods have some nice properties, like {{being able to}} produce interpretable rules for what features characterize a <b>keyphrase,</b> they also require {{a large amount of}} training data. Many documents with known keyphrases are needed. Furthermore, training on a specific domain tends to customize the extraction process to that domain, so the resulting classifier is not necessarily portable, as some of Turney's results demonstrate.Unsupervised <b>keyphrase</b> extraction removes the need for training data. It approaches the problem from a different angle. Instead of trying to learn explicit features that characterize keyphrases, the TextRank algorithm exploits the structure of the text itself to determine keyphrases that appear [...] "central" [...] to the text {{in the same way that}} PageRank selects important Web pages. Recall this is based on the notion of [...] "prestige" [...] or [...] "recommendation" [...] from social networks. In this way, TextRank does not rely on any previous training data at all, but rather can be run on any arbitrary piece of text, and it can produce output simply based on the text's intrinsic properties. Thus the algorithm is easily portable to new domains and languages.|$|E
50|$|Advanced {{thematic}} cryptic crosswords like The Listener Crossword (published in the Saturday {{edition of}} the British newspaper The Times) occasionally incorporate Playfair ciphers. Normally between 4 and 6 answers have to be entered into the grid in code, and the Playfair <b>keyphrase</b> is thematically significant to the final solution.|$|E
40|$|Abstract. <b>Keyphrases</b> {{are mainly}} words that capture the main topics of a document. We think that {{semantic}} classes {{can be used}} as <b>keyphrases</b> for a text. We have developed a semantic class–based WSD system that can tag the words of a text with their semantic class. A method is developed to compare the semantic classes of the words of a text with the correct ones based on statistical measures. We find that the evaluation of semantic classes considered as <b>keyphrases</b> is very close to 100 % in most cases. ...|$|R
40|$|In this paper, it is {{presented}} an unsupervised approach to automatically discover the latent <b>keyphrases</b> contained in scientific articles. The proposed technique is constructed {{on the basis of}} the combination of two techniques: maximal frequent sequences and pageranking. We evaluated the obtained results by using micro-averaged precision, recall and F-scores with respect to two different gold standards: 1) reader’s <b>keyphrases,</b> and 2) a combined set of author’s and reader’s <b>keyphrases.</b> The obtained results were also compared against three different baselines: one unsupervised (TF-IDF based) and two supervised (Naïve Bayes and Maximum Entropy). ...|$|R
5000|$|The task is the following. You {{are given}} a piece of text, such as a journal article, and you must produce a list of {{keywords}} or <b>keyphrases</b> that capture the primary topics discussed in the text. In the case of research articles, many authors provide manually assigned keywords, but most text lacks pre-existing <b>keyphrases.</b> For example, news articles rarely have <b>keyphrases</b> attached, {{but it would be}} useful to be able to automatically do so for a number of applications discussed below.Consider the example text from a news article: ...|$|R
50|$|Designing a {{supervised}} <b>keyphrase</b> {{extraction system}} involves deciding on several choices (some of these apply to unsupervised, too). The first choice {{is exactly how}} to generate examples. Turney and others have used all possible unigrams, bigrams, and trigrams without intervening punctuation and after removing stopwords. Hulth showed {{that you can get}} some improvement by selecting examples to be sequences of tokens that match certain patterns of part-of-speech tags. Ideally, the mechanism for generating examples produces all the known labeled keyphrases as candidates, though this is often not the case. For example, if we use only unigrams, bigrams, and trigrams, then we {{will never be able to}} extract a known <b>keyphrase</b> containing four words. Thus, recall may suffer. However, generating too many examples can also lead to low precision.|$|E
50|$|A more principled way to {{estimate}} sentence importance is using random walks and eigenvector centrality. LexRank is an algorithm essentially identical to TextRank, and both use this approach for document summarization. The two methods {{were developed by}} different groups at the same time, and LexRank simply focused on summarization, but {{could just as easily}} be used for <b>keyphrase</b> extraction or any other NLP ranking task.|$|E
5000|$|The {{unsupervised}} {{approach to}} summarization is also quite similar in spirit to unsupervised <b>keyphrase</b> extraction and gets around {{the issue of}} costly training data. Some unsupervised summarization approaches are based on finding a [...] "centroid" [...] sentence, which is the mean word vector of all the sentences in the document. Then the sentences can be ranked {{with regard to their}} similarity to this centroid sentence.|$|E
40|$|Abstract. Many {{academic}} {{journals and}} conferences require that each article will in-clude {{a list of}} <b>keyphrases.</b> These <b>keyphrases</b> should provide general information about the contents and the topics of the article. <b>Keyphrases</b> may save precious time for tasks such as filtering, summarization and categorization. In this paper, we inves-tigate automatic extraction and learning of <b>keyphrases</b> from scientific articles written in English. Firstly, we introduce various baseline extraction methods. Some of them, formalized by us have been found as very successful for academic papers. Then, we integrate these methods using different machine learning methods. The best results have been achieved by J 48, an improved variant of C 4. 5. These results are signifi-cantly better than those achieved by previous extraction systems, which are regarded as {{the state of the}} art. ...|$|R
40|$|Extracted <b>keyphrases</b> {{can enhance}} numer-ous {{applications}} ranging from search to tracking {{the evolution of}} scientific dis-course. We present SCHBASE, a hier-archical database of <b>keyphrases</b> extracted from large collections of scientific liter-ature. SCHBASE relies on a tendency of scientists to generate new abbrevia-tions that “extend ” existing forms {{as a form of}} signaling novelty. We demon-strate how these keyphrases/concepts can be extracted, and their viability as a database in relation to existing collections. We further show how <b>keyphrases</b> can be placed into a semantically-meaningful “phylogenetic ” structure and describe key features of this structure. The com-plete SCHBASE dataset is available at...|$|R
40|$|There {{are many}} {{published}} methods available for creating <b>keyphrases</b> for documents. Previous {{work in the}} field has shown that in a significant proportion of cases author selected <b>keyphrases</b> are not appropriate for the document they accompany. This requires the use of such automated methods to improve the use of <b>keyphrases.</b> Often the <b>keyphrases</b> are not updated when the focus of a paper changes or include <b>keyphrases</b> that are more classificatory than explanatory. The published methods are all evaluated using different corpora, typically one relevant to their field of study. This not only makes it difficult to incorporate the useful elements of algorithms in future work but also makes comparing the results of each method inefficient and ineffective. This paper describes the work undertaken to compare five methods across a common baseline of six corpora. The methods chosen were term frequency, inverse document frequency, the C-Value, the NC-Value, and a synonym based approach. These methods were compared to evaluate performance and quality of results, and to provide a future benchmark. It is shown that, with the comparison metric used for this study Term Frequency and Inverse Document Frequency were the best algorithms, with the synonym based approach following them. Further work in the area is required to determine an appropriate (or more appropriate) comparison metric...|$|R
5000|$|In this {{summarization}} task, {{the automatic}} system extracts {{objects from the}} entire collection, without modifying the objects themselves. Examples of this include <b>keyphrase</b> extraction, where {{the goal is to}} select individual words or phrases to [...] "tag" [...] a document, and document summarization, where the goal is to select whole sentences (without modifying them) to create a short paragraph summary. Similarly, in image collection summarization, the system extracts images from the collection without modifying the images themselves.|$|E
50|$|Once {{examples}} and features are created, {{we need a}} way to learn to predict keyphrases. Virtually any supervised learning algorithm could be used, such as decision trees, Naive Bayes, and rule induction. In the case of Turney's GenEx algorithm, a genetic algorithm is used to learn parameters for a domain-specific <b>keyphrase</b> extraction algorithm. The extractor follows a series of heuristics to identify keyphrases. The genetic algorithm optimizes parameters for these heuristics with respect to performance on training documents with known key phrases.|$|E
5000|$|From a {{mathematical}} viewpoint, the original concept of keyword density {{refers to the}} frequency (Nkr) of appearance of a keyword in a dissertation. A [...] "keyword" [...] consisting of multiple terms, e.g. [...] "blue suede shoes," [...] is an entity in itself. T frequency of the phrase [...] "blue suede shoes" [...] within a dissertation drives the <b>key(phrase)</b> density. It is [...] "more" [...] mathematically correct for a [...] "keyphrase" [...] to be calculated just like the original calculation, but considering the word group, [...] "blue suede shoes," [...] as a single appearance, not three: ...|$|E
40|$|<b>Keyphrases</b> {{are added}} to {{documents}} to help identify the areas of interest they contain. However, in {{a significant proportion of}} papers author selected <b>keyphrases</b> are not appropriate for the document they accompany: for instance, they can be classificatory rather than explanatory, or they are not updated when the focus of the paper changes. As such, automated methods for improving the use of <b>keyphrases</b> are needed, and various methods have been published. However, each method was evaluated using a different corpus, typically one relevant to the field of study of the method’s authors. This not only makes it difficult to incorporate the useful elements of algorithms in future work, but also makes comparing the results of each method inefficient and ineffective. This paper describes the work undertaken to compare five methods across a common baseline of corpora. The methods chosen were Term Frequency, Inverse Document Frequency, the C-Value, the NC-Value, and a Synonym based approach. These methods were analysed to evaluate performance and quality of results, and to provide a future benchmark. It is shown that Term Frequency and Inverse Document Frequency were the best algorithms, with the Synonym approach following them. Following these findings, a study was undertaken into the value of using human evaluators to judge the outputs. The Synonym method was compared to the original author <b>keyphrases</b> of the Reuters’ News Corpus. The findings show that authors of Reuters’ news articles provide good <b>keyphrases</b> but that more often than not they do not provide any <b>keyphrases...</b>|$|R
40|$|Many {{academic}} journals {{ask their}} authors {{to provide a}} list of about five to fifteen key words, {{to appear on the}} first page of each article. Since these key words are often phrases of two or more words, we prefer to call them <b>keyphrases.</b> There is a surprisingly wide variety of tasks for which <b>keyphrases</b> are useful, as we discuss in this paper. Recent commercial software, such as Microsoft?s Word 97 and Verity?s Search 97, includes algorithms that automatically extract <b>keyphrases</b> from documents. In this paper, we approach the problem of automatically extracting <b>keyphrases</b> from text as a supervised learning task. We treat a document as a set of phrases, which the learning algorithm must learn to classify as positive or negative examples of <b>keyphrases.</b> Our first set of experiments applies the C 4. 5 decision tree induction algorithm to this learning task. The second set of experiments applies the GenEx algorithm to the task. We developed the GenEx algorithm specifically for this task. The third set of experiments examines the performance of GenEx on the task of metadata generation, relative to the performance of Microsoft?s Word 97. The fourth and final set of experiments investigates the performance of GenEx on the task of highlighting, relative to Verity?s Search 97. The experimental results support the claim that a specialized learning algorithm (GenEx) can generate better <b>keyphrases</b> than a general-purpose learning algorithm (C 4. 5) and the non-learning algorithms that are used in commercial software (Word 97 and Search 97) ...|$|R
40|$|This paper {{presents}} {{an approach to}} summarize single scientific papers, by extracting its contributions from the set of citation sentences written in other papers. Our methodology is based on extracting significant <b>keyphrases</b> from the set of citation sentences and using these <b>keyphrases</b> to build the summary. Comparisons show how this methodology excels at the task of single paper summarization, and how it out-performs other multi-document summarization methods. ...|$|R
50|$|We {{also need}} to create {{features}} that describe the examples and are informative enough to allow a learning algorithm to discriminate keyphrases from non- keyphrases. Typically features involve various term frequencies (how many times a phrase appears in the current text or in a larger corpus), {{the length of the}} example, relative position of the first occurrence, various boolean syntactic features (e.g., contains all caps), etc. The Turney paper used about 12 such features. Hulth uses a reduced set of features, which were found most successful in the KEA (<b>Keyphrase</b> Extraction Algorithm) work derived from Turney’s seminal paper.|$|E
5000|$|TextRank is {{a general}} purpose {{graph-based}} ranking algorithm for NLP. Essentially, it runs PageRank on a graph specially designed for a particular NLP task. For <b>keyphrase</b> extraction, it builds a graph using some set of text units as vertices. Edges are based on some measure of semantic or lexical similarity between the text unit vertices. Unlike PageRank, the edges are typically undirected and can be weighted to reflect a degree of similarity. Once the graph is constructed, {{it is used to}} form a stochastic matrix, combined with a damping factor (as in the [...] "random surfer model"), and the ranking over vertices is obtained by finding the eigenvector corresponding to eigenvalue 1 (i.e., the stationary distribution of the random walk on the graph).|$|E
5000|$|Beginning {{with the}} work of Turney, many {{researchers}} have approached <b>keyphrase</b> extraction as a supervised machine learning problem.Given a document, we construct an example for each unigram, bigram, and trigram found in the text (though other text units are also possible, as discussed below). We then compute various features describing each example (e.g., does the phrase begin with an upper-case letter?). We assume there are known keyphrases available for a set of training documents. Using the known keyphrases, we can assign positive or negative labels to the examples. Then we learn a classifier that can discriminate between positive and negative examples {{as a function of the}} features. Some classifiers make a binary classification for a test example, while others assign a probability of being a <b>keyphrase.</b> For instance, in the above text, we might learn a rule that says phrases with initial capital letters are likely to be keyphrases.After training a learner, we can select keyphrases for test documents in the following manner. We apply the same example-generation strategy to the test documents, then run each example through the learner. We can determine the keyphrases by looking at binary classification decisions or probabilities returned from our learned model. If probabilities are given, a threshold is used to select the keyphrases.Keyphrase extractors are generally evaluated using precision and recall. Precision measures howmany of the proposed keyphrases are actually correct. Recall measures how many of the truekeyphrases your system proposed. The two measures can be combined in an F-score, which is theharmonic mean of the two (F = 2PR/(P + R) [...] ). Matches between the proposed keyphrases and the known keyphrases can be checked after stemming or applying some other text normalization.|$|E
5000|$|Intent {{segmentation}} is {{the problem}} of dividing written words into <b>keyphrases</b> (2 or more group of words).|$|R
3000|$|To {{validate}} {{our opinion}} different annotators reach high agreement on noun phrases, we randomly select 20 articles and annotate <b>keyphrases</b> that may contain adjectives for each article, denoted by S. Then we compare our manually labeled <b>keyphrases</b> with the benchmark {{that is used}} in the work [31], denoted by T. We find that the proportion of common general phrases is |S ∩ T|/|S ∪ T| = 44 [...]...|$|R
40|$|Effectiveness and {{efficiency}} of searching and returned results presentation {{is the key to}} a search engine. Before downloading and examining the document text, users usually first judge the relevance of a return hit to the query by looking at document metadata presented in the return result. However, the metadata coming with the return hit is usually not rich enough for users to predict the content of the document. <b>Keyphrases</b> provide a concise summary of a document’s content, offering subject metadata characterizing and summarizing document. In this paper, we propose a mechanism of enriching the metadata of the return results by incorporating automatically extracted document <b>keyphrases</b> in each return hit. By looking at the <b>keyphrases</b> in each return hit, the user can predict the content of the document more easily, quickly, and accurately. The experimental results show that our solution may save users time up to 32 % and users would like to use our proposed search interface with document <b>keyphrases</b> as part of the metadata of a return hit...|$|R
