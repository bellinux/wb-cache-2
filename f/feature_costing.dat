4|750|Public
2500|$|In 2009, Roadster {{reservation}} holders who {{had already}} placed deposits up to US$50,000 to lock in their orders were informed that their orders had been unlocked {{and that they had}} to re-option their ordered vehicles on the threat of losing their spot on the orders list. Tesla then raised the prices of several options, and a new Tesla Roadster with the same set of features that had previously been standard became US$6,700 more expensive than before. For example, the high performance charger that was previously claimed to be standard on all vehicles was changed to be an optional <b>feature</b> <b>costing</b> US$3,000, and the previously claimed standard forged alloy wheels became a US$2,300 upgrade. One of the individuals who preordered a Tesla Roadster complained: ...|$|E
40|$|Target costing is {{a widely}} used {{technique}} for cost management during product development (PD). Despite target costing's strategic intuitiveness, its operationalization during PD requires careful decomposition of a product's constituent cost elements. The main objective {{of this paper is}} to describe an experience developing early-stage cost parameters for a specific product development process effort at a mid-sized Brazilian manufacturing company by proposing and applying a target costing model. One secondary objective is to provide a model to operationalize "target costing" by breaking down cost targets into product parts, features and common elements, focusing on creating parameters for cost control during PD. Using a detailed case study, target costing is explicitly decomposed in four different stages in a PD environment. All these are intended as a complement to the strategic use of target costing. Target costing Product development Operationalization Cost <b>Feature</b> <b>costing...</b>|$|E
40|$|The {{purpose of}} this thesis is to analyse activity-based costing (ABC) and {{possible}} modified versions ofit in engineering design context. The design engineers need cost information attheir decision-making level and the cost information should also have a strong future orientation. These demands are high because traditional management accounting has concentrated on the direct actual costs of the products. However, cost accounting has progressed as ABC was introduced late 1980 s and adopted widely bycompanies in the 1990 s. The ABC has been a success, but it has gained also criticism. In some cases the ambitious ABC systems have become too complex to build,use and update. This study can be called an action-oriented case study with some normative features. In this thesis theoretical concepts are assessed and allowed to unfold gradually through interaction with data from three cases. The theoretical starting points are ABC and theory of engineering design process (chapter 2). Concepts and research results from these theoretical approaches are summarized in two hypotheses (chapter 2. 3). The hypotheses are analysed with two cases (chapter 3). After the two case analyses, the ABC part is extended to cover alsoother modern cost accounting methods, e. g. process costing and <b>feature</b> <b>costing</b> (chapter 4. 1). The ideas from this second theoretical part are operationalized with the third case (chapter 4. 2). The knowledge from the theory and three cases is summarized in the created framework (chapter 4. 3). With the created frameworkit is possible to analyse ABC and its modifications in the engineering design context. The framework collects the factors that guide {{the choice of the}} costing method to be used in engineering design. It also illuminates the contents of various ABC-related costing methods. However, the framework needs to be further tested. On the basis of the three cases {{it can be said that}} ABC should be used cautiously when formulating cost information for engineering design. It is suitable when the manufacturing can be considered simple, or when the design engineers are not cost conscious, and in the beginning of the design process when doing adaptive or variant design. If the design engineers need cost information for the embodiment or detailed design, or if manufacturing can be considered complex, or when design engineers are cost conscious, the ABC has to be always evaluated critically...|$|E
30|$|In this section, we {{evaluate}} the proposed PETs {{in combination with}} MRA {{with respect to the}} security <b>features,</b> <b>cost</b> and complexity, and real-world applicability.|$|R
50|$|Visitability <b>features</b> <b>cost</b> little {{up front}} - unlike the much higher after-the-fact cost of {{widening}} doors, adding ramps or electric porch lifts and other remodeling.|$|R
40|$|We {{consider}} {{the problem of}} learning decision rules for prediction with feature budget constraint. In particular, {{we are interested in}} pruning an ensemble of decision trees to reduce expected <b>feature</b> <b>cost</b> while maintaining high prediction accuracy for any test example. We propose a novel 0 - 1 integer program formulation for ensemble pruning. Our pruning formulation is general - it takes any ensemble of decision trees as input. By explicitly accounting for feature-sharing across trees together with accuracy/cost trade-off, our method is able to significantly reduce <b>feature</b> <b>cost</b> by pruning subtrees that introduce more loss in terms of <b>feature</b> <b>cost</b> than benefit in terms of prediction accuracy gain. Theoretically, we prove that a linear programming relaxation produces the exact solution of the original integer program. This allows us to use efficient convex optimization tools to obtain an optimally pruned ensemble for any given budget. Empirically, we see that our pruning algorithm significantly improves the performance {{of the state of the}} art ensemble method BudgetRF...|$|R
50|$|Fake saguaro cacti were {{purchased}} for $1,000 each, as the actual {{ones in the}} desert were not placed right for the action. The truck <b>featured</b> <b>cost</b> just $300, “and looks it”.|$|R
50|$|Product {{analysis}} involves examining product <b>features,</b> <b>costs,</b> availability, {{quality and}} other aspects. Product analysis is conducted by potential buyers, by product managers attempting to understand competitors and by third party reviewers.|$|R
50|$|There {{are major}} {{differences}} in capabilities, <b>features,</b> <b>cost</b> and performance between VSAT (Geostationary orbit satellites in Ku-band, C-band and Ka-band) and Low Earth orbit or Medium Earth Orbit satellites with L-band technologies in use.|$|R
5000|$|In some markets, very {{aggressive}} forms of no-frills cars may be available. For example, the supermini and city cars {{sold at the}} Mercosur markets, such as the Chevrolet Celta, Chevrolet Corsa, Fiat Uno, Fiat Palio, Ford Ka and Volkswagen Gol tend to be noisy and <b>feature</b> <b>cost</b> cuttings like: ...|$|R
50|$|On 6 December 2006, Underwater World Singapore {{launched}} {{three new}} attractionsan interactive stingray feeding pool, {{a display of}} small marine reef species, and 'Fish Reflexology', Singapore's first fish reflexology spa, where two species of doctor fish gently nibble away at the dead skin on visitors' feet. The new <b>features</b> <b>cost</b> 650,000.|$|R
40|$|This paper {{presents}} a cost estimation model of weld assemblages. It {{is based on}} the product decomposition into parts and then into assemblages. The study is about a proposition of an original definition of welding and preparing features attributed to each assemblages. This proposed approach is based on knowledge modelling at the level of process and product perception. The decomposition of the product into features and the identification of <b>cost</b> <b>features</b> remain manual. The proposed model consists in combining two cost estimating model applied to the products and to the processes on one hand, we have used an analytic model for the formalizing of the welding time, of the electrode consumption and of gas consumption according to the different parameters of the preparing and the welding features. The decomposition into features allows to formalize the time estimating expertise related to the welding. On the other hand, we have used the parameter method for the cost structuring caused by the different <b>feature</b> <b>cost</b> preparing and by the <b>feature</b> <b>cost</b> welding. ...|$|R
40|$|In the {{research}} the <b>features</b> of <b>cost</b> planning {{in the projects}} for optimization of the for estry enterprises structures (POFES) have been analyzed. Based on the results obtained in the paper the conclusion had made that the incorporation of the defined <b>features</b> of <b>cost</b> planning during the implementation of POFES would ensure the success of each the project...|$|R
40|$|Complex machine {{learning}} models are now {{an integral part}} of modern, large-scale retrieval systems. However, collection size growth continues to outpace advances in efficiency improvements in the learning models which achieve the highest effectiveness. In this paper, we re-examine the importance of tightly integrating <b>feature</b> <b>costs</b> into multi-stage learning-to-rank (LTR) IR systems. We present a novel approach to optimizing cascaded ranking models which can directly leverage a variety of different state-of-the-art LTR rankers such as LambdaMART and Gradient Boosted Decision Trees. Using our cascade model, we conclusively show that <b>feature</b> <b>costs</b> and the number of documents being re-ranked in each stage of the cascade can be balanced to maximize both efficiency and effectiveness. Finally, we also demonstrate that our cascade model can easily be deployed on commonly used collections to achieve state-of-the-art effectiveness results while only using a subset of the features required by the full model...|$|R
50|$|Depending on {{the used}} {{performance}} metric , feature computation can {{be associated with}} costs.For example, if we use running time as performance metric, we include the time to compute our instance features into the performance of an algorithm selection system.SAT solving is a concrete example, where such <b>feature</b> <b>costs</b> cannot be neglected, since instance features for CNF formulas can be either very cheap (e.g., to get the number of variables can be done in constant time for CNFs in the DIMACs format) or very expensive (e.g., graph <b>features</b> which can <b>cost</b> tens or hundreds of seconds).|$|R
25|$|Higher-end gentlemen's {{clubs have}} <b>features</b> that <b>cost</b> {{millions}} of dollars to install and maintain.|$|R
40|$|Abstract. Treatment of {{protected}} furanoses with FeCl 3 · 6 H 2 O in acetonitrile with microwave irradiation provides an efficient and mild protocol for regioselective removal of anomeric O-acetyl group. This method <b>features</b> <b>cost</b> efficient reagents, simple procedures, and high yields. The experimental results proved that microwave irradiation could notably shorten the reaction time {{and increase the}} product yield compared to the conventional thermal heating condition...|$|R
5000|$|By Bergman’s own account, {{he never}} had a problem with funding. He cited two reasons for this: one, that he did not live in the United States, which he viewed as obsessed with box-office earnings; and two, that his films tended to be low-budget affairs. (Cries and Whispers, for instance, was {{finished}} for about $450,000, while Scenes from a Marriage, a six-episode television <b>feature,</b> <b>cost</b> only $200,000.) ...|$|R
40|$|This thesis {{will address}} {{classification}} problems with two sources of cost: the <b>cost</b> of acquiring <b>feature</b> {{values and the}} cost of incorrect classifications. In particu- lar, I address problems with <b>feature</b> <b>costs</b> and instance-dependent misclassification costs. Many real-world applications, such as medical diagnosis, contain both <b>feature</b> acquisition <b>costs</b> and instance-dependent misclassification costs. The goal of my re- search is to minimize the total cost of classifying an unknown instance. This goal is accomplished with a new approach: Simultaneous <b>Feature</b> Acquisition and <b>Cost</b> Estimation (SFACE), which combines feature acquisition methods with a regression algorithm that estimates misclassification costs. The estimated cost values are used to estimate the expected cost reduction for the acquisition of each feature. SFACE is evaluated by comparing the total cost of operation to the cost incurred by existing cost-insensitive, cost-sensitive, and feature acquisition algorithms. The results show that SFACE results in lower total cost for the tested datasets...|$|R
40|$|Abstract. In some {{learning}} settings, the <b>cost</b> {{of acquiring}} <b>features</b> for classification {{must be paid}} up front, before the classifier is evaluated. In this paper, we introduce the forensic classification problem and present a new algorithm for building decision trees that maximizes classification accuracy while minimizing total <b>feature</b> <b>costs.</b> By expressing the ID 3 decision tree algorithm in an information theoretic context, we derive our algorithm from a well-formulated problem objective. We evaluate our algorithm across several datasets and show that, for a given level of accuracy, our algorithm builds cheaper trees than existing methods. Finally, we apply our algorithm to a real-world system, CLARIFY. CLARIFY classifies unknown or unexpected program errors by collecting statistics during program runtime which are then used for decision tree classification after an error has occurred. We demonstrate that if the classifier used by the CLARIFY system is trained with our algorithm, the computational overhead (equivalently, total <b>feature</b> <b>costs)</b> can decrease by many orders of magnitude with only a slight (< 1 %) reduction in classification accuracy. ...|$|R
50|$|It is {{important}} to take the overhead of feature computation into account in practice in such scenarios as otherwise a misleading impression {{of the performance of}} the algorithm selection approach is created. For example, if the decision which algorithm to choose can be made with prefect accuracy, but the features are the running time of the portfolio algorithms, there is no benefit to the portfolio approach. This would not be obvious if <b>feature</b> <b>costs</b> were omitted.|$|R
3000|$|... is the {{truncation}} threshold {{which is}} used to make intensity matching cost more robust against outliers. For defining the <b>feature</b> matching <b>cost</b> E [...]...|$|R
40|$|A common {{solution}} {{approach to}} reinforcement learning problems with large state spaces (where value functions cannot be represented exactly) is to compute an approximation {{of the value}} function in terms of state features. However, {{little attention has been}} paid to the cost of computing these state features (e. g., search-based features). To this end, we introduce a cost-sensitive sparse linear-value function approximation algorithm — FOVEA — and demonstrate its performance on an experimental domain with a range of <b>feature</b> <b>costs.</b> ...|$|R
40|$|We examine linear {{regression}} problems where the features {{may only be}} observable at some cost. To do this, we define a parsimonious {{linear regression}} objective criterion that jointly minimizes prediction error and <b>feature</b> <b>cost,</b> assuming they can be expressed in commensurable units. We are able to modify least angle regression algorithms commonly used for sparse linear regression (with non-costly features) to produce an algorithm which not only provides an efficient and parsimonious solution to linear regression with costly features as we demonstrate empirically, but it also provides formal guarantees on parsimony. status: publishe...|$|R
40|$|Apple smartwatch {{strategy}} is analyzed {{in this paper}} in comparison to its competitors like Samsung and Pebble. The <b>features,</b> <b>cost,</b> market share and sales of smartwatches are compared. The position of Apple smart watch in the technology adoption lifecycle is identified based on the sales. This paper also discusses the Porter’s five-force model and SWOT analysis as applied to Apple’s smart watch. Strength and weakness are analyzed for Apple smart watch and opportunities and threats in comparison to its competitors. The goal {{of this paper is}} to identify the position of Apple smartwatch in the smartwatch industry...|$|R
40|$|The {{design of}} {{automotive}} systems using computer codes for vehicle dynamics problems <b>features</b> <b>cost</b> reduction and quality enhancement. This paper presents two basic approaches. The first approach {{deals with the}} application of CAD data bases to the evaluation of input data for multibody system formalisms, most adequate for automotive system modelling. An object oriented data model for multibody systems is presented. The second approach covers {{the development of an}} integrated simulation tool for automotive vehicles and the corresponding animation facilities. As an example the dynamical analysis of a van is shown including the choice of optimal suspension parameters...|$|R
40|$|The {{design of}} {{automotive}} systems using simulation tools <b>features</b> <b>cost</b> reduction and quality enhancement. This paper presents two basic approaches. The rust approach {{deals with the}} application of CAD data bases to the evaluation of input data for multibody system formalisms, most adequate for automotive system modeling. An object oriented data model for multibody systems is presented. The second approach covers {{the development of an}} integrated simulation tool for automotive vehicles and the corresponding animation facilities. Driving comfort is related to the human perception of mechanical vibration. A companion paper deals with the optimization of automobile parameters using the multi body systems approach...|$|R
5000|$|Criticality of a subsystem, {{function}} or <b>feature,</b> {{including the}} <b>cost</b> of failure ...|$|R
5000|$|Whether a <b>feature</b> {{affects the}} <b>cost</b> or {{quality of the}} product; or ...|$|R
3000|$|In this section, {{we first}} {{describe}} {{the method of}} learning the hierarchical features of a given stereo pair and then describe how these features are used to define our <b>feature</b> matching <b>cost</b> E [...]...|$|R
40|$|Abstract: The {{purpose of}} the study is to {{determine}} how much time is spent maintaining and improving parks in the Willamalane park district controlling for explicit park attributes. In using this information, the study attempts to specify how much each park <b>feature</b> <b>costs</b> and, consequently, finds the cost of a park in its entirety. Results will inform Willamalane Parks as to how their resources are being utilized and will help them in minimizing maintenance costs by choosing the most cost effective amenities to include in future parks. Lastly, this project takes on the task of finding ways in which data collection techniques can be improved and makes suggestions to Willamalane...|$|R
40|$|We study a {{classification}} problem where each feature can be acquired for a cost {{and the goal}} is to optimize the trade-off between classification precision and the total <b>feature</b> <b>cost.</b> We frame the problem as a sequential decision-making problem, where we classify one sample in each episode. At each step, an agent can use values of acquired features to decide whether to purchase another one or whether to classify the sample. We use vanilla Double Deep Q-learning, a standard reinforcement learning technique, to find {{a classification}} policy. We show that this generic approach outperforms Adapt-Gbrt, currently the best-performing algorithm developed specifically for classification with costly features...|$|R
5000|$|Google's {{homepage}} {{includes a}} button labeled [...] "I'm Feeling Lucky". Prior {{to a change}} in 2012, when a user typed in a search and clicked on the button the user would be taken directly to the first search result, bypassing the search engine results page. The idea was that if a user is [...] "feeling lucky", the search engine would return the perfect match the first time without having to page through the search results. According to a study by Tom Chavez of [...] "Rapt", this <b>feature</b> <b>cost</b> Google $110 million a year as 1% of all searches use this feature and bypass all advertising.|$|R
5000|$|If {{the seller}} selects this method then the item {{will be at}} the top of the {{relevant}} section for 30 days. <b>Featured</b> listings <b>cost</b> from zero to 1.00 in a seller's local currency, however the final value fee is zero ...|$|R
40|$|We seek {{decision}} {{rules for}} prediction-time cost reduction, where complete data {{is available for}} training, but during prediction-time, each feature can only be acquired for an additional cost. We propose a novel random forest algorithm to min-imize prediction error for a user-specified aver-age feature acquisition budget. While random forests yield strong generalization performance, they do not explicitly account for <b>feature</b> <b>costs</b> and furthermore require low correlation among trees, which amplifies costs. Our random for-est grows trees with low acquisition cost and high strength based on greedy minimax cost-weighted-impurity splits. Theoretically, we es-tablish near-optimal acquisition cost guarantees for our algorithm. Empirically, {{on a number of}} benchmark datasets we demonstrate compet-itive accuracy-cost curves against state-of-the-art prediction-time algorithms. 1...|$|R
40|$|Abstract. In most {{real-world}} {{information processing}} problems, data {{is not a}} free resource; its acquisition is rather time-consuming and/or ex-pensive. We investigate how these two factors can be included in super-vised classification tasks by deriving classification as a sequential decision process and making it accessible to Reinforcement Learning. Our method performs a sequential feature selection that learns which features are most informative at each timestep, choosing the next feature depending on the already selected features and the internal belief of the classifier. Experiments on a handwritten digits classification task show significant reduction in required data for correct classification, while a medical di-abetes prediction task illustrates variable <b>feature</b> <b>cost</b> minimization as a further property of our algorithm...|$|R
