1133|10000|Public
5|$|Hermann Schoemann {{patrolled the}} Skagerrak to inspect neutral {{shipping}} for contraband goods in October. The ship attempted {{to lay a}} minefield off the British coast {{on the night of}} 12/13 November, with two of her sisters, but had to turn back after she and Z6 Theodor Riedel suffered machinery breakdowns. She made another attempt on the night of 18 December to mine the Humber estuary, together with two other destroyers, but the German ships had to abandon the sortie when they could not pinpoint their location with the required <b>degree</b> <b>of</b> <b>precision.</b> While patrolling in the Jade estuary on 23 December, she collided with her sister Z15 Erich Steinbrinck in a heavy fog. Hermann Schoemann covered minelaying sorties in January and February 1940, but spent most of March under repair for machinery problems.|$|E
5|$|The {{method of}} {{construction}} is fairly well understood by historians. The {{patron of the}} aqueduct– a rich individual or the city of Nîmes itself– would have hired a large team of contractors and skilled labourers. A surveyor or mensor planned the route using a groma for sighting, the chorobates for levelling, {{and a set of}} measuring poles five or ten Roman feet long. His figures and perhaps diagrams were recorded on wax tablets, later to be written up on scrolls. The builders may have used templates to guide them with tasks that required a high <b>degree</b> <b>of</b> <b>precision,</b> such as carving the standardised blocks from which the water conduit was constructed.|$|E
25|$|He {{was also}} {{responsible}} {{for the construction of}} the gasometer, an expensive instrument he used at his demonstrations. While he used his gasometer exclusively for these, he also created smaller, cheaper, more practical gasometers that worked with a sufficient <b>degree</b> <b>of</b> <b>precision</b> that more chemists could recreate.|$|E
50|$|Models {{encompass}} a {{wide range}} <b>of</b> <b>degrees</b> <b>of</b> <b>precision</b> and engineering: some models such as J.D. Bernal's water are conceptual, while the macromodels of Pauling and Crick and Watson were created with much greater precision.|$|R
50|$|This {{would have}} been an {{improvement}} over the High Precision Parallax Collecting Satellite (Hipparcos) which operated 1989-1993 and produced various star catalogs. Astrometric parallax measurements form part of the cosmic distance ladder, and can also be measured by other Space telescopes such as Hubble (HST) or ground-based telescopes to varying <b>degrees</b> <b>of</b> <b>precision.</b>|$|R
40|$|A {{boundary}} type quadrature formula (BTQF) is {{an approximate}} integration formula {{with all its}} of evaluation points lying on the Boundary of the integration domain. This type formulas are particularly useful for the cases when {{the values of the}} integrand functions and their derivatives inside the domain are not given or are not easily determined. In this paper, we will establish the BTQFs over sonic axially symmetric regions. We will discuss time following three questions in the construction of BTQFs: (i) What is the highest possible <b>degree</b> <b>of</b> algebraic <b>precision</b> <b>of</b> the BTQF if it exists? (ii) What is the fewest number of time evaluation points needed to construct a BTQF with the highest possible <b>degree</b> <b>of</b> algebraic <b>precision?</b> (in) How to construct the BTQF with the fewest evaluation points and the highest possible <b>degree</b> <b>of</b> algebraic <b>precision...</b>|$|R
25|$|Characterizing the {{accuracy}} of test scores is perhaps the central issue in psychometric theory and is a chief difference between IRT and CTT. IRT findings reveal that the CTT concept of reliability is a simplification. In the place of reliability, IRT offers the test information function which shows the <b>degree</b> <b>of</b> <b>precision</b> at different values of theta, θ.|$|E
25|$|There {{are various}} methods for {{generating}} screw threads. The method chosen {{for any one}} application is chosen based on constraints—time, money, <b>degree</b> <b>of</b> <b>precision</b> needed (or not needed), what equipment is already available, what equipment purchases could be justified based on resulting unit price of the threaded part (which depends on how many parts are planned), etc.|$|E
25|$|Informally, non-terminating {{decimals}} {{are easily}} understood, {{because it is}} clear that a real number can be approximated to any required <b>degree</b> <b>of</b> <b>precision</b> by a terminating decimal. If two decimal expansions differ only after the 10th decimal place, they are quite close to one another; and if they differ only after the 20th decimal place, they are even closer.|$|E
50|$|GEOREF {{is based}} on the {{standard}} system of latitude and longitude, but uses a simpler and more concise notation. GEOREF divides the Earth's surface into successively smaller quadrangles, with a notation system used to identify each quadrangle within its parent. Unlike latitude/longitude, GEOREF runs in one direction horizontally, east from the 180° meridian; and one direction vertically, north from the South Pole. GEOREF can easily be adapted to give co-ordinates with varying <b>degrees</b> <b>of</b> <b>precision,</b> using a 2-12 character geocode.|$|R
40|$|Actuator {{placement}} in adaptive truss structures is {{to cater to}} two needs: displacement control <b>of</b> <b>precision</b> points and preloading the elements to overcome joint slackness. Due to technological and financial considerations, the number of actuators available is {{much less than the}} <b>degrees</b> <b>of</b> freedom <b>of</b> <b>precision</b> points to be controlled and the <b>degree</b> <b>of</b> redundancy of the structure. An approach for optimal actuator location is outlined. Test cases to demonstrate the effectiveness of the scheme are applied to the Precision Segmented Reflector Truss...|$|R
40|$|This article reports {{some results}} on this {{correlation}} {{in the context}} of logic programs. A formal notion of the "precision" of an analysis algorithm is proposed, and this is used to characterize the worst-case computational complexity of a number of dataflow analyses with different <b>degrees</b> <b>of</b> <b>precision.</b> While this article considers the analysis of logic programs, the technique proposed, namely the use of "exactness sets" to study relationships between complexity and <b>precision</b> <b>of</b> analyses, is not specific to logic programming in any way, and is equally applicable to flow analyses of other language families...|$|R
25|$|The high {{specificity}} of meganucleases {{gives them a}} high <b>degree</b> <b>of</b> <b>precision</b> and much lower cell toxicity than other naturally occurring restriction enzymes. Meganucleases were identified in the 1990s, and subsequent work has shown that they are particularly promising tools for genome engineering and gene editing, as {{they are able to}} efficiently induce homologous recombination, generate mutations, and alter reading frames.|$|E
25|$|The {{accuracy}} of an analog computer {{is limited by}} its computing elements as well as quality of the internal power and electrical interconnections. The precision of the analog computer readout was limited chiefly by the precision of the readout equipment used, generally three or four significant figures. The precision of a digital computer {{is limited by the}} word size; arbitrary-precision arithmetic, while relatively slow, provides any practical <b>degree</b> <b>of</b> <b>precision</b> that might be needed.|$|E
25|$|The {{utility of}} a model will be given, at least in part, by the degree of {{accuracy}} and precision of the model. An accurate model with relatively poor precision could be useful to study the evolutionary relationships between the structures {{of a set of}} proteins, whereas the rational drug design requires both precise and accurate models. A model that is not accurate, regardless of the <b>degree</b> <b>of</b> <b>precision</b> with which it was obtained will not be very useful.|$|E
40|$|There exists an {{opportunity}} to study the manufacturing process of protruding features {{for the purpose of}} polymer mold fabrication at the micro-scale. An experiment is planned using Taguchi DOE methods to fabricate micro-scale positive features by varying size, spindle speed and spindle direction. Data will be collected on feature accuracy, and used to further refine the experiment in an effort to produce a precise, accurate, micro feature. Results and knowledge gained herein will be extended to features of greater complexity, requiring increasing <b>degrees</b> <b>of</b> <b>precision...</b>|$|R
40|$|This paper {{describes}} how building designers {{make sense of}} the sky and modern visualizationtechniques for representing them. The dialectic approach addresses technological innovation withrespect to existing social practices. This is done for two reasons ? to illustrate where practices are andhow they can be extended with innovative technologies. It is shown that building designers maintainvarious levels of expertise for managing daylight design. Visualization prototypes are introduced alsowith different <b>degrees</b> <b>of</b> <b>precision.</b> The paper concludes with implications for the development ofdesign tools and use by building designers...|$|R
40|$|Two {{conceptual}} {{developments in}} the Bayesian automatic adaptive quadrature approach to the numerical solution of one-dimensional Riemann integrals [Gh. Adam, S. Adam, Springer LNCS 7125, 1 – 16 (2012) ] are reported. First, it is shown that the numerical quadrature which avoids the overcomputing and minimizes the hidden floating point loss <b>of</b> <b>precision</b> asks for the consideration of three classes of integration domain lengths endowed with specific quadrature sums: microscopic (trapezoidal rule), mesoscopic (Simpson rule), and macroscopic (quadrature sums <b>of</b> high algebraic <b>degrees</b> <b>of</b> <b>precision).</b> Second, sensitive diagnostic tools for the Bayesian inference on macroscopic ranges, coming {{from the use of}} Clenshaw-Curtis quadrature, are derived...|$|R
25|$|For most capacitors, a {{physically}} conditioned dielectric strength or a breakdown voltage usually could be specified for each dielectric material and thickness. This {{is not possible}} with ceramic capacitors. The breakdown voltage of a ceramic dielectric layer may {{vary depending on the}} electrode material and the sintering conditions of the ceramic up to a factor of 10. A high <b>degree</b> <b>of</b> <b>precision</b> and control of process parameters is necessary to keep the scattering of electrical properties for today's very thin ceramic layers within specified limits.|$|E
25|$|The {{experience}} of the War of 1812 led the War Department to issue a request for contract proposals for firearms with interchangeable parts. Previously, parts from each firearm had to be carefully custom fitted; almost all infantry regiments necessarily included an artificer or armorer who could perform this intricate gunsmithing. The requirement for interchangeable parts forced forward the development of modern metal-working machine tools, including milling machines, grinders, shapers and planers. The Federal Armories perfected the use of machine tools by developing fixtures to correctly position the parts being machined and jigs to guide the cutting tools over the proper path. Systems of blocks and gauges were also developed to check the accuracy and precision of the machined parts. Developing the manufacturing techniques for making interchangeable parts by the Federal Armories took over two decades; however, the first interchangeable small arms parts were not made to a high <b>degree</b> <b>of</b> <b>precision.</b> It wasn't until mid century or later that parts for U.S. rifles and handguns could be considered truly interchangeable with a <b>degree</b> <b>of</b> <b>precision.</b> In 1853 when the British Parliamentary Committee on Small Arms questioned gun maker Samuel Colt, and machine tool makers James Nasmyth and Joseph Whitworth, there was still some question about what constituted interchangeability and whether it could be achieved at a reasonable cost.|$|E
25|$|Carbon dioxide (CO2) {{emissions}} from the combustion of fuel {{can be estimated}} {{with a high degree}} of certainty regardless of how the fuel is used as these emissions depend almost exclusively on the carbon content of the fuel, which is generally known with a high <b>degree</b> <b>of</b> <b>precision.</b> The same is true for sulphur dioxide (SO2), since sulphur contents of fuels are also generally well known. Both carbon and sulphur are almost completely oxidized during combustion and all carbon and sulphur atoms in the fuel will be present in the flue gases as CO2 and SO2 respectively.|$|E
40|$|Includes bibliographical {{references}} (pages 54 - 57) The {{purposes of}} this study were (1) to evaluate the effects of social class on the achievement of tenth grade home economics students, and (2) to discover the effects on pupil performance of the use <b>of</b> varying <b>degrees</b> <b>of</b> <b>precision</b> in statements <b>of</b> instructional objectives. The sample consisted of 21. 3 students enrolled in tenth grade clothing classes at four high schools in Los Angeles City Unified School district representing culturally advantaged and culturally disadvantaged school populations. (See more in text. ...|$|R
40|$|This paper {{reports on}} a system for {{browsing}} and searching image collections on small-screen devices. The system design was informed by our studies of how people organize and access image collections on desktop computers. The final system was evaluated in a user study where users had to search for images with varying <b>degrees</b> <b>of</b> <b>precision</b> {{about what they were}} searching for. We discovered that individual users adopt a wide variety of search strategies and that future image management tools must support users through a wide variety of interaction techniques...|$|R
40|$|This article {{presents}} the formal results {{obtained from the}} same project, defined at the initial stage, modeled in three different CAD systems, exported and prototyped in {{two different types of}} three-dimensional printer. These digital systems have varying <b>degrees</b> <b>of</b> <b>precision,</b> can result in rapid prototyping different from the original virtual model, and this could frustrate the user's initial expectations, due to the need of modeling rework. The proper use of these tools can be helpful, {{since the beginning of the}} design process, with quick and reliable information, regarding the formal intent of the architect...|$|R
25|$|As Primary Urban Areas {{were created}} to allow {{statistical}} comparisons, {{and the majority of}} statistics are produced based on administrative or electoral geographies, Primary Urban Areas are approximated to local authority and ward level, or to an additional measure called a tract - similar in size to a ward but designed to be subject to fewer revisions over time. It is for these approximate areas that statistics are available. Wards and tracts, being smaller, allow a greater <b>degree</b> <b>of</b> <b>precision</b> in comparing PUAs, but using local authority-based definitions allow PUA comparisons to be made using the wider range of statistics available at this level.|$|E
25|$|The cairns {{fell into}} disuse after about 2500 BC, but the lunar astronomical {{tradition}} {{reflected in their}} structures {{appears to have been}} transferred east to the Neolithic farmers of central Aberdeenshire. The gradation in height of the stone rings at Clava is replicated in the recumbent stone circles which appeared across Aberdeenshire during the late Neolithic and early Bronze Age, from around 2700–2000 BC. Their alignment with the southern moon is more precise than that of the Clava cairns; whereas the cairns encompass the entire arc of the moon, the orientation of most of the recumbent stones focuses on a much shorter arc. The <b>degree</b> <b>of</b> <b>precision</b> is limited, however, and the circles were clearly not observatories nor meant for precise knowledge of the moon's movements.|$|E
25|$|Closely {{following}} the derivation of Black and Scholes, John Cox, Stephen Ross and Mark Rubinstein developed {{the original version}} of the binomial options pricing model. It models {{the dynamics of the}} option's theoretical value for discrete time intervals over the option's life. The model starts with a binomial tree of discrete future possible underlying stock prices. By constructing a riskless portfolio of an option and stock (as in the Black–Scholes model) a simple formula can be used to find the option price at each node in the tree. This value can approximate the theoretical value produced by Black Scholes, to the desired <b>degree</b> <b>of</b> <b>precision.</b> However, the binomial model is considered more accurate than Black–Scholes because it is more flexible; e.g., discrete future dividend payments can be modeled correctly at the proper forward time steps, and American options can be modeled as well as European ones. Binomial models are widely used by professional option traders. The Trinomial tree is a similar model, allowing for an up, down or stable path; although considered more accurate, particularly when fewer time-steps are modelled, it is less commonly used as its implementation is more complex.|$|E
40|$|This paper {{discusses}} {{the application of}} the equilibrium displacement model (EDM) to estimate ex-ante the welfare effects of biological productivity growth for semi-subsistence crop and its impact on poverty reduction. The conventionally used EDM is compared with an alternative EDM that reflects more realistic assumptions for African semi-subsistence crops, such as the shape and shift of supply curve, significant margins due to high transportation costs between farmgate and consumption market, as well as between different consumption markets, and the <b>degree</b> <b>of</b> <b>precisions</b> <b>of</b> estimated structural parameters. The application to the dataset for Benin cassava farmers provides an example that the conventional EDM may significantly overestimate the total welfare gains, and may also lead to very different interpretation of how pro-poor the technology is. Discussion paperNon-PRIFPRI 1; GRP 32 DSG...|$|R
50|$|Different {{amounts of}} memory {{are used to}} store data values with {{different}} <b>degrees</b> <b>of</b> <b>precision.</b> The commonly used sizes are usually a power of two multiple of the unit of address resolution (byte or word). Converting the index of an item in an array into {{the address of the}} item then requires only a shift operation rather than a multiplication. In some cases this relationship can also avoid the use of division operations. As a result, most modern computer designs have word sizes (and other operand sizes) that are a power of two times the size of a byte.|$|R
40|$|We {{study the}} impact of team-based {{performance}} pay in a major UK government agency, the public employment service. The scheme covered quantity and quality targets, measured with varying <b>degrees</b> <b>of</b> <b>precision.</b> We use unique data from the agency’s performance management system and personnel records, linked to local labour market data. We show that on average the scheme had no significant effect but had a substantial positive effect in small teams, fitting an explanation combining free riding and peer monitoring. We also show that the impact was greater on better-measured quantity outcomes than quality outcomes. The scheme was very cost effective in small offices...|$|R
500|$|Most of {{the graves}} {{were laid out}} in a highly ordered fashion with a double row on the north and south sides. Each grave was set [...] apart on an east–west axis and [...] apart north to south. None were intercut. They were {{arranged}} in a pattern that formed a square enclosure, with a gap in the southern side forming a main entrance and another smaller gap on the eastern side forming a secondary entrance or exit. The <b>degree</b> <b>of</b> <b>precision</b> visible in the layout strongly suggests that the cemetery was planned in advance.|$|E
500|$|The wooden {{track is}} {{approximately}} [...] {{in length and}} {{the height of the}} lift is approximately [...] El Toro is very different from a traditional wooden roller coaster because it uses prefabricated wooden track. It was built and designed by Intamin but they also worked with members of Rocky Mountain Construction to build the ride. Instead of carpenters cutting, shaping, and laying down the track on site by hand, the track is laser cut in a factory. This means that the track is manufactured to a higher <b>degree</b> <b>of</b> <b>precision</b> than could be achieved by hand. The [...] "Plug and Play" [...] aspect of the coaster speeds construction of the coaster since track {{does not have to be}} completely manufactured on site. [...] In addition, because of the speed of construction, the costs of building the coaster are lowered due to fewer man-hours spent on the construction. [...] The riders are subject to a coaster that is as smooth as steel. El Toro is the first Intamin [...] "Plug and Play" [...] wooden roller coaster in the United States and one of four in the world. The other three are Colossos at Heide Park in Germany, Balder at Liseberg in Sweden, and T Express at Everland in South Korea.|$|E
2500|$|Modern science {{indicates}} {{various ways}} in which genetics, diet, and lifestyle affect human longevity. [...] It also allows us to determine the age of human remains with a fair <b>degree</b> <b>of</b> <b>precision.</b>|$|E
5000|$|... can {{understand}} {{and participate in}} any conversations {{within the range of}} own personal and professional experience with a high <b>degree</b> <b>of</b> fluency and <b>precision</b> <b>of</b> vocabulary ...|$|R
40|$|Bayesian {{methods have}} the {{potential}} for increasing power in mediation analysis (Koopman, Howe, Hollenbeck, & Sin, 2015; Yuan & MacKinnon, 2009). This article compares the power of Bayesian credibility intervals for the mediated effect to the power of normal theory, distribution of the product, percentile, and bias-corrected bootstrap confidence intervals at N ≤ 200. Bayesian methods with diffuse priors have power comparable to the distribution of the product and bootstrap methods, and Bayesian methods with informative priors had the most power. Varying <b>degrees</b> <b>of</b> <b>precision</b> <b>of</b> prior distributions were also examined. Increased precision led to greater power only when N ≥ 100 and the effects were small, N < 60 and the effects were large, and N < 200 and the effects were medium. An empirical example from psychology illustrated a Bayesian analysis of the single mediator model from prior selection to interpreting results...|$|R
50|$|Ferenc Csentery (December 29, 1937 - November 7, 2014) was an {{abstract}} metal sculptor {{known for his}} conceptual work related {{to the emergence of}} the US Space Program in the 1960s. He was particularly known for the high <b>degree</b> <b>of</b> technical <b>precision</b> <b>of</b> the machining and welding in his sculpture.|$|R
