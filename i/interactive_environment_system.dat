2|10000|Public
40|$|We {{present the}} {{development}} of an <b>Interactive</b> <b>Environment</b> <b>System</b> (IES). The IES is used for simulating Cell-DEVS models built in CD++ that interact with a Building Information Modeling(BIM) system using Autodesk Revit architecture and Autodesk 3 ds Max. CD++ is a modeling and simulation tool that was created to study complex systems by using a discrete event cell-based approach. It was successfully employed to define a variety of models for complex applications using a cell-based approach. The system developed has a highly modular collection of software packages designed to facilitate the creation of device independent simulation for BIM. The integration of the proposed system is investigated via the simulation of Diffusion Limited Aggregation (DLA) which represents the growth of mold in a building wall. The results affirmed the potential of the (IES) system for interactive simulation application. 1...|$|E
40|$|Recent years, {{with the}} rapid {{development}} of ICT (Information and Communication Technology) technology, {{there are more and}} more applications which can provide users with different styles of indirect communication over the internet to socially connect people more closely. As typical applications, for examples, SNS (Social Network Service) of Facebook, Twitter, and E-mail, VoIP (Voice over Internet Protocol), blog and so on can be mentioned. However, the traditional communication style which users can get face-to-face communication at same space in real time is still the most effective communication method to contribute users ' socially relationship. Therefore, recent years {{there are more and more}} applications which can induce users from indirect communication over internet into direct communication in real world. As a typical example, Facebook Places can be mentioned. However, these applications are not able to provide users with feelings of direct communication in real world through the network virtual space yet. In our research, we focused on two of real world space-time elements sharing problems. First problem is that remote user can hardly share local user's real-time motion, second problem is that remote user can hardly get space interactivity with local space. Based on the two problems above, we designed and built a mixed reality <b>interactive</b> <b>environment</b> <b>system</b> called HYBRIDi. Through proposed system we solved the above two problems, and successfully provided more real world space-time elements into users ' virtual world communications. Keywords-component; Mixed reality; 3 D virtual;Avatar I...|$|E
40|$|The {{application}} of information retrieval techniques in <b>interactive</b> <b>environments</b> requires <b>systems</b> capable of efficiently processing vague queries. To reach reasonable response times, new data structures and algorithms {{have to be}} developed. In this paper we describe an approach {{taking advantage of the}} conditions of interactive usage and special access paths. To have a reference we investigate text queries and compared our algorithms to the well known "Buckley/Lewit" algorithm. We achieved significant improvements for the response times...|$|R
5000|$|The {{game has}} {{a total of}} 10 {{missions}} or levels, and around 14 types of enemies. The game's mechanics allow for an <b>interactive</b> <b>environment,</b> a hacking <b>system,</b> and a [...] "bullet time" [...] system. It primarily features traditional first-person shooter gameplay interspersed with basic puzzle solving involving the hacking system or locating objects.|$|R
40|$|How {{does the}} public {{participate}} in environment matters to influence {{decisions that affect}} their own environment? There are two existing theories supporting the public’s participation in environment matters. However, they emphasize the certainty of the public’s participation in environment matters. The real problems that the public facing during their participation in environment matters and their practical needs lack of resolutions and responses. The way to figure out these problems is to put forward theoretical framework for the public’s participation in environment matters so that {{to set up an}} <b>interactive</b> <b>environment</b> law <b>system</b> that can reflect action subjects’ initiatives. Key words: Public participation; Certainty; Institutionalization</p...|$|R
40|$|We {{have created}} an {{automatic}} cinematography <b>system</b> for <b>interactive</b> virtual <b>environments.</b> This <b>system</b> controls a virtual camera and lights in a three-dimensional virtual world inhabited {{by a group of}} autonomous and user-controlled characters. By dynamically changing the camera and the lights, our system facilitates the interaction of human participants with this world and displays the emotional content of the digital scene. Building o...|$|R
40|$|In this paper, {{we present}} a new multi-screen <b>interactive</b> <b>environment.</b> The <b>system</b> {{extracts}} a silhouette of the participant for driving the interaction using a method that overcomes the inherent problems associated with traditional chroma-keying, background subtraction, and rear-light projection methods. We present an approach for generating a robust silhouette of the participant using specialized infrared lighting while not making the underlying technology apparent to those interacting within the system. The design also enables video projection screens {{to be placed in}} front of and behind the user without interfering with the silhouette extraction process. The framework itself is a portable system which can act as a re-usable infrastructure for many interactive projects. 1 Introduction When designing <b>interactive</b> <b>environments,</b> it's imperative for the system to be engaging as well as be reliably "aware" of the person (or people) interacting within the space. Many installations are design [...] ...|$|R
40|$|Micro PL/CS is {{a version}} of PL/CS {{developed}} for a single-user, <b>interactive</b> <b>environment.</b> A file <b>system</b> extension makes PL/CS self-sufficient for standalone file processing and secondary storage management. The basis of the file system extension is the Unrestricted File Organization which provides a free mixture of sequential, indexed and random file operations. The structure, operation, and system-interfaced procedures of the UFO are presented and explained. The Micro-PL/CS file extension implementation is then sketched {{in terms of the}} UFO primitives...|$|R
40|$|This paper {{presents}} {{important issues}} on the design and implementation of a Multimedia Digital Classroom (MDC) system with its applications. The MDC system is implemented in Java language. It aims at providing important tools to support a distributed <b>interactive</b> education <b>environment.</b> The <b>system</b> consists of a classroom manager and some powerful teaching application tools. The classroom manager is a sharing system with a database. The teaching application tool...|$|R
40|$|The {{application}} of information retrieval techniques in <b>interactive</b> <b>environments</b> require <b>systems</b> capable of efficiently processing vague queries. To reach reasonable response times, new data structures and algorithms {{have to be}} developed. In this paper we describe an approach {{taking advantage of the}} conditions of interactive usage and special access paths. To have a reference we investigate text queries and compared our algorithms to the well known Buckley/Lewit algorithm. We achieved significant improvements for the response times. 1 Introduction Information retrieval deals with information systems for vague queries and imprecise data. In text retrieval, imprecision is caused by the limited capabilities of a system for representing text content. Due to the implicit imprecision and vagueness of natural language, text queries are always vague. But even for fact retrieval, there also often is a need for vagueness. If we have a system containing texts as well as facts, then we would like [...] ...|$|R
40|$|<b>Interactive</b> {{simulation}} <b>environments</b> are <b>systems</b> {{that combine}} simulation, data presentation and interaction capabilities that together allow users {{to explore the}} results of computer simulation processes and in- uence the course of these simulations at run-time. The goal of these <b>interactive</b> <b>environments</b> is to shorten experimental cycles, decrease the cost of system resources and enhance the researcher's abilities for the exploration of data sets or problem spaces. The conceptual idea of allowing users to interactively steer a computation while it is running is not new and examples of applications that benet from it are abundant. However, very often these applications provide ad hoc solutions that are very specic to the problem at hand. This paper investigates {{the issues that are}} involved with building an <b>interactive</b> computational steering <b>environment</b> in an attempt to improve the synergy between computational simulation and interactive exploration through a generalised a [...] ...|$|R
40|$|In a {{mixed reality}} installation, {{a variety of}} {{technologies}} is integrated such as virtual reality, augmented reality, and animated virtual agents and robotic agents. One of the main challenges is how to design and implement a mixed reality installation that integrates a heterogeneous array of sensors and actuators, immersive <b>interactive</b> <b>environments</b> into aware <b>system</b> that will engage the user, providing a meaningful experience. In this paper we address the problems of building a CAVE environment in mixed reality installations, and share our experience in using a game engine as the driver for the CAVE, and in interfacing the game engine with sensors, actuators and input devices...|$|R
40|$|Abstract Internet-based {{real-time}} collaborative programming allows physically dispersed programmers to concurrently and collaboratively design, code, test, debug {{and document}} the same program. This technology {{is more and}} more demanded in nowadays software development. In this paper, we present an overview of the RECIPE (REal-time Collaborative <b>Interactive</b> Programming <b>Environment)</b> prototype <b>system,</b> which was developed to serve as a vehicle to motivate and evaluate our {{research in the area of}} Internet-based real-time collaborative programming environments. A working scenario is used to illustrate Internet-based real-time collaborative programming with the support of the RECIPE prototype system. I...|$|R
40|$|I {{have created}} an {{automatic}} cinematography system for an <b>interactive</b> virtual <b>environment.</b> This <b>system</b> controls a virtual camera and several virtual lights in a three-dimensional "world" inhabited {{by a group of}} autonomous and user-controlled characters. The virtual camera chooses the perspective from which the world is displayed on a flat screen. The lights control how the three-dimensional digital objects in the world are illuminated. By dynamically changing the camera and the lights, my system facilitates the interaction of humans with this world and displays the emotional content of the digital scene...|$|R
40|$|We {{present a}} multicamera {{real-time}} 3 D modeling system that aims at enabling new immersive and <b>interactive</b> <b>environments.</b> This <b>system,</b> called Grimage, allows to retrieve in real-time a 3 D mesh {{of the observed}} scene {{as well as the}} associated textures. This information enables a strong visual presence of the user into virtual worlds. The 3 D shape information is also used to compute collisions and reaction forces with virtual objects, enforcing the mechanical presence of the user in the virtual world. The innovation is a fully integrated system with both immersive and interactive capabilities. It embeds a parallel version of the EPVH modeling algorithm inside a distributed vision pipeline. It also adopts the hierarchical component approach of the FlowVR middleware to enforce software modularity and enable distributed executions. Results show high refresh rates and low latencies obtained by taking advantage of the I/O and computing resources of PC clusters. The applications we have developed demonstrat...|$|R
40|$|Copyright © 2010 Benjamin Petit et al. This is an {{open access}} articledistributedundertheCreativeCommonsAttributionLicense, which permits {{unrestricted}} use, distribution, and reproduction in any medium, provided the original work is properly cited. We present a multicamera real-time 3 D modeling system that aims at enabling new immersive and <b>interactive</b> <b>environments.</b> This <b>system,</b> called Grimage, allows to retrieve in real-time a 3 D mesh of the observed scene {{as well as the}} associated textures. This information enables a strong visual presence of the user into virtual worlds. The 3 D shape information is also used to compute collisions and reaction forces with virtual objects, enforcing the mechanical presence of the user in the virtual world. The innovation is a fully integrated system with both immersive and interactive capabilities. It embeds a parallel version of the EPVH modeling algorithm inside a distributed vision pipeline. It also adopts the hierarchical component approach of the FlowVR middleware to enforce software modularity and enable distributed executions. Results show high refresh rates and low latencie...|$|R
40|$|This paper {{addresses}} {{the role of}} Artificial Intelligence (AI) {{in a variety of}} game genres. Every game aims to entertain (though educational games have secondary objectives). Each genre approaches entertainment in a unique way. We explore the methods used to draw the game player’s attention. We then consider how the AI interacts with the player to promote both entertainment and an <b>interactive</b> <b>environment.</b> We also consider some of the techniques that will shape tomorrow’s games. Included are opponent strategies, <b>interactive</b> <b>environments,</b> and multiagent <b>systems</b> (MAS). While different, each approach can aid in creating more immersive and challenging gaming experiences. Our goal is to create an AI opponent that is not only a capable opponent but also reacts to and improves with player. We consider what elements are necessary to create an opponent capable of creative use of its environment. The game environment, too, is extremely important in creating an immersive experience. Finally, we consider the possibility of creating games that include emergent behavior and multiagent systems. 1...|$|R
40|$|Applications of Virtual Environments (VEs) {{are rapidly}} {{becoming}} {{more complex and}} interactive. They are not restricted to tasks that are solely perceptual in nature; rather, they involve both perception and action {{on the part of}} the user. With this increased complexity comes a host of problems relating to the user interface (UI) of such systems. Researchers have produced a body of work on displays, input devices, and other hardware, but very few guidelines have been suggested for user interface software in 3 D VEs. In this paper, we discuss the usage and implementation of constraints, a fundamental principle for desktop user interfaces, in highly <b>interactive</b> virtual <b>environment</b> <b>systems.</b> Our claims are supported with examples from the literature and from our own experience with the Conceptual Design Space (CDS) application. INTRODUCTION Virtual environments (VEs) and virtual reality (VR) hold great promise for a wide variety of applications in business, industry, education, and entertai [...] ...|$|R
40|$|International audienceWe {{present a}} multicamera {{real-time}} 3 D modeling system that aims at enabling new immersive and <b>interactive</b> <b>environments.</b> This <b>system,</b> called Grimage, allows to retrieve in real-time a 3 D mesh {{of the observed}} scene {{as well as the}} associated textures. This information enables a strong visual presence of the user into virtual worlds. The 3 D shape information is also used to compute collisions and reaction forces with virtual objects, enforcing the mechanical presence of the user in the virtual world. The innovation is a fully integrated system with both immersive and interactive capabilities. It embeds a parallel version of the EPVH modeling algorithm inside a distributed vision pipeline. It also adopts the hierarchical component approach of the FlowVR middleware to enforce software modularity and enable distributed executions. Results show high refresh rates and low latencies obtained by taking advantage of the I/O and computing resources of PC clusters. The applications we have developed demonstrate the quality of the visual and mechanical presence with a single platform and with a dual platform that allows telecollaboration...|$|R
40|$|This article {{presents}} the Distributed <b>Interactive</b> Virtual <b>Environment</b> (DIVE) <b>system,</b> a software architecture for the realization {{and implementation of}} wide-area Internet-based multi-user virtual environments. Over the years, DIVE {{has evolved into a}} generic tool that supports a wide range of applications and situations. The article focuses on the networking aspects that allow deployment of multi-user virtual environments on the Internet. Additionally, it presents the palette of programming interfaces and techniques offered by the system. This is highlighted by some example applications. Our experience has proven that DIVE's ability to mix interfaces has made it a system of choice for the implementation of distributed applications...|$|R
40|$|The Distributed <b>Interactive</b> Virtual <b>Environment</b> (DIVE) <b>system</b> is {{a mature}} toolkit {{that has been}} used for {{prototyping}} many collaborative virtual environment (CVE) applications [3]. Until recently, support for immersive systems has been limited to custom support for specific installations and the emphasis has been on broad support for desktop interfaces. Recently we have ported DIVE to the CAVElib ™ environment † and this paper describes application programming support for immersive users and our experience in using wide-area distributed applications involving immersive projection technologies. The resulting toolkit provides a very flexible system with which to build distributed VE applications involving a variety of platforms and interfaces...|$|R
5000|$|Interaction design, often {{abbreviated}} as IxD, is [...] "the {{practice of}} designing <b>interactive</b> digital products, <b>environments,</b> <b>systems,</b> and services." [...] While the digital {{side of this}} statement is true, interaction design is also useful when creating physical (non-digital) products, exploring how a user might interact with it. Common topics of interaction design include design, human-computer interaction, and software development. While interaction design {{has an interest in}} form (similar to other design fields), its main area of focus rests on behavior. Rather than analyzing how things are, interaction design synthesizes and imagines things as they could be. This element of interaction design is what clearly marks IxD as a design field as opposed to a science or engineering field.|$|R
50|$|TDMS is {{developed}} based on 3 principles, flexible and organized file storage, self-scaling hybrid data index, and an <b>interactive</b> post-processing <b>environment.</b> The <b>system</b> in practical, mainly consists of 3 components, data files with essential and relevant Metadata, data finders for organizing and managing data regardless of files formats, and, a software of searching, analyzing and reporting. With Metadata attached to original data files, the data finder can identify different related data files during searches, {{even if they}} are in different file formats. TDMS hence allows researchers to search for data like browsing the Internet. Last but not least, it can adapt to changes and update itself according to the changes, unlike databases.|$|R
40|$|Highly {{accurate}} avatars {{of humans}} promise {{a new level}} of realism in engineering and entertainment applications, including areas such as computer animated movies, computer game development <b>interactive</b> virtual <b>environments</b> and tele-presence. In order to provide high-quality avatars, new techniques for the automatic acquisition and creation are required. A framework for the capture and construction of arbitrary avatars from image data is presented in this paper. Avatars are automatically reconstructed from multiple static images of a human subject by utilizing image information to reshape a synthetic three-dimensional articulated reference model. A pipeline is presented that combines a set of hardware-accelerated stages into one seamless system. Primary stages in this pipeline include pose estimation, skeleton fitting, body part segmentation, geometry construction and coloring, leading to avatars that can be animated and included into <b>interactive</b> <b>environments.</b> The presented <b>system</b> removes traditional constraints in the initial pose of the captured subject by using silhouette-based modification techniques in combination with a reference model. Results can be obtained in near-real time with very limited user intervention...|$|R
40|$|Computer Generated Forces (CGF) are {{software}} agents which {{simulate the}} behaviour of military units or equipment in a distributed <b>interactive</b> simulation <b>environment.</b> Route planning in `realistic' terrain {{is a critical}} task for CGF agents, {{as many of the}} agent's higher-level goals can only be accomplished if the agent is {{in the right place at}} the right time. In this paper we present a new approach to route planning in complex terrains for CGF agents based on searching the space of complete plans. We describe an implementation of these ideas, the salix planner, and report some preliminary results obtained by running the planner on a number of test problems. Our work is also potentially relevant to other applications, e. g. route planning for autonomous vehicles. 1 Route planning in continuous terrains Computer Generated Forces (CGF) are software agents which simulate the behaviour of military units or equipment in a distributed <b>interactive</b> simulation <b>environment.</b> Such <b>systems</b> are becoming [...] ...|$|R
40|$|Educators and {{researchers}} have long {{recognized the importance}} of formative feedback for learning. Formative feedback helps learners understand where they are in a learning process, what the goal is, and how to reach that goal. While experimental and observational research has illuminated many aspects of feedback, modern <b>interactive</b> learning <b>environments</b> provide new tools to understand feedback and its relation to various learning outcomes. Specifically, as learners use tutoring systems, educational games, simulations, and other <b>interactive</b> learning <b>environments,</b> these <b>systems</b> store extensive data that record the learner’s usage traces. The data can be modeled, mined and analyzed to address questions including when is feedback effective, what kinds of feedback are effective, and whether there are individual differences in seeking and using feedback. Such an empirical approach can be valuable on its own, and it may be especially powerful when combined with theory, experimentation or design-based research. The findings create an opportunity to improve feedback in educational technologies and to advance the learning sciences...|$|R
40|$|MCNP{trademark} and LAHET{trademark} {{are two of}} {{the codes}} {{included}} in the LARAMIE (Los Alamos Radiation Modeling <b>Interactive</b> <b>Environment)</b> code <b>system.</b> Both MCNP and LAHET are three-dimensional continuous-energy Monte Carlo radiation transport codes. The capabilities of MCNP and LAHET are currently being merged into one code for the Accelerator Production of Tritium (APT) program at Los Alamos National Laboratory. Concurrently, a significant effort is underway to improve the accuracy of the physics in the merged code. In particular, full nuclear-data evaluations (in ENDF 6 format) for many materials of importance to APT are being produced for incident neutrons and protons up to an energy of 150 -MeV. After processing, cross-section tables based on these new evaluations will be available for use fin the merged code. In order to utilize these new cross-section tables, significant enhancements are required for the merged code. Neutron cross-section tables for MCNP currently specify emission data for neutrons and photons only; the new evaluations also include complete neutron-induced data for protons, deuterons, tritons, and alphas. In addition, no provision in either MCNP or LAHET currently exists for the use of incident charged-particle tables other than for electrons. To accommodate the new neutron-induced data, it was first necessary to expand the format definition of an MCNP neutron cross-section table. The authors have prepared a 150 -MeV neutron cross-section library in this expanded format for 15 nuclides. Modifications to MCNP have been implemented so that this expanded neutron library can be utilized...|$|R
40|$|We {{have created}} an {{automatic}} cinematography <b>system</b> for <b>interactive</b> virtual <b>environments.</b> This <b>system</b> controls a virtual camera and lights in a three-dimensional virtual world inhabited {{by a group of}} autonomous and user-controlled characters. By dynamically changing the camera and the lights, our system facilitates the interaction of human participants with this world and displays the emotional content of the digital scene. Building on the tradition of cinema, modern video games, and autonomous behavior systems, we have constructed this cinematography system with an ethologically-inspired structure of sensors, emotions, motivations, and action-selection mechanisms. Our system breaks shots into elements, such as which actors the camera should focus on or the angle it should use to watch them. Hierarchically arranged cross-exclusion groups mediate between the various options, arriving at the best shot at each moment in time. Our cinematography system uses the same approach that we use fo [...] ...|$|R
40|$|The {{overall goal}} of our {{project is to}} design and build a truly <b>interactive</b> virtual <b>environment</b> (VE) <b>system</b> which {{incorporates}} efficient dynamic simulation and motion planning techniques applicable to complex three-dimensional systems of bodies in contact. In this paper, we investigate various paradigms for enabling a human operator and an automatic motion planner to cooperatively solve a motion planning query. Communication between the operator and the planner is through haptic and visual interfaces. This research {{supported in part by}} NSF CAREER Award CCR- 9624315 (with REU Supplement), NSF Grants IIS- 9619850 (with REU Supplement), EIA- 9805823, and EIA- 9810937, and by the Texas Higher Education Coordinating Board under grant ARP- 036327 - 017. Bayazit is supported in part by the Turkish Ministry of Education. 1 Introduction Motion planning arises in many application domains such as robotics, virtual reality systems, and computeraided design. Algorithms for performing fully automatic m [...] ...|$|R
40|$|I {{have created}} an {{automatic}} cinematography system for an <b>interactive</b> virtual <b>environment.</b> This <b>system</b> controls a virtual camera and several virtual lights in a three-dimensional virtual world inhabited {{by a group of}} autonomous and user-controlled characters. The virtual camera chooses the perspective from which the world is displayed on a flat screen. The lights control how the three-dimensional digital objects in the world are illuminated. By dynamically changing the camera and the lights, my system facilitates the interaction of humans with this world and displays the emotional content of the digital scene. Building on the tradition of cinema, modern video games, and autonomous behavior systems, I have constructed this cinematography system with the same approach that the Synthetic Characters Group uses when developing our virtual characters − an ethologically-inspired structure of sensors, emotions, motivations, and action-selection mechanisms. Using the same approach for all the different elements of our virtual worlds eases the cross-over o...|$|R
40|$|To provide natural user {{interfaces}} to <b>interactive</b> <b>environments,</b> accurate and fast recognition of gestures and expressions is needed. We adopt a viewbased gesture recognition strategy that runs in an unconstrained <b>interactive</b> <b>environment,</b> which uses active vision methods to determine context cuess for the view-based method. Using vision routines already implemented for an <b>interactive</b> <b>environment,</b> we determine the spatial location of salient body parts and guide an active camera to obtain foveated images of gestures or expressions. Face recognition routines {{used to obtain}} {{an estimate of the}} identity of the user, and provide an index into the best set of view templates to use. The resulting system combines low-resolution, user-independent processing with high-resolution, user-specific models, all of which are computed in real time as part of an <b>interactive</b> <b>environment.</b> 1 Introduction Gesture and expression are important interface modalities for <b>interactive</b> <b>environments.</b> Previously, we d [...] ...|$|R
40|$|This paper {{focuses on}} the {{development}} of and experiments with a visualization and telepresence environment that together present an interactive, immersive, and context-preserving display of outdoor information. The developed visualization integrates a variety of types of information about a section of interstate such as aerial photographs, maps, and live outdoor videos into a single <b>interactive</b> <b>environment.</b> The persistence of context in the visualization aids the remote viewer in more easily comprehending and exploring the outdoor space. All the <b>environments</b> <b>systems</b> and algorithms are integrated and are being extensively tested in a real-world ITS application context using several novel testbed...|$|R
40|$|Intelligent <b>Interactive</b> <b>Environments</b> (IIE) are <b>systems</b> {{whose main}} {{features}} are intelligence, interactivity and location. Intelligence {{refers to the}} ability to solve problems in autonomous fashion, interactivity refers to the behaviour and internal states of the system being influenced by – as well as influential on – actions, intentions and goals of users, and location refers to different behaviour occuring by changing locations (aka environments), ceteris paribus. IIE are implemented in a variety of platforms, such as distributed sensors, actuators and processors for Ambient Intelligence, distributed and mobile reasoning entities in Virtual Worlds and Augmented Reality, and distributed, multiuser information systems such as Social Networks and service-oriented systems directed to the dissemination of public services and retailing. In the present article we introduce JamSession, a language to specify and execute workflow choreographies, specially useful for the specification and implementation of the coordination of real-time, multimodal and multimedia activities. JamSession functioning is based on the construction of Knowledge-based Interaction Protocols (KBIP), which are formally grounded and can be formally analysed and verified. KBIP are designed using a straightforward and user-friendly graphical language, and JamSession can be implemented using low computational resources. As a result, we strongly expect JamSession to be an ideal tool for the development of nove...|$|R
40|$|This paper {{describes}} the unencumbered <b>interactive</b> <b>environment</b> “radiomap”. The {{first version of}} this <b>interactive</b> <b>environment</b> enables one or more individuals to walk about a projected photorealistic image of the Earth (Mercator projection[1], 8 x 4 m) and listen to live internet radio broadcasts that are located at the corresponding locations. The interaction is simple and intuitive. This research project is exploring the experiential qualities of <b>interactive</b> <b>environments,</b> especially those that may be described as creating effects of presence, global awareness, holistic overview and feeling of interconnectedness...|$|R
5000|$|<b>Interactive</b> <b>Environments</b> for Teaching-Learning (LTCS Group) http://ltcs.uned.es/index.php/en/ ...|$|R
5000|$|... #Subtitle level 2: Poetry {{hypertext}} and <b>interactive</b> <b>environments</b> online ...|$|R
