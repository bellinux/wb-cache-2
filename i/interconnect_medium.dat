9|34|Public
50|$|Ultrasonic {{microscopy}} uses {{high frequency}} sound waves to image bonded interfaces. Deionized water {{is used as}} the acoustic <b>interconnect</b> <b>medium</b> between the electromagnetic acoustic transducer and the wafer.|$|E
40|$|The {{requirement}} for dense interconnect in artifi-cial neural network systems has led researchers to seek high-density interconnect technologies. This pa-per reports an implementation using multi-chip mod-ules (MCMs) as the <b>interconnect</b> <b>medium.</b> The spe-cific system described is a self-organizing, parallel, and dynamic learning model {{which requires a}} dense inter-connect technology for effective implementation; this requirement is fulfilled by exploiting MCM technology. The ideas {{presented in this paper}} regarding an MCM implementation of artificial neural networks are ver-satile and can be adapted to apply to other neural net-work and connectionist models. ...|$|E
40|$|The {{requirement}} for dense interconnect in {{artificial neural network}} systems has led researchers to seek high-density interconnect technologies. This paper reports an implementation using multi-chip modules (MCMs) as the <b>interconnect</b> <b>medium.</b> The specific system described is a self-organizing, parallel, and dynamic learning model which requires a dense interconnect technology for effective implementation; this requirement is fulfilled by exploiting MCM technology. The ideas {{presented in this paper}} regarding an MCM implementation of artificial neural networks are versatile and can be adapted to apply to other neural network and connectionist models. 1 Introduction Artificial neural networks offer an exciting area of research because of their ability to solve difficult problems, typically those dealing with pattern recognition. This ability is due, in part, to their densely interconnected parallel architecture. However, often neural networks are simulated on sequential computers and lose [...] ...|$|E
40|$|Abstract- As {{network data}} rate {{increases}} rapidly, high-speed signaling circuits for server communication pose many design challenges due to various system requirements using different <b>interconnect</b> <b>mediums.</b> This paper discusses main problems and solutions of high-speed circuits for server interconnect. Then, {{it presents a}} high-speed circuit implementation for such interconnect using 90 nm CMOS technology that achieved data rate at 6. 25 Gbps in a backplane environment. 1...|$|R
50|$|Thick film {{technology}} {{is often used}} as the <b>interconnecting</b> <b>medium</b> for hybrid integrated circuits. The use of screen printed thick film interconnect provides advantages of versatility over thin film although feature sizes may be larger and deposited resistors wider in tolerance. Multi-layer thick film is a technique for further improvements in integration using a screen printed insulating dielectric to ensure connections between layers are made only where required. One key advantage for the circuit designer is complete freedom {{in the choice of}} resistor value in thick film technology. Planar resistors are also screen printed and included in the thick film interconnect design. The composition and dimensions of resistors can be selected to provide desired values. The final resistor value is determined by design and can be adjusted by laser trimming. Once the hybrid circuit is fully populated with components, fine tuning prior to final test may be achieved by active laser trimming.|$|R
40|$|Voltage {{regulation}} in distribution systems is typically {{performed with the}} aid of multiple voltage regulating devices, such as on-load tap changer and step voltage regulators. These devices are conventionally tuned and locally coordinated using Volt/VAR optimization strategies in accordance with the time-graded operation. However, in case of distribution systems with distributed generation (DG), there could be a possibility of simultaneous responses of DG and multiple voltage regulators for correcting the target bus voltage, thereby resulting in operational conflicts. This paper proposes an online voltage control strategy for a realistic distribution system containing a synchronous machine-based renewable DG unit and other voltage regulating devices. The proposed strategy minimizes the operational conflicts by prioritizing the operations of different regulating devices while maximizing the voltage regulation support by the DG. It is tested on an <b>interconnected</b> <b>medium</b> voltage distribution system, present in New South Wales, Australia, through time-domain simulation studies. The results have demonstrated that voltage control for a distribution feeder can effectively be achieved on a real-time basis through the application of the proposed control strategy...|$|R
40|$|LESOP) {{for target}} {{tracking}} in dense wireless sensor networks. A cross-layer design perspective is adopted in LESOP for high protocol efficiency, where direct {{interactions between the}} Application layer and the Medium Access Control (MAC) layer are exploited. Unlike the classical Open Systems Interconnect (OSI) paradigm of communication networks, the Transport and Network layers are excluded in LESOP to simplify the protocol stack. A lightweight yet efficient target localization algorithm is proposed and implemented, and a Quality of Service (QoS) knob is found to control the tradeoff between the tracking error and the network energy consumption. Furthermore, LESOP serves as the first example in demonstrating the migration from the OSI paradigm to the Embedded Wireless Interconnect (EWI) architecture platform, a two-layer efficient architecture proposed here for wireless sensor networks. Index Terms—Application layer, embedded wireless <b>interconnect,</b> <b>medium</b> access control, open systems interconnect, target tracking, wireless sensor networks. I...|$|E
40|$|Cache {{coherent}} non-uniform {{memory access}} (CC-NUMA) multiprocessors {{continue to suffer}} from remote memory access latencies due to comparatively slow memory technology and data transfer latencies in the interconnection network. In this paper, we propose a novel hardware caching technique, called switch cache. The main idea is to implement small fast caches in crossbar switches of the <b>interconnect</b> <b>medium</b> to capture and store shared data as they flow from the memory module to the requesting processor. This stored data acts as a cache for subsequent requests, thus reducing the latency of remote memory accesses tremendously. The implementation of a cache in a crossbar switch needs to be efficient and robust, yet flexible {{for changes in the}} caching protocol. The design and implementation details of a CAche Embedded Switch ARchitecture, CAESAR, using wormhole routing with virtual channels is presented. Using detailed executiondriven simulations, we find that the CAESAR switch cache is capable [...] ...|$|E
40|$|In this paper, {{we propose}} a novel {{hardware}} caching technique, called switch directory, {{to reduce the}} communication latency in CC-NUMA multiprocessors. The main idea is to implement small fast directory caches in crossbar switches of the <b>interconnect</b> <b>medium</b> to capture and store ownership information as the data flows from the memory module to the requesting processor. Using the stored information, the switch directory re-routes subsequent requests to dirty blocks directly to the owner cache, thus reducing the latency for home node processing such as slow DRAM directory access and coherence controller occupancies. The design and implementation details of a DiRectory Embedded Switch ARchitecture, DRESAR, are presented. We explore the performance benefits of switch directories by modeling DRESAR in a detailed execution driven simulator. Our {{results show that the}} switch directories can improve performance by up to 60 % reduction in home node cache-to-cache transfers for several scientific applications and commercial workloads. ...|$|E
40|$|This three-part {{publication}} series {{presents the}} epistemological processes and outcomes {{of an international}} arts-based research project titled Big Blue Ball : Pictures, people, place. The project uses the creative function to investigate the nature of meaning-making. In particular, through collaborative engagement with adversity of cultures, it explores the significance of creativity and creative practice in setting up sites for shared understanding in a contemporary and globally interactive world. The project was developed and carried out by Donna Wright during her PhD Candidature at Southern Cross University, Lismore, Australia, between 2004 and 2007. Making use of practice-led research strategies, and drawing on creative arts practice, the project has exploited the inherent capacity of the creative function to support innovation. The project design offers {{a new model of}} intertextual processes of creativity that opens up spaces for intercultural negotiation, by linking spatial conceptions and processes for semiotic mediations, to multiple, <b>interconnected</b> <b>mediums</b> for the production and reception of new information. This in turn provides a context in which to support knowledge discovery that may facilitate intercultural awareness and understanding...|$|R
40|$|This study {{presents}} clay plaques {{with different}} iconographic subjects from funerary contexts recently {{discovered in the}} north-eastern necropolis of Thebes. The authors’ principal aim is to present and to analyze these plaques {{from the point of}} view of their practical use. The evidence they provide, concerning the quantity and the technical-typological features, suggests that they were not just used for furniture but decorated also textiles. Furthermore the number of items and the choise of the themes seem to be closely connected with funerary rites. Methodological issues concerning textual and iconographical evidence are also addressed. Within the present study a technological examination of the plaques was made, to provide information on the manufacture technique used. The analyses also aimed at providing information on the material these items were attached and possibly to detect the medium applied for connecting the items and the underlying material. The techniques used were optical microscopy and scanning electron microscopy -coupled with an EDAX analyzer on polished, and in resin embedded aliquots, for the study of the plaques, Fourier Transformed Infra Red Spectroscopy (FTIR) for the temperature the plaques were exposed and micro-RAMAN analysis for the <b>interconnecting</b> <b>medium...</b>|$|R
5|$|In a wind farm, {{individual}} turbines are <b>interconnected</b> with a <b>medium</b> voltage (usually 34.5 kV) {{power collection}} system and communications network. At a substation, this medium-voltage electric current is increased in voltage with a transformer for connection to the high voltage electric power transmission system.|$|R
40|$|A steady {{increase}} in the number of cores within many-core platforms causes increasing contentions for the <b>interconnect</b> <b>medium</b> and leads to non-negligible latencies of the inter-core communication. In order to study the worst-case execution times of applications, it is no longer sufficient to only take into account their schedulability requirements, but the communication delays also have to be considered. In this work, we focus on the worst-case communication delays of applications, deployed upon a NoC-based many-core platform using a Limited Migrative Model (LMM). The LMM approach is based on the multi-kernel paradigm, which is a promising step towards scalable and predictable many-cores. The contribution of this work is threefold. First, we extend LMM by allowing the inter-application communication, and subsequently adapt the existing method for the worst-case communication delay analysis, so as to make it applicable to the enhanced model. Then, we propose a novel method. Finally, we compare these two approaches. The experiments show that the new technique renders tighter upper-bound estimates in more than 90 % of the cases, and also demonstrates a comparable runtime performance. info:eu-repo/semantics/publishedVersio...|$|E
40|$|This paper {{discusses}} the reliability testing {{results of a}} lead-free version of the micro SMD, National Semiconductor’s Wafer Level-Chip Scale Package (WL-CSP). The micro SMD, a true wafer scale package {{has proven to be}} highly adaptable in the conventional assembly process, requiring no special considerations during the surface mount assembly operation. The current micro SMD utilizes standard Sn/Pb solder bumps as the <b>interconnect</b> <b>medium.</b> Based on evaluations of the various options available for the lead-free solder, micro SMD devices bumped with Sn/Ag/Cu solder were tested during this evaluation. There are two bump sizes currently available for the micro SMD package, a 170 -micron bump diameter and a 300 -micron bump diameter. This paper addresses the impact of board assembly conditions, package solder type, package bump size, and thermal cycling profiles on the reliability of the lead-free WL-CSPs. This paper will address the initial evaluations on the 170 -micron bumped micro SMD packages. Results of this work are used to determine viable combinations of leadfree and eutectic solder. The lead-free version of the micro SMD is in synch with the next packaging evolutionary stage toward a lead-free assembly process...|$|E
40|$|The stencil {{printing}} process {{is an important}} process in the assembly of Surface Mount Technology (SMT) devices. There is a wide agreement in the industry that the paste printing process accounts {{for the majority of}} assembly defects. Experience with this process has shown that typically over 60 % of all soldering defects are due to problems associated with the flow properties of solder pastes. Therefore, the rheological measurements {{can be used as a}} tool to study the deformation or flow experienced by the pastes during the {{stencil printing}} process. This paper presents results on the thixotropic behaviour of three pastes; lead-based solder paste, lead-free solder paste and isotropic conductive adhesive (ICA). These materials are widely used as <b>interconnect</b> <b>medium</b> in the electronics industry. Solder paste are metal alloys suspended in a flux medium while the ICAs consist of silver flakes dispersed in an epoxy resin. The thixotropy behaviour was investigated through two rheological test; (i) hysteresis loop test and (ii) steady shear rate test. In the hysteresis loop test, the shear rate were increased from 0. 001 to 100 s- 1 and then decreased from 100 to 0. 001 s- 1. Meanwhile, in the steady shear rate test, the materials were subjected to a constant shear rate of 0. 100, 100 and 0. 001 s- 1 for a period of 240 seconds. All the pastes showed a high degree of shear thinning behaviour with time. This might be due to the agglomeration of particles in the flux or epoxy resin that prohibits pastes flow under low shear rate. The action of high shear rate would break the agglomerates into smaller pieces which facilitates the flow of pastes, thus viscosity is reduced at high shear rate. The solder pastes exhibited a higher degree of structural breakdown compared to the ICAs. The area between the up curve and down curve in the hysteresis curve is an indication of the thixotropic behavior of the pastes. Among the three pastes, lead-free solder paste showed the largest area between the down curve and up curve, which indicating a larger structural breakdown in the pastes, followed by lead-based solder paste and ICA. In a steady shear rate test, viscosity of ICA showed the best recovery with the steeper curve to its original viscosity after the removal of shear, which indicating that the dispersion quality in ICA is good because the high shear has little effect on the microstructure of ICA. In contrast, lead-based paste showed the poorest recovery which means this paste undergo larger structural breakdown and dispersion quality in this paste is poor because the microstructure of the paste is easily disrupted by high shear. The structural breakdown during the application of shear and the recovery after removal of shear is an important characteristic in the paste printing process. If the paste’s viscosity can drop low enough, it may contribute to the aperture filling and quick recovery may prevent slumping...|$|E
40|$|International audienceWeb-based {{applications}} are increasingly demanding many computationally intensive services. On the other hand, FPGA-based hardware accelerators(HwAcc) provide good performance in accelerating computationally intensive applications. In addition, some FPGAs support a dynamic partial reconfig-uration (DPR) techniques to virtualize {{and share the}} FPGA underlying hardware resources in time multiplexing during run-time to save resource and power consumption. Integrating FPGA in a cloud environment is an indispensable way to improve efficiency and provide acceleration services to demanding users. More importantly, in recent years it was proved that FPGA resources deployed in a cloud environment can be accessed with the same OpenStack software technology used to access virtual machines. However, {{the performance of the}} virtualized FPGA is highly dependent on the communication <b>medium</b> used to <b>interconnect</b> the virtualized FPGA resources and the control manager. After analyzing the possible <b>interconnect</b> <b>mediums,</b> we have selected Network-on-Chip (NoC) which support parallel communication as the efficient medium for accelerators. Consequently, we propose a NoC based virtualized FPGA as cloud Services. Two virtualized FPGA-based cloud service: Hardware Accelerator as a Service(HAaaS) and Reconfigurable Region as a Service(RRaaS) are proposed in this paper. The NoC provides layered and parallel communication between the virtualized regions of the FPGA and helps them to communicate their status and exchange data through the routers connected to them. A 2 x 2 -mesh NoC based reconfigurable accelerators for image analysis and matrix computation are implemented and tested showing a promising result for more scalable systems in cloud computing...|$|R
40|$|The paper {{describes}} {{the new design}} criteria and control strategies for multi-density dense medium separation (DMS) circuits. The role of the multi-density separation is discussed, and it is emphasized that for many processing problems -related to minerals and coals -it may be very important to perform two or more cuts at different densities {{in order to obtain}} a remarkable improvement in quality of products, process efficiency and economy. The two-density separation by dense medium cyclones was generally performed using two dense medium plants in sequence. In contrast to the former technology, the multi-density separation can now be performed by using a single medium circuit composed of different <b>interconnected</b> <b>medium</b> sumps. The sumps, one for each density, are fed with different medium streams selected according to their density, size composition and content in non-magnetic contaminant {{in such a way that}} the rheological properties of the media are optimized. This new technology is based on dynamic systems to density the medium, on the size-density segregation of the medium in the cyclones and separating devices and on accurate control systems for the density, viscosity and stability of the dense media of the different sumps. The present paper reports on the theoretical basis for the new, advanced medium circuits and on the systems for the control of the densities and of the rheological properties of the dense media. A typical circuit for a two-density separation is also described, and some industrial applications reported and discussed...|$|R
40|$|AbstractThe seismotectonic {{characteristics}} of ten repeated earthquake swarm sequence within a seismic cluster along Jiali Fault in eastern Himalayan Syntaxis (EHS) have been analysed. The swarms are spatially disposed {{in and around}} Yigong Lake (a natural lake formed by blocking of Yigong River by landslide) and are characterized by low magnitude, crustal events with low to moderate b values. Ms : mb discriminant functions though indicate anomalous nature of the earthquakes within swarm but are considered as natural events that occurred under condition of high apparent stress and stress gradients. Composite fault plane solutions of selected swarms indicate strike–slip sense of shear on fault planes; solution parameters show low plunging compression and tensional axes along NW–SE and NE–SW respectively with causative fault plane oriented ENE–WSW, dipping steeply towards south or north. The fault plane is in excellent agreement with the disposition and tectonic movement registered by right lateral Jiali Fault. The process of pore pressure perturbation and resultant ‘r–t plot’ with modelled diffusivity (D =  0. 12  m 2 /s) relates the diffusion of pore pressure to seismic sequence in a fractured poro-elastic fluid saturated medium at average crustal depth of 15 – 20  km. The low diffusivity depicts a highly fractured <b>interconnected</b> <b>medium</b> that is generated due to high stress activity near the eastern syntaxial bent of Himalaya. It is proposed that hydro fracturing with respect to periodic pore pressure variations is responsible for generation of swarms in the region. The fluid pressure generated due to shearing and infiltrations of surface water within dilated seismogenic fault (Jiali Fault) are causative factors...|$|R
40|$|The Network-on-Chip (NoC) {{architecture}} is an interconnect network {{with a good}} performance and scalability potential. Thus, {{it comes as no}} surprise that NoCs are among the most popular <b>interconnect</b> <b>mediums</b> in nowadays available many-core platforms. Over the years, the real-time community has been attempting to make NoCs amenable to the real-time analysis. One such approach advocates to employ virtual channels. Virtual channels are hardware resources that can be used as an infrastructure to facilitate flit-level preemptions between communication traffic flows. This gives the possibility to implement priority-preemptive arbitration policies in routers, which is a promising step towards deriving real-time guarantees for NoC traffic. So far, various aspects of priority-preemptive NoCs were studied, such as arbitration, priority assignment, routing, and workload mapping. Due to a potentially large solution space, the majority of available techniques are heuristic-centric, that is, either pure heuristics, or heuristic-based search strategies are used. Such approaches may lead to an inefficient use of hardware resources, and may cause a resource over-provisioning as well as unnecessarily high design-cost expenses. Motivated by this reality, we take a different approach, and propose an integer linear program to solve the problems of priority assignment and routing of NoC traffic. The proposed method finds optimal routes and priorities, but also allows to reduce the search space (and the computation time) by fixing either priorities or routes, and derive optimal values for remaining parameters. This framework is used to experimentally evaluate both the scalability of the proposed method, as well as the efficiency of existing priority assignment and routing techniques. info:eu-repo/semantics/publishedVersio...|$|R
5|$|In a wind farm, {{individual}} turbines are <b>interconnected</b> with a <b>medium</b> voltage (often 34.5 kV), {{power collection}} system and communications network. In general, a distance of 7D (7 × Rotor Diameter of the Wind Turbine) is set between each turbine in a fully developed wind farm. At a substation, this medium-voltage electric current is increased in voltage with a transformer for connection to the high voltage electric power transmission system.|$|R
40|$|Experiments in precise clock {{comparisons}} {{using the}} two-way time transfer tech-nique via satellite began in 1962. Experience gained {{from a variety}} of experiments since tha t time steadily improved the precision and accuracy of such comparisons. Recent growth in the fixed satellite service, or FSS, has created new opportunities at moderate costs for high-accuracy time transfers using geostationary satellites. We discuss fundamental aspects of two-way timing and show an implementation of a satel-lite two-way time transfer system which has been used for two-years between USNO, Washington, D. C. and NIST, Boulder, C 0 :The raw da ta collection procedure will be discussed. We also outline the rationale for the choice of satellite uplink/downlink frequencies, signal structure, and reduction of data. Short-term noise in the time transfer limits the precision t o about 300 ps in a 300 s average. Uncertainty in accuracy is due t o uncertainty in the non-reciprocity of the two-way signal path. Accuracy limits due t o the atmosphere, earth-satellite rotating system (Sagnac effect), and the equipment are discussed. The goal is to achieve a n ac-curacy level of 1 ns after a suitable calibration of earth-station (differential) equipment delays. Satellite Two-way Time Transfer We discuss fundamental aspects of two-way time transfers first. Synchronization of clocks between two locations A and B in the two-way mode involves three elements. These are: the clocks which generate a signal, usually a pulse once per second, some method to transmit the pulses between locations A and B, and a time-difference measuring instrument, or time- interval counter (TIC), at each location. Figure 1 illustrates the principle of the two-way technique using two cables as the <b>interconnecting</b> <b>medium.</b> The difference of the clocks is given by A- B = 1 / 2 [R(A) - R(B) ] -k 1 / 2 [d A B- d B A...|$|R
40|$|The study aims {{to develop}} the theory of inbetween place. The inbetweens have been {{important}} elements in architectural design as transitional and reconciling realms. Architecture of place and its theories has been dominated the environmental design as place-making. However, the inbetween environments have not been clarified in significant, living place-forms for interval embodiment and systemic relationships between juxtaposing places. Through inbetween places, domains in juxtaposition will be comprehensively integrated as the whole. By a triangulation from three standpoints?phenomenological, embodied realism, and neo-structuralism?through case studies, the intrinsic characteristics and underlying essence of inbetween modes of place is identified. The study argues that inbetween places present themselves as living forms of connectedness, embodied presence, and significant pauses. Distinctive inbetween presences of place emerge from three frameworks?synthesized presence of place and the inbetweens, embodied presence of the inbetweens, and presence of inbetween ?Significant Forms. ? On presence of place and the inbetweens, inbetween places reflect living forms of intervals as <b>interconnecting</b> <b>mediums</b> between neighboring places. As an interval place, inbetween places, based on embodied presence, {{can be defined as}} distinct body of junctions by organized complexity of edges. According to Langer?s term ?Significant Form? of place, inbetween places convey the symbolic presence of associative, edging layers that clarify differences and spatial relations between environmental juxtapositions. From a framework triangulation, inbetween places manifest complex interval domains of associative junctions as fundamental composite presences of: 1) defined inbetween containments; 2) active edging junctions or layers of juxtaposition; and 3) associative layers with places in juxtaposition. The essential quality of concrete, interrelating junctions between places separates inbetween places from inbetween placeless-ness. Inbetween places are intermediary domains creating vital and aesthetic links between places in juxtaposition; on the other hand, inbetween placeless-ness is deprived of a significant place of meaningful interactions with nearby realms. Thus, inbetween places turn out to be critical domains to develop comprehensive relationships between juxtaposing places, drawing different domains nearby to be bonded through the presence of adaptive, edging layers of places...|$|R
40|$|We {{describe}} {{large scale}} structure at high redshift {{in terms of}} the Cosmic Web picture for fS;; O; HgCDM models: how galactic-scale "peak-patches", filaments and membranes create an <b>interconnected</b> intergalactic <b>medium.</b> The ideas are applied to our Lyff forest simulations of "shear-field patches". We discuss simulation method and design, resolution dependence, the statistical combination of patches, UV flux scaling, and whether filtered Zel'dovich maps are useful. The response to changes in power spectrum shape and amplitude, and in cosmological parameters, is described. We also showΩ b h 2 derived from UV rescaling is overestimated if the resolution is not adequate. 1 The Cosmic Web and Peak-Patches at High Redshift The Cosmic Web picture [1] provides a powerful language for understanding the structure and evolution of Lyman Alpha absorption systems [2]. It predicts the basic structural components of the IGM as a function of scale, epoch and cosmology. For density contrast [...] ...|$|R
25|$|In general, a {{distance}} of 7D (7 × Rotor Diameter of the Wind Turbine) is set between each turbine in a fully developed wind farm, but micrositing optimizes placement, particularly in hilly areas. Individual turbines are <b>interconnected</b> with a <b>medium</b> voltage (usually 34.5 kV) power collection system and communications network. At a substation, this medium-voltage electric current is increased in voltage with a transformer for connection to the high voltage transmission system. Construction of a land-based wind farm requires installation of the collector system and substation, and possibly access roads to each turbine site.|$|R
40|$|Two-photon {{polymerization}} using {{femtosecond laser}} pulses at a wavelength of 515 nm {{is used for}} three-dimensional patterning of photosensitive, biocompatible inorganic-organic hybrid polymers (ORMOCER(A (R)) s). In order to fabricate millimeter-sized biomedical scaffold structures with <b>interconnected</b> pores, <b>medium</b> numerical aperture air objectives with long working distances are applied which allow voxel lengths of several micrometers and thus the solidification of large scaffolds in an adequate time. It is demonstrated that during processing the refraction of the focused laser beam at the air/material interface leads to strong spherical aberration which decreases the peak intensity of the focal point spread function along with shifting and severely extending the focal region {{in the direction of}} the beam propagation. These effects clearly decrease the structure integrity, homogeneity and the structure details and therefore are minimized by applying a positioning and laser power adaptation throughout the fabrication process. The results will be discussed with respect to the resulting structural homogeneity and its application as biomedical scaffold...|$|R
40|$|Abstract. We {{describe}} {{large scale}} structure at high redshift {{in terms of}} the Cosmic Web picture for {S, Λ, O, H}CDM models: how galactic-scale “peak-patches”, filaments and membranes create an <b>interconnected</b> intergalactic <b>medium.</b> The ideas are applied to our Lyα forest simulations of “shear-field patches”. We discuss simulation method and design, resolution dependence, the statistical combination of patches, UV flux scaling, and whether filtered Zel’dovich maps are useful. The response to changes in power spectrum shape and amplitude, and in cosmological parameters, is described. We also show Ωbh 2 derived from UV rescaling is overestimated if the resolution is not adequate. 1 The Cosmic Web and Peak-Patches at High Redshift The Cosmic Web picture [1] provides a powerful language for understanding the structure and evolution of Lyman Alpha absorption systems [2]. It predicts the basic structural components of the IGM as a function of scale, epoch and cosmology. For density contrasts δ> 100, the rare-events at z ∼ 3 are massiv...|$|R
40|$|All rights reserved. This thesis {{may not be}} {{reproduced}} {{in whole or in}} part, by photocopy or other means, without the permission of the author. ii The <b>interconnected,</b> interactive <b>medium</b> of the Internet makes visible the realities and multiple voices associated with western, post-modern societies. This study explores through online conversations with eight adolescents how onground social and cultural constructs of research practices, age, gender, self and relationships are transformed by frequent participation within an online space in which parameters of interaction and communication can be re-defined. In an online ethnographic research context, onground concepts such as ownership of data, researcher-participant relationship as well as confidentiality and consent are re-negotiated online. In the contexts of youth experiences online, research participants are able to explore their interests and themselves through challenging activities and supportive online relationships in addition to the opportunities available for them onground. Both online and onground experiences are considered real b...|$|R
40|$|We {{describe}} {{large scale}} structure at high redshift {{in terms of}} the Cosmic Web picture for S,Lambda,O,HCDM models: how galactic-scale "peak-patches", filaments and membranes create an <b>interconnected</b> intergalactic <b>medium.</b> The ideas are applied to our Lyα forest simulations of "shear-field patches". We discuss simulation method and design, resolution dependence, the statistical combination of patches, UV flux scaling, and whether filtered Zel'dovich maps are useful. The response to changes in power spectrum shape and amplitude, and in cosmological parameters, is described. We also show Omega_b h^ 2 derived from UV rescaling is overestimated if the resolution is not adequate. Comment: 6 pages, LaTeX, with figure 1 a,b,c,d, 2, 3 included. uses conf_iap. sty To appear in Structure and Evolution of the IGM from QSO Absorption Line Systems, Proc. 13 th IAP Colloquium, ed. P. Petitjean and S. Charlot, Nouvelles Frontieres, Paris Text and colour figures also available at ftp://ftp. cita. utoronto. ca/bond/iap 9...|$|R
30|$|The {{majority}} of fully electric vehicles (FEVs) currently satisfy the electric energy requirements for motion with an on-board battery. Reference [1] analyzed the {{problems related to}} battery charging management, the uncertainty surrounding the monitoring {{of the state of}} charge (SOC), the limited availability of charging infrastructure and the long time required to recharge; problems that have generated range anxiety. Extensive research has claimed that the challenges of battery inefficiency and the large and wasted space in the FEVs can be overcome by the wireless power transfer (WPT) technology. This technology electrically conducts energy from a source to an electric device without any <b>interconnecting</b> <b>mediums</b> [2]. The maglev system, developed in the late 1970 s, utilises the high speed of a travelling vehicle to generate electricity using a linear generator [3]. Reference [4] proposed a design methodology for loosely coupled inductive power transfer systems. Such systems were used for non-contact power transfer, normally, over large air-gaps to the moving loads. Reference [5] explored the integrated pricing of electricity and roads enabled with wireless power transfer technology. The on-line electric vehicle (OLEV) system [6] and its non-contact power transfer mechanism were developed by the Korea Advanced Institute of Science and Technology (KAIST) and presented in 2009. The OLEV is an electric transport system in which the vehicles absorb the power from power lines underneath the surface of the road. The aim of this research study is to present a method for analyzing the performance of the CWD system, from both traffic and energy points of view. Beginning with an electric vehicle supply equipment (EVSE) layout defined and analyzed in a previous study [7] and using the system requirements defined in the eCo-FEV project [8], a model for the traffic flow simulation is implemented to quantify and describe the time-dependent traffic parameters along the charging lane and the electric power that should be provided by an energy supplier for proper management of the charging system. The results of this analysis confirm the influence of different traffic conditions and system requirements {{on the quality of the}} charging service.|$|R
40|$|This study {{contributed to}} a better {{understanding}} of current gender disparities that can help to ensure future inclusive market development and associated benefits. The analysis is based on empirical evidence from female and male small and medium enterprise (SME) owners along the common bean value chain that served urban and peri-urban bean markets in Kenya and Uganda. The value chain was evaluated based on cross-sectional data collected from 349 <b>interconnected</b> small and <b>medium</b> enterprises (SMEs). SMEs spanned three value chain levels, namely traders and wholesalers, which were dominated by male proprietors, and shopkeepers, which were dominated by female-proprietor...|$|R
50|$|In a wind farm, {{individual}} turbines are <b>interconnected</b> with a <b>medium</b> voltage (usually 34.5 kV) {{power collection}} system and communications network. At a substation, this medium-voltage electric current is increased in voltage with a transformer for connection to the high voltage electric power transmission system.A transmission line is required to bring the generated power to (often remote) markets. For an off-shore station this may require a submarine cable. Construction of a new high-voltage line may be too costly for the wind resource alone, but wind sites may take advantage of lines installed for conventionally fueled generation.|$|R
50|$|IEEE 802.3 {{standards}} {{apply to}} Media Access Control (MAC) sublayer and Physical sublayer specifications, {{and their respective}} management, only. For EPON, IEEE 802.3 defined separately a service provider MAC and PHY called an Optical Line Terminal (OLT) and a subscriber MAC and Physical sublayer called an Optical Network Unit (ONU). The <b>medium</b> <b>interconnecting</b> the OLT with the ONU is a fiber optical cable in which two wavelengths are defined for full-duplex operation, one for continuous downstream channel operation (OLT transmitting {{to one or more}} ONUs), and another for upstream burst mode channel operation that permits OLT-controlled time-division sharing of the upstream channel amongst all ONUs on the PON.|$|R
40|$|Thesis (Masters Diploma (Technology) [...] Cape Technikon, Cape Town, 1991 Many environments employ time {{switches}} {{to control the}} operation of electrical machinery and appliances. These devices are generally expensive and require extensive wiring and individualised treatment. The need therefore arises for a more efficient and economical control system {{that will not be}} subjected to the limitations found in conventional remote control systems. This thesis describes a universal remote control system developed to suitably replace conventional systems prone to various limitations and restrictions. The system is "mains borne" and therefore makes use of the mains wiring for interconnectivity. The term "Mains borne" refers to the communicating <b>medium</b> <b>interconnecting</b> the various components...|$|R
40|$|Microgrids {{comprise}} Low Voltage distribution {{systems with}} distributed energy sources, such as micro-turbines, fuel cells, PVs, etc., together with storage devices, i. e. flywheels, energy capacitors and batteries, and controllable loads, offering considerable control capabilities over the network operation. These systems are <b>interconnected</b> to the <b>Medium</b> Voltage Distribution network, {{but they can}} be also operated isolated from the main grid, in case of faults in the upstream network. One of the key benefits of Microgrids is the potential to increase service quality by providing generation redundancy, where most needed. In this paper the effects of Microgrids in increasing the service quality are assessed by calculating a set of reliability indices on a typical LV network with and without DG sources connected and coordinated in islanded operation. © 2007 IEEE...|$|R
40|$|Dependencies and, eventually, interdependencies among Critical Infras- tructures are {{difficult}} to identify and to model, because their effects appears in few situations with unpredictable consequences. Adding cy- ber attacks in this context makes analysis even more complex. Inte- grating cyber attacks and interdependencies consequences requires the knowledge of both fields with a common abstraction level. CISIApro is a Critical Infrastructure simulator, and it was born for eval- uating consequences of faults and failures on interdependent infrastruc- tures. In this paper, CISIApro implements the effects of cyber attacks on physical equipment and on infrastructure services. The case study highlights the main functionality of the simulator, with a complex scenario where several events may happen: first an ARP spoofing attack, and then a worm infection. The scenario considers three <b>interconnected</b> infrastructures: a <b>medium</b> voltage power grid, controlled by a SCADA control center over a SCADA network, interconnected with a general-purpose telecommunication network. The simulation results display the output of CISIApro in event of cyber attacks. The simulation demonstrates the help of CISIApro output in a decision making process for electric operators: specifically, the choice between different re-configurations...|$|R
40|$|Heterogeneous Mobile Computing System (HMCS) {{consists}} of battery operated portable heterogeneous mobile nodes <b>interconnected</b> by wireless <b>medium</b> {{are increasingly being}} used {{in many areas of}} science, engineering and business. The advancements in the computing and communication technologies excel the mobile computing devices with the potential to execute larger application. However, execution of larger program is constrained by the availability of energy/power, node mobility and availability. A significant amount of work has been carried out to execute meta (independent) tasks in mobile computing system by consuming minimum energy/power and only a very few work has been carried out for the execution of larger program represented by Directed Acyclic Graph(DAG) in mobile computing system. Therefore, in this paper, the problem of scheduling the tasks of a DAG onto the mobile computing system has been explored with objectives to minimize either the schedule length or energy/power consumption or both. A new task scheduling algorithm namely, High Performance and energy efficient task Scheduling algorithm for heterogeneous Mobile computing system (HPSM) has been proposed. The performance of the algorithm is evaluated by simulation experiments using a large set of randomly generated task graphs. The experimental results show that the HPSM algorithm significantly minimizes the schedule length or the energy consumption or both...|$|R
