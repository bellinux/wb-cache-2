27|193|Public
2500|$|Several {{weeks after}} her death, Megan Meier's parents {{were told that}} the mother of one of their daughter's friends—with whom Meier had a falling out—had created the [...] "Josh Evans" [...] account. The parent, Lori Drew, who created the <b>fake</b> <b>account,</b> {{admitted}} that she and her daughter had the password to the account, and characterized the hoax to a reporter as a [...] "joke". Initially, Drew denied knowing about the offensive messages that were sent to Meier. She told the police that the account was aimed at [...] "gaining Megan's confidence and finding out what Megan felt about her daughter and other people". The neighborhood mother who had told the Meiers that Drew had the hoax account said [...] "Lori laughed about it", and said she had intended to [...] "mess with Megan".|$|E
2500|$|In January 2017, {{it emerged}} that Wells Fargo had kept its {{talks with the}} U.S. Consumer Financial Protection Bureau about the <b>fake</b> <b>account</b> {{investigation}} silent from shareholders {{for up to six}} months beginning as early as March 2016. In June 2017, it was revealed that a new class action lawsuit alleged that Wells Fargo made unauthorized alterations in the home loans of borrowers in bankruptcy that would ultimately charge these customers more in mortgage payments over the long term. In July 2017, Wells Fargo apologized for charging as many as 570,000 customers with unnecessary automobile insurance costs, which may have caused about 20,000 of them to default on their car loans. In August 2017, a federal judge refused to dismiss a lawsuit accusing Wells Fargo of denying loans to immigrants who came to the United States as children and have been allowed to remain in the country. Also in August 2017, a lawsuit was filed against Wells Fargo in federal court for overcharging small mom-and-pop businesses for processing credit-card transactions and then charging them massive fees for early termination of the relationship. In October 2017, Wells Fargo was accused by U.S. Senator Sherrod Brown of lying to the U.S. Congress in late 2016 by failing to disclose a contemporaneous auto insurance scandal. Also in October 2017, Wells Fargo admitted to wrongly charging some borrowers [...] "mortgage rate lock extension fees" [...] for missing deadlines to lock in promised interest rates even when Wells Fargo caused the delays.|$|E
50|$|Goldberg {{reportedly}} {{set up a}} fake Twitter {{account in}} the name of anti-sexual exploitation campaigner Caitlin Roper, who allegedly earned his ire because of her efforts to get the video game Grand Theft Auto V banned in Australia. The <b>fake</b> <b>account</b> sent Promoted Tweets that targeted the transgender community.|$|E
50|$|However, a Twitter {{spokesman}} {{denied the}} claim that there are that many <b>fake</b> <b>accounts</b> on the service.|$|R
5000|$|... #Caption: [...] "Trolls from Olgino" [...] gained usage after <b>fake</b> <b>accounts</b> for Internet {{trolling}} were {{traced back}} to Saint Petersburg, Russia.|$|R
5000|$|Pro-government trolls have {{escalated}} {{their campaigns}} to harass opposition voices and organizations {{on social media}} through smear campaigns and <b>fake</b> <b>accounts</b> ...|$|R
5000|$|Meanwhile, Philippine National Police Director General Avelino Razon {{ordered the}} Criminal Investigation and Detection Group {{to find out}} who created a <b>fake</b> <b>account</b> on Friendster using his identity. The profile was laden with false {{information}} about him, saying that he [...] "wants to meet traitors, corrupts, criminals so he could crush them." ...|$|E
5000|$|... == Uses == Honeytokens {{can exist}} in many forms, from a dead, <b>fake</b> <b>account</b> to a {{database}} entry {{that would only}} be selected by malicious queries, making the concept ideally suited to ensuring data integrity. A particular example of a honeytoken is a fake email address used to track if a mailing list has been stolen.|$|E
50|$|The Sydney Morning Herald {{reported}} that Thorne {{was the victim}} of alleged online troll Joshua Ryne Goldberg, who set up a <b>fake</b> <b>account</b> {{in the name of the}} preacher with the intention of smearing Thorne, as well as reportedly creating fake jihadist personas who interacted with the fake Thorne account and then sending screengrabs of these fabricated interactions to journalists.|$|E
5000|$|The {{amount of}} [...] "likes" [...] on Facebook {{can serve as}} a {{measurement}} of interest and/or popularity in a particular brand, product or personality, though there have also been reports of the [...] "overblown importance" [...] of likes. Due to social media's role as an influential way of shaping reputations, there exists companies specializing in selling [...] "likes" [...] from <b>fake</b> <b>accounts.</b> This has caused issues for companies advertising on Facebook, due to receiving an abundance of likes without credibility that distort actual user metrics. Facebook's Terms of Service agreement states that users are only allowed to have one personal page, and it has an ongoing [...] "war" [...] against <b>fake</b> <b>accounts.</b> A May 2015 estimate put the number of <b>fake</b> <b>accounts</b> at 170 million, and a Symantec study in September 2011 found that 15% of 3.5 million video posts were made through fake likes.|$|R
40|$|Detecting and {{suspending}} <b>fake</b> <b>accounts</b> (Sybils) {{in online}} social networking (OSN) services protects both OSN operators and OSN users from illegal exploitation. Existing social-graph-based defense schemes effectively bound the accepted Sybils {{to the total}} number of social connections between Sybils and non-Sybil users. However, Sybils may still evade the defenses by soliciting many social connections to real users. We propose SybilFence, a system that improves over social-graph-based Sybil defenses to further thwart Sybils. SybilFence is based on the observation that even well-maintained <b>fake</b> <b>accounts</b> inevitably receive a significant number of user negative feedback, such as the rejections to their friend requests. Our key idea is to discount the social edges on users that have received negative feedback, thereby limiting the impact of Sybils' social edges. The preliminary simulation results show that our proposal is more resilient to attacks where <b>fake</b> <b>accounts</b> continuously solicit social connections over time. Comment: Submitted to WOSN 2012 on March 14, 201...|$|R
5000|$|Al Giordano, {{a liberal}} {{political}} commentator {{who planned to}} challenge Bernie Sanders for his Senate seat in 2018, accused Chapo Trap House of organizing <b>fake</b> <b>accounts</b> to troll him on Twitter. The accusation {{was based on an}} evident misunderstanding of the hosts' discussion of other <b>fake</b> <b>accounts</b> that had interacted with Giordano online, but not their own intention to do so. Giordano became embroiled in argument with fans of the show and other Weird Twitter users, and Daily Dot writer Jay Hathaway deemed Giordano's behavior as not [...] "looking especially great for Giordano's possible campaign or his personal brand." ...|$|R
5000|$|A <b>fake</b> <b>account</b> {{generator}} {{which would}} generate a new, fully functional AOL {{account for the}} user that lasted for about a month. This generator worked by exploiting the algorithm used by credit card companies known as the Luhn algorithm to dynamically generate apparently legitimate credit card numbers. The account would not be disabled until AOL first billed it (and discovered that the credit card was invalid). The generator could also generate fake addresses and phone numbers, resembling on their surface legitimate personal information. One example of a <b>fake</b> <b>account</b> generator was a Macintosh One-click based piece of software called Fake Maker written by a user known as McDawgg within the AOL Macwarez community. This software ran in parallel with the AOL program to create fake accounts based upon generated legitimate credit card account numbers. This software ultimately released 3 versions and helped to create thousands of fake accounts before AOL weakened its ability through more expedient account verification.|$|E
5000|$|A {{social bot}} (also: socialbot or socbot) is a {{particular}} type of chatterbot that is employed in social media networks to automatically generate messages (e.g. tweets) or in general advocate certain ideas, support campaigns, and public relations either by acting as a [...] "follower" [...] or even as a <b>fake</b> <b>account</b> that gathers followers itself. In this respect, social bots can be said to have passed the Turing test.|$|E
50|$|The FBI {{examined}} backup {{tapes and}} used testimony of DiPascali {{to conclude that}} O'Hara and Perez developed and maintained computer programs on the House 17 server that were used expressly {{for the purpose of}} entering fictitious trading data into the server. FBI agents claim that the House 17 computer programs were used to generate, among other things, thousands of pages of <b>fake</b> <b>account</b> statements, trade confirmations, trading blotters, and other books and records related to BLMIS's purported IA business.|$|E
40|$|<b>Fake</b> <b>accounts</b> {{in online}} social {{networks}} (OSNs) have known considerable sophistication {{and are now}} attempting to gain network trust by infiltrating within honest communities. Honest users have limited perspective on the truthfulness of new online identities requesting their friendship. This facilitates the task of <b>fake</b> <b>accounts</b> in deceiving honest users to befriend them. To address this, we have proposed a model that learns hidden correlations between profile attributes within OSN communities, and exploits them to assist users in estimating the trustworthiness of new profiles. To demonstrate our method, we suggest, in this demo, a game application through which players try to cheat the system and convince nodes in a simulated OSN to befriend them. The game deploys different strategies to challenge the players and to reach {{the objectives of the}} demo. These objectives are to make participants aware of how <b>fake</b> <b>accounts</b> can infiltrate within their OSN communities, to demonstrate how our suggested method could aid in mitigating this threat, and to eventually strengthen our model based on the data collected from the moves of the players...|$|R
5000|$|In 2009, the Republican Party in Connecticut set up 33 <b>fake</b> Twitter <b>{{accounts}}</b> in {{the names}} of the Democratic Party members of the state legislature. The Republicans used the accounts to send out tweets {{in the names}} of the Democrats. When Twitter discovered the scheme, it shut down the <b>fake</b> <b>accounts,</b> quoting the applicable company policy. The Hartford Courant editorialized: [...] "Republicans get an A for innovation, but a D for ethics." ...|$|R
5000|$|<b>Fake</b> {{social media}} <b>accounts</b> {{were set up}} in Unsworth's name, with the {{operator}} of one account saying that their [...] "issue" [...] with Unsworth is [...] "he is a fag". Rodney Croome stated that Unsworth was [...] "being bullied beyond the grave" [...] and that the operation of <b>fake</b> <b>accounts</b> [...] "highlights how deep the hatred of LGBTI people still runs {{in some parts of}} Australian society." ...|$|R
50|$|Unlike email spam, Twitter bombs {{may require}} {{participation}} from their targeted users. Fake accounts {{are a common}} source of Twitter bombs. In order to avoid Twitter's spam filters and to overcome their lack of followers, Twitter bombs are often sent as a reply to existing tweets about the same topic. This is done in hopes that {{the authors of the}} existing tweets will retweet the response to their own followers, spreading the Twitter bomb before the <b>fake</b> <b>account</b> is deleted.|$|E
5000|$|On March 4, 2016, Judge Knazan amended his {{original}} ruling which claimed Elliott’s tweets were [...] "obscene and homophobic {{in at least}} two instances" [...] when it was discovered that the tweets were actually made by an account impersonating Elliott. The judge issued a correction saying [...] "Mr. Elliott never wrote homophobic tweets, used homophobic language or was homophobic." [...] He further stated that the <b>fake</b> <b>account</b> could be considered the criminal offense of [...] "impersonation with intent to cause mischief." ...|$|E
5000|$|Allegations {{of racism}} {{were due to}} the {{requirement}} for the user to declare their ethnicity, {{and the ability to}} filter non-white users. However, Bradford said people wanted to know about a person's race, and the [...] "ethnicity data" [...] is meant to help the site be more inclusive by being [...] "diverse". Some users also report that the so-called [...] "concierge", who {{is supposed to be a}} [...] "special employee" [...] that should help new users, is actually a <b>fake</b> <b>account</b> created to filter out minorities.|$|E
30|$|Increasingly, hostile {{governments and}} other adversaries use <b>fake</b> <b>accounts</b> to orchestrate attacks. Governments, like Russia, hire paid trolls {{to carry out}} {{legitimate}} sounding discourse online [23, 24, 74]. They automate attacks using bots to generate a massive number of messages that flood OSNs [75, 76], and set up anonymous sybils, which are <b>fake</b> <b>accounts</b> posing as legitimate users [77], as vessels for these agents. These accounts post spam [78] and fake-news [79] in coordinated attacks to steer conversation and drown out competing ideas. Users attempting genuine discourse, especially those using anonymous accounts {{that are hard to}} distinguish from the attackers, can get lost in the noise. Our interview pool included victims of these false reporting attacks, who reported their accounts being banned due to third party reports.|$|R
50|$|Louis Vuitton {{is one of}} {{the most}} counterfeited brands in the fashion world due to its image as a status symbol. Ironically, the {{signature}} Monogram Canvas was created to prevent counterfeiting. In 2004, Louis Vuitton <b>fakes</b> <b>accounted</b> for 18% of counterfeit accessories seized in the European Union.|$|R
50|$|Sursara {{has spoken}} out against {{cyberbullying}} and bullying in schools after being targeted herself at {{school as a}} child. From 2005 she {{was a victim of}} identity theft. In a 2012 article for News.com.au, Sursara said there were over 500 <b>fake</b> <b>accounts</b> pretending to be her.|$|R
50|$|The {{existence}} of software like AOHell provided {{a sort of}} parallel 'lite' version of the hacker underground that had existed for years before, based around bulletin board systems. Programs like AOHell played {{an important part in}} defining the 'script kiddie', a user who performs basic cracking using simple tools written by others, with little understanding of what they are doing. These types of programs tended to get AOL accounts shut down and so most users were on accounts they acquired illicitly either by phishing or a <b>fake</b> <b>account</b> generator as mentioned above.|$|E
50|$|Goldberg {{reportedly}} {{set up a}} <b>fake</b> <b>account</b> in {{the name}} of Australian Muslim preacher Junaid Thorne with the alleged intention of besmirching him. Goldberg also allegedly created a number of fake jihadist accounts, which interacted with the fake Thorne account, and then allegedly sent screengrabs of the interactions to journalists, at least one of whom published a fake interaction in an article of The West Australian in April 2015. The fake jihadist personas were also used to besmirch Amnesty International and the Human Rights Law Centre by claiming the fake jihadists had employment ties or donated money to the organizations.|$|E
5000|$|Suhas Katti v. Tamil Nadu was {{the first}} case in India where a {{conviction}} was handed down {{in connection with the}} posting of obscene messages on the internet under the controversial section 67 of the Information Technology Act, 2000. The case was filed in February 2004 and In a short span of about seven months from the filing of the FIR, the Chennai Cyber Crime Cell achieved the conviction [...]In the case, a woman complained to the police about a man who was sending her obscene, defamatory and annoying messages in a Yahoo message group. The accused also forwarded emails received in a <b>fake</b> <b>account</b> opened by him in the victim's name. The victim also received phone calls by people who believed she was soliciting for sex work.|$|E
40|$|Serving {{more than}} one billion users around the world, today's online social {{networks}} (OSNs) pervade our everyday life and change the way people connect and communicate with each other. However, the open nature of OSNs attracts a constant interest in attacking and exploiting them. In particular, they are vulnerable to various attacks launched through malicious <b>accounts,</b> including <b>fake</b> <b>accounts</b> and compromised real user accounts. In those attacks, malicious accounts are used to send out spam, spread malware, distort online voting, etc. In this dissertation, we present practical systems that we have designed and built to help OSNs effectively throttle malicious accounts. The overarching contribution of this dissertation is the approaches that leverage the fundamental weaknesses of attackers to defeat them. We have explored defense schemes along two dimensions of an attacker's weaknesses: limited social relationships and strict economic constraints. The {{first part of this}} dissertation focuses on how to leverage social relationship constraints to detect <b>fake</b> <b>accounts.</b> We present SybilRank, a novel social-graph-based detection scheme that can scale up to OSNs with billions of users. SybilRank is based on the observation that the social connections between <b>fake</b> <b>accounts</b> and real users, called attack edges, are limited. It formulates the detection as scalable user ranking according to the landing probability of early-terminated random walks on the social graph. SybilRank generates an informative user-ranked list with a substantial fraction of <b>fake</b> <b>accounts</b> at the bottom, and bounds the number of <b>fake</b> <b>accounts</b> that are ranked higher than legitimate users to O(log n) per attack edge, where n is the total number of users. We have demonstrated the scalability of SybilRank via a prototype on Hadoop MapReduce, and its effectiveness in the real world through a live deployment at Tuenti, the largest OSN in Spain. The second part of this dissertation focuses on how to exploit an attacker's economic constraints to uncover malicious accounts. We present SynchroTrap, a system that uncovers large groups of active malicious <b>accounts,</b> including both <b>fake</b> <b>accounts</b> and compromised accounts, by detecting their loosely synchronized actions. The design of SynchroTrap is based on the observation that malicious accounts usually perform loosely synchronized actions to accomplish an attack mission, due to limited budgets, specific mission goals, etc. SynchroTrap transforms the detection into a scalable clustering algorithm. It uncovers large groups of accounts that act similarly at around the same time for a sustained period of time. To handle the enormous volume of user action data in large OSNs, we designed SynchroTrap as an incremental processing system that processes small data chunks on a daily basis but aggregates the computational results over the continuous data stream. We implemented SynchroTrap on Hadoop and Giraph, and we deployed it on Facebook and Instagram. This deployment has resulted in the unveiling of millions of malicious accounts and thousands of large attack campaigns per month. Dissertatio...|$|R
5000|$|Approximately 85,000 of the {{accounts}} opened incurred fees, totaling $2 million. Customers' credit scores were also likely {{hurt by the}} <b>fake</b> <b>accounts.</b> The bank was able to prevent customers from pursuing legal action as the opening of an account mandated customers enter into private arbitration with the bank.|$|R
50|$|The largest {{mass scale}} protest to Section 329 {{came in the}} 2011 federal {{election}}. In this election many people took to Twitter to disobey the law. Twitter users used proxy names for parties (from fruit and soft drinks) and created <b>fake</b> <b>accounts</b> {{to get away with}} sharing the illegal information.|$|R
5000|$|Several {{weeks after}} her death, Megan Meier's parents {{were told that}} the mother of one of their daughter's friends—with whom Meier had a falling out—had created the [...] "Josh Evans" [...] account. The parent, Lori Drew, who created the <b>fake</b> <b>account,</b> {{admitted}} that she and her daughter had the password to the account, and characterized the hoax to a reporter as a [...] "joke". Initially, Drew denied knowing about the offensive messages that were sent to Meier. She told the police that the account was aimed at [...] "gaining Megan's confidence and finding out what Megan felt about her daughter and other people". The neighborhood mother who had told the Meiers that Drew had the hoax account said [...] "Lori laughed about it", and said she had intended to [...] "mess with Megan".|$|E
50|$|A study {{conducted}} by the Stanford Graduate School of Education from January 2015 revealed difficulties that middle, high school, and college students experienced in differentiating between advertisements and news articles, or identifying where information originated. One concern noted by researchers {{of the study is}} that democracy is at risk of devolving due {{to the ways in which}} falsehoods about civic issues can quickly spread with a growing ease of access. In one assessment, high school students were asked to evaluate two Facebook posts mentioning Donald Trump's candidacy for president; one was from an actual Fox News account and the other was from a fake account. Over 30 percent of students stated that the <b>fake</b> <b>account</b> was more reliable because of its graphic elements and only a quarter recognized the significance of the blue checkmark on Twitter and Facebook, which indicates that an account was marked as legitimate.|$|E
5000|$|Wade [...] "Unique" [...] Adams (Alex Newell) is a {{recurring}} character in seasons 3, 4 and 6, and a main character in season 5. She first {{appears in the}} third-season episode [...] "Saturday Night Glee-ver" [...] as a new featured singer in Vocal Adrenaline who {{is a fan of}} both Mercedes and Kurt despite being a competition rival. Wade is a young trans woman, who wants to perform in competition as Unique but she lacks the confidence, until Mercedes and Kurt persuade her. When she appears on stage in the Glee Club Regionals competition, Unique is a success—so much so that Vocal Adrenaline director Jesse St. James decides to build the group's Nationals routine around Unique, and to promote her as a show choir star. Unique is dismayed by the publicity and pressure, but after a pep talk from Kurt and Mercedes, performs and wins the MVP award at Nationals competition, though Vocal Adrenaline comes in second to New Directions. In season four, she transfers to McKinley where she becomes a part of the New Directions. She develops a crush on Ryder, but is too afraid to demonstrate it, so she makes a <b>fake</b> <b>account</b> to get close to him. At the end of the fourth season, Ryder finds out that Unique has been behind the <b>fake</b> <b>account</b> and he tells her that he will never speak to her ever again. Although, she has felt more confident about herself since she joined the New Directions, she still struggles with others accepting her. She, along with some of the other members of New Directions transfer to other schools when the Glee Club is disbanded. Unique returns during the sixth season to help and support Coach Beiste with her decision to go through with a sex reassignment surgery. Newell was a runner-up in The Glee Project first season, and his prize was a two-episode arc on Glee. A possibility for his eventual character was described during a Project episode as [...] "the lovechild of Kurt and Mercedes". In addition to his second full appearance in [...] "Nationals", he also appears briefly in the episode [...] "Props".|$|E
25|$|Spreading {{beyond the}} {{centrally}} managed social networking platforms, user-generated content increasingly appears on business, government, and nonprofit websites worldwide. <b>Fake</b> <b>accounts</b> and comments planted by computers programmed to issue social spam can infiltrate these websites. Well-meaning and malicious human users can break websites' policies by submitting profanity, insults, hate speech, and violent messages.|$|R
50|$|Fake friends {{occurs when}} several <b>fake</b> <b>accounts</b> connect or become “friends”. These users or spambots often try to gain {{credibility}} by following verified accounts, {{such as those}} for popular celebrities and public figures. If that account owner follows the spammer back, it legitimizes the spam account, enabling it to do more damage.|$|R
50|$|Spreading {{beyond the}} {{centrally}} managed social networking platforms, user-generated content increasingly appears on business, government, and nonprofit websites worldwide. <b>Fake</b> <b>accounts</b> and comments planted by computers programmed to issue social spam can infiltrate these websites. Well-meaning and malicious human users can break websites' policies by submitting profanity, insults, hate speech, and violent messages.|$|R
