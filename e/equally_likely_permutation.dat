0|2232|Public
40|$|Spearman's Footrule, D, {{is the sum}} of the {{absolute}} values {{of the differences between the}} ranks in two rankings of n objects. For the case of <b>equally</b> <b>likely</b> <b>permutations,</b> tables of the exact cumulative distribution function (c. d. f.) of D are given for 11 [less-than-or-equals, slant] n [less-than-or-equals, slant] 18. The maximum difference between the exact c. d. f. for D and the normal approximation is given as well as the maximum difference between the exact c. d. f. for D and the normal approximation with correction for continuity. Spearman's footrule permutations cumulative distribution function normal approximation continuity correction...|$|R
25|$|In {{the output}} stream 0 and 1 are <b>equally</b> <b>likely,</b> as 10 and 01 are <b>equally</b> <b>likely</b> in the original, both having {{probability}} pqnbsp&=nbsp&qp. This extraction of uniform randomness {{does not require}} the input trials to be independent, only uncorrelated. More generally, it works for any exchangeable sequence of bits: all sequences that are finite rearrangements are <b>equally</b> <b>likely.</b>|$|R
50|$|A {{real number}} x {{is said to}} be normal if its digits in every base follow a uniform distribution: all digits being <b>equally</b> <b>likely,</b> all pairs of digits <b>equally</b> <b>likely,</b> all {{triplets}} of digits <b>equally</b> <b>likely,</b> etc. x {{is said to be}} normal in base b if its digits in base b follow a uniform distribution.|$|R
50|$|In {{the output}} stream 0 and 1 are <b>equally</b> <b>likely,</b> as 10 and 01 are <b>equally</b> <b>likely</b> in the original, both having {{probability}} pq = qp. This extraction of uniform randomness {{does not require}} the input trials to be independent, only uncorrelated. More generally, it works for any exchangeable sequence of bits: all sequences that are finite rearrangements are <b>equally</b> <b>likely.</b>|$|R
40|$|Heterogeneity in the {{underlying}} population places {{difficulties in the}} way of interpretation of all statistical data based on averages. No two persons are <b>equally</b> <b>likely</b> to die in the next year; no two marriages are <b>equally</b> <b>likely</b> to be broken up by divorce; no two businesses are <b>equally</b> <b>likely</b> to fail; no two automobiles are <b>equally</b> <b>likely</b> to break down. That on the average a given make of automobile will travel 50, 000 miles without major repairs offers little assurance for any particular automobile. Averages can be applied to individual cases only at great risk. This gross aspect of heterogeneity is not the subject of the present chapter...|$|R
50|$|Some {{treatments}} of probability {{assume that the}} various outcomes of an experiment are always defined {{so as to be}} <b>equally</b> <b>likely.</b> However, there are experiments that are not easily described by a sample space of <b>equally</b> <b>likely</b> outcomes—for example, if one were to toss a thumb tack many times and observe whether it landed with its point upward or downward, there is no symmetry to suggest that the two outcomes should be <b>equally</b> <b>likely.</b>|$|R
25|$|Originally, all six coins were <b>equally</b> <b>likely</b> to be chosen.|$|R
25|$|Originally, {{all three}} boxes were <b>equally</b> <b>likely</b> to be chosen.|$|R
50|$|Originally, all six coins were <b>equally</b> <b>likely</b> to be chosen.|$|R
50|$|Originally, {{all three}} boxes were <b>equally</b> <b>likely</b> to be chosen.|$|R
40|$|Randomness is {{a central}} concept to {{statistics}} and physics. A new statistical analysis provides evidence that tossing coins and finding last digits of prime numbers are identical problems regarding <b>equally</b> <b>likely</b> outcomes. This analysis explains why randomness of <b>equally</b> <b>likely</b> outcomes is valid at large numbers. Comment: 4 pages, 3 figures (submitted to Scientific Reports...|$|R
50|$|Yang and yin are <b>equally</b> <b>likely.</b> Static is {{more likely}} than changing.|$|R
25|$|In mathematics, {{a normal}} number {{is a real}} number whose {{infinite}} sequence of digits in every positive integer baseb is distributed uniformly {{in the sense that}} each of the b digit values has the same natural density1/b, also all possible b2pairs of digits are <b>equally</b> <b>likely</b> with densityb−2, all b3triplets of digits <b>equally</b> <b>likely</b> with densityb−3, etc.|$|R
5000|$|In {{probability}} theory and statistics, the discrete uniform distribution is a symmetric probability distribution whereby {{a finite number}} of values are <b>equally</b> <b>likely</b> to be observed; every one of n values has equal probability 1/n. Another way of saying [...] "discrete uniform distribution" [...] would be [...] "a known, finite number of outcomes <b>equally</b> <b>likely</b> to happen".|$|R
5000|$|... #Caption: Flipping a coin {{leads to}} two {{outcomes}} {{that are almost}} <b>equally</b> <b>likely.</b>|$|R
50|$|In statistics, inferences {{are made}} about {{characteristics}} of a population by studying a sample of that population's individuals. In order {{to arrive at a}} sample that presents an unbiased estimate of the true characteristics of the population, statisticians often seek to study a simple random sample—that is, a sample in which every individual in the population is <b>equally</b> <b>likely</b> to be included. The result of this is that every possible combination of individuals who could be chosen for the sample is also <b>equally</b> <b>likely</b> (that is, the space of simple random samples of a given size from a given population is composed of <b>equally</b> <b>likely</b> outcomes).|$|R
5000|$|In some sample spaces, it is {{reasonable}} to estimate or assume that all outcomes in the space are <b>equally</b> <b>likely</b> (that they occur with equal probability). For example, when tossing an ordinary coin, one typically assumes that the outcomes [...] "head" [...] and [...] "tail" [...] are <b>equally</b> <b>likely</b> to occur. An implicit assumption that all outcomes are <b>equally</b> <b>likely</b> underpins most randomization tools used in common games of chance (e.g. rolling dice, shuffling cards, spinning tops or wheels, drawing lots, etc.). Of course, players in such games can try to cheat by subtly introducing systematic deviations from equal likelihood (e.g. with marked cards, loaded or shaved dice, and other methods).|$|R
2500|$|The {{variance}} {{of a set}} of [...] <b>equally</b> <b>likely</b> values can be written as ...|$|R
5000|$|The {{applicants}} are interviewed sequentially {{in random}} order, with each order being <b>equally</b> <b>likely.</b>|$|R
40|$|In this paper, a die is {{a finite}} {{probability}} space whose outcomes are non-negative integers {{and that may}} have any probability distribution. A fair die is one for which all outcomes are <b>equally</b> <b>likely.</b> A sack is a finite set of independent dice and a sack is called fair if, when the dice are rolled, all totals are <b>equally</b> <b>likely.</b> More precis...|$|R
50|$|In mathematics, {{a normal}} number {{is a real}} number whose {{infinite}} sequence of digits in every base b is distributed uniformly {{in the sense that}} each of the b digit values has the same natural density 1/b, also all possible b2 pairs of digits are <b>equally</b> <b>likely</b> with density b−2, all b3 triplets of digits <b>equally</b> <b>likely</b> with density b−3, etc.|$|R
5000|$|Though most random {{phenomena}} do {{not have}} <b>equally</b> <b>likely</b> outcomes, it can be helpful to define a sample space {{in such a way}} that outcomes are at least approximately <b>equally</b> <b>likely,</b> since this condition significantly simplifies the computation of probabilities for events within the sample space. If each individual outcome occurs with the same probability, then the probability of any event becomes simply: ...|$|R
2500|$|As [...] observe, {{tabulation}} hashing is 3-independent but not 4-independent. [...] For {{any single}} key x, T is <b>equally</b> <b>likely</b> {{to take on}} any hash value, and the exclusive or of T with the remaining table values does not change this property. For any two keys x and y, x is <b>equally</b> <b>likely</b> to be mapped to any hash value as before, and {{there is at least}} one position i where xi≠yi; the table value T is used in the calculation of h(y) but not in the calculation of h(x), so even after the value of h(x) has been determined, h(y) is <b>equally</b> <b>likely</b> to be any valid hash value. Similarly, for any three keys x, y, and z, at least one of the three keys has a position i where its value z'i differs from the other two, so that even after the values of h(x) and h(y) are determined, h(z) is <b>equally</b> <b>likely</b> to be any valid hash value.|$|R
50|$|Of course, the two {{outcomes}} {{may not be}} <b>equally</b> <b>likely</b> (e.g. {{success of}} medical treatment).|$|R
5000|$|Facultative (FAC). <b>Equally</b> <b>likely</b> {{to occur}} in {{wetlands}} (estimated probability 34% - 66%) or non-wetlands.|$|R
2500|$|The flaw is in {{the last}} step. While those two cases were {{originally}} <b>equally</b> <b>likely,</b> {{the fact that you}} are certain to find a gold coin if you had chosen the GG box, but are only 50% sure of finding a gold coin if you had chosen the GS box, means they are no longer <b>equally</b> <b>likely</b> given that you have found a gold coin. Specifically: ...|$|R
50|$|One of the {{simplest}} examples of a discrete univariate distribution is the discrete uniform distribution, where all elements of a finite set are <b>equally</b> <b>likely.</b> It is the probability model for the outcomes of tossing a fair coin, rolling a fair die, etc. The univariate continuous uniform distribution on an interval b has the property that all sub-intervals of the same length are <b>equally</b> <b>likely.</b>|$|R
5000|$|The flaw is in {{the last}} step. While those two cases were {{originally}} <b>equally</b> <b>likely,</b> {{the fact that you}} are certain to find a gold coin if you had chosen the GG box, but are only 50% sure of finding a gold coin if you had chosen the GS box, means they are no longer <b>equally</b> <b>likely</b> given that you have found a gold coin. Specifically: ...|$|R
5000|$|A given {{threshold}} [...] partitions {{the continuum}} into regions {{above and below}} its location. The threshold corresponds with the location on a latent continuum at which it is <b>equally</b> <b>likely</b> a person will be classified into adjacent categories, and therefore to obtain one of two successive scores. The first threshold of item i, , is the location on the continuum at which a person is <b>equally</b> <b>likely</b> to obtain a score of 0 or 1, the second threshold is the location at which a person is <b>equally</b> <b>likely</b> to obtain a score of 1 and 2, and so on. In the example shown in Figure 1, the threshold locations are &minus;1.5, &minus;0.5, 0.5, and 1.5 respectively.|$|R
5000|$|Upon fixing , [...] is {{restructured}} and {{is constant}} as all codewords are <b>equally</b> <b>likely</b> to be sent.Therefore ...|$|R
5000|$|... #Caption: [...] Up or down? Flipping a brass tack {{leads to}} two {{outcomes}} {{that are not}} <b>equally</b> <b>likely.</b>|$|R
5000|$|... #Caption: Flipping a coin {{leads to}} a sample space {{composed}} of two outcomes that are almost <b>equally</b> <b>likely.</b>|$|R
2500|$|The three {{remaining}} {{possibilities are}} <b>equally</b> <b>likely,</b> so {{the probability that}} the drawer is from box GG is [...]|$|R
5000|$|How {{much change}} occurred? Is the {{difference}} significant {{or is it}} <b>equally</b> <b>likely</b> to {{have been caused by}} chance? ...|$|R
5000|$|The three {{remaining}} {{possibilities are}} <b>equally</b> <b>likely,</b> so {{the probability that}} the drawer is from box GG is [...]|$|R
30|$|If all {{polarization}} {{states are}} <b>equally</b> <b>likely</b> γ 0 [*]=[*]−π/ 2 {{and the distribution}} is uniform between 0 and 1.|$|R
