2495|3855|Public
25|$|Because {{the average}} <b>event</b> <b>rate</b> is 2.5 goals per match, ' = 2.5.|$|E
2500|$|Because {{the average}} <b>event</b> <b>rate</b> is one {{overflow}} flood per 100 years, ' = 1 ...|$|E
2500|$|If {{an event}} is {{passed by the}} Level 1 trigger all the data still {{buffered}} in the detector is sent over fibre-optic links to the [...] "High Level" [...] trigger, which is software (mainly written in C++) running on ordinary computer servers. The lower <b>event</b> <b>rate</b> in the High Level trigger allows time for much more {{detailed analysis of the}} event to be done than in the Level 1 trigger. The High Level trigger reduces the <b>event</b> <b>rate</b> by a further factor of hundred down to 1000 events per second. These are then stored on tape for future analysis.|$|E
40|$|Abstract Background Acute {{and chronic}} {{coronary}} heart disease (CHD) pose different burdens on health-care services and require different prevention and treatment strategies. Trends in acute and chronic CHD <b>event</b> <b>rates</b> can guide service implementation. This study evaluated changes in acute and chronic CHD <b>event</b> <b>rates</b> in metropolitan and regional/remote Victoria. Methods Victorian hospital admitted episodes with a principal diagnosis of acute CHD or chronic CHD were identified from 2005 to 2012. Acute and chronic CHD age-standardised <b>event</b> <b>rates</b> were calculated in metropolitan and regional/remote Victoria. Poisson log-link linear regression was used to estimate annual change in acute and chronic CHD <b>event</b> <b>rates.</b> Results Acute CHD age-standardised <b>event</b> <b>rates</b> decreased annually by 2. 9  % (95  % CI, − 4. 3 to − 1. 4  %) in metropolitan Victoria and 1. 7  % (95  % CI, − 3. 2 to − 0. 1  %) in regional/remote Victoria. In comparison, chronic CHD age-standardised <b>event</b> <b>rates</b> increased annually by 4. 8  % (95  % CI, + 3. 0 to + 6. 5  %) in metropolitan Victoria and 3. 1  % (95  % CI, + 1. 3 to + 4. 9  %) in regional/remote Victoria. On average, age-standardised <b>event</b> <b>rates</b> for regional/remote Victoria were 30. 3  % (95  % CI, 23. 5 to 37. 2  %) higher for acute CHD and 55. 3  % (95  % CI, 47. 1 to 63. 5  %) higher for chronic CHD compared to metropolitan Victoria from 2005 to 2012. Conclusion Annual decreases in acute CHD age-standardised <b>event</b> <b>rates</b> might reflect improvements in primary prevention, while annual increases in chronic CHD age-standardised <b>event</b> <b>rates</b> suggest a need to improve secondary prevention strategies. Consistently higher acute and chronic CHD age-standardised <b>event</b> <b>rates</b> were evident in regional/remote Victoria compared to metropolitan Victoria from 2005 to 2012...|$|R
40|$|<b>Event</b> <b>rates</b> {{of various}} lepton flavor violating {{processes}} in the minimal supersymmetric SU(5) model are calculated, using exact formulas which include Yukawa vertices of lepton-slepton-Higgsino. We find subtlety in evaluating <b>event</b> <b>rates</b> due to partial cancellation between diagrams. This cancellation typically reduces the <b>event</b> <b>rates</b> significantly, {{and the size of}} the reduction strongly depends on superparticle mass spectrum. 1 Fellows of the Japan Society for the Promotion of Science...|$|R
50|$|The Hosmer-Lemeshow test is a {{statistical}} test for {{goodness of fit}} for logistic regression models. It is used frequently in risk prediction models. The test assesses {{whether or not the}} observed <b>event</b> <b>rates</b> match expected <b>event</b> <b>rates</b> in subgroups of the model population. The Hosmer-Lemeshow test specifically identifies subgroups as the deciles of fitted risk values. Models for which expected and observed <b>event</b> <b>rates</b> in subgroups are similar are called well calibrated.|$|R
2500|$|An event {{can occur}} 0, 1, 2, … times in an {{interval}}. The {{average number of}} events in an interval is designated [...] (lambda). Lambda is the <b>event</b> <b>rate,</b> also called the rate parameter. The probability of observing [...] events in an interval is given by the equation ...|$|E
2500|$|To {{accomplish}} this, {{a series}} of [...] "trigger" [...] stages are employed. All the data from each crossing is held in buffers within the detector while {{a small amount of}} key information is used to perform a fast, approximate calculation to identify features of interest such as high energy jets, muons or missing energy. This [...] "Level 1" [...] calculation is completed in around 1nbsp&µs, and <b>event</b> <b>rate</b> is reduced by a factor of about thousand down to 50nbsp&kHz. All these calculations are done on fast, custom hardware using reprogrammable field-programmable gate arrays (FPGA).|$|E
2500|$|Cardiovascular disease (CVD) is a {{class of}} {{diseases}} that involve the heart or blood vessels. As the <b>event</b> <b>rate</b> is higher in men than in women, the decrease in events is more easily seen in men than women. In those at risk, but without a history of cardiovascular disease (primary prevention), statins decrease {{the risk of death}} and combined fatal and non-fatal cardiovascular disease. A United States guideline recommends statins in those who have a 12% or greater risk of cardiovascular disease over the next ten years. [...] Niacin, fibrates and CETP Inhibitors, while they may increase HDL cholesterol do not affect the risk of cardiovascular disease in those who are already on statins.|$|E
40|$|<b>Event</b> <b>rates</b> {{of various}} lepton flavor violating {{processes}} in the minimal supersymmetric SU(5) model are calculated, using exact formulas which include Yukawa vertices of lepton-slepton-Higgsino. We find subtlety in evaluating <b>event</b> <b>rates</b> due to partial cancellation between diagrams. This cancellation typically reduces the <b>event</b> <b>rates</b> significantly, {{and the size of}} the reduction strongly depends on superparticle mass spectrum. Comment: 11 pages, 8 figures. Fig. 5 where the mu-e conversion rates in nuclei was shown was incorrect due to an error in our numerical computation. It is replaced in this corrected version. All conclusions remain unchange...|$|R
40|$|Background Food and Drug Administration {{guidance}} now {{proposes that}} cardiovascular safety of new diabetes medicines be demonstrated. Consequently, trials {{should include a}} sufficient number of individuals with diabetes who are at high cardiovascular risk. We aimed to examine the impact of the presence of baseline cardiovascular disease and proteinuria, as binary criteria, on cardiovascular <b>event</b> <b>rates</b> in diabetes trials and to examine whether predicted primary end-point <b>event</b> <b>rates</b> are achieved. Methods We searched Medline and EMBASE English language records (January 1998 -June 2010) for randomized controlled trials of antiplatelet, lipid-lowering, antihypertensive, and glucose-lowering agents with > 1, 000 diabetic subjects reporting at least one of all-cause death, cardiovascular death, myocardial infarction, and stroke. Weighted mean <b>event</b> <b>rates</b> (events/ 1, 000 patient-years) were calculated. Data from published power calculations were also compared with achieved <b>event</b> <b>rates.</b> Results Twenty-nine trials met inclusion criteria. Weighted mean <b>event</b> <b>rates</b> in diabetic subjects with and those without baseline cardiovascular disease were, respectively, 28. 9 and 10. 0 for all-cause death, 16. 7 and 3. 6 for cardiovascular death, 23. 1 and 5. 2 for myocardial infarction, and 12. 1 and 5. 4 for stroke. <b>Event</b> <b>rates</b> in diabetic subjects with and those without proteinuria were, respectively, 39. 9 and 6. 3 for all-cause death and 18. 7 and 1. 2 for cardiovascular death. Nine of 11 relevant trials achieved primary end-point <b>event</b> <b>rates</b> clearly lower than predicted. Conclusions Trials including diabetic subjects without cardiovascular disease or proteinuria generate few events and require substantial participant numbers to achieve adequate power. However, the presence of coexisting cardiovascular disease or proteinuri...|$|R
40|$|Background: We {{examined}} the baseline characteristics and {{the rates of}} serious vascular events in randomized clinical trials after cerebral ischemia of presumed arterial origin to identify study features that predict vascular event incidence and to identify whether <b>event</b> <b>rates</b> have declined over time. Methods: We performed a systematic review to identify all published randomized controlled trials of patients with stroke or transient ischemic attack of presumed arterial origin that included an aspirin arm. We performed metaregression to analyze whether baseline features of included patients, design features and the year of study start and publication influenced vascular <b>event</b> <b>rates</b> under aspirin treatment. Results: Included studies comprised 23, 247 patients who had 3, 615 serious vascular events. Baseline characteristics of patients included in the different trials varied substantially over time. In multivariate metaregression analysis a shorter maximum allowed delay from symptom onset to randomization (p = 0. 012) and a double-blind design were associated with higher annual <b>event</b> <b>rates</b> (p = 0. 014). <b>Event</b> <b>rates</b> did not significantly decrease over time (p = 0. 242). Conclusion: The baseline characteristics of patients included in trials that study antiplatelet agents have changed over time. The strongest predictors for higher <b>event</b> <b>rates</b> are a double-blind design and a short delay between symptom onset and randomization. An important reduction in <b>event</b> <b>rates</b> over time could not be demonstrated. status: publishe...|$|R
50|$|The control <b>event</b> <b>rate</b> (CER) is {{identical}} to the experimental <b>event</b> <b>rate</b> except that is measured within the scientific control group of an experiment.|$|E
5000|$|... #Subtitle level 2: Vigilance Taxonomy: {{discrimination}} {{type and}} <b>event</b> <b>rate</b> ...|$|E
50|$|Because {{the average}} <b>event</b> <b>rate</b> is 2.5 goals per match, &lambda; = 2.5.|$|E
40|$|A {{review of}} supersymmetric dark matter in minimal supergravity {{unification}} with R-parity invariance and with radiative {{breaking of the}} electro-weak symmetry is given. The analysis shows the lightest neutralino is the LSP {{over most of the}} parameter space of the supergravity model. The <b>event</b> <b>rates</b> in neutralino- nucleus scattering in dark matter detectors are also discussed. It is found that the <b>event</b> <b>rates</b> are sensititive to the constraint from the b→ sγ experiment. It is also found that the <b>event</b> <b>rates</b> are sensitive to the constraints of relic density and in our analysis we have used the accurate method for the computation of the neutralino relic density. Finally,the effect of the new results on quark polarizabilities, from the data of the Spin Muon Collaboration, on <b>event</b> <b>rates</b> is also discussed. The analysis shows that the <b>event</b> <b>rates</b> for the Ge detectors and for other detectors which use heavy targets are only negligibly affected. Comment: latex file 11 pages, and 2 figs. The figs can be faxed on request. Based on talks at SUSY 95 at Ecole Polytechnique, Palaiseau, 95 and at the Pascos/ Hopkins Symposium at the John Hopkins, Baltimore, Maryland, 9...|$|R
40|$|Typically, full Bayesian {{estimation}} of correlated <b>event</b> <b>rates</b> can be computationally challenging since estimators are intractable. When {{estimation of}} <b>event</b> <b>rates</b> represents one activity {{within a larger}} modeling process, there is an incentive to develop more efficient inference than provided by a full Bayesian model. We develop a new subjective inference method for correlated <b>event</b> <b>rates</b> based on a Bayes linear Bayes model {{under the assumption that}} events are generated from a homogeneous Poisson process. To reduce the elicitation burden we introduce homogenization factors to the model and, as an alternative to a subjective prior, an empirical method using the method of moments is developed. Inference under the new method is compared against estimates obtained under a full Bayesian model, which takes a multivariate gamma prior, where the predictive and posterior distributions are derived in terms of well-known functions. The mathematical properties of both models are presented. A simulation study shows that the Bayes linear Bayes inference method and the full Bayesian model provide equally reliable estimates. An illustrative example, motivated by a problem of estimating correlated <b>event</b> <b>rates</b> across different users in a simple supply chain, shows how ignoring the correlation leads to biased estimation of <b>event</b> <b>rates...</b>|$|R
40|$|The {{possibility}} of detecting supersymmetric dark matter is examined {{within the framework}} of the minimal supergravity model (MSGM) where the Z̃_ 1 is the LSP for almost the entire parameter space. A brief discussion is given of experimental strategies for detecting dark matter. The relic density is constrained to obey 0. 10 ≤Ω_Z̃_ 1 h^ 2 ≤ 0. 35, consistent with COBE data. Expected <b>event</b> <b>rates</b> for an array of possible terrestrial detectors (^ 3 He, CaF_ 2, Ge, GaAs, NaI and Pb) are examined. In general, detectors relying on coherrent Z̃_ 1 -nucleus scattering are more sensitive than detectors relying on incoherrent (spin-dependent) scattering. The dependence of the <b>event</b> <b>rates</b> as a function of the SUSY parameters are described. The detectors are generally most sensitive to the small m_ 0 and small m_q̃ and large tanβ part of the parameter space. The current b→ s+γ decay rate eliminates regions of large <b>event</b> <b>rates</b> for μ > 0, but allows large <b>event</b> <b>rates</b> to still occur for μ< 0. MSGM models that also possess SU(5) -type proton decay generally predict <b>event</b> <b>rates</b> below the expected sensitivity of current dark matter detectors. ...|$|R
50|$|They {{observed}} {{an annual}} modulation in the <b>event</b> <b>rate</b> that could indicate light dark matter.|$|E
5000|$|Because {{the average}} <b>event</b> <b>rate</b> is one {{overflow}} flood per 100 years, &lambda; = 1 ...|$|E
5000|$|Event [...] "Z" [...] {{in control}} group : 4 in 25 peopleControl <b>event</b> <b>rate</b> : 4/25 ...|$|E
5000|$|The Hosmer-Lemeshow test uses a test {{statistic}} that asymptotically follows a [...] distribution {{to assess whether}} or not the observed <b>event</b> <b>rates</b> match expected <b>event</b> <b>rates</b> in subgroups of the model population. This test is considered to be obsolete by some statisticians because of its dependence on arbitrary binning of predicted probabilities and relative low power.|$|R
50|$|Biapenem (Japanese {{approval}} 2001) exhibits similar {{efficacy and}} adverse <b>event</b> <b>rates</b> as other carbapenems.|$|R
40|$|This study finds high adverse <b>events</b> <b>rates</b> for {{surgical}} {{patients in}} Australian hospitals.   Objectives Adverse <b>event</b> or complication <b>rates</b> are increasingly advocated as measures of hospital quality and performance. Objective {{of this study}} is to analyse patient-complexity adjusted adverse <b>events</b> <b>rates</b> to compare the performance of hospitals in Victoria, Australia. This study uses a unique hospital dataset that routinely records adverse events which arise during the admission. It identifies hospitals with below or above average performance in comparison to their peers, and show for which types of hospitals risk adjusting makes biggest difference. Methods This study estimates adverse <b>event</b> <b>rates</b> for 87, 790 elective and 43, 771 emergency episodes in 34 public hospitals over the financial year 2005 / 06 with a complementary log–log model, using patient level administrative hospital data and controlling for patient complexity with a range of covariates. Results Teaching hospitals have average risk-adjusted adverse <b>event</b> <b>rates</b> of 24. 3 % for elective and 19. 7 % for emergency surgical patients. Suburban and rural hospitals have lower rates of 17. 4 % and 17 %, and 16. 1 % and 15. 7 %, respectively. Selected non-teaching hospitals have relatively high rates, in particular hospitals in rural and socially disadvantaged areas. Risk adjustment makes a significant difference to most hospitals. Conclusion There are comparably high adverse <b>events</b> <b>rates</b> for surgical patients in Australian hospitals, possibly because our data allow identification of a larger number of adverse events than data used in previous studies. There are marked variations in adverse <b>event</b> <b>rates</b> across hospitals in Victoria, even after risk adjusting. This study discusses how policy makers could improve quality of care in Australian hospitals...|$|R
5000|$|Event [...] "Z" [...] in {{experimental}} group : 12 in 25 peopleExperimental <b>event</b> <b>rate</b> : 12/25 ...|$|E
50|$|The {{resultant}} higher <b>event</b> <b>rate</b> poses important {{challenges for}} the particle detectors located in the collision areas.|$|E
50|$|Each {{branch in}} the tree {{indicates}} a split {{on the value of}} a variable. For example, the root of the tree splits subjects with grade < 2.5 versus subjects with grade 2.5 or greater. The terminal nodes indicate the number of subjects in the node, the number of subjects who have events, and the relative <b>event</b> <b>rate</b> compared to the root. In the node on the far left, the values 1/33 indicate that 1 of the 33 subjects in the node had an event, and that the relative <b>event</b> <b>rate</b> is 0.122. In the node on the far right bottom, the values 11/15 indicate that 11 of 15 subjects in the node had an event, and the relative <b>event</b> <b>rate</b> is 2.7.|$|E
40|$|We compare adverse <b>event</b> <b>rates</b> for {{surgical}} inpatients across 36 {{public hospitals}} {{in the state of}} Victoria, Australia, conditioning on differences in patient complexity across hospitals. We estimate separate models for elective and emergency patients which stay at least one night in hospitals, using fixed effects complementary log-log models to estimate AEs as a function of patient and episode characteristics, and hospital effects. We use 4 years of patient level administrative hospital data (2002 / 03 to 2005 / 06), and estimate separate models for each year. Averaged over four years, we find that adverse <b>event</b> <b>rates</b> are 12 % for elective surgical inpatients, and 12. 5 % for emergency surgical inpatients. Most teaching hospitals have surprisingly low adverse <b>event</b> <b>rates,</b> at least after adjusting for the higher medical complexity of their patients. Some larger regional hospitals have high adverse <b>events</b> <b>rates,</b> in particular after adjusting for the below average complexity of their patients. Also, some suburban hospitals have high rates, especially the ones located in areas of low socioeconomic profile. We speculate that high rates may be due to factors beyond the control of the hospitals, such as staff shortages. We conclude that at present, care should be taken when using adverse <b>event</b> <b>rates</b> as indicators of hospital qualityAdverse events, hospital performance, hospital quality, patient complexity...|$|R
3000|$|... are weights for normalization. In {{addition}} we {{obtain the}} weekday and weekend <b>event</b> <b>rates</b> averaged over all users.|$|R
40|$|Food and Drug Administration {{guidance}} now {{proposes that}} cardiovascular safety of new diabetes medicines be demonstrated. Consequently, trials {{should include a}} sufficient number of individuals with diabetes who are at high cardiovascular risk. We aimed to examine the impact of the presence of baseline cardiovascular disease and proteinuria, as binary criteria, on cardiovascular <b>event</b> <b>rates</b> in diabetes trials and to examine whether predicted primary end-point <b>event</b> <b>rates</b> are achieved...|$|R
50|$|In epidemiology, the {{relative}} risk reduction is a measure calculated by dividing the absolute risk reduction by the control <b>event</b> <b>rate.</b>|$|E
50|$|EURECA {{will take}} this {{cryogenic}} detector technology pioneered by CRESST and EDELWEISS further {{by building a}} 1 tonne absorber mass made up from {{a large number of}} cryogenic detector modules. The experiment plans to use a range of detector materials. This provides a way to show if a positive signal is due to dark matter, as the <b>event</b> <b>rate</b> is expected to scale with the atomic mass of the target nuclei. Whereas the <b>event</b> <b>rate</b> from neutrons will be higher for lighter nuclei.|$|E
5000|$|The {{effect of}} <b>event</b> <b>rate</b> on {{monitoring}} task performance {{can be affected}} by the addition of non-target salient objects at varying frequencies. Clock test research conducted in the late 1950s and 1960s indicates that an increase in <b>event</b> <b>rate</b> for rare irregular low salience signals reduced the vigilance decrement. When non-target [...] "artificial" [...] signals similar to target signals were introduced, the vigilance decrement was also reduced. When the [...] "artificial" [...] signal differed significantly from the target signal, no performance improvement was measured.|$|E
40|$|The {{achievable}} tanbeta determination accuracy for CMS at LHC is presented. Using MSSM H/A -> tau tau decay in {{the associated}} production process gg->bbH/A, the <b>event</b> <b>rates</b> are measured at large tanbeta and the systematic and statistical errors are estimated. Due to {{sensitivity of the}} above <b>event</b> <b>rates</b> to tanbeta, it is shown {{that it is possible}} to determine constraints on tanbeta for a given set of SUSY parameters uncertainties...|$|R
5000|$|Choose a {{time step}} [...] This may be fixed, or by some {{algorithm}} {{dependent on the}} various <b>event</b> <b>rates.</b>|$|R
40|$|We {{evaluate}} the upward shower and muon <b>event</b> <b>rates</b> for two characteristic four neutrino mixing models for extragalactic neutrinos, {{as well as}} for the atmospheric neutrinos, with energy thresholds of 1 TeV, 10 TeV and 100 TeV. We show that by comparing the shower to muon <b>event</b> <b>rates,</b> one can distinguish between oscillation and no-oscillation models. By measuring shower and muon <b>event</b> <b>rates</b> for energy thresholds of 10 TeV and 100 TeV, and by considering their ratio, it is possible to use extragalactic neutrino sources to determine the type of four-flavor mixing pattern. We find that one to ten years of data taking with kilometer-size detector has a very good chance of providing valuable information about the physics beyond the Standard Model. Comment: version accepted for publication in Phys. Rev. ...|$|R
