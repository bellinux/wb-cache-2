1|30|Public
40|$|In {{this paper}} a {{procedure}} {{to test the}} equality of error distributions in several nonparametric regression models is introduced. Kolmogorov-Smirnov and Cramer-von Mises-type statistics are proposed and their asymptotic distributions are obtained. A bootstrap mechanism is used to approximate the critical values in practice. Error distribution <b>k-Samples</b> <b>problem</b> Nonparametric regression...|$|E
40|$|The present paper {{deals with}} the choice of {{clustering}} algorithms before treating a <b>k-sample</b> <b>problem.</b> We investigate multivariate data sets that are quantized by algorithms that define partitions by maximal support planes (MSP) of a convex function. These algorithms belong to a wide class containing as special cases both the well known k-means algorithm and the Kohonen (1985) algorithm and have been profoundly investigated by Potzelberger and Strasser (1999). For computing the test statistics for the <b>k-sample</b> <b>problem</b> we replace the data points by their conditional expections {{with respect to the}} MSP-partition. We present Monte Carlo simulations of power functions of different tests for the <b>k-sample</b> <b>problem</b> whereas the tests are carried out as multivariate permutation tests to ensure that they hold the level. The results presented show that {{there seems to be a}} vital and decisive connection between the optimal choice of the clustering algorithm and the tails of the probability distributi [...] ...|$|R
40|$|A {{method for}} {{estimating}} {{the ranks of}} the underlying uncensored observations in a censored data set is proposed. The derived ranks are used to extend the use of the rank transform method to the censored matched pairs and the censored <b>k-sample</b> <b>problems.</b> The derived procedure for the censored matched pairs problem is new and consists of performing a paired-t test on the defined ranks. The procedure for the <b>k-sample</b> <b>problem</b> consists of performing a one-way ANOVA F-test on the derived ranks. This is essentially identical to a statistic proposed by Peto and Peto (1972). The asymptotic power of this procedure is derived and multiple comparison procedures based on it are proposed. The robustness of this test and multiple comparison procedures to departures from the assumption of equal censoring distributions is also established. ...|$|R
40|$|Abstract. Recently {{the authors}} have {{proposed}} tests for the one-sample and the <b>k-sample</b> <b>problem,</b> and a test for independence. All three tests are based on sample space partitions, but they were originally developed in different papers. Here we give {{an overview of the}} construction of these tests, stressing the common underlying concept of “sample space partitions. ...|$|R
40|$|AbstractIn {{previous}} papers [Approximate {{and local}} Bahadur efficiency of linear rank {{tests in the}} two-sample problem, Ann. Statist. 7, 1246 – 1255, 1979; Local comparison of linear rank tests in the Bahadur sense, Metrika, 1979] the author developed for linear rank tests of the one-sample symmetry and the <b>k-sample</b> <b>problem</b> (k ≥ 2) a theory of local comparison, based {{on the concept of}} Bahadur efficiency. In the present article this theory is carried over to rank tests of the independence problem...|$|R
40|$|An {{overview}} of some nonparametric procedures based on precedence (or exceedance) statistics is given. The procedures include both tests and confidence intervals. In particular, {{the construction of}} some simple distribution-free confidence bounds for location difference of two distributions with the same shape is considered and some properties are derived. The asymptotic relative efficiency of an asymptotic form of the corresponding test relative to Wilcoxon's two-sample rank sum test and the two-sample Student t-test is given for various cases. Some <b>K-sample</b> <b>problems</b> are discussed where precedence-type tests are useful, along with {{a review of the}} literature...|$|R
40|$|In {{previous}} papers [Approximate {{and local}} Bahadur efficiency of linear rank {{tests in the}} two-sample problem, Ann. Statist. 7, 1246 - 1255, 1979; Local comparison of linear rank tests in the Bahadur sense, Metrika, 1979] the author developed for linear rank tests of the one-sample symmetry and the <b>k-sample</b> <b>problem</b> (k >= 2) a theory of local comparison, based {{on the concept of}} Bahadur efficiency. In the present article this theory is carried over to rank tests of the independence problem. Approximate and exact Bahadur efficiency rank tests local efficiency local optimality efficiency bounds...|$|R
40|$|Probably, one of {{the most}} useful criterions in order to compare {{distribution}} functions is the one introduced by the researchers Harald Cramér and Richard Edler von Mises which is known as Cramérvon Mises criterion $(C_M) $. It has been applied on a vast variety of problems. In this work, the theory of empirical processes is applied in order to obtain the asymptotic distribution for the generalization to the <b>k-sample</b> <b>problem</b> of $(C_M) $ proposed by Kiefer. The quality of this approximation is also studied and some indications about how to obtain an approximation to the final P-value are also included...|$|R
40|$|A <b>k-sample</b> testing <b>problem</b> for the {{dispersive}} {{comparison of}} distributions in the fully nonparametric sense of Bickel and Lehmann (1979) and Lewis and Thompson (1981) is considered. A functional which is monotone {{with respect to}} the ordering in dispersion is proposed. Asymptotic laws of the resulting test statistics are established. The tests are shown to be asymptotically distribution free and consistent. A result concerning the optimality in this class of tests, under a sequence of local alternatives, is obtained and asymptotic relative efficiencies with respect to other tests for some specific alternatives are given. Nonparametric Dispersive ordering <b>k-sample</b> scale <b>problem</b> Test for dispersion Order statistic Invariance...|$|R
40|$|Most of the {{traditional}} statistical methods are being adapted to the Functional Data Analysis (FDA) context. The repeated measures analysis which deals with the <b>k-sample</b> <b>problem</b> when the data are from the same subjects is investigated. Both the parametric and the nonparametric approaches are considered. Asymptotic, permutation and bootstrap approximations for the statistic distribution are developed. In order to explore the statistical power of the proposed methods in different scenarios, a Monte Carlo simulation study is carried out. The {{results suggest that the}} studied methodology can detect small differences between curves even with small sample sizes. Repeated measure Functional data analysis Paired design Bootstrap method...|$|R
40|$|Maximum {{likelihood}} {{approach for}} independent but not identically distributed observations is studied. In {{the first part}} of the thesis, conditions for consistency and asymptotic normality of the maximum likelihood estimates for this case are stated. Uniform integrability has a major role in proving the desired properties. <b>K-sample</b> <b>problem</b> serves as an example for using the described method. The second part is focused on estimates obtained by minimizing convex functions. Convexity is a key for showing the consistency and asymptotic normality of the estimates in this case. The results can be used for maximum likelihood when observations with logconcave densities are involved. Finally, normal linear model, logistic regression and Poisson regression examples are provided to present the application of the method...|$|R
40|$|Conditioning on the {{observed}} data {{is an important}} and flexible design principle for statistical test procedures. Although generally applicable, permutation tests currently in use are limited {{to the treatment of}} special cases, such as contingency tables or <b>K-sample</b> <b>problems.</b> A new theoretical framework for permutation tests opens up the way to a unified and generalized view. This article argues that the transfer of such a theory to practical data analysis has important implications in many applications and requires tools that enable the data analyst to compute on the theoretical concepts as closely as possible. We reanalyze four datasets by adapting the general conceptual framework to these challenging inference problems and using the coin add-on package in the R system for statistical computing to show what one can gain from going beyond the "classical" test procedures. © 2006 American Statistical Association...|$|R
40|$|This paper {{extends the}} work of Quessy and Éthier (2012) who {{considered}} tests for the <b>k-sample</b> <b>problem</b> with dependent samples. Here, the marginal distributions are allowed, under H 0, to differ according to their mean and their variance; in other words, one focuses on {{the shape of the}} distributions. Although easily stated, this problem nevertheless requires a careful treatment for the computation of valid P values. To this end, two bootstrap strategies based on the multiplier central limit theorem are proposed, both exploiting a representation of the test statistics in terms of a Hadamard differentiable functional. This accounts for the fact that one works with empirically standardized data instead of the original observations. Simulations reported show the nice sample properties of the method based on Cramér-von Mises and characteristic function type statistics. The newly introduced tests are illustrated on the marginal distributions of the eight-dimensional Oil currency data set...|$|R
40|$|Widely used {{parametric}} generalizedlinear models are, unfortunately,a somewhat limited {{class of}} speci � cations. Nonparametric aspects are often introduced to enrich this class, resultingin semiparametricmodels. Focusing on single or k-sample problems,many classical nonparametricapproaches{{are limited to}} hypothesistesting. Those that allow estimation are limited to certain functionals of the underlying distributions. Moreover, the associated inference often relies upon asymptotics when nonparametric speci � cations are often most appealing for smaller sample sizes. Bayesian nonparametricapproachesavoid asymptotics but have, to date, been limited {{in the range of}} inference. Working with Dirichlet process priors, we overcome the limitations of existing simulation-basedmodel � tting approaches which yield inference that is con � ned to posterior moments of linear functionals of the population distribution. This article provides a computationalapproach to obtain the entire posterior distribution for more general functionals. We illustrate with three applications: investigation of extreme value distributions associated with a single population, comparison of medians in a <b>k-sample</b> <b>problem,</b> and comparison of survival times from different populations under fairly heavy censoring...|$|R
40|$|Abstract. Testing {{hypotheses}} about variance parameters arises in contexts where uniformity {{is important and}} also in relation to checking assumptions as a preliminary to analysis of variance (ANOVA), dose-response model-ing, discriminant analysis and so forth. In contrast to procedures for tests on means, tests for variances derived assuming normality of the parent popula-tions are highly nonrobust to nonnormality. Procedures that aim to achieve robustness follow three types of strategies: (1) adjusting a normal-theory test procedure using an estimate of kurtosis, (2) carrying out an ANOVA on a spread variable computed for each observation and (3) using resampling of residuals to determine p values for a given statistic. We review these three approaches, comparing properties of procedures {{both in terms of}} the theoret-ical basis and by presenting examples. Equality of variances is first consid-ered in the two-sample problem followed by the <b>k-sample</b> <b>problem</b> (one-way design). Key words and phrases: Comparing variances, measures of spread, permu-tation method, resampling, resamples, variability. 1...|$|R
40|$|In {{this paper}} limit theorems for the {{conditional}} distributions of linear test statistics are proved. The assertions are conditioned by the sigma-field of permutation symmetric sets. Limit theorems are proved {{both for the}} conditional distributions under the hypothesis of randomness and under general contiguous alternatives with independent but not identically distributed observations. The proofs are based on results on limit theorems for exchangeable random variables by Strasser and Weber. The limit theorems under contiguous alternatives are consequences of an LAN-result for likelihood ratios of symmetrized product measures. The results of the paper have implications for statistical applications. By example it is shown that minimum variance partitions which are defined by observed data (e. g. by LVQ) lead to asymptotically optimal adaptive tests for the <b>k-sample</b> <b>problem.</b> As another application it is shown that conditional k-sample tests {{which are based on}} data-driven partitions lead to simple confidence sets which can be used for the simultaneous analysis of linear contrasts. (author's abstract) Series: Report Series SFB "Adaptive Information Systems and Modelling in Economics and Management Science...|$|R
40|$|This master thesis {{discusses}} selected {{topics of}} Functional Data Analysis (FDA). FDA {{deals with the}} random variables (and process) with realizations in the (smooth) functional space. The {{first part of this}} thesis introduces the basic assumptions, notation and ideas of FDA, here we will mainly focus on the functional basis approach. The second chapter deals with the {{one of the most popular}} FDA technique – Functional Principal Components Analysis (FPCA). FPCA is the functional analogue of the well known dimension reduction technique in the multivariate statistical analysis – search for the (pairwise orthogonal) linear transformations of the random vector with the maximal variance. In the second part of this thesis we discuss the <b>k-sample</b> <b>problem</b> in the framework of the FPCA. As the starting point we use the Common Principal Components Modelling in the multivariate statistical analysis. Apart from these theoretical considerations, the second main result of this thesis is the implementation of discussed FDA techniques in the statistical computing environment XploRe. Here we focus on the statistical macros (quantlets), graphical and plotting tools of functional data analysis...|$|R
40|$|Semiparametric {{models to}} {{describe}} the functional relationship between k groups of observations are broadly applied in statistical analysis, ranging from nonparametric ANOVA to proportional hazard (ph) rate models in survival analysis. In this paper {{we deal with the}} empirical assessment of the validity of such a model, which will be denoted as a "structural relationship model". To this end Hadamard differentiability of a suitable goodness-of-fit measure in the k-sample case is proved. This yields asymptotic limit laws which are applied to construct tests for various semiparametric models, including the Cox ph model. Two types of asymptotics are obtained, first when the hypothesis of the semiparametric model under investigation holds true, and second for the case when a fixed alternative is present. The latter result can be used to validate the presence of a semiparametric model instead of simply checking the null hypothesis "the model holds true". Finally, various bootstrap approximations are numerically investigated and a data example is analyzed. Semiparametric model Hadamard differentiability Quadratic differentiability Weak convergence <b>k-sample</b> <b>problem</b> Goodness-of-fit Proportional hazard rates Nonlinear approximation Multivariate empirical process...|$|R
40|$|AbstractIn this paper, {{we discuss}} the problem of testing the {{homogeneity}} of several populations when the available data are progressively Type-II censored. Defining for each sample a univariate counting process, we can modify all the methods that were developed {{during the last two}} decades (see e. g. [P. K. Andersen, Ø. Borgan, R. Gill, N. Keiding, Statistical Models Based on Counting Processes, Springer, New York, 1993]) for use to this problem. An important aspect of these tests is that they are based on either linear or non-linear functionals of a discrepancy process (DP) based on the comparison of the cumulative hazard rate (chr) estimated from each sample with the chr estimated from the whole sample (viz., the aggregation of all the samples), leading to either linear tests or non-linear tests. Both these kinds of tests suffer from some serious drawbacks. For example, it is difficult to extend non-linear tests to the K-sample situation when K⩾ 3. For this reason, we propose here a new class of non-linear tests, based on a chi-square type functional of the DP, that {{can be applied to the}} <b>K-sample</b> <b>problem</b> for any K⩾ 2...|$|R
40|$|Given {{independent}} samples from P and Q, two-sample permutation tests allow one to construct exact level tests when {{the null hypothesis}} is P=Q. On the other hand, when comparing or testing particular parameters θ of P and Q, such as their means or medians, permutation tests need not be level α, or even approximately level α in large samples. Under very weak assumptions for comparing estimators, we provide a general test procedure whereby the asymptotic validity of the permutation test holds while retaining the exact rejection probability α in finite samples when the underlying distributions are identical. The ideas are broadly applicable and special attention {{is given to the}} <b>k-sample</b> <b>problem</b> of comparing general parameters, whereby a permutation test is constructed which is exact level α under the hypothesis of identical distributions, but has asymptotic rejection probability α under the more general null hypothesis of equality of parameters. A Monte Carlo simulation study is performed as well. A quite general theory is possible based on a coupling construction, as well as a key contiguity argument for the multinomial and multivariate hypergeometric distributions. Comment: Published in at [URL] the Annals of Statistics ([URL] by the Institute of Mathematical Statistics ([URL]...|$|R
40|$|The <b>k-sample</b> <b>problem,</b> i. e., testing whether two or {{more data}} sets {{come from the same}} population, is a classic one in statistics. Instead of having a small number of k groups of samples, this {{dissertation}} works on a large number of p groups of samples, where within each group, the sample size, n, is a fixed, small number. We call this as a "Large p, but Small n" setting. The primary goal of the research is to provide a test statistic based on kernel density estimation (KDE) that has an asymptotic normal distribution when p goes to infinity with n fixed. In this dissertation, we propose a test statistic called Tp(S) and its standardized version, T(S). By using T(S), we conduct our test based on the critical values of the standard normal distribution. Theoretically, we show that our test is invariant to a location and scale transformation of the data. We also find conditions under which our test is consistent. Simulation studies show that our test has good power against a variety of alternatives. The real data analyses show that our test finds differences between gene distributions that are not due simply to location...|$|R
40|$|High-dimensional data {{analysis}} {{has been a}} prominent topic of statistical research in recent years due to the growing presence of high-dimensional electronic data. Much of the current {{work has been done}} on analyzing a sample of high-dimensional multivariate data. However, not as much research has been done on analyzing a sample of matrixvariate data. The population value decomposition (PVD), originated in Crainiceanu et al (2011), is a method for dimension reduction of a population of massive images. Images are decomposed into a product of two orthogonal matrices with population-specific features and one matrix with subject-specific features. The problems of finding the optimal row and column dimensions of reduction for the population of data matrices and inference in the PVD framework have yet to be solved. To find the optimal row and column dimensions, we base our methods on the low-rank approximation methods and optimization procedures of Manton et al (2003). In order to develop our inferential procedures, we assume our data to be matrix normally distributed. We introduce likelihood-ratio tests, score tests, and regression-based inferential procedures for the one, two, and <b>k-sample</b> <b>problems</b> and derive the distributions of the resulting test statistics. Results of the implementation of inferential procedures on simulated facial imaging data will be discussed. 2019 - 08 - 1...|$|R
40|$|In this paper, {{we discuss}} the problem of testing the {{homogeneity}} of several populations when the available data are progressively Type-II censored. Defining for each sample a univariate counting process, we can modify all the methods that were developed {{during the last two}} decades (see e. g. [P. K. Andersen, Ø. Borgan, R. Gill, N. Keiding, Statistical Models Based on Counting Processes, Springer, New York, 1993]) for use to this problem. An important aspect of these tests is that they are based on either linear or non-linear functionals of a discrepancy process (DP) based on the comparison of the cumulative hazard rate (chr) estimated from each sample with the chr estimated from the whole sample (viz., the aggregation of all the samples), leading to either linear tests or non-linear tests. Both these kinds of tests suffer from some serious drawbacks. For example, it is difficult to extend non-linear tests to the K-sample situation when K[greater-or-equal, slanted] 3. For this reason, we propose here a new class of non-linear tests, based on a chi-square type functional of the DP, that {{can be applied to the}} <b>K-sample</b> <b>problem</b> for any K[greater-or-equal, slanted] 2. Progressive censoring Counting processes Homogeneity tests Chi-square tests Reliability...|$|R
40|$|We {{consider}} a <b>k-sample</b> <b>problem,</b> k> 2, where samples {{have been obtained}} from k (random) generators, and {{we are interested in}} identifying those samples, if any, that exhibit substantial deviations from a pattern given by most of the samples. This main pattern would consist of component samples which should exhibit some internal degree of similarity. To handle similarity, can be of interest in a variety of situations. As an example, imagine a nation-wide evaluation test in which several markers evaluate exams coming from all the country. The interest focuses on analyzing if there are markers whose grades exhibit significant deviations from a generalized pattern. A null hypothesis of homogeneity is too strong to be considered as a realistic one because of the differences in the backgrounds of the involved students and similarity seems more appropriate. To detect deviations we need to use some pattern as a reference, that in our setup is a hidden pattern. In this paper we develop a statistical procedure designed to search for a main pattern, detecting the samples that are significantly less similar with respect to (a pooled version of) the others. This is done through a probability metric, a bootstrap approach and a stepwise search algorithm. Moreover, the procedure also allows to identify which part of each sample makes it different of the others...|$|R
40|$|In this manuscript, {{we study}} the nonparametric <b>k-sample</b> test <b>problem</b> with panel count data. The {{asymptotic}} normality of a smooth functional of the nonparametric maximum pseudo-likelihood estimator (Wellner and Zhang, 2000) is established under some mild conditions. We construct {{a class of}} easy-to-implement nonparametric tests for comparing mean functions of k populations based on this asymptotic normality. We conduct various simulations to validate and compare the tests. The simulations show that the tests perform quite well and generally have a good power to detect difference of the mean functions. The method is illustrated with two real data examples...|$|R
40|$|Doctor of PhilosophyDepartment of StatisticsPaul I. NelsonRank based {{inference}} using independent {{random samples}} to compare K> 1 continuous distributions, called the <b>K-sample</b> <b>problem,</b> based on precedence probabilities is developed and explored. There are many parametric and nonparametric approaches, most dealing with hypothesis testing, to this important, classical problem. Most existing tests {{are designed to}} detect differences among the location parameters of different distributions. Best known and most widely used {{of these is the}} F- test, which assumes normality. A comparable nonparametric test was developed by Kruskal and Wallis (1952). When dealing with location-scale families of distributions, both of these tests can perform poorly if the differences among the distributions are among their scale parameters and not in their location parameters. Overall, existing tests are not effective in detecting changes in both location and scale. In this dissertation, I propose a new class of rank-based, asymptotically distribution- free tests that are effective in detecting changes in both location and scale based on precedence probabilities. Let X_{i} be a random variable with distribution function F_{i}; Also, let _pi_ be the set of all permutations of the numbers (1, 2, [...] .,K). Then P(X_{i_{ 1 }}< [...] . <X_{i_{K}}) is a precedence probability if (i_{ 1 }, [...] .,i_{K}) belongs to _pi_. Properties of these of tests are developed using the theory of U-statistics (Hoeffding, 1948). Some of these new tests are related to volumes under ROC (Receiver Operating Characteristic) surfaces, which are of particular interest in clinical trials whose goal is to use a score to separate subjects into diagnostic groups. Motivated by this goal, I propose three new index measures of the separation or similarity among two or more distributions. These indices may be used as “effect sizes”. In a related problem, Properties of precedence probabilities are obtained and a bootstrap algorithm is used to estimate an interval for them...|$|R
40|$|A general {{iterative}} {{maximum likelihood}} procedure for {{estimation of the}} parameters of a randomly censored univariate or bivariate normal distribution is developed, based on Orchard and Woodbury's "Missing Information Principle " (HIP). This procedure is applied as a ganeral solution to univariate and bivariate <b>k-sample</b> estimation <b>problems</b> and multiple liilear regression estimation problems {{in the presence of}} random censoring on one or both variables. The proced re is applied in the univariate cases to data sets from the literature for which specific methods have been developed and for hich solutions are therefore known. Simulations are run in several bivariate cases to establish the small sample characteristics of the estimates under several censoring regimens, and to demonstrate the general applicability of the procedure. Likelihood ratio tests are derived for use under random censorship conditions::or both univariate and bivariate normal problems, and...|$|R
40|$|In this paper, we {{consider}} the general linear hypothesis testing (GLHT) problem in heteroscedastic one-way MANOVA. The well-known Wald-type test statistic is used. Its null distribution is approximated by a Hotelling T 2 distribution with one parameter estimated from the data, resulting in the so-called approximate Hotelling T 2 (AHT) test. The AHT test is shown to be invariant under affine transformation, different choices of the contrast matrix specifying the same hypothesis, and different labeling schemes of the mean vectors. The AHT test can be simply conducted using the usual F-distribution. Simulation studies and real data applications show that the AHT test substantially outperforms the test of [1] and {{is comparable to the}} parametric bootstrap (PB) test of [2] for the multivariate <b>k-sample</b> Behrens-Fisher <b>problem</b> which is a special case of the GLHT problem in heteroscedastic one-way MANOVA...|$|R
40|$|It {{is often}} {{interest}} to undertake a general linear hypothesis testing (GLHT) {{problem in the}} one-way  ANOVA without assuming the equality of thegroup variances. When the equality of the group variances is valid,it {{is well known that}} the GLHT problem can be solved by the classical F-test. The classical F-test, however,  may  lead to misleading conclusions when the variance homogeneity assumption is seriously violated since it doesnot take the group variance heteroscedasticity into account. To ourknowledge, little work has been done for this heteroscedastic GLHTproblem  except for some special cases. In this paper, we propose asimple approximate Hotelling T 2 (AHT) test.  We show that the AHTtest is invariant under affine-transformations, different choices ofthe coefficient matrix used to define the same hypothesis, anddifferent labeling schemes of the group means. Simulations and realdata applications indicate that the AHT test is comparable with oroutperforms some well-known approximate solutions proposed for the <b>k-sample</b> Behrens-Fisher <b>problem</b> which is a special case of theheteroscedastic GLHT problem. <br /...|$|R
40|$|This {{dissertation}} addresses {{two problems}} from novel perspectives. In chapter 2, I propose an empirical likelihood based method to nonparametrically adjust for baseline covariates in randomized clinical trials and in chapter 3, I develop a survival analysis framework for multivariate <b>K-sample</b> <b>problems.</b> (I) : Covariate adjustment {{is an important}} tool {{in the analysis of}} randomized clinical trials and observational studies. It can be used to increase efficiency and thus power, and to reduce possible bias. While most statistical tests in randomized clinical trials are nonparametric in nature, approaches for covariate adjustment typically rely on specific regression models, such as the linear model for a continuous outcome, the logistic regression model for a dichotomous outcome, and the Cox model for survival time. Several recent efforts have focused on model-free covariate adjustment. This thesis makes use of the empirical likelihood method and proposes a nonparametric approach to covariate adjustment. A major advantage of the new approach is that it automatically utilizes covariate information in an optimal way without fitting a nonparametric regression. The usual asymptotic properties, including the Wilks-type result of convergence to a chi-square distribution for the empirical likelihood ratio based test, and asymptotic normality for the corresponding maximum empirical likelihood estimator, are established. It is also shown that the resulting test is asymptotically most powerful and that the estimator for the treatment effect achieves the semiparametric efficiency bound. The new method is applied to the Global Use of Strategies to Open Occluded Coronary Arteries (GUSTO) -I trial. Extensive simulations are conducted, validating the theoretical findings. This work is not only useful for nonparametric covariate adjustment but also has theoretical value. It broadens the scope of the traditional empirical likelihood inference by allowing the number of constraints to grow with the sample size. (II) : Motivated by applications in high-dimensional settings, I propose a novel approach to testing equality of two or more populations by constructing a class of intensity centered score processes. The resulting tests are analogous in spirit to the well-known class of weighted log-rank statistics that is widely used in survival analysis. The test statistics are nonparametric, computationally simple and applicable to high-dimensional data. We establish the usual large sample properties by showing that the underlying log-rank score process converges weakly to a Gaussian random field with zero mean under the null hypothesis, and with a drift under the contiguous alternatives. For the Kolmogorov-Smirnov-type and the Cramer-von Mises-type statistics, we also establish the consistency result for any fixed alternative. As a practical means to obtain approximate cutoff points for the test statistics, a simulation based resampling method is proposed, with theoretical justification given by establishing weak convergence for the randomly weighted log-rank score process. The new approach is applied to a study of brain activation measured by functional magnetic resonance imaging when performing two linguistic tasks and also to a prostate cancer DNA microarray data set...|$|R

