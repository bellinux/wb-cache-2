4|10000|Public
40|$|Until right now, Central Java {{still be}} faced to problem in enhance of {{economic}} growth. Economic growth of Central Java in last six periods showed that static but lower {{better than other}} provinces in Java Island and Indonesia. Besides that, value of final goods and services or Gross Regional Domestic Product (GRDP) were lower better than other provinces in Java Island. Therefore, it need to analysis the factors who support economic growth in this region and how much effect this variable to economic growth in Central Java. This study used secondary data analysis with panel data, which consist of time series data for periods of 2004 - 2009 and cross section data of regency/ municipality in Central Java. The approaches used to estimate the regression model {{in this study is}} Fixed Effect Model (FEM), or Least Square Dummy Variable (LSDV) because this approaches used <b>dummy</b> <b>variable</b> <b>in</b> <b>regression</b> model to explained the different characteristic and resources of each region. The regression result showed that capital expenditure variable has a positive and significant impact on economic growth. Beside that, indicator of fiscal decentralization has’t effect on economic growth. And then labor force and education have a positive and significant impact on economic growt...|$|E
40|$|Background: Pollen {{information}} is indispensable for allergic individuals and clinicians. This study {{aimed to develop}} forecasting models for the total annual count of airborne pollen grains based on data monitored over the last 20 years at the Mie Chuo Medical Center, Tsu, Mie, Japan. Methods: Airborne pollen grains were collected using a Durham sampler. Total annual pollen count and pollen count from October to December (OD pollen count) {{of the previous year}} were transformed to logarithms. Regression analysis of the total pollen count was performed using variables such as the OD pollen count and the maximum temperature for mid-July of the previous year. Results: Time series analysis revealed an alternate rhythm of the series of total pollen count. The alternate rhythm consisted of a cyclic alternation of an “on” year (high pollen count) and an “off” year (low pollen count). This rhythm was used as a <b>dummy</b> <b>variable</b> <b>in</b> <b>regression</b> equations. Of the three models involving the OD pollen count, a multiple regression equation that included the alternate rhythm variable and the interaction of this rhythm with OD pollen count showed a high coefficient of determination (0. 844). Of the three models involving the maximum temperature for mid-July, those including the alternate rhythm variable and the interaction of this rhythm with maximum temperature had the highest coefficient of determination (0. 925). Conclusions: An alternate pollen dispersal rhythm represented by a dummy variable in the multiple regression analysis {{plays a key role in}} improving forecasting models for the total annual sugi pollen count...|$|E
30|$|On {{the other}} hand, those {{watching}} CNN are about 5 percentage points {{less likely to}} favor the Senate plan when not controlling for ideology and between 8 and 9 percentage points less likely when doing so. Prima facie, it is perhaps surprising that those watching CNN are systematically less likely to support the Senate plan than CBS viewers, but this result can be explained {{in light of what}} in Section 1 we have dubbed the “Lou Dobbs effect.” 27 Lou Dobbs, the former anchor and managing editor of CNN evening news, has been very vocal regarding the costs imposed by illegal immigration on the American public and has consistently opposed the Senate bill proposal. This is how he described illegal immigration on his CNN website: “The single most critical issue to protect our nation is the securing of our borders and our ports. Every day, tens of thousands of containers enter our country from other nations and they are never inspected. At the same time, our government turns {{a blind eye to the}} thousands of people who illegally cross our borders. These scenarios exist because corporate America has convinced our leaders that this is one of the best ways to remain competitive.” When the Senate passed the Comprehensive Immigration Reform Act, Lou Dobbs introduced the story with the following words: “Tonight, the Senate has just voted for a so-called comprehensive immigration reform bill. The vote, 62 - 36. The legislation gives amnesty to millions of illegal aliens and sharply escalates the war on our middle class and raises the cost of federal government substantially.” 28 From the point of view of ideological self-selection, the bias towards 0 of the CNN <b>dummy</b> <b>variable</b> <b>in</b> <b>regression</b> [1]—induced by omitting ideological controls—suggests that CNN viewers are more liberal than CBS viewers (the omitted category). In addition, and most importantly, the result for CNN—that the impact of the news program works in the opposite direction with respect to self-selection—gives us confidence that our correlations are at least in part driven by the causal impact of media exposure. In other words, the coefficient on CNN represents, if anything, a lower bound on the causal impact of CNN on attitudes towards illegal immigrants.|$|E
5000|$|The term [...] "dummy variable" [...] is also {{sometimes}} {{used for a}} bound <b>variable</b> (more often <b>in</b> general mathematics than in computer science), but that use can create an ambiguity with the definition of <b>dummy</b> <b>variables</b> <b>in</b> <b>regression</b> analysis.|$|R
40|$|This paper {{attempts}} {{to explore a}} seasonal pattern, the Ramadhan effect, in the Pakistani equity market. Ramadhan, the holy month of fasting, is expected to affect the behavior of stock market in Pakistan where the environment in Ramadhan is different from other months as people {{devote more time to}} perform rituals and the general economic activity slows down. The effects of Ramadhan on mean return and stock returns volatility are examined by including a <b>dummy</b> <b>variable</b> <b>in</b> <b>regressions</b> and GARCH models respectively. The analysis indicates a significant decline in stock returns volatility in this month although the mean return indicates no significant change. ...|$|R
40|$|The {{consequences}} of ethnic diversity in Africa {{have been widely}} noted. However, the sources of this diversity remain unexplained, which is surprising in light of Africa's high level of ethnic diversity {{as well as its}} large internal variation. Here I show that ethnic diversity in Africa is a result of its tropical location, the pre-colonial slave trade, the colonial creation of large states, and low levels of urbanization, and that my results are robust to various controls. I also show that controlling for the slave trade eliminates the statistical significance of an Africa <b>dummy</b> <b>variable</b> <b>in</b> <b>regressions</b> using data on global ethnic diversity...|$|R
40|$|The {{interpretation}} of <b>dummy</b> <b>variables</b> <b>in</b> <b>regressions</b> where {{the dependent variable}} is subject to a log transformation has been of continuing interest in economics. However, in the main, these earlier papers do not deal with the inferential aspects of the parameters estimated. In this paper we compare the inference implied by the hypotheses tested on the linear parameter estimated in the model and the tests applied to the proportional change that this parameter implies. An important element in this analysis is the asymmetry introduced by the log transformation. Suggestions are made for the appropriate test procedure in this case. Examples are presented from some common econometric applications of this model in the estimation of hedonic price models and wage equations. Hypothesis tests;lognormal distribution; measures of proportional change; wage equation; hedonic price model...|$|R
30|$|In this section, I {{present the}} {{estimation}} {{results for the}} total causal effect of displacement on education expenditure. The robustness checks show that the difference in spending on education holds across various specifications. An exact interpretation of <b>dummy</b> <b>variables</b> <b>in</b> semi-logarithmic <b>regressions</b> is provided <b>in</b> the row “Transformation” following van Garderen and Shah (2002). However, the exact interpretation deviates from the regression coefficients only slightly and also statistical significance remains unchanged.|$|R
40|$|Social {{scientists}} spend considerable energy constructing typologies {{and discussing}} {{their roles in}} mea-surement. Less discussed {{is the role of}} typologies in evaluating and revising theoretical arguments. We argue that unsupervised machine learning tools can be profitably applied to the development and testing of theory-based typologies. We review recent advances in mixture models as applied to cluster analysis and argue that these tools are particularly important in the social sciences where it is common to claim that high-dimensional objects group together in meaningful clusters. Model-based clustering (MBC) grounds analysis in probability theory, permitting the evaluation of uncertainty and application of information-based model selection tools. We show that the MBC approach forces analysts to consider dimensionality problems that more traditional clustering tools obscure. We apply MBC to the “varieties of capitalism,” a typology receiving significant attention in political science and economic sociology. We find weak and conflicting evidence for the theory’s expected grouping. We therefore caution against the current practice of including typology-derived <b>dummy</b> <b>variables</b> <b>in</b> <b>regression</b> and case-comparison research designs. ...|$|R
40|$|Statisticians {{make their}} living {{producing}} confidence intervals and pvalues. However, those in the Stata log are not ready for delivery to the end user, who usually wants to see statistical output either as a plot or as a table. This article describes a suite of programs used to convert Stata results to one or other of these forms. The eclplot package creates plots of estimates with conÞdence intervals, and the listtex package outputs a Stata dataset {{in the form of}} table rows that can be inserted into a plain TEX, LATEX, HTML, or word processor table. To create a Stata dataset that can be output in these ways, we can use the parmest, dsconcat, and lincomest packages to create datasets with one observation per estimated parameter; the sencode, tostring, ingap, and reshape packages to process these datasets into a form ready to be output; and the descsave and factext packages to reconstruct, in the output dataset, categorical predictor <b>variables</b> represented by <b>dummy</b> <b>variables</b> <b>in</b> <b>regression</b> models. Copyright 2003 by StataCorp LP. confidence interval, p-value, plot, table, estimation results, TEX, LATEX, HTML, word processor, presentation, eclplot, listtex, parmest, dsconcat, lincomest, sencode, tostring, ingap, reshape, descsave, factext...|$|R
40|$|Oaxaca and Ransom (1999) {{show that}} a {{detailed}} decomposition of the coefficients effect is destined to suffer from an identification problem since the detailed coefficients effect attributed to a <b>dummy</b> <b>variable</b> is not invariant to the choice of reference groups. It {{turns out that the}} identification problem in the decomposition equation is a disguised identification problem of constant and <b>dummy</b> <b>variables</b> <b>in</b> a <b>regression</b> equation. This paper proposes a simple and natural remedy for this problem by utilizing ?normalized? regressions which enable us to identify the constant and estimates of each <b>dummy</b> <b>variable.</b> The identification problem is automatically resolved once we obtain ?normalized? regression equations for two comparison groups...|$|R
3000|$|... where F(x) = exp(x)/(1 +exp(x)). This paper {{estimates}} Equation 4 with a {{logit model}} in all cases, {{but the results}} would be virtually the same if one would use a probit specification instead. The levels of the contract attributes are treated as separate <b>dummy</b> <b>variables</b> <b>in</b> the <b>regression</b> analysis, except for pay which enters as a single variable. The estimated models are based on differenced contract attributes as specified in Equations (2)-(3). Since the explanatory variables represent {{the differences between the}} attribute levels of two contracts, it is unnecessary to include individual effects (such as random effects). Appendix 3 describes the design of the DCE in more detail.|$|R
40|$|Care must {{be taken}} when {{interpreting}} the coefficients of <b>dummy</b> <b>variables</b> <b>in</b> semi-logarithmic <b>regression</b> models. Existing results in the literature provide the best unbiased estimator of the percentage change <b>in</b> the dependent <b>variable,</b> implied by the coefficient of a <b>dummy</b> <b>variable,</b> and of the variance of this estimator. We extend these results by establishing the exact sampling distribution of an unbiased estimator of the implied percentage change. This distribution is nonnormal, and is positively skewed in small samples. We discuss the construction of bootstrap confidence intervals for the implied percentage change, and illustrate our various results with two applications: one involving a wage equation, and one involving {{the construction of an}} hedonic price index for computer disk drives. Keywords Semi-logarithmic regression, <b>dummy</b> <b>variable,</b> percentage change, confidence interval JEL Classification...|$|R
40|$|Many {{research}} {{designs and}} statistical methodologies {{will be used}} to conduct comparative effectiveness research (CER). In particular, it is almost certainly the case that the demand for real-world evidence will drive increased demand for CER analyses of observational data. Although a great deal of {{progress has been made in}} the development and application of statistical methods for the analysis of observational data, the ordinary least squares multiple regression model remains, by far, the most widely applied multivariate analysis tool. This article begins with a brief review of the interpretation of treatment effects captured through the use of <b>dummy</b> <b>variables</b> <b>in</b> multiple <b>regression</b> models. This review makes clear just how limited this typical estimator of treatment effect is. Structural equation and decomposition methods for CER analyses of observational data are then reviewed. Although these methods have not been commonly used for outcomes research, they offer the opportunity to extract significantly more information regarding treatment effects than the standard <b>dummy</b> <b>variable</b> approach. I have attempted to make the point that traditional <b>dummy</b> <b>variable</b> methods <b>in</b> <b>regression</b> models provide an extremely limited estimate of treatment effects. Structural equation models and decomposition methods provide considerably more information about treatment effects - in particular, the ability to identify how outcomes may vary differentially with respect to patient characteristics and other factors for alternative treatment cohorts. Such an understanding is fundamental to deciphering the heterogeneity of treatment response among patient subpopulations. Structural equation and decomposition methods may be further enhanced by incorporating propensity score matching prior to the analysis. On the other hand, researchers should be wary of the potential pitfalls associated with parametric sample selection bias models. Although tests for selection bias and other forms of endogeneity are an excellent research practice, it is entirely possible that attempts to correct for endogeneity may introduce more bias than they remove. Nonparametric methods, such as differences in differences, while making strong assumptions of their own, avoid the need to identify instrumental variables that are correlated with treatment selection but uncorrelated with residuals in the outcome equation. Clinical-trial-design, Treatment-outcome...|$|R
40|$|Background: There is {{increasing}} interest in monitoring the health-related {{quality of life}} (HRQoL) of populations as opposed to clinical populations. The EQ- 5 D identifies five domains as being most able to capture the HRQoL construct. The question arises as to whether these domains are adequate within a community-based population or whether additional domains would add to the explanatory power of the instrument. Methods: As part of a community-based survey, the responses of 310 informants who reported at least one problem in one domain filled in the EQ- 5 D three-level version and the WHOQOL-BREF (World Health Organization Quality of Life Scale – Abbreviated version). Using the EQ- 5 D visual analogue scale (VAS) of rating of health as a dependent variable, the five EQ- 5 D and four selected WHOQOL-BREF items were entered as <b>dummy</b> <b>variables</b> <b>in</b> multiple <b>regression</b> analysis. Results: The additional domains increased the explanatory power of the model from 52...|$|R
40|$|The {{costs and}} {{consequences}} of ethnic diversity in Africa have been widely noted. However, despite Africa’s high level of ethnic diversity and its large internal variation, the sources of this diversity remain unexplained. Here the author shows that ethnic diversity in Africa {{is a result of}} its tropical location, the pre-colonial slave trade, the colonial creation of large states and low levels of urbanization. The effect of these variables are robust to various controls and specifications. He also shows that, once pre-colonial slavery is introduced, an African <b>dummy</b> <b>variable</b> becomes insignificant <b>in</b> <b>regressions</b> containing a world-wide sample of countries...|$|R
40|$|It {{is often}} {{necessary}} for social scientists to study differences in groups, such as gender or race differences in attitudes, buying behavior, or socioeconomic characteristics. When the researcher seeks to estimate group differences {{through the use}} of independent variables that are qualitative, <b>dummy</b> <b>variables</b> allow the researcher to represent information about group membership in quantitative terms without imposing unrealistic measurement assumptions on the categorical variables. Beginning with the simplest model, Hardy probes the use of <b>dummy</b> <b>variable</b> <b>regression</b> <b>in</b> increasingly complex specifications, exploring issues such as: interaction, heteroscedasticity, multiple comparisons and significance testing, the use of effects or contrast coding, testing for curvilinearity, and estimating a piecewise linear regression...|$|R
3000|$|It is also {{possible}} that firms with poor credibility may choose to attain an auditor’s attestation on their reports to enhance their credibility. To look into this possibility, we include an additional <b>dummy</b> <b>variable</b> PENALTY <b>in</b> the <b>regression.</b> PENALTY is set to 1 if the firm has been punished for accounting fraud or information-disclosure irregularities in the previous year, and zero otherwise. Alternatively, we set PENALTY equal to 1 if the firm had a non-clean auditor opinion in the previous year, and zero otherwise. We argue that these firms may have the incentive to hire an auditor to attest to the validity of their IC report. However, the estimated coefficient for PENALTY is unanimously insignificant. 18 [...]...|$|R
40|$|NET stations, {{ranging in}} {{distance}} from 40 to 500 km, to determine source, attenuation, and site effects for the mainshock and four aftershocks with M 7. 3, 6. 4, 5. 9, and 5. 5. The analyses {{are based on}} linear regression applied to the Fourier spectra data of each event. The ground-motion attenuation for all the events can be modeled using an as-sumed geometric spreading coefficient b 1 1 : 0 with an associated anelastic at-tenuation model given by an apparent Q 135 f 0 : 76. By using <b>dummy</b> <b>variables</b> <b>in</b> the <b>regression,</b> site amplifications relative to National Earthquake Hazard Reduc-tion Program (NEHRP) C sites are determined for D and E sites. Nonlinear site am-plification was investigated for the M 8. 1 data but was not significant in determining the overall amplification factors. Fourier spectra data were corrected to a reference near-source distance and site condition (hard rock). The source spectrum for each event was {{compared to that of}} the theoretical Brune-model spectrum, in order to com-pute seismic moment and stress drop. Seismic moments obtained in this manner agree with those of other studies. Stress drops range from 100 to 200 bars with no apparent dependence on magnitude. The mainshock stress drop was 120 bars. A similar value (100 bars) was calculated for an interface aftershock. Events with the highest stress drops (near 200 bars) may have been in-slab events...|$|R
40|$|Although {{studies have}} {{demonstrated}} significant associations between ENSO events and dengue fever, few have explored regional impacts on dengue fever of separate events. This study explores the impacts of two ENSO events on regional patterns of dengue/ dengue haemorrhagic fever (DHF) incidence in Indonesia. Data consist of monthly cases of dengue/DHF from 1992 to 2001 for each of Indonesia&# 039;s 27 provinces, and monthly figures for rainfall, rainfall anomalies, temperature, relative humidity and the Southern Oscillation Index (SOI). We conducted Pearson correlation analyses for each independent variable against dengue/DHF incidence, using a direct month-by-month correlation and applying a lag of between one and six months to each variable with respect to dengue/DHF incidence. Based on the SOI value, we identified two ENSO events between 1992 and 2001. To explore each event, we created two <b>dummy</b> <b>variables</b> and <b>in</b> <b>regression</b> analyses for eight provinces. The variance of between 12. 9 per cent and 24. 5 per cent in provincial dengue/DHF incidence is explained by two or three climate <b>variables</b> <b>in</b> each of the provinces (p &lt; 0. 01 to 0. 1). During the 1997 / 98 event, the explained variance increased by between 7 per cent and 15 per cent in provinces whose climate regimes were most affected by this event. This study demonstrates that indicators of ENSO such as the SOI may assist in the forecast of potential dengue/DHF incidence and distribution in Indonesia...|$|R
40|$|Exports are an {{important}} source of income for Sweden. They are influenced by macroeconomic factors such as GDP. This paper examines the elasticity of Swedish export to changes in the GDP of Sweden’s 25 most important export partners. The sensitivity to changes in GDP, the elasticity, can be different for different goods. Therefore, we examine export elasticities for five different commodity groups, which include durable as well as non-durable goods. Moreover, special focus is put on the trade relationship between Sweden and Germany in order to see if their long common trade history has any impact on the elasticity of Swedish exports to Germany. The analysis is based on an export demand function that links exports to GDP and geographical distance. We include <b>dummy</b> <b>variables</b> <b>in</b> our <b>regression</b> model to control for EU-membership and common borders.        For Swedish exports to Germany, we find that exports of food and live animals are least elastic, whereas exports of machinery and transport equipment are most elastic. This is coherent with previous empirical findings about demand elasticities of non-durable and durable goods. We find that exports in two out of five commodity groups are unit elastic. This means that when German GDP increases by one percent, Sweden’s export to Germany in these commodity groups also grows by approximately one percent. Thus, Sweden is not able to capture additional profit through over proportional increases in exports to Germany. For Swedish exports to its 25 most important trading partners, on average, we find that exports of manufactured goods as well as machinery and transport equipment are the least elastic exports. This gives them the lowest growth potential...|$|R
30|$|Australian {{studies have}} {{documented}} {{gender differences in}} academic outcomes at all educational levels. For example, Nghiem et al. (2015) used the first four waves of the LSAC data to report that male students outperform their female counterparts in grade 3 and 5 numeracy. In contrast, female students outperform in grade 3 writing and grade 5 reading and grammar. More recently, Justman and Méndez (2016) used administrative data from Victoria to show that male students score higher than female students in mathematics and lower in reading in grades 7 and 9. As another example, Marks (2008) used the OECD’s 2000 Programme for International Student Assessment (PISA) project to document that 15 -year-old Australian females perform better than males in reading but worse in mathematics. Using various datasets, Homel et al. (2012) reported that 18 -year-old Australian females {{are more likely to}} complete Year 12 than males. At the tertiary educational level, Booth and Kee (2011) used aggregate data to report that since 1987 Australian females were more likely than males to be enrolled at university. These studies often attempt to capture the gender educational achievement gap by including a gender <b>dummy</b> <b>variable</b> <b>in</b> a multivariate <b>regression</b> framework and only examine the mean gap.|$|R
40|$|This paper {{examines}} {{the effect of}} the degree of internationalization on capital structure for multinational corporations (MNCs) in Taiwan during the Asian financial crisis in 1997 by using <b>dummy</b> <b>variables</b> <b>in</b> a multiple <b>regression</b> analysis. The results show that: (1) For the IT industry, the higher the internationalization is, the higher the leverage will be, but it is the reverse for the NIT industry. (2) There is an industry effect on tangible assets, sales size, return on total assets, current ratio, and the times of interest earned, while the collateral value of assets is more significant for the NIT industry than the IT industry when MNCs make capital structure decisions. (3) There is an internationalization effect on the collateral value of assets, profitability, and liability payment ability. For low-internationalized MNCs, firm size and profitability are the important capital structure determinants, but for high-internationalized MNCs, the collateral value of assets is a key element of leverage decisions. (4) The liquidity risk caused by the Asian financial crisis allows the collateral value of assets and liability payment ability be the important determinants when MNCs make capital structure decisions. Finally, the results also express that international outsourcing and international financing play a somewhat important role for the IT industry during successive industry development. Capital structure, multinational corporations (MNCs), degree of internationalization, Asian financial crisis in 1997...|$|R
40|$|The use of cointegration {{techniques}} to measure market integration and Granger Causality {{to establish the}} direction and strength by which markets influence each other is taken a stage further. The importance of first testing whether trends and cycles in the price series are deterministic or stochastic processes is pointed out. This in turn establishes the appropriate form of equations {{to be used for}} measuring market integration, both over the long run trend of prices and within cycles. Testing the nature of the process is particularly important for the treatment of seasonality since <b>dummy</b> <b>variables,</b> commonly used <b>in</b> <b>regression</b> equations to allow for seasonal and other cycles, is only valid for deterministic processes. The treatment of seasonality explained here also provides new opportunities for investigating the nature of integration over cycles. The techniques are applied to data for the Indonesian rice market where both trend and seasonal processes are shown to be stochastic. Integration is shown to occur through the CPI which is "caused " by the main supplier and "causes " the prices in other markets. (N. B. Abstract contains 174 words) 1 Carol Alexander is professor of finance and chair of the risk management group at the ISMA centre, Reading University (www. ismacentre. reading. ac. uk). John Wyeth is a consultant in agricultural economics who works mainly i...|$|R
40|$|In {{the last}} few decades, several studies have found the same {{technology}} implemented in highly similar organizational settings {{to be associated with}} very different consequences for structure and process. The seminal study in this stream of research is Barley 2 ̆ 7 s (1986) Technology as an Occasion for Structuring, which reported that two similarly composed radiology departments implemented the same technology (computerized tomography scanners), yet experienced very different structural outcomes. In this paper I re-analyze the original study 2 ̆ 7 s data under three different statistical assumptions. First, I performed an arcsine transformation on the dependent variable where the original study used the raw probabilities. Second, I specified a power <b>regression</b> model <b>in</b> which the original study employed a linear regression. Finally, I user fewer <b>dummy</b> <b>variables</b> <b>in</b> the ‘combined’ <b>regression</b> models to determine the distinct phases through which the two hospitals evolved. Taken together, these assumptions produce very different results from the original study. Specifically they indicate that the radiology departments did not decentralize at different rates and did not do so over a different number of distinct phases. From my analysis come three specific recommendations for research investigating the consequences of information technology in similarly constituted organizations: (1) exchange the default assumption of homogeneity of outcomes with one of heterogeneity; (2) explicitly account for both the observable properties of technology and the context of its use; and (3) state clearly and a priori the standard used to classify structural and organizational outcomes as ‘different’...|$|R
40|$|In {{analyzing}} {{the dynamics of}} Tokyo housing price, we have compiled annual micro data sets from individual listings in a widely-circulated real estate advertising magazine. A data set compiled from "properties for investment" lists both asking (sales) prices and rents for the same properties. With such data, a price-rent ratio is directly observable and expected capital gains before tax and commissions found to be just less than 90 % in ten years. The "repeatedly-listed properties for investment" data set, {{a subset of the}} first, contains only those units in the same buildings after a one-year interval. In this data set, price, rent, and ex post capital gains are all observable. They are used to show that ex post returns on housing investment {{in the last four years}} were actually rather modest. The data sets for "housing for sale" and "housing for rent" sections were separately used for hedonic regressions, from which we constructed hedonic price and rent indexes. These regressions show the effects of various determinants of housing prices and rents. The time (year) <b>dummy</b> <b>variables</b> <b>in</b> the hedonic <b>regressions</b> give estimates of price and rent increases in the last 11 years in Tokyo. According to these estimates, prices increased 85 - 90 % over the 1981 - 92 period, while rents increased about 65 %. The price-(annual) rent ratio rents appears to have fluctuated between 17 and 32. Finally, the weak-form efficiency of excess returns on housing is rejected. However, the conclusion is tentative considering the short sample. ...|$|R
40|$|We take {{advantage}} of annual micro data sets which we have compiled from individual listings in the widely-circulated real estate advertisement magazine. A data set compiled from the "properties for investment" section lists both asking (purchase) prices and rents for the same property. With this data, the price-rent ratio is directly observable and expected capital gains before tax and commissions {{are found to be}} just less than 90 percent in ten years. The "repeatedly-listed properties for investment" data set, a subset of the first data set, contains only those units in the same buildings after a one-year interval. In this data set, price, rent, and ex post capital gains are all observable. They are used to show that ex post returns on housing investment {{in the last four years}} were actually rather modest. The data set for "housing for purchase" and the data set for "housing for rent" data sections were separately used for hedonic regressions, from which we constructed the hedonic price index and the hedonic rent index. Those regressions show the effects of various determinants for housing prices and rents. The time (year) <b>dummy</b> <b>variables</b> <b>in</b> the hedonic <b>regressions</b> give that estimate of increases in prices and rents in the last eleven years in Tokyo. According to these estimates, prices increased 85 to 90 percent over the 1981 - 92 period, while rents increased about 65 percent during the same period. The price-(annual) rent ratio rents appears to have fluctuated around a constant ratio between 17 and 32. Finally, the weak-form efficiency of excess returns on housing is rejected. However, the conclusion is tentative considering the small sample of our data...|$|R
40|$|This is an {{intriguing}} paper that raises important questions, and I feel privileged for {{being invited to}} discuss it. The paper deals with a very basic problem of sample surveys: how to weight the survey data in order to estimate finite population quantities of interest like means, differences of means or regression coefficients. The paper focuses {{for the most part}} on the common estimator of a population mean, ¯yw = ∑ n i= 1 wiyi/ ∑ ni= 1 wi, and discusses different approaches to constructing the weights by use of linear regression models. These models vary {{in terms of the number}} and nature of the regressors in the model and in the assumptions regarding the regression coefficients, whether fixed or random with prespecified distributions. The idea behind regression weighting is to include <b>in</b> the <b>regression</b> model all the variables and interactions that are related to the outcome values and affect the sample selection and the response probabilities, such that the sampling and response mechanisms are ignorable in the sense that the model fitted to the observed data is the same as the population model before sampling. Assuming that all the important regressors affecting the sample selection and response are discrete, the set of all possible combinations of categories of these variables defines poststratification cells, which in turn define the <b>dummy</b> independent <b>variables</b> <b>in</b> the <b>regression</b> model. The target population parameter of interest can be written then as θ = ∑ J j= 1 Njθj / ∑ J j= 1 Nj, where θj is the parameter for cell j (say the true cel...|$|R
40|$|OBJECTIVES: Workers in horse stables {{are likely}} exposed {{to high levels}} of organic dust. Organic dusts play a role in {{increased}} risk of inflammatory reactions and are associated with respiratory diseases. The aim {{of this study was to}} investigate dust, endotoxin, beta(1 [...] > 3) -glucan, and culturable microorganisms exposure levels in horse stables. METHODS: Ambient (n = 38) and personal (n = 42) inhalable dust samples were collected using PAS- 6 sampling heads. As a special measurement, we included sampling near the horses' heads. Samples were analyzed for endotoxin and beta(1 [...] > 3) -glucan by Limulus amebocyte lysate assay and an inhibition enzyme immunoassay, respectively. Culturable bacteria and fungi were collected with an Anderson impactor. RESULTS: Geometric means (GMs) of personal exposure to dust, endotoxin, and beta(1 [...] > 3) -glucan were 1. 4 mg m(- 3) (range 0. 2 - 9. 5), 608 EU m(- 3) (20 - 9846), and 9. 5 microg m(- 3) (0. 4 - 631 microg m(- 3)), respectively. Exposure levels in the morning shift were higher compared to other shifts. The GMs (ranges) of culturable bacteria and fungi were 3. 1 x 10 (3) colony-forming unit (CFU) m(- 3) (6. 7 x 10 to 1. 9 x 10 (4)) and 1. 9 x 10 (3) CFU m(- 3) (7. 4 x 10 to 2. 4 x 10 (4)), respectively. Variance components for endotoxin and beta(1 [...] > 3) -glucan were considerably higher than for dust. Based on <b>dummy</b> <b>variable</b> <b>in</b> a mixed <b>regression</b> analysis, the predominant task explaining exposure levels of dust, endotoxin, and beta(1 [...] > 3) -glucan was sweeping the floor. For beta(1 [...] > 3) -glucan, feeding the horse was also an important determinant. CONCLUSION: Dust, endotoxin, and beta(1 [...] > 3) -glucan exposure are considerable in horse stables. Bacterial and fungal exposure levels were moderate. Endotoxin exposures were above the Dutch proposed standard limits, suggesting workers in horse stables to be at risk of adverse health effects...|$|R
40|$|The recent {{debate on}} {{executive}} compensation among media and politicians in Finland has been centered upon the possible inefficiency of boards as monitors and controllers of executive compensation schemes. It {{has also been}} suggested that firm owners {{should be allowed to}} vote for the CEO compensation arrangements. The purpose of this thesis is to examine whether and how the monitoring and controlling efficiency of the boards and outside owners are related to CEO compensation level in Finland. The monitoring efficiency is proxied with the following variables: Board size, Fraction of outside directors, Fraction of busy outside directors, Outside ownership concentration, Institutional investor ownership and Foreign ownership. The monitoring efficiency will be investigated separately in terms of 5 different CEO compensation variables: (1) Fixed compensation, (2) Short-term bonus compensation, (3) Cash compensation (1 + 2), (4) Long-term compensation and (5) Total compensation (3 + 4). Our research data draws on the unbalanced panel of 66 (318 firm-year observations) Finnish companies from 2007 to 2012. The data was collected from companies' annual reports, companies' web pages, Orbis database and the web pages of: Nasdaq OMX, Central Statistical Office of Finland and Bank of Finland. We examine the monitoring efficiency by using correlation analysis and multiple least squares <b>regression.</b> Using <b>dummy</b> <b>variable</b> technique <b>in</b> the <b>regression</b> models we account for the industry-specific and year-specific factors affecting CEO compensation level. We also control for the wide range of firm-specific factors that can be assumed to be important in the CEO pay equation. These factors are: Firm size, Firm performance, Firm growth opportunities and Firm risk. We document minor evidence that larger boards are associated with weaker monitoring efficiency consequently leading to higher level of CEO fixed compensation. Furthermore, our results lend some weak evidence that concentrated outside ownership and board consisted more of non-executive members may allow a more efficient monitoring consequently leading to lower level of CEO equity-based compensation. We also report evidence that larger firms pay their CEOs higher level of compensation suggesting that larger and more complex firms require higher quality and more expensive CEO talent. Additionally, we show evidence that higher prior firm performance is positively associated with CEO short-term bonus and total compensation...|$|R
5000|$|<b>Dummy</b> <b>variables</b> are {{incorporated}} <b>in</b> {{the same way}} as quantitative variables are included (as explanatory <b>variables)</b> <b>in</b> <b>regression</b> models. For example, if we consider a Mincer-type regression model of wage determination, wherein wages are dependent on gender (qualitative) and years of education (quantitative): ...|$|R
5000|$|... an integer, e.g. a <b>dummy</b> <b>variable</b> <b>in</b> summations, or {{an index}} of a matrix.|$|R
3000|$|... [...]) is 0.004 {{without those}} <b>dummy</b> <b>variables,</b> {{compared}} with 0.0036 with those <b>dummy</b> <b>variables.</b> <b>In</b> addition, including these sets of dummies increased the adjusted R [...]...|$|R
30|$|In addition, {{there is}} a <b>dummy</b> <b>variable</b> <b>in</b> the {{empirical}} model that takes a value of one if the previous unemployment spell was due to a quit instead of a layoff.|$|R
40|$|This study {{examines}} {{the role of}} oil exports in the economic development of Saudi Arabia. It is an econometric application of the staple theory of economic growth to the special case of Saudi Arabia. ^ Because oil revenues accrue directly to the Government, the study focuses {{on the impact of}} oil-induced financial linkages on the domestic non-oil economy of Saudi Arabia. It also evaluates {{the extent to which the}} high level of government domestic spending has helped bring about structural changes in the key sectors of the economy. It particularly concentrates on the government 2 ̆ 7 s efforts to enhance the capital absorptive capacity of the Saudi Arabian economy and to diversify its production and employment structures. ^ To achieve the goals of this study, a simple Keynesian multiplier static model is presented in order to provide a fairly accurate depiction of the impact of oil revenues on the non-oil economy of Saudi Arabia. Next, we offer a modified version of the Samuelson 2 ̆ 7 s multiplier-accelerator model to shed light on the dynamics of Saudi Arabia 2 ̆ 7 s growth process. To operationalize the staple theory for empirical estimations we employed the Koyck 2 ̆ 7 s distributed lag model as our basic tool for the econometric portion of the study and subsequent analysis. Since economic growth in the staple theory is determined by current (the direct effect) and past (the spread effects) export activity, the choice of Koyck 2 ̆ 7 s model is appropriate because it is capable of indicating the short-and long-run impacts of the independent variable (oil) on the dependent variables (components of the Saudi non-oil economy). Also, the use of <b>dummy</b> <b>variables</b> is employed <b>in</b> <b>regression</b> equations to test for any additional structural changes which might have occurred as a result of the 1973 / 74 oil price shock. ^ By and large, the econometric results reveal the dominance of oil revenues 2 ̆ 7 spread effects over their direct effects indicating the supremacy of fiscal linkages over the production (forward and backward) and consumption (final demand) linkages. Although the non-oil economy had experienced some structural changes even before 1973, the analysis shows that the capital absorptive capacity of the non-oil economy had not improved greatly to absorb the large oil-income flows that followed the 1973 and subsequent oil price increases. Nevertheless, the Saudi government launched a massive investment program for economic development of the country, in addition to making large investments in foreign assets abroad. ^ This study, however, argues that it might have been more prudent for Saudi Arabia to adjust the flow of oil revenues equal to amounts matched by the economy 2 ̆ 7 s capital absorptive capacity. This would have required the management of both the price and output of Saudi oil. A less ambitious development effort, particularly during the 1973 - 1981 period, might have proved to be more effective in transforming the Saudi economy. By permitting a more gradual process of adaptation through manpower development and skill formation and a more moderate rate of expansion, the economy might well have avoided the creation of bottlenecks in the form of shortages of infrastructure, raw materials, and consumer goods. ^ With at least one-quarter of the world 2 ̆ 7 s known oil reserves and at least half a century of potential oil exports ahead, Saudi Arabia should be able to create a viable diversified economy, with less dependence on oil, in the not too distant future. (Abstract shortened by UMI.) ...|$|R
30|$|For the {{specification}} {{of the system}} of models we considered socio-economic, level-of-service and <b>dummy</b> <b>variables.</b> <b>In</b> Table 5 model attributes, model parameters and validation tests are reported. In Table 6 the attributes used are described.|$|R
