26|6|Public
5|$|The massive, compact {{nature of}} a white dwarf {{produces}} a strong surface gravity. Astronomers denote this value by the <b>decimal</b> <b>logarithm</b> of the gravitational force in cgs units, or log g. For IK Pegasi B, log g is 8.95. By comparison, log g for the Earth is 2.99. Thus the surface gravity on IK Pegasi is over 900,000 times the gravitational force on the Earth.|$|E
25|$|Small numbers {{refer to}} ISO 14644-1 standards, which specify the <b>decimal</b> <b>logarithm</b> {{of the number}} of {{particles}} 0.1µm or larger permitted per m3 of air. So, for example, an ISO class 5 cleanroom has at most 105 particles/m3.|$|E
5000|$|... pH {{is defined}} as the <b>decimal</b> <b>logarithm</b> of the {{reciprocal}} of the hydrogen ion activity, aH+, in a solution.|$|E
2500|$|... 1617– Henry Briggs {{discusses}} <b>decimal</b> <b>logarithms</b> in Logarithmorum Chilias Prima.|$|R
40|$|Adhered spores of Bacillus cereus {{represent}} {{a significant part}} of the surface-derived contamination in processing equipment used in the dairy industry. As germinated spores lose their resistance capacities instantaneously, efficient germination prior to a cleaning in place treatment could aid to the disinfecting effect of such a treatment. Therefore, spores of B. cereus ATCC 14579 and that of the environmental isolate B. cereus CMCC 3328 were assessed for their germination behaviour when adhered to a stainless steel surface. A mixture of l-alanine and inosine initiated germination of adhered spores efficiently, resulting in 3. 2 <b>decimal</b> <b>logarithms</b> of germination. Notably, implementation of a germination-inducing step prior to a representative cleaning in place procedure reduced the number of survivors with over 3 decimal log units, while an alkali treatment alone, as part of the cleaning in place procedure, did not show any effect on B. cereus spore viability. These results show that implementation of a germination step enhances the disinfection effect of currently used cleaning in place procedures...|$|R
40|$|Gauss a {{collection}} of mathematics books which included logarithm tables by Schulze. 1 These were the first logarithm tables that Gauss possessed. The tables listed <b>decimal</b> <b>logarithms</b> up to 7 digits as well as natural logarithms of all natural numbers up to 2200 and prime numbers up to 10, 009 [3]. Gauss worked on extending the tables: a computation of ln(10037) {{can be found in}} his papers from that time. It is conceivable that seeing and using the tables of logarithms of primes, Gauss was led to discover the law governing the distribution of primes, the Prime Number Theorem. Throughout his life Gauss returned again and again to this issue, matching data from published tables of prime numbers with his prediction. Here are the first lines of a four-page letter from Gauss to his student Johann Franz Encke, lieutenant of artillery and later astronomer in Berlin, dated December 24, 1849 : 2 My distinguished friend, Your remarks concerning the frequency of primes were of interest to me in mor...|$|R
5000|$|A similar {{calculation}} {{can be done}} using {{a natural}} logarithm instead of a <b>decimal</b> <b>logarithm,</b> resulting in nepers instead of decibels: ...|$|E
50|$|The {{value of}} pH {{is used to}} {{describe}} pzc only for systems in which H+/OH− are the potential-determining ions (which is the common case). Generally, pzc {{is the value of}} the negative <b>decimal</b> <b>logarithm</b> of the activity of the potential-determining ion in the bulk fluid. For example, the charge on the surface of silver iodide crystals may be determined by the concentration of iodide ions in the solution above the crystals. Then, the pzc value of the AgI surface will be described by the concentration of I− in the solution (or negative <b>decimal</b> <b>logarithm</b> of this concentration, pI−).|$|E
50|$|Small numbers {{refer to}} ISO 14644-1 standards, which specify the <b>decimal</b> <b>logarithm</b> {{of the number}} of {{particles}} 0.1 µm or larger permitted per m3 of air. So, for example, an ISO class 5 cleanroom has at most 105 particles/m3.|$|E
40|$|International audienceThe {{purpose of}} this study was to {{quantify}} the lag time of re-growth of heated spores of Bacillus cereus as a function of the conditions of the heat treatment: temperature, duration and pH of the recovery medium. For a given heating temperature, curves plotting lag times versus time of heating show more or less complex patterns. However, under a heating time corresponding to a decrease of 2 <b>decimal</b> <b>logarithms</b> of the surviving populations of spores, a linear relationship between the lag time of growth and the time of the previous heat treatment can be observed. The slope of this linear relationship followed itself a Bigelow type linear relationship, the slope of which yielded a - value very close to the observed conventional z-value. It was then concluded that the slope of the regrowth lag time versus the heating time followed a linear relationship with the sterilisation value reached in the course of the previous heat treatment. A sharp effect of the pH of the medium which could be described by a simple "secondary" model was observed. As expected, the observed intercept of the linear relationship between lag time and heating time (lag without previous heating) was dependent on only the pH of the medium and not on the heating temperature...|$|R
50|$|Alexander J. Ellis based {{the measure}} on the {{acoustic}} <b>logarithms</b> <b>decimal</b> semitone system developed by Gaspard de Prony in the 1830s, at Robert Holford Macdowell Bosanquet's suggestion. Ellis made extensive measurements of musical instruments {{from around the}} world, using cents extensively to report and compare the scales employed, and further described and employed the system in his 1875 edition of Hermann von Helmholtz's On the Sensations of Tone. It has become the standard method of representing and comparing musical pitches and intervals.|$|R
40|$|International audienceThe {{scholarly}} {{books of}} mathematics from the 18 th and 19 th centuries, those on which historians of mathematics {{have so far}} focused primarily, reflect only partially the computation practices that were in use in various professional milieus. Centered {{on the benefits of}} <b>decimal</b> fractions and <b>logarithms,</b> these books certainly fitted the needs of professional mathematicians and astronomers, but certainly not those of bankers, merchants, artisans, workers and peasants. Today everyone uses the decimal system, has received basic education in mathematics and owns an electronic calculator, so it has become almost impossible to perceive the difficulty of calculations underlying the daily transactions of the 18 th century. The numerous non-decimal measurement units specific to each country, each region or each city, led constantly to tedious problems, simultaneously requiring measure conversions and currency conversions, and also to highly technical operations. In addition, practices of counting and measurement could vary according to the professions, especially according to whether they needed exact results or just more or less crude approximations. This situation resulted in a multiplication of books of "comptes faits" – as they were called in France – with a general or specialized scope, as well as of many numerical and graphical tables to facilitate daily calculations. These works regularly define mathematics as composed of arithmetic, i. e., measurement of discrete quantities, and geometry, i. e., measurement of continuous quantities. This view of mathematics as entirely organized around the concept of measurement and its applications in everyday life deserves attention. The usual distinction between abstract numbers and measured numbers is magnified here by the omnipresence of 'complex numbers', that is to say numbers that express at the same time several kinds of units depending in a non uniform fashion on each other. Also observed in these books is a constant interaction between different mathematical objects in a process of mutual reinforcement and popularization: whole numbers, fractions, <b>decimal</b> fractions, <b>logarithms,</b> linear scales, tables, charts. We finally meet there an ongoing effort to ensure that the concepts and basic operations of calculation become accessible to a large audience who did not receive a high level of mathematical education or received no education at all. After a brief general overview, these issues will be illustrated by a case study on the measurement of wood and the calculation of its price in France around the year 1800, certainly an important and significant problem if one believes the many specialized books which were published at the time on this peculiar subject. We will try to identify the different groups of actors involved in the production and trade of wood, their practices and instruments of measurement and calculation, and their specific mathematical knowledge...|$|R
5000|$|In neutral water, the pH, {{being the}} {{negative}} <b>decimal</b> <b>logarithm</b> of the H3O+ concentration, it is 7. Similarly, the pOH is also 7. Each unit decrease in pH indicates a tenfold {{increase of the}} H3O+ concentration. Similarly, each unit increase in pH indicates a tenfold increase of the OH - [...] concentration.|$|E
50|$|The massive, compact {{nature of}} a white dwarf {{produces}} a strong surface gravity. Astronomers denote this value by the <b>decimal</b> <b>logarithm</b> of the gravitational force in cgs units, or log g. For IK Pegasi B, log g is 8.95. By comparison, log g for the Earth is 2.99. Thus the surface gravity on IK Pegasi is over 900,000 times the gravitational force on the Earth.|$|E
5000|$|In mathematics, {{the common}} {{logarithm}} is the logarithm with base 10. It {{is also known}} as the decadic logarithm and also as the <b>decimal</b> <b>logarithm,</b> named after its base, or Briggsian logarithm, after Henry Briggs, an English mathematician who pioneered its use, as well as [...] "standard logarithm". Historically, it was known as logarithmus decimalis or logarithmus decadis. It is indicated by log10(x), or sometimes Log(x) with a capital L (however, this notation is ambiguous since it can also mean the complex natural logarithmic multi-valued function). On calculators it is usually [...] "log", but mathematicians usually mean natural logarithm (logarithm with base e ≈ 2.71828) rather than common logarithm when they write [...] "log". To mitigate this ambiguity the ISO 80000 specification recommends that log10(x) should be written lg (x) and loge(x) should be ln (x).|$|E
40|$|Figure 4 - Correlations between {{duration}} (in seconds) of TI of Porcellio scaber {{induced by}} the different treatments: a correlation between duration of TI induced by squeeze and drop b correlation between duration of TI induced by touch and drop c correlation between duration of TI induced by touch and squeeze. Data were transformed by <b>decimal</b> <b>logarithm...</b>|$|E
40|$|This study {{aimed to}} {{characterize}} the bacterium-destroying properties of a gliding arc plasma device during electric discharges and also under temporal postdischarge conditions (i. e., when the discharge was switched off). This phenomenon was reported {{for the first time}} in the literature in the case of the plasma destruction of microorganisms. When cells of a model bacterium, Hafnia alvei, were exposed to electric discharges, followed or not followed by temporal postdischarges, the survival curves exhibited a shoulder and then log-linear decay. These destruction kinetics were modeled using GinaFiT, a freeware tool to assess microbial survival curves, and adjustment parameters were determined. The efficiency of postdischarge treatments was clearly affected by the discharge time (t*); both the shoulder length and the inactivation rate kmax were linearly modified as a function of t*. Nevertheless, all conditions tested (t* ranging from 2 to 5 min) made it possible to achieve an abatement of at least 7 <b>decimal</b> <b>logarithm</b> units. Postdischarge treatment was also efficient against bacteria not subjected to direct discharge, and the disinfecting properties of “plasma-activated water” were dependent on the treatment time for the solution. Water treated with plasma for 2 min achieved a 3. 7 -decimal-logarithm-unit reduction in 20 min after application to cells, and abatement greater than 7 <b>decimal</b> <b>logarithm</b> units resulted from the same contact time with water activated with plasma for 10 min. These disinfecting properties were maintained during storage of activated water for 30 min. After that, they declined as the storage time increased...|$|E
40|$|Heterozygous hypobetalipoproteinemia is {{characterized}} by reduced plasma concentrations of LDL cholesterol, total triglycerides, and apo B to less than 50 % of normal values. The molecular basis of this disorder remains unknown. The phenotype cosegregates with a DNA haplotype of the apo B gene in an Idaho pedigree, with a maximum <b>decimal</b> <b>logarithm</b> of the ratio (LOD) score of 7. 56 at a recombination rate of zero. Individuals carrying this haplotype had total cholesterol levels of 96 mg/dl, LDL cholesterol levels of 37 mg/dl, triglycerides levels of 51 mg/dl, and apo B levels of 38 mg/dl. This study strongly suggests that apo B mutations underlie hypobetalipoproteinemia, and demonstrates {{the power of the}} candidate gene approach in linkage analysis for unraveling genetic determinants in metabolic disorders of undefined etiology...|$|E
40|$|Among {{the various}} soil {{indicators}} established {{in order to}} discuss physical properties of soils is the S-index, derived from the slope of the soil water retention curve at its inflection point, used by a number of authors. In this publication we discuss the value of the slope at the inflection point of the soil water retention curve according to the independent variable used to plot it. We show that a representation of the water content according to the arithmetic rather than logarithmic expression of the suction for the S-index yields a different result for the soil selected. More generally, our results show that examining the physical properties of soil using a water retention curve plotted with an arithmetic expression of suction offers greater potential than when plotted with its natural or <b>decimal</b> <b>logarithm</b> as is often found in the literature...|$|E
40|$|The {{kinetics}} of post-exercise {{heart rate}} (HR) and oxygen consumption (EPOC) was studied in 10 elite cyclists subjected to 4 laboratory cycle ergometer maximal exercises lasting 30, 90, 180 or 360 s. Heart rate and oxygen uptake (VO 2) were recorded {{over a period}} of 6 min postexercise. By applying the logit transformation to the recorded variables and relating them to the <b>decimal</b> <b>logarithm</b> of the recovery time, uniform, single-phase courses of changes were shown for both variables in all subjects and exercises. This enabled computing half-recovery times (t) for both variables. Half-time for VO 2 negatively correlated with square root of exercise duration (within-subject r = – 0. 629; p< 0. 001), the total post-exercise oxygen uptake till t was thus constant irrespectively of exercise intensity. The method is simple and enables reliable comparisons of various modes of exercise with respect to the rate of recovery...|$|E
40|$|P-glycoprotein (P-gp) is an ATP (adenosine triphosphate) -binding {{cassette}} transporter {{that causes}} multidrug resistance of various chemotherapeutic substances by active efflux from mammalian cells. P-gp plays {{a pivotal role}} in limiting drug absorption and distribution in different organs, including the intestines and brain. Thus, the prediction of P-gp–drug interactions is of vital importance in assessing drug pharmacokinetic and pharmacodynamic properties. To find the strongest P-gp blockers, we performed an in silico structure-based screening of P-gp inhibitor library (1, 300 molecules) by the gradient optimization method, using polynomial empirical scoring (POLSCORE) functions. We report a strong correlation (r 2 = 0. 80, F= 16. 27, n= 6, P< 0. 0157) of inhibition constants (Kiexp or pKiexp; experimental Ki or negative <b>decimal</b> <b>logarithm</b> of Kiexp) converted from experimental IC 50 (half maximal inhibitory concentration) values with POLSCORE-predicted constants (KiPOLSCORE or pKiPOLSCORE), using a linear regression fitting technique. The hydrophobic interactions between P-gp and selected drug substances were detected as the main forces responsible for the inhibition effect. The results showed that this scoring technique might be useful in the virtual screening and filtering of databases of drug-like compounds at the early stage of drug development processes...|$|E
40|$|High {{somatic cell}} counts (SCC) is {{associated}} with mastitis infection, in dairy herds, worldwide. This work describes Machine Learning (ML) techniques designed to improve the information offered to farmers on animals producing high SCCs according to particular herd profiles. The analysed population included 71 dairy farms in Asturias (Northern Spain) {{and a total of}} 2, 407 lactating cows. Four sources of information were available: a) a questionnaire survey describing facilities, milking routines and management practices of the farms studied; b) dairy recording information; c) classification of the cows suspected of being healthy or subclinical mastitic according to farmers’ expertise; and d) positive or negative scores with respect to the California Mastitis Test (CMT). The <b>decimal</b> <b>logarithm</b> of the SCC (linear score), lactation number, herd size, lactating cows per milker, milk urea concentration, number of clusters per milker and actual SCC are shown to be the most informative attributes for mimicking both farmers’ expertise or CMT performance in order to identify animals producing persistently high SCCs in dairy herds. However, to improve the identification of cows suspected of being non-healthy, the system uses other information related to management and milking routines. Decision rules to predict CMT performance can provide useful, additional information to farmers to improve the management of dairy herds included in milk recording programs...|$|E
40|$|The <b>decimal</b> <b>logarithm</b> of {{spontaneous}} fission half-life of the superheavy nucleus ^ 286 Fl experimentally determined is _ 10 T_f^exp (s) = - 0. 632. We present {{a method to}} calculate the half-life based on the cranking inertia and the deformation energy, functions of two independent surface coordinates, using the best asymmetric two center shell model. In the first stage we study the statics. At a given mass asymmetry up to about η= 0. 5 the potential barrier has a two hump shape, but for larger η it has only one hump. The touching point deformation energy versus mass asymmetry shows the three minima, produced by shell effects, corresponding to three decay modes: spontaneous fission, cluster decay and α decay. The least action trajectory is determined in the plane (R,η) where R is the separation distance of the fission fragments and η is the mass asymmetry. We may find a sequence of several trajectories one of which gives the least action. The parametrization with two deformation coordinates (R,η) and the radius of the light fragment, R_ 2, exponentially decreasing with R is compared with the simpler one, in which R_ 2 =constant. The latter {{is closer to the}} reality and reminds us about the alpha or cluster preformation at the nuclear surface. Comment: 18 pages, 9 figures, 3 tables, URL: [URL]...|$|E
40|$|Sergey Shityakov, Carola FörsterDepartment of Anesthesia and Critical Care, University of Würzburg, Würzburg, GermanyAbstract: P-glycoprotein (P-gp) is an ATP (adenosine triphosphate) -binding {{cassette}} transporter {{that causes}} multidrug resistance of various chemotherapeutic substances by active efflux from mammalian cells. P-gp plays {{a pivotal role}} in limiting drug absorption and distribution in different organs, including the intestines and brain. Thus, the prediction of P-gp–drug interactions is of vital importance in assessing drug pharmacokinetic and pharmacodynamic properties. To find the strongest P-gp blockers, we performed an in silico structure-based screening of P-gp inhibitor library (1, 300 molecules) by the gradient optimization method, using polynomial empirical scoring (POLSCORE) functions. We report a strong correlation (r 2 = 0. 80, F= 16. 27, n= 6, P< 0. 0157) of inhibition constants (Kiexp or pKiexp; experimental Ki or negative <b>decimal</b> <b>logarithm</b> of Kiexp) converted from experimental IC 50 (half maximal inhibitory concentration) values with POLSCORE-predicted constants (KiPOLSCORE or pKiPOLSCORE), using a linear regression fitting technique. The hydrophobic interactions between P-gp and selected drug substances were detected as the main forces responsible for the inhibition effect. The results showed that this scoring technique might be useful in the virtual screening and filtering of databases of drug-like compounds at the early stage of drug development processes. Keywords: ATP-binding cassette transporter, P-gp inhibitors, multidrug resistance, molecular docking, POLSCOR...|$|E
40|$|Machine Learning {{as an aid}} to {{management}} decisions on high somatic cell counts in dairy farms High somatic cell counts (SCC) is associated with mastitis infection, in dairy herds, worldwide. This work describes Machine Learning (ML) techniques designed to improve the information offered to farmers on animals producing high SCCs according to particular herd profiles. The analysed population included 71 dairy farms in Asturias (Northern Spain) and a total of 2, 407 lactating cows. Four sources of information were available: a) a questionnaire survey describing facilities, milking routines and management practices of the farms studied; b) dairy recording information; c) classification of the cows suspected of being healthy or subclinical mastitic according to farmers’ expertise; and d) positive or negative scores with respect to the California Mastitis Test (CMT). The <b>decimal</b> <b>logarithm</b> of the SCC (linear score), lactation number, herd size, lactating cows per milker, milk urea concentration, number of clusters per milker and actual SCC are shown to be the most informative attributes for mimicking both farmers ’ expertise or CMT performance in order to identify animals producing persistently high SCCs in dairy herds. However, to improve the identification of cows suspected of being non-healthy, the system uses other information related {{to management}} and milking routines. Decision rules to predict CMT performance can provide useful, additional information to farmers to improve the management of dairy herds included in milk recording programs...|$|E
40|$|In {{the present}} work, the cluster {{radioactivity}} of even A uranium isotopes (218236 U) with the emission of both alpha-like and non-alpha-like neon clusters (20, 22, 24, 26, 28 Ne) was studied. The <b>decimal</b> <b>logarithm</b> of half-lives (expressed in seconds) were calculated by three different approaches based on (i) the single line of Universal curve (UNIV) for alpha and cluster radioactive decay, (ii) the Universal Decay law (UDL) and (iii) by considering a fission-like {{model in which}} the interacting nuclear potential barrier was taken to be the sum of Coulomb and proximity potentials (CPPM) respectively. Based on the half-lives calculated by using the three different approaches mentioned above, significance {{of the role of}} 208 Pb nucleus (doubly magic nucleus) and nuclear shell effects in trans-lead cluster radioactivity were investigated. The calculated half-lives have also been compared with available experimental results. It was observed that cluster decay modes leading to the formation of 208 Pb daughter nucleus have the lowest half-lives. This implies that there is a shell closure at proton number (Z) = 82 and neutron number (N) = 126. Hence, it confirms the existence of nuclear shell effect and stresses the significance of role of 208 Pb daughter nucleus in the trans-lead cluster radioactivity. It can be noticed that the calculated half-lives for several cluster decay modes are well within the present experimental upper limit for measurements (T 1 / 2 < 1030 S). These results may be useful for future experiments...|$|E
40|$|International audienceFor many years, {{pavement}} engineers use mechanistic design {{methods that}} are based on algorithms to compute stresses, strains and displacements in a flexible pavement structure, or in a multi-layered structure in general. Most of these methods assume, to ease the modelling of the structure and the computation process, that the layers are fully bonded or completely unbounded to each other. Moreover, determining the effectiveness of the bonding between two layers is difficult since there is no standard test procedure to assess it. Hence, proper modelling of the interface bonding condition will represent an important finding in understanding the real behaviour of road structures, and will lead to reduce maintenance and rehabilitation costs. Asphalt emulsion is commonly used, as tack coat, to ensure the bond between two pavement layers. This study deals with an experimental characterization of interfaces shear fatigue behaviour through laboratory tests. A testing device for determining the shear fatigue behaviour is described in this paper. Shear fatigue tests, at a temperature of 5 °C and a frequency of 1 Hz, were performed on asphalt concrete mix layers interface with tack coat. Samples were subjected to a cyclic symmetrical alternate shearing load at the interfaces, aiming interfaces failures within the range of 104 to 105 cycles of loading. Within this range of number of cycles, the fatigue results indicate a linear evolution of the initial shear stress half-amplitude with the <b>decimal</b> <b>logarithm</b> of the number of cycles to failure. These results are used to derive a linear fatigue law, which will serve to model the real behaviour of the interface with tack coat studied in this research...|$|E
40|$|International audienceIn {{order to}} upscale the induced {{polarization}} (IP) response of porous media, from the pore scale to the sample scale, we implement a procedure {{to compute the}} macroscopic complex resistivity response of random tube networks. A network is made of a 2 -D square-meshed grid of connected tubes, which obey to a given tube radius distribution. In a simplified approach, the electrical impedance of each tube follows a local Pelton resistivity model, with identical resistivity, chargeability and Cole–Cole exponent values for all the tubes—only the time constant varies, as {{it depends on the}} radius of each tube and on a diffusion coefficient also identical for all the tubes. By solving the conservation law for the electrical charge, the macroscopic IP response of the network is obtained. We fit successfully the macroscopic complex resistivity also by a Pelton resistivity model. Simulations on uncorrelated and correlated networks, for which the tube radius distribution is so that the <b>decimal</b> <b>logarithm</b> of the radius is normally distributed, evidence that the local and macroscopic model parameters are the same, except the Cole–Cole exponent: its macroscopic value diminishes with increasing heterogeneity (i. e. with increasing standard deviation of the radius distribution), compared to its local value. The methodology is also applied to six siliciclastic rock samples, for which the pore radius distributions from mercury porosimetry are available. These samples exhibit the same behaviour as synthetic media, that is, the macroscopic Cole–Cole exponent is always lower than the local one. As a conclusion, the pore network method seems to be a promising tool for studying the upscaling of the IP response of porous media...|$|E
40|$|Objective {{to develop}} the economicmathematical model of the {{dependence}} of revenue on other balance sheet items {{taking into account the}} sectoral affiliation of the companies. 	Methods using comparative analysis the article studies the existing approaches to the construction of the company management models. Applying the regression analysis and the least squares method which is widely used for financial management of enterprises in Russia and abroad the author builds a model of the dependence of revenue on other balance sheet items taking into account the sectoral affiliation of the companies which can be used in the financial analysis and prediction of small enterprisesrsquo performance. 	Results the article states the need to identify factors affecting the financial management efficiency. The author analyzed scientific research and revealed the lack of comprehensive studies on the methodology for assessing the small enterprisesrsquo management while the methods used for large companies are not always suitable for the task. The systematized approaches of various authors to the formation of regression models describe the influence of certain factors on the company activity. It is revealed that the resulting indicators in the studies were revenue profit or the company relative profitability. The main drawback of most models is the mathematical not economic approach to the definition of the dependent and independent variables. Basing on the analysis it was determined that the most correct is the model of dependence between revenues and total assets of the company using the <b>decimal</b> <b>logarithm.</b> The model was built using data on the activities of the 507 small businesses operating in three spheres of economic activity. Using the presented model it was proved that there is direct dependence between the sales proceeds and the main items of 	the asset balance as well as differences in the degree of this effect depending on the economic activity of small enterprises. 	Scientific novelty the article presents a regression model of dependence of revenues on the major categories of assets for small businesses based on the principles of economic expediency not of mathematically correct dependencies. 	Practical significance the main findings of this paper can be useful in the practical management of small businesses for financial analysis and forecasting in particular in the benchmarking of companies in certain sectors. In addition the results of this research can be used in scientific and teaching activities in covering the issues of financial management of small businesses...|$|E
40|$|O {{experiment}}o foi conduzido no Campo Experimental de Coronel Pacheco - MG da EMBRAPA Gado de Leite. O efeito de doses de enxofre (sulfato de amônio, 0, 15; 0, 31; 0, 46 e 0, 92 % de S na matéria verde / dia) na população de protozoários ruminais, foi avaliado utilizando-se quatro novilhas 7 / 8 Holandês X Zebu, arranjadas em um quadrado latino de 4 x 4. Forneceu-se diariamente capim-elefante de baixa qualidade (76, 1 % FDN na MS), picado, com correção do teor de PB para 7 % com uréia, mais mistura mineral sem enxofre fornecida diretamente no rúmen. Foram feitas amostragens do conteúdo ruminal, uma hora após a alimentação. A estimativa das populações microbianas ruminais foi realizada por microscópica direta. Os resultados foram transformados para logaritmos decimais e avaliados estatisticamente. Não houve diferença significativa entre os tratamentos para microrganismos. O tratamento 0, 92 %S apresentou o menor consumo de matéria seca e ainda, causou início de intoxicação em dois animais. De acordo com esses resultados, doses de 0, 31 % de enxofre adicionadas a dieta promoveram o incremento das populações de microganismos ruminais e com isso um maior consumo voluntário. The {{experiment was}} carried out in the Experimental Field of Coronel Pacheco belonging to EMBRAPA Dairy Cattle, Minas Gerais. The effects of the doses of sulfur (ammonium sulfate, 0. 15 %, 0. 31 %, 0. 46 % and 0. 92 %S fresh matter/day) on the ruminal protozoa population was evaluated by utilizing four 7 / 8 Holstein x Zebu, heifers arranged in 4 x 4 Latin square. Low quality elephant grass (76. 1 % NDF in DM), chopped with correction of the CP content to 7 % with urea plus a mineral mixture without sulfur given directly into the rumen. Samplings of the ruminal content were done, one hour after feeding. The estimate of the ruminal microbial populations was done by means of the direct microscopy. The results were transformed to <b>decimal</b> <b>logarithm</b> and evaluated statistically. There were no significant differences among the treatments for microorganisms. The 0. 92 %S treatment presented the least dry matter intake and, in addition, caused start of intoxication in two animals. According to those results, doses of 0. 31 % of sulfur added to the diet promoted the increase of the ruminal microorganism populations and hence a greater voluntary intake...|$|E
40|$|Analytical and {{geometrical}} {{properties of}} generalized power-law (GPL) density profiles are investigated in detail. In particular, a one-to-one correspondence is found between mathematical parameters (a scaling radius, r 0, a scaling density, ρ 0, and three exponents, α, β, γ), and geometrical parameters (the coordinates of {{the intersection of}} the asymptotes, xC, yC, and three vertical intercepts, b, bβ, bγ, related to the curve and the asymptotes, respectively) : (r 0,ρ 0,α,β,γ) ↔ (xC,yC,b,bβ,bγ). Then GPL density profiles are compared with simulated dark haloes (SDH) density profiles, and nonlinear least-absolute values and least-squares fits involving the above mentioned five parameters (RFSM 5 method) are prescribed. More specifically, the sum of absolute values or squares of absolute logarithmic residuals, Ri=logρSDH(ri) − logρGPL(ri), is evaluated on 10 points making a 5 dimension hypergrid, through a few iterations. The size is progressively reduced around a fiducial minimum, and superpositions on nodes of earlier hypergrids are avoided. An application is made to a sample of 17 SDHs on the scale of cluster of galaxies, within a flat ΛCDM cosmological model (Rasia et al. 2004). In dealing with the mean SDH density profile, a virial radius, Rvir, averaged over the whole sample, is assigned, which allows the calculation of the remaining parameters. Using a RFSM 5 method provides a better fit with respect to other methods. The geometrical parameters, averaged over the whole sample of best fitting GPL density profiles, yield (α, β, γ) ≈ (0. 6, 3. 1, 1. 0), to be compared with (α, β, γ) = (1, 3, 1), i. e. the NFW density profile (Navarro et al. 1995, 1996, 1997), (α, β, γ) = (1. 5, 3, 1. 5) (Moore et al. 1998, 1999), (α, β, γ) = (1, 2. 5, 1) (Rasia et al. 2004); and, in addition, γ ≈ 1. 5 (Hiotelis 2003), deduced from the application of a RFSM 5 method, but using a different definition of scaled radius, or concentration; and γ ≈ 1. 21. 3 deduced from more recent high-resolution simulations (Diemand et al. 2004, Reed et al. 2005). No evident correlation is found between SDH dynamical state (relaxed or merging) and asymptotic inner slope of the fitting logarithmic density profile or (for SDH comparable virial masses) scaled radius. Mean values and standard deviations of some parameters are calculated, and in particular the <b>decimal</b> <b>logarithm</b> of the scaled radius, ξvir, reads = 0. 74 and σslogξvir = 0. 150. 17, consistent with previous results related to NFW density profiles. It provides additional support to the idea, that NFW density profiles may be considered as a convenient way to parametrize SDH density profiles, without implying that it necessarily produces the best possible fit (Bullock et al. 2001). A certain degree of degeneracy is found in fitting GPL to SDH density profiles. If it is intrinsic to the RFSM 5 method or it could be reduced by the next generation of high-resolution simulations, still remains an open question. ...|$|E
40|$|Analytical and {{geometrical}} {{properties of}} generalized power-law (GPL) density profiles are reviewed, and special effort {{is devoted to}} the special cases where GPL density profiles reduce to (i) a double power-law (DPL), and (ii) a single power-law (SPL). Then GPL density profiles are compared with simulated dark haloes (SDH) density profiles, and non-linear least-squares fits are prescribed, involving five parameters (a scaling radius, r 0, a scaling density, ρ 0, and three exponents, α, β, γ), which specify the fitting profile (RFSM 5 method). More specifically, the validity of a necessary condition for the occurrence of an extremal point, is related to the existence of an intersection between three surfaces in a three-dimension space. Using the algorithm makes also establish that the extremal point is a fiducial minimum, while the explicit calculation of the Hessian determinant is avoided to gain in simplicity. In absence of a rigorous proof, the fiducial minimum can be considered as nothing but a fiducial absolute minimum. An application is made to a sample of 17 SDHs on the scale of cluster of galaxies, within a flat ΛCDM cosmological model (E. Rasia, G. Tormen, L. Moscardini, MNRAS 351 (2004) 237). In dealing with the averaged SDH density profile (ADP), a virial radius, rvir, equal to the mean over the whole sample, is assigned, which allows the calculation of the remaining parameters. The following results are found. (i) A necessary condition for the occurrence of an extremal point is satisfied for eight sample haloes, and is not for the remaining nine together with ADP. In the former alternative, an extremal minimum point (EMP) may safely exist. In the latter alternative, the occurrence of an EMP cannot be excluded, but only a non-extremal minimum can be determined. (ii) The occurrence of an EMP implies a sum of square residuals which is systematically lower than its counterpart deduced by use of numerical RFSM 5 methods. Accordingly, EMPs may safely be thought of as absolute minima. With regard to sample haloes where no EMP is detected, the above result maintains in four cases (including ADP), while the contrary holds for the remaining five cases. (iii) The best fit (with no EMP detected) is provided by DPL density profiles for three sample haloes. In addition, DPL density profiles make a rough, but viable approximation in fitting SDH density profiles. The contrary holds for SPL density profiles. No evident correlation is found between SDH dynamical state (relaxed or merging) and asymptotic inner slope of the logarithmic density profile or (for SDH comparable virial masses) scaled radius. Mean values and standard deviations of some parameters are calculated and, in particular, the <b>decimal</b> <b>logarithm</b> of the scaled radius, ξvir, reads and, the standard deviation exceeding by a factor 3. 3 – 3. 4 its counterpart evaluated in an earlier attempt using Navarro et al. (J. F. Navarro, C. S. Frenk, S. D. M. White, MNRAS 275 (1995) 720, J. F. Navarro, C. S. Frenk, S. D. M. White, ApJ 462 (1996) 563, J. F. Navarro, C. S. Frenk, S. D. M. White, ApJ 490 (1997) 493) density profiles (J. S. Bullock, T. S. Kolatt, Y. Sigad, MNRAS 321 (2001) 559). If a large dispersion still maintains for richer samples, in dealing with analytical RSFM 5 methods, a low dispersion found in N-body simulations seems to be an artefact, due to the assumption of Navarro et al. (or any equivalent choice) density profile. It provides additional support to the idea, that Navarro et al. density profiles may be considered as a convenient way to parametrize SDH density profiles, without implying that it necessarily produces the best possible fit (J. S. Bullock, T. S. Kolatt, Y. Sigad, MNRAS 321 (2001) 559). With regard to RFSM 5 methods formulated in the current paper, the exponents of both the best fitting GPL density profile to ADP, (α, β, γ) ≈ (0. 3, 4. 5, 1. 5), and related averages calculated over the whole halo sample,, are far from their Navarro et al. counterparts, (α, β, γ) = (1, 3, 1). The last result, together with the large value of the standard deviation,, is interpreted as due to a certain degree of degeneracy in fitting GPL to SDH density profiles. If it is a real feature of the problem, or it could be reduced by the next generation of high-resolution simulations, still remains an open question. Values of asymptotic inner slope of fitting logarithmic density profiles, are consistent with results from recent high-resolution simulations (J. Diemand, B. Moore, J. Stadel, MNRAS 353 (2004) 624; D. Reed, F. Governato, L. Verde, et al., MNRAS 357 (2005) 82) ...|$|E

