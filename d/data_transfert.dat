1|3|Public
40|$|The systems {{supporting}} {{signal and}} image applications process {{large amount of}} data. That involves an intensive use of the memory which becomes the bottleneck of systems. Memory limits performances and represents {{a significant proportion of}} total consumption. In the development high level synthesis tool called GAUT Low Power, we are interested in the synthesis of the memory unit. In this work, we integrate the data storage and <b>data</b> <b>transfert</b> to constraint the high level synthesis of the datapath's execution unit...|$|E
40|$|This report {{presents}} the Data-aware Process Networks, a new parallel execution model {{adapted to the}} hardware constraints of high-level synthesis, where the <b>data</b> <b>transferts</b> are made explicit. We show that the DPN model is consistant in the meaning where any translation of a sequential program produces an equivalent DPN without deadlocks. Finally, we show how to compile a sequential program to a DPN and how to optimize the input/output and the parallelism...|$|R
40|$|International audienceWe {{consider}} a network model where bandwidth is fairly shared by a dynamic number of elastic and adaptive streaming flows. Elastic flows correspond to <b>data</b> <b>transferts</b> while adaptive streaming flows correspond to audio/video applications with variable rate codecs. In particular, {{the former are}} characterized by a fixed size (in bits) while the latter are characterized by a fixed duration. This flow-level model {{turns out to be}} intractable in general. In this paper, we give performance bounds for both elastic and streaming traffic by means of sample-path arguments. These bounds present the practical interest of being insensitive totraffic characteristics like the distribution of elastic flo size and streaming flow duration...|$|R
40|$|Due {{to network}} {{bandwidth}} growth, grid computing has been envisionned. As grids are aggregation of computer clusters based on high performance local networks and interconnected by very high speed core networks, access links to core networks remain bottleneck locations. In order to optimize grid computing overall performance, we propose to organize data transfers from one cluster to an other. This organization must allow ressource schedulers to schedule <b>data</b> <b>transferts</b> in addition of tasks. Based on a grid network resource reservation model {{this paper presents}} the design f a grid gateway, located at the LAN/WAN interface. To implement this approach, we have develop a prototype based on Network Processors Intel IXP 2400 which is able to control flows at 1 gigabits/s. We discuss the main design choices and experimental result...|$|R

