280|4961|Public
50|$|Sorts {{a variety}} of objects so that all things in the group have a single common <b>feature</b> (<b>classification</b> skill: all are food items or boats or animals).|$|E
50|$|One <b>feature</b> <b>classification,</b> regio, was {{originally}} used on early {{maps of the}} Moon and Mercury (drawn from telescopic observations) to describe vague albedo features. It is now used to delineate a broad geographic region.|$|E
50|$|Mosquito bugs have a {{characteristic}} spine on the scutellum, {{which is a}} diagnostic <b>feature.</b> <b>Classification</b> {{in the field is}} based on morphological characteristics, with considerable variations in colouration between insects of the same species (although for example, H. theivora is characteristically green and H. antonii red-brown).|$|E
40|$|Invasive {{plants of}} the south Colchis are studied for more than 10 years. In a current paper we {{represent}} {{the results of the}} investigations on biomorphological and environmental <b>features,</b> <b>classification,</b> characters of reproduction and development, eco-pathologic features for advent grasses of Adjraare region...|$|R
30|$|For multidimensional <b>features,</b> <b>classification</b> {{becomes more}} difficult. Advanced classifiers, such as Gaussian mixture models (GMM) or neural {{networks}} (NN), {{can be trained}} to distinguish speech from noise based on the feature vectors. Also for these features, finally, a binary and scalar decision is achieved.|$|R
40|$|A {{new method}} of feature {{extraction}} {{in the social}} network for within-network classification is proposed in the paper. The method provides new features calculated by combination of both: network structure information and class labels assigned to nodes. The influence of various <b>features</b> on <b>classification</b> performance has also been studied. The experiments on real-world data have shown that features created owing to the proposed method can lead to significant improvement of <b>classification</b> accuracy. Comment: <b>feature</b> extraction, label-dependent <b>features,</b> <b>classification,</b> social network analysis, AMD social networ...|$|R
50|$|Going beyond Bioimaging applications, BisQue {{has been}} used in {{analyzing}} underwater images and video (REF here) and in medical imaging applications. The current BisQue interface now supports the latest DICOM standard. BisQue has integrated over 100 different image features in its feature service and the next release will include support for deep learning methods and <b>feature</b> <b>classification</b> services.|$|E
5000|$|Specifically, in {{the area}} of {{computer}} vision, the N-jet is usually computed from a scale space representation [...] of the input image , and the partial derivatives of [...] are used as a basis for expressing various types of visual modules. For example, algorithms for tasks such as feature detection, <b>feature</b> <b>classification,</b> stereo matching, tracking and object recognition can be expressed in terms of N-jets computed at one or several scales in scale space.|$|E
50|$|In general, {{increases}} in the attentiveness of the subject lead to decreased amplitude of the P2. Increased attention decreases the amount of search space, or number of associations {{that need to be}} made, and may facilitate <b>feature</b> <b>classification</b> in visual search at the stage of perceptual processing. More probable targets also lead to decreased amplitude of the P2, which is sensitive to the number of non-target (distracter) features in a visual search. The amplitude of the P2 is greater when the visual search is more efficient (selective attention), but this does not affect the latency.|$|E
5000|$|... #Subtitle level 2: <b>Features</b> & <b>classification</b> of truck campers ...|$|R
5000|$|... Leimer was {{excluded}} from <b>Feature</b> Race <b>classification</b> for causing collisions.|$|R
40|$|Relational {{categories}} underlie many uniquely human {{cognitive processes}} including analogy, problem solving, and scientific discovery. Despite their ubiquity and importance, {{the field of}} category learning has focused almost exclusively on categories based on <b>features.</b> <b>Classification</b> of featurebased categories is typically modeled by calculating similarity to stored representations, an approach that successfully models the learning of both probabilistic and deterministi...|$|R
50|$|When Gaussian {{derivative}} {{operators and}} differential invariants {{are used in}} this way as basic feature detectors at multiple scales, the uncommitted first stages of visual processing are {{often referred to as}} a visual front-end. This overall framework has been applied to a large variety of problems in computer vision, including feature detection, <b>feature</b> <b>classification,</b> image segmentation, image matching, motion estimation, computation of shape cues and object recognition. The set of Gaussian derivative operators up to a certain order {{is often referred to as}} the N-jet and constitutes a basic type of feature within the scale-space framework.|$|E
50|$|The visual P2 {{has also}} been studied {{in the context of}} the visual priming paradigm, which seeks to {{understand}} how prior information shapes future response. In this experimental design, participants are briefly presented with an image or word, followed by a delay, and a subsequent stimulus upon which participants must make a classification. Researchers have used the visual search paradigm with stimulus arrays and found that target stimuli elicited larger anterior P2 components compared with standards. This evidence suggests that top-down information processing about <b>feature</b> <b>classification</b> affected processing at the visual perception stage. Thus, the P2 may index mechanisms for selective attention, feature detection (including color, orientation, shape, etc.) and other early stages of item encoding.|$|E
50|$|Optical music {{recognition}} (OMR) is {{software to}} “read” scanned sheet music. Although OMR {{contributed to the}} evolution of digital sheet music, it is currently still a complex problem. While the earliest attempts of OMR were made in the early 1970s, the first commercial products appeared in the early 90s. Currently, many commercial OMR tools are available: SharpEye2, SmartScore, Photoscore, CapellaScan. OMR can be simplified into four smaller tasks: staff line identification, musical object location, musical <b>feature</b> <b>classification</b> and musical semantics (Bainbridge & Bell, 2001). However, in most cases,s these systems operate only properly with well-scanned documents of high quality. When it comes to precision and reliability, none of the commercial OMR systems solve the problem in a satisfactory way. Especially since the tradition of notating music is quite diffuse and varied, it remains difficult to reduce its aesthetics to a few principles for a machine to follow.|$|E
5000|$|... pyAudioAnalysis (last {{repository}} update: September 2016): Python Audio Analysis Library: <b>Feature</b> Extraction, <b>Classification,</b> Segmentation and Applications https://github.com/tyiannak/pyAudioAnalysis ...|$|R
40|$|Matrix factorizations {{and their}} {{extensions}} to tensor factorizations and decompositions have become prominent techniques for linear and multilinear blind source separation (BSS), especially multiway Independent Component Analysis (ICA), NonnegativeMatrix and Tensor Factorization (NMF/NTF), Smooth Component Analysis (SmoCA) and Sparse Component Analysis (SCA). Moreover, tensor decompositions have many other potential applications beyond multilinear BSS, especially <b>feature</b> extraction, <b>classification,</b> dimensionality reduction and multiway clustering. In this paper, we briefly overview new and emerging models and approaches for tensor decompositions in applications to group and linked multiway BSS/ICA, <b>feature</b> extraction, <b>classification</b> andMultiway Partial Least Squares (MPLS) regression problems. Keywords: Multilinear BSS, linked multiway BSS/ICA, tensor factorizations and decompositions, constrained Tucker and CP models, Penalized Tensor Decompositions (PTD), <b>feature</b> extraction, <b>classification,</b> multiway PLS and CCA...|$|R
30|$|Full {{features}} (FF) which adopts all the <b>features</b> for <b>classification.</b> It {{is used as}} baseline {{method in}} this paper.|$|R
50|$|Although {{not nearly}} as fast and energy efficient, digital CNN {{processors}} do not share the problems of process variation and feature size of their analog counterparts. This allows digital CNN processors to include nested processor units, non-linearities, etc. In addition, digital CNN are more flexible, cost less and are easier to integrate. The most common implementation of digital CNN processors uses an FPGA. Eutecus, founded in 2002 and operating in Berkeley, provides intellectual property that can be synthesized into an Altera FPGA. Their digital 320x280, FPGA-based CNN processors run at 30 frame/s and there are plans to make a fast digital ASIC. Eustecus is a strategic partner of AnaLogic computers, and their FPGA designs {{can be found in}} several of AnaLogic’s products. Eutecus is also developing software libraries to perform tasks including but not limited to video analytics for the video security market, <b>feature</b> <b>classification,</b> multi-target tracking, signal and image processing and flow processing. Many of these routines are derived using CNN-like processing. For those wanting to perform CNN simulations for prototyping, low-speed applications, or research, there are several options. First, there are precise CNN emulation software packages like SCNN 2000. If the speed is prohibitive, there are mathematical techniques, such as Jacobi’s Iterative Method or Forward-Backward Recursions {{that can be used to}} derive the steady state solution of a CNN processor. Said techniques can be performed by any mathematics tool, e.g. Matlab. Lastly, digital CNN processors can be emulated on highly parallel, application-specific processors, such as graphics processors. Implementing neural networks using graphics processors is an area of exploration for the research community.|$|E
30|$|For the SVM classifier, {{this paper}} {{presents}} two improved methods: <b>feature</b> <b>classification</b> normalization and SVM combination classifier.|$|E
40|$|There {{are around}} 10, 426 bird species around the world. Recognizing the bird species for an untrained person is almost {{impossible}} either by watching or listening them. In order to identify the bird species from their sounds, {{there is a need}} for an application that can detect the bird species from its sound. Time-frequency domain analysis techniques are used to implement the application. We implemented two time-frequency domain feature extraction methods. In feature extraction, a signature matrix which consist of extracted features is created for bird sound signals. A database of signature matrix is created with bird chirps extracted features. We implemented two <b>feature</b> <b>classification</b> methods. They are auto-correlation <b>feature</b> <b>classification</b> method and reference difference <b>feature</b> <b>classification</b> method. An unknown bird chirp is compared with the database to detect the species name. The main aim of the research is to implement the time-frequency domain feature extraction method, create a signature matrix database, implement two <b>feature</b> <b>classification</b> methods and compare them. At last, bird species were identified in the research and the auto-correlation classification method detects the bird species better than the reference difference classification method...|$|E
40|$|A linear Support Vector Machine (SVM) {{classifier}} {{is designed}} to detect and classify seizures in EEG signals based on a few simple features such as mean, variance, dominant frequency, and the mean power spectrum. The SVM classifier is tested on a benchmark EEG database. Using {{a combination of these}} <b>features,</b> <b>classification</b> rates up to 98 % were achieved. The proposed classifier that utilizes a few simple features is computationally efficient to be deployed in a real-time seizure monitoring system...|$|R
40|$|We {{present a}} named entity {{recognition}} and classification system that uses only probabilis-tic character-level <b>features.</b> <b>Classifications</b> by multiple orthographic tries are combined in a hidden Markov model framework to incorpo-rate {{both internal and}} contextual evidence. As part of the system, we perform a preprocess-ing stage in which capitalisation is restored to sentence-initial and all-caps words with high accuracy. We report f-values of 86. 65 and 79. 78 for English, and 50. 62 and 54. 43 for the German datasets. ...|$|R
40|$|This master thesis {{deals with}} the use of {{gestures}} in user interfaces. The goal of this thesis is to create library for hand tracking and gesture recognition in real time. For hand tracking was choosen algorithm Flock of <b>Features.</b> <b>Classification</b> of gestures is done by using algorithm DTW. This thesis also contains stage design, design and implementation of a system that uses this library. Within the tests was tested control of various application using this library...|$|R
40|$|Feature {{extraction}} is {{the first}} and most critical step in vari-ous vision applications. The detected features must be clas-sified into different feature types before they can be effi-ciently and effectively applied on further vision tasks. In this paper, we propose a <b>feature</b> <b>classification</b> algorithm that classifies the detected regions into four types including blobs, edges and lines, textures, and texture boundaries, by using the correlations with the neighbouring regions. The effectiveness of the <b>feature</b> <b>classification</b> is evaluated on image retrieval. 1...|$|E
40|$|This paper {{points out}} that {{different}} local feature points provide different impacts to near-duplicate detection and related applications. Aiming to automatic representative photo selection, we develop three <b>feature</b> <b>classification</b> methods, i. e., point-based, region-based, and pLSA-based classification, to differentiate local feature points described by SIFT descriptors. We investigate the performance of these classification methods, and discuss how they influence near-duplicate detection and extended applications. Experiments show that, with effective <b>feature</b> <b>classification,</b> more accurate representative selection results can be achieved. Categories and Subject Descriptor...|$|E
40|$|Noncooperation frequency-hopping (FH) {{transmitter}} fingerprint <b>feature</b> <b>classification</b> is {{a significant}} but challenging issue for FH transmitter recognition, since {{not only is it}} sensitive to noise but also it has the nonlinear, non-Gaussian and nonstability characteristics, which make it difficult to guarantee the classification in the original signal space. To address these problems, a method of frequency-hopping transmitter fingerprint <b>feature</b> <b>classification</b> based on kernel collaborative representation classifier is proposed in this paper. First, the noise suppression pretreatment of the FH transmitter signal is carried out by using the wave atoms frame method. Then, the nuances of the FH transmitters in the feature space are characterized by the surrounding-line integral bispectra features. And finally, incorporating the kernel function, a classifier which can generalize a linear algorithm to nonlinear counterpart is constructed for the final transmitter fingerprint <b>feature</b> <b>classification.</b> Extensive experiments on real-world FH transmitter “turn-on” transient signals demonstrate the robust classification of our method...|$|E
40|$|Audio {{classification}} {{serves as}} the fundamental step towards the rapid growth in audio data volume. Automatic audio classification is very useful in audio indexing; content based audio retrieval and online audio distribution. The accuracy of the classification relies {{on the strength of}} the <b>features</b> and <b>classification</b> scheme. In this work both, time domain and frequency domain features are extracted from the input signal. Time domain features are Zero Crossing Rate (ZCR) and Short Time Energy (STE). Frequency domain features are spectral centroid, spectral flux, spectral entropy and spectral roll-off. After <b>feature</b> extraction, <b>classification</b> is carried out, using SVM model. The proposed <b>feature</b> extraction and <b>classification</b> models results in better accuracy in speech/music classification...|$|R
30|$|The button ‘Select File’ {{allows the}} user to select the patient file, and the button ‘Biomark’ {{performs}} preprocessing, <b>feature</b> extraction, <b>classification,</b> and biomarking.|$|R
5000|$|There {{are four}} main types of pseudogenes, all with {{distinct}} mechanisms {{of origin and}} characteristic <b>features.</b> The <b>classifications</b> of pseudogenes are as follows: ...|$|R
3000|$|Our ICANet-based face {{recognition}} system adopts unsupervised {{learning in the}} feature extraction and <b>feature</b> <b>classification</b> stages. Thus, the system does not need labeled training samples and is easily used [...]...|$|E
40|$|While {{the primary}} purpose of edge {{detection}} schemes {{is to be able to}} produce an edge map of a given image, the ability to distinguish between different feature types is also of importance. In this paper we examine <b>feature</b> <b>classification</b> based on local energy detection and show that local energy measures are intrinsically capable of making this classification because of the use of odd and even filters. The advantage of <b>feature</b> <b>classification</b> is that it allows for the elimination of certain feature types from the edge map, thus simplifying the task of object recognition. <br /...|$|E
30|$|The above {{test results}} show that {{combining}} the LBP and HOG features for capturing the texture and gradient information around the cavity region, and using the GTM for shape recognition, contributes to the low MR of the proposed coarse <b>feature</b> <b>classification</b> technique.|$|E
40|$|This {{bachelor}} thesis {{deals with}} inteligent <b>features</b> <b>classification</b> aimed to support diagnosis of glaucoma. First part focuses on eye anatomy and disease called glaucoma. In next part is briefly described texture analysis {{and how do}} we get attributes for classification. In last part it is dealt with attribute classification with the aid of neural networks and algorithm HoKashyap and AdaBoost. This thesis is therefore focused on comparing effectivity of these classifiers on the field of optical diagnostics which was managed successfully...|$|R
40|$|The basic {{principle}} of data mining is {{to analyze the}} data from different perspectives, classify it and recapitulate it. Data mining has become very popular in each and every application. Though we have large amount of data but we don’t have useful information in every field. There are many data mining tools and software to facilitate us the useful information. This paper gives the fundamentals of data mining steps like preprocessing the data (removing the noisy data, replacing the missing values etc.), feature selection (to select the relevant features and removing the irrelevant and redundant <b>features),</b> <b>classification</b> and evaluation of different classifier models using WEKA tool. The WEKA tool is not useful for only one type of application, though it can be used in various applications. This tool consists of various algorithms for <b>feature</b> selection, <b>classification</b> and clustering as well...|$|R
40|$|The {{proposed}} {{framework for}} agent based <b>feature</b> selection and <b>classification</b> system {{works with the}} help of software agents. These agents are rule based and are able to guide the user in <b>feature</b> selection and <b>classification.</b> With number of <b>feature</b> selection and <b>classification</b> algorithms available the framework paves way for an integrated approach in <b>feature</b> selection and <b>classification.</b> Initial results with partially implemented system prove to be promising in the field of machine learning. The algorithm was used on a live web site data for three years and the results were mined using the framework. The results give hope to show that agent based decision making can be very useful for persons who do not have idea of mining but are decision makers...|$|R
