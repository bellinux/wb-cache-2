2|40|Public
40|$|A sensor is {{developed}} for simple, in situ characterization of dielectric thermal interface materials (TIMs) at bond line thicknesses less than 100 lm. The working principle {{is based on}} the detection of regions of contrasting electric permittivity. An array of long, parallel electrodes is flush-mounted into each opposing substrate face of a narrow gap interface, and exposed to the gap formed between the two surfaces. Electrodes are oriented such that their lengthwise dimension in one substrate runs perpendicular to those in the other. A capacitance measurement taken between opposing electrodes is used to characterize the interface region in the vicinity of their crossing point (junction). The electric field associated with each electrode junction is numerically simulated and analyzed. Criteria are developed for the design of electrode junction geometries that localize the electric fields. The capacitances between floating-ground electrodes in the electrode sensor configuration employed give rise to a nontrivial network of interacting capacitances which strongly influence the measured response at any junction. A generalized solution for analyzing the <b>floating</b> <b>network</b> response is presented. The technique is used to experimentally detect thermal grease spots of 0. 2 mm to 1. 8 mm diameter within a 25 lm interface gap. It is necessary to use the generalized solution to the capacitance network developed in this work to properly delineate regions of contrasting permittivity in the interface gap region using capacitance measurements...|$|E
40|$|In Francis and Steel (2015), it {{was shown}} that there exists non-trivial {{networks}} on $ 4 $ leaves upon which the distance metric affords a metric on a tree {{which is not the}} base tree of the network. In this paper we extend this result in two directions. We show that for any tree $T$ there exists a family of non-trivial HGT networks $N$ for which the distance metric $d_N$ affords a metric on $T$. We additionally provide a class of networks on any number of leaves upon which the distance metric affords a metric on a tree which is not the base tree of the network. The family of networks are all "floating" networks, a subclass of a novel family of networks introduced in this paper, and referred to as "versatile" networks. Versatile networks are then characterised. Additionally, we find a lower bound for the number of `useful' HGT arcs in such networks, in a sense explained in the paper. This lower bound is equal to the number of HGT arcs required for each <b>floating</b> <b>network</b> in the main results, and thus our networks are minimal in this sense. Comment: This paper has been withdrawn due to an error in Theorem 3. 7, which may has implications for the main theorem. An updated version may follow soo...|$|E
5000|$|... #Caption: The {{launch of}} 100 {{floating}} sensors into the Sacramento River for the <b>Floating</b> Sensor <b>Network</b> project ...|$|R
40|$|The general {{objective}} of the IOCCG BIO-Argo working group is to elaborate recommendations for establishing a framework for the future development of a cost-effective, bio-optical <b>float</b> <b>network</b> corresponding {{to the needs and}} expectations of the scientific community. In this context, our recommendations will necessarily be broad; they range from the identification of key bio-optical measurements to be implemented on floats, to the real-time management of the data flux resulting from the deployment of a "fleet of floats". Each chapter of this report is dedicated to an essential brick leading towards the goal of implementing a bio-optical profiling <b>float</b> <b>network.</b> The following topics are discussed in the Chapters listed below: - Chapter 2 reviews the scientific objectives that could be tackled through the development of such networks, by allowing some of the gaps in the present spatio-temporal resolution of bio-optical variables to be progressively filled. - Chapter 3 identifies the optical and bio-optical properties that are now amenable to remote and autonomous measurement through the use of optical sensors mounted on floats. - Chapter 4 addresses the question of sensor requirements, in particular with respect to measurements performed from floats. - Chapter 5 proposes and argues for the development of dedicated float missions corresponding to specific scientific objectives and relying on specific optical sensor suites, as well as on specific modes of float operation. - Chapter 6 identifies technological issues {{that need to be addressed}} for the various bio-optical float missions to become even more cost-effective. - Chapter 7 covers all aspects of data treatment ranging from the development of various quality control procedures (from real-time to delayed mode) to the architecture required for favoring easy access to data. - Chapter 8 reviews the necessary steps and experience required before the operational implementation of different types of <b>float</b> <b>networks</b> can become a reality. JRC. H. 5 -Land Resources Managemen...|$|R
50|$|Other {{plans have}} been drafted and <b>floated</b> to <b>Network</b> Rail for {{reinstatement}} of track on the curves and direct services for Brentford Football Club's redevelopment of its Lionel Road stadium.|$|R
40|$|The {{establishment}} of the Argo <b>float</b> <b>network</b> few years ago represents an observational milestone in physical oceanography, while dissolved oxygen is the most widely measured chemical parameter of sea water with a historic background {{of more than a}} century. We present examples of their synthesis: The extension of the Argo core mission to regions above 60 ° N/S and the deployment of reliable oxygen sensors on floats to study seasonal and interannual biogeochemical processes. First measurements from the Norwegian Sea and the Weddell Sea are shown alongside the steps necessary to establish a sound oxygen data source...|$|R
25|$|Some time later, Pi's boat comes ashore on a <b>floating</b> island <b>network</b> {{of algae}} and {{inhabited}} {{by hundreds of}} thousands of meerkats. Soon, Pi and Richard Parker regain strength, but the boy's discovery of the carnivorous nature of the island's plant life forces him to return to the ocean.|$|R
50|$|World News Now {{was used}} as the {{prototype}} for Fred, ABC's plan to operate a cable news channel. The plan was <b>floated</b> by <b>network</b> management in 1995 and was later dropped within a couple of years due to issues with cable carriage, including competition with the recently launched MSNBC and Fox News Channel.|$|R
40|$|This work investigates multiagent path {{planning}} in strong, dynamic currents using thousands of highly underactuated vehicles. We address the specific task of {{path planning}} for a global <b>network</b> of ocean-observing <b>floats.</b> These submersibles are typified by the Argo global network consisting of over 3000 sensor platforms. They can control their buoyancy to float at depth for data collection or rise to the surface for satellite communications. Currently, floats drift at a constant depth regardless of the local currents. However, accurate current forecasts have become available which present the possibility of intentionally controlling floats' motion by dynamically commanding them to linger at different depths. This project explores {{the use of these}} current predictions to direct <b>float</b> <b>networks</b> to some desired final formation or position. It presents multiple algorithms for such path optimization and demonstrates their advantage over the standard approach of constant-depth drifting...|$|R
25|$|Burrell, {{along with}} fellow Food Network personalities Sunny Anderson and Claire Robinson, {{appeared}} in the 2009 Macy's Thanksgiving Day Parade on the Food <b>Network</b> <b>float.</b>|$|R
40|$|The Argo {{profiling}} <b>float</b> <b>network</b> {{has repeatedly}} sampled {{much of the}} World Ocean. This study uses Argo temperature and salinity data to form the tracer structure function of ocean variability at the macroscale (10 – 1000 km, mesoscale and above). Here, second-order temperature and salinity structure functions over horizontal separations are calculated along either pressure or potential density surfaces, which allows analysis of both active and passive tracer structure functions. Using Argo data, a map of global variance is created from the climatological average and each datum. When turbulence is homogeneous, the structure function slope from Argo {{can be related to}} the wavenumber spectrum slope in ocean temperature or salinity variability. This first application of structure function techniques to Argo data gives physically meaningful results based on bootstrapped confidence intervals, showing geographical dependence of the structure functions with slopes near ⅔ on average, independent of depth. United States. National Aeronautics and Space AdministrationNational Science Foundation (U. S.) (Grant 1023499...|$|R
40|$|Abstract—We {{describe}} and evaluate a new programming and communications framework that eases {{the creation of}} complex heterogeneous systems comprising robots and sensor networks. We use a light-weight RPC-based service framework that allows robots and static sensor nodes to be considered as services, accessible to an internet connected end-user, or to each other. We present experimental results for a very large environmental monitoring application comprising a <b>floating</b> sensor <b>network</b> and a robotic boat. I...|$|R
40|$|We {{describe}} {{the construction of}} large scale clusters for lattice QCD computing being developed {{under the umbrella of}} the U. S. DoE SciDAC initiative. We discuss the study of <b>floating</b> point and <b>network</b> performance that drove the design of the cluster, and present our plans for future multi-Terascale facilities...|$|R
50|$|The Sacramento-San Joaquin River Delta’s {{channel system}} {{supports}} California's agricultural industry and provides drinking water for 22 million Californians. The <b>Floating</b> Sensor <b>Network</b> {{project is a}} collaborative effort between the Center for Information Technology Research in the Interest of Society (CITRIS), Berkeley Lab and its National Energy Research Scientific Computing Center (NERSC), and UC Berkeley’s Departments of Civil and Environmental Engineering and Electrical Engineering. The project will collect data to help researchers and scientists better understand how water flows from the Delta to pumping stations and the San Francisco Bay.|$|R
50|$|Launch {{was founded}} in 2010 by NASA, Nike, USAID, and the US Department of State. The inaugural event, LAUNCH: Water, {{was held at the}} NASA Kennedy Space Station in March 2010 and {{highlighted}} innovations and research related to water sustainability. Some of the innovations included bacterial water sensing, a <b>floating</b> contaminant sensor <b>network,</b> and evaporation-based underground irrigation technology.|$|R
40|$|International audienceThe {{relative}} {{merits of}} the Tropical Atmosphere-Ocean (TAO) /Triangle Trans-Ocean Buoy Network (TAO/TRITON) and Pilot Research Moored Array in the Tropical Atlantic mooring networks, the Vol- untary Observing Ship (VOS) expendable bathythermograph (XBT) network, and the Argo <b>float</b> <b>network</b> are evaluated through their impact on ocean analyses and seasonal forecast skill. An ocean analysis is performed in which all available data are assimilated. In two additional experiments the moorings and the VOS datasets are withheld from the assimilation. To estimate the impact on seasonal forecast skill, the set of ocean analyses is then used to initialize a corresponding set of coupled ocean-atmosphere model fore- casts. A further set of experiments is conducted {{to assess the impact}} of the more recent Argo array. A key parameter for seasonal forecast initialization is the depth of the thermocline in the tropical Pacific. This depth is quite similar in all of the experiments that involve data assimilation, but withdrawing the TAO data has a bigger effect than withdrawing XBT data, especially in the eastern half of the basin. The forecasts mainly indicate that the TAO/TRITON in situ temperature observations are essential to obtain optimum forecast skill. They are best combined with XBT, however, because this results in better predictions for the west Pacific. Furthermore, the XBTs play an important role in the North Atlantic. The ocean data assimi- lation performs less well in the tropical Atlantic. This may be partly a result of not having adequate observations of salinity...|$|R
40|$|This paper {{describes}} a novel Autonomous Surface Vehicle capable of navigating throughout complex inland water storages and measuring {{a range of}} water quality properties and greenhouse gas emissions. The 16 ft long solar powered catamaran can collect this information throughout the water column whilst the vehicle is moving. A unique feature of this ASV is its integration into a storage scale <b>floating</b> sensor <b>network</b> to allow remote mission uploads, data download and adaptive sampling strategies. This paper {{provides an overview of}} the vehicle design and operation including control, laser-based obstacle avoidance, and vision-based inspection capabilities. Experimental results are shown illustrating its ability to continuously collect key water quality parameters and compliment intensive manual monitoring campaigns. ...|$|R
40|$|This article explores an {{ensemble}} strategy {{for evaluating the}} impact of different observing networks. The impact {{is represented by the}} relative ensemble spread increase, in model space, of data-denial ensemble simulations with respect to an ‘all-observation’ ensemble experiment, evaluated independently for each observing network. The forecast-error covariance intercomparison reduces to the ensemble spread intercomparison; thus, the method can be applied to any assimilation system and requires only the proper construction of {{an ensemble}} system, although the impact assessment results depend on the specific configuration of the investigated analysis system. Our approach allows us to determine the impact of the observing networks in model space (unlike Observing System Experiments) and for different forecast ranges of the ocean general circulation model. No tangent-linear and adjoint coding of the ocean model are required. The method is applied for demonstration to a large-scale global ocean variational analysis system. The ensemble members are generated by (i) perturbing the observations within the 3 D-Var assimilation scheme, (ii) perturbing the surface forcing, and (iii) stochastically perturbing the ocean model parametrisation tendencies. The impact is calculated for CTDs, XBTs, moorings, Argo, sea-level anomaly observations and sea-surface temperature measurements from space-borne microwave instruments within the three-year period from January 2003 to December 2005. It turns out, on the global scale, that altimetry exhibits the largest impact on near-surface temperature and sea-surface height. In contrast, deep-ocean impacts are led by the Argo <b>float</b> <b>network.</b> As expected, space-borne observations (sea-level anomaly and sea-surface temperature observations) increase their impact in the Southern Ocean, {{due to the lack of}} a robust network of in situ observations. The results of the impact on the salinity indicate the great importance of Argo floats, especially in the northern Extratropics...|$|R
40|$|The {{capacity}} of deep velocity estimates {{provided by the}} Argo <b>float</b> <b>network</b> to reconstruct both mean and eddying quantities, such as the heat flux, is addressed using an idealized eddy resolving numerical model, designed to {{be representative of the}} Southern Ocean. The model is seeded with 450 "virtual" Argo floats, which are then advected by the model fields for 10 years. The role of temporal sampling, network density and length of the float experiment are then systematically investigated by comparing the reconstructed velocity, eddy kinetic energy and heat-flux from the virtual Argo floats with the "true" values from the from the model output. We find that although errors in all three quantities decrease with increasing temporal sampling rate, number of floats and time span, the error approaches an asymptotic limit. Thus, as these parameters exceed this limit, only marginal reductions in the error are observed. The parameters of the real Argo network, when scaled to match those of the virtual Argo network, generally fall near to, or within, the asymptotic region. Using the numerical model, a method for the calculation of cross-stream heat-fluxes is demonstrated. This methodology is then applied to 5 years of Argo derived velocities using the ANDRO dataset of Ollitrault & Rannou (2013) in order to estimate the eddy heat flux at 1000 m depth across the Polar Front in the Southern Ocean. The heat-flux is concentrated in regions downstream of large bathymetric features, consistent with the results of previous studies. 2 ± 0. 5 TW of heat transport across the Polar Front at this depth is found, with more than 90 % of that total concentrated in less than 20 % of the total longitudes spanned by the front. Finally, the implications of this work for monitoring the ocean climate are discussed. Comment: Submitted to Ocean Modellin...|$|R
40|$|This paper {{describes}} the experimental {{evaluation of a}} novel Autonomous Surface Vehicle capable of navigating complex inland water reservoirs and measuring a range of water quality properties and greenhouse gas emissions. The 16 ft long solar powered catamaran is capable of collecting water column profiles whilst in motion. It is also directly integrated with a reservoir scale <b>floating</b> sensor <b>network</b> to allow remote mission uploads, data download and adaptive sampling strategies. This paper {{describes the}} onboard vehicle navigation and control algorithms as well as obstacle avoidance strategies. Experimental results are shown demonstrating its ability to maintain track and avoid obstacles {{on a variety of}} large-scale missions and under differing weather conditions, as well as its ability to continuously collect various water quality parameters complimenting traditional manual monitoring campaigns...|$|R
40|$|The Atlantic meridional {{overturning}} circulation {{represents the}} strongest mechanism for oceanic northward heat transport. This {{is accomplished by}} moving warm water northward in the upper ocean compensated by a deep return flow of cold and dense North Atlantic Deep Water (NADW). Labrador Sea Water (LSW) constitutes the shallowest component of NADW. Since LSW is also {{supposed to be the}} most sensitive NADW component to climate change it is of particular interest. LSW is formed by deep convection not only in the centre of the Labrador Sea but also near its western boundary. Recent studies have suggested that LSW formed in the boundary region enters its export route from the Labrador Sea, the Deep Western Boundary Current, faster than LSW originating from the central Labrador Sea. In this study the spatial and temporal evolution of the export of newly formed LSW is investigated. For this purpose hydrographic mooring data from an array located at the western bounndary at 53 °N starting in the late 1990 s until 2014 and data from the Argo <b>float</b> <b>network</b> is used. The averaged seasonal salinity cycle at the array, particularly at the moorings further onshore, shows a pronounced freshwater signal in May indicating the arrival of newly formed LSW in the boundary current. In order to learn more about its preceding pathway and the corresponding export timescale the mooring data is complemented by data from Argo floats. Besides the annual cycles of LSW formation and export, their interannual variations are important aspects affecting the large-scale circulation. For instance, in years of relatively strong convection, as in 2008 and 2012, LSW is observed to pass the boundary current array at 53 °N earlier, i. e. in February and March, respectively, than in years with weak convection, as in 2007 or 2010. Besides seasonal variations in the boundary current, a possible explanation for the earlier freshwater signal in years of enhanced convection might be a shift in convection sites southwards and/ or towards the boundary...|$|R
40|$|Atrial {{thrombosis}} is {{a relatively}} rare event in children. We report {{a case of a}} newborn with AFI who after restoration of sinus rhythm, developed atrial thrombus on a prominent Chiari <b>network</b> <b>floating</b> between the right and left atrium through the patent foramen ovale. The thrombus was resolved following treatment with heparin without events. Conclusion: Atrial stunning was proposed as a key mechanistic phenomenon because the thrombus occurred after the cardioversion of AFI to sinus rhythm. Heparin may be effective in the resolution of atrial thrombus within a few day...|$|R
40|$|Abstract—In-situ data {{collection}} for mobile {{wireless sensor network}} deployments has received little study, {{such as in the}} case of <b>floating</b> sensor <b>networks</b> for storm surge and innundation monitoring. We demonstrate through quantitative study that traditional approaches to routing in mobile environments do not work well due to volatile topology changes. Consequently, we propose Sidewinder, a predictive data forwarding protocol for mobile wireless sensor networks. Like a heat-seeking missile, data packets are guided towards a sink node with increasing accuracy as packets approach the sink. Different from conventional sensor network routing protocols, Sidewinder continuously predicts the current sink location based on distributed knowledge of sink mobility among nodes in a multi-hop routing process. Moreover, the continuous sink estimation is scaled and adjusted to perform with resource-constrained wireless sensors. Our design is implemented with nesC and evaluated in TOSSIM. The performance evaluation demonstrates that Sidewinder significantly outperforms state-of-the-art solutions in packet delivery ratio, time delay, and energy efficiency. I...|$|R
40|$|Mobile sensor {{networks}} present {{opportunities for}} improved in situ sensing in complex hydrodynamic environments such as estuarial deltas. This dissertation considers {{the design and}} implementation of the mobile sensor network system that was built as part of the <b>Floating</b> Sensor <b>Network</b> project for use in the Sacramento-San Joaquin Delta in California over the 2007 - 2012 time period. Individual Lagrangian sensor units collect hydrodynamic state information, which is then transmitted to a centralized server and assimilated to produce a state estimate for the entire hydrodynamic system. Physical obstacles, including the shoreline and natural vegetation, present a major challenge to operating mobile sensors in estuarial environments. Actuated mobile sensors are shown to be a viable solution; appropriate control techniques allow these sensors to avoid obstacles, meet navigational goals, and still collect the Lagrangian data necessary for the sensing objective. Issues addressed include physical design, communication techniques for mobile sensor networks, control schemes for fleets of underactuated vehicles in unstructured flow environments, assimilation techniques for mobile Lagrangian data, and field experiments to validate and demonstrate the actuated mobile Lagrangian sensor concept...|$|R
40|$|Wireless Sensor Networks (WSNs) are a {{pioneering}} technology in many environmental monitoring applications owing {{to their ability}} to be deployed {{for long periods of time}} in locations that cannot be reached manually. One such use-case is the monitoring of underwater sediment transport, a process that plays a significant role in coastal erosion. Previous examples of WSNs deployed for this purpose have been in the form of underwater sensor networks (UWSNs), which have a number of shortcomings from both a practical and technical viewpoint. As such, this paper provides a comparative assessment of UWSNs and an alternative deployment approach of <b>floating</b> echosounding sensor <b>networks</b> for the purpose of monitoring underwater sediment transport...|$|R
50|$|Open Your Mouth for the Speechless...In Case of Those Appointed to Die is {{the debut}} album from Philadelphia band A Life Once Lost. The 2004 reissue of this album, {{originally}} released in 2000 {{in a limited}} edition, features an improved remix and remastering, all-new artwork, and a trio of bonus tracks, two early demos of songs from this album's follow-up and a more recent live recording. This album is noticeably heavier than ALOL's newer recordings. There is a demo recording <b>floating</b> around P2P <b>networks</b> and the internet of the track Falls River Farewell. It includes backing vocals from Anthony Green and is 5:31 in length, {{as compared to the}} A Falls River Farewell album version.|$|R
40|$|The {{interest}} in the exploitation of wireless sensor networks in dissipative media (other than the free space) is nowadays growing in importance, thanks to the identification of ever newer fields of applications. This paper introduces an efficient design methodology for an easy definition {{of the characteristics of}} mobile sensors inserted in pipes filled with fluids. The proposed procedure takes into account all the physical parameters of the systems such as: the performance range of the acoustic transducer, the acoustic and electromagnetic coupling mechanism among different media, and the electromagnetic interaction within the sensor and among the electronic and metallic components. Results obtained for the design of mobile sensor <b>networks</b> <b>floating</b> in underground water conduits confirm the adequacy of the proposed metho...|$|R
40|$|This paper {{describes}} {{the consequences of}} a fault in a medium voltage network on the grounding systems at the LV-side. To study the current distribution and to verify the models, we deliberately introduced one phase to ground faults in the 10 kV <b>floating</b> MV <b>network.</b> The selected site was the end of a 2 km long buried MV cable feeding a small group of houses; the soil there had a high resistivity. The fault current was 127 A. The current distribution and the relevant voltages were measured at several positions in MV and LV net. We compare the results for a TT and a quasi-TN earthing system in the houses, also taking the telecom cable into account. The distribution of the fault current over the MV cable, measured at another MV station at 2. 2 km distance, are in agreement with calculations, based on a model which includes the contact of the lead shield of the MV cable with the ground. Current and voltage data are compared with calculations. Eindhoven University of Technology and the Dutch power distribution company NUON, carry out a joint research project on global earthing. In this project we treat different faults and various interference sources e. g. lightning and switching events togethe...|$|R
40|$|Online Social Networks explode with {{activity}} whenever a crisis event takes place. Most content generated {{as part of}} this activity is a mixture of text and images, and is particularly useful for first responders to identify popular topics of interest and gauge the pulse and sentiment of citizens. While multiple researchers have used text to identify, analyze and measure themes and public sentiment during such events, little work has explored visual themes <b>floating</b> on <b>networks</b> in the form of images, and the sentiment inspired by them. Given the potential of visual content for influencing users' thoughts and emotions, we perform a large scale analysis to compare popular themes and sentiment across images and textual content posted on Facebook during the terror attacks that took place in Paris in 2015. Using state-of-the-art image summarization techniques, we discovered multiple visual themes which were popular in images, but were not identifiable through text. We uncovered instances of misinformation and false flag (conspiracy) theories among popular image themes, which were not prominent in user generated textual content, and can be of particular inter- est to first responders. Our analysis also revealed that while textual content posted after the attacks reflected negative sentiment, images inspired positive sentiment. To the best of our knowledge, this is the first large scale study of images posted on social networks during a crisis event. Comment: 8 + 1 page...|$|R
40|$|Advances in {{healthcare}} IT bring new concerns {{with respect to}} privacy and security. Security critical patient data no longer resides on mainframes physically isolated within an organization, where physical security measures {{can be taken to}} defend the data and the system. Modern solutions are heading towards open, interconnected environments where storage outsourcing and operations on untrusted servers happen frequently. In order to allow secure sharing of health records between different healthcare providers, Rights Management Techniques facilitating a datacentric protection model can be employed: data is cryptographically protected and allowed to be outsourced or even freely <b>float</b> on the <b>network.</b> Rather than relying on different networks to provide confidentiality, integrity and authenticity, data is protected at the end points of the communication. In this paper we compare Enterprise/Digital Rights Management with traditional security techniques and discuss how Rights Management can be applied to secure Electronic Health Records...|$|R
40|$|Using analog, {{non-linear}} {{and highly}} parallel networks, {{we attempt to}} perform decoding of block and convolutional codes, equalization of certain frequency-selective channels, decoding of multi-level coded modulation and reconstruction of coded PCM signals. This {{is in contrast to}} common practice where these tasks are performed by sequentially operating processors. Our advantage is that we operate fully on soft values for input and output, similar to what is done in `turbo' decoding. However, we do not have explicit iterations because the <b>networks</b> <b>float</b> freely in continuous time. The decoder has almost no latency in time because we are only restricted by the time constants from the parasitic RC values of integrated circuits. Simulation results for several simple examples are shown which, in some cases, achieve the performance of a conventional MAP detector. For more complicated codes we indicate promising solutions with more complex analog networks based on the simple ones. Furthermore, [...] ...|$|R
40|$|A crucial {{issue for}} a mobile ad hoc network is the {{handling}} {{of a large number}} of nodes. As more nodes join the mobile ad hoc network, contention and congestion are more likely. The on demand routing protocols which broadcasts control packets to discover routes to the destination nodes, generate a high number of broadcast packets in a larger networks causing contention and collision. We propose an efficient route discovery protocol, which reduces the number of broadcast packet, using controlled flooding technique. The simulation results show that the proposed probabilistic flooding decreases the number of control packets <b>floating</b> in the <b>network</b> during route discovery phase, without lowering the success ratio of path discoveries. Furthermore, the proposed method adapts to the normal network conditions. The results show that up to 70 % of control packet traffic is saved in route discovery phase when the network is denser. Comment: Probabilistic Route Discover Algorithm for DENSE MANET...|$|R
40|$|Turbulence is {{inherently}} chaotic and unsteady, so observing it and modeling it {{are no easy}} tasks. The ocean 2 ̆ 7 s sheer size {{makes it even more}} difficult to observe, and its unpredictable and ever-changing forcings introduce additional complexities. Turbulence in the oceans ranges from basin scale to the scale of the molecular viscosity. The method of energy transfer between scales is, however, an area of active research, so observations of the ocean at all scales are crucial to understanding the basic dynamics of its motions. In this collection of work, I use a variety of datasets to characterize a wide range of scales of turbulence, including observations from multiple instruments and from models with different governing equations. I analyzed the largest scales of the turbulent range using the global salinity data of the Argo profiling <b>float</b> <b>network.</b> Taking advantage of the scattered and discontinuous nature of this dataset, the second-order structure function was calculated down to 2000 m depth, and shown to be useful for predicting spectral slopes. Results showed structure function slopes of 2 / 3 at small scales, and 0 at large scales, which corresponds with spectral slopes of - 5 / 3 at small scales, and - 1 at large scales. Using acoustic Doppler velocity measurements, I characterized the meter- to kilometer-scale turbulence at a potential tidal energy site in the Puget Sound, WA. Acoustic Doppler current profiler (ADCP) and acoustic Doppler velocimeter (ADV) observations provided the data for an analysis that includes coherence, anisotropy, and intermittency. In order to more simply describe these features, a parameterization was done with four turbulence metrics, and the anisotropy magnitude, introduced here, was shown to most closely capture the coherent events. Then, using both the NREL TurbSim stochastic turbulence generator and the NCAR large-eddy simulation (LES) model, I calculated turbulence statistics to validate the accuracy of these methods in reproducing the tidal channel. TurbSim models statistics at the height of a turbine hub (5 m) well, but do not model coherent events, while the LES does create these events, but not realistically in this configuration, based on comparisons with observations. Each of the datasets have disadvantages when it comes to observing turbulence. The Argo network is sparse in space, and few measurements are taken simultaneously in time. Therefore spatial and temporal averaging is needed, which requires the turbulence to be homogeneous and stationary {{if it is to be}} generalized. Though the acoustic Doppler current profiler provides a vertical profile of velocities, the fluctuations are dominated by instrument noise and beam spread, preventing it from being used for most turbulence metrics. ADV measurements have much less noise, and no beam spread, but the observations are made at one point in space, limiting us to temporal statistics or an assumption of 2 ̆ 2 frozen turbulence 2 ̆ 2 to infer spatial scales. As for the models, TurbSim does not have any real-world forcing, and uses parameterized spectra, and coherence functions and randomizes phase information, while LES models must make assumptions about sub-grid scales, which may be inaccurate. Additionally, all models are set up with idealizations of the forcing and domain, which may make the results unlike observations in a particular location and time. Despite these difficulties in observing and characterizing turbulence, I present several quantities that use the imperfect, yet still valuable observations, to attain a better description of the turbulence in the oceans...|$|R
30|$|Gossiping [4] is an {{alternative}} to the classic flooding approach that uses randomization to conserve energy. Instead of indiscriminately forwarding data to all its neighbours, a gossiping node only forwards data on to one randomly selected neighbour. If a gossiping node receives data from a given neighbour, it can forward data back to that neighbour if it randomly selects that neighbour. Whenever data travel to a node with high degree in a classic flooding network, more copies of the data start <b>floating</b> around the <b>network.</b> At some point, however, these copies may end up imploding. Gossiping avoids such implosion because it only makes one copy of each message at any node. The fewer copies it made, the lower the likelihood that any of these copies will ever implode. Although gossiping largely avoids implosion, it does not solve the overlap problem as a gossiping node receives data from a given neighbour, it can forward data back to that neighbour if it randomly selects that neighbour. In addition, the gossiping approach does not solve the sink mobility problem.|$|R
40|$|We {{present a}} {{synthesis}} framework to map logic networks into quantum circuits for quantum computing. The synthesis framework {{is based on}} LUT networks (lookup-table networks), which {{play a key role}} in conventional logic synthesis. Establishing a connection between LUTs in a LUT network and reversible single-target gates in a reversible network allows us to bridge conventional logic synthesis with logic synthesis for quantum computing, despite several fundamental differences. We call our synthesis framework LUT-based Hierarchical Reversible Logic Synthesis (LHRS). Input to LHRS is a classical logic network; output is a quantum network (realized in terms of Clifford+$T$ gates). The framework offers to trade-off the number of qubits for the number of quantum gates. In a first step, an initial network is derived that only consists of single-target gates and already completely determines the number of qubits in the final quantum network. Different methods are then used to map each single-target gate into Clifford+$T$ gates, while aiming at optimally using available resources. We demonstrate the effectiveness of our method in automatically synthesizing IEEE compliant <b>floating</b> point <b>networks</b> up to double precision. As many quantum algorithms target scientific simulation applications, they can make rich use of floating point arithmetic components. But due to the lack of quantum circuit descriptions for those components, it can be difficult to find a realistic cost estimation for the algorithms. Our synthesized benchmarks provide cost estimates that allow quantum algorithm designers to provide the first complete cost estimates for a host of quantum algorithms. Thus, the benchmarks and, more generally, the LHRS framework are an essential step towards the goal of understanding which quantum algorithms will be practical in the first generations of quantum computers. Comment: 15 pages, 10 figure...|$|R
40|$|Online social {{networks}} {{have become a}} favorite platform for marketers and advertisers. Due to the wide reach of these networks and low cost of advertisement, {{there has been an}} upsurge of marketing and advertising campaigns on social media. Social networks like facebook, twitter and google+ possess the capability to quickly turn any piece of information viral, thus increasing its impact. However, there do not exist many tools which can tell whether an information circulating on social media is genuine or fraudulent. We confine ourselves to a specific section of marketing campaigns in this work, which is – “Work from home ” campaigns. “Work from home ” schemes are run with the intention of providing users an attractive option of working from home in return of some remuneration. Unfortunately, many of such “work-from-home ” ads <b>floating</b> on social <b>network</b> are actually scams which mislead and cheat on the end user in more than one way. In this work, we present a study of online money making campaigns run on a popular social network – Google+, and propose an approach to distinguish genuine campaigns from scams...|$|R
