5|6809|Public
40|$|Abstract − In wind tunnels, {{aerospace}} vehicle {{models are}} tested {{in order to}} analyze their performance in real flight situations. The forces and moments exerted by the airflow {{on the surface of}} the test article are measured using multicomponent balances. The balance measures the aerodynamic loads by using strain-gages. It is calibrated prior to the tests, resulting in the estimation of the parameters of the polynomial mathematical modelling relating the strain-gage readings to the aerodynamic loads. This paper presents the aerodynamic load values acting on a sounding rocket vehicle under test in a transonic aerodynamic facility. The force and moment coefficients and corresponding uncertainties are also estimated. The vehicle was tested in low Mach number conditions, with the airflow being supplied by the injection system. The second stage of the model was fitted with three different fin deflections. The measured quantities are total pressure, static pressure and total temperature of the flow, as well as the strain gage readings supplied by an internal balance. An analysis of the contribution for the uncertainties in the aerodynamic loads revealed that the measurement precision is the dominant component. The <b>intermediate</b> <b>measurement</b> <b>precision</b> of the tests was also considered...|$|E
40|$|International audienceAlthough initial {{studies have}} {{demonstrated}} the applicability of Ni isotopes for cosmochemistry and as a potential biosignature, the Ni isotope composition of terrestrial igneous and sedimentary rocks, and ore deposits remains poorly known. Our contribution is fourfold: (a) to detail an analytical procedure for Ni isotope determination, (b) to determine the Ni isotope composition of various geological reference materials, (c) to assess the isotope composition of the Bulk Silicate Earth relative to the Ni isotope reference material NIST SRM 986 and (d) to report the range of mass-dependent Ni isotope fractionations in magmatic rocks and ore deposits. After purification through a two-stage chromatography procedure, Ni isotope ratios were measured by MC-ICP-MS and were corrected for instrumental mass bias using a double-spike correction method. Measurement precision (two standard error of the mean) was between 0. 02 and 0. 04 ‰, and <b>intermediate</b> <b>measurement</b> <b>precision</b> for NIST SRM 986 was 0. 05 ‰ (2 s). Igneous- and mantle-derived rocks displayed a restricted range of δ 60 / 58 Ni values between − 0. 13 and + 0. 16 ‰, suggesting an average BSE composition of + 0. 05 ‰. Manganese nodules (Nod A 1; P 1), shale (SDO- 1), coal (CLB- 1) and a metal-contaminated soil (NIST SRM 2711) showed positive values ranging between + 0. 14 and + 1. 06 ‰, whereas komatiite-hosted Ni-rich sulfides varied from − 0. 10 to − 1. 03 ‰...|$|E
40|$|The {{analysis}} of counting and catching errors of both catching and non-catching types of rain intensity (RI) gauges {{was possible for}} the first time over a wide variety of measuring principles and instrument design solutions based on the recent Field Intercomparison of Rainfall Intensity Gauges promoted by WMO, the World Meteorological Organisation. This paper investigates the frequency distribution of the observed deviations of one-minute RI measurements from the assumed reference value (a weighted average of four selected pit gauges) obtained in real world conditions during the measurement campaign in the field. The presented non-parametric {{analysis of}} these deviations confirms that the accuracy of the investigated RI gauges is generally high and contained within the limits established by WMO. Exceptions are the majority of non-catching gauges, especially the optical and acoustic disdrometers, which show significant biases. The <b>intermediate</b> <b>measurement</b> <b>precision</b> was also investigated revealing that the frequency distribution of deviations around their mean value is not indicative of an underlying Gaussian population, being much more peaked in most cases than what can be expected from samples extracted from a Gaussian distribution and indicative of a better precision. Non-catching gauges showed a markedly different behaviour. The analysis of variance (one-way ANOVA), assuming the instrument model as the only potentially affecting factor, does not confirm the hypothesis of a single common underlying distribution for all instruments. Pair-wise multiple comparisons revealed that this hypothesis is generally acceptable for two paired instruments. The cases where significant differences are observed could be easily identified...|$|E
40|$|To {{improve the}} <b>measurement</b> <b>precision</b> of the {{structured}} light target angle, this paper studies {{the relation between}} the structured light system parameters and measurement accuracy of the angle. Firstly, the main system structure parameters influencing the angle <b>measurement</b> <b>precision</b> are analyzed based on the structured light measurement principle; secondly, simulation research on the laws of how the structured parameters influence the angle <b>measurement</b> <b>precision</b> are conducted, and the optimized range of values of the structured parameters is proposed; finally, the experimental studies show that, the optimized parameters can improve the angle <b>measurement</b> <b>precision</b> effectively, which lays the design foundation for later improvement schemes of the structured light 3 D four-wheel alignment instrument...|$|R
5000|$|Minimum {{and maximum}} {{expected}} values and <b>measurement</b> <b>precision</b> (...) ...|$|R
40|$|There {{are many}} factors to {{influence}} <b>measurement</b> <b>precision</b> of nuclear instrumentation, which include radioactive statistical fluctuation, signal processing method, use environment and so on. Aiming at these factors, this article adopts some concrete methods to enhance <b>measurement</b> <b>precision</b> {{and makes the}} isotope level meter (instrumentation) achieve better effects through the designs of hardware and software...|$|R
40|$|Airborne respirable {{crystalline}} silica (RCS) is a hazard {{that can affect}} the health of workers and more sensitive measurements are needed {{for the assessment of}} worker exposure. To investigate the use of Raman microscopy for the analysis of RCS particulate collected on filters, aliquots of quartz or cristobalite suspended in isopropanol were pipetted onto silver filters. Samples were measured by arbitrarily selecting positions along the filter and collecting spectra at 50 discrete points. The calculated limits of quantification on test samples were between ~ 0. 066 – 0. 161 µg and 0. 106 – 0. 218 µg for quartz and cristobalite respectively. Three respirable quartz calibration dusts (A 9950, NIST 1878 and Quin B) with different mass median aerodynamic particle sizes obtained similar Raman response relationships per unit mass. The difference between NIST 1878 and Quin B was not significant (p= 0. 22). The <b>intermediate</b> <b>measurement</b> <b>precision</b> of replicate samples was 10 - 25 % over the measured range for quartz (0. 25 – 10 µg) and could potentially be improved. Results from mixtures of quartz and cristobalite were within 10 % of their theoretical values. Results from samples of 5 % quartz in calcite were close to the theoretical quartz mass. The upper measurement limit for a mixture of 20 % RCS in the light absorbing mineral hematite (Fe 2 O 3) was 5 µg. These data show that Raman spectroscopy is a viable option for the quantification of the mass of respirable {{crystalline silica}} on filters with a limit of detection approaching 1 / 10 th of that obtained with other techniques. The improvement in sensitivity may enable the measurement of particulate in samples from low concentration environments (e. g. inside a mask) or from miniature samplers operating at low flow rates...|$|E
40|$|The {{continuous}} in situ {{measurement of}} δ 18 O in atmospheric CO 2 opens a new door to differentiating between CO 2 source and sink components with high temporal resolution. Continuous 13 C–CO 2 measurement systems have already been commercially available for some time, but until now, only few instruments {{have been able to}} provide a continuous measurement of the oxygen isotope ratio in CO 2. Besides precise 13 C/ 12 C observations, the Fourier transform infrared (FTIR) spectrometer is also able to measure the 18 O / 16 O ratio in CO 2, but the precision and accuracy of the measurements have not yet been evaluated. Here we present a first analysis of δ 18 O-CO 2 (and δ 13 C-CO 2) measurements with the FTIR analyser in Heidelberg. We used Allan deviation to determine the repeatability of δ 18 O-CO 2 measurements and found that it decreases from 0. 25 ‰ for 10 min averages to about 0. 1 ‰ after 2 h and remains at that value up to 24 h. We evaluated the measurement precision over a 10 -month period (<b>intermediate</b> <b>measurement</b> <b>precision)</b> using daily working gas measurements and found that our spectrometer measured δ 18 O-CO 2 to better than 0. 3 ‰ at a temporal resolution of less than 10 min. The compatibility of our FTIR-spectrometric measurements to isotope-ratio mass-spectrometric (IRMS) measurements was determined by comparing FTIR measurements of cylinder gases and ambient air with IRMS measurements of flask samples, filled with gases of the same cylinders or collected from the same ambient air intake. Two-sample t tests revealed that, at the 0. 01 significance level, the FTIR and the IRMS measurements do not differ significantly from each other and are thus compatible. We describe two weekly episodes of ambient air measurements, one in winter and one in summer, and discuss what potential insights and new challenges combined highly resolved CO 2, δ 13 C-CO 2 and δ 18 O-CO 2 records may provide in terms of better understanding regional scale continental carbon exchange processes...|$|E
40|$|We {{introduce}} {{a new class of}} quantum many-particle entangled states, called the Dicke squeezed (or DS) states, which can be used to improve the precision in quantum metrology beyond the standard quantum limit. We show that the enhancement in <b>measurement</b> <b>precision</b> is characterized by a single experimentally detectable parameter, called the Dicke squeezing ξ_D, which also bounds the entanglement depth for this class of states. The <b>measurement</b> <b>precision</b> approaches the ultimate Heisenberg limit as ξ_D attains the minimum in an ideal Dicke state. Compared with other entangled states, we show that the Dicke squeezed states are more robust to decoherence and give better <b>measurement</b> <b>precision</b> under typical experimental noise...|$|R
5000|$|The angle <b>measurement</b> <b>precision</b> and {{accuracy}} {{is limited to}} slightly better than one arcsec.|$|R
40|$|The {{presence}} of loss limits {{the precision of}} an approach to phase measurement using maximally entangled states, {{also referred to as}} NOON states. A calculation using a simple beam-splitter model of loss shows that, for all nonzero values L of the loss, phase <b>measurement</b> <b>precision</b> degrades with increasing number N of entangled photons for N sufficiently large. For L above a critical value of approximately 0. 785, phase <b>measurement</b> <b>precision</b> degrades with increasing N for all values of N. For L near zero, phase <b>measurement</b> <b>precision</b> improves with increasing N down to a limiting precision of approximately 1. 018 L radians, attained at N approximately equal to 2. 218 /L, and degrades as N increases beyond this value. Phase <b>measurement</b> <b>precision</b> with multiple <b>measurements</b> and a fixed total number of photons N_T is also examined. For L above a critical value of approximately 0. 586, the ratio of phase <b>measurement</b> <b>precision</b> attainable with NOON states to that attainable by conventional methods using unentangled coherent states degrades with increasing N, the number of entangled photons employed in a single measurement, for all values of N. For L near zero this ratio is optimized by using approximately N= 1. 279 /L entangled photons in each <b>measurement,</b> yielding a <b>precision</b> of approximately 1. 340 sqrt(L/N_T) radians. Comment: Additional references include...|$|R
40|$|By {{exploiting}} the correlation properties of ultracold atoms in a multi-mode interferometer, we show how quantum enhanced <b>measurement</b> <b>precision</b> {{can be achieved}} with strong robustness to particle loss. While the potential for enhanced <b>measurement</b> <b>precision</b> is limited for even moderate loss in two-mode schemes, multi-mode schemes can be more robust. A ring interferometer for sensing rotational motion with non-interacting fermionic atoms can realize an uncertainty scaling of 1 /(N√(η)) for N particles with a fraction η remaining after loss, which undercuts the shot noise limit of two mode interferometers. A second scheme with strongly-interacting bosons achieves a comparable <b>measurement</b> <b>precision</b> and improved readout. Comment: 5 pages, 2 figures, replaced by final versio...|$|R
40|$|The {{presence}} of loss limits {{the precision of}} an approach to phase measurement using NOON states. A calculation using a simple beam-splitter model of loss shows that, for all nonzero values L of the loss, phase <b>measurement</b> <b>precision</b> degrades with increasing number N of entangled photons for N sufficiently large. For L above a critical value of approximately 0. 785, phase <b>measurement</b> <b>precision</b> degrades with increasing N for all values of N. For L near zero, phase <b>measurement</b> <b>precision</b> improves with increasing N down to a limiting precision of approximately 1. 018 L radians, attained at N approximately equal to 2. 218 /L, and degrades as N increases beyond this value. Phase <b>measurement</b> <b>precision</b> with multiple <b>measurements</b> and a fixed total number of photons NT is optimized, for L near zero, by using approximately 1. 279 /L entangled photons in each <b>measurement,</b> yielding a <b>precision</b> of approximately 1. 340 √ L/NT radians. 1 NOON States and the Heisenberg Limit The use of NOON states has been proposed {{as a means of}} performing phase <b>measurements</b> with a <b>precision</b> δφmin at the Heisenberg limit. In this limit, δφmin scales as δφmin ∼ 1 /N, (1) This work was sponsored by the Air Force under Air Force Contract FA 8721 - 05 -C- 0002. Opinions, interpretations, conclusions, and recommendations {{are those of the authors}} and are not necessarily endorsed by the U. S. Government. 1 with increasing photon number N, rather than at the standard quantum limit This fact can be seen as follows: NOON states are entangled states of the for...|$|R
40|$|For many applications, {{the precise}} {{knowledge}} of the beta function at a given location is essential. Several measurement techniques for optics functions {{are used in the}} LHC to provide the most suitable method for a given scenario. A new tool to run k-modulation measurements and analysis is being developed with the aim to be fully automatic and online. It will take constraints of various systems such as tune <b>measurement</b> <b>precision,</b> powering limits of the LHC superconducting circuits and limits of their quench protection systems into account. It will also provide the possibility to sinusoidally modulate the currents of the investigated quadrupoles with a predefined frequency and amplitude to increase the <b>measurement</b> <b>precision</b> further. This paper will review the advantages and limitations of k-modulation measurements in the LHC with and without sinusoidal current modulation. The used algorithms and tools will be presented and estimates on the obtainable beta function <b>measurement</b> <b>precision</b> will be given...|$|R
40|$|The {{present report}} {{analysed}} the variance between instruments and estimated the <b>measurement</b> <b>precision</b> of the Wool ComfortMeter instrument by conducting an international round trial. The firstinternational round trial {{was conducted in}} 2014; however the calculated precision estimates were relatively large. In the present trial, instruments were standardised by harmonising parameters such as wire height and measuring length, and a new calibration method was used to improve the <b>measurement</b> <b>precision.</b> The data from five laboratories, measuring ten fabric-samples and 5 sub-samples per fabric sample, was used to estimate the components of variance and the prickle <b>measurement</b> <b>precision.</b> The results showed good agreement between laboratory measurements. Analysis of the data shows an improvement in the 95 % confidence limit for this round trial compared to the first round trial. Particularly, relatively smaller confidence limits were found for low prickle measurements. It is recommended that the new precision estimates {{be incorporated into the}} IWTO DTM- 66 : 2014...|$|R
40|$|In this paper, we derive the Jarzynski {{equality}} (JE) for {{an isolated}} quantum system {{in three different}} cases: (i) the full evolution is unitary with no <b>intermediate</b> <b>measurements,</b> (ii) with <b>intermediate</b> <b>measurements</b> of arbitrary observables being performed, and (iii) with <b>intermediate</b> <b>measurements</b> whose outcomes are used to modify the external protocol (feedback). We assume that the measurements will involve errors that are purely classical in nature. Our treatment is based on path probability in state space for each realization. This {{is in contrast to}} the formal approach based on projection operator and density matrices. We find that the JE remains unaffected in the second case, but gets modified in the third case where the mutual information between the measured values with the actual eigenvalues must be incorporated into the relation. Comment: 7 page...|$|R
40|$|Photonic spin Hall effect (SHE) holds great {{potential}} applications in precision metrology. How {{to obtain a}} high <b>measurement</b> <b>precision</b> {{is an important issue}} to detect the photonic SHE. In this letter, we propose using optimal preselection and postselection in weak measurements to enhance the <b>measurement</b> <b>precision.</b> We find that the maximum weak value and pointer shift can be obtained with an optimal overlap of preselection and postselection states. These findings offer the possibility for improving the <b>precision</b> of weak <b>measurements</b> and thereby have possible applications for accurately characterizing the parameters of nanostructures. Comment: 4 pages, 4 figure...|$|R
40|$|An {{increased}} use of forest fuels resulted in a new Timber Measurement Act, specifying the requirements for measurements of these assortments. The law has increased the demands when measuring quality parameters, e. g. moisture and ash content. This thesis aims to a) develop a robust validation method for <b>measurement</b> <b>precision</b> and accuracy; b) validate instruments using electric capacitance (CAP), magnetic resonance (MR), near infrared spectroscopy (NIR), and X-ray technologies for moisture content determination; and c) evaluate the possibility to determine other parameters using x-ray data. The tested instruments had similar <b>measurement</b> <b>precision.</b> All except for the CAP produced 95...|$|R
40|$|In {{attempt to}} improve the <b>measurement</b> <b>precision</b> by a multiple-choice test, two IRT multi-category models were applied to an English test and {{compared}} to a binary model. The multi-category models were graded response model and nominal response model. Each item of the test consisted of 5 alternatives, which were classified according to their correctness into 3 categories : "correct, " "nearly correct, " and "far from correct. " It {{was found that the}} two multi-category models showed the almost equal effect on improving the <b>measurement</b> <b>precision</b> compared to 2 -parameter logistic model. The improvement was most remarkable for subjects with low ability...|$|R
40|$|The {{objective}} {{of the study is}} to investigate the measurement accuracy of latent variables depending on a number of dichotomous test items and variation range. Methods: Investigation is based on the simulation experiments. Results: The authors make recommendations for selecting a number of dichotomous test items and variation range depending on the required <b>measurement</b> <b>precision</b> of latent variables. Scientific novelty: The research demonstrates statistical correlation between the <b>measurement</b> <b>precision</b> of latent variables and a number of test items and variation range. Importance for practice: The research results can be used while developing the questionnaires and tests for measuring the latent variables. </p...|$|R
50|$|Dilution of {{precision}} (DOP), or geometric dilution {{of precision}} (GDOP), {{is a term}} used in satellite navigation and geomatics engineering to specify the additional multiplicative effect of navigation satellite geometry on positional <b>measurement</b> <b>precision.</b>|$|R
40|$|If {{a quantum}} system is {{prepared}} and later post-selected in certain states, "paradoxical" predictions for <b>intermediate</b> <b>measurements</b> can be obtained. This {{is the case}} both when the <b>intermediate</b> <b>measurement</b> is strong, i. e. a projective measurement with Luders-von Neumann update rule, or with weak measurements where they show up in anomalous weak values. Leifer and Spekkens [quant-ph/ 0412178] identified a striking class of such paradoxes, known as logical pre- and post-selection paradoxes, and showed that they are indirectly connected with contextuality. By analysing the measurement-disturbance required in models of these phenomena, {{we find that the}} strong measurement version of logical pre- and post-selection paradoxes actually constitute a direct manifestation of quantum contextuality. The proof hinges on under-appreciated features of the paradoxes. In particular, we show by example that {{it is not possible to}} prove contextuality without Luders-von Neumann updates for the <b>intermediate</b> <b>measurements,</b> nonorthogonal pre- and post-selection, and 0 / 1 probabilities for the <b>intermediate</b> <b>measurements.</b> Since one of us has recently shown that anomalous weak values are also a direct manifestation of contextuality [arXiv: 1409. 1535], we now know that this is true for both realizations of logical pre- and post-selection paradoxes. Comment: In Proceedings QPL 2015, arXiv: 1511. 0118...|$|R
40|$|Managing test specifications—both {{multiple}} nonstatistical {{constraints and}} flexibly defined constraints—has {{become an important}} part of designing item selection pro-cedures for computerized adaptive tests (CATs) in achievement testing. This study compared the effectiveness of three procedures: constrained CAT, flexible modified constrained CAT, and the weighted penalty model in balancing multiple flexible con-straints and maximizing <b>measurement</b> <b>precision</b> in a fixed-length CAT. The study also addressed the effect of two different test lengths— 25 items and 50 items—and of including or excluding the randomesque item exposure control procedure with the three methods, all of which were found effective in selecting items that met flexible test constraints when used in the item selection process for longer tests. When the randomesque method was included to control for item exposure, the weighted pen-alty model and the flexible modified constrained CAT models performed better than did the constrained CAT procedure in maintaining <b>measurement</b> <b>precision.</b> When no item exposure control method was used in the item selection process, no practical difference was found in the <b>measurement</b> <b>precision</b> of each balancing method...|$|R
40|$|In this {{dissertation}} {{we focused}} on some quantum states with strong entanglement and robustness to noise. We constructed a spinor BEC Hamiltonian which has already been realized in experiment with several different kinds of atoms and proposed an adiabatic passage method to produce the maximal entangled Dicke state. We also analyzed the entanglement behavior of the Dicke state under various noises and demonstrate its use in high <b>precision</b> <b>measurement</b> experiment. We introduce {{a new class of}} quantum many-particle entangled states, called the Dicke squeezed (or DS) states, which can be used to improve the precision in quantum metrology beyond the standard quantum limit. We show that the enhancement in <b>measurement</b> <b>precision</b> is characterized by a single experimentally detectable parameter, called the Dicke squeezing, which also bounds the entanglement depth for this class of states. The <b>measurement</b> <b>precision</b> approaches the ultimate Heisenberg limit as the Dicke squeezing parameter attains the minimum in an ideal Dicke state. Compared with other entangled states, we show that the Dicke squeezed states are more robust to decoherence and give better <b>measurement</b> <b>precision</b> under typical experimental noise. On the other hand, we explore other choices of <b>precision</b> <b>measurement</b> with spin squeezed states. Spin squeezed states have strong manybody entanglement and are good candidates to be used in quantum metrology. A robust squeezing parameter is proposed to characterize the experimental phase <b>measurement</b> <b>precision</b> for spin squeezed states. The behavior of this parameter under various experimental noises is compared with other parameters in the history and it is shown to have better performance. Finally we present a scalable implementation scheme for Boson sampling using local transverse phonon modes in trapped ion system, which is a promising model for quantum computers...|$|R
40|$|Motivation: <b>Measurement</b> <b>precision</b> {{determines the}} power of any {{analysis}} to reliably identify significant signals, such as in screens for differential expression, independent of whether the experimental design incorporates replicates or not. With the compilation of large-scale RNA-Seq datasets with technical replicate samples, however, we can now, for the first time, perform a systematic analysis of the precision of expression level estimates from massively parallel sequencing technology. This then allows considerations for its improvement by computational or experimental means. Results: We report on a comprehensive study of target identification and <b>measurement</b> <b>precision,</b> including their dependence on transcript expression levels, read depth and other parameters. In particular, an impressive recall of 84...|$|R
40|$|International audienceWe {{compare the}} <b>measurement</b> <b>precision</b> of a polarimetric camera {{to that of}} a simple {{intensity}} camera when imaging a partially polarized light-mark embedded in an intense and partially polarized background. We show that the gain in <b>measurement</b> <b>precision</b> while using a polarimetric camera is maximized when the noise fluctuations on the two polarimetric channels are significantly correlated. Further, we implement a snapshot polarimetric camera for long distance imaging of a highly polarized light source through fog and compare the contrast obtained using various representations of the polarimetric images. We show that the representation that provides the best contrast depends on the visibility conditions and matches well with theoretical predictions...|$|R
40|$|We {{study the}} best {{attainable}} <b>measurement</b> <b>precision</b> when a double-well trap with bosons inside {{acts as an}} interferometer to measure the energy difference of the atoms on {{the two sides of}} the trap. We introduce time independent perturbation theory as the main tool in both analytical arguments and numerical computations. Nonlinearity from atom-atom interactions will not indirectly allow the interferometer to beat the Heisenberg limit, but in many regimes of the operation the Heisenberg limit scaling of <b>measurement</b> <b>precision</b> is preserved in spite of added tunneling of the atoms and atom-atom interactions, often even with the optimal prefactor. Comment: very close to published versio...|$|R
40|$|Introduction. The {{application}} {{domains of}} the radiometric measuring are described {{and the basic}} types of radiometers are listed. The best "price ? measurement precision" index (in the authors' opinion) has a Dicke radiometer. The microwave self-noise level of this radiometer very affects on the <b>measurement</b> <b>precision.</b> It {{is a function of}} the waveguide devices characteristics, generally, of the microwave switch parameters. Microwave noise sources of the radiometer. A mixer and heterodyne are the basic sources of microwave noises in a radiometer. Analysis of the selfnoise influence on the <b>measurement</b> <b>precision</b> of the radiometer with pin-modulator in the switching mode. The considered radiometer involves a pindiodes switch. The theoretical and experimental investigations show, that the level of microwave noi-se depends on the channels nonidentity of the switch, and also on mismatch of its ports. Abatement of noise is possible due to reduction of the heterodyne noise factor of the radiometer, antennas noise, and also reduction of the input and output switch mismatch factors. Analysis of the selfnoise influencing on the <b>measurement</b> <b>precision</b> of the radiometer with pinmodulator in the commutation mode. The results of experimental determination of the basic radiometer characteristics in this mode are described. The main devices of the radiometer waveguide transmission line are analyzed. Their influence on the input power <b>measurement</b> <b>precision</b> is shown. The computation data of the measurement error are cited for the concrete parameters of the microwave devices. In the event that a relation a "signal ? noise" equals 1 and the switch coefficient of reflection is 0, 35 - 0, 55, the error can equal 18 %. It is suggested to decrease considerably this error through an additional ferrite isolator and using the switches with similar waveguide channels. Conclusion. Comparison of the offered methods shows that adding ferrite isolator and using the switch with similar waveguide channels are preferential. That allows ignoring the microwave selfnose influence on the <b>measurement</b> <b>precision?</b> ?????? ??????????? ??????? ????????????? ???????????????????? ????? ? ????????????? ?????????? ? ?? ??????? ?? ??? ???????? ?????????. ????????, ??? ???????? ???????? ????????? ??????? ? ?????? ?????? ?????, ??????????? ?? ??????? ?????? ??????????. ????????? ?????????? ????????????? ? ????????????????? ???????????? ??????????? ??????????? ????????? ?? ????????????? ?????????? ???????? ???????????????????? ????? ???????? ?????? ??????? ? ????????? ????? ?????????????????? ?? ??????????? ?????...|$|R
40|$|Abstract. Two {{measuring}} techniques, {{the parallel}} plate method and the cylinder cavity perturbation me-thod, for complex permittivity of microwave dielectric ceramics were introduced. Attention {{was focused on}} the theoretical consideration of <b>measurement</b> <b>precision</b> and suitable applications of the techniques...|$|R
40|$|Photogrammetry {{has been}} used to control the {{assembly}} of a convex paraboloidal jig, used in the construction of a 500 m dish concentrator. The photogrammetric <b>measurement</b> <b>precision</b> was ~ 1 : 175, 000, corresponding to an accuracy of better than 1 mm at the jig reference points. Equipment (camera, flash and retro-reflective film) and software are discussed. Photogrammetry was also used to characterise the dish mirror panels: the rear surface of the panels was mapped, as it made possible a denser target array and quicker image capture than if the reflective surface was used. The targets were produced with a digital projector, and the <b>measurement</b> <b>precision</b> attained was ~ 1 : 150, 000...|$|R
40|$|Depleted {{field effect}} {{transistors}} (DEPFET) {{are used to}} achieve very low noise signal charge readout with sub-electron <b>measurement</b> <b>precision.</b> This is accomplished by repeatedly reading an identical charge, thereby suppressing not only the white serial noise but also the usually constant 1 /f noise. The repetitive non-destructive readout (RNDR) DEPFET is an ideal central element for an active pixel sensor (APS) pixel. The theory has been derived thoroughly and results have been verified on RNDR-DEPFET prototypes. A charge <b>measurement</b> <b>precision</b> of 0. 18 electrons has been achieved. The device is well-suited for spectroscopic X-ray imaging and for optical photon counting in pixel sensors, even at high photon numbers in the same cell...|$|R
30|$|To {{overcome}} these limitations, {{a major focus}} of current PRO research is the development of computer-adaptive tests (CAT) [3 – 5] based on item response theory (IRT) measurement models. CAT represents a sophisticated form of assessing PROs more precisely by tailoring the questions to the health status of the individual patient. CAT requires an item bank containing a number of IRT-calibrated questions and an algorithm for selecting the most informative questions. A key item characteristic is the so-called item difficulty, a parameter that describes on which part of the measurement continuum an item provides the most information (i.e. has the highest <b>measurement</b> <b>precision)</b> [6]. The CAT algorithm is initiated with a start item and, based on the patient’s first response, calculates a first estimate of the level of the measured PRO. The algorithm then selects an item from the item bank whose item difficulty matches the patient’s construct level and administers this item next. This procedure is repeated until a predefined <b>measurement</b> <b>precision</b> has been reached or a maximum number of items have been asked. By using such tailored sets of items, <b>measurement</b> <b>precision</b> can be increased without increasing completion time.|$|R
40|$|The three-box {{problem is}} {{analysed}} {{in terms of}} virtual pathways, interference between which is destroyed {{by a number of}} <b>intermediate</b> <b>measurements.</b> The Aharonov-Bergmann-Lebowitz (ABL) rule is shown to be a particular case of Feynman's recipe for assigning probabilities to exclusive alternatives. The 'paradoxical' features of the three box case arise in an attempt to attribute, in contradiction to the uncertainty principle, properties pertaining to different ensembles produced by different <b>intermediate</b> <b>measurements</b> to the same particle. The effect can be mimicked by a classical system, provided an observation is made to perturb the system in a non-local manner...|$|R
50|$|EMF probes {{may respond}} to fields only on one axis, {{or may be}} tri-axial, showing {{components}} of the field in three directions at once. Amplified, active, probes can improve <b>measurement</b> <b>precision</b> and sensitivity but their active components may limit their speed of response.|$|R
40|$|OBJECTIVE: To {{evaluate}} {{and compare the}} <b>measurement</b> <b>precision</b> and sensitivity to change of the Health Assessment Questionnaire disability index (HAQ DI), the Short Form 36 physical functioning scale (PF- 10), and simulated Patient-Reported Outcomes Measurement Information System (PROMIS) physical function computer adaptive tests (CATs) with 5, 10, and 15 items, using item response theory-based simulation studies. METHODS: The <b>measurement</b> <b>precision</b> of the various physical function instruments was evaluated by calculating root mean square errors (RMSEs) between true physical function levels (latent physical function score) and estimated physical function levels. <b>Measurement</b> <b>precision</b> was evaluated at 9 levels of physical function, with 5, 000 simulated response patterns per level. Sensitivity to change was evaluated by {{the ability of a}} simple statistical test to detect simulated change scores of small to moderate magnitude (standardized effect sizes 0. 20, 0. 35, and 0. 50). RESULTS: RMSEs were smaller for the PROMIS physical function 15 -item CAT (CAT- 15) and CAT- 10 than for the HAQ DI and PF- 10 across all levels of the latent physical function scale. Only marginal improvement in performance was observed for the CAT- 15 compared with the CAT- 10, and the CAT- 5 performed quite similarly to the HAQ DI and PF- 10 across most levels of the latent physical function scale. Substantially improved sensitivity to change was observed for the CAT- 10 compared with the HAQ DI and PF- 10, particularly in detecting moderate effect sizes. CONCLUSION: Clearly higher <b>measurement</b> <b>precision</b> was observed for the PROMIS CAT compared with the HAQ DI and PF- 10. Higher reliability also translated into lower sample size requirements for detecting changes in clinical status...|$|R
40|$|Objective Several authors {{proposed}} a shortened {{version of the}} State scale of the State-Trait Anxiety Inventory (S-STAI) to obtain a more efficient measurement instrument. Psychometric theory shows that test shortening makes a total score more vulnerable to measurement error, and this may result in inaccurate and biased research results and {{an increased risk of}} making incorrect decisions about individuals. This study investigated whether the reliability and the <b>measurement</b> <b>precision</b> of shortened versions of the S-STAI are adequate for psychological research and making decisions about individuals in clinical practice. Methods Secondary data analysis was used to compare reliability and <b>measurement</b> <b>precision</b> between twelve shortened S-STAI versions and the full-length 20 -item S-STAI version. Data for the 20 -item version came from a longitudinal study performed previously in the Netherlands and included 377 patients and 375 of their family members. This was our master data set. A literature study was conducted to identify shortened S-STAI versions that are used in research and clinical practice. Data for each shortened version were obtained from the master data set by selecting the relevant items from the 20 -item version. All analyses were done by means of classical test theory statistics. Results The effect of test shortening on total-score reliability was small, the effect on <b>measurement</b> <b>precision</b> was large, and the effect on individual diagnosis and assessment of individual change was ambiguous. Conclusion We conclude that shortened versions of the S-STAI seem to be acceptable for research purposes, but may be problematic in clinical practice. Keywords: Assessment of individual change, Individual diagnosis, <b>Measurement</b> <b>precision,</b> State-Trait Anxiety Inventory, Test shortening, Total-score reliabilit...|$|R
