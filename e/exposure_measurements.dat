426|576|Public
25|$|On the {{international}} level, the International Society of Indoor Air Quality and Climate (ISIAQ), formed in 1991, organises two major conferences, the Indoor Air and the Healthy Buildings series. ISIAQ's journal Indoor Air is published 6 {{times a year}} and contains peer-reviewed scientific papers {{with an emphasis on}} interdisciplinary studies including <b>exposure</b> <b>measurements,</b> modeling, and health outcomes.|$|E
5000|$|OSHA {{requires}} that records of <b>exposure</b> <b>measurements</b> and audiometric tests be maintained. Records are also {{required to have}} the following: ...|$|E
50|$|On the {{international}} level, the International Society of Indoor Air Quality and Climate (ISIAQ), formed in 1991, organises two major conferences, the Indoor Air and the Healthy Buildings series. ISIAQ's journal Indoor Air is published 6 {{times a year}} and contains peer-reviewed scientific papers {{with an emphasis on}} interdisciplinary studies including <b>exposure</b> <b>measurements,</b> modeling, and health outcomes.|$|E
5000|$|... #Subtitle level 2: Workplace <b>exposure,</b> <b>measurement</b> and {{modelling}} ...|$|R
40|$|An {{important}} goal of many epidemiological studies is {{to estimate the}} magnitude of association between an exposure and an outcome. <b>Exposure</b> <b>measurement</b> error causes bias in such estimates of association and can be substantial. In this article, we describe the problem of <b>exposure</b> <b>measurement</b> error and its effects. We show how a simple hand calculation, in conjunction with validation study data and a calibration equation, {{can be used to}} correct estimates for the bias caused by <b>exposure</b> <b>measurement</b> error. Correcting estimates of association for measurement error helps researchers appropriately assess effect size...|$|R
5000|$|... 1986-present: Chief, <b>Exposure</b> <b>Measurement</b> and Assessment Division, DECM of Rutgers-RWJMS ...|$|R
5000|$|Later smaller {{impacts on}} these near-Earth objects {{dislodged}} rock-sized meteorites, {{some of which}} later struck Earth. On the basis of cosmic ray <b>exposure</b> <b>measurements,</b> {{it is thought that}} most HED meteorites arose from several distinct impact events of this kind, and spent from about 6 million to 73 million years in space before striking the Earth.|$|E
50|$|An {{alternative}} to concentrating on disease occurrence is to monitor exposure. An exposure register records data relevant to occupational health-and-safety outcomes. It {{is different from}} a disease register in that it concentrates on workplace exposure, rather than the disorders it causes. The measurement services of the institutions for statutory accident insurance and prevention (BGs) in Germany perform <b>exposure</b> <b>measurements</b> at workplaces. The data are stored in the BG/BIA exposure database.|$|E
50|$|Light is {{most easily}} {{controlled}} {{through the use}} of the camera's aperture (measure in f-stops), {{but it can also be}} regulated by adjusting the shutter speed. Using faster or slower film is not usually something that can be done quickly, at least using roll film. Large format cameras use individual sheets of film and each sheet could be a different speed. Also, if you're using a larger format camera with a polaroid back, you can switch between backs containing different speed polaroids. Digital cameras can easily adjust the film speed they are simulating by adjusting the exposure index, and many digital cameras can do so automatically in response to <b>exposure</b> <b>measurements.</b>|$|E
40|$|OBJECTIVES: This paper {{describes}} 2 {{statistical methods}} designed to correct for bias from <b>exposure</b> <b>measurement</b> error in point and interval estimates of relative risk. METHODS: The first method takes the usual point and interval {{estimates of the}} log relative risk obtained from logistic regression and corrects them for nondifferential measurement error using an <b>exposure</b> <b>measurement</b> error model estimated from validation data. The second, likelihood-based method fits an arbitrary measurement error model suitable for the data at hand and then derives {{the model for the}} outcome of interest. RESULTS: Data from Valanis and colleagues' study of the health effects of antineoplastics exposure among hospital pharmacists were used to estimate the prevalence ratio of fever in the previous 3 months from this exposure. For an interdecile increase in weekly number of drugs mixed, the prevalence ratio, adjusted for confounding, changed from 1. 06 to 1. 17 (95 % confidence interval [CI] = 1. 04, 1. 26) after correction for <b>exposure</b> <b>measurement</b> error. CONCLUSIONS: <b>Exposure</b> <b>measurement</b> error is often an important source of bias in public health research. Methods are available to correct such biases...|$|R
5000|$|... 1965 PRAKTICA mat by VEB Pentacon Dresden is {{the first}} 35 mm single-lens reflex camera with TTL <b>exposure</b> <b>measurement</b> in Europe.|$|R
40|$|Abstract Studies in air {{pollution}} epidemiology may suffer from some specific forms of confounding and <b>exposure</b> <b>measurement</b> error. This contribution discusses these, {{mostly in the}} framework of cohort studies. Evaluation of potential confounding is critical in studies of the health effects of {{air pollution}}. The association between long-term exposure to ambient air pollution and mortality has been investigated using cohort studies in which subjects are followed over time with respect to their vital status. In such studies, control for individual-level confounders such as smoking is important, as is control for area-level con-founders such as neighborhood socio-economic status. In addition, there may be spatial dependencies in the survival data that need to be addressed. These issues are illustrated using the American Cancer Society Cancer Prevention II cohort. <b>Exposure</b> <b>measurement</b> error is a challenge in epidemiology because inference about health effects can be incorrect when the measured or predicted exposure used in the analysis is different from the underlying true exposure. Air pollution epidemiology rarely if ever uses personal <b>measurements</b> of <b>exposure</b> for reasons of cost and feasibility. <b>Exposure</b> <b>measurement</b> error in air pollution epidemiology comes in various dominant forms, which are different for time-series and cohort studies. The challenges are reviewed and a number of suggested solutions are discussed for both study domains...|$|R
50|$|Bone {{density or}} bone mineral density (BMD) {{is the amount}} of bone mineral in bone tissue. The concept is of mass of mineral per volume of bone (relating to density in the physics sense), {{although}} clinically it is measured by proxy according to optical density per square centimeter of bone surface upon imaging. Bone density measurement is used in clinical medicine as an indirect indicator of osteoporosis and fracture risk. It is measured by a procedure called densitometry, often performed in the radiology or nuclear medicine departments of hospitals or clinics. The measurement is painless and non-invasive and involves low radiation <b>exposure.</b> <b>Measurements</b> are most commonly made over the lumbar spine and over {{the upper part of the}} hip. The forearm may be scanned if the hip and lumbar spine are not accessible.|$|E
50|$|From its {{earliest}} years, IOM {{has had a}} tradition of using quantitative <b>exposure</b> <b>measurements</b> to explore links between the working environment and health and has pioneered {{the development of new}} methods to measure the concentration of aerosols in ways that are relevant to human biology. The MRE 113A respirable dust sampler developed for use in our pneumoconiosis research was the first landmark and led to greater insight into the causes of this disease. Under Dr Jim Vincent's leadership, an innovative research programme, begun by Dr Trevor Ogden, was aimed at designing new sampling instruments for coarser aerosols. The culmination of this work was the development of the IOM inhalable dust sampler, which has become established as the device of choice for measuring the part of an aerosol that penetrates beyond the larynx. IOM scientists {{played a key role in}} defining the internationally agreed size fractions of dust relevant to human lung disease, i.e. inhalable, thoracic and respirable.|$|E
50|$|Dosimeters {{are also}} used to collect data for use in legal proceedings, {{development}} of engineering noise controls, and other industrial hygiene purposes. When planning to conduct noise <b>exposure</b> <b>measurements,</b> steps {{must be taken to}} ensure that the dosimeters are calibrated and operated according to manufacturers’ specifications. It is also necessary to understand the properties of the acoustic environment, the main measurement objectives as they relate to determining the risk to hearing damage, and the limitations {{associated with the use of}} dosimeters. Dosimeter manufacturers recommend that the instrument be calibrated with an acoustical calibrator such as a pistonphone before and after each measurement to verify reliable operation. In addition to field calibration routines, the manufacturers recommend periodic comprehensive calibration and certification of the instrument by an accredited laboratory using traceable reference sources. Field calibration of contemporary dosimeters has been mostly automated through PC-based programs that run the calibration routine, document the time and date, and adjust for any offset in levels.|$|E
50|$|Noise <b>exposure</b> <b>measurement</b> records must be {{maintained}} for at least 2 years. Audiometric test records must be retained {{for the duration of}} the affected employee's employment. Additionally, employees, former employees, representatives designated by the individual employee and the Assistant Secretary all must have access to these records.|$|R
40|$|Texto completo: acesso restrito. p. 957 - 963 Aim: To {{compare the}} use of {{different}} definitions for <b>exposure</b> <b>measurement</b> in cases of association between periodontal disease (PD) and prematurity and/or low birth weight (PLBW). Material and Methods: A database from a previous case–control study {{was used to compare}} four different definitions for periodontitis: at least one site with probing depth geqslant R: gt-or-equal, slanted 4 mm (1); at least one site with clinical attachment loss (CAL) geqslant R: gt-or-equal, slanted 3 mm (2); at least four teeth with one or more sites presenting probing depth geqslant R: gt-or-equal, slanted 4 mm, with CALgeqslant R: gt-or-equal, slanted 3 mm at the same site (3); and at least four teeth with one or more sites with probing depth geqslant R: gt-or-equal, slanted 4 mm, with CALgeqslant R: gt-or-equal, slanted 3 mm at the same site and presence of bleeding on probing (4). The PD frequency, diagnostic values and adjusted association measurements were calculated. Results: PD frequency ranged from 33. 1 % to 94. 7 %. Odds ratioadjusted varied slightly according to the <b>exposure</b> <b>measurement</b> used. Conclusions: The association between PD and PLBW weight was consistent, except for <b>exposure</b> <b>measurement</b> 1, i. e. using at least one site with CALgeqslant R: gt-or-equal, slanted 3 mm for periodontitis diagnosis, while the magnitude of this varied according to the definition established...|$|R
50|$|Introduced in 1987 the R5 offered {{variable}} program mode and, more importantly, automatic TTL flash <b>exposure</b> <b>measurement</b> for {{the first}} time in a Leica camera along with control improvements of the R4s. Flash metering required a second light receptor in the base and measured full field only off the film itself during exposure.|$|R
50|$|However, by the 1960s the clamour for in-camera {{exposure}} metering was rising. It {{was possible}} to attach an external CdS (Cadmium sulfide) exposure meter to the later AP-derived models, but in 1960 the next breakthrough arrived. At the 1960 photokina camera show, Asahi exhibited the Spot-matic prototype. This camera took <b>exposure</b> <b>measurements,</b> via a spotmeter, through the taking lens, an incredible innovation. The camera excited tremendous attention and in 1964 the first production Spotmatic (hyphen dropped) emerged. The Spotmatic was virtually identical to the prototype; however, the spotmeter was replaced with an all-over average-reading exposure meter {{in order to give}} more consistent results. The camera was an instant success and was snapped up by the thousands, although Asahi had been beaten into production by the Topcon RE Super which went on sale in April 1963; the Topcon failed to attract the same degree of commercial success. The Spotmatic was replaced by the Spotmatic II with many upgrades 1971 - 1976.|$|E
5000|$|Advertiser {{demands for}} {{accountability}} will require new measurements of advertising effectiveness {{that differ from}} the [...] "exposure" [...] measurements now so prevalent for determining media cost and efficiencies. [...] <b>Exposure</b> <b>measurements</b> will still have a significant {{role to play in}} both pricing and efficiency analyses; but exposure will be a first level of measurement: creating the initial opportunity to generate demand. The concept of exposure will now have to be expanded from real time to include time-shifted and cross platform exposure. The second level of measurement for media pricing and efficiency will be for delivery of additional information. In some ways, this parallels the internet click through model. Here we measure and compensate the media for delivery of additional commercial content based on the requests of the audience. The third level of measurement is transactional. At this level, we measure response and compensate the media for assisting in generating the desired response: ...|$|E
40|$|In the {{supplemental}} material {{additional information}} is provided on <b>exposure</b> <b>measurements.</b> The supplement also presents additional information on quality of clinical measurements and additional analyses on the associations between exposure to and inhaled doses of air pollutants and changes in biomarkers. Table of Contents 1. Additional information on <b>exposure</b> <b>measurements</b> 2 2. Details clinical measurements...|$|E
50|$|In photography, the {{pellicle}} mirror {{has been}} employed in single-lens reflex (SLR) cameras, {{at first to}} enable through-the-lens <b>exposure</b> <b>measurement</b> and possibly to reduce camera shake, but later most successfully to enable fast series photography, which otherwise would be slowed down by {{the movement of the}} reflex mirror, while maintaining constant finder vision.|$|R
40|$|Characterization of {{exposure}} {{is a central}} issue {{in the analysis of}} observational data; however, no “one size fits all ” solution exists for <b>exposure</b> <b>measurement.</b> In this chapter, we discuss potential <b>exposure</b> <b>measurement</b> approaches for observational comparative effectiveness research (CER). First, it is helpful to lay out a theoretical link between the exposure and the event/outcome of interest that draws from the study’s conceptual framework. For interventions that target health and well-being, the physiological or psychological basis for the mechanism of action, whether known or hypothesized, should guide the development of the exposure definition. When possible, an operational definition {{of exposure}} that has evidence of validity with estimates of sensitivity, specificity, and positive predictive value should be used. Other important factors to consider when defining exposure are the timeframe (induction and latent periods), changes in exposure status or exposure to other therapies, and consistency and accuracy of <b>exposure</b> <b>measurement.</b> The frequency, format, and intensity of the exposure is another important consideration for the <b>measurement</b> of <b>exposure</b> in CER studies, which is applicable to medications (e. g. dose) as well as health service interventions that may require multiple sessions, visits, or interactions. This chapter also discusses methods for avoiding nondifferential and differential measurement error, which can introduce bias, and describes the importance of determining the likelihood of bias and effects on study results. We conclude with a checklist of key considerations for the characterization and operationalization of exposure in CER protocols. 4...|$|R
5000|$|Various dust {{sampling}} methods exist that are internationally recognised. Inhalable dust is determined using the modern {{equivalent of the}} Institute of Occupational Medicine (IOM) MRE 113A monitor (see section on workplace <b>exposure,</b> <b>measurement</b> & modelling). Inhalable dust {{is considered to be}} dust of less than 100 micrometers aerodynamic equivalent diameter (AED) that enters through the nose and or mouth. See Lungs ...|$|R
40|$|Possible {{health risks}} {{associated}} with occupational inhalation of mycotoxin-containing dust remain largely unknown, partly because methods for mycotoxin detection are not sensitive enough for the small dust masses obtained by personal sampling, which is needed for inhalable <b>exposure</b> <b>measurements.</b> Specific and sensitive PCR detection of fungi with mycotoxin-producing potential {{seem to be a}} good surrogate for occupational <b>exposure</b> <b>measurements</b> that include all fungal structures independent of morphology and cultivability. Results should, however, be interpreted with caution due to variable correlations with mycotoxin concentrations...|$|E
40|$|Estimation and Assessment of Substance Exposure (EASE) is a {{computerized}} expert system {{developed by the}} UK Health and Safety Executive to facilitate exposure assessments {{in the absence of}} <b>exposure</b> <b>measurements.</b> The system uses a number of rules to predict a range of likely exposures or an ‘end-point ’ for a given work situation. The {{purpose of this study was}} to identify a number of inhalation <b>exposure</b> <b>measurements</b> covering a wide range of end-points in the EASE system to compare with the predicted exposures. Occupational exposure data sets were identified from previous research projects or from consultancy work. Available information for each set of measurements was retrieved from archive storage and reviewed to ensure that it was adequate to enable EASE (version 2) predictions to be obtained. <b>Exposure</b> <b>measurements</b> and other relevant contextual data were abstracted and entered into a computer spreadsheet. EASE predictions were then obtained for each task or job and entered into the spreadsheet. In addition, we generated a random exposure range for each data set for comparison with the EASE predictions. Finally, we produced exposure assessments for a subset of the data using a structured subjective assessment method. We were able to identify 4000 inhalation <b>exposure</b> <b>measurements</b> covering 52 different scenarios and 28 EASE end-points. The data include...|$|E
40|$|The paper {{focuses on}} an {{occupational}} health study where {{the goal is}} to associate a worker's true log-normal-scale mean dust exposure over the year with forced expiratory volume. A previous analysis used repeated shift-long dust <b>exposure</b> <b>measurements,</b> taken over a year, as a surrogate {{to address the issue of}} the mean exposure being unobservable. However, in this study the associated measurement error is further complicated by the fact that some <b>exposure</b> <b>measurements</b> fall below a detectable limit. We extend the previous analysis via full maximum likelihood, to account appropriately for non-detectable exposures. Copyright 2005 Royal Statistical Society. ...|$|E
40|$|We {{consider}} an epidemiologic study with a fixed budget, in which resources may {{be put into}} increasing sample size or into improving accuracy of exposure assessments. To maximize study power (efficiency), improving accuracy is preferable {{if and only if}} the proportional increase in the square of the validity coefficient is more than the proportional increase in total study costs per subject that is required to achieve it. (The validity coefficient is the correlation between the true exposure and the approximate assessment in the study base.) This is most likely to be so if the cost of <b>exposure</b> <b>measurement</b> remains a small proportion of the overall costs per subject. The design with maximum power will not generally have minimum bias in measure of effect, so that alternative optimally criteria are required if this bias is important. Am J Epidemiol 1996; 144 : 192 - 7. statistics Improving the accuracy of <b>exposure</b> <b>measurement</b> in an epidemiologic study will in general improve study power and the accuracy of the estimate of the effect of the <b>exposure.</b> However, improving <b>measurement</b> ac-curacy usually requires resources {{that could be used in}} other ways, in particular to improve other study in...|$|R
40|$|Through {{accident}} prediction models, {{researchers have}} identified correlation between crash risk and many different explanatory factors, such as traffic volume, roadway geometries, temporal effects, driver characteristics, and and use, but cannot give definite safety effects of countermeasures. This dissertation proposes a methodology {{that accounts for}} crash causality by defining collision type categories, with the crashes in each sharing common contributing factors to support estimation of prediction models that offer a more accurate understanding of crash risk correlation for each collision type as well as suggesting appropriate countermeasures for reducing the predicted collisions. Furthermore, this dissertation intends to advance the state of crash prediction modeling by redefining crash exposure to consider the practical (or causal) relationship between traffic volume and crashes. Therefore, each crash category could conceivably use a different measure of <b>exposure</b> <b>measurement</b> for its distinct occurrence mechanism. Combining this {{with the idea of}} linking prediction models to crash causalities through the established collision type categories, the proposed <b>exposure</b> <b>measurement</b> can potentially explain with more accuracy the variation observed in crash risk due to the traffic flow state. ^ Studies using statistical methodologies of generalized linear models are carried out to evaluate the new exposure definitions. The new crash exposure for opposite-direction collisions including head-on and sideswipe is defined as the number of times vehicles traveling in opposite directions meet. Vehicle time spent following is then proposed as a new exposure definition for same-direction collisions. This new exposure is found to have a linear relationship with the same-direction crashes while the collision categories defined based on contributing factors are also considered in the models. This linearity implies a well defined traffic flow intensity and state by the new exposure, and provides for the possibility of a constant crash rate by dividing the number of rear-end crashes by this <b>exposure</b> <b>measurement.</b> Moreover, finding VTSF being linearly related to the rear-end crash count further suggests categorizing crashes by crash causality rather than the nature of the collision and defining the <b>exposure</b> <b>measurement</b> based on the contributing factor can lead to more accurate and explainable prediction models. ...|$|R
40|$|Use of {{computerized}} adaptive testing (CAT) {{has increased}} substantially {{since it was}} first formulated in the 1970 s. This paper {{provides an overview of}} CAT and introduces the contributions to this Special Issue. The elements of CAT discussed here include item selection procedures, estimation of the latent trait, item <b>exposure,</b> <b>measurement</b> precision, and item bank development. Some topics for future research are also presented...|$|R
40|$|Introduction: In {{occupational}} epidemiology, {{differences in}} the temporal coverage of the exposure history by available exposure measurement data may affect the uncertainty of exposure estimates. In the reporting of results of studies, greater attention should {{be paid to the}} extent to which exposure assessments require extrapolation outside the timeframe for which <b>exposure</b> <b>measurements</b> are available. We propose a simple graphical method that can be used to visualise the temporal coverage of exposure history with <b>exposure</b> <b>measurements</b> and the extent of temporal extrapolation needed. Methods: We construct a graph that displays the accumulated work history years for which exposure had to be assessed in each calendar year. Years for which <b>exposure</b> <b>measurements</b> were available are shaded. The proportion of work history years covered by <b>exposure</b> <b>measurements</b> and the proportion of work history years accrued before the first measurements are summarised. When available, the actual number of measurements available in each calendar year is shown. Results: We demonstrate the application of the graphical tool in three nested case-control studies that reported on leukaemia in relation to low-level benzene exposures in the petroleum industry. Considerable differences in temporal coverage between the studies were illustrated, which may have resulted in {{differences in the}} reliability of the retrospective exposure estimates derived for these studies. Conclusion: We introduce a graphical tool for visualising the temporal coverage by available exposure measurement data in epidemiological studies and encourage others to use similar graphs to derive and share better qualitative insights into the uncertainty in exposure assessment...|$|E
40|$|AbstractHuman {{exposure}} to fine particles can have significant harmful {{effects on the}} respiratory and cardiovascular system. To investigate daily exposure characteristics to PM 2. 5 with ambient concentrations in an urban environment, a personal <b>exposure</b> <b>measurements</b> were conducted for school children, office workers and at their residents, {{in the city of}} Taj ‘Agra’, India. In order to account for all the sources of particulate matter <b>exposure,</b> <b>measurements</b> on several different days during December 2013 to February 2014 were carried out. Personal environment monitors (PEM) and APM 550 were used to measure PM 2. 5 concentration. The research findings provide insight into possible sources and their interaction with human activities in modifying the human exposure levels...|$|E
40|$|Introduction: An {{industrial}} hygiene database has been constructed for the exposure assessment {{in a study}} of cancer risk among asphalt workers. Aim: To create models of bitumen and polycyclic aromatic hydrocarbons (PAH) exposure intensity among paving workers. Methods: Individual <b>exposure</b> <b>measurements</b> from pavers (N = 1581) were collected from...|$|E
5000|$|The exposome {{encompasses}} {{the totality of}} human environmental (i.e. non-genetic) exposures from conception onwards, complementing the genome. It was first proposed in 2005 by a cancer epidemiologist, in an article entitled [...] "Complementing the genome with an [...] "exposome": the outstanding challenge of environmental <b>exposure</b> <b>measurement</b> in molecular epidemiology". The concept of the exposome and how to assess {{it has led to}} lively discussions with varied views in 2010,2012 and 2014, ...|$|R
40|$|Summary. We {{introduce}} {{sequential testing}} {{procedures for the}} planning and analysis of reliability studies to assess an <b>exposure’s</b> <b>measurement</b> error. The designs allow repeated evaluation of reliability of the measurements and stop testing if early evidence shows the measurement error is within the level of tolerance. Methods are developed and critical values tabulated {{for a number of}} two-stage designs. The methods are exemplified using an example evaluating the reliability of biomarkers associated with oxidative stress...|$|R
50|$|Under the cents-per-mile system, {{rewards for}} driving less are {{delivered}} automatically, {{without the need}} for administratively cumbersome and costly GPS technology. Uniform per-mile <b>exposure</b> <b>measurement</b> for the first time provides the basis for statistically valid rate classes. Insurer premium income automatically keeps pace with increases or decreases in driving activity, cutting back on resulting insurer demand for rate increases and preventing today's windfalls to insurers, when decreased driving activity lowers costs but not premiums.|$|R
