2704|673|Public
25|$|Data mining {{requires}} {{data preparation}} which can uncover information or patterns which may compromise confidentiality and privacy obligations. A common way {{for this to}} occur is through <b>data</b> <b>aggregation.</b> <b>Data</b> <b>aggregation</b> involves combining data together (possibly from various sources) {{in a way that}} facilitates analysis (but that also might make identification of private, individual-level data deducible or otherwise apparent). This is not data mining per se, but a result of the preparation of data before – and for the purposes of – the analysis. The threat to an individual's privacy comes into play when the data, once compiled, cause the data miner, or anyone who has access to the newly compiled data set, to be able to identify specific individuals, especially when the data were originally anonymous.|$|E
25|$|Microsoft Office Project Portfolio Server 2007 allows {{creation}} of a project portfolio, including workflows, hosted centrally, so that the information is available throughout the enterprise, even from a browser. It also aids in centralized <b>data</b> <b>aggregation</b> regarding the project planning and execution, and in visualizing and analyzing the data to optimize the project plan. It can also support multiple portfolios per project, to track different aspects of it. It also includes reporting tools to create consolidated reports out of the project data.|$|E
25|$|The {{majority}} of {{the focus was on}} the last three options which comprise an administrative <b>data</b> <b>aggregation</b> approach as these are less well understood. Administrative data, underpinned by a National Address Register (yet to be established), includes public sector data obtained from government departments (e.g. HMRC) and agencies, (such as the DVLA), local authorities, electoral registers, the Annual School Census, the Higher Education Student Statistics database, and from the NHS Central Patients Register. From the private sector e.g. utility companies, retail and financial sectors, credit reference agencies and customer information systems.|$|E
50|$|MapReduce can be {{used for}} batch {{processing}} of <b>data</b> and <b>aggregation</b> operations.|$|R
3000|$|Process {{observed}} information (low-level contextual <b>data)</b> through <b>aggregation</b> and fusion {{to generate}} a high-level abstraction of context [...]...|$|R
5000|$|ROLAP - Relational OLAP - Both fact <b>data</b> and <b>aggregations</b> {{remain in}} the {{relational}} data source, {{eliminating the need for}} special processing.|$|R
25|$|Initially, eight {{options were}} {{identified}} which were assessed. Following initial consideration {{it was found}} that some of the options had identical components so it was decided to redefine the options in the form of varying quality standards covering census, survey and administrative <b>data</b> <b>aggregation,</b> which would each be assessed in terms of accuracy, frequency and geography. In 2012 the second round of assessment commenced with six possible options identified for detailed investigation. The criteria for assessment of these options will comprise cost, technical feasibility, risk, public acceptability, and fitness for purpose.|$|E
25|$|Continuous data {{assurance}} verifies {{the integrity}} of data flowing through the information systems. Continuous data assurance uses software to extract data from IT systems for analysis at the transactional level to provide more detailed assurance. CDA systems provide the ability to design expectation models for analytical procedures at the business-process level, {{as opposed to the}} current practice of relying on ratio or trend analysis at higher levels of <b>data</b> <b>aggregation.</b> CDA software can continuously and automatically monitor transactions, comparing their generic characteristics with predetermined benchmarks, thereby identifying anomalous situations. When significant discrepancies occur, alarms are triggered and routed to appropriate stakeholders and auditors.|$|E
500|$|Organizations {{have also}} {{attempted}} to give newer assessments of Clinton once she reentered elective politics in 2015. Based on her stated positions from the 1990s to the present, On the Issues places her in their [...] "Left Liberal" [...] region on their two-dimensional grid {{of social and}} economic ideologies, with a social score of 80 on a scale of 0 more-restrictive to 100 less-government stances and an economic score of 10 on a scale of 0 more-restrictive to 100 less-government stances. Crowdpac, which does a <b>data</b> <b>aggregation</b> of campaign contributions, votes and speeches, gives her a 6.5L rating on a one-dimensional left-right scale from 10L (most liberal) to 10C (most conservative). Through 2008, she had an average lifetime 90percent [...] "Liberal Quotient" [...] from Americans for Democratic Action, and a lifetime 8percent rating from the American Conservative Union.|$|E
5000|$|MOLAP - Multidimensional OLAP - Both fact <b>data</b> and <b>aggregations</b> are processed, stored, and indexed using {{a special}} format {{optimized}} for multidimensional data.|$|R
40|$|The {{performance}} of programs {{written in the}} Java programming language is not trivial to analyse. The Java Virtual Machine hides the details of bytecode execution while not providing an accessible profiling mechanism. Most tools used for Java performance evaluations are based on sampling and only present engineers with sampled <b>data</b> <b>aggregations.</b> In this paper, we present the Java DTrace Toolkit, a collection of scripts that is specifically designed to assist engineers in identifying the roots of various performance problems observed with other tools. 1...|$|R
5000|$|Request modes (raw <b>data,</b> last-known value, <b>aggregation,</b> interpolation), ...|$|R
2500|$|ChoicePoint (previous NYSE {{ticker symbol}} CPS) was a <b>data</b> <b>aggregation</b> {{company based in}} Alpharetta, near Atlanta, Georgia, United States, that acted as a private {{intelligence}} service to government and industry. ChoicePoint was a spinoff of Equifax's Insurance Services Group, and it was purchased in February 2008 by Reed Elsevier (parent corporation of LexisNexis) in a cash deal for $4.1 billion USD. [...] The company was rebranded as LexisNexis Risk Solutions.|$|E
2500|$|In the United States, privacy {{concerns}} {{have been addressed}} by the US Congress via the passage of regulatory controls such as the Health Insurance Portability and Accountability Act (HIPAA). The HIPAA requires individuals to give their [...] "informed consent" [...] regarding information they provide and its intended present and future uses. According to an article in Biotech Business Week, [...] "'n practice, HIPAA may not offer any greater protection than the longstanding regulations in the research arena,' says the AAHC. More importantly, the rule's goal of protection through informed consent is approach a level of incomprehensibility to average individuals." [...] This underscores the necessity for data anonymity in <b>data</b> <b>aggregation</b> and mining practices.|$|E
50|$|In 2005, {{the company}} shifted its focus towards <b>data</b> <b>aggregation</b> and began {{building}} a <b>data</b> <b>aggregation</b> platform. The following year, {{the company was}} approached by T-Mobile {{with the concept of}} becoming a data aggregator in the M2M space, and RacoWireless was officially founded in 2006.|$|E
40|$|Important {{principles}} in modelling forest industry development in New Zealand are enunciated. Recent sector modelling {{efforts by the}} Forest Service and Forestry Council and those contained in the CNIPS report are briefly reviewed, before presenting an out-line of the integrated and hierarchical modelling of the sector {{carried out by the}} authors. The need to reflect a wide range of interests, objectives, emphases and <b>data</b> <b>aggregations</b> is catered for in this approach, as is the ability to allow ready interaction {{with a wide range of}} contributors to, and potential users of the results. 1...|$|R
5000|$|<b>Data</b> Analysis - <b>aggregation,</b> {{calculation}} {{and interpretation}} of data ...|$|R
5000|$|... #Subtitle level 3: Searches, queries and <b>data</b> {{processing}} and <b>aggregation</b> ...|$|R
50|$|Two main {{security}} {{challenges in}} secure <b>data</b> <b>aggregation</b> are confidentiality {{and integrity of}} data. While encryption is traditionally used to provide end to end confidentiality in wireless sensor network, the aggregators in a secure <b>data</b> <b>aggregation</b> scenario need to decrypt the encrypted data to perform aggregation. This exposes the plaintext at the aggregators, making the data vulnerable to attacks from an adversary. Similarly an aggregator can inject false data into the aggregate and make the base station accept false data. Thus, while <b>data</b> <b>aggregation</b> improves energy efficiency of a network, it complicates the existing security challenges.|$|E
5000|$|... <b>data</b> <b>aggregation,</b> {{which is}} {{connecting}} many related but unconnected {{pieces of information}} ...|$|E
5000|$|Delays in <b>data</b> <b>aggregation</b> {{networks}} such as Reuters IDN, Bloomberg, IDC {{and others}} ...|$|E
40|$|A {{formal system}} for proving {{properties}} of programs accessing a database is introduced. Proving that a program preserves {{consistency of the}} database {{is one of the}} possible applications of the system. The formal system is a variant of dynamic logic and incorporates a data definition language (DDL) for describing relational databases and a data manipulation language (DML) whose programs access data in a database. The DDL is a many-sorted first-order language that accounts for <b>data</b> <b>aggregations.</b> The DML features a many-sorted assignment i place of the usual data manipulation statements, in addition to the normal programming language constructs...|$|R
40|$|Abstract:- In cluster-based {{wireless}} sensor networks (WSN), {{the most}} of energy is consumed in cluster head which performs <b>data</b> <b>aggregations</b> and relaying. The lifetime in cluster-based WSN is subjected by the lifetime of cluster heads. Therefore, in this paper, we equalize the energy consumption of the cluster heads to prolong the lifetime of WSN. After equalization, we obtain the length of sides of cluster area. Numerical {{results show that the}} length of far site cluster is shorter than the nearest cluster to perform equalization for all three routing schemes. Moreover, simulation results show that the three-hop scheme can obtain the most energy efficiency than other two schemes...|$|R
40|$|This paper {{describes}} a procedure designed for incorporating improved information on taxes into existing GTAP <b>data</b> <b>aggregations.</b> The {{aim of this}} procedure is to maintain {{the internal consistency of}} the data base while minimizing the impacts of the tax change on the value flows in the data base. It utilizes a variant of the GTAP Model, for which the model structure and parameter settings have been designed to achieve this aim. The features include Cobb-Douglas production and consumption functions, inter-intermediate input substitution (also Cobb-Douglas), universal factor mobility and fixed trade balances. Instructions and computer files for implementation of the procedure are provided in the attached files. ...|$|R
5000|$|Five-way {{data and}} six-way {{data can be}} {{represented}} by similarly higher levels of <b>data</b> <b>aggregation.</b>|$|E
50|$|<b>Data</b> <b>aggregation</b> is the {{compiling}} {{of information}} from databases with intent to prepare combined datasets for data processing.|$|E
5000|$|Chalermek Intanagonwiwat, Deborah Estrin, Ramesh Govindan, John Heidemann, [...] "Impact of Network Density on <b>Data</b> <b>Aggregation</b> in Wireless SensorNetworks," [...] November 4, 2001.|$|E
40|$|Most {{database}} applications manage time-referenced, or temporal, data. Temporal {{data management}} is difficult when using conventional database technology, and many contributions {{have been made}} for how to better model, store, and query temporal <b>data.</b> Temporal <b>aggregation</b> illustrates well {{the problems associated with}} the management of temporal <b>data.</b> Indeed, temporal <b>aggregation</b> is complex and among the most difficult, and thus interesting, temporal functionality to support. This paper presents a general framework for temporal aggregation that accommodates existing kinds of aggregation, and it identifies open challenges within temporal aggregation...|$|R
40|$|In on-line {{analytical}} processing (OLAP), precomputing (materializing as views) and indexing auxiliary <b>data</b> <b>aggregations</b> is {{a common}} way of reducing query-evaluation time costs for important data-analysis queries. We consider an OLAP view- and index-selection problem stated as an optimization problem, where (i) the inputs include the data-warehouse schema, a set of data-analysis queries of interest, and a storage-limit constraint, and (ii) the output {{is a set of}} views and indexes that minimizes the costs of the input queries, subject to the storage limit. While greedy and other heuristic strategies for choosing views or indexes might help to some extent in improving the costs, it is highly nontrivial to arrive at a globally optimum solution, one that reduces th...|$|R
40|$|This {{paper is}} focused on the fault {{tolerance}} of Human Machine Interfaces in the field of air traffic control (ATC) by accepting the overall user's body language as input. We describe ongoing work in progress in the project called Sixth Sense. Interaction patterns are reasoned from the combination of a recommendation and inference engine, the analysis of several graph database relationships and from multiple sensor raw <b>data</b> <b>aggregations.</b> Altogether, these techniques allow us to judge about different possible meanings of the current user's interaction and cognitive state. The results obtained from applying different machine learning techniques will be used to make recommendations and predictions on the user's actions. They are currently monitored and rated by a human supervisor...|$|R
50|$|The OIX board {{represents}} {{leaders in}} online {{identity in the}} internet, telecom and <b>data</b> <b>aggregation</b> industries concerned with both market expansion and information security.|$|E
50|$|This {{is a form}} of in-network {{processing}} where sensor nodes {{are assumed}} to be unsecured with limited available energy, while the base station is assumed to be secure with unlimited available energy. Aggregation complicates the already existing security challenges for wireless sensor networks and requires new security techniques tailored specifically for this scenario. Providing security to aggregate data in wireless sensor networks is known as secure <b>data</b> <b>aggregation</b> in WSN. were the first few works discussing techniques for secure <b>data</b> <b>aggregation</b> in wireless sensor networks.|$|E
50|$|BCBS 239 is the Basel Committee on Banking Supervision's {{regulation}} number 239. The subject {{title of}} the regulation is:Principles for effective risk <b>data</b> <b>aggregation</b> and risk reporting.|$|E
40|$|The {{demand for}} meat has been {{estimated}} by many studies utilizing various data and estimation methods. In this study, we perform a meta-analysis of the income elasticity of meat that involves regressing 3357 estimated income elasticities, collected from 393 studies, on variables that control for study characteristics. Across several meta-regression specifications, we find significant differences in income elasticities tied {{to the type of}} meat being studied, as well as a few functional forms, <b>data</b> <b>aggregations,</b> publication characteristics, and locations of demand. However, many study characteristics do not significantly influence reported income elasticities. Less concern should be given to such characteristics when choosing an income elasticity from the literature. Copyright 2010 The Author. AJARE 2010 Australian Agricultural and Resource Economics Society Inc. and Blackwell Publishing Asia Pty Ltd. ...|$|R
50|$|The {{product data}} service is {{responsible}} for the storage of product specific data as well as the product <b>aggregation</b> <b>data.</b>|$|R
50|$|Service {{management}} {{features that}} orchestrate and automate over-the-air (OTA) vehicle software and data management; software and firmware updates; <b>data</b> collection, <b>aggregation,</b> and distribution; <b>data</b> and privacy settings; network connectivity and transmission optimization; IT system and software catalog integration; consumer notifications and prompts; and back-end service management portal.|$|R
