261|9782|Public
5000|$|... {{initialize}} network weights (often small random values) do forEach training example named ex prediction = neural-net-output(network, ex) // forward pass actual = teacher-output(ex) compute <b>error</b> (<b>prediction</b> - actual) at {{the output}} units compute [...] for all weights from hidden layer to output layer // backward pass compute [...] for all weights from input layer to hidden layer // backward pass continued update network weights // input layer not modified by error estimate until all examples classified correctly or another stopping criterion satisfied return the network ...|$|E
40|$|Validating TAFEI: {{reliability}} and validity of a human <b>error</b> <b>prediction</b> technique This paper reports on the theoretical and empirical developments for an <b>error</b> <b>prediction</b> methodology called Task analysis For Error Identification (TAFEI). Other researchers have noted the need for theoretically-driven approaches that are able to provide practical utility in <b>error</b> <b>prediction.</b> Theoretical developments include the concept of ‘rewritable routines’, that describes the loop between cognitive processing, action and devices states. This has been proposed as a way of unifying ideas from systems theory and cognitive psychology. The empirical research shows that TAFEI is superior to heuristic methods, which supports the idea that structured methods assist in <b>error</b> <b>prediction.</b> The validation study shows that TAFEI reaches acceptable levels in terms of test-retest {{reliability and}} concurrent validity. It is believed that the method has reached a level of maturity after ten years of development work. This is demonstrated by the many uses that the method has been put, including that of a design tool...|$|E
40|$|This {{paper is}} {{discusses}} {{the role of}} quality measures in biometric classification. We challenge a common notion that quality measures are performance predictors of the baseline biometric classifier. Instead, we postulate that quality measures are class-independent classification features, and as such are conditionally relevant class predictors. We present a systematic, probabilistic approach towards <b>error</b> <b>prediction</b> in biometric classification systems, where quality measures play an integral role in a stacked classifier ensemble. We demonstrate the results of <b>error</b> <b>prediction</b> in face verification using the proposed method. 1...|$|E
40|$|This article {{introduces}} two {{new types}} of <b>prediction</b> <b>errors</b> in time series: the filtered <b>prediction</b> <b>errors</b> and the deletion <b>prediction</b> <b>errors.</b> These two <b>prediction</b> <b>errors</b> are obtained in the same sample used for estimation, but {{in such a way}} that they share some common properties with out of sample <b>prediction</b> <b>errors.</b> It is proved that the filtered <b>prediction</b> <b>errors</b> are uncorrelated, up to terms of magnitude order O(T- 2), with the in sample innovations, a property that share with the out-of-sample <b>prediction</b> <b>errors.</b> On the other hand, deletion <b>prediction</b> <b>errors</b> assume that the values to be predicted are unobserved, a property that they also share with out-of-sample <b>prediction</b> <b>errors.</b> It is shown that these <b>prediction</b> <b>errors</b> can be computed with parameters estimated by assuming innovative or additive outliers, respectively, at the points to be predicted. Then the <b>prediction</b> <b>errors</b> are obtained by running the procedure for all the points in the sample of data. Two applications of these new <b>prediction</b> <b>errors</b> are presented. The first is the estimation and comparison of the <b>prediction</b> mean squared <b>errors</b> of competing predictors. The second is the determination of the order of an ARMA model. In the two applications the proposed filtered <b>prediction</b> <b>errors</b> have some advantages over alternative existing methods [...] ...|$|R
40|$|Measured {{sound power}} data from eight {{different}} spur, single and {{double helical gear}} designs are compared with <b>predictions</b> of transmission <b>error</b> by the Load Distribution Program. The sound power data {{was taken from the}} recent Army-funded Advanced Rotorcraft Transmission project. Tests were conducted in the NASA gear noise rig. Results of both test data and transmission <b>error</b> <b>predictions</b> are made for each harmonic of mesh frequency at several operating conditions. In general, the transmission <b>error</b> <b>predictions</b> compare favorably with the measured noise levels...|$|R
40|$|In this note, we {{analyze the}} {{relationship}} between one-step ahead <b>prediction</b> <b>errors</b> and interpolation errors in time series. We obtain {{an expression of the}} <b>prediction</b> <b>errors</b> in terms of the interpolation errors and then we show that minimizing the sum of squares of the one-step ahead standardized <b>prediction</b> <b>errors</b> is equivalent to minimizing the sum of squares of standardized interpolation errors. Fixed-point smoothing Interpolation <b>error</b> Kalman filter <b>Prediction</b> <b>error...</b>|$|R
40|$|This paper {{introduces}} SHERPA (Systematic Human Error Reduction and Prediction Approach) as a {{means for}} predicting pilot error. SHERPA was initially developed for predicting human error in the nuclear industry about 15 years ago. Since that time validation studies to support the continued use of SHERPA have been encouraging. Most research shows that SHERPA is amongst the best human <b>error</b> <b>prediction</b> tools available. Yet there is little research in the open literature of <b>error</b> <b>prediction</b> for cockpit tasks. This study attempts to provide some evidence for {{the reliability and validity of}} SHERPA in aviation domai...|$|E
40|$|This paper {{reports on}} the {{theoretical}} and empirical developments for an <b>error</b> <b>prediction</b> methodology called task analysis for error identification (TAFEI). Other researchers have noted the need for theoretically driven approaches {{that are able to}} provide practical utility in <b>error</b> <b>prediction.</b> Theoretical developments include the concept of 'rewritable routines', which describe the loop between cognitive processing, action and devices states. This has been proposed as a way of unifying ideas from systems theory and cognitive psychology. The empirical research shows that TAFEI is superior to heuristic methods, which supports the idea that structured methods assist in <b>error</b> <b>prediction.</b> The validation study shows that TAFEI reaches acceptable levels in terms of test - retest reliability and concurrent validity. It is believed that the method has reached a level of maturity after 10 years of development work. This is demonstrated by the many uses to which the method has been put, including that of a design tool...|$|E
3000|$|... (3) Estimating Occupancy with <b>Error</b> <b>Prediction</b> (EOwEP): Another {{method for}} finding the traffic flow class is {{extended}} version of EO. This method calculates occupancy estimators {{by adding the}} predicted error values.|$|E
40|$|Understanding <b>prediction</b> <b>errors</b> and {{determining}} {{how to fix}} them is critical to building effective predictive systems. In this paper, we delineate four types of <b>prediction</b> <b>errors</b> and demonstrate that these four types characterize all <b>prediction</b> <b>errors.</b> In addition, we describe potential remedies and tools {{that can be used}} to reduce the uncertainty when trying to determine the source of a <b>prediction</b> <b>error</b> and when trying to take action to remove a <b>prediction</b> <b>errors...</b>|$|R
40|$|A {{nonlinear}} modeling {{technique was}} used to characterize response surfaces for non-dimensional longitudinal aerodynamic force and moment coefficients, based on wind tunnel data from a commercial jet transport model. Data were collected using two experimental procedures - one based on modem design of experiments (MDOE), and one using a classical one factor at a time (OFAT) approach. The nonlinear modeling technique used multivariate orthogonal functions generated from the independent variable data as modeling functions in a least squares context to characterize the response surfaces. Model terms were selected automatically using a <b>prediction</b> <b>error</b> metric. <b>Prediction</b> <b>error</b> bounds computed from the modeling data alone were found to be- a good measure of actual <b>prediction</b> <b>error</b> for <b>prediction</b> points within the inference space. Root-mean-square model fit <b>error</b> and <b>prediction</b> <b>error</b> were less than 4 percent of the mean response value in all cases. Efficacy and prediction performance of the response surface models identified from both MDOE and OFAT experiments were investigated...|$|R
40|$|The {{equations}} of {{calculation of}} percentage <b>prediction</b> <b>error</b> ((percentage <b>prediction</b> <b>error</b> = frac(measured value - predicted value, measured value) × 100 or; percentage <b>prediction</b> <b>error</b> = frac(predicted value - measured value, measured value) × 100) and) similar equations {{have been widely}} used. However, not much {{is known about the}} property of this type of equation and the caution which should be taken into account when using this type of equation. Moreover, {{little is known about the}} power of percentage <b>prediction</b> <b>error</b> as statistical inference. In the present study we address these points in the use of this type of equation...|$|R
40|$|The Human Error Template (HET) is a {{recently}} developed methodology for predicting designed induced pilot error. This article describes a validation study undertaken {{to compare the}} performance of HET against three contemporary Human Error Identification (HEI) approaches when used to predict pilot errors for an approach and landing task and also to compare individual analyst error predictions to an approach to enhancing <b>error</b> <b>prediction</b> sensitivity: the multiple analysts and methods approach, whereby multiple analyst predictions using a range of HEI technique are pooled. The findings indicate that, of the four methodologies used in isolation, analysts using the HET methodology offered the most accurate error predictions, and also that the multiple analysts and methods approach was more successful overall in terms of <b>error</b> <b>prediction</b> sensitivity than the three other methods but not the HET approach. The results suggest that when predicting design induced error, {{it is appropriate to}} use domain specific approaches and also a toolkit of different HEI approaches and multiple analysts in order to heighten <b>error</b> <b>prediction</b> sensitivity...|$|E
30|$|On {{the basis}} of {{instrument}} <b>error</b> <b>prediction</b> methods, use modular least squares support vector machines to predict the error of inventory reconciliation and eliminate it subsequently. On the one hand, the feature extraction has been implemented for the independent variables by partial least squares regression. On the other hand, the problems of large computation and low accuracy for <b>error</b> <b>prediction</b> have been solved by using the modified fruit fly algorithm to optimize parameters of least squares support vector machine. Compared with other three different prediction methods, experiments show that the method of PLS and MFOA-LSSVM can predict the error of inventory reconciliation model effectively.|$|E
30|$|Aiming at {{the error}} of {{inventory}} reconciliation caused by different metering systems, the <b>error</b> <b>prediction</b> method of inventory reconciliation during storage and transportation process based on PLS and MFOA-LSSVM is proposed in the paper. This method uses PLS to achieve the goal of key factors feature extraction for inventory reconciliation model equations firstly. Then, {{in order to avoid}} falling into local optimum, LSSVM optimized by MFOA is adopted for modeling. Finally, the validity of the method is verified by the experiment of oil storage and transportation process on the advanced process control experimental platform. In order to simplify the calculation, the <b>error</b> <b>prediction</b> model is established when the pump frequency is 42.5  Hz.|$|E
3000|$|... are the {{estimation}} <b>error</b> covariance matrix, <b>prediction</b> <b>error</b> covariance matrix, and Kalman Gain, respectively; e [...]...|$|R
30|$|Embed a {{bit into}} the <b>prediction</b> <b>error</b> value using the <b>prediction</b> <b>error</b> {{expansion}} and histogram shift method.|$|R
5000|$|Accuracy of {{prediction}} at validation points: mean <b>prediction</b> <b>error</b> (MPE) {{and root}} mean square <b>prediction</b> <b>error</b> (RMSPE); ...|$|R
40|$|Human factors {{methods have}} a key {{role to play in}} the design and {{evaluation}} of battlefield technologies. This article presents an application of task analysis and <b>error</b> <b>prediction</b> methods for evaluating the usability of a new digitised battle management system. Based on data collected during live observation of an operational field trial of the battle management system, task and <b>error</b> <b>prediction</b> analyses were undertaken to identify usability issues. The analyses identified several issues, including general design flaws and a range of design-induced user errors. Recommendations for enhancing user interactions with the battle management system are specified. In closing, the key role that human factors methods have to play in the design and evaluation of battlefield technologies is discussed...|$|E
40|$|The NASA System-Wide Accident Prevention Program is {{intended}} to promote {{the development of new}} technologies to reduce accidents in aviation. Reducing human errors is a significant part of this effort. The Human Error Modeling element within this program is supporting this effort by focusing on the development and application of computer simulation and modeling tools for the prediction of human error. The goal of this particular research, headed by Micro Analysis & Design, is to look at existing human performance modeling architectures to determine their suitability for human <b>error</b> <b>prediction.</b> Specifically, this report reviews a diverse range of human performance modeling architectures to highlight the aspects of each that are most useful to <b>error</b> <b>prediction.</b> In addition, hybrid approaches are explored, where features from different modeling architectures are combined to enhance <b>error</b> <b>prediction</b> capabilities. A compilation of human error taxonomies was assembled in an attempt to define the scope of errors that human performance models would potentially need to predict. The taxonomies are predominantly conceptual in nature – they focus on understanding the cognitive process involved in the production of human error rather than describing the observable characteristic of the error. The four error taxonomies are...|$|E
40|$|The lofty goal of autonomous, onboard {{trajectory}} design motivates {{this investigation}} of automated patch point placement techniques. The motion of a particle {{affected by the}} gravitational fields of two massive particles moving on two concentric circular orbits, as defined in the Circular Restricted Three Body Problem (CR 3 BP), provides the dynamical environment for this study. Differential correctors are employed in converging multiple-segment trajectories subject to continuity and other constraints. A new approach for the Two-Level Corrector is derived and demonstrated. The relationship between Local Lyapunov Exponents (LLE) and the convergence behavior of parallel shooting targeters is explored, then formalized as an <b>error</b> <b>prediction</b> model. Lastly, an automated patch point placement algorithm is developed using that <b>error</b> <b>prediction</b> model. The placement algorithm is not restricted to the current error model, nor is the analysis restricted to the CR 3 BP. The <b>error</b> <b>prediction</b> model and patch point placement algorithm are applied to initial guesses obtained by randomly perturbing a viable solution, simulating the conditions used in deriving the error model. The patch point placement algorithm is then used in a sample design problem, demonstrating its ability to achieve convergence where arbitrary patch point placement causes the targeter to diverge. ...|$|E
3000|$|Mean {{absolute}} error (MAE): mean of absolute <b>errors</b> between estimated <b>prediction</b> <b>error</b> degrees and their true degrees [...]...|$|R
30|$|In this paper, large <b>prediction</b> <b>errors</b> mean errors {{for which}} {{absolute}} values of [Prediction error] are large. As stated above, since {{there might be}} large <b>prediction</b> <b>errors</b> in numerical weather prediction, meteorologists must constantly monitor observed data and compare them to the predicted values. Furthermore, when large <b>prediction</b> <b>errors</b> occur, meteorologists must also modify the forecast based on the obtained errors. Therefore, the development of methodologies for estimating large <b>prediction</b> <b>errors</b> is important to assist meteorologists who monitor observed data and modify the forecast. Although it is preferable to minimize the <b>prediction</b> <b>error</b> instead of predicting the error, the problem of minimization of the <b>prediction</b> <b>error</b> is as difficult as numerical weather prediction. Therefore, in this paper, we first focus on the easier problem.|$|R
50|$|As {{mentioned}} earlier, this architecture makes <b>error</b> <b>predictions</b> {{based on}} the amount of overlapping features. Such as, the most likely error for R should be P. Thus, in order to show this architecture represents the human pattern recognition system we must put these predictions into test. Researchers have constructed scenarios where various letters are presented in situations that make them difficult to identify; then types of errors were observed, which was used to generate confusion matrices: where all of the errors for each letter are recorded. Generally, the results from these experiments matched the <b>error</b> <b>predictions</b> from the pandemonium architecture. Also {{as a result of these}} experiments, some researchers have proposed models that attempted to list all of the basic features in the Roman alphabet.|$|R
40|$|Abstract — Timing {{margin of}} a chip varies chip by chip due to {{manufacturing}} variability, and depends on operating environment and aging. Adaptive speed control with timing <b>error</b> <b>prediction</b> is a promising approach {{to mitigate the}} timing margin variation, whereas it inherently has a critical risk of timing error occurrence when a circuit is slowed down. This paper presents how to evaluate the relation between timing error rate and power dissipation in self-adaptive circuits with timing <b>error</b> <b>prediction.</b> The discussion is experimentally validated using a 32 -bit ripple carry adder in subthreshold operation in a 90 nm CMOS process. We show a trade-off between timing error rate and power dissipation, and reveal the dependency of the trade-off on design parameters. I...|$|E
40|$|Abstract—This paper {{presents}} a new aging sensor architecture for <b>error</b> <b>prediction</b> of performance errors in synchronous digital circuits. The aging sensor {{is based on}} a new flip-flop with built-in logic that predicts the errors by monitoring long-term performance degradation of CMOS digital systems. The main advantage is that the sensor’s long-term degradation effects increase its sensitivity to performance <b>error</b> <b>prediction.</b> Moreover, the reduction of the power-supply voltage (V) and the increase of the temperature (T) also make the sensor to increase its sensitivity, making the sensor to adapt its monitoring capability with aging and VT variations. Performance failure prediction is implemented by the detection of late transitions at flip-flop data input, caused by aging (namely, due to NBTI), or to physical defects activated by long lifetime operation, or even by a worst-case operating condition (namely, V and/or T). Extensive SPICE simulations allowed achieving a new flip-flop with additional aging sensor capability, however with negligible performance degradation, because the sensing circuitry is out of the signal path. Simulation results are presented for two CMOS technologies (65 nm and 22 nm), using Berkeley Predictive Technology Models (PTM). It is shown that PVTA (Process, power supply Voltage, Temperature and Aging) variations on the sensor enhance <b>error</b> <b>prediction</b> capability. Keywords-aging sensor; performance failure prediction; NBTI; on-line monitoring. I...|$|E
40|$|Brain {{processing}} of reward information {{is essential for}} complex functions such as learning and motivation. Recent primate electrophysiological studies using concepts from information, economic and learning theories indicate that the midbrain may code two statistical parameters of reward information: a transient reward <b>error</b> <b>prediction</b> signal that varies linearly with reward probability and a sustained signal that varies highly non-linearly with reward probability and that is highest with maximal reward uncertainty (reward probability 5 0. 5). Here, using event-related functional magnetic resonance imaging, we disentangled these two signals in humans using a novel paradigm that systematically varied monetary reward probability, magnitude and expected reward value. The midbrain was activated both transiently with the <b>error</b> <b>prediction</b> signal and in a sustained fashion with reward uncertainty. Moreover, distinct activity dynamics were observed in postsynaptic midbrain projection sites: the prefrontal cortex responded to the transient <b>error</b> <b>prediction</b> signal while the ventral striatum covaried with the sustained reward uncertainty signal. These {{data suggest that the}} prefrontal cortex may generate the reward prediction while the ventral striatum may be involved in motivational processes that are useful when an organism needs to obtain more information about its environment. Our results indicate that distinct functional brain networks code different aspects of the statistical properties of reward information in humans...|$|E
40|$|The {{empirical}} Bayes estimators {{in mixed}} models {{are useful for}} small area estimation {{in the sense of}} increasing precision of prediction for small area means, and one wants to know the <b>prediction</b> <b>errors</b> of the empirical Bayes estimators based on the data. This paper is concerned with conditional <b>prediction</b> <b>errors</b> in the mixed models instead of conventional unconditional <b>prediction</b> <b>errors.</b> In the mixed models based on natural exponential families with quadratic variance functions, it is shown that the difference between the conditional and unconditional <b>prediction</b> <b>errors</b> is significant under distributions far from normality. Especially for the binomial-beta mixed and the Poisson-gamma mixed models, the leading terms in the conditional <b>prediction</b> <b>errors</b> are, respectively, a quadratic concave function and an increasing function of the direct estimate in the small area, while the corresponding leading terms in the unconditional <b>prediction</b> <b>errors</b> are constants. Second-order unbiased estimators of the conditional <b>prediction</b> <b>errors</b> are also derived and their performances are examined through simulation and empirical studies...|$|R
40|$|In this paper, a novel {{reversible}} video watermarking scheme using {{motion estimation}} and <b>prediction</b> <b>error</b> expansion is presented, which can embed {{a large amount}} of secret data into videos with imperceptible modification. Different with other reversible water-marking schemes based on <b>prediction</b> <b>error</b> expansion, motion estimation is employed to explore the relationship of neighboring frames and work out <b>prediction</b> <b>errors,</b> which sig-nificantly sharpen the distribution of <b>prediction</b> <b>errors.</b> Then histogram modification is used to expand the <b>prediction</b> <b>errors,</b> wherein a <b>prediction</b> <b>error</b> is changed by 1 or left un-changed for embedding one secret bit. Due to the slight modification of pixels, high video quality is preserved. In the phases of motion estimation and histogram modification, a lit-tle side information used for extracting and recovering are generated, which will be com-bined with the secret bits and embedded into the video. Experimental results demonstrate that the proposed scheme provides a much larger watermark capacity and a better quality of watermarked video than those of as reported in other state-of-the-art literature...|$|R
2500|$|Neurobiologically, neuromodulators like {{dopamine}} {{are considered}} to report the precision of <b>prediction</b> <b>errors</b> by modulating the gain of principal cells encoding <b>prediction</b> <b>error.</b> This {{is closely related to}} – but formally distinct from – the role of dopamine in reporting <b>prediction</b> <b>errors</b> per se [...] and related computational accounts.|$|R
40|$|We give a short {{proof of}} the {{following}} fact: sequential choice of linear functional observations in a Hilbert space context yields no benefit for mean square <b>error</b> <b>prediction</b> of a linear operator if the underlying distribution is elliptically contoured. Gaussian measures elliptically contoured measures prediction adaptation...|$|E
40|$|Abstract—This paper {{gives an}} {{overview}} of the English and Japanese CALL systems which have been developed at Kyoto University. Both systems incorporate automatic speech recognition (ASR) technologies to detect pronunciation errors. In order to cope with non-native speech, <b>error</b> <b>prediction</b> mechanisms are prepared based on linguistic knowledge and corpus-based decision tree learning. Several choices of acoustic modeling for non-native speech including erroneous pronunciations are also investigated. The English CALL system is designed for Japanese college students so that they can introduce Japanese cultures to foreign people, thus the acoustic model and <b>error</b> <b>prediction</b> are tuned to the specific native language (L 1 =Japanese). On the other hand, the Japanese CALL system is for foreign visitors of any L 1, and focuses on basic-level sentence production and adopts GUI for easy practice. I...|$|E
30|$|Process {{optimization}} and {{fault diagnosis}} technology, which {{is represented by}} production process monitoring, design and production condition adjustment, {{play an important role}} in the modern petroleum industry. Accurate inventory reconciliation model is the basis of process optimization and fault diagnosis. To eliminate the impact of the inventory reconciliation error caused by different metering systems, the <b>error</b> <b>prediction</b> method of inventory reconciliation during storage and transportation process based on partial least squares (PLS) and least squares support vector machine optimized by modified fruit fly optimization algorithm (MFOA-LSSVM) is proposed. The general <b>error</b> <b>prediction</b> method flow of inventory reconciliation is provided. The principles of PLS and MFOA-LSSVM are elaborated in detail. Firstly, the algorithm of PLS is used to exclude the interference of unrelated factors and extract the most relevant factors that influence the error of inventory reconciliation. Then the modified three-dimensional fruit fly optimization algorithm with diminishing steps as well as a good global search capability is adopted to select the LSSVM model parameters and build the <b>error</b> <b>prediction</b> model. Finally, the sample data were revised by using the predictive value to verify the validity of the proposed method. The experimental modeling was carried out by PLS and MFOA-LSSVM. Compared with other forecasting methods, this method not only has the advantage of faster calculations, but also can well predict the error of reconciliation.|$|E
40|$|About 30 {{years ago}} there was concern in both the beef and dairy {{industries}} that too much emphasis was being given to accuracy of genetic evaluation. This article will discuss attempts to reduce emphasis on accuracy and, thus increase emphasis on the predictor of genetic value itself which {{is commonly known as}} estimated breeding value (EBV). Accuracy is a key component of more useful measures of risk such as standard <b>error</b> of <b>prediction</b> which can be used to create confidence ranges in units of measurement for true breeding value based on the EBV and the standard <b>error</b> of <b>prediction.</b> The concept of standard <b>error</b> of <b>prediction</b> can be extended to comparison of pairs of EBV. The influence of genomic relationships and Bayesian analyses on accuracies and standard <b>errors</b> of <b>prediction</b> will also be briefly introduced...|$|R
40|$|Individuals {{can learn}} by {{interacting}} with the environment and experiencing a difference between predicted and obtained outcomes (<b>prediction</b> <b>error).</b> However, many species also learn by observing the actions and outcomes of others. In contrast to individual learning, observational learning cannot be based on directly experienced outcome <b>prediction</b> <b>errors.</b> Accordingly, the behavioral and neural mechanisms of learning through observation remain elusive. Here we propose that human observational learning {{can be explained by}} two previously uncharacterized forms of <b>prediction</b> <b>error,</b> observational action <b>prediction</b> <b>errors</b> (the actual minus the predicted choice of others) and observational outcome <b>prediction</b> <b>errors</b> (the actual minus predicted outcome received by others). In a functional MRI experiment, we found that brain activity in the dorsolateral prefrontal cortex and the ventromedial prefrontal cortex respectively corresponded to these two distinct observational learning signals...|$|R
40|$|<b>Error</b> <b>Predictions</b> is a {{preliminary}} document {{based on the}} theoretical predictions of Omega signal strengths and VLF noise level in the equatorial regions. Only limited empirical verification is included, essentially at Majuro in the Marshall Islands. The accuracy of the wind <b>error</b> <b>predictions</b> is now being evaluated from experimental data recently made available from the Indian Ocean region. These data {{will be used to}} improve the theoretical model and confirm whether or not the processors used in these experiments were operating near theoretical performance levels. Therefore, the results presented in this document should be used with some reservations. As {{a preliminary}} guide {{it can be said that}} the Indian Ocean data suggest that the analytical wind error model is more representative of the real world than the Majuro data-fitted model...|$|R
