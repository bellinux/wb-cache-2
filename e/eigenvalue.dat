10000|10000|Public
25|$|The {{geometric}} multiplicity γ'T(λ) of an <b>eigenvalue</b> λ is {{the dimension}} of the eigenspace associated with λ, i.e., {{the maximum number of}} linearly independent eigenvectors associated with that <b>eigenvalue.</b> By the definition of eigenvalues and eigenvectors, γ'T(λ) ≥ 1 because every <b>eigenvalue</b> has at least one eigenvector.|$|E
25|$|If μ'A(λ'i) = 1, then λ'i {{is said to}} be {{a simple}} <b>eigenvalue.</b> If μ'A(λ'i) equals the {{geometric}} multiplicity of λ'i, γ'A(λ'i), defined in the next section, then λ'i {{is said to be}} a semisimple <b>eigenvalue.</b>|$|E
25|$|The {{algebraic}} {{multiplicity of}} each <b>eigenvalue</b> is 2; {{in other words}} they are both double roots. The sum of the algebraic multiplicities of each distinct <b>eigenvalue</b> is μ'A = 4 = n, {{the order of the}} characteristic polynomial and the dimension of A.|$|E
40|$|We {{consider}} the Steklov <b>eigenvalues</b> of the Laplace operator as limiting Neumann <b>eigenvalues</b> in {{a problem of}} mass concentration at the boundary of a ball. We discuss the asymptotic behaviour of the Neumann <b>eigenvalues</b> and find explicit formulae for their derivatives in the limiting problem. We deduce that the Neumann <b>eigenvalues</b> have a monotone behaviour in the limit and that Steklov <b>eigenvalues</b> locally minimize the Neumann <b>eigenvalues...</b>|$|R
3000|$|Discrete <b>eigenvalues</b> {{are given}} by {{analytic}} functions, E_j(θ [...]). Since changing Re θ provides unitarily equivalent H’s, E_j(θ [...]) is constant under changes of Re θ, so constant by analyticity. We conclude that {{so long as}} discrete <b>eigenvalues</b> avoid S_θ, they remain discrete <b>eigenvalues</b> of H(θ [...]). In particular, negative <b>eigenvalues</b> of H are <b>eigenvalues</b> of H(θ [...]) if |Im θ | < π 2. An additional argument shows that embedded positive <b>eigenvalues</b> become discrete <b>eigenvalues</b> of H(θ [...]) for Im θ∈ (0,π 2).|$|R
40|$|Second order {{statistics}} estimates {{in the form}} of sample <b>eigenvalues</b> and sample eigenvectors give a sub optimal description of the population density. So far only {{attempts have been made to}} reduce the bias in the sample <b>eigenvalues.</b> However, because the sample eigenvectors differ from the population eigenvectors as well, the population <b>eigenvalues</b> are biased estimates of the variances along the sample eigenvectors. Therefore correction of the sample <b>eigenvalues</b> towards the population <b>eigenvalues</b> is not sufficient. The experiments in this paper show that replacing the sample <b>eigenvalues</b> with the variances along the sample eigenvectors often results in better estimates of the population density than replacing the sample <b>eigenvalues</b> with the population <b>eigenvalues...</b>|$|R
25|$|Let λ'i be an <b>eigenvalue</b> of an n by n matrix A. The {{algebraic}} multiplicity μ'A(λ'i) of the <b>eigenvalue</b> is its multiplicity as a root of {{the characteristic}} polynomial, that is, the largest integer k such that (λ − λ'i)k divides evenly that polynomial.|$|E
25|$|This {{equation}} {{is called the}} <b>eigenvalue</b> equation for T, and the scalar λ is the <b>eigenvalue</b> of T corresponding to the eigenvector v. Note that T(v) {{is the result of}} applying the transformation T to the vector v, while λv is the product of the scalar λ with v.|$|E
25|$|In the meantime, Liouville studied <b>eigenvalue</b> {{problems}} {{similar to}} those of Sturm; the discipline that grew out of their work is now called Sturm–Liouville theory. Schwarz studied the first <b>eigenvalue</b> of Laplace's equation on general domains {{towards the end of the}} 19th century, while Poincaré studied Poisson's equation a few years later.|$|E
3000|$|The product across modes {{increases}} {{the gap between}} the predicted and the actual <b>eigenvalues</b> as shown in Figure 1. We compare {{the gap between the}} actual <b>eigenvalues</b> and the predicted <b>eigenvalues</b> in the r th mode to the gap between the actual global <b>eigenvalues</b> and the predicted global <b>eigenvalues.</b> Here, we consider that [...]...|$|R
40|$|Abstract: Two {{standard}} matrix {{representations of}} a graph are the adjacency matrix and the Laplace matrix. The <b>eigenvalues</b> of these matrices are interesting {{parameters of the}} graph. Graphs with few <b>eigenvalues</b> in general have nice combinatorial properties and a rich structure. A well investigated family of such graphs comprises the strongly regular graphs (the regular graphs with three <b>eigenvalues),</b> and we may see other graphs with few <b>eigenvalues</b> as algebraic generalizations of such graphs. We study the (nonregular) graphs with three adjacency <b>eigenvalues,</b> graphs with three Laplace <b>eigenvalues,</b> and regular graphs with four <b>eigenvalues.</b> The last ones are also studied in relation with three-class association schemes. We also derive bounds on the diameter and {{on the size of}} special subsets in terms of the <b>eigenvalues</b> of the graph. Included are lists of feasible parameter sets of graphs with three Laplace <b>eigenvalues,</b> regular graphs with four <b>eigenvalues,</b> and three-class association schemes. ...|$|R
40|$|We {{consider}} the Steklov <b>eigenvalues</b> of the Laplace operator as limiting Neumann <b>eigenvalues</b> in {{a problem of}} boundary mass concentration. We discuss the asymptotic behavior of the Neumann <b>eigenvalues</b> in a ball and we deduce that the Steklov <b>eigenvalues</b> minimize the Neumann <b>eigenvalues.</b> Moreover, we study the dependence of the <b>eigenvalues</b> of the Steklov problem upon perturbation of the mass density and show that the Steklov <b>eigenvalues</b> violates a maximum principle in spectral optimization problems. Comment: This is a preprint version of a paper that {{will appear in the}} Proceedings of the 9 th ISAAC Congress, Kraków 201...|$|R
25|$|The number 0 {{is not an}} <b>eigenvalue</b> of A.|$|E
25|$|Lambda {{indicates}} an <b>eigenvalue</b> in the mathematics of linear algebra.|$|E
25|$|Both {{one-dimensional}} and multi-dimensional <b>eigenvalue</b> {{problems can}} be formulated as variational problems.|$|E
40|$|AbstractGood approximations of <b>eigenvalues</b> {{exist for}} the regular square and {{hexagonal}} tessellations. To complement this situation, spatial scientists need good approximations of <b>eigenvalues</b> for irregular tessellations. Starting from known or approximated extreme <b>eigenvalues,</b> the remaining <b>eigenvalues</b> may be in turn approximated. One reason spatial scientists are interested in <b>eigenvalues</b> {{is because they are}} needed to calculate the Jacobian term in the autonormal probability model. If <b>eigenvalues</b> are not needed for model fitting, good approximations are needed to give the interval within which the spatial parameter will lie...|$|R
40|$|The {{study on}} limit points of <b>eigenvalues</b> of undirected graphs was {{initiated}} by A. J. Hoffman in 1972. Now we extend {{the study to}} digraphs. We prove: 1. Every real number is a limit point of <b>eigenvalues</b> of graphs. Every complex number is a limit point of <b>eigenvalues</b> of digraphs. 2. For a digraph D, the set of limit points of <b>eigenvalues</b> of iterated subdivision digraphs of D is the unit circle in the complex plane {{if and only if}} D has a directed cycle. 3. Every limit point of <b>eigenvalues</b> of a set D of digraphs (graphs) is a limit point of <b>eigenvalues</b> of a set of bipartite digraphs (graphs), where consists of the double covers of the members in D. 4. Every limit point of <b>eigenvalues</b> of a set D of digraphs is a limit point of <b>eigenvalues</b> of line digraphs of the digraphs in D. 5. If M is a limit point of the largest <b>eigenvalues</b> of graphs, then -M is a limit point of the smallest <b>eigenvalues</b> of graphs...|$|R
40|$|The non-Hermitian PT-symmetric quantum-mechanical Hamiltonian H=p^ 2 +x^ 2 (ix) ^ϵ has real, positive, and {{discrete}} <b>eigenvalues</b> for all ϵ≥ 0. These <b>eigenvalues</b> are analytic continuations of {{the harmonic}}-oscillator <b>eigenvalues</b> E_n= 2 n+ 1 (n= 0, 1, 2, 3, [...] .) at ϵ= 0. However, the harmonic oscillator also has negative <b>eigenvalues</b> E_n=- 2 n- 1 (n= 0, 1, 2, 3, [...] .), and one may ask {{whether it is}} equally possible to continue analytically from these <b>eigenvalues.</b> It is shown in this paper that for appropriate PT-symmetric boundary conditions the Hamiltonian H=p^ 2 +x^ 2 (ix) ^ϵ also has real and negative discrete <b>eigenvalues.</b> The negative <b>eigenvalues</b> fall into classes labeled by the integer N (N= 1, 2, 3, [...] .). For the Nth class of <b>eigenvalues,</b> ϵ lies in the range (4 N- 6) / 3 <ϵ< 4 N- 2. At the low and high ends of this range, the <b>eigenvalues</b> are all infinite. At the special intermediate value ϵ= 2 N- 2 the <b>eigenvalues</b> are the negatives of those of the conventional Hermitian Hamiltonian H=p^ 2 +x^ 2 N. However, when ϵ≠ 2 N- 2, there are infinitely many complex <b>eigenvalues.</b> Thus, while the positive-spectrum sector of the Hamiltonian H=p^ 2 +x^ 2 (ix) ^ϵ has an unbroken PT symmetry (the <b>eigenvalues</b> are all real), the negative-spectrum sector of H=p^ 2 +x^ 2 (ix) ^ϵ has a broken PT symmetry (only some of the <b>eigenvalues</b> are real). Comment: 12 pages, 8 figure...|$|R
25|$|The {{passage from}} real to complex {{is similar to}} the <b>eigenvalue</b> case.|$|E
25|$|They {{are also}} eigenfunctions (with <b>eigenvalue</b> (i)n) of the {{continuous}} Fourier transform.|$|E
25|$|If A is unitary, every <b>eigenvalue</b> has {{absolute}} value |λ'i| = 1.|$|E
3000|$|... [...]) be the {{positive}} and negative <b>eigenvalues</b> of A, respectively, where r and s denote the number of positive <b>eigenvalues</b> and zero <b>eigenvalues</b> of A (counted by multiplicity), respectively. Moreover, we denote by q the number of negative <b>eigenvalues</b> of A (counted by multiplicity). We make the following assumption: [...]...|$|R
30|$|The minimax {{principle}} of the <b>eigenvalues,</b> i.e. equation (45) for the <b>eigenvalues</b> {{makes it possible to}} study the dependence of the <b>eigenvalues</b> on the coefficients of the differential equation. In this section we shall establish the monotonicity of the <b>eigenvalues</b> with respect to the potential q(x) for fixed boundary-transmission conditions.|$|R
50|$|For {{the zero}} matrix and the {{identity}} matrix, the spread is zero. The zero matrix has only zero as its <b>eigenvalues,</b> and the identity matrix {{has only one}} as its <b>eigenvalues.</b> In both cases, all <b>eigenvalues</b> are equal, so no two <b>eigenvalues</b> can be at nonzero distance from each other.|$|R
25|$|If λ is an <b>eigenvalue</b> of T, {{then the}} {{operator}} (T − λI) is not one-to-one, and therefore its inverse (T − λI)−1 does not exist. The converse {{is true for}} finite-dimensional vector spaces, but not for infinite-dimensional vector spaces. In general, the operator (T − λI) may not have an inverse even if λ is not an <b>eigenvalue.</b>|$|E
25|$|The matrix A is {{invertible}} if {{and only}} if every <b>eigenvalue</b> is nonzero.|$|E
25|$|Then {{there is}} only one <b>eigenvalue,</b> , and its {{algebraic}} multiplicity is m = 2.|$|E
40|$|In this paper, a {{fundamentally}} new method, {{based on the}} denition, is introduced for numerical computation of <b>eigenvalues,</b> generalized <b>eigenvalues</b> and quadratic <b>eigenvalues</b> of matrices. Some examples are provided to show the accuracy and reliability of the proposed method. It is shown that the proposed method gives other sequences than that of existingmethods but they still are convergent to the desired <b>eigenvalues,</b> generalized <b>eigenvalues</b> and quadratic <b>eigenvalues</b> of matrices. These examples show an interesting phenomenon in the procedure: The diagonal matrix that converges to <b>eigenvalues</b> gives them in decreasing order {{in the sense of}} absolute value. Appendices A to C provide Matlab codes that implement the proposed algorithms. They show that the proposed algorithms are very easy to progra...|$|R
40|$|AbstractWe study {{singular}} left-definite Sturm–Liouville {{problems with}} an indefinite weight function. The existence of <b>eigenvalues</b> is established {{based on the}} existence of <b>eigenvalues</b> of corresponding right-definite problems. Furthermore, for each singular left-definite problem with limit-circle non-oscillatory endpoints we construct a regular left-definite problem with the same <b>eigenvalues</b> and use it to obtain properties of <b>eigenvalues</b> and eigenfunctions. Inequalities among <b>eigenvalues</b> recently established for regular left-definite problems are extended to the singular case...|$|R
50|$|It {{may seem}} strange to {{consider}} only real <b>eigenvalues,</b> since in linear algebra the <b>eigenvalues</b> of a matrix with all real entries can have complex <b>eigenvalues.</b> In geometric algebra, however, the blades of different grades can exhibit a complex structure. Since both vectors and pseudovectors {{can act as}} eigenblades, they may each {{have a set of}} <b>eigenvalues</b> matching the degrees of freedom of the complex <b>eigenvalues</b> that would be found in ordinary linear algebra.|$|R
25|$|Proof. Case I: all {{operators}} have {{exactly one}} <b>eigenvalue.</b> Then any basis for H will do.|$|E
25|$|The {{condition}} that γ'A(λ) ≤ μ'A(λ) can be proven by considering a particular <b>eigenvalue</b> ξ of A and diagonalizing the first γ'A(ξ) columns of A {{with respect to}} the eigenvectors of ξ, described in a later section. The resulting similar matrix B is block upper triangular, with its top left block being the diagonal matrix ξI'γ'A(ξ). As a result, the characteristic polynomial of B will have a factor of (ξ−λ)γ'A(ξ). The other factors of the characteristic polynomial of B are not known, so the algebraic multiplicity of ξ as an <b>eigenvalue</b> of B is no less than the geometric multiplicity of ξ as an <b>eigenvalue</b> of A. The last element of the proof is the property that similar matrices have the same characteristic polynomial.|$|E
25|$|A is {{diagonalizable}} if {{and only}} if, for every <b>eigenvalue</b> λ of A, its geometric and algebraic multiplicities coincide.|$|E
5000|$|Extraction sums of squared loadings: Initial <b>eigenvalues</b> and <b>eigenvalues</b> after {{extraction}} (listed by SPSS as [...] "Extraction Sums of Squared Loadings") are {{the same}} for PCA extraction, but for other extraction methods, <b>eigenvalues</b> after extraction will be lower than their initial counterparts. SPSS also prints [...] "Rotation Sums of Squared Loadings" [...] and even for PCA, these <b>eigenvalues</b> will differ from initial and extraction <b>eigenvalues,</b> though their total will be the same.|$|R
5000|$|The {{trace of}} [...] {{is equal to}} the sum of its <b>eigenvalues.</b> Because the rank of [...] is at most , and it is a {{positive}} semidefinite matrix, [...] has at most [...] positive <b>eigenvalues</b> with its remaining <b>eigenvalues</b> all equal to zero. Writing the non-zero <b>eigenvalues</b> of [...] as [...] with [...] and applying the Cauchy-Schwarz inequality to the inner product of an -vector of ones with a vector whose components are these <b>eigenvalues</b> yields ...|$|R
30|$|The {{dependence}} of <b>eigenvalues</b> {{with respect to}} the data {{plays an important role in}} the theory of differential operators. It gives theoretical support for the numerical computation of <b>eigenvalues.</b> Moreover, the properties of monotonicity of <b>eigenvalues</b> {{with respect to the}} parameters can be obtained by the derivatives of <b>eigenvalues</b> on the given parameter.|$|R
