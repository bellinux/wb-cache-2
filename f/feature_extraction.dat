10000|1286|Public
5|$|The <b>feature</b> <b>extraction</b> using {{speeded up}} robust {{features}} (SURF) is {{also able to}} perform the inspection of certain elements having two possible states, such as pitot probes or static ports being covered or not covered. A pairing is performed between images of the element to be inspected in different states and that present on the scene. For these simple items to be inspected, an analysis during navigation is possible and preferable due to its time saving.|$|E
25|$|Image pre-processing, and <b>feature</b> <b>extraction</b> and {{classification}} are {{two main}} stages of these CAD algorithms.|$|E
25|$|In 2011, Wu and Wang {{proposed}} using DWT for <b>feature</b> <b>extraction,</b> PCA for feature reduction, and FNN with scaled chaotic artificial {{bee colony}} (SCABC) as classifier.|$|E
40|$|This paper {{deals with}} {{temporal}} segmentation of acoustic signals and <b>features</b> <b>extraction.</b> Segmentation and <b>features</b> <b>extraction</b> {{are aimed at}} being a first step for sound signal representation, coding, transformation, indexation and multimedia. Three interdependent schemes of segmentation are defined, which correspond to different levels of signal attributes. A complete segmentation and <b>features</b> <b>extraction</b> system is shown. Applications and results on various examples are presented. The paper is divided into four sections: a definition of the segmentation schemes; and description of the techniques used for each of them...|$|R
40|$|We present {{two studies}} on {{robustness}} of <b>feature</b> <b>extractions</b> for an remote classroom intelligent autopilot: (1) robust fea-ture extractions and (2) a simple automated calibration of we-bcams. For the robust <b>feature</b> <b>extractions,</b> use of quantified vectors is studied as <b>feature</b> <b>extractions</b> of fuzzy classifiers in Perceptual State Machine, i. e. our core Computational Intel-ligence model for this intelligent autopilot. The simple auto-mated calibration of devices is studied mainly {{for the sake}} of maximizing device utility. Those studies have shown promis-ing results for actual use of this intelligent autopilot in ordi-nary classrooms that are not necessarily ideal for teleconfer-ence lectures...|$|R
30|$|The HOG and color-based <b>features</b> <b>extraction</b> will be {{described}} in the next section.|$|R
25|$|A 2D or {{primal sketch}} of the scene, based on <b>feature</b> <b>extraction</b> of {{fundamental}} components of the scene, including edges, regions, etc. Note the similarity in concept to a pencil sketch drawn quickly by an artist as an impression.|$|E
25|$|Non-uniform {{illumination}} correction is {{a technique}} that adjusts for non-uniform illumination in fundoscopic image. Non-uniform illumination can be a potential error in automated detection of diabetic retinopathy because of changes in statistical characteristics of image. These changes can affect latter processing such as <b>feature</b> <b>extraction</b> and are not observable by humans. Correction of non-uniform illumination (f') {{can be achieved by}} modifying the pixel intensity using known original pixel intensity (f), and average intensities of local (λ) and desired pixels (μ) (see formula below). Walter-Klein transformation is then applied to achieve the uniform illumination. This technique is the least used pre-processing method in the review from 2014.|$|E
2500|$|Emerging data mining, <b>feature</b> <b>extraction,</b> {{image and}} video processing, and human-computer {{interaction}} applications ...|$|E
40|$|Abstract—In {{order to}} improve the {{recognition}} rate, this document proposes an automatic system to recognize isolated printed Tifinagh characters by using a fusion of 3 classifiers and a combination of some <b>features</b> <b>extraction</b> methods. The Legendre moments, Zernike moments and Hu moments are used as descriptors in the <b>features</b> <b>extraction</b> phase due to their invariance to translation, rotation and scaling changes. In the classification phase, the neural network, the multiclass SVM (Support Vector Machine) and the nearest neighbour classifiers are combined together. The experimental results of each single <b>features</b> <b>extraction</b> method and each single classification method are compared with our approach to show its robustness...|$|R
40|$|In {{computer}} vision {{all of the}} existing researches are interested in synthetic images <b>features</b> <b>extraction.</b> Theses images contain many types of features. Indeed, the features are classified in 1 D feature (step, roof…) and 2 D features (corners). Nevertheless, some approaches interest {{in the study of}} real images. Moreover, the satellite images are one most complex real image. It presents a widespread real application (weather, military…). Accordingly, many researches are developed in this way. The satellite images present a great variety of features due to the trouble what returns their treatment is little delicate. In this paper, we introduce a new application of phase congruency model for <b>features</b> <b>extraction</b> in satellite images. The aim {{of this paper is to}} exploit the advantages and the limitations of this model applied in satellite images <b>features</b> <b>extraction.</b> On the other hand, two smoothing algorithms are used to improve the <b>features</b> <b>extraction</b> procedure. Key words: Satellite images, phase congruency model, smoothing algorith...|$|R
30|$|Comparative {{analysis}} of BRISK and ORB algorithm {{in the same}} scale rotating 90 ° image <b>feature</b> point <b>extraction</b> and different scale scaling 50 % and rotating 90 ° image <b>feature</b> point <b>extraction</b> time, <b>feature</b> point <b>extraction</b> number, accuracy, etc.|$|R
2500|$|Dimensionality {{reduction}} [...] {{the process}} of {{reducing the number of}} random variables under consideration, and can be divided into feature selection and <b>feature</b> <b>extraction.</b>|$|E
2500|$|Kinect {{was first}} {{announced}} on June 1, 2009 at E3 2009 under the code name [...] "Project Natal". Three demos {{were shown to}} showcase Kinect when it was revealed at Microsoft's E3 2009 Media Briefing: Ricochet, Paint Party and Milo & Kate. A demo based on Burnout Paradise was also shown outside of Microsoft's media briefing. The skeletal mapping technology shown at E3 2009 was capable of simultaneously tracking four people, with a <b>feature</b> <b>extraction</b> of 48 skeletal points on a human body at 30Hz.|$|E
2500|$|Described by Microsoft {{personnel}} as {{the primary}} innovation of Kinect, the software technology enables advanced gesture recognition, facial recognition and voice recognition. According to information supplied to retailers, Kinect is capable of simultaneously tracking up to six people, including two active players for motion analysis with a <b>feature</b> <b>extraction</b> of 20 joints per player. However, PrimeSense has stated {{that the number of}} people the device can [...] "see" [...] (but not process as players) is only limited by how many will fit in the field-of-view of the camera.|$|E
40|$|International audienceWe {{present a}} Multiscale Convolutional Neural Network (MCNN) {{approach}} for vision-based classification of cells. Based on several deep Convolutional Neural Networks (CNN) acting at different resolutions, the proposed architecture avoid the classical handcrafted <b>features</b> <b>extraction</b> step, by processing <b>features</b> <b>extraction</b> and classification as a whole. The proposed approach gives better classification rates than classical state-of-the-art methods allowing a safer Computer-Aided Diagnosis of pleural cancer...|$|R
40|$|The most {{important}} stages of Automatic Fingerprint Identification System (AFIS) are enhancement stage, <b>features</b> <b>extraction</b> stage, and matching stage. The {{main purpose of}} the enhancement stage {{is to increase the}} clarity of the fingerprint image, convert poor quality image to good quality image, and prepare the image for <b>features</b> <b>extraction</b> stage. Both of the two last stages (<b>features</b> <b>extraction</b> & matching stage) depend heavily on the enhancement stage, therefore this paper focus on the enhancement stage. Practically most of the input fingerprint images are corrupted by noise, body conditions, and environmental factors. Therefore it is necessary to use an effectively enhancement method. This paper present new efficient fingerprint image enhancement algorithm works by performing threshold on Fast Discrete Curvelet Transfor...|$|R
40|$|This paper {{proposed}} {{the use of}} multimodal feature-level fusion to prove the improvement performance of multimodal authentication. Different algorithm used for <b>features</b> <b>extraction,</b> LG for extracting FKP features, LPQ for iris and Palmprint <b>features</b> <b>extraction,</b> and PCA for extracting face features. Results brought to light that the multimodal authentication process gained higher performance than single modality. The biometric performance using feature-level fusions under “Z-score”, “Tanh”, “Median”, and Min-Max normalization has been demonstrated in this paper...|$|R
50|$|Summarization {{of media}} content (<b>feature</b> <b>extraction).</b> The result of <b>feature</b> <b>extraction</b> is a description.|$|E
5000|$|The second {{context in}} which chessboards arise in {{computer}} vision is to demonstrate several canonical <b>feature</b> <b>extraction</b> algorithms. In <b>feature</b> <b>extraction,</b> one seeks to identify image interest points, which summarize the semantic content of an image and, hence, offer a reduced dimensionality representation of one's data. Chessboards - in particular - are often used to demonstrate <b>feature</b> <b>extraction</b> algorithms because their regular geometry naturally exhibits local image features like edges, lines, and corners. The following sections demonstrate the application of common <b>feature</b> <b>extraction</b> algorithms to a [...]|$|E
50|$|Techniques to {{transform}} the raw feature vectors (<b>feature</b> <b>extraction)</b> are sometimes used prior to application of the pattern-matching algorithm. For example, <b>feature</b> <b>extraction</b> algorithms attempt to reduce a large-dimensionality feature vector into a smaller-dimensionality vector that is easier {{to work with and}} encodes less redundancy, using mathematical techniques such as principal components analysis (PCA). The distinction between feature selection and <b>feature</b> <b>extraction</b> is that the resulting features after <b>feature</b> <b>extraction</b> has taken place are of a different sort than the original features and may not easily be interpretable, while the features left after feature selection are simply a subset of the original features.|$|E
30|$|After the textural <b>features</b> <b>extraction,</b> the {{following}} <b>features</b> assessment parameter are also {{required to be}} obtained for better analysis on brain MRI images.|$|R
5000|$|... bonzaiboost, a fast (and multi-threaded) C++ {{implementation}} of multi-class/multi-label Adaboost.MH algorithm over small decision tree (bonsai). It offers several text <b>features</b> <b>extraction</b> facilities.|$|R
5000|$|Intelligent systems Supervised and {{unsupervised}} learning; <b>Features</b> <b>extraction</b> and selection; Recurrent networks (RC, ESN); Convolutional neural Networks; Deep learning; Classification and regression real-world problems.|$|R
5000|$|... #Caption: Fig.1 General HPCP <b>feature</b> <b>extraction</b> {{block diagram}} ...|$|E
5000|$|... #Subtitle level 3: Document {{processing}} and <b>feature</b> <b>extraction</b> ...|$|E
5000|$|<b>Feature</b> <b>extraction,</b> such as image {{understanding}} and speech recognition.|$|E
30|$|Another major trend, in the aging-related facial <b>features</b> <b>extraction,</b> {{focuses on}} the use of an {{appearance}} model that can be handled as a global or local <b>features</b> <b>extraction</b> issue. The first attempts in this research line were in [72, 73] where texture and shape features were jointly exploited to increase the descriptor robustness in order to estimate the human ages through a multiple-group classification scheme with 5 -year intervals taking also advantage from the gender knowledge (since the aging patterns are different for males and females). Successively, the interest in appearance-based descriptors arose exponentially and LBP was used for appearance <b>features</b> <b>extraction</b> in an automatic age estimation system proposed in [74], whereas some variants were proposed and tested in [75, 76]. Gabor features were also tried for age estimation purposes [77] demonstrating their discriminative power. BIF [78, 79] in aging problems were also explored by Guo et al. in [80] and Lian et al. in [81].|$|R
40|$|Abstract — Unlike occidental flutes, Arabian flutes {{have gained}} only limited {{attention}} in literature {{over the past}} years. Moreover, the least tone-to-tone distance in Arabian music is only half of that of occidental music and therefore the analysis and <b>features</b> <b>extraction</b> process of Arabian music is more challenging. This paper investigates the tone-to-tone features of two traditional Arabian flutes; Al-Nay and Shabbaba. These two kinds of flute gain wide popularity in the Middle Eastern and North African countries. A previously reported analysis and <b>features</b> <b>extraction</b> package is adapted and used for query-by –playing melody retrieval. Experimental tone-to-tone investigations based on the Discrete Fourier Transform (DFT) are presented for both flutes. The obtained {{results showed that the}} analysis approach is robust and successfully performed the task of query-by –playing melody retrieval. Comparison results for Al-Nay and Shabbaba were obtained and evaluated using the Arabian musical Scale “Bayat”, as a reference. Index Terms — Arabian flute, automatic music transcription, <b>features</b> <b>extraction,</b> music information retrieval, time-frequency analysis. I...|$|R
40|$|Texture <b>features</b> <b>extraction</b> {{algorithms}} are key {{functions in}} various image processing {{applications such as}} medical images, remote sensing, and content-based image retrieval. The most common way to extract texture features {{is the use of}} Gray Level Co-occurrence Matrices (GLCMs). The GLCM contains the second-order statistical information of spatial relationship of the pixels of an image. Haralick texture features are extracted using these GLCMs. However, the GLCMs and Haralick texture <b>features</b> <b>extraction</b> algorithms are computationally intensive. In this paper, we apply different parallel techniques such as task- and data-level parallelism to exploit available parallelism of those applications on the Cell multi-core processor. Experimental results have shown that our parallel implementations using 16 Synergistic Processor Elements significantly reduce the computational times of the GLCMs and texture <b>features</b> <b>extraction</b> algorithms by a factor of 10 × over non-parallel optimized implementations for different image sizes from 128 × 128 to 1024 × 1024. Software Computer TechnologyElectrical Engineering, Mathematics and Computer Scienc...|$|R
5000|$|Compared to {{classical}} <b>feature</b> <b>extraction</b> techniques, snakes have multiple advantages: ...|$|E
5000|$|... 2000 - Stereo Analyst 1.0 (module for stereo <b>feature</b> <b>extraction)</b> ...|$|E
5000|$|The General HPCP <b>feature</b> <b>extraction</b> {{procedure}} is summarized as follows: ...|$|E
50|$|The {{prototype}} processor included eight <b>featured</b> <b>extraction</b> using kiss_fft, a Fast Fourier Transform {{library to}} derive frequency-domain features while also providing a recognition module that implemented a decision tree algorithm.|$|R
40|$|Ultrasound {{systems can}} be {{enhanced}} to combine 3 D data and corresponding spatial information. This approach, called 3 D freehand Ultrasound (3 DFUS), uses ultrasound (US) images and the corresponding pose of the transducer {{with the purpose of}} reconstructing the 3 D morphology for large anatomical parts. So far, this 3 D reconstruction has only limited clinical use as the procedure is not widely accessible and <b>features</b> <b>extraction</b> is very time consuming. Our current work is aimed at developing a new tool for image reconstruction and to optimizing the <b>features</b> <b>extraction</b> process in 3 DFUS. status: accepte...|$|R
40|$|Abstract: The {{performance}} of the fingerprint identification process highly depends on its extractor of fingerprint features. So, to reduce the dimensionality of the fingerprint image and improve the identification rate, a fingerprint <b>features</b> <b>extraction</b> method based on Curvelet transform is proposed and presented in this paper. Thus, our paper focuses on presenting of our Curvelet-based fingerprint <b>features</b> <b>extraction</b> method. This method consists of two steps: decompose the fingerprint into set of sub-bands by the Curvelet transform and automatic extraction of the most discriminative statistical features of these sub-bands. An extensive experimental evaluation shows that the proposed method is effective and encouraging. 1...|$|R
