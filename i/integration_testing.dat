534|2138|Public
25|$|Debugging tactics {{can involve}} {{interactive}} debugging, control flow analysis, unit testing, <b>integration</b> <b>testing,</b> log file analysis, monitoring at the application or system level, memory dumps, and profiling.|$|E
25|$|Difficult to unit test: Drupal 7 doesn't follow MVC {{framework}} and stores {{all of its}} configurations in database and as a result, unit testing the code without touching the database becomes extremely difficult. As a result, developers have resorted to using <b>integration</b> <b>testing</b> frameworks such as Red Test or behavior-driven development framework such as Behat and Codeception. Drupal 8 has taken a great stride in {{making it easier for}} developers to write unit-testable code.|$|E
2500|$|On 24 June 2013, a P-8 {{successfully}} {{scored a}} direct hit with a live AGM-84D Block IC Harpoon anti-ship missile during weapons <b>integration</b> <b>testing.</b> On 1 July 2013, an initial operational test and evaluation (IOT) report found that the P-8A was [...] "operationally effective, operationally suitable, and ready for fleet introduction." [...] Six test and nine low-rate initial production aircraft had been delivered at that point. On 31 July 2013, Boeing received a $2.04 billion contract to build 13 P-8As in the fourth low-rate initial production lot, for a fleet of 37 aircraft {{by the end of}} 2016, and long-lead parts for 16 P-8As of the first full-rate production lot.|$|E
5000|$|<b>Integration</b> <b>test</b> report, {{this test}} report {{contains}} the test-results which are formed after an <b>integration</b> <b>test</b> of the application. Based on this test-report the project-team can decide which action to undertake further.|$|R
50|$|Dynamic {{analysis}} {{is in contrast}} to static <b>testing.</b> Unit <b>tests,</b> <b>integration</b> <b>tests,</b> system tests and acceptance tests use dynamic testing.|$|R
5000|$|TestSwarm, a {{distributed}} continuous <b>integration</b> <b>test</b> suite for JavaScript.|$|R
5000|$|Unit {{testing and}} <b>integration</b> <b>testing.</b> One {{study found that}} the average defect {{detection}} rates of unit testing and <b>integration</b> <b>testing</b> are 30% and 35% respectively.|$|E
50|$|In the big-bang approach, {{most of the}} {{developed}} modules are coupled {{together to form a}} complete software system or major part of the system and then used for <b>integration</b> <b>testing.</b> This method is very effective for saving time in the <b>integration</b> <b>testing</b> process. However, if the test cases and their results are not recorded properly, the entire integration process will be more complicated and may prevent the testing team from achieving the goal of <b>integration</b> <b>testing.</b>|$|E
50|$|Support for {{performing}} <b>integration</b> <b>testing</b> via JUnit.|$|E
5000|$|Testing: support {{classes for}} writing unit <b>tests</b> and <b>integration</b> <b>tests</b> ...|$|R
5000|$|Verification and Validation (V&V): Embedded {{throughout}} the software development process (e.g. user requirements specification, functional specification, design specification, code review, unit <b>tests,</b> <b>integration</b> <b>tests,</b> system tests).|$|R
40|$|<b>Integration</b> and <b>test</b> {{planning}} of embedded systems {{is a task}} often performed by industry experts. The {{reason for this is}} the multi-disciplinary nature of the embedded system, the complexity of the components and their environment and the volatility of the <b>integration</b> and <b>test</b> plan. The Tangram research project aims at reducing the <b>integration</b> and <b>test</b> duration of complex embedded systems, like ASML wafer scanners, without influencing the product quality or cost. <b>Integration</b> and <b>test</b> planning is one of the areas where model-based techniques and algorithms can reduce the <b>integration</b> and <b>test</b> duration. This paper presents a structured <b>integration</b> and <b>test</b> planning method including several improvement cycles. This method is applicable for multi-disciplinary systems and can be used to guide the modeling and optimization effort of industrial-size <b>integration</b> and <b>test</b> plans. This method {{has been used as a}} framework for our research into <b>integration</b> and <b>test</b> modeling, sequencing, planning and optimization...|$|R
5000|$|Regarding {{the launch}} of modules of the International Space Station (ISS), there had been {{philosophical}} differences for years between designers and payload processors whether to ship-and-shoot or perform <b>integration</b> <b>testing</b> prior to launch. The former involved building a station module and launching it without ever physically testing it with other modules. The <b>integration</b> <b>testing</b> was not originally in the ISS plan, but in 1995 Johnson Space Center designers began to consider it and embedding KSC personnel at module factories. Multi-Element <b>Integration</b> <b>Testing</b> (MEIT) of ISS modules at KSC was officially in the books in 1997.|$|E
50|$|System-wide <b>integration</b> <b>testing</b> was encouraged, initially, as a daily {{end-of-day}} activity, {{for early}} detection of incompatible interfaces, to reconnect before the separate sections diverged widely from coherent functionality. However, system-wide <b>integration</b> <b>testing</b> has been reduced, to weekly, or less often, depending on {{the stability of the}} overall interfaces in the system.|$|E
5000|$|System <b>integration</b> <b>testing</b> of a {{database}} layer might proceed as follows: ...|$|E
40|$|In this thesis, {{we look at}} {{unit and}} <b>integration</b> <b>test</b> suites and {{look for ways to}} improve the quality of the tests. The first step in this {{research}} is the development of the JUnitCategorizer tool to distinguish between unit <b>tests</b> and <b>integration</b> <b>tests.</b> JUnitCategorizer determines the actual class under test using a new heuristic and ultimately decides whether the test method is a unit or <b>integration</b> <b>test.</b> We show that JUnitCategorizer correctly determines the class under test with an accuracy of over 90 %. Our analysis also shows an accuracy of 95. 8 % on correctly distinguishing unit and <b>integration</b> <b>tests.</b> We applied JUnitCategorizer on several open and closed source projects to obtain a classification of the test suites based on their ratio of <b>integration</b> <b>tests.</b> The second part of this research looks at applicable methods to increase the quality of the tests, for example elimination of boiler-plate code and detection (and possibly generation) of missing tests. Using the classification of test suites, we show that the aforementioned test problems occur in both unit as <b>integration</b> <b>tests.</b> We then propose a new tool called Java Test Assistant (JTA), which can generate boiler-plate tests and some hard tests. An experiment was conducted to assess JTA and showed promising results. Code coverage increased and several of our generated tests fail on the current code base because the implementations are not entirely correct. Software TechnologyElectrical Engineering, Mathematics and Computer Scienc...|$|R
5000|$|Test cases: {{creating}} <b>integration</b> <b>tests</b> {{cases that}} will be run automatically during Test.|$|R
40|$|Planning an <b>integration</b> and <b>test</b> {{phase is}} often done by {{experts in the}} visited organizations. These experts have a {{thorough}} knowledge about the system, <b>integration</b> and <b>testing</b> and the business drivers of an organization. An <b>integration</b> and <b>test</b> plan developedfor an airplane is different than the <b>integration</b> and <b>test</b> plan for a wafer scanner. Safety (quality) is most important for an airplane, while time-to-market is most important for a wafer scanner. These important aspects {{are reflected in the}} <b>integration</b> and <b>test</b> plan. A number of companies has been visited to investigate the influence of the business drivers on the resulting <b>integration</b> and <b>test</b> plans...|$|R
50|$|An {{elaborate}} {{hierarchy of}} unit tests does not equal <b>integration</b> <b>testing.</b> Integration with peripheral units {{should be included}} in integration tests, but not in unit tests. <b>Integration</b> <b>testing</b> typically still relies heavily on humans testing manually; high-level or global-scope testing can be difficult to automate, such that manual testing often appears faster and cheaper.|$|E
50|$|An {{alternative}} {{definition of}} a test harness is software constructed to facilitate <b>integration</b> <b>testing.</b> Where test stubs are typically components of the application under development and are replaced by working components as the application is developed (top-down <b>integration</b> <b>testing),</b> test harnesses are external to the application being tested and simulate services or functionality not available in a test environment.|$|E
5000|$|Software construction: The {{detailed}} {{creation of}} working, meaningful software {{through a combination}} of coding, verification, unit testing, <b>integration</b> <b>testing,</b> and debugging.|$|E
40|$|The <b>integration</b> and <b>test</b> plan {{of a newly}} {{developed}} or manufactured product often has a typical form in a specific organization. This paper describes a number of typical <b>integration</b> and <b>test</b> plans encountered at various organizations with different business drivers. The <b>integration</b> and <b>test</b> plans are described using the same simple notation. A number of aspects per organization is investigated: a typical <b>integration</b> and <b>test</b> plan, the organization size, product volume, business drivers, number of components in the product and the used technology. The investigated organizations are grouped according to product complexity and a rough classification of <b>integration</b> and <b>test</b> plans: flexible and regulated <b>integration</b> and <b>test</b> plans. We conclude that flexible <b>integration</b> and <b>test</b> plans are used in time-to-market driven organizations, while regulated plans are used for non-time-to-market driven organizations...|$|R
40|$|We {{extend the}} {{rational}} speculative bubbles literature to the frontier emerging stock markets. For this purpose, this paper employs fractional <b>integration</b> <b>tests</b> and duration dependence tests {{based on the}} ARFIMA models and nonparametric smoothed hazard functions. Unlike traditional bubble <b>tests,</b> fractional <b>integration</b> <b>tests</b> and duration dependence tests do not show strong evidence of rational speculative bubbles in the frontier emerging stock markets...|$|R
5000|$|<b>Integration</b> <b>test</b> {{code for}} testing HelloActable wired {{together}} with Greeter {{may look like}} the following: ...|$|R
5000|$|Systems <b>{{integration}}</b> <b>testing</b> environment, where basic {{testing of}} a system's integration points to other upstream or downstream {{systems can be}} tested, ...|$|E
50|$|Regression testing. White-box testing during {{regression}} testing {{is the use}} of recycled white-box test cases at the unit and <b>integration</b> <b>testing</b> levels.|$|E
5000|$|There {{are many}} {{combinations}} of data imports and export {{which we can}} perform by considering the time period for system <b>integration</b> <b>testing</b> ...|$|E
5000|$|<b>Integration</b> <b>tests</b> at the Saclay ALS {{shallow depth}} lab, {{which has been}} ongoing since 2010.|$|R
40|$|A component-based {{software}} system consists of well-encapsulated components that {{interact with each}} other via their interfaces. Software <b>integration</b> <b>tests</b> are generated to test the interactions among different components. These tests are usually in the form of sequences of interface method calls. Although many components are equipped with documents that provide informal specifications of individual interface methods, few documents specify component interaction constraints on the usage of these interface methods, including the order in which these methods should be called and the constraints on the method arguments and returns across multiple methods. In this paper, we propose Substra, a framework for automatic generation of software <b>integration</b> <b>tests</b> based on callsequence constraints inferred from dynamic executions. Two types of sequencing constraints are inferred: shared subsystem states and object define-use relationships. The inferred constraints are used to guide automatic generation of <b>integration</b> <b>tests.</b> We have implemented Substra with a tool and applied the tool on an ATM example. The preliminary results show that the tool can effectively generate <b>integration</b> <b>tests</b> that exercise new program behaviors...|$|R
50|$|Ayres wrote {{two books}} {{and more than}} thirty journal articles. In 1975 she {{standardized}} tests originally known as the Southern California Sensory <b>Integration</b> <b>Tests</b> and later revised the Sensory <b>Integration</b> and Praxis <b>Tests</b> in 1989.|$|R
50|$|<b>Integration</b> <b>testing</b> (sometimes called {{integration}} and testing, abbreviated I&T) is the phase in software testing in which individual software modules are combined and tested as a group. It occurs after unit testing and before validation testing. <b>Integration</b> <b>testing</b> takes as its input modules {{that have been}} unit tested, groups them in larger aggregates, applies tests defined in an integration test plan to those aggregates, and delivers as its output the integrated system ready for system testing.|$|E
50|$|All {{the bottom}} or {{low-level}} modules, procedures or functions are integrated and then tested. After the <b>integration</b> <b>testing</b> of lower level integrated modules, {{the next level}} of modules will be formed and can be used for <b>integration</b> <b>testing.</b> This approach is helpful only when all or most of the modules of the same development level are ready. This method also helps to determine the levels of software developed and makes it easier to report testing progress {{in the form of a}} percentage.|$|E
50|$|The {{spacecraft}} was {{rolled out}} on 19 February 2016and completed ground-based system <b>integration</b> <b>testing</b> in September 2016, {{prior to its}} first flight on 8 September 2016.|$|E
40|$|Abstract. As model-driven {{software}} development is increasingly used, techniques to derive additional information from design models are rapidly explored. One kind of these additional information is test information. In this paper we present an approach of deriving {{a certain kind}} of test information for system <b>integration</b> <b>test</b> from a given design model. For a given domain with a generic behavioral model our approach has the ability to generate system <b>integration</b> <b>tests</b> that are specific for any design model of the same domain. The system <b>integration</b> <b>tests</b> are generated as sequence diagrams, where every diagram represents one specific test case for a concrete design model. The approach is of general use since all models are UML 2 models. We illustrate our approach using a case study for a simplified MOST audio system...|$|R
40|$|The {{complexity}} of semiconductor manufacturing equipment is growing. This growth {{results in a}} complexity increase of the <b>integration</b> and <b>test</b> phase of these systems. Simply adding more test resources is not possible anymore, {{because of the cost}} involved. A better design of an <b>integration</b> and <b>test</b> strategy can help to optimize this hectic phase. However, methods to design and evaluate <b>integration</b> and <b>test</b> strategies for multi-disciplinary systems are hardly available. In this paper, we present a method to design and compare <b>integration</b> and <b>test</b> strategies. Following this method, an optimal <b>integration</b> and <b>test</b> strategy can be chosen from a set of possible strategies. A case has been performed where a system is integrated and tested using three different <b>integration</b> and <b>test</b> strategies: a time-to-market-driven strategy, a quality-driven strategy and a combined quality and time-to-market strategy...|$|R
50|$|When mock {{objects are}} {{replaced}} by real ones, the end-to-end functionality will need further testing. These will be <b>integration</b> <b>tests</b> rather than unit tests.|$|R
