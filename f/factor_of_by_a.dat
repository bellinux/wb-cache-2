0|10000|Public
50|$|Archaeology {{provides}} {{a date for}} the earliest city as 5000 BC as Tell Brak (Ur et al. 2006), therefore a date for cooperation and <b>factors</b> <b>of</b> demand, <b>by</b> <b>an</b> increased community size and population to make something like factory level production a conceivable necessity.|$|R
40|$|AbstractNeural {{implementation}} of classical High-Threshold Theory reveals fundamental flaws {{in its applicability}} to realistic neural systems and to the two-alternative forced-choice (2 AFC) paradigm. For 2 AFC, Signal Detection Theory provides a basis for accurate analysis of the observer’s attentional strategy and effective degree of probability summation over attended neural channels. The resulting theory provides substantially different predictions from those of previous approximation analyses. In additive noise, attentional probability summation depends on the attentional model assumed. (1) For an ideal attentional strategy in additive noise, summation proceeds at a diminishing rate from an initial level of fourth-root summation {{for the first few}} channels. The maximum improvement asymptotes to about <b>a</b> <b>factor</b> <b>of</b> 4 <b>by</b> <b>a</b> million channels. (2) For a fixed attention field in additive noise, detection is highly inefficient at first and approximates fourth-root summation through the summation range. (3) In physiologically plausible root-multiplicative noise, on the other hand, attentional probability summation mimics a linear improvement in sensitivity up to about ten channels, approaching <b>a</b> <b>factor</b> <b>of</b> 1000 <b>by</b> <b>a</b> million channels. (4) Some noise sources, such as noise from eye movements, are fully multiplicative and would prevent threshold determination within their range of effectiveness. Such results may require reappraisal of previous interpretations of detection behavior in the 2 AFC paradigm...|$|R
40|$|Modifications to our {{previously}} described detector of magnetic monopoles resulting in substantial improvements in performance have been made. The sensitivity has been increased <b>a</b> <b>factor</b> <b>of</b> 35 <b>by</b> using <b>a</b> sensitive magnetometer (SQUID) to measure changes in current. The modifications, new measurement techniques, {{and implications for}} past and future experiments are described...|$|R
40|$|Langmuir probe {{measurements}} were performed in magnetized expanding plasmas of different compns. Under {{the assumption that}} a function fitted to results in argon is valid in other plasmas, {{it is possible to}} study the influence of the magnetic field in nitrogen and hydrogen plasmas. The electron d. in nitrogen can be increased <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 10 <b>by</b> the application <b>of</b> <b>a</b> magnetic field of 4. 5 mT. In hydrogen the d. can be increased <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 100 <b>by</b> <b>a</b> magnetic field <b>of</b> 20 mT. The dominant ionic species in the magnetized nitrogen and hydrogen plasmas is the at. ion (N+ and H+, resp.). [on SciFinder (R) ...|$|R
40|$|We {{introduce}} {{an innovation}} expansion method for estimation <b>of</b> <b>factor</b> models for conditional variance (volatility) of a multivariate time series. We estimate the factor loading {{space and the}} number <b>of</b> <b>factors</b> <b>by</b> <b>a</b> stepwise optimization algorithm on expanding the "white noise space". Simulation and a real data example are given for illustration...|$|R
40|$|Abstract. Given an {{irreducible}} sofic shift X, we {{show that}} an irreducible shift of finite type Y of lower entropy is a <b>factor</b> <b>of</b> X {{if and only if}} it is <b>a</b> <b>factor</b> <b>of</b> X <b>by</b> <b>an</b> open bi-continuing code. If these equivalent conditions hold and Y is mixing, then any code from a proper subshift of X to Y can be extended to an open bi-continuing code on X. These results are still valid when X is assumed to be only an almost specified shift, i. e., a subshift satisfying an irreducible version of the specification property...|$|R
30|$|The {{analyses}} above {{reveal that}} CR characteristics are different by facility type, {{which may be}} related to the different geometric designs and traffic characteristics. However, CR analysis is insufficient to examine <b>a</b> variety <b>of</b> <b>factors</b> <b>by</b> <b>a</b> single model. Instead, PCA is applied and the affecting mechanisms <b>of</b> individual <b>factors</b> are further investigated.|$|R
40|$|Abstract. We {{study the}} {{approximation}} complexity of certain kinetic variants of the Traveling Salesman Problem where we consider {{instances in which}} each point moves with a xed constant speed in a xed direction. We prove the following results. 1. If the points all move with the same velocity, {{then there is a}} PTAS for the Kinetic TSP. 2. The Kinetic TSP cannot be approximated better than <b>by</b> <b>a</b> <b>factor</b> <b>of</b> two <b>by</b> <b>a</b> polynomial time algorithm unless P=NP, even if there are only two moving points in the instance. 3. The Kinetic TSP cannot be approximated better than <b>by</b> <b>a</b> facto...|$|R
40|$|In this paper, a Monte-Carlo simulator, {{including}} quantum corrections to {{the potential}} and an improved physically based model for surface roughness scattering is used to study the electronic transport in double gate (DG) SO 1 MOSFETs with Lc down to 14 nm. Our results demonstrate that, for the explored LG values, scattering still controls the ON current (IDS), which for Lc = 25 nm is overestimated <b>by</b> about <b>a</b> <b>factor</b> <b>of</b> 2 <b>by</b> <b>a</b> ballistic model. <b>By</b> monitoring the electrons back-scattered at the source, we discuss {{the role of the}} scattering {{in different parts of the}} device...|$|R
40|$|In {{order to}} be {{considered}} a low-cost market, the cost advantage of one or more <b>factors</b> <b>of</b> production offered <b>by</b> <b>a</b> state – generally, a developing one – must be exploited by the multinational firms. Therefore, we may speak about these markets only after 19 multinational company, low-cost market, foreign direct investments, developing state, location advantages...|$|R
40|$|Anti-reflection {{coatings}} {{on glass}} substrates were prepared <b>by</b> the application <b>of</b> sol-gel coatings of silica containing crystalline tin oxide particles. The sol was coated on commercially available float glass by dip-coating and spin-coating techniques. Increasing the surface roughness of the float glass (<b>factor</b> <b>of</b> 50) <b>by</b> <b>a</b> particulate coating material resulted in anti-reflection effects comparable to frosted glass. Haze and clarity, {{which are a}} measure for the contrast and definition of an optical system, were determined and compared to the uncoated and the commercial frosted glass. The reflectivity of the float glass could be reduced from 9 % to 3 %, which is a <b>factor</b> <b>of</b> two better than that of glasses...|$|R
40|$|Given an {{irreducible}} sofic shift X, we {{show that}} an an irreducible SFT Y of lower entropy is a <b>factor</b> <b>of</b> X {{if and only if}} it is <b>a</b> <b>factor</b> <b>of</b> X <b>by</b> <b>an</b> open bi-continuing code. If these equivalent conditions hold and Y is mixing, then any code from a proper subshift of X to Y can be extended to an open bi-continuing code on X. These results are still valid when X is assumed to be only an almost specified shift, i. e., a subshift satisfying an irreducible version of the specification property. Comment: 20 pages, 3 figures. v 2 : minor revision. typos corrected. Final version to appear in Transactions AM...|$|R
40|$|Two-boson-exchange charge density {{operator}} {{is obtained}} for static nucleons <b>by</b> taking account <b>of</b> rr-, p · and aJ-meson exchanges and Ll-intermediate {{state with a}} consistent treatment of nuclear wave function and effective operator. We study its effect to the charge form <b>factor</b> <b>of</b> 'He <b>by</b> adopting <b>a</b> simple nuclear wave function. At high momentum transfer, two-boson-exchange charge density is found to have an appreciable contribution to the nuclear charge form factor...|$|R
40|$|Deng, Z. Pera-Titus, M. Guo, Y. Giroir-Fendler, A. International audienceHigh quality {{nanocomposite}} B-MFI {{hollow fibers}} were successfully prepared by pore-plugging hydrothermal synthesis. The incorporation of boron into the MFI structure modifies the n-hexane/ 2, 2 -dimethylbutane vapor separation {{properties of the}} membranes, with the materials improving the n-hexane/ 2, 2 -dimethylbutane intrinsic separation <b>factors</b> <b>of</b> Al-MFI <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 2 (up to a value of 200) at comparable conditions. The permeation performance of the membranes is essentially governed <b>by</b> <b>a</b> molecular sieving mechanism driven <b>by</b> preferential diffusion <b>of</b> n-C 6 and configurational diffusion effects favoring n-hexane adsorption from n-hexane/ 2, 2 -dimethylbutane mixtures. A strong confinement scenario for surface diffusion of both n-hexane and 2, 2 -dimethylbutane seems to prevail...|$|R
40|$|Factor {{analysis}} (FA) is {{a statistical}} procedure {{widely used in}} psychological research, especially in evaluating latent variables. Despite its widespread popularity, in our milieu FA has an incipient use. FA is consistent with data reduction, as {{to determine the number}} and nature <b>of</b> <b>factors</b> represented <b>by</b> <b>a</b> pool <b>of</b> items and their correlation. Each <b>factor</b> captures items <b>of</b> the questionnaire with a similar pattern of variation among the studied individuals, Comment on “Factor structure o...|$|R
40|$|AbstractPrinciples and {{characteristics}} of a parallel plate resonator are reviewed based upon a transfer function concept. From the transfer function, we obtain the resonance frequency, the bandwidth, and the quality <b>factor</b> <b>of</b> the resonator <b>by</b> <b>a</b> simple procedure. This simplified approach is easier than the traditional electromagnetic field theory approach or the ray optics approach. Validity of this transfer function approach on the parallel plate resonator is verified by experiments in X-band microwaves and other published literature...|$|R
30|$|It can be said, as per Gelles and Levine (1995), {{that most}} {{definitions}} of culture {{have a common}} element: culture is <b>a</b> set <b>of</b> <b>factors</b> shared <b>by</b> <b>a</b> society, especially beliefs and values, as well as norms, traditions, symbols, language and technology. This definition {{has been used in}} several studies, as its broad meaning allows scholars to use their own criteria to determine shared factors, with beliefs and values being the most common.|$|R
40|$|It is {{well known}} that some {{topography}} causes a wind increase and unexpected gust factors. To examine the characteristics <b>of</b> the gust <b>factors</b> <b>by</b> every wind direction throughout Kyushu area, the authors have organized a database of strong wind data classified into non-typhoon and typhoon. The authors have confirmed the different tendencies <b>of</b> gust <b>factors</b> according to the wind direction at several terrains using the database. The database shows that the gust <b>factors</b> <b>of</b> winds <b>by</b> <b>a</b> typhoon are generally higher than by non-typhoon even when the wind speed is high. And the authors have found that the gust factor at Imajuku, the western part of Fukuoka City, is much higher in southern wind direction. Such a database on the gust factors is useful to estimate a peak gust in strong winds...|$|R
40|$|International audienceReal time {{segmentation}} {{of a scene}} into {{objects and}} background is really important and represents an initial step of objects tracking. Starting from the codebook method we propose some modifications which show significant improvements {{in most of the}} normal and also difficult conditions. We also propose an evaluation method in order to objectively compare several segmentation techniques, based on receiver operating characteristic (ROC) analysis and on precision and recall method. We propose to summarize the quality <b>factor</b> <b>of</b> <b>a</b> method <b>by</b> <b>a</b> single value, based either on a weighted Euclidian Distance or on a harmonic mean between two related characteristics...|$|R
40|$|We propose an {{incomplete}} {{split plot design}} where levels <b>of</b> one <b>factor</b> (say A) are applied to the wholeplots and levels of the other (say B) to subplots, and where the number of subplots in each wholeplot may be less than the number <b>of</b> levels <b>of</b> <b>factor</b> B. The t levels <b>of</b> <b>factor</b> A are arranged in a completely randomized design. The s levels <b>of</b> <b>factor</b> B are arranged in a connected and proper incomplete block design within each level <b>of</b> <b>factor</b> <b>A,</b> <b>by</b> considering the wholeplots as blocks. block design intra-block analysis inter-block analysis incomplete split plot design analysis of variance...|$|R
40|$|Previous {{formulas}} for {{the design}} of radiation thermopiles to be used with a Thomson galvanometer are summarized and new formulas {{for the design}} of thermopiles for use with D'Arsonval galvanometers are developed. A design of thermopile is described in which the cold junctions almost entirely surround the hot junctions thus reducing drifts. In this design, each element is constructed as a separate unit and when all are completed they are simply stacked up and fastened together with one screw, thereby minimizing the danger of breakage. The whole thermopile fits into a cubical evacuated case only 10 mm on an edge and, being so small, it can be used directly in front of an elliptical mirror which forms a small hot image, in some cases increasing the deflection due to <b>a</b> given radiation <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 3. <b>By</b> <b>a</b> slight modification <b>of</b> the spectrometer, a thermopile having adjustable compensation can be utilized which, theoretically, will give almost no drifts due to changes in temperature of the optical parts of the spectrometer or of the surroundings. A convenient technique of construction is described...|$|R
40|$|In {{this paper}} I show how {{reliable}} {{estimates of the}} Value of a Statistical Life (VSL) can be obtained using cross sectional data using Garen's instrumental variable (IV) approach. The increase in the range confidence intervals due to the IV setup can be reduced <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 3 <b>by</b> using <b>a</b> proxy to risk attitude. In order state the "precision" of the cross sectional VSL estimates I estimate the VSL using Chilean panel data and use them as benchmark for different cross sectional specifications. The use of the proxy eliminates need for using hard-to-find instruments for the job risk level and narrows the confidence intervals for the workers in the Chilean labor market for the year 2009...|$|R
40|$|In {{this paper}} we present SPADE, a new {{algorithm}} for fast discovery of Sequential Patterns. The existing solutions {{to this problem}} make repeated database scans, and use complex hash structures which have poor locality. SPADE utilizes combinatorial properties to decompose the original problem into smaller sub-problems, that can be independently solved in main-memory using efficient lattice search techniques, and using simple join operations. All sequences are discovered in only three database scans. Experiments show that SPADE outperforms the best previous algorithm <b>by</b> <b>a</b> <b>factor</b> <b>of</b> two, and <b>by</b> <b>an</b> order <b>of</b> magnitude with some pre-processed data. It also has linear scalability {{with respect to the}} number of customers, {{and a number of other}} database parameters...|$|R
40|$|A {{review of}} some field records {{showed that a}} two-wedge {{mechanism}} formed when failure occurred in <b>a</b> slope underlain <b>by</b> <b>a</b> thin weak layer. A physical model which promoted plane strain conditions was designed {{for the study of}} the sequence of failure. The model consisted of a simple granular slope resting at its angle of repose on a cohesive layer. At low confining pressures, the failure of the sand in plane strain was described <b>by</b> <b>a</b> deformational failure criterion. The sequence of failure of the model slope was determined from measurements of photographic records of experiments. The slope was analysed using numerical models and stability methods, with emphasis on the discontinuous nature of the material. A method based on the principle of virtual work and using an energy dissipation function for the definition of the critical failure mechanism was proposed by the author, who found its predictions concurred with the experimental observations. The use of an energy based analysis led to the replacement <b>of</b> the <b>factor</b> <b>of</b> safety <b>by</b> <b>an</b> energy quotient, Q. The virtual work analysis was applied to a prototype example and was found to give good agreement with field measurements...|$|R
40|$|We {{present a}} network {{influence}} game that models players strategically seeding {{the opinions of}} nodes embedded in a social network. A social learning dynamic, whereby nodes repeatedly update their opinions to resemble those of their neighbors, spreads the seeded opinions through the network. After a fixed period of time, the dynamic halts and each player's utility {{is determined by the}} relative strength of the opinions held by each node in the network vis-a-vis the other players. We show that the existence of a pure Nash equilibrium cannot be guaranteed in general. However, if the dynamics are allowed to progress for a sufficient amount of time so that a consensus among all of the nodes is obtained, then the existence of a pure Nash equilibrium can be guaranteed. The computational complexity of finding a pure strategy best response is shown to be NP-complete, but can be efficiently approximated to within a (1 - 1 /e) <b>factor</b> <b>of</b> optimal <b>by</b> <b>a</b> simple greedy algorithm. Comment: Published in the proceedings of the 6 th EAI International Conference on Game Theory for Networks (GAMENETS 2016). May 11 - 12, 201...|$|R
40|$|Azadinium spinosum, a small toxic dinoflagellate, was {{recently}} isolated and {{identified as a}} primary producer of azaspiracid toxins (AZAs). Previous experiments related to AZA accumulation in blue mussels upon direct feeding with A. spinosum revealed increased mussel mortality and had negative effects on {{the thickness of the}} digestive gland tubules. Therefore we conducted follow up experiments in order to study effects of A. spinosum on mussel feeding behaviour. Individual assessment of mussel feeding time activity (FTA), clearance rate (CR), filtration rate (TFR), absorption rate (AR), faeces and pseudofaeces production were carried out on mussel fed either toxic (A. spinosum) or non-toxic (Isochrisis aff. galbana (T-Iso)) diets. Furthermore, AZA accumulation and biotransformation in mussels were followed using liquid chromatography coupled to tandem mass spectrometry (LC–MS/MS). A. spinosum had a significant effect on mussel feeding behaviour compared to T-Iso: CR was lower <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 6, FTA <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 5, TFR <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 3 and AR even decreased to negative values for the last day of exposure. Even so, a rapid AZA accumulation was observed during the first hours of the trial; less than 6 h of feeding were required to reach AZA concentration in mussel above regulatory level. In consistence with physiological observations, AZA concentration of about 200 �g kg− 1 did not increase further {{until the end of the}} study. AZA bioconversion was also found to be a fast process: after 3 h of exposure AZA 17, - 19 and AZA 7 - 10 were already found, with a proportion of AZA 17 equal to AZA 2. These results show a negative effect of A. spinosum on blue mussel feeding activity and indicate a possible regulation <b>of</b> AZA uptake <b>by</b> decreasing filtration and increasing pseudofaeces production...|$|R
40|$|Lithography {{techniques}} {{based on}} electron-beam-induced processes are inherently slow compared to light lithography techniques. The authors demonstrate {{here that the}} throughput can be enhanced <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 196 <b>by</b> using <b>a</b> scanning electron microscope equipped with a multibeam electron source. Using electron-beam induced deposition with MeCpPtMe 3 as a precursor gas, 14 ?×? 14 arrays of Pt-containing dots were deposited on a W/Si 3 N 4 /W membrane, with each array of 196 dots deposited in a single exposure. The authors demonstrate that by shifting the array of beams over distances of several times the beam pitch, one can deposit rows of closely spaced dots that, although originating from different beams within the array, are positioned within 5 ?nm of a straight line. IST/Imaging Science and TechnologyApplied Science...|$|R
40|$|International audienceMassive {{galaxies in}} the early Universe {{have been shown to}} be forming stars at {{surprisingly}} high rates. Prominent examples are dust-obscured galaxies which are luminous when observed at sub-millimetre wavelengths and which may be forming stars at a rate of 1, 000 solar masses (Msolar) per year. These intense bursts of star formation are believed to be driven by mergers between gas-rich galaxies. Probing the properties of individual star-forming regions within these galaxies, however, is beyond the spatial resolution and sensitivity of even the largest telescopes at present. Here we report observations of the sub-millimetre galaxy SMMJ 2135 - 0102 at redshift z = 2. 3259, which has been gravitationally magnified <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 32 <b>by</b> <b>a</b> massive foreground galaxy cluster lens. This magnification, when combined with high-resolution sub-millimetre imaging, resolves the star-forming regions at a linear scale of only 100 parsecs. We find that the luminosity densities of these star-forming regions are comparable to the dense cores of giant molecular clouds in the local Universe, but they are about a hundred times larger and 107 times more luminous. Although vigorously star-forming, the underlying physics of the star-formation processes at z~ 2 appears to be similar to that seen in local galaxies, although the energetics are unlike anything found in the present-day Universe...|$|R
40|$|Graphene double quantum {{open the}} {{possibility}} to use charge or spin degrees of freedom for storing and manipulating quantum information in this new electronic material. However, impurities and edge disorders in etched graphene nano-structures hinder {{the ability to control}} the inter-dot tunnel coupling, tc,the most important property of the artificial molecule. Here we report measurements of tc in an all-metal-gates-tuned graphene DQD. We find that tc can be controlled continuously about <b>a</b> <b>factor</b> <b>of</b> four <b>by</b> employing <b>a</b> single gate. Furthermore, tc, can be changed monotonically about another <b>factor</b> <b>of</b> four as electrons are gate-pumped into the dot one by one. The results suggest that the strength of tunnel coupling in etched DQDs can be varied in a rather broad range and in a controllable manner, which improves the outlook to use graphene as a base material for qubit applications. Comment: 18 pages, 10 figure...|$|R
40|$|Environmental stress {{activates}} sigma B, {{the general}} stress response sigma <b>factor</b> <b>of</b> Bacillus subtilis, <b>by</b> <b>a</b> pathway that is negatively {{controlled by the}} RsbX protein. To determine whether stress activation of sigma B occurs <b>by</b> <b>a</b> direct effect <b>of</b> stress on RsbX, we constructed B. subtilis strains which synthesized various amounts of RsbX or lacked RsbX entirely and subjected these strains to ethanol stress. Based on the induction of a sigma B-dependent promoter, stress activation of sigma B can occur {{in the absence of}} RsbX. Higher levels of RsbX failed to detectably influence stress induction, but reduced levels of RsbX resulted in greater and longer-lived sigma B activation. The data suggest that RsbX is not a direct participant in the sigma B stress induction process but rather serves as a device to limit the magnitude of the stress response...|$|R
40|$|An acid {{phosphatase}} from an extract of mugwort (Artemisia vulgaris) pollen was purified <b>by</b> <b>a</b> <b>factor</b> <b>of</b> 48 <b>by</b> <b>a</b> combination <b>of</b> ion exchange and gel-chromatography. The molecular weights of the enzyme were 76 kDa and 73 kDa, determined by gel filtration on a Sephadex G- 100 sf column and by SDS PAGE (under reducing and non-reducing conditions), respectively. In analytical isoelectrofocusing, the enzyme appears as two very close bands, pI at about 4. 2. The optimum pH for the enzyme is 5. 4. The apparent Km for p-nitrophenyl phosphate {{was estimated to}} be 0. 16 mM. The purified enzyme has broad specificity, and hydrolyses p-nitrophenyl phosphate and a-naphthyl phosphate. Pyrophosphate and O-phospho-L-tyrosine were estimated to be the best substrates for this enzyme as potential in vivo substrates. The enzyme is inhibited competitively by phosphate (Ki = 1. 25 mM), molybdate (Ki = 0. 055 mM) and pyrophosphate (Ki = 6. 7 mM) and non-competitively by fluoride (Ki = 9. 8 mM). Metal ions such as Hg 2 +, Cu 2 + and Zn 2 + express an inhibitory effect on the enzyme, while the enzyme is slightly activated by non-ionic detergents, Tween 20 and Triton X- 100. There is no change in the enzyme activity in the presence of tartrate, citrate, EDTA, 1, 10 -phenanthroline and sulfhydryl-group modifiers such as p-chloromercuribenzoate and N-ethylmaleimide...|$|R
40|$|Impurity seeding of plasma {{discharges}} {{has led to}} {{regimes of}} improved thermal and parti-cle confinement in many tokamaks [1]. Extending these results to a larger device such as the JET tokamak allows size scaling and {{the evaluation of the}} potential of this approach to future fusion reactors. In the initial JET experiments reported here, neon impurity seeding produced modest increases in thermal energy confine-ment, H 89 P < 1. 4, a reduction in the thermal diffusivity, χi, and increases in the thermal neutron rate of more than <b>a</b> <b>factor</b> <b>of</b> 2, ac-companied <b>by</b> <b>a</b> large increase in radiated power, Prad/Pin < 0. 6. Gyrokinetic simulation(GKS) code simulations show a decrease in the growth rate of low k modes in discharges with impurity injection, consistent with a reduction in ion temperature gradient (ITG) modes. Two discharges with neon impurity in...|$|R
40|$|Abstract. In {{this paper}} we present SPADE, a new {{algorithm}} for fast discovery of Sequential Patterns. The existing solutions {{to this problem}} make repeated database scans, and use complex hash structures which have poor locality. SPADE utilizes combinatorial properties to decompose the original problem into smaller sub-problems, that can be independently solved in main-memory using efficient lattice search techniques, and using simple join operations. All sequences are discovered in only three database scans. Experiments show that SPADE outperforms the best previous algorithm <b>by</b> <b>a</b> <b>factor</b> <b>of</b> two, and <b>by</b> <b>an</b> order <b>of</b> magnitude with some pre-processed data. It also has linear scalability {{with respect to the}} number of input-sequences, {{and a number of other}} database parameters. Finally, we discuss how the results of sequence mining can be applied in a real application domain. Keywords: sequence mining, sequential patterns, frequent patterns, data mining, knowledge discover...|$|R
40|$|In January 2002, the Fermilab Director {{initiated}} a design study {{for a high}} average power, modest energy proton facility. An intensity upgrade to Fermilab's 120 -GeV Main Injector (MI) represents an attractive concept for such a facility, which would leverage existing beam lines and experimental areas and would greatly enhance physics opportunities at Fermilab and in the U. S. With a Proton Driver replacing the present Booster, the beam intensity of the MI {{is expected to be}} increased <b>by</b> <b>a</b> <b>factor</b> <b>of</b> five. Accompanied <b>by</b> <b>a</b> shorter cycle, the beam power would reach 2 MW. This would make the MI a more powerful machine than the SNS or the J-PARC. Moreover, the high beam energy (120 GeV) and tunable energy range (8 - 120 GeV) would make it a unique high power proton facility. The upgrade study has been completed and published. This paper gives a summary report...|$|R
30|$|We {{have already}} {{reported}} {{the results on}} XRD analyses of the MS-C 20 binary LB systems {{before and after the}} HTT processes [18, 24]. The analyses revealed that the d-spacing of the as-deposited MS-C 20 binary system is 5.52 nm, which corresponds to the well-known Cd-Cd spacing in the Y-type LB film of C 20 (2 × 2.76 nm). By HTT, the positions of diffraction peaks remain almost unchanged, while the diffraction intensities remarkably increase associated with a narrowing in width. For instance, the intensity of the peak of fifth order increases <b>by</b> <b>a</b> <b>factor</b> <b>of</b> two <b>by</b> HTT. <b>A</b> similar change, i.e., the increase in peak intensity associated with the narrowing, is also observed when the dry-heat treatment (DHT, conventional annealing without water vapor) is applied to the same LB system. However, the J-band is not reorganized but simply dissociated by heat treatment without water molecules (DHT). Therefore, we consider that the lubrication effect <b>by</b> the presence <b>of</b> water molecules predominates in the HTT process.|$|R
40|$|Given an {{undirected graph}} G with n nodes and m edges, we {{address the problem}} of finding a largest {{collection}} of edge-disjoint cycles in G. The problem, dubbed Cycle Packing, is very closely related to a few genome rearrangement problems in computational biology. In this paper, we study the complexity and approximability of Cycle Packing, about which very little is known although the problem is natural and has practical applications. We show that the problem is APX-hard but can be approximated within <b>a</b> <b>factor</b> <b>of</b> O(log n) <b>by</b> <b>a</b> simple greedy approach. We do not know whether the O(log n) factor is tight, but we give a nontrivial example for which the ratio achieved by greedy is not constant, namely Ω iq log n log log n j. We also show that, for &quot;not too sparse&quot; graphs, i. e. graphs for which m = Ω (...|$|R
