9|1110|Public
40|$|Digital <b>image</b> <b>centering</b> {{algorithms}} {{were compared}} {{in a test}} involving microdensitometer raster scans of a refractor parallax series consisting of 22 stars on 26 plates. The highest accuracy in determining stellar image positions was provided by an algorithm which involved fitting of a symmetric Gaussian curve and a flat background to the image marginal density distributions. Algorithms involving transmission marginals instead of density marginals {{were found to be}} less accurate. The repeatability and computational efficiency of the digital <b>image</b> <b>centering</b> technique were also studied...|$|E
40|$|A {{method of}} {{incorporating}} {{the effects of}} photographic emulsion grain noise into digital <b>image</b> <b>centering</b> algorithms is presented which improves {{the accuracy of the}} derived stellar positions and magnitudes. Theoretical formulae are then derived for the limiting error of the center, and the photometric parameters. For IIIa-J, this error is 0. 2 - 0. 3 mu for bright unsaturated images, which agrees quite well with measurements made with the Yale PDS microdensitometer. It is expected that, with further improvements in the positional accuracy of the PDS, {{it should be possible to}} reach the emulsion grain noise limit, providing that emulsion shifts or other large scale errors do not dominate. It is also shown that, with appropriate trimming, marginal distribution <b>image</b> <b>centering</b> algorithms can yield an accuracy only slightly poorer than that obtained with two-dimensional distributions...|$|E
40|$|The astrometric {{application}} of the Wide Field Camera and the Planetary Camera is reviewed. It is shown that the digital <b>image</b> <b>centering</b> algorithms can yield a positional accuracy of 0. 1 milli-arcsecond. Deconvolution of CCD's sensitivity, non-flatness of the filters, and crinkling of the CCD surface may limit the positional accuracy of 1 milli-arcsecond...|$|E
40|$|People need to {{calibrate}} camera systems {{in order to}} determine the relationship between the positions of features in object space and their corresponding positions in the image. Part of camera calibration is the determination of <b>image</b> <b>center.</b> But, what is the <b>image</b> <b>center?</b> Ideally, the <b>image</b> <b>center</b> is considered to be the point of intersection of the camera's optical axis with the camera's sensing plane. In fact there are many possible definitions of <b>image</b> <b>center,</b> and in real lenses most do not have the same coordinates. In addition, the <b>image</b> <b>centers</b> move as lens parameters are changed. In this paper we examine why <b>image</b> <b>centers</b> are not necessarily the same for different image properties and why they vary with lens parameters. We then provide a taxonomy of 16 different <b>image</b> <b>centers</b> and describe procedures for measuring them. Finally we examine the calibration of <b>image</b> <b>center</b> for a variable parameter lens. Several techniques are applied to a precision automated zoom lens and experiment [...] ...|$|R
40|$|There are mangt {{possible}} {{definitions of}} <b>image</b> <b>center,</b> and in real lenses most {{do not have}} the same coordinates. Moreover, <b>image</b> <b>centers</b> move as lens parameters are changed. [n this paper we present a tarohorny that includes I 5 different definitions of <b>image</b> <b>center.</b> We conclude that the accuracy of the <b>image</b> <b>center</b> can be an important factor in the accuracy of the overall camera calibration, and that the large variation in the position of the <b>image</b> <b>center</b> across different definitions and different lens settings makes the calibration problem complez. With proper modeling, by usin appropriate definitions for all <b>image</b> <b>centers</b> in a system, we can improve the accuracy of our camera calibration...|$|R
40|$|To {{model the}} way that cameras project the {{three-dimensional}} world into a two-dimensional image {{we need to know}} the camera's <b>image</b> <b>center.</b> First-order models of lens behavior, such as the pinhole-camera model and the thin-lens model, suggest that the <b>image</b> <b>center</b> is a single, fixed, and intrinsic parameter of the lens. On closer inspection, however, we find that there are many possible definitions for <b>image</b> <b>center.</b> Most <b>image</b> <b>centers</b> {{do not have the same}} coordinates and, moreover, move as lens parameters are changed. We present a taxonomy that includes 15 techniques for measuring <b>image</b> <b>center.</b> Several techniques are applied to a precision automated zoom lens, and experimental results are shown...|$|R
40|$|Abstract. This paper {{deals with}} the {{retrieval}} of document images especially applied to the digitized old books. In these old books our system allows the retrieval of graphical parts and especially the ornamental letters. The aim of our system is to process large image databases. For this purpose, we have developed a fast approach based on a Run Length Encoding (RLE) of images. We use the RLE in an image comparison algorithm using two steps: one of <b>image</b> <b>centering</b> and then a distance computation. Our centering step allows to solve the shifting problems usually met between scanned images. We present experiments and results about our system according to criteria of processing time and recognition precision. ...|$|E
40|$|Abstract. This paper {{deals with}} the CBIR of old printed {{graphics}} (of XVI ◦ and XVII ◦ centuries) like the headpieces, the pictures and the ornamental letters. These graphical parts are previously segmented from digitized old books in order to constitute image databases for the historians. Today, large databases exist and involves to use automatic retrieval tools able to process large amounts of data. For this purpose, we have developed a fast retrieval system based on a Run Length Encoding (RLE) of images. We use the RLE in an image comparison algorithm using two steps: one of <b>image</b> <b>centering</b> and then a distance computation. Our centering step allows to solve the shifting problems usually met between the segmented images. We present experiments and results about our system concerning the processing time and the retrieval precision. ...|$|E
40|$|This {{article has}} been cited by other {{articles}} in PMC. Adaptive optics (AO) ophthalmoscopes with small fields of view have limited clinical utility. We propose {{to address this problem}} in reflective instruments by incorporating a viewfinder pupil relay designed by considering pupil and <b>image</b> <b>centering</b> and conjugation. Diverting light from an existing pupil optical relay to the viewfinder relay allows switching field of view size. Design methods that meet all four centering and conjugation conditions using either a single concave mirror or with two concave mirrors forming an off-axis afocal telescope are presented. Two different methods for calculating the focal length and orientation of the concave mirrors in the afocal viewfinder relay are introduced. Finally, a 2. 2 × viewfinder mode is demonstrated in an AO scanning light ophthalmoscope. OCIS codes: (080. 4035) Mirror system design, (110. 1080) Active or adaptive optics, (170. 3890) Medical optics instrumentation, (170. 4460) Ophthalmic optics and devices 1...|$|E
5000|$|... #Caption: Forollhogna (<b>image</b> <b>center)</b> as {{seen from}} Ilfjellet(west) ...|$|R
40|$|The Documentation Center of Photography and Audiovisual INSPAI, <b>Image</b> <b>Center,</b> Council of Girona, is a cross-service and {{integration}} {{with the rest}} of expertise and resources of the <b>Image</b> <b>Center,</b> especially on the technical treatment of the documentation. Its main tasks are the retrieval and dissemination of documentation, with text and image as well as the dissemination and communication activities conducted by the center of the screen. To make that possible, <b>Image</b> <b>Center</b> has highly specialized services and professionals of different areas of knowledge that carry out the tasks and activities of this multipurpose center...|$|R
50|$|Danbury Diagnostic <b>Imaging</b> <b>Center</b> {{opened in}} Danbury in 2001.|$|R
40|$|It {{is often}} diJficult {{to come up}} with a well-principled {{approach}} to the selection of a spatial indexing mechanism for medical image databases. Spatial information about lesions in medical images is critically important in disease diagnosis and plays an important role in image retrieval. Unfortunately, the images are rarely indexed properly for clinically useful retrieval. One example is the well-known R-tree and its variants which index image objects based on their physical locations in an "absolute" way. However, such information is not meaningful in medical content-based image retrieval systems, and the approaches above suffer from problems caused by variations in object size and shape, imprecise <b>image</b> <b>centering,</b> etc. A more appropriate approach, which does not require object registration, is to model the spatial relationships between the lesions and anatomical landmarks. To convey diagnostic information, lesions must exist in certain locations with regard to the landmarks. In this paper, we show that the histogram of forces (which represents the relative position between two objects) provides an eJficient spatial indexing mechanism in the medical domain...|$|E
40|$|Eye {{alignment}} to {{the optical}} system is very critical in many modern devices, such as for biometrics, gaze tracking, head mounted displays, and health. We show alignment {{in the context}} of the most difficult challenge: retinal imaging. Alignment in retinal imaging, even conducted by a physician, is very challenging due to precise alignment requirements and lack of direct user eye gaze control. Self-imaging of the retina is nearly impossible. We frame this problem as a user-interface (UI) challenge. We can create a better UI by controlling the eye box of a projected cue. Our key concept is to exploit the reciprocity, "If you see me, I see you", to develop near eye alignment displays. Two technical aspects are critical: a) tightness of the eye box and (b) the eye box discovery comfort. We demonstrate that previous pupil forming display architectures are not adequate to address alignment in depth. We then analyze two ray-based designs to determine efficacious fixation patterns. These ray based displays and a sequence of user steps allow lateral (x, y) and depth (z) wise alignment to deal with <b>image</b> <b>centering</b> and focus. We show a highly portable prototype and demonstrate the effectiveness through a user study. Vodafone Americas FoundationUnited States. Army Research OfficeDeshpande Center for Technological Innovatio...|$|E
40|$|Abstract. In this paper, {{an outer}} {{conductor}} diameter measuring system for coaxial transmission lines are introduced. The structure of pole-distance changing cylinder capacitor sensor probe aperture measuring is analyzed. The signal analysis and control {{system of the}} whole measurement system is introduced in detail. The guarding ring technology is used to eliminate edge effect of effective measuring sensor electrode. The operation amplifying transform circuit is used to overcome the nonlinear problem of pole-distance changing sensor. Driving cable technology is adopted to reduce the influence of parasitic capacitance. Through the CCD <b>image</b> <b>centering</b> and grating encoder driven by stepping motor drive system and encoder system X, Y, Z axis precision positioning, in order to realize the long hole in any section of the nano measuring diameter; The measuring types of this system is: Φ 0. 8 mm, Φ 1 mm, Φ 1. 8 mm to Φ 7 mm hole diameter. The resolution is 5 nm [...] 20 nm, the standard deviation of repeated measurement is 0. 05 µm [...] 0. 1 µm. The measurement uncertainty is 2 µm— 0. 2 µm. The section size and shape measurement of deep-blind pinhole (especially high deep-width ration hole) is a difficult problem in precision measurement. It {{is not only a}} research hot spot in domestic but also in international. Capacitive sensor has many advantages: simple structure, hig...|$|E
5000|$|Midsayap Neuro <b>Imaging</b> <b>Center,</b> Inc. (Poblacion 8, Midsayap, Cotabato) ...|$|R
5000|$|... 5 Biomedical <b>Imaging</b> <b>Center,</b> Pontificia Universidad Católica de Chile.|$|R
5000|$|American College of Radiology - Breast <b>Imaging</b> <b>Center</b> of Excellence ...|$|R
5000|$|... #Caption: Maulnes (near <b>image</b> <b>center)</b> on an 18th-century Cassini map ...|$|R
5000|$|National History Museum and the Polovtsian stone <b>images</b> (<b>center,</b> Lenin).|$|R
5000|$|... 2001-2014: Director, Advanced <b>Imaging</b> <b>Center,</b> Harvard Medical School, NeuroDiscovery Center ...|$|R
5000|$|Breast <b>Imaging</b> <b>Center</b> of Excellence by the American College of Radiology ...|$|R
5000|$|... 2000-2009 Celebration Health Director of Surgical <b>Imaging</b> <b>Center</b> for Surgical Advancement ...|$|R
5000|$|The Mission Surgery Center and the Mission Regional <b>Imaging</b> <b>Center</b> opened.|$|R
5000|$|Woman's <b>Imaging</b> <b>Center</b> (1220 Hobson Road, Suite 124 Naperville, IL 60540) ...|$|R
50|$|The {{mapping of}} a {{sideways}} object {{leads to a}} picture position displacement from the <b>image</b> <b>center.</b> The manner of this conversion is the mapping function. The distance of a point from the <b>image</b> <b>center</b> 'r' {{is dependent on the}} focal length of the optical system 'f', and the angle from the optical axis 'θ', where 'θ' is in radians.|$|R
5000|$|... #Caption: Vinjeronden (<b>image</b> <b>center)</b> {{seen from}} the higher Rondeslottet. Storrondenbehind to the left.|$|R
5000|$|Houston Methodist <b>Imaging</b> <b>Center</b> - West Houston; 8333 Katy Freeway, Houston, Texas 77024 ...|$|R
5000|$|Memorial Sloan-Kettering Cancer <b>Center</b> Breast and <b>Imaging</b> <b>Center,</b> New York, New York, USA ...|$|R
5000|$|... 1989 - 1994 Director, McConnell Brain <b>Imaging</b> <b>Center</b> (BIC), Montreal Neurological Institute, Canada ...|$|R
5000|$|... #Caption: Oblique Lunar Orbiter 4 <b>image</b> <b>centered</b> on Riemann with Bealsat {{lower left}} ...|$|R
5000|$|... #Caption: Oblique Lunar Orbiter 4 <b>image</b> <b>centered</b> on Riemannwith Beals {{at lower}} left ...|$|R
30|$|This study {{received}} {{research and}} development funding from Helsinki University Hospital Medical <b>Imaging</b> <b>Center.</b>|$|R
5000|$|... #Caption: Lunar Orbiter 5 <b>image</b> <b>centered</b> on {{the landing}} site. Width is 17.2 km.|$|R
5000|$|... #Caption: CT image (left), PET <b>image</b> (<b>center)</b> and overlay of both (right) after correct registration.|$|R
50|$|Calculation of <b>image</b> <b>centers</b> - {{calculation}} of coordinates of each image with image scales and overlap.|$|R
