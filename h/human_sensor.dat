28|390|Public
5000|$|Calling {{patterns}} of mobile phone users {{can determine the}} socioeconomic standings of the populace {{which can be used}} to deduce [...] "its access to housing, education, healthcare, and basic services such as water and electricity". Researchers from Columbia University and Karolinska Institute utilize information from mobile phone providers, in order to assist in the dispersal of resources by deducing the movement of those displaced by natural disasters. Big data can also provide information on looming disasters and can assist relief organizations in rapid response and locating displaced individuals. By analyzing certain patterns within this 'big data', could successively transform the response to destructive occurrences like natural disasters, outbreaks of diseases and global economic distress, by employing real-time information to achieve a comprehension of the welfare of individuals. Corporations utilize digital services, such as <b>human</b> <b>sensor</b> systems to detect and solve impending problems within communities. This is a strategy implemented by the private sector in order to protect its citizens by anonymously dispersing customer information to the public sector, whilst also ensuring the protection of their privacy.|$|E
40|$|Introduction and {{statement}} of problem The report {{deals with a}} possibility to objectively determine (using purely instrumental methods) <b>human</b> <b>sensor</b> system parameters which influence his adaptability to natural and technogenic environment. First qualitative studies of the <b>human</b> <b>sensor</b> sphere started more than a centur...|$|E
40|$|This work {{describes}} an approach of a socio-geographic network for crowdsourcing sensor tasks to a <b>human</b> <b>sensor</b> web. Users can register as human sensors {{at the system}} by defining their skills and impact area. Based on that information, submitted sensor tasks are forwarded to the most suitable <b>human</b> <b>sensor.</b> Motivated by their willingness to help, users can support others by supplying information about their local environment as responses to sensor task requests. This enables people to retrieve data which is currently not existing or publicly accessible on the Web. A person who is moving to another country and interested in renting a flat without knowing much about its environment is one example for a potential requester of <b>human</b> <b>sensor</b> tasks. Data contributed once to this <b>human</b> <b>sensor</b> web is henceforth {{available to the public}} via existing Web 2. 0 platforms...|$|E
40|$|While the <b>human</b> as a <b>sensor</b> {{concept has}} been {{utilised}} extensively {{for the detection}} of threats to safety and security in physical space, especially in emergency response and crime reporting, the concept is largely unexplored in the area of cyber security. Here, we evaluate the potential of utilising users as <b>human</b> <b>sensors</b> {{for the detection of}} cyber threats, specifically on social media. For this, we have conducted an online test and accompanying questionnaire-based survey, which was taken by 4, 457 users. The test included eight realistic social media scenarios (four attack and four non-attack) in the form of screenshots, which {{the participants were asked to}} categorise as “likely attack” or “likely not attack”. We present the overall performance of <b>human</b> <b>sensors</b> in our experiment for each exhibit, and also apply logistic regression and Random Forest classifiers to evaluate the feasibility of predicting that performance based on different characteristics of the participants. Such prediction would be useful where accuracy of <b>human</b> <b>sensors</b> in detecting and reporting social media security threats is important. We identify features that are good predictors of a <b>human</b> <b>sensor’s</b> performance and evaluate them in both a theoretical ideal case and two more realistic cases, the latter corresponding to limited access to a user’s characteristics...|$|R
40|$|Thirty {{secondary}} teachers from varied subjects participated in STEM professional development. Design projects included LED wristbands, LilyPad Arduino <b>human</b> <b>sensors,</b> Arduino Uno ambient sensors, and 3 D printing. Teachers collaboratively developed and implemented interdisciplinary design-based learning units with students. We assess changes in content knowledge, classroom perceptions, and student mindsets...|$|R
40|$|Smart {{cities are}} {{powered by the}} ability to self-monitor and respond to signals and data feeds from {{heterogeneous}} physical sensors. These physical sensors, however, are fraught with interoperability and dependability challenges. Moreover, they also cannot shed light on human emotions and factors that impact smart city initiatives. Yet everyday, millions of city dwellers share their observations, thoughts, feelings, and experiences about their city through social media updates. This paper describes how citizens can serve as <b>human</b> <b>sensors</b> in providing supplementary, alternate, and complementary sources of information for smart cities. It presents a methodology, based on a probabilistic language model, to extract the perceptions that may be relevant to smart city initiatives from social media updates. Geo-tagged tweets collected over a two-month period from New York City are used to illustrate the potential of social media powered <b>human</b> <b>sensors...</b>|$|R
40|$|Many {{disaster}} {{warning and}} response systems can improve their surveillance {{coverage of the}} threatened area by supplementing in-situ and remote sensor data with crowdsourced <b>human</b> <b>sensor</b> data captured and sent by people in the area. This revised version of a 2012 technical report also presents fusion methods which enable a crowdsourcing enhanced system to use <b>human</b> <b>sensor</b> data and physical sensor data synergistically to improve its sensor coverage {{and the quality of}} its decisions. The methods are built on results of classical statistical detection and estimation theory and use value fusion and decision fusion of <b>human</b> <b>sensor</b> data and physical sensor data in a coherent way. They are building blocks of a central fusion unit in a crowdsourcing support system for disaster surveillance. In addition, this version contains a brief description of CROSS, a crowdsourcing support platform {{that can be used to}} enhance existing disaster surveillance systems, as well as performance data on relative merits o...|$|E
40|$|Design for human-borne sensing faces a key challenge: {{to provide}} {{increasingly}} high-quality, day-by-day sensing accuracy {{and reporting from}} an energy-constrained and aggressively miniaturized computing form factor. Long-term maintenance-free operation is an another important goal for devices intended to be carried by people throughout their daily life. The <b>human</b> <b>sensor</b> form factor is driven by its energy storage requirements, hence power consumption resulting from data sensing, processing, and communication. This thesis studies the energy costs in the full end-to-end <b>human</b> <b>sensor</b> platform, however {{specific attention is paid}} to optimizing energy use in the worn sensor device. Three computing layers comprising the <b>human</b> <b>sensor</b> platform are examined: the <b>human</b> <b>sensor</b> device, the mobile data aggregator, including smart phone and smart watch, and cloud-side data warehousing. The heterogeneous compute and energy capacity qualities of the layers are exploited for both intra-layer and cross-layer improvements in energy efficiency. Opportunities to offload power consumption from the sensor device, thus enabling smaller battery capacity and further scaling of sensor device form factor are prioritized. The full data handling flow, including data sensing, data cleaning, feature extraction and classification, data communications and storage, is considered, and tradeoffs between computed result accuracy and energy cost are tailored across a range of applications. Wearable <b>human</b> <b>sensor</b> applications implemented and reported on in this thesis include mobile online gait analysis for runners, grocery store aisle localization with augmented reality driven item recommendation, and wearable in-field electroencephalographic brain sensing. Results include improvements in energy-efficiency over the state-of-the-art, including an 11 X speedup in cloud data processing, a 47 % power reduction in a wearable running sensor when applying a smartphone-to-wearable collaboration, and, most significantly, a one-order-of-magnitude power reduction when applying an event-driven sparse adaptive sampling method to a wearable human running gait analysis sensor...|$|E
40|$|Abstract. Semantic {{technologies}} are prominent for gathering <b>human</b> <b>sensor</b> observations. Linked Data supports sharing and accessing {{of not just}} data but also vocabularies describing the data. <b>Human</b> <b>sensor</b> obser-vations are often a combination of natural language and categorizable en-tries, thus calling for semantic treatment. Space and time serve as natural integrators of data in addition to concepts. In this paper we demonstrate YouSense tool which supports gathering of experiences about spaces (like generic buildings or office spaces). Our contribution is also a vocabulary for describing the experiences as RDF and tools for visualizing and mak-ing sense of the gathered user experiences. ...|$|E
40|$|We report our {{experience}} {{in building a}} working system, SportSense ([URL] which exploits Twitter users as <b>human</b> <b>sensors</b> {{of the physical world}} to detect events in real-time. Using the US National Football League (NFL) games as a case study, we report in-depth measurement studies of the delay and post rate of tweets, and their dependence on other properties. We subsequently develop a novel event detection method based on these findings, and demonstrate that it can effectively and accurately extract game events using open access Twitter data. SportSense has been evolving during the 2010 - 11 and 2011 - 12 NFL seasons and is able to recognize NFL game big plays in 30 to 90 seconds with 98 % true positive, and 9 % false positive rates. Using a smart electronic TV program guide, we show that SportSense can utilize <b>human</b> <b>sensors</b> to empower novel services...|$|R
40|$|Abstract: In {{this paper}} we outline the {{functionalities}} {{of a system}} that integrates and controls a fleet of Unmanned Aircraft Vehicles (UAVs). UAVs have a set of payload sensors employed for territorial surveillance, whose outputs are stored in the system and analysed by the data exploitation functions at different levels. In particular, we detail the second level data exploitation function whose aim is to improve the sensors data interpretation in the post-mission activities. It is concerned with the mosaicking of the aerial images and the cartography enrichment by <b>human</b> <b>sensors</b> - the social media users. We also describe the software architecture {{for the development of a}} mash-up - the integration of information and functionalities coming from the Web - and the possibility of using <b>human</b> <b>sensors</b> in the monitoring of the territory, a field in which, traditionally, the involved sensors were only the hardware one...|$|R
40|$|Recent {{scientific}} advances {{allow the}} use of technology to expand the number of forms of energy that can be perceived by <b>humans.</b> Smart <b>sensors</b> can detect hazards that <b>human</b> <b>sensors</b> are unable to perceive, for example radiation. This fusing of technology to human’s forms of perception enables exciting new ways of perceiving the world around us. In this paper we describe the design of SpiderSense, a wearable device that projects the wearer’s near environment on the skin and allows for directional awareness of objects around him. The millions of sensory receptors that cover the skin presents opportunities for conveying alerts and messages. We discuss the challenges and considerations of designing similar wearable devices...|$|R
40|$|Abstract. Human {{observations}} {{have the}} potential to significantly improve the actuality and completeness of data about phenomena such as noise distribution in urban environments. The <b>Human</b> <b>Sensor</b> Web aims at providing approaches for creating and sharing human observations as well as sensor observations on the Web. One challenge is the integration of these observations for further analysis. The aspects presented in this paper are examined by the example of a noise mapping community. ...|$|E
40|$|Autonomous systems, {{particularly}} unmanned aerial systems (UAS), remain {{limited in}} autonomous capabilities {{largely due to}} a poor understanding of their environment. Current sensors simply do not match human perceptive capabilities, impeding progress towards full autonomy. Recent work has shown the value of humans as sources of information within a human-robot team; in target applications, communicating human-generated ‘soft data’ to autonomous systems enables higher levels of autonomy through large, efficient information gains. This requires development of a ‘human sensor model’ that allows soft data fusion through Bayesian inference to update the probabilistic belief representations maintained by autonomous systems. Current <b>human</b> <b>sensor</b> models that capture linguistic inputs as semantic information are limited {{in their ability to}} generalize likelihood functions for semantic statements: they may be learned from dense data; they do not exploit the contextual information embedded within groundings; and they often limit human input to restrictive and simplistic interfaces. This work provides mechanisms to synthesize <b>human</b> <b>sensor</b> models from constraints based on easily attainable a priori knowledge, develops compression techniques to capture information-dense semantics, and investigates the problem of capturing and fusing semantic information contained within unstructured natural language. A robotic experimental testbed is also developed to validate the above contributions...|$|E
40|$|We have {{developed}} a universal robot hand with tactile and other sensors. An array-type tactile sensor is crucial for dexterous manipulation of objects using a robotic hand, since this sensor can measure the pressure distribution on finger pads. The sensor has a very high resolution, and {{the shape of a}} grasped object can be classified by using this sensor. The more the number of measurement points provided, the higher the accuracy of the classification, but with a corresponding lengthening of the measurement cycle. In this paper, the problem of slow response time is resolved by using software for an array-type tactile sensor with high resolution that emulates the <b>human</b> <b>sensor</b> system. The validity of the proposed method is demonstrated through experiments...|$|E
40|$|Adelaide Festival of Ideas session, The Braggs, 11 : 30 am, Saturday 19 th October, 2013. Chaired by Susannah Eliot. Working {{with more}} than 100 journalists from around the world, Rick Smolan {{believes}} we’re witnessing {{the emergence of a}} global nervous system, with each of us <b>human</b> <b>sensors.</b> Does Big Data have the potential to be “humanity’s dashboard”? Smolan discusses a revolution that may have as big an impact as the internet...|$|R
40|$|The {{technological}} and conceptual implications of industry 4. 0 require an {{evolution of the}} traditional maintenance: maintenance has to become smart. The main aim {{is to establish a}} concept for maintenance, that combines technical related goals with economical goals of industrial companies. Therefore, the four key elements of smart maintenance, namely <b>humans,</b> <b>sensors,</b> data-management and assistance- systems, have to be combined in an integrated management approach. This article presents a reference-approach for this idea...|$|R
50|$|Some <b>human</b> {{proximity}} <b>sensors</b> use passive infrared sensing in the {{far infrared}} wavelength to detect both static and/or moving human bodies.|$|R
40|$|Abstract- Gait Analysis {{is a new}} {{profound}} <b>human</b> <b>sensor</b> {{which focuses}} on human locomotion. The word ‘gait ’ means the manner of walking. It is a highly secured technique in which a person’s gait is stored offline in a database and for security reasons the previous data is matched with the present one in order to grant access to a highly secured area. Before considering human locomotion, many other parameters like age, height, weight, health, speed etc. are taken into account. This paper focuses on how Gait Analysis {{can be used in}} the field of security in comparison with other existing techniques. Previously and presently, Gait Analysis is being used in animation movie making, visual world creation etc. Its use can be expanded to various other fields like medical sciences, biometric identification etc. in order to provide benefit to the human beings...|$|E
40|$|Current {{and ongoing}} {{research}} and experimentations in the creation, {{design and build}} of low-cost, high-value prototypes for novel and unconventional interaction devices (IxD) in combination with cyber-physical system (CPS) (i. e. hybrid design tools (HDT), blended spaces) tangible user interfaces (TUI) and use of sensor technology lead {{to a variety of}} novel interaction modalities, experiences and possibilities. In line with this research, we propose a first prototype <b>Human</b> <b>Sensor</b> Selection Tool (HSST) as a preliminary guide and guidelines for design and engineering domains. The HSST is based on and inspired by the ‘five human senses’ [1], a plethora in human body signals (e. g. proprioceptive, vestibular) and gestures (e. g. facial expression, (e-) motions) that could be integrated, translated, transformed, adapted or mimicked to enhance and enrich the interaction modalities with for example computer-aided design (CAD), computer-aided technologies (CAx), and effectively affective CPS...|$|E
40|$|This paper {{presents}} {{the design of}} a probabilistic model of human perception {{as an integral part of}} a decentralized data fusion system. The system consists of a team of human operators and robotic platforms, together forming a heterogenous sensor network. Human operators are regarded as information sources submitting raw observations. The observations are converted into a probabilistic representation suitable for fusion with the system 2 ̆ 7 s belief. The conversion is performed by a <b>Human</b> <b>Sensor</b> Model (HSM). The initial HSM is built offline based on an average of multiple human subjects conducting a calibration experiment. Since individual human operators may vary in their performance an online adaptation of the HSM is required. The network estimate is used for adaptation because the true feature state is unknown at runtime. Results of an outdoor calibration experiment using range and bearing observations are presented. Simulations show the feasibility of efficient online adaptation...|$|E
40|$|The {{challenge}} of OMNISCIENTIS {{is to develop}} a community based odour moni-toring and information system to mitigate odour annoyance and to foster citizens’ participation in environmental governance. The core is an information system collect-ing various data of odour emissions obtained by electronic noses and other sensors, meteorological conditions and observations by citizens acting as <b>human</b> <b>sensors.</b> A specific odour dispersion model is developed to use all this information and provide immediate feedback to all stakeholders. This work presents the architecture of the environmental information system, some first results from odour monitoring and model development and validation. ...|$|R
40|$|Contextual data {{monitoring}} {{plays an important}} role in increasing the quality of life of <b>humans.</b> <b>Sensors</b> observing specific activities report contextual data to a central system capable of situational reasoning. The system responds to any event related to the observed phenomenon. We propose an intelligent mechanism that builds on top of sensors measurements and derives the appropriate decisions for immediate identification of events. The mechanism adopts multivariate data fusion, time-series prediction, and consensus theory for aggregating measurements. We adopt Fuzzy Logic for handling the induced uncertainty in the decision making on the derived alerts. Simulations over real contextual data showcase the advantages and disadvantages of our monitoring mechanism...|$|R
50|$|Sensors provide analogs {{to human}} senses and can monitor other {{phenomena}} for which <b>humans</b> lack explicit <b>sensors.</b>|$|R
40|$|Abstract. In {{recent years}} the Sensor Web Enablement (SWE) stan-dards of the Open Geospatial Consortium (OGC) have been {{successfully}} applied in several practical applications. Typical domains range from en-vironmental monitoring over homeland security to disaster management. At the same time, mobile communication technology has spread widely so that {{large parts of the}} world's population are able to communicate electronically. In several developing countries the mobile communication infrastructure has even reached a better availability than the supply with water and electricity. The combination of these two aspects- the SWE architecture and the common availability of mobile communication net-works- opens up the perspective to create even more powerful monitoring systems. This work shows how human observations can be integrated with the Sensor Web technology and presents a system design which makes use of the <b>Human</b> <b>Sensor</b> Web idea to build a monitoring system for improving the water supply in Zanzibar. ...|$|E
40|$|This paper {{discusses}} {{the design of}} a social media analysis system for decision making in natural disasters where tweets are analyzed to achieve situational awareness in earthquake and tsunami events. The system is demonstrated and evaluated using a scenario-based methodology. An empirical study is undertaken to get feedback and further requirements from practitioners working in the field of hazard detection and early warning. The main contribution of the paper is that we propose a framework which builds upon a system for tsunami detection and early warning, developed in the project Collaborative, Complex, and Critical Decision-Support in Evolving Crises (TRIDEC). The system is evaluated by the Kandilli Observatory and Earthquake Research Institute (KOERI) and the Portuguese Institute for the Sea and Atmosphere (IPMA) against official international requirements as well as individual national requirements to incorporate new features and functionalities related to <b>human</b> <b>sensor</b> network analysis, and to fit into existing workflows...|$|E
40|$|This {{dissertation}} {{presents a}} novel approach that utilizes quantifiable social media data as a human aware, near real-time observing system, coupled with geophysical predictive models for improved response to disasters and extreme events. It shows that social media data {{has the potential to}} significantly improve disaster management beyond informing the public, and emphasizes the importance of different roles that social media can play in management, monitoring, modeling and mitigation of natural and human-caused extreme disasters. In the proposed approach Social Media users are viewed as human sensors that are deployed in the field, and their posts are considered to be sensor observations, thus different social media outlets all together form a <b>Human</b> <b>Sensor</b> Network. We utilized the <b>human</b> <b>sensor</b> observations, as boundary value forcings, to show improved geophysical model forecasts of extreme disaster events when combined with other scientific data such as satellite observations and sensor measurements. Several recent extreme disasters are presented as use case scenarios. In the case of the Deepwater Horizon oil spill disaster of 2010 that devastated the Gulf of Mexico, the research demonstrates how social media data from Flickr {{can be used as a}} boundary forcing condition of GNOME oil spill plume forecast model, and results in an order of magnitude forecast improvement. In the case of Hurricane Sandy NY/NJ landfall impact of 2012, we demonstrate how the model forecasts, when combined with social media data in a single framework, can be used for near real-time forecast validation, damage assessment and disaster management. Owing to inherent uncertainties in the weather forecasts, the NOAA operational surge model only forecasts the worst-case scenario for flooding from any given hurricane. Geolocated and time-stamped Instagram photos and tweets allow near real-time assessment of the surge levels at different locations, which can validate model forecasts, give timely views of the actual levels of surge, as well as provide an upper bound beyond which the surge did not spread. Additionally, we developed AsonMaps [...] a crisis-mapping tool that combines dynamic model forecast outputs with social media observations and physical measurements to define the regions of event impacts...|$|E
5000|$|... #Caption: Midsagittal {{view of the}} <b>human</b> mouth. Transducer (<b>sensor)</b> coils are {{typically}} placed on the tongue and lips.|$|R
40|$|Abstract—Crowdsensing {{applications}} are increasing at a tremendous rate. In crowdsensing, mobile <b>sensors</b> (<b>humans,</b> vehicle-mounted <b>sensors,</b> etc.) generate streams {{of information that}} is used for inferring high-level phenomena of interest (e. g., traffic jams, air pollution). Unlike traditional sensor network data, crowdsensed data has a highly skewed spatio-temporal distribution caused {{largely due to the}} mobility of sensors [1]. Thus, designing systems that can mitigate this effect by acquiring crowdsensed at a fixed spatio-temporal rate are needed. In this paper we propose using multi-dimensional point processes (MDPPs), a mathematical modeling tool that can be effectively used for performing this data acquisition task. I...|$|R
40|$|Abstract – Claude Shannon’s {{pioneering}} work quantified the performance limits of communications systems operating over classic wireline Gaussian channels. However, his source and channel coding theorems were derived {{for a range}} of idealistic conditions, which may not hold in low-delay, interactive wireless multimedia communications. Firstly, Shannon’s ideal lossless source encoder, namely the entropy encoder may have an excessive codeword length, hence exhibiting a high delay and a high error sensitivity. However, in practice most multimedia source signals are capable of tolerating lossy, rather than lossless delivery to the human eye, ear and other <b>human</b> <b>sensors.</b> The corresponding lossy and preferably low-delay multimedia source codecs however exhibit unequal error sensitivity, which is not the case for Shannon’s ideal entropy codec. There are further numerous differences between the Shannonian lessons originally outlined for Gaussia...|$|R
40|$|Highly dynamic {{real-time}} microblog {{systems have}} already published petabytes of real-time <b>human</b> <b>sensor</b> {{data in the}} form of status updates. However, the lack of user adoption of geo-based features per user or per post signals that the promise of microblog services as location-based sensing systems may have only limited reach and impact. Thus, in this article, we propose and evaluate a probabilistic framework for estimating a microblog user’s location based purely on the content of the user’s posts. Our framework can overcome the sparsity of geo-enabled features in these services and bring augmented scope and breadth to emerging location-based personalized information services. Three of the key features of the proposed approach are: (i) its reliance purely on publicly available content; (ii) a classification component for automatically identifying words in posts with a strong local geo-scope; and (iii) a lattice-based neighborhood smoothing model for refining a user’s location estimate. On average we find that the location estimates converge quickly, placing 51 % of users within 100 miles of their actual location...|$|E
40|$|For {{the first}} time the blind source de-mixing is applied to {{authenticity}} protection for multimedia products. We give an overview of the current state of multimedia authenticity protection, including the requirements of various multimedia applications, current approaches to the problem, and the robustness of the approaches. We then introduce the de-mixing algorithm, based on independent component analysis (ICA) seeking statistically factorized probability density and yielding a fast de-mixing computing using unsupervised artificial neural networks. We describe how their blind demixing capability extends signal processing from the conventional one-sensor approach to a multi-sensor approach, as in the 2 eyes and 2 ears of <b>human</b> <b>sensor</b> systems but packaged in a spatio-temporal multiplexing fashion. For trademark security, a covert ICA can serve as a dormant digital watermark embedded within the multimedia data. Unauthorized removal of the trademark as plagiarism could degrade the quality of the content data (not shown here). We show how these new approaches contribute to a flexible, robust, and relative secure system for protecting the authenticity of multimedia products...|$|E
40|$|Effective human-machine {{collaboration}} {{can significantly}} improve many learning and planning strategies for information gathering via fusion of 'hard' and 'soft' data originating from machine and human sensors, respectively. However, gathering the most informative data from human sensors without task overloading remains a critical technical challenge. In this context, Value of Information (VOI) {{is a crucial}} decision-theoretic metric for scheduling interaction with human sensors. We present a new Deep Learning based VOI estimation framework {{that can be used}} to schedule collaborative human-machine sensing with computationally efficient online inference and minimal policy hand-tuning. Supervised learning is used to train deep convolutional neural networks (CNNs) to extract hierarchical features from 'images' of belief spaces obtained via data fusion. These features can be associated with soft data query choices to reliably compute VOI for human interaction. The CNN framework is described in detail, and a performance comparison to a feature-based POMDP scheduling policy is provided. The practical feasibility of our method is also demonstrated on a mobile robotic search problem with language-based semantic <b>human</b> <b>sensor</b> inputs. Comment: 10 pages, to appear in ICCPS 201...|$|E
40|$|Abstract — This work {{presents}} {{the design of}} a new electronic system to save electrical energy. In this design is to focus on the use of low power digital IR motion <b>sensors</b> to perform <b>human</b> motion to voltage conversion. PIC 16 F 84 A microcontroller have been used to control the entire system. Three electrical devices (Televisions, Fan and Lump) was controller by this system. PROTEUS 8 professional software was used for simulating the designed system, and MikroC software from MikroElektronika was used to programing the pic 16 F 84 A microcontroller. Results of the system design showed how to saving electrical energy by using <b>human</b> motion <b>sensor</b> and PIC 16 F 84 A microcontroller. Index Terms — saving energy, PIC 16 f 84 A and <b>human</b> motion <b>sensor.</b> I...|$|R
40|$|This paper {{presents}} a socio-technical study about perceptions of human trustworthiness {{as a key}} component for countering insider threats in virtual collaborative context. This study focuses on understanding how anomalous behavior can be detected by observers in a close social network. While human observations are fallible, this study adopts the concept of human-observed changes in behavior as analogous to ???sensors??? on a computer network. Using online team-based game-playing, this study seeks to re-create realistic situations in which <b>human</b> <b>sensors</b> {{have the opportunity to}} observe changes in the behavior of a focal individual ??? in this case a team leader. Four sets of experimental situations are created to test hypotheses. Results of this study may lead to the development of semi-automated or fully-automated behavioral detection systems that attempt to predict the occurrence of malfeasance...|$|R
40|$|The {{advent of}} online services, social networks, crowdsourcing, and serious Web games has {{promoted}} {{the emergence of}} a novel computation paradigm, where complex tasks are solved by exploiting the capacity of human beings and computer platforms in an integrated way. Water Resources Management systems can take advantage of human and social computation in several ways: collecting and validating data, complementing the analytic knowledge embodied in models with tacit knowledge from individuals and communities, using <b>human</b> <b>sensors</b> to monitor the variation of conditions at a fine grain and in real time, activating human networks to perform search tasks or actuate management actions. This exploratory paper overviews different forms of human and social computation and analyzes how they can be exploited to enhance the effectiveness of ICT-based Water Resources Management...|$|R
