11|91|Public
50|$|Historically, in the United States {{motion picture}} cameras {{had been used}} since the 1920s for {{recording}} race-meets but were unsuitable for photo-finish photography as the frame rate was too infrequent to catch the critical instant horses or dogs reached the finish line. This record was achieved by using a special slit camera. Lorenzo Del Riccio, a Paramount Pictures motion picture engineer improved the circular <b>flow</b> <b>camera,</b> a device which had been invented in the 1930s especially {{for the purpose of}} photographing moving objects. The first racing club to make use of Del Riccio's 'Photo-Chart' camera for photo-finishes was the Del Mar Turf Club in California at its inaugural meeting in 1937.|$|E
50|$|Unlike {{conventional}} cameras {{the circular}} <b>flow</b> <b>camera</b> used a single vertical slit {{instead of a}} shutter; a strip of film moved horizontally across the fine vertical opening located in the focal plane. This limited the field of vision {{to no more than}} a few inches, the restricted field being aligned with the vertical line on the winning post on which the lens was focused. The strip film moved across the slit in the opposite direction to the race and at substantially the same speed as the rate of movement of the image of the horses as each passed the finishing line. This kept the image of the horses more or less stationary with respect to the film. As soon as the first horse started to pass over the line, the camera began to record its image on the moving film from the nose backwards, progressively along the length of the body, with the arrival of every horse at the finishing post in succession. This produced a strip photographic record of the horses as they passed the vertical plane (winning post). Film was advanced continuously at a pace equivalent to the average speed of a racing horse, resulting in distortions of length (slower-moving horses appear to be stretched), but still preserving the order of finishers.|$|E
40|$|This {{contribution}} {{reports on}} the major developments and achievements in our group on fabricating highly sensitive biomimetic flow-sensor arrays. The mechanoreceptive sensory hairs of crickets are taken as a model system {{for their ability to}} perceive flow signals at thermal noise levels and, moreover, to extract spatio-temporal flow information of the surroundings. To reach our final goal, i. e., a <b>flow</b> <b>camera</b> consisting of biomimetic flow-sensor arrays, most of our efforts have been focusing on increasing the performance of the biomimetic flow sensors and reliability of the fabrication process, respectively, by sensor-model optimizations and by optimization of processing procedures and materials...|$|E
50|$|Special purpose <b>flow</b> <b>cameras</b> film {{both sides}} of documents, putting both images {{side by side on}} 16 mm film. These cameras are used to record cheques and betting slips.|$|R
5000|$|<b>Flowing</b> - the <b>camera</b> {{chooses a}} longer shutter speed for {{deliberate}} motion or panning blur.|$|R
5000|$|In 1956, Nikkatsu Studios {{made three}} popular Sun Tribe films, a genre {{focused on a}} {{contemporary}} youth subculture noted for their affinity for beach life, jazz music and their progressive attitudes towards sex. The films met with moral public outcries and a fourth production was halted {{at the behest of}} Eirin (The Motion Picture Code of Ethics Committee). However, the genre later resurged and included Everything Goes Wrong. The film was based on the author Akira Ichijō's story High Teen Mistress ( [...] Hai tīn jōfu), adapted for the screen by Seiji Hoshikawa. Former fashion model Yoshiko Yatsu made her feature film debut. Hit singer Kyu Sakamoto made an appearance, performing a musical number. The film employed an improvisational jazz score and free <b>flowing</b> <b>camera</b> work in a semi-documentary style. Production was completed on September 13, 1960.|$|R
40|$|This article {{presents}} {{the development of}} a vision-based VTOL UAV docking system for outdoor applications. A new marker type is constructed, along with a robust detection algorithm based on the Hough transform, which forms the basis of the positioning system. For verification pur-poses, a binary classifier based on support vec-tor machines is trained. Test data show great ro-bustness against varying lighting, partial occlu-sion and unsharpness. The practical usefulness is demonstrated by creating a single tracking mod-ule, based upon the PX 4 <b>FLOW</b> <b>camera.</b> Equip-ping a quadrotor with the new positioning sensor allows it to perform a precision landing. ...|$|E
40|$|This paper {{presents}} {{the design and}} implementation details of a complete unmanned aerial system (UAS) based on commercial-off-the-shelf (COTS) components, focusing on safety, security, search and rescue scenarios in GPS-denied environments. In particular, The aerial platform is capable of semi-autonomously navigating through extremely low-light, GPS-denied indoor environments based on onboard sensors only, including a downward-facing optical <b>flow</b> <b>camera.</b> Besides, an additional low-cost payload camera system is developed to stream both infra-red video and visible light video to a ground station in real-time, {{for the purpose of}} detecting sign of life and hidden humans. The total cost of the complete system is estimated to be $ 1150, and the effectiveness of the system has been tested and validated in practical scenarios...|$|E
40|$|Nature offers {{human being}} elegant {{solutions}} for various engineering problems. Mimicking principles and designs offered by nature enables humans {{to better understand}} related phenomena and may help to provide better engineered systems. Hair-based flow sensing in crickets {{is an example of}} a biological system that has recently attracted great interest from engineers. This inspired engineers to develop an artificial system, a <b>flow</b> <b>camera,</b> as an alternative to more traditionally engineered systems. The work reported on in this thesis addresses the track to develop highly-sensitive sensor-array systems (made of artificial hair sensors) towards fulfilling the requirements for an airflow camera. The current research could shed some light on the detection and processing of flow phenomena in nature. Additionally, it can be considered one-step further with the tendency of constructing live aerodynamic images...|$|E
500|$|Several {{aspects of}} Within the Woods were later {{presented}} in future Raimi films, {{including the use}} of the [...] "Raimi-cam", a camera rig that creates a fluent <b>flow</b> of <b>camera</b> movement. Other elements, such as graphic imagery, bleak endings, and mutilations, defined many of Raimi's other films. Raimi has put Campbell in cameo roles in all three of Raimi's Spider-Man trilogy, as well as several other films.|$|R
500|$|Among Kubrick's notable {{innovations}} in cinematography are {{his use of}} special effects, as in 2001, where he used both slit-scan photography and front-screen projection, which won Kubrick his only Oscar for special effects. Some reviewers have described and illustrated with video clips, Kubrick's use of [...] "one-point perspective", which leads the viewer's eye towards a central vanishing point. The technique relies on creating a complex visual symmetry using parallel lines in a scene which all converge on that single point, leading away from the viewer. Combined with camera motion it could produce an effect that one writer describes as [...] "hypnotic and thrilling". The Shining {{was among the first}} half-dozen features to use the then-revolutionary Steadicam (after the 1976 films Bound for Glory, Marathon Man and Rocky). Kubrick used it to its fullest potential, which gave the audience smooth, stabilized, motion-tracking by the camera. Kubrick described Steadicam as being like a [...] "magic carpet", allowing [...] "fast, <b>flowing,</b> <b>camera</b> movements" [...] in the maze in The Shining which otherwise would have been impossible.|$|R
2500|$|Inferno {{continues}} to have a mixed critical reputation. The film has a 64% favorable rating on the [...] "Tomatometer" [...] at movie review aggregator website Rotten Tomatoes, out of twelve surveyed internet film reviewers. Leonard Maltin's Movie Guide gave the film {{two and a half}} stars and opined it was a [...] "surreal, hypnotic shocker...short on sense, but long on style." [...] But several critics have praised the film. Upon its initial release on videotape, Tim Lucas in The Video Watchdog Book said, [...] "The movie is terrific, much more exciting than most contemporary horror video releases..." [...] Kim Newman, in The Penguin Encyclopedia of Horror and the Supernatural, noted that Inferno was [...] "a dazzling series of set pieces designed to give the impression that the real world is terrifying, beautiful, erotic and dangerous Inferno is a masterpiece of absolute film, and perhaps the most underrated horror movie of the 1980s." [...] In 2013, Time Out compiled a list of the 100 greatest horror films ever made based on the top ten lists of over one hundred film directors, screenwriters, and critics, and Inferno was listed as #92; in the resulting critical commentary for the film, Nigel Floyd wrote, [...] "Horror cinema at its most baroque: a simple libretto is embroidered with elaborate, <b>flowing</b> <b>camera</b> movements, abstract blocks of colour, unsettling sound effects and soundtrack composer Keith Emerson’s thunderous rock variations on Verdi...Argento’s best work is far behind him, but this alone justifies his cult reputation." ...|$|R
40|$|A Low-Cost Vision-Based Unmanned Aerial System for Extremely Low-Light GPS-Denied Navigation and Thermal Imaging}, {{abstract}} = {This paper {{presents the}} design and implementation details of a complete unmanned aerial system (UAS) based on commercial-off-the-shelf (COTS) components, focusing on safety, security, search and rescue scenarios in GPS-denied environments. In particular, the aerial platform is capable of semi-autonomously navigating through extremely low-light, GPS-denied indoor environments based on onboard sensors only, including a downward-facing optical <b>flow</b> <b>camera.</b> Besides, an additional low-cost payload camera system is developed to stream both infrared video and visible light video to a ground station in real-time, {{for the purpose of}} detecting sign of life and hidden humans. The total cost of the complete system is estimated to be $ 1150, and the effectiveness of the system has been tested and validated in practical scenarios...|$|E
40|$|MEMS offers {{exciting}} {{possibilities for}} the fabrication of bio-inspired mechanosensors. Over the last few years, {{we have been working}} on cricket- inspired hair-sensor arrays for spatio-temporal flow-field observations (i. e. <b>flow</b> <b>camera)</b> and source localisation. Whereas making flow-sensors as energy efficient as cricket hair-sensors appears to be a real challenge we have managed to fabricate capacitively interrogated sensors with sub-millimeter per second flow sensing thresholds, to use them in lateral line experiments, address them individually while in arrays, track transient flows, and use non-linear effects to achieve parametric filtering and amplification. In this research, insect biologists and engineers have been working in close collaboration, generating a bidirectional flow of information and knowledge, beneficial to both, for example, where the engineering has greatly benefitted from the insights derived from biology and biophysical models, the biologists have taken advantage of MEMS structures allowing for experiments that are hard to do on living material...|$|E
40|$|This paper {{presents}} {{the design of}} quadrotor control architecture, based on crowd-sourcing electronics. The aim of this quadrotor {{is to provide a}} test-bed for vision-based autonomous navigation system in GPS denied environments. The control architecture consists of a cascaded structure, where an attitude controller nested in velocity and altitude controllers. The sub-controllers are all linear controllers with feedforward term to linearize the quadrotor dynamics. The control and sensor fusion algorithm is developed under Arduino compatible open source electronics, whereas the complete design also includes an additional downward facing optical flow sensor (PX 4 <b>FLOW</b> <b>camera)</b> for horizontal velocity estimation and vehicle altitude estimation, and a separate Linux embedded computer (Odriod-U 3) for future Simultaneous Localization And Mapping (SLAM) vision algorithm development. In current stage, by utilizing the PX 4 FLOW sensor, it is capable of horizontal velocity control and altitude hold. Besides, a ground station GUI software is developed in MATLAB for two-way telemetry visualization and in-air parameter tuning...|$|E
40|$|Abstract. A head-mounted {{camera is}} {{a useful tool for}} {{studying}} the usability of mobile devices in the field. In this paper, a computerized visualization method is presented. It includes the target trajectory mapped with the deformable template-based tracking algorithm and landmarks-based relative object registration. A landmine detection training video is used for the case study. The results show that this approach has advantages over optical <b>flow</b> and overhead <b>camera</b> methods. ...|$|R
40|$|We {{perform a}} {{qualitative}} and quantitative analysis of various multi-frame color optical flow methods for synthetic and real panning and zooming image sequences. We show that optical flow accuracy improvement can be significant if color images are available instead of gray value or saturation images. We show the usefulness of a directional regularization constraint for computing optical <b>flow</b> when the <b>camera</b> motion {{is known to be}} panning or zooming. 1...|$|R
5000|$|The episode {{on which}} Hexum {{had been working}} was {{broadcast}} on November 3, 1984, two weeks after Hexum's death. Cover Up continued production without Hexum's character. Three weeks later, on November 24, Antony Hamilton was introduced as agent Jack Striker, posing as a new member of the modeling team. Hexum's character, Mac, is noticeably absent, said to be on another mission. At {{the end of the}} episode, Jack breaks the news that Mac has been killed on the other assignment and would not be coming back. As the tears <b>flowed,</b> the <b>camera</b> panned back, and a memoriam written by Glen Larson appeared onscreen:"When a star dies, its light continues to shineacross the universe for millenniums.Jon-Erik Hexum died in October of this year...but the lives he touched will continue to be brightened by his light...forever...and ever." ...|$|R
40|$|The filliform hairs of crickets {{are among}} the most {{sensitive}} flow sensing elements in nature. The high sensitivity of these hairs enables crickets in perceiving tiny air-movements which are only just distinguishable from noise. This forms our source of inspiration to design highly-sensitive array system made of artificial hair sensors for flow pattern observation i. e. <b>flow</b> <b>camera.</b> The realization of such high-sensitive hair sensor requires designs with low thermo-mechanical noise to match the detection-limit of crickets’ hairs. Here we investigate the damping factor in our artificial hair-sensor using different methods, as it {{is the source of the}} thermo-mechanical noise in MEMS structures. The theoretical analysis was verified with measurements in different conditions to estimate the damping factor. The results show that the damping factor of the artificial hair sensor as estimated in air is in the range of 10 − 12 N m/rad s− 1, which translates into a 93 μm/s threshold airflow velocity...|$|E
40|$|Laser Doppler Blood Flowmetry is a {{non-invasive}} technique {{that has been}} I developed and used for measuring microvascular blood flow in tissue. The technique utilises the backscattering of the laser light from moving red blood cells and static tissue in order to extract information such as the concentration and flow. This thesis describes {{the early stages of}} the development of an integrated optical sensor array to perform full field laser Doppler blood flow imaging. This technique will eliminate the need for mechanical scanning and the data bottleneck that exists between the photodiode array and processing unit, so allowing the direct measurement ofblood flow maps to be obtained in real time. A single channel laser Doppler blood flowmetry device has been implemented using a photodetector linked to a field programmable gate array. Filters (low pass, band pass and frequency weighted) have been developed for processing the Doppler signals to obtain flow and concentration measurements. The responses of these filters are demonstrated using measurements from modulated light signals, a rotating diffusing disc and in vivo measurements of blood flow. Several types of a linear array system and current to voltage converter are considered for the first fabrication run of the project based on the cost of fabrication and performance of the system such as operating frequency, gain, bandwidth and signal to noise ratio. A 16 x 1 linear array of photodiodes is developed and integrated on the same chip with the laser Doppler processing design, successfully implemented in the single channel laser Doppler system, using the standard 0. 35 Jlm CMOS technology. The characterisation of each individual part of the design was carried out and compared with the Cadence simulation results. The performance of the system on a single pixel is also evaluated using a modulated laser as a light source. The knowledge gained from the characterisation and the overall performance of the linear array system is then used to develop a full field laser Doppler blood <b>flow</b> <b>camera.</b> EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|The {{structural}} {{properties of}} optic flow fields {{are used to}} develop constraints on the motion of image features over time. For several restricted cases of motion, these constraints greatly simplify the determination of inter-frame motion and the inference of environmental information. These structural properties are briefly reviewed. Procedures are presented for computing, and making environmental inferences from, optic <b>flow</b> produced when <b>camera</b> motion is known, translational, or restricted to a plane. Some applications are discussed. I...|$|R
40|$|In this paper, {{we propose}} {{a method for}} {{estimating}} ob-ject motion by three-dimensional scene <b>flow</b> using multiple <b>cameras.</b> The scene <b>flow</b> is regularized by applying sub-space constraints and then object motion is estimated us-ing RANSAC estimation. Regularizing the scene flow us-ing subspace constraints results in highly accurate scene flow because it eliminates the effect of noise caused by com-puting of optical flow. Simulation and experimental results demonstrated that this method {{can be used to}} accurately es-timate scene flow and object motion parameters for trans-lation and rotation. ...|$|R
40|$|Methane and {{nitrous oxide}} {{emissions}} fluxes were measured in 10 rice plantations located in Liberia, Guanacaste, working {{at least with}} 04 varieties of rice and two types of soil in the period August 2012 - April 2013. For the determination of <b>flows</b> static <b>camera</b> technique were used taking four air gas samples located in the headspace of the chamber using a plastic syringe of 12 ml at 0, 10, 20 and 30 min after camera location. The gas samples were analyzed with a gas chromatograph, equipped with FID and ECD. Averages of flow methane and nitrous oxide were recorded between 0, 12 to 1, 9 kg ha- 1 d- 1 and 0, 11 - 1, 1 mg ha- 1 d- 1, respectively, and no {{significant difference was found}} (p < 0, 05) in the values between different rice varieties and soil types subject experimental design...|$|R
40|$|The paper {{describes}} {{conception of}} a reconnaissance mobile robot TELERESCUER for inspecting underground coal mine areas affected by catastrophic events. The introduction describes the whole project background and the following sections deal with {{the design of the}} control system and communication between individual subsystems. The subsystems described include the motion subsystem, the sensory subsystem (temperatures, gas concentration, air <b>flow,</b> navigation and <b>cameras),</b> the subsystem for 3 D map data acquisition and the communication subsystem. Mentioned also is the ATEX implementation (where the robot can safely operate in an environment with dangerous concentrations of methane) ...|$|R
50|$|The {{cinematography}} of D’Est’ {{uses only}} available light and is executed through long, real-time shots, {{contributing to the}} genuine and unstaged nature of the film. Akerman uses two main filming approaches: the stationary fixed perspective, with figures <b>flowing</b> towards the <b>camera,</b> and the tracking shot, with the camera moving slowly along streets and paths. The film also includes examples of the panning shot, where the camera rotates around a central point. The moving shots {{convey a sense of}} anxiety and vertigo. The stalking nature of the shots reveals the inhumanity of the camera.|$|R
40|$|A {{novel model}} for {{simultaneous}} estimation of full 3 D motion and 3 D position in world coordinates from multi camera sequences is presented. To this end scene flow [29] and disparity are estimated {{in a single}} estimation step. The key idea is to interpret sequences of 2 or more cameras as one 4 D data set. In this 4 D space a given motion model, a camera model and a brightness change model are combined into a brightness change constraint equation (BCCE) combining changes due to object motion and different camera positions. The es-timation of parameters in this constraint equation is demonstrated using a weighted total least squares es-timator called structure tensor. An evaluation of sys-tematic errors and noise stability for a 5 camera setup is shown as well as results on synthetic sequences with ground truth and data acquired under controlled labo-ratory conditions. KEY WORDS optical flow, scene <b>flow,</b> multiple <b>cameras,</b> disparity, depth, 3 D motion...|$|R
30|$|For {{large-scale}} consumer-generated video archives, {{a simple}} and fast method is effective since camera motions in consumer-generated videos are often very simple compared to those in professional videos. Our proposed method uses voting of optical <b>flows</b> to capture <b>camera</b> motions. It captures horizontal and vertical slow panning, {{which is the most}} frequent camera motion in consumer-generated videos, to remove camera motions. While complicated camera motions such as zoom, tilt, and their combinations cannot be captured, major foreground objects that have important meaning in multi-media events are expected to be detected since they are often {{in the center of a}} video with camera panning.|$|R
40|$|A {{wide variety}} of {{techniques}} for visual navigation using robot-mounted cameras have been described {{over the past several}} decades, yet adoption of optical flow navigation techniques has been slow. This demo illustrates what visual navigation has to offer: robust hazard detection (including precipices and obstacles), high-accuracy open-loop odometry, and stable closed-loop motion control implemented via an optical flow based visual odometry system. This work is based on 1) open source vision code, 2) common computing hardware, and 3) inexpensive, consumer-quality cameras, and as such should be accessible to many robot builders. Demo Overview Optical <b>flow</b> field and <b>camera</b> ego-motion estimation hav...|$|R
40|$|We {{investigate}} {{methods to}} reconstruct the optical <b>flow</b> generated by <b>camera</b> rotation using autoassociative learning. A multi-layer perceptron is trained to reduce the dimensionality of flow data which are obtained from real image sequences while the camera is rotating against static scenes. After this learning, the perceptron is able to produce reconstructions of the flow removing the noises in the original flow data. It is also shown that robustness of reconstruction for noisy data is improved by two changes: introduction of confidence values of optical flow into the error function and application of an additional data correction method...|$|R
40|$|International audienceWe present here a novel {{cross-platform}} {{library to}} facilitate {{research and development}} applications dealing with augmented reality (AR). Features include 2 D and 3 D objects visualization and interaction, <b>camera</b> <b>flow</b> and image manipulation, and soft-body deformation. Our aim is to provide computer vision specialists' with tools to facilitate AR application development by providing easy and {{state of the art}} access to GUI creation, visualization and hardware management. We demonstrate both the simplicity and the efficiency of coding AR applications through three detailed examples. PoLAR can be downloaded at [URL] and is distributed under the GPL licence...|$|R
40|$|We {{apply the}} 3 D-orientation tensor {{representation}} {{to construct an}} object tracking algorithm. 2 D-line normal flow is estimated by computing the eigenvector associated with the largest eigenvalue of 3 D (two spatial dimensions plus time) tensors with a planar structure. Object's true 2 D velocity is computed by averaging tensors with consistent normal flows, generating a 3 D line represention that corresponds to a 2 D point in motion. <b>Flow</b> induced by <b>camera</b> rotation is compensated for by ignoring points with velocity consistent with the ego-rotation. A region-of-interest growing process based on motion consistency generates estimates of object size and position...|$|R
40|$|The paper {{presents}} {{experimental results}} of the optical measurements of flow field around a fluttering NACA 0015 profile elastically supported with {{two degrees of freedom}} in subsonic wind <b>flow.</b> The high-speed <b>camera</b> was used for the interferometry visualization of the airflow in different phases of the profile motion. Special care was devoted to the plotting of the fringes near the surface of the profile, which was blurry due to the fast vibration. Examples of the interferograms, pressure and velocity development around the surface of the vibrating body and the phase shift between rotation and translation cycles are presented...|$|R
40|$|International audienceThis paper {{presents}} {{a novel approach}} for object identification and steady tracking in mobile augmented reality applications. First, the system identifies the object of interest using the KAZE algorithm. Then, the target tracking is enabled with the optical <b>flow</b> throughout the <b>camera</b> instant video stream. Further, the camera pose is determined by estimating the key transformation relating the camera reference frame {{according to the world}} coordinate system. Therefore, the visual perception is augmented with 3 D virtual graphics overlaid on target object within the scene images. Finally, experiments are conducted to evaluate the system performances in terms of accuracy, robustness and computational efficiency as wel...|$|R
40|$|In this study, {{effect of}} water jet on the {{hydraulic}} jump in horizontal channel was investigated. The {{aim of this}} study was to determine effect of the water jet with different flow rates to the hydraulic jump characteristics. The experiments were carried out in different upstream Froude numbers in the range of 3. 43 - 4. 83 and five different water jet discharges. Free jump and jumps with jets were analyzed by image processing technique with a high speed SVHS <b>camera.</b> <b>Flow</b> structures, roller lengths, water surface profiles and energy losses during free hydraulic jump and hydraulic jumps with water jet were studied and compared experimentally...|$|R
30|$|Stereo-motion fusion {{has been}} studied in a {{theoretical}} manner by Waxman and Duncan [22]. The important result was the relationship between camera’s 3 D motion and corresponding image velocities with stereo constraints. Our work builds on the basic principles presented in [22] and extends it to dynamic scene analysis. In this work, a mathematical model, integrating optical <b>flow,</b> depth, and <b>camera</b> ego-motion parameters, is firstly derived from Waxman and Duncan’s theoretical analysis. Camera’s ego-motion is then estimated from the model by using ground feature points, and accordingly ego-motion flow of the image is calculated from the model. A moving target is detected from the difference of the mixed flow and the ego-motion flow.|$|R
40|$|We {{address the}} {{procurement}} of new components for recyclable {{products in the}} context of Kodak's single-use camera. The objective is to find an ordering policy that minimizes the total expected procurement, inventory holding, and lost sales cost. Distinguishing characteristics of the system are the uncertainty and unobservability associated with return <b>flows</b> of used <b>cameras.</b> We model the system as a closed queueing network, develop a heuristic procedure for adaptive estimation and control, and illustrate our methods with disguised data from Kodak. Using this framework, we investigate the effects of various system characteristics such as informational structure, procurement delay, demand rate, and length of the product's life cycle. closed queueing networks, production control, em algorithms, distributed lag model...|$|R
