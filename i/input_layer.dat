908|541|Public
5000|$|The input [...] to a neuron is the {{weighted}} sum of outputs [...] of previous neurons. If the neuron {{is in the}} first layer after the <b>input</b> <b>layer,</b> the [...] of the <b>input</b> <b>layer</b> are simply the inputs [...] to the network. The number of input units to the neuron is [...] The variable [...] denotes the weight between neurons [...] and [...]|$|E
5000|$|If the neuron is in {{the first}} layer after the <b>input</b> <b>layer,</b> [...] is just [...]|$|E
5000|$|Architecturally, the {{simplest}} {{form of an}} autoencoder is a feedforward, non-recurrent neural network {{very similar to the}} multilayer perceptron (MLP) - having an <b>input</b> <b>layer,</b> an output layer and one or more hidden layers connecting them -, but with the output layer having the same number of nodes as the <b>input</b> <b>layer,</b> and with the purpose of reconstructing its own inputs (instead of predicting the target value [...] given inputs [...] ). Therefore, autoencoders are unsupervised learning models.|$|E
30|$|Artificial {{recharge}} of aquifers is {{a needed}} strategy for water resources reinforcement in semiarid regions. The new model {{will be of}} interest to select the favorable area for aquifer recharge based on five <b>input</b> <b>layers</b> (temperature, rainfall, slope, stream network density and the geology of the basin).|$|R
40|$|AbstractThe aimof {{this paper}} is to {{evaluate}} the suitability of land for barley in the Benghazi region in Northeast Libya. A land evaluation model was constructed using limiting factor method and application of GIS (Weighted Overlay Technique) integrated with multi-criteria analysis (Analytical Hierarchy Process). How the results change when employing different approaches and analytical methods within the weighted overlay technique was explored, i. e., when the number of <b>input</b> <b>layers</b> is increased to 14 suitability layers and each land characteristic is considered as a map layer by itself, as proposed in this study, compared with previous studies where the resultant land suitability map was calculated from just three <b>input</b> <b>layers</b> suitability layer. CROSSTAB module was used to assess the agreement between the two land suitability maps. The overall agreement was about 19 %. The obtained results were compared with observed yield; this comparison showed that the land suitability produced by model 2 was more accurate...|$|R
30|$|In (7) and (8), ωHO is a N[*]×[*]K vector indicting {{the weights}} between the hidden layers and output layers, and ωIH is a J[*]×[*]N vector indicting the weights between the <b>input</b> <b>layers</b> and hidden layers, where N {{is the number}} of hidden nodes. hi is the hidden layer’s output vector and g is the {{activation}} function in hidden nodes [27].|$|R
5000|$|Perform {{a forward}} {{activation}} pass by feeding an {{input from the}} <b>input</b> <b>layer</b> to the hidden layer and record the activations at the hidden layer ...|$|E
50|$|An autoencoder, autoassociator or Diabolo {{network is}} similar to the {{multilayer}} perceptron (MLP) - with an <b>input</b> <b>layer,</b> an output layer and one or more hidden layers connecting them. However, the output layer has the same number of units as the <b>input</b> <b>layer.</b> Its purpose is to reconstruct its own inputs (instead of emitting a target value. Therefore, autoencoders are unsupervised learning models. An autoencoder is used for unsupervised learning of efficient codings, typically for the purpose of dimensionality reduction and for learning generative models of data.|$|E
5000|$|... {{initialize}} network weights (often small random values) do forEach training example named ex prediction = neural-net-output(network, ex) // forward pass actual = teacher-output(ex) compute error (prediction - actual) at {{the output}} units compute [...] for all weights from hidden layer to output layer // backward pass compute [...] for all weights from <b>input</b> <b>layer</b> to hidden layer // backward pass continued update network weights // <b>input</b> <b>layer</b> not modified by error estimate until all examples classified correctly or another stopping criterion satisfied return the network ...|$|E
40|$|Neocortical neurons in vivo receive {{concurrent}} synaptic inputs {{from multiple}} sources, including feedforward, horizontal, and feedback pathways. Layer 2 / 3 {{of the visual}} cortex receives feedforward <b>input</b> from <b>layer</b> 4 and horizontal <b>input</b> from <b>layer</b> 2 / 3. Firing of the pyramidal neurons, which carries the output to higher cortical areas, depends critically on the interaction of these pathways. Here we examined synaptic integration of <b>inputs</b> from <b>layer</b> 4 and layer 2 / 3 in rat visual cortical slices. We found that the integration is sublinear and temporally asymmetric, with larger responses if layer 2 / 3 <b>input</b> preceded <b>layer</b> 4 <b>input.</b> The sublinearity depended on inhibition, and the asymmetry was largely attributable {{to the difference between}} the two inhibitory inputs. Interestingly, the asymmetric integration was specific to pyramidal neurons, and it strongly affected their spiking output. Thus via cortical inhibition, the temporal order of activation of layer 2 / 3 and layer 4 pathways can exert powerful control of cortical output during visual processing...|$|R
30|$|An autoencoder, firstly {{introduced}} in Rumelhart et al. [72], is a feedforward network that {{can learn a}} compressed, distributed representation of data, usually {{with the goal of}} dimensionality reduction or manifold learning. An autoencoder usually has one hidden <b>layer</b> between <b>input</b> and output <b>layer.</b> Hidden layer usually has a more compact representation than <b>input</b> and output <b>layers,</b> i.e., hidden layer has fewer units than <b>input</b> or output <b>layer.</b> <b>Input</b> and output <b>layer</b> usually has the same setting, which allows an autoencoder to be trained unsupervised with same data fed in at the input and to be compared with what is at the output layer. The training process is the same as traditional neural network with backpropagation; the only difference lying in the error is computed by comparing the output to the data itself [2]. Mitchell et al. [73], showed a nice illustration of autoencoder. He built a three-layer structure (eight unit for <b>input</b> and output <b>layer</b> and three unit for the hidden layer in between), then he fed the one-hot vector representation into the <b>input</b> and output <b>layer,</b> the hidden layer turned out to approximating the data with inputs’ binary representation [2].|$|R
40|$|For ship detection, X-band {{synthetic}} aperture radar (SAR) imagery provides very useful data, in that ship targets look much brighter than surrounding sea clutter due to the corner-reflection effect. However, there are many phenomena which bring out false detection in the SAR image, such as noise of background, ghost phenomena, side-lobe effects and so on. Therefore, when ship-detection algorithms are carried out, we should consider these effects and mitigate them to acquire a better result. In this paper, we propose an efficient method to detect ship targets from X-band Kompsat- 5 SAR imagery using the artificial neural network (ANN). The method produces the ship-probability map using ANN, and then detects ships from the ship-probability map by using a threshold value. For the purpose of getting an improved ship detection, we strived to produce optimal <b>input</b> <b>layers</b> used for ANN. In order to reduce phenomena related to the false detections, the non-local (NL) -means filter and median filter were utilized. The NL-means filter effectively reduced noise on SAR imagery without smoothing edges of the objects, and the median filter {{was used to remove}} ship targets in SAR imagery. Through the filtering approaches, we generated two <b>input</b> <b>layers</b> from a Kompsat- 5 SAR image, and created a ship-probability map via ANN from the two <b>input</b> <b>layers.</b> When the threshold value of 0. 67 was imposed on the ship-probability map, the result of ship detection from the ship-probability map was a 93. 9 % recall, 98. 7 % precision and 6. 1 % false alarm rate. Therefore, the proposed method was successfully applied to the ship detection from the Kompsat- 5 SAR image...|$|R
5000|$|Use the {{difference}} between the old activation (Aold) and the sharpened activation (Anew) as an error, backpropagate this error to the <b>input</b> <b>layer,</b> and modify the weights of input-to-output appropriately ...|$|E
50|$|Using {{theoretical}} approaches, he {{has provided}} {{insights into the}} structure and function of neural circuits, showing that synaptic connectivity within the cerebellar <b>input</b> <b>layer</b> is optimal for encoding information and separating overlapping activity patterns.|$|E
5000|$|In {{artificial}} neural networks, {{a hybrid}} Kohonen self-organizing map {{is a type}} of self-organizing map (SOM) named for the Finnish professor Teuvo Kohonen, where the network architecture consists of an <b>input</b> <b>layer</b> fully connected to a 2-D SOM or Kohonen layer.|$|E
30|$|Clustering was {{performed}} independently {{for each of}} the two subpopulations of 317 female and 342 male patients. A series of experiments {{was performed}} so that different parts of available information about patients were used as <b>input</b> <b>layers.</b> The presented results were obtained by using biological measurements and laboratory data (in total 56 descriptors) as the first layer, and symptoms and clinical data (in total 187 descriptors) as the second layer.|$|R
40|$|The {{mushroom}} bodies, central neuropils in the arthropod brain, {{are involved}} in learning and memory and in the control of complex behavior. In most bisects, the mushroom bodies receive direct olfactory input in their calyx region. In Hymenoptera, olfactory <b>input</b> is <b>layered</b> in the calyx. In ants, several layers can be discriminated that correspond to different clusters of glomeruli in the antennal lobes, perhaps corresponding to different classes of odors. Only in Hymenoptera, the mushroom body calyx also receives direct visual input from the optic lobes. In bees, six calycal <b>layers</b> receive <b>input</b> from different classes of visual interneurons, probably representing {{different parts of the}} visual field and different visual properties. Taken together, the mushroom bodies receive distinct multisensory information in many segregated <b>input</b> <b>layers...</b>|$|R
30|$|In {{order to}} utilize the ANN, {{different}} types of remote sensing data are required. In this study, TanDEM-X (Wessel 2016), SRTM, surveyed high accuracy DEM and multispectral imagery from Sentinel 2 were used. As the SRTM is attributed with 30 [*]m horizontal resolution in contrast to TanDEM-X (12 [*]m), surveyed DEM (5 [*]m) and Sentinel 2 (10 – 60 [*]m), all <b>input</b> <b>layers</b> are standardized to 20 [*]m resolution through sampling method.|$|R
50|$|The <b>input</b> <b>layer</b> neurode {{connect to}} each neurode in the hidden layer. The hidden layer is a Kohonen network which categorizes the pattern that was input. The output layer is an outstar array which reproduces the correct output pattern for the category.|$|E
5000|$|It {{consists}} of one <b>input</b> <b>layer,</b> one hidden layer and one output layer. The number of neurons in the output layer {{depends on the}} number of hidden units K. Each hidden neuron has N binary input neurons: The weights between input and hidden neurons are also binary: ...|$|E
50|$|A key {{application}} is the direct targeting of hidden nodes in neural networks. By applying a Monte Carlo Polarization filter to the <b>input</b> <b>layer</b> of the neural system, hidden layers will be systematically and dynamically {{selected based on}} user-defined characteristics. Only the specified layers and units will receive and process the data.|$|E
5000|$|The output adapter {{layer is}} {{typically}} responsible for archival of measurements {{received from the}} <b>input</b> adapter <b>layer</b> and the action adapter layer.|$|R
40|$|Visual {{perception}} and action are strongly linked with parallel processing channels connecting the retina, the lateral geniculate nucleus, and the <b>input</b> <b>layers</b> {{of the primary}} visual cortex. Achromatic vision is provided by {{at least two of}} such channels formed by the M and P neurons. These cell pathways are similarly organized in primates having different lifestyles, including species that are diurnal, nocturnal, and which exhibit a variety of color vision phenotypes. We describe the M and P cell properties by 3 D Gábor functions and their 3 D Fourier transform. The M and P cells occupy different loci in the Gábor information diagram or Fourier Space. This separation allows the M and P pathways to transmit visual signals with distinct 6 D joint entropy for space, spatial frequency, time, and temporal frequency. By combining the M and P impacts on the cortical neurons beyond V 1 <b>input</b> <b>layers,</b> the cortical pathways are able to process aspects of visual stimuli with a better precision than it would be possible using the M or P pathway alone. This performance fulfils the requirements of different behavioral tasks...|$|R
30|$|Based on calculation, {{the area}} {{potential}} for development is 6300  ha and 25, 200 cells (50 [*]×[*] 50  m). For modeling, nine <b>input</b> <b>layers,</b> nine hidden layers, and one output layer like the previous model is used. In the forecasting process and in producing the exclusionary map, worn-out tissue, vacant and abandoned urban lands, and unsuitable land-use maps are coded as development potential and existing green spaces and lands with high potential for natural hazards are coded as development restriction areas.|$|R
50|$|Each neuron in the <b>input</b> <b>layer</b> {{represents}} a predictor variable. In categorical variables, N-1 neurons are used {{when there are}} N number of categories. It standardizes {{the range of the}} values by subtracting the median and dividing by the interquartile range. Then the input neurons feed the values to each of the neurons in the hidden layer.|$|E
5000|$|The {{question}} is how many middle subswitches are needed, and therefore how many total wires should connect the <b>input</b> <b>layer</b> to the middle layer. Since telephone switches are symmetric (callers and callees are interchangeable), the same logic will apply to the output layer, and the middle subswitches will be [...] "square", having {{the same number of}} inputs as outputs.|$|E
5000|$|Radial basis {{function}} (RBF) networks {{typically have}} three layers: an <b>input</b> <b>layer,</b> a hidden layer with a non-linear RBF activation function and a linear output layer. The input can be modeled as a vector of real numbers [...] The {{output of the}} network is then a scalar function of the input vector, , and is given by ...|$|E
40|$|Every {{year during}} the rainy season, water-induced soil erosion poses serious spatial-environ-mental problems, causing heavy damage to {{agricultural}} lands, sedimentation in reservoirs, and water quality problems in nearby surface water bodies, from the plains to the mountain areas in Nepal. The goal {{of this study is}} to identify potential areas for soil erosion in sub and macro wa-tershed in Mustang, Nepal using remote sensing (RS) and geographic information systems (GIS) techniques. The study examines the possibility of advanced mapping of soil erosion-prone areas using a high spatial resolution image of QuickBird satellite and medium spatial resolution of Landsat satellite. The satellite image was classified using object-based image analysis (OBIA) tech-niques, taking into account spectral, spatial, and context information as well as hierarchical prop-erties. The resulting land cover classification was thereafter combined with additional data in ArcGIS, where the <b>input</b> <b>layers</b> were reclassified and all classes of the <b>input</b> <b>layers</b> were ranked according to their proneness to soil erosion. Soil erosion-prone areas were delineated in five classes ranging from “very high ” to “very low”. Using high spatial resolution image the study re-vealed that 22 % area categorized as “high erosion-prone ” areas and 5 % as “very high ” or “extreme...|$|R
30|$|Many Neural Networks (NN) {{models are}} similar or {{identical}} to well-known statistical {{techniques such as}} linear regression, polynomial regression, nonparametric regression, discriminant analysis, principal components analysis and cluster analysis. Radial Basis Function Network (RBFN) is {{a special kind of}} NNs that consists of <b>input</b> <b>layers,</b> only one hidden layer and output layers. It has radial basis functions in hidden units and linear functions in output units, with adjustable weights. In recent years, various fuzzified versions of the NNs and the RBF Network have been developed for linear, nonlinear and nonparametric regression models.|$|R
40|$|This paper {{discusses}} the function approximation {{properties of the}} "Gelenbe" random neural network (GNN) [5, 6, 9]. We use two extensions of the basic model: the bipolar GNN (BGNN) [7] and the clamped GNN (CGNN). We limit the networks to being feedforward and consider the case where the number of hidden layers does not exceed the number of <b>input</b> <b>layers.</b> With these constraints we show that the feedforward CGNN and the BGNN with s hidden layers (total of s + 2 layers) can uniformly approximate continuous functions of s variables...|$|R
5000|$|The {{neural network}} {{is a type}} of parallel-processing {{architecture}} that transforms any stimulus received by the input unit (i.e., stimulus units) to a signal for the output unit (i.e., response units) through a series of mid-level hidden units. Each unit in the <b>input</b> <b>layer</b> is connected to each unit in the hidden layer and, in turn, to each unit in the output layer.|$|E
5000|$|Input layer: One neuron {{appears in}} the <b>input</b> <b>layer</b> for each {{predictor}} variable. In the case of categorical variables, N-1 neurons are used where N {{is the number of}} categories. The input neurons standardizes the value ranges by subtracting the median and dividing by the interquartile range. The input neurons then feed the values to each of the neurons in the hidden layer.|$|E
50|$|The {{feedforward}} {{neural network}} {{was the first and}} simplest type. In this network the information moves only from the <b>input</b> <b>layer</b> directly through any hidden layers to the output layer without cycles/loops. Feedforward networks can be constructed with various types of units, such as binary McCulloch-Pitts neurons, the simplest of which is the perceptron. Continuous neurons, frequently with sigmoidal activation, are used in the context of backpropagation.|$|E
40|$|The {{data set}} {{was created for}} the purpose of updating/processing static <b>input</b> <b>layers</b> for LISFLOOD model. The LISFLOOD model is a {{hydrological}} rainfall-runoff model that is capable of simulating the hydrological processes that occur in a catchment. The new data set contains gridded numerical and descriptive information related to topography, channel geometry, land cover and soil characteristics of European and African river basins. This document gives a brief summary of the source geo-spatial data sets, the applied methodology and the main characteristics of the resulted data. JRC. DDG. H. 7 -Land management and natural hazard...|$|R
40|$|Based on a {{large scale}} spiking neuron model of the <b>input</b> <b>layers</b> 4 Cα and β of macaque, we {{identify}} neural mechanisms for the observed contrast dependent receptive field size of V 1 cells. We observe a rich variety of mechanisms for the phenomenon and analyze them based on the relative gain of excitatory and inhibitory synaptic inputs. We observe an average growth in the spatial extent of excitation and inhibition for low contrast, as predicted from phenomenological models. However, contrary to phenomenological models, our simulation results suggest this is neither sufficient nor necessary to explain the phenomenon. ...|$|R
40|$|This paper {{explores the}} {{possibilities}} of adopting Business Intelligence (BI), and Geographic Information System (GIS) to build a spatial intelligence and predictive analytical approach. The proposed approach will help in solving spatial problem which faces decision makers at health sector. The proposed spatial analytical approach will cover three main health planning issues. These issues are tackling health inequalities through geospatial monitor for inequalities in distribution of health units and its services, support decision-making with predictive analytics for common health indicators, and geoprocessing for <b>input</b> <b>layers</b> through dynamic health map and motion charts to support decision making...|$|R
