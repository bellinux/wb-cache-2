1246|1757|Public
5|$|<b>Facial</b> <b>recognition</b> software: A {{photograph}} {{transmitted by}} the SEALs to CIA headquarters in Langley, Virginia, for <b>facial</b> <b>recognition</b> analysis yielded a 90 to 95 percent likely match.|$|E
5|$|<b>Facial</b> <b>recognition</b> {{technology}} is {{being introduced to}} coincide with the release of the Biometric Passport. This technology will be used to improve identity verification, reduce identity-related fraud, and protect the legal identity of the citizens of the Republic of Lebanon. Similar {{technology is}} used in the Lebanese identity card.|$|E
5|$|Domestic sheep are {{sometimes}} used in medical research, particularly for researching cardiovascular physiology, {{in areas such}} as hypertension and heart failure. Pregnant sheep are also a useful model for human pregnancy, and have been used to investigate the effects on fetal development of malnutrition and hypoxia. In behavioral sciences, sheep have been used in isolated cases for the study of <b>facial</b> <b>recognition,</b> as their mental process of recognition is qualitatively similar to humans.|$|E
40|$|Two studies {{examined}} an unexplored motivational {{determinant of}} facial emotion recognition: observer regulatory focus. It was predicted that a promotion focus would enhance <b>facial</b> emotion <b>recognition</b> {{relative to a}} prevention focus because the attentional strategies associated with promotion focus enhance performance on well-learned or innate tasks - such as <b>facial</b> emotion <b>recognition.</b> In Study 1, a promotion or a prevention focus was experimentally induced and better <b>facial</b> emotion <b>recognition</b> was observed in a promotion focus compared to a prevention focus. In Study 2, individual differences in chronic regulatory focus were assessed and attention allocation was measured using eye tracking during the <b>facial</b> emotion <b>recognition</b> task. Results indicated that the positive relation between a promotion focus and <b>facial</b> emotion <b>recognition</b> is mediated by shorter fixation duration on the face which reflects a pattern of attention allocation matched to the eager strategy in a promotion focus (i. e., striving to make hits). A prevention focus {{did not have an}} impact neither on perceptual processing nor on <b>facial</b> emotion <b>recognition.</b> Taken together, these findings demonstrate important mechanisms and consequences of observer motivational orientation for <b>facial</b> emotion <b>recognition...</b>|$|R
40|$|Abstract. In this paper, <b>facial</b> {{expression}} <b>recognition</b> as {{the starting}} point, it is extracted the mixing characteristics of the facial expression, including geometric and texture features. It can {{solve the problem of}} the collection contains the degree based on Variable Precision Fuzzy Rough Set, It could improved the accuracy of <b>facial</b> expression <b>recognition</b> using the method, thus making the <b>facial</b> expression <b>recognition</b> process more accurate and efficient...|$|R
40|$|Aim: Deficits in <b>facial</b> affect <b>recognition</b> {{are well}} {{established}} in schizophrenia, yet relatively {{little research has}} examined <b>facial</b> affect <b>recognition</b> in hypothetically psychosis-prone or ‘schizotypal’ individuals. Those studies that have examined social cognition in psychosis-prone individuals have {{paid little attention to}} the association between <b>facial</b> emotion <b>recognition</b> and particular schizotypal personality features. The present study therefore sought to investigate relationships between <b>facial</b> emotion <b>recognition</b> and the different aspects of schizotypy. Methods: <b>Facial</b> affect <b>recognition</b> accuracy was examined in 50 psychiatrically healthy individuals assessed for level of schizotypy using the Schizotypal Personality Questionnaire. This instrument provides a multidimensional measure of schizophrenia proneness, encompassing ‘cognitive-perceptual’, ‘interpersonal’ and ‘disorganized’ features of schizotypy. It was hypothesized that the cognitive-perceptual and interpersonal aspects of schizotypy would be associated with difficulties identifying facial expressions of emotion during a forced-choice recognition task using a standardized series of colour photographs. Results: As predicted, interpersonal aspects of schizotypy (particularly social anxiety) were associated with reduced accuracy on the <b>facial</b> affect <b>recognition</b> task, but there was no association between affect recognition accuracy and cognitive-perceptual features of schizotypy. Conclusions: These results suggest that subtle deficits in <b>facial</b> affect <b>recognition</b> in otherwise psychiatrically healthy individuals {{may be related to the}} vulnerability for interpersonal communication difficulties, as seen in schizophrenia. <br /...|$|R
5|$|Sheep can {{recognize}} individual human and ovine faces, and remember them for years. In addition to long-term <b>facial</b> <b>recognition</b> of individuals, sheep can also differentiate emotional states through facial characteristics. If worked with patiently, sheep may learn {{their names and}} many sheep are trained to be led by halter for showing and other purposes. Sheep have also responded well to clicker training. Sheep {{have been used as}} pack animals; Tibetan nomads distribute baggage equally throughout a flock as it is herded between living sites.|$|E
5|$|The {{biometric}} data {{that is to}} be included on the Lebanese passport is the bearer's name, gender, date and place of birth, and a digital image of their face, ten fingerprints, palmprints. Lebanese immigration checkpoints will not be the only ones with the technology to read and authenticate the data from the RFID chip using a fingerprint scanner and <b>facial</b> <b>recognition</b> technology, but widespread adoption of Biometric passport technology around the world has seen the technology installed in international airports in the US, the UK and other countries.|$|E
5|$|Adoption of Snapdragon {{contributed to}} Qualcomm's {{transition}} from a wireless modem company to one that also produces {{a wider range of}} hardware and software for mobile devices. In July 2011 Qualcomm acquired certain assets from GestureTek in order to incorporate its gesture recognition intellectual property into Snapdragon SoCs. In mid-2012 Qualcomm announced the Snapdragon software development kit (SDK) for Android devices at the Uplinq developer conference. The SDK includes tools for <b>facial</b> <b>recognition,</b> gesture recognition, noise cancellation and audio recording. That November Qualcomm acquired some assets from EPOS Development in order to integrate its stylus and gesture recognition technology into Snapdragon products. It also collaborated with Microsoft to optimize Windows Phone 8 for Snapdragon semiconductors.|$|E
40|$|This {{thesis is}} to develop new <b>facial</b> {{expression}} <b>recognition</b> techniques based on 2 D/ 3 D images or videos, with the purpose to improve the recognition efficiency and accuracy of the current state-of-art. A fully automatic <b>facial</b> expression <b>recognition</b> system is designed, including real-time landmark detection, spatio-temporal feature extraction, hierarchical classification, and most discriminant facial regions identification for expression recognition. In general, the proposed system improved the <b>facial</b> expression <b>recognition</b> state-of-art...|$|R
40|$|Patients with {{schizophrenia}} {{suffer from}} impairments in <b>facial</b> affect <b>recognition</b> and social functioning. Since antipsychotic medication affects different {{areas in the}} brain, they may also affect target areas involved in emotional processing mechanisms. In this article, we review {{the findings of the}} effect of antipsychotic medication on <b>facial</b> affect <b>recognition</b> in schizophrenia. We searched PubMed for articles in English with the keywords schizophrenia, facial, affect, emotion, antipsychotic and medication, published till January 2008. Eight relevant articles were found describing original studies. No substantial improvements in <b>facial</b> affect <b>recognition</b> were found after treatment with either typical or atypical antipsychotic drugs. <b>Facial</b> affect <b>recognition</b> was not related to neuropsychological functioning, and it was unclear whether improvement of symptom severity was related to performance on the <b>facial</b> affect <b>recognition</b> tasks. It is recommended that future research should focus on measuring social skills and social functioning more directly, and by investigating the effects of additional behavioural treatments on <b>facial</b> affect <b>recognition</b> and social functioning relative to treatment with antipsychotic medication alone <br/...|$|R
40|$|Abstract — In this paper, {{we explore}} {{bilinear}} models for jointly addressing 3 D face and <b>facial</b> expression <b>recognition.</b> An elas-tically deformable model algorithm that establishes correspon-dence among {{a set of}} faces is proposed first and then bilinear models that decouple the identity and facial expression factors are constructed. Fitting these models to unknown faces enables us to perform face <b>recognition</b> invariant to <b>facial</b> expressions and <b>facial</b> expression <b>recognition</b> with unknown identity. A quantitative evaluation of the proposed technique is conducted on the publicly available BU- 3 DFE face database in comparison with Wang et al. ’s work [1] on <b>facial</b> expression <b>recognition</b> and our previous work [2] on face recognition. Experimental results demonstrate an overall 90. 5 % <b>facial</b> expression <b>recognition</b> rate and an 86 % rank- 1 face recognition rate. Index Terms — 3 D <b>facial</b> expression <b>recognition,</b> 3 D face recog-nition, elastically deformable model, bilinear model. I...|$|R
5|$|Cognitive {{disturbances}} {{can occur}} {{in the early stages}} of the disease and sometimes prior to diagnosis, and increase in prevalence with duration of the disease. The most common cognitive deficit in PD is executive dysfunction, which can include problems with planning, cognitive flexibility, abstract thinking, rule acquisition, inhibiting inappropriate actions, initiating appropriate actions, working memory, and control of attention. Other cognitive difficulties include slowed cognitive processing speed, impaired recall and impaired perception and estimation of time. Nevertheless, improvement appears when recall is aided by cues. Visuospatial difficulties are also part of the disease, seen for example when the individual is asked to perform tests of <b>facial</b> <b>recognition</b> and perception of the orientation of drawn lines. A person with PD has two to six times the risk of dementia compared to the general population.|$|E
5|$|Safety {{features}} on Lexus models range from {{stability and handling}} programs (Vehicle Stability Control and Vehicle Dynamics Integrated Management) to backup cameras, swivel headlights, and sonar warning systems. The Lexus Pre-Collision System (PCS) integrates multiple safety systems. In 2007, Lexus introduced the first car safety systems with infrared and pedestrian detection capabilities, lane keep assist, a Driver Monitoring System with <b>facial</b> <b>recognition</b> monitoring of driver attentiveness, and rear pre-collision whiplash protection, {{as part of the}} LS 460 PCS. As a safety precaution, Lexus GPS navigation systems in many regions feature a motion lockout when the vehicle reaches a set speed; to prevent distraction, navigation inputs are limited, while voice input and certain buttons are still accessible. This safety feature has attracted criticism because passengers cannot use certain functions when the vehicle is in motion. Pre-2007 models came with a hidden manufacturer override option, and updated European models allow operation in motion.|$|E
25|$|In 2017, {{the airport}} will begin using <b>facial</b> <b>recognition</b> technology, {{as part of}} the Primary Inspection Kiosk program.|$|E
40|$|International audienceObjective: Deficit in <b>facial</b> affect <b>recognition</b> is a {{well-documented}} {{impairment in}} schizophrenia, closely connected to social outcome. This deficit could {{be related to}} psychopathology, but also to a broader dysfunction in processing facial information. In addition, patients with schizophrenia inadequately use configural information-a type of processing that relies on spatial relationships between facial features. To date, no study has specifically examined the link between symptoms and misuse of configural information in the deficit in <b>facial</b> affect <b>recognition.</b> Method: Unmedicated schizophrenia patients (n = 30) and matched healthy controls (n = 30) performed a <b>facial</b> affect <b>recognition</b> task and a face inversion task, which tests aptitude to rely on configural information. In patients, regressions were carried out between <b>facial</b> affect <b>recognition,</b> symptom dimensions and inversion effect. Results: Patients, compared with controls, showed a deficit in <b>facial</b> affect <b>recognition</b> and a lower inversion effect. Negative symptoms and lower inversion effect could account for 41. 2 % of the variance in <b>facial</b> affect <b>recognition.</b> Conclusion: This study confirms the presence of a deficit in <b>facial</b> affect <b>recognition,</b> and also of dysfunctional manipulation in configural information in antipsychotic-free patients. Negative symptoms and poor processing of configural information explained a substantial part of the deficient <b>recognition</b> of <b>facial</b> affect. We speculate that this deficit may be caused by several factors, among which independently stand psychopathology and failure in correctly manipulating configural information...|$|R
40|$|AbstractDeficits {{in social}} {{cognition}} including <b>facial</b> affect <b>recognition</b> and their detrimental effects on functional outcome are well established in schizophrenia. Structured training can have substantial effects on social cognitive measures including <b>facial</b> affect <b>recognition.</b> Elucidating training effects on cortical mechanisms involved in <b>facial</b> affect <b>recognition</b> may identify causes of dysfunctional <b>facial</b> affect <b>recognition</b> in schizophrenia and foster remediation strategies. In the present study, 57 schizophrenia patients {{were randomly assigned}} to (a) computer-based facial affect training that focused on affect discrimination and working memory in 20 daily 1 -hour sessions, (b) similarly intense, targeted cognitive training on auditory-verbal discrimination and working memory, or (c) treatment as usual. Neuromagnetic activity was measured before and after training during a dynamic <b>facial</b> affect <b>recognition</b> task (5  s videos showing human faces gradually changing from neutral to fear or to happy expressions). Effects on 10 – 13  Hz (alpha) power during the transition from neutral to emotional expressions were assessed via MEG based on previous findings that alpha power increase is related to <b>facial</b> affect <b>recognition</b> and is smaller in schizophrenia than in healthy subjects. Targeted affect training improved overt performance on the training tasks. Moreover, alpha power increase during the dynamic <b>facial</b> affect <b>recognition</b> task was larger after affect training than after treatment-as-usual, though similar to that after targeted perceptual–cognitive training, indicating somewhat nonspecific benefits. Alpha power modulation was unrelated to general neuropsychological test performance, which improved in all groups. Results suggest that specific neural processes supporting <b>facial</b> affect <b>recognition,</b> evident in oscillatory phenomena, are modifiable. This should be considered when developing remediation strategies targeting social cognition in schizophrenia...|$|R
40|$|Impairment in <b>facial</b> affect <b>recognition</b> is {{prevalent}} after {{moderate to}} severe traumatic brain injury (TBI), and may underlie some problems in social functioning. Tentative work indicates that emotion recognition can improve with training, but {{the effectiveness of these}} programmes remains unclear. Little is known about whether broader cognitive deficits underlie <b>facial</b> affect <b>recognition</b> impairment. Less is known about baseline cognitive variables that predict treatment response and the relationship between changes in cognitive functioning and improvement in <b>facial</b> affect <b>recognition</b> after treatment. The present research formed part of a multi-centre randomised controlled trial examining the efficacy of two affect recognition training programmes designed to improve emotion recognition in adults with {{moderate to severe}} TBI. Study One reports outcome data from the main trial. Seventy people with TBI and <b>facial</b> affect <b>recognition</b> difficulties were randomly assigned to nine sessions of one of three treatments: Faces, focusing on <b>facial</b> affect <b>recognition,</b> Stories, determining emotions from social context, and a control group. Participants completed tests assessing cognition, emotion recognition, community integration, interpersonal behaviour and empathy, and informants completed interpersonal and social functioning measures. Participants were assessed five times: initial screening, pre- and post-treatment, and at three- and six-month follow-up. Significant improvement was seen in the Faces group on the primary <b>facial</b> affect <b>recognition</b> outcome measure (DANVA 2 -Adult Faces). These gains were sustained at six months. No significant differences between treatment groups and the control group were found on interpersonal and social functioning measures. Study Two had 75 participants with <b>facial</b> affect <b>recognition</b> difficulties and investigated the relationship between <b>facial</b> affect <b>recognition</b> impairment and cognitive functioning. Greater <b>facial</b> affect <b>recognition</b> failures were related particularly to working memory, processing speed, and nonverbal memory. No relationship was found with executive functioning. Study Three explored the relationship between baseline cognitive variables, changes in cognitive functioning, and long term treatment response. Only older age was predictive of a better long-term response to Faces treatment. Improvement of <b>facial</b> affect <b>recognition</b> was not mediated by changes in cognitive functioning. This research provides further evidence that retraining is possible for affect recognition difficulties after traumatic brain injury...|$|R
25|$|Visuospatial skills difficulties, {{which are}} seen {{when the person}} with PD is for example asked to perform tests of <b>facial</b> <b>recognition</b> and {{perception}} of line orientation.|$|E
25|$|Damage to the FFA {{has been}} shown to lead to severe deficits in <b>facial</b> <b>recognition</b> and processing. These deficits can lead to {{difficulty}} in maintaining normal social relationships over an extended period.|$|E
25|$|Since her discovery, {{the girl}} was reconstructed forensically in efforts to {{identify}} her through <b>facial</b> <b>recognition.</b> The National Center for Missing & Exploited Children has released two illustrations and other artists have produced their own renderings.|$|E
40|$|As an {{important}} part of artificial intelligence and pattern <b>recognition,</b> <b>facial</b> expression <b>recognition</b> has drawn much attention recently and numerous methods have been proposed. Feature extraction is the most important part which directly affects the final recognition results. Independent component analysis (ICA) is a subspace analysis method, which is also a novel statistical technique in signal processing and machine learning that aims at finding linear projections of the data that maximize their mutual independence. In this paper, we introduce the basic theory of ICA algorithm in detail and then present the process of <b>facial</b> expression <b>recognition</b> based on ICA model. Finally, we use PCA and ICA algorithm to extract facial features, and then SVM classifier is used for <b>facial</b> expression <b>recognition.</b> Experimental results show ICA is a real effective <b>facial</b> expression <b>recognition</b> method and the recognition rate based on ICA is greater than based on PCA and 2 DPC...|$|R
40|$|Nonclinical {{psychotic}} symptoms (for example, low intensity or {{low frequency}} psychotic {{symptoms such as}} ideas of reference or single word auditory hallucinations) are common in adolescents and {{may be associated with}} an increased risk of developing a psychotic disorder in adulthood. Those at high risk of developing a psychotic disorder appear to perform poorly on <b>facial</b> emotion <b>recognition</b> tasks but the relationship between <b>facial</b> emotion <b>recognition</b> and nonclinical “psychosis like symptoms” (PLIKS) in children is unclear. We aimed to examine the association between childhood <b>facial</b> emotion <b>recognition</b> and PLIKS in adolescents...|$|R
40|$|<b>Facial</b> Expression <b>Recognition</b> {{is one of}} the {{exciting}} and challenging field; it has important applications in many areas such as data driven animation, human computer interaction and robotics. Extracting effective features from the human face is an important step for successful <b>facial</b> expression <b>recognition.</b> In this paper we have evaluated Local Binary Patterns of some important parts of human face, for person independent as well as person dependent <b>facial</b> expression <b>recognition.</b> Extensive experiments on JAFFE database are conducted. The experiment results show that person dependent method is highly accurate and outperform many existing methods...|$|R
25|$|White Paper: Explore Intel's user {{experience}} research, which shows how touchless multifactor authentication (MFA) can help healthcare organizations mitigate security risks while improving clinician efficiency, convenience, and patient care. This touchless MFA solution combines <b>facial</b> <b>recognition</b> and device recognition capabilities for two-factor user authentication.|$|E
25|$|Galdorisi and Verria used {{interviews}} of claimants, expert photo analysis, identifying {{people in the}} background and consultations with forensic anthropologists and <b>facial</b> <b>recognition</b> specialists. They concluded that the woman was Greta Zimmer Friedman and that she was wearing her dental hygienist uniform in the photograph.|$|E
25|$|Techniques from {{linear algebra}} {{are also used}} in {{analytic}} geometry, engineering, physics, natural sciences, computer science, computer animation, advanced <b>facial</b> <b>recognition</b> algorithms {{and the social sciences}} (particularly in economics). Because linear algebra is such a well-developed theory, nonlinear mathematical models are sometimes approximated by linear models.|$|E
40|$|In this paper, {{we explore}} {{bilinear}} models for jointly addressing 3 D face and <b>facial</b> expression <b>recognition.</b> An elastically deformable model algorithm that establishes correspondence among {{a set of}} faces is proposed first and then bilinear models that decouple the identity and facial expression factors are constructed. Fitting these models to unknown faces enables us to perform face <b>recognition</b> invariant to <b>facial</b> expressions and <b>facial</b> expression <b>recognition</b> with unknown identity. A quantitative evaluation of the proposed technique is conducted on the publicly available BU- 3 DFE face database in comparison with Wang et al. ’s work [1] on <b>facial</b> expression <b>recognition</b> and our previous work [2] on face recognition. Experimental results demonstrate an overall 90. 5 % <b>facial</b> expression <b>recognition</b> rate and an 86 % rank- 1 face recognition rate...|$|R
40|$|The {{performance}} of an automatic <b>facial</b> expression <b>recognition</b> {{system can be}} significantly improved by modeling the reliability of different streams of facial expression information utilizing multi-stream hidden Markov models (HMMs). In this paper, we present an automatic multi-stream HMM <b>facial</b> expression <b>recognition</b> system and analyze its performance. The proposed system utilizes facial animation parameters (FAPs), supported by the MPEG- 4 standard, as features for facial expression classification. Specifically, the FAPs describing {{the movement of the}} outer-lips and eyebrows are used as observations. Experiments are first performed employing single-stream HMMs under several different scenarios, utilizing outer-lip and eyebrow FAPs individually and jointly. A multi-stream HMM approach is proposed for introducing facial expression and FAP group dependent stream reliability weights. The stream weights are determined based on the <b>facial</b> expression <b>recognition</b> results obtained when FAP streams are utilized individually. The proposed multi-stream HMM facial expression system, which utilizes stream reliability weights, achieves relative reduction of the <b>facial</b> expression <b>recognition</b> error of 44 % compared to the single-stream HMM system. Index Terms- <b>facial</b> expression <b>recognition,</b> multi-stream HMMs, <b>facial</b> animation parameter...|$|R
40|$|Background A {{plethora of}} {{research}} on <b>facial</b> emotion <b>recognition</b> in autism spectrum disorders (ASD) exists and reported deficits in ASD compared to controls, particularly for negative basic emotions. However, these studies have largely used static high intensity stimuli. The current study investigated <b>facial</b> emotion <b>recognition</b> across three levels of expression intensity from videos, looking at accuracy rates to investigate impairments in <b>facial</b> emotion <b>recognition</b> and error patterns (’confusions’) to explore potential underlying factors. Method Twelve individuals with ASD (9 M/ 3 F; M(age) = 17. 3) and 12 matched controls (9 M/ 3 F; M(age) = 16. 9) completed a <b>facial</b> emotion <b>recognition</b> task including 9 emotion categories (anger, disgust, fear, sadness, surprise, happiness, contempt, embarrassment, pride) and neutral, each expressed by 12 encoders at low, intermediate, and high intensity. Results A <b>facial</b> emotion <b>recognition</b> deficit was found overall for the ASD group compared to controls, as well as deficits in recognising individual negative emotions at varying expression intensities. Compared to controls, the ASD group showed significantly more, albeit typical, confusions between emotion categories (at high intensity), and significantly more confusions of emotions as ‘neutral’ (at low intensity). Conclusions The <b>facial</b> emotion <b>recognition</b> deficits identified in ASD, particularly for negative emotions, {{are in line with}} previous studies using other types of stimuli. Error analysis showed that individuals with ASD had difficulties detecting emotional information in the face (sensitivity) at low intensity, and correctly identifying emotional information (specificity) at high intensity. These results suggest different underlying mechanisms for the <b>facial</b> emotion <b>recognition</b> deficits at low vs high expression intensity...|$|R
25|$|Machine {{perception}} {{is the ability}} to use input from sensors (such as cameras, microphones, tactile sensors, sonar and others) to deduce aspects of the world. Computer vision {{is the ability to}} analyze visual input. A few selected subproblems are speech recognition, <b>facial</b> <b>recognition</b> and object recognition.|$|E
25|$|On September 12, 2017, Apple {{introduced}} the iPhone 8 and iPhone 8 Plus, standing as evolutionary updates to its previous phones with a faster processor, improved display technology and upgraded camera systems. The company also announced iPhone X, which radically changes the hardware of the iPhone lineup, removing the home button {{in favor of}} <b>facial</b> <b>recognition</b> technology and featuring a near bezel-less design along with introducing wireless charging.|$|E
25|$|The {{biometric}} data {{included on the}} Malaysian passport is a digital photograph of the bearer's face, and images of their two thumbprints. Malaysian immigration checkpoints {{were the only ones}} with the technology to read and authenticate the data from the RFID chip using a fingerprint scanner and <b>facial</b> <b>recognition</b> technology, but widespread adoption of ePassport technology around the world has seen the technology installed in international airports in the US, the UK and other countries.|$|E
40|$|Deficits in <b>facial</b> emotion <b>recognition</b> in Parkinson’s disease {{patients}} {{has been}} well documented. Nevertheless, {{it is still not}} clear whether <b>facial</b> emotion <b>recognition</b> deficits are secondary to other cognitive impairments. The aim {{of this study was to}} answer the question of whether deficits in <b>facial</b> emotion <b>recognition</b> in PD result from impaired sensory processes, or from impaired decision processes. To address this question, we tested the ability to recognize a mixture of basic and complex emotions in 38 non-demented PD patients and 38 healthy controls matched on demographic characteristics. By using a task with an increased level of ambiguity, in conjunction with the Signal Detection Theory, we were able to differentiate between sensitivity and response bias in <b>facial</b> emotion <b>recognition.</b> Sensitivity and response bias for <b>facial</b> emotion <b>recognition</b> were calculated using a d-prime value and a c index respectively. Our study is the first to employ the EIS-F scale for assessing <b>facial</b> emotion <b>recognition</b> among PD patients; to test its validity as an assessment tool, a group comprising schizophrenia patients and healthy controls were also tested. Patients with PD recognized emotions with less accuracy than healthy individuals (d-prime) and used a more liberal response criterion (c index). By contrast, patients with schizophrenia merely showed diminished sensitivity (d-prime). Our results suggest that an impaired ability to recognize facial emotions in PD patients may result from both decreased sensitivity and a significantly more liberal response criteria, whereas <b>facial</b> emotion <b>recognition</b> in schizophrenia may stem from a generalized sensory impairment only...|$|R
40|$|Facial {{expression}} and emotion-related {{research has been}} a longstanding activity in psychology while computerized/automatic <b>facial</b> expression <b>recognition</b> of emotion is a relative recent and still emerging but active research area. Although many automatic computer systems have been proposed to address <b>facial</b> expression <b>recognition</b> problems, {{the majority of them}} fail to cope with the requirements of many practical application scenarios arising from either environmental factors or unexpected behavioural bias introduced by the users, such as illumination conditions and large head pose variation to the camera. In this thesis, two of the most influential and common issues raised in practical application scenarios when applying automatic <b>facial</b> expression <b>recognition</b> system are comprehensively explored and investigated. Through a series of experiments carried out under a proposed texture-based system framework for multi-view <b>facial</b> expression <b>recognition,</b> several novel texture feature representations are introduced for implementing multi-view <b>facial</b> expression <b>recognition</b> systems in practical environments, for which the state-of-the-art performance is achieved. In addition, a variety of novel categorization schemes for the configurations of an automatic multi-view <b>facial</b> expression <b>recognition</b> system is presented to address the impractical discrete categorization of facial expression of emotions in real-world scenarios. A significant improvement is observed when using the proposed categorizations in the proposed system framework using a novel implementation of the block based local ternary pattern approach...|$|R
40|$|We {{investigated}} {{the relationship between}} a change in sleep quality and <b>facial</b> emotion <b>recognition</b> accuracy in a group of mentally-disordered inpatients at a secure forensic psychiatric unit. Patients whose sleep improved over time also showed improved <b>facial</b> emotion <b>recognition</b> while patients who showed no sleep improvement showed no change in emotion recognition...|$|R
