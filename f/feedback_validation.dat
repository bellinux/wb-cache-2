5|51|Public
50|$|The {{desire to}} form and {{maintain}} social bonds {{is among the most}} powerful human motives. If an individual’s sense of social connectedness is threatened, their ability to self-regulate suffers. Social relationships are important for human functioning and well-being therefore, research on how social relationships affect people’s personal interests and motivated behavior has been a focus of numerous studies. Walton, Cohen, and Spencer for example, believed that a mere sense of social connectedness (even with people who were unfamiliar) can cause one to internalize the goals and motivations of others. By doing so, this shapes people’s motivated behavior suggesting achievement motivation and one’s self-identity are highly sensitive to minor cues of social connection. Mere belonging is defined as an entryway to a social relationship which is represented by a small cue of social connection to an individual or group. Social belonging is a sense of relatedness which is connected to a positive, lasting, and significant interpersonal relationships. While mere belonging is a minimal or even chance social connection, social belonging factors are characterized as social <b>feedback,</b> <b>validation,</b> and shared experiences. Sharing common goals and interests with others strengthens positive social bonds and may enhance feelings of self-worth.|$|E
40|$|Setting the {{baseline}} for the greenhouse effect, quantification of the water-vapor <b>feedback,</b> <b>validation</b> of longwave radiation models, {{determination of the}} trend in the clear sky albedo of the ocean, and determination {{of the role of}} clouds in climate are considered. A summary of cloud radiative forcing estimates is presented, and it is noted that the longwave cloud forcing is essentially the greenhouse effect of the clouds, and that the CO 2 concentration in the atmosphere has to be increased by a factor of 250 to equal the cloud greenhouse effect. It is pointed out that the short-wave cloud forcing is due to the enhancement of the albedo of the planet by clouds. The decrease in the solar absorption of 48. 4 W/sq m by clouds is found to be larger than its greenhouse effect by about 50 pct...|$|E
40|$|A {{flexible}} endoscope {{could reach the}} potential surgical site via a single small incision on the patient or even through natural orifices, making it a very promising platform for surgical procedures. However, endoscopic surgery has strict spatial constraints on both tool-channel size and surgical site volume. It is therefore very challenging to deploy and control dexterous robotic instruments to conduct surgical procedures endoscopically. Pioneering endoscopic surgical robots have already been introduced, but the performance {{is limited by the}} flexible neck of the robot that passes through the endoscope tool channel. In this article we present a series of new developments to improve the performance of the robot: a force transmission model to address flexibility, elongation study for precise position control, and tissue property modeling for haptic <b>feedback.</b> <b>Validation</b> experiment results are presented for each sector. An integrated control architecture of the robot system is given in the end. © 2013 Elsevier Ireland Ltd. link_to_subscribed_fulltex...|$|E
40|$|Disturbances {{observations}} q Crayons or colored pencils R elating various observations {{with each}} other and with ideas/ theories/concepts about how other similar systems operate can help us understand the processes in the observed system. 10 INTERPRETING OBSERVATIONS For accuracy, compile all data before team members separate! Summarize and <b>feedback</b> for <b>validation</b> as soon as possible...|$|R
40|$|This paper {{describes}} the main design principles underlying DVS and NUCM {{together with the}} basics issues regarding their implementation. DVS has been used and is currently being used for collaborative authoring involving several authors distributed over five different sites on the Internet. We also discuss this first experience and the <b>feedback</b> and <b>validation</b> for both DVS and NUCM...|$|R
40|$|In our service-based society, {{expertise}} {{is becoming increasingly}} recognized as a valuable and scarce resource. Thus, the demand for an integrated expert finder that understands whether it has found a current, relevant and credible expert will grow. We offer a three pronged approach which combines data mining, self reporting and referral by others together {{with a number of}} strategies which provide <b>feedback</b> and <b>validation</b> of the data gathered via data mining and self-reporting. The feedback mechanism offers a two-way communication channel between the service requester and the service provider, the expert. 6 page(s...|$|R
40|$|This paper {{describes}} {{the development of}} standards {{for the use of}} classroom teaching and learning materials. The draft standards included in this paper have been developed by International Association for Research on Textbooks on Educational Media (IARTEM). The standards were developed in Australia but have been discussed in a number of international forums, including the 2013 IARTEM conference at the University of Ostrava (Czech Republic). At this conference the standards were shared for <b>feedback,</b> <b>validation</b> and further research refinement and revision. Data was collectedfrom IARTEM members about the standards and Professor Arno Reints from the University of Utrecht is leading an international IARTEM project to further develop the standards. Feedback on the standards can be made on the IARTEM website at any time − [URL] The paper is divided into a number of sections: A. Origin of the standards B. Process of standard development C. Purpose of the standards D. The standards continuum E. Development of the domains F. The domains G. The standards...|$|E
40|$|Effective {{leadership}} {{is crucial for}} organisational survival and growth, especially in demanding modern business environments. It is particularly challenging for women leaders who may function in gendered organisations that do not necessarily support their development. Group coaching is more time and cost-effective than individual coaching, is scalable and sustainable and is appropriate for the relational context of leadership. It is, however, in its infancy in terms of cohesive and differentiated research. This study investigated the impact of group coaching on leadership effectiveness in South African women managers. Data was gathered from pre-and-post questionnaire administrations as well as interviews and was analysed using mixed methods in comparative t-tests and thematic analysis. The findings indicated that leadership effectiveness did change significantly over a six month leadership development programme, most notably {{in the areas of}} enabling self, enabling others and self-confidence. Specific impacts of group coaching on leadership effectiveness were by increasing awareness of self and values; enabling learning through external input; enabling sharing and support through safety and a sense of direction. These themes relate to factors inherent in a group context: multiple interactions to explore identity and self, multiple feedback inputs and collective sharing and support. The respondents reported less impact in the achievement of personal goals or results. It is possible that there is a trade-off in focus on the individual’s objectives for the learning advantages of multiple interactions and exchanges in group coaching. The effects of group coaching, however, appear to be relevant for current business realities that demand modern leaders to be authentic and confident in complex and hyper-connected social environments. Women who work in male-dominated organisations may benefit particularly from alternative groups that provide safe <b>feedback,</b> <b>validation</b> and a sense of identification with similarly positioned women. This study deepened understanding of how group coaching adds value in a leadership development context. The results add to the body of knowledge on group coaching and leadership effectiveness and help to inform the practice of effective leadership in organisations, particularly for women managers...|$|E
40|$|Analysis {{procedures}} {{are needed to}} extract useful information from {{the large amount of}} gene expression data that is becoming available. This work describes a set of analytical tools and their application to yeast cell cycle data. The components of our approach are (1) a similarity measure that reduces the number of false positives, (2) a new clustering algorithm designed specifically for grouping gene expression patterns, and (3) an interactive graphical cluster analysis tool that allows user <b>feedback</b> and <b>validation.</b> We use the clusters generated by our algorithm to summarize genome-wide expression and to initiate supervised clustering of genes into biologically meaningful groups...|$|R
40|$|AbstractUser-friendly {{interfaces}} {{can play}} an important role in bringing the benefits of a machine-readable representation of formal arguments to a wider audience. The aartifact system is an easy-to-use lightweight verifier for formal arguments that involve logical and algebraic manipulations of common mathematical concepts. The system provides validation capabilities by utilizing a database of propositions governing common mathematical concepts. The aartifact systemʼs multi-faceted interactive user interface combines several approaches to user-friendly interface design: (1) a familiar and natural syntax based on existing conventions in mathematical practice, (2) a real-time keyword-based lookup mechanism for interactive, context-sensitive discovery of the syntactic idioms and semantic concepts found in the systemʼs database of propositions, and (3) immediate <b>validation</b> <b>feedback</b> in the form of reformatted raw input. The systemʼs natural syntax and database of propositions allow it to meet a userʼs expectations in the formal reasoning scenarios for which it is intended. The real-time keyword-based lookup mechanism and <b>validation</b> <b>feedback</b> allow the system to teach the user about its capabilities and limitations in an immediate, interactive, and context-aware manner...|$|R
40|$|Based on {{experiences}} {{from the}} GreenRegio research project that investigates framework conditions for innovations in sustainable/green building, this working paper explores {{the potential of}} interactive and collaborative methods for knowledge generation and co-production. Engagement with local practi-tioners, private industry, academics, political decision-makers {{and representatives of the}} non-profit sector early on in the research process allows researchers to gain better understanding of the re-search object and context. It also creates a platform for (mutual) knowledge exchange. Methodologi-cally, the project incorporates interactive workshops and Delphi-based <b>feedback</b> and <b>validation</b> rounds, that – over the lifespan of the project – offer a mutual learning process further inspired by in-sights and experiences across four case studies in Europe, Australia, and Canada. The exchange and learning processes provide important insights on different forms and pathways of sustainability transi-tions in the building sector to all participants involved in the project, researchers and researched alike...|$|R
40|$|In many companies, product {{management}} struggles in getting accurate customer <b>feedback.</b> Often, <b>validation</b> and confirmation of functionality with customers takes place {{only after the}} product has been deployed, {{and there are no}} mechanisms that help product managers to continuously learn from customers. Although there are techniques available for collecting customer feedback, these are typically not applied as part of a continuous feedback loop. As a result, the selection and prioritization of features becomes far from optimal, and product deviates from what the customers need. In this paper, we present a literature review of currently recognized techniques for collecting customer feedback. We develop a model in which we categorize the techniques according to their characteristics. The purpose of this literature review is to provide an overview of current software engineering research in this area and to better understand the different techniques that are used for collecting customer feedback...|$|R
40|$|We {{describe}} the design, implementation, and outcomes of an advanced engineering course emulating the working environment of a company. Shifting {{from a traditional}} teaching style to an approach where students must be completely involved in project-related research, implementation, preparation of deliverables, and presentation of results helps to: 1) foster self-learning, 2) engage students more and enable them to be pro-active and competition-aware, and 3) enable a smoother transition from full-time student to full-time employee. We used anonymous questionnaires as the primary methodology of data collection along with ratings of the projects in terms of extent of challenge/complexity and type of work (individual vs. team-work). The questionnaires assessed the following dimensions satisfaction, fairness, knowledge acquired, challenge, <b>feedback,</b> and <b>validation.</b> Students are more satisfied with their learning experience when they work in teams on more complex projects split into smaller subprojects rather than working individually on projects, irrespective of their complexity...|$|R
40|$|Background- In the Internet-able era reviewers {{are faced}} with an {{increased}} number of manuscripts and decreased time to review. In {{order to maintain the}} same, if not higher level of quality in the peer-review process, a net gain in productivity is required. Our goal is to inserm- 00109425, version 1 - 10 Oct 2008 present a manuscript peer-review checklist to help reviewers achieve this secondary yet critical task in a more systematic fashion. Methods- To this end, we have compiled, structured and processed information from nine reference standards, guidelines or directives, resulting in a 70 criterias checklist. We ensured that criterias were assessable based on the verification, validation and evaluation paradigm. Results- The checklist is presented in the manuscript, along with a description of a review workflow. Findings It is hoped that the checklist will be widely disseminated, and we are looking for <b>feedback</b> on <b>validation</b> and improvements in order to perform a quantitative study on productivity gains using this tool...|$|R
40|$|This paper {{deals with}} the problem of {{controlling}} the interaction of a robot manipulator with an elastic surface. The goal of tracking a desired position trajectory and a desired time-varying contact force is pursued. The controller design is carried out in a passivity framework and adaptive algorithms are used to counteract the effects of the uncertain estimate of the stiffness coefficient of the environment. Two alternative adaptive control laws are considered, with and without force time-derivative <b>feedback.</b> The experimental <b>validation</b> is carried out on an industrial robot with open control architecture equipped with a force sensor...|$|R
40|$|The field {{feedback}} formulation {{is applied}} to the solution of time-harmonic plane wave scattering by 2 -D penetrable objects of arbitrary shape and composition. A conformal mesh, finite element algorithm is employed in the forward operator construction while a near-field Green’s function integration is used in forming the <b>feedback</b> operator. Scattering <b>validations</b> for midresonance sized objects include a circular cylinder, a two-region bisected cylinder, a half-circular cylinder, a semicircular shell and a thin lossy planar strip. This work {{was supported in part by}} grants from the Air Force Office of Scientific Research and the National Science Foundation...|$|R
5000|$|In {{qualitative}} research, {{a member}} check, {{also known as}} informant <b>feedback</b> or respondent <b>validation,</b> is a technique used by researchers to help improve the accuracy, credibility, validity, and transferability (also known as applicability, internal validity, or fittingness) of a study. [...] There are many subcategories of members checks, including; narrative accuracy checks, interpretive validity, descriptive validity, theoretical validity, and evaluative validity. In many member checks, the interpretation and report (or a portion of it) is given {{to members of the}} sample (informants) in order to check the authenticity of the work. Their comments serve as a check on the viability of the interpretation.|$|R
40|$|Portfolios are {{important}} tools {{to document the}} professional experience of engineers, architects and other professionals. When implementing the portfolios at undergraduate level, often {{the quality of the}} portfolios’ entries and the frequency of their update by students are cited as obstacles. Other obstacles include the time consumed in assessing the portfolio and the timeliness of feedback given to students. To address these difficulties, an integrated Portfolio and Advising system was introduced at two modules offered at undergraduate engineering courses. The system requires the students to track the progress of their learning outcomes, provide documentary evidence to support claims of achievement of these learning outcomes and regularly meet their academic Advisors to seek <b>feedback</b> and <b>validation</b> of the achievement of the learning outcomes. This aimed at creating intentional learners out of these students as they take ownership of their academic progress. Feedback from both the students and the lecturers (Advisors) is very encouraging as both students and lectures agreed that the system provides a useful and comprehensive tool to track the achievement of the module’s learning outcome...|$|R
40|$|DVS is {{a simple}} {{versioning}} system that adopts a check-in/check-out policy with exclusive locks {{much like the one}} implemented by RCS. In addition to the basic functionalities of RCS, DVS provides extensions in two main directions: distribution of artifacts and versioning of collections of artifacts. DVS has been implemented on top of NUCM 2, a generic distributed platform aimed at providing a policy-neutral programmable interface for realizing configuration management systems. NUCM provides support for storing artifacts and collections of artifacts and their attributes in a set of distributed servers. DVS implements the locking policy and all the related higher level services including check-in and check-out of single artifacts as well as collections, managing locks, change logs, and recursive check-in and check-out. This paper describes the main design principles underlying DVS and NUCM together with the basics issues regarding their implementation. DVS has been used and is currently being used for collaborative authoring involving several authors distributed over five different sites on the Internet. We also discuss this first experience and the <b>feedback</b> and <b>validation</b> for both DVS and NUCM. ...|$|R
40|$|The {{european}} standard EN 1591 - 1 [1], initially published in 2001, defines a calculation method for bolted gasketed circular flanges, {{alternative to the}} TAYLOR-FORGE method, used as the basic method in most codes. In 2007, a new part, XP CEN/TS 1591 - 3 [2], {{has been added to}} the EN 1591 series. This technical specification enables {{to take into account the}} Metal to Metal Contact (MMC), appearing inside the bolt circle on some assemblies. Due to a lack of industrial <b>feedback</b> and detailed <b>validation,</b> this document has not been raised to the standard status. In that context, under the request of its Pressure Vessel and Piping commission, CETIM has performed a study comparing this calculation method to Finite Element Analysis (FEA) on several industrial configurations. After...|$|R
40|$|Robotic orthoses {{have the}} {{potential}} to provide effective rehabilitation while overcoming the availability and cost constraints of therapists. These orthoses must be characterized by the naturally safe, reliable, and controlled motion of a human therapist's muscles. Such characteristics are only possible in the natural kingdom through the pain sensing realized by the interaction of an intelligent nervous system and muscles' embedded sensing organs. McKibben fluidic muscles or pneumatic muscle actuators (PMAs) are a popular orthosis actuator because of their inherent compliance, high force, and muscle-like load-displacement characteristics. However, the circular cross-section of PMA increases their profile. PMA are also notoriously unreliable and difficult to control, lacking the intelligent pain sensing systems of their biological muscle counterparts. Here the Peano fluidic muscle, a new low profile yet high-force soft actuator is introduced. This muscle is smart, featuring bioinspired embedded pressure and soft capacitive strain sensors. Given this pressure and strain <b>feedback,</b> experimental <b>validation</b> shows that a lumped parameter model based on the muscle geometry and material parameters can be used to predict its force for quasistatic motion with an average error of 10 - 15 N. Combining this with a force threshold pain sensing algorithm sets a precedent for flexible orthosis actuation that uses embedded sensors to prevent damage to the actuator and its environment...|$|R
40|$|X-ray {{crystallography}} 3 D atomic {{models are}} used {{in a variety of}} research areas to understand and manipulate protein structure. Research and application are dependent {{on the quality of the}} models. Low-resolution experimental data is a common problem in crystallography which makes solving structures and producing the reliable models that many scientists depend on difficult. In this work, I develop new, automated tools for validation and correction of low-resolution structures. These tools are gathered under the name CaBLAM, for C-alpha Based Low-resolution Annotation Method. CaBLAM uses a unique, C-alpha-geometry-based parameter space to identify outliers in protein backbone geometry, and to identify secondary structure that may be masked by modeling errors. CaBLAM was developed in the Python programming language as part of the Phenix crystallography suite and the open CCTBX Project. It makes use of architecture and methods available in the CCTBX toolbox. Quality-filtered databases of high-resolution protein structures, especially the Top 8000, were used to construct contours of expected protein behavior for CaBLAM. CaBLAM has also been integrated into the codebase for the Richardson Lab's online MolProbity validation service. CaBLAM succeeds in providing useful <b>validation</b> <b>feedback</b> for protein structures in the 2. 5 - 4. 0 A resolution range. This success demonstrates the relative reliability of the C-alpha; trace of a protein in this resolution range. Full mainchain information can be extrapolated from the C-alpha; trace, especially for regular secondary structure elements. CaBLAM has also informed our approach to validation for low-resolution structures. Moderation of <b>feedback,</b> to reduce <b>validation</b> overload and to focus user attention on modeling errors that are both significant and correctable, is one of our goals. CaBLAM and the related methods that have grown around it demonstrate the progress towards this goal. Dissertatio...|$|R
40|$|Graduation date: 1996 Weed {{resistance}} is usually diagnosed after a weed control practice has lost efficacy and weed populations begin to increase rapidly. Prediction and validation {{in the field}} {{at a very early}} stage of resistance development is a promising method for preventing an uncontrollable problem. Pattern-thinking helped individuals connect their experience of weed infestations with development of weed resistance. Field representatives connected early verification with immediate management to reduce the potential problem of weed resistance. A method for rapid detection of weed resistance by microcalorimetry was developed to distinguish between herbicide resistant and susceptible biotypes. This general method was used to test three different weed species and three different herbicide modes of action. Heat evolution as a product of plant respiration by samples of meristematic tissue was compared between resistant and susceptible biotypes. The procedure readily distinguished between biotypes. Since microcalorimetry provided quick and accurate results, all field representatives stated that the combination of pattern-thinking and rapid assay would improve management of weed resistant populations. The combination would improve visual detection based on the standard growth and development model for weed resistance and population growth. Also, biological verification using microcalorimetry provides immediate <b>feedback</b> and <b>validation</b> of weed resistance. Thus, early detection of weed {{resistance is}} a very important tool which will assist farmers in dynamically managing weed infestations...|$|R
40|$|The {{original}} article {{is available on}} the Taylor & Francis Online website in the following link: [URL] paper describes the validation study of our software that uses combined webcam and microphone data for real-time, continuous, unobtrusive emotion recognition as part of our FILTWAM framework. FILTWAM aims at deploying a real time multimodal emotion recognition method for providing more adequate feedback to the learners through an online communication skills training. Herein, timely feedback is needed that reflects on their shown intended emotions and which is also useful to increase learners’ awareness of their own behaviour. At least, a reliable and valid software interpretation of performed face and voice emotions is needed to warrant such adequate <b>feedback.</b> This <b>validation</b> study therefore calibrates our software. The study uses a multimodal fusion method. Twelve test persons performed computer-based tasks in which they were asked to mimic specific facial and vocal emotions. All test persons’ behaviour was recorded on video and two raters independently scored the showed emotions, which were contrasted with the software recognition outcomes. A hybrid method for multimodal fusion of our multimodal software shows accuracy between 96. 1 % and 98. 6 % for the best-chosen WEKA classifiers over predicted emotions. The software fulfils its requirements of real-time data interpretation and reliable results. The Netherlands Laboratory for Lifelong Learning (NELLL) of the Open University Netherlands...|$|R
40|$|Objectives: The aim of {{this study}} was to analyze and {{describe}} process and outcomes of two pilot assessments based on the HTA Core Model, discuss the applicability of the model, and explore areas of development. Methods: Data were gathered from HTA Core Model and pilot Core HTA documents, their <b>validation</b> <b>feedback,</b> questionnaires to investigators, meeting minutes, emails, and discussions in the coordinating team meetings in the Finnish Office for Health Technology Assessment (FINOHTA). Results: The elementary structure of the HTA Core Model proved useful in preparing HTAs. Clear scoping and good coordination in timing and distribution of work would probably help improve applicability and avoid duplication of work. Conclusions: The HTA Core Model can be developed into a platform that enables and encourages true HTA collaboration in terms of distribution of work and maximum utilization of a common pool of structured HTA information for national HTA report...|$|R
40|$|Existing {{models of}} the writing task from a {{cognitive}} viewpoint agree {{on the importance of}} draft revision in the overall process. This is generally assumed to focus on reviewing intermediate drafts in search for feedback on how to modify them to match the driving constraints. However, in literary creativity it is often the case that the feedback leads not to a revision of the current draft but to a redefinition of the constraints that are driving the process. This phenomenon is explicitly described in Sharples’ model of writing as a creative task. Yet existing computational models of literary creativity do not contemplate it. The present paper describes a computational model of the creative processes in literary creativity that contemplates the explicit representation of the constraints driving the process, and allows for the <b>feedback</b> from the <b>validation</b> to modify not just the ongoing draft but also the constraints that it is expected to satisfy. This allows the model to represent cases of serendipitous discovery of interesting features...|$|R
40|$|The {{usage of}} {{industrial}} robots for milling tasks {{is limited by}} their lack of absolute accuracy in presence of process forces. While there are techniques and products available for increasing the absolute accuracy of free-space motions, the mechanical weaknesses of the robot {{in combination with the}} milling forces limits the achievable performance. If the dynamic effects causing the deviations can be compensated for, there would be several benefits of using industrial robots for machining applications. To enable the compensation, the causes of the path deviations have to be adequately modeled, and there must be a method for determining the model parameters in a simple and inexpensive way. To that end, we propose a radically new method for identification of robot joint model parameters, based on clamping of the robot to a rigid environment. The rigidity of the environment then eliminates the need for expensive measurement equipment, and the internal sensors of the robot give sufficient <b>feedback.</b> An experimental <b>validation</b> shows the feasibility of the method...|$|R
40|$|Tele-intensive care {{collaboration}} {{in care of}} critically ill patients improves both the safety and quality of nursing care. However, the full benefits of the telemedicine service may not be realized unless tele-critical care nurses {{have the ability to}} communicate clearly with their remote nursing peers. The purpose of this DNP project was to create and validate an acronym style communication tool to assist the tele-critical care nurses with their communication. The relational coordination theory was the primary communication theory utilized for tool development. The tool creation phase of the project included informal observations and discussion with a convenience sample of 11 tele-critical care staff nurses. The formative feedback from this group helped to identify the episode of communication for which the tool was designed and suggested communication elements for inclusion. During the validation phase of this project, 9 volunteer experts evaluated the communication tool with a 5 -point Likert scale survey. Descriptive statistics were used to analyze the survey results and provided summative <b>feedback</b> for <b>validation</b> of the tool. Mean scores between 3. 44 and 4. 44 demonstrated that the experts agreed with the applicability, relevance, and necessity of the tool. Feedback indicated the need for a pilot study implementing the tool to compare it with traditional communication practices and to evaluate its performance in clinical practice. This tool will be useful for future partnerships utilizing telemedicine. The project is socially significant because of its focus on communication and collaboration among healthcare providers in facilitating the patient experience and safety...|$|R
40|$|This {{paper is}} in closed access until 25 th Dec 2018. This study {{examined}} the effectiveness of an evidence-based sport parent education programme {{designed to meet the}} stage-specific needs of British tennis parents. Using an organisational action research framework, six workshops were run over a 12 -week period for tennis parents with {{children between the ages of}} 5 and 10 years. Workshops took place in three high performance tennis centres and had an average attendance of 22 parents. Data were collected using participant diaries, emails, social <b>validation</b> <b>feedback</b> forms, reflective diaries, and post-programme focus groups (n= 19). The impact and effectiveness of the programme was evaluated qualitatively using a thematic analysis. Results indicated that the programme was effective in enhancing tennis parents’ perceived knowledge, affective states, and skills across a range of learning objectives. Results also provide a unique understanding of parents’ experiences of participating in a sport parent education programme. Insights are provided for practitioners in relation to the design, content, and delivery of future sport parent education programs...|$|R
40|$|International audienceEstimation of soil {{moisture}} at large scale has been performed using several satellite-based passive microwave sensors {{and a variety}} of retrieval methods over the past two decades. The most recent source of {{soil moisture}} is the European Space Agency Soil Moisture and Ocean Salinity (SMOS) mission. A thorough validation must be conducted to insure product quality that will, in turn, support the widespread utilization of the data. This is especially important since SMOS utilizes a new sensor technology and is the first passive L-band system in routine operation. In this paper, we contribute to the validation of SMOS using a set of four in situ soil moisture networks located in the U. S. These ground-based observations are combined with retrievals based on another satellite sensor, the Advanced Microwave Scanning Radiometer (AMSR-E). The watershed sites are highly reliable and address scaling with replicate sampling. Results of the validation analysis indicate that the SMOS soil moisture estimates are approaching the level of performance anticipated, based on comparisons with the in situ data and AMSR-E retrievals. The overall root-mean-square error of the SMOS soil moisture estimates is 0. 043 m 3 /m 3 for the watershed networks (ascending). There are bias issues at some sites that need to be addressed, as well as some outlier responses. Additional statistical metrics were also considered. Analyses indicated that active or recent rainfall can contribute to interpretation problems when assessing algorithm performance, which is related to the contributing depth of the satellite sensor. Using a precipitation flag can improve the performance. An investigation of the vegetation optical depth (tau) retrievals provided by the SMOS algorithm indicated that, for the watershed sites, these are not a reliable source of information about the vegetation canopy. The SMOS algorithms will continue to be refined as <b>feedback</b> from <b>validation</b> is evaluated, and it is expected that the SMOS estimates will improve...|$|R
40|$|Abstract Background Development and {{increasing}} acceptance of rehabilitation robots {{as well as}} advances in technology allow new forms of therapy for patients with neurological disorders. Robot-assisted gait therapy can increase the training duration and the intensity for the patients while reducing the physical strain for the therapist. Optimal training effects during gait therapy generally depend on appropriate feedback about performance. Compared to manual treadmill therapy, there is a loss of physical interaction between therapist and patient with robotic gait retraining. Thus, {{it is difficult for}} the therapist to assess the necessary feedback and instructions. The aim {{of this study was to}} define a biofeedback system for a gait training robot and test its usability in subjects without neurological disorders. Methods To provide an overview of biofeedback and motivation methods applied in gait rehabilitation, previous publications and results from our own research are reviewed. A biofeedback method is presented showing how a rehabilitation robot can assess the patients' performance and deliver augmented <b>feedback.</b> For <b>validation,</b> three subjects without neurological disorders walked in a rehabilitation robot for treadmill training. Several training parameters, such as body weight support and treadmill speed, were varied to assess the robustness of the biofeedback calculation to confounding factors. Results The biofeedback values correlated well with the different activity levels of the subjects. Changes in body weight support and treadmill velocity had a minor effect on the biofeedback values. The synchronization of the robot and the treadmill affected the biofeedback values describing the stance phase. Conclusion Robot-aided assessment and feedback can extend and improve robot-aided training devices. The presented method estimates the patients' gait performance with the use of the robot's existing sensors, and displays the resulting biofeedback values to the patients and therapists. The therapists can adapt the therapy and give further instructions to the patients. The feedback might help the patients to adapt their movement patterns and to improve their motivation. While it is assumed that these novel methods also improve training efficacy, the proof will only be possible with future in-depth clinical studies. </p...|$|R
40|$|Needle biopsy is an {{important}} and common procedure for lesion detection or tissue extraction within the human body. Physicians conducting such procedures rely primarily on the sense of “touch ” (kinesthetic feedback from needle) to estimate the current needle position and organs within its vicinity. This skill takes time to acquire and mature, often by biopsies on live patients. Medical residents and fellow trainees thus have limited opportunities {{both in terms of}} real life scenarios as well as testing platforms to develop and validate their skills. This paper focuses on building a biopsy simulator for training on virtual phantoms (using both visual and force <b>feedback)</b> and cross <b>validation</b> using a real physical phantom. In order to develop a virtual- haptic model of biopsy phantom, material testing experiments were conducted to obtain motion-force profiles from an instrumented 6 -DOF robot platform serving as a needle driver. The measured force-displacement data was then used to develop three types of haptic models for the phantom to calculate the force feedback for the haptic device. Neural network based models provided a more accurate force-reflection model compared to the other two methods from the literature and will form the basis of the virtual phantoms within our framework...|$|R
40|$|Human motor {{function}} {{emerges from}} {{the interaction between the}} neuromuscular and the musculoskeletal systems. Despite the knowledge of the mechanisms underlying neural and mechanical functions, there is no relevant understanding of the neuro-mechanical interplay in the neuro-musculo-skeletal system. This currently represents the major challenge to the understanding of human movement. We address this challenge by proposing a paradigm for investigating spinal motor neuron contribution to skeletal joint mechanical function in the intact human in vivo. We employ multi-muscle spatial sampling and deconvolution of high-density fiber electrical activity to decode accurate α-motor neuron discharges across five lumbosacral segments in the human spinal cord. We use complete α-motor neuron discharge series to drive forward subject-specific models of the musculoskeletal system in open-loop with no corrective <b>feedback.</b> We perform <b>validation</b> tests where mechanical moments are estimated with no knowledge of reference data over unseen conditions. This enables accurate blinded estimation of ankle function purely from motor neuron information. Remarkably, this enables observing causal associations between spinal motor neuron activity and joint moment control. We provide a new class of neural data-driven musculoskeletal modeling formulations for bridging between movement neural and mechanical levels in vivo with implications for understanding motor physiology, pathology, and recovery...|$|R
40|$|The Moderate Resolution Imaging Spectroradiometer (MODIS) {{was sent}} into orbit on the Earth Observing System (EOS) Terra {{spacecraft}} in December 1999. The MODIS began taking observations on February 24, 2000. Instrument checkout and characterization progressed {{to the point}} in the Fall of 2000 along with the checkout of algorithms so that approximately 40 products for land, ocean and atmosphere studies on global and regional scales were and are now being produced systematically. These products are now designated "beta", products indicating that they are still being examined and validated, but in most cases are amenable to examination by the scientific and applications community to further assess their utility and provide <b>feedback</b> to the <b>validation</b> process and the MODIS Science Team. It is expected that many products will progress to "provisionally useful" or fully "validated" status by mid-year 2001. one goal is to produce a systematically processed data set by the end of 2001 from MODIS extends from November 2000 through October 2001. Overall the MODIS instrument and the associated data processing systems are performing well. The many examples of MODIS observations indicate that the prospect for highly useful and exciting studies of the Earth-atmosphere system using MODIS data looks very good...|$|R
40|$|Science {{and policy}} {{increasingly}} request {{for sustainable development}} and growth. Similarly, Digital Earth undergoes a paradigm shift to an open platform that actively supports user engagement. While the public becomes able to contribute new content, we recognize a gap in user-driven <b>validation,</b> <b>feedback</b> and requirements capture, and innovative application development. Rather than defining Digital Earth applications top down, we see a need for methods and tools that will help building applications bottom up and driven by community needs. These should include a technology toolbox of geospatial and environmental enablers, which allow to access functional building blocks and content in multiple ways, but – equally important – enable the collaboration within partially unknown stakeholder networks. The validation and testing in real-life scenarios will be a central requirement when approaching the Digital Earth 2020 goals, which were articulated recently. We particularly argue to follow a Living Lab approach for co-creation and awareness rising in relation to environmental and geospatial matters. We explain why and how such a Digital Earth Living Lab {{could lead to a}} sustainable approach for developing, deploying, and using Digital Earth applications and suggest a paradigm shift for Virtual Globes becoming forums for research and innovation. JRC. H. 6 -Digital Earth and Reference Dat...|$|R
40|$|Background: At a time {{of growing}} {{emphasis}} on both the use of research and accountability, {{it is important for}} research funders, researchers and other stakeholders to monitor and evaluate the extent to which research contributes to better action for health, and find ways to enhance the likelihood that beneficial contributions are realized. Past attempts to assess research 'impact' struggle with operationalizing 'impact', identifying the users of research and attributing impact to research projects as source. In this article we describe Contribution Mapping, a novel approach to research monitoring and evaluation that aims to assess contributions instead of impacts. The approach focuses on processes and actors and systematically assesses anticipatory efforts that aim to enhance contributions, so-called alignment efforts. The approach is designed to be useful for both accountability purposes and for assisting in better employing research to contribute to better action for health. Methods: Contribution Mapping is inspired by a perspective from social studies of science on how research and knowledge utilization processes evolve. For each research project that is assessed, a three-phase process map is developed that includes the main actors, activities and alignment efforts during research formulation, production and knowledge extension (e. g. dissemination and utilization). The approach focuses on the actors involved in, or interacting with, a research project (the linked actors) and the most likely influential users, who are referred to as potential key users. In the first stage, the investigators of the assessed project are interviewed to develop a preliminary version of the process map and first estimation of research-related contributions. In the second stage, potential key-users and other informants are interviewed to trace, explore and triangulate possible contributions. In the third stage, the presence and role of alignment efforts is analyzed and the preliminary results are shared with relevant stakeholders for <b>feedback</b> and <b>validation.</b> After inconsistencies are clarified or described, the results are shared with stakeholders for learning, improvement and accountability purposes. Conclusion: Contribution Mapping provides an interesting alternative to existing methods that aim to assess research impact. The method is expected to be useful for research monitoring, single case studies, comparing multiple cases and indicating how research can better be employed to contribute to better action for health. © 2012 Kok and Schuit; licensee BioMed Central Ltd...|$|R
