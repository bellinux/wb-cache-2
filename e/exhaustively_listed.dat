6|41|Public
5000|$|Note that f takes {{a maximum}} value of 1 at each whole integer, {{so we may}} limit our {{examination}} to the space between [...] and [...] Since ε has a finite denominator of b, the only values for which f may return a value greater than ε are those with a reduced denominator no larger than b. There exist only {{a finite number of}} values between two integers with denominator no larger than b, so these can be <b>exhaustively</b> <b>listed.</b> Setting δ to be smaller than the nearest distance from x to one of these values guarantees every value within δ of x has f(x) < ε.|$|E
40|$|In {{the case}} of Byankov the Court of Justice ruled as follows: EU law must be {{interpreted}} as precluding legislation under which an administrative procedure {{that has resulted in}} the adoption of a prohibition on leaving the territory, which has become final and has not been contested before the courts, may be reopened - in the event of the prohibition being clearly contrary to EU law - only in circumstances such as those <b>exhaustively</b> <b>listed</b> in Article 99 of the Code of Administrative Procedure, despite the fact that such a prohibition continues to produce legal effects with regard to its addressee. This study discusses how the ruling can be placed in the case law of the Court that in accordance with the principle of legal certainty, EU law does not require that administrative authorities be placed under an obligation to re-examine a national final administrative decision...|$|E
40|$|This article reviews {{research}} {{over the}} past decade involving compara-tive studies of gifted and nongifted populations on questions of dif-ferential cognitive styles, cognitive developmental patterns, cognitive strategy selection, and social and emotional factors associated with the academic setting. Significant differences were found in all four areas. The implications of those differences on instructional design and curricular planning are also discussed. At a time of increasing interest in giftedness, there has been a cor-responding {{increase in the number of}} theories concerning its nature. Definitions abound in almost infinite numbers, each with its own “agenda ” of so-called characteristics that differentiate the gifted from other learners. Are these characteristics differences in performance excellence, as described by the United States Office of Education? A learner will be defined as gifted [...] . if he/she is ex-hibiting outstanding performance in one or more of the following areas: (1) general intellectual; (2) specific aca-demic aptitude; (3) visual/performing arts; (4) creative production; and (5) leadership. Or are these characteristics differences in the cognitive, affective, physical, social, emotional, and intuitive domains, as <b>exhaustively</b> <b>listed</b> in the form of behavioral checklists by Clark (1980), Renzulli (1 975 and later) and others? Or are these characteristics due to differences in learning or devel-opmental rates, as suggested by many researchers in the field (fo...|$|E
5|$|Boykett {{used this}} {{algebraic}} formulation {{as the basis}} for algorithms that <b>exhaustively</b> <b>list</b> all possible inequivalent reversible cellular automata.|$|R
5000|$|Frank Ruskey is a combinatorialist and {{computer}} scientist, {{and professor at}} the University of Victoria. His research involves algorithms for <b>exhaustively</b> <b>listing</b> discrete structures, combinatorial Gray codes, Venn and Euler diagrams, combinatorics on words, and enumerative combinatorics. [...] Frank Ruskey {{is the author of}} the Combinatorial Object Server (COS), a website for information on and generation of combinatorial objects.|$|R
25|$|The Constitution of the French Fifth Republic distinguishes two {{distinct}} kinds of legislation: statute law, which is normally voted upon by Parliament (except for ordonnances) and government regulations, which are {{enacted by the}} Prime Minister and his government as decrees and other regulations (arrêtés). Article 34 of the Constitution <b>exhaustively</b> <b>lists</b> the areas reserved for statute law: these include, for instance, criminal law.|$|R
40|$|Spanish Translation of this Report The {{human genome}} sellout The ‘bioinformatics ’ gold rush The reality test Will it deliver? Governments {{in the industrialized}} {{countries}} have handed over the human genome to private ownership together with the most triumphant hyperboles to boot, notwithstanding that it was mapped and sequenced at great public expense. A multi-billion bio-informatics ‘goldrush ’ is on, as private companies scramble to mine the public database for genes to patent and to assemble their own proprietary databases which are sold at exorbitant fees to subscribers. Beneath the hype, bio-informatics is {{a desperate attempt to}} turn the exponentially increasing amount of information into knowledge. The human genome programme has dominated the scientific scene for the past ten years, raising hopes and fears in equal measure. Is it likely to deliver? No, especially if it continues to be misguided by a discredited genetic determinist paradigm that serves to divert attention and resources away from the real causes of ill-health and to stigmatize the victims. We are already witnessing the resurgence of genetic discrimination and eugenics that have blighted the history of much of the last century. Bio-informatics suffers from the reductionist fallacy that knowledge will automatically arise once information is <b>exhaustively</b> <b>listed.</b> Molecular biology is suffocating from information overload. What we need is a quantum leap to a new paradigm for understanding the organism as a coherent whole. Otherwise, human genome research will remain a scientific and financial black hole that swallows up all public and private resources without any return either to investors or to improving the health of nations...|$|E
40|$|A {{method for}} {{processing}} sentences which contain unknown words, i. e. words {{for which no}} lexical entry exists, is presented. There are three different stages of processing: 1. The sentence with the unknown word is parsed. There are no special requirements for the parsing algorithm, but the lexical lookup procedure needs to be modified. 2. Based on the syntactic structure of the parse, information about the unknown word can be extracted. 3. The information obtained in step 2 may be too fully specified for a lexical entry. Therefore a filter is applied to it {{to create a new}} lexical entry. An application of the method is illustrated with examples from Categorial Unification Grammar. The problem of using the extracted information for lexical knowledge acquisition is discussed. Keywords: Parsing, Lexicon, Learning - 1 - 1 On the need for processing unknown words Within the past few years, the importance of comprehensive lexical resources for natural-language processing systems has been recognized. Yet {{it is clear that the}} lexicon cannot be complete because new words can be created and proper names cannot be <b>exhaustively</b> <b>listed</b> in the lexicon. Moreover, for many applications, the size of the lexicon is limited by the size of the available memory. Therefore, robust approaches for processing unknown words are needed. (Gust, Ludewig 1989) discuss several approaches for extending the lexicon when an unknown word is encountered: These include word formation rules for analyzing compounds, interactive user input and access to machine-readable (conventional) dictionaries. The method presented in this paper allows the automatic extraction of syntactic information about unknown words. A system with this capacity can be a useful tool in the automatic or machine-aided creation of lexi [...] ...|$|E
40|$|The Brussels I Regulation ((EU) No 1215 / 2010) {{governs the}} {{division}} of jurisdiction between the Member States of the European Union and provides for the circulation of judgments within the Member States in civil and commercial matters. Arbitration is excluded from {{the scope of the}} Regulation, and the Regulation should not affect the application of the New York Convention in the Member States. The arbitration exclusion reflects a traditional understanding that the systems of international civil procedure and international arbitration are expected to function autonomously. Despite this, the two systems occasionally collide as parties to a dispute attempt to initiate parallel court and arbitral proceedings. Further, if parallel court and arbitral proceedings on the same matter and between the same parties cannot be prevented, they may result in two at least partially overlapping and conflicting decisions. This study concerns first whether parallel court and arbitral proceedings can be prevented in ways that are compatible with the Regulation and the New York Convention. The second research question concerns on which grounds a Member State court is able to refuse recognition and enforcement of a Brussels I regime judgment that conflicts with an arbitral award. The study is based on doctrinal research, and the objectives of the study are twofold. First, the study examines the prevailing interpretation of the Regulation’s interface with arbitration and secondly, the study aims at presenting a recommendation regarding the application of the Regulation in case a Member State court is requested to enforce a judgment conflicting with an arbitral award. Regarding the first research question, the study examines the availability of measures restricting or discouraging parallel court and arbitral proceedings. The prohibition of court-ordered anti-suit injunctions established in the case-law of the CJEU under the old Brussels I Regulation ((EC) No 44 / 2001) remains applicable under the recast Regulation. Further, the assessment of whether Member State courts are permitted to order damages for breach of arbitration agreement appears to give a negative answer as such damages are argued to be contrary to the principle of mutual trust between Member State courts. On the contrary, the recognition and enforcement of anti-suit injunctions ordered by arbitrators and arbitral awards ordering damages for breach of arbitration agreement appear to be outside the scope of the Regulation but national laws of the Member States strongly limit the availability and enforceability of such measures. This leads to a conclusion that parallel court and arbitral proceedings cannot be effectively prevented under the Regulation. As a main rule, the decision which is rendered first is to be recognised and enforced in other Member States on the application of a party regardless of any pending parallel proceedings. The Regulation particularly prescribes that it shall not affect the application of the New York Convention, which has led to a discussion concerning the possibility of anti-enforcement injunctions directed against the enforcement of a judgment that has been rendered prior to an arbitral award on the same matter and between the same parties. Such injunctions appear, however, both incompatible with the Regulation and unnecessary with regard to the unaffected application of the New York Convention. If a Brussels I regime judgment has been given first, it can be enforced in accordance with the Regulation. The same applies to an arbitral award under the New York Convention if the recognition and enforcement of the award is sought first. The Regulation does not address on which grounds a Member State court may refuse the enforcement of a Brussels I regime judgment in case the enforcement is requested only after a conflicting arbitral award is recognised and enforced in the Member State addressed. It appears clear that the enforcement must be refused in such situation but, on the other hand, the grounds for refusal of recognition and enforcement of a Brussels I regime judgment are <b>exhaustively</b> <b>listed</b> in the Regulation. The study discusses four alternative grounds for refusing the enforcement. It is concluded that the enforcement of a conflicting Brussels I regime judgment should be refused on the grounds of being contrary to the public policy in the Member State addressed since the national public policy cannot accommodate recognition and enforcement of two irreconcilable decisions...|$|E
40|$|This {{document}} is a reference {{guide to the}} Xyce Parallel Electronic Simulator, and is a companion document to the Xyce Users' Guide. The focus of this {{document is}} (to the extent possible) <b>exhaustively</b> <b>list</b> device parameters, solver options, parser options, and other usage details of Xyce. This document {{is not intended to}} be a tutorial. Users who are new to circuit simulation are better served by the Xyce Users' Guide...|$|R
5000|$|The twenty-minute film <b>exhaustively</b> <b>list</b> {{the number}} of {{institutions}} of higher learning and many different war activities that have begun at each, including the University of Texas, Texas A&M, Harvard, Dartmouth College and the University of California. There are many different shots of ROTC units and auxiliary formations. Many men are in the military and in college at the same time. Among the war related classes and activities: ...|$|R
40|$|This {{document}} is a reference {{guide to the}} Xyce Parallel Electronic Simulator, and is a companion document to the Xyce Users' Guide [1]. The focus of this {{document is}} (to the extent possible) <b>exhaustively</b> <b>list</b> device parameters, solver options, parser options, and other usage details of Xyce. This document {{is not intended to}} be a tutorial. Users who are new to circuit simulation are better served by the Xyce Users' Guide [1]...|$|R
5000|$|Attempts {{to state}} the {{conditions}} that constitute a certain personality trait and attempts to <b>exhaustively</b> <b>list</b> all the acts that identify a bearer of a trait have not been very successful in providing exact definitions for trait-related terms (such as [...] "creative", [...] "humorous", and [...] "ambitious"). The question of what exactly defines an individual as being—for example—courageous is an open one. Another difficulty is measuring how strongly a trait is pronounced in an individual.|$|R
50|$|A {{study by}} Roger Taylor and Edward Wakeling <b>exhaustively</b> <b>lists</b> every {{surviving}} print, and Taylor calculates that {{just over half}} of his surviving work depicts young girls, though about 60% of his original photographic portfolio is now missing. Dodgson also made many studies of men, women, boys, and landscapes; his subjects also include skeletons, dolls, dogs, statues, paintings, and trees. His pictures of children were taken with a parent in attendance {{and many of the}} pictures were taken in the Liddell garden because natural sunlight was required for good exposures.|$|R
40|$|By {{maintaining}} {{appropriate data}} structures, we develop constant-time transposition oracles that answer {{whether or not}} two adjacent vertices in a simple elimination ordering (SEO) or a semiperfect elimination ordering (semiPEO) can be swapped to produce a new SEO or semiPEO, respectively. Combined with previous results regarding convex geometries and antimatroids, this allows us to list all SEOs of a strongly chordal graph and all semiPEOs of an HHDA-free graph in Gray code order. By applying a new amortized analysis we show that the algorithms run in constant amortized time. Additionally, we provide a simple framework {{that can be used}} to <b>exhaustively</b> <b>list</b> the basic words for other antimatroids...|$|R
30|$|Characterizing Macroscopic Port Roles from {{network traffic}} {{provides}} highly valuable information for various network management tasks. The {{main purpose of}} this paper is not to <b>exhaustively</b> <b>list</b> all possible port behaviors, but provides a definition and classification of port roles. In this paper, we firstly classify port roles into six categories, which are scanned ports, failed service ports, client ports, server ports, P 2 P ports, and overlay ports. Secondly, we propose a port role distribution diagram and define a port behavior measurement metrics to characterize network traffic. A two-class EM fuzzy clustering algorithm is designed to quantitatively determine the classification criteria in the classification distribution diagram. Finally we validate the proposed method based on network traffic captured from a link in the CERNET.|$|R
40|$|Nowadays, in a Hospital Information System (HIS) {{huge amounts}} of data are stored about the care {{processes}} as they unfold. This data {{can be used for}} process mining. This way we can analyse the operational processes within a hospital based on facts rather than fiction. In order to enhance the uptake of process mining within the healthcare domain we present a healthcare reference model which <b>exhaustively</b> <b>lists</b> the typical types of data that exists within a HIS and {{that can be used for}} process mining. Based on this reference model, we elaborate on the most interesting kinds of process mining analyses that can be performed in order to illustrate the potential of process mining. As such, a basis is provided for governing and improving the processes within a hospital. Keywords: healthcare, process mining, reference mode...|$|R
40|$|A prefix normal word is {{a binary}} word with the {{property}} that no substring has more 1 s than the prefix {{of the same}} length. This class of words {{is important in the}} context of binary jumbled pattern matching. In this paper we present an efficient algorithm for <b>exhaustively</b> <b>listing</b> the prefix normal words with a fixed length. The algorithm is {{based on the fact that}} the language of prefix normal words is a bubble language, a class of binary languages with the property that, for any word w in the language, exchanging the first occurrence of 01 by 10 in w results in another word in the language. We prove that each prefix normal word is produced in O(n) amortized time, and conjecture, based on experimental evidence, that the true amortized running time is O(polylog(n)). Comment: 12 pages, 5 figure...|$|R
50|$|The books <b>exhaustively</b> <b>list</b> the syllables {{and give}} pronunciations, {{but do not}} {{describe}} the phonology of the language.This was first attempted in the rime tables, the oldest of which date from the Song dynasty, but which may represent a tradition {{going back to the}} late Tang dynasty.Though not quite a phonemic analysis, these tables analysed the syllables of the rime books using lists of initials, finals and other features of the syllable.The initials are further analysed in terms of place and manner of articulation, suggesting inspiration from Indian linguistics, at that time the most advanced in the world.However the rime tables were compiled some centuries after the Qieyun, and many of its distinctions would have been obscure.Edwin Pulleyblank treats the rime tables as describing a Late Middle Chinese stage, in contrast to the Early Middle Chinese of the rime dictionaries.|$|R
50|$|Cusco {{was likely}} not {{organized}} as a wamani, or province. Rather, {{it was probably}} somewhat akin to a modern federal district, like Washington, D.C. or Mexico City. The city sat {{at the center of}} the four suyu and served as the preeminent center of politics and religion. While Cusco was essentially governed by the Sapa Inca, his relatives and the royal panaqa lineages, each suyu was governed by an Apu, a term of esteem used for men of high status and for venerated mountains. Both Cusco as a district and the four suyu as administrative regions were grouped into upper hanan and lower hurin divisions. As the Inca did not have written records, it is impossible to <b>exhaustively</b> <b>list</b> the constituent wamani. However, colonial records allow us to reconstruct a partial list. There were likely more than 86 wamani, with more than 48 in the highlands and more than 38 on the coast.|$|R
40|$|Users often issue vague queries; when {{we cannot}} predict their intents precisely, a natural {{solution}} is to diversify the search results, hoping {{that some of the}} results correspond to the intent: This is usually called “result diversification”. Only a few studies have been completed to systematically evaluate approaches on result diversity. Some questions still remain unanswered: 1) As we cannot <b>exhaustively</b> <b>list</b> all intents in an evaluation, how does an incomplete intent set influence evaluation results? 2) Intents are not equally popular; so how can we estimate the probability of each intent? In this paper, we address these questions in building up a test collection for multi-intent queries. The labeling tool that we have developed allows assessors to add new intents while performing relevance assessments. Thus, we can investigate the influence of an incomplete intent set through experiments. Moreover, we propose two simple methods to estimate the probabilities of the underlying intents. Experimental results indicate that the evaluation results are different if we take the probabilities into consideration...|$|R
50|$|The capital area, Cusco, {{was likely}} not {{organized}} as a wamani. Rather, {{it was probably}} somewhat akin a modern federal district, like Washington, D.C. or Mexico City. The city sat {{at the center of}} the four suyu and served as the preeminent center of politics and religion. While Cuzco was essentially governed by the Sapa Inca, his relatives, and the royal panaqa lineages, each suyu was governed by an Apu, a term of great esteem used for men of very high status and for venerated mountains. Just as with so much of Andean society and Inca administration, both Cuzco as a district and the four suyu as administrative regions were grouped into upper hanan and lower hurin divisions. As the Inca did not have written records, it is impossible to <b>exhaustively</b> <b>list</b> the constituent wamani. However, records created during the Spanish colonial period allow us to reconstruct a partial list. There were likely more than 86 wamani, with more than 48 in the highlands and more than 38 on the coast.|$|R
5000|$|Certain {{categories}} of aeroplanes are however deliberately left outside EASA responsibility, thus remaining under {{control of the}} national CAA's: ultralights, experimentals, balloons are a few examples. They are generally referred to as [...] "Annex II" [...] aeroplanes, and are <b>listed</b> <b>exhaustively</b> on the EASA website.|$|R
40|$|This {{document}} is a reference {{guide to the}} Xyce Parallel Electronic Simulator, and is a companion document to the Xyce Users Guide. The focus of this {{document is}} (to the extent possible) <b>exhaustively</b> <b>list</b> device parameters, solver options, parser options, and other usage details of Xyce. This document {{is not intended to}} be a tutorial. Users who are new to circuit simulation are better served by the Xyce Users Guide. The Xyce Parallel Electronic Simulator has been written to support, in a rigorous manner, the simulation needs of the Sandia National Laboratories electrical designers. It is targeted specifically to run on large-scale parallel computing platforms but also runs well on a variety of architectures including single processor workstations. It also aims to support a variety of devices and models specific to Sandia needs. This document is intended to complement the Xyce Users Guide. It contains comprehensive, detailed information about a number of topics pertinent to the usage of Xyce. Included in this document is a netlist reference for the input-file commands and elements supported within Xyce; a command line reference, which describes the available command line arguments for Xyce; and quick-references for users of other circuit codes, such as Orcad's PSpice and Sandia's ChileSPICE...|$|R
40|$|My {{research}} lies in {{the field}} of theoretical computer science with a primary focus in computational complexity theory and a secondary focus in (approximation) algorithms. These two areas may seem unconnected on the surface, but are in fact two sides of a coin: one of the chief goals in my complexity research is to establish limits on our ability to solve certain problems with computers, whereas in my work on approximation algorithms I attempt to work around the proven (or seeming) intractability of computational problems that need to be solved, for various applications. Both areas place great emphasis on precise mathematical modelling of computational problems and rigorous proofs (rather than experimental evidence) to ensure that the research results remain valid in spite of future advances in computer hardware and software. Finally, both areas draw upon, and contribute to, a common toolkit of ideas and basic techniques, leading to plenty of opportunities for cross-fertilisation. Below, I provide some basic background for both these focus areas. I then identify key themes in my research so far, in Section 2 and move on to outlining my most important specific results (rather than <b>exhaustively</b> <b>listing</b> all my results), loosely grouped by topic, in Sections 3 and 4. Finally, in Section 5, I discuss some research directions and specific challenges that I would like to tackle in my future work. Copies of my papers can be found a...|$|R
40|$|Radioactive {{materials}} {{transportation is}} stringently {{regulated by the}} Department of Transportation and the Nuclear Regulatory Commission {{to protect the public}} and the environment. As a Federal agency, however, the U. S. Department of Energy (DOE) must seek State, Tribal and local input on safety issues for certain transportation activities. This interaction has invariably resulted in the imposition of extra-regulatory requirements, greatly increasing transportation costs and delaying schedules while not significantly enhancing the level of safety. This paper discusses the results an analysis of the regulatory and negotiated requirements established for a July 1998 shipment of spent nuclear fuel from foreign countries through the west coast to the Idaho National Engineering and Environmental Laboratory (INEEL). Staff from the INEEL Nuclear Materials Engineering and Disposition Department undertook the analysis in partnership with HMTC, to discover if there were instances where requirements derived from stakeholder interactions duplicate, contradict, or otherwise overlap with regulatory requirements. The study <b>exhaustively</b> <b>lists</b> and classifies applicable Department of Transportation (DOT) and Nuclear Regulatory Commission (NRC) regulations. These are then compared with a similarly classified list of requirements from the Environmental Impact Statements (EIS) and those developed during stakeholder negotiations. Comparison and analysis reveals numerous attempts to reduce transportation risk by imposing more stringent safety measures than those required by DOT and NRC. These usually took the form of additional inspection, notification and planning requirements. There are also many instances of overlap with, and duplication of regulations. Participants will gain a greater appreciation for the need to understand the risk-oriented basis of the radioactive materials regulations and their effectiveness in ensuring safety when negotiating extra-regulatory requirements...|$|R
40|$|Nominalisation {{refers to}} the process of forming a noun from some other word-class. Nominalsations derived from verbs are very {{productive}} in English and are usually created by means of suffixation (i. e., suffixes that form nouns are attached to verb bases). The identification of nominalisations and their associated verbs (e. g. “statement ” and “state”) is important for a number of NLP tasks such as machine translation or information retrieval. Since nominalisation is a productive morphological phenomenon, it is impractical to <b>exhaustively</b> <b>list</b> all acceptable nominalised forms. New words keep being added to any particular language, including new nominalisations. Several NLP techniques have been developed to analyse morphology without focusing specifically on nominalisations. Current algorithms require the building of rules for morphological structures manually, while recent work has focused on machine-learning approaches to induce morphological structures using large corpora {{in order to avoid the}} labour-intensive process of rule-building. Yet another approach is the knowledge-free induction of inflectional morphologies. The principal goal of this project is to develop a system which can recognise nominalisations, together with the verbs from which they are derived. The machine-learning approach of decision tree learning was adopted. Attributes based on frequency statistics and the syntactic context in which nominalisations appear were used for training. The BNC corpus provided the data for the experiments. The obtained “nominalisations ” were evaluated against the CELEX morphological lexicon. The best decision tree can recognise nominalisations with an F-score as high as 81. 6. The associated verbs can then be found using a matching algorithm. Attributes for training are evaluated and possible improvements are discussed. ...|$|R
40|$|Recommender {{systems are}} widely used to predict {{personalized}} preferences of goods or services using users' past activities, such as item ratings or purchase histories. If collections of such personal activities were made publicly available, they {{could be used to}} personalize a diverse range of services, including targeted advertisement or recommendations. However, there would be an accompanying risk of privacy violations. The pioneering work of Narayanan et al. demonstrated that even if the identifiers are eliminated, the public release of user ratings can allow for the identification of users by those who have only a small amount of data on the users' past ratings. In this paper, we assume the following setting. A collector collects user ratings, then anonymizes and distributes them. A recommender constructs a recommender system based on the anonymized ratings provided by the collector. Based on this setting, we <b>exhaustively</b> <b>list</b> the models of recommender systems that use anonymized ratings. For each model, we then present an item-based collaborative filtering algorithm for making recommendations based on anonymized ratings. Our experimental results show that an item-based collaborative filtering based on anonymized ratings can perform better than collaborative filterings based on 5 [...] 10 non-anonymized ratings. This surprising result indicates that, in some settings, privacy protection does not necessarily reduce the usefulness of recommendations. From the experimental analysis of this counterintuitive result, we observed that the sparsity of the ratings can be reduced by anonymization and the variance of the prediction can be reduced if k, the anonymization parameter, is appropriately tuned. In this way, the predictive performance of recommendations based on anonymized ratings can be improved in some settings...|$|R
40|$|This {{thesis is}} a {{monograph}} {{on the work}} of famous Danish filmmaker Jorgen Leth and the main aim of it is to introduce this author to Czech readers. It summarizes basic biographical data and the roots of Leth?s artistic inspiration and focuses on his distinctive filmic style. By the way of several examples, it shows basic creative methods and main thematic areas of his films. The text is based ? besides of sources quoted in the references ? on the personal interview with J&# 248;rgen Leth conducted in July 2008 during the International Film Festival in Karlovy Vary. Important part of the thesis creates <b>exhaustively</b> elaborated <b>list</b> of Leth?s films supplemented with short annotations and some pictures captured from the movies. Except of full-length experimental film The Five Obstructions (2005) directed together with Lars von Trier, {{there is a lack of}} knowledge of his work in the Czech Republic. This thesis wants to contribute to better acquaintance with this interesting and inspiring author...|$|R
40|$|This {{article is}} {{concerned}} with how computer science, and more exactly computational complexity theory, can inform cognitive science. In particular, we suggest factors {{to be taken into}} account when investigating how people deal with computational hardness. This discussion will address the two upper levels of Marr’s Level Theory: the computational level and the algorithmic level. Our reasons for believing that humans indeed deal with hard cognitive functions are threefold: (1) Several computationally hard functions are suggested in the literature, e. g., in the areas of visual search, visual perception and analogical reasoning, linguistic processing, and decision making. (2) People appear to be attracted to computationally hard recreational puzzles and games. Examples of hard puzzles include Sudoku, Minesweeper, and the 15 -Puzzle. (3) A number of research articles in the area of human problem solving suggest that humans are capable of solving hard computational problems, like the Euclidean Traveling Salesperson Problem, quickly and near-optimally. This article gives a brief introduction to some theories and foundations of complexity theory and motivates the use of computationally hard problems in human problem solving with a short survey of known results of human performance, a review of some computationally hard games and puzzles, and the connection between complexity theory and models of cognitive functions. We aim to illuminate the role that computer science, in particular complexity theory, can play in the study of human problem solving. Theoretical computer science can provide a wealth of interesting problems for human study, but it can also help to provide deep insight into these problems. In particular, we discuss the role that computer science can play when choosing computational problems for study and designing experiments to investigate human performance. Finally, we enumerate issues and pitfalls that can arise when choosing computationally hard problems as the subject of study, in turn motivating some interesting potential future lines of study. The pitfalls addressed include: choice of presentation and representation of problem instances, evaluation of problem comprehension, and the role of cognitive support in experiments. Our goal is not to <b>exhaustively</b> <b>list</b> all the ways in which these choices may impact experimental studies, but rather to provide a few simple examples in order to highlight possible pitfalls...|$|R
40|$|Digital {{objects in}} the field of earth and {{biological}} sciences are known to be often compound and complex. If one takes biodiversity as example, an <b>exhaustively</b> long <b>list</b> of information systems can be found on-line. These systems often contain valuable and historically relevant information gathered over several decades using distinct archival resources, data models and transport protocols. In order to assure long term preservation of this distributed and not yet networked mass of information on worlds biota, we need to create an abstract interoperability layer in which digital objects sharing the same data model are aggregated so as to allow for information preservation, transformation, re-use and exchange. Using panFMP and FEDORA technologies, we propose a strategy for creating an information network for biodiversity and related contextual content (e. g., oceanographic data). A prototype for the proposed information network was built upon existing PlanktonNet data providers, publication repositories and environmental data archived in WDC-Mare/Pangaea. Because XML schemas for metadata description and for expressing relationships among digital objects are available, interoperability with other federated networks will be assured. In addition, a panFMP front-end customized specifically for PlanktonNet is presented as metadata porta...|$|R
40|$|Dictionary look-up is {{the primary}} {{strategy}} for deriving pronunciations for input words in a text-to-speech (TTS) system. This strategy is accurate for dictionary words, {{but it is not}} complete: it is impossible to <b>list</b> <b>exhaustively</b> all input words. The proper treatment of `unknown' words is currently an unsolved problem in TTS synthesis. There are many competing techniques for letter-to-sound conversion and the system developer must make a rational selection among them. However, it is unclear how different techniques should be properly compared. In this paper, we report a comparative assessment of the competitor methods of letter-to-sound rules, pronunciation by analogy, feedforward neural networks and a k-nearest neighbour method, with respect to their success at automatic phonemisation. This is achieved by using standardised scoring methods, test lexicon and phoneme inventories. The problem of standardising the phoneme set (`harmonisation') is deceptive: this is much harder than at fi [...] ...|$|R
40|$|This paper extends {{previous}} work on pronunciation by analogy (PbA) in several directions. PbA is a data-driven method for converting letters to sound, with potential application to next-generation text-to-speech systems. We experiment {{with a range}} of methods for matching letter patterns in input words to those in the system dictionary when building a pronunciation lattice. We give preliminary consideration to deriving lexical stress for input words. Common errors are analysed: these mostly involve vowel letters and phonemes. An output is not necessarily guaranteed in PbA [...] the so-called silence problem. We report on a simple but effective strategy for silence avoidance. Finally, we introduce the idea of using different strategies in combination to improve performance. 1. INTRODUCTION Modern text-to-speech (TTS) systems use look-up in a large dictionary as the primary strategy to determine the pronunciation of input words. However, {{it is not possible to}} <b>list</b> <b>exhaustively</b> all the word [...] ...|$|R
40|$|Kloosterman sums are {{exponential}} sums on finite {{fields with}} important applications in Cryptography and Coding Theory. Of particular importance are those field elements {{at which the}} Kloosterman sum attains the value 0, which are called Kloosterman zeros. They exist only in fields of characteristic 2 and 3. We prove an upper bound on {{the density of the}} classical modular polynomial when it is considered as a polynomial over GF(2). We develop an algorithm to <b>list</b> <b>exhaustively</b> Kloosterman zeros in a given field of characteristic 2. Using this algorithm we list all Kloosterman zeros in fields of order $ 2 ^m$ for $mle 63 $, whereas this has been done only for $mle 14 $ in the literature. We develop an algorithm to discover relations satisfied by coefficients of minimal polynomials of Kloosterman zeros in characteristic 2. We rediscover five such relations that have been proved in the literature and we conjecture two new relations...|$|R
40|$|Free listing is an {{important}} ethnographic tool for defining semantic domains. How-ever, when informants free list items from a particular domain, they often do not mention all items they know because they forget items and/or do not understand that they should <b>list</b> <b>exhaustively.</b> In this article, the author reviews results from research on three supplementary interviewing techniques to encourage full responding and enhance recall in such tasks (nonspecific prompting, reading back to the informant the items he or she free listed, and using free-listed items as semantic cues). These methods increase substantially {{the number of items}} elicited from individual infor-mants and the number of items in a domain identified from informants in the aggre-gate. Moreover, these techniques do not require the interviewer to have any prior domain knowledge to be effective. Free listing is a basic ethnographic tool for defining semantic domains (Weller and Romney 1988). When people free list items from a semantic domain—such as the names of plants, treatments for a particular illness, or brands in a specific product category—they often do not list all the items the...|$|R
40|$|To browse a notebook, {{download}} the relevant file, unzip {{to a local}} disk, {{and click on the}} "index" file. This will allow the ELN to be navigated in a web browser. Links between lab notebooks may not function correctly. Finding compounds within the lab notebooks may be achieved using the OSM codes mentioned in the research paper, or using cheminformatic strings (e. g. SMILES). When using the search function, tick the "simple text search" for more relevant results. The files are zipped snapshots of the electronic laboratory notebooks (ELNs) used by the Open Source Malaria (OSM) consortium that are relevant to the paper "Open Source Drug Discovery - Highly Potent Antimalarial Compounds Derived from the Tres Cantos Arylpyrroles". The current "live" versions of the ELNs, and ELNs relevant to other parts of OSM, may be found at [URL] Many scientists contributed to these resources, and their names may be found within the ELNs and in the paper authorship list. Australian Research Council and the Medicines for Malaria Venture. There were numerous project inputs (cash and in-kind) from other sources, and these are <b>listed</b> <b>exhaustively</b> in the acknowledgements section of the relevant paper. Chemistr...|$|R
