9|5|Public
50|$|MapReduce is a {{framework}} for processing parallelizable problems across large datasets using {{a large number of}} computers (nodes), collectively referred to as a cluster (if all nodes are on the same local network and use similar hardware) or a grid (if the nodes are shared across geographically and administratively distributed systems, and use more <b>heterogenous</b> <b>hardware).</b> Processing can occur on data stored either in a filesystem (unstructured) or in a database (structured). MapReduce {{can take advantage of the}} locality of data, processing it near the place it is stored in order to minimize communication overhead.|$|E
40|$|Abstract—Reconfigurable {{networked}} {{systems have}} often been developed via dynamically deployed software components that are executing on top of interconnected <b>heterogenous</b> <b>hardware</b> nodes. The challenges resulting from the complexity of those systems have been traditionally mitigated by indi-vidual ad-hoc problem solutions and industrial best practices guidelines tuned to the particular domain specific modeling frameworks and methodologies. Targeting this deficiency, this paper disseminates an alternative, semi-formal methodology that incorporates a first-order logic based structural modeling language, Alloy, {{in the analysis of}} component deployment and reconfiguration. This novel approach could help to extend the limits of the generic domain specific metamodeling method-ology that has been developed for creating Reconfigurable Ubiquitous Networked Embedded Systems. Keywords-Alloy; formal model semantics; metamodeling; dynamic component system; platform middleware; RUNES; Erlang; ErlCOM I...|$|E
40|$|Abstract. Complex {{physical}} simulations {{have driven}} {{the need for}} exascale computing, but reaching exascale will require more power-efficient supercomputers. <b>Heterogenous</b> <b>hardware</b> offers one way to increase efficiency, but is difficult to program and lacks a unifying programming model. Abstracting problems {{at the level of}} the domain rather than hardware offers an alternative approach. In this paper we describe the design of Liszt, a domain-specific language for solving partial-differential equations on meshes. There have been many domain-specific languages and frameworks proposed for physical simulation. Liszt is unique in that it targets current and future heterogeneous platforms. We have found that designing a DSL requires a careful balance between features that allow for automatic parallelization, and features that make the language flexible. 1...|$|E
40|$|Software {{development}} for autonomous mobile robots {{is a difficult}} task. One {{of the reasons is}} the very challenging characteristics of this application domain. It features an extremely <b>heterogenous</b> set of <b>hardware</b> devices, the necessity of concurrent and distributed information processing, a tight coupling of algorith-mic solutions to the physical properties of the robot and its environment, the stochastic properties of the physical world, as well as timeliness constraints and resource constraints. And all these features need to be addressed simultaneously when developing solutions in the field of autonomous mobile robots. ...|$|R
40|$|The {{continuous}} {{progress in}} communication, networking and database systems demands a new perception of data processing. A growing amount of network-based applications requires {{access to a}} multitude of mostly autonomous data sources located in a <b>heterogenous</b> software and <b>hardware</b> environment. Advances in database design o#er new possibilities for the integration of autonomous local database systems. Active component systems do not only provide access to stored data, but significantly control business rules and integrity constraints by working cooperatively with each other while retaining the greatest possible extent of local autonomy. We introduce ideas and concepts for the realisation of active multidatabases by extending standard database interfaces...|$|R
40|$|This paper {{examines}} economic {{resource allocation}} {{through a number}} of auction types for a grid of e-waste computers. It examines the time to complete tasks and the energy usage of completing the tasks on a grid. A model of a simulated grid is developed and used to evaluate the resource allocation mechanisms. The model is an agent-based simulation where by user agents submit tasks to node agents that process these tasks. We evaluate three types of resource-allocator agents which all use a type of auction. The auction types are batch auction, continuous double auction and a pre-processed batch auction. The pre-processed batch auction is developed to try to have the advantages of both the continuous double auction and the batch auction. The simulated grid is calibrated to a real e-waste grid where each node has a performance index. This grid is a test grid of eight nodes of <b>heterogenous</b> computer <b>hardware</b> and with differing computational ability and energy usage. We simulate the auction types under the same task input streams. We consider a task impulse response stream on energy usage and time to complete all tasks and a input stream step response. Finally we consider the three auction allocation mechanisms under a random task stream. The paper finds that the choice of auction method makes a substantial difference in the time to complete tasks and in total energy consumption...|$|R
40|$|This paper {{presents}} a new conception for a distributed task-oriented real-time operating system comprising a compiler, an operating system kernel and communication packages. The system TOROS supplies the tools for a uniform programming of complex process control applications on <b>heterogenous</b> <b>hardware</b> including workstation, PC, programmable controller and microcontroller. The whole control task is split into {{a set of}} small modules. These modules are uniquely programmed by defining a state machine and using guarded commands. They are connected logically through calls to tasks provided by other modules. The specification of the modules is done in an hardware independent language. At compile time the modules are distributed to specified target computers. The system automatically translates each module into the particular code and realizes the communication between the modules either on the same computer or through the links. Keywords. Real-time operating system, real-time language, distr [...] ...|$|E
40|$|The {{state-of-the-art}} OpenFlow technology {{only partially}} realized SDN vision of abstraction and centralization for packet forwarding in switches. OpenFlow/P 4 falls short in implementing middlebox functionalities {{due to the}} fundamental limitation in its match-action abstraction. In this paper, we advocate the vision of Software-Defined Middleboxes (SDM) to realize abstraction and centralization for middleboxes. We further propose OpenFunction, an SDM reference architecture and a network function abstraction layer. Our SDM architecture and OpenFunction abstraction are complementary to existing SDN and Network Function Virtualization (NFV) technologies. SDM complements SDN as SDM realizes abstraction and centralization for middleboxes, whereas SDN realizes those for switches. OpenFunction complements OpenFlow as OpenFunction addresses network functions whereas OpenFlow addresses packet forwarding. SDM also complements NFV in that SDM gives NFV {{the ability to use}} <b>heterogenous</b> <b>hardware</b> platforms with various hardware acceleration technologies. Comment: 15 page...|$|E
40|$|Despite the admittedly hesitating, but {{increasing}} {{market acceptance}} of CIM communication standards such as MMS (Manufacturing Message Specification) {{the development and}} integration of CIME applications (CIM and Engineering) in a <b>heterogenous</b> <b>hardware</b> and software environment remains an enourmous cost factor. A very promising improvement of this situation is expected by the provision of a powerful software platform based upon standard components. The article describes the open and distributed software platform CCE (CIME Computing Environment) {{for the support of}} CIME applications. First, the essential requirements for an application-oriented software platform are described from the viewpoint of the user. Derived from these the system architecture of the CCE platform is considered by focussing on the properties of transparency of the information access method (eg. MMS, database access, file transfer, [...] .), application-specific extensibility and re-usability of software. The article finishe s with a presentation of the benefits of such a platform in the light of a pilot installation at Mercedes-Benz...|$|E
40|$|This report concludes phase I of the project. Two {{significant}} accomplishments are reported, {{the first}} {{relating to the}} design of heterogeneous parallel systems, and the second related to the synthesis of parallel programs for the CM- 5 from Thinking Machines. A methodology for design and evaluation of parallel architectures with heterogeneous compo-nents has been developed. Specifically, the "communicating processes " (CP) domain in Ptolemy has been used to model <b>heterogenous</b> parallel <b>hardware</b> systems. Our first demonstra-tion design uses the "ALPS " concept (Alternative Low-level Primitive Structures). Use of the CP domain is a departure from our proposal, where we had proposed to use a discrete-event model. We have determined, however, that the CP model is considerably more convenient for high-level design of heterogeneous parallel hardware. The CP domain in Ptolemy has a multi-W tasking kernel managing concurrent processes. A process, or thread, is created for each com- 1 ý c putational and communications system resource in a particular design. The CP model of coin-L putation makes it easy to write and interconnect a variety of computational resources and-ýq simulate the execution of an application to evaluate the particular architectural configuration. We have developed a Target in Ptolemy for the CM- 5 from Thinking Machines Inc. The pro- 0 S] cessing nodes of the CM- 5 (Sparc processors with dedicated network interfaces) match wel...|$|R
40|$|Abstract: This paper {{examines}} economic {{resource allocation}} {{through a number}} of auction types for a grid of e-waste computers. It examines the time to complete tasks and the energy usage of completing the tasks on a grid. A model of a simulated grid is developed and used to evaluate the resource allocation mechanisms. The model is an agent-based simulation where by user agents submit tasks to node agents that process these tasks. We evaluate three types of resource-allocator agents which all use a type of auction. The auction types are batch auction, continuous double auction and a pre-processed batch auction. The pre-processed batch auction is developed to try to have the advantages of both the continuous double auction and the batch auction. The simulated grid is calibrated to a real e-waste grid where each node has a performance index. This grid is a test grid of eight nodes of <b>heterogenous</b> computer <b>hardware</b> and with differing computational ability and energy usage. We simulate the auction types under the same task input streams. We consider a task impulse response stream on energy usage and time to complete all tasks and a input stream step response. Finally we consider the three auction allocation mechanisms under a random task stream. The paper finds that the choice of auction method makes a substantial difference in the time to complete tasks and in total energy consumption. Key–Words: grid computing, resource allocation, auctions, e-waste, energy consumption...|$|R
40|$|We {{report on}} the 3 DNSITE system, a web-based {{client-server}} 3 D visualizationtoolforstreamingandvisualizinglargetridimensional hybrid data (georeferenced point clouds and photographs with associated viewpoints and camera parameters). The system is motivated {{by the need to}} simplify data acquisition and location recognition for crisis managers and first responders during emergency operations or training sessions. In this peculiar context, {{it is very important to}} easily share 3 D environment data among people in a distributed environment, accessing huge 3 D models with embedded photographs on devices with <b>heterogenous</b> <b>hardware</b> capabilitiesandinterconnectedondifferentnetworktypes. Moreover,since the specific end-users are not necessary skilled with virtual reality and 3 D objects interaction, the navigation interface must be simple and intuitive. Taking into account these constraints, we propose a mixel object-based/image-based system, which enhances the current state-of-the-art by exploiting a multi-resolution representation for the 3 D model and a multi-level cache system for both the imagesand 3 Dmodelsstructure. Anovellow-degree-of-freedomuser interface is presented to navigate in the scenario with touchscreen devices. The proposed implementation, included in a more general training and decision framework for emergency operations, is evaluated onreal-world datasets...|$|E
40|$|Future {{intelligent}} environments will be {{inhabited by}} humans, robots and ‘Smart Objects’ {{and allow for}} seamless interaction beyond the desktop. These environments therefore have to be adaptive, self-organizing, provide autonomous reasoning and integrate a variety of <b>heterogenous</b> <b>hardware,</b> objects, sensors and actuators – which goes far beyond merely interconnecting different kinds of technology. In light of the dawn of personal robotics, these environments should be equally usable and supportive for humans and robots. Manipulation tasks involving physical objects are at core of the interaction in these environments. This places novel challenges on the involved ‘Smart Objects’. We present an approach for supporting robotic systems in the interaction with physical objects while maintaining human usability and functionality by using so-called ‘Cognitive Objects’. We describe our infrastructure to support developing, simulating, testing and deploying of pervasive computing systems, using ROS (Robot Operating System) as middleware, and present several application scenarios. The scenarios {{are not limited to}} the robotics domain, but include location-aware services, intelligent environments and mobile interaction therein. Based on our experience, recommendations for the design of ‘Cognitive Objects’ (CO) and environments are given, to address the individual strengths of humans and machines and to foster new synergies in shared human-robot environments...|$|E
30|$|Middleware {{infrastructure}} {{represents the}} logic glue in a distributed computing system, as it connects and coordinates many components constituting distributed applications. This occurs, more specifically, ‘in {{the midst of}} a variety of heterogeneous hardware systems and software applications needed for realizing smart environments and their proper functioning. To put it differently, in order for the massively embedded, distributed, networked devices and systems, which are invisibly integrated into the environment, to coordinate require middleware components, architectures, and services. Middleware allows multiple processes running on various sensors, devices, computers, and networks to link up and interact to support (and maintain the operation of context-aware applications needed by citizens and urban entities to cope with and perform their) activities wherever and whenever needed.’ ([19], p. 50). Indeed, it is the ability of multiple, <b>heterogenous</b> <b>hardware</b> and software systems to cooperate, interconnect, and communicate seamlessly across disparate networks that create smart environments rather than just their ubiquitous presence and massive use. In the context of smart sustainable cities, such systems in their various forms (e.g. sensors, smartphones, computers, databases, data warehouses, application integration methods, application servers, web servers, context management systems, and messaging systems) are highly distributed, interoperable, and dynamic, involving a myriad of embedded devices and information processing units ‘whose numbers are set to increase by orders of magnitude and which are to be exploited in their full range to transparently provide services on a hard-to-imagine scale, regardless of time and place’ [19]. This in turn allows for the functioning of context-aware applications across the diverse domains of smart sustainable cities.|$|E

