43|10000|Public
25|$|SQL Server Analysis Services adds OLAP {{and data}} mining {{capabilities}} for SQL Server databases. The OLAP engine supports MOLAP, ROLAP and HOLAP storage modes for <b>data.</b> <b>Analysis</b> <b>Services</b> supports the XML for Analysis standard as the underlying communication protocol. The cube {{data can be}} accessed using MDX and LINQ queries.|$|E
25|$|SharePoint Server allows searching of all Office {{documents}} {{which are}} being managed by it, centrally, thereby making data more accessible. It also provides access control for documents. Specialized server components can plug into the SharePoint Server to extend the functionality of the server, such as Excel Services exposing <b>data</b> <b>analysis</b> <b>services</b> for Excel services. Data from other data sources can also be merged with Office data.|$|E
2500|$|CUBE {{functions}} {{which allow}} importing data, including set aggregated data, from <b>data</b> <b>analysis</b> <b>services,</b> such as SQL Server Analysis Services ...|$|E
40|$|This paper {{illustrates}} how a grid computing architecture and a service oriented architecture (SOA) will accelerate telemetry (TM) data processing and make flexible TM <b>data</b> <b>analysis</b> <b>service.</b> Moreover, {{this paper will}} articulate grid computational and data resources management, tacking a TM system {{as a case study}} from the Egyptian space program (ESP). General Terms Modeling, distributed computin...|$|R
40|$|Translation of <b>Data</b> <b>analysis</b> {{algorithms}} from <b>data</b> <b>analysis</b> {{language to}} high-level programming language {{is hard work}} when we construct a cloud computing platform for <b>data</b> <b>analysis.</b> It adds implementation difficulty and maintenance cost of constructing the platform. This paper suggests a new method to use the popular <b>data</b> <b>analysis</b> language R directly on constructing a cloud computing platform. By using resource virtualization techniques, computing resource environment is virtualized into R cluster based on given configurations. By allocating different R machines from R cluster to specified <b>data</b> <b>analysis</b> <b>service,</b> we solve the problem that <b>data</b> <b>analysis</b> algorithms implemented in R should be run in single-user mode only and cannot be customized. After verification, this method simplifies the work of translating <b>data</b> <b>analysis</b> algorithms and speeds up the process of constructing a cloud computing platform for <b>data</b> <b>analysis...</b>|$|R
50|$|In 1984, Gray {{founded the}} company Gray Data in Chicago, which {{provided}} <b>data</b> <b>analysis</b> research <b>services</b> and published reference cards for microcomputer software. He {{continues to work}} as a data analyst through his company Gray Consulting.|$|R
5000|$|Fios Genomics - genomic and {{bioinformatics}} <b>data</b> <b>analysis</b> <b>services</b> {{for drug}} discovery & development ...|$|E
5000|$|CUBE {{functions}} {{which allow}} importing data, including set aggregated data, from <b>data</b> <b>analysis</b> <b>services,</b> such as SQL Server Analysis Services ...|$|E
50|$|Computomics is a {{biotechnology}} company co-founded by Detlef Weigel and MEGAN author Daniel Huson. Computomics provides bioinformatics <b>data</b> <b>analysis</b> <b>services</b> {{for plant}} breeding and metagenomics analyses for plant protection.|$|E
40|$|AMDA (Automated Multi-Dataset <b>Analysis),</b> a new <b>data</b> <b>analysis</b> <b>service,</b> re-cently {{opened at}} the French Plasma Physics Data Center (CDPP). AMDA is {{developed}} according to the Virtual Observatory paradigm: it is a web-based facility for on-line analyses of space physics. Data may come from its own local database as well as remote ones. This tool allows the user to perform classical manipulations such as data visualization, parameter computation and data ex-traction. AMDA also offers innovative functionalities such as event searches {{on the content of}} the data in either visual or automated ways, generation, use and ∗Corresponding autho...|$|R
50|$|Baker Atlas - Baker Atlas {{provides}} wireline-conveyed well logging, <b>data</b> <b>analysis</b> and perforating <b>services</b> for formation evaluation, {{production and}} reservoir management.|$|R
50|$|A bespoke research, <b>data</b> and <b>analysis</b> <b>service,</b> MEED Insight specialises in Middle East {{industry}} or sector scoping, market surveys, evaluation and forecasting, market entry assistance, project overviews and competitor analysis. Core sectors are oil and gas, petrochemicals, banking and finance, manufacturing, transport and logistics, power and water.|$|R
50|$|Deals {{with the}} process {{management}} and outsourcing for testing and qualifications; <b>data</b> <b>analysis</b> <b>services</b> for teachers, education managers and policy makers. Clients include Cambridge Assessment and the International Baccalaureate.|$|E
50|$|ICSU World Data System {{superseded}} the World Data Centres (WDCs) and Federation of Astronomical and Geophysical <b>data</b> <b>analysis</b> <b>Services</b> (FAGS) {{created by}} ICSU to manage data {{generated by the}} International Geophysical Year (1957-1958).|$|E
50|$|Data Desk's developer, Data Description, pioneered linked graphic {{displays}} {{including a}} 3-D rotating plot and graphical slider control of parameters. It has also developed proprietary technology for computer-based multimedia instruction and currently provides contract <b>data</b> <b>analysis</b> <b>services.</b>|$|E
40|$|Abstract. B-Course is {{a web-based}} <b>data</b> <b>analysis</b> <b>service</b> for Bayesian modeling. Although already in use by {{researchers}} from many scientific disciplines, the {{current version of}} B-Course does not allow domain experts to incorporate prior knowledge into the system, but the models are constructed from sample data only by using machine learning techniques. P-Course is an attempt to modify B-Course so that domain knowledge can be expressed in form of priors, which are then combined with the statistical data. The current version of P-Course is designed for supervised classification problems. We discuss the design principles of the P-Course system and demonstrate its usefulness by using real-world examples from the medical domain. ...|$|R
40|$|International audienceAMDA (Automated Multi-Dataset <b>Analysis),</b> a new <b>data</b> <b>analysis</b> <b>service,</b> {{recently}} {{opened at the}} French Plasma Physics Data Center (CDPP). AMDA is developed according to the Virtual Observatory paradigm: it is a web-based facility for on-line analyses of space physics. Data may come from its own local database as well as remote ones. This tool allows the user to perform classical manipulations such as data visualization, parameter computation and data extraction. AMDA also offers innovative functionalities such as event searches {{on the content of}} the data in either visual or automated ways, generation, use and management of time tables (event lists). The general functionalities of AMDA are presented in the context of Space Weather with example scientific use cases...|$|R
40|$|Source {{code for}} META-pipe {{authorization}} server {{as described in}} our F 1000 publication. Abstract. We describe the design, implementation, {{and use of the}} META-pipe Authorization service. META-pipe is a complete workflow for the analysis of marine metagenomics data. We will provide META-pipe as a web based <b>data</b> <b>analysis</b> <b>service</b> for ELIXIR users. We have integrated our Authorization service with the ELIXIR Authorization and Authentication Infrastructure (AAI) that allows single sign-on to services across the ELIXIR infrastructure. We use the Authorization service to authorize access to data on the META-pipe storage system and jobs in the META-pipe job queue. Our Authorization server was among the first services that integrated with ELIXIR AAI. The code is open source at: [URL]...|$|R
5000|$|ICSU-WDS {{goals are}} to {{preserve}} quality assured scientific data and information, to facilitate open access, {{and promote the}} adoption of standards.ICSU World Data System created in 2008 superseded the World Data Centeres (WDCs) and Federation of Astronomical and Geophysical <b>data</b> <b>analysis</b> <b>Services</b> (FAGS) created by ICSU to manage data generated by the International Geophysical Year ...|$|E
50|$|From 1956 until 1987 the BIH {{was part}} of the Federation of Astronomical and Geophysical <b>Data</b> <b>Analysis</b> <b>Services</b> (FAGS). In 1987 the bureau's tasks of {{combining}} different measurements of Universal Time were taken over by the BIPM. Its tasks related to the correction of time with respect to the celestial reference frame and the earth's rotation were taken over by the IERS.|$|E
50|$|In March 2011, GyPSii {{partnered with}} Chinese web portal Sina.com to launch WeiLingDi, a Chinese {{language}} location-based mobile social networking application that {{allows users to}} share their location and status, broadcast events and updates, find friends, and earn rewards points and badges. In 2011, analysts speculated that WeiLingDi could generate substantial income from advertising and <b>data</b> <b>analysis</b> <b>services</b> based on Sina's 100 million users.|$|E
30|$|As {{shown in}} Fig.  1, {{different}} services are situated—in a microservice-based architecture—on {{top of the}} Big Data software stack. The <b>data</b> <b>analysis</b> <b>service</b> {{is the one that}} allows frontend applications to start, monitor, and manage forecasting computations on the cluster. Such applications can access the service through a REST API. Additionally, {{with the help of a}} Web UI, i.e. a more convenient frontend application, the data analyst can operate the services using a highly customizable and dynamic user interface. These frontend applications spare the data analyst any interaction with the actual cluster and hide the complexity of the different Big Data tools. Furthermore, to develop different algorithms using Spark the data analyst can use the Apache Zeppelin 6 tool to implement and document new computation jobs dynamically.|$|R
50|$|EAA also {{provides}} scanning, <b>data</b> <b>analysis</b> and reporting <b>services</b> to commercial and educational institutions. In addition, our psychometric, research and assessment teams are {{currently working on}} various other commercial and research projects.|$|R
5000|$|In 2000, Microsoft {{released}} <b>Analysis</b> <b>Services</b> 2000. It {{was renamed}} from [...] "OLAP Services" [...] {{due to the}} inclusion of <b>data</b> mining <b>services.</b> <b>Analysis</b> <b>Services</b> 2000 was considered an evolutionary release, since it {{was built on the}} same architecture as OLAP Services and was therefore backward compatible with it. Major improvements included more flexibility in dimension design through support of parent child dimensions, changing dimensions, and virtual dimensions. Another feature was a greatly enhanced calculation engine with support for unary operators, custom rollups, and cell calculations. Other features were dimension security, distinct count, connectivity over HTTP, session cubes, grouping levels, and many others.|$|R
50|$|SharePoint Server allows searching of all Office {{documents}} {{which are}} being managed by it, centrally, thereby making data more accessible. It also provides access control for documents. Specialized server components can plug into the SharePoint Server to extend the functionality of the server, such as Excel Services exposing <b>data</b> <b>analysis</b> <b>services</b> for Excel services. Data from other data sources can also be merged with Office data.|$|E
50|$|Tandberg-Hanssen {{was vice}} {{president}} of Commission 10 of the International Astronomical Union from 1979 to 1982 and president from 1982 to 1985. He {{was president of the}} Federation of Astronomical and Geophysical <b>Data</b> <b>Analysis</b> <b>Services</b> from 1990 to 1994. He was a fellow of the Norwegian Academy of Science and Letters from 1982 and received the NASA Exceptional Service Medal. He died in July 2011 in Huntsville.|$|E
5000|$|<b>Data</b> <b>analysis</b> <b>services</b> {{are offered}} by firms, {{also known as}} tab houses, that {{specialize}} in computer analysis of quantitative data such as those obtained in large surveys. Initially most data analysis firms supplied only tabulations (frequency counts) and cross tabulations (frequency counts that describe two or more variables simultaneously). With the proliferation of software, many firms now {{have the capability to}} analyze their own data, but, data analysis firms are still in demand.|$|E
40|$|Source {{code for}} the tools {{described}} in the paper: META-pipe Cloud Setup and Execution. Abstract. META-pipe is a complete <b>service</b> for the <b>analysis</b> of marine metagenomic data. It provides assembly of high-throughput sequence data, functional annotation of predicted genes, and taxonomic profiling. The functional annotation is computationally demanding and is therefore currently run on a high-performance computing cluster in Norway. However, additional compute resources are necessary to open the service to all ELIXIR users. We describe our approach for setting up and executing the functional analysis of META-pipe on additional academic and commercial clouds. Our goal {{is to provide a}} powerful <b>analysis</b> <b>service</b> that is easy to use and to maintain. Our design therefore uses a distributed architecture where we combine central servers with multiple distributed backends that execute the computationally intensive jobs. We believe our experiences developing and operating META-pipe provides a useful model for others that plan to provide a portal based <b>data</b> <b>analysis</b> <b>service</b> in ELIXIR and other organizations with geographically distributed compute and storage resources...|$|R
40|$|The paper {{deals with}} the {{problems}} related to the usage of relational database management system (RDBMS), mainly in the <b>analysis</b> of large <b>data</b> content, including <b>data</b> <b>analysis</b> based on web services in the Internet. A solution of these problems can be represented as a web-oriented distributed system of the <b>data</b> <b>analysis</b> with the processor of service requests as an executive kernel. The functions of such system {{are similar to the}} functions of relational DBMS, only with the usage of web services. The processor of service requests is responsible for planning of <b>data</b> <b>analysis</b> web <b>services</b> calls and their execution. The efficiency of such web-oriented system depends on the efficiency of web services calls plan and their program implementation where the basic element is the facilities of analyzed data storage – relational DBMS. The main attention is given to extension of functionality of relational DBMS for the <b>analysis</b> of large <b>data</b> content, in particular, the perspective estimation of web <b>services</b> <b>data</b> <b>analysis</b> implementation on the basis of SQL/MapReduce platform. With a view of obtaining this result, analytical task was chosen as an application-oriented part, typical for <b>data</b> <b>analysis</b> in various social networks and web portals, based on <b>data</b> <b>analysis</b> of users’ attendance. In the practical part of this research the algorithm for planning of web services calls was implemented for application-oriented task solution. SQL/MapReduce platform efficiency is confirmed by experimental results that show the opportunity of effective application for <b>data</b> <b>analysis</b> web <b>services...</b>|$|R
30|$|A usage {{scenario}} for the Big Data forecasting concept {{is illustrated in}} Fig. 2. First, the data analyst implements a forecasting model using the Zeppelin software. After thorough tests, the source code can be uploaded to the cluster using the Web UI. Thereafter, the <b>data</b> <b>analysis</b> <b>service</b> triggers the compilation of the source code {{and the creation of}} a new Spark job that is then persisted in the Hadoop Distributed File System (HDFS). In the next step, the data analyst selects a time series training set and starts the training algorithm. The resulting model and parameters are stored in the cluster. Using these results, the forecasting model can be applied to new data. Afterwards, the forecast results are stored in the time series database with a link to the forecasting model for later retrieval. The Spark job itself has to be able to access the databases in order to load the data in a distributed way. This is an important criterion in terms of performance.|$|R
50|$|Headquartered in St. Louis, Missouri, Express Scripts {{provides}} integrated pharmacy benefit {{management services}} including network-pharmacy claims processing; home delivery pharmacy services; specialty pharmacy benefit management, through its subsidiary Accredo; benefit-design consultation; drug-utilization review; formulary management; and medical and drug <b>data</b> <b>analysis</b> <b>services</b> to manage drug plans for health plans, self-insured employers {{and government agencies}} (both as administrator of employee benefits and public assistance programs). One of its largest clients is the United States Department of Defense's Tricare program.|$|E
50|$|SQL Server Analysis Services adds OLAP {{and data}} mining {{capabilities}} for SQL Server databases. The OLAP engine supports MOLAP, ROLAP and HOLAP storage modes for <b>data.</b> <b>Analysis</b> <b>Services</b> supports the XML for Analysis standard as the underlying communication protocol. The cube {{data can be}} accessed using MDX and LINQ queries.Data mining specific functionality is exposed via the DMX query language. Analysis Services includes various algorithms—Decision trees, clustering algorithm, Naive Bayes algorithm, time series analysis, sequence clustering algorithm, linear and logistic regression analysis, and neural networks—for use in data mining.|$|E
40|$|The Ribosomal Database Project (RDP) is a curated {{database}} that offers ribosome-related <b>data,</b> <b>analysis</b> <b>services</b> and associated computer programs. The offerings include phylogenetically ordered alignments of ribosomal RNA (rRNA) sequences, derived phylogenetic trees, rRNA secondary structure diagrams and various software for handling, analyzing and displaying alignments and trees. The {{data are available}} via anonymous ftp (rdp. life. uiuc. edu), electronic mail (server@rdp. life. uiuc. edu), gopher (rdpgopher. life. uiuc. edu) and World Wide Web (WWW) ([URL] The electronic mail and WWW servers provide ribosomal probe checking, screening for possible chimeric rRNA sequences, automated alignment and approximate phylogenetic placement of user-submitted sequences on an existing phylogenetic tree...|$|E
50|$|Simulations Plus, Inc. {{develops}} absorption, distribution, metabolism, excretion, and toxicity (ADMET) {{modeling and}} simulation software for the pharmaceutical and biotechnology, industrial chemicals, cosmetics, food ingredients, and herbicide industries. In September 2014, the company acquired Cognigen Corporation, a leading provider of clinical trial <b>data</b> <b>analysis</b> and consulting <b>services.</b>|$|R
40|$|The NERC Earth Observation <b>Data</b> Acquisition and <b>Analysis</b> <b>Service</b> (NEODAAS) {{provides}} a central point of Earth Observation (EO) satellite data access and expertise for UK researchers. The service is tailored to individual users’ requirements {{to ensure that}} researchers can focus effort on their science, rather than struggling with correct use of unfamiliar satellite data...|$|R
40|$|We {{present the}} design and {{implementation}} of the Japanese Virtual Observatory (JVO) system. JVO is a portal site to various kinds of astronomical resources distributed all over the world. We have developed five components for constructing the portal: (1) registry, (2) data service, (3) workflow system, (4) <b>data</b> <b>analysis</b> <b>service</b> (5) portal GUI. Registry services are used for publishing and searching data services in the VO, and they are constructed using an OAI-PMH metadata harvesting protocol and a SOAP web service protocol so that VO standard architecture is applied. Data services are developed based on the Astronomical Data Query Language (ADQL) which is an international VO standard and an extension of the standard SQL. The toolkit for building the ADQL-based service is released to the public on the JVO web site. The toolkit also provides the protocol translation from a Simple Image Access Protocol (SIAP) to ADQL protocol, so that both the VO standard service can be constructed using our toolkit. In order to federate the distributed databases and <b>analysis</b> <b>services,</b> we have designed a workflow language which is described in XML and developed execution system of the workflow. We have succeeded to connect to a hundred of data resources of the world as of April 2006. We have applied this system to the study of QSO environment by federating a QSO database, a Subaru Suprim-Cam database, and some <b>analysis</b> <b>services</b> such a SExtractor and HyperZ web services. These experiences are described is thi...|$|R
