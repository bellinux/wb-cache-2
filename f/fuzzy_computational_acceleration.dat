0|100|Public
40|$|Image {{segmentation}} of retinal vessels is {{an important}} and very challenging task in any automated system for the diagnosis of vascular conditions associated with diabetic retinopathy, which {{are the most common}} complications of diabetes. In this paper we propose several <b>fuzzy</b> <b>computational</b> models for detecting retinal vessels in images, which are subjected to inconsistent contrast and vague boundaries...|$|R
40|$|In {{our recent}} {{publication}} [1] we presented an exponential series approximation suitable for highly accurate computation {{of the complex}} error function in a rapid algorithm. In this Short Communication we describe how a simplified representation of the proposed complex error function approximation makes possible further algorithmic optimization resulting in a considerable <b>computational</b> <b>acceleration</b> without compromise on accuracy. Comment: 4 page...|$|R
30|$|Iris {{recognition}} {{stands out}} {{as one of the}} most accurate biometric methods in use today. One of the first iris recognition algorithms was introduced by pioneer Dr. John Daugmann [4]. An alternate iris recognition algorithm, referred to as the Ridge Energy Direction (RED) algorithm [5], will be the basis for this work. There are many iris detection algorithms. What follows is a brief description of the RED algorithm. Since this research is focused on <b>computational</b> <b>acceleration,</b> we refer the reader to [6 â€“ 12].|$|R
40|$|The {{advent of}} new matrix-valued {{magnetic}} resonance imaging modalities such as Diffusion Tensor Imaging (DTI) requires extensive <b>computational</b> <b>acceleration.</b> <b>Computational</b> <b>acceleration</b> on graphics processing units (GPUs) can make the regularization (denoising) of DTI images attractive in clinical settings, hence {{improving the quality of}} DTI images in a broad range of applications. Construction of DTI images consists of direction-specific Magnetic Resonance (MR) measurements. Compared with conventional MR, direction-sensitive acquisition has a lower signal-to-noise ratio (SNR). Therefore, high noise levels often limit DTI imaging. Advanced post-processing of imaging data can improve the quality of estimated tensors. However, the post-processing problem is only made more computationally difficult when considering matrix-valued imaging data. This paper describes the acceleration of a Total Variation regularization method for matrix-valued images, in particular, for DTI images on NVIDIA Quadro FX 5600. The TV regularization of a 3 -D image with 128 3 voxels ultimately achieves 266 X speedup and requires 1 minute and 30 seconds on the Quadro, while this algorithm on a dual-core CPU completes in more than 3 hours. In this application study we are aimed at analyzing the effective of excessive synchronization, which provides an insight into generally adapting Variational methods to the GPU architecture for other image processing algorithms designed for matrix-valued images...|$|R
40|$|It {{has been}} {{constantly}} {{pointed out by}} various academics that the option pricing methodology based on probabilistic assumptions is no longer considered to be adequate, valid and reliable. This paper proposes a <b>fuzzy</b> <b>computational</b> method for pricing financial options. We demonstrate how fuzzy algebra can be successfully applied to the discrete Cox-Ross-Rubinstein (1979) binomial risk neutral option pricing model. Our fuzzy option pricing model provides a much more natural and intuitive {{way to deal with}} fuzziness and uncertainty. The validity of this fuzzy approach to option pricing methodology has been highlighted with an illustrative numerical example...|$|R
5000|$|... hakia - hakia is an Internet search engine. The {{company has}} invented an {{alternative}} new infrastructure to indexing that uses SemanticRank algorithm, a solution mix from the disciplines of ontological semantics, <b>fuzzy</b> logic, <b>computational</b> linguistics, and mathematics.|$|R
40|$|Power system dynamic {{simulations}} {{are crucial}} for the operation of electric power systems as they provide important information on the dynamic evolution of the system after an occurring disturbance. This paper proposes a robust, accurate and efficient parallel algorithm based on the Schur complement domain decomposition method. The algorithm provides numerical and <b>computational</b> <b>acceleration</b> of the procedure. Based on the shared-memory parallel programming model, a parallel implementation of the proposed algorithm is presented. The implementation is general, portable and scalable on inexpensive, shared-memory, multi-core machines. Two realistic test systems, a medium-scale and a large-scale, are used for performance evaluation of the proposed method. Peer reviewe...|$|R
40|$|In {{this paper}} we {{describe}} how timescale separation in micro/nano flows can be exploited for <b>computational</b> <b>acceleration.</b> A {{modified version of}} the seamless heterogenous multiscale method (SHMM) is proposed: a multi-step SHMM. This maintains the main advantages of SHMM (e. g., re-initialisation of micro data is not required; temporal gearing (computational speed-up) is easily controlled; and it is applicable to full and intermediate degrees of timescale separation) while improving on accuracy and greatly reducing the number of macroscopic computations and micro/macro coupling instances required. The improved accuracy of the multi-step SHMM is demonstrated for two canonical one-dimensional transient flows (oscillatory Poiseuille and oscillatory Couette flow) and for rarefied-gas oscillatory Poiseuille flow...|$|R
40|$|Fuller et. al (Asiacrypt 2013) studied on <b>computational</b> <b>fuzzy</b> extractors, and showed, as a {{negative}} result, {{that the existence of}} a computational "secure sketch" implies the existence of an information-theoretically secure sketch with slightly weaker parameters. In this work, we show a similar negative result such that, under some computational assumption, the existence of a <b>computational</b> <b>fuzzy</b> extractor also implies the existence of an information-theoretic fuzzy extractor with slightly weaker parameters. The assumption is that the generation procedure of the fuzzy extractor can be efficiently invertible. This result implies that to circumvent the limitations of information-theoretic fuzzy extractors, we need to employ <b>computational</b> <b>fuzzy</b> extractors in which the generation procedure cannot be efficiently invertible...|$|R
50|$|The company invented QDEXing technology, an {{alternative}} infrastructure to indexing that uses SemanticRank algorithm, a solution mix from the disciplines of ontological semantics, <b>fuzzy</b> logic, <b>computational</b> linguistics, and mathematics. Founded in 2004, {{the company is}} privately held and based in New York City.|$|R
40|$|As {{the need}} for faster power system dynamic {{simulations}} increases, {{it is essential to}} develop new algorithms that exploit parallel computing to accelerate those simulations. This paper proposes a parallel algorithm based on a two-level, Schur complement-based, domain decomposition method. The two-level partitioning provides high parallelization potential (coarse and fine-grained). In addition, due to the Schur-complement approach used to update the sub-domain interface variables, the algorithm exhibits high global convergence rate. Finally, it provides significant numerical and <b>computational</b> <b>acceleration.</b> The algorithm is implemented using the shared-memory parallel programming model, targeting inexpensive multi-core machines. Its performance is reported on a real system as well as on a large test system combining transmission and distribution networks. Peer reviewe...|$|R
40|$|Abstract In {{this paper}} we {{describe}} how timescale separation in micro/nano flows can be exploited for <b>computational</b> <b>acceleration.</b> A {{modified version of}} the seamless heterogenous multiscale method (SHMM) is proposed: a multi-step SHMM. This maintains the main advantages of SHMM (e. g., re-initialisation of micro data is not required; temporal gearing (computational speed-up) is easily controlled; and it is applicable to full and intermediate degrees of timescale separation) while improving on accuracy and greatly reducing the number of macroscopic computations and micro/macro coupling instances required. The improved accuracy of the multi-step SHMM is demonstrated for two canonical one-dimensional transient flows (oscillatory Poiseuille and oscillatory Couette flow) and for rarefied-gas oscillatory Poiseuille flow...|$|R
40|$|An {{intelligent}} {{physical agent}} must incorporate motor and perceptual processes {{to interface with}} the physical world, and abstract cognitive processes to reason about {{the world and the}} options available. One crucial aspect of incorporating cognitive processes into a physically embedded reasoning system is the integration between the symbols used by the reasoning processes to denote physical objects, and the perceptual data corresponding to these objects. We treat this integration aspect by proposing a <b>fuzzy</b> <b>computational</b> theory of anchoring. Anchoring is the process of creating and maintaining the correspondence between symbols and percepts that refer to the same physical objects. Modeling this process using fuzzy set-theoretic notions enables dealing with perceptual data that can be affected by uncertainty/imprecision and imprecise/vague linguistic descriptions of objects...|$|R
40|$|Since many complex {{decision}} making {{problems can be}} solved solely {{by means of an}} ap-propriate algorithm, checking the quality of such algorithm is a key issue, even more relevant in the presence of fuzzy uncertainty. In this paper we postulate that the de-sign and formal specication of algorithms can be translated into a fuzzy framework introducing fuzzy rst order logic and assert transformations. Following the classical crisp scheme we rst formalize the concepts of a fuzzy algorithm specication and a fuzzy computing state, and then a new <b>fuzzy</b> <b>computational</b> logic is presented, so we can derive a computational reasoning for correctness of algorithms. A proposal for the evaluation and setting of suitable degrees of truth to computing states is also introduced...|$|R
30|$|As {{mentioned}} in the previous section, in case of nonlinear ROM simulation, hyperreduction needs to be performed {{in order to obtain}} <b>computational</b> <b>acceleration.</b> First, if using a global hyperreduction Ansatz (i.e., single global sample mesh for GNAT, or single collateral basis set and interpolation points for DEIM), no changes in Algorithm 1 or 2 are required. as they only address the (Galerkin) projection stage, but not the nonlinearity approximation. However, the use of local hyperreduction (i.e., local interpolation bases, submeshes, etc.) would require essential extensions of the offline and online phases. We refrain from detailed presentation of these extensions, as we do not make use of that in the experiments, but the extensions can be obtained by following the ideas of [9].|$|R
40|$|There {{have been}} many {{research}} developments on the conceptual description of topological relations between spatial objects. In order to practically implement these conceptual topological relations in a computer environment, we need to calculate {{the values of the}} topological relations. One of the theoretical bases for doing this is a <b>computational</b> <b>fuzzy</b> topology, which is the research focus of this study. Here, we present a development of <b>computational</b> <b>fuzzy</b> topology, which is based on the interior operator and closure operator. These operators are further defined as a coherent fuzzy topology-the complement of the open set is the closed set and vice versa; where the open set and closed set are defined by interior and closure operators-two level cuts. The elementary components of fuzzy topology for spatial objects-interior, boundary and exterior-are thus computed based on the <b>computational</b> <b>fuzzy</b> topology. An example of calculating the interior, boundary, and exterior of Mikania micrantha based on the aerial photographs of the Hong Kong countryside is provided in order to demonstrate the application of the theoretical development. Practically, the developed <b>computational</b> <b>fuzzy</b> topology is applicable for computing the values of fuzzy topological relations, such as defined conceptually by the 9 -intersection model. Department of Land Surveying and Geo-Informatic...|$|R
40|$|In the new spread {{model for}} forest fire, bitmaps are {{operated}} and outlines of images are searched at {{the basis of}} the metagraphic set of fire-area shapes and the gray level image for spread calculation. Complex topological relations among geographical elements are solved with the scan-line flood-fill algorithms. The projection transition of the fire-area shape is replaced by a combined graphical transformation of rotation and shear. And the solar radiations are calculated by means of the gray level image of terrains. Thus the limitation on computational performances of the original wave propagation spread model is overcome. The essence of <b>computational</b> <b>acceleration</b> making use of computer graphic techniques is analyzed primarily. A calculation case is presented in order to show that the new spread model can provide forest fire management with precise, reliable, overall, maintainable and adaptable diagram of fire development in real time...|$|R
40|$|We present parallelization {{of single}} and {{two phase flow}} CFD solvers on a {{graphics}} processing unit (GPU) platform. Numerical simulations are done for some standard benchmark test cases for both single and two phase flow solvers. The formulation is based on finite volume method with SMAC algorithm on regular cartesian and collocated grid. Volume of fluid method in used for tracking the interface in multiphase flow solver. Pressure poisson equation is the most time consuming part of the solvers and hence this part is imported on to GPU. Pressure Poisson equation is solved by the conventional Gauss siedel method. Present day modern graphics hardware has several hundred cores which can be effectively used by CFD solvers to parallelize the computation. The results are validated against the reference solutions of the teat cases. A comparison is done between CPU and GPU simulations to estimate the <b>computational</b> <b>acceleration</b> and accuracy obtaine...|$|R
40|$|We {{present a}} Hessenberg {{reduction}} (HR) algorithm for hybrid multicore + GPU systems that gets more than 16 Ã— performance {{improvement over the}} current LAPACK algorithm running just on current multicores (in double precision arithmetic). This enormous acceleration is due to proper matching of algorithmic requirements to architectural strengths of the hybrid components. The reduction itself is an important linear algebra problem, especially with its relevance to eigenvalue problems. The results described in this paper are significant because Hessenberg reduction {{has not yet been}} accelerated on multicore architectures, and it plays a significant role in solving nonsymmetric eigenvalue problems. The approach {{can be applied to the}} symmetric problem and in general, to two-sided matrix transformations. The work further motivates and highlights the strengths of hybrid computing: to harness the strengths of the components of a hybrid architecture to get significant <b>computational</b> <b>acceleration</b> which otherwise may have been impossible...|$|R
40|$|We {{propose a}} new {{computational}} framework that combines the recently developed time-parallel (TP) and the compound wavelet matrix (CWM) methods. The framework, termed tpCWM, offers significant <b>computational</b> <b>acceleration</b> by making multiscale/multiphysics simulations computationally scalable {{in time and}} space domains. We demonstrate the accuracy and the scalability of the method on a prototype problem with oscillatory trajectory. The method corrects the coarse solution by iterative use of the CWM, which compounds the fine and the coarse solutions for the processes. Computational savings, over the fine solution as well as the TP method, in terms of the real time required to perform the simulations, can reach several orders of magnitude. We believe that this method is general enough to be applicable to a wide-class of computational physics problems. Tendency towards large number of cores and processors in parallel computers is compatible with the computational scalability of the algorithm. Comment: 10 pages, 4 figure...|$|R
40|$|Chemical {{algorithms}} are statistical control algorithms {{described and}} represented as chemical reaction networks. They are analytically tractable, they reinforce a deterministic state-to-dynamics relation, they have configurable stability properties, {{and they are}} directly implemented in state space using a high-level visual representation. These properties make them attractive solutions for traffic shaping and generally the control of dynamics in computer networks. In this paper, we present a framework for deploying chemical algorithms on field programmable gate arrays. Besides substantial <b>computational</b> <b>acceleration,</b> we introduce a low-overhead approach for hardware-level programmability and re-configurability of these algorithms at runtime, and without service interruption. We {{believe that this is}} a promising approach for expanding the control-plane programmability of software defined networks (SDN), to enable programmable network dynamics. To this end, the simple high-level abstractions of chemical algorithms offer an ideal northbound interface to the hardware, aligned with other programming primitives of SDN (e. g., flow rules) ...|$|R
40|$|GENIUSA <b>fuzzy</b> <b>computational</b> {{approach}} {{that takes into}} account several molecular subtypes in order to provide more accu ate bre st cancer p ognosis Early gene expression studies classified breast tumors into at least three clinically relevant subtypes. Although most current gene signatures are prognostic for estrogen receptor (ER) positive/human epidermal growth factor receptor 2 (HER 2) negative breast cancers, few are informative for ER negative/HER 2 negative and HER 2 positive subtypes. Here we present Gene Expression Prognostic Index Using Subtypes (GENIUS), a fuzzy approach for prognostication {{that takes into account}} the molecular heterogeneity of breast cancer. In systematic evaluations, GENIUS significantly outperformed current gene signatures and clinical indices in the global population of patients. Background Early gene expression studies [1 - 6] classify breast cancer into at least three clinically relevant molecular subtypes: basal-like (predominantly estrogen receptor (ER) negative and human epidermal growth factor receptor 2 (HER 2) neg-ative), HER 2 -positive, and luminal-like (ER-positive) tumors. Although this classification has changed the wa...|$|R
40|$|II The goal of {{this project}} is to design an {{application}} acceleration architecture that can be integrated into a multimedia communication baseband SoC, and a OS kernel scheduler for dynamic partitioning of tasks for heterogeneous multi-core systems. Conventional baseband processor only provides <b>computational</b> <b>acceleration</b> for speech codecs and network protocol stacks at layer- 2 and below. However, {{in order to support}} new multimedia communication applications efficiently, new chip venders such as TI, Freescale, and Qualcomm have all announced baseband chipset with multimedia acceleration capabilities. For the past three years, our project team has completed the following major tasks. First of all, we have designed a multi-format video codec acceleration SoC platform. The platform is different from the conventional codec SoC that is hard-wired for a particular codec. Instead, we have followed the latest Reconfigurable Video Codec Framework Standard that is being developed within MPEG. Secondly, we have designed a dynamic task partitioning OS kernel scheduler for heterogeneous multi-processor (HMP) platforms. The design is completely implemented in...|$|R
40|$|The future {{upgrades}} to the LHC {{are expected}} to increase the design luminosity by {{an order of magnitude}} leading to new computational challenges for the ATLAS experiment. One such challenge will be the ability to handle a much higher rate of interesting physics events by the ATLAS High Level Trigger system. We will present results from the adoption of General Purpose Graphics Processing Units (GPGPUs) to provide <b>computational</b> <b>acceleration</b> for key algorithms in the ATLAS Inner Detector Trigger. The z-finder algorithm - used to determine the accurate z position of primary interactions - and the Kalman Filter based track reconstruction routine have been adapted for GPGPU execution using the CUDA parallel computing architecture. We describe the programming and benchmarking methods used and demonstrate the relative throughput performance for different trigger scenarios. Where significant performance boost is found we will outline how GPGPU acceleration could be exploited and incorporated into the future ATLAS computing framework...|$|R
40|$|Now {{a day in}} GIS {{application}} fuzzy spatial objects {{have become}} extremely important. There have been many research developments on the conceptual description of topological relation between spatial objects. In this paper a formal definition of the <b>computational</b> <b>fuzzy</b> topology is shown {{which is based on}} the interior operator and closure operators. In spatial object modeling the interior and exterior boundary are computed based on <b>computational</b> <b>fuzzy</b> topology. An example for determining interior boundary and exterior boundary of flood affected areas of upper Assam based on data collected from Govt. of Assam GOI Directory Assam Tourism NIC ASHA Districts of India...|$|R
40|$|We {{propose a}} {{differential}} evolution (DE) algorithm for {{the calculation of}} the interval and fuzzy variance. In particular, {{we see that the}} DE methods can be efficient for the fuzzy variance of a relatively high number of <b>fuzzy</b> data; <b>computational</b> results with up to 100 data show that the number of function evaluations to obtain the estimated global solutions grows less then quadratically with the number of data...|$|R
40|$|Several methodologies {{based on}} ISO/IEC 27000 {{international}} standard {{have been developed}} to deal with risk analysis in information systems (IS). These methodologies do not, however, consider imprecise valuations, but use precise values on different, usually percentage, scales. We propose an extension of the MAGERIT methodology based on classical <b>fuzzy</b> <b>computational</b> models. A linguistic term scale is used to represent asset values, their dependencies and frequency and asset degradation associated with threats. Computations are based on trapezoidal fuzzy numbers associated with linguistic terms. A similarity function is used to associate a linguistic term on the previously defined scale to the trapezoidal fuzzy numbers resulting from computations. Finally, regarding the selection of preventive safeguards to reduce risks in IS, we propose a dynamic programming-based method that incorporates simulated annealing to tackle optimizations problems with the aim of minimizing costs while keeping the risk at acceptable levels. An example of an administrative unit using in-house and third-party information systems internally and to provide public information services is used to illustrate the methodology...|$|R
40|$|Because of the non-local {{nature of}} the {{integral}} kernels at play, the discretization of boundary integral equations leads to dense matrices, which would imply high <b>computational</b> complexity. <b>Acceleration</b> techniques, such as hierarchical matrix strategies combined with Adaptive Cross Approximation (ACA), are available in literature. Here we apply such a technique to the solution of an elastostatic problem, arising from industrial applications, posed at the surface of highly irregular cracks networks...|$|R
40|$|Abstract. In {{this paper}} we discuss {{parametrized}} partial differential equations (P 2 DEs) for parameters that describe the geometry of the underlying problem. One can think of applications in control theory and optimization which depend on time-consuming parameter-studies of such problems. Therefore, we want to reduce the order of complexity of the numerical simulations for such P 2 DEs. Reduced Basis (RB) methods are a means to achieve this goal. These methods have gained popularity {{over the last few}} years for model reduction of finite element approximations of elliptic and instationary parabolic equations. We present a RB method for parabolic problems with general geometry parameterization and finite volume (FV) approximations. After a mapping on a reference domain, the parabolic equation leads to a convection-diffusion-reaction equation with anisotropic diffusion tensor. Suitable FV schemes with gradient reconstruction allow to discretize such problems. A model reduction of the resulting numerical scheme can be obtained by an RB technique. We present experimental results, that demonstrate the applicability of the RB method, in particular the <b>computational</b> <b>acceleration.</b> Key words. Reduced basis methods, model reduction, geometry transformation, heat equation AMS subject classifications. 76 M 12, 76 R 50, 35 K 0...|$|R
40|$|Fast and {{efficient}} calculations of optical responses using electromagnetic models require <b>computational</b> <b>acceleration</b> and compression techniques. A hierarchical matrix approach is adopted for this purpose. In order to model large-scale molecular structures these methods {{should be applied}} over wide frequency spectra. Here we introduce a novel parametric hierarchical matrix method that allows one for a rapid construction of a wideband system representation and enables an efficient wideband solution. We apply the developed method to the modeling of the optical response of bacteriochorophyll tubular aggregates as found in green photosynthetic bacteria. We show that the parametric method can provide one with the frequency and time-domain solutions for structures {{of the size of}} 100, 000 molecules, which is comparable {{to the size of the}} whole antenna complex in a bacterium. The absorption spectrum is calculated and the significance of electrodynamic retardation effects for relatively large structures, i. e. with respect to the wavelength of light, is briefly studied. Comment: The following article has been submitted AIP Journal of applied physics and is currently under revision. After final acceptance and publication proper copyright information and web-link to the journal article will be provide...|$|R
40|$|This {{paper was}} {{presented}} at the 3 rd Micro and Nano Flows Conference (MNF 2011), which was held at the Makedonia Palace Hotel, Thessaloniki in Greece. The conference was organised by Brunel University and supported by the Italian Union of Thermofluiddynamics, Aristotle University of Thessaloniki, University of Thessaly, IPEM, the Process Intensification Network, the Institution of Mechanical Engineers, the Heat Transfer Society, HEXAG - the Heat Exchange Action Group, and the Energy Institute. In this paper we describe how timescale separation in micro/nano flows can be exploited for <b>computational</b> <b>acceleration.</b> A modified version of the seamless heterogenous multiscale method (SHMM) is proposed: a multi-step SHMM. This maintains the main advantages of SHMM (e. g., re-initialisation of micro data is not required; temporal gearing (computational speed-up) is easily controlled; and it is applicable to full and intermediate degrees of timescale separation) while improving on accuracy and greatly reducing the number of macroscopic computations and micro/macro coupling instances required. The improved accuracy of the multi-step SHMM is demonstrated for two canonical one-dimensional transient flows (oscillatory Poiseuille and oscillatory Couette flow) and for rarefied-gas oscillatory Poiseuille flow. This research is financially supported by the EPSRC Programme Grant EP/I 011927 / 1...|$|R
40|$|In {{this paper}} {{we present a}} novel {{artificial}} auditory system for humanoid robots. We {{address the problem of}} estimating an articulatory representation of the speech of the talker who is speaking to the robot using our auditory system. According to the motor theory of perception, the articulatory representation is the first step of a robust speech understanding process. The system is composed by two parts, namely a beam-forming module and a perception module. The beam-former is two-channel (i. e. dual-microphones) and {{it is based on the}} super-directive beam-forming algorithm. The environment is scanned for seeking a sound source; when the direction of the source is found, the reception lobe of the dual-microphone system is steered to that direction and the signal is acquired. The perception module is based on a <b>fuzzy</b> <b>computational</b> model of human vocalization. In summary, the relationships between places of articulation and speech acoustic parame-ters are represented with fuzzy rules. Starting from the ar-ticulatory features, a set of acoustic parameters are generated according to the fuzzy rules. These acoustic parameters are used to generate a synthetic utterance which is compared in the perceptual domain to the corresponding spoken utterance. The goal of that is to estimate the membership degrees of the articulatory features using analysis-by-synthesis and genetic optimization...|$|R
40|$|Abstract: Traditionally {{fuzzy logic}} has been {{grounded}} in crisp logic. This paper challenges this idea, instead relating <b>fuzzy</b> logic to <b>computational</b> geometry. A geometric {{representation of a}} fuzzy set is given along with the AND and OR operations for such sets. Comparisons between the two methods are made...|$|R
40|$|Abstractâ€”PID {{controllers}} {{were widely}} used in real-life appli-cations due to their advantages over other kinds of controllers. At the same time, fuzzy controllers have been developed as an important branch of intelligent controllers recently. They also gain good performances in general. However, they can not meet the demands as the system {{becomes more and more}} complex. In this paper, computational verb theory is used to improve fuzzy PID controllers. As examples, the control performances of both <b>fuzzy</b> and <b>computational</b> verb PID controllers for controlling fuel annealers are studied. Keywords-computational verb; fuzzy control; PID control I...|$|R
40|$|Motivation: Primer design {{involves}} various parameters such as string-based alignment scores, melting temperature, primer {{length and}} GC content. This entails a design approach from multicriteria decision making. Values {{of some of}} the criteria are easy to compute while others require intense calculations. Results: The reference point method was found to be tractable for trading-off between deviations from ideal values of all the criteria. Some criteria computations are based on dynamic programs with value iteration whose run time can be bounded by a low-degree polynomial. For designing standard PCR primers, the scheme offers in a relative gain in computing speed of up to 50 : 1 over ad-hoc computational methods. Single PCR primer pairs have been used as model systems in order to simplify the quantization of the <b>computational</b> <b>acceleration</b> factors. The program has been structured so as to facilitate the analysis of large numbers of primer pairs with minor modifications. The scheme significantly increases primer design throughput which in turn facilitates the use of oligonucleotides {{in a wide range of}} applications including: multiplex PCR and other nucleic acid-based amplification systems, as well as in zip code targeting, oligonucleotide microarrays and nucleic acid-based nanoengineering. Availability: A public version of the software DOPRIMER is accessible unde...|$|R
40|$|Purpose: A CT scanner {{measures}} {{the energy that}} is deposited in each channel of a detector array by x rays that have been partially absorbed on {{their way through the}} object. The measurement process is complex and quantitative measurements are always and inevitably associated with errors, so CT data must be preprocessed prior to reconstruction. In recent years, the authors have formulated CT sinogram preprocessing as a statistical restoration problem in which the goal is to obtain the best estimate of the line integrals needed for reconstruction from the set of noisy, degraded measurements. The authors have explored both penalized Poisson likelihood (PL) and penalized weighted least-squares (PWLS) objective functions. At low doses, the authors found that the PL approach outperforms PWLS in terms of resolution-noise tradeoffs, but at standard doses they perform similarly. The PWLS objective function, being quadratic, is more amenable to <b>computational</b> <b>acceleration</b> than the PL objective. In this work, the authors develop and compare two different methods for implementing PWLS sinogram restoration with the hope of improving computational performance relative to PL in the standard-dose regime. Sinogram restoration is still significant in the standard-dose regime since it can still outperform standard approaches and it allows for correction of effects that are not usually modeled in standard CT preprocessing...|$|R
