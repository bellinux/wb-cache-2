2|23|Public
5000|$|At {{the design}} {{stage of the}} IPv6 DNS architecture, the AAAA scheme faced a rival proposal. This {{alternate}} approach, designed to facilitate network renumbering, uses A6 records for the <b>forward</b> <b>lookup</b> {{and a number of}} other innovations such as bit-string labels and DNAME records. It is defined in [...] and its references (with further discussion of the pros and cons of both schemes in [...] ), but has been deprecated to experimental status (...) [...]|$|E
40|$|Spike-timing-dependent {{plasticity}} (STDP) incurs both causal and acausal {{synaptic weight}} updates, for {{negative and positive}} time differences between pre-synaptic and post-synaptic spike events. For realizing such updates in neuromorphic hardware, current implementations either require forward and reverse lookup access to the synaptic connectivity table, or rely on memory-intensive architectures such as crossbar arrays. We present a novel method for realizing both causal and acausal weight updates using only <b>forward</b> <b>lookup</b> access of the synaptic connectivity table, permitting memory-efficient implementation. A simplified implementation in FPGA, using a single timer variable for each neuron, closely approximates exact STDP cumulative weight updates for neuron refractory periods greater than 10 ms, and reduces to exact STDP for refractory periods greater than the STDP time window. Compared to conventional crossbar implementation, the forward table-based implementation leads to substantial memory savings for sparsely connected networks supporting scalable neuromorphic systems with fully reconfigurable synaptic connectivity and plasticity. Comment: Submitted to BioCAS 201...|$|E
5000|$|When it {{receives}} a Lookup message {{for any other}} identifier, it <b>forwards</b> the <b>Lookup</b> message to E ...|$|R
40|$|Typically, {{multicast}} {{data distribution}} uses rendezvous points (PIM, CBT), multicast distribution tree building protocols, and multicast forwarding. While {{the first two}} approaches have been extensively studied, scaling multicast forwarding state while simplifying <b>forwarding</b> <b>lookups</b> have not been addressed in detail. Having a scalable strategy for aggregation of multicast forwarding state is essential for inter-domain multicast which could have any number of concurrent multicast groups especially in application such as event notification and web cache invalidation mechanisms...|$|R
5000|$|The first RBridge that a unicast frame {{encounters}} in a campus, RB1, encapsulates the received frame with a TRILL header that specifies the last RBridge, RB2, where {{the frame is}} decapsulated. RB1 {{is known as the}} [...] "ingress RBridge" [...] and RB2 is known as the [...] "egress RBridge". To save room in the TRILL header and simplify <b>forwarding</b> <b>lookups,</b> a dynamic nickname acquisition protocol is run among the RBridges to select two-octet nicknames for RBridges, unique within the campus, which are an abbreviation for the six-octet IS-IS system ID of the RBridge. The two-octet nicknames are used to specify the ingress and egress RBridges in the TRILL header.|$|R
40|$|Event {{forwarding}} in a content-based publish-subscribe {{system is}} an expensive task due {{to the need to}} match an event’s content against registered subscriptions at every router. We introduce lookup reuse, a novel approach to improve the efficiency of event <b>forwarding.</b> <b>Lookup</b> reuse enables faster event forwarding through reusing matching results computed by upstream routers in making forwarding decisions at downstream routers. In many cases, this lets downstream routers replace an expensive content-match with a much cheaper hash-table lookup. We investigate the integration of lookup reuse into existing content-based event forwarding algorithms. Our simulations show that lookup reuse reduces the event processing overhead on average by 40 to 55 percent, when used with existing content-based event forwarding algorithms. 1...|$|R
40|$|This paper {{presents}} an architectural model called the Multi-Domain Communication Model (MDCM) {{to describe the}} relationship between protocol layers, network hops and regions of multi-hop, multi-layer communication systems. MDCM treats communication processes {{as a series of}} recursive domain conversions and propagation within each domain. The concept of domain is a generalization of protocol layers and transit hops. MDCM includes end point resolution to map source and destination from one domain to the other, such as name/address resolutions, <b>forwarding</b> <b>lookups,</b> and content searching. MDCM integrates these aspects of communication processes and abstracts the core functionality into a simple, recursive model. It can describe a wide range of communication systems, and provide a new way of thinking regarding communication processes and system architecture designs...|$|R
40|$|Abstract A {{protocol}} for a distributed hash table (DHT) incurs communi-cation costs {{to keep up}} with churn [...] changes in membership [...] in order to maintain its ability to route lookups efficiently. This pa-per formulates a unified framework for evaluating cost and performance. Communication costs are combined into a single costmeasure (bytes), and performance benefits are reduced to a single latency measure. This approach correctly accounts for backgroundmaintenance traffic and timeouts during lookup due to stale routing data, and also correctly leaves open the possibility of different pref-erences in the tradeoff of lookup time versus communication cost. Using the unified framework, this paper analyzes the effects of DHTparameters on the performance of four protocols under churn. 1 Introduction The design space of DHT protocols is large. While all designsare similar in that nodes <b>forward</b> <b>lookups</b> for keys throug...|$|R
30|$|In {{the case}} of pure intra-cluster <b>forwarding,</b> the <b>lookup</b> {{operation}} never fails in step 4. If the target is unknown, an inter-cluster forwarding is started as explained in the following subsection. Therefore, the major benefit of the proposed intra-cluster forwarding scheme {{is that all the}} exchanges of messages involving nodes within the same cluster are constrained to the cluster.|$|R
40|$|International audienceBloom Filter is {{a widely}} used data {{structure}} in computer science. It enables memory efficient and fast set membership queries. Bloom filter-based solutions have been proposed {{in the past decade}} for <b>lookup</b> in <b>forwarding</b> tables of backbone routers [2]. However, the main shortcomings of using Bloom Filters for lookup lie in the absence of support for deletion operations that are needed to update the forwarding tables. Counting Bloom Filter supporting deletion has therefore to be used, increasing significantly the memory requirement. Moreover, Counting Bloom Filter suffers from both false positive and false negative. In this paper, we propose to solve the issue with deletion of Bloom Filters by using a Withdrawal To annOuncement (WTO) mapping that replaces withdrawal with announcements, transforming deletions into additions or record changes. Experimental evaluation show that the proposed techniques improve largely the performance of Bloom Filter used for <b>forwarding</b> <b>lookup</b> and open way for the use of Bloom Filters in real operational settings...|$|R
50|$|They were {{introduced}} {{at the same}} time in September 2000, because they had similar architectures with two different throughput capabilities (5Mpps and 2.5 Gbit/s on the M5, 10Mpps and 5Gbit/s on the M10). Both routers employs the Internet Processor II ASIC, providing <b>forwarding</b> table <b>lookups</b> at 40Mpps. There are two forwarding engine boards (FEBs) in the M10, allowing for a maximum of eight physical interface cards (PICs) to be used.|$|R
50|$|JavaScript (and its {{standardized}} version: ECMAScript) is a prototype-based object-oriented language. In JavaScript {{an object}} is a mapping from property names to values—that is, an associative array with one caveat: since property names are strings, only string and (coerced) integer keys are allowed. Other than that difference, objects also include one feature unrelated to associative arrays: a prototype {{link to the}} object they inherit from. Doing a lookup for a property will <b>forward</b> the <b>lookup</b> to the prototype if the object does not define the property itself.|$|R
50|$|Using an ISP's {{mail server}} as a relay may solve the reverse DNS problem, because the {{requirement}} is the <b>forward</b> and reverse <b>lookup</b> for the sending relay have to match, {{it does not}} have to be related to the from-field or sending domain of messages it relays.|$|R
40|$|This paper {{presents}} a fast near linear run-time algorithm for deadline-satisfying packet <b>forwarding</b> and route <b>lookup.</b> This algorithm {{has been designed}} after a Constraint Resource Planning (CRP) methodology of approximation algorithm design. The algorithm uses scheduling and forwarding heuristics to produce nearoptimal performance. These heuristics execute within a generic shell. In this paper we present the algorithm, the shell architecture, and the simulation results...|$|R
5000|$|... quasardb also {{provides}} secondary indexes, called tags, which are {{visible to the}} API user as normal data entries.Tags allow the user to perform <b>forward</b> and reverse <b>lookup</b> as well as basic queries involving multiple tags.Such queries can involve negation and intersection over a collection of tags, {{as well as the}} specification of the entry type.A query is a string with a formally defined grammar, for instance: ...|$|R
40|$|Over {{the past}} few years, network {{processors}} have become an important component in packet delivery over the internet with its packet processing rate determining the bottleneck of usage of bandwidth of transmission medium. The architectures of network processors have mainly focused on achieving a particular line rate for IPv 4 packets. As the usage of new format IPv 6 increases, changes in architecture models {{become one of the}} primary concerns. In this paper, we propose to modify an existing network processor architecture to improve performance by reducing the overload of preprocessing a packet header. We also introduce the concept of cache for <b>forwarding</b> address <b>lookup</b> to find the packet destination address to increase efficiency of the lookup system. ...|$|R
40|$|This poster will {{describe}} a new Ethernet <b>forwarding</b> <b>lookup</b> architecture {{that enables the}} simple construction of switches that can contain {{tens of millions of}} forward-ing entries. The core design is based upon recent work on concurrent multi-reader cuckoo hashing [1] to create fast and memory-efficient lookup tables. This work has two primary benefits: First, it suggests that were a need for such scale to arise—whether for flat addressing or for more extreme uses such as content-based networking— such huge-scale tables could be practically constructed. Second, as a pragmatic byproduct, the technique allows storing several hundred thousand forwarding entries en-tirely in fast L 3 CPU cache, facilitating the construction of high-throughput software-based switches. Why Big, Fast Tables? Recent technology advances, such as scalable enterprise networks [3] and data center networks [2, 5], have made much larger layer- 2 networks a reality. Such ever-larger flat networks require Ethernet switches to store an increasing number of entries in the forwarding tables. At the same time, line speeds are in-creasing to 10 G and 40 G. Current Techniques won’t do High-speed memories (e. g. TCAM) are widely used by hardware switches to implement high performance forwarding tables. How-ever, their small size severely limits scalability. For example, the Mellanox SX 1016 64 -Port 10 GbE Switch can only support 48 K layer- 2 forwarding entries. Some approximate solutions are very memory efficient, e. g. BUFFALO [6], but we seek instead a solution that pro-vides exact matching, thus inducing no path stretch. MAC addresses can also be mapped to outging port using a hash table. However, prior hashing schemes suf-fer from either memory inefficiency and/or unacceptable lookup performance to handle collisons, which makes them much less attractive. Solution Overview To address the aforementioned chal-lenges, we use optimistic cuckoo hashing [1] to achieve high memory efficiency (94 % table occupancy [4]) and concurrent access to the hash table with read-intensive workloads. The high performance of our cuckoo hash table come...|$|R
40|$|This paper {{presents}} a fast near linear run-time system for customizable criteria based packet <b>forwarding</b> and route <b>lookup.</b> It presents {{the case for}} deadline line based packet forwarding. This system has been designed after the Constraint Resource Planning (CRP) methodology for algorithm designs. The resulting near-optimum algorithm operates within an extensible CRP shell and uses two pluggable scheduling and forwarding heuristics to produce near-optimal performance. In this paper we present the shell architecture, the algorithm, and the simulation results of this system for dead-line based packet forwarding...|$|R
40|$|Part 2 : Middleboxes and AddressingInternational audienceThe {{migration}} of network functions (NFs) to datacenters, as promoted by Network Function Virtualization (NFV), raises {{the need for}} service chaining (i. e., steering traffic through a sequence of NFs). Service chaining is typically performed by installing forwarding entries in switches within datacenters (DCs). However, {{as the number of}} service chains in DCs grows, switches will be required to maintain a large amount of forwarding state. This will raise a dataplane scalability issue, due to the relatively small flow table size of switches. To mitigate this problem, we present a software-defined network (SDN) based source routing architecture for scalable service chaining, at which the NF-path is encoded into the packet header obviating the need for any <b>forwarding</b> state and <b>lookup</b> in the switches. We assess the feasibility and efficiency of our architecture using a prototype implementation...|$|R
40|$|Well known {{requirements}} for handling multimedia flows in routers are resource reservation and fast packets forwarding. The former {{takes into account}} the quite stable and long lasting bandwidth occupation, whereas the latter {{takes into account the}} large number of packets routed along the same path. Many techniques have been proposed and standardized to face these requirements, but their application is often complex, expensive and sometimes limited by the need of agreements between network managers of the many networks and Autonomous Systems. This paper introduces IMFM (Integrated Multimedia Flows Management), an innovative, scalable, and extremely lightweight technique to provide routers deterministic and dynamic resource reservation and a fast <b>forwarding</b> table <b>lookup.</b> It is based on a distributed linked data structure that allows direct (searchless) access to entries in the routers’ tables, extending the resource reservation algorithm REBOOK. Unlike conventional virtual circuits, IMFM does not require any interaction with (nor change in) the underlying routing protocols and autonomously recovers from errors, faults and route changes. If information stored in its data structure becomes obsolete, packet handling is reverted to best-effort, lookup-driven forwarding, so that packets are never dropped nor misrouted. IMFM can be gradually deployed, providing a framework for congestion avoidance solutions and increasing the forwarding speed in IMFM-aware router even along partially IMFMunaware paths. IMFM has been fully implemented. Experiments have been designed to demonstrate its feasibility and the measured performance is reported and compared with existing technique...|$|R
40|$|Abstract—We {{suggest a}} new simple {{forwarding}} technique {{to speed up}} IP destination address lookup. The technique is {{a natural extension of}} IP, requires 5 bits in the IP header (IPv 4, 7 in IPv 6), and performs IP lookup nearly as fast as IP/Tag switching but with a smaller memory requirement and a much simpler protocol. The basic idea is that each router adds a “clue ” to each packet, telling its downstream router where it ended the IP <b>lookup.</b> Since the <b>forwarding</b> tables of neighboring routers are similar, the clue either directly determines the best prefix match for the downstream router, or provides the downstream router with a good point to start its IP lookup. The new scheme thus prevents repeated computations and distributes the lookup process across the routers along the packet path. Each router starts the lookup computation at the point its upstream neighbor has finished. Fur-thermore, the new scheme is easily assimilated into heterogeneous IP networks, does not require routers coordination, and requires no setup time. Even a flow of one packet enjoys the benefits of the scheme without any additional overhead. The speedup we achieve is about 10 times faster than current standard techniques. In a sense, this paper shows that the current routers employed in the Internet are clue-less; namely, it is possible to speed up the IP lookup by an order of magnitude without any major changes to the existing protocols. Index Terms—Best matching prefix, IP <b>forwarding,</b> IP <b>lookup,</b> IP routing, MPLS. I...|$|R
40|$|For some time, the Internet {{community}} has {{believed that it}} is impossible to do IP routing lookups in software fast enough to support gigabit speeds. IP routing lookups must find the routing entry with the longest matching prefix, a task that has been thought to require hardware support at lookup frequencies of millions per second. We present a forwarding table data structure designed for quick routing <b>lookups.</b> <b>Forwarding</b> tables are small enough to fit in the cache of a conventional general purpose processor. With the table in cache, a 200 MHz Pentium Pro or a 333 MHz Alpha 21164 can perform a few million lookups per second. This means that it is feasible to do a full routing lookup for each IP packet at gigabit speeds without special hardware. The forwarding tables are very small, a large routing table with 40, 000 routing entries can be compacted to a forwarding table of 150 [...] 160 Kbytes. A lookup typically requires less than 100 instructions on an Alpha, using eight memory references accessing a total of 14 bytes. Godkänd; 1997; 20080326 (ysko...|$|R
40|$|IP Routers use {{sophisticated}} <b>forwarding</b> table (FIB) <b>lookup</b> algorithms that minimize lookup time, storage, {{and update}} time. This paper presents SMALTA, a practical, near-optimal FIB aggregation scheme that shrinks forwarding table size without modifying routing semantics or the external behavior of routers, and without requiring changes to FIB lookup algorithms and associated hardware and software. On typical IP routers using the FIB lookup algorithm Tree Bitmap, SMALTA shrinks FIB storage {{by at least}} 50 %, representing roughly four years of routing table growth at current rates. SMALTA also reduces average lookup time by 25 % for a uniform traffic matrix. Besides the benefits this brings to future routers, SMALTA provides a critical easy-to-deploy one-time benefit to the installed base should IPv 4 address depletion result in increased routing table growth rate. The effective cost of this improvement is a sub-second delay in inserting updates into the FIB once every few hours. We describe SMALTA, prove its correctness, measure its performance using data from a Tier- 1 provider as well as Route-Views. We also describe an implementation in Quagga that demonstrates its ease of implementation. 1...|$|R
40|$|Optimizing SQL {{subqueries}} {{has been}} an active area in database research and the database industry throughout the last decades. Pre-vious work has already identified some approaches to efficiently execute relational subqueries. For satisfactory performance, proper choice of subquery execution strategies becomes even more essen-tial today {{with the increase in}} decision support systems and auto-matically generated SQL, e. g., with ad-hoc reporting tools. This {{goes hand in hand with}} increasing query complexity and growing data volumes – which all pose challenges for an industrial-strength query optimizer. This current paper explores the basic building blocks that Microsoft SQL Server utilizes to optimize and execute relational subqueries. We start with indispensable prerequisites such as detection and removal of correlations for subqueries. We identify a full spectrum of fundamental subquery execution strategies such as <b>forward</b> and reverse <b>lookup</b> as well as set-based approaches, explain the different execution strategies for subqueries implemented in SQL Server, and relate them to the current state of the art. To the best of our knowl-edge, several strategies discussed in this paper have not been pub-lished before. An experimental evaluation complements the paper. It quantifies the performance characteristics of the different approaches and shows that indeed alternative execution strategies are needed in different circumstances, which make a cost-based query optimizer indispen-sable for adequate query performance...|$|R

