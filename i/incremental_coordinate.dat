1|11|Public
40|$|In a {{companion}} paper the authors presented a convenient formulation for the stability analysis of structures using the finite element method. The main assumptions are linear elasticity, a linear fundamental path {{and the existence}} of distinct critical loads. The formulation developed is known as the W-formulation, where the energy is written in terms of a sliding set of <b>incremental</b> <b>coordinate...</b>|$|E
40|$|Abstract-In a {{companion}} paper the authors presented a convenient fonnulation for the stability analysis of structures using the finite element method. The main assumptions are linear elasticity, a linear fundamental path {{and the existence}} of distinct critical loads. The fonnulation developed is known as the W-formulation, where the energy is written in terms ofa sliding set of <b>incremental</b> <b>coordinates</b> measured with respect to the fundamental path. In the present paper a number of aPrlications of finit ~ elements for post-buckling analysis on composite plate assemblies are presented. ThIn-walled composIte plates, I-beams, angle sections, and a specially designed box-beam with flanges (unicolumn) are studied in post-buckling when axially loaded. The results are in good agreement with previous studies. Moreover, a parametric study involving critical buckling load and geometry is presented for the case of the unicolumn. 1...|$|R
5000|$|A {{convenient}} {{means of}} expressing the metric tensor {{in combination with}} the <b>incremental</b> intervals of <b>coordinate</b> distance that it relates to is through the line element: ...|$|R
40|$|Abstract-This paper {{presents}} a convenient fonnulation for the stability analysis of structures using the finite element method. The main assumptions are linear elasticity, a linear fundamental path, {{and the existence}} of distinct critical loads (i. e. no coupling between buckling modes occurs). The fonnulation developed is known as W-formulation, in which the energy is written in terms of a sliding set of <b>incremental</b> <b>coordinates</b> measured with respect to the fundamental path. In the presentation developed here, the only ingredients required to carry out the analysis are the strain-displacement and the constitutive matrices at the element level. The present fonnulation is compared with the so called V-formulation, in which the displacements refer to the unloaded state. It is shown that under the present assumptions of linear fundamental path, the advantages of the V-formulation are lost and both approaches are similar. An example of a circular plate under in-plane loading illustrates the procedures. Part II of this paper deals with the application to the post buckling analysis of plate assemblies made of composite materials. 1...|$|R
40|$|Fault-tolerant {{techniques}} that can cope with system failures in software distributed shared memory (SDSM) {{are essential for}} creating productive and highly available parallel computing environments on clusters of workstations. In this paper, we propose a new, efficient coordinated checkpointing technique, called coherence-based coordinated checkpointing (CCC), for SDSM. Our CCC minimizes both the checkpointing overhead during failure-free execution {{and the cost of}} recovery from failures by leveraging existing coherence information maintained by SDSM. In the presence of system failures, it allows SDSM to recover from the most recent checkpoint, saving the re-computation time. We have performed experiments on a cluster of eight Sun Ultra- 5 workstations, comparing our CCC technique against both simple coordinated checkpointing (SCC) and <b>incremental</b> <b>coordinated</b> checkpointing (ICC) techniques by actually implementing these techniques in TreadMarks, a state-of-the-art SDSM system. The experimental results demonstrate that our CCC technique consistently outperforms both SCC and ICC techniques. In particular, our technique increases the execution time slightly by 0. 5 % to 4 % for a 2 -minute checkpointing interval during failurefree execution, while SCC and ICC techniques result in the execution time overhead of 4 % to 100 % and 3 % to 64 %, respectively, for the same checkpointing interval. 1...|$|R
40|$|This paper {{presents}} {{a survey of}} four aspects of nonlinear analysis - basic formulation, plasticity relations, computational procedures, and methods of solution. This survey is {{for the most part}} limited to static geometric and material nonlinear analysis under the assumption of small strains. The two formulations covered are the total Lagrangian and the <b>incremental</b> moving <b>coordinate</b> formulations. A comparison of the two formulations is presented and an attempt is made to clarify the underlying basis of each formulation. The survey of computational procedures reveals that most researchers are now using some form of numerical integration to evaluate nonlinear contributions...|$|R
40|$|Identification of {{the optimum}} {{generation}} schedule by various methods of <b>coordinating</b> <b>incremental</b> generation costs and incremental transmission losses {{has been described}} previously in the literature. This paper presents an analytical approach which reduces the time-consuming iterative procedure into a mere positive-root determination of a third-order polynomial in λ. This approach includes the effect of transmission losses and is suitable for systems with any number of plants. The validity and effectiveness of this method are demonstrated by analysing a sample system...|$|R
40|$|As {{tactical}} {{software development}} moves more toward open standards and becomes {{more focused on}} reducing development time and creating re-usable capabilities, the need for efficient and thorough testing of software becomes more critical than ever before. Testing artifacts {{can no longer be}} used only during initial development and then discarded. <b>Coordinated</b> <b>incremental</b> software builds and highly re-usable software testing capabili-ties will allow developers to coordinate and reuse software tests and testing tools repeatedly. Automated software testing leverages tools to stimulate the software under test, measure its response, and assess the correctness of its response without significant human intervention. Automated Testing (AT) tools and systems will be based on affordable COTS hardware and software tools that allow more flexible and repeatable use. These capabilities are directly enabled, and necessitated by the proliferation of Open Architec-ture software and computing environments and standards. This is in contrast to traditional testing methodologies and systems that require specialized hardware to test new software sys-tems and component interfaces. AT will investigate and enable automated, affordable, rapid, high quality, and reusable testing of large software-based systems throughout the entire lifecycle...|$|R
40|$|Mergers can a¤ect the extent, probability, and payo¤s of coordinated {{interaction}} among …rms in an industry. Current analyses of coordinated e¤ects typically provide little quanti…cation of these e¤ects and instead typically rely on arguments {{based on the}} number of …rms, Her…ndahl Index, ability to detect and punish deviations, ease of entry, and maverick …rms. We o¤er an approach for quantifying the magnitude of the potential post-merger gains from incremental explicit collusion by subsets of …rms in the post-merger industry. If the incremental payo¤s to post-merger collusion are small (large), then coordinated e¤ects are less (more) of a concern. Our approach also allows one to identify which post-merger cartels create the greatest concern and to quantify the e¤ects of post-merger collusion on consumer surplus. The approach can incorporate divestitures and the evaluation of entry, should it occur, as well as quality improvements and cost savings resulting from the merger. We illustrate the implementation and value of this approach with applications to Arch Coal and Hospital Corporation. The views expressed are those of the authors and do not necessarily re‡ect the views of the Federal Trade Commission or its individual Commissioners. y Although this research continued while Marx was on leave from Duke University and serving as Chief Economist at the Federal Communications Commission, the views expressed are those of the authors and do not necessarily re‡ect the views of the Federal Communications Commission, its Mergers tend to create <b>incremental</b> opportunities for <b>coordinated</b> behavior...|$|R
40|$|Master of ScienceDepartment of Computing and Information SciencesGurdip SinghSevere energy {{constraints}} and limited computing {{abilities of the}} nodes in a network present a major challenge {{in the design and}} deployment of a wireless sensor network. This thesis aims to present energy efficient algorithms for data fusion and information aggregation in a sensor network. The various methodologies of data fusion presented in this thesis intend to reduce the data traffic within a network by mapping the sensor network application task graph onto a sensor network topology. Partitioning of an application into sub-tasks that can be mapped onto the nodes of a sensor network offers opportunities to reduce the overall energy consumption of a sensor network. The first approach proposes a grid based <b>coordinated</b> <b>incremental</b> data fusion and routing with heterogeneous nodes of varied computational abilities. In this approach high performance nodes arranged in a mesh like structure spanning the network topology, are present amongst the resource constrained nodes. The sensor network protocol performance, measured in terms of hop-count is analysed for various grid sizes of the high performance nodes. To reduce network traffic and increase the energy efficiency in a randomly deployed sensor network, distributed clustering strategies which consider network density and structure similarity are applied on the network topology. The clustering methods aim to improve the energy efficiency of the sensor network by dividing the network into logical clusters and mapping the fusion points onto the clusters. Routing of network information is performed by inter-cluster and intra-cluster routing...|$|R
40|$|The thesis {{investigates the}} {{application}} of sustainability principles on a specific "superblock", the expansion unit of Bangkok. The case site {{is located in the}} urban fringe northeast of Bangkok and is characterized by the sprawl of leapfrogging developments and concurrent intensification of the urban fabric. The thesis proposes that sprawl and the associated environmental degradation can be arrested and mitigated within the framework of sustainability and the context of the superblock. The thesis begins by investigating the theories of sustainability which provides the basis upon which the case site is selected and the design/planning scenarios are analyzed. The research utilizes the case study approach to investigate the phenomena of contemporary sustainable design practice in Bangkok, combined with the generation of alternative scenarios/futures as a method and design tool to investigate the possibilities for a more sustainable urbanization. Through studies of Bangkok's sprawl, a representation model of the site is generated from which two alternative scenarios are projected-the `business as usual' unmediated change and the more `sustainable' mediated change stressing the central roles of khlong's and open spaces. A preliminary process of "backcasting" then speculates the varying local barriers and contexts to practicing and implementing sustainability. In the tradition of alternative visions of the designed future as major contributions to knowledge, the design/planning process provides an heuristic device as a framework that can inform and potentially assist practitioners, decision makers and stakeholders in navigating, engaging with the complexities and {{the application of}} the metanarrative of sustainability at a local level. Through the reorganization and retrofitting of the local urban ingredients and typologies of Bangkok, the thesis demonstrates that sustainability, while providing the generic theoretical framework, should, in practice, be <b>coordinated,</b> <b>incremental</b> and variable-catering to the specific evolutions in the socioeconomic, political, cultural and environmental facets of placeRestricted Access: University of Melbourne Staff and Students Onl...|$|R
40|$|Given that {{achieving}} nominal (all {{dimensions are}} theoretically perfect) geometry is challenging during building construction, understanding and anticipating sources of geometric variation through tolerances modeling and allocation is critical. However, existing building modeling environments lack {{the ability to}} support <b>coordinated,</b> <b>incremental</b> and systematic specification of manufacturing and construction requirements. This issue becomes evident when adding multi-material systems produced off site by different vendors during building erection. Current practices to improve this situation include costly and time-consuming operations that challenge the relationship among the stakeholders of a project. As one means to overcome this issue, this research proposes {{the development of a}} knowledge-aided modeling framework that integrates a parametric CAD tool with a system modeling application to assess variability in building construction. The CAD tool provides robust geometric modeling capabilities, while System Modeling allows for the specification of feature-based manufacturing requirements aligned with construction standards and construction processes know-how. The system facilitates the identification of conflicting interactions between tolerances and manufacturing specifications of building material systems. The expected contributions of this project are the representation of manufacturing knowledge and tolerances interaction across off-site building subsystems to identify conflicting manufacturing requirements and minimize costly construction errors. The proposed approach will store and allocate manufacturing knowledge as Model-Based Systems Engineering (MBSE) design specifications for both single and multiple material systems. Also, as new techniques in building design and construction are beginning to overlap with engineering methods and standards (e. g. in-factory prefabrication), this project seeks to create collaborative scenarios between MBSE and Building Information Modeling (BIM) based on parametric, simultaneous, software integration to reduce human-to-data translation errors, improving model consistency among domains. Important sub-stages of this project include the comprehensive review of modeling and allocation of tolerances and geometric deviations in design, construction and engineering; an approach for model integration among System Engineering models, mathematical engines and BIM (CAD) models; and finally, a demonstration computational implementation of a System-level tolerances modeling and allocation approach. Ph. D...|$|R

