62|95|Public
5000|$|... 2008 - Announced <b>Edge</b> <b>Server,</b> a Secure Gateway Appliance to {{facilitate}} secure file transfer with external parties ...|$|E
50|$|Edge can be {{configured}} {{for high}} availability with a backup Edge failover server that takes over sessions if the primary <b>Edge</b> <b>server</b> fails.|$|E
50|$|<b>Edge</b> <b>Server</b> is an appliance-based {{proxy server}} that {{provides}} a secure gateway for bi-directional communications between enterprise file transfer systems and external business partners and systems.|$|E
3000|$|... {{denote the}} maximum {{possible}} outgoing networking bandwidth {{of the virtual}} machines available to the origin or <b>edge</b> <b>servers.</b> Cluster Compute Instances (CCI) of the AWS EC 2 service provide a 10 GBit ethernet connection. Thus, with CCI {{it would be possible}} to achieve a maximum of 25 million independent output streams in presence of a 2 MBit input stream. This limit could be expanded by introduction of a meshed cluster architecture. In a meshed cluster the <b>edge</b> <b>servers</b> would have the possibility to connect to a further layer of <b>edge</b> <b>servers,</b> implementing a tree-like streaming network to transmit a potentially unlimited number of streams.|$|R
40|$|Systems {{consisting}} of multiple <b>edge</b> <b>servers</b> are a popular solution {{to deal with}} performance and network resource utilization problems related {{to the growth of}} the Web. After a first period of prevalent enthusiasm towards cooperating <b>edge</b> <b>servers,</b> the research community is exploring in a more systematic way the real benefits and limitations of cooperative caching. Hierarchical cooperation has clearly shown its limits. We show that the pure protocols (e. g., directory-based, query-based) applied to a flat cooperation topology do not scale as well. For increasing numbers of cooperating <b>edge</b> <b>servers,</b> the amount of exchanged data necessary for cooperation augments exponentially, or the cache hit rates fall down, or both events occur. We propose and evaluate two hybrid cooperation schemes for document discovery and delivery. They are based on a semi-flat architecture that organizes the <b>edge</b> <b>servers</b> in groups and combines directory-based and query-based cooperation protocols. A large set of experimental results confirms that the combination of directory-based and query-based schemes increases the scalability of flat architectures based on pure protocols, guarantees more stable performance and tends to reduce pathologically long response times...|$|R
3000|$|... [*]Virtual {{machines}} hosted in the AWS EC 2 {{availability zone}} [...] "eu-west- 1 ", implementing a streaming service {{provided by a}} streaming cluster (Origin <b>server</b> and <b>edge</b> <b>servers).</b>|$|R
50|$|Network Deployment. This version {{supports}} {{deployment of}} a cell configuration with cluster and J2EE failover support. It now also includes Edge Components, previously known as <b>Edge</b> <b>Server.</b> This provides a proxy server, load balancing, and content-based routing.|$|E
5000|$|Content Distribution: This {{feature is}} used in {{conjunction}} with the load balancer, where multiple <b>Edge</b> <b>server</b> components are used, to distribute HTTP requests based on URL or other administrator configured characteristics, eliminating the need to store identical content on all Edge servers.|$|E
5000|$|A {{scalable}} CDN is used {{to deliver}} media streaming to an Internet audience. The CDN receives the stream from the source at its Origin server, then replicates it to many or all of its Edge cache servers. The end-user requests the stream and is redirected to the [...] "closest" [...] <b>Edge</b> <b>server.</b> This can be tested using libdash and the Distributed DASH (D-DASH) dataset, which has several mirrors across Europe, Asia and the US. The use of HTTP-based adaptive streaming allows the <b>Edge</b> <b>server</b> to run a simple HTTP server software, whose licence cost is cheap or free, reducing software licensing cost, compared to costly media server licences (e.g. Adobe Flash Media Streaming Server). The CDN cost for HTTP streaming media is then similar to HTTP web caching CDN cost.|$|E
40|$|Abstract. The Ubiquitous Web {{requires}} novel programming paradigms {{and distributed}} architectures {{for the support}} of advanced services to a multitude of user devices and profiles. In this paper we describe a Scalable Intermediary Software Infrastructure (SISI) that aims at efficiently providing content adaptation and combinations of other complex functionalities at <b>edge</b> <b>servers</b> on the WWW. SISI adopts different user profiles to achieve automatic adaptation of the content according to the capabilities of the target devices and users. We demonstrate SISI efficiency by comparing its performance against another framework for content adaptation at <b>edge</b> <b>servers.</b> ...|$|R
40|$|Edge {{computing}} pushes {{application logic}} {{and the underlying}} data {{to the edge of}} the network, with the aim of improving availability and scalability. As the <b>edge</b> <b>servers</b> are not necessarily secure, there must be provisions for users to validate the results—that values in the result tuples are not tampered with, that no qualifying data are left out, that no spurious tuples are introduced, and that a query result is not actually the output from a different query. This paper aims to address the challenges of ensuring data integrity in edge computing. We study three schemes that enable users to check the correctness of query results produced by the <b>edge</b> <b>servers.</b> Two of the schemes are our original contributions, while the third is an adaptation of existing work. Our study shows that each scheme offers different security features, and imposes different demands on the <b>edge</b> <b>servers,</b> user machines, and interconnecting network. In other words, all three schemes are useful for different application requirements and resource configurations...|$|R
40|$|This paper {{presents}} a mitigation scheme {{to cope with}} the random query string Denial of Service (DoS) attack, which is based on a vulnerability of current Content Delivery Networks (CDNs). The attack exploits the fact that <b>edge</b> <b>servers</b> composing a CDN, receiving an HTTP request for a resource with an appended random query string never saw before, ask the origin server for a (novel) copy of the resource. Such characteristics can be employed to take an attack against the origin <b>server</b> by exploiting <b>edge</b> <b>servers.</b> Our strategy adopts a simple gossip protocol executed by <b>edge</b> <b>servers</b> to detect the attack. Based on such a detection, countermeasures can be taken to protect the origin server and the CDN against the attack. We provide simulation results that show the viability of our approach. Comment: a revised version will appear in Proc. of the 6 th International Conference on Information Systems, Technology and Management (ICISTM- 2012), Grenoble, France, Springer Series in Communications in Computer and Information Science (CCIS), March 201...|$|R
5000|$|Caching Proxy: The caching proxy {{system can}} be {{configured}} as either a forward- or reverse-proxy server. Requested content is cached by Edge before {{being sent to the}} requestor and subsequent requests can, based on its internal algorithm that can be customized, be served from the cache instead of forwarding them to application server for reprocessing. This improves response time and minimizes network bandwidth use. A primary use of <b>Edge</b> <b>server</b> is therefore to increase the performance and scalabity of J2EE applications.|$|E
50|$|SiteGround has {{data centers}} in 5 countries, the United States, the Netherlands, UK, Milan and Singapore. SiteGround runs CentOS, Apache, MySQL, PHP and WHM/cPanel on its servers. The company has {{developed}} software solutions for account isolation, monitoring and reaction, and speed-optimization, sold under the 1H brand {{and used by}} other Linux hosting companies. Their in-house built SuperCacher provide users to boost their website speed {{and with the help}} LXC technology, they managed to build cutting <b>edge</b> <b>server</b> technology to deliver maximum server uptime.|$|E
50|$|The content {{delivery}} process {{begins with a}} user submitting a request to a browser. When a user enters a URL, a DNS request is triggered and an IP address is retrieved. With the IP address, the browser can then contact a web server directly for subsequent requests. In a {{content delivery}} network structure, the domain name of the URL is translated by the mapping system into the IP address of an <b>edge</b> <b>server</b> to serve the content to the user.|$|E
40|$|The {{majority}} of web pages served today are generated dynamically, usually by an application server querying a back-end database. To enhance the scalability of dynamic content serving in large sites, application servers are offloaded to front-end nodes, called <b>edge</b> <b>servers.</b> The improvement from such application offloading is marginal, however, if data is still fetched from the origin database system. To further improve scalability and cut response times, data must be effectively cached on such <b>edge</b> <b>servers.</b> The scale of deployment of <b>edge</b> <b>servers</b> {{and the rising}} costs of their administration demand that such caches be self-managing and adaptive. In this paper, we describe DBProxy, an edge-of-network semantic data cache for web applications. DBProxy is designed to adapt {{to changes in the}} workload in a transparent and graceful fashion by caching a large number of overlapping and dynamically changing "materialized views". New "views" are added automatically while others may be discarded to save space. In this paper, we discuss the challenges of designing and implementing such a dynamic edge data cache, and describe our proposed solutions...|$|R
40|$|In this paper, we {{describe}} our work on enabling personalization services {{on the edge}} of the Internet. In contrast to traditional approaches, this method offers many advantages. First, content providers can make their content people-aware while the content is delivered to the user. Second, since the personalization work is distributed to an overlay network of <b>edge</b> <b>servers,</b> it greatly improves the scalability and availability of the services. Third, the sufficiency of user data collected in <b>edge</b> <b>servers</b> enables us to build more accurate user models which further enhance the performance of personalization services. We describe the implementation of a prototype system named Avatar and present some experimental result in this paper...|$|R
50|$|The entire China Central Television website (CCTV.com), {{including}} its streaming video, has been hosted on Akamai's <b>edge</b> <b>servers</b> since late 2009. Hulu uses Akamai for hosting video. MIT OpenCourseWare utilizes Akamai's EdgeSuite for its content delivery network.|$|R
50|$|DB2 {{information}} management software (DB2 Universal Database, DB2 Cube Views, DB2 Everyplace, DB2 Intelligent Miner Modelling, Scoring & Visualization, Informix Dynamic Server)Lotus software (Lotus Domino, Lotus Instant Messaging, Lotus Learning Management System, Lotus Notes, Lotus Workplace, Lotus Workplace Designer, Workplace for Business Controls and Reporting, Workplace for Business Strategy Execution, Workplace Client Technology, Workplace Collaboration Services)Rational software (Rational Application Developer, WebSphere Rational ClearCase, Rational Unified Process, Rational Functional Tester, Rational PurifyPlus, Rational Suite, Rational Rose Developer, Rational Software Architect, Rational Software Modeler, Rational Web Developer)Tivoli software (Tivoli Access Manager, Tivoli Intelligent Orchestrator, Tivoli Storage Manager, Tivoli Storage Resource Manager)WebSphere software (WebSphere Application Server, WebSphere Business Integration software, WebSphere <b>Edge</b> <b>Server,</b> WebSphere Everyplace, WebSphere Information Integrator Brand, WebSphere MQ, WebSphere Portal, WebSphere Services Express).|$|E
5000|$|Dr. Bahl {{designed}} and deployed the world’s first free public area Wi-Fi hotspot {{network in the}} Crossroads Shopping Center in Bellevue, Washington on 11 June 1999. [...] The network known as CROWN, short for CROssroads Wireless Network, was operational {{for two years before}} being retired on 14 June 2001. [...] At a time when the telecommunications industry was vigorously pushing 3G networks, CROWN demonstrated how Wi-Fi hotspots could be an inexpensive alternative to cellular Internet access. CROWN’s <b>edge</b> <b>server</b> architecture supported important features such as network discovery, global authentication, differentiated services, last hop cryptographic security, and location-based services. The design and the accompanying protocols influenced Internet Engineering Task Force (IETF) working groups and companies deploying Wi-Fi hot-spots. The centralized dumb access point and smart switch architecture deployed in enterprise Wi-Fi networks can also be traced back to CROWN. Dr. Bahl published influential papers and was awarded several US patents for his inventions (United States patents: 6,834,341, 7,032,241, 7,089,415, 7,085,924, 7,149,896, 7,313,237, 7,406,707, 7,444,510, 7,444,669, 7,500,263, 7,548,976).|$|E
50|$|Proginet Corporation, {{which was}} {{acquired}} by Tibco Software in 2010, was a systems management software company. It {{is best known for}} having developed a breakthrough product in the late 1980s called XCOM, which allowed companies to manage the process of moving bulk data between 26 different computer operating systems. In the early 1990s, the company's rights in XCOM were sold to its distributor, which was itself later acquired by CA-Inc. XCOM went on to generate {{hundreds of millions of dollars}} in sales for CA-Inc. After the sale of its only product, the company secured equity stakes from Microsoft and Novell, and began the development of enterprise managed file transfer products across many major computing platforms including Windows, UNIX, Linux, AS/400 and the mainframe. The company has been in business since 1986. Proginet's products include CyberFusion Integration Suite, Slingshot, <b>Edge</b> <b>Server,</b> Harbor NSM and HFT, and the Rocketstream software suite. Proginet's global customer base spans more than 23 countries and includes many Fortune 500 companies. The company is headquartered in Garden City, New York, has offices in Toronto, Canada. On June 22, 2010 the company announced that it is to be acquired by TIBCO Corporation for $23 million.|$|E
40|$|Parallel {{invocation}} of <b>edge</b> <b>servers</b> within a Web infrastructure {{has been shown}} to provide benefits, in terms of system responsiveness, for both content delivery applications and non-transactional Web services. This is achieved thanks to the exploitation of path-diversity proper of multihop networks over the Internet, which typically reduces the likelihood of client perceived link congestion. In this work we address parallel {{invocation of}} geographically spread <b>edge</b> <b>servers</b> in the context of transactional Web-based applications. Actually, parallel invocation protocols are not trivial for this type of applications, since we need to deal with a set of issues not present in classical content delivery applications, such as (i) non-idempotent business logic and (ii) increase of the workload on the data centers. I...|$|R
40|$|We study {{bulk data}} {{distribution}} schemes for content distribution networks (CDNs) using application-level overlay. Given the outbound bandwidth {{of all the}} CDN <b>edge</b> <b>servers,</b> a fluid-flow based analytical model is constructed to derive the optimal bandwidth allocations at the origin server and among all the <b>edge</b> <b>servers.</b> From which, a lower bound on the content update time is obtained. In order to have an efficient and practical scheme for bulk data distribution, ServerCast is designed to take advantages of the analytical results. Simulations are conducted to evaluate the performance of ServerCast. We show that ServerCast not only outperforms the two existing schemes, FastReplica and Multiple Unicast, but also yields a content update time within 18 % of the derived lower bound. © 2005 IEEE. published_or_final_versio...|$|R
50|$|Cloudbleed is a {{security}} bug discovered on February 17, 2017 affecting Cloudflare's reverse proxies, which caused their <b>edge</b> <b>servers</b> to run past {{the end of}} a buffer and return memory that contained private information such as HTTP cookies, authentication tokens, HTTP POST bodies, and other sensitive data.|$|R
30|$|Failures of edge servers {{would affect}} just the viewers {{consuming}} streams from the corresponding location. The streaming client would simply reconnect requesting a new <b>edge</b> <b>server</b> from the origin server. On the client side the player would react on an <b>edge</b> <b>server</b> fault automatically.|$|E
40|$|Handle {{on demand}} network {{popularity}} of the Content Delivery Network and solve the flash crowd problem, caching web content at the internet‘s <b>edge</b> <b>server</b> has been emerged. To provide faster service of the web users, content come from nearby edge servers. Therefore nearest <b>edge</b> <b>server</b> finding of a particular web user is an open research problem and it ensures a faster response time and download time of the requested content due to reduced latency...|$|E
40|$|The {{performance}} {{enhancement of}} the <b>edge</b> <b>server</b> in Content Delivery Network is the budding {{area of the}} research {{in the fields of}} modern Information Technology and Communication Engineering so that the web users or the cloud users across the network get faster service irrespective of any geographic locations during browsing over internet {{and at the same time}} downloading multimedia contents. As an aftermath, several approaches and aspects have been introduced so far with the efflux of time. Therefore, our main objective is to facilitate this area of improvement by finding the selection of an appropriate <b>edge</b> <b>server</b> which will provide the multimedia contents and ensuring a faster response time and downloading time of the requested content due to reduced latency to the web users as well. Our proposed method will show the efficient technique for choosing the appropriate <b>edge</b> <b>server</b> with comparatively less complexity...|$|E
40|$|A {{clear trend}} of the Web is {{that a variety of}} new {{consumer}} devices with diverse computing powers, display capabilities, and wired/wireless network connections is gaining access to the Internet. Tailoring Web content to match the device characteristics requires functionalities for content transformation, namely transcoding, that are typically carried out by the content Web server or by an <b>edge</b> proxy <b>server.</b> In this paper, we explore how to improve the user response time by considering systems of cooperative <b>edge</b> <b>servers</b> which collaborate in discovering, transcoding, and delivering multiple versions of Web objects. The transcoding functionality opens an entirely new space of investigation in the research area of distributed cache cooperation, because it transforms the proxy servers from content repositories along the client-server path into pro-active network elements providing computation and adaptive delivery. We propose and investigate different algorithms for cooperative discovery, delivery, and transcoding in the context of <b>edge</b> <b>servers</b> organized in hierarchical and flat peer-to-peer topologies. We compare the performance of the proposed schemes through ColTrES (Collaborative Transcoder Edge Services), a flexible prototype testbed that implements all considered mechanisms. ...|$|R
5000|$|IBM WebSphere Edge Components (formerly {{known as}} [...] "IBM WebSphere Edge Server") {{is a set}} of web server/application server {{components}} that are intended to improve the performance of web-based systems, particularly as <b>edge</b> <b>servers.</b> It is part of the IBM WebSphere product suite. Current version is version 8.5. It consists of two independent products: ...|$|R
40|$|We {{describe}} {{the goals and}} architecture of a new frame-work that aims at facilitating the deployment of adapta-tion services running on intermediate <b>edge</b> <b>servers.</b> The main goal is to guarantee robustness and quick prototyp-ing of functions that should integrate mobile/fixed-network services. Moreover, we intend to design a distributed archi-tecture {{with the purpose of}} guaranteeing efficient delivery. 1...|$|R
40|$|On-demand {{streaming}} from {{a remote}} server through best-effort Internet poses several challenges because of network losses and variable delays. We provide {{a comprehensive review}} and develop taxonomy of current methods to enhance the delivery quality of multimedia streaming. We then develop new delivery models for a distributed architecture in which video is streamed from a remote server to an <b>edge</b> <b>server</b> where the video is buffered and then streamed to the client through a last mile connection. The model uses a novel revolving indexed buffering mechanism at the <b>edge</b> <b>server</b> and employs selective retransmissions of lost packets between the remote and edge servers for a best-effort recovery of the losses. The performance of buffer management and retransmission policies at the <b>edge</b> <b>server</b> is modeled and assessed using a probabilistic analysis of the streaming process and system simulations. The influence of different endogenous control parameters {{on the quality of}} stream received by the client is studied. Calibration curves on the QoS metrics for different network conditions have been obtained using simulations. These could be used to set the values of the different endogenous control parameters for specific QoS in real-time streaming operations. A methodology to benchmark transmission characteristics using real-time traffic data is developed to enable effective decision making on <b>edge</b> <b>server</b> buffer allocation and management strategies...|$|E
40|$|Content {{delivery}} networks (CDNs) are {{an essential}} component of modern website infrastructures: edge servers located closer to users cache content, increasing robustness and capacity while decreasing latency. However, this situation becomes complicated for HTTPS content that is to be delivered using the Transport Layer Security (TLS) protocol: the <b>edge</b> <b>server</b> must be able to carry out TLS handshakes for the cached domain. Most commercial CDNs require that the domain owner give their certificate's private key to the CDN's <b>edge</b> <b>server</b> or abandon caching of HTTPS content entirely. We examine the security and performance of a recently commercialized delegation technique in which the domain owner retains possession of their private key and splits the TLS state machine geographically with the <b>edge</b> <b>server</b> using a private key proxy service. This allows the domain owner to limit the amount of trust given to the <b>edge</b> <b>server</b> while maintaining the benefits of CDN caching. On the performance front, we find that latency is slightly worse compared to the insecure approach, but still significantly better than the domain owner serving the content directly. On the security front, we enumerate the security goals for TLS handshake proxying and identify a subtle difference between the security of RSA key transport and signed-Diffie [...] Hellman in TLS handshake proxying; we also discuss timing side channel resistance of the key server and the effect of TLS session resumption...|$|E
40|$|Edge {{computing}} is {{a powerful}} tool to face the challenging performance requirements of modern Internet applications. By replicating applications ’ data and logic across {{a large number of}} geographically distributed servers, edge computing platforms allow to achieve significant enhancements of the proximity between clients and contents, and of the system scalability. These platforms reveal highly effective when handling requests entailing readonly access to the application data, as these requests can be autonomously served by some <b>edge</b> <b>server</b> typically located closer to the client than the origin site. However, in contexts where end-users can trigger transactional manipulations of the application state (e. g., e-Commerce, auctions or financial applications), the corresponding update requests typically need to be re-directed to the origin transactional data sources, thus nullifying any performance benefit arising from data replication and client proximity. In orderto copewith this issue, in this articlewe presentaparallelinvocationprotocol, which exploits the path-diversity along the end-to-end interaction towards the origin sites by concurrently routing transactional requests towards multiple edge servers. Request processing is finally carried out by a single <b>edge</b> <b>server,</b> adaptively selected as the most responsive one depending on current system conditions. The proposed <b>edge</b> <b>server</b> selection scheme does not require coordination among (geographically distributed) <b>edge</b> <b>server</b> instances, thus being very light and scalable. The benefits from our protocol in terms of both reduced and more predictable end-to-end latency are quantified via an extended simulation study...|$|E
30|$|Apart from OpenCDN software, {{the online}} {{measurement}} tool (OMT) is deployed at the <b>edge</b> <b>servers.</b> OMT retrieves periodically (i) server CPU load and throughput values and (ii) latency and cache hit ratio values by the OpenCDN log files. Moreover, it captures the link quality {{for each of}} the CDN end users the surrogate serves. OMT is also implemented as a custom shell script.|$|R
40|$|Poor Internet {{performance}} currently {{undermines the}} efficiency of hyper-responsive mobile apps such as augmented reality clients and online games, which require low-latency access to real-time backend services. While edge-assisted execution, i. e. moving entire services {{to the edge of}} an access network, helps eliminate part of the communication overhead involved, this does not scale to the number of users that share an edge infrastructure. This is due to a mismatch between the scarce availability of resources in access networks and the aggregate demand for computational power from client applications. Instead, this paper proposes a hybrid edge-assisted deployment model in which only part of a service executes on LTE <b>edge</b> <b>servers.</b> We provide insights about the conditions that must hold for such a model to be effective by investigating in simulation different deployment and application scenarios. In particular, we show that using LTE <b>edge</b> <b>servers</b> with modest capabilities, performance can improve significantly as long as at most 50...|$|R
50|$|Lync Server also {{supports}} remote users, both corporate users on the Internet (e.g. mobile or home workers) {{as well as}} users in partner companies. Lync supports identity federation, enabling interoperability with other corporate IM networks. Federation can be configured either manually (where each partner manually configures the relevant <b>edge</b> <b>servers</b> in the other organization) or automatically (using the appropriate SRV records in the DNS).|$|R
