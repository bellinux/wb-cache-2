320|0|Public
5000|$|Given {{an initial}} guess for a snake, the energy {{function}} of the snake is iteratively minimized. Gradient descent minimization {{is one of the}} simplest optimizations which can be used to minimize snake energy. Each iteration takes one step in the negative gradient of the point with controlled step size [...] to find local minima. This <b>gradient-descent</b> minimization can be implemented as ...|$|E
50|$|Among {{the most}} used {{adaptive}} algorithms is the Widrow-Hoff’s {{least mean squares}} (LMS), which represents a class of stochastic <b>gradient-descent</b> algorithms used in adaptive filtering and machine learning. In adaptive filtering the LMS is used to mimic a desired filter by finding the filter coefficients that relate to producing the least mean square of the error signal (difference between the desired and the actual signal).|$|E
5000|$|The (non-negative) {{damping factor}} λ is {{adjusted}} at each iteration. If reduction of S is rapid, a smaller value can be used, bringing the algorithm {{closer to the}} Gauss-Newton algorithm, whereas if an iteration gives insufficient reduction in the residual, λ can be increased, giving {{a step closer to}} the <b>gradient-descent</b> direction. Note that the gradient of S with respect to δequals [...] Therefore, for large values of λ, the step willbe taken approximately {{in the direction of the}} gradient. If either the length of the calculated step δ or the reduction of sum of squares from the latest parameter vector β + δ fall below predefined limits, iteration stops, and the last parameter vector β is considered to be the solution.|$|E
40|$|A new genetic {{mutation}} operator {{was created to}} approximate <b>gradient-descent</b> techniques in a genetic algorithm. The performance of this genetic operator was evaluated on the search space of the five De Jong test functions. The results of GA runs with this <b>Gradient-Descent</b> Mutation (GDM) operator were compared to the same GA with the standard mutation operator – the results were greatly {{in favor of the}} GDM operator with as many as 4 of 5 runs producing a fitter individual with this new technique. The possibilities for enhancement of this specific GDM operator are discussed along with general possibilities of this hybrid paradigm. 1. Statement and Motivation of the Problem While an evolutionary search is a robust approach to seek solutions in a search space, other more mainstream paradigms offer specific advantages. In this paper, I implement a genetic algorithm that features a new mutation operator that approximately recreates a <b>gradient-descent</b> technique. While a purely calculus-based <b>gradient-descent</b> technique may converge to a sub-optimal solution in a non-linear search-space (in local minima or maxima), a hybrid of both techniques pose an interesting situation. Could we effectively combine the efficiency of hill-climbin...|$|E
30|$|Training {{algorithms}} are {{utilized to}} achieve optimum classification, {{some of these}} are perceptron learning, Levenberg-Marquardt (LM), scaled conjugate gradient, and <b>gradient-descent</b> algorithms. These algorithms generally differ in computational cost and optimization speed. Overall, LM algorithms produce faster speeds but with higher memory usage. Perceptron learning requires linearly separable data to operate and suffers from being a rather slow algorithm in practice. <b>Gradient-descent</b> algorithms and scaled conjugate gradient offer a balanced trade-off between computational cost and speed for training neural networks.|$|E
3000|$|... 1986) is {{the most}} {{frequently}} used one. The BP algorithm is a <b>gradient-descent</b> method which searches an error surface for points with minimum error. Optimization methods such as Levenberg-Marquardt (Levenberg [...]...|$|E
30|$|Training {{algorithm}} the <b>Gradient-Descent</b> algorithm [22]. Although the Levenberg–Marquardt {{algorithm is}} quick and yields {{a very small}} error, it tends to overfit, resulting in a poor generalization for the testing data [16].|$|E
40|$|AbstractThis work {{presents}} the restricted <b>gradient-descent</b> (RGD) algorithm, a training method for local radial-basis function networks specifically developed {{to be used}} in the context of reinforcement learning. The RGD algorithm can be seen as a way to extract relevant features from the state space to feed a linear model computing an approximation of the value function. Its basic idea is to restrict the way the standard <b>gradient-descent</b> algorithm changes the hidden units of the approximator, which results in conservative modifications that make the learning process less prone to divergence. The algorithm is also able to configure the topology of the network, an important characteristic in the context of reinforcement learning, where the changing policy may result in different requirements on the approximator structure. Computational experiments are presented showing that the RGD algorithm consistently generates better value-function approximations than the standard <b>gradient-descent</b> method, and that the latter is more susceptible to divergence. In the pole-balancing and Acrobot tasks, RGD combined with SARSA presents competitive results with other methods found in the literature, including evolutionary and recent reinforcement-learning algorithms...|$|E
40|$|International audienceThis paper {{addresses}} {{the problem of}} variable ranking for support vector regression. The ranking criteria that we proposed are based on leave-one-out bounds and some variants and for these criteria we have compared different search-space algorithms: recursive feature elimination and scaling factor optimization based on <b>gradient-descent.</b> All these algorithms have been compared on toy problems and real-world QSAR data sets. Results show that the radius-margin criterion is the most efficient criterion for ranking variables. Using this criterion can then lead to support vector regressor with improved error rate while using fewer variables. Our results also support the evidence that <b>gradient-descent</b> algorithm achieves a better variable ranking compared to backward algorithm...|$|E
40|$|Abstract—This paper {{proposes a}} novel fuzzy {{learning}} vector quantization algorithm for lossy image compression. In the first place, we introduce a modified objective function for the fuzzy c-means algorithm. In the second place, we obtain a reformulating {{version of this}} function, which then is minimized {{by means of an}} iterative <b>gradient-descent</b> based optimization procedure. The transition from fuzzy mode, where each training vector is assigned to more than one codebook vectors, to crisp mode, where each training vector is assigned to only one codebook vector is accomplish through the adjustment of the <b>gradient-descent</b> learning parameter. Index terms—fuzzy learning vector quantization, modified fuzzy c-means, lossy image compression I...|$|E
40|$|This {{paper is}} {{triggered}} by the preprint "Computing Matrix Squareroot via Non Convex Local Search" by Jain et al. (bluearXiv: 1507. 05854), which analyzes <b>gradient-descent</b> for computing the square root of a positive definite matrix. Contrary to claims of jain 2015, our experiments reveal that Newton-like methods compute matrix square roots rapidly and reliably, even for highly ill-conditioned matrices and without requiring commutativity. We observe that <b>gradient-descent</b> converges very slowly primarily due to tiny step-sizes and ill-conditioning. We derive an alternative first-order method based on geodesic convexity: our method admits a transparent convergence analysis (< 1 page), attains linear rate, and displays reliable convergence even for rank deficient problems. Though superior to <b>gradient-descent,</b> ultimately our method is also outperformed by a well-known scaled Newton method. Nevertheless, the primary value of our work is its conceptual value: it shows that for deriving gradient based methods for the matrix square root, the manifold geometric view of positive definite matrices can be much more advantageous than the Euclidean view. Comment: 8 pages, 12 plots, this version contains several more references and more words about the rank-deficient cas...|$|E
40|$|The use of {{evolutionary}} algorithms {{to design and}} train boolean neural networks have shown to be e#cient, but seems to be complex for the learning process of any real feedforward networks. For feedforward net learning, some gradientdescent methods are more appropriate than the evolutionary ones in converging on an exact optimal solution in a reasonable time, unfortunately they are inclined to fall into local optima. In this framework, this paper proposes an evolutionary approach to initialize the weight and bias values of neural networks before back-propagation trainings. The evolutionary algorithm provides a good solution, then we apply a <b>gradient-descent</b> method to obtain a more accurate optimal solution. Simulation results show that our initialization reduces the neural network training time and improves the robustness of <b>gradient-descent</b> algorithms...|$|E
3000|$|The {{advantage}} {{provided by}} the constellations with {{two degrees of freedom}} (such as quadrature amplitude modulation (QAM)) over the ones with one degree of freedom (such as phase-shift-keying (PSK), and pulse amplitude modulation (PAM)) was shown [1], and a proper mapping (based on a <b>gradient-descent</b> procedure) of the [...]...|$|E
40|$|This paper compares {{alternative}} methods for approximating and solving the stochastic growth model with parameterized expectations. We compare polynomial and neural netowork specifications for expectations, and we employ both genetic algorithm and <b>gradient-descent</b> methods for solving the alternative models of parameterized expectations. Many of the statistics {{generated by the}} neural network specification {{in combination with the}} genetic algorithm and gradient descent optimization methods approach the statistics generated by the exact solution with risk aversion coefficients close to unity and full depreciation of the capital stock. For the alternative specification, with no depreciation of capital, the neural network results approach those generated by computationally-intense methods. Our results suggest that the neural network specification and genetic algorithm solution methods should at least complement parameterized expectation solutions based on polynomial approximation and pure <b>gradient-descent</b> optimization. ...|$|E
40|$|We {{present an}} {{analytic}} {{solution to the}} problem of on-line <b>gradient-descent</b> learning for two-layer neural networks with an arbitrary number of hidden units in both teacher and student networks. The technique, demonstrated here for the case of adaptive input-to-hidden weights, becomes exact as the dimensionality of the input space increases...|$|E
40|$|Long {{short-term}} memory (LSTM) recurrent neural networks (RNNs) outperform traditional RNNs {{when dealing with}} sequences involving not only short-term but also long-term dependencies. The decoupled extended Kalman filter learning algorithm (DEKF) works well in online environments and reduces significantly the number of training steps {{when compared to the}} standard <b>gradient-descent</b> algorithms...|$|E
3000|$|... {{however, the}} {{literature}} provides both theoretical [36] and practical criteria [37] {{to address that}} task. The multilayer perceptron (MLP) [34] is possibly the most popular type of feedforward network. The MLP learning problem is usually tackled by the backpropagation (BP) algorithm [34], which applies a stochastic <b>gradient-descent</b> strategy over the weight space.|$|E
40|$|An {{approach}} to the formulation of fuzzy if-then rules based on clustering objective functions is proposed. The membership functions are then calibrated with the generalized neural networks technique to achieve a desired input-output mapping. The learning procedure is basically a <b>gradient-descent</b> algorithm. A Kalman filter algorithm is used to improve the overall performance...|$|E
3000|$|... -norm {{sense as}} the {{similarity}} measure and introduce four different regularization terms. In the same section, we solve the existing optimization {{problem in a}} systematic manner by the techniques in variational calculus such as <b>gradient-descent</b> based methods. Computational results given in the last section indicate that new regularization terms provide fast, stable, and efficient image registration models.|$|E
40|$|A {{major goal}} of {{research}} on networks of neuron-like processing units is to discover efficient learning procedures that allow these networks to construct complex internal representations of their environment. The learning procedures must be capable of modifying the connection strengths {{in such a way}} that internal units which are not part of the input or output come to represent important features of the task domain. Several interesting <b>gradient-descent</b> procedures have recently been discovered. Each connection computes the derivative, with respect to the connection strength, of a global measure of the error in the performance of the network. The strength is then adjusted in the direction that decreases the error. These relatively simple, <b>gradient-descent</b> learning procedures work well for small tasks and the new challenge is to find ways of improving their convergence rate and their generalization abilities so that they can be applied to larger, more realistic tasks...|$|E
40|$|We {{introduce}} a general algorithm for continuous- and discrete-time nonlinear <b>gradient-descent.</b> The nonlinearity is {{captured by the}} choice of a link function. The discrete-time algorithm yields, for various choices of link function, the conventional <b>gradient-descent</b> algorithm as well as several exponentiated gradient ones. We obtain relative loss bounds for the general algorithm in an on-line setting for both the continuous- and discrete-time versions. These bounds reveal the dependence on the link function and show that an additional term is present in the discrete-time case which disappears in the continuous-time case. This additional term is responsible for the pair of dual norms that appear in the relative loss bounds for linear and logistic regression. The continuous-time version is also shown to have a simple proof of convergence in the batch setting. Convergence of Hopfield recurrent neural networks is seen as a special case. 1 Introduction This paper introduces continuous- and [...] ...|$|E
40|$|This report {{describes}} {{the use of}} Genetic Programming (GP) to solve multipleclass object classification problems. Objects is reduced to feature vectors containing four features. GP is then used to evolve classifiers for the feature vectors. Objects are taken from four image datasets of increasing difficulty. Three research directions are discussed in this report. Three classification strategies are compared, including two new ones, Centred Dynamic Range Selection (CDRS) and Slotted Dynamic Range Selection (SDRS). The new strategies were found to improve {{the performance of the}} system, over the standard SRS. This is especially true for harder problems with classes in an arbitrary order. <b>Gradient-descent</b> search on individual programs is introduced to GP in this report. GP is still used as a global beam search, but another, local gradientdescent search is made on programs. The subject of the search is the numeric terminals of the programs. The use of <b>gradient-descent</b> markedly improves th...|$|E
40|$|Convergence {{speed and}} local minimum issue {{have been the}} major issues for inverse lithography. In this paper, we propose an inverse {{algorithm}} that employs an iterative <b>gradient-descent</b> method to improve convergence and reduce the Edge Placement Error (EPE). The algorithm employs a constrained gradient-based optimization to attain the fast converging speed, while a cross-weighting technique is introduced to overcome the local minimum trapping...|$|E
40|$|Despite {{the wide}} use of machine {{learning}} in adversarial settings including computer security, {{recent studies have}} demonstrated vulnerabilities to evasion attacks [...] -carefully crafted adversarial samples that closely resemble legitimate instances, but cause misclassification. In this paper, we examine {{the adequacy of the}} leading approach to generating adversarial samples [...] -the gradient descent approach. In particular (1) we perform extensive experiments on three datasets, MNIST, USPS and Spambase, in order to analyse the effectiveness of the <b>gradient-descent</b> method against non-linear support vector machines, and conclude that carefully reduced kernel smoothness can significantly increase robustness to the attack; (2) we demonstrate that separated inter-class support vectors lead to more secure models, and propose a quantity similar to margin that can efficiently predict potential susceptibility to <b>gradient-descent</b> attacks, before the attack is launched; and (3) we design a new adversarial sample construction algorithm based on optimising the multiplicative ratio of class decision functions. Comment: 10 pages, 7 figures, 10 table...|$|E
40|$|Currently, {{almost all}} discriminative {{training}} algorithms for nonlinear classifier design {{are based on}} <b>gradient-descent</b> methods, such as backpropagation and generalized probabilistic descent algorithms. Those algorithms are easy to derive and are effective in applications; however, a drawback for the <b>gradient-descent</b> approaches is the slow training speed, which limits their applications to large training problems, such as large vocabulary speech recognition and many other applications with time requirements. On the other hand, some training algorithms, such as maximum likelihood estimation (MLE), are fast {{but they are not}} in discriminative training; therefore, the performances are not as good as the discriminative one. To address the problem, we proposed a fast discriminative training algorithm in this paper. It is a batch-mode algorithm derived from the objective function of minimal error rates. The significant theoretical advantage is its closed-form solution for parameter estimation during iterations. Thus, training problems can be solved in a few iterations. Experiments show that the proposed algorithm provides better performances than MLE. 1...|$|E
30|$|We have {{designed}} this method since it provides fast results, typically {{stopping at the}} second iteration. Other known methods, like <b>gradient-descent</b> or second-order optimization procedures, have been tested in this context, being much more unstable. The reason is that they greatly depend {{on the quality of}} the Jacobian approximation, which, in our problem, introduces too much error and makes the system tend to lose the track.|$|E
40|$|Synaptic {{connections}} adjusted {{one at a}} time {{in small}} increments. Simplified <b>gradient-descent</b> learning scheme for electronic neural-network processor less efficient than better-known back-propagation scheme, but offers two advantages: easily implemented in circuitry because data-access circuitry separated from learning circuitry; and independence of data-access circuitry makes possible to implement feedforward as well as feedback networks, including those of multiple-attractor type. Important in such applications as recognition of patterns...|$|E
40|$|The parity {{function}} {{is one of}} the most used boolean function for testing learning algorithms because both of its simple denition and its great complexity. Being one of the hardest problems, many dierent architectures have been constructed to compute parity, essentially by adding neurons in the hidden layer in order to reduce the number of local minima where <b>gradient-descent</b> learning algorithms could get stuck. We construct...|$|E
40|$|A 134 -control-channel adaptive-optics system {{consisting}} of a microelectromechanical mirror array (m-mirror), a wave-front tilt-control mirror, and a very large scale integration controller utilizing a stochastic <b>gradient-descent</b> optimization of a performance metric is presented. A maximum adaptation rate of � 11, 000 iterations�s was achieved. The system was used to demonstrate real-time compensation for dynamic phase distortions from a laboratory-generated turbulence simulator in a laser-focusing experiment. © 2002 Optical Society o...|$|E
40|$|Abstract-We can {{memorize}} long sequences like melodies or {{poems and}} it is intriguing to develop efficient connectionist representations for this problem. Recurrent neural networks have been proved to offer a reasonable approach here. We start from a few axiomatic assumptions and provide a simple mathematical framework that encapsulates the problem. A <b>gradient-descent</b> based algorithm is derived in this framework. Demonstrations on a benchmark problem show the applicability of our approach...|$|E
40|$|Abstract. This paper derives a new {{algorithm}} that performs independent {{component analysis}} (ICA) by optimizing the contrast {{function of the}} RADICAL algorithm. The core idea of the proposed optimization method is to combine the global search of a good initial condition with a <b>gradient-descent</b> algorithm. This new ICA algorithm performs faster than the RADICAL algorithm (based on Jacobi rotations) while still preserving, and even enhancing, the strong robustness properties that result from its contrast...|$|E
40|$|This paper {{presents}} <b>gradient-descent</b> coverage algorithms for a {{group of}} nonholonomic vehicles. Similarly to previous approaches, the deployment strategy relies on Locational Optimization techniques and algorithms are distributed {{in the sense of the}} Delaunay graph. In order to deal with unicycle dynamics and guarantee performance, we introduce several vehicle modes and integrate them in a hybrid system We then analyze the algorithms with a recently introduced invariance principle for hybrid systems. I...|$|E
40|$|Alopex is a correlation-based gradient-free {{optimization}} technique useful in many learning problems. However, {{there are no}} analytical results on the asymptotic behavior of this algorithm. This article presents {{a new version of}} Alopex that can be analyzed using techniques of two timescale stochastic approximation method. It is shown that the algorithm asymptotically behaves like a <b>gradient-descent</b> method, though it does not need (or estimate) any gradient information. It is also shown, through simulations, that the algorithm is quite effective...|$|E
40|$|This paper {{presents}} a decentralized motion planning algorithm for the distributed sensing of a noisy dynamical process by multiple cooperating mobile sensor agents. This problem {{is motivated by}} localization and tracking tasks of dynamic targets. Our <b>gradient-descent</b> method {{is based on a}} cost function that measures the overall quality of sensing. We also investigate the role of imperfect communication between sensor agents in this framework, and examine the trade-offs in performance between sensing and communication. Simulations illustrate the basic characteristics of the algorithms...|$|E
40|$|We {{discuss a}} novel {{decision}} tree architecture with soft decisions at the internal nodes where we choose both children with probabilities {{given by a}} sigmoid gating function. Our algorithm is incremental where new nodes are added when needed and parameters are learned using <b>gradient-descent.</b> We visualize the soft tree fit on a toy data set and then compare it with the canonical, hard decision tree over ten regression and classification data sets. Our proposed model has significantly higher accuracy using fewer nodes. 1...|$|E
40|$|Simple {{algorithm}} for recurrent {{neural networks}} that can learn sequence completion Abstract — We can memorize long sequences like melodies or poems {{and it is}} intriguing to develop efficient connectionist representations for this problem. Recurrent neural networks have been proved to offer a reasonable approach here. We start from a few axiomatic assumptions and provide a simple mathematical framework that encapsulates the problem. A <b>gradient-descent</b> based algorithm is derived in this framework. Demonstrations on a benchmark problem show the applicability of our approach...|$|E
