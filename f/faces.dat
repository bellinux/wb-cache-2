10000|10000|Public
5|$|During {{the early}} Renaissance, {{painters}} such as Duccio di Buoninsegna learned to paint <b>faces</b> {{first with a}} green undercoat, then with pink, which gave the <b>faces</b> a more realistic hue. Over the centuries the pink has faded, making some of the <b>faces</b> look green.|$|E
5|$|An {{iconographic}} {{tradition of}} representing Sun and Moon with <b>faces</b> {{developed in the}} late medieval period.|$|E
5|$|Any {{counting}} formula involving vertices and <b>faces</b> that {{is valid}} for all planar graphs may be transformed by planar duality into an equivalent formula {{in which the}} roles of the vertices and <b>faces</b> have been swapped. Euler's formula, which is self-dual, is one example. Another given by Harary involves the handshaking lemma, according to which the sum of the degrees of the vertices of any graph equals twice the number of edges. In its dual form, this lemma states that in a plane graph, the sum of the numbers of sides of the <b>faces</b> of the graph equals twice the number of edges.|$|E
5000|$|All seven cowry shells {{are used}} in each throw.Scoring is as follows:All 7 <b>facing</b> down - 7 points1 <b>facing</b> up, 6 <b>facing</b> down - 11 points2 <b>facing</b> up, 5 <b>facing</b> down - 2 points3 <b>facing</b> up, 4 <b>facing</b> down - 3 points4 <b>facing</b> up, 3 <b>facing</b> down - 4 points5 <b>facing</b> up, 2 <b>facing</b> down - 25 points 6 <b>facing</b> up, 1 <b>facing</b> down - 30 pointsAll 7 <b>facing</b> up - 14 points ...|$|R
40|$|<b>Face</b> {{identity}} and facial expression are processed in two distinct neural pathways. However, {{most of the}} existing <b>face</b> adaptation literature studies them separately, {{despite the fact that}} they are two aspects from the same <b>face.</b> The current study conducted a systematic comparison between these two aspects by <b>face</b> adaptation, investigating how top- and bottom-half <b>face</b> parts contribute to the processing of <b>face</b> {{identity and}} facial expression. A real <b>face</b> (sad, “Adam”) and its two size-equivalent <b>face</b> parts (top- and bottom-half) were used as the adaptor in separate conditions. For <b>face</b> identity adaptation, the test stimuli were generated by morphing Adam's sad <b>face</b> with another person's sad <b>face</b> (“Sam”). For facial expression adaptation, the test stimuli were created by morphing Adam's sad <b>face</b> with his neutral <b>face</b> and morphing the neutral <b>face</b> with his happy <b>face.</b> In each trial, after exposure to the adaptor, observers indicated the perceived <b>face</b> identity or facial expression of the following test <b>face</b> via a key press. They were also tested in a baseline condition without adaptation. Results show that the top- and bottom-half <b>face</b> each generated a significant <b>face</b> identity aftereffect. However, the aftereffect by top-half <b>face</b> adaptation is much larger than that by the bottom-half <b>face.</b> On the contrary, only the bottom-half <b>face</b> generated a significant facial expression aftereffect. This dissociation of top- and bottom-half <b>face</b> adaptation suggests that <b>face</b> parts play different roles in <b>face</b> identity and facial expression. It thus provides further evidence for the distributed systems of <b>face</b> perception...|$|R
5000|$|Dinosaurs (1991-1994) .... Robbie Sinclair (eyes), Roy Hess (arms), Baby Sinclair (arms; Season 4), Ansel (<b>face),</b> Aubrey Molehill (<b>face),</b> Crazy Lou (<b>face),</b> Elder No. 3 (<b>face),</b> Ethyl Phillips (<b>face,</b> occasionally), Katie (<b>face),</b> Mindy (face/voice), Monica DeVertebrae (<b>face),</b> Shopper (puppet/voice), Sitcom Wife (puppet/voice), {{various other}} {{characters}} ...|$|R
5|$|As an {{irregular}} star (self-intersecting) polyhedron with 20 identical self-intersecting enneagrammic <b>faces,</b> 90 edges, 60 vertices.|$|E
5|$|At SuperBrawl VII on February 23, 1997, the <b>Faces</b> of Fear {{competed in}} a Three Way match. They faced The Public Enemy and Harlem Heat but lost when Rocco Rock from The Public Enemy pinned The Barbarian. At Fall Brawl 1997, The Barbarian and Meng faced Wrath and Mortis. Because Wrath and Mortis {{were part of}} a heel group, WCW had the <b>Faces</b> of Fear compete as <b>faces</b> during the match. Wrath and Mortis won the match, as Wrath pinned Meng for the victory. The <b>Faces</b> of Fear were {{successful}} at World War 3 1997, however, when they defeated the team of Glacier and Ernest Miller.|$|E
5|$|By {{seven to}} nine months, infants {{can tell the}} sexes apart based on hair length, voice pitch and <b>faces.</b>|$|E
40|$|Figure 6 - Selaginella neospringiana Valdespino. A Megaspore, {{proximal}} <b>face</b> B Close-up of megaspore, proximal <b>face</b> C Megaspore, distal <b>face</b> D Close-up of megaspore, distal <b>face</b> E Microspore, proximal <b>face</b> F Close-up of microspore, proximal <b>face</b> G Microspore, distal <b>face</b> H Close-up of microspore, distal <b>face</b> I Microspore, equatorial view. A–I {{taken from}} the isotype, Glaziou 11723 (PMA) ...|$|R
40|$|<b>Face</b> {{recognition}} {{system has}} come to a wide area drawing attention for researchers since a long period. In this time <b>face</b> recognition system has a number of areas, like forensic, psychology, and security. Algorithm which used in <b>face</b> recognition is quite a lot and varies, but altogether have three elementary phases, that are <b>face</b> detection, <b>face</b> features extraction, and <b>face</b> recognition. <b>Face</b> detection phase determines and dissociates the part of an image (still image) which definitioned as a <b>face.</b> <b>Face</b> feature extraction phase can detect <b>face</b> features as information. <b>Face</b> recognition phase identifies human <b>face</b> based on information got from the <b>face</b> feature extraction phase. <b>Face</b> feature extraction is important phase. This phase will look for information which is special characteristic of human <b>face.</b> The characteristic in general will always remain to every adult human and different each other, so that can be made as the basis for <b>face</b> identity. Algorithm used to detect <b>face</b> features comes from algorithm found [1][2] had been adapted for the experiment situation. From 70 samples <b>face</b> image, the level efficacy of feature <b>face</b> equals to 88, 6 %...|$|R
40|$|A typical {{automatic}} <b>face</b> recognition {{system is}} composed of three parts: <b>face</b> detection, <b>face</b> alignment and <b>face</b> recognition. Conventionally, these three parts are processed in a bottom-up manner: <b>face</b> detection is performed first, then the results are passed to <b>face</b> alignment, and finally to <b>face</b> recognition. The bottom-up approach is one extreme of vision approaches. The other extreme approach is topdown. In this paper, we proposed a Markovian stochastic mixture approach for combining bottom-up and top-down <b>face</b> recognition: <b>face</b> recognition is performed {{from the results of}} <b>face</b> alignment in a bottom-up way, and <b>face</b> alignment is performed {{based on the results of}} <b>face</b> recognition in a top-down way. By modeling the mixture <b>face</b> recognition as a stochastic process, the recognized person is decided probabilistically according to the probability distribution coming from the stochastic <b>face</b> recognition, and the recognition problem becomes that “who the most probable person is when the stochastic process of <b>face</b> recognition goes on for an infinite long duration”. This problem is solved with the theory of Markov chains by properly modeling the stochastic process of <b>face</b> recognition as a Markov chain. As conventional <b>face</b> alignment is not suitable for this mixture approach, discriminative <b>face</b> alignment is proposed. And we also prove that the Markovian mixture <b>face</b> recognition results only depend on discriminative <b>face</b> alignment, not on conventional <b>face</b> alignment. Our approach can surprisingly outperform the <b>face</b> recognition performance with manual <b>face</b> localization, which is demonstrated by extensive experiments. 1...|$|R
5|$|Caracals possess {{distinctive}} black {{markings on}} their <b>faces,</b> and some individuals may have pronounced 'eyebrow' markings.|$|E
5|$|Holmes, June (2006). The Many <b>Faces</b> of Bewick. Natural History Society of Northumbria Transactions.|$|E
5|$|In 2014, the {{hardware}} and software behind the fountain's operation were replaced. At the time there were plans to replace LED lighting with incandescent bulbs {{on each of the}} non-video display surfaces and to replace the video surface LEDs. Plensa, who maintained control of the video <b>faces</b> for {{the first two years of}} the fountain's operation, understands that future generations may wish to update the <b>faces</b> used in the rotation of videos to reflect changes in humanity going forward. In 2014, an additional 1000 <b>faces</b> were anticipated for 2016.|$|E
3000|$|The <b>face</b> {{image is}} divided into a low-frequency <b>face</b> image and three {{high-frequency}} <b>face</b> images by wavelet transform. Low-frequency <b>face</b> image information {{plays a key role}} in <b>face</b> recognition because it represents the global (whole) information of <b>face</b> images. What is calculated is only the classification membership of <b>face</b> recognition for the low-frequency part. High-frequency <b>face</b> images include horizontal, vertical, and diagonal image information. Firstly, the decomposed high-frequency <b>face</b> images are merged to obtain the information of the high-frequency <b>face</b> fusion image of the <b>face</b> image. Then, the <b>face</b> recognition method of the merged image is performed by the <b>face</b> recognition method of sparse representation, and the classification membership degree of only the high-frequency <b>face</b> image for <b>face</b> recognition is obtained. The low-frequency part and the high-frequency part membership are merged together by the dynamic weighted fusion method as the final classification membership degree, and the final <b>face</b> image classification and recognition are performed. The specific algorithm is as follows: [...]...|$|R
50|$|In 2014 <b>Face</b> Off Unlimited opened The NYC Improv <b>Face</b> Off in Times Square at Times Scare. Improv <b>Face</b> Off {{features}} <b>Face</b> Off's {{best and}} brightest stars. Also, in 2014, <b>Face</b> Off opened <b>Face</b> Off's 11th Hour Improv Show, which features the newest and rising stars in the <b>Face</b> Off company.|$|R
5000|$|Killing Season (film) (<b>Face</b> à <b>face</b> (film, 2013) - <b>Face</b> à <b>Face)</b> (2013): Emil Kovac ...|$|R
5|$|Jovovich {{played the}} role of Dr. Abigail Tyler in the science-fiction thriller The Fourth Kind and starred in the {{psychological}} thriller <b>Faces</b> in the Crowd, which was written and directed by Julien Magnat; in the latter film, she plays the survivor of a serial killer’s attack that leaves her suffering from a condition called prosopagnosia, which renders her unable to recognize <b>faces.</b>|$|E
5|$|Like {{the other}} Galilean {{satellites}} and the Moon, Io rotates synchronously with its orbital period, keeping one face nearly pointed toward Jupiter. This synchronicity provides the definition for Io's longitude system. Io's prime meridian intersects the equator at the sub-Jovian point. The side of Io that always <b>faces</b> Jupiter {{is known as}} the subjovian hemisphere, whereas the side that always <b>faces</b> away {{is known as the}} antijovian hemisphere. The side of Io that always <b>faces</b> in the direction that Io travels in its orbit is known as the leading hemisphere, whereas the side that always <b>faces</b> in the opposite direction is known as the trailing hemisphere.|$|E
5|$|Meanwhile, Coach Taylor {{attempts}} to win {{games with the}} Panthers but <b>faces</b> a number of issues.|$|E
40|$|We {{propose a}} new near-real time {{technique}} for 3 D <b>face</b> pose tracking from a monocular image sequence obtained from an uncalibrated camera. The basic idea behind our {{approach is that}} instead of treating 2 D <b>face</b> detection and 3 D <b>face</b> pose estimation separately, we perform simultaneous 2 D <b>face</b> detection and 3 D <b>face</b> pose tracking. Specifically, 3 D <b>face</b> pose at a time instant is constrained by the <b>face</b> dynamics using Kalman Filtering and by the <b>face</b> appearance in the image. The use of Kalman Filtering limits possible 3 D <b>face</b> poses to a small range while the best matching between the actual <b>face</b> image and the projected <b>face</b> image allows to pinpoint the exact 3 D <b>face</b> pose. <b>Face</b> matching is formulated as an optimization problem so that the exact <b>face</b> location and 3 D <b>face</b> pose can be estimated e#ciently. Another major feature of our approach lies {{in the use of}} active IR illumination, which allows to robustly detect eyes. The detected eyes can in turn constrain the <b>face</b> in the image and regularize the 3 D <b>face</b> pose, therefore the tracking drift issue can be avoided and the processing can speedup. Finally, the <b>face</b> model is dynamically updated to account for variations in <b>face</b> appearances caused by <b>face</b> pose, <b>face</b> expression, illumination and the combination of them. Compared wit...|$|R
2500|$|... 2008 Nadir <b>Face</b> a <b>Face</b> com Einstein/ Nadir <b>Face</b> to <b>Face</b> with Einstein,Chaves Ferreira Publicações, Lisbon.|$|R
5000|$|There are {{basically}} {{three types of}} <b>facing.</b> 1. Shaped <b>facing</b> 2. Extended <b>facing</b> 3. Bias <b>facing</b> ...|$|R
5|$|Only {{the most}} highly skilled Chacoans shaped and set stone; others carried {{supplies}} and mixed mortar. The width of a given wall was determined by its place in a structure. The first story of a two-story wall is always wider than the second. Chacoan walls are often called core-and-veneer, but only the widest walls had cores. The Chacoans tried to build walls with two flush <b>faces,</b> but because the stones were typically quite small, to build a wider wall they built up a space between the two faces; this spacing is often called the core. In most walls, the core consisted of roughly shaped stone or rubble laid {{at the same time}} as the two <b>faces.</b> In others, the <b>faces</b> were built up independently, and the core packed between them. Chacoan walls derive their stability from the degree of contact between stones in the <b>faces</b> and the width of the wall itself, not from the strength of the core.|$|E
5|$|Structure E3 is {{a square}} altar {{in the middle}} of the Group E plaza. It <b>faces</b> towards Pyramid E1.|$|E
5|$|The Clal Center {{is located}} in Jerusalem, Israel, at the southeastern corner of Jaffa Road and Kiah Street, one block east of the Mahane Yehuda Market. Its {{northern}} facade <b>faces</b> Jaffa Road and Davidka Square and its southern facade <b>faces</b> Agrippas Street. The building has several entrances opening onto Jaffa Road, Kiah Street, and Agrippas Street, {{as well as an}} underground parking garage accessible from Kiah Street.|$|E
40|$|Abstract. Recent year, {{the method}} based on <b>face</b> {{verification}} {{has been one}} of the most vibrant study aspect in <b>face</b> verification field. The problem of <b>face</b> verification can be defined: imputing the picture or video, identifying or validating by using <b>face</b> database. “video-video ” <b>face</b> verification means inputting video setting, verification by using <b>face</b> video data。It has most useful information, including: a lots of pictures of one person, continuity of <b>face</b> in time and space in video, three dimension <b>face</b> model etc. 1. PCA <b>face</b> verification Recent year, the method based on <b>face</b> verification {{has been one of}} the most vibrant study aspect in <b>face</b> verification field. The problem of <b>face</b> verification can be defined: imputing the picture or video, identifying or validating by using <b>face</b> database. “video-video ” <b>face</b> verification means inputing video setting, verification by using <b>face</b> video data。It has most useful information, including: a lots of pictures of one person, continuity of <b>face</b> in time and space in video, three dimension <b>face</b> model etc. The way that <b>face</b> information be described in video in present literature can be summarized as follows: vector、matrix probability 、 dynamic model 、fashion. daopting modes of probabilit...|$|R
50|$|The {{silhouette}} edge(s) {{consist of}} all edges separating a front <b>facing</b> <b>face</b> from a back <b>facing</b> <b>face.</b>|$|R
30|$|Changes in {{lighting}} conditions mainly lead {{to changes}} in the brightness and contrast of the <b>face</b> image. After the <b>face</b> image is transformed, the low-frequency <b>face</b> image and the high-frequency <b>face</b> image are obtained. In order to more accurately analyze the influence of illumination on the <b>face</b> image, the low-frequency <b>face</b> image and the high-frequency <b>face</b> image are processed separately. The high-frequency component of the <b>face</b> image represents detailed information such as texture and edge, and the high-frequency information of the <b>face</b> image is mainly reflected in the position of the eyes, the nose, the lips, the mouth, the wrinkles of the <b>face,</b> and the skin color changes. When the brightness and contrast of the <b>face</b> are changed, the low-frequency components of the <b>face</b> change and the high-frequency components change a little. Therefore, when the illumination causes the grayscale of the <b>face</b> image to change, the high-frequency <b>face</b> image is basically unaffected, mainly affecting the low-frequency <b>face</b> image. The <b>face</b> image is transformed by the wavelet transform multi-resolution feature to realize the separate processing of the low-frequency component and the high-frequency component of the <b>face</b> image, so that the <b>face</b> image not only contains useful information of <b>face</b> recognition but also avoids the influence of illumination.|$|R
5|$|The clock <b>faces</b> on {{the tower}} were {{added in the}} 1920s, {{possibly}} around the time the carillon was added. The 1897 image of the city hall above shows the tower without the clock <b>faces</b> (though the stonework shows obvious intent to have clock <b>faces</b> installed). City hall {{was added to the}} National Register of Historic Places on September 4, 1972.|$|E
5|$|The {{main body}} of the fort {{consisted}} of a diamond-shaped structure made up of two flanks and two <b>faces.</b> The two <b>faces</b> and the right flank originally had embrasures, but they were dismantled in the late 19th century by the British. A blockhouse, with courtyards on either side, was located in the centre of the fort.|$|E
5|$|The player then <b>faces</b> {{a choice}} to {{determine}} {{the fate of the}} Mojave Wasteland.|$|E
40|$|<b>Face</b> {{recognition}} {{systems have}} been widely used in various security applications, for example in attendance system. The success of <b>face</b> recognition system relies on the trained <b>face</b> images as well as the <b>face</b> image captured that being recognized. Among the variables that determine the success of <b>face</b> recognition is <b>face</b> pose. Previous works showed that frontal <b>face</b> pose produced the best <b>face</b> recognition success rate. This paper proposes a <b>face</b> pose tracking subsystem that {{can be used as a}} filter so that only the frontal <b>face</b> pose that will be processed in the <b>face</b> recognition subsystem. The criteria for various <b>face</b> poses, i. e. frontal, tilted and turned, either left or right, have been formulated. Experimental results showed that the success rate of <b>face</b> recognition by implementing frontal <b>face</b> pose tracking can improve by 70. 5 %. However, it has trade off in reduced <b>face</b> image capture speed from 61 images per minute to 10 images per minute...|$|R
40|$|Abstract — <b>Face</b> {{recognition}} {{systems have}} been widely used in various security applications, for example in attendance system. The success of <b>face</b> recognition system relies on the trained <b>face</b> images as well as the <b>face</b> image captured that being recognized. Among the variables that determine the success of <b>face</b> recognition is <b>face</b> pose. Previous works showed that frontal <b>face</b> pose produced the best <b>face</b> recognition success rate. This paper proposes a <b>face</b> pose tracking subsystem that {{can be used as a}} filter so that only the frontal <b>face</b> pose that will be processed in the <b>face</b> recognition subsystem. The criteria for various <b>face</b> poses, i. e. frontal, tilted and turned, either left or right, have been formulated. Experimental results showed that the success rate of <b>face</b> recognition b...|$|R
50|$|<b>Face</b> to <b>Face</b> is the 1996 self-titled third studio album by the California punk band <b>Face</b> to <b>Face.</b>|$|R
