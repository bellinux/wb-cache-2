49|45|Public
5|$|Videos with {{progressive}} scanning or <b>interlaced</b> <b>scanning</b> can be uploaded, but for {{the best}} video quality, YouTube suggests interlaced videos be deinterlaced before uploading. All the video formats on YouTube use progressive scanning. YouTube's statistics shows that interlaced videos are still being uploaded to YouTube, {{and there is no}} sign of that actually dwindling. YouTube attributes this to uploading of made-for-TV content.|$|E
25|$|The FCC adopted NTSC {{television}} engineering {{standards on}} May 2, 1941, calling for 525 lines of vertical resolution, 30 {{frames per second}} with <b>interlaced</b> <b>scanning,</b> 60 fields per second, and sound carried by frequency modulation. Sets sold since 1939 that were built for slightly lower resolution could still be adjusted to receive the new standard. (Dunlap, p31). The FCC saw television ready for commercial licensing, and the first such licenses were issued to NBC- and CBS-owned stations in New York on July 1, 1941, followed by Philco's station WPTZ in Philadelphia.|$|E
2500|$|The final {{standard}} {{adopted by}} the FCC did not require a single standard for scanning formats, aspect ratios, or lines of resolution. This outcome resulted from a dispute between the consumer electronics industry (joined by some broadcasters) and the computer industry (joined by the film industry and some public interest groups) over {{which of the two}} scanning processes—interlaced or progressive—is superior. <b>Interlaced</b> <b>scanning,</b> which is used in televisions worldwide, scans even-numbered lines first, then odd-numbered ones. Progressive scanning, which is the format used in computers, scans lines in sequences, from top to bottom. The computer industry argued that progressive scanning is superior because it does not [...] "flicker" [...] in the manner of <b>interlaced</b> <b>scanning.</b> It also argued that progressive scanning enables easier connections with the Internet, and is more cheaply converted to interlaced formats than vice versa. The film industry also supported progressive scanning because it offers a more efficient means of converting filmed programming into digital formats. For their part, the consumer electronics industry and broadcasters argued that <b>interlaced</b> <b>scanning</b> was the only technology that could transmit the highest quality pictures then feasible, that is, 1080 lines per picture and 1920 pixels per line. William F. Schreiber, who was a director of the Advanced Television Research Program at the Massachusetts Institute of Technology from 1983 until his retirement in 1990, thought that the continued advocacy of interlaced equipment originated from consumer electronics companies that were trying to get back the substantial investments they made in the interlaced technology.|$|E
40|$|The {{advantages}} of sequential over <b>interlaced</b> <b>scan</b> for {{any type of}} digital processing are well known but its penalty is the doubled bandwidth. A sequential 4 -channel camera, which avoids this penalty, is presented and the three camera types-interlaced, sequential, 4 -channel-are compared with regard to temporal and spatial resolution...|$|R
50|$|ABS-CBN HD is {{a digital}} high-definition feed of ABS-CBN. It was {{launched}} on October 3, 2015 initially on Sky Cable and Destiny Cable HD digital subscribers {{and later on}} I Want TV, Sky On Demand, and Sky Direct. Its resolution is 1080i (1,920x1,080 pixels <b>interlaced</b> <b>scan</b> and aspect ratio of 16:9) at 30 fields per second.|$|R
50|$|The lower resolutions {{can operate}} either in {{progressive}} <b>scan</b> or <b>interlaced</b> mode, {{but not the}} largest picture sizes. The 1080-line system does not support progressive images at the highest frame rates of 50, 59.94 or 60 frames per second, because such technology was seen as too advanced at the time. The standard also requires 720-line video be progressive scan, since that provides better picture quality than <b>interlaced</b> <b>scan</b> at a given frame rate, {{and there was no}} legacy use of <b>interlaced</b> <b>scan</b> for that format. The result is that the combination of maximum frame rate and picture size results in the same maximum number of samples per second for both the 1080-line interlaced format and the 720-line format, as 1980*1080*30 is equal to 1280*720*60. A similar equality relationship applies for 576 lines at 25 frame per second versus 480 lines at 30 frames per second.|$|R
5000|$|The {{scanning}} system: progressive scanning (p) or <b>interlaced</b> <b>scanning</b> (i). Progressive scanning (p) redraws {{an image}} frame (all of its lines) when refreshing each image, for example 720p/1080p. <b>Interlaced</b> <b>scanning</b> (i) draws the image field every other line or [...] "odd numbered" [...] lines {{during the first}} image refresh operation, and then draws the remaining [...] "even numbered" [...] lines during a second refreshing, for example 1080i. <b>Interlaced</b> <b>scanning</b> yields greater image resolution if subject is not moving, but loses {{up to half of}} the resolution and suffers [...] "combing" [...] artifacts when subject is moving.|$|E
5000|$|Scanning {{system is}} {{identified}} with the letter p for progressive scanning or i for <b>interlaced</b> <b>scanning.</b>|$|E
5000|$|Note: 1 Image {{is either}} a frame or, in case of <b>interlaced</b> <b>scanning,</b> two fields. (EVEN and ODD) ...|$|E
5000|$|<b>Interlaced</b> <b>scan</b> {{refers to}} one of two common methods for [...] "painting" [...] a video image on an {{electronic}} display screen (the other being progressive scan) by scanning or displaying each line or row of pixels. This technique uses two fields to create a frame. One field contains all odd-numbered lines in the image; the other contains all even-numbered lines.|$|R
50|$|Progressive scan captures, transmits, and {{displays}} an image in a path similar to text on a page—line by line, top to bottom.The <b>interlaced</b> <b>scan</b> pattern in a CRT display also completes such a scan, but in two passes (two fields). The first pass displays {{the first and}} all odd numbered lines, from the top left corner to the bottom right corner. The second pass displays the second and all even numbered lines, filling in the gaps in the first scan.|$|R
5000|$|IDTV {{improvements}} {{may be made}} at {{the television}} transmitter or receiver. Improvements include enhancements in encoding, digital filtering, <b>scan</b> interpolation, <b>interlaced</b> line <b>scanning,</b> and ghost cancellation.|$|R
5000|$|The final {{standard}} {{adopted by}} the FCC did not require a single standard for scanning formats, aspect ratios, or lines of resolution. This outcome resulted from a dispute between the consumer electronics industry (joined by some broadcasters) and the computer industry (joined by the film industry and some public interest groups) over {{which of the two}} scanning processes—interlaced or progressive—is superior. <b>Interlaced</b> <b>scanning,</b> which is used in televisions worldwide, scans even-numbered lines first, then odd-numbered ones. Progressive scanning, which is the format used in computers, scans lines in sequences, from top to bottom. The computer industry argued that progressive scanning is superior because it does not [...] "flicker" [...] in the manner of <b>interlaced</b> <b>scanning.</b> It also argued that progressive scanning enables easier connections with the Internet, and is more cheaply converted to interlaced formats than vice versa. The film industry also supported progressive scanning because it offers a more efficient means of converting filmed programming into digital formats. For their part, the consumer electronics industry and broadcasters argued that <b>interlaced</b> <b>scanning</b> was the only technology that could transmit the highest quality pictures then (and currently) feasible, i.e., 1,080 lines per picture and 1,920 pixels per line. Broadcasters also favored <b>interlaced</b> <b>scanning</b> because their vast archive of interlaced programming is not readily compatible with a progressive format.|$|E
50|$|For example, 1920×1080p25 {{identifies}} progressive scanning format with 25 frames per second, each frame being 1,920 pixels {{wide and}} 1,080 pixels high. The 1080i25 or 1080i50 notation identifies <b>interlaced</b> <b>scanning</b> format with 25 frames (50 fields) per second, each frame being 1,920 pixels wide and 1,080 pixels high. The 1080i30 or 1080i60 notation identifies <b>interlaced</b> <b>scanning</b> format with 30 frames (60 fields) per second, each frame being 1,920 pixels wide and 1,080 pixels high. The 720p60 notation identifies progressive scanning format with 60 frames per second, each frame being 720 pixels high; 1,280 pixels horizontally are implied.|$|E
5000|$|Progressive scanning, {{the format}} that the {{computer}} industry had long adopted for computer display monitors, scans every line in sequence, from top to bottom. Progressive scanning in effect doubles the amount of data generated for every full screen displayed in comparison to <b>interlaced</b> <b>scanning</b> by painting the screen in one pass in 1/60-second, instead of two passes in 1/30-second. The computer industry argued that progressive scanning is superior {{because it does not}} [...] "flicker" [...] on the new standard of display devices in the manner of <b>interlaced</b> <b>scanning.</b> It also argued that progressive scanning enables easier connections with the Internet, and is more cheaply converted to interlaced formats than vice versa. The film industry also supported progressive scanning because it offered a more efficient means of converting filmed programming into digital formats. For their part, the consumer electronics industry and broadcasters argued that <b>interlaced</b> <b>scanning</b> was the only technology that could transmit the highest quality pictures then (and currently) feasible, i.e., 1,080 lines per picture and 1,920 pixels per line. Broadcasters also favored <b>interlaced</b> <b>scanning</b> because their vast archive of interlaced programming is not readily compatible with a progressive format. William F. Schreiber, who was director of the Advanced Television Research Program at the Massachusetts Institute of Technology from 1983 until his retirement in 1990, thought that the continued advocacy of interlaced equipment originated from consumer electronics companies that were trying to get back the substantial investments they made in the interlaced technology.|$|E
50|$|Historically, video frames were {{represented}} as analog waveforms in which varying voltages represented {{the intensity of}} light in an analog raster scan across the screen. Analog blanking intervals separated video frames {{in the same way}} that frame lines did in film. For historical reasons, most systems used an <b>interlaced</b> <b>scan</b> system in which the frame typically consisted of two video fields sampled over two slightly different periods of time. This meant that a single video frame was usually not a good still picture of the scene, unless the scene being shot was completely still.|$|R
50|$|Note: Because the {{refresh rate}} has been slowed {{down by a}} factor of three, and the {{resolution}} is less than half a resolution of a typical interlaced video, the flicker in the simulated interlaced portions and also the visibility of the black lines in these examples are exaggerated. Also, the images above are based on what it would look like on a monitor that does not support <b>interlaced</b> <b>scan,</b> such as a PC monitor or an LCD or plasma-based television set, with the interlaced images displayed using the same mode as the progressive images.|$|R
40|$|This thesis {{presents}} a CMOS image sensor which can implement the charge domain interlacing principle. Inspired by the shared amplifier pixel structure {{and based on}} a pinned photodiode four transistor (4 T) structure, two innovative pixel designs combined with two different readout directions are presented. These novel pixels are designed to fit the charge domain interlacing principle, which used the charge binning technology in the field integration mode of <b>interlaced</b> <b>scan</b> to improve the signal-to-noise ratio of the sensor. To realize this working principle and compared it with other working modes, a programmable universal image sensor peripheral circuit is designed for controlling and driving the pixel array in the most flexible and most efficient way. As a result, the designed sensor can be used {{not only in the}} progressive scan mode, frame integration <b>interlaced</b> <b>scan,</b> and voltage domain interlacing mode but also in the charge domain interlacing mode. This is a very unique feature for CMOS image sensors, and without the shared pixel concept, charge domain interlacing was only possible with CCDs. The proposed image sensor is implemented in TSMC 0. 18 um 1 P 6 M CMOS technology. Some preliminary measurement results of the chip are shown to prove the functional correctness of the image sensor. Microelectronics & Computer EngineeringElectrical Engineering, Mathematics and Computer Scienc...|$|R
50|$|The final {{standards}} {{adopted by}} the FCC did not require a single standard for scanning formats, aspect ratios, or lines of resolution. This compromise resulted from a dispute between the consumer electronics industry (joined by some broadcasters) and the computer industry (joined by the film industry and some public interest groups) over {{which of the two}} scanning processes—interlaced or progressive—would be best suited for the newer digital HDTV compatible display devices. <b>Interlaced</b> <b>scanning,</b> which had been specifically designed for older analogue CRT display technologies, scans even-numbered lines first, then odd-numbered ones. In fact, <b>interlaced</b> <b>scanning</b> can be looked at as the first video compression model as it was partly designed in the 1940s to double the image resolution to exceed the limitations of the television broadcast bandwidth. Another reason for its adoption was to limit the flickering on early CRT screens whose phosphor coated screens could only retain the image from the electron scanning gun for a relatively short duration. However <b>interlaced</b> <b>scanning</b> does not work as efficiently on newer display devices such as Liquid-crystal (LCD), for example, which are better suited to a more frequent progressive refresh rate.|$|E
50|$|The term {{refers to}} devices capable of {{displaying}} 480-line or 576-line signals in progressive scan, {{commonly referred to}} as 480p (NTSC-HQ) and 576p (PAL) respectively, as opposed to <b>interlaced</b> <b>scanning,</b> {{commonly referred to as}} 480i (NTSC) or 576i (PAL). High-motion is optional for EDTV.|$|E
50|$|HiDef (short {{for high}} definition), also called 24p, is a 24 frames-per-second digital video format for {{high-resolution}} capture of motion pictures. The 24 {{refers to the}} frame rate (24 frames/second) and the p stands for progressive scanning (as opposed to <b>interlaced</b> <b>scanning).</b> As of 2003, there are two 24p HD formats: Sony 24p and Panasonic 24p.|$|E
50|$|Panasonic AVCHD camcorders offer <b>interlaced,</b> {{progressive}} <b>scan</b> or native progressive {{recording and}} combinations of these modes depending {{on a particular}} model. 1080-line and 720-line recording is possible depending on a model.|$|R
40|$|When <b>interlaced</b> <b>scan</b> (IS) is {{used for}} {{television}} transmission, the received video must be deinterlaced to be displayed on progressive scan (PS) displays. To achieve good performance, the deinterlacing operation is typically computationally expensive. We propose a receiver compatible approach which performs a deinterlacing operation inexpensively, with good performance. At the transmitter, the system analyzes the video and transmits an additional low bit-rate stream. Existing receivers ignore this information. New receivers utilize this stream and perform a deinterlacing operation inexpensively with good performance. Results indicate that this approach can improve the digital television standard in a receiver compatible manner...|$|R
5000|$|... 7561 VDUs were memory-mapped display monitors, and not character-based terminals. The tube {{phosphor}} was green in colour. The keyboards were separate input/output devices whose data was decoded by the operating software {{to update the}} screen display or trigger actions by the system. Security identifiers (Personal Identity Device, or PID) based on magnetically coded pens with a reader at the top {{right corner of the}} keyboard unit could be used to provide levels of access-privilege to users. Early 7561/1 VDUs had simple composite-video inputs, while the updated 7561/2 VDU had improved display tubes and <b>interlaced</b> <b>scan.</b> The native screen resolution was 25 lines of 80 characters, but there were options for a 960-character display format.|$|R
5000|$|Alternate {{lighting}} of surfaces (ALiS) is type of plasma display technology jointly developed by Fujitsu and Hitachi in 1999. Alternate {{lighting of}} surfaces uses an <b>interlaced</b> <b>scanning</b> method {{rather than a}} progressive one. This technique allows native lower resolution plasma display panels to display at higher resolutions. This technique also helps in prolonging panel life and power consumption reductions.|$|E
50|$|PsF is {{utilized}} in some DV, HDV and AVCHD camcorders for 25-frame/s and 30-frame/s progressive-scan recording. To achieve this, the camera acquires 30 (NTSC) or 25 (PAL) independent images per second. These images are output as 60 (NTSC) or 50 (PAL) interlaced fields. The {{result is a}} progressive-scan content, which is compatible with traditional <b>interlaced</b> <b>scanning</b> systems.|$|E
50|$|Videos with {{progressive}} scanning or <b>interlaced</b> <b>scanning</b> can be uploaded, but for {{the best}} video quality, YouTube suggests interlaced videos be deinterlaced before uploading. All the video formats on YouTube use progressive scanning. YouTube's statistics shows that interlaced videos are still being uploaded to YouTube, {{and there is no}} sign of that actually dwindling. YouTube attributes this to uploading of made-for-TV content.|$|E
50|$|The {{problem with}} flying-spot {{scanners}} {{was the difference}} in frequencies between television field rates and film frame rates. This was solved first by the Mk. I Polygonal Prism system, which was optically synchronised to the television frame rate by the rotating prism and could be run at any frame rate. This {{was replaced by the}} Mk. II Twin Lens, and then around 1975, by the Mk. III Hopping Patch (jump scan). The Mk. III series progressed from the original “jump scan” <b>interlace</b> <b>scan</b> to the Mk. IIIB which used a progressive scan and included a digital scan converter (Digiscan) to output interlaced video. The Mk. IIIC was the most popular of the series and used a next generation Digiscan plus other improvements.|$|R
50|$|This rough {{animation}} compares progressive <b>scan</b> with <b>interlace</b> <b>scan,</b> also {{demonstrating the}} interline twitter effect associated with interlacing. On the left {{there are two}} progressive scan images. In the middle there are two interlaced images and on the right there are two images with line doublers. The original resolutions are above and the ones with spatial anti-aliasing are below. The interlaced images use half the bandwidth of the progressive ones. The images in the center column precisely duplicate the pixels of {{the ones on the}} left, but interlacing causes details to twitter. Real interlaced video blurs such details to prevent twittering, but as seen in the pictures of the lower row, such softening (or anti-aliasing) comes at the cost of image clarity. A line doubler shown in the bottom center picture cannot restore the previously interlaced image to the full quality of the progressive image shown in the top left one.|$|R
40|$|Video signals can be {{interlaced}} or noninterlaced. The <b>interlaced</b> <b>scan</b> format su#ers {{from several}} possible artifacts such as flicker, twitter, and crawling. De-interlacing algorithms convert an interlaced video {{signal to the}} progressive scan format by interpolating the missing lines. These algorithms {{can be used to}} improve picture quality, but can also be necessary to use interlaced video on progressive devices such as LCD displays or video printers. Motion adaptive techniques are not as complex as motion compensating methods but are cheaper to implement in hardware. Still they can improve the quality of the de-interlaced video signal very much if they adapt properly to the presence of motion. This paper presents a motion adaptive de-interlacing technique using a novel fuzzy-based motion detector. Several di#erence signals are combined by a fuzzy logic controller to produce a useful indication of the presence of motion. This value is then used to combine two di#erent methods: a spatial [...] ...|$|R
5000|$|Some {{players have}} a feature called [...] "3:2 {{pulldown}} detection" [...] or [...] "inverse telecine" [...] which attempts to better handle the artifacts which result from differing {{film and video}} rates in conjunction with <b>interlaced</b> <b>scanning</b> of the film. However most line doublers used in these players {{are not able to}} achieve the anticipated inverse telecine functionality, refer to line doubler for details.|$|E
5000|$|The final {{standard}} {{adopted by}} the FCC did not require a single standard for scanning formats, aspect ratios, or lines of resolution. This outcome resulted from a dispute between the consumer electronics industry (joined by some broadcasters) and the computer industry (joined by the film industry and some public interest groups) over {{which of the two}} scanning processes—interlaced or progressive—is superior. <b>Interlaced</b> <b>scanning,</b> which is used in televisions worldwide, scans even-numbered lines first, then odd-numbered ones. Progressive scanning, which is the format used in computers, scans lines in sequences, from top to bottom. The computer industry argued that progressive scanning is superior because it does not [...] "flicker" [...] in the manner of <b>interlaced</b> <b>scanning.</b> It also argued that progressive scanning enables easier connections with the Internet, and is more cheaply converted to interlaced formats than vice versa. The film industry also supported progressive scanning because it offers a more efficient means of converting filmed programming into digital formats. For their part, the consumer electronics industry and broadcasters argued that <b>interlaced</b> <b>scanning</b> was the only technology that could transmit the highest quality pictures then feasible, that is, 1080 lines per picture and 1920 pixels per line. William F. Schreiber, who was a director of the Advanced Television Research Program at the Massachusetts Institute of Technology from 1983 until his retirement in 1990, thought that the continued advocacy of interlaced equipment originated from consumer electronics companies that were trying to get back the substantial investments they made in the interlaced technology.|$|E
50|$|Moiré {{patterns}} are commonly {{seen on television}} screens {{when a person is}} wearing a shirt or jacket of a particular weave or pattern, such as a houndstooth jacket. This is due to <b>interlaced</b> <b>scanning</b> in televisions and non-film cameras, referred to as interline twitter. As the person moves about, the Moiré pattern is quite noticeable. Because of this, newscasters and other professionals who appear on TV regularly are instructed to avoid clothing which could cause the effect.|$|E
50|$|Many {{personal}} computers {{introduced in the}} late 1970s and the 1980s were designed to use television receivers as their display devices, making the resolutions dependent on the television standards in use, including PAL and NTSC. Picture sizes were usually limited to ensure the visibility of all the pixels in the major television standards and {{the broad range of}} television sets with varying amounts of over scan. The actual drawable picture area was, therefore, somewhat smaller than the whole screen, and was usually surrounded by a static-colored border (see image to right). Also, the <b>interlace</b> <b>scanning</b> was usually omitted in order to provide more stability to the picture, effectively halving the vertical resolution in progress. 160 × 200, 320 × 200 and 640 × 200 on NTSC were relatively common resolutions in the era (224, 240 or 256 scanlines were also common). In the IBM PC world, these resolutions came to be used by 16-color EGA video cards.|$|R
5000|$|... {{decoupling}} physical scan {{lines from}} the 'logical' lines. The repeat count of physical scan lines could be 0 to 15 per line (Due to <b>interlacing</b> a physical <b>scan</b> was two pixels high), ...|$|R
40|$|Bluetooth devices {{on board}} of traffic objects depict {{an easy way}} of {{detecting}} motions of persons and goods. However, the precondition is that one Bluetooth device (the observer) discovers another Bluetooth device - namely the on board device - within {{a very short time}} range. Device discovery in case of Bluetooth connection establishment is heavily dependent from the so called inquiry process which allows Bluetooth devices to look for each other and to exchange relevant information to build up a lasting connection. In this paper we give an analytical model of the time it takes a Bluetooth-based moving observer to discover a Bluetooth device within a floating traffic object by considering the specific behaviour of the inquiry procedure. Therefore, the analytical model refers to the inquiry process described in the official Bluetooth standard protocol version 1. 2 and thus includes a specific mode - named <b>interlaced</b> <b>scan</b> mode-which was introduced to speed up discovery times. We show that, taking that kind of mode into account gives more reasonable results in terms of reflecting practical measurements by means of simulations. As a result, we can much better describe the observers behaviour concerning the probability of the first detection...|$|R
