2|4588|Public
40|$|The hybrid {{coding scheme}} is {{employed}} in all established coding standards. A <b>forward</b> <b>motion</b> <b>vector</b> field is estimated and applied for motion compensation. The remaining prediction error and the motion vectors are {{transmitted to the}} decoder. The discrete cosine transform is used for transform coding of the prediction error. The extension of this coding scheme to scalability is not easily achieved {{and the performance of}} standard video coders when using scalability options can often be reduced to the performance of simulcast coding...|$|E
40|$|We present several compressed-domain {{methods for}} reverse-play {{transcoding}} of MPEG video streams. A reverse-play transcoder takes any original MPEG IPB bitstream as input and creates an output MPEG IPB bitstream which, when decoded by a generic MPEG decoder, dis plays the original video frames in reverse order. A baseline spatial-domain method requires decoding the MPEG bitstream, storing and reordering the decoded video frames, and re-encoding the reordered video. The proposed compressed-domain transcoding methods achieve {{an order of}} magnitude reduction in computational complexity over the baseline spatial-domain approach. Much of the savings are achieved by using the <b>forward</b> <b>motion</b> <b>vector</b> fields available in the forward-play MPEG bitstream to efficiently generate the reverse motion vector fields used in the reverse-play MPEG bitstream. Furthermore, the storage requirements of the compressed-domain methods are reduced and the resulting image quality is within 0. 6 dB of the baseline spatial-domain approach for a difficult highly detailed computer-generated video sequence. For more typical video sequences, the resulting image quality is even closer to the baseline spatial-domain approach...|$|E
3000|$|... {{estimates}} {{the reliability of}} the <b>motion</b> <b>vectors</b> at each point by measuring the similarity of the backward and <b>forward</b> <b>motion</b> <b>vectors</b> and the difference in pixel intensities at the estimated displacements.|$|R
30|$|We {{assume that}} the motion {{trajectory}} is linear; so, the obtained <b>forward</b> <b>motion</b> <b>vectors</b> (MVs) are split into backward (MVB) and <b>forward</b> (MVF) <b>motion</b> <b>vector</b> fields for the current field f_n. As a block in f_n could have zero or more than one MVs passing through, the corresponding MV_n for the block b_n ∈ f_n is obtained by the minimization of the Euclidean distance between b_n’s center, (y_n, 0,x_n, 0), and the passing vectors MVs. In our minimization, we consider only the MVs obtained for the blocks {{in the neighborhood of}} the collocated block b_n- 1 in the left field f_n- 1 (thus, a total of nine MVs, obtained for b_n- 1 and the blocks adjacent to b_n- 1 ∈ f_n- 1, as these MVs are supposed to be the most correlated to the one in the current block, e.g., belonging to the same motion object).|$|R
40|$|Filtering (MCTF) technique, {{especially}} with the adaptive 5 / 3 wavelet kernel, efficiently exploits the temporal correlation among neighboring pictures. It can be achieved alternatively by the hierarchical B picture coding technique with the same decomposition as the temporal 5 / 3 lifting structure but without update step. This technique has been supported by H. 264 /AVC [1] with stored B technique. The performance of hierarchical B obviously outperforms that of the conventional IBBP…GOP structure. Direct mode which derives <b>motion</b> <b>vectors</b> from the colocated block of backward reference and does not require any bits for coding <b>motion</b> <b>vectors</b> is a very efficient bi-prediction technique for B pictures coding. Considering that the <b>forward</b> <b>motion</b> <b>vectors</b> in the backward reference is not available when it belongs to block only with backward <b>motion</b> <b>vector,</b> in this paper, we propose an extended direct mode for hierarchical B picture coding to further improve the accuracy of derived <b>motion</b> <b>vectors.</b> It effectively utilizes the <b>forward</b> and backward <b>motion</b> <b>vectors</b> of the co-located blocks in references for scaling. Keywords-hierarchical B picture; extended direct mode I...|$|R
40|$|A known {{problem in}} video {{streaming}} is that {{loss of a}} packet usually results into loss of a whole video frame. In this paper we propose an error concealment algorithm specifically designed to handle this sort of losses. The technique exploits information in a few past frames (namely the <b>motion</b> <b>vectors)</b> in order to estimate the <b>forward</b> <b>motion</b> <b>vectors</b> of the last received frame. This information is used to project the last frame onto {{an estimate of the}} missing frame. The algorithm has been tested on MPEG- 2 video, providing very satisfactory results, and outperforming by several dBs in PSNR the concealment technique based on repetition of the last received frame...|$|R
40|$|Distributed {{source coding}} theory has long promised a new method of {{encoding}} video {{that is much}} lower in complexity than conventional methods. In the distributed framework, the decoder is tasked with exploiting the redundancy of the video signal. Among the difficulties in realizing a practical codec has been the problem of motion estimation at the decoder. In this paper, we propose a mechanism for unsupervised learning of <b>forward</b> <b>motion</b> <b>vectors</b> during the decoding of a frame with reference to its previous reconstructed frame. The mechanism, described for both pixel-domain and transform-domain coding, is an instance of the Expectation Maximization algorithm. Our experiments indicate that a video codec based on unsupervised motion learning outperforms a codec with zero motion compensation by up to 1. 5 dB. It performs within about 0. 5 dB of a codec that knows the <b>motion</b> <b>vectors</b> through an oracle. Keywords: Wyner-Ziv video coding, Expectation Maximization 1...|$|R
40|$|In this paper, a novel {{algorithm}} for the real-time, unsupervised segmentation {{of image}} sequences in the compressed domain is proposed. The algorithm utilizes the motion information {{present in the}} compressed stream {{in the form of}} P-frame <b>forward</b> <b>motion</b> <b>vectors,</b> as well as basic color information in the form of DC coefficients present in I-frames. An iterative rejection scheme based on the bilinear motion model is used for performing foreground/background segmentation. Further examining the temporal consistency of the output of iterative rejection, clustering to connected regions and performing region tracking, results to foreground spatiotemporal objects being formed. Background segmentation to spatiotemporal objects is also performed. Experimental results on known sequences demonstrate the efficiency of the proposed approach and reveal the potential of employing it in content-based applications such as objectbased video indexing and retrieval...|$|R
40|$|In this work, {{the motion}} {{parameters}} of the bi-directionally predicted pictures (B-pictures) of MPEG- 1, 2 are exploited for concealment of large portions of corrupted anchor pictures that might arise due to channel errors or packet losses. To further {{enhance the quality of}} the concealed anchor pictures, we propose two methods of constraining the <b>motion</b> <b>vectors</b> of the B-pictures that strengthen the tie between them and those of the anchor pictures in the same picture sub-group. In one method, the macroblock decisions on the last B-picture in each sub-group is constrained to be bi-directional if those of the other B-pictures are not, such that the derived <b>motion</b> <b>vectors</b> for the concealment of the anchor picture are always composed from the <b>forward</b> and backward <b>motion</b> <b>vectors</b> of the bi-directional motions. Second, the bi-directional <b>motion</b> <b>vectors</b> of the B-pictures in each sub-group is constrained such that the vectorial sum of their <b>forward</b> and backward <b>motion</b> <b>vectors</b> results in accurate motion prediction of the anchor picture. The experimental results show that while the composed <b>motion</b> <b>vectors</b> improve the quality of concealment over the conventional methods by more than 3 - 4 dB, another 2 dB improvement can be achieved by constraining the generation of the bi-directional <b>motion</b> <b>vectors.</b> * Author for correspondence...|$|R
40|$|A {{compressed}} domain {{generic object}} tracking algorithm offers, {{in combination with}} a face detection algorithm, a low-compu-tational-cost {{solution to the problem}} of detecting and locating faces in frames of compressed video sequences (such as MPEG- 1 or MPEG- 2). Objects such as faces can thus be tracked through a compressed video stream using motion information provided by existing <b>forward</b> and backward <b>motion</b> <b>vectors.</b> The described solution requires only low computational resources on CE devices and offers at one and the same time sufficiently good location rates. </p...|$|R
25|$|Friction. This {{is a force}} always {{opposing}} the <b>forward</b> <b>motion,</b> whereby the <b>vector</b> invariably acts in the negative direction s with an effect to reduce the speed. The friction at play in the balanced-flow models is the one exerted by the roughness of the Earth's surface on the air moving higher above. For simplicity, we here assume that the frictional force (per unit mass) adjusts to the parcel's speed proportionally through a constant coefficient of friction K. In more realistic conditions, the dependence of friction on the speed is non-linear except for slow laminar flows.|$|R
40|$|This thesis {{describes}} {{the implementation of}} a real-time, full search, 16 x 16 bidirectional motion estimation at 24 frames per second with the record performance of 155 Gop/s (1538 ops/pixel) at a high clock rate of 125 MHz. The core of bidirectional motion estimation uses close to 100 % FPGA resources with 7 Gbit/s bandwidth to external memory. The architecture allows extremely controlled, macro level floor-planning with parameterized block size, image size, placement coordinates and data words length. The FPGA chip is part of the board that was developed at the Institute of Computer & Communication Networking Engineering, Technical University Braunschweig Germany, in collaboration with Grass Valley Germany in the FlexFilm research project. The goal of the project was to develop hardware and programming methodologies for real-time digital film image processing. Motion estimation core uses FlexWAFE reconfigurable architecture where FPGAs are configured using macro components that consist of weakly programmable address generation units and data stream processing units. Bidirectional motion estimation uses two cores of motion estimation engine (MeEngine) forming main data processing unit for backward and <b>forward</b> <b>motion</b> <b>vectors.</b> The building block of the core of motion estimation is an RPM-macro which represents one processing element and performs 10 -bit difference, a comparison, and 19 -bit accumulation on the input pixel streams. In order to maximize the throughput between elements, the processing element is replicated and precisely placed side-by-side by using four hierarchal levels, where each level is a very compact entity with its own local control and placement methodology. The achieved speed was further improved by regularly inserting pipeline stages in the processing chain...|$|R
30|$|The {{compression}} {{efficiency of}} DVC depends strongly on {{the correlation between}} the SI and the actual WZ frame. The SI is commonly generated by linear interpolation of the motion field between successive previously decoded frames. While the linear motion assumption holds for sequences with simple motion, the coding performance drops for more complex sequences. In [21, 22], spatial smoothing and refinement of the <b>motion</b> <b>vectors</b> is carried out. By removing some discontinuities and outliers in the motion field, it leads to better prediction. In the same way, in [23], two SIs are generated by extrapolation of the previous and next key frames, respectively, using <b>forward</b> and backward <b>motion</b> <b>vectors.</b> Then, the decoding process makes use of both SI concurrently. Subpixel accuracy, similar to the method in H. 264 /AVC, is proposed in [24] in order to further improve motion estimation for SI generation.|$|R
40|$|A {{method and}} an {{apparatus}} for processing occlusions in motion estimation are described. For processing an occlusion in a <b>forward</b> <b>motion</b> field {{of a second}} frame relative to a first frame the <b>forward</b> <b>motion</b> field of the second frame relative to the first frame is determined with a motion estimator. Then an area in the second frame that is occluded in the first frame is identified with an occlusion identifier. Finally, a motion corrector determines a corrected <b>forward</b> <b>motion</b> field by filling the <b>forward</b> <b>motion</b> field in the identified area in the second frame using <b>motion</b> <b>vectors</b> of a previous backward motion field of the second frame relative to a previous third frame...|$|R
40|$|Abstract — In {{multimedia}} communication video plays an importance, {{because it gives}} the very perfect flow of frames or image for our visual effect with good realistic view experience. So in this paper gives a new low complexity true motion estimation technique is introduced for video processing application, like motion-compensated temporal frame rate up conversion (MCTFRUC) or motion compensated temporal frame interpolation (MCTFI). In basically main role of motion estimation is to produce the <b>motion</b> <b>vectors</b> for reduce the temporal redundancy. Where as in this paper explains true motion estimation which is mainly used to track the motioned object {{as closely as possible}} by imposing the explicit and/or implicit smoothness constraints on block matching algorithm. To get the good interpolated frames the dense <b>motion</b> <b>vector</b> field is obtained for both <b>forward</b> and backward <b>motion</b> <b>vectors</b> is applied by adding both. Then the performance parameter is calculated and is produced, at last the good quality of video frame is produced with smoothly. Key words: frame rate up conversion, frame interpolation, motion estimation, true motion, clustering, video processing, and motion compensated temporal frame interpolation (MCTFI), structural similarity(SSIM),peak signal to noise ratio(PSNR). I...|$|R
3000|$|... [...]. Thus, a <b>forward</b> {{translational}} <b>motion</b> {{field is}} obtained {{to provide the}} starting point for the forward perspective transform search performed in step 6. Note that some of the <b>motion</b> <b>vectors</b> obtained in this step are not correlated in any way with the <b>motion</b> <b>vectors</b> from step 1, especially when occlusions or illumination changes occur, thus justifying the adoption of both the forward ME and backward ME steps.|$|R
40|$|AbstractThe side {{information}} quality has an immense {{effect on the}} compression efficiency of the distributed video coding (DVC) system. This article, based on the hierarchical motion estimation (HME), proposes a new {{side information}} generation algorithm which is integrated into DVC system. First, <b>forward</b> <b>motion</b> estimation (FME) and bidirectional motion estimation (BME) {{on the basis of}} variable block size HME algorithm are used to acquire relatively accurate <b>motion</b> <b>vectors.</b> Second, a <b>motion</b> <b>vector</b> filter (MVF) is introduced to correct the false estimated <b>motion</b> <b>vectors</b> caused by partial similarity in the video sequences. Finally, a decision mechanism is adopted to handle the overlapped areas in the interpolated frame. The simulation shows that the DVC system associated with the proposed side information generation algorithm can achieve a gain as much as 3 - 4 dB higher than conventional video coding of INTRA mode and only 0. 5 - 1. 0 dB less than that of IBIB mode...|$|R
40|$|A motion {{estimation}} unit (500) for estimating a current <b>motion</b> <b>vector</b> comprises a match error unit (506) for calculating match errors of respective candidate <b>motion</b> <b>vectors</b> and a selector (508) for selecting the current <b>motion</b> <b>vector</b> from the candidate <b>motion</b> <b>vectors</b> {{by means of}} comparing the match errors of the respective candidate <b>motion</b> <b>vectors.</b> Some of the candidate <b>motion</b> <b>vectors</b> are extracted from a set of previously estimated <b>motion</b> <b>vectors.</b> Other candidate <b>motion</b> <b>vectors</b> are calculated based on multiple <b>motion</b> <b>vectors</b> which are selected from the set of previously estimated <b>motion</b> <b>vectors...</b>|$|R
40|$|Abstract The {{proposed}} deinterlacing {{scheme is}} aimed towards high-quality progressive image output, typically for a videotape-to-film blow-up operation. This operation consists in increasing {{the resolution of}} video images, recording these images on 16 mm or 35 mm film and reducing the typical video artefacts (due to interlaced scanning, electronic noise), eventually adding some film-look features (color correction, motion blur, [...] .). This paper focuses on the deinterlacing part. Since video real-time is not relevant for digital blow-up (film recorders are slow), the proposed approach gives more weight to quality for both spatial and temporal characteristics of the image. Each field from the interlaced source is extended to a full frame by using an accurate in-painting process, outstretching edges and preserving their intensity. Motion estimation is then performed from these two inpainted images, and the computed <b>forward</b> and backward <b>motion</b> <b>vector</b> fields are finally used for temporal integration. During this process, the interfield motion is converted to a motion blur appearance, {{similar to the one}} physically produced by the prolonged exposure time in film cameras. Finally, the resulting image is upsized and enhanced by a warp-filter, which unlike high pass filters does not augment noise...|$|R
40|$|A {{selector}} (502) {{for selecting}} a background <b>motion</b> <b>vector</b> for a pixel in an occlusion region of an image, from {{a set of}} <b>motion</b> <b>vectors</b> being computed for the image, comprises: computing means (510) for computing a model-based <b>motion</b> <b>vector</b> for the pixel on basis of a motion model being determined on basis of a part of (402 - 436) a <b>motion</b> <b>vector</b> field (400) of the image; comparing means (511) for comparing the model-based <b>motion</b> <b>vector</b> {{with each of the}} <b>motion</b> <b>vectors</b> of the set of motion vectors; and selecting means (512) for selecting a particular <b>motion</b> <b>vector</b> of the set of <b>motion</b> <b>vectors</b> on basis of the comparing and for assigning the particular <b>motion</b> <b>vector</b> as the background <b>motion</b> <b>vector...</b>|$|R
40|$|In {{this paper}} a new very {{low bit rate}} video coding scheme is presented. It {{is based on a}} <b>forward</b> <b>motion</b> {{estimation}} technique using an image warping model, thus delivering the basis for temporal tracking of regions or objects. In order to deal with new or disappearing image contents a new algorithm for the adaptation of a tracked control grid is proposed. correlation of <b>motion</b> <b>vectors</b> may be exploited to improve the motion estimation step and the motion coding. Due to a bad motion estimation or new or disappearing image content, the <b>forward</b> <b>motion</b> estimation may lead to an over distorted grid, which yields to a reduced prediction quality. A common solution is to adapt the grid to the edges of the image in each frame thus loosing the ability to track the motion [7, 8]. In [8, 9] the deletion and insertion of node points is introduced in order to handle new and disappearing image content. To improve the coding efficiency a high quality pixel interpolation in the warping based predictor [...] ...|$|R
40|$|ABSTRACT: We {{present a}} new <b>motion</b> <b>vector</b> coding {{technique}} based on minimum bitrate prediction. In the proposed scheme, the current block <b>motion</b> <b>vector</b> is predicted among three causal neighboring <b>motion</b> <b>vectors</b> {{so that it}} can produce minimum bitrate in <b>motion</b> <b>vector</b> coding. And then prediction error and mode information for determining the true <b>motion</b> <b>vector</b> at the decoder are coded and transmitted. Since MVD (<b>motion</b> <b>vector</b> difference) code bits are ahead of MODE bits in syntax, the bit amount for MODE information can be minimized by using the fact that the minimum bitrate predictor is used for the <b>motion</b> <b>vector</b> prediction. 1...|$|R
40|$|In this paper, {{we address}} the {{potential}} issues in bidi-rectional motion compensated frame interpolation when the received <b>motion</b> <b>vector</b> field is directly used. Based on this <b>motion</b> <b>vector</b> analysis, we therefore propose us-ing bidirectional <b>motion</b> <b>vector</b> processing method to elim-inate the ghost artifacts around the moving objects. The artifacts caused by large <b>motion</b> <b>vector</b> magnitude can be effectively removed by correcting <b>motion</b> <b>vectors</b> bidirec-tionally. Moreover, since the proposed <b>motion</b> <b>vector</b> se-lection process chooses the best <b>motion</b> <b>vector</b> from adja-cent <b>motion</b> <b>vectors,</b> the computational complexity can be greatly reduced comparing to motion estimation. We also demonstrate how to obtain clearer object edges by allow-ing displacement adjustment during the bidirectional mo-tion vector processing. Experimental {{results show that}} the proposed algorithm outperforms other methods in terms of visual quality. 1...|$|R
40|$|In a video {{processing}} system where <b>motion</b> <b>vectors</b> are estimated for {{a subset of}} the blocks of data forming a video frame, and <b>motion</b> <b>vectors</b> are interpolated {{for the remainder of the}} blocks of the frame, a method includes determining, for at least at least one block of the current frame for which a <b>motion</b> <b>vector</b> is not estimated (204), whether a block to the left or right has an estimated zero <b>motion</b> <b>vector</b> (206), determining whether the at least one block had an estimated zero <b>motion</b> <b>vector</b> in a previous frame (206), and if both determinations are affirmative (208), providing a predetermined <b>motion</b> <b>vector</b> for the at least one block. The predetermined <b>motion</b> <b>vector</b> may be a zero <b>motion</b> <b>vector</b> (208) ...|$|R
40|$|In video downscaling, simply reusing the <b>motion</b> <b>vectors</b> {{extracted}} from an incoming video bitstream may {{not result in}} good quality pictures. Several refinement schemes have been proposed recently to correct their recomposed new <b>motion</b> <b>vectors</b> in order to optimize the coding efficiency during the transcoding process. However, the major concern is that an optimal resampled <b>motion</b> <b>vector</b> may not exist during video downscaling process. In other words, {{it is difficult to}} use one <b>motion</b> <b>vector</b> to represent four <b>motion</b> <b>vectors</b> when the diversity of the incoming <b>motion</b> <b>vectors</b> is high. Besides, redundant computation for refinement has also been carried out even if the resampled <b>motion</b> <b>vector</b> is already optimal. Motivated by this, we propose an adaptive <b>motion</b> <b>vector</b> re-composition algorithm using two new measures: the diversity and importance measures of <b>motion</b> <b>vectors.</b> Using the importance measure, our proposed scheme manages to differentiate the most representative <b>motion</b> <b>vector</b> as a consideration to recompose a new <b>motion</b> <b>vector.</b> In addition, the diversity measure provides information for the video transcoder controlling the size of the refinement window to achieve a significant reduction of computational complexity. Experimental results show that our proposed adaptive <b>motion</b> <b>vector</b> re-composition scheme provides a high coding efficiency in terms of both quality and complexity. Department of Electronic and Information EngineeringRefereed conference pape...|$|R
40|$|In transcoding, simply reusing the <b>motion</b> <b>vectors</b> {{extracted}} from an incoming {{video bit stream}} may not result in the best quality. In this paper, we show that the incoming <b>motion</b> <b>vectors</b> become nonoptimal due to the reconstruction errors. To achieve the best video quality possible, a new motion estimation should be performed in the transcoder. We propose a fast-search adaptive <b>motion</b> <b>vector</b> refinement scheme {{that is capable of}} providing video quality comparable to that can be achieved by performing a new full-scale motion estimation but with much less computation. We discuss the case when some incoming frames are dropped for frame-rate conversions, and propose <b>motion</b> <b>vector</b> composition method to compose a <b>motion</b> <b>vector</b> from the incoming <b>motion</b> <b>vectors.</b> The composed <b>motion</b> <b>vector</b> can also be refined using the proposed <b>motion</b> <b>vector</b> refinement scheme to achieve better results...|$|R
40|$|The <b>motion</b> <b>vectors</b> take a {{large portion}} of the H. 264 /AVC encoded bitstream. This video coding {{standard}} employs predictive coding to minimize the amount of <b>motion</b> <b>vector</b> information to be transmitted. However, the <b>motion</b> <b>vectors</b> still accounts for around 40 % of the transmitted bitstream, which suggests further research in this area. This paper presents an algorithm which employs a feature selection process to select the neighboring <b>motion</b> <b>vectors</b> which are most suitable to predict the <b>motion</b> <b>vectors</b> mv being encoded. The selected <b>motion</b> <b>vectors</b> are then used to approximate mv using Linear Regression. Simulation results have indicated a reduction in Mean Squared Error (MSE) of around 22 % which results in reducing the residual error of the predictive coded <b>motion</b> <b>vectors.</b> This suggests that higher compression efficiencies can be achieved using the proposed Linear Regression based <b>motion</b> <b>vector</b> predictor. peer-reviewe...|$|R
40|$|In this paper, a novel correlation-based <b>motion</b> <b>vector</b> process-ing {{method is}} {{proposed}} for motion compensated frame interpolation. We first {{address the problem}} of unreliable <b>motion</b> <b>vectors</b> due to low correlation. Unlike other <b>motion</b> <b>vector</b> processing methods using vector median filter, we proposed using bidirectional prediction dif-ference to select the best <b>motion</b> <b>vectors</b> with constraint on increas-ing <b>motion</b> <b>vector</b> correlation. Furthermore, to reduce the blockiness artifacts while maintaining edges, we use an adaptive vector aver-aging filter to obtain a finer motion field by taking <b>motion</b> <b>vector</b> correlation into account. Experimental results show that the pro-posed scheme outperforms other methods in terms of visual quality and PSNR performance. Index Terms — motion compensated frame interpolation, frame rate up conversion, <b>motion</b> <b>vector</b> processing 1...|$|R
40|$|The {{direct mode}} coding in the bi-predictive {{pictures}} (B-pictures) can efficiently improve {{the performance of}} bi-predictive coding, because it exploits the temporal correlation by bi-directional prediction from both forward and backward reference pictures, and meanwhile {{it does not require}} any bits for coding the <b>motion</b> <b>vectors.</b> Accordingly, how to accurately calculate the <b>motion</b> <b>vectors</b> in terms of direct mode coding is very important to obtain better prediction values. In other words, it is more desirable to obtain the true <b>motion</b> <b>vectors,</b> because the derived <b>motion</b> <b>vectors</b> need not be coded. The traditional direct mode coding usually derives the <b>motion</b> <b>vector</b> of the current block by scaling the <b>motion</b> <b>vector</b> of the co-located block in the subsequent reference picture. It {{is based on the assumption}} that the near blocks would have the same motion trajectory. In this paper, we present an improved method based on combining <b>motion</b> <b>vector</b> tracking technique and spatial <b>motion</b> <b>vector</b> prediction technique. The proposed method can accurately calculate the <b>motion</b> <b>vectors</b> for the direct mode coding...|$|R
40|$|In this paper, an {{effective}} and computationally efficient method for the recovery of lost <b>motion</b> <b>vectors</b> in video codecs is proposed. The method clusters <b>motion</b> <b>vectors</b> into groups exhibiting coherent motion. The cluster {{with the majority of}} <b>motion</b> <b>vectors</b> is selected and a statistical method is applied to the group to estimate the lost <b>motion</b> <b>vector.</b> Simulation results are presented, including comparison with existing methods, such as the Average or Median of the <b>motion</b> <b>vectors</b> in the neighbouring blocks. 1...|$|R
40|$|This paper {{presents}} a new algorithm for moving object detection in the H. 264 /AVC compressed domain which relies on <b>motion</b> <b>vector</b> information. In contrast to other motion vector-based algorithms, special {{attention is paid}} to noisy <b>motion</b> <b>vectors</b> as they highly decrease the performance of these algorithms. We propose to estimate the reliability of <b>motion</b> <b>vectors</b> by comparing them with projected <b>motion</b> <b>vectors</b> from surrounding frames. As such, noisy <b>motion</b> <b>vectors</b> are localized. By combining this information with the magnitude of <b>motion</b> <b>vectors,</b> foreground objects are distinguished. Experimental results demonstrate that our algorithm achieves significantly better segmentation quality compared to other motion vector-based approaches...|$|R
30|$|Therefore, each of {{the motion}} {{hypotheses}} for the block in the central frame is assigned a reliability measure, which depends on the compensation error and the similarity of the current motion hypothesis to the best <b>motion</b> <b>vectors</b> from its spatial neighbourhood. The reason we introduce these penalties is that the motion compensation error grows with the temporal distance {{and the amount of}} texture in the sequence. From the previous equations, it can be concluded that the current <b>motion</b> <b>vector</b> candidate v is not reliable if it is significantly different from all <b>motion</b> <b>vectors</b> in its neighbourhood. Motion compensation errors of <b>motion</b> <b>vectors</b> in uniform areas are usually close to the motion compensation error of the best <b>motion</b> <b>vector</b> in the neighbourhood. However, in the occluded areas, estimated <b>motion</b> <b>vectors</b> have values which are inconsistent with the best <b>motion</b> <b>vectors</b> in their neighbourhood. Therefore, the <b>motion</b> <b>vectors</b> in the occluded areas usually have low a posteriori probabilities and thus low reliabilities.|$|R
40|$|In block-based motion-compensated video coding, a fixed-resolution motion {{field with}} one <b>motion</b> <b>vector</b> per image block {{is used to}} improve the {{prediction}} of the frame to be coded. All <b>motion</b> <b>vectors</b> are encoded with the same fixed accuracy, typically 1 or 1 / 2 pixel accuracy. In this work, we explore the benefits of encoding the <b>motion</b> <b>vectors</b> with other accuracies, and of encoding different <b>motion</b> <b>vectors</b> with different accuracies within the same frame. To do this, we analytically model the effect of <b>motion</b> <b>vector</b> accuracy and derive expressions for the encoding rates for both <b>motion</b> <b>vectors</b> and difference frames, {{in terms of the}} accuracies. Minimizing these expressions leads to simple formulas that indicate how accurately to encode the <b>motion</b> <b>vectors</b> in a classical blockbased motion-compensated video coder. These formulas also show that the <b>motion</b> <b>vectors</b> must be encoded more accurately where more texture is present, and less accurately when there is much interframe noise. We implement [...] ...|$|R
40|$|The {{objective}} of this thesis is to investigate algorithms that yield improved image quality for motion compensated frame interpolation or frame rate up-conversion. We address the problems of having broken edges and deformed structures in an interpolated frame by hierarchically refining <b>motion</b> <b>vectors</b> on different block sizes. The proposed novel, low complexity <b>motion</b> <b>vector</b> processing algorithm at the decoder explicitly considers the reliability of each received <b>motion</b> <b>vector</b> based on the received residual energy and <b>motion</b> <b>vector</b> correlation. By analyzing the distribution of residual energies and effectively merging blocks that have unreliable <b>motion</b> <b>vectors,</b> the structure information can be preserved. In addition to the unreliable <b>motion</b> <b>vectors</b> due to high residual energies, there are still other unreliable <b>motion</b> <b>vectors</b> that cause visual artifacts but cannot be detected by high residual energy or bidirectional prediction difference in motion compensated frame interpolation. We further propose a correlation-based <b>motion</b> <b>vector</b> processing to classify <b>motion</b> <b>vector</b> reliability and correct identified unreliable <b>motion</b> <b>vectors</b> by analyzing <b>motion</b> <b>vector</b> correlation in the neighborhood. These unreliable <b>motion</b> <b>vectors</b> are gradually corrected based on their bidirectional difference energy levels {{so that we can}} effectively discover the areas where no motion is reliable to be used, such as occlusions and deformed structures. For these areas, we further propose an adaptive frame interpolation scheme by analyzing their surrounding motion distribution and accurately choosing forward or backward predictions. Since the proposed <b>motion</b> <b>vector</b> processing method exploits the spatial information such as residual energy and <b>motion</b> <b>vector</b> correlation, experimental results show that our interpolated results have better visual quality than other methods. However, we still can observe the flickering effects during video display especially in motion boundaries and areas having uniformly distributed texture. Therefore, to further ensure the temporal stability in these motion sensitive areas or video frames, a novel <b>motion</b> <b>vector</b> processing approach based on motion temporal reliability analysis is proposed. For each <b>motion</b> <b>vector</b> candidate, its temporal variation of absolute bidirectional prediction difference along the motion trajectory is examined and classified into several predefined curvatures that are obtained by motion reliability statistic analysis. Any <b>motion</b> <b>vectors</b> that can match one of the predefined curvatures will be considered as possibly temporal reliable motion. This algorithm is employed to improve the motion quality for the proposed <b>motion</b> <b>vector</b> processing method. As a result, the proposed method can effectively improve the motion accuracy for the bidirectional <b>motion</b> <b>vector</b> processing and outperforms other approaches in terms of visual quality, PSNR (Peak Signal to Noise Ratio), and structure similarity...|$|R
30|$|If the {{selected}} <b>motion</b> <b>vectors</b> remain unchanged for neighboring blocks (which is valid when transcoding with mode and MV reuse), the predicted <b>motion</b> <b>vectors</b> and consequently {{the rate of}} the candidate <b>motion</b> <b>vectors</b> (RMC) remain unaffected for the current block.|$|R
30|$|To {{find the}} {{displacement}} of objects within a scene captured by single camera, we use the <b>motion</b> <b>vector</b> estimation procedure of the H. 264 standard. Since H. 264 <b>motion</b> <b>vector</b> estimation is block-based (i.e., it measures {{the displacement of}} a block and not a point or object), we propose correction steps that reevaluate and refine the estimated <b>motion</b> <b>vectors</b> in order to calculate the <b>motion</b> <b>vectors</b> for the objects within the scene. Then the resulting object <b>motion</b> <b>vectors</b> are transformed to depth information. The following subsections elaborate on different steps of our proposed scheme.|$|R
