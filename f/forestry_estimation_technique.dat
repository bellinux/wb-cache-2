0|9813|Public
40|$|In this paper, the {{analysis}} methods used for developing imaging systems estimating the spectral reflectance are considered. The system incorporates the <b>estimation</b> <b>technique</b> for the spectral reflectance. Several traditional and machine learning <b>estimation</b> <b>techniques</b> are compared for this purpose. The accuracy of spectral estimation with this system and each <b>estimation</b> <b>technique</b> is evaluated and the system’s performance is presented...|$|R
40|$|This article gives a brief {{survey of}} penalized spline {{smoothing}}. Penalized spline smoothing {{is a general}} nonparametric <b>estimation</b> <b>technique</b> which allows to fit smooth but else unspecified functions to empirical data. We depict the theory behind this <b>estimation</b> <b>technique</b> and we present an example demonstrating how this nonparametric <b>estimation</b> <b>technique</b> can help to gain insight into economics. ...|$|R
40|$|Abstract- In this paper, various channel <b>estimation</b> <b>techniques</b> for {{iterative}} receivers {{are compared}} for OFDM-IDMA system. Pilot –assisted based, semi-blind estimation, blind estimation and Decision –directed channel <b>estimations</b> <b>techniques</b> are considered and there comparisons are presented. The considered <b>estimation</b> <b>techniques</b> differ {{in terms of}} complexity, as well as performance. The main contribution {{of this paper is}} to give an overview of different channel <b>estimation</b> <b>techniques</b> OFDM-IDMA systems. There is no single channel estimator providing the best tradeoff and our comparison shows the system load and SNR influence the estimator choice...|$|R
5000|$|Dugan has {{developed}} bankruptcy prediction model limitations and accounting-based <b>estimation</b> <b>techniques</b> for corporate risk [...] His assessments reveal limitations in {{the accuracy of}} some widely accepted bankruptcy prediction models. The <b>estimation</b> <b>techniques</b> provide measures of degrees of risk inherent in corporate stock.|$|R
50|$|Noninvasive <b>estimation</b> <b>techniques</b> {{have been}} proposed.|$|R
30|$|The {{simulations}} have illustrated {{that the}} presented CFO and STO <b>estimation</b> <b>technique</b> outperforms current time-domain <b>estimation</b> <b>techniques</b> for small STOs. The low {{complexity of the}} technique {{makes it even more}} attractive. However, since the estimation is done in the frequency domain, the estimation error will increase when the actual STO and CFO increase. Hence, it is advisable to have a prior coarse estimation. This is not the case for time-domain <b>estimation</b> <b>techniques.</b> Having the possibility to reuse the preamble for channel estimation purposes is another advantage.|$|R
40|$|Abstract—This paper {{presents}} performance {{comparison of}} three <b>estimation</b> <b>techniques</b> used for peak load forecasting in power systems. The three optimum <b>estimation</b> <b>techniques</b> are, genetic algorithms (GA), least error squares (LS) and, least absolute value filtering (LAVF). The problem is formulated as an estimation problem. Different forecasting models are considered. Actual recorded data {{is used to}} perform the study. The performance of the above three optimal <b>estimation</b> <b>techniques</b> is examined. Advantages of each algorithms are reported and discussed. Keywords—Forecasting, Least error squares, Least absolute Value, Genetic algorithms...|$|R
40|$|Software {{inspections}} {{have established}} an impressive track record for early defect detection and correction. To increase their benefits, recent research efforts {{have focused on}} two different areas: systematic reading techniques and defect content <b>estimation</b> <b>techniques.</b> While reading techniques are to provide guidance for inspection participants on how to scrutinize a software artifact in a systematic manner, defect content <b>estimation</b> <b>techniques</b> aim at controlling and evaluating the inspection process by providing {{an estimate of the}} total number of defects in an inspected document. Although several empirical studies have been conducted to evaluate the accuracy of defect content <b>estimation</b> <b>techniques,</b> only few consider the reading approach as an influential factor. In this paper we examine the impact of two specific reading techniques - a scenario-based reading technique and checklist-based reading - on the accuracy of different defect content <b>estimation</b> <b>techniques.</b> The examination is based on data that were collected in a large experiment with students of the Vienna University of Technology. The results suggest that the choice of the reading technique has little impact on the accuracy of defect content <b>estimation</b> <b>techniques.</b> Although more empirical work is necessary to corroborate this finding, it implies that practitioners can use defect content <b>estimation</b> <b>techniques</b> without any consideration of their current reading technique...|$|R
50|$|Australian National Pollutant Inventory Emissions <b>Estimation</b> <b>Technique</b> Manuals.|$|R
40|$|A plan is {{presented}} for a supplemental experiment {{to evaluate a}} sample allocation technique for selecting picture elements from remotely sensed multispectral imagery for labeling {{in connection with a}} new crop proportion <b>estimation</b> <b>technique.</b> The method of evaluating an improved allocation and proportion <b>estimation</b> <b>technique</b> is also provided...|$|R
40|$|The {{variety of}} {{software}} projects {{being carried out}} today is enormous. Some of them succeed while others fail. One key reason for failure of projects is lack of proper estimation {{or the use of}} inappropriate <b>estimation</b> <b>techniques.</b> While there are many <b>estimation</b> <b>techniques</b> developed for projects each of the...|$|R
40|$|Worldwide Interoperability for Microwave Access (WiMAX) {{provides}} {{wireless broadband}} to fixed and mobile terminals. In this paper, firstly performance evaluation of WiMAX system without channel estimation is carried out. Then a fuzzy logic based channel <b>estimation</b> <b>technique</b> is proposed. Channel estimation is used because amplitude and phase shift causes error in wireless channel. Finally, Performance evaluation of WiMAX system using channel <b>estimation</b> <b>technique</b> is done. Bit error rate performance for different modulation schemes is then compared. Results show that by using channel <b>estimation</b> <b>technique,</b> {{bit error rate}} for all adaptive modulation techniques are improved...|$|R
40|$|Abstract. In {{order to}} be cost {{competitive}} in the consumer electronics industry, it is needed to estimate product costs earlier in the design phase. In this study, we reviewed quality and quantity cost <b>estimation</b> <b>techniques</b> to develop a cost estimation system. The qualitative cost <b>estimation</b> <b>technique</b> is used to store expert's knowledge {{in the form of}} rules or a decision tree, and quantitative cost <b>estimation</b> <b>techniques</b> is used to extract a similar cost basis based on historical cost data of products. Also, we developed a cost comparison system using these two methods...|$|R
40|$|This paper {{presents}} a concurrent <b>estimation</b> <b>technique</b> that broadens {{the set of}} queueing systems where concurrent <b>estimation</b> <b>techniques</b> are applicable. Our technique utilizes a proportional relation and concurrently estimates performance measures with respect to various buffer capacity values in a queueing system. Our technique applies to a queueing system that characterizes a router/switch in packet networks, and unlike existing concurrent <b>estimation</b> <b>techniques,</b> it also works with correlated and feedback controlled input streams. Simulation examples show that our technique concurrently estimates performances of the queueing system with superior accuracy and efficiency...|$|R
40|$|The {{objective}} {{of this study is}} to evaluate travel time <b>estimation</b> <b>techniques.</b> An application area of these techniques is motorway traffic control. Several of such travel time <b>estimation</b> <b>techniques</b> are developed and applied within the DACCORD project of the European Telematics Application Programme (TAP). DACCORD is an acronym for Development and Application of Co-ordinated Control of Corridors. The relative performance of these techniques and their behaviour under different circumstances is unknown. The evaluation of these <b>estimation</b> <b>techniques</b> is based on two approaches. Qualitative analysis of <b>estimation</b> <b>techniques</b> Simulation based quantitative analysis of <b>estimation</b> <b>techniques</b> The functional requirements and user-requirements of travel time <b>estimation</b> <b>techniques</b> in motorway traffic control applications are defined in order to assess on the suitability of the various <b>estimation</b> <b>techniques.</b> The qualitative analysis involves analysing the various <b>estimation</b> <b>techniques</b> for the way in which these techniques work, and the way in which techniques behave under changing flow conditions. The simulation based quantitative analysis focuses on the quantitative performance of the techniques under different conditions. The micro-simulation model FOSIM is used to generate traffic data and to simulate various conditions. The <b>estimation</b> <b>techniques</b> are implemented in the mathematical programming language Matlab. The results of the <b>estimation</b> <b>techniques</b> based on the generated traffic data were compared to the simulated travel time by a number of performance indicators. Both the absolute error of estimates compared to the simulated travel time and the relative error related to errors of other techniques give insight into the performance of the <b>estimation</b> <b>techniques</b> and into the effect of various conditions. Based on the qualitative analysis it is concluded that all <b>estimation</b> <b>techniques</b> are based on the assumption that speed is constant over a section, and that vehicle trajectories are parallel. Moreover, the techniques assume that the arithmetic time-mean speed as computed at induction loop detectors equals the harmonic time-mean speed. This is likely to introduce an bias, especially with changing flow conditions such as congestion building or resolving. The computed travel time underestimates the real travel time. Based on the qualitative and quantitative analyses the following conclusions are drawn: 9 ̆ 5 With a constant flow regime all techniques follow the free-flow and congestion situation relatively accurate. However, variations are higher under congestion than under free-flow conditions. 9 ̆ 5 With a changing flow regime all techniques follow the simulated TI with a lag during congestion building. The techniques follow quite accurately during congestion resolving. 9 ̆ 5 According to the qualitative analysis the dynamic travel time estimator is superior to the other techniques. Simulation experiments show that this technique displays the smallest lag and results in the lowest error of estimate. However, the dynamic travel time is an off-line <b>estimation</b> <b>technique</b> and therefore only can be used for off-line tasks such as planning and evaluation. 9 ̆ 5 The instantaneous network level travel time estimator performs well in the qualitative and quantitative analyses. It can be computed using a simple and direct procedure and is a suitable tool for control applications. Transport & PlanningCivil Engineering and Geoscience...|$|R
5000|$|... "Cost <b>Estimation</b> <b>Techniques</b> for Web Projects", Emilia Mendes, IGI Publishing, ...|$|R
30|$|The rest of {{the paper}} {{proceeds}} as follows. Theoretical framework section discusses the arbitrage pricing theory (APT) framework. <b>Estimation</b> <b>technique</b> and model specification section presents the <b>estimation</b> <b>technique</b> and model specification. Data and empirical analysis section reports the empirical analysis and results. Finally, Conclusion and recommendation section provides the conclusions and recommendations.|$|R
40|$|This paper {{investigates the}} use of Multivariate State <b>Estimation</b> <b>Techniques</b> as input in {{predicting}} the remaining useful life prediction of electronic products. A prognostics approach combining the Multivariate State <b>Estimation</b> <b>Technique</b> with life cycle damage prediction is then presented, along with a case study. The challenges of the approach are also discussed...|$|R
40|$|Abstract [...] - High-level <b>estimation</b> <b>techniques</b> are of {{paramount}} importance for design decisions like hardware/softwarepartition-ing or design space explorations. In both cases an appropriate compromise between accuracy and computation time determines about the feasibility of those <b>estimation</b> <b>techniques.</b> In this paper we present high [...] level <b>estimation</b> <b>techniques</b> for hardware effort and hardware/software communication time. Our techniques deliver fast results at sufficient accuracy. Furthermore, it is shown in which way these techniques are applied in order to cope with contradictory design goals like performance constraints and hardware effort constraints. As a solution, we present a cost function {{for the purpose of}} hardware/software partitioning that offers a dynamic weighting of its components. The conducted experiments show that the usage of our <b>estimation</b> <b>techniques</b> in conjunction with their efficient combination leads to reasonable hardware/software implementations as opposed to approaches that consider single constraints only. I...|$|R
40|$|ABSTRACT] The {{leaf area index}} (LAI), was {{estimated}} in mountaineous beech forest stands different <b>estimation</b> <b>techniques.</b> The effective LAI (Le) {{was estimated}} optically by measurements with the gap fraction instrument LAI- 2000, SunScan, and Fish-eye. The {{aim of this study}} was to find out the most reliable <b>estimation</b> <b>technique</b> in mountaineous beech forest stands...|$|R
30|$|See Brückner and Ciccone (2011) {{for further}} {{details on the}} <b>estimation</b> <b>technique.</b>|$|R
40|$|In {{this paper}} {{the problem of}} TOA {{estimation}} in multipath channels are discussed. Brief introductions of TOA <b>estimation</b> <b>techniques</b> {{that can be used}} to improve the performance in multipath channels are presented. Some simulation results based on channel measurement data in indoor environment is presented to demonstrate and compare the performance of different TOA <b>estimation</b> <b>techniques...</b>|$|R
25|$|Some of {{the more}} common <b>estimation</b> <b>techniques</b> for linear {{regression}} are summarized below.|$|R
5000|$|Many {{other popular}} <b>estimation</b> <b>techniques</b> can be cast {{in terms of}} GMM optimization: ...|$|R
40|$|Abstract—This note {{presents}} a concurrent <b>estimation</b> <b>technique</b> that broadens {{the set of}} queueing systems where concurrent <b>estimation</b> <b>techniques</b> are applicable. Our technique utilizes a proportional relation and concurrently estimates performance measures with respect to various buffer capacity values in a queueing system. Our technique applies to a queueing system that characterizes a router/switch in packet networks, and unlike existing concurrent <b>estimation</b> <b>techniques,</b> it also works with correlated and feedback controlled input streams. Simulation examples show that our technique concurrently estimates performances of the queueing system with superior accuracy and efficiency. Index Terms—Concurrent estimation, correlated and feedback controlled input streams, dynamic buffer allocation, proportional relation, queueing systems. I...|$|R
40|$|Relative to {{the speech}} {{production}} and perception models, spectral envelopes {{play an important}} role in speech analysis, synthesis, and coding. Recently, spectral envelope <b>estimation</b> <b>technique</b> has made a rapid progress. There are several ways to obtain spectral envelope. These ways include SEEVOC technique, discrete cepstrum method, regularized discrete cepstum estimation, DAP, MVDR, etc. In this paper, we compared the different spectral <b>estimation</b> <b>techniques</b> by using the different spectral-distortion measures. It aims to compare the different envelope <b>estimation</b> <b>techniques</b> from some different perspective. The work is implemented in a low bit-rate coder based on the sinusoidal model by using the different techniques to captures the spectral amplitudes. 1...|$|R
30|$|Royle and Bezdan 2001 have {{demonstrated}} the comparison of shear wave velocity <b>estimation</b> <b>techniques.</b>|$|R
40|$|In this paper, {{we propose}} a novel noise {{reduction}} system using a hybrid noise <b>estimation</b> <b>technique</b> and post-filtering which {{is effective in}} dealing with localized and non-localized noise components. To suppress localized noises, we develop a hybrid noise <b>estimation</b> <b>technique</b> that combines a reformulated multi-channel <b>estimation</b> <b>technique</b> and a soft-decision single-channel <b>estimation</b> <b>technique.</b> Final <b>estimation</b> accuracy is significantly improved by a speech absence probability estimator which considers the strong correlations of speech presence uncertainty between adjacent frequency components and consecutive frames. The estimated spectra of localized noises are subtracted from those of noisy observations by spectral subtraction. The non-localized noises are further reduced by a multi-channel post-filter which minimizes the mean squared error of log-spectra. An estimator for the a priori speech absence probability {{is derived from the}} coherence characteristic of the noise field at spectral subtraction output, improving the spectral enhancement of the desired speech signal. Experimental results demonstrated that the hybrid <b>estimation</b> <b>technique</b> produces more accurate spectral estimates for localized noises and the proposed noise reduction system results in significant improvements in terms of objective speech quality measures: segmental SNR (SEGSNR) and Mel-Frequency Cepstral Coefficient (MFCC) distance and subjective speech quality measures: spectrograms and listening tests in various noise conditions...|$|R
30|$|In the following, we expose some head pose <b>estimation</b> <b>techniques</b> for {{monitoring}} driver vigilance state.|$|R
40|$|A {{model of}} the {{determinants}} of relative house prices was formulated and used to obtain estimates {{of the importance of}} various aspects of the dwelling and its environment. Two <b>estimation</b> <b>techniques</b> were employed: multiple regression analysis and the method of principal components. The results of the two exercises are compared and the relative efficiency of the <b>estimation</b> <b>techniques</b> is assessed in relation to the problem of multicollinearity. ...|$|R
40|$|A Real-Time Optimizer is {{an on-line}} {{steady-state}} model-based optimizer {{that aims to}} improve the process profitability by adjusting operations in response to process changes. Optimizer effectiveness depends on such factors as parameter <b>estimation</b> <b>technique</b> and measurement selection for parameter updating. This thesis evaluates parameter <b>estimation</b> <b>techniques</b> in terms of parameter quality and develops Sensor System Design Cost {{as a tool for}} sensor selection. Back-substitutio...|$|R
40|$|This paper {{investigates the}} {{characteristics}} of different beta <b>estimation</b> <b>techniques</b> in infrequently traded and inefficient stock markets. These markets are artificially created from actual stock market data by removing return observations and by delaying the information transfer from market returns to individual stocks. Alternative beta <b>estimation</b> <b>techniques</b> are reported to behave differently in different types of markets. estimation beta estimation inefficient stock markets infrequently traded stock markets...|$|R
40|$|Several {{ways for}} {{detection}} {{and assessment of}} collinearity in measured data are discussed. Because data collinearity usually results in poor least squares estimates, two <b>estimation</b> <b>techniques</b> which can limit a damaging effect of collinearity are presented. These two techniques, the principal components regression and mixed estimation, belong to a class of biased <b>estimation</b> <b>techniques.</b> Detection and assessment of data collinearity and the two biased <b>estimation</b> <b>techniques</b> are demonstrated in two examples using flight test data from longitudinal maneuvers of an experimental aircraft. The eigensystem analysis and parameter variance decomposition {{appeared to be a}} promising tool for collinearity evaluation. The biased estimators had far better accuracy than the results from the ordinary least squares technique...|$|R
40|$|International audienceThis paper {{presents}} {{a new technique}} for estimating the center of mass of articulated rigid body systems. This <b>estimation</b> <b>technique</b> uses the statically equivalent serial chain, a serial chain representation of any multi-link branched chain whose end-effector locates directly the center of mass. This technique works based on a knowledge of only the kinematic architecture {{of the system and}} does not require the total mass, or any of the individual body's mass or length properties. This constitutes an advance in center of mass estimation, providing an alternate to techniques requiring a force plate. A comparison of these <b>estimation</b> <b>techniques</b> is presented. The modeling and <b>estimation</b> <b>technique</b> is then implemented on a human subject...|$|R
3000|$|..., {{which is}} {{inspired}} by spatial spectrum <b>estimation</b> <b>techniques.</b> Then we evaluate the estimation accuracy of F [...]...|$|R
40|$|M. Com. (Econometrics) The {{objective}} {{of this study is}} to evaluate different <b>estimation</b> <b>techniques</b> that can be used to estimate the coefficients of a model. The <b>estimation</b> <b>techniques</b> were applied to empirical data drawn from the South African economy. The Monte Carlo studies are unique in that data was statistically generated for the experiments. This approach was due to the fact that actual observations on economic variables contain several econometric problems, such as autocorrelation and MUlticollinearity, simultaneously. However, the approach in this study differs in that empirical data is used to evaluate the <b>estimation</b> <b>techniques.</b> The <b>estimation</b> <b>techniques</b> evaluated are : • Ordinary least squares method • Two stage least squares method • Limited information maximum likelihood method • Three stage least squares method • Full information maximum likelihood method. The estimates of the different coefficients are evaluated on the following criteria : • The bias of the estimates • The variance of the estimates • t-values of the estimates • The root mean square error. The ranking of the <b>estimation</b> <b>techniques</b> on the bias criterion is as follows : 1 Full information maximum likelihood method. 2 Ordinary least squares method 3 Three stage least squares method 4 Two stage least squares method 5 Limited information maximum likelihood method The ranking of the <b>estimation</b> <b>techniques</b> on the variance criterion is as follows : 1 Full information maximum likelihood method. 2 Ordinary least squares method 3 Three stage least squares method 4 Two stage least squares method 5 Limited information maximum. likelihood method All the <b>estimation</b> <b>techniques</b> performed poorly with regard to the statistical significance of the estimates. The ranking of the <b>estimation</b> <b>techniques</b> on the t-values of the estimates is thus as follows 1 Three stage least squares method 2 ordinary least squares method 3 Two stage least squares method and the limited information maximum likelihood method 4 Full information maximum likelihood method. The ranking of the <b>estimation</b> <b>techniques</b> on the root mean square error criterion is as follows : 1 Full information maximum likelihood method and the ordinary least squares method 2 Two stage least squares method 3 Limited information maximum likelihood method and the three stage least squares method The results achieved in this study are very similar to those of the Monte Carlo studies. The only exception is the ordinary least squares method that performed better on every criteria dealt with in this study. Though the full information maximum likelihood method performed the best on two of the criteria, its performance was extremely poor on the t-value criterion. The ordinary least squares method is shown, in this study, to be the most constant performer...|$|R
