2|87|Public
40|$|System {{performance}} of Gigabit network hosts can severely be degraded due to interrupt overhead caused by heavy incoming traffic. One {{of the most}} popular solutions to mitigate such overhead is <b>interrupt</b> <b>disabling</b> and then enabling. In this solution, interrupt overhead is significantly reduced by disabling interrupts and only re-enabling them after processing all queued packets. In this paper we investigate analytically the {{performance of}} the scheme of <b>interrupt</b> <b>disabling</b> and enabling and compare it with normal interruption and interrupt coalescing. The system performance is analyzed and compared in terms of throughput, latency, and CPU availability for user applications. 1...|$|E
40|$|Interrupt {{processing}} {{can be a}} major bottleneck in the end-to-end {{performance of}} Gigabit networks. The performance of Gigabit network end hosts or servers can be severely degraded due to interrupt overhead caused by heavy incoming traffic. In particular, excessive latency and significant degradation in system throughput can be encountered. Also, user applications may livelock as the CPU power gets mostly consumed by interrupt handling and protocol processing. A number of interrupt handling schemes has been proposed and employed to mitigate the interrupt overhead and improve OS performance. Among the most popular interrupt handling schemes are normal interruption, polling, interrupt coalescing, and disabling and enabling of interrupts. In previous work, we presented a preliminary analytical study and models of normal interruption and interrupt coalescing. In this article, we extend our analysis and modeling to include polling and the scheme of <b>interrupt</b> <b>disabling</b> and enabling. For polling, we study both pure (or FreeBSD-style) polling and Linux NAPI polling. The performances for all these schemes are compared using both mathematical analysis and discrete-event simulation. The performance is studied in terms of three key performance indictors: throughput, system latency, and the residual CPU bandwidth available for user applications. As opposed to our previous work, we consider not only Poisson traffic, but also bursty traffic with empirical packet size distribution. Our analysi...|$|E
50|$|The <b>interrupt</b> <b>disable</b> flag {{is set in}} {{the status}} register.|$|R
50|$|Regardless of {{what the}} {{hardware}} might support, typical UNIX-type systems only make use of two levels: the minimum (all <b>interrupts</b> <b>disabled)</b> and the maximum (all interrupts enabled).|$|R
50|$|In uniprocessor {{systems with}} no kernel {{preemption}} supported, it {{is sufficient to}} <b>disable</b> <b>interrupts</b> before accessing a critical section.However, in multiprocessor systems (even with <b>interrupts</b> <b>disabled)</b> two or more processors could be attempting to access the same memory at the same time. The fetch-and-add instruction allows any processor to atomically increment a value in memory, preventing such multiple processor collisions.|$|R
50|$|On the Zilog Z80, {{executing}} DI (<b>disable</b> <b>interrupts)</b> {{followed by}} HALT (wait for an interrupt) {{results in the}} CPU staying frozen indefinitely, waiting for an interrupt that cannot happen. The similar processor found in the Game Boy contained a partial fix allowing it to recover from one HALT, but it would become frozen with two consecutive HALTs with <b>interrupts</b> <b>disabled.</b>|$|R
5000|$|When <b>disabling</b> <b>interrupts</b> {{are used}} to prevent {{priority}} inversion, {{there are only two}} priorities: preemptible, and <b>interrupts</b> <b>disabled.</b> With no third priority, inversion is impossible. Since there's only one piece of lock data (the interrupt-enable bit), misordering locking is impossible, and so deadlocks cannot occur. Since the critical regions always run to completion, hangs do not occur. Note that this only works if all <b>interrupts</b> are <b>disabled.</b> If only a particular hardware device's <b>interrupt</b> is <b>disabled,</b> priority inversion is reintroduced by the hardware's prioritization of interrupts. In early versions of UNIX, a series of primitives named splx(0) ... splx(7) <b>disabled</b> all <b>interrupts</b> up through the given priority. By properly choosing the highest priority of any interrupt that ever entered the critical section, the priority inversion problem could be solved without locking out all of the interrupts. Ceilings were assigned in rate-monotonic order, i.e. the slower devices had lower priorities.|$|R
40|$|RTOS based {{embedded}} systems {{are designed with}} priority based multiple tasks. Inter task communication and data corruptions are major constraints in multi-tasking RTOS system. This study we describe about the solution for these issues with an example Real-time Liquid level control system. Message queue and Mail box are used to perform inter task communication to improve the task execution time and performance of the system. Critical section scheduling is used to eliminate the data corruption. In this application process value monitoring is considered as critical. In critical section the <b>interrupt</b> <b>disable</b> time {{is the most important}} specification of a real time kernel. RTOS is used to keep the <b>interrupt</b> <b>disable</b> time to a minimum. The algorithm is studied with respect to task execution time and response of the interrupts. The study also presents the comparative analysis of the system with critical section and without critical section based on the performance metrics...|$|R
50|$|An integer based IPL may be {{as small}} as a single bit, with just two values: 0 (all {{interrupts}} enabled) or 1 (all <b>interrupts</b> <b>disabled),</b> as in the MOS Technology 6502. However, some architectures permit a greater range of values, where each value enables interrupt requests that specify a higher level, while blocking ones from the same or lower level.|$|R
50|$|University of Michigan Multi-Programming Supervisor (UMMPS) is {{the name}} of the MTS {{supervisor}}. UMMPS is the only portion of the system that runs in S/360 supervisor state. It runs with virtual memory (relocation) turned off and with hardware <b>interrupts</b> <b>disabled.</b> With multi-processor configurations it may be executing on more than one processor concurrently. UMMPS is what today would be called a microkernel, although UMMPS was developed long before that term was in common use.|$|R
50|$|A {{look at the}} {{performance}} requirements at high bit rates shows why the 16, 32, 64 or 128 byte FIFO is a necessity. The Microsoft specification for a DOS system requires that <b>interrupts</b> not be <b>disabled</b> for more than 1 millisecond at a time. Some hard disk drives and video controllers violate this specification. 9600 bit/s will deliver a character approximately every millisecond, so a 1 byte FIFO should be sufficient at this rate on a DOS system which meets the maximum <b>interrupt</b> <b>disable</b> timing. Rates above this may receive a new character before the old one has been fetched, and thus the old character will be lost. This {{is referred to as}} an overrun error and results in one or more lost characters.|$|R
50|$|If {{using the}} Plus3 in screen modes 0-3, the pseudo-variable TIME would be thrown off, as the <b>interrupts</b> were <b>disabled</b> during disk access in these modes.|$|R
50|$|CAS, {{and other}} atomic instructions, are {{sometimes}} {{thought to be}} unnecessary in uniprocessor systems, because the atomicity of any sequence of instructions {{can be achieved by}} <b>disabling</b> <b>interrupts</b> while executing it. However, <b>disabling</b> <b>interrupts</b> has numerous downsides. For example, code that is allowed to do so must be trusted not to be malicious and monopolize the CPU, as well as to be correct and not accidentally hang the machine in an infinite loop or page fault. Further, <b>disabling</b> <b>interrupts</b> is often deemed too expensive to be practical. Thus, even programs only intended to run on uniprocessor machines will benefit from atomic instructions, {{as in the case of}} Linux's futexes.|$|R
5000|$|Even in a CPU which {{supports}} nested interrupts, a handler is often reached with all interrupts globally masked by a CPU hardware operation. In this architecture, an interrupt handler would normally save the smallest amount of context necessary, and then reset the global <b>interrupt</b> <b>disable</b> flag {{at the first}} opportunity, to permit higher priority interrupts to interrupt the current handler. It is also important for the interrupt handler to quell the current interrupt source by some method (often toggling a flag bit of some kind in a peripheral register) so that the current interrupt isn't immediately repeated on handler exit, resulting in an infinite loop.|$|R
50|$|Interrupt {{coalescing}} {{can also}} be implemented without support in hardware, by <b>disabling</b> <b>interrupts</b> in the interrupt controller and using timer-based polling.|$|R
5000|$|A 1-level stack is also {{available}} for the STATUS, WREG and BSR registers. They are saved on every interrupt, and may be restored on return. If <b>interrupts</b> are <b>disabled,</b> {{they may also be}} used on subroutine call/return by setting the s bit (appending [...] ", FAST" [...] to the instruction).|$|R
5000|$|... the {{interrupt}} handler - is called after hardware interrupt has occurred. In this part <b>interrupts</b> are <b>disabled,</b> so execution cannot be continued for long time, otherwise the system responsiveness is compromised. In this layer only jobs that require fast response for interrupt should be processed, any others should be passed to higher layer, ...|$|R
50|$|In {{parallel}} {{to the development of}} L4Ka::Hazelnut, in 1998 the Operating Systems Group TUD:OS of the TU Dresden (Dresden University of Technology) started to develop their own C++ implementation of the L4 kernel interface, called L4/Fiasco. In contrast to L4Ka::Hazelnut, which does not allow concurrency in the kernel at all and its successor L4Ka::Pistachio, which allows interrupts in the kernel only at specific preemption points, L4/Fiasco was fully preemptible (with the exception of extremely short atomic operations) to achieve a low interrupt latency. This was considered necessary because L4/Fiasco is used as the basis of DROPS, a hard real-time capable operating system, also developed at the TU Dresden. However, the complexities of a fully preemptible design prompted later versions of Fiasco to return to the traditional L4 approach of running the kernel with <b>interrupts</b> <b>disabled,</b> except for a limited number of preemption points.|$|R
50|$|General-purpose {{operating}} systems {{usually do not}} allow user programs to mask (<b>disable)</b> <b>interrupts,</b> because the user program could control the CPU {{for as long as}} it wishes. Some modern CPUs don't allow user mode code to <b>disable</b> <b>interrupts</b> as such control is considered a key operating system resource. Many embedded systems and RTOSs, however, allow the application itself to run in kernel mode for greater system call efficiency and also to permit the application to have greater control of the operating environment without requiring OS intervention.|$|R
50|$|Usually {{the data}} {{structure}} of the ready list in the scheduler is designed to minimize the worst-case length {{of time spent in}} the scheduler's critical section, during which preemption is inhibited, and, in some cases, all <b>interrupts</b> are <b>disabled.</b> But the choice of data structure depends also on the maximum number of tasks that can be on the ready list.|$|R
5000|$|Do not {{acquire the}} lock. In many {{situations}} {{it is possible}} to design data structures that do not require locking, e.g. by using per-thread or per-CPU data and <b>disabling</b> <b>interrupts.</b>|$|R
5000|$|There was {{a single}} {{interrupt}} line on the PDP-8 I/O bus. The processor handled any <b>interrupt</b> by <b>disabling</b> further <b>interrupts</b> and executing a [...] to location 0000. As {{it was difficult to}} write reentrant subroutines, it was difficult to nest interrupts and this was usually not done; each interrupt ran to completion and re-enabled interrupts just before executing the [...] instruction that returned from the interrupt.|$|R
50|$|Some pins {{have special}} {{purposes}} either as inputs or outputs. (For example, timer pins can be configured as capture inputs or PWM outputs.) In this case, the PxDIR bit controls {{which of the}} two functions the pin performs when the PxSEL bit is set. If there is only one special function, then PxDIR is generally ignored.The PxIN register is still readable if the PxSEL bit is set, but <b>interrupt</b> generation is <b>disabled.</b> If PxSEL is clear, the special function's input is frozen and disconnected from the external pin. Also, configuring a pin for general purpose output does not <b>disable</b> <b>interrupt</b> generation.|$|R
50|$|Enabling and {{disabling}} of kernel preemption replaced spinlocks on uniprocessor systems. Prior to kernel version 2.6, Linux <b>disabled</b> <b>interrupt</b> {{to implement}} short critical sections. Since version 2.6 and later, Linux is fully preemptive.|$|R
50|$|When the OS Vertical Blank Interrupt is enabled, direct updates to the ANTIC DLIST {{registers}} by the CPU or the ANTIC Jump instructions will be overwritten by the OS {{during the}} next Vertical Blank by the values in the shadow registers. Therefore, page flipping implemented by Display Lists that point to the next Display List in series will not operate as expected unless the Vertical Blank <b>interrupt</b> is <b>disabled.</b>|$|R
50|$|CLI is {{commonly}} used as a synchronization mechanism in uniprocessor systems. For example, a CLI is used in operating systems to <b>disable</b> <b>interrupts</b> so kernel code (typically a driver) can avoid race conditions with an interrupt handler. Note that CLI only affects the interrupt flag for the processor on which it is executed; in multiprocessor systems, executing a CLI instruction does not <b>disable</b> <b>interrupts</b> on other processors. Thus, a driver/interrupt handler race condition can still occur because other processors may service interrupts and execute the offending interrupt handler. For these systems, other synchronization mechanisms such as locks must be used in addition to CLI/STI to prevent all race conditions.|$|R
50|$|Once the real-mode {{virtual device}} drivers are loaded, driver initialization, on Windows 95 and Windows 98 occurs. Vmm32 then {{switches}} CPU from real mode to protected mode.The {{next step is}} initialization of protected mode drivers. It is executed in three phases for each device: critical part of initialization (while <b>interrupts</b> are <b>disabled),</b> device initialization (when file I/O is allowed) and InitComplete phase. After initialization of display driver, Windows switch to graphical mode.|$|R
50|$|The Rabbit {{processor}} {{family has}} unique features. For example, the Z80/Z180 family <b>disables</b> <b>interrupts</b> once an interrupt is serviced by an interrupt service routine. However, the Rabbit processors permit interrupts to interrupt service routines according to priorities (a total of 4).|$|R
50|$|The {{most widely}} {{supported}} kernel mode of oprofile uses a system timer (See: Gathering profiling events). However, this mode {{is unable to}} measure kernel functions where <b>interrupts</b> are <b>disabled.</b> Newer CPU models support a hardware performance counter mode which uses hardware logic to record events without any active code needed. In Linux 2.2/2.4 only 32-bit x86 and IA64 are supported; in Linux 2.6 there is wider support: x86 (32 and 64 bit), DEC Alpha, MIPS, ARM, sparc64, ppc64, AVR32.|$|R
5000|$|The {{detection}} of a [...] signal causes the processor {{to enter a}} system initialization period of six clock cycles, after which it sets the <b>interrupt</b> request <b>disable</b> flag in the status register and loads the program counter with the values stored at the processor initialization vector ( [...] - [...] ) before commencing execution. [...] If operating in native mode, the 65C816/65C802 are switched back to emulation mode and stay there until returned to native mode under software control.|$|R
50|$|Uniprocessor {{architectures}} {{have the}} option of using uninterruptable sequences of instructions—using special instructions or instruction prefixes to <b>disable</b> <b>interrupts</b> temporarily—but this technique does not work for multiprocessor shared-memory machines. Proper support for locks in a multiprocessor environment can require quite complex hardware or software support, with substantial synchronization issues.|$|R
50|$|The {{system used}} by NAPI {{is an example}} of the {{hardware-based}} approach: the system (driver) starts in interrupt enabled state, and the <b>Interrupt</b> handler then <b>disables</b> the <b>interrupt</b> and lets a thread/task handle the event(s) and then task polls the device, processing some number of events and enabling the interrupt.|$|R
5000|$|In the above, [...] can {{be called}} by {{different}} threads without any problem. But if the function is used in a reentrant interrupt handler and a second interrupt arises inside the function, the second routine will hang forever. As <b>interrupt</b> servicing can <b>disable</b> other <b>interrupts,</b> the whole system could suffer.|$|R
50|$|When using global variables, each task or ISR {{must ensure}} that it has {{exclusive}} access to variables. If an ISR is involved, {{the only way to}} ensure exclusive access to common variables is to <b>disable</b> <b>interrupts.</b> If two tasks share data, each can gain exclusive access to variables by either <b>disabling</b> <b>interrupts,</b> locking the scheduler, using a semaphore, or preferably, using a mutual exclusion semaphore. Messages can be sent to either an intermediate object called a message queue, or directly to a task, since in µC/OS-III, each task has its own built-in message queue. Use an external message queue if multiple tasks are to wait for messages. Send a message directly to a task if only one task will process the data received. While a task waits for a message to arrive, it uses no CPU time.|$|R
40|$|The {{worst case}} {{execution}} time (WCET) of a task {{is a key}} component {{in the design and}} development of hard real-time systems. Malfunctional real-time systems could cause an aeroplane to crash or the anti-lock braking system in a car to stop working. Static WCET analysis is a method to derive WCET estimates of programs. Such analysis obtains a WCET estimate without executing the program, instead relying on models of possible program executions and models of the hardware. In this thesis WCET estimates have been derived on an industrial real-time operating system code with a commercial state-of-the art WCET analysis tool. The goal was to investigate if WCET analysis tools are suited for this type of code. The analyses have been performed on selected system calls and on regions where <b>interrupts</b> are <b>disabled.</b> Our results indicate that static WCET analysis is a feasible method for deriving WCET estimates for real-time operating system code, with more or less intervention by the user. For all analysed code parts of the real-time operating system we were able to obtain WCET estimates. Our results show that the WCET of system calls are not always fixed but could depend on {{the current state of the}} operating system. These things are by nature hard to derive statically, and often require much manual intervention and detailed system knowledge. The regions where <b>interrupts</b> are <b>disabled</b> are easier to analyse automatically, since they are usually short and have simple code structures...|$|R
40|$|Abstract: Generally, {{there are}} {{periodic}} interrupt {{services in the}} real-time embedded systems even when the system is in the idle state such as the periodic clock tick interrupts. To minimize the idle power, power management therefore should consider the effect of periodic interrupt services. In this paper, we {{deal with this problem}} considering two scenarios. In case the periodic <b>interrupt</b> cannot be <b>disabled,</b> we first model the power consumption and then propose static and dynamic approaches for the optimal frequency selection to save idle power. On the other hand, in case the periodic <b>interrupt</b> can be <b>disabled,</b> we propose an approach to delay the interrupt service until the next task is released so that the processor can stay in low power mode for longer time. The proposed approaches are implemented in a real-time OS and its effectiveness has been validated by theoretical calculations and actually measurements on an embedded processor. Key words: dynamic power management; dynamic voltage/frequency scaling; real-time embedded systems 1...|$|R
