551|4639|Public
25|$|Originally, {{data was}} simply passed one-way from a central {{processing}} unit (CPU) to a graphics processing unit (GPU), then to a display device. However, as time progressed, it became valuable for GPUs to store at first simple, then complex structures of data to be passed back to the CPU that analyzed an image, or a set of scientific-data represented as a 2D or 3D format that a video card can understand. Because the GPU has access to every draw operation, it can analyze data in these forms quickly, whereas a CPU must poll every pixel or <b>data</b> <b>element</b> much more slowly, as the speed of access between a CPU and its larger pool of random-access memory (or in an even worse case, a hard drive) is slower than GPUs and video cards, which typically contain smaller amounts of more expensive memory that is much faster to access. Transferring {{the portion of the}} data set to be actively analyzed to that GPU memory in the form of textures or other easily readable GPU forms results in speed increase. The distinguishing feature of a GPGPU design is the ability to transfer information bidirectionally back from the GPU to the CPU; generally the data throughput in both directions is ideally high, resulting in a multiplier effect on the speed of a specific high-use algorithm. GPGPU pipelines may improve efficiency on especially large data sets and/or data containing 2D or 3D imagery. It is used in complex graphics pipelines as well as scientific computing; more so in fields with large data sets like genome mapping, or where two- or three-dimensional analysis is useful especially at present biomolecule analysis, protein study, and other complex organic chemistry. Such pipelines can also vastly improve efficiency in image processing and computer vision, among other fields; as well as parallel processing generally. Some very heavily optimized pipelines have yielded speed increases of several hundred times the original CPU-based pipeline on one high-use task.|$|E
50|$|In metadata, a <b>data</b> <b>element</b> {{definition}} {{is a human}} readable phrase or sentence associated with a <b>data</b> <b>element</b> within a data dictionary that describes the meaning or semantics of a <b>data</b> <b>element.</b>|$|E
5000|$|... 3.3.51 <b>data</b> <b>element</b> {{representation}} classthe {{class of}} {{representation of a}} <b>data</b> <b>element</b> ...|$|E
50|$|A {{semantic}} mapper processes {{on a list}} of <b>data</b> <b>elements</b> in {{the source}} namespace. The semantic mapper will successively translate the <b>data</b> <b>elements</b> from the source namespace to the destination namespace. The mapping does not necessarily need to be a one-to-one mapping. Some <b>data</b> <b>elements</b> may map to several <b>data</b> <b>elements</b> in the destination.|$|R
40|$|The {{main goal}} of this {{research}} is to determine mapping of Iran MARC <b>data</b> <b>elements</b> to Functional Requirement for Bibliographic Records (FRBR) model group one entities and attributes. FRBR group one entities are work, expression, manifestation and item and each one has special attributes. Therefore all fields and <b>data</b> <b>elements</b> of Iran MARC were examined via comparative method to the entities and attributes of the first group. In first segment a table was made and all of the <b>data</b> <b>elements</b> were mapped based on similar research conducted on MARC 21 by U. S Congress Library. Research findings showed that from the total of 1558 <b>data</b> <b>elements</b> that exist in Iran MARC, 531 <b>data</b> <b>elements</b> are manifestation, 73 <b>data</b> <b>elements</b> are Work y, 65 <b>data</b> <b>elements</b> are expression and 33 <b>data</b> <b>elements</b> are Item. Totally 702 <b>data</b> <b>elements</b> in Iran MARC(45. 05 %) have adaption capability. Among attributes of every entity, the Form of work for Work entity, language of Expression attribute for expression, Manifestation identifier attribute for Manifestation and Item identifier for item entity have the major frequency in Iran MARC structure and totally 692 <b>data</b> <b>elements</b> (44. 41 %) adopted this pattern...|$|R
40|$|Controlled medical terminologies {{that have}} been {{developed}} to describe terms utilized in the field of Radiation Oncology, include SNOMED-CT and DICOM-RT. However, a literature review has failed to provide evidence that the coverage and the level of granularity of these nomenclatures have satisfied the needs of radiation oncologists. Indeed most investigations conclude that the coverage is generally unsatisfactory. Fur-thermore, {{there is no evidence that}} an objective specification of the specialist medical terms used in Radiation Oncology has been developed. We report the development of a Specialist Medical Vocabu-lary for Radiation Oncology using an objective and systematic method of discovery of <b>data</b> <b>elements</b> published in the Radia-tion Oncology literature. The importance of the <b>data</b> <b>elements</b> to radiation oncologists is judged according to the criterion that a submitted report has been deemed worthy of publica-tion. Within the time period of discovery, 97 articles were retrieved and, during the analysis of 80 articles, 622 individual <b>data</b> <b>elements</b> and 2392 instances of use were found. Infrequent <b>data</b> <b>elements</b> comprised the majority of individual <b>data</b> <b>elements</b> (54 %), and frequently used <b>data</b> <b>elements</b> were a minority (27 individual <b>data</b> <b>elements</b> with 10 or more in-stances of use). However these 10 <b>data</b> <b>elements</b> comprised 49. 5 % of the total <b>data</b> <b>elements</b> found...|$|R
50|$|A Representation Term may {{be thought}} of as an {{attribute}} of a <b>data</b> <b>element</b> in a metadata registry that classifies the <b>data</b> <b>element</b> according to the type of data stored in the <b>data</b> <b>element.</b>|$|E
50|$|Note that a {{registered}} <b>data</b> <b>element</b> is any <b>data</b> <b>element</b> that already exists within a metadata registry.|$|E
50|$|<b>Data</b> <b>element</b> to <b>data</b> <b>element</b> mapping is {{frequently}} complicated by complex transformations that require one-to-many and many-to-one transformation rules.|$|E
50|$|<b>Data</b> <b>elements</b> are the {{individual}} fields carrying the transaction information. There {{are up to}} 128 <b>data</b> <b>elements</b> specified in the original ISO 8583:1987 standard, and up to 192 <b>data</b> <b>elements</b> in later releases. The 1993 revision added new definitions, deleted some, while leaving the message format itself unchanged.|$|R
40|$|A {{method for}} storing a vector of process <b>data</b> <b>elements</b> (D 1,..., D 8) {{that have a}} size of n bits from a {{register}} file (RF) into a memory (M) is described. The memory is arranged for storage of a vector of storage <b>data</b> <b>elements</b> in locations (M 1,..., M 5) having a size of m bits, wherein m 2 ̆ 6 gt;n. The method comprises the steps of: exchanging bits (S 2) between process <b>data</b> <b>elements</b> in the vector stored in mutually subsequent register elements, the exchanging resulting in a vector of modified <b>data</b> <b>elements</b> (DmI,..., Dm 8), shuffling (S 3) groups of k subsequent bits in the resulting vector, [...] storing (S 4) the resulting shuffled vector of modified <b>data</b> <b>elements</b> as a vector of storage <b>data</b> <b>elements</b> in the memory (M) ...|$|R
50|$|<b>Data</b> <b>elements</b> are {{frequently}} assigned to data stewards or data stewardship {{teams that are}} responsible for the maintenance of individual <b>data</b> <b>elements.</b>|$|R
5000|$|... {{is greater}} than each <b>data</b> <b>element</b> in [...] and {{less than or equal}} to each <b>data</b> <b>element</b> in [...]|$|E
5000|$|... #Subtitle level 3: Count the Input <b>Data</b> <b>Element</b> Types, the Data entity Types Referenced, and the Output <b>Data</b> <b>Element</b> Types ...|$|E
50|$|Part 7 {{provides}} RDF mappings of {{the different}} MLR entities introduced in the MLR framework: <b>Data</b> <b>element</b> specifications, resource classes, data elements, application profiles, MLR records and <b>data</b> <b>element</b> group specifications. It also provides an OWL 2 DL ontology for the resource classes and <b>data</b> <b>element</b> specifications.|$|E
40|$|Manual 4000. 25 - 5 -M, prescribes uniform procedures, rules, data elementsf codes, formats, {{and time}} {{standards}} concerning the interchange of cent ract related data {{between and among}} DoD Components. This series of appendices is devoted to descriptions of <b>data</b> <b>elements</b> and codes used in MILSCAP. <b>Data</b> <b>elements</b> developed under the criteria outlined in DoD 5000. 12 -M, “DoD Manual for Standard <b>Data</b> <b>Elements,</b> ” reference (f), have {{been approved by the}} Washington Headquarters Services (Director for Information, Operations, and Reports). All other <b>data</b> <b>elements</b> in this manua...|$|R
5000|$|... data model: Terms, definitions, naming conventions, {{representations}} {{and one or}} more {{representations of}} the <b>data</b> <b>elements</b> {{as well as the}} beginning of specification of the relationships between <b>data</b> <b>elements</b> including abstractions and containers.|$|R
40|$|The {{purpose of}} the child maltreatment uniform {{definitions}} and recommended <b>data</b> <b>elements</b> is to present a definition of child maltreatment, its associated terms, and recommended <b>data</b> <b>elements</b> for voluntary use by individuals and organizations in the public health community. The definitions and <b>data</b> <b>elements</b> are intended to promote and improve consistency of child maltreatment surveillance for public health practices. It {{is designed to be}} used by state and local health department staff to assist in and provide a framework for the collection of public health surveillance data on child maltreatment. The definitions included in the document draw upon definitions that are currently in use in the literature and were adapted in collaboration with a panel of experts on child maltreatment and public health surveillance. The definitions and <b>data</b> <b>elements</b> are designed be flexible tools for developing an ongoing surveillance system. Agencies that use the document can modify <b>data</b> <b>elements</b> to fit their system. This document is the third in a series of Uniform Definitions and Recommended <b>Data</b> <b>Elements</b> which includes: Intimate Partner Violence Surveillance: Uniform Definitions and Recommended <b>Data</b> <b>Elements</b> and Sexual Violence Surveillance: Uniform Definitions and Recommended <b>Data</b> <b>Elements.</b> Rebecca T. Leeb, Leonard J. Paulozzi, Cindi Melanson, Thomas R. Simon, Ileana Arias. "January 2008. "Also available via the World Wide Web as an Acrobat. pdf file (4. 12 MB, 148 p.). Includes bibliographical references (p. 131 - 135). Suggested citation: Leeb RT, Paulozzi L, Melanson C, Simon T, Arias I. Child Maltreatment Surveillance: Uniform Definitions for Public Health and Recommended <b>Data</b> <b>Elements,</b> Version 1. 0. Atlanta (GA) : Centers for Disease Control and Prevention, National Center for Injury Prevention and Control; 2008...|$|R
5000|$|Universal <b>Data</b> <b>Element</b> Framework Forum - {{merged with}} Open Platform 3.0 in 2015; {{now known as}} O-DEF (Open <b>Data</b> <b>Element</b> Framework) ...|$|E
50|$|If a <b>data</b> <b>element</b> {{is used to}} {{identify}} a record within a data set, the <b>data</b> <b>element</b> uses the Identifier representation term.|$|E
5000|$|In metadata, {{the term}} <b>data</b> <b>element</b> is an atomic unit {{of data that}} has precise meaning or precise semantics. A <b>data</b> <b>element</b> has: ...|$|E
40|$|The {{values of}} <b>data</b> <b>elements</b> stored in {{biomedical}} databases often draw from biomedical ontologies. Authorization rules {{can be defined}} on these ontologies to control access to sensitive and private <b>data</b> <b>elements</b> in such databases. Authorization rules may be specified by different authorities at different times for various purposes, and as such policy rules may conflict with each other, inadvertently allowing access to sensitive information. Detecting policy conflicts is nontrivial because it involves identification of applicable rules and detecting conflicts among them dynamically during execution of data access requests. It also requires dynamically verifying conformance with required policies and logging relevant information about decisions for audit. Another problem in biomedical data protection is inference attacks, in which a user who has legitimate access to some <b>data</b> <b>elements</b> is able to infer information related to other <b>data</b> <b>elements.</b> This type of inadvertent data disclosure should be prevented by ensuring policy consistency; that is, <b>data</b> <b>elements</b> {{which can lead to}} inference about other <b>data</b> <b>elements</b> should be protected by the same level of authorization policies as the other <b>data</b> <b>elements.</b> We propose two strategies; one for detecting policy consistencies to avoid potential inference attacks and the other for detecting policy conflicts. We have implemented these algorithms in Java language and evaluated their execution times experimentally...|$|R
5000|$|... "Personal information" [...] {{means an}} individual's first name or first initial and last name in combinationwith any {{one or more}} of the {{following}} <b>data</b> <b>elements,</b> when either the name or the <b>data</b> <b>elements</b> are not encrypted: ...|$|R
40|$|AbstractIntroductionMedical {{documentation}} is a time-consuming {{task and}} there is a growing number of documentation requirements. In order to improve documentation, harmonization and standardization based on existing forms and medical concepts are needed. Systematic analysis of forms can contribute to standardization building upon new methods for automated comparison of forms. Objectives of this research are quantification and comparison of <b>data</b> <b>elements</b> for breast and prostate cancer to discover similarities, differences and reuse potential between documentation sets. In addition, common <b>data</b> <b>elements</b> for each entity should be identified by automated comparison of forms. Materials and methodsA collection of 57 forms regarding prostate and breast cancer from quality management, registries, clinical documentation of two university hospitals (Erlangen, Münster), research datasets, certification requirements and trial documentation were transformed into the Operational Data Model (ODM). These ODM-files were semantically enriched with concept codes and analyzed with the compareODM algorithm. Comparison results were aggregated and lists of common concepts were generated. Grid images, dendrograms and spider charts were used for illustration. ResultsOverall, 1008 <b>data</b> <b>elements</b> for prostate cancer and 1232 <b>data</b> <b>elements</b> for breast cancer were analyzed. Average routine documentation consists of 390 <b>data</b> <b>elements</b> per disease entity and site. Comparisons of forms identified up to 20 comparable <b>data</b> <b>elements</b> in cancer conference forms from both hospitals. Urology forms contain up to 53 comparable <b>data</b> <b>elements</b> with quality management and up to 21 with registry forms. Urology documentation of both hospitals contains up to 34 comparable items with international common <b>data</b> <b>elements.</b> Clinical documentation sets share up to 24 comparable <b>data</b> <b>elements</b> with trial documentation. Within clinical documentation administrative items are most common comparable items. Selected common medical concepts are contained in up to 16 forms. DiscussionThe amount of documentation for cancer patients is enormous. There is an urgent need for standardized structured single source documentation. Semantic annotation is time-consuming, but enables automated comparison between different form types, hospital sites and even languages. This approach can help to identify common <b>data</b> <b>elements</b> in medical documentation. Standardization of forms and building up forms on the basis of coding systems is desirable. Several comparable <b>data</b> <b>elements</b> within the analyzed forms demonstrate the harmonization potential, which would enable better data reuse. ConclusionIdentifying common <b>data</b> <b>elements</b> in medical forms from different settings with systematic and automated form comparison is feasible...|$|R
50|$|Standards {{such as the}} ISO/IEC 11179 Metadata Registry {{specification}} give {{guidelines for}} creating precise <b>data</b> <b>element</b> definitions. Specifically chapter four of the ISO/IEC 11179 metadata registry standard covers <b>data</b> <b>element</b> definition quality standards http://standards.iso.org/ittf/PubliclyAvailableStandards/c035346_ISO_IEC_11179-4_2004(E).zip.|$|E
50|$|Assignment of each <b>data</b> <b>element</b> to {{a person}} {{sometimes}} seems like an unimportant process. But many groups have found that users have greater trust and usage rates in systems where they can contact a person with questions on each <b>data</b> <b>element.</b>|$|E
50|$|Metadata {{registries}} {{frequently have}} a formal <b>data</b> <b>element</b> submission, approval and publishing approval process. Each <b>data</b> <b>element</b> should {{be accepted by}} a data stewardship team and reviewed before data elements are published. After publication change control processes should be used.|$|E
50|$|<b>Data</b> <b>elements</b> usage can be {{discovered}} by inspection of software applications or application data files {{through a process}} of manual or automated Application Discovery and Understanding. Once <b>data</b> <b>elements</b> are discovered they can be registered in a metadata registry.|$|R
40|$|Abstract—The {{values of}} <b>data</b> <b>elements</b> stored in {{biomedical}} databases often draw from biomedical ontologies. Authorization rules {{can be defined}} on these ontologies to control access to sensitive and private <b>data</b> <b>elements</b> in such databases. Authorization rules may be specified by different authorities at different times for various purposes, and as such policy rules may conflict with each other, inadvertently allowing access to sensitive information. Detecting policy conflicts is nontrivial because it involves identification of applicable rules and detecting conflicts among them dynamically during execution of data access requests. It also requires dynamically verifying conformance with required policies and logging relevant information about decisions for audit. Another problem in biomedical data protection is inference attacks, in which a user who has legitimate access to some <b>data</b> <b>elements</b> is able to infer information related to other <b>data</b> <b>elements.</b> This type of inadvertent data disclosure should be prevented by ensuring policy consistency; that is, <b>data</b> <b>elements</b> {{which can lead to}} inference about other <b>data</b> <b>elements</b> should be protected by the same level of authorization policies as the other <b>data</b> <b>elements.</b> We propose two strategies; one for detecting policy consistencies to avoid potential inference attacks and the other for detecting policy conflicts. We have implemented these algorithms in Java language and evaluated their execution times experimentally. Keywords-Authorization policy, Biomedical ontology, Inference attacks, Policy conflicts...|$|R
50|$|Users can merge the <b>data</b> <b>elements</b> on the Hospital Market Structure Files to the {{corresponding}} NIS, KID, or SID hospitals {{by the hospital}} identification number (HOSPID). Using the merged <b>data</b> <b>elements,</b> hospital market structure measures can then be included in analyses.|$|R
50|$|A <b>data</b> <b>element</b> {{name is a}} name {{given to}} a <b>data</b> <b>element</b> in, for example, a data {{dictionary}} or metadata registry. In a formal data dictionary, {{there is often a}} requirement that no two data elements may have the same name, to allow the <b>data</b> <b>element</b> name to become an identifier, though some data dictionaries may provide ways to qualify the name in some way, for example by the application system or other context in which it occurs.|$|E
5000|$|The {{data format}} of a DXF {{is called a}} [...] "tagged data" [...] format which [...] "means that each <b>data</b> <b>element</b> in the file is preceded by an integer number that is called a group code. A group code's value {{indicates}} what type of <b>data</b> <b>element</b> follows. This value also indicates {{the meaning of a}} <b>data</b> <b>element</b> for a given object (or record) type. Virtually all user-specified information in a drawing file can be represented in DXF format." ...|$|E
5000|$|Exact match - where <b>data</b> <b>element</b> {{linkages}} {{are made}} {{based on the}} exact name of a column in a database, {{the name of an}} XML element or a label on a screen. For example, if a database column has the name [...] "PersonBirthDate" [...] and a <b>data</b> <b>element</b> in a metadata registry also has the name [...] "PersonBirthDate", automated tools can infer that the column of a database has the same semantics (meaning) as the <b>data</b> <b>element</b> in the metadata registry.|$|E
40|$|In this paper, we {{investigated}} {{the problem of}} approximately processing rank queries against distinct <b>data</b> <b>elements</b> in a <b>data</b> stream {{with the presence of}} duplicated <b>data</b> <b>elements.</b> Novel space and time efficient techniques are developed for continuously maintaining order statistics so that rank queries can be answered with a relative error guarantee. This is the first work providing the space and time efficient data stream techniques to process approximate rank queries with relative error guarantees against distinct <b>data</b> <b>elements...</b>|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThis thesis investigates {{the relationship between}} Department of Defense oriented corporations and commercially oriented corporations, along {{with the government and}} commercially oriented business segments of these same corporations. The <b>data</b> <b>elements</b> of backlog, net sales, operating profits, and identifiable assets are examined, and the methodology for deriving these <b>data</b> <b>elements</b> from the SEC 10 K reports in their total and segmented forms is explained. The analyses of variance on the unsegmented <b>data</b> <b>elements</b> determined no difference between corporation groups, however analyses of segmented <b>data</b> <b>elements</b> resulted in significant variations. Segmented data appears to be necessary to explain the variations due to either type of corporation or time period. [URL] United States Nav...|$|R
40|$|Sexual Violence Surveillance: Uniform Definitions and Recommended <b>Data</b> <b>Elements,</b> Version 2. 0 {{is a set}} of {{recommendations}} designed to promote consistency in the use of terminology and data collection related to sexual violence. This document was developed through an extensive consultation process. It is published by the National Center for Injury Prevention and Control of the Centers for Disease Control and Prevention. Suggested citation: Basile KC, Smith SG, Breiding MJ, Black MC, Mahendra RR. Sexual Violence Surveillance: Uniform Definitions and Recommended <b>Data</b> <b>Elements,</b> Version 2. 0. Atlanta (GA) : National Center for Injury Prevention and Control, Centers for Disease Control and Prevention; 2014. CS 240344 Panel members [...] External reviewers [...] Acknowledgements [...] Introduction [...] Uniform definitions [...] Recommended <b>data</b> <b>elements</b> for record-based and survey surveillance of sexual violence [...] Recommended <b>data</b> <b>elements</b> for sexual violence [...] Technical notes 22 ̆ 0 ac 2 ̆ 01 c References [...] Appendix A: Panel members and external reviewers for 2002 [...] Appendix B: Summary of recommended <b>data</b> <b>elements...</b>|$|R
