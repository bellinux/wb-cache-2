10000|10000|Public
5|$|Blair's {{departure}} {{came as a}} {{shock to}} Beebe, and he was severely depressed {{for more than a year}} afterward. Despite her assistance during the pheasant expedition, Beebe excised any mention of her from the monograph he was preparing based on the <b>data</b> <b>gathered</b> during it.|$|E
5|$|Discovered {{during the}} mapping of California's coast in 1933, Davidson Seamount {{is named after}} {{geographer}} George Davidson of the U.S. National Geodetic Survey. Studied only sparsely for decades, NOAA expeditions to the seamount in 2002 and 2006 cast light upon its unique deep-sea coral ecosystem. Davidson Seamount is populated by a dense population of large, ancient corals, {{some of which are}} over 100 years of age. The <b>data</b> <b>gathered</b> during the studies fueled the making of Davidson Seamount into a part of the Monterey Bay National Marine Sanctuary in 2009.|$|E
5|$|In 2009, {{primatologist}} James Thorn used environmental niche modelling in Indonesia {{to supplement}} the poor population <b>data</b> <b>gathered</b> to date to predict the remaining available habitat for slow lorises on the islands of Sumatra, Java, and Borneo. These estimates indicated that the Javan slow loris was the most threatened by habitat loss, followed by the Sunda slow loris from Sumatra. The Bornean slow loris was in a better situation since much of its range consists of low-risk areas. Both the Bengal slow loris and pygmy slow loris are found in more than 20protected areas, although their populations are either low or insufficiently recorded.|$|E
50|$|Microsoft <b>Data</b> <b>Gathering</b> (previously Nokia <b>Data</b> <b>Gathering)</b> is an {{application}} designed for NGOs and charities originally launched on Symbian and Series 40 devices and launched for Windows Phone 7 in 2012. Microsoft <b>Data</b> <b>Gathering</b> enables organisations to create questionnaires {{that they can}} send over to fieldworkers via WiFi and mobile networks, the application has had several past successes such as in Brazil where the Nokia <b>Data</b> <b>Gathering</b> application {{was used by the}} Health Vigilance Foundation to track the spread of dengue fever. The software was originally developed by the Instituto Nokia de Tecnologia a Brazilian research centre founded by Nokia.|$|R
40|$|Most of the {{wireless}} sensor networks consist of static sensors, which can be deployed in a wide environment for monitoring applications. While transmitting the data from source to static sink, {{the amount of energy}} consumption of the sensor node is high. It results in reduced lifetime of the network. Some of the WSN architectures have been proposed based on Mobile Elements. There is large number of approaches to resolve the above problem. It is found those two approaches, namely Single Hop <b>Data</b> <b>Gathering</b> problem (SHDGP) and mobile <b>Data</b> <b>Gathering,</b> which is used to increase the lifetime of the network. Single Hop <b>Data</b> <b>Gathering</b> Problem is used to achieve the uniform energy consumption. The mobile <b>Data</b> <b>Gathering</b> algorithm is used to find the minimal set of points in the sensor network, which serves as data gathering points for mobile network. Even after so many decades of research, there are some unresolved problems like non uniform energy consumption, increased latency, which needs to be resolved. Comment: 4 pages, 1 figure, "Published with International Journal of Engineering Trends and Technology (IJETT) ...|$|R
5000|$|BAH changes every year, {{based on}} <b>data</b> <b>gather</b> during the Summer / Spring active rental seasons. Generally BAH changes 2-5% {{annually}} and 5-10% in [...] "hot" [...] markets.|$|R
5|$|Additionally, {{despite the}} initial {{positive}} {{response to the}} Geneva experts' report, <b>data</b> <b>gathered</b> from Hardtack operations of 1958 (namely the underground Rainier shot) would further complication verification provisions as US scientists, including Hans Bethe (who backed a ban), became convinced that the Geneva findings were too optimistic regarding detection of underground tests, though Macmillan warned that using the data to block progress on a test ban might be perceived in the public as a political ploy. In early 1959, Wadsworth told Tsarapkin of new US skepticism towards the Geneva System. While the Geneva experts believed the system could detect underground tests down to five kilotons, the US now believed that it could only detect tests down to 20 kilotons (in comparison, the Little Boy bomb dropped on Hiroshima had an official yield of 13 kilotons). As a result, the Geneva detection regime {{and the number of}} control posts would have to be significantly expanded, including new posts within the Soviet Union. The Soviets dismissed the US argument as a ruse, suggesting that the Hardtack data had been falsified.|$|E
5|$|On Enterprise, {{analysis}} of <b>data</b> <b>gathered</b> {{in the previous}} encounter with the Romulan ship reveals that the ship is being piloted telepathically by an Andorian. Commander Shran (Jeffrey Combs) explains that the data indicates that the pilot is probably {{a member of the}} Aenar, a white-skinned and blind Andorian sub-race. This, however, seems unlikely, since the Aenar are few in number, reclusive pacifists, and inhabitants of the isolated extreme northern polar region of their moon. Shran and Captain Jonathan Archer (Scott Bakula) then beam down to contact the Aenar. The Aenar's spokesperson, Lissan (Alicia Adams), initially declines to assist as the Aenar do not want to get involved in a war. However, a young Aenar named Jhamel (Alexandra Lydon) decides to help, since doing so may help locate Gareb (Scott Allen Rinker), her missing brother.|$|E
5|$|The Mastiff RPVs went {{in first}} {{to cause the}} Syrian SAMs to turn on their radars by convincing the Syrians that many attack {{aircraft}} were overhead. Once the Mastiffs were tracked by Syrian radar, the tracking signals were relayed to another Scout outside of the missiles' range. The Scout then relayed the signal to E2C Hawkeye aircraft orbiting off the coast. The <b>data</b> <b>gathered</b> was analyzed by the E2Cs and Boeing 707 ECM aircraft. Once the SAM crews fired missiles at the drones, the F-15s and F-16s provided air cover while F-4 Phantoms attacked the SAM batteries, destroying them with AGM-78 and AGM-45 anti-radiation missiles. The rapid flight time of the missiles minimized the F-4s' exposure to the SAMs. The Syrians reportedly fired 57 SA-6s, to no effect.|$|E
5000|$|Treu, Marvin H., Worden, Simon P., Bedard, Michael G., Bartlett, Randall, K., 1998, Earth, Moon, and Planets, 82/83, 27, “USAF Perspectives on Leonid Threat and <b>Data</b> <b>Gathering</b> Campaigns.” ...|$|R
3000|$|... aThis {{section was}} partly {{presented}} at the 1 st IET International Conference on Wireless Sensor Network (IET-WSN 2010), [...] "Competition-based Clustering and Energy-saving <b>Data</b> <b>Gathering</b> in Wireless Sensor Networks".|$|R
40|$|International Telemetering Conference Proceedings / October 17 - 20, 1994 / Town & Country Hotel and Conference Center, San Diego, CaliforniaRadarMap is {{designed}} to take PCM-encoded radar data and process it to display the trace of radar targets on {{a map of the}} Eglin Test Range. Written in C, X Window, and OSF/Motif, RadarMap runs on a DECStation 5000 / 240 and utilizes the Loral <b>Data</b> <b>Gathers</b> C functions library to directly access PCM parameters from a Loral System 500 telemetry rack. X Window (a hardware-independent bitmapped graphics display system), OSF/Motif, and the <b>Data</b> <b>Gathers</b> libraries allow portability to other operating systems that support a C compiler and these libraries...|$|R
5|$|To {{convert the}} {{backlink}} <b>data</b> <b>gathered</b> by BackRub's web crawler into {{a measure of}} importance for a given web page, Brin and Page developed the PageRank algorithm, and realized {{that it could be}} used to build a search engine far superior to existing ones. The new algorithm relied on a new kind of technology that analyzed the relevance of the backlinks that connected one Web page to another, and allowed the number of links and their rank, to determine the rank of the page. Combining their ideas, the pair began utilizing Page's dormitory room as a machine laboratory, and extracted spare parts from inexpensive computers to create a device that they used to connect the nascent search engine with Stanford's broadband campus network. After filling Page's room with equipment, they then converted Brin's dorm room into an office and programming center, where they tested their new search engine designs on the Web. The rapid growth of their project caused Stanford's computing infrastructure to experience problems.|$|E
5|$|The {{completion}} {{of all the}} major objectives, {{as well as some}} that were not considered vital, upgraded the telescope to its most technologically advanced state since its launch nineteen years ago, and made it more powerful than ever. The upgrades will also help Hubble to see deeper into the universe, and farther into the past, closer to the time of the Big Bang. Hubble's importance to science is not just seen in the dramatic images it provides, but also in the volume of work it has generated – an average of fourteen scientific articles are published each week based on <b>data</b> <b>gathered</b> from the telescope. Officially, the upgrades should extend Hubble's life through 2014, but Hubble Space Telescope Senior Scientist David Leckrone noted prior to the mission that if all of the mission's objectives were successful, the telescope could easily last longer than that. The next large telescope scheduled to be launched is the James Webb Space Telescope in 2018, which is infrared-only, so to have Hubble, which has ultraviolet, visible, and near-infrared capabilities, still operational after 2018 would be of great benefit to the scientific community.|$|E
5|$|The {{first modern}} {{population}} census {{in the country}} was conducted in 1857, and 15 more have been performed since then. Since 1961 the censuses are conducted in regular ten-year intervals, with the latest one in 2011. The first institution {{set up in the}} country specifically for the purposes of maintaining population statistics was the State Statistical Office, founded in 1875. Since its founding, the office changed its name and structure several times and was alternately subordinated to other institutions and independent, until the most recent changes in 1992, when the institution became the Croatian Bureau of Statistics. The 2011 census was performed on 1–28 April 2011, recording situation as of 31 March 2011. The first census results, containing the number of the population by settlement, were published on 29 June 2011, and the final comprehensive set of data was published in December 2012. The 2011 census and processing of the <b>data</b> <b>gathered</b> by the census was expected to cost 171.9million kuna (23.3million euro). The 2011 census was performed using new methodology: the permanent population was determined as the enumerated population who lived in the census area for at least 12 months prior to the census, or plans to live in the same area for at least 12 months after the census. This method was also retroactively applied to the 2001 census data.|$|E
3000|$|... select {{function}} {{to choose the}} correct component version, thus maintaining the system consistency. In Fig.  2, for instance, Receiver depends on Sender, and Post-Processor depends on Processor, which in turn depends on Pre-Processor, and Pre-Processor depends on <b>Data</b> <b>Gathering.</b>|$|R
40|$|Bachelor {{thesis is}} focused on {{comparing}} development of selected landscape from Stable Cadastre till today and on possibility of using modern technology for wetlands identification and land a melioration mapping. As an area of interest, two locations, in cadastral area of town Dříteň, were chosen. In practical part available map <b>data</b> were <b>gathered</b> and evaluated. In conclusion, map <b>data</b> and <b>gathered</b> <b>data</b> from Earth remote sensing were compared...|$|R
40|$|Dr. D. V. Ashoka Abstract- In Wireless Sensor Network (WSN), {{gathering}} sensed {{information and}} relay {{it to the}} Base station using multi-hop communication in an energy efficient manner is of prominent importance [1]. A novel approach for Intelligent <b>Data</b> <b>Gathering</b> in WSN is proposed in this paper. This scheme implements sensing of the intelligent data by sensor nodes and <b>Data</b> <b>Gathering</b> at the Base station using respective algorithms. Hardware implementation results prove that proposed scheme is effective to collect Intelligent Data at the Base station. The proposed algorithm is implemented using JN 5148 microcontroller based Base Station (Access Point). Future work focuses on tackling with the undesirable situations like Data Redundancy and Congestion to improve the life time of the WSN...|$|R
5|$|The general {{election}} {{was held on}} Thursday 6 May 2010 and saw an increase in voter turnout from 61% in 2005 to 65% in 2010. Throughout the day GfK NOP and Ipsos MORI conducted an exit poll {{on behalf of the}} BBC, Sky and ITV news services – the results of which were announced as the polls closed at 10:00pm. <b>Data</b> <b>gathered</b> from individuals at 130 polling stations around the country suggested a hung parliament, with an initial estimate that the Conservative Party would achieve 307 seats–19 seats short of a controlling majority. This deficit was later adjusted to 21 seats. The distribution of seats was initially predicted to be 307 to the Conservatives, 255 to Labour, 59 to the Liberal Democrats and 29 to the other parties, but these figures were later updated with a minor adjustment in Labour's favour. The apparently poor prospects for the Liberal Democrats were a surprise to commentators, as many previous opinion polls had indicated they would receive more seats. A later BBC exit poll published at 5:36am on Friday 7 May predicted the Conservatives on 306, 20 short of an overall majority, with Labour on 262, and the Liberal Democrats on 55.|$|E
25|$|The Integrated Medical Model (IMM) {{group at}} Glenn Research Center in Ohio has been {{analyzing}} and optimizing <b>data</b> <b>gathered</b> on renal stone formation since late 2008.|$|E
25|$|Although the Merganser {{never entered}} production, further development, {{based on the}} <b>data</b> <b>gathered</b> from its test programme, {{would lead to the}} larger Prince, President and Pembroke series for which a {{suitable}} powerplant was available.|$|E
5000|$|EDGAR, the Electronic <b>Data</b> <b>Gathering,</b> Analysis, and Retrieval system, {{performs}} automated collection, validation, indexing, acceptance, and forwarding of submissions {{by companies}} {{and others who}} are required by law to file forms with the U.S. Securities and Exchange Commission (the [...] "SEC"). The database is freely available to the public via the Internet (HTTPS).|$|R
40|$|Recent {{research}} has shown that using mobile robots as mobile nodes to <b>gather</b> and carry <b>data</b> in WSNs can effectively reduce the data relay hop count and improve the lifetime of the WSNs. But because of the low speed feature of the mobile robot, a greater time delay has been produced in the process of gathering data in WSNs with mobile robot. In order to make a balance between the lifetime of WSNs and the time delay of mobile robot data gathering, this paper proposes a Bounded Relay Hop in the Cluster based Multi-robot <b>Data</b> <b>Gathering</b> (BRHC-MRDG) problem, and formulates the BRHC-MRDG as an integer linear programming. In order to solve the BRHC-MRDG problem, the Distributed Doublelayer Clustering <b>Data</b> <b>Gathering</b> Algorithm (DDC-DGA) is proposed. In different parameter values, the comparison experiments are designed to verify the effectiveness of the DDC-DGA...|$|R
30|$|EEG <b>data</b> was <b>gathered</b> from {{subjects}} from 4 different areas and age groups.|$|R
25|$|Although {{available}} GISP <b>data</b> <b>gathered</b> {{over the}} earlier seven years, pointed to north-central Greenland as the optimum site {{location for the}} first deep drilling, financial restrictions forced {{the selection of the}} logistically convenient Dye-3 location.|$|E
25|$|SQL Server Reporting Services is {{a report}} {{generation}} environment for <b>data</b> <b>gathered</b> from SQL Server databases. It is administered via a web interface. Reporting services features a web services interface to support the development of custom reporting applications. Reports are created as RDL files.|$|E
25|$|An {{analysis}} {{based on}} <b>data</b> <b>gathered</b> in the US suggested an exponent of 2.6 would yield the best fit for children aged 2 to 19 years old. For US adults, exponent estimates range from 1.92 to 1.96 {{for males and}} from 1.45 to 1.95 for females.|$|E
50|$|The RAISE Project <b>data</b> is <b>gathered</b> by {{systematically}} {{searching the}} websites for posted awards.|$|R
40|$|Baalsrud Hauge, J., Boyle, E., Mayer, I., Nadolski, R. J., Riedel, J. C. K. H., Moreno-Ger, P., Bellotti, F., Lim, T., & Ritchie, J. (2013). Study Design and <b>Data</b> <b>Gathering</b> Guide for Serious Games’ Evaluation. In T. M. Connolly, T. Hainey, E. Boyle, G. Baxter, & P. Moreno-Ger (Eds.), Psychology, Pedagogy, and Assessment in Serious Games (pp. 394 - 419). Hershey PA: IGI...|$|R
40|$|We {{present the}} results of an {{evaluation}} study on the re-structuring of a latency-bound mesh generation algorithm into a latency-tolerant parallel kernel. We use concurrency at a ne-grain level to tolerate long, variable, and unpredictable latencies of remote <b>data</b> <b>gather</b> operations required for parallel guaranteed quality Delaunay triangulations. Our performance data from a 16 node SP 2 and 32 node Cluster of Sparc Workstations suggest that more than 90 % of the latency from remote <b>data</b> <b>gather</b> operations can be masked eectively at the cost of increasing communication overhead between 2 and 20 % of the total run time. Despite the increase in the communication overhead the latency-tolerant mesh generation kernel we present in this paper can generate tetrahedral meshes for parallel eld solvers eight to nine times faster than the traditional approach. Copyright? 2003 John Wiley & Sons, Ltd. KEY WORDS: mesh generation; parallel computing; Delaunay triangulation; guaranteed quality; latency tolerant algorithm...|$|R
25|$|The Encyclopedia of World Problems and Human Potential {{is made up}} from <b>data</b> <b>gathered</b> {{from many}} sources. Those data are grouped into various {{databases}} which constitute {{the backbone of the}} Encyclopedia. The databases are searchable; query results may be seen as lists or as various visualizations.|$|E
25|$|After {{the risk}} {{management}} plan is implemented, it is tested and evaluated, often by means of formal audits. The IA process is an iterative one, in that the risk assessment and {{risk management plan}} {{are meant to be}} periodically revised and improved based on <b>data</b> <b>gathered</b> about their completeness and effectiveness.|$|E
25|$|According {{to a study}} {{conducted}} by the Railway Technology Strategy Centre at Imperial College London, and <b>data</b> <b>gathered</b> by Nova/CoMET, the Taipei Metro has ranked number 1 in the world for four consecutive years in terms of reliability, safety, and quality standards (2004–2007). The most congested route sections handle over 38,000 commuters per hour during peak times.|$|E
40|$|Synthesis is {{a process}} for {{combining}} common-shot <b>data</b> <b>gathers</b> tp produce reflection responses from more general sources or from prescribed incident waves. Synthesis can provide survey-wide data sets, similar in that regard to common-offset <b>data</b> <b>gathers,</b> with the advantage that each synthesized data set is a solution to a single wave equation. A common-offset data set does not have this last feature. Thus, synthesized data sets can be processed by true amplitude wave equation migration. The output is then known to be true amplitude, as well, {{in the same sense}} as the output of Kirchhoff inversion. We present here a theory of data synthesis based on application of Green’s theorem to the ensemble of common-shot gathers and using prescribed more general sources or prescribed incident waves. Specific examples include delayed-shot line sources and incident dipping plane waves at the upper surface. We also discuss two cases in which waves are prescribed at depth, back-projected to the upper surface and then used to generate a synthesized data set...|$|R
30|$|By {{aggregating}} {{the sensor}} nodes using the above equations, the <b>data</b> also <b>gathered</b> for transmission.|$|R
40|$|This is a {{feasibility}} {{study of a}} coordinated medical home network to address the health needs of vulnerable people in Franklin County, Ohio. <b>Data</b> was <b>gathered</b> through literature review, interviews with key informants representing healthcare, government, business, philanthropic, and advocacy organizations, and focus groups with consumers. In addition, <b>data</b> was <b>gathered</b> for detailed projections and analyses of population trends, primary care capacity, and costs related to three potential medical home models...|$|R
