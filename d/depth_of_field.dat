1678|10000|Public
5|$|By {{combining}} the wide angle focal lengths with narrow apertures, the lens provides strong <b>depth</b> <b>of</b> <b>field</b> {{rather than making}} blurred backgrounds. The lens is constructed with a hybrid aspherical lens that when combined with two glass mold elements provides excellent correction for distortion as well as astigmatism.|$|E
5|$|Call of Duty 4: Modern Warfare {{runs on the}} IW engine, {{specifically}} IW 3.0, featuring true world-dynamic lighting, HDR lighting effects, dynamic {{shadows and}} <b>depth</b> <b>of</b> <b>field.</b> Bullet penetration is calculated by the engine, taking into account factors such as surface type and entity thickness. The game runs in a native resolution of 600p on the Xbox 360 and PS3.|$|E
5|$|Hunter's {{directing}} of {{the episode}} was inspired by Otto Preminger's 1945 film Fallen Angel, making use of small sets and long <b>depth</b> <b>of</b> <b>field</b> shots. Engels has identified several 1960s television series—The Wild Wild West, Mayberry R.F.D. and The Fugitive—as being influential to the series as a whole.|$|E
25|$|Moritz von Rohr {{also used}} an object field method, but unlike Merklinger, {{he used the}} {{conventional}} criterion of a maximum circle of confusion diameter in the image plane, leading to unequal front and rear <b>depths</b> <b>of</b> <b>field.</b>|$|R
50|$|The camera has {{image quality}} {{comparable}} to industry standards, the lenses utilize state-of-the-art components {{with the camera}} itself is still compact and lightweight. The zoom lenses optimize maximum image quality, thus enabling <b>depths</b> <b>of</b> <b>field</b> similar to the 35mm cine formats seen today.|$|R
50|$|In {{his early}} studies Cvetkovic found himself mainly {{occupied}} {{with the issue}} of the complexity of light and image, its disintegration into layers with various <b>depths</b> <b>of</b> <b>field,</b> in order to envisage a new image and to formulate or to frame it on the Bauhaus modernist plane.|$|R
5|$|Halo 3 {{utilizes}} a proprietary, in-house graphics engine. As detailed on the Bungie website, {{it employs}} advanced graphics {{technologies such as}} high dynamic range, global lighting and <b>depth</b> <b>of</b> <b>field</b> effects within cutscenes. Motion blurring was absent from the beta, but {{was added to the}} final game. Most of the dynamic objects in the game cast real-time shadows on themselves and the environment around them, including the game's plant life. Halo 3 uses normal, bump, and parallax mapping to give surfaces more detail without dramatically increasing the number of polygons. Players can see distances of up to ten miles (16km) away, all fully three-dimensional. Real time reflections were written into the engine; however, they are often unused as Bungie considered it a waste of resources.|$|E
5|$|In {{an attempt}} to imitate the {{conventions}} of silent cinema in its infancy, the staging and acting of the film are exaggerated and artificial. The equipment used by Acevedo had limitations, causing the indoor scenes to be underexposed and the outdoor scenes to be overexposed. The Pathé camera did not allow camera movement, had imprecise definition, and dark rendering. The Kodak Ektachrome lacked a large <b>depth</b> <b>of</b> <b>field,</b> producing a flat image, and required good lighting to operate effectively. Overhead shots are most commonly used, with some medium shots and {{a small number of}} large shots.|$|E
5|$|Most birds cannot {{move their}} eyes, {{although}} there are exceptions, such as the great cormorant. Birds with eyes {{on the sides of}} their heads have a wide visual field, while birds with eyes on the front of their heads, such as owls, have binocular vision and can estimate the <b>depth</b> <b>of</b> <b>field.</b> The avian ear lacks external pinnae but is covered by feathers, although in some birds, such as the Asio, Bubo and Otus owls, these feathers form tufts which resemble ears. The inner ear has a cochlea, but it is not spiral as in mammals.|$|E
5000|$|TrueFocus sensors {{are able}} to {{simulate}} older autofocus technologies that use rangefinders and narrow <b>depth</b> <b>of</b> <b>fields.</b> [...] In fact, the technology theoretically allows {{for any number of}} combinations of focal points per pixel for effect. It is the only technology not limited to EDoF (Extended-Depth-of-Field).|$|R
50|$|On October 24, 2016, it was {{announced}} that Europacorp is planning an English-language remake to be penned by Creighton Rothenberger and Katrin Benedikt and produced by <b>Depth</b> <b>of</b> <b>Field's</b> Chris Weitz, Andrew Miano and Dan Balgoyen and All Nippon Entertainment Works's Sanford Climan and Annmarie Bailey, and Nippon Television's Naoaki Kitajima.|$|R
40|$|Purpose - This study aims to {{consider}} active vision in low-visibility environments {{to reveal the}} factors of optical properties which affect visibility and to explore a method <b>of</b> obtaining different <b>depths</b> <b>of</b> <b>fields</b> by multimode imaging. Bad weather affects the driver&# 39;s visual range tremendously and thus has a serious impact on transport safety...|$|R
5|$|Principal {{photography}} commenced on August 15, 1983. All but {{two days}} of production were filmed on Paramount soundstages, by cinematographer Charles Correll. The Search for Spock {{was one of the}} first major feature films to use Eastman 5294, a color high speed negative film stock. The film allowed Correll latitude in choosing a broad range of exposure indexes. Since The Search for Spock was shot with anamorphic lenses and many theatergoers would see widescreen 70mm prints, Correll needed to produce a crisp <b>depth</b> <b>of</b> <b>field,</b> a difficult task on many sets. For scenes on the bridge, Correll pushed the exposure index above the Eastman recommendation to keep the image crisp at less than 50foot-candles.|$|E
5|$|Principal {{photography}} {{took place}} between April 16, 1991 and September 27, 1991, using a mix of fixed sets and on-location footage. The production suffered {{from a lack of}} available set space because of shortages; the Starfleet Headquarters set was actually built a few blocks away from Paramount Pictures at the Hollywood Presbyterian Church. Meyer copied a technique used during filming of Citizen Kane, where the filmmakers let the set fall into darkness to save money on construction. The film was shot in Super 35 instead of anamorphic format, because of the former's greater flexibility in framing and lens selection, larger <b>depth</b> <b>of</b> <b>field,</b> and faster lenses.|$|E
5|$|Hunter's {{direction}} in some scenes {{was inspired by}} Otto Preminger's work on the 1945 film noir Fallen Angel. That film featured several scenes shot in tight spaces with a very small mise en scène; Hunter found himself using several of Preminger's techniques {{to make the most}} out of several of the episode's smaller sets such as the RR Diner. Several scenes in the episode were also shot using a split diopter lens, allowing for a greater <b>depth</b> <b>of</b> <b>field.</b> For example, a scene featuring Sherilyn Fenn and Richard Beymer talking had the actors at either side of a room; the split diopter lens allowed for both of them to still be in sharp focus. The episode ends with a shot featuring a Dutch angle; Hunter was the only director on the series who Frost and Lynch allowed to use this shot, which was otherwise forbidden.|$|E
40|$|After {{spending}} such {{a considerable}} time working with narratives and type I came across {{this process of}} cutting out type to create different <b>depths</b> <b>of</b> <b>field.</b> The columns <b>of</b> a newspaper were it's original inspiration. Obviously, now though, this piece is no longer about the actual words. Instead I was implying that the space between words is where our thoughts take shape...|$|R
40|$|In a {{world where}} digital {{photography}} is almost ubiquitous, the size of image capturing devices and their lenses limit their capabilities to achieve shallower <b>depths</b> <b>of</b> <b>field</b> for aesthetic purposes. This work proposes a novel approach to simulate this effect using the color and depth images from a 3 D camera. Comparative tests yielded results {{similar to those of}} a regular lens...|$|R
2500|$|Digital {{methods of}} image capture and display {{processing}} have enabled {{the new technology}} <b>of</b> [...] "light <b>field</b> photography" [...] (also known as synthetic aperture photography). This process allows focusing at various <b>depths</b> <b>of</b> <b>field</b> to be selected after the photograph has been captured. As explained by Michael Faraday in 1846, the [...] "light field" [...] is understood as 5-dimensional, with each point in 3-D space having attributes of two more angles that define the direction of each ray passing through that point.|$|R
5|$|In 1953, Erwin Panofsky {{established}} that Schöne's dating {{was at least}} twenty years too early. In his view, the girl's dress resembles Burgundian high fashion of the late 1460s to mid-1470s. He compared the hennin worn by Maria Portinari in a c. 1470 portrait by Hans Memling, and her gown to that worn by a lady in an illumination from around the 1470s Froissart of Louis of Gruuthuse of Bruges. Sterling, placing the work as c. 1465, remarks that the hennin in the Berlin panel is of a different type {{to that of the}} New York painting. The New York headdress is far more extended, and seems to be of a style prevalent a few years after, and moreover lacks the draped and hanging veil. Sterling further notes that the panel has increased <b>depth</b> <b>of</b> <b>field</b> and more intricate detailing of light than Christus' earlier works. On this basis he believes the work was executed late in the artist's career.|$|E
5|$|To {{promote the}} game, Valve has {{produced}} three machinima trailers depicting {{the game in}} play. The trailers are themed around wartime propaganda news reports for both Germany and the United States. To convey this effect, the trailers make extensive usage of the Source engine's capabilities for film grain, color correction, motion blur and <b>depth</b> <b>of</b> <b>field,</b> as well as sepia toning. The first trailer was released {{as part of the}} game's post-release marketing on December 20, 2005. Entitled Prelude to Victory, the trailer depicted a large firefight in the game as a report from the German perspective, complete with a commentator speaking in the German language. Two further trailers were released to promote the major update to Day of Defeat: Source {{in the second quarter of}} 2006. The trailers, both from the American viewpoint, displayed how the new detonation gameplay worked, emphasising teamwork as the key to success, as well as introducing the viewer to the two new maps added by the update. To further create interest in the game, Valve has opened Day of Defeat: Source to three free weekends, the first taking place on February 10, 2006, the second on July 8, 2006 and the third on July 4, 2008, where anyone with a Steam account could download and play the game for a maximum of 48 hours free of charge.|$|E
25|$|For any of these, {{doubling}} the f-number will approximately double the <b>depth</b> <b>of</b> <b>field.</b>|$|E
50|$|A third {{approach}} to digital matting is using three video streams with different focusing distances and <b>depths</b> <b>of</b> <b>field.</b> As {{with the previous}} method, all three image sensors share a common optical axis, though now the algorithm uses information about {{what part of the}} image is in focus in which video feed to generate its foreground matte. With this technique, both the foreground and background can have dynamic content, and there are no restrictions on what colors or complexity the background has.|$|R
40|$|Experimental {{observations}} of heat fluxes on divertor plates of tokamaks show typical structures (boomerang wings) for varying edge safety factors. The heat flux patterns follow from general principles of nonlinear dynamics. The pattern selection {{is due to}} the unstable and stable manifolds of the hyperbolic fixed points of the last intact island chain. Based on the manifold analysis, the experimental observations can be explained in full detail. Quantitative results are presented in terms <b>of</b> the penetration <b>depths</b> <b>of</b> <b>field</b> lines. (c) 2007 American Institute of Physics...|$|R
40|$|This paper {{describes}} {{current research}} and development on a robotic visual servoing system for assembly of LIGA (Lithography Galvonoforming Abforming) parts. The workcell consists of an AMTI robot, precision stage, long working distance microscope, and LIGA fabricated tweezers for picking up the parts. Fourier optics methods are used to generate synthetic microscope images from CAD drawings. These synthetic images are used off-line to test image processing routines under varying magnifications and <b>depths</b> <b>of</b> <b>field,</b> They also provide reference image features which are used to visually servo the part to the desired position...|$|R
25|$|The {{apertures}} that smaller sensor cameras {{have available}} give much more <b>depth</b> <b>of</b> <b>field</b> than equivalent angles {{of view on}} a DSLR. For example, a 6mm lens on a 2/3″ sensor digicam has a field of view similar to a 24mm lens on a 35mm camera. At an aperture of 2.8 the smaller sensor camera (assuming a crop factor of 4) has a similar <b>depth</b> <b>of</b> <b>field</b> to that 35mm camera set to 11.|$|E
25|$|American {{engineers}} {{create a}} multi-lens digital camera that mimics an insect's compound eye, providing immense <b>depth</b> <b>of</b> <b>field</b> without distorting the image.|$|E
25|$|Focus {{stacking}} is {{a digital}} image processing technique which combines multiple images taken at different focus distances to give a resulting image with a greater <b>depth</b> <b>of</b> <b>field</b> {{than any of the}} individual source images. Available programs for multi-shot DOF enhancement include Adobe Photoshop, Syncroscopy AutoMontage, PhotoAcute Studio, Helicon Focus and CombineZ. Getting sufficient <b>depth</b> <b>of</b> <b>field</b> can be particularly challenging in macro photography. The images to the right illustrate the extended DOF that can be achieved by combining multiple images.|$|E
50|$|Heidenheim {{annually}} hosts a World Cup fencing {{tournament in}} épée. Because {{of the size}} and <b>depth</b> <b>of</b> the <b>field,</b> the Heidenheim event is considered the strongest épée event in the world, stronger even than the World Championships or the Olympic Games.|$|R
40|$|Defocus matting is a fully {{automatic}} and passive method for pulling mattes from video captured with coaxial cameras that have different <b>depths</b> <b>of</b> <b>field</b> and planes <b>of</b> focus. Nonparametric sampling can accelerate the video-matting process from minutes to seconds per frame. In addition, a super-resolution technique efficiently bridges {{the gap between}} mattes from high-resolution video cameras and those from low-resolution cameras. Off-center matting pulls mattes for an external high-resolution camera that doesn´t share the same center of projection as the low-resolution cameras used to capture the defocus matting data. In this article, we address these limitations and extend defocus matting in several important ways...|$|R
40|$|This thesis {{research}} proposes several {{significant improvements}} to a previously developed structured light range sensor {{in order to}} enhance its robustness. By applying modern methods to classical structured light techniques, the improved sensor is capable of adapting to many different environments and generating 3 D surface reconstructions of more general and unconstrained scenes. This is achieved by combining several algorithms in parallel, which permits the sensor to adapt in a reliable and autonomous manner to multiple colours, reflective characteristics and <b>depths</b> <b>of</b> <b>field</b> <b>of</b> the scene. The main motivation of this research is to ultimately mount the range sensor on a mobile platform, and perform autonomous navigation, mapping, modelling and exploration of complex environments. This thesis presents enhancements to the processing stage of the sensor, a complete overhaul of the acquisition stage, as well as a comprehensive set of results that demonstrate how the sensor adapts to the environment. Also, a complete prototype for a robotic mobile exploration system is presented and tested, validating the methods and techniques presented in this work...|$|R
25|$|A {{person may}} {{sometimes}} experience better vision in daylight than at night {{because of an}} increased <b>depth</b> <b>of</b> <b>field</b> due to constriction of the pupil (i.e., miosis).|$|E
25|$|<b>Depth</b> <b>of</b> <b>field</b> {{increases}} with f-number, {{as illustrated in}} the image here. This means that photographs taken with a low f-number (large aperture) will tend to have subjects at one distance in focus, {{with the rest of}} the image (nearer and farther elements) out of focus. This is frequently used for nature photography and portraiture because background blur (the aesthetic quality of which is known as 'bokeh') can be aesthetically pleasing and puts the viewer's focus on the main subject in the foreground. The <b>depth</b> <b>of</b> <b>field</b> of an image produced at a given f-number is dependent on other parameters as well, including the focal length, the subject distance, and the format of the film or sensor used to capture the image. <b>Depth</b> <b>of</b> <b>field</b> can be described as depending on just angle of view, subject distance, and entrance pupil diameter (as in von Rohr's method). As a result, smaller formats will have a deeper field than larger formats at the same f-number for the same distance of focus and same angle of view since a smaller format requires a shorter focal length (wider angle lens) to produce the same angle of view, and <b>depth</b> <b>of</b> <b>field</b> {{increases with}} shorter focal lengths. Therefore, reduced–depth-of-field effects will require smaller f-numbers when using small-format cameras than when using larger-format cameras.|$|E
25|$|In {{semiconductor}} photolithography applications, <b>depth</b> <b>of</b> <b>field</b> {{is extremely}} important as integrated circuit layout features must be printed with high accuracy at extremely small size. The difficulty is that the wafer surface is not perfectly flat, but may vary by several micrometres. Even this small variation causes some distortion in the projected image, and results in unwanted variations in the resulting pattern. Thus photolithography engineers take extreme measures to maximize the optical <b>depth</b> <b>of</b> <b>field</b> of the photolithography equipment. To minimize this distortion further, semiconductor manufacturers may use chemical mechanical polishing to make the wafer surface even flatter before lithographic patterning.|$|E
40|$|The {{influence}} of the unbalance of electron distributions on processes of the generation <b>of</b> magnetic <b>fields</b> and currents has been investigated in the paper. The correspondence of results of the two-dimensional numerical modelling to the analytical theory of the ionic-sound turbulence has been obtained. Expressions for the <b>depth</b> <b>of</b> electromagnetic <b>field</b> penetration into non-isothermic plasma have been foundAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|The {{permafrost}} degradation is {{the fundamental}} cause generating embankment diseases and pavement diseases in permafrost region while the permafrost degradation is related with temperature. Based on the <b>field</b> monitoring results <b>of</b> ground temperature along G 214 Highway in high temperature permafrost regions, both the ground temperatures in superficial layer and the annual average temperatures under the embankment were discussed, respectively, for concrete pavements and asphalt pavements. The maximum <b>depth</b> <b>of</b> temperature <b>field</b> under the embankment for concrete pavements and asphalt pavements was also studied by using the finite element method. The results of numerical analysis indicate that there were remarkable seasonal differences of the ground temperatures in superficial layer between asphalt pavement and concrete pavement. The maximum influencing <b>depth</b> <b>of</b> temperature <b>field</b> under the permafrost embankment for every pavement was under the <b>depth</b> <b>of</b> 8 [*]m. The thawed cores under both embankments have close relation with the maximum thawed depth, the embankment height, and the service time. The effective measurements will be proposed to keep the thermal stabilities of highway embankment by the results...|$|R
40|$|This paper {{discusses}} recent {{experiments in}} the manipulation and assembly of parts with 100 micron outside dimensions and submicron tolerances. The objective of this work {{is to develop a}} micromanipulation workcell which can automatically assemble LIGA (Lithography Galvonoforming Abforming) parts using an assembly plan and a CAD drawing of each of the components. The workcell consists of an AdeptOne robot, precision stages, long distance microscope, and a high aspect ratio modeled polysilicon tweezers for picking up the parts. Fourier optics methods are used to generate synthetic microscope images from CAD drawings. These synthetic images are used off-line to test image processing routines under varying magnifications an <b>depths</b> <b>of</b> <b>field.</b> They also provide reference image features which are used to visually servo the true part to the desired position...|$|R
