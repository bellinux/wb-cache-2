3|10000|Public
5000|$|During the {{demolition}} of Florence H., it was erroneously assumed that the explosive, submerged for more than 13 years, was not reactive. On 8 December 1930, {{as a result of}} a demolition charge, the payload inside the ship also exploded. The Artiglio, positioned by a fatal <b>error</b> <b>of</b> <b>assessment</b> at an insufficient distance, was destroyed by the explosion and sank in the Bay of Biscay between Belle Île and Houat, Morbihan, France. Twelve crew members died in the accident, including divers Alberto Gianni, Aristide Franceschi, and Alberto Bargellini, all from Viareggio, and the ship's commander, Captain Bertolotto di Camogli. [...] The survivors were rescued by the Rostro.|$|E
40|$|In Italy the Iridaceae show high {{biodiversity}} and {{consist of a}} fair number of genera and species. Some of these are well distributed in the regions, others show a punctiform distribution and are found only in some regions, while the remainder are endemic to Italy. The distribution of some species is reported repeatedly in the literature with certainty, while that of other less easily identifiable taxa (with diagnostic characters barely discernible, and/or the presence of polymorphism and polyploidy in populations), in fact, shows an <b>error</b> <b>of</b> <b>assessment</b> regarding their true areas of distribution. In particular, a thorough and methodical comparative study (analysis of observations in the field and of biosystematics) is important and more likely to promote the solution of taxonomic-nomenclatural problems. Such an approach will not only discourage the proliferation of species names, but also emphasise the real separation of those closely related yet distinct taxa and allow the recognition of synonymy, especially in taxa {{with a high level of}} criticality, as in Crocus vernus (L.) Hill, Iris sicula Tod., I. lutescens Lam., I. x germanica L., etc. As a result, all of this contributes towards a better understanding of their real status and encourages experts to take appropriate protective measures, according to the Strategic Plan for the Protection of Biodiversity, 2011 - 2020...|$|E
40|$|It is {{conventionally}} {{assumed that}} administrative discretionary decisions {{are determined by}} political and expert-driven considerations and that law’s structuring and constraining capacity in that regard is and should be limited. Law defines a space within which discretionary choices are irrelevant to law {{because they have the}} same legal value. These tenets have shaped both the ways the Court of Justice of the European Union has approached judicial review of discretion and, more generally, the way law is perceived to structure administrative discretion in the Member States and also in the EU. However, the recent expansion of the regulatory powers of the European Union justifies revisiting these basic axioms. In particular, how far should discretion be shielded from the values that EU law conveys? This paper proposes a normative elaboration of a core idea of public law to stress that law twins administrative discretion with a duty of regard to pre-determined public interests. On this basis, legal rules are able to provide a yardstick of critique of decisions that administrative officials adopt within spaces of discretion. An analysis of the Meroni judgment shows how this argument applies to EU law. But this claim only prepares the ground for a more complex inquiry: How does law operate – and how should it operate – within the spaces of administrative discretion, and how should courts review discretionary decisions? Administrative decision-makers construct the law in a specific institutional context in view of their specific tasks. Arguably, one should understand the specific processes through which they interpret the law to know how law may provide substantive criteria that guide discretionary choices. Such understanding would also be the basis to define and assess suitable degrees of judicial review of administrative discretion. One could then make a critical assessment – difficult to make at present – of the shifting boundaries between spaces of discretion and of judicial review that the dictum “manifest <b>error</b> <b>of</b> <b>assessment,</b> misuse of power or excess of power” conceals. This latter argument draws on the debate among US administrative law scholars on agency interpretation of statutes, but it is also mindful of conceptual distinctions that have prevailed in legal scholarship in Europe. The paper defines the prolegomena of a normative framework of a broader research project. It is work in progress...|$|E
5000|$|On February 9, 2011 [...] Boris Boillon is {{appointed}} ambassador of France in Tunis {{instead of}} Pierre Ménat {{that the costs}} <b>of</b> <b>errors</b> <b>of</b> <b>assessment</b> by the French foreign policy at the Tunisian revolution.|$|R
40|$|This study {{examines}} {{the limits of}} global corruption indicators based on experts' perceptions. It draws on a wave of original surveys conducted in eight African countries that combined two types of approaches. The first approach covers a sample of over 35, 000 people and uses experience-based questions to measure petty bureaucratic corruption. The second (Mirror Survey) reports 350 experts' opinions. A comparison of these two sources paints a clear picture <b>of</b> the experts' <b>errors</b> <b>of</b> <b>assessment.</b> We also find evidence for ideological biases, with experts tending to rank countries {{based on their own}} political preferences, and the existence of an erroneous implicit cultural model of "how Africa works"...|$|R
40|$|Summary This study {{examines}} {{the limits of}} global corruption indicators based on experts' perceptions. It draws on a wave of original surveys conducted in eight African countries that combined two types of approaches. The first approach covers a sample of over 35, 000  people and uses experience-based questions to measure petty bureaucratic corruption. The second (Mirror Survey) reports 350  experts' opinions. A comparison of these two sources paints a clear picture <b>of</b> the experts' <b>errors</b> <b>of</b> <b>assessment.</b> We also find evidence for ideological biases, with experts tending to rank countries {{based on their own}} political preferences, and the existence of an erroneous implicit cultural model of "how Africa works". corruption governance perception sub-Saharan Africa expert surveys household surveys...|$|R
40|$|A {{compromise}} {{is the final}} decision adopted by mediating between two or more opposite proposals. A compromise can be achieved in various ways, and all ways have been tried in Tunisia {{over the last few}} years, starting from 2011, when the Arab world entered a cycle of generalized revolution. A {{compromise is}} historic when in a society the trade-off is decided by a number of influential political actors and comports with the major political and social guidelines or even fits into a historical context in rapid evolution (marked by sudden and massive changes). It is therefore a fundamental choice of orientation which cannot be considered ordinary administration. A profusion <b>of</b> approximations, <b>errors</b> <b>of</b> <b>assessment,</b> and "clichés" have been circulating about the revolution, particularly about the one that took place in Tunisia. In an effort to clear away these misunderstandings, this essay offers some observations on the conditions that bring about a revolution...|$|R
30|$|The {{demand for}} {{automated}} assessment and certification systems has grown {{due to the}} fact that it would be extremely complex and hard to assess the huge amount of candidates manually by humans. This demand is confirmed by both employability and institutional needs. This situation drives the design <b>of</b> automated <b>assessment</b> systems in order to decrease both cost and time <b>of</b> manual <b>assessment</b> processes. Furthermore, automated assessment and certification systems are expected to avoid subjectivity and <b>errors</b> <b>of</b> human <b>assessment.</b> Indeed, a panoply of systems and tools have been designed and implemented in order to automatically assess IT skills. The next section provides a detailed review of those developments.|$|R
40|$|Rectifications of {{multispectral}} scanner and thematic mapper data sets for full and subscene areas, analyses <b>of</b> planimetric <b>errors,</b> <b>assessments</b> <b>of</b> {{the number and}} distribution of ground control points required to minimize errors, and factors contributing to error residual are examined. Other investigations include the generation of three dimensional terrain models {{and the effects of}} spatial resolution on digital classification accuracies...|$|R
40|$|Abstract- Low-height vegetation, {{common in}} {{semiarid}} regions, {{is difficult to}} characterize with airborne LiDAR (light detection and ranging) due to the similarities, in time and space, of the point returns of vegetation and ground. Other complications may occur due to the lowheight vegetation structural characteristics {{and the effects of}} terrain slope. This research is focused on modeling methods and <b>error</b> <b>assessment</b> <b>of</b> low-height vegetation in varying terrain. Several methods to best determine vegetation height and 2 -d crown area are developed using both the LiDAR point cloud and rasters derived from the point cloud. These methods are tested on varying sloped terrain. <b>Error</b> <b>assessments</b> <b>of</b> bare earth terrain models in low-height vegetation cover types and slopes are also performed. Recommendations for modeling low-height vegetation and/or filtering lowheight vegetation from terrain models will be presented, along with open-source algorithms...|$|R
40|$|What is the {{precision}} needed for measures of albedo? • The IPCC, section 2. 5. 3. 1. 3 provides <b>error</b> <b>assessments</b> <b>of</b> albedo measurements for croplands • Both models demonstrate a high sensitivity to very {{small changes in}} albedo • Albedo changes between 0. 03 - 0. 05 seem significant 3 Albedo models using potential natura...|$|R
40|$|Abstract: All {{digital data}} contain error {{and many are}} uncertain. Digital models of {{elevation}} surfaces consist of files containing large numbers of measurements representing {{the height of the}} surface of the earth, and therefore a proportion of those measurements are very likely to be subject to some level <b>of</b> <b>error</b> and uncertainty. The collection and handling of such data and their associated uncertainties has been a subject of considerable research, which has focused largely upon the description of the effects of interpolation and resolution uncertainties, as well as modelling the occurrence <b>of</b> <b>errors.</b> However, digital models of elevation derived from new technologies employing active methods of laser and radar ranging are becoming more widespread, and past research will need to be re-evaluated in the near future to accommodate such new data products. In this paper we review the source and nature <b>of</b> <b>errors</b> in digital models of elevation, and in the derivatives of such models. We examine the correction <b>of</b> <b>errors</b> and <b>assessment</b> <b>of</b> fitness for use, and finally we identify some priorities for future research...|$|R
40|$|Like all {{experimentally}} determined {{physical and}} chemical properties, pH measurements {{are affected by the}} limited precision and accuracy of the measurement procedures. Fundamental studies of pH standards, based on measurement of the potential of an electrochemical cell without transference, known as the Harned cell, containing a platinum-hydrogen electrode and a silver-silver chloride reference electrode, indicate that vapour condensation phenomena on potentiometric cell walls not immersed in the thermostatic bath are a major source <b>of</b> <b>error</b> in <b>assessment</b> <b>of</b> pH values. In this work a study was conducted on phthalate buffer, 0. 05 mol kg(- 1) supercript stop KHPhth, and results are reported for the effect of this phenomenon on the assignment of pH values and on their corresponding uncertainties. Identification and quantification of this effect constitute an original contribution to improvement of the primary method of pH measurement and, therefore, more rigorous pH (PS) values...|$|R
40|$|With the {{development}} of mobile phone platforms and systems using numerical methods, it opens wide opportunities building a trustworthy engineering construction projects. Exploring models of real structures requires major computing resources costs, so {{it is important to}} find quick quality solutions. However, most of the engineering design area facing challenges where currect solution is not known. For this chalanges are using approximate methods of calculation, which finding the most appropriate solution. For several decades, the prevailing numerical methods, using engineering design computing technologies is the finite element method. This approach dealing with one of the difficulties, which affects the calculation results in an implicit dependence on the selected finite element mesh. Although this area is examined for decades, but the finite element generation mesh {{is one of the most}} widely investigated area. Designing the model of the construction, is important to obtain reliable calculation results, calculation errors in assessing the specific case of the calculation. Qualitative evaluation of finite element solutions, can be used finite element strategies. This method is an iterative process managed solution from pre-defined tolerances and the various definitions <b>of</b> <b>errors</b> <b>of</b> <b>assessment</b> procedures. Using finite element strategies can be qualitatively assess the results obtained, which are sufficiently accurate models describing the structure in question, at different external influences. Using finite element strategies and their application at issue, mechanical construction models are popular in computational mechanics and mechanical engineering challenges, extending the possibilities of numerical experiments...|$|R
40|$|Abstract. Traditionally, {{the classes}} in {{thematic}} maps {{have been treated}} as crisp sets, using classical set theory. In this formulation, map classes {{are assumed to be}} mutually exclusive and exhaustive. This approach limits the ability of thematic maps to represent the continuum of variation found in most landscapes. Substitution of fuzzy sets allows more � exibility for treatment of map classes in the areas <b>of</b> accuracy <b>assessment</b> and area estimation. Accuracy assessment methods based on fuzzy sets allow consideration of the magnitude <b>of</b> <b>errors</b> and <b>assessment</b> <b>of</b> the frequency of ambiguity in map classes. An example <b>of</b> an accuracy <b>assessment</b> from a vegetation map of the Plumas National Forest illustrates the implementation of these methods. Area estimation based on fuzzy sets and using accuracy assessment data allows estimation of the area of classes as a function of levels of class membership. The fuzzy area estimation methods are an extension of previous methods presented by Card (1982). One interesting result is that the sum of the areas of the classes in a map need not be unity. This approach allows a wider range of queries within a GIS. 1...|$|R
40|$|An attempt {{has been}} made to {{substantiate}} the behavioral features of the economic choice of an economic entity {{in the context of the}} decision-making environment transformation, and also to study their influence on the forming subjective preferences. At the same time, the behavioral paradigm is identified as a basic theoretical construct, which makes it possible to identify the main irrationalizing factors. Based on the study of the conceptual provisions of the behavioral paradigm, it was concluded that the preferences of the economic entity in the process of implementing the economic choice are formed under the influence of motivational and cognitive predictors, which limit the rationality of the economic entity. Deviating from rational criteria towards irrational, the economic entity shapes its preferences on the basis of economic and non-economic criteria, systematically making mistakes in the context of the influence of cognitive distortions manifested in decision-making under modern conditions. Based on the findings, the author constructs a model of economic choice, taking into account behavioral predictors. Among the most important cognitive distortions are herd instinct, professional deformation, "curse of knowledge", bias toward information retrieval, <b>error</b> <b>of</b> substantiation <b>of</b> <b>assessment,</b> bias <b>of</b> confirmation, neglect of formalized methods of cognition, conservatism, preferences of personified trust and heuristics of asymmetric perception...|$|R
40|$|The aim of {{this thesis}} is to {{initiate}} the reader into the business process modelling and error analysis when creating them. In the beginning, the work deals with the theory of business processes reengineering, methodologies, standards, CASE tools and subsequently with modeling itself. The contribution of this thesis lies in the <b>error</b> <b>assessment</b> <b>of</b> process diagrams and diagrams related to them based on the type division with possible consequences <b>of</b> <b>errors</b> and techniques how to avoid them {{with the use of}} methodologies or CASE tools...|$|R
30|$|This {{study used}} a {{specially}} designed accuracy assessment phantom (Koivukangas 2012) to assess the accuracy of a commercial surgical navigator, the StealthStation S 7 (Medtronic Inc., Louisville, CO, USA). The navigator enabled the interchangeable use of both OTS and EMTS. The phantom consisted of three separate levels attached with screws to form the total reference volume. On each level a total <b>of</b> 49 accuracy <b>assessment</b> points were machined with 20 mm displacement between the beveled holes. This gave a specific region of surgical interest (ROSI) volume of 120 x 120 x 100 mm. The phantom was industrially verified at Oulu PMC using the Mitutoyo Strato 9166 (Mitutoyo, Japan) accuracy sensing device. The displacement <b>error</b> <b>of</b> the accuracy <b>assessment</b> points {{was found to be}} +/− 0.015 mm.|$|R
40|$|Remote sensing derived {{data are}} {{increasingly}} being utilized as a data source in geographic information systems (GIS). Remote sensing and GIS error associated with the data acquisition, processing. analysis, conversion, and final product presentation can {{have a significant impact}} on the confidence of decisions made using the data. This paper attempts to identify potential sources <b>of</b> <b>error</b> at each data integration process step, assess potential impacts <b>of</b> <b>error</b> propagation on the decision making process, and recommend priority error quantification research topics. There is an immediate need for the development and standardization <b>of</b> <b>error</b> <b>assessment</b> procedures and reporting conventions. Suggested error quantification research topic priorities include the development of more cost-effective remote sensing accuracy <b>assessment</b> procedures, development <b>of</b> field verification data collection guidelines, procedures for vector-to-raster and raster-to-vector conversions, <b>assessment</b> <b>of</b> scaling issue [...] ...|$|R
40|$|Techniques {{being applied}} {{to test the}} {{sensitivity}} of the physical characteristics of clouds, as determined by remote sensing, to the spatial resolution of the scans are described. The sensitivity is being evaluated with an <b>error</b> <b>assessment</b> <b>of</b> data from the AVHRR instrument on Nimbus- 7. A spatial coherence analysis is being applied to AVHRR data for a 250 sq km region in the Pacific off the Mexican coast. Errors in the derived cloud cover and radiances from which cloud-free regions and cloud-covered regions are being estimated on the basis of radiance values in pixel-sized areas...|$|R
40|$|This study {{investigated}} interrater reliability and measurement <b>error</b> <b>of</b> the Melbourne <b>Assessment</b> <b>of</b> Unilateral Upper Limb Function (Melbourne Assessment) and the Quality of Upper Extremity Skills Test (QUEST), and assessed {{the relationship between}} both scales in 21 children (15 females, six males; mean age 6 y 4 mo [SD 1 y 3 mo], range 5 - 8 y) with hemiplegic CP. Two raters scored the videotapes <b>of</b> the <b>assessments</b> independently in a randomized order. According to the House Classification, three participants were classified as level 1, one participant as level 3, eight as level 4, three as level 5, one participant as level 6, and five as level 7. The Melbourne Assessment and the QUEST showed high interrater reliability (intraclass correlation 0. 97 for Melbourne Assessment; 0. 96 for QUEST total score; 0. 96 for QUEST hemiplegic side). The standard <b>error</b> <b>of</b> measurement and the smallest detectable difference was 3. 2 % and 8. 9 % for the Melbourne Assessment and 5. 0 % and 13. 8 % for the QUEST score on the hemiplegic side. Correlation analysis indicated that different dimensions of upper limb function are addressed in both scales. status: publishe...|$|R
40|$|Large scale studies {{frequently}} use complex sampling procedures, disproportionate sampling weights, {{and adjustment}} techniques {{to account for}} potential bias due to nonresponses {{and to ensure that}} results from the sample can be generalized to a larger population. Survey researchers are concerned about measurement error and the use of weights in developing models. Consequently, multiple weighting factors are used and these weighting factors are manifested as a final survey (composite) weight available for analysis. We developed a method to incorporate an external weighting factor like this for analyses <b>of</b> measurement <b>errors</b> in the theory of generalizability to provide researchers with a tool to evaluate the measurement <b>error</b> components <b>of</b> survey quality and undesirable <b>error</b> components <b>of</b> large-scale <b>assessment</b> programs such as national and stat...|$|R
5000|$|... "In 1812, Petru Maior (...) {{wrote his}} The History of the Romanian Beginnings in Dacia. In his {{tendency}} {{to prove that}} we Romanians are un-corrupted descendants of the Romans, Maior maintains, in the fourth paragraph, that Dacians were entirely exterminated by the Romans, and there was thus no mixing of these two peoples. In order to prove such an unnatural hypothesis, our historian relies on a dubious passage in Eutropius and a passage in Julian, to which he gives an interpretation that no sane mind could admit, and thus begins the demonstration of our Romance identity through history - with a falsification of history. (...) that which surprises and saddens concerning these creations is not their error itself, since this can be explained and at times justified through {{the circumstances of the}} period, but rather the <b>error</b> <b>of</b> our <b>assessment</b> <b>of</b> them nowadays, the haughtiness and self-satisfaction with which they are defended by the Romanian intelligentsia as if true acts of science, the blindness that provides for a failure to see that building a Romanian national awareness cannot rely on a basis that would enclose a lie." ...|$|R
40|$|Accurate {{measurement}} of pressure differences across a diseased heart valve involves either laborious planimetry or elaborate digital computing facilities. An analogue device is described, simple and inexpensive to construct, which {{derives from the}} recorder input of two pressure signals the time (seconds/minute) of valve opening and the mean pressure difference during this time. Measurements may be repeated over long periods. The importance of using pressure differences as compared with peak or end diastolic gradients is noted; serious <b>errors</b> in <b>assessment</b> <b>of</b> valvular disease may otherwise occur...|$|R
40|$|This {{technical}} note (TN) {{focuses on the}} <b>assessment</b> <b>of</b> the atmospheric effects and their compensation in SAR interferometry and especially in persistent scatterer interferometry (PSI). Different strategies to reduce atmospheric effects exist for mountainous areas. In principle, the topographically-correlated atmospheric phase can be estimated • directly from the data, • from global coarse grid GPS zenith path delay data and • from numerical weather prediction models (NWP). These methods are compared and the related assessment is described in this {{technical note}}. The output is a recommendation how to implement the atmosphere mitigation in mountainous areas and an <b>error</b> propagation <b>assessment</b> <b>of</b> the NWP method...|$|R
40|$|The goal of {{this study}} was to test the {{hypothesis}} that reintroduction of Continuous Performance Improvement (CPI) methodology, a lean approach to management at Seattle Children’s (Hospital, Research Institute, Foundation), would facilitate engagement of vivarium employees in the development and sustainment of a daily management system and a work-in-process board. Such engagement was implemented through reintroduction of aspects of the Toyota Production System. Iterations of a Work-In-Process Board were generated using Shewhart’s Plan-Do-Check-Act process improvement cycle. Specific attention was given to the importance of detecting and preventing <b>errors</b> through <b>assessment</b> <b>of</b> th...|$|R
40|$|Background: Recent high-precision {{measurements}} of alpha-induced reaction data below the Coulomb barrier {{have pointed out}} questions of the alpha-particle optical-model potential (OMP) which are yet open within various mass ranges. Purpose: The applicability of a previous optical potential and eventual uncertainties and/or systematic <b>errors</b> <b>of</b> the OMP <b>assessment</b> at low energies can be further considered on this basis. Method: Nuclear model parameters based on the analysis of recent independent data, particularly gamma-ray strength functions, have been involved within statistical model calculation of the (alpha,x) reaction cross sections. Results: The above-mentioned potential provides a consistent description of the recent alpha-induced reaction data with no empirical rescaling factors of the and/or nucleon widths. Conclusions: A suitable <b>assessment</b> <b>of</b> alpha-particle optical potential below the Coulomb barrier should involve the statistical-model parameters beyond this potential {{on the basis of}} a former analysis of independent data. Comment: 12 pages, 8 figures. Updated citations. Minor correctio...|$|R
40|$|This paper {{deals with}} the study of {{preparations}} based on medicinal plants used in traditional Chinese medicine for treatment and prevention {{of a wide range}} of diseases. The purpose of this research was evaluation of the capabilities of a multisensor system for instrumental <b>assessment</b> <b>of</b> the samples bitterness. 33 samples of medicinal plants were evaluated by tasters according to bitterness intensity from 0 to 6. Methodology of the analysis was developed and repeated measurements of the samples were performed by multisensor system. Tasters’ assessments were used as reference data while multisensor system calibrating. A regression model built according to these data displayed good correlation of the system response with bitterness perceived by people. The parameters of the regression model give the possibility for concluding that the multisensor system is capable to predict the bitterness of the medicinal plants preparations with average precision equal to ± 1 of the reference bitterness scale. Relative <b>error</b> <b>of</b> bitterness determination is 14 %, which is a good result for such type <b>of</b> measurements (typical <b>error</b> <b>of</b> the taster’s <b>assessment</b> is, as a rule, in the range of 15 - 30 %) ...|$|R
40|$|An M/G/ 1 queue is {{approached}} by stationary Poisson traffic with known arrival rate. Observations of service times {{are all that}} {{is known about the}} service distribution. Nonparametric estimates of the probability of a long customer delay are given. The estimates include the solution of an equation involving the empirical transform of the service times. Asymptotic properties of the estimates are derived. Simulation studies of the small sample behavior of the estimates are reported. The jackknife is used to provide <b>error</b> <b>assessment</b> <b>of</b> the estimates and to construct confidence intervals in the simulation studies of small sample behavior. Keywords: Asymptotic NormalityOffice of Naval Research[URL]...|$|R
40|$|This chapter takes a legal {{perspective}} on educational assessment issues, examining court responses to challenges to educational assessment in the jurisdictions of Australia, the United States of America (United States) and England. To date, the predominant focus of legal challenges in {{education has been}} regarding either education for children with special needs, or allegations of negligence resulting in physical or emotional injury. However, throughout the jurisdictions considered, challenges on assessment-focused grounds have included discrimination in assessment and testing, allegations <b>of</b> inappropriate <b>assessment</b> and/or failure to provide appropriate educational instruction as a result <b>of</b> <b>errors</b> in <b>assessment.</b> The chapter explains briefly the nature of law in the jurisdictions considered, including legislation and case law. Arts, Education & Law Group, School of Education and Professional StudiesNo Full Tex...|$|R
40|$|Abst rac t Dermatoscopy is {{a method}} of in vivo {{evaluation}} of the structures within the epidermis and dermis. Currently, {{it may be the}} most precise pre-surgical method of diagnosing melanocytic lesions. Diagnostic errors may result in unnecessary removal of benign lesions or what is even worse, they can cause early and very early melanomas to be overlooked. <b>Errors</b> in <b>assessment</b> <b>of</b> dermatoscopy can be divided into those arising from failure to maintain proper test procedures (procedural and technical errors) and knowledge based mistakes related to the lack of sufficient familiarity and experience in dermatoscopy. The article discusses the most common mistakes made by beginner or inexperienced dermatoscopists...|$|R
40|$|Study Design: Systematic review. Purpose of the Study: The {{purpose was}} to review the {{available}} literature for evidence on the reliability and measurement <b>error</b> <b>of</b> protractor-based goniometry <b>assessment</b> <b>of</b> the finger joints. Methods: Databases were searched for articles with key words "hand," "goniometry," "reliability," and derivatives <b>of</b> these terms. <b>Assessment</b> <b>of</b> the methodological quality was carried out using the Consensus-Based Standards for the Selection of Health Measurement Instruments checklist. Two independent reviewers performed a best evidence synthesis based on criteria proposed by Terwee et al (2007). Results: Fifteen articles were included. One article was of fair methodological quality, and 14 articles were of poor methodological quality. An acceptable level for reliability (intraclass correlation coefficient > 0. 70 or Pearson's correlation > 0. 80) was reported in 1 study of fair methodological quality and in 8 articles of low methodological quality. Because the minimal important change was not calculated in the articles, there was an unknown level of evidence for the measurement error. Discussion: Further research with adequate sample sizes should focus on reference outcomes for different patient groups. For valid therapy evaluation, {{it is important to}} know if the change in range of motion reflects a real change of the patient or if this is due to the measurement <b>error</b> <b>of</b> the goniometer. Until now, there is insufficient evidence to establish this cut-off point (the smallest detectable change). Conclusion: Following the Consensus-Based Standards for the Selection of Health Measurement Instruments criteria, there was limited level of evidence for an acceptable reliability in the dorsal measurement method and unknown level of evidence for the measurement <b>error.</b> Level <b>of</b> Evidence: 2 a...|$|R
40|$|This study aims at the {{detection}} of gully-affected areas by applying object-based image analysis {{in the region of}} Taroudannt, Morocco, which is highly affected by gully erosion while simultaneously  representing a major region of agro-industry with a high demand of arable land. As high-resolution optical satellite data are readily available from various sensors and with a much better temporal resolution than 3 D terrain data, an area-wide mapping approach to extract gully-affected areas using only optical satellite imagery was developed. The methodology additionally incorporates expert knowledge and freely-available vector data in a cyclic object-based image analysis approach. This connects the two fields of geomorphology and remote sensing. The classification results show the successful implementation of the developed approach and allow conclusions on the current distribution of gullies. The results of the classification were checked against manually delineated reference data incorporating expert knowledge based on several field campaigns in the area, resulting in an overall classification accuracy of 62 %. The <b>error</b> <b>of</b> omission accounts for 38 % and the <b>error</b> <b>of</b> commission for 16 %, respectively. Additionally, a manual assessment was carried out to assess the quality of the applied classification algorithm. The limited <b>error</b> <b>of</b> omission contributes with 23 % to the overall <b>error</b> <b>of</b> omission and the limited <b>error</b> <b>of</b> commission contributes with 98 % to the overall <b>error</b> <b>of</b> commission. This <b>assessment</b> improves the results and confirms the high quality of the developed approach for area-wide mapping of gully-affected areas in larger regions. In the field of landform mapping, the overall quality of the classification results is often assessed with more than one method to incorporate all aspects adequately...|$|R
50|$|As {{a simple}} example, an {{expenditure}} of ten cents on paper is generally immaterial, and, {{if it were}} forgotten or recorded incorrectly, then no practical difference would result, even for a very small business. However, a transaction of many millions of dollars is almost always material, {{and if it were}} forgotten or recorded incorrectly, then financial managers, investors, and others would make incorrect decisions as a result <b>of</b> this <b>error.</b> The <b>assessment</b> <b>of</b> what is material - where to draw the line between a transaction that is big enough to matter or small enough to be immaterial - depends upon factors such as the size of the organization's revenues and expenses, and is ultimately a matter of professional judgment.|$|R
40|$|Atmospheric {{measurements}} {{from new}} high spectral resolution remote sensing instruments will contain {{a huge amount}} of information. To use these data efficiently it is necessary to select a subset of the measurements for use in the retrieval of atmospheric profiles. The use of sections of spectrum, 'microwindows', increases the efficiency of forward model calculations. An objective scheme has been developed to select microwindows, which are optimal in spectral and altitude range, using the reduction in retrieval error. The method has been applied to MIPAS-B measurements, a balloon-borne Fourier transform infrared spectrometer. Results show reasonable retrieval <b>errors.</b> An <b>assessment</b> <b>of</b> the best achievable accuracy has been made, and the most important error sources are thus demonstrated...|$|R
40|$|AbstractObjectives. We {{sought to}} analyze the value of echocardiographic left {{ventricular}} (LV) diameters in assessing LV remodeling. Background. LV diameters are easily measured and commonly used {{as a substitute for}} volumetric analysis to evaluate LV remodeling caused by ventricular overload or dysfunction. However, the impact of these measurements on outcome is disputed, suggesting that they may not adequately assess LV remodeling. Methods. M-mode echocardiographically measured LV dimensions and the derived LV ejection fraction and end-systolic wall stress were compared with LV volumes and the derived LV ejection fraction and wall stress using the biplane Simpson rule. These measurements were made prospectively and simultaneously in 463 patients (289 men, 174 women; mean [±SD] age 62 ± 15 years), including 46 normal subjects, 52 with aortic regurgitation, 253 with mitral regurgitation and 112 with LV dysfunction. Results. The correlation between diameter and volume was good at end-systole (r = 0. 91, p < 0. 0001) and end-diastole (r = 0. 86, p < 0. 0001). However, the relation was exponential, and the 95 % confidence interval increased with increasing diameter. The calculated LV ejection fraction and wall stress using LV diameter and volume correlated linearly with a limited range <b>of</b> <b>error</b> (r = 0. 96, SEE = 5 %, p < 0. 0001 and r = 0. 95, SEE = 20 g/cm 2, p < 0. 0001, respectively). Conclusions. For assessing LV remodeling, LV diameters measured by M-mode echocardiography allow acceptable estimation of LV ejection fraction and wall stress and correlate significantly with LV volumes but are hindered by a wide range <b>of</b> <b>error</b> for <b>assessment</b> <b>of</b> LV size, especially for enlarged ventricles, suggesting that measurement of LV volume should be the preferred method of echocardiographically assessing LV remodeling...|$|R
