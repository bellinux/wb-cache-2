15|17|Public
500|$|It was {{reported}} these same <b>hardware</b> <b>integrity</b> checks would trigger an unrecoverable loop into [...] "Recovery Mode" [...] if iOS is updated or restored, with attempts {{to restore the}} device via iTunes software resulting in an [...] "error 53" [...] message. Beyond the explanation that this is related to <b>hardware</b> <b>integrity</b> errors regarding Touch ID components, Apple provided no official explanation of what specifically triggers error 53 or {{how it can be}} fixed without replacing the entire device.|$|E
50|$|The {{threat of}} a serious, malicious, design {{alteration}} can be especially relevant to government agencies. Resolving doubt about <b>hardware</b> <b>integrity</b> {{is one way to}} reduce technology vulnerabilities in the military, finance, energy and political sectors of an economy. Since fabrication of integrated circuits in untrustworthy factories is common, advanced detection techniques have emerged to discover when an adversary has hidden additional components in, or otherwise sabotaged, the circuit's function.|$|E
40|$|Every {{integrated}} circuit contains {{a piece of}} design-for-test (DFT) infra- structure in order to guarantee the chip quality after manufacture. The DFT resources are employed only once in the fab and are usually not available during regular system operation. In order to assess the <b>hardware</b> <b>integrity</b> of a chip over its complete life- cycle, {{it is promising to}} reuse the DFT infrastructure as part of system- level test. In this thesis, the provided system, a Tricore processor from Infineon, must be partitioned and modified in order to enable the autonomous structural test of every component of the system in the field without expensive external tester...|$|E
5000|$|Inspection {{and control}} of <b>hardware</b> means <b>integrity,</b> of system and {{application}} software located at the servers and workstations.|$|R
50|$|The International Electrotechnical Commission's (IEC) {{standard}} IEC 61508 defines SIL using requirements {{grouped into}} two broad categories: <b>hardware</b> safety <b>integrity</b> and systematic safety integrity. A device or system {{must meet the}} requirements for both categories to achieve a given SIL.|$|R
40|$|Abstract—Safety {{instrumented}} systems (SISs) {{are becoming}} increasingly complex {{and the proportion of}} programmable electronic parts is growing. The IEC 61508 global standard was established to ensure the functional safety of SISs, but it was expressed in highly macroscopic terms. This study introduces an evaluation process for <b>hardware</b> safety <b>integrity</b> levels through failure modes, effects, and diagnostic analysis (FMEDA). FMEDA is widely used to evaluate safety levels, and it provides the information on failure rates and failure mode distributions necessary to calculate a diagnostic coverage factor for a given component. In our evaluation process, the components of the SIS subsystem are first defined in terms of failure modes and effects. Then, the failure rate and failure mechanism distribution are assigned to each component. The safety mode and detectability of each failure mode are determined for each component. Finally, the <b>hardware</b> safety <b>integrity</b> level is evaluated based on the calculated results. Keywords—Safety instrumented system; Safety integrity level; Failure modes, effects, and diagnostic analysis; IEC 61508. I...|$|R
40|$|Engineers {{regularly}} analyze SSME {{ground test}} and flight data {{with respect to}} engine systems performance. Recently, a redesigned SSME powerhead was introduced to engine-level testing in part to increase engine operational margins through optimization of the engine internal environment. This paper presents {{an overview of the}} MSFC personnel engine systems analysis results and conclusions reached from initial engine level testing of the redesigned powerhead, and further redesigns incorporated to eliminate accelerated main injector baffle and main combustion chamber hot gas wall degradation. The conclusions are drawn from instrumented engine ground test data and <b>hardware</b> <b>integrity</b> analysis reports and address initial engine test results with respect to the apparent design change effects on engine system and component operation...|$|E
40|$|Abstract. 3 D {{integration}} is a promising advanced manufacturing process offering {{a variety of}} new hardware security protection opportunities. This paper presents a way of securing 3 D ICs using Hamiltonian paths as <b>hardware</b> <b>integrity</b> verification sensors. As 3 D integration consists in the stacking of many metal layers, one can consider surrounding a security-sensitive circuit part by a wire cage. After exploring and comparing different cage construction strategies (and reporting preliminary implementation results on silicon), we introduce a ”hardware canary”. The canary is a spatially distributed chain of functions Fi positioned at the vertices of a 3 D cage surrounding a protected circuit. A correct answer (Fn ◦ [...] . ◦ F 1) (m) to a challenge m attests the canary’s integrity. ...|$|E
40|$|Test {{programs}} for Software-based Self-Test (SBST) can be exploited during the mission phase of microprocessor-based systems to periodically assess <b>hardware</b> <b>integrity.</b> However, several additional constraints {{must be imposed}} due to the coexistence of test programs with the mission application. This paper proposes a method for the generation of SBST on-line test {{programs for}} embedded RISC processors, systems where the impact of on-line constraints is significant. The proposed strategy exploits an evolutionary optimizer that is {{able to create a}} complete test set of programs relying on a new cooperative scheme. Experimental results showed high fault coverage values on two different modules of a MIPS-like processor core. These two case studies demonstrate the effectiveness of the technique and the low human effort required for its implementatio...|$|E
50|$|The SIL {{requirements}} for <b>hardware</b> safety <b>integrity</b> {{are based on}} a probabilistic analysis of the device. In order to achieve a given SIL, the device must meet targets for the maximum probability of dangerous failure and a minimum safe failure fraction. The concept of 'dangerous failure' must be rigorously defined for the system in question, normally in the form of requirement constraints whose integrity is verified throughout system development. The actual targets required vary depending on the likelihood of a demand, the complexity of the device(s), and types of redundancy used.|$|R
40|$|Recovery in a {{fault-tolerant}} {{computer means}} {{the continuation of}} system operation with data integrity after an error occurs. This paper delineates two parallel concepts embodied in the hardware and software functions required for recovery; detection, diagnosis, and reconfiguration for <b>hardware,</b> data <b>integrity,</b> checkpointing, and restart for the software. The hardware relies on the recovery variable set, checking circuits, and diagnostics, and the software relies on the recovery information set, audit, and reconstruct routines, to characterize the system state and assist in recovery when required. Of particular utility is a handware unit, the recovery control unit, which serves as an interface between error detection and software recovery programs in the supervisor and provides dynamic interactive recovery...|$|R
40|$|Computer {{security}} {{is one of}} the most important factor of online/internet security. Computer {{security is}} the protection of computer assets by making sure that the computer system works properly, and any third party (un-authorized person, attacker) has no access to the sensitive information stored on the user's computer. This information can be Credit Cards details, User personal information, bank information & financial assets and user data. Security concerns associated with these advanced technologies like fraud, privacy invasion, hackers, lost data and computer viruses all are risking. Information on these concerns is often widely scattered. This volume attempts to bring these facts, figures and resources together to better assist the home user in navigating computer security issues like <b>hardware</b> drive <b>integrity</b> and backups, software bugs, protecting from data loss, privacy rights and policies and most important firewalls and virus protection...|$|R
40|$|We {{describe}} the software {{architecture of the}} Longitudinal Feedback System being built for the PEP-II BFactory at SLAC, the ALS light source at LBL and the DAFNE phi factory at Frascati. This VME/VXI based system utilizes commercially available embedded CPU controller boards running the VxWorks real time operating system. The operator interface for PEP-II and ALS {{is based on the}} EPICS control system package. Embedded processors are used to load, monitor and diagnose various components of the system. The feedback function is implemented using digital filtering techniques on a DSP farm residing in the VME crates. The operator interface is written to allow the loading of applications, e. g., accelerator diagnostic functions, system <b>hardware</b> <b>integrity</b> functions, etc., without intervening controller reboots. 1. INTRODUCTION The Longitudinal FeedBack (LFB) system [1] [2] is intended to be easily portable to various storage rings. In order to accomplish this, its control system software has [...] ...|$|E
40|$|With the {{globalization}} of semiconductor production, out-sourcing IC fabrication has become a trend in various aspects. This, however, introduces serious threats from the entire untrusted supply chain. To combat these threats, DARPA (Defense Advanced Research Projects Agency) proposed the SHIELD (Supply Chain <b>Hardware</b> <b>Integrity</b> for Electronics Defense) program to design a secure hardware root-of-trust, called dielet, to be inserted into the host package of legitimately produced ICs. Dielets are RF powered and communicate {{with the outside world}} through their RF antennas. They have sensors which allow them to passively (without the need for power) record malicious events which can later be read out during an authentication protocol between the dielet and server with a smartphone as intermediary. We propose the first concrete protocol design for initialization in SHIELD and an improved protocol design for authentication in SHIELD (compared to DARPA’s call for proposals for SHIELD). As the basis for authentication we propose to use AES counter mode encryption (as opposed to DARPA’s plain AES encryption). We show that this leads to several advantages: (1) resistance to a “try-and-check ” attack which in case of DARPA’s authentication protoco...|$|E
40|$|Objective. To {{describe}} {{the role of}} imaging in vascular composite allotransplantation based on one institution’s experience with upper extremity allotransplant patients. Methods. The institutional review board approved this review of HIPAA-compliant patient data {{without the need for}} individual consent. A retrospective review was performed of imaging from 2008 to 2011 on individuals undergoing upper extremity transplantation. This demonstrated that, of the 19 patients initially considered, 5 patients {{with a mean age of}} 37 underwent transplantation. Reports were correlated clinically to delineate which preoperative factors lead to patient selection versus disqualification and what concerns dictated postoperative imaging. Findings were subdivided into musculoskeletal and vascular imaging criterion. Results. Within the screening phase, musculoskeletal exclusion criterion included severe shoulder arthropathy, poor native bone integrity, and marked muscular atrophy. Vascular exclusion criterion included loss of sufficient arterial or venous supply and significant distortion of the native vascular architecture. Postoperative imaging was used to document healing and <b>hardware</b> <b>integrity.</b> Postsurgical angiography and ultrasound were used to monitor for endothelial proliferation or thrombosis as signs of rejection and vascular complication. Conclusion. Multimodality imaging is an integral component of vascular composite allotransplantation surgical planning and surveillance to maximize returning form and functionality while minimizing possible complications...|$|E
40|$|Often, {{valuable}} document processing {{intellectual capital}} is lost due to staff transitions or project restructuring prior to technology transfer. Furthermore, <b>hardware</b> and software <b>integrity,</b> dependencies, and compatibility are critical components that often impede technology migration. While many open source tools attempt to mitigate these issues, {{they do not}} always address specific design needs and tailored-process that Government organizations must adhere to. This paper addresses {{the need for a}} common document processing research vehicle through which institutions can develop and share researchrelated software and applications across academic, business, and Government domains. ...|$|R
40|$|Abstract—Remote {{attestation}} {{of computing}} platforms, using trusted <b>hardware,</b> guarantees the <b>integrity,</b> {{and by this}} the trustworthiness of a host to remote parties. While classical binary attestation attests the configuration itself, property-based attestation (PBA) attests properties and thus offers higher privacy guarantees to the host and its user. Nonetheless, both techniques are free from any user authentication mechanisms. Especially in distributed applications involving user interactions, the remote party may require assurance for the trustworthiness of the host and the authenticity of its user. Independence of user authentication from platform attestation may become an obstacle due to potential relay attacks. The User-Authenticated Property-Based Attestation (UPBA), introduced in this work, can assure a remote party that some computing platform is trustworthy, {{and that it is}} used at that very moment by some particular user...|$|R
40|$|Outsourcing {{services}} to third-party providers {{comes with a}} high security cost—to fully trust the providers. Using trusted hardware can help, but current trusted execution environments do not adequately support services that process very large scale datasets. We present LASTGT, a system that bridges this gap by supporting the execution of self-contained services over a large state, with a small and generic trusted computing base (TCB). LASTGT uses widely deployed trusted <b>hardware</b> to guarantee <b>integrity</b> and verifiability of the execution on a remote platform, and it securely supplies data to the service through simple techniques based on virtual memory. As a result, LASTGT is general and applicable to many scenarios such as computational genomics and databases, as we show in our experimental evaluation based on an implementation of LASTGT on a secure hypervisor. We also describe a possible implementation on Intel SGX...|$|R
40|$|Clinical Vignette:  A 64 -year-old {{male with}} a history of {{essential}} tremor with bilateral thalamic ventralis intermedius deep brain stimulation implants had elevated therapeutic impedance values despite normal lead integrity impedances and good response to stimulation. Clinical Dilemma:  Do elevated therapeutic impedance values indicate a sign of hardware malfunction? What are the guidelines to approach deep brain stimulation hardware malfunction? Clinical Solution:  Lead integrity impedance values are a better evaluation of <b>hardware</b> <b>integrity.</b> The discrepancy between therapeutic and lead-integrity impedance values can arise when using low voltage settings. Gaps in Knowledge:  There are no established guidelines for the management of possible hardware malfunction in deep brain stimulation. The recommended approach is to distinguish between open and short circuit problems followed by an “inching” evaluation, assessing the structures from the implantable and programmable generator to the intracranial leads. Constant-current devices will deliver a more stable stimulation but the effect of their adoption is still not clear. Expert Commentary:  This case emphasizes the need for clinicians to understand fundamental differences in lead integrity and therapeutic impedance while utilizing a methodical approach in treating hardware malfunction. It highlights future avenues of investigation regarding the utility of constant current DBS technology. </p...|$|E
40|$|This {{document}} {{presents an}} overview of a profiling and rut depth project. The objectives were to (1) assess the capabilities that are needed in to measure profile and rut depth at highway apeeds, (2) develop a design tailored to minimize life costs of the system, (3) build the system for delivery to FHWA, and (4) validate the system. A system based on the IBM PC microcomputer was designed. With {{the exception of a}} signal conditioning unit, the system is constructed from commercial components. The software controls the measurement of road profile and rut depth, the viewing of the data, and daily checks of the <b>hardware</b> <b>integrity.</b> A prototype-presently known as the PRORUT system-was built and delivered to the FHWA. A Road Profdometer Meeting (RPM) was organized to determine performance limits of the profiling capabilities of the PRORUT and 10 other profdometers. (The capability for measuring rut depth was added after the meeting; thus, the rut depth performance has not yet been tested to the same extent as the profiling capabilities.) There are three companion reports prepared as part of the same project. One is the PRORUT user's manual (FHWA/RD- 87 / 043), another is a reference manua...|$|E
40|$|AbstractWith {{increased}} use of forensic memory analysis, the soundness of memory acquisition becomes more important. We therefore present a black box analysis technique in which memory contents are constantly changed via our payload application with a traceable access pattern. This way, given the correctness of a memory acquisition procedure, we can evaluate its atomicity and one aspect of integrity as defined by Vömel and Freiling (2012). We evaluated our approach on several memory acquisition techniques represented by 12 memory acquisition tools using a Windows 7 64 -bit operating system running on a i 5 - 2400 with 2 GiB RAM. We found user-mode memory acquisition software (ProcDump, Windows Task Manager), which suspend the process during memory acquisition, to provide perfect atomicity and integrity for snapshots of process memory. Cold-boot attacks (memimage, msramdump), virtualization (VirtualBox) and emulation (QEMU) all deliver perfect atomicity and integrity of full physical system memory snapshots. Kernel level software acquisition tools (FTK Imager, DumpIt, win 64 dd, WinPmem) exhibit memory smear from concurrent system activity reducing their atomicity. There integrity is reduced by running within the imaged memory space, hence overwriting part of the memory contents to be acquired. The least amount of atomicity is exhibited by a DMA attack (inception using IEEE 1394). Further, even if DMA is performed completely in <b>hardware,</b> <b>integrity</b> violations {{with respect to the}} point in time of the acquisition let this method appear inferior to all other methods. Our evaluation methodology is generalizable to examine further memory acquisition procedures on other operating systems and platforms...|$|E
40|$|This paper {{describes}} {{the experiences of}} Collins Commercial Avionics and SRI International in formally specifying and verifying the microcode for the AAMP 5 microprocessor with the PVS verification system. This project was conducted to determine if an industrial microprocessor designed for use in real [...] time embedded systems could be formally specified at the instruction set and register transfer levels and if formal proofs {{could be used to}} prove the microcode correct. The paper provides a brief technical overview, but its emphasis is on the lessons learned in using PVS for an example of this size and the implications for using formal methods in an industrial setting. Keywords: Formal Methods, Formal Specification, Formal Verification, Microprocessor Verification, Microcode Verification, <b>Hardware</b> Verification, High <b>Integrity</b> Systems, Safety Critical Systems, PVS #### Software and digital hardware are increasingly being used in situations where failure could be life threatening, such as a [...] ...|$|R
40|$|The {{challenges}} faced in securing embedded computing systems against multifaceted memory safety vulnerabilities have prompted {{great interest in}} the development of memory safety coun-termeasures. These countermeasures either provide protection only against their corresponding type of vulnerabilities, or incur substantial architectural modifications and overheads in order to provide complete safety, which makes them infeasible for embedded systems. In this paper, we propose M-MAP: a comprehensive system based on multi-factor memory authentication for complete memory safety, inspired by everyday user authentication factors. We examine certain crucial theoretical and practical implications of composing memory integrity verification and bounds checking protection schemes in a comprehensive system. Based on these implications, we implement M-MAP with <b>hardware</b> based memory <b>integrity</b> verification and software based bounds checking to achieve a balance between hardware modifications and performance. We demonstrate that M-MAP implemented on top of a lightweight out-of-order processor delivers complete memory safety with only 32 % performance overhead on average, and incurs minimal hardware modifications and area overhead...|$|R
40|$|Remote {{attestation}} {{of computing}} platforms, using trusted <b>hardware,</b> guarantees the <b>integrity,</b> {{and by this}} the trustworthiness of a host to remote parties. While classical binary attestation attests the configuration itself, property-based attestation (PBA) attests properties and thus offers higher privacy guarantees to the host and its user. Nonetheless, both techniques are free from any user authentication mechanisms. Especially in distributed applications involving user interactions, the remote party may require assurance for the trustworthiness of the host and the authenticity of its user. Independence of user authentication from platform attestation may become an obstacle due to potential relay attacks. The User-Authenticated Property-Based Attestation (UPBA), introduced in this work, can assure a remote party that some computing platform is trustworthy, {{and that it is}} used at that very moment by some particular user. Our basic protocol is secure and practical. We prove its security formally, discuss its compatibility with current trusted computing technology, and illustrate several nice enhancements...|$|R
40|$|Performance of the Tethered Satellite System (TSS) Deployer {{during the}} STS- 46 mission (July and August 1992) is {{analyzed}} {{in terms of}} hardware operation at the component and system level. Although only a limited deployment of the satellite was achieved (256 meters vs 20 kilometers planned), the mission served to verify the basic capability of the Deployer to release, control and retrieve a tethered satellite. - Deployer operational flexibility that was demonstrated during the flight is also addressed. Martin Marietta was the prime contractor {{for the development of}} the Deployer, under management of the NASA George C. Marshall Space Flight Center (MSFC). The satellite was provided by Alenia, Torino, Italy under contract to the Agencia Spaziale Italiana (ASI). Proper operation of the avionics components and the majority of mechanisms was observed during the flight. System operations driven by control laws for the deployment and retrieval of the satellite were also successful for the limited deployment distance. Anomalies included separation problems for one of the two umbilical connectors between the Deployer and satellite, tether jamming (at initial Satellite fly-away and at a deployment distance of 224 meters), and a mechanical interference which prevented tether deployment beyond 256 meters. The Deployer was used in several off-nominal conditions to respond to these anomalies, which ultimately enabled a successful satellite retrieval and preservation of <b>hardware</b> <b>integrity</b> for a future re-flight. The paper begins with an introduction defining the significance of the TSS- 1 mission. The body of the paper is divided into four major sections: (1) Description of Deployer System and Components, (2) Deployer Components/Systems Demonstrating Successful Operation, (3) Hardware Anomalies and Operational Responses, and (4) Design Modifications for the TSS- 1 R Re-flight Mission. Conclusions from the TSS- 1 mission, including lessons learned are presented at the end of the manuscript...|$|E
40|$|The {{importance}} of Information Assurance (IA) in military operations cannot be overstated. It is a {{sine qua non}} that achieving IA requires the effort of all personnel in the organization; just a single untrained end-user is needed to defeat many well thought-out and well-executed security strategies This thesis demonstrated that CyberCIEGE, with its rich elements and tools, {{can be used to}} create game scenarios, mimicking real life IA issues, for conveying security lessons to a wide audience of trainees. It provides an excellent alternative to the traditional methods of security education which so often fail in driving home the intended lessons. A military-based CyberCIEGE scenario definition file (SDF) was developed to illustrate and train players on the {{importance of}} ensuring <b>hardware</b> and software <b>integrity</b> in operational-critical systems. The focus of the research was on the protection of sensitive information systems through the maintenance of their software integrity and the application of an airgapped network architecture. The test cases developed in this thesis research also contributed to the improvement of the CyberCIEGE game engine...|$|R
40|$|This paper evaluates sealed {{hardware}} {{that meets}} the requirements of DOE-STD- 3013, ''Criteria for Preparing and packaging Plutonium Metals and Oxides for Long-Term Storage'' with respect to radioactive material (Type B quantity) transportation requirements. The Standard provides criteria for packaging of the plutonium materials for storage periods of at least 50 years. The standard requires the <b>hardware</b> to maintain <b>integrity</b> under both normal storage conditions and under anticipated handling conditions. To accomplish this, the standard requires that the plutonium be loaded in {{a minimum of two}} nested stainless steel sealed containers that are both tested for leak-tightness per ANSI N 14. 5. As such the 3013 hardware is robust. While the 3013 STD may provide appropriate storage criteria, it is not intended to provide criteria for transporting the material under the requirements of the Department of Transportation (DOT). In this evaluation, it is assumed that the activity of plutonium exceeds A 1 and/or A 2 curies as defined in DOT 49 CFR 173. 431 and therefore must be shipped as a Type B package meeting the Nuclear Regulatory Commission (NRC) requirements of 10 CFR 71. The evaluation considers Type B shipment of plutonium in the 3013 hardware within a certified package for such contents...|$|R
40|$|This thesis investigates novel robust {{hardware}} {{elements for}} weightless artificial neural systems with a bias towards high integrity avionics applications. The author initially reviews {{the building blocks}} of physiological neural systems and then chronologically describes the development of weightless artificial neural systems. Several new design methodologies for the implementation of robust binary sum-and-threshold neurons are presented. The new techniques do not rely on weighted binary counters or registered arithmetic units for their operation making them less susceptible to transient single event upsets. They employ Boolean, weightless binary, asynchronous elements throughout thus increasing robustness in the presence of impulsive noise. Hierarchies formed from these neural elements are studied and a weightless probabilisitic activation function proposed for non-deterministic applications. Neuroram, an auto-associative memory created using these weightless neurons is described and analysed. The signal-to-noise ratio characteristics are compared with the traditional Hamming distance metric. This led to the proposal that neuroram can form a threshold logic based digital signal filter. Two weightless autoassociative memory based neuro-filters are presented and their filtration properties studied and compared with a traditional median filter. Eachn novel architecture was emulated using weightless numericM ATLAB code prior to schematic design and functional simulation. Several neural elements were implemented and validated using FPGA technology. A preliminary robustness evaluation was performed. The large scale particle accelerator at the Theodor Svedberg Laboratory at the University of Uppsala, Sweden, was used to generate transienut psetsin an FPGA performing a weightless binary neural function. One paper,two letters and five international patents have been published {{during the course of this}} research. The author has significantly contributed to the field of weightless artificial neural systems in high <b>integrity</b> <b>hardware</b> applications...|$|R
40|$|Future {{trend of}} RFID system is moving towards {{integration}} with other devices, and hence {{making it more}} pervasive. Even though RFID technology brings numerous benefits, it also comes with potential security and privacy threats. In this thesis, we investigate how the integration and interconnection of RFID system with other devices introduce security vulnerabilities which could be exploited by attackers and adversary systems equipped with advanced techniques and attacking tools to achieve their evil objectives. We examined past works on RFID with privacy-preserving solutions dealing with issues on system integrity and availability. We found out that these unprotected RFID system without integrity verification could also be subjected to malicious code attacks and impersonation attacks. We found a solution that could exactly protect the RFID system in three main protection areas, namely security, trust, and privacy (STP). We {{believe that we have}} used a unique approach in our research study because we have taken. into account all potential issues and we tackle them in a unified and integrated way. Our main contribution is that we proposed a unified STP protection in RFID framework which protected against unauthorized access and adversary attacks. We call this framework as MF-JaSa 2 RFID framework. The framework offers enhanced unified STP features in RFID system advanced techniques such as encrypted-based attestation, integrity verification techniques with respect to protect user privacy, utilization of Trusted Platform Module (TPM), a tamper proof <b>hardware</b> to provide <b>integrity</b> verification for RFID system and utilization of MJS-Watcher as runtime integrity-checker, elliptic curve cryptography (ECC) for security protection and anonymizer for privacy-preserving protection. Based on formal method analysis, we proved that MF-JaSa 2 RFID protocol always maintains its platforms in trusted and secured mode and keeps tags anonymous. Based on experiments, we proved MF-JaSa 2 framework is able to protect RFID system against any attack especially the runtime-based attack and impersonation attack. Finally, MF-JaSa 2 RFID framework is considered as trusted, secured and privacy-preserved RFID system...|$|R
40|$|Given {{the pervasiveness}} and {{extremely}} critical nature of activities performed by cyber-physical systems (CPSs), a better integration of security {{into the core}} architecture {{of the system is}} required in order to design and deploy survivable and secure infrastructures. The major challenges of modeling, designing and securing CPSs arise from the intrinsic heterogeneity, the geographical scale and the uncertainty regarding sensors readings, status and trustworthiness. These fundamental system properties of CPSs require to address security in ways more closely tied to the physical application and through a design that supports the inclusion of security within the application architecture. This thesis addresses challenges in both design and security of cyber-physical systems and its contribution is threefold. First, it proposes compositional and multiformalism modeling approaches for the design and validation of large scale monitoring infrastructures. The proposed approach is intended to integrate and model the interaction between different embedded nodes and between the environment and embedded nodes. The main limitation of state of art solution to modeling and simulating monitoring infrastructure, arise from their specificity: they are able to give a number of details on a particular aspect. Most of them are specifically intended to model a system part: such as network simulators, software simulators and hardware platform simulators. On the other hand, compositional and multiformalism modeling approaches allow the adoption of the best suiting modeling formalism at different levels of system abstraction and provide a concrete scalable mean to perform early performance evaluation and what-if analysis to ease the design process. They have been adopted in this thesis with regard to CPS's monitoring infrastructure modeling and simulation. Second, it proposes two ways to advance the software and hardware security for CPSs monitoring infrastructures. Todays approaches to secure the monitoring infrastructure are based on lightweight hardening techniques, in order not to stress the limited resources of wireless sensor nodes and this may limit their strength. Moreover, security seems to be approached as a feature that is not considered from the early stages of design and consequently is not intrinsically integrated within the embedded nodes architecture. On the other hand, this thesis proposes mechanisms for software and hardware security that are closely tied to the embedded architecture. As regards the software security, in this thesis efforts have been done to make security Adaptation Techniques (AT) applicable for embedded sensor nodes. Mechanisms based on AT consider security in a proactive way; the system is modified over time in order to reduce vulnerability exposure and disrupt attackers reconnaissance efforts. To make it possible to exploit the advantages of AT at the monitor infrastructure level, a novel node's software reconfiguration framework is presented. The feasibility of the proposed mechanism is shown for battery-supplied wireless sensor nodes through the demonstration of how to alter the network topology, exploit software diversity and react to threats. As regards the advances to the hardware security of the monitoring infrastructure, the thesis presents a special purpose hardware architecture specifically intended to address CPSs' physical security challenges through the adoption of TPM-based (Trusted Platform Module) architectures. An architecture based on FPGA is proposed and it is shown how it can provide secure primitives to asses the <b>hardware</b> and software <b>integrity,</b> as well as offering cryptographic operation. Finally, the thesis focuses on improving the processing infrastructure security. Efforts aimed at protecting CPSs should not only focus on the monitoring infrastructure even if it seems the weakest point. The processing infrastructure is generally composed of several networked systems. In this field a number of state of art solution are applicable. This thesis investigates the adoption of novel security adaptation techniques in order to overcame the limitation of static hardening techniques that are generally applied to networked systems. The focus will be on disrupting attacks that are intended to identify the CPS processing infrastructure's network architecture. The thesis will address this challenge by looking at security from a control prospective. Again it will exploit adaptation techniques but with the final goal of disrupting reconnaissance attack targeting CPS's back-end infrastructures. The thesis proposes a graph-based algorithmic solution to manipulate attacker's view of processing systems. This formalization is then used to design a deception based defense to defeating operating system and services fingerprinting. Experimental results show that the proposed approach can efficiently and effectively deceive attackers...|$|R

