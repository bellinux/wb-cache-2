3|14|Public
5000|$|Simply making {{source code}} {{available}} {{does not guarantee}} review. An example of this occurring is when Marcus Ranum, an expert on security system design and implementation, released his first public firewall toolkit. At one time, there were over 2,000 sites using <b>his</b> <b>toolkit,</b> but only 10 people gave him any feedback or patches.|$|E
40|$|This work {{deal with}} {{controlling}} of robotic arm EPSON {{both in terms}} of forward and inverse kinematics. The work describes the procedures how these kinematic chains solved with using knowledge homogeneous transformation. Subsequently are the results of the work simulated using program MatLAB with <b>his</b> <b>toolkit</b> Simulink...|$|E
40|$|A decade ago, a {{beautiful}} paper by Wagner [Wag 87] developed a "toolkit" that {{in certain cases}} allows one to prove problems hard for parallel access to NP. However, the problems <b>his</b> <b>toolkit</b> applies to most directly are not overly natural. During the past year, problems that previously were known only to be NP-hard or coNP-hard {{have been shown to}} be hard even for the class of sets solvable via parallel access to NP. Many of these problems are longstanding and extremely natural, such as the Minimum Equivalent Expression problem [GJ 79] (which was the original motivation for creating the polynomial hierarchy), the problem of determining the winner in the election system introduced by Lewis Carroll in 1876 [Dod 76], and the problem of determining on which inputs heuristic algorithms perform well. In the present article, we survey this recent progress in raising lower bounds. 1 Introduction Suppose you are given some nice, challenging problem and you are able to prove an NPhardness lower boun [...] ...|$|E
50|$|His {{research}} has also resulted {{in the development of}} techniques, tools and algorithms for high-performance distributed computing and parallel computing. <b>His</b> Globus <b>Toolkit</b> project encouraged collaborative computing for engineering, business and other fields. In March 2004, Foster co-founded Univa Corporation to commercialize the technology.|$|R
50|$|Mark Kilgard {{wrote and}} {{released}} many OpenGL technical sample programs during the pushback against Microsoft's competitive FUD against the API, and <b>his</b> GLUT <b>toolkit</b> (ported to Windows by Nate Robins) allowed these examples to run cross platform on Windows PC systems {{as well as}} SGI workstations.|$|R
50|$|From 1997 until 2007, Bouguet {{worked at}} Intel Research where he contributed camera {{calibration}} {{ideas to the}} Open Source Computer Vision Library (OpenCV), based on <b>his</b> Matlab <b>toolkit</b> that he developed at Caltech. In 2007 he joined Google as senior software engineer working in their Street View group.|$|R
5000|$|Amphetamine is {{frequently}} {{mentioned in the}} work of American journalist Hunter S. Thompson. Speed not only appears among the inventory of drugs Thompson consumed for what could broadly be defined as recreational purposes but also receives frequent, explicit mention as an essential component of <b>his</b> writing <b>toolkit,</b> such as in his [...] "Author's Note" [...] in Fear and Loathing on the Campaign Trail '72.|$|R
50|$|Peat {{trained as}} an {{economist}} at Bristol University and University College London. He worked as an economist for various UK Government departments - including a brief spell at HM Treasury and eight years at the Scottish Office - and also carried <b>his</b> economic <b>toolkit</b> to assignments overseas, to Bangkok in 1972-74 and Botswana in 1980-84.He was Group Chief Economist at the Royal Bank of Scotland. On 1 July 2005 Peat was appointed the Director of the David Hume Institute.|$|R
5000|$|As an {{intelligent}} and clever poet, Quasimodo used a hermetical, [...] "closed" [...] language to sketch recurring motifs like Sicily, religion and death. Subsequently, {{the translation of}} authors from Roman and Greek Antiquity enabled him to extend <b>his</b> linguistic <b>toolkit.</b> The disgust and sense of absurdity of World War II also had {{its impact on the}} poet's language.This bitterness, however, faded in his late writings, and was replaced by the mature voice of an old poet reflecting upon his world.|$|R
5000|$|Francesca {{stops at}} a mall and she, and Sheldon, walk off {{together}} while she sticks pieces of paper on an [...] "Exit" [...] sign and a palm tree. The papers show a drawing of long hair and eyebrows with the words [...] "I'm here". Francesca falls off a ledge and injures her knee. Sheldon repairs her knee with <b>his</b> built-in <b>toolkit,</b> and they listen to [...] "There Are Many of Us" [...] by ASKA & The Lost Trees on her car radio.|$|R
50|$|GTK+ was {{originally}} designed {{and used in}} the GNU Image Manipulation Program (GIMP) as a replacement of the Motif toolkit; at some point Peter Mattis became disenchanted with Motif and began to write <b>his</b> own GUI <b>toolkit</b> called the GIMP toolkit and had successfully replaced Motif by the 0.60 release of GIMP. Finally GTK was re-written to be object-oriented and was renamed GTK+. This was first used in the 0.99 release of GIMP. GTK+ was subsequently adopted for maintenance by the GNOME Foundation, which uses it in the GNOME desktop environment.|$|R
40|$|This paper {{presents}} a methodology for implementing natural language morphology in the functional language Haskell. The main idea behind is simple: {{instead of working}} with untyped regular expressions, which {{is the state of}} the art of morphology in computational linguistics, we use finite functions over hereditarily finite algebraic datatypes. The definitions of these datatypes and functions are the language-dependent part of the morphology. The languageindependent part consists of an untyped dictionary format which is used for synthesis of word forms, and a decorated trie, which is used for analysis. Functional Morphology builds on ideas introduced by Huet in <b>his</b> computational linguistics <b>toolkit</b> Zen, which he has used to implement the morphology of Sanskrit. The goal has been to make it easy for linguists, who are not trained as functional programmers, to apply the ideas to new languages. As a proof of the productivity of th...|$|R
40|$|This study {{explored}} mid-adolescents’ {{views and}} experiences of socio-ecological influences on their drinking practices {{in order to help}} inform the development of interventions to reduce alcohol-related risk. We conducted 31 in-depth interviews with young people aged 13 – 17 in North East England. Verbatim interview transcripts and field notes were coded systematically and analysed thematically, following the principles of constant comparison. We adopted Bourdieu’s idea of social game-playing and elements of <b>his</b> conceptual <b>toolkit</b> (particularly habitus, capital and field) during analysis. Analysis yielded three intersecting themes: (1) ‘drinking etiquette’: conveying taste and disgust; (2) ‘playing the drinking game’: demonstrating cultural competency; (3) ‘hidden habitus’—the role of alcohol marketing. Our work demonstrates that there is a nexus of influential factors which come together to help shape and reinforce mid-adolescents’ behaviour, norms and values in relation to alcohol consumption. Drinking practices are not just formed by friendships and family traditions, these are also subject to wider cultural shaping including by the alcohol industry which can encourage brand identification, and gear specific products to add ‘distinction’. However young people are not inactive players and they use aspects of capital and social games to help cement their identity and present themselves in particular ways which in turn are influenced by age, gender and social status. Guided by promising work in the tobacco field, interventions which focus on critical awareness of the framing of alcohol products by key stakeholders, such as policymakers, commercial industry and public health professionals, and by wider society may facilitate behaviour change among young people...|$|R
40|$|The main aim of {{my thesis}} is to mediate {{information}} about interactive {{tables in the}} Czech language teaching at elementary schools and elaboration of the methodical support for teaching. The thesis is divided into the theoretical part, which includes the first three chapters, and the practical part which has two chapters. In the theoretical part the author first introduces readers with interactivity, technical and historical development of the tables and their use in teaching. Second chapter brings knowledge about teaching methods {{with the use of}} interactive tables, the requirements on teachers, and the positive and negative advantages of the use of the tables based on the teachers and the students view. The third chapter represents main resources of teaching materials. The practical part is based on the creation of the methodical support for teaching, which provides detailed instructions for working with the SMART Table. The subject of the fourth chapter is working with the SMART table, adjustment of the table and the work with activities. Fifth chapter will introduce the computer program SMART Table <b>Toolkit,</b> <b>his</b> installation, adjustment, adjustment of activities and their use in teaching...|$|R
40|$|Diese Dissertation ist auf den Internetseiten der Hochschulbibliothek online verfügbar. To my parents, Ildikó and GáborAcknowledgments First of all I {{would like}} to thank my supervisor, Prof. Dr. -Ing. Hermann Ney, head of the Chair of Human Language Technology and Pattern Recognition, Lehrstuhl für Informatik VI, at the RWTH Aachen-University, for his support and his interest. He {{introduced}} me to speech recognition in 2000 when I started my studies as a PhD student and he has since then given me the opportunity and the freedom to pursue my ideas. I {{would also like to thank}} my second supervisor Prof. Dr. -Ing. Reinhold Häb-Umbach, head of the Department of Communications Engineering at the University of Paderborn, for his interest in this thesis and his valuable advice. I am very grateful to Dr. rer. -nat. Ralf Schlüter for his support in the field of signal analysis and acoustic modeling. His supportive coaching helped me to make decisions and to define my long-term research goals. I am also very much indebted to my colleagues Max Bisani and Stephan Kanthak for their advises in research and software technology. Their revolutionary ideas and delight in programming escorted me through the past five years. I am enriched by the experience of developing the new RWTH research software SPRINT in cooperation with Max and Stephan. I would also like to thank Georg Heigold for his hard work in designing and implementing the Discriminative Model Combination <b>toolkit.</b> <b>His</b> contribution was essential for completing the goals of this thesis. It should not be left unmentioned that I would not have enjoyed my last year without our two guest researchers. Prof. Umesh, from the Indian Institute of Technology, Kanpur, India, supported me with his experience and interest in feature extraction and especiall...|$|R
40|$|This thesis {{describes}} two {{applications of}} functional programming to process formal and natural languages. The techniques {{described in this}} thesis are closely connected to compiler construction, which is obvious in the work on BNF Converter. The {{first part of the}} thesis describes the BNFC (the BNF Converter) application, a multi-lingual compiler tool. BNFC takes as its input a grammar written in Labelled BNF (LBNF) notation, and generates a compiler front-end (an abstract syntax, a lexer, and a parser). Furthermore, it generates a case skeleton usable as the starting point of back-end construction, a pretty printer, a test bench, and a Latex document usable as a language specification. The program components can be generated in Haskell, Java, C and C++, and their standard parser and lexer tools. BNFC itself was written in Haskell. The methodology used for the generated front-end is based on Appel's books on compiler construction. BNFC {{has been used as a}} teaching tool in compiler construction courses at Chalmers. It has also beenapplied to research-related programming language development, and in an industrial application producing a compiler for a telecommunications protocol description language. The second part of the thesis describes Functional Morphology, a toolkit for implementing natural language morphology in the functional language Haskell. The main idea behind is simple: instead of working with untyped regular expressions, which is the state of the art of morphology in computational linguistics, we use finite functions over hereditarily finite algebraic data types. The definitions of these data types and functions are the language-dependent part of the morphology. The language-independent part consists of an untyped dictionary format which is used for translation to other morphology formats and synthesis of word forms, and to generate a decorated trie, which is used for analysis. Functional Morphology builds on ideas introduced by Huet in <b>his</b> computational linguistics <b>toolkit</b> Zen, which he has used to implement the morphology of Sanskrit. The goal has been to make it easy for linguists who are not trained as functional programmers, to apply the ideas to new languages. As a proof of the productivity of the method, morphologies for Swedish, Italian, Russian, Spanish, and Latin have already been implemented...|$|R
30|$|The legal {{organisation}} of multi-constituent revenue-seeking endeavours {{not only}} matters, but remains—for {{a large number}} of reasons (among others, predictability, enforceability, participation rights and responsibilities, resource allocation, asset partitioning, and the accounting, distribution and taxation of profits)—a core necessity for efficient collective productivity. Legal organisation happens—either proactively and by design (i.e. through proper advance planning) or reactively and by default (i.e. through post-investment statutory or common-law ‘gap-filling’ of incomplete contracts). Accordingly, for the current purpose of conceptualising triple helix intermediation organisationally, this article posits, as a secondary systems-theoretical hypothesis and assumption, that efficient triple helix trilateral network collaboration in action also critically requires an internal sphere- 1 intermediator ‘meeting platform’ (Suvinen et al. 2010 : 1369) which, as an institutionalised legal substructure specifically and exclusively works the interstitial spaces of a given triple helix trilateral network. To date, such organisational function has not been accomplished (nor been sufficiently analysed) from a legal perspective. Rather, it appears that the legal organisation of university-industry-government collaborations is pre-dominantly adapted from contractual, market-based mechanisms traditionally used for ‘simple [commercial and arm’s-length] supply-chain collaborations’ (Fitjar et al. 2014 : 2). For example, in the UK, the so-called Lambert toolkit, which has been in place since 2005 (Andersen et al. 2013; Eggington et al. 2013), is intended ‘for universities and companies that wish to undertake collaborative research projects with each other’ (UK Intellectual Property Office 2014) and ‘to help [the] potential collaborators negotiate deals, lower the transaction costs of the negotiations, and provide examples of best practice’ (Wrobel 2013). The toolkit includes five bilateral model research collaboration agreements, four multilateral model consortium agreements, a decision guide, and related guidance materials (UK Intellectual Property Office 2014). A 2013 research study (Eggington et al. 2013) commissioned by the UK Intellectual Property Office in order to empirically test awareness, adoption and overall utility of the Lambert toolkit among British universities and industry reported that the <b>toolkit</b> <b>‘is</b> most suitable [only] for a minority of university-business interactions,’ further concluded that ‘industrial support for the toolkit has been lacking [because] large companies are more likely to view the Lambert agreements as biased towards universities,’ and finally estimated that ‘less than 10 or 15  % by value of collaborative research between universities and business in the UK is based on a Lambert-like agreement’ (Eggington et al. 2013 : 3 – 4; see also Andersen et al. (2013 : 45)). In other words, the UK government’s contract-based and market-paradigmed solution to the intermediation of university-industry collaborations turned out to be ‘little used[,] seen as straightjacketing relationships between industry and academics, rather than enabling and supporting them[, and] not support[ing] open innovation’ (Wrobel 2013).|$|R

