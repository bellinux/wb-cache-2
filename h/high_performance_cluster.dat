80|10000|Public
5000|$|High Performance Cluster: IISER, Pune also {{houses a}} <b>High</b> <b>Performance</b> <b>Cluster</b> (HPC) boasting a 10 TB {{ultra-fast}} HDD, and sixty four nodes with 18 GB RAM per node. The faculty and research students use the HPC to solve real-life {{problems in the}} fields of biology, chemistry, materials science, nano-science, and computational physics.|$|E
40|$|The main {{objective}} of this poster is to present an affordable and easy-to-use <b>high</b> <b>performance</b> <b>cluster</b> system {{that can be used}} for the classroom in teaching-oriented computer science curriculum. In order to address this, we design and implement an affordable <b>high</b> <b>performance</b> <b>cluster</b> system that is based on PlayStation 3 (r). PS 3 is a well-known for game console manufactured by Sony. Since each PS 3 console has IBM Cell BE processor that consists of 8 Synergistic Processing Elements (SPEs) and 1 Power Processing Element (PPE), it can be used as a processing node with multiple-core processor in the cluster system. In addition, the implemented cluster system has been used for new and existing computer science courses, such as CPSC 592 : Parallel and Distributed Database, CPSC 590 : Parallel and Distributed Processing, and CPSC 591 : Parallel Programming...|$|E
40|$|The SIRAC {{laboratory}} {{has developed}} SciFS, a Distributed Shared Memory (DSM) {{that tries to}} benefit from the high performances and the remote addressing capabilities of the Scalable Coherent Interface (SCI) memory mapped network. We use SciFS for <b>high</b> <b>performance</b> <b>cluster</b> computing but we now experiment with it to build large scale clustered web caches...|$|E
40|$|The {{goals of}} <b>high</b> <b>performance</b> {{computing}} (HPC) seem {{at odds with}} current technology for computer security. Specifically, existing encryption algorithms that can protect network communication incur much larger overheads than are deemed acceptable in HPC environments. As a result, security within <b>high</b> <b>performance</b> <b>clusters</b> is all but ignored. As <b>high</b> <b>performance</b> <b>clusters</b> become used in more critical applications outside of academia, leaving security to chance becomes risky and undesirable...|$|R
5000|$|Clusters. To {{reduce the}} number of GPUs {{installed}} in <b>High</b> <b>Performance</b> <b>Clusters.</b> This leads to energy savings, as well as other related savings like acquisition costs, maintenance, space, cooling, etc.|$|R
5000|$|HPCC - LexisNexis Risk Solutions <b>High</b> <b>Performance</b> Computing <b>Cluster</b> ...|$|R
40|$|When a <b>high</b> <b>performance</b> <b>cluster</b> is demanded and {{the cost}} for {{purchase}} and operation of servers,workstations or personal computers as nodes is a challenge, single board computers may be an option t build inexpensive cluster systems. This paper describes the construction of such clusters and analyzes their performance and energy-efficiency with the High Performance Linpack (HPL) benchmark. ...|$|E
40|$|As the Grid evolves from a <b>high</b> <b>performance</b> <b>cluster</b> {{middleware}} to a multipurpose utility computing framework, a {{good understanding}} of Grid applications, their statistics and utilisation patterns is required. This study looks at job execution times and resource utilisations in a Grid environment, and their significance in cluster and network dimensioning, local level scheduling and resource management...|$|E
30|$|At {{the core}} of OTB is the C++ API, which {{implements}} the pipeline. This core model of processing supports multi-threading, streaming and message passing. Thus all applications and filters can process images and scale to the available memory and CPU resources. With additional features like in memory application chaining (to minimize disk I/O), porting code from a development machine and scaling up to a <b>high</b> <b>performance</b> <b>cluster</b> is often trivial.|$|E
40|$|The {{complexity}} of developing distributed applications for <b>High</b> <b>Performance</b> <b>Clusters</b> {{can be daunting}} to non-professional programmers such as physicists and mathematicians. This thesis investigates the possibility of creating a Virtual Machine capable of hiding the distributed properties of the environment under a Single System Image using the <b>high</b> <b>performance</b> InfiniBand technology, and its Remote Direct Memory Access operations...|$|R
50|$|HornetQ is an {{open source}} {{asynchronous}} messaging project from JBoss. It {{is an example of}} Message-oriented middleware. HornetQ {{is an open}} source project to build a multi-protocol, embeddable, very <b>high</b> <b>performance,</b> <b>clustered,</b> asynchronous messaging system. During much of its development, the HornetQ code base was developed under the name JBoss Messaging 2.0.|$|R
50|$|From 1994 to 1998, {{the company}} {{sponsored}} Charlton Athletic F.C., expiring when they won promotion to the FA Premier League. Viglen focuses {{particularly on the}} education and public sectors, selling both desktop and server systems. Viglen also has interests in other IT markets such as managed services, <b>high</b> <b>performance</b> <b>clusters,</b> and network attached storage.|$|R
40|$|Component {{oriented}} {{distributed computing}} uses {{a collection of}} different types of components to achieve high performance in solving a problem by identifying each component as an object. The usefulness of the transactional paradigm in Component Oriented Programming (COP) is explained. We also describe a simplified version of COP (a master-slave-like computation) that is suitable for <b>high</b> <b>performance</b> <b>cluster</b> computing and indicate how to implement this paradigm using MPI. 1...|$|E
40|$|This note applies {{conditional}} density estimation as {{a visual}} method to present results. The proposed method is illustrated by application to a firm-level manufacturing data set from Ecuador in 2002. We acknowledge the usage of the R package-hdrcde- by Hyndman and Einbeck (2006). We also acknowledge the usage of the Libra <b>High</b> <b>Performance</b> <b>Cluster</b> at Indiana University where the computations were performed. All remaining errors are our own...|$|E
40|$|The ALICE {{collaboration}} presents Quantum Corp with an award for the <b>high</b> <b>performance</b> <b>cluster</b> {{file system}} (StorNext) for the ALICE DAQ system, {{and for their}} outstanding cooperation in implementing the software. From left to right: Jurgen Schukraft (ALICE Spokesperson), Pierre vande Vyvre (ALICE DAQ), Hans Boggild (ALICE), Ewan Johnston (Quantum Corp.), Derek Barrilleaux (Quantum Corp.), Lance Hukill (Quantum Corp.), Ulrich Fuchs (ALICE DAQ), Catherine Decosse (ALICE) and Roberto Divia (ALICE DAQ) ...|$|E
40|$|<b>High</b> <b>performance</b> <b>clusters</b> {{have been}} widely used to provide amazing {{computing}} capability for both commercial and scientific applications. However, huge power consumption has prevented the further application of large-scale clusters. Designing energyefficient scheduling algorithms for parallel applications running on clusters, especially on the <b>high</b> <b>performance</b> heterogeneous <b>clusters,</b> is highly desirable. In this regard, we propose a novel scheduling strategy called energy efficient task duplication schedule (EETDS for short), which can significantly conserve power by judiciously shrinking communication energy cost when allocating parallel tasks to heterogeneous computing nodes. We present the preliminary simulation results for Gaussian and FFT parallel task models to prove the efficiency of our algorithm. 1...|$|R
50|$|The firm {{works with}} a <b>High</b> <b>Performance</b> Computing <b>Cluster</b> and {{develops}} specific software for different problem solutions.|$|R
5000|$|Rock Flow Dynamics tNavigator {{supports}} black oil, compositional {{and thermal}} compositional simulations for workstations and <b>High</b> <b>Performance</b> Computing <b>clusters</b> ...|$|R
40|$|Environment) at LRR-TUM investigates in <b>high</b> <b>performance</b> <b>cluster</b> {{computing}} using {{system area}} networks. In {{the context of}} this project, a hardware monitor is being developed to observe the SAN traffic. This hardware monitor is therefore capable of delivering detailed information about the run-time communication behavior of applications run on SMiLE clusters. The central part of this monitor consists of a contentaddressable counter array managing a small working set of the most recently referenced memory regions...|$|E
40|$|Fault {{management}} in <b>high</b> <b>performance</b> <b>cluster</b> networks {{has been focused}} on the notion of hard faults (i. e., link or node failures). Network degradations that negatively impact performance but do not result in failures often go unnoticed. In this paper, we classify such degradations as soft faults. In addition, we identify consistent performance as an important requirement in cluster networks. Using this service requirement, we describe a comprehensive strategy for cluster fault management...|$|E
40|$|Abstract—This article {{studies the}} {{performance}} optimization of the large-scale cluster system by the performance test for Dawning Tiankuo <b>high</b> <b>performance</b> <b>cluster</b> system. The efficiency {{of this system}} is exhibited through the test and analysis for this cluster system by running the test software in different parallel environment. Results prove that the high performance computer cluster has acceleration function and stability. These results offer a foundation for the exploiture and study. Index Terms—-performance, PCG, parallel computing, MPI, Open MP, PG...|$|E
40|$|This paper {{surveys the}} {{research}} on power management techniques for <b>high</b> <b>performance</b> systems. These include both commercial <b>high</b> <b>performance</b> <b>clusters</b> and scientific <b>high</b> <b>performance</b> computing (HPC) systems. Power consumption has rapidly risen to an intolerable scale. This results in both high operating costs and high failure rates so {{it is now a}} major cause for concern. It is imposed new challenges to the development of <b>high</b> <b>performance</b> systems. In this paper, we first review the basic mechanisms that underlie power management techniques. Then we survey two fundamental techniques for power management: metrics and profiling. After that, we review the research for the two major types of <b>high</b> <b>performance</b> systems: commercial <b>clusters</b> and supercomputers. Based on this, we discuss the new opportunities and problems presented by the recent adoption of virtualization techniques, and again we present the most recent research on this. Finally, we summarise and discuss future research directions. Key Words: <b>High</b> <b>performance</b> systems, Commercial <b>clusters,</b> Power management...|$|R
50|$|PelicanHPC is an {{operating}} {{system based on}} the Debian Live which provides a rapid means of setting up a <b>high</b> <b>performance</b> computer <b>cluster.</b>|$|R
50|$|In August 2007, Luxtera {{announced}} {{the availability of}} Blazar, a 40GB optical active cable for interconnect within <b>high</b> <b>performance</b> computer <b>clusters</b> using single-mode fiber.|$|R
3000|$|... may be feasible, but O(n^ 3) may exceed {{available}} resources. When computing distances, {{we chose}} algorithms that provide exact answers at {{costs less than}} quadratic. When computing centralities, we opted for approximation algorithms given {{the high cost of}} the exact ones. Computations were performed on the shared <b>High</b> <b>Performance</b> <b>Cluster</b> (HPC) Gaea at Northern Illinois University, typically using 5 nodes (each equipped with 2 Intel X 5650 processors and 72 Gb RAM). Our scripts for analysis are available within the ‘Analysis’ folder at [URL] [...]...|$|E
30|$|Christiane was {{a member}} of the <b>High</b> <b>Performance</b> <b>Cluster</b> Commission for the German Government and took part in the expert team on Industry 4.0 Smart Service World at the German Academy for Science and Engineering. She is an expert for Chinese SAFEA and European DG Regional & Urban Growth. Her {{research}} is on regional innovation systems linked to Strategy, Governance, and Organizational Design. She has evaluated Chinese, European, and US programs addressing innovation and carries out consulting for larger firms, SME, research organizations, cluster organizations, and scientific startups. Christiane teaches innovation studies at Heidelberg University.|$|E
40|$|Recent attacks enabled by stolen {{authentication}} passwords {{and keys}} have allowed intruders to masquerade as legitimate users on high performance computing clusters. With {{the motivation of}} detecting masqueraders on clusters, this work seeks to discriminate different types of users based on their command behavior [...] in particular, user command behavior on a multi-user public machine versus user command behavior on a high performance computing cluster. Our intuition is that these users act differently and the unique <b>high</b> <b>performance</b> <b>cluster</b> environment is constrained such that command behavior discrimination is enhanced versus enterprise environments...|$|E
5000|$|Computer Centre with <b>High</b> <b>Performance</b> Scientific Computing <b>cluster</b> ...|$|R
5000|$|The DEGIMA (DEstination for Gpu Intensive MAchine) is a <b>high</b> <b>performance</b> {{computer}} <b>cluster</b> {{used for}} hierarchical N-body simulations at the Nagasaki Advanced Computing Center, Nagasaki University.|$|R
40|$|Cloud {{environment}} is offering different {{services to the}} users {{and more and more}} companies are working to tap the benefits being provided by this environment. Data mining algorithms are proven algorithms to find hidden useful information from large database. K-Means clustering algorithm is one of the very popular and <b>high</b> <b>performance</b> <b>clustering</b> algorithms. The main aim of this work is to implement and deploy K-Means algorithm in Google Cloud using Google App Engine wit...|$|R
40|$|This work {{shows the}} results using {{different}} strategies {{to implement a}} simulation software in Java to measure {{the performance of a}} communication system with the main aim of obtaining gains in simulation processing time. The results obtained using a <b>high</b> <b>performance</b> <b>cluster</b> computing and a multi core desktop are described. Three different approaches are used, serial programming, parallel multithreading and Fork/Join. The simulation results shows that, as the parallelism increases a saturation occurs, and even a performance degradation is observed, indicating that the time processing gains are not a monotonically increasing function of the parallelism...|$|E
40|$|The cluster {{computing}} {{is becoming}} increasingly popular. The latest technological developments and research innovations are pushing clusters into mainstream computing. The <b>high</b> <b>performance</b> <b>cluster</b> provides an approach to parallel processing that yields super computer level performance. This trend makes it very promising to build high performance computing environments by clusters, with various performance measures from which high availability, load balancing and fault tolerance {{needs to be addressed}} The clusters present a set of challenges and have their own advantages and limitations. The clusters with their performance parameters are analyzed and are reported...|$|E
40|$|Abstract – This paper {{describes}} several {{scenarios that}} could potentially be used to implement attacks against a Linux <b>high</b> <b>performance</b> <b>cluster,</b> resulting in actions that corrupt information in the system (i. e. integrity issues), collect important information (i. e. confidentiality violations), and perform denial of service attacks (i. e. availability issues). These attacks were designed and tested for the MPI/PRO and C environments. We have implemented anomaly detection algorithms which are able to verify the correct execution of parallel programs. We also report representative results of our detection efforts that provide evidence of success. Technical level 4. Attacking a High Performance Computer Cluste...|$|E
40|$|<b>High</b> <b>performance</b> <b>clusters</b> play a {{vital role}} {{nowadays}} both in the industry and research area. In the past decade, some scheduling schemes have been investigated to achieve high availability or energy efficiency in large-scale clusters. However, leveraging scheduling algorithms to ensure <b>high</b> availability and <b>performance</b> while conserving energy remains an open problem. To bridge this technology gap, in this paper, we propose a high availability guaranteed energy efficient scheduling strategy (HAGEES for short) that aims at comprehensively consider the most important three factors, namely, availability, energy conservation, and <b>high</b> <b>performance...</b>|$|R
5000|$|Open Source Cluster Application Resources (OSCAR) is a Linux-based {{software}} installation for high-performance cluster computing. OSCAR {{allows users}} to install a Beowulf type <b>high</b> <b>performance</b> computing <b>cluster.</b>|$|R
40|$|AbstractThe OpenDBDDAS Toolkit is a {{software}} framework {{to provide support}} for more easily creating and expanding dynamic big data-driven application systems (DBDDAS) that are common in environmental systems, many engineering applications, disaster management, traffic management, and manufacturing. In this paper, we describe key features needed to implement a secure MapReduce and Hadoop-like system for <b>high</b> <b>performance</b> <b>clusters</b> that guarantees {{a certain level of}} privacy of data from other concurrent users of the system. We also provide examples of a secure MapReduce prototype and compare it to another <b>high</b> <b>performance</b> MapReduce, MR-MPI...|$|R
