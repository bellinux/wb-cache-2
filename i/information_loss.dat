2491|770|Public
25|$|A {{data loss}} {{prevention}} software platform, Digital Guardian integrates content, context and location awareness along with encryption and data level controls {{to reduce the}} risk of <b>information</b> <b>loss</b> or misuse, and purposeful data theft. Its host-based security technology empowers organizations to monitor, control, audit and prevent data from wrongful disclosure or malicious theft, while automatically enforcing data security policies and procedures. This scalable platform provides multiple, independent layers of protection to enable secure data sharing across physical, virtual, mobile and cloud environments.|$|E
25|$|However, {{according}} to the conjectured gauge-gravity duality (also known as the AdS/CFT correspondence), black holes in certain cases (and perhaps in general) are equivalent to solutions of quantum field theory at a non-zero temperature. This means that no <b>information</b> <b>loss</b> is expected in black holes (since the theory permits no such loss) and the radiation emitted by a black hole is probably the usual thermal radiation. If this is correct, then Hawking's original calculation should be corrected, {{though it is not}} known how (see below).|$|E
2500|$|The network {{construction}} (based on soft thresholding the [...] correlation coefficient) {{preserves the}} continuous {{nature of the}} underlying correlation information. For example, weighted correlation networks that are constructed {{on the basis of}} correlations between numeric variables do not require the choice of a hard threshold. Dichotomizing information and (hard)-thresholding may lead to <b>information</b> <b>loss.</b>|$|E
50|$|The 44.1 kHz {{sampling}} {{rate of the}} CD format, in theory, restricts CD <b>information</b> <b>losses</b> to above the theoretical upper-frequency limit of human hearing - 20 kHz, see Nyquist limit. Despite this, newer formats such as DVD-Audio and Super Audio Compact Disc (SACD), have {{sampling rate}}s of 88.2 kHz or 96 kHz or even higher.|$|R
40|$|Abstract- This paper proposes the use {{of network}} coding in {{handover}} strategies applied in Smart Gateway Diversity (SGD) architectures, in order to mitigate <b>information</b> <b>losses</b> usually experienced by traditional handover techniques. The focus is actually about the benefit resulting from network coding application in terms of improved transmission robustness {{at the cost of}} reasonable satellite capacity waste. 1...|$|R
40|$|The {{real-time}} {{operational requirements}} for SARCOM translation into a high speed image data handler and processor {{to achieve the}} desired compression ratios and {{the selection of a}} suitable image data compression technique with as low as possible fidelity (<b>information)</b> <b>losses</b> and which can be implemented in an algorithm placing a relatively low arithmetic load on the system are described...|$|R
2500|$|By 2003, {{consensus}} among physicists was growing that Hawking {{was wrong about}} the loss of information in a black hole. In a 2004 lecture in Dublin, he conceded his 1997 bet with Preskill, but described his own, somewhat controversial solution to the information paradox problem, involving the possibility that black holes have more than one topology. In the 2005 paper he published on the subject, he argued that the information paradox was explained by examining all the alternative histories of universes, with the <b>information</b> <b>loss</b> in those with black holes being cancelled out by those without such loss. In January 2014 he called the alleged loss of information in black holes his [...] "biggest blunder".|$|E
2500|$|Such an {{analysis}} was performed by Di Ventra and Pershin {{with regard to the}} genuine current-controlled memristor. As the proposed dynamic state equation [...] provides no physical mechanism enabling such a memristor to cope with inevitable thermal fluctuations, a current-controlled memristor would erratically change its state in course of time just under the influence of current noise. Di Ventra and Pershin thus concluded that memristors whose resistance (memory) states depend solely on the current or voltage history would be unable to protect their memory states against unavoidable Johnson–Nyquist noise and permanently suffer from <b>information</b> <b>loss,</b> a so-called [...] "stochastic catastrophe". A current-controlled memristor can thus not exist as a solid state device in physical reality.|$|E
2500|$|The victory {{scores of}} the pilots {{represented}} at List of World War I flying aces (pilots with at least five victories to their credit) often cannot be definitive, but are based on itemized lists that are the best available sources of <b>information.</b> <b>Loss</b> of records (especially records of casualties and lost aircraft, which are at their best a very good guide {{to the degree of}} over-claiming), by mischance and the passage of time – and the detail to which such records were kept in the first place – often complicates the reconstruction of [...] the actual count for a given ace. Additionally, the German victory confirmation system began to buckle in February 1918; after August 1918, such records as survived were unit records.|$|E
5000|$|Visual Information Fidelity (VIF): {{considers}} <b>information</b> fidelity <b>loss</b> at {{four different}} spatial scales ...|$|R
30|$|This {{research}} {{goes beyond}} the state-of-the-art by providing a method to effectively reduce the dimensionality of the consumption data time series and additional power-usage-relevant data (e.g., weather, energy price, GDP, holidays and weekends, etc.) while minimizing <b>information</b> <b>losses</b> and enhancing accuracy of results, which forms a corner stone of subsequent policy analysis through personalized smart-metering-based interventions on a usable level.|$|R
50|$|The Useware {{development}} process (see figure 1) distinguishes the following steps: analysis, structure design, design, realisation and evaluation.Each of these steps {{should not be}} regarded separately but rather overlapping. The continuity of the process {{as well as the}} use of suitable tools, e.g. {{on the basis of the}} Extensible Markup Language (XML) make it possible to avoid <b>information</b> <b>losses</b> and media breaks.|$|R
2500|$|MSUG then trained Vietnamese {{personnel}} in the use and maintenance of this equipment. In general, MSUG trained instructors, who could then teach others; direct instruction, except in special cases like revolver training for the presidential guard, [...] "was done only as a temporary expedient". The police administration project was largely successful in this, since the training was based in hands-on demonstration and thus much more immediate and tangible. Also, the MSUG-taught Vietnamese instructors rapidly assumed training themselves. At the same time, classroom sessions in the principles of police procedure and theory suffered {{from a number of}} problems that limited their success. Few MSUG professors spoke Vietnamese or French, leading to a translation delay and <b>information</b> <b>loss.</b> In addition, American-style lectures were a source of dissonance for a student body raised on the French juridical system. (This was also an issue in NIA classes taught by MSUG staff.) ...|$|E
2500|$|Einstein remarked [...] "God {{does not}} play dice with the Universe". And those agreeing with him {{are looking for}} a classical, {{deterministic}} aether theory that would imply quantum-mechanical predictions as a statistical approximation, a hidden variable theory. In particular, Gerard 't Hooft conjectured that: [...] "We should not forget that quantum mechanics does not really describe what kind of dynamical phenomena are actually going on, but rather gives us probabilistic results. To me, it seems extremely plausible that any reasonable theory for the dynamics at the Planck scale would lead to processes that are so complicated to describe, that one should expect apparently stochastic fluctuations in any approximation theory describing the effects of all of this at much larger scales. It seems quite reasonable first to try a classical, deterministic theory for the Planck domain. One might speculate then that what we call quantum mechanics today, may be nothing else than an ingenious technique to handle this dynamics statistically." [...] In their paper Blasone, Jizba and Kleinert [...] "have attempted to substantiate the recent proposal of G. ’t Hooft in which quantum theory is viewed as not a complete field theory, but is in fact an emergent phenomenon arising from a deeper level of dynamics. The underlying dynamics are taken to be classical mechanics with singular Lagrangians supplied with an appropriate <b>information</b> <b>loss</b> condition. With plausible assumptions about the actual nature of the constraint dynamics, quantum theory is shown to emerge when the classical Dirac-Bergmann algorithm for constrained dynamics is applied to the classical path integral [...]" ...|$|E
5000|$|... or in {{the dual}} {{variables}} as {{in the value of}} the Hamiltonian over the time horizon. To address the <b>information</b> <b>loss,</b> Ross and Fahroo introduced the concept of closure conditions which allow the known <b>information</b> <b>loss</b> to be put back in. This is done by an application of the covector mapping principle.|$|E
30|$|Besides the {{information}} that the care personnel receives from discussions with the client, the care personnel obviously needs information on previous conditions, laboratory results and other health history. When dealing with several service providers, {{it is essential that}} the flow of information from one actor to another is seamless with no time lag or <b>information</b> <b>losses.</b> Also methods of incorporating information provided by the individual (e.g. measurement data) to the official information systems are of importance.|$|R
50|$|For the {{professionals}} {{involved in a}} project, BIM enables a virtual information model to be handed from the design team (architects, landscape architects, surveyors, civil, structural and building services engineers, etc.) to the main contractor and subcontractors {{and then on to}} the owner/operator; each professional adds discipline-specific data to the single shared model. This reduces <b>information</b> <b>losses</b> that traditionally occurred when a new team takes 'ownership' of the project, and provides more extensive information to owners of complex structures.|$|R
40|$|Abstract. This paper {{deals with}} video {{transmission}} over lossy communication networks. The main {{idea is to}} develop video concealment method for <b>information</b> <b>losses</b> and errors correction. At the beginning, three main groups of video concealment methods, divided by encoder/decoder collaboration, are briefly described. The modified algorithm based on the detection and filtration of damaged watermark blocks encapsulated to the transmitted video was developed. Finally, the efficiency of developed algorithm is presented in experimental part of this paper...|$|R
5000|$|Restored and {{original}} texts are very close, some insignificant <b>information</b> <b>loss</b> ...|$|E
5000|$|Restored and {{original}} texts have some differences in meaning, important <b>information</b> <b>loss</b> ...|$|E
50|$|As an example, {{suppose that}} there are three {{candidate}} models, whose AIC values are 100, 102, and 110. Then the second model is exp((100 − 102)/2) = 0.368 times as probable as the first model to minimize the <b>information</b> <b>loss.</b> Similarly, the third model is exp((100 − 110)/2) = 0.007 times as probable as the first model to minimize the <b>information</b> <b>loss.</b>|$|E
40|$|It is {{designed}} a new quantum cryptography protocol that generates various secret and secure keys {{of the same}} size of the transmitted qubits, implying zero <b>information</b> <b>losses</b> between the interlocutors. Besides, generates key swapping between the two recipients of photons, without even sharing a past between them. This protocol differs from BB 84 just in the classic procedures, using a random seed and asymmetric cryptography. Comment: 3 pages, 1 Table, revtex 4, submitted for publication. Comments are welcom...|$|R
40|$|This paper {{deals with}} video {{transmission}} over lossy communication networks. The main {{idea is to}} develop video concealment method for <b>information</b> <b>losses</b> and errors correction. At the beginning, three main groups of video concealment methods, divided by encoder/decoder collaboration, are briefly described. The modified algorithm based on the detection and filtration of damaged watermark blocks encapsulated to the transmitted video was developed. Finally, the efficiency of developed algorithm is presented in experimental part of this paper. </em...|$|R
40|$|Information-theoretical {{restrictions}} on the information transfer in quantum measurements are studied. They are derived for the measurement of system S by detector D, registrated and processed by information system O. The formalism of inference maps in Hilbert space is used for it; it permit to calculate O restricted state which contains all finally available information on S parameters. It's shown that the principal <b>information</b> <b>losses,</b> inevitable in this formalism, stipulate the stochasticity of measurement outcomes registrated by O in the individual events...|$|R
5000|$|Restored and {{original}} texts have some differences in meaning, some insignificant <b>information</b> <b>loss</b> ...|$|E
5000|$|... #Subtitle level 2: Rate of <b>information</b> <b>loss</b> and {{sensitive}} dependence on initial conditions ...|$|E
5000|$|Restored and {{original}} texts have quite big differences in meaning and crucial <b>information</b> <b>loss</b> ...|$|E
40|$|Most {{existing}} QMFs closely {{match the}} derived closed form expression for an efficient class of Quadrature Mirror Filters. We use the closed form expressions to derive {{the relationship between}} <b>information</b> theoretic <b>loss</b> and the frequency selectivity of the QMF, by calculating first order entropy as well as rate distortion theoretic performance of a two band QMF system. We find that practical QMFs do not suffer a significant <b>information</b> theoretic <b>loss</b> with first order autoregressive Gaussian sources. With second order autoregressive sources we find that practical QMFs suffer a notable <b>information</b> theoretic <b>loss</b> when the bandwidth of the source is extremely narrow, but incur a small loss when the bandwidth is wider. We suggest that our results broadly apply to higher order autoregressive sources as well. Index Terms - quadrature mirror filters, subband coding, source coding, rate-distortion theory. 1 Introduction The discrete-time Fourier transforms of the impulse responses h l [...] ...|$|R
30|$|An MD video {{coding scheme}} using {{priority}} encoding transmission {{has been developed}} in the paper. Effective design of priority has been accommodated in the proposed system to achieve better performance against the packet loss rate. For the message construction, different motion characteristics between frames are taken into account, so in each message, better temporal correlation can be maintained for better estimation when <b>information</b> <b>losses</b> occur. Furthermore, {{in view of the}} compatibility with the standard video codec, the proposed scheme may be a worthy choice for the MD coding.|$|R
40|$|Abstract. A {{computer}} disk drive's {{motor speed}} varies slightly but irregularly, principally because of air turbulence inside the disk's enclosure. The unpredictability of turbulence is well-understood mathematically; it reduces not to computational complexity, but to <b>information</b> <b>losses.</b> By timing disk accesses, a program can e ciently extract at least 100 independent, unbiased bits per minute, at no hardware cost. This paper has three parts: a mathematical argument tracing our RNG's randomness to a formal de nition of turbulence's unpredictability, anovel {{use of the}} FFT as an unbiasing algorithm, and a check &quot; data analysis. ...|$|R
5000|$|To {{find the}} <b>information</b> <b>loss</b> when we discard {{some of the}} {{eigenvalues}} and eigenvectors we can perform following analysis: ...|$|E
50|$|Dimensionality {{reduction}} loses information, in general. PCA-based dimensionality reduction {{tends to}} minimize that <b>information</b> <b>loss,</b> under certain signal and noise models.|$|E
5000|$|To apply AIC in practice, {{we start}} {{with a set of}} {{candidate}} models, and then find the models' corresponding AIC values. There will almost always be information lost due to using a candidate model to represent the [...] "true" [...] model (i.e. the process that generates the data). We wish to select, from among the candidate models, the model that minimizes the <b>information</b> <b>loss.</b> We cannot choose with certainty, but we can minimize the estimated <b>information</b> <b>loss.</b>|$|E
40|$|At the {{ubiquitous}} age, applications of Wireless Personal Area Network (WPAN) technology using LEDs are in progress. However, visible light communication using LED have weakness, which deteriorates performance of communication. To reduce <b>information</b> <b>losses,</b> {{which is caused}} by optical noise, such as incandescent lamps, fluorescent lamps, sunbeam etc., proposed channel coding scheme, double binary turbo codes. In this paper, encoding scheme of the proposed system is described and simulation results are analyzed. We had expected improved performance by using double binary turbo codes. Finally, performances of the proposed system came up to our expectations...|$|R
40|$|Abstract. This paper {{describes}} a versatile, robust, and parametric ball animation model {{that can be}} used in many types of interactive Virtual Reality (VR) environments. The generic model is particularly useful for animation of ball-like objects such as tennis balls, footballs, or darts, and for networked collaborative environments where low frame rates, network delays and <b>information</b> <b>losses</b> complicate collision detection of fast moving objects. The ball animation model includes a multi-level physical modeling as well as collision detection and treatment. Finally, the parameterization of typical applications is discussed. ...|$|R
30|$|Inspired by [17], in this paper, {{we attempt}} to {{overcome}} the limitation of specific scalable video codec and apply FEC-MD to a common video coder, such as the standard H. 264. According to different motion characteristics between frames, an original video sequence is divided into several subsequences as messages, so in each message better temporal correlation can be maintained for better estimation when <b>information</b> <b>losses</b> occur. Based on priority encoding transmission, unequal protections are assigned in each message. Furthermore, the priority is designed in view of packet loss rate of channels and the significance of bit streams.|$|R
