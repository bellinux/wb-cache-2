0|7933|Public
50|$|With the Hand Unit most {{important}} recording {{features of the}} camera can be remote controlled: START/STOP, <b>frame</b> <b>rate</b> adjustment, <b>frame</b> <b>rate</b> ramp settings, <b>frame</b> <b>rate</b> jumps. The ergonomic design allows comfortable one hand use to start and stop recording. With the well fitted hand wheel the <b>frame</b> <b>rate</b> can be changed smoothly while recording.|$|R
40|$|Although {{motion is}} a {{defining}} feature of moving images, {{it is also}} one of their most problematic aspects due to blurred or partially stuttering images (strobe effect) at the standard <b>frame</b> <b>rate</b> of 24 <b>frames</b> per second (fps). This research was conducted to test the aesthetic and perceptual consequences of higher <b>frame</b> <b>rates</b> in narrative films. In a first step, typical camera movements were recorded at different <b>frame</b> <b>rates</b> and shutter angles to compare assumptions about production aesthetics. Film sequences were then tested using questionnaires and eye-tracking measurements in a cinema experiment involving 69 participants. The results showed that while participants valued the enhanced image quality of higher <b>frame</b> <b>rates,</b> they <b>rated</b> the standard <b>frame</b> <b>rate</b> as more realistic. Movements recorded with higher <b>frame</b> <b>rates</b> seem slower. In general, high <b>frame</b> <b>rates</b> produced more perceptual exploration (e. g. higher number of fixations). Second, a complete short film was shot at 96 fps and finished in different versions (96 fps, 48 fps, 24 fps, and a variable <b>frame</b> <b>rate).</b> All <b>frame</b> <b>rate</b> conversions were carried out in postproduction. The version with a variable <b>frame</b> <b>rate</b> was produced to assess its aesthetic potential. Several presentations and subsequent discussions with film professionals, experts, and students revealed an initial preference for the “cinematic look” of the standard <b>frame</b> <b>rate</b> of 24 fps. Some film professionals believe that both staging and editing need to be adapted to higher <b>frame</b> <b>rates.</b> This paper discusses the aesthetic, perceptual, and artistic consequences of higher <b>frame</b> <b>rates...</b>|$|R
40|$|We {{conducted}} a subjective quality assessment experiment {{to measure the}} impact of video <b>frame</b> <b>rate</b> decimation and variation in relation with impairment duration but also with content motion and texture. We found that for intermediate and high <b>frame</b> <b>rate</b> values, quality was similar independently from {{the duration of the}} <b>frame</b> <b>rate</b> decimation. On the other hand, for very low <b>frame</b> <b>rates,</b> quality decreased as the duration of the <b>frame</b> <b>rate</b> decimation increased. Our results also do not confirm the traditional thinking of higher motion content requiring a higher <b>frame</b> <b>rate</b> to produce a given level of quality. Our observations indicate that for a given <b>frame</b> <b>rate,</b> perceived quality does not necessarily increase with decreasing motion speed and that a reduction of the temporal resolution over the entire video does not lead necessarily to a significant loss of quality. Index Terms — MOS, <b>frame</b> <b>rate</b> decimation, jerkiness, mobile video broadcasting, video-conferencing. 1...|$|R
5000|$|Telecine: {{a method}} for {{converting}} film <b>frame</b> <b>rates</b> to television <b>frame</b> <b>rates</b> using interlacing ...|$|R
50|$|Digital Cinema Initiatives has {{published}} a document outlining recommended practice for high <b>frame</b> <b>rate</b> digital cinema. This document outlines the <b>frame</b> <b>rates</b> and resolutions {{that can be used}} in high <b>frame</b> <b>rate</b> digital theatrical presentations with currently available equipment.|$|R
50|$|The XH-A1S is {{a native}} HDV {{that is capable of}} {{recording}} 1080/24p, 1080/30p. When using the 1080/24p, or 1080/30p features, you should use the 24F (24 <b>frame</b> <b>rate)</b> or 30F (30 <b>frame</b> <b>rate)</b> mode in the Camera Setup menu. This camera is capable of shooting sports, television, music videos, commercials, and movies. (The 60 <b>frame</b> <b>rate</b> option is generally the best for sports.) Although this is a Video Camera, the 24F, or 24 <b>frame</b> <b>rate</b> option is usually the best option for replicating film. 24 <b>frame</b> <b>rate</b> is generally what is used when shooting Film.|$|R
50|$|The new {{standards}} supports 1080p at 50, 59.94 and 60 frames per second; such <b>frame</b> <b>rates</b> require H.264/AVC High Profile Level 4.2, while standard HDTV <b>frame</b> <b>rates</b> only require Levels 3.2 and 4, and SDTV <b>frame</b> <b>rates</b> require Levels 3 and 3.1.|$|R
5000|$|Bluesky <b>Frame</b> <b>Rate</b> Converter - a DirectShow Filter {{that can}} convert the <b>frame</b> <b>rate</b> using AMD Fluid Motion.|$|R
50|$|In {{motion picture}} technology—either film or video—high <b>frame</b> <b>rate</b> (HFR) refers to higher <b>frame</b> <b>rates</b> than typical prior practice.|$|R
30|$|The target <b>frame</b> <b>rate</b> of each {{recognition}} {{agent is}} set to 30 [*]fps. Then, the <b>frame</b> <b>rate</b> control is started.|$|R
30|$|Average <b>Frame</b> <b>Rate</b> (in <b>frames</b> per second). This {{measures}} {{the number of}} complete frames received per second, averaged over the duration of a measurement trial (the higher, the better). The <b>frame</b> <b>rate</b> may range from 0 to a maximum <b>frame</b> <b>rate</b> of 30 on the Axis cameras.|$|R
40|$|In this paper, the {{requirement}} and optimization of the <b>frame</b> <b>rate</b> for myocardial elastography {{was investigated in}} normal mice and humans in vivo. Using a retrospective electrocardiogram (ECG) gating technique, the highest <b>frame</b> <b>rate</b> was 8 kHz and 481 Hz, respectively. Axial displacement and strain of myocardium were estimated using an RF speckle tracking method consisting of a 1 -D kernel in a 2 -D search. The <b>frame</b> <b>rate</b> was then decimated to study its effects on the image quality of myocardial elastography, in terms of elastographic signal-to-noise (SNRe) and correlation coefficient. Trade-offs between SNRe and effective <b>frame</b> <b>rate</b> were identified in the murine case. The optimum range of <b>frame</b> <b>rate</b> {{was found to be}} between 2000 and 2700 Hz, or equivalently, 250 - 350 frames per cardiac cycle (fpc). In the human case, the image quality increased monotonously with the <b>frame</b> <b>rate.</b> A <b>frame</b> <b>rate</b> higher than 480 Hz (i. e., 350 fpc) was thus required for both systole and diastole. © 2007 IEEE. link_to_subscribed_fulltex...|$|R
5000|$|Theora streams with {{different}} <b>frame</b> <b>rates</b> can be chained {{in the same}} file, but each stream has a fixed <b>frame</b> <b>rate.</b>|$|R
500|$|Many reviewers {{considered}} the technical enhancements, {{such as the}} increased <b>frame</b> <b>rate,</b> a welcome advancement from the original game. Turi of Game Informer felt that the <b>frame</b> <b>rate</b> [...] "dramatically elevate" [...] the game above the original. Jim Sterling of The Escapist complimented the upgraded <b>frame</b> <b>rate,</b> commenting that the original <b>frame</b> <b>rate</b> is a [...] "noticeably inferior experience". IGN's Moriarty stated that, though the change was initially [...] "jarring", he appreciated it through further gameplay. Tom Hoggins of The Daily Telegraph echoed these statements, feeling as though the increased <b>frame</b> <b>rate</b> heightened {{the intensity of the}} gameplay. Metros David Jenkins felt that the increased <b>frame</b> <b>rate</b> is almost imperceptible, though stating that it is [...] "definitely an improvement". Philip Kollar of Polygon appreciated the game's improved textures and loading times.|$|R
3000|$|... (fps) is {{the target}} <b>frame</b> <b>rate.</b> The <b>frame</b> <b>rate</b> is {{stabilized}} by controlling the load of the recognition modules. Control inputs are determined {{in accordance with the}} response from <b>frame</b> <b>rate</b> detector. The feedback control is applied as long as the control deviation does not fall within the minimal error range.|$|R
40|$|The <b>rate</b> {{at which}} <b>frames</b> are {{rendered}} {{in a computer}} game directly impacts player performance, influencing both the game playability and enjoyability. However, despite the importance of <b>frame</b> <b>rate</b> and the wide-spread popularity of computer games, {{to the best of}} our knowledge, there is little quantitative understanding of the effects of <b>frame</b> <b>rate</b> on player performance in computer games. This paper provides a unique classification of actions in First Person Shooter (FPS) games based on interaction requirements that allow qualitative assessment of the impact of <b>frame</b> <b>rates</b> on player performance. This qualitative assessment is supported by quantitative analysis from two large user studies that measure the effects of <b>frame</b> <b>rate</b> on the fundamental player actions in a FPS game. Nearly 100 users participated in the two user study experiments, providing performance and perception data over a range of <b>frame</b> <b>rates</b> commonly studied for video streaming and inclusive of <b>frame</b> <b>rates</b> found in many computer game platforms. In general, the analysis shows that actions that require precise, rapid response, such as shooting, are greatly impacted by degradations in <b>frame</b> <b>rates,</b> while actions with lower precision and response requirements, such as moving, are more tolerant of low <b>frame</b> <b>rates.</b> These insights into the effects of <b>frame</b> <b>rates</b> on player performance can guide players in their choice for game settings and new hardware purchases, and inform system designers in their development of new hardware...|$|R
30|$|Increasing {{the number}} of p-pictures also {{increases}} the scalability ratio in terms of bit <b>rate</b> and <b>frame</b> <b>rate.</b> Depending on the sequence the IpP coding allows for up to 33 % bit rate reduction, which means that 33 % of the total bit rate lies in the temporal enhancement layer. The <b>frame</b> <b>rate</b> can be reduced by half. Using IppP allows for bit rate reduction of slightly over 50 %, whereas the <b>frame</b> <b>rate</b> {{can be reduced to}} one-third of the full <b>frame</b> <b>rate.</b> The IpppP coding structure can offer two temporal enhancement layers. Dropping the first temporal layer results in similar scalability features as observed with IpP coding. Additional dropping the second temporal layer allows a bit rate reduction up to 60 % with the football sequence and a <b>frame</b> <b>rate</b> reduction down to one-fourth of the full sequence <b>frame</b> <b>rate.</b>|$|R
50|$|Internally, the EVR uses a mixer object for {{mixing the}} streams. It can also deinterlace the output and apply color correction, if required. The composited frame is handed {{off to a}} {{presenter}} object, which schedules them for rendering onto a Direct3D device, which it shares with the DWM and other applications using the device. The <b>frame</b> <b>rate</b> of the output video is synchronized with the <b>frame</b> <b>rate</b> of the reference stream. If {{any of the other}} streams (called substreams) have a different <b>frame</b> <b>rate,</b> EVR discards the extra frames (if the substream has a higher <b>frame</b> <b>rate),</b> or uses the same frame more than once (if it has a lower <b>frame</b> <b>rate).</b>|$|R
50|$|In {{moving picture}} (TV) {{the number of}} frames scanned per second {{is known as the}} <b>frame</b> <b>rate.</b> The higher the <b>frame</b> <b>rate,</b> the better the sense of motion. But again, {{increasing}} the <b>frame</b> <b>rate</b> introduces technical difficulties. So the <b>frame</b> <b>rate</b> is fixed at 25 (System B/G) or 29.97 (System M). To increase the sense of motion it is customary to scan the very same frame in two consecutive phases. In each phase only half of the lines are scanned; only the lines with odd numbers in the first phase and only the lines with even numbers in the second phase. Each scan is known as a field. So the field rate is two times the <b>frame</b> <b>rate.</b>|$|R
30|$|Temporal scalability. The {{base layer}} is coded {{at a low}} <b>frame</b> <b>rate.</b> By adding {{enhancement}} layers, the <b>frame</b> <b>rate</b> of the decoded sequence can be increased.|$|R
30|$|The <b>frame</b> <b>rates</b> {{at source}} sensor nodes are {{calculated}} {{in a different}} manner for each protocol. SUIT and FCE use fuzzy logic-based approach whereas QCC uses local buffer occupancy for deciding on the congestion level. According to the congestion level, the <b>frame</b> <b>rate</b> is assigned dynamically while generating images. In Figure  10, the average calculated <b>frame</b> <b>rate</b> at the source sensor nodes is illustrated. All of the protocols decrease the <b>frame</b> <b>rate</b> as the network is getting congested. QCC estimates the congestion level optimistically and therefore calculates higher <b>frame</b> <b>rates</b> than the others. On the other hand, FCE estimates the congestion in a pessimistic manner and calculates lower <b>frame</b> <b>rates</b> than the others. SUIT provides a balanced congestion level via its efficient fuzzy logic-based congestion estimation technique. Therefore, SUIT provides better performance than its competitors in all QoS metrics, except of the average received frame quality.|$|R
40|$|Conventional <b>frame</b> <b>rate</b> up-conversion {{adopted in}} low hit-rate video codinglstrcaniing cannot obtain good quality due to {{artifacts}} caused hy composition problems. In this paper, a region bascd multiple frame-rate tradcoff scheme is proposcd to reduce artifacts. The video frames {{are divided into}} regions of interest (KOIs) and backgrounds by the visual attention model. The motion intensity and complexity of KO 1 and background are computed by perceptive motion energy spectrum (PMES) to decide {{the ratio of the}} <b>frame</b> <b>rate</b> of ROI to that of background. The background is encoded at a low <b>frame</b> <b>rate,</b> and up-converted to the same. <b>frame</b> <b>rate</b> as R 01 at the decoder, with an integrated background motion composition model. The experimental results indicate that, compared to conventional <b>frame</b> <b>rate</b> up-conversion and normal codec schemc without <b>frame</b> <b>rate</b> up-conversion at the same bandwidth, the proposed scheme has higher PNSR performance and better subjective visual quality...|$|R
40|$|We {{present a}} pilot study {{investigating}} the relationship between <b>frame</b> <b>rate</b> and latency and their effects on moving target selection. In several latency/frame rate conditions, participants were given a 20 second time frame to click as many moving targets as possible. Performance with 60 FPS <b>frame</b> <b>rate</b> was 14 % higher than 30 FPS, but the difference between 45 and 60 FPS was not significant. Latency alone had lower impact than the corresponding <b>frame</b> <b>rate</b> difference. While both factors impact performance, <b>frame</b> <b>rate</b> had a larger effect than the latency it introduces...|$|R
50|$|Format {{identifiers}} like 576i 50 and 720p 50 {{specify the}} <b>frame</b> <b>rate</b> for progressive scan formats, but for interlaced formats they typically specify the field rate (which is twice the <b>frame</b> <b>rate).</b> This {{can lead to}} confusion, because industry-standard SMPTE timecode formats always deal with <b>frame</b> <b>rate,</b> not field rate. To avoid confusion, SMPTE and EBU always use <b>frame</b> <b>rate</b> to specify interlaced formats, e.g., 480i 60 is 480i/30, 576i 50 is 576i/25, and 1080i 50 is 1080i/25. This convention assumes that one complete frame in an interlaced signal consists of two fields in sequence.|$|R
50|$|In early cinema history, {{there was}} no {{standard}} <b>frame</b> <b>rate</b> established. Edison's early films were shot at 40 fps, while the Lumière Brothers used 16 fps. This {{had to do with}} a combination of the use of a hand crank rather than a motor, which created variable <b>frame</b> <b>rates</b> because of the inconsistency of the cranking of the film through the camera. After the introduction of synch sound recording, 24 fps became the industry standard <b>frame</b> <b>rate</b> for capture and projection of motion pictures. 24 fps was chosen because it was the minimum <b>frame</b> <b>rate</b> that would produce adequate sound quality. This was done because film was expensive, and using the lowest possible <b>frame</b> <b>rate</b> would use the least amount of film.|$|R
50|$|SheerVideo {{supports}} all standard {{resolutions and}} <b>frame</b> <b>rates,</b> including the NTSC and PAL or SECAM SD formats and all HD formats, {{as well as}} arbitrary resolutions and <b>frame</b> <b>rates.</b>|$|R
50|$|Digital cinema {{equipment}} is now {{capable of handling}} much higher <b>frame</b> <b>rates,</b> such as the 48p <b>frame</b> <b>rate</b> , along with the traditional 24p. 48p has twice the motion resolution of 24p, but also requires more bandwidth, data storage, and potentially illumination level. Peter Jackson's three part film The Hobbit is a production that makes use of the 48p <b>frame</b> <b>rate.</b>|$|R
40|$|The {{preservation}} of QoS for multimedia traffic through a data network {{is a difficult}} problem. We focus our attention on video <b>frame</b> <b>rate</b> and study its influence on speech perception. When sound and picture are discrepant (e. g., acoustic "ba" combined with visual "ga"), subjects perceive a different sound (such as "da"). This phenomenon {{is known as the}} McGurk effect. In this paper, the influence of degraded video <b>frame</b> <b>rate</b> on speech perception was studied. It was shown that when <b>frame</b> <b>rate</b> decreases, correct hearing is improved for discrepant stimuli and is degraded for congruent (voice and picture are the same) stimuli. Furthermore, we studied the case where lip closure was always captured by the synchronization of sampling time and lip position. In this case, <b>frame</b> <b>rate</b> has little effect on mishearing for congruent stimuli. For discrepant stimuli, mishearing is decreased with degraded <b>frame</b> <b>rate.</b> These results indicate that stiff motion of lips resulting from low <b>frame</b> <b>rate</b> cannot [...] ...|$|R
40|$|User {{performance}} in virtual environments with degraded visual conditions due to low <b>frame</b> <b>rates</b> {{is an interesting}} area of inquiry. Visual content shown in a low <b>frame</b> <b>rate</b> simulation has {{the quality of the}} original image, but persists for an extended period until the next frame is displayed (so-called high persistence - HP). An alternative, called low persistence (LP), involves displaying the rendered frame for a single display frame and blanking the screen while waiting for the next frame to be generated. Previous research has evaluated the usefulness of the LP technique in low <b>frame</b> <b>rate</b> simulations during a static target acquisition task. To gain greater knowledge about the LP technique, we have conducted a user study to evaluate user performance and learning during a dynamic target acquisition task. The acquisition task was evaluated under a high <b>frame</b> <b>rate,</b> (60 fps) condition, a traditional low <b>frame</b> <b>rate</b> HP condition (10 fps), and the experimental low <b>frame</b> <b>rate</b> LP technique. The task involved the acquisition of targets moving along several different trajectories, modeled after a shotgun trap shooting task. The results of our study indicate the LP condition approaches high <b>frame</b> <b>rate</b> performance within certain classes of target trajectories. Interestingly we also see that learning is consistent across conditions, indicating that it may not always be necessary to train under a visually high <b>frame</b> <b>rate</b> system to learn a particular task. We discuss implications of using the LP technique to mitigate low <b>frame</b> <b>rate</b> issues as well as for training both virtual and real world tasks...|$|R
50|$|Before 2011, UHDTV {{allowed for}} <b>frame</b> <b>rates</b> of 24, 25, 50, and 60 fps. In an ITU-R meeting during 2011, an {{additional}} <b>frame</b> <b>rate</b> {{was added to}} UHDTV of 120 fps.|$|R
40|$|We {{developed}} a compact vision system for wearable interface applications using a vision chip. The vision chip {{is capable of}} real-time vision at higher <b>frame</b> <b>rates</b> than the video <b>frame</b> <b>rate</b> with a single chip. Using this system, vision-based wearable man-machine interfaces, such as a portable eye tracker and a six-degrees-of-freedom input device, can be realized at higher <b>frame</b> <b>rates</b> than ever before. 1...|$|R
25|$|Frame rate: High <b>frame</b> <b>rates</b> (i.e. images {{acquired}} per second) {{are needed}} to visualize fast motion without stroboscopic effects. However, the higher the <b>frame</b> <b>rate,</b> the higher the radiation dose. Therefore, the <b>frame</b> <b>rate</b> should be chosen according to the clinical need and be as low as reasonably possible. For example, in pediatric cardiology, <b>frame</b> <b>rates</b> of 60 pulses per second are required compared to 0.5 p/s for slowly moving objects. A reduction to half pulse rate reduces dose by about half. The reduction from 30 p/s to 7.5 p/s results in a dose saving of 75%.|$|R
50|$|When {{vertical}} synchronization is used, the <b>frame</b> <b>rate</b> of the {{rendering engine}} gets {{limited to the}} video signal <b>frame</b> <b>rate.</b> Though this feature normally improves video quality, it involves trade-offs in some cases.|$|R
5000|$|Ultrafast imaging. A single laser shot {{is needed}} to produce one image. The <b>frame</b> <b>rate</b> is thus limited to the {{repetition}} rate of the laser system or the <b>frame</b> <b>rate</b> of the CCD camera.|$|R
30|$|<b>Frame</b> <b>rate</b> (temporal resolution) dropped {{significantly}} in the received images. <b>Frame</b> <b>rate</b> as viewed on the laptop was equal to the <b>frame</b> <b>rate</b> viewed on the ultrasound machine, approximately 11.9  fps at a scanning depth of 13  cm. On the iPhone <b>frame</b> <b>rate</b> dropped to approximately 1.1  fps at this depth when connected via WiFi (approximately 11 times slower), and 0.4  fps when connected via 3 G (approximately 31  times slower). For the majority of applications (FAST, aorta, pericardial effusion) images viewed at this slow <b>frame</b> <b>rate</b> were still perfectly sufficient to make an accurate diagnosis. <b>Frame</b> <b>rate</b> did affect the ability to judge cardiac ejection fraction, as accurate estimation of this requires real-time visualization of motion. For the same reason, {{one would expect that}} other motion-dependent applications may also be challenging, such as advanced echo, Doppler, or procedural guidance. While actual lung sliding was difficult to perceive at 0.4  fps, the lung tissue deep to the pleural line was visualized at different positions. In addition, comet tails were observed, and these findings together were enough for the IP to make the interpretation of “no pneumothorax.” <b>Frame</b> <b>rate</b> is dependent on the depth and on the ultrasound machine ranged from 24.8  fps at a depth of 4.7  cm to 5.8 fps at a depth of 30  cm. We did not measure the <b>frame</b> <b>rate</b> of the received images at these other depths, but presumably they would have decreased proportionately.|$|R
30|$|The motion {{synthesis}} method {{can be used}} {{to increase}} the <b>frame</b> <b>rate</b> of the motion data. The current commercially available depth cameras have an update rate of 50 – 60  Hz with variable <b>frame</b> <b>rates</b> depending on the computational load. The motion synthesis method {{can be used to}} increase and stabilize the <b>frame</b> <b>rate</b> as motion data is synthesized by a separate thread once the gesture is recognized.|$|R
