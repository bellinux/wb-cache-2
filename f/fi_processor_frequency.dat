0|326|Public
50|$|AMD Turbo Core {{is similar}} to Intel Turbo Boost, which is another dynamic <b>processor</b> <b>frequency</b> {{adjustment}} technology used to increase performance, as well as AMD PowerNow!, {{which is used to}} dynamically adjust laptop <b>processor's</b> operating <b>frequencies</b> in order to decrease power consumption (saving battery life), reduce heat, and lower noise. AMD PowerNow! is used to decrease <b>processor</b> <b>frequency,</b> whereas AMD Turbo Core is used to increase <b>processor</b> <b>frequency.</b>|$|R
5000|$|<b>Processor</b> <b>frequency</b> up to 600 MHz (LX900), 500 MHz (LX800) and 433 MHz (LX700).|$|R
5000|$|The {{effect of}} <b>processor</b> <b>frequency</b> on {{computer}} speed {{can be seen}} by looking at the equation for computer program runtime: ...|$|R
30|$|In this section, {{the impact}} of <b>processor</b> <b>frequency</b> on the context switch {{overhead}} for static and dynamic frequency cases is discussed.|$|R
30|$|The voltage Vdrop {{across the}} {{processor}} increases {{with the rise}} of the <b>processor</b> <b>frequency</b> so that the power consumption increases with the frequency.|$|R
30|$|DVFS is {{a method}} used to control a <b>processor's</b> {{calculation}} <b>frequency</b> {{to reduce the amount}} of energy used for calculations. Basically, when the number of calculations is large, the voltage is amplified to increase the <b>processor's</b> <b>frequency.</b> The correlation formula can be calculated using formulas  8 and 9 as with [2, 16, 17].|$|R
5000|$|In {{computer}} architecture, {{frequency scaling}} (also known as frequency ramping) is {{the technique of}} increasing a <b>processor's</b> <b>frequency</b> so as to enhance {{the performance of the}} system containing the <b>processor</b> in question. <b>Frequency</b> ramping was the dominant force in commodity processor performance increases from the mid-1980s until roughly the end of 2004.|$|R
50|$|The SPARC T5 {{processor}} {{is used in}} Oracle's {{entry and}} mid-size SPARC T5-2, T5-4, and T5-8 servers. All servers are using the same <b>processor</b> <b>frequency,</b> number of cores per chip and cache configuration.|$|R
40|$|Nowadays, {{virtualization}} {{is present}} in almost all computing infrastructures. Thanks to VM migration and server consolidation, virtualization helps in reducing power consumption in distributed environments. On another side, Dynamic Voltage and Frequency Scaling (DVFS) allows servers to dynamically modify the <b>processor</b> <b>frequency</b> (according to the CPU load) {{in order to achieve}} less energy consumption. We observe that while DVFS is widely used, it still generates a waste of energy. By default and thanks to the ondemand governor, it scales up or down the <b>processor</b> <b>frequency</b> according to the current load and the different predefined threshold (up and down). However, DVFS frequency scaling policies are based on advertised <b>processor</b> <b>frequencies,</b> i. e. the set of frequencies constitutes a discrete range of frequencies. The frequency required for a given load will be set to a frequency higher than necessary; which leads to an energy waste. In this paper, we propose a way to emulate a precise CPU frequency thanks to the DVFS management in virtualized environments. We implemented and evaluated our prototype in the Xen hypervisor...|$|R
30|$|Processing time τ {{indicates}} that the <b>processor</b> <b>frequency</b> is not sufficient for the real-time processing and requires a four times more powerful processor. And {{in case of an}} even bigger matrix, a need in increased performance grows exponentially.|$|R
5000|$|... where {{instructions}} per {{program is}} the total instructions being executed in a given program, cycles per instruction is a program-dependent, architecture-dependent average value, and time per cycle is by definition the inverse of <b>processor</b> <b>frequency.</b> An increase in frequency thus decreases runtime.|$|R
30|$|We vary several {{parameters}} {{when running}} the test programs. The applicative parameter {{that we can}} change is the scheduling policy. We also modify the <b>processor</b> <b>frequency</b> as a hardware parameter. We are interested in studying the influence of three scheduling policies: SCHED_FIFO, SCHED_RR and SCHED_OTHER.|$|R
40|$|This thesis {{analyzes}} the dependency of performance, power consumption and temperature on <b>processor</b> <b>frequency.</b> Theoretical part discusses the processor architecture, benchmarks and algorithm types. Experimental part {{is focused on}}  benchmarks - matrix multiplication, Quicksort, PI number calculation, Ackermann function, LAMMPS, PMBW, Linpack. This set of benchmarks includes both single-threaded and multi-threaded algorithms. Testing consist of three different settings of <b>processor</b> <b>frequency.</b> Multi-threaded benchmarks using different number of threads. Informations regarding the power consumption of CPU and RAM were recorded during these tests. Every test logs his running time. The impact of parallelization on power consumption and runtime is also reflected. Results from the tests are shown in charts and tables. The proper configuration of CPU for each given algorithm is analyzed in conclusion...|$|R
40|$|Abstract—To {{efficiently}} {{utilize the}} computing resources and provide good Quality of Service (QoS) to the end-to-end tasks in the distributed real-time systems, we can enforce the utilization bounds on multiple processors. The utilization control is challenging {{especially when the}} workload in the system is unpredictable. To handle the workload uncertainties, current research favors feedback control techniques, and recent work combines the task rate adaptation and <b>processor</b> <b>frequency</b> scaling in an asynchronous way for CPU utilization control, where task rates and the <b>processor</b> <b>frequencies</b> are tuned asynchronously in two decoupled control loops for control convenience. Since the two manipulated variables, task rates and <b>processor</b> <b>frequencies,</b> contribute to the CPU utilizations together with strong coupling, adjusting them asynchronously may degrade the utilization control performance. In this paper, we provide a novel scheme to make Synchronous Rate and Frequency Adjustment to enforce the utilization setpoint, referred to as SyRaFa scheme. SyRaFa can handle the workload uncertainties by identifying the system model online and can simultaneously adjust the manipulated variables by solving an optimization problem in each sampling period. Extensive evaluation results demonstrate SyRaFa outperforms the existing schemes especially under severe workload uncertainties. Index Terms—Distributed systems, embedded systems, real-time systems, end-to-end task, quality of service, optimization. ...|$|R
50|$|This problem occurs only on {{some models}} of the {{original}} Pentium processor. The bug only existed in some Pentium family processors with a clock speed of less than 120 MHz. On affected models, the Intel <b>Processor</b> <b>Frequency</b> ID Utility checks {{for the presence of}} this bug.|$|R
50|$|AMD Turbo Core {{and similar}} dynamic <b>processor</b> <b>frequency</b> {{adjustment}} technologies {{take advantage of}} the fact that average power consumed is less than the maximum design limits and therefore frequency (and the accompanying power and heat) is able to be increased for short amounts of time and still be within design limits.|$|R
40|$|As the {{processor}} architecture becomes more advanced, Intel introduced its Intel Core 2 Duo series processors. Performance impact on Intel Core 2 Duo processors are analyzed using SPEC CPU INT 2006 performance numbers. This paper studied {{the behavior of}} Artificial Intelligence (AI) benchmarks on Intel Core 2 Duo series processors. Moreover, we estimated the task completion time (TCT) @ 1 GHz, @ 2 GHz and @ 3 GHz Intel Core 2 Duo series <b>processors</b> <b>frequency.</b> Our results show the performance scalability in Intel Core 2 Duo series processors. Even though AI benchmarks have similar execution time, they have dissimilar characteristics which are identified using principal component analysis and dendogram. As the <b>processor</b> <b>frequency</b> increased from 1. 8 GHz to 3. 167 GHz the execution time is decreased by ~ 370 sec for AI workloads. In the case of Physics/Quantum Computing programs it was ~ 940 sec...|$|R
40|$|Dynamic voltage scaling (DVS) {{algorithms}} {{save energy}} by scaling down the <b>processor</b> <b>frequency</b> when the <b>processor</b> {{is not fully}} loaded. Many algorithms have been proposed for periodic and aperiodic task models but none support the periodic and sporadic task models when the deadlines are not equal to their periods. A DVS algorithm, called General Dynamic Voltage Scaling (GDVS), {{that can be used}} with sporadic or periodic tasks in conjunction with the preemptive EDF scheduling algorithm with no constraints on the deadlines is presented here. The algorithm is proven to guarantee each task meets its deadline while saving the maximum amount of energy possible with <b>processor</b> <b>frequency</b> scaling when tasks execute with their worst-case execution times. GDVS was implemented in the µC/OS-II real-time operating system for embedded systems. Though theoretically optimal, the actual power savings realized with GDVS depends on the type of the task set and the processor’...|$|R
40|$|As <b>processor</b> clock <b>frequencies</b> {{continue}} to improve {{at a rate that}} exceeds the rate of improvement in the performance of semiconductor memories, so the effect of memory latency on processor efficiency increases. Unless steps are taken to mitigate the effect of memory latency, the increased <b>processor</b> <b>frequency</b> is of little benefit. This work demonstrates how multithreading can reduce the effect of memory latency on processor performance and how just a few threads are required to achieve close to optimal performance. A lightweight multithreaded architecture is discussed and simulated to show how threads derived from an application's instruction-level parallelism may be used to tolerate memory latency...|$|R
40|$|The {{problem of}} {{reducing}} energy consumption is becoming {{very important in}} the design of embedded real-time systems. Many of these systems, in fact, are powered by rechargeable batteries, and the goal is to extend, {{as much as it is}} possible, the autonomy of the system. To reduce energy consumption, one possible approach is to selectively slow down the <b>processor</b> <b>frequency...</b>|$|R
40|$|Intel co-founder Gordon E. Moore {{observed}} in 1965 that transistor density, {{the number of}} transistors that could be placed in an integrated circuit per square inch, increased exponentially, doubling roughly every two years. This would be later known as Moore's Law, correctly predicting the trend that governed computing hardware manufacturing for the late 20 th century. For many decades, software developers have enjoyed a steady application performance increase due to continuous hardware improvements as described by Moore's Law, as well as computer architecture improvements. Currently, however, the memory wall, which refers to the increasing speed di erence between the CPU and memory, and the instruction-level parallelism wall (ILP wall), which refers to the inability to nd more operations in an application which can be performed simultaneously due to data dependency, have been reached. Application performance no longer bene ts from continuous <b>processor</b> <b>frequency</b> increases as it had before. Furthermore, other issues such as wire delays and static and dynamic power density prevent signi cant <b>processor</b> <b>frequency</b> increase...|$|R
2500|$|At 3.2GHz, each channel flows {{at a rate}} of 25.6GB/s. Viewing the EIB in {{isolation}} from the system elements it connects, achieving twelve concurrent transactions at this flow rate works out to an abstract EIB bandwidth of 307.2GB/s. Based on this view many IBM publications depict available EIB bandwidth as [...] "greater than 300GB/s". This number reflects the peak instantaneous EIB bandwidth scaled by <b>processor</b> <b>frequency.</b>|$|R
40|$|Multimedia {{applications}} today {{constitute a}} significant {{fraction of the}} workload running on portable devices such as mobile phones, PDAs and MP 3 players. However, the processors in such devices are usually not powerful enough to support multiple concurrently executing multimedia tasks. In this context, different processor scheduling algorithms have attracted a lot of attention. This paper attempts to address the CPU constraint problem from a different perspective. It {{is based on the}} observation that by increasing the playout delay of a multimedia task, the minimum <b>processor</b> <b>frequency</b> required to run the task decreases. This is due to the high data-dependent variability in the execution requirements of multimedia tasks. We also present a framework, using which it is possible to compute the minimum <b>processor</b> <b>frequency</b> corresponding to any playout delay. Given a set of concurrently executing multimedia tasks, using our framework it is possible to compute the playout delays for each of these tasks, such that the sum of their corresponding processor cycle requirements do not exceed the maximum frequency supported by the processor...|$|R
40|$|Nowadays, {{virtualization}} {{is present}} in almost all computing infrastructures. Thanks to VM migration and server consolidation, virtualization helps reducing power consumption in distributed environments. On another side, Dynamic Voltage and Frequency Scaling (DVFS) allows servers to dynamically modify the <b>processor</b> <b>frequency</b> (according to the CPU load) {{in order to achieve}} less energy consumption. We observed that these two techniques have several incompatibilities. For instance, if two virtual machines VM 1 and VM 2 are running on the same physical host (with their respective allocated credits), VM 1 being overloaded and VM 2 being underloaded, the host may be globally underloaded leading to a reduction of the <b>processor</b> <b>frequency,</b> which would penalize VM 1 even if VM 1 ’s owner booked a given CPU capacity. In this paper, we analyze the compatibility of available VM schedulers with DVFS management in virtualized environments, we identify key issues and finally propose a DVFS aware VM scheduler which addresses these issues. We implemented and evaluated our prototype in the Xen virtualized environment...|$|R
40|$|Power {{conservation}} {{has become}} a key design issue for many systems, including clusters deployed for embedded systems, where power availability ultimately determines system lifetime. These clusters execute {{a high rate of}} requests of highly-variable length, such as in satellite-based multiprocessor systems. The goal of power management in such systems is to minimize the aggregate energy consumption of the whole cluster while ensuring timely responses to requests. In the past, dynamic voltage scaling (DVS) and on/off schemes have been studied under the assumptions of continuously tunable <b>processor</b> <b>frequencies</b> and perfect load-balancing. In this work, we focus on the more realistic case of discrete <b>processor</b> <b>frequencies</b> and propose a new policy that adjusts the number of active nodes based on the system load, not system frequency. We also design a threshold scheme which prevents the system from reacting to short-lived temporary workload changes in the presence of unstable incoming workload. Simulation and implementation results on real hardware show that our policy is very effective in reducing the overall power consumption of clusters executing embedded applications...|$|R
40|$|Parameter {{variation}} in integrated circuits causes sections of a chip to be slower than others. If, {{to prevent any}} resulting timing errors, we design processors for worst-case parameter values, we may lose substantial performance. An alternate approach explored in {{this paper is to}} design for closer to nominal values, and provide some transistor budget to tolerate unavoidable variationinduced errors. To assess this approach, this paper first presents a novel framework that shows how microarchitecture techniques can trade off variation-induced errors for power and <b>processor</b> <b>frequency.</b> Then, the paper introduces an effective technique to maximize performance and minimize power in the presence of variationinduced errors, namely High-Dimensional dynamic adaptation. For efficiency, the technique is implemented using a machinelearning algorithm. The results show that our best configuration increases <b>processor</b> <b>frequency</b> by 56 % on average, allowing the processor to cycle 21 % faster than without variation. Processor performance increases by 40 % on average, resulting in a performance that is 14 % higher than without variation — at only a 10. 6 % area cost. ...|$|R
40|$|Part 2 : Cloud ComputingInternational audienceNowadays, {{virtualization}} {{is present}} in almost all computing infrastructures. Thanks to VM migration and server consolidation, virtualization helps reducing power consumption in distributed environments. On another side, Dynamic Voltage and Frequency Scaling (DVFS) allows servers to dynamically modify the <b>processor</b> <b>frequency</b> (according to the CPU load) {{in order to achieve}} less energy consumption. We observed that these two techniques have several incompatibilities. For instance, if two virtual machines VM 1 and VM 2 are running on the same physical host (with their respective allocated credits), VM 1 being overloaded and VM 2 being underloaded, the host may be globally underloaded leading to a reduction of the <b>processor</b> <b>frequency,</b> which would penalize VM 1 even if VM 1 's owner booked a given CPU capacity. In this paper, we analyze the compatibility of available VM schedulers with DVFS management in virtualized environments, we identify key issues and finally propose a DVFS aware VM scheduler which addresses these issues. We implemented and evaluated our prototype in the Xen virtualized environment...|$|R
40|$|Dynamic voltage scaling (DVS) {{algorithms}} {{save energy}} by scaling down the <b>processor</b> <b>frequency</b> when the <b>processor</b> {{is not fully}} loaded. Many algorithms have been proposed for periodic and aperiodic task models but none support the canonical sporadic task model. A DVS algorithm, called DVSST, is presented {{that can be used}} with sporadic tasks in conjunction with preemptive EDF scheduling. The algorithm is proven to guarantee each task meets its deadline while saving the maximum amount of energy possible with <b>processor</b> <b>frequency</b> scaling. DVSST was implemented in the µC/OS-II real-time operating system for embedded systems and its overhead was measured using a stand-alone Rabbit 2000 test board. Though theoretically optimal, the actual power savings realized with DVSST {{is a function of the}} sporadic task set and the processor’s DVS support. It is shown that the DVSST algorithm achieves 83 % of the theoretical power savings for a Robotic Highway Safety Marker real-time application. The difference between the theoretical power savings and the actual power savings is due to the limited number of frequency levels the Rabbit 2000 processor supports. ...|$|R
40|$|This section {{provides}} a high-level overview of MPC 8548 E features. Figure 1 shows the major functional units within the MPC 8548 E. Although this document is written {{from the perspective}} of the MPC 8548 E, most of the material applies to the other family members, such as MPC 8547 E, MPC 8545 E, and MPC 8543 E. When specific differences occur, such as pinout differences and <b>processor</b> <b>frequency</b> ranges, they are identified as such...|$|R
5000|$|... where P {{is power}} consumption, C is the {{capacitance}} being switched per clock cycle, V is voltage, and F is the <b>processor</b> <b>frequency</b> (cycles per second). Increases in frequency thus {{increase the amount}} of power used in a processor. Increasing processor power consumption led ultimately to Intel's May 2004 cancellation of its Tejas and Jayhawk processors, which is generally cited as the end of frequency scaling as the dominant computer architecture paradigm.|$|R
50|$|A related-but-opposite {{technique}} is overclocking, whereby processor performance is increased by ramping the <b>processor's</b> (dynamic) <b>frequency</b> beyond the manufacturer's design specifications.|$|R
40|$|The energy {{consumption}} issue in distributed computing systems has become quite critical due to environmental concerns. In response to this, many energy-aware scheduling algorithms {{have been developed}} primarily by using the dynamic voltage-frequency scaling (DVFS) capability incorporated in recent commodity processors. The majority of these algorithms involve two passes: schedule generation and slack reclamation. The latter is typically achieved by lowering <b>processor</b> <b>frequency</b> for tasks with slacks. In this paper, we revisit this energy reduction technique {{from a different perspective}} and propose a new slack reclamation algorithm which uses a linear combination of the maximum and minimum <b>processor</b> <b>frequencies</b> to decrease {{energy consumption}}. This algorithm has been evaluated based on results obtained from experiments with three different sets of task graphs: 1, 500 randomly generated task graphs, and 300 task graphs of each of two real-world applications (Gauss-Jordan and LU decomposition). The results show that the amount of energy saved in the proposed algorithm is 13. 5 %, 25. 5 % and 0. 11 % for random, LU decomposition and Gauss-Jordan task graphs, respectively; these percentages for the reference DVFS-based algorithm are 12. 4 %, 24. 6 % and 0. 1 %, respectively. 10 page(s...|$|R
40|$|Parameter {{variation}} is detrimental to a <b>processor’s</b> <b>frequency</b> and leakage power. One proposed technique to mitigate it is Fine-Grain Body Biasing (FGBB), where {{different parts of}} the processor chip are given a voltage bias that changes the speed and leakage properties of their transistors. This technique has been proposed for static application, with the bias voltages being programmed at manufacturing time for worst-case conditions. In this paper, we introduce Dynamic FGBB (D-FGBB), which allows the continuous re-evaluation of the bias voltages to adapt to dynamic conditions. Our results show that D-FGBB is very versatile and effective. Specifically, with the processor working in normal mode at fixed frequency, D-FGBB reduces the leakage power of the chip by an average of 28 – 42 % compared to static FGBB. Alternatively, with the processor working in a high-performance mode, D-FGBB increases the <b>processor</b> <b>frequency</b> by an average of 7 – 9 % compared to static FGBB — or 7 – 16 % compared to no body biasing. Finally, we also show that D-FGBB can be synergistically combined with Dynamic Voltage and Frequency Scaling (DVFS), creating an effective means to manage power. 1...|$|R
25|$|The Alpha 21164 or EV5 became {{available}} in 1995 at <b>processor</b> <b>frequencies</b> {{of up to}} 333MHz. In July 1996 the line was speed bumped to 500MHz, in March 1998 to 666MHz. Also in 1998 the Alpha 21264 (EV6) was released at 450MHz, eventually reaching (in 2001 with the 21264C/EV68CB) 1.25GHz. In 2003, the Alpha 21364 or EV7 Marvel was launched, essentially an EV68 core with four 1.6 GB/s inter-processor communication links for improved multiprocessor system performance, running at 1 or 1.15GHz.|$|R
40|$|With the {{constant}} {{advances in technology}} {{that lead to the}} increasing of the transistor count and <b>processor</b> <b>frequency,</b> power dissipation is becoming one of the major issues in high-performance processors. These processors increase their clock frequency by lengthening the pipeline, which puts more pressure on the branch prediction engine since branches take longer to be resolved. Branch mispredictions are responsible for around 28 % of the power dissipated by a typical processor due to the useless activities performed by instructions that are squashed...|$|R
40|$|Although many {{converter}} {{control circuits}} have been integrated digitally, digital circuits {{are limited by}} the sampling rate, the <b>processor</b> <b>frequency</b> and other factors, and the response speed is slower than the analog circuits. In this paper, the combination of PI regulator and hysteresis loop PWM control is adopted {{to set up a}} DC/DC analog control circuit. The simulations and experiments show that the design achieves DC/DC bi-directional conversion and phase-shifting output. The DC/DC transformation function has been realized safely and reliably...|$|R
