11|140|Public
50|$|Like classic American railroads, TRA’s {{published}} timetable specifies train class (thus <b>dispatching</b> <b>priority).</b> Premium-fare expresses, like Tze-Chiang, have {{highest priority}} and almost never take sidings. Customers understand the system, and aren't surprised when lower priority trains are held, allowing others to pass. Dispatching decisions are fairly straightforward; even when trains {{are out of}} sequence, stationmasters wouldn't hesitate to hold trains if releasing them could delay a subsequent Tze-Chiang. Close proximity of sidings mean unscheduled holds are likely short, usually less than 5 minutes.|$|E
40|$|International audienceWater {{requirement}} allocation {{plays an}} important role in modern farming management. Evapotranspiration-based irrigation controllers can ideally provide irrigation according to the water requirements of the plant. This chapter describes predictive irrigation scheduling in nurseries with multiple crop species and high-frequency water requirements under limited resources. Based on historical data, time-series analysis is used to forecast evapotranspiration, an essential element in water balance equation. An algorithm based on a hierarchical research including <b>dispatching</b> <b>priority</b> rules and taking into account crop characteristics, available water, and constraints of the hydraulic network is proposed to predict irrigation schedules, with the objective of minimizing crop’s water stress periods and optimizing resource materials. Simulation results with different climatic conditions show on the one hand the ability of the time-series model to forecast potential evapotranspiration, and on the other hand that, given a typical nursery, the proposed predictive approach of irrigation scheduling compared to the non-predictive approach makes it possible to prevent crop’s water stres...|$|E
40|$|The {{eligibility}} criteria adopted to assess polygeneration plants as “highly efficient” {{can play a}} determinant role in favouring or discouraging the market growth of polygeneration systems, especially for buildings applications where economic viability is often more difficult to achieve. Based on the current European framework, in this paper the opportunity to adopt sector- and user-oriented criteria is discussed. After having identified three buildings with different uses (a large hotel, a hospital and an office building), the optimal lay-out and operation strategy of a polygeneration plant serving each building is determined; then, ex-post processing of economic and energetic results is used to assess at what extent sectororiented {{eligibility criteria}} would be justified and could contribute to a more effective promotion of polygeneration. Finally, for a centralized polygeneration system serving the above three buildings, a particular context condition is analysed, that is the availability of free space to install a large heat storage; it will be shown that this condition moderately influences the amount of electricity assessed as “CHP electricity” and then eligible to obtain “guarantee of origin” and <b>dispatching</b> <b>priority...</b>|$|E
5000|$|... #Subtitle level 3: Explicit {{scheduling}} and <b>dispatching</b> <b>priorities</b> ...|$|R
50|$|WLM {{controls}} the access {{of the work}} to the system processors, the I/O units, the system storage and starts and stops processes for work execution. The access to the system processors for example is controlled by a <b>dispatch</b> <b>priority</b> which defines a relative ranking between the units of work which want to execute. The same <b>dispatch</b> <b>priority</b> is assigned to all units of work which were classified to the same service class. As already stated the <b>dispatch</b> <b>priority</b> is not fixed and not simply derived from {{the importance of the}} service class. It changes based on goal achievement, system utilization and demand of the work for the system processors. Similar mechanisms exist for controlling all other system resources. This way of z/OS Workload Manager controlling the access of work to system resources is named goal oriented workload management and is in contrast to resource entitlement based workload management which defines a much more static relationship how work can access the system resources. Resource entitlement based workload management is found on larger UNIX operating systems for example.|$|R
50|$|MPDS was {{developed}} by Jeff Clawson from 1976 to 1979 when he worked as an Emergency Medical Technician and dispatcher prior to medical school. He designed a set of standardized protocols to triage patients via the telephone and thus improve the emergency response system. Cards were first alphabetized by chief complaint that included key questions to ask the caller, pre-arrival instructions, and <b>dispatch</b> <b>priorities.</b> After many revisions, these simple cards have evolved into MPDS.|$|R
40|$|In static {{scheduling}} problems it {{is assumed}} that jobs are ready at zero time or before processing begins. In dynamic scheduling problems a job arrival can be given at any instant in the time interval between zero and a limit established by its processing time, ensuring to accomplish it before the due date deadline. In the cases where the arrivals are near to zero the problem comes closer to the static problem, otherwise the problem becomes more restrictive. This paper proposes two approaches for resolution of the dynamic problem of Total W ighted Tardiness for a single machine environment. The first approach uses, as a list of dispatching priorities a schedule, which an evolutionary algorithm found as the best for a similar static problem: same job features, processing time, duedat s and weights. The second approach uses as a <b>dispatching</b> <b>priority</b> a schedule created by a robust non-evolutionary heuristic. The details of implementation of the proposed algorithms and results for a group of selected instances are discussed in this work...|$|E
40|$|In dynamic {{scheduling}} arrival {{times as}} well as some or all job attributes are unknown in advance. Dynamism can be classified as partial or total. In simplest partially dynamic problems the only unknown attribute of a job is its arrival time rj. A job arrival can be given at any instant in the time interval between zero and a limit established by its processing time, ensuring to accomplish it before the due date deadline. In totally dynamics problems, other job attributes such as processing time pj, due date dj, and tardiness penalty wj, are also unknown. Our research proposes different approaches for resolution of Weighted Tardiness dynamic problems (partial and total) in a single machine environment. A first approach uses, as a list of dispatching priorities a final schedule, found as the best by another heuristic for a similar static problem: same job features, processing time, due dates and weights. A second approach uses as a <b>dispatching</b> <b>priority</b> the order imposed by a partial schedule created, at each decision point, by another heuristic. The details of implementation of the proposed algorithms and results for a group of selected instances are discussed in this work. Eje: Informática de Gestió...|$|E
40|$|The MoDOT Tracker {{performance}} measure “Number of Rail Passengers ” is directly {{correlated with the}} level of passenger train delays. Therefore, the objective {{of this study was to}} develop a prioritized list of rail enhancements that addresses current passenger and freight rail performance on the Union Pacific line from St. Louis to Kansas City in order to improve on-time passenger service and reduce freight delays. An integrated systems analysis and modeling approach was used in this study. Based on a Theory of Constraints analysis the core problem was identified as the high level (and increasing) train load, both from a quantity and weight of train perspective. Corresponding to this four issues were identified that impact the overall delay in the system: geographic conditions, maintenance processes, crew scheduling, and Amtrak <b>dispatching</b> <b>priority.</b> Finally, based on the analysis conducted a set of six primary rail enhancement alternatives (with some having multiple options) were generated, together with potential alternative combinations. The alternatives were generated with respect to minimizing congestion, and therefore delay, within and between freight and passenger trains. The rail alternatives were analyzed by simulating the reduction in overall time for a train to cross the state of Missouri, then...|$|E
50|$|The Medical <b>Priority</b> <b>Dispatch</b> System (MPDS) is {{a unified}} system used to {{dispatch}} appropriate aid to medical emergencies including systematized caller interrogation and pre-arrival instructions. <b>Priority</b> <b>Dispatch</b> Corporation is licensed {{to design and}} publish MPDS and its various products.|$|R
50|$|The Advanced Medical <b>Priority</b> <b>Dispatch</b> System (AMPDS) is an Emergency Medical Dispatch (EMD) system {{developed}} and marketed by <b>Priority</b> <b>Dispatch</b> Corporation. AMPDS is primarily {{used in the}} United Kingdom and Ireland, where it is medically approved. The developer has similar products for police and fire.|$|R
40|$|We {{examine the}} {{economic}} efficiency of incentive mechanisms {{used to promote}} Renewable Energy (RE) across the European Union (EU) by looking at returns to investors along with any negative externalities or social costs. Using electricity price data from 2009 to 2013, we evaluate the RE support mechanisms adopted {{by some of the}} largest EU economies. We explain the limitations of various metrics used to inform incentives for RE and propose an alternative metric reflecting investor requirements. Our results show that while the EU schemes were effective in delivering RE capacity, the incentives provided were overly generous and economically inefficient. To assess the indirect costs of RE in liberalized electricity markets we employ real option theory to quantify the costs of hedging and pricing the exposure faced by conventional fossil fuel generators required to accept RE under <b>dispatch</b> <b>priority.</b> We find that the cost of hedging against random RE output under <b>dispatch</b> <b>priority</b> is expensive while increasing RE in liberalized markets, by depressing prices and increasing price volatility, may place greater burden on conventional, dispatchable generators. As support for RE is presented as a public good, we argue that economically efficient RE support mechanisms require recognizing both their direct and indirect costs...|$|R
30|$|For example, Fig.  3 shows a {{generalized}} schedule construction algorithm [16, 89, 119] {{to construct an}} active schedule, a non-delay schedule or a hybrid of both active and non-delay schedules with a specific <b>dispatching</b> (<b>priority)</b> rule. This algorithm {{was based on the}} Giffler and Thompson [39] and has been widely used in the scheduling literature to deal with different production scheduling problems. The algorithm first identifies the machine m ^* to be scheduled based on the earliest completion time of all available operations P. Then a subset P’ ∈ P including candidate operations to be scheduled next is determined by checking if the ready times of these operations are smaller than S ^*+alpha(C ^*-S ^*). The parameter alpha is the non-delay factor ∈ [0, 1] to control the look-ahead ability of the algorithm by restricting operations included in P’ (the algorithm generates non-delay schedules if alpha = 0 and active schedules if alpha= 1). A dispatching rule is applied to determine the next operation in P’ to schedule next. It is clear that performance of the algorithm depends on how the subset P’ is determined and how the next operation is picked. This algorithm is very efficient because the next operation can be determined easily by calculating priorities for jobs in P’. These two decisions are governed by the non-delay factor alpha and the dispatching rule. In this algorithm, alpha and dispatching rule are the two variable components and the rest are fixed. When designing scheduling heuristics based on the algorithm in Fig. 3, we need to decide alpha and dispatching rule to apply to obtain optimal or near optimal schedules. These two are candidate components which can be evolved using GP.|$|E
40|$|The {{well-known}} priority dispatching rule MOD (Modified Operational Due Date) in {{job shop}} scheduling considers job urgency through ODD (Operational Due Date) and also incorporates SPT(Shortest Processing Time) -effect in prioritising operationally late jobs; leading to robust behaviour in Mean Tardiness (MT) {{with respect to}} tightness/looseness of due dates. In the present paper, we study {{an extension of the}} MOD rule using job-waiting-time based discrimination among operationally late jobs to protect long jobs from excessive delays by incorporating an 'acceleration property' into the scheduling rule. Formally, we employ a weighted-SPT <b>dispatching</b> <b>priority</b> index of the form: (Processing time) /(Waiting time) (alpha) for operationally late jobs, while the priority index is ODD for operationally non-late jobs; and the latter class of jobs has a lower priority than the former class. In the context of Assembly Job Shop scheduling, some existing literature includes considerable focus around the concept of 'Staging Delay', i. e., waiting of components or sub-assemblies for their counterparts for assembly. Some existing approaches attempt dynamic anticipation of staging delay problems and re-prioritisation of operations along converging branches. In the present paper, rather than depending on such a centralised and largely backward scheduling approach, we consider a partially decentralised approach, endowing jobs with a priority index yielding an 'acceleration property' based on a 'look-back' in terms of waiting time, rather than 'look-ahead'. For the particular case, in our proposed rule, when alpha is set at zero and when all jobs at a machine are operationally late, our rule agrees with MOD as both exhibit the SPT effect. In simulation tests of our priority scheme for assembly job shops, in comparison with leading heuristics in literature, we found our rule to be particularly effective in: (1) minimising conditional mean tardiness, (2) minimising 99 -percentile-point of the tardiness distribution, through proper choice of alpha. We also exploit an interesting duality between the scheduling and queueing control versions of the problem. Based on this, some exact and heuristic analysis is given to guide the choice of alpha, which is also supported by numerical evidence...|$|E
40|$|This thesis studies Production Scheduling in a {{multistage}} hybrid flowshop facility. It first {{states the}} general Production Planning and Scheduling problem and highlights some drawbacks of classical solutions. A theoretical decomposition-based approach is introduced whose main issue is to overcome non-efficient capacity utilization. By using Branch and Bound methods, an in-depth {{analysis of the}} scheduling {{part of the system}} is then carried out throughout the study and development of upper and lower bounds as well as branching schemes. Already-existing and new heuristics are presented and compared on different shop floor configurations. Five different heuristic approaches are studied. By scheduling the HFS one stage at a time the first approach uses different stage sequencing orders. The second and third approaches are mainly list heuristics. The second approach uses ideas derived from the multistage classical flowshop with a single machine per stage, while the third approach uses classical <b>dispatching</b> <b>priority</b> rules. The fourth and fifth approaches, respectively, use random scheduling and local search techniques. Statistical analysis is carried out in order to compare the heuristics and to select the best of them for each shop configuration. Already-existing and new lower bounds on the single stage subproblem are also presented and compared. Three new lower bounds are developed: a dual heuristic based bound, a partially preemptive bound and a heuristic for the so-called subset bound. Some of these lower bounds use a network flow algorithm. A new version of the "Preflow Push" algorithm which runs faster than the original one is presented. The best lower bounds are selected based on numerical tests. Two branch and bound algorithms are presented, an improved version of the sequence enumeration method and a generalization of the so-called interval branching method, along with several bounding strategies. Based on the upper and lower bound studies, several branch and bound algorithms are presented and compared using numerical tests on different shop floor configurations. Eventually, an Object Model for Scheduling Algorithm Implementations (OMSAI), that has been used for the computer implementation of the developed algorithms, is presented. (IAG 3) [...] UCL, 199...|$|E
40|$|The {{problem of}} how to find a {{schedule}} on m > 2 processors of equal capacity that minimises the whole processing time of independent tasks has been shown as belonging to the NP-complete class (Horowitz and Sahni [12]). Evolutionary Algorithms (EAs) have been used in the past to implement the allocation of the components (tasks) of a parallel program to processors [12], [13], [14], [16], [17]. Those approaches showed their advantages when contrasted against conventional approaches and different chromosome representations were proposed. This paper shows four algorithms {{to solve the problem of}} allocating a number of non-identical related tasks in a multiprocessor or multicomputer system. The model assumes that the system consists of a number of identical processors and only one task may execute on a processor at a time. All schedules and tasks are non-preemptive. Three evolutionary algorithms, using an indirect-decode representation, are contrasted with the well-known Graham’s [11] list scheduling algorithm (LSA). All of them use the conventional Single Crossover Per Couple (SCPC) approach and indirectdecode representation but they differ in what is represented by the decoders. In the first representation scheme, decoders represent processor <b>dispatching</b> <b>priorities,</b> in the second decoders represent tasks priority lists, and in the third decoders represent both processor <b>dispatching</b> <b>priorities</b> and tasks priority lists in a bipartite chromosome. Chromosome structure, genetic operators, experiments and results are discussed. Eje: Programación concurrent...|$|R
5000|$|Documents leaked in late-2016 {{reveal that}} a {{confidential}} European Union impact assessment analyzes four scenarios for paring back the 'priority dispatch' system afforded to renewable generation in many countries. The assessment concludes that removing <b>priority</b> <b>dispatch</b> could increase carbon emissions by 45million to 60million {{tonnes per annum}} or up to 10%, {{with the aim of}} making European energy generators more flexible and cost-competitive. <b>Priority</b> <b>dispatch</b> is mandated under the current EU renewable energy directive, although the United Kingdom, the Netherlands, and Sweden do not comply. Industry sources told The Guardian that it is [...] "highly likely" [...] that <b>priority</b> <b>dispatch</b> will be removed from the next EU directive, which takes effect from 2020. Sources also said that renewable generators would seek financial compensation if <b>priority</b> <b>dispatch</b> is eliminated. The WindEurope trade association reacted strongly to the news.|$|R
40|$|BACKGROUND: <b>Priority</b> <b>dispatch</b> {{accuracy}} {{is a key}} issue in optimizing the match between patients' medical needs and pre-hospital resources. This study measures the accuracy of a Criteria Based Dispatch (CBD) system, by evaluating discrepancies between <b>dispatch</b> <b>priorities</b> and ambulance crews' severity evaluations. METHODS: This is a retrospective study conducted from January 2011 to December 2011. We ruled that a National Advisory Committee for Aeronautics (NACA) score[*]>[*] 3 (injuries/diseases which can possibly lead to deterioration of vital signs) to 7 (lethal injuries/ diseases) should require a <b>priority</b> <b>dispatch</b> with lights and siren (L&S), while NACA scores[*][*] 3. RESULTS: There were 29, 008 primary missions in 2011, 1122 were excluded. Of the 15, 749  L&S missions, 12, 333 patients had a NACA score[*][*] 3, leading to an under triage rate of 4. 6  %. Sensitivity was 86  % (95  % confidence interval: 85. 6 - 86. 4  %), specificity 48  % (47. 4 - 48. 6  %), positive predictive value 21. 7  % (21. 2 - 22. 2  %), and negative predictive value 95. 4  % (95. 2 - 95. 6  %). CONCLUSION: The rates of over triage and under triage in our CBD are 78 and 4. 6  % respectively. The lack of consistent or universal metrics {{is perhaps the most}} important limitation in dispatch accuracy research. This is mainly due to the large heterogeneity of dispatch systems and prehospital emergency system...|$|R
40|$|Syfte: Syftet med denna studie var att utvärdera tillförlitligheten av informationen som ambulanspersonalen får från sjukvårdens larmcentral. Frågeställningen är i vilken utsträckning utalarmeringsinformationen stämmer överens med vad ambulans personalen gör för bedömningar väl framme på plats hos patienten. Metod: I denna studie användes en deskriptiv och korrelativ design och sambandet mellan de två variablerna utalarmeringsorsak och bedömt tillstånd. Studien inkluderade alla de larm som utalarmerats som prioritet 1 A/B under insamlingsperioden, vecka 10 till vecka 18 2012, vilket resulterade i 62 larm. Resultat: Analysen av utalarmeringsorsak och bedömt tillstånd på plats visar en hög grad av överensstämmelse, kappa koefficienten 0. 78. Det är enbart fem fall av sextiotvå, cirka 8 % som avviker utan någon rimlig förklaring, det kan därav antas att det medicinska beslutsstödet fungerar bra. Resultatet visar dock att det sker avvikanden när den intervjuande sjuksköterskan får ett larm med en medvetandepåverkad patient vid utalarmeringen. Slutsats: Studien visar att den utalarmeringsinformation som ambulansen får från sjukvårdens larmcentral anses fungera bra vid utalarmeringen av prioritering 1. Dock upptäcktes att det förekommer oförklarliga avvikande utalarmeringar, där det behövs mer forskning för att kunna utvärdera orsaken kring. Objective: The {{objective}} {{of this study is}} to evaluate the reliability of the information that the ambulance crew receive from the emergency dispatch center. And in what extent the dispatch information is consistent with the ambulance crew’s evaluation of the patient’s condition. Method: In this study, a descriptive and correlative design and the relationship between two variables, emergency dispatch and assessed condition, and how well these were consistent with each other were evaluated. The study included all alarms that were dispatched as a priority 1 A/B during the data collection period that lasted between week 10 to week 18 2012. This resulted in sixty-two alarms from the emergency dispatch center and the assessments made by the ambulance crew. Results: The analysis of the emergency dispatch and the assessed condition on the seen shows a high level of agreement, kappa coefficient 0. 78. There are only five cases of sixty-two, about 8 % that’s without reasonable explanation. It can be assumed that the medical dispatch support tool works well. The result also shows that it sometimes occur mistakes when the interviewing nurse at the medical dispatch center had a patient whit impaired consciousness. Conclusion: The study shows that the dispatch information received from the emergency dispatch center should be considered to work well when <b>dispatching</b> <b>priority</b> 1 alarms. Furthermore, it was discovered that there are unexplained divergent dispatches, where more research is needed to evaluate the occurred mistakes...|$|E
40|$|Lean Manufacturing {{has become}} the most popular and {{dominant}} management strategy in the pursuit of perfection and in strengthening the competitive edges of manufacturers to face the challenges in the global markets. However, today’s global markets drive manufacturers to create highly customer-oriented job-shop manufacturing systems characterized by high dynamic behavior, uncertainty and high variability, in contradiction to lean being originally designed for high repetitive-production systems with a high-volume low-mix work environment with stable demand and a low degree of customization. Moreover, since the product is the changing agent, another challenging aspect that faces the effectiveness of lean is that the product life cycle is rapidly decreasing; and thus some of the lean initiatives often die after the product life cycle ends. In this regard, in order to constantly cope with the resulting rapid changes and adapt new process designs while reviving lean initiatives and keeping them alive; an effective real-time lean-based IT system should be developed, since lean without a real-time IT system has become impracticable and unthinkable in today’s high-customized manufacturing environments. In this context, due to the special characteristics and superior capabilities of Radio Frequency Identification technology (RFID), it could be the major enabler to support such a real-time IT system with real-time production data. However, RFID remains questionable and doubtable and manufacturers are still quite hesitant to adopt it in their manufacturing systems. This thesis introduces a solid basis for a standard framework of a digitalized smart real-time lean-based system. This framework describes the best practice of RFID technology through the integration of real-time production data captured via RFID with lean manufacturing initiatives in manufacturing systems, in order to overcome today’s lean manufacturing challenges. The introduced framework represents a new kind of smart real-time monitoring and controlling lean-based IT mechanism for the next-generation of manufacturing systems with dynamic and intelligent aspects concerning lean targets. The idea of this mechanism has been derived from the main concepts of traditional value stream mapping (VSM), where the time-based flow is greatly emphasized and considered as the most critical success factor of lean. The proposed mechanism is known as Dynamic Value Stream Mapping (DVSM), a computerized event-driven lean-based IT system that runs in real-time according to lean principles that cover all manufacturing aspects through a diversity of powerful practices and tools that are mutually supportive and synergize well together to effectively reduce wastes and maximize value. Therefore, DVSM represents an intelligent, comprehensive, integrated, and holistic real-time lean- based manufacturing system. The DVSM is proposed to contain different types of engines of which the most important engine is the “Lean Practices and Tools Engine” (LPTE) due to its involvement with several lean modules that guarantees the comprehensiveness of the real-time lean system. Each of these modules is specified to control a specific lean tool that is equipped with suitable real-time monitoring and controlling rules called “Real-Time Lean Control Rules” (RT-LCRs), which are expressed using “Complex Event Processing” (CEP) method. The RT-LCRs enable DVSM to smartly detect any production interruptions or incidents and accordingly trigger real-time re/actions to reduce wastes and achieve a smart real-time lean environment. Practically, the basis of this introduced framework in this dissertation is derived based on a highly customized job-shop manufacturing environment of an international switchgear manufacturer in Germany. The contributions of this dissertation are represented as follows: building the main framework of the DVSM starting with a systematic RFID deployment scheme on the production shop floor; introducing the main components of the DVSM (i. e. Event Extractor-engine, AVSM-engine, VVSM-engine, Real-time Rules-engine, and LPTE); demonstrating the feasibility of the DVSM concerning lean targets through developing a number of Lean Practices and Tools Modules that are supplied with RT-LCRs (e. g. Real-time Manufacturing Lead-time Analysis, Smart Real-time Waste Analysis, Real-time <b>Dispatching</b> <b>Priority</b> Generator (RT-DPG), Real-time Smart Production Control (RT-SPC), Smart- 5 S, Smart Standardized Work, Smart Poka-Yoke, Real-time Manufacturing Cost Tracking (RT-MCT), etc.); verifying the effectiveness of RT-LCRs in RT-DPG and RT-MCT modules through building simulation models using ProModel simulation software and finally proposing a framework of the tools “Smart- 5 S, Smart Standardized Work, Smart Poka-Yoke” to be implemented in the switchgear manufacturing environment...|$|E
40|$|Within the German System of feed-in tariffs for {{renewable}} electricity supply (RES) producers of renewable electricity {{also have the}} privilege of <b>priority</b> <b>dispatch.</b> Depending {{on the design of}} the tariff this is either a physical <b>priority</b> <b>dispatch</b> (“guaranteed grid access”) or a financial priority (“bonus payments”). In either case suppliers of renewable energy sources are inclined to deliver energy even when the cost of production exceeds the market price, i. e. the electricity’s value. We suggest to remove the <b>priority</b> <b>dispatch</b> and to modify the design of feed-in tariffs {{in such a way that}} RES suppliers receive a payment for their potential supply in cases where the price of electricity drops below their marginal costs. Thereby, renewable electricity producers will suffer no drawbacks but social welfare increases...|$|R
40|$|Droop {{schemes for}} {{parallel}} source control usually aims for proportional power sharing tuned {{in accordance to}} the source ratings. This works fine for sources with close similarity, but not really for an autonomous microgrid where different types of Distributed Generators (DGs) may be present without centralized optimal dispatch control. To better adapt to this non-uniformity, an alternative viewpoint based on reducing the Total Generation Cost (TGC including fuel cost, emission penalty and other operational concerns) of the microgrid is discussed, from which two new cost-prioritized droop schemes are developed. The schemes operate by tuning the <b>dispatch</b> <b>priorities</b> of the DGs and curve shapes of their resulting active power versus frequency plots. Their effective reduction of TGC has been verified through simulation...|$|R
40|$|The aversion {{dynamics}} {{research agenda}} has incorporated within dispatching heuristics {{a number of}} real-world observations involving risk mitigation practices used by real schedulers. One such observation is that schedulers occasionally offload risky jobs from a primary machine to otherwise less desirable machine (older, slower) during periods of peak load to avoid the effects the risky job can have on subsequent jobs. This paper examines this situation within the proportional parallel machine environment. Safety time is used to adjust <b>dispatching</b> <b>priorities</b> of risky jobs to reflect the aversion. The effect of various safety time values on performance is studied. Robust safety time values and/or intervals are identified {{across a variety of}} experimental factors related to risk level, percent risky jobs in the job stream, and due date distribution...|$|R
50|$|In the United States, the Medical <b>Priority</b> <b>Dispatch</b> System (MPDS), Criterion-Based Dispatch, and Computer aided call {{handling}} (CACH) are common protocols.|$|R
50|$|The {{system is}} often used {{in the form of}} a {{software}} system called ProQA, which is also produced by <b>Priority</b> <b>Dispatch.</b>|$|R
2500|$|Documents leaked in late-2016 {{reveal that}} a {{confidential}} European Union impact assessment analyzes four scenarios for paring back the 'priority dispatch' system afforded to renewable generation in many countries. [...] <b>Priority</b> <b>dispatch</b> is mandated under the Renewable Energy Directive 2009/28/EC which expires in 2020. [...] The assessment concludes that removing <b>priority</b> <b>dispatch</b> could increase carbon emissions by 45million to 60million {{tonnes per annum}} or up to 10%, {{with the aim of}} making European energy generators more flexible and cost-competitive.|$|R
40|$|In {{this paper}} we propose an {{integrated}} algorithm based on combination of a discrete- event simulation and genetic algorithm. The simulation model is considered as a constraint-satisfaction procedure and if the streaming operations are initiated, then the meta-heuristic takes predefined steps to improve the solution. The latter is constructed through an interface, namely control matrix, implemented as interaction between the simulation model and refined solution of meta-heuristic. In run-time, the control matrix is accessed via simulation model for further modifications. The proposed method is implemented on classical job-shop problems with objective of makespan and results are compared with mixed integer programming model. Moreover, the appropriate <b>dispatching</b> <b>priorities</b> are achieved for dynamic job-shop problem minimizing a multi-objective criteria. The results show that simulation-based optimization are highly capable to capture the main characteristics of the shop and produce optimal/near-optimal solutions with highly credibility degree...|$|R
40|$|In {{order to}} meet the {{individual}} performance goals of each class in a complex multiclass database workload, today's database management systems require the adjustment of a number of low-level performance "knobs," such as buffer pool sizes, multiprogramming levels, data placement, <b>dispatching</b> <b>priorities,</b> etc. As the complexity of database systems is increasing, while their cost is declining at the same time, manually adjusting low-level DBMS performance knobs will become increasingly impractical. Ideally, the DBMS should simply accept per-class performance goals as inputs, and it should adjust its own low-level knobs in order to achieve them; this self-tuning capability is called goal-oriented resource allocation. This thesis makes three contributions in the area of goal-oriented resource allocation for database management systems. First, it defines an overall architecture for goal-oriented resource allocation that includes techniques to insure a stable and responsive system and to accu [...] ...|$|R
3000|$|Completely {{reactive}} scheduling no {{schedule is}} generated {{in advance and}} decisions are made in real time. <b>Priority</b> <b>dispatching</b> rules are the main techniques for completely reactive scheduling.|$|R
40|$|We {{examine the}} problem of {{scheduling}} a given set of jobs on a single machine to minimize total early and tardy costs. Two <b>dispatch</b> <b>priority</b> rules are proposed and tested for this NP-complete problem. These were found to perform far better than known heuristics that ignored early costs. For situations where the potential cost savings are sufficiently high to justify more sophisticated techniques, we propose {{a variation of the}} Beam Search method developed by researchers in artificial intelligence. This variant, called Filtered Beam Search, is able to use priority functions to search a number of solution paths in parallel. A computational study showed that this search method was not only efficient but also consistent in providing near-optimal solutions with a relatively small search tree. The study also includes an investigation of the impacts of Beam Search parameters on three variations of Beam Search for this problem. production/scheduling, deterministic job shop, single stage...|$|R
5000|$|The Exec {{supports}} up to 4095 <b>dispatching</b> <b>priorities</b> {{although most}} sites define {{only a small}} subset of those. The two highest [...] "priorities" [...] aren’t switchable. They are recognition of certain types of processing that {{must be allowed to}} continue on the processor on which they started until they voluntarily give up control. Interrupt lockout occurs when an interrupt arrives or in a few special cases when other Exec code prevents all interrupts (in order to change some data that an interrupt handler may also access). Interlock is used by interrupt post processing routines that either need to run on the same physical processor or simply should not be interrupted. The Dispatcher, I/O completions, and I/O initiation are some examples. All locks used by both of these priorities are spin locks as {{the only way they can}} be set by someone else is on another processor and the design requires that they only be set for very short instruction sequences.|$|R
40|$|Decentralized {{economic}} operation schemes {{have several}} advantages {{when compared with}} the traditional centralized management system for microgrids. Specifically, decentralized schemes are more flexible, less computationally intensive, and easier to implement without relying on communication infrastructure. Economic operation of existing decentralized schemes is also usually achieved by either tuning the droop characteristics of distributed generators (DGs) or prioritizing their dispatch order. For the latter, an earlier scheme has tried to prioritize the DG dispatch based on their no-load generation costs. Although the prioritization works well with some generation costs saved, its reliance on only the DG no-load generation costs does not allow it to operate well under certain conditions. This paper thus presents a more comprehensive economic dispatch scheme, which considers the DG generation costs, their power ratings, and other necessary constraints, before deciding the DG <b>dispatch</b> <b>priorities</b> and droop characteristics. The proposed scheme also allows online power reserve to be set and regulated within the microgrid. This, together with the generation cost saved, has been verified experimentally under different reserve, load, and DG conditions...|$|R
50|$|In {{conjunction}} with <b>Priority</b> <b>Dispatch</b> Corporation, Clinical Solutions {{also created a}} fully integrated 911-nurse triage product - {{thought to be the}} first. The integrated product is being used by ambulance dispatch organizations in several countries.|$|R
50|$|Lubbock's 911 Emergency Medical Service is {{provided}} through University Medical Center, serving over 300,000 people (city and county) with MICU (paramedic-staffed) ambulances. UMC EMS responds to over 31,000 911 calls per year through a <b>priority</b> <b>dispatch</b> system.|$|R
50|$|The BC Ambulance Service {{utilizes}} the Advanced Medical <b>Priority</b> <b>Dispatch</b> System (AMPDS) to triage {{calls and}} a customized Resource Allocation Plan (RAP) to allocate First Responders, Primary Care Paramedics, and Advanced Care Paramedics to calls as needed.|$|R
40|$|Long-term {{demand for}} freight and {{passenger}} rail traffic in North America is expected to expand increasingly leading to capacity constraints. Both infrastructure investment and operational changes can relieve congestion. However, given the high cost to build and maintain infrastructure, careful consideration of how operational practices can affect or mitigate demand is critical for cost-effective planning of new capacity. A key aspect {{of this is the}} effect of heterogeneous traffic characteristics on capacity. Different {{freight and passenger}} trains have substantially different operating characteristics including: speed, acceleration, braking and <b>dispatching</b> <b>priorities.</b> Greater heterogeneity on a line increases interference between trains and creates more delays than if all trains have similar characteristics. Train dispatching simulation software was used to analyze the impact of heterogeneity under a range of realistic infrastructure configurations and operational conditions. Analyses were conducted {{to evaluate the effectiveness of}} various operational changes to reduce delays. The trade-off between reduced congestion and increased cost was considered for each change. A benefit of operational changes is that they can be more rapidly implemented and offer greater flexibility than capital infrastructure investments if future traffic patterns change...|$|R
