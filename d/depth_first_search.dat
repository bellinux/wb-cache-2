319|4154|Public
5|$|Two {{vertices}} in a {{directed graph}} {{are said to}} be strongly connected to each other if there is a directed path {{from one to the other}} and vice versa. This is an equivalence relation, and the vertices of the graph may be partitioned into strongly connected components, subsets within which every two vertices are strongly connected. There are several efficient linear time algorithms for finding the strongly connected components of a graph, based on depth first search: Tarjan's strongly connected components algorithm and the path-based strong component algorithm each perform a single <b>depth</b> <b>first</b> <b>search.</b> Kosaraju's algorithm performs two depth first searches, but is very simple.|$|E
25|$|It is {{possible}} to test whether a graph is bipartite, and to return either a two-coloring (if it is bipartite) or an odd cycle (if it is not) in linear time, using depth-first search. The main idea is to assign to each vertex the color that differs from the color of its parent in the depth-first search forest, assigning colors in a preorder traversal of the depth-first-search forest. This will necessarily provide a two-coloring of the spanning forest consisting of the edges connecting vertices to their parents, {{but it may not}} properly color some of the non-forest edges. In a depth-first search forest, one of the two endpoints of every non-forest edge is an ancestor of the other endpoint, and when the <b>depth</b> <b>first</b> <b>search</b> discovers an edge of this type it should check that these two vertices have different colors. If they do not, then the path in the forest from ancestor to descendant, together with the miscolored edge, form an odd cycle, which is returned from the algorithm together with the result that the graph is not bipartite. However, if the algorithm terminates without detecting an odd cycle of this type, then every edge must be properly colored, and the algorithm returns the coloring together with the result that the graph is bipartite.|$|E
500|$|In any graph, {{directed}} or undirected, {{there is}} a straightforward algorithm for finding a widest path once the weight of its minimum-weight edge is known: simply delete all smaller edges and search for any path among the remaining edges using breadth first search or <b>depth</b> <b>first</b> <b>search.</b> Based on this test, there also exists a linear time algorithm for finding a widest [...] path in an undirected graph, that does not use the maximum spanning tree. The main idea of the algorithm is to apply the linear-time path-finding algorithm to the median edge weight in the graph, and then either to delete all smaller edges or contract all larger edges according to whether a path does or does not exist, and recurse in the resulting smaller graph.|$|E
40|$|Abstract – Fault {{detection}} {{is critical}} for all-optical networks (AONs). This paper introduces the concept of monitoring cycles and proposes a mechanism for fault detection and path performance monitoring based on decomposing AONs into monitoring cycles. Two monitoring cycle finding algorithms are developed: heuristic <b>depth</b> <b>first</b> <b>searching</b> (HDFS) and shortest path Eulerian matching (SPEM). The two algorithms are compared in terms of wavelength overhead in nodes and links. The comparison results are obtained for four typical networks, including NSFNET, ARPA 2, SmallNet and Bellcore. It is shown that the proposed fault detection mechanism based on monitoring cycles is effective and cost efficient. Keywords – All-optical networks, fault detection, cycle cover, monitoring cycles I...|$|R
40|$|Fault {{detection}} {{is critical}} for all-optical networks (AONs). This paper introduces the concept of monitoring cycle and proposes a fault detection mechanism based on decomposing AONs into a set of cycles (a cycle cover), in which each one {{is defined as a}} monitoring cycle. Two cycle-finding algorithms are developed and compared for the proposed fault detection mechanism: heuristic <b>depth</b> <b>first</b> <b>searching</b> (HDFS) and shortest path Eulerian matching (SPEM). The degradation of wavelength utilization and the cardinality of cycle covers are analyzed for evaluating the proposed mechanism. The proposed mechanism is applied to four network examples: NSFNET, ARPA 2, SmallNet and Bellcore. The evaluation results show that the proposed fault detection mechanism is effective and cost efficient...|$|R
40|$|Fault {{detection}} {{is critical}} for all-optical networks (AONs). This paper introduces the concept of monitoring cycles and proposes a mechanism for fault detection and path performance monitoring based on decomposing AONs into monitoring cycles. Two monitoring cycle finding algorithms are developed: heuristic <b>depth</b> <b>first</b> <b>searching</b> (HDFS) and shortest path Eulerian matching (SPEM). The two algorithms are compared in terms of wavelength overhead in nodes and links. It is shown that the proposed fault detection mechanism based on monitoring cycles is effective and cost efficient. Heuristic <b>depth</b> <b>first</b> <b>searching</b> (HDFS) : 1) Given graph G(V, E), let the cycle cover C = = = null; number all nodes in V; and label all nodes in V and all links in E as “uncovered”; 2) Select an uncovered link e in E, if multiple such links are available; select the uncovered link whose endpoints are also uncovered. Start DFS from e and go to that Uncovered endpoints of e if possible; if no uncovered link with uncovered endpoint is available, apply the largest/smallest rule described below; 3) At {{each step of the}} DFS, select an uncovered link if possible. If multiple links are available, alternatively use the largest/smallest node number first rule in the iteration, e. g. if the last time we selected the node with the largest number among multiple nodes with the same priority, then this time we select the node with the smallest number; 4) Once a link returns to the previously visited part, a cycle c can be formed and add the cycle to the cover C; label all the links and nodes in cycle c as “covered”; 5) Repeat (2) -(4) until all links in E are “covered”. Shortest path Eulerian matching (SPEM) : (1) For a non-Eulerian graph G (V, E), find the set V’ of odd-degree nodes; (2) Start from a node x∈∈∈V’ and find the shortest path to every other node, select the smallest one among them, denote as p(x, y). Add path p(x, y) to G (now some links in G are “doubled”) and remove x, y from V’; (3) Repeat (2) until V’ = = = null. Now G (V, E) is Eulerian; (4) Find an Eulerian cycle of the augmented G(V, E) and decompose it to a cycle cover as mentioned above. This paper introduced the concept of monitoring cycles and proposed a fault detection and path performance monitoring mechanism based on decomposing AONs into monitoring cycles. The heuristic <b>depth</b> <b>first</b> <b>searching</b> (HDFS) and shortest path Eulerian matching (SPEM) algorithms are developed for finding monitoring cycles in AONs. The two algorithms are compared with respect to the maximum and average number of wavelengths occupied by monitoring in nodes and links. The results for the 4 network examples show that the wavelength overhead is pretty low with this mechanism. Thus the proposed mechanism based on monitoring cycles is a promising fault detection method for AONs. It is also applicable to path transmission performance monitoring. The results also suggest that the SPEM algorithm is better than the HDFS algorithm in terms of the wavelength overhead...|$|R
2500|$|Each phase {{consists}} of a single breadth first search and a single <b>depth</b> <b>first</b> <b>search.</b> Thus, a single phase may be implemented in [...] time.|$|E
2500|$|The {{algorithm}} finds a maximal set of vertex disjoint augmenting {{paths of}} length [...] (Maximal means {{that no more}} such paths can be added. This is different from finding {{the maximum number of}} such paths, which would be harder to do. Fortunately, it is sufficient here to find a maximal set of paths.) This set may be computed by <b>depth</b> <b>first</b> <b>search</b> (DFS) from [...] to the free vertices in , using the breadth first layering to guide the search: the DFS is only allowed to follow edges that lead to an unused vertex in the previous layer, and paths in the DFS tree must alternate between matched and unmatched edges. Once an augmenting path is found that involves one of the vertices in , the DFS is continued from the next starting vertex. Any vertex encountered during the DFS can immediately be marked as used, since if there is no path from it to [...] at the current point in the DFS, then that vertex can't be used to reach [...] at any other point in the DFS. This ensures [...] running time for the DFS. It is also possible to work in the other direction, from free vertices in [...] to those in , which is the variant used in the pseudocode.|$|E
50|$|A strong {{orientation}} {{of a given}} bridgeless undirected graph {{may be found in}} linear time by performing a <b>depth</b> <b>first</b> <b>search</b> of the graph, orienting all edges in the <b>depth</b> <b>first</b> <b>search</b> tree away from the tree root, and orienting all the remaining edges (which must necessarily connect an ancestor and a descendant in the <b>depth</b> <b>first</b> <b>search</b> tree) from the descendant to the ancestor. Although this algorithm is not suitable for parallel computers, due to the difficulty of performing <b>depth</b> <b>first</b> <b>search</b> on them, alternative algorithms are available that solve the problem efficiently in the parallel model. Parallel algorithms are also known for finding strongly connected orientations of mixed graphs.|$|E
40|$|In this paper, we {{consider}} the problem of determining {{whether or not a}} directed graph contains a pair of vertices connected by two distinct simple paths; if it does not, we say it is singly connected. A straightforward implementation using n <b>depth</b> <b>first</b> <b>searches</b> requires O(nm) time on an n-vertex, m-arc digraph; we obtain an O(n 2) time algorithm by using contraction wherever possible. 1 Supported by a Fannie and John Hertz Foundation fellowship, National Science Foundation Grant No. CCR- 8920505, and the Center for Discrete Mathematics and Theoretical Computer Science (DIMACS) under NSF-STC 88 - 09648. 2 Supported by a National Science Foundation Graduate Fellowship and the Fannie and John Hertz Foundation. 1 Introduction Graph connectivity has become a widely studied component of graph theory. To date, most of the work in this area has dealt with determining if an undirected graph contains at least two, three, or more vertex- or edge-disjoint paths between every pair of vertices [...] ...|$|R
40|$|The need {{to fulfill}} {{customer}} satisfaction and increase product quality has motivated many manufacturing firms {{to investigate and}} diagnose their product failure. To gain a correct and accurate diagnostic, the entire processing root must be recorded and controlled in {{every step of the}} manufacturing process. In this research, a prototype system has been developed for a tile manufacturing company to diagnose tile defects and to recommend actions for improvement. This system consists of two main components, the knowledge base and inference engine. The knowledge base has been developed by capturing data and information that are related to tile defects, such as symptoms, probable causes, types of defects, processes, sub processes, tile classifications, etc. On the other hand, the inference engine has been built by implementing the forward chaining and <b>depth</b> <b>first</b> <b>searching</b> methods to search for the causes of defects. The analysis proves that this system can help the workers in the company to diagnose tile defects and solve the problems. Besides this, the system can also help to share and transfer knowledge among the knowledge workers in the company...|$|R
40|$|Abstract—In {{this paper}} we present {{concepts}} for vectorization of sphere detection algorithms based on regularization of <b>depth</b> <b>first</b> tree <b>search</b> algorithms. Due to data dependant control flow, these tree search algorithms exhibit a highly irregular structure not allowing an efficient collaborative detection of multiple received symbols in parallel. In order to enable parallel symbol processing, {{a transformation of}} the irregular tree search algorithm is proposed resulting in a novel regular algorithm structure. Based on this, a concept for a vectorized List Sphere Detector is introduced, employing a SIMD computational model. In addition to this, limiting effects of vector processing are studied, leading to concepts which ease these effects and enable the utilization of vectorization’s benefits. I...|$|R
50|$|Kosaraju's {{algorithm}} uses two passes of <b>depth</b> <b>first</b> <b>search.</b> The first, in {{the original}} graph, is used to choose {{the order in which}} the outer loop of the second <b>depth</b> <b>first</b> <b>search</b> tests vertices for having been visited already and recursively explores them if not. The second <b>depth</b> <b>first</b> <b>search</b> is on the transpose graph of the original graph, and each recursive exploration finds a single new strongly connected component. It is named after S. Rao Kosaraju, who described it (but did not publish his results) in 1978; Micha Sharir later published it in 1981.|$|E
50|$|There {{were two}} types of searching {{algorithms}} tried out for this implementation. There was the random search and the <b>depth</b> <b>first</b> <b>search.</b> A random search is where each of the agents go in any direction through the environment {{and try to find}} a pathway out. The <b>depth</b> <b>first</b> <b>search</b> is where agents follow one path as far as it can go then return and try another path if the path they traversed does not contain an exit. If was found that <b>depth</b> <b>first</b> <b>search</b> gave a speed up of 15 times versus a random search.|$|E
50|$|Once a 2-SAT {{problem is}} reduced to a graph, then if a <b>depth</b> <b>first</b> <b>search</b> finds a {{strongly}} connected component with both phases of a variable, then the 2-SAT problem is not satisfiable. Likewise, if the <b>depth</b> <b>first</b> <b>search</b> does not find a strongly connected component with both phases of a variable, then the 2-SAT problem is satisfiable.|$|E
40|$|G. 729 or Conjugate {{structure}} algebraic CELP is a audio voice codec that compresses {{speech signal}} based on model characteristics of human voice. This paper {{deals with the}} reduction of the computational complexity for estimating the open loop pitch of the CS-ACELP codec, described in ITU recommendation G. 729. For reduction in computation of open loop pitch analysis using Matlab 7. 4, the weighted delta-LSP function is used. This <b>depth</b> <b>first</b> tree <b>search</b> is also used in G. 729 for reducing the search complexity with minimum effort. In experimental study of our paper we are showing the comparing graphical result of Open Loop Pitch in Matlab 7. 4, we are trying to prove that our proposed method save the computational time for calculation of open loop pitc...|$|R
40|$|This paper {{describes}} {{the use of}} inexpensive robotics platforms to create engaging student projects for a second course in computer programming. These projects employ the stack and queue data structures, reinforce basic concepts such as two dimensional arrays, and are situated {{in the context of}} modern, object-oriented programming. Advanced concepts from autonomous mobile robotics are introduced in a gentle manner, including occupancy grids, path planning, and sensor fusion. The fundamentals of <b>depth</b> and breadth <b>first</b> <b>search</b> are used in the solutions to the various projects described...|$|R
40|$|We {{present a}} very simple {{parallel}} execution model suitable for inference systems with nondeterministic choices (OR-branching points). All the parallel processors solve the same task without any communication. Their programs only differ in the initialization of the random number generator used for branch selection in <b>depth</b> <b>first</b> backtracking <b>search.</b> This model, called random competition, permits us to calculate analytically the parallel performance for arbitrary numbers of processors. This can be done exactly and without any experiments on a parallel machine. Finally, due to their simplicity, competition architectures are easy (and therefore low-priced) to build. As an application of this systematic approach we compute speedup expressions for specific problem classes defined by their run-time distributions. The results vary from a speedup of 1 for linearly degenerate search trees up to clearly "superlinear" speedup for strongly imbalanced search trees. Moreover, {{we are able to}} give esti [...] ...|$|R
50|$|The path-based strong {{component}} algorithm uses a <b>depth</b> <b>first</b> <b>search,</b> like Tarjan's algorithm, {{but with}} two stacks. One of the stacks {{is used to}} keep track of the vertices not yet assigned to components, while the other keeps track of the current path in the <b>depth</b> <b>first</b> <b>search</b> tree. The first linear time version of this algorithm was published by Edsger W. Dijkstra in 1976.|$|E
5000|$|A strong {{orientation}} {{of a given}} bridgeless undirected graph {{may be found in}} linear time by performing a <b>depth</b> <b>first</b> <b>search</b> of the graph, orienting all edges in the <b>depth</b> <b>first</b> <b>search</b> tree away from the tree root, and orienting all the remaining edges (which must necessarily connect an ancestor and a descendant in the <b>depth</b> <b>first</b> <b>search</b> tree) from the descendant to the ancestor. If an undirected graph [...] with bridges is given, together with a list of ordered pairs of vertices that must be connected by directed paths, it is possible in polynomial time to find an {{orientation of}} [...] that connects all the given pairs, if such an orientation exists. However, the same problem is NP-complete when the input may be a mixed graph.|$|E
5000|$|Lexicographically First <b>Depth</b> <b>First</b> <b>Search</b> Ordering - Given a graph with fixed ordered {{adjacency}} lists, and nodes u and v, is vertex u visited before vertex v in a {{depth-first search}} {{induced by the}} order of the adjacency lists? ...|$|E
40|$|Abstract — G. 729 or Conjugate {{structure}} algebraic CELP is a audio voice codec that compresses {{speech signal}} based on model characteristics of human voice. This paper {{deals with the}} reduction of the computational complexity for estimating the open loop pitch of the CS-ACELP codec, described in ITU recommendation G. 729. For reduction in computation of open loop pitch analysis using Matlab 7. 4, the weighted delta-LSP function is used. This <b>depth</b> <b>first</b> tree <b>search</b> is also used in G. 729 for reducing the search complexity with minimum effort. In experimental study of our paper we are showing the comparing graphical result of Open Loop Pitch in Matlab 7. 4, we are trying to prove that our proposed method save the computational time for calculation of open loop pitch Index Terms — Open loop pitch analysis of G. 729, Graphical result of open loop pitch, A-CELP, bit allocation of 8 kbps i...|$|R
40|$|Stochastic {{modeling}} {{forms the}} basis for analysis in many areas, including biological and economic systems, {{as well as the}} performance and reliability modeling of computers and communication networks. One common approach is the state [...] space [...] based technique, which, starting from a high [...] level model, uses <b>depth</b> [...] <b>first</b> <b>search</b> to generate both a description of every possible state of the model and the dynamics of the transitions between them. However, these state spaces, besides being very irregular in structure, are subject to a combinatorial explosion, and can thus become extremely large. In the interest therefore of utilizing both the large memory capacity and the greater computational performance of modern multiprocessors, we are interested in implementing parallel algorithms for the generation and solution of these problems. In this paper we describe the techniques we use to generate the state space of a stochastic Petri [...] net model using shared [...] memory multiprocessors. We describe s [...] ...|$|R
40|$|The <b>depth</b> <b>first</b> proof number <b>search</b> (df-pn) is an {{effective}} and popular algorithm for solving and-or tree problems by using proof and disproof numbers. This paper presents a sim-ple but effective parallelization of the df-pn search algorithm for a shared-memory system. In this parallelization, multiple agents autonomously conduct the df-pn with a shared trans-position table. For effective cooperation of agents, virtual proof and disproof numbers are introduced for each node, which is an estimation of future proof and disproof numbers by using the number of agents working on the node’s descen-dants as a possible increase. Experimental results on large checkmate problems in shogi, which is a popular chess vari-ant in Japan, show that reasonable increases in speed were achieved with small overheads in memory...|$|R
5000|$|Each phase {{consists}} of a single breadth first search and a single <b>depth</b> <b>first</b> <b>search.</b> Thus, a single phase may be implemented in [...] time.Therefore, the first [...] phases, in a graph with [...] vertices and [...] edges, take time [...]|$|E
5000|$|Traversal Conjecture: Let [...] and [...] be two splay trees {{containing}} the same elements. Let [...] be the sequence obtained by visiting {{the elements in}} [...] in preorder (i.e., <b>depth</b> <b>first</b> <b>search</b> order). The total cost of performing the sequence [...] of accesses on [...] is [...]|$|E
50|$|Because tree-depth is {{monotonic}} under graph minors, it is fixed-parameter tractable: {{there is}} an algorithm for computing tree-depth running in time is , where d is {{the depth of the}} given graph and n is its number of vertices. Thus, for every fixed value of d, the problem of testing whether the tree-depth is at most d can be solved in polynomial time. More specifically, the dependence on n in this algorithm can be made linear, by the following method: compute a <b>depth</b> <b>first</b> <b>search</b> tree, and test whether this tree's depth is greater than 2d. If so, the tree-depth of the graph is greater than d and the problem is solved. If not, the shallow <b>depth</b> <b>first</b> <b>search</b> tree can be used to construct a tree decomposition with bounded width, and standard dynamic programming techniques for graphs of bounded treewidth can be used to compute the depth in linear time.|$|E
40|$|We present Solrex,an {{automated}} solver for {{the game}} of Reverse Hex. Reverse Hex, also known as Rex, or Misere Hex, is the variant of the game of Hex in which the player who joins her two sides loses the game. Solrex performs a mini-max search of the state space using Scalable Parallel <b>Depth</b> <b>First</b> Proof Number <b>Search,</b> enhanced by the pruning of inferior moves and the early detection of certain winning strategies. Solrex is implemented on the same code base as the Hex program Solver, and can solve arbitrary positions on board sizes up to 6 x 6, with the hardest position taking less than four hours on four threads. Comment: Presented at Computers and Games 2016 Leiden, International Conference on Computers and Games. Springer International Publishing, 201...|$|R
40|$|Model {{checking}} is {{an automatic}} approach for the verification of systems. Explicit states model checking applies a search algorithm (e. g., <b>depth</b> or breadth <b>first</b> <b>search)</b> {{to the state}} space of the verified system. In concurrent systems, and in particular in communication protocols, the number of states can grow exponentially {{with the number of}} independent components (processes). There axe many different methods that attempt to automatically reduce the number of checked states. Such methods show encouraging results, but often still fail {{to reduce the number of}} states required for the verification to become manageable. We propose here the use of code annotation in order to control the verification process and reduce the number of states searched. Our extension of the C programming language allows the user to put into the code instructions that are executed by the model checker during the verification. With the new language construct, we may exploit additional insight that the verifier may have about the checked program in order to limit the search. We describe our implementation and present some experimental results...|$|R
30|$|The main {{assumption}} for algorithms {{that use}} dominance {{as a basis}} is that either there are sparse connections or there is some overall hierarchical structure to the network. Network analysis in a static situation can reveal this type of information {{with many of the}} basic tools already established, such as <b>depth</b> <b>first</b> or breadth <b>first</b> <b>searches.</b> Dynamic networks, however present a complex field of parameters that can confound a single method of finding a solution. A dynamic network that is relatively stable might mimic a static environment; however edges can still be presented that could disrupt the assumptions of dominance or sparsity.|$|R
50|$|Each vertex is {{processed}} once, each edge is examined only when its two endpoints are processed, and (with an appropriate representation for the sets in Σ that allows items {{to be moved}} from one set to another in constant time) each iteration of the inner loop takes only constant time. Therefore, like simpler graph search algorithms such as breadth-first search and <b>depth</b> <b>first</b> <b>search,</b> this algorithm takes linear time.|$|E
50|$|In {{order to}} do that a linked list is formed that will keep the indexes of the pixels that are {{connected}} to each other, steps (2) and (3) below. The method of defining the linked list specifies the use of a depth or a breadth first search. For this particular application, there is no difference which strategy to use. The simplest kind of a last in first out queue implemented as a singly linked list will result in a <b>depth</b> <b>first</b> <b>search</b> strategy.|$|E
5000|$|Tarjan's {{strongly}} connected components algorithm, {{published by}} Robert Tarjan in 1972, performs a single pass of <b>depth</b> <b>first</b> <b>search.</b> It maintains {{a stack of}} vertices that have been explored by the search but not yet assigned to a component, and calculates [...] "low numbers" [...] of each vertex (an index number of the highest ancestor reachable in one step from a descendant of the vertex) which it uses to determine when a set of vertices should be popped off the stack into a new component.|$|E
40|$|Researchers have {{proposed}} frequent pattern mining algorithms {{that are more}} efficient than previous algorithms and generate fewer but more important patterns. Many techniques such as <b>depth</b> first/breadth <b>first</b> <b>search,</b> use of tree/other data structures, top down/bottom up traversal and vertical/horizontal formats for frequent pattern mining have been developed. Most frequent pattern mining algorithms use a support measure to prune the combinatorial search space. However, support-based pruning is not enough when taking into consideration the characteristics of real datasets. Additionally, after mining datasets to obtain the frequent patterns, {{there is no way}} to adjust the number of frequent patterns through user feedback, except for changing the minimum support. Alternative measures for mining frequent patterns have been suggested to address these issues. One of the main limitations of the traditional approach for mining frequent patterns is that all items are treated uniformly when, in reality, items have different importance. For this reason, weighted frequent pattern mining algorithms have been suggested that give different weights to items according to their significance. The main focus in weighted frequent pattern mining concerns satisfying the downward closure property. In this research, frequent pattern mining approaches with weight constraints are suggested. Our main approach is to push weight constraints into the pattern growth algorithm while maintaining the downward closure property. We develop WFIM (Weighted Frequent Itemset Mining with a weight range and a minimum weight), WLPMiner (Weighted frequent Pattern Mining with length decreasing constraints), WIP (Weighted Interesting Pattern mining with a strong weight and/or support affinity), WSpan (Weighted Sequential pattern mining with a weight range and a minimum weight) and WIS (Weighted Interesting Sequential pattern mining with a similar level of support and/or weight affinity) The extensive performance analysis shows that suggested approaches are efficient and scalable in weighted frequent pattern mining...|$|R
40|$|Assuming a {{suitably}} compressed input, we {{also show}} {{how to do}} <b>depth</b> [...] <b>first</b> and breadth [...] <b>first</b> <b>search</b> and how to compute strongly connected components and biconnected components in time 0 (nλ + n^ 2 /λ), and how to solve the single source shortest path problem with integer costs in the range [0 [...] C] in time 0 (n^ 2 (C) / n) ...|$|R
40|$|This paper {{describes}} a {{knowledge based system}} employing certain expert system rules to detect different kind of eye diseases found in Malaysia. The types of eye diseases that can be detected with this system are allergic or infectious conjunctivitis, secondary and senile cataract, open angle glaucoma and acute glaucoma, keratitis and dry eyes syndrome. These are the most frequent eye diseases infecting the Malaysian population. The project was designed and programmed via the object-oriented expert system shell software, EXSYS. Expert rules were developed based on the symptoms of each type of the eye diseases, and they were presented using a tree graph forward chaining with <b>depth</b> <b>search</b> <b>first</b> method. In order to enhance user interaction with the system, graphical user interfaces were employed. Previously, several similar works have been published, but they are limited to detecting a single disease and also required expert medical officer to operate. The expert system described in this paper is able to detect and gives early diagnosis of five types of eye diseases; inclusive of senile, secondary, open angle, acute, allergic and infections...|$|R
