540|2294|Public
25|$|On {{the other}} hand, DT is so useful for {{simplifying}} the syntactical proof process {{that it can}} be considered and used as another <b>inference</b> <b>rule,</b> accompanying modus ponens. In this sense, DT corresponds to the natural conditional proof <b>inference</b> <b>rule</b> {{which is part of the}} first version of propositional calculus introduced in this article.|$|E
25|$|Both {{premises}} and {{the conclusion}} are propositions. The premises are {{taken for granted}} {{and then with the}} application of modus ponens (an <b>inference</b> <b>rule)</b> the conclusion follows.|$|E
25|$|It is {{possible}} to define another version of propositional calculus, which defines most of the syntax of the logical operators by means of axioms, and which uses only one <b>inference</b> <b>rule.</b>|$|E
40|$|We present locally {{complete}} <b>inference</b> <b>rules</b> for probabilistic deduction from taxonomic and probabilistic knowledge bases over conjunctive events. Crucially, {{in contrast}} to similar <b>inference</b> <b>rules</b> in the literature, our <b>inference</b> <b>rules</b> are locally complete for conjunctive events and under additional taxonomic knowledge. We discover that our <b>inference</b> <b>rules</b> are extremely complex {{and that it is}} at first glance not clear at all where the deduced tightest bounds come from. Moreover, analyzing the global completeness of our <b>inference</b> <b>rules,</b> we find examples of globally very incomplete probabilistic deductions. More generally, we even show that all systems of <b>inference</b> <b>rules</b> for taxonomic and probabilistic knowledge bases over conjunctive events are globally incomplete. We conclude that probabilistic deduction by the iterative application of <b>inference</b> <b>rules</b> on interval restrictions for conditional probabilities, even though considered very promising in the literature so far, seems very limited in its field of application. </p...|$|R
40|$|The {{concept of}} well-behaved <b>inference</b> <b>rules</b> is {{developed}} in first-order polynomial based theorem proving. It is shown that well-behaved <b>inference</b> <b>rules</b> are complete {{for both the}} set-of-support strategy and the linear strategy. Two concrete such <b>inference</b> <b>rules</b> are presented, and other two strategies for them are proposed...|$|R
40|$|We {{define the}} notion of {{inductive}} invariants for continuous dynamical systems {{and use it to}} present <b>inference</b> <b>rules</b> for safety verification of polynomial continuous dynamical systems. We present two different sound and complete <b>inference</b> <b>rules,</b> but neither of these rules can be effectively applied. We then present several simpler and practical <b>inference</b> <b>rules</b> that are sound and relatively complete for different classes of inductive invariants. The simpler <b>inference</b> <b>rules</b> can be effectively checked when all involved sets are semi-algebraic...|$|R
25|$|Although {{its name}} may suggest otherwise, {{mathematical}} induction {{should not be}} misconstrued {{as a form of}} inductive reasoning (also see Problem of induction). Mathematical induction is an <b>inference</b> <b>rule</b> used in proofs. Proofs by mathematical induction are, in fact, examples of deductive reasoning.|$|E
25|$|This can {{be shown}} as follows: Every proof in propositional {{calculus}} uses only axioms and the inference rules. Each use of an axiom scheme yields a true logical formula, and can thus be proven in sequent calculus; examples for these are shown below. The only <b>inference</b> <b>rule</b> in the systems mentioned above is modus ponens, which is implemented by the cut rule.|$|E
25|$|The {{preceding}} alternative calculus is {{an example}} of a Hilbert-style deduction system. In the case of propositional systems the axioms are terms built with logical connectives and the only <b>inference</b> <b>rule</b> is modus ponens. Equational logic as standardly used informally in high school algebra is a different kind of calculus from Hilbert systems. Its theorems are equations and its inference rules express the properties of equality, namely that it is a congruence on terms that admits substitution.|$|E
5000|$|Furthermore, {{with respect}} to a set of <b>inference</b> <b>rules</b> , we say that a {{functional}} dependency [...] is derivable from the functional dependencies in [...] by the set of <b>inference</b> <b>rules</b> , and we denote it by [...] if and only if [...] is obtainable by means of repeatedly applying the <b>inference</b> <b>rules</b> in [...] to functional dependencies in [...] We denote by [...] the set of all functional dependencies that are derivable from [...] by <b>inference</b> <b>rules</b> in [...]|$|R
40|$|ABSTRACT. We {{define the}} notion of {{inductive}} invariants for continuous dynamical systems {{and use it to}} present <b>inference</b> <b>rules</b> for safety verification of polynomial continuous dynamical systems. We present two different sound and complete <b>inference</b> <b>rules,</b> but neither of these rules can be effectively applied. We then present several simpler and practical <b>inference</b> <b>rules</b> that are sound and relatively complete for different classes of inductive invariants. The simpler <b>inference</b> <b>rules</b> can be effectively checked when all involved sets are semi-algebraic. ...|$|R
40|$|The aim of {{this book}} is to present the {{fundamental}} theoretical results concerning <b>inference</b> <b>rules</b> in deductive formal systems. Primary attention is focused on: admissible or permissible <b>inference</b> <b>rules</b> the derivability of the admissible <b>inference</b> <b>rules</b> the structural completeness of logics the bases for admissible and valid <b>inference</b> <b>rules.</b> There is particular emphasis on propositional non-standard logics (primary, superintuitionistic and modal logics) but general logical consequence relations and classical first-order theories are also considered. The book is basically self-contained an...|$|R
25|$|The {{substitution}} rule demonstrates several common {{aspects of}} rules of inference. It is entirely syntactical; {{one can tell}} whether it was correctly applied without appeal to any interpretation. It has (syntactically defined) limitations on when it can be applied, which must be respected to preserve the correctness of derivations. Moreover, {{as is often the}} case, these limitations are necessary because of interactions between free and bound variables that occur during syntactic manipulations of the formulas involved in the <b>inference</b> <b>rule.</b>|$|E
25|$|We treat R1 as an <b>inference</b> <b>rule,</b> {{even though}} it is like an axiom in having no premises, because it is a domain-independent rule along with R2 and R3 common to all equational axiomatizations, whether of groups, rings, or any other variety. The only entity {{specific}} to Boolean algebras is axiom schema A1. In this way when talking about different equational theories we can push the rules to one side as being independent of the particular theories, and confine attention to the axioms as {{the only part of the}} axiom system characterizing the particular equational theory at hand.|$|E
25|$|Many {{problems}} in AI {{can be solved}} in theory by intelligently searching through many possible solutions: Reasoning {{can be reduced to}} performing a search. For example, logical proof can be viewed as searching for a path that leads from premises to conclusions, where each step is the application of an <b>inference</b> <b>rule.</b> Planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis. Robotics algorithms for moving limbs and grasping objects use local searches in configuration space. Many learning algorithms use search algorithms based on optimization.|$|E
40|$|We {{introduce}} a specification language {{that can be}} used to specify semantic analysis as well as intermediate code generation. This specification language defines semantic properties by means of many-sorted <b>inference</b> <b>rules.</b> Type <b>inference</b> <b>rules</b> are just a one-sorted special case. We demonstrate that <b>inference</b> <b>rules</b> can also be used to infer other semantic information such as definitions of identifiers, scoping, inheritance relations, etc. To distinguish the different kinds of semantic information described by the rules, we use a many-sorted language to formulate the <b>inference</b> <b>rules.</b> We further show how to transform a set of <b>inference</b> <b>rules</b> algorithmically into an attribute grammar, thus proving that semantic analysis and intermediate code generation can be generated from such specifications...|$|R
40|$|Natural Language Inference (NLI) is a key, complex task where machine {{learning}} (ML) is playing an important role. However, ML has progressively obfuscated {{the role of}} linguistically-motivated <b>inference</b> <b>rules,</b> which should be the core of NLI systems. In this paper, we introduce distributed <b>inference</b> <b>rules</b> as a novel way to encode linguistically-motivated <b>inference</b> <b>rules</b> in learning interpretable NLI classifiers. We propose two encoders: the Distributed Partial Tree Encoder and the Distributed Smoothed Partial Tree Encoder. These encoders allow modeling syntactic and syntactic-semantic <b>inference</b> <b>rules</b> as distributed representations ready {{to be used in}} ML models over large datasets. Although far from the state-of-the-art of end-to-end deep learning systems on large datasets, our shallow networks positively exploit <b>inference</b> <b>rules</b> for NLI, improving over baseline systems. This is a first positive step towards interpretable and explainable end-to-end deep learning systems...|$|R
40|$|Our paper {{investigates the}} linear logic of {{knowledge}} and time LTK_r with reflexive intransitive time relation. The logic is defined semantically, [...] as the set of formulas which are true at special frames with intransitive and reflexive time binary relation. The LTK_r -frames are linear chains of clusters connected by a reflexive intransitive relation $R_T$. Elements inside a cluster are connected by several equivalence relations imitating the knowledge of different agents. We study the decidability problem for formulas and <b>inference</b> <b>rules.</b> Decidability for formulas follows from decidability w. r. t. admissible <b>inference</b> <b>rules.</b> To study admissibility, we introduce some special constructive Kripke models useful for description of admissibility of <b>inference</b> <b>rules.</b> With a special technique of definable valuations we find an algorithm determining admissible <b>inference</b> <b>rules</b> in LTK_r. That is, we show that the logic LTK_r is decidable and decidable with respect to admissibility of <b>inference</b> <b>rules...</b>|$|R
500|$|By {{grouping}} {{together all}} of the clauses that use the same variable, and applying the <b>inference</b> <b>rule</b> to each pair of clauses, {{it is possible to}} find all inferences that are possible from a given 2-CNF instance, and to test whether it is consistent, in total time , where [...] is the number of variables in the instance. This formula comes from multiplying the number of variables by the [...] number of pairs of clauses involving a given variable, to which the <b>inference</b> <b>rule</b> may be applied. Thus, it is possible to determine whether a given 2-CNF instance is satisfiable in time [...] Because finding a satisfying assignment using Krom's method involves a sequence of [...] consistency checks, it would take time [...] [...] quote a faster time bound of [...] for this algorithm, based on more careful ordering of its operations. Nevertheless, even this smaller time bound was greatly improved by the later linear time algorithms of [...] and [...]|$|E
500|$|Krom {{writes that}} a formula is {{consistent}} if repeated {{application of this}} <b>inference</b> <b>rule</b> cannot generate both the clauses [...] and , for any variable [...] As he proves, a 2-CNF formula is satisfiable {{if and only if}} it is consistent. For, if a formula is not consistent, {{it is not possible to}} satisfy both of the two clauses [...] and [...] simultaneously. And, if it is consistent, then the formula can be extended by repeatedly adding one clause of the form [...] or [...] at a time, preserving consistency at each step, until it includes such a clause for every variable. At each of these extension steps, one of these two clauses may always be added while preserving consistency, for if not then the other clause could be generated using the <b>inference</b> <b>rule.</b> Once all variables have a clause of this form in the formula, a satisfying assignment of all of the variables may be generated by setting a variable [...] to true if the formula contains the clause [...] and setting it to false if the formula contains the clause [...]|$|E
500|$|In {{terms of}} the {{implication}} graph of the 2-satisfiability instance, Krom's <b>inference</b> <b>rule</b> {{can be interpreted as}} constructing the transitive closure of the graph. As [...] observes, it can also be seen as an instance of the Davis–Putnam algorithm for solving satisfiability problems using the principle of resolution. Its correctness follows from the more general correctness of the Davis–Putnam algorithm. Its polynomial time bound follows from the fact that each resolution step increases the number of clauses in the instance, which is upper bounded by a quadratic function of the number of variables.|$|E
40|$|Experience-based {{reasoning}} (EBR) is a reasoning paradigm used {{in almost}} every human activity such as business, military missions, and teaching activities. However, EBR has not been seriously studied from a fuzzy reasoning viewpoint. This paper will give an attempt {{to resolve this issue}} by providing four new fuzzy <b>inference</b> <b>rules</b> for EBR. More specifically, the paper first reviews the logical approach to EBR, in which eight fundamental different <b>inference</b> <b>rules</b> for EBR are discussed. Then the paper proposes fuzzy logic-based models to the four new <b>inference</b> <b>rules</b> in EBR, which forms a theoretical foundation for EBR together with the four traditional fuzzy <b>inference</b> <b>rules.</b> The proposed approach will facilitate research and development of EBR, e-commerce, and experience management...|$|R
50|$|In {{mathematical}} logic, a proof calculus {{corresponds to}} a family of formal systems that use a common style of formal inference for its <b>inference</b> <b>rules.</b> The specific <b>inference</b> <b>rules</b> {{of a member of}} such a family characterize the theory of a logic.|$|R
40|$|This paper {{presents}} a health advice system using an on-tology and <b>inference</b> <b>rules.</b> The ontology {{consists of the}} various concepts and their relationships about health and exercise. By combining the ontology and <b>inference</b> <b>rules</b> to derive health advices, recommended and/or non-recommended exercises are inferred and presented to the users...|$|R
2500|$|... can be {{transformed}} {{by means of the}} converse of the deduction theorem into the <b>inference</b> <b>rule</b> ...|$|E
2500|$|A first-order formula [...] implies all {{formulae}} [...] where [...] is {{a ground}} term. The following <b>inference</b> <b>rule</b> is therefore correct: ...|$|E
2500|$|Mathematical {{induction}} as an <b>inference</b> <b>rule</b> can be formalized as a second-order axiom. The axiom of induction is, in logical symbols, ...|$|E
40|$|Semantic {{inference}} is a {{core component}} of many natural language applications. In response, several researchers have developed algorithms for automatically learning <b>inference</b> <b>rules</b> from textual corpora. However, these rules are often either imprecise or underspecified in directionality. In this {{paper we propose}} an algorithm called LEDIR that filters incorrect <b>inference</b> <b>rules</b> and identifies the directionality of correct ones. Based on an extension to Harris’s distributional hypothesis, we use selectional preferences to gather evidence of inference directionality and plausibility. Experiments show empirical evidence that our approach can classify <b>inference</b> <b>rules</b> significantly better than several baselines. ...|$|R
5000|$|... #Subtitle level 3: <b>Inference</b> <b>rules</b> for the {{calculus}} of constructions ...|$|R
40|$|This paper {{supplies}} {{a theoretical}} approach on implementing <b>inference</b> <b>rules</b> in the Topic Maps model. Topic Maps is an ISO standard {{that allows for}} the modeling and representation of knowledge in an interchangeable form, that can be extended by <b>inference</b> <b>rules.</b> These rules specify conditions for inferrable facts. Any implementation requires a syntax for storage in a file, a storage model and method for processing and a system {{to keep track of}} changes in the inferred facts. The most flexible and optimisable storage model is a controlled cache, giving options for processing. Keeping track of changes is done by listeners. One of the most powerful applications of <b>inference</b> <b>rules</b> in Topic Maps is interoperability. By mapping ontologies to each other using <b>inference</b> <b>rules</b> as converter, it is possible to exchange extendable knowledge. Any implementation must choose methods and options optimized for the system it runs on, with the facilities available. Further research is required to analyze optimization problems between options. ...|$|R
2500|$|The {{converse}} of DT has powerful implications: {{it can be}} used {{to convert}} an axiom into an <b>inference</b> <b>rule.</b> For example, the axiom AND-1, ...|$|E
2500|$|In default logic, a default {{is similar}} to an <b>inference</b> <b>rule,</b> except that it includes, besides its {{premises}} and conclusion, a list of formulas called justifications. A default {{can be used to}} derive its conclusion under the assumption that its justifications are consistent with what is currently believed. Nicole Bidoit and Christine Froidevaux [...] proposed to treat negated atoms in the bodies of rules as justifications. For instance, the rule ...|$|E
2500|$|In mathematics, a Heyting algebra is a bounded lattice (with join {{and meet}} {{operations}} written ∨ and ∧ and with least element 0 and greatest element 1) {{equipped with a}} binary operation a → b of implication such that c ∧ a ≤ b is equivalent to c ≤ a → b. From a logical standpoint, A → B is by this definition the weakest proposition for which modus ponens, the <b>inference</b> <b>rule</b> A → B, A ⊢ B, is sound. [...] Equivalently a Heyting algebra is a residuated lattice whose monoid operation a⋅b is a ∧ b; yet another definition is as a posetal cartesian closed category with all finite sums. [...] Like Boolean algebras, Heyting algebras form a variety axiomatizable with finitely many equations. Heyting algebras were introduced by [...] to formalize intuitionistic logic.|$|E
40|$|Generalising what {{is learned}} about one {{stimulus}} to other but perceptually related stimuli {{is a basic}} behavioural phenomenon. We evaluated whether a rule learning mechanism may serve to explain such generalisation. To this end, we assessed whether <b>inference</b> <b>rules</b> communicated through verbal instructions affect generalisation. Expectancy ratings, but not valence ratings, proved sensitive to this manipulation. In addition to revealing a role for <b>inference</b> <b>rules</b> in generalisation, our study has clinical implications as well. More specifically, we argue that targeting <b>inference</b> <b>rules</b> might prove {{to be an effective}} strategy to affect the excessive generalisation that is often observed in psychopathology...|$|R
40|$|We give {{a set of}} <b>inference</b> <b>rules</b> with {{constant}} constraints. Then we show how to extend a set of equational clauses, so that if the application of these <b>inference</b> <b>rules</b> halts on these clauses, then the theory is decidable by applying a standard set of Paramodulation <b>inference</b> <b>rules.</b> In addition, we can {{determine the number of}} clauses generated in this decision procedure. For some theories, such as the theory of lists, there are O(n Θ lg(n)) clauses. For others it is polynomial. And for others it is simply exponential such as the theory of (extensional) arrays...|$|R
2500|$|Finally {{we define}} syntactical {{entailment}} such that [...] is syntactically entailed by [...] if {{and only if}} we can derive it with the <b>inference</b> <b>rules</b> that were presented above in a finite number of steps. This allows us to formulate exactly what it means for the set of <b>inference</b> <b>rules</b> to be sound and complete: ...|$|R
