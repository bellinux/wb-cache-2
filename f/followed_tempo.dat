0|54|Public
5000|$|The Symphonys movements, with English {{translation}} of titles <b>followed</b> by <b>tempo</b> markings, are as follows: ...|$|R
50|$|The song {{is written}} in the key of C minor and <b>follows</b> a <b>tempo</b> of 134 beats per minute. It follows a basic chord {{progression}} of Cm-A-B, and the vocals span from G3 to F5.|$|R
5000|$|... "Cold Hearted" [...] {{is written}} in the key of G minor and <b>follows</b> a <b>tempo</b> of 122 beats per minute. The song follows a chord {{progression}} of GmEmaj7Dm7, and Abdul's vocals span one-and-a-half octaves, from F3 to B4.|$|R
5000|$|... "After Midnight" [...] is a mid tempo anthem {{that was}} written about [...] "damaged people who fall in love." [...] The song is written in the key of A major and <b>follows</b> a <b>tempo</b> of 84 beats per minute.|$|R
5000|$|... "Orphans no Namida" [...] {{is written}} in the key of B-flat minor and <b>follows</b> a <b>tempo</b> of 76 beats per minute. Misia's vocals span from G3 to D5 in the single version and G3 to F5 in the album version.|$|R
50|$|Although {{the use of}} {{synthesizer}} performers {{to substitute}} for orchestral instruments is a more flexible approach than using prerecorded music (in that the synthesizer players can <b>follow</b> the <b>tempo</b> of the conductor), high-quality synthesizers and samples must be used to obtain a fairly convincing tone. With an inexpensive synthesizer, the orchestral instrument sounds are often thin-sounding and artificial.|$|R
50|$|The {{sections}} {{are named}} and tempo markings given as <b>follows.</b> Where the <b>tempo</b> markings {{of the two}} versions differ, the one for Op. 56b is shown in parentheses.|$|R
50|$|Their {{software}} also {{attempts to}} expand the relationship between acoustic instruments and the computer. An {{example of this is}} a score-following program called ComParser. The program determines which part of the music is being played and initiates pre-programmed sequences of sound processors at the appropriate times. ComParser <b>follows</b> the <b>tempo</b> of the musician. ComParser is not a pitch-follower, but a spectrum-follower.|$|R
5000|$|The term Virtual Orchestra is more {{accurately}} used today {{to describe the}} real time simulation of the traditional acoustic orchestra in the live performance genres such as musical theater, ballet, and opera. This use of Virtual Orchestra emphasizes the interactive capabilities of the technology as opposed to non-real time and studio-based genres such as film music. The term Virtual Orchestra implies {{a high degree of}} human interaction during live performance and suggests that the method simulates both the sound and behavior of an acoustic orchestra. The behavioral characteristics would include the ability to <b>follow</b> <b>tempo</b> in real time while making simultaneous adjustments to various expressive parameters including volume, articulation, phrasing, etc. While the definition has expanded to include creative and research activity in a broader aesthetic range well beyond traditional orchestral simulation, the ability to interact with the sonic and behavioral elements in real time via human performance has remained one the requisite attributes of a Virtual Orchestra.|$|R
3000|$|In this paper, {{rather than}} {{focusing}} on a particular piece of custom build hardware, we will focus on a deliberately simple design, namely a Lego robot percussionist. The goal of our percussionist will be to <b>follow</b> the <b>tempo</b> of a human performer and generate a pattern to play in sync with the performer. A generic solution to this task, while obviously simpler than that for an acoustic instrument, captures some of the central aspects or robotic performance, namely: [...]...|$|R
40|$|Research {{consistently}} {{shows that}} many human processes and behaviours <b>follow</b> the <b>tempo</b> of music. From automatic processes like cardiovascular and respiratory rates, to deliberate behaviours like dining, humans do things faster {{when the music}} is 2 ̆ 2 up tempo 2 ̆ 2. Studies have examined multiple restaurant categories from cafeterias to fine dining, {{and the results are}} basically the same. Diners eat more quickly - literally bring their forks to their mouths more frequently - when the music is fast rather than slow...|$|R
30|$|Guitar playing {{is mainly}} {{categorized}} into two styles: stroke and arpeggio. Stroke style consists of hand waving motions. In arpeggio style, however, a guitarist pulls strings with their fingers mostly without moving their arms. Unlike most beat-trackers in the literature, our current {{system is designed}} for a much more limited case where the guitar is strummed, not in a finger picked situation. This limitation allows our system to perform well in a noisy environment, to <b>follow</b> sudden <b>tempo</b> changes more reliably and to address single instrument music pieces.|$|R
50|$|Beyoncé and Luther Vandross's 2003 cover {{version of}} the song {{appeared}} on both Vandross' final album Dance with My Father and Knowles' solo debut Dangerously in Love. Their version was recorded at The Hit Factory and the Right Track Studios, in New York City. It <b>follows</b> a <b>tempo</b> of 98 beats per minute, slightly faster than the original version. It {{is set in the}} key of E major, and follows the chord progression Gm7-Cm7-Emaj9-A. It was serviced to US urban contemporary and urban adult contemporary radio on June 13, 2004.|$|R
50|$|The song {{is written}} in the key of B major and <b>follows</b> a slow <b>tempo</b> of 67 beats per minute in common time. It follows a chord {{progression}} of Bmaj7FsusGm7E, and the vocals span from E3 to A4. In the final chorus of the song, the key changes to D major.|$|R
50|$|The World Dance Council (WDC) {{rules for}} {{international}} competitions are lengthy and detailed. The music for competitions is kept confidential until the event. The music always <b>follows</b> a strict <b>tempo</b> and, for a couples competition, {{it will have}} a duration of no less than 90 seconds, and no more than two minutes.|$|R
50|$|He {{left the}} music {{industry}} in the early 1990s and became a computer programmer. He designed systems for Digidesigns and for Adobe for use by musicians and arrangers. His technological creations include the Session8 Digital Audio Workstation for PC, the Impulse Drum Trigger, and the Human Clock, which instructs computerized musical devices to <b>follow</b> a human <b>tempo.</b>|$|R
40|$|Abstract—An {{approach}} for tempo estimation from musical pieces with near-constant tempo is proposed. The method {{consists of three}} main steps: measuring the degree of musical accent {{as a function of}} time, periodicity analysis, and tempo estimation. Novel accent features based on the chroma representation are proposed. The periodicity of the accent signal is measured using the generalized autocorrelation function, <b>followed</b> by <b>tempo</b> estimation using-Nearest Neighbor regression. We propose a resampling step applied to an unknown periodicity vector before finding the nearest neighbors. This step improves the performance of the method significantly. The tempo estimate is computed as a distance-weighted median of the nearest neighbor tempi. Experimental results show that the proposed method provides significantly better tempo estimation accuracies than three reference methods. Index Terms—Chroma features,-nearest neighbor (-NN) regression, music tempo estimation. I...|$|R
40|$|Wood {{cellulose}} nanofibrils (CNF) {{have been}} suggested as a potential wound healing material, but its utilization is limited by FDA requirements regarding endotoxin levels. In this study a method using sodium hydroxide <b>followed</b> by <b>TEMPO</b> mediated oxidation was developed to produce ultrapure cellulose nanofibrils, with an endotoxin level of 45 endotoxin units/g (EU/g) cellulose. Scanning transmission electron microscopy (S(T) EM) revealed a highly nanofibrillated structure (lateral width of 3. 7 ± 1. 3 nm). Assessment of cytotoxicity and metabolic activity on Normal Human Dermal Fibroblasts and Human Epidermal Keratinocytes was done. CNF-dispersion of 50 μg/ml {{did not affect the}} cells. CNF-aerogels induced a reduction of metabolic activity by the fibroblasts and keratinocytes, but no significant cell death. Cytokine profiling revealed no induction of the 27 cytokines tested upon exposure to CNF. The moisture-holding capacity of aerogels was relatively high (∼ 7500...|$|R
50|$|His {{greatest}} successes {{as a pro}} cyclist came in 1995. At the 1995 Tour de France, he won stage 7, {{which began}} in Charleroi and ended in Liège, Belgium, and took the yellow jersey in his home country. Bruyneel launched an escape and was joined by eventual winner Miguel Indurain. The Spaniard took the lead and rode the stage as a time-trial to gain time on his main rivals, with Bruyneel latched onto his wheel, barely able to <b>follow</b> the <b>tempo.</b> He then beat Indurain in the end sprint to win the stage. Bruyneel admitted he felt somewhat uneasy about how he had won. However, the win into Liège afforded him a chance meeting with the King of Belgium during the prize presentations. That same year, Bruyneel achieved his only podium finish in a Grand Tour when he finished 3rd at the 1995 Vuelta a España and won the Aalst criterium.|$|R
500|$|Poker Face {{is set in}} {{a common}} time time signature, with a fast tempo of 120 beats per minute. It is written in the key of G minor with Gaga's vocal range {{spanning}} from the note F3 to the note B4. It begins with a medium <b>tempo</b> <b>followed</b> by electronic chord arrangement and the [...] "Mum-mum-mum-mah" [...] hook. The chords follow in this order: Gm–E/G–F, and then for the chorus Gm–E–B–F. This is followed by the sound of dance music, produced by a powerful beat from the instruments, and a stuttering hook following the chorus.|$|R
40|$|Score. Bugles in the sky. On cover: "Bugles in the sky, by Ben Forrest, Glenn Burrs, Frank Furlett; M. M. Cole Publishing Co., Chicago. [Page 1]: Bugles in the sky, {{words and}} music by Ben Forrest, Glenn Burrs, Frank Furlett; Slow blues <b>tempo,</b> <b>followed</b> {{by the words}} and music. At the bottom of [page] 1 is the {{copyright}} date,the name of the publisher and place of publication. Words and music continue on to [pages] 2 and 3. [Page] 5 are advertisements for piano books. [Page] 6 is an advertisement for "Outstanding songs of the air"...|$|R
5000|$|Poker Face {{is set in}} {{a common}} time time signature, with a fast tempo of 120 beats per minute. It is written in the key of G minor with Gaga's vocal range {{spanning}} from the note F3 to the note B4. It begins with a medium <b>tempo</b> <b>followed</b> by electronic chord arrangement and the [...] "Mum-mum-mum-mah" [...] hook. The chords follow in this order: Gm-E/G-F, and then for the chorus Gm-E-B-F. This is followed by the sound of dance music, produced by a powerful beat from the instruments, and a stuttering hook following the chorus.|$|R
40|$|Presented at the 22 nd International Conference on Auditory Display (ICAD- 2016) Physical {{inactivity}} is {{a worldwide}} issue causing {{a variety of}} health problems. Exploring novel ways {{to encourage people to}} engage in physical activity is a topic at the forefront of research for countless stakeholders. Based upon a review of the literature, a pilot study, and exit interviews, we propose an app prototype that utilizes music tempo manipulation to guide users into a target heart rate zone during an exercise session. A study was conducted with 26 participants in a fifteen-minute cycling session using different sonification mappings and combinations of audiovisual feedback based on the user's current heart rate. Results suggest manipulating the playback speed of music in real time based on heart rate zone departures can be an effective motivational tool for increasing or decreasing activity levels of the listener. Participants vastly preferred prescriptive sonifications mappings over descriptive mappings, due to people's natural inclination to <b>follow</b> the <b>tempo</b> of music...|$|R
40|$|We {{formulate}} tempo tracking in a Bayesian framework where a tempo tracker {{is modeled}} as a stochastic dynamical system. The tempo is modeled as a hidden state variable {{of the system}} and is estimated from a MIDI performance by Kalman filtering and smoothing. We also introduce the Tempogram representation, a wavelet-like multiscale expansion of a real performance, on which the Kalman filter operates. 1 Introduction An important and interesting subtask in automatic music transcription is tempo tracking: how to <b>follow</b> the <b>tempo</b> in a performance that contains expressive timing and tempo variations. When these tempo fluctuations are correctly identified it becomes much easier to separate the continuous expressive timing from the discrete note categories (i. e. quantization). The sense of tempo seems to be carried by the beats and thus tempo tracking is related to the study of beat induction, the perception of beats or pulse while listening to music (see Desain and Honing (1994)). However, [...] ...|$|R
40|$|In {{this paper}} {{we present a}} pilot study {{evaluating}} the effec-tiveness of a tactile metronome for music performance and training. Four guitar players were asked to synchronize to a metronome click-track delivered either aurally or via a vibrotactile stimulus. We recorded their performance at different tempi (60 and 120 BPM) and compared the re-sults across modalities. Our results indicate that a tactile metronome can reliably cue participants to <b>follow</b> the tar-get <b>tempo.</b> Such a device could hence be used in musical practice and performances as a reliable alternative to tradi-tional auditory click-tracks, generally considered annoying and distracting by performers. 1...|$|R
50|$|Rhythmic Auditory Stimulation or RAS is a Neurologic {{music therapy}} tool in which audible, rhythmic cues are {{provided}} to clients {{in order to}} strengthen and improve intrinsic rhythmic functions, such as gait. Through entrainment, the process in which a person's internal rhythm syncs with an external source, RAS can provide a safe, effective treatment in rehabilitation of rhythmic biological movements. The rhythmic cues can be provided by a guitar, a metronome, or any other medium that can deliver accented beats {{in a manner that}} <b>follows</b> a prescribed <b>tempo.</b> These cues are most often in meters of 2/4 and 4/4.|$|R
40|$|In this paper, an {{approach}} that estimates the times at which musical beats occur is presented. The system uses a hybrid multi-band decomposition in order to estimate the music <b>tempo.</b> <b>Following</b> this, beat events are tracked by using a dynamic programming approach, which is updated by using short time tempo estimates. The hybrid decomposition is used in order to calculate the tempo by using different onset detection functions in different frequency bands. In addition, a method that estimates which frequency bands provide reliable periodicities is also presented. The accuracy of the model is evaluated by comparing the presented system against existing approaches using a database of 474 songs...|$|R
40|$|The aim of {{this study}} is to {{manipulate}} musical cues systematically to determine the aspects of music that contribute to emotional expression, and whether these cues operate in additive or interactive fashion, and whether the cue levels can be characterized as linear or non-linear. An optimized factorial design was used with six primary musical cues (mode, tempo, dynamics, articulation, timbre, and register) across four different music examples. Listeners rated 200 musical examples according to four perceived emotional characters (happy, sad, peaceful, and scary). The results exhibited robust effects for all cues and the ranked importance of these was established by multiple regression. The most important cue was mode <b>followed</b> by <b>tempo,</b> register, dynamics, articulation, and timbre, although the ranking varied across the emotions. The second main result suggested that most cue levels contributed to the emotions in a linear fashion, explaining 77 – 89 % of variance in ratings. Quadratic encoding of cues did lead to minor but significant increases of the models (0 – 8 %). Finally, the interactions between the cues were non-existent suggesting that the cues operate mostly in an additive fashion, corroborating recent findings on emotional expression in music (Juslin & Lindstr&# 246;m, 2010) ...|$|R
40|$|This study {{extends the}} {{perspective}} of music performance research with an examination of a long-term performance. In a single case study, an uninterrupted recording of Erik Satie’s “Vexations ” performed by one pianist over almost 28 hours {{is used as a}} performance of extreme length to explore new approaches in performance data analysis. The MIDI and acoustical data are analysed with linear and non-linear methods to describe changes in tempo and loudness. Addi-tionally, the performer’s changing states of consciousness (alertness, trance, drowsiness) were observed to exert a strong influence on tempo and loudness stability. Tempo and loudness remain stable over the first 14 hours of alertness. A state of trance begins after 15 hours and shows a destabili-sation of <b>tempo</b> <b>followed</b> by uncontrolled deviations i...|$|R
50|$|Several music genres {{and styles}} are covered {{over the course}} of the album, {{including}} easy listening, chanting, drone, noise and metal, generally being separated by ambience and sounds and voices in a surgical setting. There are no lyrics or song structures as such as one would traditionally expect; the band instead focuses on atmosphere and the creation of suspense through the use of eerie noises, wordless vocals, and sudden, jarring changes in volume and intensity. Approximately the last 20 minutes of the track consist of the sound of a turntable stylus stuck in the runout groove of a record. The track then ends abruptly, with the sound of someone counting in a fast <b>tempo,</b> <b>followed</b> immediately by the stylus sliding across a record's surface.|$|R
50|$|The 1st {{movement}} {{starts with}} an introductory 18 bars (without key signature) of Adagio in 6/8 time marked quaver = 66, {{with the character}} almost of a cadenza with increasingly rococo embellishment, before leading to the main body which is a Moderato Assai, quasi andantino in F major, in 4/4 time, crotchet = 80. The 2nd movement (5 flats) Allegro Giusto, dotted crotchet = 112, in a mixed 6/8 and 9/8 tempo in mostly a 2 bars of 6/8 + 1 bar of 9/8 pattern, occasionally augmented to 3+1 and 4+1; a middle section in 3/4 (3 sharps) marked l'istesso <b>tempo</b> <b>follows,</b> then {{a return to the}} asymmetrical 2+1 complex tempo; as tension mounts at the end the pattern is stretched to 14+1.|$|R
40|$|We present two new beat {{tracking}} algorithms {{based on}} the autocorrelation analysis, which showed state-of-the-art performance in the MIREX 2010 beat tracking contest. Unlike the traditional approach of processing a list of onsets, we propose to use a bidirectional Long Short-Term Memory recurrent neural network to perform a frame by frame beat classification of the signal. As inputs to the network the spectral features of the audio signal and their relative differences are used. The network transforms the signal directly into a beat activation function. An autocorrelation function is then {{used to determine the}} predominant tempo to eliminate the erroneously detected- or complement the missing- beats. The first algorithm is tuned for music with constant tempo, whereas the second algorithm is further capable to <b>follow</b> changes in <b>tempo</b> and time signature. 1...|$|R
5000|$|The dance <b>follows</b> {{a strict}} <b>tempo</b> with {{emphasis}} in the [...] "attitude, style and grace" [...] of the dancer. It is a [...] meter with steps [...] "slow-quick-quick". The dance is a row dance, with a lead dancer performing skillfully executed steps. He then drops to his knees, arches his back and extends his chest upward, forming a bridge. The other dancers then step forward onto the lead dancer's stomach and dance {{on top of his}} stomach. The dancers hold each other from the hands, bend 90 degrees upwards at the elbows. It takes a sturdy hand, especially if you are supporting the first or last person of the line. This symbolizes the strength and centrality of the lead dancer as he forms a bridge with his body for the other men to cross over.|$|R
5000|$|The Virtual Orchestra is {{technology}} {{capable of}} simulating {{the sound and}} behavior of a traditional acoustic orchestra. That includes the ability to <b>follow</b> a conductor’s <b>tempo</b> and {{to respond to a}} variety of expressive musical nuances in real time. Opponents of the technology believe that the Virtual Orchestra does not qualify as a musical instrument because its output is far too complex to be under the control of a single performer. In order to achieve the increased gains in productivity, the system is viewed as relying on automation. More specifically, the one-to-one relationship between the input and output that has historically defined traditional musical instruments appears to have been breached. The traditional one-to-one relationship between performer and instrument implies that the instrument was designed within the performance capabilities of a human performer.|$|R
40|$|The {{ability to}} process {{temporal}} relations in sensory input {{is a prerequisite}} for adequate coordination of behavioral responses and environmental events. Here, sensorimotor synchronization was investigated in an adaptive timing task (Repp & Keller 2004). Patients with basal ganglia (BG) lesions and healthy controls were asked to align finger tapping to tone sequences that either did or did not contain a tempo change. At the end of each sequence participants continued tapping at the final tempo. The initial inter-onset interval (IOI) was 600 ms, <b>followed</b> by <b>tempo</b> accelerations or decelerations of 30, 45, 60 or 75 ms, respectively. Also, each participant´s spontaneous motor tempo (SMT) was assessed before and after the task (McAuley et al. 2006). Results indicate that SMT before the task was more variable in patients than in controls. Both groups showed less variability after the adaptive timing task. During sensorimotor synchronization overall adaption to tempo changes was greater at faster tempi than at slower tempi. Error correction mechanisms, that is, phase- and period correction, were affected differently with phase correction being more effective in tempo decelerations whereas period correction was more effective in tempo accelerations. Especially for slower tempi patients responded more variable and less sensitive to tempo change. The data show that the BG are involved in the detection of tempo change, in particular at slower rates...|$|R
40|$|Synthetic {{efforts toward}} {{fumonisin}} analog were described. These are accomplished via amino acid Schiff base methodology. These efforts {{can be divided}} three major phases. First, tandem reductive alkylation with DIBAL/TRIBAL and different types of organo-lithium or Grignard nucleophiles provided threo-amino alcohol with excellent stereoselecitivites (2 - 27 : 1). The reductive alkylation utilized most hydrocarbon nucleophiles, e. g. alkyl-, vinyl-, alkenyl-, phenyl-, and dienyl-, and afforded high selectivites unless donor solvents (e. g. THF and Et 2 O) were used. Second, syntheses of the protected threo-γ-amino-β-hydroxy aldehydes and their stereoselectivities were introduced. The reductive alkylated threo-amino allyl alcohol was transformed via Brown’s hydroboration/oxidation protocol with 9 -BBN, <b>followed</b> by <b>TEMPO</b> oxidation to give the resultant aldehydes in reasonable yields. Then, TBDPS and Schiff base protected aldehyde was coupled with phenyl- and decyl Grignard reagents to obtain predominant 3, 5 -anti-diols (ca. 80 : 20 anti:syn), characterized by ¹³C NMR analysis of Rychnovsky’s 1, 3 -acetonide groups. Products can be useful analogues for fumonisin and 5 -hydroxy-sphingosine due to their structural similarity. Third stage involved the synthesis of C₁₁-C₂₀ fragment analog of fumonisin. Chiral auxiliaries (e. g. Evans and Myers) were administrated for stereoselective methylation, Sharpless asymmetric dihydroxylation {{in the presence of}} (DHQ) 2 PHAL catalyst was performed to form 1, 2 - syn-diols, and the manipulation of protection/deprotection and Finklestein reaction furnished C₁₁-C₂₀ fragment analog of fumonisin...|$|R
