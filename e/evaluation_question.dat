58|881|Public
25|$|Happiness, well-being, or {{satisfaction}} with life, {{was seen as}} unmeasurable in classical and neo-classical economics. Van Praag {{was the first person}} who organized large surveys in order to explicitly measure welfare derived from income. He did this with the Income <b>Evaluation</b> <b>Question</b> (IEQ). This approach is called the Leyden School. It named after the Dutch university where this approach was developed. Other Researchers included Arie Kapteyn and Aldi Hagenaars.|$|E
5000|$|During his Leyden period (1972-84), Van Praag {{initiated}} {{and acted}} {{as leader of}} the Leyden School project, his main co-authors being Arie Kapteyn and Aldi Hagenaars. Van Praag argued in his Ph.D. dissertation (1968) that utility of money (called by Van Praag the [...] "individual welfare function of income", WFI) could be seen as a cardinal concept.Based on this idea he devised a specific question module, the Income <b>Evaluation</b> <b>Question</b> (IEQ), intended to ask respondents which income level they would call [...] "good", [...] "sufficient", [...] "bad", etc. The IEQ has been posed since 1970 to many thousands of respondents in large-scale surveys. Van Praag estimated the WFI for thousands of individuals in most countries of Western Europe.|$|E
40|$|A {{survey of}} {{residents}} in two small Florida cities provided an opportu-nity {{to examine the}} potential for question-order effects, since the sur-vey instrument contained a general <b>evaluation</b> <b>question</b> about the qual-ity of municipal services {{as well as a}} series of questions soliciting evaluations of specific services. The only difference between the two versions of the questionnaire was the placement of the following gen-eral evaluation question: "On the whole, how would you rate the ser-vices and facilities provided by the City of (NAME OF CITY) —very good, good, adequate, poor, or very poor? " On a random basis, approxi-mately one-half of the respondents were asked this general <b>evaluation</b> <b>question</b> first and then later in the interview were asked to indicate their preference to have a series of 12 specific services cut back, kept the same, or improved (version A). The question order was reversed for {{the other part of the}} sample (version B). ' Previous research (MacFarland 1981; Schuman and Presser 1981...|$|E
30|$|Schneider et al. [13] have divided their <b>evaluation</b> <b>questions</b> into {{mandatory}} and optional. All {{mandatory criteria}} {{have to be}} fulfilled to receive the lowest acceptable reliability category. The highest reliability category is reserved for studies which fulfill all mandatory <b>evaluation</b> <b>questions</b> and at least 18 of the 21 <b>evaluation</b> <b>questions</b> in total. This method differed from the other methods by, in our evaluation, assigning studies the highest reliability category (see the Summary of the reliability evaluation of the non-standard test data section).|$|R
40|$|The {{purpose of}} this {{document}} is to provide elaboration on overall mixed methods design and how the key <b>evaluation</b> <b>questions</b> and broad hypotheses link to specific methods. First is a short discussion of the mixed methods design for the baseline studies; second is a brief discussion of types of research and <b>evaluation</b> <b>questions</b> as a framework;; third, the more inquiry-oriented broad <b>evaluation</b> <b>questions</b> are listed with {{a discussion about the}} specific methods and items to respond to them; and fourth, preliminary broad hyotheses are listed with a discussion of which items in the baseline surveys and in proposed targeted studies can respond to these. Annexes include a short discussion on what constitutes evidence (A); the objectives of the baseline surveys (B); a table indicating methods and timing (C); and a table listing overall <b>evaluation</b> <b>questions</b> and methodologies (D) ...|$|R
50|$|Section II: Free-Response (one {{data-set}} question, one document-based question, and two synthesis and <b>evaluation</b> <b>questions,</b> 90 minutes).|$|R
40|$|This {{report is}} also {{available}} online at: [URL] report is the last {{in a series of}} evaluating the impact of the Local Housing Allowance (LHA) on Housing Benefit (HB) delivery in the Coventry Pathfinder. It provides an overview of the impacts of LHA on HB administration, the issues raised over the two year evaluation period and seeks to answer the broad <b>evaluation</b> <b>question</b> of whether, overall, the LHA offers substantial administrative advantages...|$|E
30|$|Each {{level in}} Bloom’s {{taxonomy}} is subsumed by the higher levels, for example a student functioning at the application level had mastered the educational concepts {{in the knowledge}} and comprehension levels (BS 1956). Bloom’s associated the levels hierarchical order with the question’s difficulty (BS 1956), for example knowledge level questions are easier than questions which assess other levels in Bloom’s taxonomy, and synthesis and <b>evaluation</b> <b>question</b> are more difficult than the comprehension level question (BS 1956).|$|E
40|$|Includes bibliographical {{references}} (leaves 39 - 41). This is {{a theory}} evaluation of the Touchline Media (TLM) employee induction programme. Organisations use induction training {{as part of the}} new employee welcoming process, {{making it one of the}} most common types of organisational training programmes (Klein & Weaver, 2000). Employees who have participated in structured induction programmes are 69 % more likely to stay with their chosen organisation than compared to employees who did not receive a similar programme (Brodie, 2006). Ideal induction programmes with appropriate content, process, support and follow-up components have universally been shown to improve employee retention and identification. The one-day TLM induction programme is set in a media and magazine production environment that is very fast paced and deadline driven. It was constructed as a means of ensuring that the organisation's legal obligation surrounding employee induction was fulfilled by informing new employees of their specific job requirements, performance standards and company policies. There are three evaluation questions that are addressed in this evaluation: <b>Evaluation</b> <b>question</b> 1 : Does the HRM's programme theory work for the recipients? In other words, are they aware that the outcome of the induction programme should be fulfilling a legal obligation? <b>Evaluation</b> <b>question</b> 2 : Would the original induction programme lead, by default, to identification with the employer and staff retention? This <b>evaluation</b> <b>question</b> was included, as it was assumed that the programme activities might have unintended consequences like identification and retention. <b>Evaluation</b> <b>question</b> 3 : If the original programme theory is changed (based on existing literature regarding induction programmes) would it lead to an improved design and in the end, to a more effective programme? Data was collected from programme participants using a ten item questionnaire. Questionnaire items were included by the evaluators to test three factors (Legal Obligation, Retention and Identification), with responses in a five-point Likert format. No statistically significant differences in the mean scores for Legal Obligation, Retention and Identification for the three groups of programme attendees (Group 1 : New employees with first month induction attendance; Group 2 : New employees with later induction attendance; Group 3 : Long-serving employees with later induction attendance) were found. This is an indication that the TLM induction programme did not lead to the outcomes of Legal Obligation, Retention or Identification. The main suggestions for improvement were presented according to the four universal components that make up a well organised induction programme, namely content, support, follow-up and process (D' Aurizio, 2007) ...|$|E
50|$|In {{the late}} 1970's, Peter Rossi {{with the help}} of his colleagues Mark W. Lipsey & Howard E Freeman {{developed}} an evaluation model called the Five-Domain Evaluation Model. In this model, each evaluation should be custom-made to fit resources, local needs, and the type of program. This includes custom-fitting the <b>evaluation</b> <b>questions,</b> methods and procedures, and the nature of the evaluator-stakeholder relationship. In the eyes of Rossi, the <b>evaluation</b> <b>questions</b> were the core while the rest of the evaluation evolves around it.|$|R
40|$|A. Direct {{lending to}} the private sector: a Bank action mandate [...] 1 B. Private sector lending {{activity}} [...] 1 C. The core <b>evaluation</b> <b>questions</b> [...] ...|$|R
40|$|This session {{will explore}} {{underlying}} assumptions impacting on evaluation research into student learning, particularly that occurring {{through the use}} of educational technology. It will consider issues in designing an evaluation of the effectiveness of an educational innovation, and describe a framework {{that can be used to}} scaffold the development of broad and specific <b>evaluation</b> <b>questions.</b> The framework will be used to develop an evaluation plan focused on an evaluation matrix, where specific <b>evaluation</b> <b>questions</b> are matched to sources of data which provide appropriate evidence to answer each of them. The sources of data may be both qualitative and quantitative. Examples will be given of the way that the framework has been used in various evaluation research projects...|$|R
30|$|Schneider et al. [13] <b>evaluation</b> <b>question</b> is also {{wide and}} {{concerns}} relevance, rather than reliability. In the accompanying guidance {{material to the}} question, a variety of aspects are included: the chosen test system and its applicability domain, consideration of physio-chemical properties and stability of test substance, number of replicates, number of concentration levels and their range and spread, suitability of administration method, inclusion of all relevant endpoints, and statistical evaluation. The method would benefit from separating these aspects into several questions.|$|E
30|$|Although {{interaction}} data {{does not}} necessarily reflect user perception, such data can be of interest for evaluation. For HCI, instrumental and manually annotated data is usually {{used to describe the}} course of interaction, either because it represents a genuine <b>evaluation</b> <b>question</b> (e.g. the relationship between measured and user perceived interaction duration). In this case, such data can complement questionnaire data, e.g. for topics concerning smoothness or naturalness of interaction (topics 1 and 2); nonverbal and verbal functions (topics 3 and 4) or user’s internal states (topic 6 from Section “Theoretical foundations of evaluation”).|$|E
30|$|In {{two of the}} {{evaluated}} studies, {{the authors}} did not report whether controls were used or not. Acceptability criteria were not stated {{in any of the}} studies, but since Schneider et al. [13] asks whether the variability of the results and control was acceptable, one of the studies were considered to fulfill this <b>evaluation</b> <b>question.</b> The origin of the control and test organisms and whether the control media is identical to test media in all respect except the treatment variable was not specifically stated in any of the studies. A possible reason for this could be that this is considered to be self-evident.|$|E
40|$|As a classically trained {{statistician}} (M. Stat., 1971), I found limitations {{imposed by}} having only quantitative methodologies in my toolbox a hard pill to swallow. That realization came {{quickly in the}} early 1970 s as I became more involved in evaluation. At that time, good qualitative references were scarce and most qualitative people seldom spoke with quantitative people and vice versa. In addition, most of the material on qualitative methods was from disciplines that were foreign {{to me at the}} time. However, it was obvious that different types of <b>evaluation</b> <b>questions</b> (or research questions) required different methodologies and many <b>evaluation</b> <b>questions</b> could only be addressed with qualitative methodologies. It is interesting that among my first references for qualitative methods were thos...|$|R
40|$|The {{aim of this}} {{bachelor}} {{thesis is}} a comparison of real estate evaluation methods. The work is mainly concerned with <b>evaluation</b> <b>questions</b> and expert’s legislation. The first part contains theory, which is necessary for analysis of evaluation methods. The next practical part includes analysis of a particular real estate property...|$|R
40|$|Studies that {{examine the}} impacts of {{education}} interventions on key student, teacher, and school outcomes typically collect data on large samples and on many outcomes. In analyzing these data, researchers typically conduct multiple hypothesis tests to address key impact <b>evaluation</b> <b>questions.</b> Tests are conducted to assess intervention effects for multiple outcomes...|$|R
40|$|This paper {{provides}} {{evidence that}} subjective measures of individual well being {{can be used}} to study the impact of income uncertainty from an ex ante point of view. Two different measures of subjective well being are under study: Satisfaction with household income and the income <b>evaluation</b> <b>question</b> as developed by Van Praag. It can be shown that satisfaction with income is more affected by ex ante than by ex post volatility of income. The ordinal version of the Van Praag approach might be biased if income uncertainty is essential. The paper was written in 1994. income uncertainty, subjective well-being, satisfaction, income evaluation...|$|E
40|$|Within {{a public}} {{environment}} in which accountability is at the forefront, an important <b>evaluation</b> <b>question</b> is how to document the economic value of innovation-related outputs and outcomes from intramural research relative {{to the cost of}} funding an intramural research programme. In this paper, we apply a counterfactual method to an evaluation of the US Advanced Technology Program's (ATP) Intramural Research Initiative. We also suggest more general applications of the methodology – for example, economic development applications to project evaluations in the developing areas of a country or in developing nations. intramural research; project evaluation; public accountability; cost-benefit analysis; ATP; Advanced Technology Program; USA; United States; public policy; economic development. ...|$|E
40|$|There {{is growing}} {{interest}} in evaluating policy implementation in ways that grapple with {{the complexity of the}} process. This article offers an example of using systems methodology to explore how the child protection policy in child contact centres has functioned in practice. Rather than just asking the traditional <b>evaluation</b> <b>question</b> “is it working?” this study sought to understand how the policy was working and how it was interpreted as it interacted with other systems, producing conflicts, local variation and emergent effects. It illustrates how the systems concepts of ‘emergence’, ‘local rationality’, ‘socio-technical systems’ and ‘feedback for learning’ can contribute new knowledge and understanding to a complex policy evaluation problem...|$|E
30|$|This grading {{procedure}} {{has been}} used in numerous clinical trials and has shown good to excellent reproducibility for assessment of vascular lesions and macular edema. <b>Evaluation</b> <b>questions</b> for the types of chorioretinal lesions were drafted to be descriptive and not diagnostic {{due to the lack of}} consensus on the classification of various posterior uveitides.|$|R
30|$|The {{assessment}} of expertise {{during the process}} is therefore better suited for Open Foresight processes than the a priori accreditation since it is dynamic and scalable {{and it is possible}} to define expertise post-hoc for very specific topic areas [73]. This works especially well if the <b>evaluation</b> <b>questions</b> are non-compulsory, which leads to only “true” experts answering them [77].|$|R
40|$|Definition {{and nature}} of service evaluation, Imetus and purpose, Models of evaluation, Types of evaluation, Aspects of evaluation, Values in service delivery, Stages in <b>evaluation</b> studies, <b>Evaluation</b> <b>questions,</b> Pitfalls and {{difficulties}} in evaluation, Evaluation measures and data sources, Sevice evaluation methods, Assessing needs, Assessing patient satisfaction, Presenting results, Evaluation results and decision making, Ethical aspects of evaluatio...|$|R
40|$|Presented are the {{findings}} of Project Echo, a research project designed to replicate an earlier study on a supplementary instructional program for secondary level learning disabled students. Brief introductory sections cover the three major project components (the instructional curriculum, the teacher training materials, and the classroom management handbook), the five replication sites in Texas, and the evaluation design. The. bulk of the document is organized around 10 elementsacademic achievement, student attendance, student dropouts, parent involvement, community information dissemination, teacher training, Project Echo dissemination, activity audit, instructional content mastery,-and teacher perception. For each element, a report is provided which outlines the following: <b>evaluation</b> <b>question</b> of interest, instrumentation, design configuration, data analysis model, desig...|$|E
40|$|Family size affects {{welfare in}} two ways. First, if family {{increases}} and income is constant, income {{has to be}} spread over more family members. This would suggest that a family increase would yield a welfare decrease. However, the fact that families have children, even if technically avoidable, points to a value of children as consumption goods. In this paper we analyze two attitude questions, viz. the Income <b>Evaluation</b> <b>Question</b> and the Cantril Question. The first may be interpreted as capturing the first effect only, while the second captures both. We derive family equivalence scales based on the two questions and we find quite different scales. Furthermore we show that both scales do not satisfy the IB-property...|$|E
40|$|This {{dissertation}} was {{an outcome}} {{evaluation of the}} Living Through Learning's Coronation Reading Adventure Room Programme. LTL's reading programme objectives include aspects of improving and developing English literacy in disadvantaged schools, teaching learners {{how to read and}} write and equipping teachers with the necessary skills to teach effectively. LTL also provides facilitators to offer assistance to the teachers in order to teach effectively in overcrowded classes. The main programme beneficiaries are teachers and grade one learners. This dissertation focuses on 18 schools in disadvantaged communities in Cape Town who received the literacy programme in 2015. Two evaluation questions were formulated, for the literacy programme. The first <b>evaluation</b> <b>question</b> focused on the learners and assessed whether or not the learners who were part of the CRAR programme were better off regarding literacy performance than they were before the programme. For the teacher characteristics, the <b>evaluation</b> <b>question</b> asked if the teachers' language teaching experience, English language proficiency, teaching self-efficacy, perceptions of usefulness of the LTL materials, and usage of the reading room had any influence on the learner's performance. Secondary data provided by LTL was utilised to answer the literacy programme <b>evaluation</b> <b>question.</b> The data included test scores of grade 1 learners from 18 different schools. Primary data was used for teacher's characteristics and this was done through a questionnaire sent out to the different teachers. Data analysis methods included descriptive statistics for the learners' assessments and inferential statistics for teacher characteristics. The results showed that learners who were part of the LTL programme showed improvement in assessment scores. All schools, except one, attained the realistic NGO (60 %) standard in their reading assessments. Three schools attained the high standard (85 %). Furthermore, all schools attained the 50 % Curriculum Assessment Policy Statements standard in the CAPS based-assessments. Therefore, it can be concluded that the LTL programme successfully aided improvement of literacy skills of the learners who were part of the programme. In an analysis of teacher's characteristics, teacher experience in literacy was the only variable that significantly predicted learner performance in literacy. However, the results must be interpreted with caution; the absence of a comparison group makes it difficult to give all credit to the LTL programme alone. At this point I simply do not know whether it was only the programme that led to the improvement in literacy scores or whether other factors had an influence, or a joint influence in combination with the literacy programme (e. g. learners started reading more in their own time {{as a result of the}} programme) ...|$|E
40|$|Straightlining, an {{indicator}} of satisficing, refers to giving the same answer {{in a series of}} questions arranged on a grid. We investigated whether straightlining changes with respondents' panel experience in two open-access Internet panels in the Netherlands: the LISS and Dutch Immigrant panels. Specifically, we considered straightlining on 10 grid questions in LISS core modules (7 waves) and on a grid of <b>evaluation</b> <b>questions</b> in both the LISS panel (150 + waves) and the Dutch immigrant panel (50 + waves). For both core modules and <b>evaluation</b> <b>questions</b> we found that straightlining increases with respondents' panel experience for at least three years. Straightlining is also associated with younger age and non-western 1 st generation immigrants. Where straightlining was a plausible set of answers, prevalence of straightlining was much larger (15 - 40 %) than where straightlining was implausible (< 2 % in wave 1). " (author's abstract...|$|R
40|$|Logic {{models are}} graphic {{representations}} {{of the relationship between}} program activities and their intended effects and are used for both program planning and evaluation. Logic models can provide an important foundation for program evaluation by identifying <b>evaluation</b> <b>questions</b> that most appropriately assess program processes and outcomes and by guiding measurement decisions. We demonstrate how logic models can be used to plan program evaluation by describing the adoption of logic modeling by the Washington State Heart Disease and Stroke Prevention Program (WaHDSPP) and by specifying the changes in process and use of logic models since the program’s initial funding. Our paper describes how a logic model was used in generating the program evaluation plan for the WaHDSPP, including the identification of <b>evaluation</b> <b>questions</b> and development of indicators to track progress effectively. We describe the use of evaluation results, as well as steps state programs can take to use logic models in program evaluation...|$|R
40|$|This paper {{examines}} some of {{the important}} policy issues pertaining to student {{access to higher education}} and raises <b>evaluation</b> <b>questions</b> for which <b>evaluation</b> research is needed. For illustrative purposes, the paper presents data that show the progress the nation has made in expanding access persistence and degree completion for various segments of the population at different levels, types and qualities of colleges and universitie...|$|R
30|$|In {{addition}} to the often-analyzed standard life <b>evaluation</b> <b>question</b> using the Cantril ladder, this paper also examines various measures of subjective well-being based on time use—the U-index, net affect, meaningfulness, happiness, pain, sadness, and stress—and self-rated health status. The U-index, net affect, happiness, pain, sadness, and stress all measure the presence of pleasure {{and the absence of}} displeasure, which corresponds to affective (or hedonistic) views of subjective well-being, while meaningfulness and the Cantril ladder measure a cognitive state or a positive attitude towards one’s life, which corresponds to cognitive (or attitudinal) views of subjective well-being (Angner 2010; Brülde 2007). By analyzing these various measures of subjective well-being, this paper can help provide a fuller picture of the link between job displacement and subjective well-being.|$|E
40|$|IntroductionThe Centers for Disease Control and Prevention (CDC) {{developed}} the Web-based Injury Statistics Query and Reporting System (WISQARSTM) {{to meet the}} data needs of injury practitioners. In 2015, CDC completed a Portfolio Review of this system to inform its future development. MethodsEvaluation questions addressed utilization, technology and innovation, data sources, and tools and training. Data were collected through environmental scans, a review of peer-reviewed and grey literature, a web search, and stakeholder interviews. ResultsReview findings led to specific recommendations for each <b>evaluation</b> <b>question.</b> ResponseCDC reviewed each recommendation and initiated several enhancements that will improve the ability of injury prevention practitioners to leverage these data, better make sense of query results, and incorporate findings and key messages into prevention practices. CC 999999 /Intramural CDC HHS/United States 2018 - 06 - 01 T 00 : 00 : 00 Z 28454867 PMC 5605760 vault: 2475...|$|E
40|$|This study {{analyzes}} {{participation of}} selected minorities {{and female students}} in particular second-ary-school courses in six Southwestern Ontario boards of education during the 1988 - 1989 school year. Relative over- or underrepresentation of each group studied was tabulated by course type, grade, and level of difficulty. Results taken across all six boards indicate, among other relationships, overrepresentation of recently immigrated students in advanced-level university-entrance English classes, modest underrepresentation of Black students in advanced-level core subjects, and strong underrepresentation of Native Canadian Indian students in advanced-level English and math. Individual board analyses showed considerable deviation from across-board patterns. Genesis and Limits of the Study This study grew out of Lasswell's (1958) most elemental policy <b>evaluation</b> <b>question</b> "Who gets what? " applied to public educa-tion in an increasingly pluralistic Ontario— {{and out of a}} vexing methodological barrier t...|$|E
40|$|This report {{describes}} the main {{findings of a}} detailed evaluation of a burglary reduction project located in Liverpool in the North of England. The scheme consisted of four interventions: alley-gating, target hardening of property, property marking and an offender rehabilitation intervention. New analytical techniques, discussed in detail in this report, were developed in order to answer the key <b>evaluation</b> <b>questions.</b> The results may be summarised as follows...|$|R
40|$|AbstractThis paper {{sets out}} a {{step-by-step}} {{plan to help}} readers design, implement and disseminate evaluations of interprofessional education (IPE). We present the following twelve steps that are central to this process: formulating <b>evaluation</b> <b>questions,</b> agreeing on the evaluation approach, using evaluation frameworks, drawing upon evaluation expertise, reviewing the literature, selecting a methodology and design, securing ethical approval, accessing data, addressing fieldwork issues, using evaluation instruments, considering resources, and outlining disseminating choices...|$|R
40|$|Care. This report {{presents}} the interim evaluation results. Conclusions about the <b>evaluation</b> <b>questions</b> cannot {{be drawn from}} these interim results. Final evaluation results are not yet available. A final report {{will be published in}} 2008. The views expressed in this publication do not represent any official position {{on the part of the}} Social Policy Research Centre, but the views of the individual authors. ATTENDANT CARE DIRECT FUNDING Social Policy Research Centr...|$|R
