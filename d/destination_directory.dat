9|5|Public
5000|$|The NeXT {{functionality}} builds {{upon this}} concept {{by allowing the}} <b>destination</b> <b>directory</b> {{to be put on}} the Shelf as well, and the file can be merely dragged to the <b>destination</b> <b>directory</b> icon.|$|E
5000|$|... {{the file}} is dragged from the Shelf to the <b>destination</b> <b>directory</b> ...|$|E
50|$|When the program's {{arguments}} are the path names to two directories, cp copies all files in the source directory to the <b>destination</b> <b>directory,</b> creating any files or directories needed. This {{mode of operation}} requires an additional option flag, typically r, to indicate the recursive copying of directories. If the <b>destination</b> <b>directory</b> already exists, the source is copied into the destination, while a new directory is created if the destination does not exist.|$|E
5000|$|... 1 - Each {{subdirectory}} has {{exactly one}} parent directory (not including shortcuts to the directory's location; while such files may have similar icons to the icons of the <b>destination</b> <b>directories,</b> {{they are not}} directories at all).|$|R
40|$|As {{sizes of}} {{circuits}} are shrinking and the clock speed is increasing, functional delay tests are receiving more attention within each day. Based on circuits “black-box” behavioural description, {{it is possible}} to generate a high quality functional delay test at initial circuits design stages, which covers more than 99 % of all circuits’ transition faults. To make more reliable and speed up the process of finding a better functional delay test generating method, an experimenting system was developed. One of the system`s main features is its capability of automatically storing data files to their set <b>destination</b> <b>directories,</b> which lowers the risk of human being error-prone. This thesis analyses methods used for creating functional delay tests and suggests four more implementations using activity vectors. By using partly automated experimenting system, all four methods were tested, together with the experimenting system. The results reveal how much the functional delay testing process speed up using automated system compared to launching all the testing tasks personally. As experimenting system automatically creates functional delay test method comparison table, it was possible to easily evaluate the most acceptable method that produces tests with high fault coverage and low test size...|$|R
40|$|Abstract — The Knowledge File System (KFS) {{is a smart}} {{virtual file}} system that sits between the {{operating}} system and the file system. Its primary functionality is to automatically organize files in a transparent and seamless manner so as to facilitate easy retrieval. Think of the KFS as a personal assistant, who can file {{every one of you}} documents into multiple appropriate folders, so that when it comes time for you to retrieve a file, you can easily find it among any of the folders that are likely to contain it. Technically, KFS analyzes each file and hard links (which are simply pointers to a physical file on POSIX file systems) it to multiple <b>destination</b> <b>directories</b> (categories). The actual classification can be based on a combination of file content analysis, file usage analysis, and manually configured rules. Since the KFS organizes files using the familiar file/folder metaphor, it enjoys 3 key advantages against desktop search based solutions such as Google’s Desktop Search, namely 1) usability, 2) portability, and 3) compatibility. The KFS has been prototyped using the FUSE (Filesystem in USErspace) framework on Linux. Apache Lucene was used to provide traditional desktop search capability in the KFS. A machine learning text classifier was used as the KFS content classifier, complimenting the customizable rule-based KFS classification framework. Lastly, an embedded database is used to log all file access to support file-usage classification. virtual file system; search engine; personal information management; indexing; classification I...|$|R
5000|$|When {{synchronizing}} mono-directionally in {{a custom}} mode, DirSync Pro detects synchronization conflicts. These conflicts may occur if a file is edited in the <b>destination</b> <b>directory</b> independently. DirSync Pro offers these options {{to solve the}} mono-directional synchronization conflicts: ...|$|E
50|$|When {{the program}} has one or more {{arguments}} of path names of files and following those an argument of a path to a directory, then the program copies each source file to the <b>destination</b> <b>directory,</b> creating any files not already existing.|$|E
50|$|The Gnome Commander {{is one of}} {{the file}} {{managers}} with two separate panels, based on the split-view interface of Norton Commander. This allows the simultaneous view of a source and <b>destination</b> <b>directory</b> for copying and moving files or directories. This also makes comparing directories very convenient. The number of windows on the desktop is thereby reduced. In Gnome Commander the two panels can be arranged either horizontally or vertically.|$|E
40|$|Southern Indiana Gas and Electric Company (SIGECO), {{now known}} as Vectren, {{has had a long}} history in the Evansville area. Founded in 1912, the company took the name SIGECO in 1920. They {{supplied}} both gas and/or electric to their customers. In the early 1930 s, they laid miles of underground natural gas pipelines and made sure to advertise this resource which they did with ads like this one in the 1932 Evansville city <b>directory.</b> <b>Destination</b> Indiana Gas Boom in Indian...|$|R
40|$|This {{directory}} contains {{data files}} that describe travel times in Nairobi, Kenya. Three different modes of transportation are included: - Walking, according to MapQuest and filled in with Google Maps where MapQuest fails {{to find a}} route. - Driving, under normal traffic conditions. - Matatus, the informal public transportation network. The travel times are computed from a gridded origin location to a collection of gridded destination locations. In the directories, each file contains destination location times for a given origin location. These are titled -###. csv. The CSV is organized from north to south, along rows, and west to east, along columns. An additional. csv file in each directory gives {{the organization of the}} numbered files, again from north to south, along rows, and west to east, along columns. There are also "extended" versions of each grid, with larger destination grids for each origin point, formed by "daisy-chaining" together the original <b>destination</b> grids. The <b>directory</b> also contains source files for working with the data: - calc_access. R shows how to calculate a simple mobility measure, using the functions in tools_calc_access. R - tools_analyze. R are a more general set of functions for performing arbitrary callback-based operations on the travel time data. - tools_calc_access. R contains underlying functions for setting up access to the grids and calculating access. - tools_map. R contains the grid origin and destination definitions and functions for plotting...|$|R
5000|$|In {{this version}} all tables are read into memory upon [...] "connecting" [...] to the {{database}} and [...] "touched" [...] tables are written out upon checkpoint. Each table is {{represented as a}} separate file in the <b>destination</b> <b>directory,</b> {{and there is a}} [...] "data definition" [...] file as well (a list of data definition declarations). During active use a log file appears in the active directory as well, and if the process crashes this log file is used to recover committed operations.|$|E
40|$|A {{harvester}} {{to collect}} records from an OAI-PMH enabled provider. The harvester {{can be used}} to carry out one-time harvesting of all records from a particular OAI-PMH provider by giving its base URL. It can also be used for selective harvesting, e. g. to harvest only records updated after, or before specified dates. To assist in regular harvesting from one or more OAI-PMH providers, there's a provider registry. It is possible to associate a short memorable name for a provider with its base URLs, <b>destination</b> <b>directory</b> for harvested records, and the format (metadataPrefix) in which records should be harvested. The registry will also record the date and time of the most recent harvest, and automatically add this to subsequent requests in order to avoid repeatedly harvesting unmodified records. ENHANCEMENTS 	Check that specified URL is an OAI-PMH server before attempting to harves...|$|E
40|$|The aim of {{this work}} is to design "dual panel" file manager with WebDAV {{protocol}} support which extends well-known HTTP. The application is an alternative to FTP clients. That brings some benefits such as ability to work behind firewall or cooperation support. The application provides well arranged graphical user interface to manage either local or webdav files. Users can run basic file operations like copy, move, rename, delete within local and webdav directories or between them. Furthermore, the application offers sophisticated synchronizaction support. It allows users to run oneshot synchronization of two directories especially the local and webdav one. What is more, the automatic synchronization checks every changes in source directory and carry out the appropriate file operations in <b>destination</b> <b>directory.</b> The other features of the application are the ability to lock webdav files and directories, saving connections profiles and secure communication over HTTPS...|$|E

