0|501|Public
3000|$|The [...]. 022 <b>inch</b> <b>system</b> has {{mechanical}} {{advantages in}} some clinical situations, such as during sliding mechanics when a [...]. 019 × [...]. 025 " [...] SS archwire is used, nevertheless, [...]. 018 <b>inch</b> <b>system</b> {{seems to be}} superior {{in the amount of}} the couple it is able to express, when a [...]. 017 ×. 025 " [...] SS archwire is engaged [10]. On the other hand, clinical studies on the final outcome of [...]. 018 and [...]. 022 <b>inch</b> <b>systems</b> did not show any significant difference, as the operator experience seems to be the fundamental parameter [11].|$|R
5000|$|The Glasgow Haskell Compiler (GHC) for the {{language}} Haskell uses lightweight threads which are scheduled on operating <b>system</b> <b>threads.</b>|$|R
5000|$|Once all the Boot and System {{drivers have}} been loaded, the kernel (<b>system</b> <b>thread)</b> starts the Session Manager Subsystem (...) [...]|$|R
5000|$|Multiple views for threads: Linear (a flat <b>system),</b> <b>threaded</b> (display of {{the entire}} thread tree), and hybrid (a {{combination}} of both).|$|R
40|$|Three {{experiments}} {{were conducted in}} Maricopa, Marana, and Glendale, Arizona in 2001 to measure cotton growth, yield, micronaire, and production costs in single and double seed line per bed systems on 32 and 40 inch beds. Canopy development was faster and canopy closure was greater in the double seed line than in the single seed line systems and was greater in the 32 inch than in the 40 <b>inch</b> row <b>systems.</b> At Maricopa, the single line 32 <b>inch</b> <b>system</b> yield of 1571 lbs. /A was significantly greater than the yields of the other seed line/row spacing systems. The yields of the single line 40 and the double line 32 <b>inch</b> <b>systems</b> {{were not significantly different}} at 1476 and 1411 lbs. of lint/A, respectively, and the yields of the double line 32 and the double line 40 <b>inch</b> <b>systems</b> also were not significantly different at 1411 and 1396 lbs. of lint/A, respectively. There were no significant lint yield differences at the Marana or Glendale location. At Marana, the lint yields were 1063 and 1066 lbs. /A for the single and double seed line 40 <b>inch</b> row spacing <b>systems,</b> respectively. At Glendale, the single and double seed line 38 <b>inch</b> row spacing <b>systems</b> yielded 1474 and 1551 lbs. of lint/A, respectively. In all 2001 experiments, there was a trend for reduced micronaire in the double seed line per bed systems compared to the single seed line per bed systems. At Maricopa, the average micronaire was 5. 0 and 4. 7 for the single and double seed line per bed 32 <b>inch</b> row <b>system,</b> respectively, and 5. 2 and 4. 9 for the single and double seed line per bed 40 <b>inch</b> row <b>systems,</b> respectively. At Marana, the micronaire was 4. 7 and 4. 5 for the single and double seed line per bed 40 <b>inch</b> row <b>systems,</b> respectively. At Glendale, the micronaire was 5. 1 and 4. 6 for the single and double seed line per bed 38 <b>inch</b> row <b>systems,</b> respectively. Production costs were similar for the single and double seed line per bed systems. Additional research will be conducted in 2002 to determine the optimum plant populations and in-row plant spacings for double seed line per bed production systems...|$|R
5000|$|The Unified Thread Standard (UTS) is most {{commonly}} used in the United States, but is also extensively used in Canada and occasionally in other countries. The size of a UTS screw is described using the following format: X-Y, where X is the nominal size (the hole or slot size in standard manufacturing practice through which the shank of the screw can easily be pushed) and Y is the threads per inch (TPI). For sizes [...] inch and larger the size is given as a fraction; for sizes less than this an integer is used, ranging from 0 to 16. The integer sizes {{can be converted to}} the actual diameter by using the formula 0.060 + 0.013 &times; number. For example, a #4 screw is 0.060 + 0.013 &times; 4 = 0.112 inches in diameter. There are also screw sizes smaller than [...] "0" [...] (zero or ought). The sizes are 00, 000, 0000 which are usually referred to as two ought, three ought, and four ought. Most eyeglasses have the bows screwed to the frame with 00-72 (pronounced double ought - seventy two) size screws. To calculate the major diameter of [...] "ought" [...] size screws count the number of 0's and multiply this number by [...]013 and subtract from [...]060. For example, the major diameter of a 000-72 screw thread is [...]060 - (3 x [...]013) = [...]060-.039 = [...]021 inches. For most size screws there are multiple TPI available, with the most common being designated a Unified Coarse Thread (UNC or UN) and Unified Fine Thread (UNF or UF). Note: In countries other than the United States and Canada, the ISO Metric Screw <b>Thread</b> <b>System</b> is primarily used today. Unlike most other countries the United States and Canada still use the Unified (<b>Inch)</b> <b>Thread</b> <b>System.</b> However, both are moving over to the ISO Metric System. It is estimated that approximately 60% of screw threads in use in the United States are still inch based.67 ...|$|R
5000|$|... coThreads, a {{concurrent}} programming library of OCaml, offers STM (originally STMLib) as a module. Just {{like any other}} components in this library, the STM module can be used uniformly with VM-level <b>threads,</b> <b>system</b> <b>threads</b> and processes.|$|R
50|$|For example, Windows NT/XP/Vista uses a {{multilevel}} feedback queue, {{a combination}} of fixed-priority preemptive scheduling, round-robin, and first in, first out algorithms. In this <b>system,</b> <b>threads</b> can dynamically increase or decrease in priority depending on if it has been serviced already, or if it has been waiting extensively. Every priority level is represented by its own queue, with round-robin scheduling among the high-priority threads and FIFO among the lower-priority ones. In this sense, response time is short for most threads, and short but critical <b>system</b> <b>threads</b> get completed very quickly. Since threads can only use one time unit of the round-robin in the highest-priority queue, starvation {{can be a problem}} for longer high-priority threads.|$|R
50|$|Thread uses 6LoWPAN, {{which in}} turn uses the IEEE 802.15.4 {{wireless}} protocol with mesh communication, as does ZigBee and other <b>systems.</b> <b>Thread</b> however is IP-addressable, with cloud access and AES encryption. It currently supports up to 250 devices in one local network mesh.|$|R
40|$|Despite an {{increasing}} need for thread support in language run-time systems and parallel libraries {{such as in}} Java and OpenMP, there is limited support for custom, multiprocessor capable, user-level <b>thread</b> <b>systems</b> in the Linux kernel. To address this lack of support we have developed the virtual processor interface (VPI) for Linux. Our VPI implementation consists of a small set of kernel modifications and new system calls combined with a small user-level library that provide an interface {{that can be used}} to build <b>thread</b> <b>systems.</b> VPI uses a form of scheduler activations so that user-level <b>thread</b> <b>systems</b> can have complete control over the amount of parallelism for an application and the scheduling of threads onto processors. In addition, VPI allows user-level <b>thread</b> <b>systems</b> to schedule new threads in the presence of blocking system calls and page faults. This paper describes VPI and our implementation. We have implemented a complete <b>thread</b> <b>system</b> using VPI, called VPIthreads, and compare its performance to that of current user-level and kernel-level <b>thread</b> <b>systems.</b> Our initial results show the VPI-based <b>thread</b> <b>systems</b> can perform better than current production <b>thread</b> <b>systems.</b> Keywords: High Performance Computing and Networking, Parallel computing, User-level threads, Linux kerne...|$|R
2500|$|Erlang's main {{strength}} is support for concurrency. It {{has a small}} but powerful set of primitives to create processes and communicate among them. Erlang is conceptually similar to the occam programming language, though it recasts the ideas of communicating sequential processes (CSP) in a functional framework and uses asynchronous message passing. Processes are the primary means to structure an Erlang application. [...] They are neither operating system processes nor operating <b>system</b> <b>threads,</b> but lightweight processes that are scheduled by Erlang's BEAM VM. Like operating system processes (but unlike operating <b>system</b> <b>threads),</b> they share no state with each other. The estimated minimal overhead for each is 300 words. Thus, many processes can be created without degrading performance. A benchmark with 20 million processes has been successfully performed. Erlang has supported symmetric multiprocessing since release R11B of May 2006.|$|R
5000|$|In the DioneOS <b>system</b> the <b>thread</b> {{can be in}} one of {{following}} states: ...|$|R
40|$|This {{dissertation}} addresses operating <b>system</b> <b>thread</b> scheduling for chip multithreaded processors. Chip multithreaded processors {{are becoming}} mainstream {{thanks to their}} superior performance and power characteristics. Threads running concurrently on a chip multithreaded processor share the processor’s resources. Resource contention, and accordingly performance, depends on characteristics of the co-scheduled <b>threads.</b> The operating <b>system</b> controls <b>thread</b> co-scheduling, and thus affects performance of a chip multithreaded system. This dissertation describes the design and implementation of three new scheduling algorithms for chip multithreaded processors: the nonwork-conserving algorithm, the target-miss-rate algorithm, and the cachefair algorithm. These algorithms target contention for the second-level cache, a recognized performance-critical resource, and pursue several objectives: performance optimization, fairness, and performanc...|$|R
50|$|New {{features}} in 3.7 included an inline spam management & prevention <b>system,</b> <b>thread</b> tagging and tag cloud, thread prefixes, reciprocal friendship between users, public visitor messaging on user profile pages, user picture albums, user-created social groups, user-customizable profile pages, a lightbox viewer for images attached to posts, post edit history, a notices system, multiple human verification systems, and social bookmarking integration.|$|R
50|$|Note that ApacheBench {{will only}} use one {{operating}} <b>system</b> <b>thread</b> {{regardless of the}} concurrency level (specified by the -c parameter). In some cases, especially when benchmarking high-capacity servers, a single instance of ApacheBench can itself be a bottleneck. When using ApacheBench on hardware with multiple processor cores, additional instances of ApacheBench {{may be used in}} parallel to more fully saturate the target URL.|$|R
50|$|Stackless Python, or Stackless, is a Python {{programming}} language interpreter, {{so named because}} it avoids depending on the C call stack for its own stack. The most prominent feature of Stackless is microthreads, which avoid much of the overhead associated with usual operating <b>system</b> <b>threads.</b> In addition to Python features, Stackless also adds support for coroutines, communication channels and task serialization.|$|R
5000|$|The primary {{concurrency}} construct is the goroutine, {{a type of}} light-weight process. A {{function call}} prefixed with the [...] keyword starts a function in a new goroutine. The language specification does not specify how goroutines should be implemented, but current implementations multiplex a Go process's goroutines onto a smaller set of operating <b>system</b> <b>threads,</b> similar to the scheduling performed in Erlang.|$|R
40|$|We {{present a}} formal and {{numerical}} analysis of current distribution through {{two-dimensional electron gas}} <b>systems</b> <b>threaded</b> by a magnetic field. The nonequilibrium Keldysh formalism is elaborated into a procedure well suited to describe both local features of carrier flow and universal features connected to the spatial chirality produced by strong magnetic fields. The interplay between disorder and chirality is illustrated by numerical simulations of significant models...|$|R
50|$|In Windows NT, {{the boot}} loader is called NTLDR. It is {{responsible}} for accessing the file system on the boot drive, for starting ntoskrnl.exe and for loading boot-time device drivers into memory. Once all the Boot and System drivers have been loaded, the kernel (<b>system</b> <b>thread)</b> starts the Session Manager Subsystem (smss.exe), which in turn starts winlogon, which loads the graphical identification and authentication library.|$|R
50|$|Virtuoso is {{designed}} {{to take advantage of}} operating <b>system</b> <b>threading</b> support and multiple CPUs. It consists of a single process with an adjustable pool of threads shared between clients. Multiple threads may work on a single index tree with minimal interference with each other. One cache of database pages is shared among all threads and old dirty pages are written back to disk as a background process.|$|R
40|$|In this paper, we {{show how}} thread {{partitioning}} helps in proving properties of mobile <b>systems.</b> <b>Thread</b> partitioning consists in gathering the threads of a mobile system into several classes. The partitioning criterion is left as a parameter {{of both the}} mobility model and the properties we are interested in. Then, we design a polynomial time abstract interpretationbased static analysis that counts the number of threads inside each partition class. ...|$|R
40|$|The aim of {{this thesis}} {{is to create a}} {{framework}} for guaranteeing real-time constraints on parallel OpenMP C++ code. The framework provides a static schedule for the allocation of tasks on <b>system</b> <b>threads</b> and a run-time support for the real-time execution. In order to do so the original source code is instrumented, profiled and rewritten by means of clang. Performance results are provided on a Computer Vision application...|$|R
5000|$|Processes: their hierarchy, PIDs, {{user and}} group authenticators (UID, GID, SID, etc.), <b>system</b> capabilities, <b>threads,</b> and running and stopped states ...|$|R
50|$|Ada has {{language}} {{support for}} task-based concurrency. The fundamental concurrent unit in Ada {{is a task}} which is a built-in limited type. Tasks are specified in two parts - the task declaration defines the task interface (similar to a type declaration), the task body specifies {{the implementation of the}} task.Depending on the implementation, Ada tasks are either mapped to operating <b>system</b> <b>threads</b> or processes, or are scheduled internally by the Ada runtime.|$|R
50|$|The {{mechanism}} {{consists of}} a central tower around which rows of seats are placed with the riders facing outward away from the tower. In {{the center of the}} tower is a large columnar pipe <b>system.</b> <b>Threaded</b> through the main pipe column is a cable that is attached to a piston on one end, looped over a pulley {{at the top of the}} tower and attached to the seat carriage on the other.|$|R
40|$|Flow Java {{integrates}} {{single assignment}} variables (logic variables) into Java. This paper presents and compares three implementation strategies for single assignment variables in Flow Java. One strategy uses forwarding and dereferencing {{while the two}} others are variants of Taylor's scheme. The paper introduces how to adapt Taylor's scheme for a concurrent language based on operating <b>system</b> <b>threads,</b> token equality, and update of data structures. Evaluation of the strategies clarifies that the key issue for e#ciency is reducing memory usage...|$|R
40|$|This paper {{describes}} initial {{results for}} an architecture called the Shared-Thread Multiprocessor (STMP). The STMP com-bines {{features of a}} multithreaded processor and a chip mul-tiprocessor; specically, it enables distinct cores on a chip multiprocessor to share thread state. This shared thread state allows the <b>system</b> to schedule <b>threads</b> from a shared pool onto individual cores, allowing for rapid movement of threads between cores. This paper demonstrates and evaluates three benets of this architecture: (1) By providing more thread state stor-age than available in the cores themselves, the architecture enjoys the ILP benets of many threads, but carries the in-core complexity of supporting just a few. (2) Threads can move between cores fast enough to hide long-latency events such as memory accesses. This enables very-short-term load balancing in response to such events. (3) The <b>system</b> can redistribute <b>threads</b> to maximize symbiotic be-havior and balance load much more often than traditional operating <b>system</b> <b>thread</b> scheduling and context switching...|$|R
30|$|HEROS adopts the component-based system {{architecture}} {{to perform the}} event-driven and/or real-time operations. It contains two main <b>system</b> components: <b>thread</b> and etask (event task).|$|R
40|$|The Java {{programming}} language and standard libraries provide a portable interface to traditional operating system services. We present {{a set of}} microbenchmarks to help evaluate the performance of these services. Building on previous work on operating system microbenchmarks, we present an -to-apples" comparison of Java and C performance of memory bandwidth, le <b>system,</b> <b>thread,</b> and network performance tests. We present experimental results for several Java runtime systems on Windows NT, which show both {{strengths and weaknesses of}} current Java implementations. ...|$|R
50|$|To prevent this, {{threading}} application programming interfaces (APIs) offer synchronization primitives such as mutexes to lock data structures against concurrent access. On uniprocessor <b>systems,</b> a <b>thread</b> {{running into}} a locked mutex must sleep and hence trigger a context switch. On multi-processor <b>systems,</b> the <b>thread</b> may instead poll the mutex in a spinlock. Both of these may sap performance and force processors in symmetric multiprocessing (SMP) systems to contend for the memory bus, {{especially if the}} granularity of the locking is fine.|$|R
5000|$|Cheat Engine Lazarus has {{the ability}} to load its {{unsigned}} 64-bit device driver on Windows Vista and later x64 bit versions of Windows, by using DBVM, a virtual machine by the same developers that allows access to kernel space from user mode. It is used to allocate nonpaged memory in kernel mode, manually loading the executable image, and creating a <b>system</b> <b>thread</b> at [...] However, since the DriverEntry parameters are not actually valid, the driver must be modified for DBVM.|$|R
40|$|Threads, or "lightweight processes," {{have become}} a common and {{necessary}} component of new languages and operating <b>systems.</b> <b>Threads</b> allow the programmer or compiler to express, create, and control parallel activities, contributing to the structure and performance of programs. In this article, we discuss the many alternatives that present themselves when designing a support <b>system</b> for <b>threads</b> on a shared-memory multiprocessor. These alternatives influence the ease, granularity, and performance of parallel programming. We conclude with a brief survey of three contemporary <b>thread</b> management <b>systems</b> (Windows NT, Presto, and Multilisp), using them to illustrate the issues raised in this article. Index Terms [...] <b>thread,</b> multiprocessor, operating <b>system,</b> parallel programming, performance 1 Introduction Disciplined concurrent programming can improve the structure and performance of computer programs on both uniprocessor and multiprocessor systems. As a result, support for threads, or "lightweig [...] ...|$|R
40|$|This paper {{describes}} {{an experiment in}} programming part of an operating system kernel using the Esterel synchronous programming language. Using a synchronous programming language allows the construction of provable, deterministic reactive systems. The paper {{describes an}}d analyzes the small executive realized and the formal verification {{of some of its}} properties. It also presents how multiple interconnected instances of this executive can be synchronized, yielding a distributed real-time platform operating under a sparse-time model. Key Words : Synchronous programming, distributed <b>systems,</b> <b>thread</b> management, real-time <b>systems,</b> deterministic system...|$|R
6000|$|An {{extraordinary}} possibility {{came rushing}} into my mind. Suddenly I saw, as in a vision, the whole solar <b>system</b> <b>threaded</b> with Cavorite liners and spheres deluxe. [...] "Rights of pre-emption," [...] came floating into my head--planetary rights of pre-emption. I recalled the old Spanish monopoly in American gold. It wasn't {{as though it}} was just this planet or that--it was all of them. I stared at Cavor's rubicund face, and suddenly my imagination was leaping and dancing. I stood up, I walked up and down; my tongue was unloosened.|$|R
5000|$|The {{load test}} concludes, [...] "The problem with Apache {{is not related}} to the Apache code per se but is due to {{the manner in which the}} {{underlying}} operating system (Linux) implements concurrency. We believe that any system implemented using operating <b>system</b> <b>threads</b> and processes would exhibit similar performance. Erlang does not make use of the underlying OS's threads and processes for managing its own process pool and thus does not suffer from these limitations".and in the underlined part above (formatting added), expresses the opinion that the founding technologies make the difference in scalability.|$|R
40|$|We {{present the}} design and {{implementation}} of Arachne, a <b>threads</b> <b>system</b> that can be interfaced with a communications library for multi-threaded distributed computations. In particular, Arachne supports thread migration between heterogeneous platforms, with dynamic stack size management and recursive thread functions. Arachne is efficient, flexible and portable [...] - it is based entirely on C and C++. To facilitate heterogeneous thread operations, we have added three keywords to the C++ language. The Arachne preprocessor takes as input code written in that language, and outputs C++ code, suitable for compilation with a conventional C++ compiler. The Arachne runtime <b>system</b> manages all <b>threads</b> during program execution. We present some performance measurements on the costs of basic thread operations and thread migration in Arachne, and compare these to costs in other <b>threads</b> <b>systems.</b> Keywords: heterogeneous <b>thread</b> migration, user-level threads, compile-time code transformations, C++ Supporte [...] ...|$|R
