7|2|Public
40|$|The {{effects of}} silica, nitrogen, and {{phosphorus}} limitation {{on the amount}} of cellular lipid, fatty acid, glucan, protein and chlorophyll of Cyclotella meneghiniana Kutz. were investigated in batch and semi-continuous culture experiments. In batch cultures, cells were removed from nutrient-replete media and resuspended in nutrient-deficient media according to a 2 (2 ̆ 73) factorial design in <b>fractional</b> <b>replication.</b> Cells were analyzed 3 and 9 days after transfer to treatment media. Of the 3 nutrients, only silica had a significant effect on a biochemical variable. Silica deficiency caused a significant increase (300...|$|E
40|$|Master of ScienceDepartment of StatisticsJames J. HigginsCompletely {{random and}} {{randomized}} block designs involving n factors {{at each of}} two levels are used to screen {{for the effects of}} a large number of factors. With such designs it may not be possible either because of costs or because of time to run each treatment combination more than once. In some cases, only a fraction of all the treatments may be run. With a large number of factors and limited observations, even one outlier can adversely affect the results. Robust regression methods are designed to down-weight the adverse affects of outliers. However, to our knowledge practitioners do not routinely apply robust regression methods in the context of <b>fractional</b> <b>replication</b> of 2 ^n factorial treatment structures. The purpose of this report is examine how robust regression methods perform in this context...|$|E
40|$|This book {{is about}} the {{statistical}} principles behind the design of effective experiments and focuses on the practical needs of applied statisticians and experimenters engaged in design, implementation and analysis. Emphasising the logical principles of statistical design, rather than mathematical calculation, the authors demonstrate how all available information {{can be used to}} extract the clearest answers to many questions. The principles are illustrated {{with a wide range of}} examples drawn from real experiments in medicine, industry, agriculture and many experimental disciplines. Numerous exercises are given to help the reader practise techniques and to appreciate the difference that good design can make to an experimental research project. Based on Roger Mead's Design of Experiments, this new edition is thoroughly revised and updated to include modern methods relevant to applications in industry, engineering and modern biology. It also contains seven new chapters on contemporary topics, including restricted randomisation and <b>fractional</b> <b>replication...</b>|$|E
40|$|Classical {{fractional}} factorial designs yield biased {{estimates of}} a set of parameters when aliased parameters are nonzero. In the early 1960 s Ehrenfeld and Zacks constructed Randomization Procedures I and II to remove this bias from estimation of a subset of parameters of a full factorial experiment. The subset of parameters to be estimated using either of these randomization procedures must have a certain group structure and the sample size must be a multiple of the group size. In this paper, we discuss the nonorthogonal estimator which removes these restrictions while producing unbiased estimates {{in the case of a}} two-level experiment. Examples are provided. <b>Fractional</b> <b>replications</b> Unbiased estimators Randomized estimators...|$|R
40|$|It is {{demonstrated}} how to select error mean squares for setting confidence intervals and testing for significance for various effects. Often a complete or <b>fractional</b> factorial without <b>replication</b> is used. Often some {{function of the}} factors such as orthogonal polynomials {{can be used to}} explain most or all of the variation in the factor effects. In other situations, the complexity of the experimental design dictates that different error mean squares are needed for different factors in the experiment. Two such cases are a split-block experiment design and a repeated measures experiment design. Example 1 could be considered as a split-block designed experiment within runs and units or as a repeated measures experiment design. Example 2 is a non-replicated three-factor factorial treatment design with one combination missing. This makes the treatment design a fractional factorial. The data obtained from conducting the experiment are also presented. Analyses of variance partitioning of degrees of freedom are given for both examples. A SAS/GLM code and output from the program are given for Example 1 and for Example 2...|$|R
40|$|A {{one-stop}} {{reference to}} fractional factorials and related orthogonal arrays. Presenting {{one of the}} most dynamic areas of statistical research, this book offers a systematic, rigorous, and up-to-date treatment of fractional factorial designs and related combinatorial mathematics. Leading statisticians Aloke Dey and Rahul Mukerjee consolidate vast amounts of material from the professional literature [...] expertly weaving <b>fractional</b> <b>replication,</b> orthogonal arrays, and optimality aspects. They develop the basic theory of fractional factorials using the calculus of factorial arrangements, thereby providing a unified approach to the study of fractional factorial plans. An indispensable guide for statisticians in research and industry as well as for graduate students, Fractional Factorial Plans features: * Construction procedures of symmetric and asymmetric orthogonal arrays. * Many up-to-date research results on nonexistence. * A chapter on optimal fractional factorials not based on orthogonal arrays. * Trend-free plans, minimum aberration plans, and search and supersaturated designs. * Numerous examples and extensive references...|$|E
40|$|Saving {{energy for}} storage is of major {{importance}} as storage devices (and cooling them off) may contribute over 25 {{percent of the}} total energy consumed in a datacenter. Recent work introduced the concept of energy proportionality and argued that it is a more relevant metric than just energy saving as it takes into account the tradeoff between energy consumption and performance. In this paper, we present a novel approach, called FREP (<b>Fractional</b> <b>Replication</b> for Energy Proportionality), for energy management in large datacenters. FREP includes a replication strategy and basic functions to enable flexible energy management. Specifically, our method provides performance guarantees by adaptively controlling the power states of a group of disks based on observed and predicted workloads. Our experiments, using a set of real and synthetic traces, show that FREP dramatically reduces energy requirements with a minimal response time penalty. Categories andSubject Descriptors C. 4 [Performance of Systems]: Reliability, availability, and serviceabilit...|$|E
30|$|Kim et al. (2012) {{presented}} a novel approach, called FREP (<b>Fractional</b> <b>Replication</b> for Energy Proportionality), for energy management in big data. FREP includes a replication strategy and basic functions to enable flexible energy management {{according to the}} cloud needs, including load distribution and update consistency. However, {{the impact of the}} replication on the over storage cost of the system has not presented. Kaushik and Bhandarkar (2010) proposed an energy conserving hybrid multi zone variant of HDFS for intensive data processing, commodity Hadoop clusters. This variant has considerably improved energy efficiency up to 26  % in 3  months as a simulation run. This technique has cut the power budget to $ 14.6 million dollars. Different types of cloud infrastructures including traditional cloud and high performance computing (HPC), need to be enhanced to support dynamic power demands (i.e., adjust powers automatically), which in turn creates new challenges in designing architecture, infrastructure, and communications which are energy efficient and power aware resources. This concept was given by Bruschi et al. in (2011).|$|E
40|$|Energy saving {{has become}} a crucial concern in datacenters as several reports predict that the {{anticipated}} energy costs over a three year period will exceed hardware acquisition. In particular, saving energy for storage is of major importance as storage devices (and cooling them off) may contribute over 25 {{percent of the total}} energy consumed in a datacenter. Recent work introduced the concept of energy proportionality and argued that it is a more relevant metric than just energy saving as it takes into account the tradeoff between energy consumption and performance. In this paper, we present a novel approach, called FREP (<b>Fractional</b> <b>Replication</b> for Energy Proportionality), for energy management in large datacenters. FREP includes a replication strategy and basic functions to enable flexible energy management. Specifically, our method provides performance guarantees by adaptively controlling the power states of a group of disks based on observed and predicted workloads. Our experiments, using a set of real and synthetic traces, show that FREP dramatically reduces energy requirements with a minimal response time penalty...|$|E

