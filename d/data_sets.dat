10000|10000|Public
5|$|Multiple <b>data</b> <b>sets</b> may be {{necessary}} for certain phasing methods. For example, MAD phasing requires that the scattering be recorded at least three (and usually four, for redundancy) wavelengths of the incoming X-ray radiation. A single crystal may degrade too much during the collection of one data set, owing to radiation damage; in such cases, <b>data</b> <b>sets</b> on multiple crystals must be taken.|$|E
5|$|The precise {{relationships}} between pterosaurs is still unsettled. Many studies of pterosaur {{relationships in the}} past have included limited data and were highly contradictory. However, newer studies using larger <b>data</b> <b>sets</b> are beginning to make things clearer. The cladogram (family tree) below follows a phylogenetic analysis presented by Andres & Myers in 2013.|$|E
5|$|Ground {{temperature}} measurements, {{like most}} weather observations, are logged by location. Their siting predates the massive sprawl, roadbuilding programs, and high- and medium-rise expansions which {{contribute to the}} UHI. More importantly, station logs allow sites in question to be filtered easily from <b>data</b> <b>sets.</b> Doing so, the presence of heat islands is visible, but overall trends change in magnitude, not direction.|$|E
30|$|<b>Data</b> <b>set</b> feature {{processing}} scheme includes feature collection, feature {{conversion and}} reservation. The filter feature of <b>data</b> <b>set</b> would be pre-fetched. The classification characteristics of <b>data</b> <b>set</b> {{could be obtained}} based on the classification accuracy of <b>data</b> <b>set.</b> According to {{the characteristics of the}} <b>data</b> <b>set,</b> the crowd filter would select the appropriate crowd incentive strategy. Based on the complexity characteristics of the <b>data</b> <b>set</b> classification, the transformation of the subset of the <b>data</b> <b>set</b> would be completed.|$|R
3000|$|... (a) to {{represent}} target <b>data</b> <b>set</b> and auxiliary <b>data</b> <b>set,</b> respectively. Denote the feature matrix of target <b>data</b> <b>set</b> as X^(t)∈R^k× n^(t), the feature matrix of spectral information of auxiliary <b>data</b> <b>set</b> as X^(a)∈R^k× n^(a), and the texture feature information matrix in auxiliary <b>data</b> <b>set</b> as T^(a)∈R^m× n^(a). For target <b>data</b> <b>set,</b> {{we assume that}} each sample corresponds to particular auxiliary information. We use S [...]...|$|R
30|$|The {{experiments}} adopts {{the classic}} <b>data</b> <b>set</b> DataSet 1 provided by KDD Cup’ 99 {{to test the}} correctness of the proposed parallel spectral clustering algorithm; we use respectively 10000 (<b>Data</b> <b>Set</b> DS 1), 50000 (<b>Data</b> <b>Set</b> DS 2), 100000 (<b>Data</b> <b>Set</b> DS 3), 1000000 (<b>Data</b> <b>Set</b> DS 4), 5000000 (<b>Data</b> <b>Set</b> DS 5) to verify {{the superiority of the}} proposed parallel algorithm, and data samples is the multidimensional data listed in literature [20, 21].|$|R
5|$|The PROC step {{consists}} of PROC statements that call upon named procedures. Procedures perform analysis and reporting on <b>data</b> <b>sets</b> to produce statistics, analyses, and graphics. There {{are more than}} 300 procedures and each one contains a substantial body of programming and statistical work. PROC statements can also display results, sort data or perform other operations.|$|E
25|$|Special {{considerations}} for very extensive <b>data</b> <b>sets.</b>|$|E
25|$|A variant named binary {{merge sort}} uses a binary {{insertion}} sort to sort groups of 32 elements, {{followed by a}} final sort using merge sort. It combines the speed of insertion sort on small <b>data</b> <b>sets</b> {{with the speed of}} merge sort on large <b>data</b> <b>sets.</b>|$|E
40|$|The <b>data</b> <b>set</b> {{specifications}} for the NASA Aerospace Safety Information System (NASIS) are presented. The <b>data</b> <b>set</b> specifications describe the content, format, and medium of communication of every <b>data</b> <b>set</b> {{required by the}} system. All relevant information pertinent to a particular <b>data</b> <b>set</b> is prepared in a standard form and centralized in a single document. The format for the <b>data</b> <b>set</b> is provided...|$|R
30|$|Hypotheses {{related to}} {{operating}} core (innovation process, cross-functional organisation, {{and implementation of}} tools/technology) and competition-informed pricing The result of H 4 is supported in the full <b>data</b> <b>set</b> (β =  0.170, p <  0.05) and the Malaysian <b>data</b> <b>set</b> (β =  0.255, p <  0.05), while in the Bangladeshi data it was not supported. The result of H 5 was supported in the full <b>data</b> <b>set</b> (β =  0.266, p <  0.05) and the Bangladeshi <b>data</b> <b>set</b> (β =  0.275, p <  0.05), while in the Malaysian <b>data</b> <b>set</b> it was not supported. The result of H 6 was supported in the full <b>data</b> <b>set</b> (β =  0.295, p <  0.01) and the Bangladeshi <b>data</b> <b>set</b> (β =  0.536, p <  0.01), while in the Malaysian <b>data</b> <b>set,</b> H 6 was not supported.|$|R
40|$|The method {{involves}} manufacturing {{an object}} (1) {{based on the}} binary <b>data</b> <b>set</b> referred to as target <b>data</b> <b>set</b> by the generative manufacturing method. The actual space form of a partial region of the object is detected and the binary <b>data</b> <b>set</b> describing the actual space form of the partial region of the object is generated. The geometric deviation between the space form of the partial region of the object, which {{is provided by the}} target <b>data</b> <b>set</b> and the space form of the partial region of the object, at which the actual <b>data</b> <b>set</b> is generated, is determined. The binary <b>data</b> <b>set</b> provides the space form of the object. The target <b>data</b> <b>set</b> is changed {{on the basis of a}} correcting function, which is derived from the geometric deviations, for obtaining a binary correction <b>data</b> <b>set.</b> The object is generated based on the binary binary correction <b>data</b> <b>set</b> using the generative manufacturing process...|$|R
25|$|It is {{very compact}} for low {{dimension}} <b>data</b> <b>sets.</b>|$|E
25|$|It was {{eventually}} replaced by ICD-10, the version currently in {{use by the}} WHO and most countries. Given the widespread expansion in the tenth revision, {{it is not possible}} to convert ICD-9 <b>data</b> <b>sets</b> directly into ICD-10 <b>data</b> <b>sets,</b> although some tools are available to help guide users.|$|E
25|$|Ideal GPGPU {{applications}} {{have large}} <b>data</b> <b>sets,</b> high parallelism, and minimal dependency between data elements.|$|E
5000|$|Creating {{partitioned}} output <b>data</b> <b>set</b> from sequential input <b>data</b> <b>set.</b>|$|R
50|$|In statistics, econometrics, {{and related}} fields, multidimensional {{analysis}} is a data analysis process that groups data into two categories: data dimensions and measurements. For example, a <b>data</b> <b>set</b> {{consisting of the}} number of wins for a single football team at each of several years is a single-dimensional (in this case, longitudinal) <b>data</b> <b>set.</b> A <b>data</b> <b>set</b> consisting {{of the number of}} wins for several football teams in a single year is also a single-dimensional (in this case, cross-sectional) <b>data</b> <b>set.</b> A <b>data</b> <b>set</b> consisting of the number of wins for several football teams over several years is a two-dimensional <b>data</b> <b>set.</b>|$|R
5000|$|A {{simplified}} {{example of}} this process is shown below where <b>data</b> <b>set</b> [...] "α" [...] is fused with <b>data</b> <b>set</b> β to form the fused <b>data</b> <b>set</b> δ. <b>Data</b> points in <b>set</b> [...] "α" [...] have spatial coordinates X and Y and attributes A1 and A2. <b>Data</b> points in <b>set</b> β have spatial coordinates X and Y and attributes B1 and B2. The fused <b>data</b> <b>set</b> contains all points and attributes ...|$|R
25|$|FlowRepository {{facilitates}} MIFlowCyt compliance, {{and as of}} July 2013 contained 65 public <b>data</b> <b>sets.</b>|$|E
25|$|Consequently, some later {{studies using}} average {{national}} IQ data have checked their results against both <b>data</b> <b>sets.</b>|$|E
25|$|Researchers {{attempting}} to understand relative species abundance patterns usually approach {{them in a}} descriptive or mechanistic way. Using a descriptive approach biologists attempt to fit a mathematical model to real <b>data</b> <b>sets</b> and infer the underlying biological principles at work from the model parameters. By contrast, mechanistic approaches create a mathematical model based on biological principles and then test how well these models fit real <b>data</b> <b>sets.</b>|$|E
30|$|The {{complete}} 20  cm cylinder <b>data</b> <b>set</b> {{consisted of}} 55 scans, 4 {{of which are}} with the TEM material. The complete liter bottle <b>data</b> <b>set</b> contained 17 scans, of which 14 are 1 -L bottle scans, 2 are 2 -L bottle scans, and 1 is a 4 -L bottle scan. The mean conversion factors for the full <b>data</b> <b>set,</b> cylinder <b>data</b> <b>set,</b> and the liter <b>data</b> <b>set</b> only vary by approximately 2 to 3  %, indicating stability.|$|R
30|$|LiverDisorder: This <b>data</b> <b>set</b> {{corresponds}} to liver disorder data. There are total 345 instances in the <b>data</b> <b>set.</b> Each instance is having 6 features. There are two output classes for this <b>data</b> <b>set.</b>|$|R
40|$|A {{method of}} validating a {{probability}} of detection (POD) testing system using directed design of experiments (DOE) includes recording an input <b>data</b> <b>set</b> of observed hit and miss or analog data for sample components {{as a function of}} size of a flaw in the components. The method also includes processing the input <b>data</b> <b>set</b> to generate an output <b>data</b> <b>set</b> having an optimal class width, assigning a case number to the output <b>data</b> <b>set,</b> and generating validation instructions based on the assigned case number. An apparatus includes a host machine for receiving the input <b>data</b> <b>set</b> from the testing system and an algorithm for executing DOE to validate the test system. The algorithm applies DOE to the input <b>data</b> <b>set</b> to determine a <b>data</b> <b>set</b> having an optimal class width, assigns a case number to that <b>data</b> <b>set,</b> and generates validation instructions based on the case number...|$|R
25|$|The ONS {{announced}} in March the release {{plan for the}} results of the 2011 census which stated in July 2012. NISRA made a similar announcement with identical release plan. In June 2012 GROS advised on its release plan which commences in December 2012. The releases will comprise <b>data</b> <b>sets</b> enabling the standard comparison with previous census data reports as well as over a hundred new <b>data</b> <b>sets</b> based on the new questions asked in the 2011 census.|$|E
25|$|The current {{motion of}} the tectonic plates is today {{determined}} by remote sensing satellite <b>data</b> <b>sets,</b> calibrated with ground station measurements.|$|E
25|$|There is {{speculation}} {{of introducing}} objects without identity (value types), {{as well as}} moving towards 64-bit addressable arrays to support large <b>data</b> <b>sets.</b>|$|E
40|$|Medicare Encounter data is {{received}} by each state’s Peer Review Organization as an Oracle database {{known as the}} SDPS (Standard Data Processing System) <b>data</b> <b>set.</b> This <b>data</b> <b>set</b> is used for quality improvement projects, integrity investigations, and research. This <b>data</b> <b>set</b> is then queried with SAS software and the SAS SQL pass-through facility. Often the criteria for selecting data from the SDPS <b>data</b> <b>set</b> are contained in a preextracted SAS <b>data</b> <b>set.</b> Using the criterion information from the SAS <b>data</b> <b>set,</b> additional <b>data</b> is extracted from the SDPS database and merged or combined with the existing SAS <b>data</b> <b>set</b> or its information. In this example used to document comorbidities and disease progression for HIV, a SAS <b>data</b> <b>set</b> is run against the SDPS Oracle database to obtain subsequent admissions and diagnoses for each patient (Medicare beneficiary). This paper illustrates four methods for performing this query using SAS/ACCESS, SAS/CONNECT®, and Proc SQL...|$|R
5000|$|Contains {{an array}} of 24 byte big <b>data</b> <b>set,</b> one for each used tag. The <b>data</b> <b>set</b> {{contains}} the tag {{and the number of}} points with that tag. Each <b>data</b> <b>set</b> is structured as follows: ...|$|R
5000|$|Iris flower <b>data</b> <b>set</b> - Multivariate <b>data</b> <b>set</b> {{introduced}} by Ronald Fisher (1936).|$|R
25|$|Another {{consideration}} in the configuration of a projection is its compatibility with <b>data</b> <b>sets</b> to be used on the map. <b>Data</b> <b>sets</b> are geographic information; their collection depends on the chosen datum (model) of the Earth. Different datums assign slightly different coordinates to the same location, so in large scale maps, such as those from national mapping systems, {{it is important to}} match the datum to the projection. The slight differences in coordinate assignation between different datums is not a concern for world maps or other vast territories, where such differences get shrunk to imperceptibility.|$|E
25|$|Biomechanics was a field barely in its infancy. It was {{therefore}} necessary to employ {{two types of}} test subjects {{in order to develop}} initial <b>data</b> <b>sets.</b>|$|E
25|$|It is {{not known}} how Anscombe created his datasets. Since its publication, several methods to {{generate}} similar <b>data</b> <b>sets</b> with identical statistics and dissimilar graphics have been developed.|$|E
40|$|Files {{in support}} of Denton [2017 or 2018, Electromagnetic ion {{cyclotron}} wave fields in a realistic dipole field, to be submitted to JGR Space Physics]: This file: README. txt Paper: EMIC_waveFields. pdf Supplementary information file describing the data sets: EMIC_waveFieldsSupplementaryInformation. pdf <b>Data</b> <b>set</b> 1 : DentonEmic 17 _ds 01. zip (DentonEmic 17 _ds 01. csv zipped) <b>Data</b> <b>set</b> 2 : DentonEmic 17 _ds 02. csv <b>Data</b> <b>set</b> 3 : DentonEmic 17 _ds 03. zip (DentonEmic 17 _ds 03. csv zipped) Matlab program testing <b>data</b> <b>set</b> 1 : testDs 01. m Matlab program testing <b>data</b> <b>set</b> 2 : testDs 02. m Matlab program testing <b>data</b> <b>set</b> 3 : testDs 03. ...|$|R
40|$|The data {{presented}} show the typical values {{and range of}} ionospheric and magnetospheric characteristics, as viewed from 1400 km with the ISIS 2 instruments. The definition of each <b>data</b> <b>set</b> depends partly on geophysical parameters and partly on satellite operating mode. Preceding the <b>data</b> <b>set</b> is {{a description of the}} organizational parameters and a review of the objectives and general characteristics of the <b>data</b> <b>set.</b> The <b>data</b> are shown as a selection from 12 different data formats. Each <b>data</b> <b>set</b> has a different selection of formats, but uniformity of a given format selection is preserved throughout each <b>data</b> <b>set.</b> Each <b>data</b> <b>set</b> consists of a selected number of passes, each comprising a format combination that is most appropriae for the particular <b>data</b> <b>set.</b> Description of ISIS 2 instruments are provided...|$|R
40|$|This paper {{illustrates}} {{the use of}} a real-time <b>data</b> <b>set</b> for forecasting. The <b>data</b> <b>set</b> consists of vintages, or snapshots, of the major macroeconomic data available at quarterly intervals in real time. The paper explains the construction of the <b>data</b> <b>set,</b> examines the properties of several of the variables in the <b>data</b> <b>set</b> across vintages, and shows how forecasts can be affected by data revisions. Forecasting...|$|R
