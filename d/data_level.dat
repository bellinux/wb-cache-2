564|10000|Public
5|$|A level-number of 66 is used {{to declare}} a re-grouping of {{previously}} defined items, irrespective of how those items are structured. This <b>data</b> <b>level,</b> also referred to by the associated , is rarely used and, circa 1988, was usually found in old programs. Its ability to ignore the hierarchical and logical structure data meant its use was not recommended and many installations forbade its use.|$|E
25|$|A {{data loss}} {{prevention}} software platform, Digital Guardian integrates content, context and location awareness along with encryption and <b>data</b> <b>level</b> controls {{to reduce the}} risk of information loss or misuse, and purposeful data theft. Its host-based security technology empowers organizations to monitor, control, audit and prevent data from wrongful disclosure or malicious theft, while automatically enforcing data security policies and procedures. This scalable platform provides multiple, independent layers of protection to enable secure data sharing across physical, virtual, mobile and cloud environments.|$|E
5000|$|... <b>data</b> <b>level</b> (individual {{columns and}} {{attributes}} of data stores) ...|$|E
50|$|The {{warehouse}} {{data service}} {{is responsible for}} the storage of package <b>level</b> <b>data</b> and distribution <b>level</b> <b>data.</b>|$|R
40|$|Large-scale session log {{analysis}} typically includes {{statistical methods}} and detailed log examinations. While both methods have merits, statistical methods can miss previously unknown subpopulations {{in the data}} and detailed analyses may have selection biases. We therefore built Session Viewer, a visualization tool to facilitate and bridge between statistical and detailed analyses. Taking a multiple-coordinated view approach, Session Viewer shows multiple session populations at the Aggregate, Multiple, and Detail <b>data</b> <b>levels</b> to support different analysis styles. To bridge between the statistical and the detailed analysis levels, Session Viewer provides fluid traversal between <b>data</b> <b>levels</b> and side-by-side comparison at all <b>data</b> <b>levels.</b> We describe an analysis of a large-scale web usage study to demonstrate the use of Session Viewer, where we quantified the importance of grouping sessions based on task type...|$|R
40|$|In this paper, {{we present}} high {{resolution}} time-lapse resistivity tomography study for slope monitoring using two optimized resistivity arrays of Wenner-Schlumberger and pole-dipole. These optimized resistivity arrays of Wenner-Schlumberger and pole-dipole give total of 2038 datum points for each data set. This slope monitoring {{study was conducted}} at Minden, Penang Island, Malaysia. Inversion results from computer suggested that optimized Wenner-Schlumberger and pole-dipole arrays would be equally effective but the merge <b>data</b> <b>levels</b> technique for both arrays would able to provide high resolution at imaging slope area. Our in-field data {{results showed that the}} two arrays imaged the subsurface for slope monitoring equally well. When in-field <b>data</b> <b>levels</b> from these two different arrays were merged and analyzed using 2 -D inversion, however, the merging <b>data</b> <b>levels</b> using two different arrays was able to resolve the subsurface characterizations. Because the merging <b>data</b> <b>levels</b> using two different arrays requires roughly two times as measurement per line, we conclude that this technique is preferable for environmental geophysics than single array only when the high improvement in resolution at sensitivity, horizontal coverage, signal strength and investigation depth is more important than rapid data acquisition. The overall results using these two different arrays were quite compromising and remarkably significant for good improvement in data quality and data acquisition technique...|$|R
50|$|Level 1 - Part Submission Warrant (PSW) only {{submitted}} to the customer. Level 2 - PSW with product samples and limited supporting <b>data.</b> <b>Level</b> 3 - PSW with product samples and complete supporting <b>data.</b> <b>Level</b> 4 - PSW and other requirements {{as defined by the}} customer. Level 5 - PSW with product samples and complete supporting data available for review at the supplier's manufacturing location.|$|E
5000|$|In telecommunication, {{standard}} telegraph level (STL) is {{the power}} per individual telegraph channel required to yield the standard composite <b>data</b> <b>level.</b>|$|E
50|$|The initial idea {{of works}} on MDI, was the {{application}} of model-driven methods and techniques for solving interoperability problems from business level down to <b>data</b> <b>level.</b>|$|E
30|$|The {{huge amount}} of data that is {{obtained}} at the most varied <b>data</b> <b>levels</b> during the course of participatory (futures) research projects constitutes a fundamental problem of this research approach.|$|R
5000|$|... #Caption: Ethnic Poles {{share in}} Belarus (2009 census), {{district}} <b>level</b> <b>data,</b> district <b>level</b> cities and Minsk were depicted with circles.|$|R
5000|$|... #Caption: Ethnic Poles {{distribution}} in Belarus (2009 census), district <b>level</b> <b>data,</b> district <b>level</b> cities and Minsk values were summed {{with the surrounding}} districts.|$|R
5000|$|Semantic {{heterogeneities}} {{arise when}} there is a disagreement about meaning, interpretation or intended use of data. At the schema and <b>data</b> <b>level,</b> classification of possible heterogeneities include: ...|$|E
50|$|While these {{processing}} {{levels are}} particularly suitable for typical satellite data processing pipelines, other <b>data</b> <b>level</b> vocabularies have been defined {{and may be}} appropriate for more heterogeneous workflows.|$|E
5000|$|For example, for a {{composite}} <b>data</b> <b>level</b> of -13 dBm at 0-dBm {{transmission level point}} (0TLP), the STL would be approximately -25 dBm for a 16-channel VFCT terminal computed from STL = - (13+10log10 n [...] ), where n {{is the number of}} telegraph channels and the STL is in dBm.|$|E
40|$|We {{are pleased}} that Dunning et al. (2006) have {{provided}} macro (country) <b>level</b> <b>data</b> demonstrating the increased internationalization of many nations {{over the past}} decade. We also appreciate their findings lending support to our perspective on the regional nature of world business. Our work was based solely on micro (firm) <b>level</b> <b>data,</b> see Rugman and Verbeke (2004 a). Both country <b>level</b> <b>data</b> and firm <b>level</b> <b>data</b> have methodological problems which we attempt to reconcile in this comment. We also address the broader conceptual issues of how to interpret country level versus firm <b>level</b> <b>data.</b> Regional strategy, home region bound firm-specific advantages, liability of regional foreignness, methodology...|$|R
50|$|This report {{discusses}} the myths surrounding American education. Topics include presentation of real <b>data,</b> <b>levels</b> of performance on academic indicators as actually reflecting demographic factors, job prospects, {{and the role}} of media in the perception of education.|$|R
50|$|The {{results are}} {{displayed}} {{with a high}} resolution of 1 km x 1 Â° x 230 km grid with 256 <b>data</b> <b>levels.</b> There is an automatic extraction of the storm motion which is integrated in the algorithms for corrections.|$|R
50|$|The OSLC {{specifications}} {{build on}} the W3C Resource Description Framework (RDF), Linked Data and REST, enabling integration at <b>data</b> <b>level</b> via links between related resources. OSLC resources are {{defined in terms of}} RDF properties. Operations on resources are performed using HTTP. OSLC also specifies user interface techniques to enable preview, creation and selection of links.|$|E
5000|$|Following {{the success}} of the Legal OnRamp {{collaboration}} platform, OnRamp Systems launched a number of private, enterprise-scale, collaboration platform projects. The OnRamp Exchange (ORX) system allows attorneys to collaborate with large teams as well as store and manage documents. [...] The focus of these projects is on managing legal complexity at the systems and <b>data</b> <b>level,</b> instead of relying on complex reasoning.|$|E
50|$|A level-number of 66 is used {{to declare}} a re-grouping of {{previously}} defined items, irrespective of how those items are structured. This <b>data</b> <b>level,</b> also referred to by the associated , is rarely used and, circa 1988, was usually found in old programs. Its ability to ignore the hierarchical and logical structure data meant its use was not recommended and many installations forbade its use.|$|E
40|$|Michael Snow, Historian, U. S. Census BureauSince {{the late}} nineteenth century, the U. S. Census Bureau has met the growing demand for new types of small area data. Beginning with the 1890 Census, {{a history of the}} Census Bureau's small area <b>data,</b> tract <b>level</b> <b>data,</b> block group and block <b>level</b> <b>data,</b> and more...|$|R
30|$|TBI has {{the scope}} {{to use all}} these <b>data</b> <b>levels</b> {{with the goal of}} {{answering}} clinical questions, but this objective could benefit from not just attempting to answer clinical questions but questions on all levels. Perhaps future research in TBI and Health Informatics overall could focus on using <b>data</b> from all <b>levels</b> in order to find correlations and connections between them, possibly giving physicians more ways of diagnosing, treating, and helping their patients. All future work in Health Informatics should have a translational approach of using <b>data</b> from all <b>levels</b> of human existence.|$|R
40|$|Power {{consumption}} {{imposes a}} significant cost for data centers. Thus, {{it is not}} surprising that optimizing energy cost in data center is receiving increasing attention. In this thesis, we focus on the algorithmic issues at three levels of energy optimization for <b>data</b> centers: server <b>level,</b> local <b>data</b> center <b>level</b> and global <b>data</b> center <b>level.</b> At the server level, we analyze the common speed scaling algorithms in both worst-case model and stochastic model to answer some fundamental issues in the design of speed scaling algorithms. At the local <b>data</b> center <b>level,</b> we develop an online algorithm to make data center more power-proportional by dynamically adapting the number of active servers to match the current workload. At the global <b>data</b> center <b>level,</b> we propose a framework to explore the diversity of power prices and the diversity of propagation delays given geographically distributed data centers...|$|R
50|$|The {{development}} of IDEF4 {{came from the}} recognition that the modularity, maintainability and code reusability that results from the object-oriented programming paradigm can be realized in traditional data processing applications. The proven ability of the object-oriented programming paradigm to support <b>data</b> <b>level</b> integration in large complex distributed systems is also {{a major factor in}} the widespread interest in this technology from the traditional data processing community.|$|E
5000|$|The query {{execution}} architecture {{makes use}} of [...] "Vectorized Query Execution" [...] processing in chunks of cache-fitting vectors of data. This allows to involve the principles of vector processing and single instruction, multiple data (SIMD) to perform the same operation on multiple data simultaneously and exploit <b>data</b> <b>level</b> parallelism on modern hardware. It also reduces overheads found in traditional [...] "row-at-a-time processing" [...] found in most RDBMSes.|$|E
5000|$|In his {{formulation}} of the hierarchy, Henry defined information as [...] "data that changes us", this being a functional, rather than structural, distinction between data and information. Meanwhile, Cleveland, who did not refer to a <b>data</b> <b>level</b> in his version of DIKW, described information as [...] "the sum total of all the facts and ideas {{that are available to}} be known by somebody at a given moment in time".|$|E
3000|$|... 1 Individual <b>level</b> <b>data</b> {{generally}} allow detecting worker flows, while firm <b>level</b> <b>data</b> allow detecting job flows.|$|R
50|$|Files {{created with}} only one level are, by default, {{dictionary}} files. Some versions of the Pick system allow multiple <b>data</b> <b>levels</b> {{to be linked to}} one dictionary level file, in which case there would be multiple data-level identifiers in the dictionary file.|$|R
40|$|The {{effects of}} {{horizontal}} and vertical data resolution, data density, data location, different objective analysis algorithms, and measurement error on mesoscale-forecast accuracy are studied with observing-system simulation experiments. Domain-averaged errors are shown to generally decrease with time. It is found that the vertical distribution of error growth depends on the initial vertical distribution of the error itself. Larger gravity-inertia wave noise is produced in forecasts with coarser vertical data resolution. The use of a low vertical resolution observing system with three <b>data</b> <b>levels</b> leads to more forecast errors than moderate and high vertical resolution observing systems with 8 and 14 <b>data</b> <b>levels.</b> Also, with poor vertical resolution in soundings, the initial and forecast errors are not affected by the horizontal data resolution...|$|R
50|$|A {{data loss}} {{prevention}} software platform, Digital Guardian integrates content, context and location awareness along with encryption and <b>data</b> <b>level</b> controls {{to reduce the}} risk of information loss or misuse, and purposeful data theft. Its host-based security technology empowers organizations to monitor, control, audit and prevent data from wrongful disclosure or malicious theft, while automatically enforcing data security policies and procedures. This scalable platform provides multiple, independent layers of protection to enable secure data sharing across physical, virtual, mobile and cloud environments.|$|E
50|$|The {{business}} logic supported full cross-dimensional calculations, automatic ordering of rules using static data-flow analysis, and {{the identification and}} solution of simultaneous equations. The rules treated all dimensions in an orthogonal fashion. The aggregation process did not distinguish between simple summation or average calculations, and more complex non-commutative calculations. Both {{could be applied to}} any dimension member. The process allowed aggregation levels (i.e. those calculation levels starting with base <b>data</b> (<b>level</b> 0) and proceeding up to the overall grand total) to be individually pre-stored or left to be calculated on demand.|$|E
50|$|Single instruction, {{multiple}} data (SIMD), is a {{class of}} parallel computers in Flynn's taxonomy. It describes computers with multiple processing elements that perform the same operation on multiple data points simultaneously. Thus, such machines exploit <b>data</b> <b>level</b> parallelism, but not concurrency: there are simultaneous (parallel) computations, but only a single process (instruction) at a given moment. SIMD is particularly applicable to common tasks like adjusting the contrast in a digital image or adjusting the volume of digital audio. Most modern CPU designs include SIMD instructions {{in order to improve}} the performance of multimedia use.|$|E
5000|$|... {{discovering}} discrepancies, gaps, lineage, metrics at <b>data</b> structure <b>level.</b>|$|R
5000|$|Defining <b>data</b> as <b>levels,</b> {{with group}} items and {{elementary}} items.|$|R
5000|$|Digital Feature Analysis <b>Data</b> (DFAD) <b>Level</b> - 1 for Aircraft Simulations ...|$|R
