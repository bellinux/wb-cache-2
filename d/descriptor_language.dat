17|45|Public
50|$|SmartList {{is written}} in Bash and Multigram's own <b>descriptor</b> <b>language.</b> Multigram is SmartList's {{proprietary}} DWIM (Do What I Mean) parser, and it {{is written in}} C like Procmail.|$|E
50|$|IDL (Interface Description Language) is a {{software}} interface description language (also {{referred to as}} Interface <b>Descriptor</b> <b>Language)</b> created by William Wulf and John Nestor of Carnegie Mellon University and David Lamb of Queens University, Canada.|$|E
50|$|Facets {{correspond}} to {{properties of the}} information elements. They are often derived by analysis of the text of an item using entity extraction techniques or from pre-existing fields in a database such as author, <b>descriptor,</b> <b>language,</b> and format. Thus, existing web-pages, product descriptions or online collections of articles can be augmented with navigational facets.|$|E
40|$|Keywords {{still seem}} to {{form the basis for}} {{document}} content and query representation. Approaches to use more advanced linguistic structures, such as noun phrases, still are in an experimental phase. In addition, Boolean <b>descriptor</b> <b>languages</b> have often been applied for Information Retrieval. However, th...|$|R
50|$|Security <b>Descriptor</b> Definition <b>Language</b> (SDDL) {{defines the}} string format {{that is used}} to {{describe}} a security descriptor as a text string.|$|R
50|$|YAML {{itself does}} not have XML's language-defined {{document}} schema descriptors that allow, for example, a document to self-validate. However, there are several externally defined schema <b>descriptor</b> <b>languages</b> for YAML (e.g. Doctrine, Kwalify and Rx) that fulfill that role. Moreover, the semantics provided by YAML's language-defined type declarations in the YAML document itself frequently relaxes {{the need for a}} validator in simple, common situations. Additionally, YAXML, which represents YAML data structures in XML, allows XML schema importers and output mechanisms like XSLT to be applied to YAML.|$|R
40|$|The eectiveness and eciency of {{searches}} for relevant documents strongly depend on key {{features of the}} <b>descriptor</b> <b>language</b> supported by the retrieval system. Eectiveness, for instance, {{is limited by the}} expressiveness of the descriptors. In addition, system eciency is proportional to tractability. Furthermore, user eort is relative to comprehensibility and compactness. From a formulation point of view, compactness allows a high degree of integration, combining several occurrences of an analogous concept in a single expression. A proper <b>descriptor</b> <b>language</b> for information discovery should thus nd a workable balance between these features. Boolean index expressions (BIEs) are proposed as balanced descriptors for the communication of information needs. Compared to many other descriptor languages, an advantage of BIEs is their compactness, oering the opportunity to convey much information in a succinct way. The goal {{of this article is to}} investigate compactness of BIEs. For i [...] ...|$|E
40|$|Thesauri {{have been}} used in the library and {{information}} science field to provide a standard <b>descriptor</b> <b>Language</b> for indexers or searchers to use in an information storage and retrieval system. One difficulty has been the maintenance and updating of thesauri considering that terms used to describe concepts in books and papers change over time and vary between users. This study investigated a mechanism by which thesauri can be updated and maintained using citation, co-citation analysis and citation context analysis. It has been demonstrated that citation analysis reflects concepts in a specialty, and reflects term use in a specialty, following the work of Henry Small. This technique of citation context analysis may be used to trace term change in a specialty over time and variation among researchers [...] the basic pieces of information needed in thesaurus development.;Data bases in sociology and economics were developed using the Social Sciences Citation Indexes, 1966 - 67, 1973 - 74 and 1980 - 81. Twenty-six highly cited and co-cited papers common to these three time periods were then used. Seventy-eight terminology lists were developed from the citation contexts of other papers citing these papers. Two experts in each discipline were asked to group and comment on the lists. The <b>descriptor</b> <b>language</b> produced was compared with a standard <b>descriptor</b> <b>language,</b> i. e., the Library of Congress Subject Headings.;Overall, the experts were able to correctly group and identify these terminology lists and thus were able to identify variation between specialty area terminology. The experts judged a high level of the terms appropriate, i. e., 93. 7 percent in economics and 98. 7 percent in sociology. The experts were not able to identify any change over time. The comparison with the Library of Congress Subject Headings showed an adequate level of compatibility.;Thus, citation contexts may be a most useful method for developing indexing and thesaural terms descriptive of specialty areas in sociology and economics. Suggestions are given to automate these procedures...|$|E
40|$|The {{effectiveness}} {{and efficiency of}} searches for relevant documents strongly depend on key features of the <b>descriptor</b> <b>language</b> supported by the retrieval system. Effectiveness, for instance, {{is limited by the}} expressiveness of the descriptors. In addition, system efficiency is proportional to tractability. Furthermore, user effort is relative to comprehensibility and compactness. From a formulation point of view, compactness allows a high degree of integration, combining several occurrences of an analogous concept in a single expression. A proper <b>descriptor</b> <b>language</b> for information discovery should thus find a workable balance between these features. Boolean index expressions (BIEs) are proposed as balanced descriptors for the communication of information needs. Compared to many other descriptor languages, an advantage of BIEs is their compactness, offering the opportunity to convey much information in a succinct way. The goal {{of this article is to}} investigate compactness of BIEs. For instance, we analyse how compactness is brought about in BIEs and how it can be effectively measured. In addition, two classes of BIEs are investigated that illustrate the bounds on the compactness of BIEs: minimal and maximal BIEs. The bounds are explicitly derived and illustrated by generic examples. Furthermore, we report on experiments that ascertain the merit of minimal and maximal BIE...|$|E
40|$|In this paper, {{we report}} {{preliminary}} findings from an experimental {{study in which}} twenty-eight users answered questions by performing strategic information searches on web pages. Pages, which varied in length from 100 to 850 words, were displayed on either a standard, desktop monitor (full-sized) or a palm handheld interface (small-screen). Overall, users took more time to perform the tasks {{on the small screen}} interface, with the break in efficacy appearing between 225 and 350 word-lengths. Finally, contrary to our hypothesis, participants were similarly accurate across conditions. Categories and Subject <b>Descriptors</b> <b>Language</b> Contructs and Features – abstract data types, polymorphism, control structure...|$|R
50|$|As of Windows Server 2012, Microsoft has {{implemented}} an ABAC {{approach to}} controlling access to files and folders. This achieved through dynamic access control lists (DACL) and Security <b>Descriptor</b> Definition <b>Language</b> (SDDL). SDDL {{can be seen}} as an ABAC language as it uses metadata of the user (claims) and of the file / folder to control access.|$|R
40|$|In {{this paper}} we {{introduce}} {{a class of}} <b>descriptors</b> for regular <b>languages</b> arising from an application of the Stone duality between finite Boolean algebras and finite sets. These descriptors, called classical fortresses, are object specified in classical propositional logic and capable to accept exactly regular languages. To prove this, we show that the languages accepted by classical fortresses and deterministic finite automata coincide. Classical fortresses, besides being propositional <b>descriptors</b> for regular <b>languages,</b> also {{turn out to be}} an efficient tool for providing alternative and intuitive proofs for the closure properties of regular languages...|$|R
40|$|A compact Modular Chemical <b>Descriptor</b> <b>Language</b> (MCDL) {{chemical}} structure editor (Java applet) is described. The small size (approximately 200 KB) of the applet allows its use to display and edit {{chemical structure}}s in various Internet applications. The editor supports the MCDL format, in which structures {{are presented in}} compact canonical form and is capable of restoring bond orders {{as well as of}} managing atom and bond drawing overlap. A small database of cage and large cyclic fragment is used for optimal representation of difficult-to-draw molecules. The improved algorithm of the structure diagram generation can be used for other chemical notations that lack atomic coordinates (SMILES, InChI) ...|$|E
40|$|Abstract. The present work {{discusses}} the aspects {{pertaining to the}} change of scientific software development practices towards the paradigm of component-based programming [1]. It summarizes the symptoms that indicate the ne-cessity of a renewal in computational sciences. The main ingredients for the solution are identified and a vision on how effective code sharing can affect future scientific research is presented. Starting from the premises of today’s scientific software development a set of requirements for the framework, com-ponent <b>descriptor</b> <b>language,</b> component wiring and component repository are formulated. We claim that the community rather needs a useful tool even if of restricted use than an ultimate high-tech solution that will remain unac-cessible to a community not willing to change overnight those programming practices it has been accustomed to for decades. 1...|$|E
40|$|Abstract Background In our {{previous}} papers we introduced the Modular Chemical <b>Descriptor</b> <b>Language</b> (MCDL) for providing a linear representation of chemical information. A subsequent development was the MCDL Java Chemical Structure Editor which {{is capable of}} drawing chemical structures from linear representations and generating MCDL descriptors from structures. Results In this paper we present MCDL modules and accompanying software that incorporate unique representation of molecular stereochemistry based on Cahn-Ingold-Prelog and Fischer ideas in constructing stereoisomer descriptors. The paper also contains additional discussions regarding canonical representation of stereochemical isomers, and brief algorithm descriptions of the open source LINDES, Java applet, and Open Babel MCDL processing module software packages. Conclusions Testing of the upgraded MCDL Java Chemical Structure Editor on compounds taken from several large and diverse chemical databases demonstrated satisfactory performance for storage and processing of stereochemical information in MCDL format. </p...|$|E
50|$|This concept {{occurs in}} the {{discussion}} of exoteric and esoteric religions. Exoteric concepts are concepts which can be fully conveyed using <b>descriptors</b> and <b>language</b> constructs, such as mathematics. Esoteric concepts are concepts which cannot be fully conveyed except by direct experience. For example, a person who has never tasted an apple will never fully understand through language what the taste of an apple is. Only through direct experience (eating an apple) can that experience be fully understood.|$|R
50|$|Stands for Integrity Control Access Control List. Windows Server 2003 Service Pack 2 {{and later}} include icacls, an in-box {{command-line}} utility that can display, modify, {{backup and restore}} ACLs for files and folders, {{as well as to}} set integrity levels and ownership in Vista and later versions. It is not a complete replacement for cacls, however. For example, it does not support Security <b>Descriptor</b> Definition <b>Language</b> (SDDL) syntax directly via command line parameters (only via the /restore option).|$|R
5000|$|The ALTE (Association of Language Testers in Europe) [...] "Can Do" [...] project {{developed}} a simplified set of 400+ <b>descriptors</b> for <b>language</b> examinations which {{relate to the}} Common Reference Levels. These descriptors are {{in the form of}} [...] "can-do statements", each saying more simply what a learner can do at every level. There are four sections: general, social/ tourist, work and study. The ALTE project also gave its own names to the CEFR levels from the [...] "Breakthrough level" [...] to [...] "Level 5".|$|R
40|$|Keywords {{still seem}} to {{form the basis for}} {{document}} content and query representation. Approaches to use more advanced linguistic structures, such as noun phrases, still are in an experimental phase. In addition, Boolean descriptor languages have often been applied for Information Retrieval. However, the synthesis of logic and linguistics in one <b>descriptor</b> <b>language</b> still is an open issue. In this paper, Boolean index expressions, combining Boolean logic and linguistic structure, are proposed as a good balance between expresiveness and practical issues. Boolean index expressions are obtained by augmenting regular index expressions with logical operators for disjunction, conjunction, and negation. Boolean index expressions are more expressive than both index expressions and the Boolean query language based on keywords. They allow a compact representation of logical combinations of index expressions. In addition, Boolean index expressions are still eÆciently parsible and their meaning can b [...] ...|$|E
40|$|Background: In our {{previous}} papers we introduced the Modular Chemical <b>Descriptor</b> <b>Language</b> (MCDL) for providing a linear representation of chemical information. A subsequent development was the MCDL Java Chemical Structure Editor which {{is capable of}} drawing chemical structures from linear representations and generating MCDL descriptors from structures. Results: In this paper we present MCDL modules and accompanying software that incorporate unique representation of molecular stereochemistry based on Cahn-Ingold-Prelog and Fischer ideas in constructing stereoisomer descriptors. The paper also contains additional discussions regarding canonical representation of stereochemical isomers, and brief algorithm descriptions of the open source LINDES, Java applet, and Open Babel MCDL processing module software packages. Conclusions: Testing of the upgraded MCDL Java Chemical Structure Editor on compounds taken from several large and diverse chemical databases demonstrated satisfactory performance for storage and processing of stereochemical information in MCDL format. Background In {{our previous}} paper we introduced the Modular Chemica...|$|E
40|$|A high {{performance}} standardized System-on-Chip (SoC) communication {{system has been}} developed as an embedded core. A high level synthesis of a Fibre Channel core has been realized that {{takes advantage of the}} performance advantages and specifications associated with the Fibre Channel protocol. A soft IP core of a Fibre Channel port is presented {{in the form of a}} register transfer level (RTL) <b>descriptor</b> <b>language</b> which can be implemented in arbitrary target technologies. A full-speed (1. 0625 GHz link clock) sign-off quality tape-out of the design in TSMC 2 ̆ 7 s 0. 18 mum technology has been carried out using a design flow centered on the Cadence SoC Encounter platform. Paper copy at Leddy Library: Theses 2 ̆ 6 Major Papers - Basement, West Bldg. / Call Number: Thesis 2005. K 84. Source: Masters Abstracts International, Volume: 44 - 03, page: 1456. Thesis (M. A. Sc.) [...] University of Windsor (Canada), 2005...|$|E
30|$|Several {{empirical}} CEFR-related {{studies have}} also emerged in recent years. Huang and Jia (2012) tried to align College English Test (CET) with the CEFR using the Dutch Grid (Alderson et al. 2006). Yang et al. (2011) did a pilot study to develop the speaking ability scales of English, and explored the ways of collecting, analyzing and scaling descriptors. The most recent attempt was made by Wang (2012) who investigated the ways to develop and validate <b>descriptors</b> for <b>language</b> comprehension, i.e., listening and reading, for Chinese learners of English.|$|R
40|$|Abstract. Natural <b>language</b> <b>{{descriptors}}</b> {{used for}} categorizations are present from folksonomies to ontologies. While some descriptors are com-posed of simple expressions, other descriptors have complex composi-tional patterns (e. g. ‘French Senators Of The Second Empire’, ‘Churches Destroyed In The Great Fire Of London And Not Rebuilt’). As con-ceptual models get {{more complex and}} decentralized, more content is transferred to unstructured natural <b>language</b> <b>descriptors,</b> increasing the terminological variation, reducing the conceptual integration and the structure level of the model. This work describes a formal representa-tion for complex natural <b>language</b> category <b>descriptors</b> (NLCDs). In the representation, complex categories are decomposed into a graph of prim-itive concepts, supporting their interlinking and semantic interpretation. A category extractor is built {{and the quality of}} its extraction under the proposed representation model is evaluated. ...|$|R
40|$|Folksonomy ” {{is a term}} {{coined by}} Thomas Vander Wal from “folk ” and “taxonomy ” (Smith, 2004) to {{describe}} systems in which people (not professional indexers) assign natural <b>language</b> <b>descriptors</b> to resources. Many definitions of varying precision and breadth {{have been used for}} “folksonomy ” (Vander Wal, 2005), and...|$|R
40|$|An {{interactive}} program, {{based on}} the classical theory of Irvin, has been developed for predicting the junction depth in diffused pn junctions in silicon. Students are able to vary the input parameters (surface concentration, sheet resistivity, and background concentration) {{of the problem and}} junction depth versus various processing parameter information is displayed. Supporting information, such as the concentration versus depth profiles of the dopant and the concentration dependence of the dopant mobility are also available. Our program is based on technology we have developed for a much broader class of interactive problems similar to the one described here. The underlying computational package is written in 100 % pure Java. The graphical user interface used is dynamically constructed by parsing a file containing a specified set of XML tags we call XPDL (eXtensible Problem <b>Descriptor</b> <b>Language),</b> thus making it easy for those with experience writing web pages in HTML to transition into modifying the present application or to writing new applications. 1...|$|E
40|$|Current {{biological}} research workflows {{make use}} of disparate, poorly integrated systems that cause large mental burden on the scientist leading to mistakes on often long, complex and costly experimental procedures. The lack of open tools {{to assist in the}} collection of distributed experimental conditions and data is largely responsible making protocols difficult to debug and laboratory practice hard to learn. In this thesis, we describe an open Protocol <b>Descriptor</b> <b>Language</b> (PDL) and system to enable a context-rich, quantitative approach to biological research. We detail the development of a closed-loop pipetting technology and a wireless, sample temperature sensor that integrate with our Protocol Description platform enabling novel, real-time experimental feedback to the researcher thereby reducing mistakes and increasing overall scientific reproducibility. by Charles Fracchia. Thesis: S. M., Massachusetts Institute of Technology, School of Architecture and Planning, Program in Media Arts and Sciences, 2014. Cataloged from PDF version of thesis. Includes bibliographical references (pages 95 - 100) ...|$|E
40|$|The {{discovery}} of non-coding RNA (ncRNA) motifs {{and their role}} in regulating gene expres-sion has recently attracted considerable attention. The goal is to discover these motifs in a sequence database. Current RNA motif search methods start from the primary sequence and only then take into account secondary structure considerations. One can think of developing a flexible structure-based motif search method that will filter datasets based on secondary structure first, while allowing extensive primary sequence factors and additional factors such as potential pseudoknots as constraints. Since different motifs vary in structure rigidity and in local sequence constraints, {{there is a need}} for algorithms and tools that can be fine-tuned according to the searched RNA motif, but differ in their approach from the RNAMotif <b>descriptor</b> <b>language.</b> We present an RNA motif search tool called STRMS (Structural RNA Motif Search), which takes as input the secondary structure of the query, including local se-quence and structure constraints, and a target sequence database. It reports all occurrences of the query in the target, ranked by their similarity to the query, and produces an html file that displays graphical images of the predicted structures for both the query and the candi...|$|E
40|$|The IMDI Framework offers {{next to a}} {{suitable}} set of metadata <b>descriptors</b> for <b>language</b> resources, a set of tools and an infrastructure to use these. This paper gives an overview of all these aspects {{and at the end}} describes the intentions and hopes for ensuring the interoperability of the IMDI framework within more general ones in development. An evaluation of {{the current state of the}} IMDI Framework is presented with an analysis of the benefits and more problematic issues. Finally we describe work on issues of long-term stability for IMDI by linking up to the work done within the ISO TC 37 /SC 4 subcommittee (TC 37 /SC 4) ...|$|R
40|$|This DVD was {{developed}} by the National Association for Language Development in the Curriculum (NALDIC) for the Training and Development Agency for Schools (TDA) as a resource for teachers and teacher educators who are interested in developing approaches to assessment in multilingual classroms. The 30 -minute DVD presents primary bilingual pupils and their teachers working on aspects of their language development, with a commentary on assessment for learning and pupils learning EAL. The DVD contains interviews with teachers and a well-known expert explaining approaches to classroom assessment for bilingual pupils. The DVD also contains transcripts of the teaching sessions, texts of the audio commentary and interviews, session notes for teacher trainers, and formative <b>descriptors</b> of <b>language</b> development...|$|R
5000|$|The Big Five {{personality}} traits, {{also known}} as the five factor model (FFM), is a model based on common <b>language</b> <b>descriptors</b> of personality. When factor analysis (a statistical technique) is applied to personality survey data, some words used to describe aspects of personality are often applied to the same person. For example, someone described as [...] "conscientious" [...] {{is more likely to be}} described as [...] "always prepared" [...] rather than [...] "messy". This theory is based therefore on the association between words but not on neuropsychological experiments. This theory uses <b>descriptors</b> of common <b>language</b> and therefore suggests five broad dimensions commonly used to describe the human personality and psyche. The five factors have been defined as openness to experience, conscientiousness, extraversion, agreeableness, and neuroticism, often represented by the acronyms OCEAN or CANOE. Beneath each proposed global factor, a number of correlated and more specific primary factors are claimed. For example, extraversion is said to include such related qualities as gregariousness, assertiveness, excitement seeking, warmth, activity, and positive emotions.|$|R
40|$|A {{feasibility}} study for an automated scheme for spectrum sharing between passive and active users is presented. The needs of spectrum users {{can be represented}} by manifolds in a Euclidean hyperspace called electrospace which has 7 dimensions: frequency (f); Cartesian coordinates (x,y,z); angular coordinates (θ,ø), and time (t). The entire globe is tessellated into geographical areas containing spectrum users, called user domains. Each user domain is recursively tessellated into smaller user domains, or subdomains. A computer cluster, or broker, in each smallest subdomain performs the calculations necessary {{to determine if a}} particular user in the subdomain experiences interference. Throughout this thesis, the Chicago Loop (area of 4. 09 km 2, population ~ 21, 000) is taken to be the representative example of a smallest subdomain. Within each subdomain, the number of users served by a broker is reduced to a manageable number by the process of culling. There are three orders of culling. In first-order culling, subdomain pairs without line of sight and not close enough to mutually interfere are culled, or removed from further consideration for interference calculations. In second-order culling, within each subdomain an intersection test of the electrospace manifolds of all user pairs is performed. User pairs whose manifolds do not intersect are culled. In third-order culling a Friis calculation is performed for all remaining user pairs. The output of third-order culling is an RFI flag bit for each user indicating whether interference is present or not. The computational complexity of first-, second-, and third-order culling calculations was determined. Three representative user classes will be discussed: WiFi access points, Terminal Doppler Weather Radars, and passive EESS satellites. The manifold <b>descriptor</b> <b>language</b> (MDL) {{for each of the three}} user classes was described. The computational complexity of broker calculations to determine electrospace parameters from the MDL was determined. Using this complexity and the complexity of culling calculations, the total computational requirements for a broker in a representative subdomain is determined in GFLOPS (Giga Floating Point Operations Per Second) ...|$|E
5000|$|This phrase {{was used}} in print by Nicholas P. Andriotis, {{professor}} of Linguistics at the University of Thessaloniki. Chapter VI of his book, 'The Federative Republic of Skopje and its Language' (Athens, 1966), is entitled [...] "The impact of the Greek Language on the Slavic Dialect of the State of Skopje". His choice of <b>descriptors</b> for the <b>language</b> reflects Greek objections both {{to the use of}} the term 'Macedonian' to designate the language of the Republic of Macedonia, and {{to the use of the}} term 'Macedonia' to designate the state.|$|R
40|$|This {{paper is}} {{in the nature of}} a {{challenge}} to artificial intelligence experts. It suggests that the techniques of artificial intelligence should be applied to some realistic problems which exist in the programming and data processing fields. After a brief review of the little related existing work which has been done, the characteristics of programming problems which make them suitable for the application of artificial intelligence techniques are given. Specific illustrations of problems are provided under the broad categories of data structure and organization, program structure and organization, improvements and corrections of programs, and <b>language.</b> <b>Descriptors</b> artificial intelligence applications programming heuristic techniques I...|$|R
40|$|International audienceThis {{study is}} based on a {{large-scale}} research project concerning a task-based blended language learning programme for first-year Business English undergraduate students in a university in France. The communication focuses on the evaluation of the learning program, which combines face-to-face and distance learning, on the one hand, and task-based learning on the other hand, and its impact on learning outcomes. We first measured the effectiveness of the task-based learning program qualitatively for the development of second language (L 2) acquisition in writing using pre-tests and post-tests (n= 300) and evaluation grids adapted from the Common European Framework of Reference for Languages (CEFR). The grids use CEFR criteria, <b>descriptors</b> and <b>language</b> proficiency scale which defines proficiency at six ascending levels including A 1 /A 2 (basic user), B 1 /B 2 (independent user) to C 1 /C 2 (proficient user). In addition a sample of students’ written productions (n= 15) were analysed using quantitative complexity, accuracy and fluency (CAF) measures (Skehan, 2009, Ortega, 2009, Wolf-Quintero, Inagaki and Kim, 1998;) ...|$|R
40|$|This paper {{presents}} a semantic classification of reflexive verbs in Bulgarian, augmenting the morphosyntactic classes of verbs {{in the large}} Bulgarian Lexical Data Base- a language resource utilized {{in a number of}} Language Engineering (LE) applications. The semantic descriptors conform to the Unified Eventity Representation (UER), developed by Andrea Schalley. The UER is a graphical formalism, introducing the object-oriented system design to linguistic semantics. Reflexive/non-reflexive verb pairs are analyzed where the nonreflexive member of the opposition, a two-place predicate, is considered the initial linguistic entity from which the reflexive correlate is derived. The reflexive verbs are distributed into initial syntactic-semantic classes which {{serve as the basis for}} defining the relevant semantic descriptors in the form of EVENTITY FRAME diagrams. The factors that influence the categorization of the reflexives are the lexical paradigmatic approach to the data, the choice of only one reading for each verb, top level generalization of the semantic <b>descriptors.</b> The <b>language</b> models described in this paper provide the possibility for building linguistic components utilizable in knowledge-driven systems. 1...|$|R
40|$|Semantic {{annotation}} is {{the process}} of identifying expressions in texts and linking them to some semantic structure. In particular, Linked data-based Semantic Annotators are now becoming the new Holy Grail for meaning extraction from unstructured documents. This paper presents an evaluation of the main linked data-based annotators available with a focus on domain topics and named entities. In particular, we compare the ability of each tool to annotate relevant domain expressions in text. The paper also proposes a combination of annotators through voting methods and machine learning. Our results show that some linked-data annotators, especially Alchemy, can be considered as a useful resource for topic extraction. They also show that a substantial increase in recall can be achieved by combining the annotators with a weighted voting scheme. Finally, an interesting result is that by removing Alchemy from the combination, or by combining only the more precise annotators, we get a significant increase in precision, at the cost of a lower recall. Categories and Subject <b>Descriptors</b> [Natural <b>Language</b> Processing]: [Text analysis, Information extraction...|$|R
