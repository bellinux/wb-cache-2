0|10000|Public
50|$|Groovy's changes <b>in</b> <b>code</b> <b>through</b> {{prototyping}} are {{not visible}} in Java, since each attribute/method invocation in Groovy {{goes through the}} metaclass registry. The changed code can only be accessed from Java {{by going to the}} metaclass registry.|$|R
40|$|Building a web {{application}} or a website can become difficult, just {{because so many}} technologies are involved. Generally companies tend to people that work in teams to develop {{web application}}s. These teams {{are made up of}} professionals that focus on different technologies, such as CGI, HTML, JavaScript, CSS and databases. When the work of many people gathers to make up a single document there is often a mismatch between parts of code written by different team members. This article focuses on improving this matter by bringing consistency <b>in</b> <b>code</b> <b>through</b> the use of HTML helpers in server-side scripting languages. The examples in this article use PHP as the server-side language, but the model can be applied in any other language a developer works with. HTML, CGI, Helper, OOP, code generation...|$|R
500|$|Another {{threatening}} {{letter was}} sent in October, threatening to attack Tesco customers with pipe bombs if the demands were not met. The letter contained a cipher which allowed {{the police to}} communicate with [...] "Sally" [...] <b>in</b> <b>code</b> <b>through</b> cryptic adverts <b>in</b> the Bournemouth Daily Echo. James contacted {{the editor of the}} Echo and the police were allowed to place the messages in the Echo, disguised as Mensa puzzles and made to look like wordsearches. By this time, the police had narrowed the focus of their investigation on a square-mile area of Bournemouth and James became convinced that they would find [...] "Sally" [...] through the postbox on Bradpole Road, through which the fire-damaged letter had passed in August. The box was placed under surveillance and, eventually, the October letter was traced back to that box. The footage from the surveillance operation was reviewed, but the image was of poor quality.|$|R
40|$|Includes bibliographical {{references}} (pages 95) In this Project a Z- 80 based Microcomputer System is presented. The System {{is basically}} designed to execute programs entered <b>in</b> their machine <b>code</b> <b>through</b> the keyboard. It is also {{capable of being}} interfaced with outside world for other applications such as burglar alarm, telephone dialer, frequency generator or else simply by software modification...|$|R
40|$|A medical {{classification}} system for coding a patient's reason for visit {{has been developed}} {{for use in the}} National Ambulatory Medical Care Survey and for ambulatory care settings. The <b>code</b> is developed <b>in</b> a modular structure and includes modules for Symptoms; Diseases; Diagnostic, Screening and Preventive Procedures; Therapeutic Procedures, Process Problems and Counseling; Injuries and Adverse Effects; Follow-ups for Test Results; and Administrative Reasons for Visits. The system was evaluated <b>in</b> <b>coding</b> tests, <b>through</b> review by medical societies representing the major specialties, and by other health care providers. An extensive coding index is available...|$|R
40|$|Hamming {{codes are}} widely used for the single bit error {{correction}} double bit error detection (SEC-DED) which occurred during data transmission process. This paper presents an enhanced detection of double adjacent bit errors and correcting all possible single bit errors <b>in</b> Hamming <b>codes</b> <b>through</b> selective bit placement technique for memory application. Soft errors occur due to the radiation particles which affects the memory elements. These soft errors cause flipping of single bit or more often adjacent bits in the memory. Proposed technique improves the probability of detecting double adjacent bit errors and also provides a simple method of detecting double adjacent bit errors as compared to convolution <b>coding</b> <b>through</b> interleaving which is complex and requires higher memory. Hamming (12, 8) is implemented on hardware using RL 78 (G 13) Microcontroller...|$|R
40|$|An {{approach}} for incorporating embedded simulation and analysis capabilities <b>in</b> complex simulation <b>codes</b> <b>through</b> template-based generic programming is presented. This approach relies on templating and operator overloading within the C++ language to transform a given calculation into {{one that can}} compute a variety of additional quantities that are necessary for many state-of-the-art simulation and analysis algorithms. An {{approach for}} incorporating these ideas into complex simulation <b>codes</b> <b>through</b> general graph-based assembly is also presented. These ideas have been implemented within a set of packages in the Trilinos framework and are demonstrated on a simple problem from chemical engineering...|$|R
40|$|Abstract — Concept drift {{is usually}} met in rapidly {{changing}} environments, especially in sequential data classification, where {{different types of}} concept drift occur on regular basis. This paper presents an approach to dynamic visualization of sequential data characteristics aiming to improve the comprehensibility of concept drifts that result in significant change of classification performance. The proposed approach is applied to sequential multi-label hospital discharge dataset containing diagnosis information {{for more than two}} million patients. Our experimental results demonstrate visualization of the anomalies <b>in</b> diagnosis <b>coding</b> <b>through</b> time that can explain the differences in sudden changes of class distribution or classification performance. Keywords- concept drift; multi-label classification; interpretability of classifiers I...|$|R
50|$|Because {{it is used}} to run one of the highest-traffic {{sites on}} the Web, Wikipedia, MediaWiki {{performance}} and scalability have been highly optimized. MediaWiki supports Squid, load-balanced database replication, client-side caching, memcached or table-based caching for frequently accessed processing of query results, a simple static file cache, feature-reduced operation, revision compression, and a job queue for database operations. According to Wikimedia Networking Coordinator Mark Bergsma, MediaWiki developers have attempted to optimize the software by not doing anything stupid, avoiding expensive algorithms, database queries, etc., caching every result that is expensive and has temporal locality of reference, and focusing on the hot spots <b>in</b> the <b>code</b> <b>through</b> profiling.|$|R
40|$|Abstract—We {{investigate}} a binary code, which is implemented by serially concatenating a multiplexer, a multilevel delay proces-sor, and a signal mapper to a binary turbo encoder. To achieve improved convergence behavior, we modify the binary code by passing {{only a fraction}} of the bits <b>in</b> the turbo <b>code</b> <b>through</b> the multilevel delay processor and the signal mapper. Two decoding methods are discussed and their performances are evaluated. Index Terms—Turbo codes, concatenated codes, binary codes. I...|$|R
40|$|Abstract. Application {{frameworks}} provide reusable {{concepts that}} are instantiated <b>in</b> application <b>code</b> <b>through</b> potentially complex implementation steps such as subclassing, implementing callbacks, and making calls. Existing applications contain valuable {{examples of such}} steps, except that locating them <b>in</b> the application <b>code</b> is often challenging. We propose the notion of concept implementation templates, which summarize the necessary implementation steps, and an approach to automatic extraction of such templates from traces of sample applications. We demonstrate the feasibility of the template extraction with high precision and recall through an empirical study with twelve realistic concepts from four widely-used frameworks. Finally, we report on a user experiment with twelve subjects in which the choice of templates vs. documentation had much less impact on development time than the concept complexity. ...|$|R
50|$|Several women's rights groups, {{such as the}} Association of Malian Women Lawyers, the Association of Women in Law and Development, the Collective of Women's Associations, and the Association for the Defense of Women's Rights, {{worked to}} {{highlight}} legal inequities, primarily <b>in</b> the family <b>code,</b> <b>through</b> debates, conferences, and women's rights training. These groups also provided legal assistance to women and targeted magistrates, police officers, and religious and traditional leaders in educational outreach to promote women's rights.|$|R
50|$|He {{was born}} in Leeds, England and became a lawyer in 1923 {{following}} studies at the University of Toronto and Osgoode Hall. Sedgwick contributed to changes <b>in</b> the Criminal <b>Code</b> <b>through</b> a Royal Commission in the early 1950s. He was counsel to George and Viola R. MacMillan in the 1964 Royal Commission to probe the activity of Windfall Oil and Mines Ltd. Politically, he was Progressive Conservative. He also served as Treasurer for the Law Society of Upper Canada from 1962 to 1963.|$|R
40|$|Object-Z is an {{extension}} of the formal specification language Z, augmenting the class concept as a struc-turing facility. This paper introduces and discusses a structural mapping sys tem f r o m Object-Z to the pro-gramming language C++, and reports on its imple-mentat ion o n UNIX. The structural mapping trans-lates an Object-Z specification consisting of classes into class interfaces of C++ such as data members and prototypes of member functions. Thus it is not intended as a code generation system, but rather as a tool for analyzing specification (including syntax and type checking) and for aiding a software developer <b>in</b> obtaining <b>code.</b> <b>Through</b> the implementation of the mapping sys tem several language features of Object-Z and C++ concerning object-orientation are clarified. ...|$|R
25|$|Several women's rights groups, {{such as the}} Association of Malian Women Lawyers, the Association of Women in Law and Development, the Collective of Women's Associations, and the Association for the Defense of Women's Rights (Association pour le Progres et la Defense des Droits des Femmes Maliennes – APDF), {{worked to}} {{highlight}} legal inequities, primarily <b>in</b> the family <b>code,</b> <b>through</b> debates, conferences, and women's rights training. These groups also provided legal assistance to women and targeted magistrates, police officers, and religious and traditional leaders in educational outreach to promote women's rights.|$|R
40|$|In {{this paper}} we propose an {{architecture}} whose main goal is to improve productivity in user interface develop-ment for data-intensive applications. This objective is to be achieved by defining a high level model that describes the user interface structure. That model will be integrated <b>in</b> the source <b>code</b> <b>through</b> non-functional language extensions. Our final goal is allowing developers to define user inter-face model by adding language extensions to the source code and then acquiring an external software package to which they delegate {{the implementation of the}} concrete user interface. 1...|$|R
40|$|The tome is the {{biography}} of a pretorian prefect during the years 397 - 399 and it is pieced togheter thanks to the few evidence about the officer and the laws that the Emperor Onorio refers to him. Flavius Manlius Theodorus, consul during the year 399, {{lives and works in}} Milan, which was the West Empire capital in that period. We are trying to make a portrait of an author who was important for the varied and complex imperial legislation included <b>in</b> the Theodosian <b>code</b> <b>through</b> the rebuilt of his life and his officer career...|$|R
50|$|Several women's rights groups, {{such as the}} Association of Malian Women Lawyers, the Association of Women in Law and Development, the Collective of Women's Associations, and the Association for the Defense of Women's Rights (Association pour le Progres et la Defense des Droits des Femmes Maliennes - APDF), {{worked to}} {{highlight}} legal inequities, primarily <b>in</b> the family <b>code,</b> <b>through</b> debates, conferences, and women's rights training. These groups also provided legal assistance to women and targeted magistrates, police officers, and religious and traditional leaders in educational outreach to promote women's rights.|$|R
40|$|One of {{the largest}} growing uses of spray {{polyurethane}} foam (SPF) insulation is in residential attics and crawl spaces. As with all other foam insulation applications, this use is regulated by building codes to assure that occupants are properly protected from the risk of fire. In order to demonstrate compliance with these requirements, the spray foam supplier typically performs fire tests, the results of which are submitted to an evaluation organization, such as the International Code Councils Evaluation Services (ICC ES), for review. A product’s performance is assessed against an Acceptance Criteria meant to clarify code requirements or to provide a technical basis for products or systems that are alternates to what is specified <b>in</b> the <b>code.</b> <b>Through</b> a public hearing process, the ICC-ES developed the Acceptance Criteria for Spray-applie...|$|R
40|$|Many {{applications}} access {{memory in}} an irregular manner, causing poor cache performance {{due to the}} lack of data locality. In complex scienti c applications such as computational uid dynamics and N-body simulation, irregular and/or dynamic accesses are abundant. Most research has been focused on improving locality <b>in</b> regular <b>codes</b> <b>through</b> computation and data reorganization. Unfortu-nately, since irregular codes have di erent computation structures, transforma-tion techniques for regular computations are not directly applicable to irregular <b>codes.</b> <b>In</b> my thesis, I present locality transformations of computation and data to exploit locality inirregular computations. Codes are rst classi ed according to the numberofirregular accesses in each unitofcomputation (e. g., loop iter-ation). Transformations are then applied appropriately. For sequential codes, data and computation reordering is applied. Computations are sorted based on the location of data being accessed. Elements of data are partitioned according to access patterns. For parallel codes, locality-conscious data and computatio...|$|R
40|$|Health {{services}} research is multifaceted and {{impacted by the}} multiple contexts and stakeholders involved. Hence, large data sets are necessary to fully understand the complex phenomena (e. g., scope of nursing practice) being studied. The management of these large data sets can lead to numerous challenges in establishing trustworthiness of the study. This article reports on strategies utilized in {{data collection and analysis}} of a large qualitative study to establish trustworthiness. Specific strategies undertaken by the research team included training of interviewers and coders, variation in participant recruitment, consistency in data collection, completion of data cleaning, development of a conceptual framework for analysis, consistency <b>in</b> <b>coding</b> <b>through</b> regular communication and meetings between coders and key research team members, use of N 6 ™ software to organize data, and creation of a comprehensive audit trail with internal and external audits. Finally, we make eight recommendations that will help ensure rigour for studies with large qualitative data sets: organization of the study by a single person; thorough documentation of the data collection and analysis process; attention to timelines; the use of an iterative process for data collection and analysis; internal and external audits; regular communication among the research team; adequate resources for timely completion; and time for reflection and diversion. Following these steps will enable researchers to complete a rigorous, qualitative research study when faced with large data sets to answer complex health {{services research}} questions...|$|R
5000|$|When Finch {{discovered}} that the Machine was tracking all premeditated crimes (episode 2, [...] "Ghosts") rather than just terrorist activities, he initially programmed it to delete the [...] "irrelevant" [...] cases every night at midnight, explaining to Ingram that the Machine is not built [...] "to save somebody, we built it to save everybody." [...] Unknown to Finch, Ingram created a backdoor function called [...] "Contingency", {{on the eve of}} the government handover, to allow access to the non-relevant data (shown accessed in the season 2 episode [...] "Zero Day"). Finch is appalled that Ingram has this data sent directly to him and shuts down the routine, but reactivates it after Ingram's death. To minimize detectability, The Machine feeds him numbers <b>in</b> <b>coded</b> messages <b>through</b> public telephones.|$|R
40|$|Previous {{researchers}} in user-level message-passing parallel computing {{have attempted to}} reduce communication overhead via several techniques: integrating part {{or all of the}} network interface (NI) on the CPU[8, 2], allowing NI device register accesses to be cached[11, 6], or using polling to avoid the overhead of interrupts[15, 18]. Unfortunately, these techniques incur significant overhead if applied to a superscalar processor system. We have developed architectural features that have the potential to alleviate these overheads. In this paper we present the results of simulations which demonstrate successful overlap of communication overhead and network latency with useful work. This benefit was achieved without sacrificing programmibility [...] - our message-passing libraries use PVM semantics. 1 Introduction Developments in processor design have created CPUs that are able to find and exploit low-level parallelism <b>in</b> sequential <b>code</b> <b>through</b> techniques such as pipelining, superscalar issue [...] ...|$|R
50|$|The channel {{encoding}} {{process in}} GPRS {{consists of two}} steps: first, a cyclic code is used to add parity bits, which are {{also referred to as}} the Block Check Sequence, followed by coding with a possibly punctured convolutional code. The Coding Schemes CS-1 to CS-4 specify the number of parity bits generated by the cyclic code and the puncturing rate of the convolutional <b>code.</b> <b>In</b> <b>Coding</b> Schemes CS-1 <b>through</b> CS-3, the convolutional code is of rate 1/2, i.e. each input bit is converted into two <b>coded</b> bits. <b>In</b> <b>Coding</b> Schemes CS-2 and CS-3, the output of the convolutional code is punctured to achieve the desired <b>code</b> rate. <b>In</b> <b>Coding</b> Scheme CS-4, no convolutional coding is applied. The following table summarises the options.|$|R
40|$|With {{the data}} output from the LHC increasing, {{many of the}} LHC {{experiments}} have made significant improvements to their code {{to take advantage of}} modern CPU architecture and the accompanying advanced features. With the grid environment changing to heavily include virtualisation and cloud services, we look at whether these two systems can be compatible, or whether improvements <b>in</b> <b>code</b> are lost <b>through</b> virtualisation. We compare the runtime speed improvements achieved in more recent versions of ATLAS code and see if these improvements hold up on various grid paradigms...|$|R
40|$|At present, {{the fuel}} {{assemblies}} of Light Water Reactors require mainly cost-effective production of electricity. The objective of in-core fuel management {{is to achieve}} the objective of minimizing the cost of fuel cycle using advanced models of core loading strategies. Current development is focused mainly on optimizing the design of gadolinium fuel, thereby to reduce the average enrichment of fuel assemblies and the binding of the excess reactivity {{at the beginning of the}} fuel cycle. This paper deals with the different ways to optimize fuel assemblies containing burnable absorber for PWR and VVER reactors. These calculations were made <b>in</b> SCLAE 6 <b>code</b> <b>through</b> TRION module...|$|R
40|$|Signature {{files are}} widely used in {{information}} retrieval and database. They act as search filters for content-based retrieval. In a large database server, a parallel device is utilized to achieve concurrency access. Efficient allocation of signature files on parallel devices minimizes the query response time and {{is important in the}} design of access methods for large scale index servers. We have developed an algorithm to organize the storage of signatures in parallel secondary storage to reduce the query response time. First, signature file is clustered into signature pages. Then, the clustered signature pages are distributed among the disks using the parity check matrix of error correcting <b>code</b> <b>in</b> <b>coding</b> theory. <b>Through</b> the construction of error correcting code, the least frequently simultaneously accessed pages are allocated on the same disk. Performance analysis shows that this algorithm improves the efficiency of access...|$|R
40|$|In recent years, {{the authors}} have {{investigated}} methods to improve the effectiveness of modeling collisional processes <b>in</b> particle-in-cell <b>codes.</b> <b>Through</b> the use of generalized collision models, plasma dynamics can be followed both in the regime of nearly collisionless plasmas {{as well as in}} the hydrodynamic limit of collisional plasmas. They have developed a collision-field method to treat both the case of collisions between unlike plasma species (inter-species collisions), through the use of a deterministic, grid-based force, and between particles of the same species (intra-species collisions), through the use of a Langevin equation. While the approach used for inter-species collisions is noise-free in that the collision experienced by a particle does not require any random numbers, such random numbers are used for intra-species collisions. This gives rise to a stochastic cooling effect inherent in the Langevin approach. In this paper, the authors concentrate on intra-species collisions and describe how the accuracy of the model can be improved by appropriate corrections to velocity and spatial moments...|$|R
40|$|Optimistic {{coalescing}} {{has been}} proven as an elegant and effective technique that provides better chances of safely coloring more registers in register allocation than other coalescing techniques. Its algorithm originally assumes homogeneous registers, which are all gathered in the same register file. Although this register architecture is still common in most general-purpose processors, embed-ded processors often contain heterogeneous registers, which are scattered in physically different register files dedicated for each dissimilar purpose and use. In this work, we show that optimistic coalescing is also useful for an embedded processor to better handle such heterogeneity of the reg-ister architecture, and developed a modified algorithm for optimal coalescing that helps a register allocator. In the experiment, an existing register allocator was able to achieve up to 13. 0 % reduction <b>in</b> <b>code</b> size <b>through</b> our coalescing, and avoid many spills {{that would have been}} generated without our scheme...|$|R
40|$|The {{purpose of}} this paper is to study the Bose, Chaudhuri, and Hocquenghem (BCH) code, with an aim to {{simulate}} the encoding and decoding processes. The gain of the proposed <b>code</b> <b>in</b> investigated <b>through</b> applying it to binary phase sift keying (BPSK) modulation scheme in symmetric additive white Gaussian noise (AWGN) channel. The bit error probability (BEP) of coded (63, 36) BCH system was evaluated and compared with the performance of un-coded system...|$|R
40|$|Presently, most {{tabu search}} {{designers}} devise their applications without considering {{the potential of}} design and code reuse, which consequently prolong the development of subsequent applications. In this paper, we propose a software solution known as Tabu Search Framework (TSF), which is a generic C++ software framework for tabu search implementation. The framework excels <b>in</b> <b>code</b> recycling <b>through</b> {{the use of a}} well- designed set of generic abstract classes that clearly define their collaborative roles in the algorithm. Additionally, the framework incorporates a centralized process and control mechanism that enhances the search with intelligence. This results in a generic framework that is capable of solving a wide range of combinatorial optimization problems using various tabu search techniques and adaptive strategies. The applications of TSF are demonstrated on the implementation of two NP-hard problems, the Vehicle Routing Problem with Time Windows (VRPTW) and Quadratic Assignment Problem (QAP). We show that TSF is able to obtain quality solutions within reasonable implementation as well as computation time...|$|R
40|$|Two related {{numerical}} {{schemes for}} calculating the 3 D collapse of protostellar clouds are defined, developed, and checked {{on a wide}} variety of test problems in spherical symmetry and multiple dimensions. One scheme is first-order accurate <b>in</b> time (<b>code</b> S), and the other second-order accurate <b>in</b> time (<b>code</b> ST). <b>Through</b> convergence testing, the codes are shown to be second-order accurate in spatial differences. Compared with the previous 3 D code, the combination of reduced numerical dissipation through second-order accuracy and of removing the systematic bias toward central concentrations implies that the tendency for fragmentation into binary or multiple protostars should increase. A reinvestigation of fragmentation as a mechanism for forming binary stars is expected to yield an even more favorable evaluation...|$|R
50|$|Originally, each {{mobile phone}} {{operator}} was issued one mobile phone <b>code.</b> <b>Through</b> {{a series of}} mergers, there are currently three major mobile phone operators: AIS, True and DTAC. As existing numbers begin to run out, the three mobile phone operators are assigned numbers <b>in</b> <b>code</b> 081, distinguished by the first digit of the subscriber number.|$|R
40|$|This paper {{provides}} a meta- analysis of how {{total hours worked}} re-spond to permanent and transitory changes <b>in</b> the tax <b>code.</b> Chetty, Guren, Manoli, and Weber’s thesis is that existing studies provide im-portant information about the Hicksian and Frisch elasticities of labor supply. The labor supply elasticity has been a key parameter in most macroeconomic models since Lucas and Rapping (1969), and so the au-thors argue that we need systematic evidence to pin down its value. In particular, they conclude that the elasticity of labor supply {{in response to a}} transitory shock to after- tax earnings is about 0. 25 on the extensive margin and twice as large on the intensive margin. This is far smaller than macroeconomic models need in order to explain the volatility of employment and hours worked over the business cycle. The authors illustrate the discrepancy between microeconomic and macroeconomic elasticities of labor supply by examining three real-world changes <b>in</b> the tax <b>code</b> <b>through</b> the lens of a particular life cycl...|$|R
40|$|This paper aims at the {{implementation}} {{details of a}} condensation model <b>in</b> the CFD <b>code</b> FLUENT and its validation {{so that it can}} be used in performing the containment hydrogen distribution studies. In such studies, computational fluid dynamics simulations are necessary for obtaining accurate predictions. While steam condensation plays an important role, commercial CFD codes such as FLUENT do not have an in-built condensation model. Therefore, a condensation model was developed and implemented <b>in</b> the FLUENT <b>code</b> <b>through</b> user defined functions (UDFs) for the sink terms in the mass, momentum, energy and species balance equations together with associated turbulence quantities viz., kinetic energy and dissipation rate. The implemented model was validated against the ISP- 47 test of TOSQAN facility using the standard wall functions and enhanced wall treatment approaches. The best suitable grid size and the turbulence model for the low density gas (He) distribution studies are brought out in this paper. (C) 2014 Elsevier B. V. All rights reserved...|$|R
40|$|Abstract: Presently, most {{tabu search}} {{designers}} devise their applications without considering {{the potential of}} design and code reuse, which consequently prolong the development of subsequent applications. In this paper, we propose a software solution known as Tabu Search Framework (TSF), which is a generic C++ software framework for tabu search implementation. The framework excels <b>in</b> <b>code</b> recycling <b>through</b> {{the use of a}} welldesigned set of generic abstract classes that clearly define their collaborative roles in the algorithm. Additionally, the framework incorporates a centralized process and control mechanism that enhances the search with intelligence. This results in a generic framework that is capable of solving a wide range of combinatorial optimization problems using various tabu search techniques and adaptive strategies. The applications of TSF are demonstrated on the implementation of two NP-hard problems, the Vehicle Routing Problem with Time Windows (VRPTW) and Quadratic Assignment Problem (QAP). We show that TSF is able to obtain quality solutions within reasonable implementation as well as computation time. Key words: Tabu Search, software framework, reusability, combinatorial optimization...|$|R
