281|54|Public
50|$|Cowell is the Editor of Economica and Associate Editor of Hacienda Pública Española/Revista de Economia Publica and Journal of Income Inequality. He is {{also the}} Director of <b>Distributional</b> <b>Analysis</b> Research Programme at the Suntory-Toyota International Centre for Economics and Related Disciplines.|$|E
5000|$|In Functionally-based <b>Distributional</b> <b>Analysis,</b> {{the child}} groups {{together}} words that perform similar functions (e.g. words that denote events) and {{that appear in}} similar sentence constructions. This would presumably allow the child to extract words such as 'eat', 'kick' and 'hit' from the input 'I X-ing it' or vice versa. This process is presumably essential to all accounts of language learning, whether nativist or otherwise.|$|E
50|$|Notable {{figures in}} the {{philosophical}} and empirical study of the mind have challenged the {{various aspects of the}} poverty of stimulus argument. Much of the criticism comes from researchers who study language acquisition and computational linguistics. Additionally, some connectionist researchers have refuted aspects of Chomsky's model, owing to premises that are at odds with connectionist beliefs about the structure of cognition. Constructionists are theorists who do not believe Chomskyan arguments and believe language is learned through some kind of functional <b>distributional</b> <b>analysis</b> (Tomasello 1992). One problem in language is called the no negative evidence problem. This is basically that children can use only positive evidence to learn language. Constructionists appeal to statistical and social learning mechanisms, which they claim can overcome a lack of negative evidence, whereas nativists simply use linguistic constraint theories (Baker 1979, Jackendoff 1975).|$|E
50|$|<b>Distributional</b> {{cost-effectiveness}} <b>analysis</b> (DCEA) is {{an extension}} of standard cost-effectiveness analysis that incorporates concern for both the average levels of outcomes as well as the distribution of outcomes, particularly useful when evaluating interventions to tackle health inequality.|$|R
40|$|AbstractAmong {{the uses}} for global {{sensitivity}} analysis is factor prioritization. A key assumption {{for this is}} that a given factor can, through further research, be fixed to some point on its domain. For factors containing epistemic uncertainty, this is an optimistic assumption, which can lead to inappropriate resource allocation. Thus, this research develops an original method, referred to as <b>distributional</b> sensitivity <b>analysis,</b> that considers which factors would on average cause the greatest reduction in output variance, given that the portion of a particular factor's variance that can be reduced is a random variable. A key aspect of the method is that the analysis is performed directly on the samples that were generated during a global sensitivity analysis using acceptance/rejection sampling. In general, if for each factor, N model runs are required for a global sensitivity analysis, then those same N model runs are sufficient for a <b>distributional</b> sensitivity <b>analysis...</b>|$|R
40|$|In {{this paper}} {{we present a}} survey of <b>distributional</b> impact <b>analysis</b> of {{environmental}} policies envisaged or implemented to reduce greenhouse gasses emissions. Implementation of policies by developed countries has an objective of reducing greenhouse gasses directly or indirectly. However, these policies can produce important changes in factor allocation, relative prices in specific countries {{as well as on}} world markets when large countries of when policies are adopted by a large number of countries. These policies can produce important changes in welfare for important portion of vulnerable groups of population in developing countries. This survey reveals that the computable general equilibrium (CGE) microsimulation approach has not been fully exploited in the context of <b>distributional</b> impact <b>analysis</b> of CC policies and that developing economics exhibit features that warrant country specific applications to draw clear conclusions on the regressivity or progressivity of CC policies. Global warming, environmental policies, income distribution, developing countries...|$|R
5000|$|Fundamental to this approach, and, indeed, {{making it}} possible, is Harris' {{recognition}} that phonemic contrast cannot {{be derived from}} <b>distributional</b> <b>analysis</b> of phonetic notations but rather that the fundamental data of linguistics are speakers' judgments of phonemic contrast. He developed and clarified methods of controlled experiment employing substitution tests, such as the pair test (Harris 1951:32) in which informants distinguish repetition from contrast. It is probably {{accurate to say that}} phonetic data are regarded as fundamental in all other approaches to linguistics. For example, Chomsky (1964:78) [...] "assumes that each utterance of any language can be uniquely represented as a sequence of phones, each of which can be regarded as an abbreviation for a set of features". Recognizing the primacy of speaker perceptions of contrast enabled remarkable flexibility and creativity in Harris's linguistic analyses which others - without that improved foundation - labelled [...] "game playing" [...] and [...] "hocus-pocus." ...|$|E
5000|$|Koti {{has five}} vowels. The open vowels [...] and [...] are {{normally}} written e and o. The high vowels i and u {{do not occur}} word-initially. There is a restricted form of vowel harmony in verbal bases which causes /u/ in verbal extensions to be rendered as o after another /o/; thus, the separative extensions -ul- and -uw- appear as -ol- and -ow- after the vowel o. Furthermore, a <b>distributional</b> <b>analysis</b> shows that /o/ tends to occur mainly after another /o/, and only rarely after the other vowels.Vowel length is contrastive in Koti, except in word-final position. Long vowels are best treated as two tone-bearing units. Several vowel coalescense processes do take place, within words as well as across morpheme boundaries: mathápá mawíxí apa → mathápá mawíx'áapa 'these green leaves' (the apostrophe shows the location of coalescence). In case of word-final 'i' it is sometimes accompanied with glide formation: olíli áka → olíly'aáka 'my bed'.|$|E
50|$|Other {{than his}} {{criticism}} of Chomsky and the nativist perspective, {{one of the major}} theoretical contributions in Tomasello’s Constructing a Language: A Usage-Based Theory of Language Acquisition (2003) is an account of how children may eventually form adult-like grammatical categories through abstract generalizations over patterns attested in child speech production. Children are believed to form slot-and-frame patterns or constructions such as 'Wanna +X' or 'It's X' where X starts off being a particular lexical item, and as the frames collapse onto one another through low-scope generalization, X may start to refer to something less specific and more abstract, such as an ACTION (in the case of 'Wanna + X'). In this case the ACTION refers not to a fully operational VERB class or category as it is supposed that adult-like syntactic behaviour emerges only much later in a child's development. Crucially, it is argued that (a) the child's productions themselves are used directly in the low-scope generalizations through which these slot-and-frame patterns emerge (b) That the intermediate slot-and-frame stages are necessary to the child's acquisition of adult-like grammar (c) That the child is unable to form an adult-like linguistic category (e.g. 'VERB') through mere <b>distributional</b> <b>analysis</b> over individual lexical items.|$|E
5000|$|A Study of Abortion in Primitive Societies; a typological, <b>distributional,</b> {{and dynamic}} <b>analysis</b> of the {{prevention}} of birth in 400 pre-industrial societies, New York: Julian Press, 1955 ...|$|R
50|$|Cost-utility {{analysis}} {{is similar to}} cost-effectiveness analysis. Cost-effectiveness analyses are often visualized on a plane consisting of four-quadrants, the cost represented on the x-axis and the effectiveness on the y- axis. Cost-effectiveness analysis focuses on maximising the average level of an outcome, <b>distributional</b> cost-effectiveness <b>analysis</b> extends the core methods of CEA to incorporate concerns for the distribution of outcomes {{as well as their}} average level and make trade-offs between equity and efficiency, these more sophisticated methods are of particular interest when analysing interventions to tackle health inequality.|$|R
40|$|Measuring the {{incidence}} of public spending in education requires an intergenerational framework distinguishing between what current and future generations - that is, parents and children - give and receive. In standard <b>distributional</b> incidence <b>analysis,</b> households are assumed to receive a benefit equal to what is spent on their children enrolled in the public schooling system and, implicitly, to pay a fee proportional to their income. This paper shows that, in an intergenerational framework, this is equivalent to assuming perfectly altruistic individuals, {{in the sense of}} the dynastic model, and perfect capital markets. But in practice, credit markets are imperfect and poor households cannot borrow against the future income of their children. The authors show that under such circumstances, standard <b>distributional</b> incidence <b>analysis</b> may greatly over-estimate the progressivity of public spending in education: educational improvements that are progressive in the long-run steady state may actually be regressive for the current generation of poor adults. This is especially true where service delivery in education is highly inefficient - as it is in poor districts of many developing countries - so that the educational benefits received are relatively low in comparison with the cost of public spending. The results have implications for both policy measures and analytical approaches.,Debt Markets,Access to Finance,Economic Theory&Research,Public Sector Expenditure Analysis&Management...|$|R
50|$|There are {{different}} processes and GIS functionalities {{that are used}} in archaeological research. Intrasite spatial analysis or <b>distributional</b> <b>analysis</b> of the information on the site helps in understanding the formation, process of change and in documentation of the site. This leads to research, analysis and conclusions. The old methods utilized for this provide limited exposure to the site and provide only a small picture of patterns over broad spaces. Predictive modeling is used through data acquisition like that of hydrography and hypsography to develop models along with archaeological data for better analysis. Point data in GIS is used to focus on point locations and to analyze trends in data sets or to interpolate scattered points. Density mapping is done for the analysis of location trends and interpolation is done to aid surface findings through the creation of surfaces through point data and is used to find occupied levels in a site. Aerial data is more commonly used. It focuses on the landscape and the region and helps interpret archaeological sites in their context and settings. Aerial data is analyzed through predictive modeling which is used to predict location of sites and material in a region. It is based on the available knowledge, method of prediction and on the actual results. This is used primarily in cultural resource management.|$|E
3000|$|... 32 <b>Distributional</b> <b>analysis</b> is {{performed}} using DASP (Araar and Duclos 2009) and DAD (Duclos and Araar 2004).|$|E
40|$|<b>Distributional</b> <b>analysis</b> {{is widely}} used to study social choice in Euclidean models [28, 29, 1, 3, 8, 15, 5, 2, e. g. ]. This method assumes a {{continuum}} of voters distributed according to a distribution function. Since infinite populations do not exist, the goal of <b>distributional</b> <b>analysis</b> is to give insight into the behavior of large finite populations. However, properties of finite populations do not in general converge to the properties of infinite populations. Thus the method of <b>distributional</b> <b>analysis</b> is flawed. In some cases it will predict that a point is in the core with probability 1, while the true probability converges to 0. On the other hand, it is sometime possible to combine <b>distributional</b> <b>analysis</b> with probabilistic analysis to make correct predictions about the asymptotic behavior of large populations, as in [2, e. g. ]. Results on the uniform convergence of empirical measures [18, e. g. ] are employed to yield simpler proofs of min-max Simpson-Cramer majority [5, 2] and yolk shrinkage [26]. The analysis suggests {{a rule of thumb}} {{as to whether or not}} a prediction based on <b>distributional</b> <b>analysis</b> will be valid for large finite populations. From the experimental point of view, the discussion helps clarify the mathematical underpinnings of statistical analysis of empirical voting data. A careful reading shows Tullock's original paper [28] to be consistent with the analysis given here. National Research Council and National Science Foundation[URL] Direct FundingN...|$|E
40|$|This paper {{presents}} {{an application of}} a new methodological framework for undertaking <b>distributional</b> cost-effectiveness <b>analysis</b> to combine the objectives of maximising health and minimising unfair variation in health when evaluating population health interventions. The National Health Service bowel cancer screening programme introduced in 2006 is expected to improve population health on average and to worsen population health inequalities associated with deprivation and ethnicity - {{a classic case of}} 'intervention-generated inequality'. We demonstrate the <b>distributional</b> cost-effectiveness <b>analysis</b> framework by examining two redesign options for the bowel cancer screening programme: (i) the introduction of an enhanced targeted reminder aimed at increasing screening uptake in deprived and ethnically diverse neighbourhoods and (ii) the introduction of a basic universal reminder aimed at increasing screening uptake across the whole population. Our analysis indicates that the universal reminder is the strategy that maximises population health, while the targeted reminder is the screening strategy that minimises unfair variation in health. The framework is used to demonstrate how these two objectives can be traded off against each other, and how alternative social value judgements influence the assessment of which strategy is best, including judgements about which dimensions of health variation are considered unfair and judgements about societal levels of inequality aversion...|$|R
40|$|This paper {{focuses on}} {{approaches}} to linking macroeconomic models to household income data for poverty and <b>distributional</b> and <b>analysis.</b> Given that linkage methods {{can influence the}} resulting poverty and income distribution effects, understanding the benefits and costs of various linkages is important. Simulation exercises do not show fundamentally different results when comparing three approaches: a simple micro-accounting method, an extension of that method to account for changes in employment structure, and the Beta distribution approach. However, potential differences can be very large. We also highlight the extended micro-accounting method as a practical approach to linking macroeconomic models to household income data...|$|R
40|$|This paper {{performs}} a <b>distributional</b> incidence <b>analysis</b> {{to study the}} patterns describing access to, and expenditures on, basic services (education, health, public transport, water, electricity, gas and telecommunications) in Latin American countries. We find that household expenditures on these services are pro-rich distributed, mainly because poorest households face limited access to services. Also, services with the highest expenditure shares (education, health, and transport) are characterized by moderate to small Kakwani indices, while services with high Kakwani indices (telecommunication and gas) represent {{a small part of}} total household consumption, suggesting small distributional effects of potential reforms of services sectors. ...|$|R
40|$|<b>Distributional</b> <b>analysis</b> {{is widely}} used to study social choice in Euclidean models [35, 36, 1, 5, 11, 19, 8, 2, e. g]. This method assumes a {{continuum}} of voters distributed according a probability measure. Since infinite populations do not exist, the goal of <b>distributional</b> <b>analysis</b> is to give insight into the behavior of large finite populations. However, properties of finite populations do not necessarily converge to the properties of infinite populations. Thus the method of <b>distributional</b> <b>analysis</b> is flawed. In some cases [1] it will predict that a point is in the core with probability 1, while the true probability converges to 0. In other cases it can be combined with probabilistic analysis to make accurate predictions about the asymptotic behavior of large populations, as in [2]. Uniform convergence of empirical measures [23] is employed here to yield a simpler, more general proof of α-majority convergence, a short proof of yolk shrinkage, and suggests {{a rule of thumb}} to determine the accuracy of distribution-based predictions. The results also help clarify the mathematical underpinnings of statistical analysis of empirical voting data. ...|$|E
3000|$|... 26 A typical {{example of}} this claim is given by the Tax Foundation (2013), in their {{response}} to the Institute for Taxation and Economic Policy release of their 2013 <b>distributional</b> <b>analysis</b> for states (ITEP 2013).|$|E
40|$|<b>Distributional</b> <b>analysis</b> {{is widely}} used to study social choice in Euclidean models ([35], [36], [1], [5], [11], [19], [7] and [4],Â e. g). This method assumes a {{continuum}} of voters distributed according to a probability measure. Since infinite populations do not exist, the goal of <b>distributional</b> <b>analysis</b> is to give an insight into the behavior of large finite populations. However, the properties of finite populations do not necessarily converge to the properties of infinite populations. Thus the method of <b>distributional</b> <b>analysis</b> is flawed. In some cases (Arrow, 1969) it will predict that a point is in the core with probability 1, while the true probability converges to 0. In other cases it can be combined with probabilistic analysis to make accurate predictions about the asymptotic behavior of large populations, as in Caplin and Nalebuff (1988). Uniform convergence of empirical measures (Pollard, 1984) is employed here to yield a simpler, more general proof of [alpha]-majority convergence, a short proof of yolk shrinkage, and suggests {{a rule of thumb}} to determine the accuracy of distribution-based predictions. The results also help clarify the mathematical underpinnings of statistical analysis of empirical voting data. Probability Euclidean preference Voting Minimax Convergence Yolk...|$|E
40|$|This paper {{presents}} the results of research devoted to one of the significant aspects of language categories, namely, their interaction. Alternativeness and antonymy are described in their interaction, the realization of which in the English language is shown through the <b>distributional</b> and contextual <b>analysis.</b> The form and variety of this interaction also reveal the diversity of alternative situations existing in reality. </p...|$|R
40|$|Abstract. This study {{provides}} new results about the probabilistic behaviour {{of a class}} of Euclidean algorithms. It proves that the asymptotic distribution of a whole class of parameters associated to these algorithms is normal. Furthermore, it precisely compares the expected properties of continued fraction expansions of real numbers and rational numbers. This paper also focuses on the basic parameter of the algorithms, the number of steps. Hensley [23] already proved that there exists a Local Limit Theorem for this parameter, {{in the case of}} the standard Euclidean algorithm. This paper provides a new proof of this fact, both more natural and more concise, and, at the same time, an extension to two other Euclidean algorithms. The whole paper is based on the so–called dynamical analysis methodology, that views an algorithm as a dynamical system and introduces tools that come from dynamical systems into analysis of algorithms. The tranfer operator of the underlying dynamical system then plays a fundamental rôle, together with various other tools: Dirichlet series, Perron’s formula, the Quasi-Powers theorem, saddle point method. Furthermore, this work introduces, for the first time, a new facet in dynamical <b>analysis,</b> <b>distributional</b> dynamical <b>analysis,</b> and it needs precise estimates on the transfer operators when the parameter varies along vertical complex lines. Such estimates are provided by adapting to the Euclidean context powerful methods due to Dolgopyat [15]. 1...|$|R
40|$|This thesis {{explores the}} {{economics}} of health inequalities in the English National Health Service (NHS). It consists of five applied economic studies that explore different questions regarding socioeconomic inequalities and the NHS. It is bound together by an integrative chapter that provides the historical background to, and draws conclusions across, the body of work. The first of the five applied studies examined the financial costs that socioeconomic inequalities exact on the NHS, the second looked at socioeconomic inequalities in access to primary care, the third looked at socioeconomic inequalities in health outcomes attributable to the NHS, and the final two studies extended the established methods for the economic evaluation of health care programmes to explicitly value minimising socioeconomic health inequalities as well as maximising population health. These extended methods were termed <b>distributional</b> cost-effectiveness <b>analysis.</b> The studies found that dealing with the excess morbidity associated with socioeconomic inequalities cost the NHS approximately a fifth of its annual budget. Socioeconomic inequalities in access to and quality of primary care significantly improved from 2004 to 2011 in response to government policy to tackle these. However, socioeconomic inequalities in health outcomes stubbornly persisted over this period, by 2011 socioeconomic inequality was still associated with over 158 000 patients experiencing one or more preventable hospital admissions and almost 40 000 patients dying from causes amenable to health care. <b>Distributional</b> cost-effectiveness <b>analysis</b> methods were shown to be practically applicable in an NHS setting. This was demonstrated using a case study comparing population health programmes in which trading off between health maximisation and health inequality minimisation was necessary. The thesis provides an evidence base and practical new methods that {{should serve as a}} foundation to better understand the role of the NHS in tackling socioeconomic inequalities in health. In so doing, it also outlines an exciting programme of further research. ...|$|R
40|$|We {{carry out}} the <b>distributional</b> <b>analysis</b> of the {{geometry}} of a spacetime associated to gravitational waves propagating in a magnetic universe, obtaining their distributional curvature tensor following two different approaches. This curvature {{turns out to have}} singular parts proportional to Dirac's ± distribution...|$|E
40|$|Abstract—Sparse {{superposition}} codes with a fast adaptive successive decoder for the additive white Gaussian noise channel {{were introduced}} {{last year by}} the authors, along with presentation of reliability at rates approaching capacity. The present work presents ingredients of the <b>distributional</b> <b>analysis</b> of the decoder. I...|$|E
40|$|In {{this paper}} {{we examine the}} concept of “vulnerability ” {{within the context of}} income {{mobility}} of the poor. We test for the dynamics of vulnerable households in the UK using Waves 1 - 12 of the British Household Panel Study and find that, of three different types of risks that we test for, household-specific shocks and economy-wide aggregate shocks have the greatest impact on consumption, in comparison to shocks to the income stream. Acknowledgement 1 We are grateful to John Rigg for helpful discussions, and Elena Barcena and Guillermo Cruces for useful comments. <b>Distributional</b> <b>Analysis</b> Research Programme The <b>Distributional</b> <b>Analysis</b> Research Programme was established in 1993 with funding from the Economic and Social Research Council. It is located withi...|$|E
40|$|Figure 3 - Strict {{consensus}} cladogram of 49 taxa of Pacific platynine carabid beetles. Type species, where included, {{indicated by}} asterisks. See text for further explanation of cladistic <b>analysis.</b> <b>Distributional</b> areas of species include: As, Asia; Au, Australia; F, Fiji; HI, Hawaiian Islands; I, India including Sri Lanka; Jp, Japan; Jv, Java; NC, New Caledonia; NG, New Guinea; NZ, New Zealand; Ph, Philippine Islands; R, Rapa; Sa, Samoa; So, Solomon Islands; Sunda, Sunda Islands; T, Tahiti and Society Islands; V, Vanuatu...|$|R
40|$|In this paper, {{we propose}} a unified Bayesian {{approach}} for multivariate structured additive <b>distributional</b> regression <b>analysis</b> where inference is applicable {{to a huge}} class of multivariate response distributions, comprising continuous, discrete and latent models, and where each parameter of these potentially complex distributions is modelled by a structured additive predictor. The latter is an additive composition {{of different types of}} covariate effects e. g. nonlinear effects of continuous variables, random effects, spatial variations, or interaction effects. Inference is realised by a generic, efficient Markov chain Monte Carlo algorithm based on iteratively weighted least squares approximations and with multivariate Gaussian priors to enforce specific properties of functional effects. Examples will be given by illustrations on analysing the joint model of risk factors for chronic and acute childhood malnutrition in India and on ecological regression for German election results...|$|R
40|$|This article {{offers a}} <b>distributional</b> corpus <b>analysis</b> of the Northern Sotho noun and gender system. The aim is twofold: first, {{to assess whether}} the {{existing}} descriptions of the noun class system in Northern Sotho are corroborated by {{information provided by the}} analysis of a large electronic corpus for this language, with specific reference to singular-plural pairings, and second, to present a number of novel visualisation aids to characterise a noun class system (in a radar diagram) and a noun gender system (using a two-directional weighted representation) for Northern Sotho in particular, and for any Bantu language in general. The findings include the discovery of two new genders in Northern Sotho (i. e. class pairs 1 / 6 and 3 / 10), and also indicate that the Northern Sotho noun class system, and by extension any one for Bantu, should be seen as dynamic...|$|R
40|$|<b>Distributional</b> <b>analysis</b> {{of river}} {{discharge}} time series {{is an important}} task {{in many areas of}} hydrological engineering, including optimal design of water storage and drainage networks, management of extreme events, risk assessment for water supply, and environmental flow management, among many others. Having diverging moments, heavy-tailed power-law distributions have attracted widespread attention, especially for the modeling of the likelihood of extreme events such as floods and droughts. However, straightforward <b>distributional</b> <b>analysis</b> does not connect well with the complicated dynamics of river flows, including fractal and multifractal behavior, chaos-like dynamics, and seasonality. To better reflect river flows 2 ̆ 7 dynamics, we propose to carry out <b>distributional</b> <b>analysis</b> of river flow time series according to three 2 ̆ 2 flow seasons 2 ̆ 2 : dry, wet, and transitional. We present a concrete statistical procedure to partition river flow data into such three seasons, and fit data in these seasons using two types of distributions, power-law and lognormal. The latter distribution is a salient property of the cascade multiplicative multifractal model, which is among the best models for turbulence and rainfall. We show that while both power-law and lognormal distributions are relevant to dry seasons, river flow data in wet seasons are typically better fitted by lognormal distributions than by power-law distributions. ...|$|E
40|$|This thesis {{introduces}} a general method for incorporating the <b>distributional</b> <b>analysis</b> of textual and linguistic objects into text-to-speech (TTS) conversion systems. Conventional TTS conversion uses intermediate layers of representation {{to bridge the}} gap between text and speech. Collecting the annotated data needed to produce these intermediate layers is a far from trivial task, possibly prohibitively so for languages in which no such resources are in existence. <b>Distributional</b> <b>analysis,</b> in contrast, proceeds in an unsupervised manner, and so enables the creation of systems using textual data that are not annotated. The method therefore aids the building of systems for languages in which conventional linguistic resources are scarce, but is not restricted to these languages. The <b>distributional</b> <b>analysis</b> proposed here places the textual objects analysed in a continuous-valued space, rather than specifying a hard categorisation of those objects. This space is then partitioned during the training of acoustic models for synthesis, so that the models generalise over objects' surface forms in a way that is acoustically relevant. The method is applied to three levels of textual analysis: to the characterisation of sub-syllabic units, word units and utterances. Entire systems for three languages (English, Finnish and Romanian) are built with no reliance on manually labelled data or language-specific expertise. Results of a subjective evaluation are presented...|$|E
40|$|Two salient {{characteristics}} of spoken dialogs, {{in contrast to}} written texts, {{is that they are}} processes in time and that they are co-constructed by the interlocutors. Most current corpusbased methods for analyzing dialog phenomena, however, abstract away from these characteristics. This paper introduces a new corpus-based analysis method, temporal <b>distributional</b> <b>analysis,</b> which can reveal such aspects of dialog. Given a word of interest, this method identifies which words tend to cooccur with it at specific temporal offsets. This can be done not only for words produced by the same speaker but also for the interlocutor’s words. This paper explains the method, presents several ways to visualize the results, illustrates what it reveals about the words I, uh and uh-huh, compares it to non-temporal <b>distributional</b> <b>analysis,</b> and discusses potential applications to speech recognition, generation, and synthesis. ...|$|E
40|$|<b>Distributional</b> {{cost-effectiveness}} <b>analysis</b> (DCEA) is {{a framework}} for incorporating health inequality concerns into the economic evaluation of health sector interven-tions. In this tutorial, we describe the technical details of how to conduct DCEA, using an illustrative example com-paring alternative ways of implementing the National Health Service (NHS) Bowel Cancer Screening Programme (BCSP). The 2 key stages in DCEA are 1) modeling social distributions of health associated with different interven-tions, and 2) evaluating social distributions of health {{with respect to the}} dual objectives of improving total population health and reducing unfair health inequality. As well as describing the technical methods used, we also identify the data requirements and the social value judgments that have to be made. Finally, we demonstrate the use of sensitivity analyses to explore the impacts of alternative modeling assumptions and social value judgments. Key words: cost-effectiveness analysis; economic evaluation; efficiency; equality; equity; fairness; health distribution; health inequality; inequality measures; opportunity cost; social value judgments; social welfare functions; tradeoff. (Med Decis Making XXXX;XX:XXX–XXX...|$|R
40|$|In this paper, {{we present}} a <b>distributional</b> impact <b>analysis</b> of climate change {{policies}} envisaged or implemented to reduce greenhouse gas emissions in Senegal. We consider policies implemented in developed countries {{and their impact on}} a developing country. Moreover, we simulate the diminishing productivity of agricultural land as a potential result of climate change (CC) for Senegal. This country is exposed to the direct consequences of CC and is vulnerable to changes in world prices of energy, given its lack of substitution capacity. Past researches have shown that countries with this profile will bear the greatest burden of CC and its mitigation policies. Our results reveal slight increases in poverty when the world price of fossil fuels increases and the negative impact is further amplified with decreases in land productivity. However, subsidizing electricity consumption to protect consumers from world price increases in fossil fuels is shown to provide a weak cushion to poverty increase. © 2013 by the authors. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|In 2005, the Indonesian {{government}} {{implemented a}} massive fuel price increase. While {{the benefits of}} the reform on efficiency grounds have been widely acknowledged, there is still debate about whether the reform was equitable [...] , That question is answered in this paper using a Computable General Equilibrium (CGE) model with disaggregated households that allows for a rich and accurate <b>distributional</b> story. <b>Analysis</b> of various counter-factual scenarios analysis of the reform is carried out. It suggests that the reform could have been progressive if it increased only vehicle fuel prices. However, it tends to increase inequality especially in urban area when the price of domestic fuel (kerosene) is also increased. Proper and effective compensation is important in mitigating the distributional cost or poverty impact of the reform. A uniform cash transfer to poor households that disregards poor households’ heterogeneity tends to over-compensate the rural poor but under-compensate the urban poor. FUel pricing reform, Distribution, CGE, Indonesia...|$|R
