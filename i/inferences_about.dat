5150|1824|Public
5|$|Remote sensing of snowpacks with {{satellites}} and other platforms typically includes multi-spectral collection of imagery. Multi-faceted {{interpretation of the}} data obtained allows <b>inferences</b> <b>about</b> what is observed. The science behind these remote observations has been verified with ground-truth studies of the actual conditions.|$|E
5|$|Rachel Yuen-Collingridge and Malcolm Choat (Macquarie University) used stichometry {{along with}} other kinds of {{evidence}} to make <b>inferences</b> <b>about</b> scribal practice and copying techniques. Congrès international de papyrologie, in the series Recherches et Rencontres published by the Faculté des Lettres de l’Université de Genève, 2012, Volume 30, 827–834.|$|E
5|$|<b>Inferences</b> <b>about</b> {{behavior}} {{can also be}} drawn from examination of the inner ear. The semicircular canals within the inner ear aid in balance, and the lateral semicircular canal is usually {{parallel to the ground}} when the animal holds its head in an alert posture. When the skull of Majungasaurus is rotated so that its lateral canal is parallel to the ground, the entire skull is nearly horizontal. This contrasts with many other theropods, where the head was more strongly downturned when in the alert position. The lateral canal is also significantly longer in Majungasaurus than in its more basal relative Ceratosaurus, indicating a greater sensitivity to side-to-side motions of the head.|$|E
40|$|This paper {{considers}} nonstandard {{hypothesis testing}} problems that involve a nuisance parameter. We establish a bound on the weighted average power of all valid tests, {{and develop a}} numerical algorithm that determines a feasible test with power close to the bound. The approach is illustrated in six applications: <b>inference</b> <b>about</b> a linear regression coefficient when {{the sign of a}} control coefficient is known; small sample <b>inference</b> <b>about</b> the difference in means from two independent Gaussian samples from populations with potentially different variances; <b>inference</b> <b>about</b> the break date in structural break models with moderate break magnitude; predictability tests when the regressor is highly persistent; <b>inference</b> <b>about</b> an interval identified parameter; and <b>inference</b> <b>about</b> a linear regression coefficient when the necessity of a control is in doubt...|$|R
5000|$|Stating {{general rules}} that support <b>inference</b> <b>about</b> the concepts.|$|R
5000|$|... #Subtitle level 5: Expert <b>inference</b> <b>about</b> {{economic}} intelligence collection by the US ...|$|R
5|$|Isotope {{analysis}} {{can be used}} to allow researchers to make <b>inferences</b> <b>about</b> the diet of the species being studied. Two isotope analyses of bone collagen extracted from the remains of Late Pleistocene wolves found in Beringia and Belgium indicate that wolves from both areas preyed mainly on Pleistocene megafauna, which became rare {{at the beginning of the}} Holocene 12,000 years ago. The Beringian wolf preyed most often on horse and steppe bison. In the period leading up to the Last Glacial Maximum (50,000YBP–23,000YBP), they also ate woodland muskox, and after this time they also ate mammoth. The analysis supports the conclusion that these wolves were capable of killing and dismembering large prey.|$|E
25|$|Wood can be dated by carbon {{dating and}} in some species by {{dendrochronology}} to make <b>inferences</b> <b>about</b> when a wooden object was created.|$|E
25|$|The child uses contextual {{clues to}} draw <b>inferences</b> <b>about</b> the {{category}} {{and meaning of}} new words. By doing so, the child distinguishes between names and ordinary nouns.|$|E
50|$|Seymour Geisser (October 5, 1929 - March 11, 2004) was a {{statistician}} {{noted for}} emphasizing predictive inference. In his book Predictive Inference: An Introduction, he held that conventional statistical <b>inference</b> <b>about</b> unobservable population parameters amounts to <b>inference</b> <b>about</b> {{things that do}} not exist, following the work of Bruno de Finetti. He also pioneered the theory of cross-validation.|$|R
40|$|Abstract: Over {{the last}} two decades, philosophers, statisticians, and {{computer}} scientists have converged on the fundamental outline of a theory of causal representation and causal inference (Spirtes, Glymour, and Scheines, 2000; Pearl, 2000). Some conditions and assumptions under which reliable <b>inference</b> <b>about</b> the effects of manipulations is possible have been precisely characterized; other conditions and assumptions under which reliable <b>inference</b> <b>about</b> the effects of manipulation is impossible have also been characterized. However, the theory of <b>inference</b> <b>about</b> the effects of manipulations that has been developed does not consider the problem of “defined variables”. In causal modeling, sometimes variables are deliberately introduced as defined functions of others variables. More interestingly, sometimes two or more measured variables are deterministic functions of one another, not deliberately, but because of redundant measurements. In these cases, manipulation of an observed defined variable may actually be an ambiguous description of a manipulation of some underlying variables, although the manipulator does not {{know that this is}} the case. In this article we revisit the question of precisely characterizing conditions and assumption under which reliable <b>inference</b> <b>about</b> the effects of manipulations is possible, even when the possibility of “ambiguous manipulations ” is allowed. ...|$|R
5000|$|When the t {{labels are}} collected, {{we can make}} an <b>inference</b> <b>about</b> the {{positive}} set Ht based on posterior distribution given by St ...|$|R
25|$|First, {{dividing}} the population into distinct, independent strata can enable researchers to draw <b>inferences</b> <b>about</b> specific subgroups {{that may be}} lost in a more generalized random sample.|$|E
25|$|Experimental {{cognitive}} psychologists {{carry out}} research on reasoning behaviour. Such research may focus, for example, on how people perform on tests of reasoning such as intelligence or IQ tests, or on how well people's reasoning matches ideals set by logic (see, for example, the Wason test). Experiments examine how people make inferences from conditionals e.g., If A then B and how they make <b>inferences</b> <b>about</b> alternatives, e.g., A or else B. They test whether people can make valid deductions about spatial and temporal relations, e.g., A is {{to the left of}} B, or A happens after B, and about quantified assertions, e.g., All the A are B. Experiments investigate how people make <b>inferences</b> <b>about</b> factual situations, hypothetical possibilities, probabilities, and counterfactual situations.|$|E
25|$|Delusions do not {{necessarily}} have to be false or 'incorrect <b>inferences</b> <b>about</b> external reality'. Some religious or spiritual beliefs by their nature may not be falsifiable, and hence cannot be described as false or incorrect, no matter whether the person holding these beliefs was diagnosed as delusional or not.|$|E
40|$|Interpretation of my assignment: Describe methods {{which provide}} {{defensible}} statistical <b>inference</b> <b>about</b> shape analysis tools. Achieve success by demonstrating: 1 (outcomes reflect “truth”) Validity 2 (same shape if repeat study) Reliability 3 between methodsDifferences a) computer method A better than method B b) computer method better than human c) computer method {{as good as}} human 4 to population of interestGeneralizability 3 1. 2 Assumptions and Implications 1) Shape analysis aimed at natural objects. Implies need to draw <b>inference</b> <b>about</b> the populatio...|$|R
50|$|A PRM {{is usually}} {{developed}} {{with a set}} of algorithms for reducing, <b>inference</b> <b>about</b> and discovery of concerned distributions, which are embedded into the corresponding PRPL.|$|R
40|$|This chapter {{reviews the}} {{usefulness}} of the Kalman filter for parameter estimation and <b>inference</b> <b>about</b> unobserved variables in linear dynamic systems. Applications include exact maximum likelihood estimation of regressions with ARMA disturbances, time-varying parameters, missing observations, forming an <b>inference</b> <b>about</b> the public's expectations about inflation, and specification of business cycle dynamics. The chapter also reviews models of changes in regime and develops the parallel between such models and linear state-space models. The chapter concludes with a brief discussion of alternative approaches to nonlinear filtering. ...|$|R
25|$|The {{progress}} of Mee's research accelerated in 1981 {{as he began}} distributing tables of nine countries' currency relationships, with which he could make rapid and trustworthy calculations. It shortly became apparent, however, that the Italian data were not sufficiently dependable {{for him to make}} reliable <b>inferences</b> <b>about</b> that country's currency values.|$|E
25|$|A true {{experiment}} with random allocation of subjects to conditions allows researchers to make strong <b>inferences</b> <b>about</b> causal relationships. In an experiment, the researcher alters parameters of influence, called independent variables, and measures resulting changes of interest, called dependent variables. Prototypical experimental research is {{conducted in a}} laboratory with a carefully controlled environment.|$|E
25|$|As {{evidence}} from archaeology, thousands of artifacts from Neolithic Europe have been discovered, {{mostly in the}} form of female figurines. As a result a goddess theory has occurred. The leading historian was Marija Gimbutas, still this interpretation is a subject of great controversy in archaeology due to her many <b>inferences</b> <b>about</b> the symbols on artifacts.|$|E
50|$|The {{basic idea}} of {{bootstrapping}} is that <b>inference</b> <b>about</b> a population from sample data, (sample → population), can be modelled by resampling the sample data and performing <b>inference</b> <b>about</b> a sample from resampled data, (resampled → sample). As {{the population is}} unknown, the true error in a sample statistic against its population value is unknown. In bootstrap-resamples, the 'population' {{is in fact the}} sample, and this is known; hence the quality of inference of the 'true' sample from resampled data, (resampled → sample), is measurable.|$|R
40|$|This paper proposes {{methods for}} testing the null {{hypothesis}} {{that a number of}} so-called long run canonical correlations (LRCCs) are zero. Two test statistics are proposed and their limiting distributions are derived under {{the null hypothesis}}. The finite sample properties of the tests are illustrated via a simulation study that reveals the asymptotic theory provides a good guidance to behaviour in moderate or large sized samples. It is shown that the statistics provide a natural way for testing the asymptotic independence of two standardized sums. The usefulness of the tests is illustrated via the following examples: <b>inference</b> <b>about</b> cointegrating vector in a particular cointegration model; <b>inference</b> <b>about</b> break points in a cointegration model; moment estimation; parameter estimation in Generalized Method of Moments estimation. Key Words: Long run canonical correlations; Canonical coherences; Asymptotic independence of standardized sums; Cointegration; <b>Inference</b> <b>about</b> and based on moment conditions...|$|R
40|$|This paper {{develops}} {{procedures for}} <b>inference</b> <b>about</b> {{the moments of}} smooth functions of out of sample predictions and prediction errors, {{when there is a}} long time series of predictions and realizations, and each prediction is based on regression parameters estimated from a long time series. The aim is to provide tools for <b>inference</b> <b>about</b> predictive accuracy and efficiency, and, more generally, about predictive ability. The paper allows for nonlinear models and estimators, as well as for possible dependence of predictions and prediction errors on estimated regression parameters. Simulations indicate that the procedures work well. ...|$|R
25|$|The {{concept of}} {{prediction}} intervals {{need not be}} restricted to inference about a single future sample value but can be extended to more complicated cases. For example, {{in the context of}} river flooding where analyses are often based on annual values of the largest flow within the year, there may be interest in making <b>inferences</b> <b>about</b> the largest flood likely to be experienced within the next 50 years.|$|E
25|$|Self-perception is a {{specialized}} form of attribution that involves making <b>inferences</b> <b>about</b> oneself after observing one's own behavior. Psychologists {{have found that}} too many extrinsic rewards (e.g. money) tend to reduce intrinsic motivation through the self-perception process, a phenomenon known as overjustification. People's attention is directed to the reward and they lose interest in the task when the reward is no longer offered. This is an important exception to reinforcement theory.|$|E
25|$|<b>Inferences</b> <b>about</b> regoliths from phase curves are {{frequently}} based on Hapke parameterization. However, in a blind test M. Shepard and P. Helfenstein found no {{strong evidence that}} {{a particular set of}} Hapke parameters derived from photometric data could uniquely reveal the physical state of laboratory samples. These tests included modeling the three-term Henyey-Greenstein phase functions and the coherent backscatter opposition effect. This negative finding suggests that the radiative transfer model developed by B. Hapke may be inadequate for physical modeling based on photometry.|$|E
40|$|Data envelopment {{analysis}} (DEA) {{and free}} disposal hull (FDH) estimators {{are widely used}} to estimate efficiencies of production units. In applications, both efficiency scores for individual units as well as average efficiency scores are typically reported. While several bootstrap methods {{have been developed for}} making <b>inference</b> <b>about</b> the efficiencies of individual units, until now no methods have existed for making <b>inference</b> <b>about</b> mean efficiency levels. This paper shows that standard central limit theorems do not apply in the case of means of DEA or FDH efficiency scores due to the bias of the individual scores, which is of larger order than either the variance or covariances among individual scores. The main difficulty {{comes from the fact that}} such statistics depend on efficiency estimators evaluated at random points. Here, new central limit theorems are developed for means of DEA and FDH scores, and their efficacy for <b>inference</b> <b>about</b> mean efficiency levels is examined via Monte Carlo experiments...|$|R
40|$|We {{consider}} {{statistical analysis}} of multiple answers in a questionna-ire. We propose a new method of calculating simultaneous confidence regions. In a communication presented at the European Academy of Allergy and Clinical Immunology the authors (Borowicz et al. (2009)) reported the proportions of respondents which gave one of three po-ssible exclusive answers in a questionnaire concerning the role of vo-luntary health insurance. There were three possible answers. Apart from percentages of answers confidence intervals of every single an-swer have been reported. Unfortunately <b>inference</b> <b>about</b> the popula-tion based on such intervals may lead to imprecise conclusions. The <b>inference</b> <b>about</b> the respective population suffering from allergy and asthma proportions requires the construction of two-dimensional confidence region. We propose {{the use of a}} simultaneous confidence intervals to <b>inference</b> <b>about</b> true population proportions. Most of our attention is given to the case of three possible answers but the results may be generalized to any questionnaire with more than two excluding answers. Key words: confidence region, health insurance, multiple responses, questionnair...|$|R
25|$|The {{nature of}} the genuine danger of {{allowing}} a jury to make an inappropriate <b>inference</b> <b>about</b> the nature of such evidence has led to misunderstandings {{about the nature of}} hearsay.|$|R
25|$|No {{agreement}} using modern DNA: In 2016, a whole-genome {{study of}} wolves and dogs concluded that admixture had confounded {{the ability to}} make <b>inferences</b> <b>about</b> the place of dog domestication. Past studies based on single-nucleotide polymorphisms, genome-wide similarities with Chinese wolves, and lower linkage disequilibrium might reflect regional admixture between dogs with wolves and gene flow between dog populations, with divergent dog breeds possibly maintaining more wolf ancestry in their genome. The study proposed that the analysis of ancient DNA might be a better approach.|$|E
25|$|The goal of density {{estimation}} {{is to take}} {{a finite}} sample of data and to make <b>inferences</b> <b>about</b> the underlying probability density function everywhere, including where no data are observed. In kernel density estimation, the contribution of each data point is smoothed out from a single point into a region of space surrounding it. Aggregating the individually smoothed contributions gives an overall picture {{of the structure of the}} data and its density function. In the details to follow, we show that this approach leads to a reasonable estimate of the underlying density function.|$|E
25|$|Although Paleolithic {{cultures}} left no written records, {{the shift}} from nomadic life to settlement and agriculture can be inferred {{from a range of}} archaeological evidence. Such evidence includes ancient tools, cave paintings, and other prehistoric art, such as the Venus of Willendorf. Human remains also provide direct evidence, both through the examination of bones, and the study of mummies. Though concrete evidence is limited, scientists and historians have been able to form significant <b>inferences</b> <b>about</b> the lifestyle and culture of various prehistoric peoples, and the role technology played in their lives.|$|E
30|$|In other terms, {{the main}} problem becomes one of how to design {{structured}} data fusion strategies allowing the embedding of data linkages and synergies useful to optimize <b>inference</b> <b>about</b> diabetes.|$|R
50|$|Another {{approach}} is numerical classification, also called ordination, where soil individuals are grouped by multivariate statistical {{methods such as}} cluster analysis. This produces natural groupings without requiring any <b>inference</b> <b>about</b> soil genesis.|$|R
40|$|An asset pricing {{restriction}} {{that permits}} <b>inference</b> <b>about</b> the familiar CAPM despite the market return being unobservable is generalized to allow an observable proxy {{of the market}} return to be endogenously determined along with the individual asset returns the proxy is supposed to price. Making this allowance reduces the efciency of the proxy relative to the market return by upwards of 20 %. Such a reduction is capable of reversing an <b>inference</b> <b>about</b> {{the validity of the}} CAPM theory under the aforementioned pricing restriction. Rendering this pricing restriction feasible empirically is a new method for estimating triangular systems given GARCH errors...|$|R
