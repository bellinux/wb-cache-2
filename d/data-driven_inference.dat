25|28|Public
50|$|In {{the vast}} {{majority}} of the related literature, the number of possible latent states is considered a user-defined constant.However, ideas from nonparametric Bayesian statistics, which allow for <b>data-driven</b> <b>inference</b> of the number of states, have been also recently investigated with success, e.g.|$|E
40|$|This paper {{introduces}} the new GRASS GIS add-on module g. infer. The module enables rule-based analysis and workflow management in GRASS GIS, via <b>data-driven</b> <b>inference</b> processes {{based on the}} expert system shell CLIPS. The paper discusses the theoretical and developmental background that will help prepare the reader to use the module for Knowledge Engineering applications. In addition, potential application scenarios are sketched out, ranging from the rule-driven formulation of nontrivial GIS-classification tasks and GIS workflows to ontology management and intelligent software agents...|$|E
40|$|<b>Data-driven</b> <b>inference</b> {{is widely}} {{encountered}} in various scientific domains {{to convert the}} observed measurements into information that cannot be directly observed about a system. Despite the quickly-developing sensor and imaging technologies, in many domains, data collection remains an expensive endeavor due to financial and physical constraints. To overcome the limits in data and to reduce the demand on expensive data collection, {{it is important to}} incorporate prior information in order to place the <b>data-driven</b> <b>inference</b> in a domain-relevant context and to improve its accuracy. Two sources of assumptions have been used successfully in many inverse problem applications. One is the temporal dynamics of the system (dynamic structure). The other is the low-dimensional structure of a system (sparsity structure). In existing work, these two structures have often been explored separately, while in most high-dimensional dynamic system they are commonly co-existing and contain complementary information. In this work, our main focus is to build a robustness inference framework to combine dynamic and sparsity constraints. The driving application in this work is a biomedical inverse problem of electrophysiological (EP) imaging, which noninvasively and quantitatively reconstruct transmural action potentials from body-surface voltage data with the goal to improve cardiac disease prevention, diagnosis, and treatment. The general framework can be extended to a variety of applications that deal with the inference of high-dimensional dynamic systems...|$|E
50|$|Because {{the list}} of goals determines which rules are {{selected}} and used, this method is called goal-driven, in contrast to <b>data-driven</b> forward-chaining <b>inference.</b> The backward chaining approach is often employed by expert systems.|$|R
40|$|The {{evaluation}} {{of the performance of}} a continuous diagnostic measure is a commonly encountered task in medical research. We develop Bayesian non-parametric models that use Dirichlet process mixtures and mixtures of Polya trees for the analysis of continuous serologic data. The modelling approach differs from traditional approaches to the analysis of receiver operating characteristic curve data in that it incorporates a stochastic ordering constraint for the distributions of serologic values for the infected and non-infected populations. Biologically such a constraint is virtually always feasible because serologic values from infected individuals tend to be higher than those for non-infected individuals. The models proposed provide <b>data-driven</b> <b>inferences</b> for the infected and non-infected population distributions, and for the receiver operating characteristic curve and corresponding area under the curve. We illustrate and compare the predictive performance of the Dirichlet process mixture and mixture of Polya trees approaches by using serologic data for Johne's disease in dairy cattle. Copyright (c) 2008 Royal Statistical Society. ...|$|R
40|$|Wepresent a {{framework}} for the analysis and synthesis of acoustical instruments based on <b>data-driven</b> probabilistic <b>inference</b> modeling. Audio time series and boundary conditions of a played instrument are recorded and the non-linear mapping from the control data into the audio space is inferred using the general inference framework of Cluster-Weighted Modeling. The resulting model is used for real-time synthesis of audio sequences from new input data...|$|R
40|$|We {{describe}} a nonparametric Bayesian approach for estimating the three-way ROC surface based on mixtures of finite Polya trees (MFPT) priors. Mixtures of finite Polya trees are robust models {{that can handle}} nonstandard features in the data. We address the difficulties in modeling continuous diagnostic data with skewness, multimodality, or other nonstandard features, and how parametric approaches can lead to misleading results in such cases. Robust, <b>data-driven</b> <b>inference</b> for the ROC surface and for the volume under the ROC surface is obtained. A simulation study is performed to assess {{the performance of the}} proposed method. Methods are applied to data from a magnetic resonance spectroscopy study on human immunodeficiency virus patients...|$|E
40|$|Contextual {{information}} provides important cues for disambiguating visually similar pixels in scene segmentation. In this paper, we {{introduce a}} neuron-level Selective Context Aggregation (SCA) module for scene segmentation, comprised of a contextual dependency predictor and a context aggregation operator. The dependency predictor is implicitly trained to infer contextual dependencies between different image regions. The context aggregation operator augments local representations with global context, which is aggregated selectively at each neuron {{according to its}} on-the-fly predicted dependencies. The proposed mechanism enables <b>data-driven</b> <b>inference</b> of contextual dependencies, and facilitates context-aware feature learning. The proposed method improves strong baselines built upon VGG 16 on challenging scene segmentation datasets, which demonstrates its effectiveness in modeling context information...|$|E
40|$|Diffusion process {{models are}} widely used in science, engineering, and finance. Most {{diffusion}} processes are described by stochastic differential equations in continuous time. In practice, however, data are typically observed only at discrete time points. Except for a few very special cases, no analytic form exists for the likelihood of such discretely observed data. For this reason, parametric inference is often achieved by using discrete-time approximations, with accuracy controlled through the introduction of missing data. We present a new multiresolution Bayesian framework to address the inference difficulty. The methodology relies {{on the use of}} multiple approximations and extrapolation and is significantly faster and more accurate than known strategies based on Gibbs sampling. We apply the multiresolution approach to three <b>data-driven</b> <b>inference</b> problems, one of which features a multivariate diffusion model with an entirely unobserved component...|$|E
40|$|AbstractWe {{study the}} order in Grammatical Inference algorithms, and its {{influence}} on the polynomial (with respect to the data) identification of languages. This work is motivated by recent results on the polynomial convergence of <b>data-driven</b> grammatical <b>inference</b> algorithms. In this paper, we prove a sufficient condition that assures {{the existence of a}} characteristic sample whose size is polynomial with respect to the minimum DFA of the target language...|$|R
40|$|Chromatin is {{the driver}} of gene regulation, yet {{understanding}} the molecular interactions underlying chromatin factor combinatorial patterns (or the "chromatin codes") remains a fundamental challenge in chromatin biology. Here we developed a global modeling framework that leverages chromatin profiling data to produce a systems-level view of the macromolecular complex of chromatin. Our model ultilizes maximum entropy modeling with regularization-based structure learning to statistically dissect dependencies between chromatin factors and produce an accurate probability distribution of chromatin code. Our unsupervised quantitative model, trained on genome-wide chromatin profiles of 73 histone marks and chromatin proteins from modENCODE, enabled making various <b>data-driven</b> <b>inferences</b> about chromatin profiles and interactions. We provided a highly accurate predictor of chromatin factor pairwise interactions validated by known experimental evidence, {{and for the first}} time enabled higher-order interaction prediction. Our predictions can thus help guide future experimental studies. The model can also serve as an inference engine for predicting unknown chromatin profiles [...] we demonstrated that with this approach we can leverage data from well-characterized cell types to help understand less-studied cell type or conditions...|$|R
40|$|Abstract: Receiver {{operating}} characteristic (ROC) curves provide a graphical measure of diagnostic test accuracy. Because ROC curves are determined using the distributions of diagnostic test outcomes for noninfected and infected populations, {{there is an}} increasing trend to develop flexible models for these component distributions. We present methodology for joint nonparametric estimation of several ROC curves from multivariate serologic data. We develop an empirical Bayes approach that allows for arbitrary noninfected and infected component distributions that are modelled using Bayesian multivariatemixtures of finite Polya trees priors. Robust, <b>data-driven</b> <b>inferences</b> for ROC curves and the area under the curve are obtained, and a straightforward method for testing a Dirichlet process versus a more general Polya tree model is presented. Computational challenges can arise when using Polya trees to model large multivariate data sets that exhibit clustering. We discuss and implement practical procedures for addressing these obstacles, which are applied to bivariate data {{used to evaluate the}} performances of two ELISA tests for detection of Johne’s disease. Key words: Bayesian nonparametrics; diagnostic test evaluation; empirical Baye...|$|R
40|$|This paper {{studies the}} issues of {{designing}} a Bayesian framework for the reliable diagnosis of various yield-loss factors induced in semiconductor manufacturing. The proposed framework integrates both the results from knowledge-based and <b>data-driven</b> <b>inference</b> tools as input data, where the former resembles expert’s knowledge on diagnosing pre-known yield-loss factors while the latter serves for exploring new yield-loss factors. Three modules with specific designs for yield diagnosis applications are addressed: Pre-Process for generating candidate factors and corresponding prior distributions, Bayesian Inference for calculating posterior distributions, and Post-Process for deriving reliable rankings of candidate factors. The final output, a Bubble Diagram with Pareto Frontier, provides visual interpretations on the integral results from data-driven, knowledge-based and Bayesian inference tools. Specific issues addressed in the proposed Bayesian framework provide directions for implementing a real system. ...|$|E
40|$|Inferences on {{subsurface}} {{temperatures in}} geothermal studies, based on sparse datasets and modelling, contain many sources of significant uncer tainty. Further, a problem arises {{in the scale}} of computation needed for <b>data-driven</b> <b>inference</b> when an inversion is posed on geodynamical constraints, such as heat flow over basins or systems of basins. Here we outline an approach to understanding the sensitivity in model parameters in a forward modelling suite of a basin-scale geothermal problem, which allows the fundamental controlling parameters in the problem to be identified and constrained. We have been improving this approach and making our implementations much more readily available to the community. An example of this approach was first done for the Sydney Gunnedah basin model. We've extended this work with updates to the method implementation and extrapolations to include the Bowen basin. 1 page(s...|$|E
40|$|Abstract: Software agent {{technology}} has matured {{enough to produce}} intelligent agents, {{which can be used}} to control a large number of Concurrent Engineering tasks. Multi-Agent Systems (MAS) are communities of agents that exchange information and data in the form of messages. The agents’ intelligence can range from rudimentary sensor monitoring and data reporting, to more advanced forms of decision-making and autonomous behaviour. The behaviour and intelligence of each agent in the community can be obtained by performing Data Mining on available application data and the respected knowledge domain. We have developed Agent Academy (AA), a software platform for the design, creation, and deployment of MAS, which combines the power of knowledge discovery algorithms with the versatility of agents. Using this platform, we illustrate how agents, equipped with a <b>data-driven</b> <b>inference</b> engine, can be dynamically and continuously trained. We also discuss thre...|$|E
40|$|Diagnosis and {{prognosis}} {{of potential}} faults {{is crucial to}} maintain and improve {{the efficiency of the}} wind energy system. In this paper, we propose a SCADA-based condition monitoring and prognostics system. We apply particle swarm optimization to recognize different patterns of turbine health condition by fusing performance test results. As monitoring daily turbine health condition, we design a <b>data-driven</b> Bayesian <b>inference</b> approach to predict turbine potential failures by tracking the abnormal variations. 1...|$|R
40|$|Many {{systems are}} {{partially}} stochastic in nature. We have derived data driven approaches for extracting stochastic state machines (Markov models) directly from observed data. This chapter {{provides an overview}} of our approach with numerous practical applications. We have used this approach for inferring shipping patterns, exploiting computer system side-channel information, and detecting botnet activities. For contrast, we include a related <b>data-driven</b> statistical <b>inferencing</b> approach that detects and localizes radiation sources. Comment: Accepted by 2017 International Symposium on Sensor Networks, Systems and Securit...|$|R
40|$|A {{major problem}} in {{robotics}} vision is the segmentation of images of natural scenes {{in order to understand}} their content. This thesis presents a new solution to the image segmentation problem that is based on the design of a rule-based expert system. General knowledge about low level properties of an image is formulated into production rules. A number of processes employ the rules to segment the image into uniform regions and connected lines. In addition to the knowledge rules, a set of control rules are also employed. These include meta-rules that embody inferences about the order in which the knowledge rules are matched. They also include focus of attention rules that determine the path of processing within the image. A third set of rules contains the strategy rules which are <b>data-driven</b> <b>inferences</b> about the control rules. They dynamically modify the processing strategy. Different rule ordering and focus of attention strategies are selected according to a set of performance parameters. These measure the quality of the segmentation output at any point in time. Experiments with the knowledge rules resulted in an optimal set based on output quality and processing efficiency. Overall system performance is shown to be qualitatively and quantitatively superior to previous segmentation algorithms...|$|R
40|$|The aim of {{this study}} is to provide an {{automatic}} computational framework to assist clinicians in diagnosing Focal Liver Lesions (FLLs) in Contrast-Enhancement Ultrasound (CEUS). We represent FLLs in a CEUS video clip as an ensemble of Region-of-Interests (ROIs), whose locations are modeled as latent variables in a discriminative model. Different types of FLLs are characterized by both spatial and temporal enhancement patterns of the ROIs. The model is learned by iteratively inferring the optimal ROI locations and optimizing the model parameters. To efficiently search the optimal spatial and temporal locations of the ROIs, we propose a <b>data-driven</b> <b>inference</b> algorithm by combining effective spatial and temporal pruning. The experiments show that our method achieves promising results on the largest dataset in the literature (to the best of our knowledge), which we have made publicly available. Comment: 5 pages, 1 figure...|$|E
40|$|Abstract — In this paper, we {{demonstrate}} <b>data-driven</b> <b>inference</b> {{of mechanical}} properties of objects using a tactile sensor array (skin) covering a robot’s forearm. We {{focus on the}} mobility (sliding vs. fixed), compliance (soft vs. hard), and identity of objects in the environment, as this information could be useful for efficient manipulation and search. By using the large surface area of the forearm, a robot could potentially search and map a cluttered volume more efficiently, and be informed by incidental contact during other manipulation tasks. Our approach tracks a contact region on the forearm over {{time in order to}} generate time series of select features, such as the maximum force, contact area, and contact motion. We then process and reduce the dimensionality of these time series to generate a feature vector to characterize the contact. Finally, we use the k-nearest neighbor algorithm (k-NN) to classify a new feature vector based on a set of previously collected feature vectors. Our results show a high cross-validation accuracy in both classification of mechanical properties and object recognition. In addition, we analyze the effect of taxel resolution, duration of observation, feature selection, and feature scaling on the classification accuracy. I...|$|E
40|$|We {{would like}} to thank Bruce Lehmann, Richard Roll, and seminar {{participants}} at UCLA and UCSD for comments on the paper. The authors are grateful to QuantMetrics R&D Associates, LLC of San Diego, California for making available its proprietary patent pending Reality Check software algorithms. Dangers of <b>Data-Driven</b> <b>Inference</b> Economics is primarily a non-experimental science. Typically, we cannot generate new data sets on which to test hypotheses independently of the data that may have led to a particular theory. The common practice of using the same data set to formulate and test hypotheses introduces data-snooping biases that, if not accounted for, invalidate the assumptions underlying classical statistical inference. A striking example of a datadriven discovery is the presence of calendar effects in stock returns. There appears to be very substantial evidence of systematic abnormal stock returns related to the day of the week, the week of the month, the month of the year, the turn of the month, holidays, and so forth. However, this evidence has largely been considered without accounting for the intensive search preceding it. In this paper we use 100 years of daily data and a ne...|$|E
40|$|In {{this paper}} {{we present a}} new {{approach}} to plan understanding that explains observed actions in terms of domain knowledge. The process operates over hierarchical methods and utilizes an incremental form of <b>data-driven</b> abductive <b>inference.</b> We report experiments on problems from the Monroe corpus that demonstrate a basic ability to construct plausible explanations, graceful degradation of performance with reduction of the fraction of actions observed, and results with incremental processing that are comparable to batch interpretation. We also discuss research on related tasks such as plan recognition and abductive construction of explanations...|$|R
40|$|Granger {{causality}} is {{a statistical}} notion of causal influence based on prediction via vector autoregression. Developed originally {{in the field}} of econometrics, it has since found application in a broader arena, particularly in neuroscience. More recently transfer entropy, an information-theoretic measure of time-directed information transfer between jointly dependent processes, has gained traction in a similarly wide field. While it has been recognized that the two concepts must be related, the exact relationship has until now not been formally described. Here we show that for Gaussian variables, Granger causality and transfer entropy are entirely equivalent, thus bridging autoregressive and information-theoretic approaches to <b>data-driven</b> causal <b>inference.</b> Comment: In review, Phys. Rev. Lett., Nov. 200...|$|R
40|$|Abstract. This article {{introduces}} three Stata {{commands to}} conduct “robust” <b>data-driven</b> statistical <b>inference</b> in the regression-discontinuity (RD) design. First, we present the command rdrobust that implements the robust bias-corrected confidence intervals for sharp RD treatment effects proposed in Calonico, Cattaneo, and Titiunik (2012). This command also implements other conventional nonparametric RD treatment-effect point estimators and confidence intervals. Second, {{we describe the}} companion command rdbwselect, which implements several bandwidths selectors proposed in the RD literature. Third, we introduce the command rdbinselect, which implements a novel data-driven optimal choice of evenly-spaced bins using the results in Cattaneo and Farrell (2012). This command employs the resulting optimal bins to approximate the underlying regression functions by local sample means and construct the familiar RD plots usually found in empirical applications...|$|R
40|$|We {{present a}} <b>data-driven</b> <b>inference</b> method that can {{synthesize}} a photorealistic texture map {{of a complete}} 3 D face model given a partial 2 D view of {{a person in the}} wild. After an initial estimation of shape and low-frequency albedo, we compute a high-frequency partial texture map, without the shading component, of the visible face area. To extract the fine appearance details from this incomplete input, we introduce a multi-scale detail analysis technique based on mid-layer feature correlations extracted from a deep convolutional neural network. We demonstrate that fitting a convex combination of feature correlations from a high-resolution face database can yield a semantically plausible facial detail description of the entire face. A complete and photorealistic texture map can then be synthesized by iteratively optimizing for the reconstructed feature correlations. Using these high-resolution textures and a commercial rendering framework, we can produce high-fidelity 3 D renderings that are visually comparable to those obtained with state-of-the-art multi-view face capture systems. We demonstrate successful face reconstructions {{from a wide range of}} low resolution input images, including those of historical figures. In addition to extensive evaluations, we validate the realism of our results using a crowdsourced user study...|$|E
40|$|We {{show that}} results in the recent strand of the {{literature}} that tries to explain stock returns by weather induced mood shifts of investors might be <b>data-driven</b> <b>inference.</b> More specifically, we consider two recent studies (Kamstra, Kramer and Levi, 2003 a and Cao and Wei, 2004) that claim that a seasonal anomaly in stock returns is caused by mood changes of investors {{due to lack of}} daylight and temperature variations, respectively. We confirm earlier results in the literature that there is indeed a strong seasonal effect in stock returns in many countries: stock market returns tend to be significantly lower during summer and fall months than during winter and spring months. However, we also show that at best, these two studies offer two of many possible explanations for the observed seasonal effect. As an illustration we link ice cream production and airline travel to the stock market seasonality using similar reasoning. Our results suggest that without any further evidence the correlation between weather variables and stock returns might be spurious and the conclusion that weather affects stock returns through mood changes of investors is premature. temperature;seasonal affective disorder;sell in May;spurious correlations;stock market seasonality...|$|E
40|$|Control {{algorithms}} {{combined with}} microfluidic devices and microscopy have enabled in vivo real-time control of protein expression in synthetic gene networks. Most control algorithms {{rely on the}} a priori availability of mathematical models of the gene networks to be controlled. These models are typically black/grey box models, which can be obtained {{through the use of}} data-driven techniques developed in the context of systems identification. <b>Data-driven</b> <b>inference</b> of both model structure and parameters is the main focus of this paper. There are two main challenges associated with the inference of dynamical models for real-time control of gene regulatory networks in living cells. Since biological systems are typically evolving over time, the first challenge {{stems from the fact that}} model selection needs to be done online, which prevents the application of computationally expensive identification algorithms iterating through large amounts of streaming data. The second challenge consists in performing nonlinear model selection, which is typically too burdensome for Kalman filtering related techniques due the heterogeneity and nonlinearity of the candidate models. In this paper, we combine sparse Bayesian techniques with classic Kalman filtering techniques to tackle these challenge...|$|E
40|$|Abstract. In this paper, {{we propose}} a {{so-called}} AutoGate algorithm for fast and automatic Doppler gate localization in B-mode echocardiography. The algorithm has two components: 1) cardiac standard view classification and 2) gate location inference. For cardiac view classification, we incorporate the probabilistic boosting network (PBN) principle to local-structure-dependent object classification, which speeds up the processing {{time as it}} breaks down the computational dependency {{on the number of}} classes. The gate location is computed using a <b>data-driven</b> shape <b>inference</b> approach. Online clinical evaluation was performed by integrating the algorithm to a real machine. Experiment results show that the proposed algorithm performs very comparable to expert manual gate placement. To the best of our knowledge, this is the first to provide a feasible solution to automate the Doppler gate placement in real time environment. ...|$|R
40|$|We {{present a}} {{framework}} for the analysis and synthesis of acoustical instruments based on <b>data-driven</b> probabilistic <b>inference</b> modeling. Audio time series and boundary conditions of a played instrument are recorded and the non-linear mapping from the control data into the audio space is inferred using the general inference framework of Cluster-Weighted Modeling. The resulting model is used for real-time synthesis of audio sequences from new input data. 1 Introduction Most of today's musical synthesis is based on either sampling acoustical instruments [Massie, 1998] or detailed first-principles physical modeling [Smith, 1992]. The sampling approach typically results in high sound quality, but has no notion of the instrument as a dynamic system with variable control. The physical modeling approach retains this dynamic control but results in intractably large models when all the physical degrees of freedom are considered. The search for {{the right combination of}} model parameters is difficul [...] ...|$|R
40|$|This article {{gives an}} {{introduction}} to the R package rdrobust. This package includes three main functions to conduct robust <b>data-driven</b> statistical <b>inference</b> in regressiondiscontinuity (RD) designs. The first and main function, rdrobust, implements conventional nonparametric RD treatment-effect point estimators and confidence intervals, as well as the robust bias-corrected confidence intervals proposed in Calonico, Cattaneo, and Titiunik (2013 c) for local average treatment effects. This function covers sharp RD, sharp kink RD, fuzzy RD and fuzzy kink RD designs, among other possibilities. The second function, rdbwselect, implements several bandwidth selectors proposed in the RD literature. Finally, the third function, rdbinselect, implements a novel data-driven optimal choice of evenly-spaced bins, employs the resulting optimal bins to approximate the underlying regression functions by local sample means, and constructs the familiar RD plots usually found in empirical applications. A companion Stata package is described in Calonico, Cattaneo, and Titiunik (2013 b). Preliminary and incomplete, comments welcom...|$|R
40|$|Deep {{generative}} models (DGMs) {{have brought}} about a major breakthrough, as well as renewed interest, in generative latent variable models. However, an issue current DGM formulations do not address concerns the <b>data-driven</b> <b>inference</b> {{of the number of}} latent features needed to represent the observed data. Traditional linear formulations allow for addressing this issue by resorting to tools from the field of nonparametric statistics: Indeed, nonparametric linear latent variable models, obtained by appropriate imposition of Indian Buffet Process (IBP) priors, have been extensively studied by the machine learning community; inference for such models can been performed either via exact sampling or via approximate variational techniques. Based on this inspiration, in this paper we examine whether similar ideas from the field of Bayesian nonparametrics can be utilized in the context of modern DGMs in order to address the latent variable dimensionality inference problem. To this end, we propose a novel DGM formulation, based on the imposition of an IBP prior. We devise an efficient Black-Box Variational inference algorithm for our model, and exhibit its efficacy in a number of semi-supervised classification experiments. In all cases, we use popular benchmark datasets, and compare to state-of-the-art DGMs...|$|E
40|$|We {{show that}} results in the recent strand of the literature, which tries to explain stock returns by weather induced mood shifts of investors, might be <b>data-driven</b> <b>inference.</b> More specifically, we {{consider}} two recent studies [Kamstra, Mark J., Kramer, Lisa A., Levi, Maurice D., 2003 a. Winter blues: A SAD stock market cycle. American Economic Review 93 (1), 324 - 343; Cao, Melanie, Wei, Jason, 2005. Stock market returns: A note on temperature anomaly. Journal of Banking and Finance 29 (6), 1559 - 1573] that claim that a seasonal anomaly in stock returns is caused by mood changes of investors {{due to lack of}} daylight and temperature variations, respectively. While we confirm earlier results in the literature that there is indeed a strong seasonal effect in stock returns in many countries: stock market returns tend to be significantly lower during summer and fall months than during winter and spring months as documented by Bouman and Jacobsen [Bouman, Sven, Jacobsen, Ben, 2002. The Halloween indicator, Sell in May and go away: Another puzzle. American Economic Review, 92 (5), 1618 - 1635], there is little evidence in favor of a SAD or temperature explanation. In fact, we find that a simple winter/summer dummy best describes this seasonality. Our results suggest that without any further evidence the correlation between weather-related variables and stock returns might be spurious and the conclusion that weather affects stock returns through mood changes of investors is premature. ...|$|E
40|$|ABSTRACT Inference of the insulin {{secretion}} rate (ISR) from C-peptide measurements as a quantification of pancreatic b-cell {{function is}} clinically important in diseases related to reduced insulin sensitivity and insulin action. ISR derived from C-peptide concentration {{is an example}} of nonparametric Bayesian model selection where a proposed ISR time-course {{is considered to be a}} ‘‘model’’. An inferred value of inaccessible continuous variables from discrete observable data is often problematic in biology and medicine, because it is a priori unclear how robust the inference is to the deletion of data points, and a closely related question, how much smoothness or continuity the data actually support. Predictions weighted by the posterior distribution can be cast as functional integrals as used in statistical field theory. Functional integrals are generally difficult to evaluate, especially for nonanalytic constraints such as positivity of the estimated parameters. We propose a computationally tractable method that uses the exact solution of an associated likelihood function as a prior probability distribution for a Markov-chain Monte Carlo evaluation of the posterior for the full model. As a concrete application of our method, we calculate the ISR from actual clinical C-peptide measurements in human subjects with varying degrees of insulin sensitivity. Our method demonstrates the feasibility of functional integral Bayesian model selection as a practical method for such <b>data-driven</b> <b>inference,</b> allowing the data to determine the smoothing timescale and the width of the prior probability distribution on the space of models. In particular, our mode...|$|E
40|$|CADRE is {{a system}} for the {{detection}} of complex events in relational data. It implements a form of abductive reasoning that combines <b>data-driven</b> and pattern-driven <b>inferencing</b> to efficiently search for matches in massive amounts of data. It has been applied to a number of pattern detection problems, most notably to the problem of threat detection in massive amounts of data. This paper describes the details of CADRE processing and compares CADRE with other systems for abductive inference. We show that CADRE has unique features that make it especially suitable for the problem of pattern detection in very large relational databases. CADRE: Continuous Analysis and Discovery from Relational Evidenc...|$|R
40|$|In {{performing}} morpho-phonological sequence processing tasks, such as letterphoneme conversion or morphological analysis, it {{is typically}} {{not enough to}} base the output sequence on local decisions that map local-context input windows to single output tokens. We present a global sequence-processing method that repairs inconsistent local decisions. The approach is based on local predictions of overlapping trigrams of output tokens, which open up a space of possible sequences; a <b>data-driven</b> constraint satisfaction <b>inference</b> step then searches for the optimal output sequence. We demonstrate significant improvements in terms of word accuracy on English and Dutch letter-phoneme conversion and morphological segmentation, and we provide qualitative analyses of error types prevented by the constraint satisfaction inference method. ...|$|R
40|$|This study {{focus on}} the {{implementation}} of datadriven multi-layer fuzzy in welfare disbursement based on the only data source available which human expert knowledge. The proposed study is designed to determine the welfare candidate eligibility. This study highlights on welfare distribution to the new urban poor household which is categorized into three multidimensional classes namely, the needy, poor and non-poor. Firstly this study highlights on {{the establishment of the}} data-driven expert system which is the human expert knowledge in welfare and the experts’ analytical steps. The welfare data collected from households is analysed using descriptive statistics. The study demonstrates the accuracy of the analysis for welfare eligibility of new urban poor using <b>data-driven</b> multi-layer fuzzy <b>inference</b> system compared to the domain human experts...|$|R
