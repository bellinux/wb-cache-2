20|7|Public
25|$|At the Berlin Radio Show in August 1931, Manfred von Ardenne gave {{a public}} {{demonstration}} {{of a television}} system using a CRT for both transmission and reception. However, Ardenne had not developed a camera tube, using the CRT instead as a <b>flying-spot</b> <b>scanner</b> to scan slides and film. Philo Farnsworth gave the world's first public demonstration of an all-electronic television system, using a live camera, at the Franklin Institute of Philadelphia on August 25, 1934, and for ten days afterwards.|$|E
2500|$|Herbert E. Ives and Frank Gray of Bell Telephone Laboratories gave a {{dramatic}} demonstration of mechanical television on April 7, 1927. The reflected-light television system included both {{small and large}} viewing screens. The small receiver had a two-inch-wide by 2.5-inch-high screen. The large receiver had a screen 24inches wide by 30inches high. Both sets were capable of reproducing reasonably accurate, monochromatic moving images. Along with the pictures, the sets also received synchronized sound. The system transmitted images over two paths: first, a copper wire link from Washington to New York City, then a radio link from Whippany, New Jersey. Comparing the two transmission methods, viewers noted no difference in quality. Subjects of the telecast included Secretary of Commerce Herbert Hoover. A <b>flying-spot</b> <b>scanner</b> beam illuminated these subjects. The scanner that produced the beam had a 50-aperture disk. The disc revolved {{at a rate of}} 18 frames per second, capturing one frame about every 56 milliseconds. (Today's systems typically transmit 30 or 60 frames per second, or one frame every 33.3 or 16.7 milliseconds respectively.) Television historian Albert Abramson underscored the significance of the Bell Labs demonstration: [...] "It was in fact the best demonstration of a mechanical television system ever made to this time. It would be several years before any other system could even begin to compare with it in picture quality." ...|$|E
5000|$|... #Caption: The first {{image of}} {{the far side of}} the Moon, {{transmitted}} back to Earth using a <b>flying-spot</b> <b>scanner</b> by Luna 3 ...|$|E
50|$|Telecines {{that use}} a {{monochrome}} CRT {{as the light}} source {{can be referred to}} as <b>flying-spot</b> <b>scanners.</b> The advantage of the FSS technique is that as colour analysis is done after scanning; simple dichroics may be used to split the light to each photomultiplier —and there are no registration errors, as would have been introduced by early electronic cameras.|$|R
25|$|Photomultipliers {{are used}} in {{numerous}} medical equipment designs. For example, blood analysis devices used by clinical medical laboratories, such as flow cytometers, utilize photomultipliers to determine the relative concentration of various components in blood samples, in combination with optical filters and incandescent lamps. An array of photomultipliers is used in a gamma camera. Photomultipliers are typically used as the detectors in <b>flying-spot</b> <b>scanners.</b>|$|R
50|$|Historically, <b>flying-spot</b> <b>scanners</b> {{were also}} used as {{primitive}} live-action studio cameras {{at the dawn of}} electronic television, in the 1920s.A projector equipped with a spinning perforated Nipkow disc created the spot that scanned the stage. Scanning a subject this way required a completely dark stage, and was impractical for production use, but gave early researchers a way to generate live images before practical imaging pickup tubes were perfected.|$|R
50|$|A <b>flying-spot</b> <b>scanner</b> (FSS) uses a {{scanning}} {{source of}} a spot of light, such as a high-resolution, high-light-output, low-persistence cathode ray tube (CRT), to scan an image. Usually the image to be scanned is on photographic film, such as motion picture film, or a slide or photographic plate. The output of the scanner is usually a television signal.|$|E
50|$|The system's opening {{was inaugurated}} by the Minister of Posts Paul von Eltz-Rübenach in Berlin on March 1, 1936, who viewed {{and spoke with}} Leipzig's chief burgomaster. It {{employed}} a Nipkow disk <b>flying-spot</b> <b>scanner</b> for its transmitter, and a cathode ray display tube with (an initial) resolution of 150 lines at its receiving-end videophone booth. The same coaxial cables were also used to distribute television programming.|$|E
5000|$|The [...] "Mark" [...] {{series was}} then {{replaced}} by the Ursa (1989), the first in their line of telecines capable of producing digital data in 4:2:2 color space. The Ursa Gold (1993) stepped this up to 4:4:4 and then the Ursa Diamond (1997), which incorporated many third-party improvements on the Ursa system. Cintel's C-Reality and ITK's Millennium <b>flying-spot</b> <b>scanner</b> {{are able to do}} both HD and Data.|$|E
50|$|The {{problem with}} <b>flying-spot</b> <b>scanners</b> was the {{difference}} in frequencies between television field rates and film frame rates. This was solved first by the Mk. I Polygonal Prism system, which was optically synchronised to the television frame rate by the rotating prism and could be run at any frame rate. This {{was replaced by the}} Mk. II Twin Lens, and then around 1975, by the Mk. III Hopping Patch (jump scan). The Mk. III series progressed from the original “jump scan” interlace scan to the Mk. IIIB which used a progressive scan and included a digital scan converter (Digiscan) to output interlaced video. The Mk. IIIC was the most popular of the series and used a next generation Digiscan plus other improvements.|$|R
40|$|The primary {{research}} {{interest of}} this group is in the real-time acquisition and pro-cessing of visual information for display to the visual and nonvisual senses, and in the psychology of human utilization of such information, for both communication and control. The motivation is an interest in human capabilities for information processing and in human information requirements. Applications include sensory-aids systems for the blind and the blind-deaf, picture-transmission systems, and special information-display systems for enhancement of human performance under conditions of stress. Major projects now in progress include studies on reading machines, picture pro-cessing, pattern recognition, and automatic processing of visual data of significance in studies of biology and medicine. 1. Reading Machine Studies Research {{during the past few}} years in the Cognitive Information Processing Group of the Research Laboratory of Electronics has led to the construction and operation of an experimental reading system for the blind. In its present configuration the system consists of a document-handling carriage, a <b>flying-spot</b> opaque <b>scanner,</b> a digital scan...|$|R
5000|$|The {{earliest}} {{video cameras}} were mechanical <b>flying-spot</b> <b>scanners</b> {{which were in}} use in the 1920s and 1930s {{during the period of}} mechanical television. Improvements in video camera tubes in the 1930s ushered in the era of electronic television. Earlier, cameras were very large devices, almost always in two sections. The camera section held the lens and tube pre-amplifiers and other necessary electronics, and was connected to a large diameter multicore cable to the remainder of the camera electronics, usually mounted in a separate room in the studio, or a remote truck. The camera head could not generate a video picture signal on its own. The video signal was output to the studio for switching and transmission. By the fifties, electronic miniaturization had progressed to the point where some monochrome cameras could operate stand alone and even be handheld. But the studio configuration remained, with the large cable bundle transmitting the signals back to the camera control unit (CCU). The CCU in turn was used to align and operate the camera's functions, such as exposure, system timing, video and black levels.The first color cameras (1950s in the US, early 1960s in Europe), notably the RCA TK-40/41 series, were much more complex with their three (and in some models four) pickup tubes, and their size and weight drastically increased. Handheld color cameras did not come into general use until the early 1970s - the first generation of cameras were split into a camera head unit (the body of the camera, containing the lens and pickup tubes, and held on the shoulder or a body brace in front of the operator) connected via a cable bundle to a backpack CCU. The Ikegami HL-33, the RCA TK45 and the Thomson Microcam were portable two piece color cameras introduced in the early 1970s. For field work a separate VTR was still required to record the camera's video output. Typically this was either a portable 1" [...] reel to reel VTR, or a portable 3/4" [...] U-matic VCR. Typically, the two camera units would be carried by the camera operator, while a tape operator would carry the portable recorder. With the introduction of the RCA TK76 in 1976, camera operators were finally able to carry on their shoulders a one piece camera containing all the electronics to output a broadcast quality composite video signal. A separate videotape recording unit was still required.|$|R
50|$|At the Berlin Radio Show in August 1931, Manfred von Ardenne gave {{a public}} {{demonstration}} {{of a television}} system using a CRT for both transmission and reception. However, Ardenne had not developed a camera tube, using the CRT instead as a <b>flying-spot</b> <b>scanner</b> to scan slides and film. Philo Farnsworth gave the world's first public demonstration of an all-electronic television system, using a live camera, at the Franklin Institute of Philadelphia on August 25, 1934, and for ten days afterwards.|$|E
50|$|At the Berlin Radio Show in August 1931, Ardenne {{gave the}} world's first public {{demonstration}} {{of a television}} system using a cathode ray tube for both transmission and reception. (Ardenne never developed a camera tube, using the CRT instead as a <b>flying-spot</b> <b>scanner</b> to scan slides and film.) Ardenne achieved his first transmission of television pictures on 24 December 1933, followed by test runs for a public television service in 1934. The world's first electronically scanned television service then started in Berlin in 1935, culminating in the live broadcast of the 1936 Summer Olympic Games from Berlin to public places all over Germany.|$|E
5000|$|A {{series of}} systems were {{developed}} {{for use in}} the 1960, 1970, 1980 and 1990 U.S. census. The first system, delivered in 1954 used vacuum tubes and analog processing. Later versions used software control with a PDP-11 minicomputer. FOSDIC used a <b>flying-spot</b> <b>scanner</b> to detect marks on forms that had previously been photographed on microfilm. Other applications included digitizing unemployment data, EPA Pollutant charts, NOAA Underwater current meter records and [...] The U.S. Postal Research Laboratory used a surplus FOSDIC system to make high resolution images of dead-letter mail to create a data base for evaluating character-recognition techniques ...|$|E
50|$|Some EVR films had a {{separate}} chroma track {{in place of}} the opposite-direction monochrome track for color EVR films. The images stored on an EVR film were visible frames much like motion picture film, and were read by a <b>flying-spot</b> <b>scanner</b> inside an EVR player to be converted to a video signal to be sent to a television set. EVR was also released by CBS as a professional version for television broadcasting, called BEVR (Broadcast EVR). As a professional medium, the format offered extremely high quality. It was, however, quickly superseded by professional and consumer magnetic tape formats.|$|E
5000|$|However, Vitascan cameras only worked indoors, due to Vitascan {{being in}} essence a <b>flying-spot</b> <b>scanner</b> based system. The system's camera {{basically}} worked in reverse by projecting a {{light through the}} camera's lens onto the subject from a cathode ray tube, or CRT, mounted behind the lens (instead of a pickup tube like conventional television cameras), providing the [...] "flying spot". Four photomultiplier tubes (two for red, one for green, and one for blue) mounted inside special [...] "scoops" [...] placed {{in the studio and}} pointed at the subject would pick up the light from the camera's CRT and produce the final image to be televised.|$|E
50|$|The flying-spot store used a {{photographic}} plate as the store of binary data. Each {{spot on the}} plate was an opaque (logical 0) or transparent (logical 1) area that stored one bit. Spots were read and written with an optical mechanism with an access time of ca. one microsecond. The optical system consisted of a cathode ray tube that functioned as a <b>flying-spot</b> <b>scanner,</b> the source of light beams produced on its face and focused onto the photographic plates with a system of lenses. A photomultiplier detected the light beam. The light beam could be split into several components to read multiple plates simultaneously, permitting {{the formation of a}} group of bits for each location.|$|E
50|$|In the United Kingdom, Rank Precision Industries was {{experimenting with}} the <b>flying-spot</b> <b>scanner</b> (FSS), which {{inverted}} the {{cathode ray tube}} (CRT) concept of scanning using a television screen. The CRT emits a pixel-sized electron beam which is converted to a photon beam through the phosphors coating the envelope. This dot of light is then focused by a lens onto the film's emulsion, and finally collected by a pickup device. In 1950 the first Rank flying spot monochrome telecine was installed at the BBC's Lime Grove Studios. The advantage of the FSS is that colour analysis is done after scanning, so {{there can be no}} registration errors as can be produced by vidicon tubes where scanning is done after colour separation—it also allows simpler dichroics to be used.|$|E
5000|$|<b>Flying-spot</b> <b>scanner</b> {{technology}} was later implemented by DuMont Laboratories in the Vitascan color television system, released in 1956. Vitascan produced NTSC color video using a [...] "camera" [...] that acted in reverse by housing the flying-spot CRT which was projected through the [...] "camera"'s lens and illuminated {{the subject in}} a special light-tight studio. The light from the CRT [...] "camera" [...] was then picked up by special [...] "scoops" [...] housing 4 photomultiplier tubes (2 for red, 1 for green, and 1 for blue), which then would provide video of the talent in the studio. Unlike earlier FSS systems that relied on the studio being entirely darkened, Vitascan used a special strobe light would illuminate the studio for the talent's convenience, and would turn on during the photomultiplier scoop's blanking interval pulses, {{so as not to}} interfere with the scanning.|$|E
5000|$|At the Berlin Radio Show in August 1931, Manfred von Ardenne gave {{a public}} {{demonstration}} {{of a television}} system using a CRT for both transmission and reception. However, Ardenne had not developed a camera tube, using the CRT instead as a <b>flying-spot</b> <b>scanner</b> to scan slides and film. Philo Farnsworth gave the world's first public demonstration of an all-electronic television system, using a live camera, at the Franklin Institute of Philadelphia on 25 August 1934, and for ten days afterwards. Mexican inventor Guillermo González Camarena also {{played an important role}} in early TV. His experiments with TV (known as telectroescopía at first) began in 1931 and led to a patent for the [...] "trichromatic field sequential system" [...] color television in 1940. In Britain, the EMI engineering team led by Isaac Shoenberg applied in 1932 for a patent for a new device they dubbed [...] "the Emitron", which formed the heart of the cameras they designed for the BBC. On 2 November 1936, a 405-line broadcasting service employing the Emitron began at studios in Alexandra Palace, and transmitted from a specially built mast atop one of the Victorian building's towers. It alternated for a short time with Baird's mechanical system in adjoining studios, but was more reliable and visibly superior. This was the world's first regular [...] "high-definition" [...] television service.|$|E
5000|$|Herbert E. Ives and Frank Gray of Bell Telephone Laboratories gave a {{dramatic}} demonstration of mechanical television on 7 April 1927. Their reflected-light television system included both {{small and large}} viewing screens. The small receiver had a 2-inch-wide by 2.5-inch-high screen. The large receiver had a screen 24 inches wide by 30 inches high. Both sets were capable of reproducing reasonably accurate, monochromatic, moving images. Along with the pictures, the sets received synchronized sound. The system transmitted images over two paths: first, a copper wire link from Washington to New York City, then a radio link from Whippany, New Jersey. Comparing the two transmission methods, viewers noted no difference in quality. Subjects of the telecast included Secretary of Commerce Herbert Hoover. A <b>flying-spot</b> <b>scanner</b> beam illuminated these subjects. The scanner that produced the beam had a 50-aperture disk. The disc revolved {{at a rate of}} 18 frames per second, capturing one frame about every 56 milliseconds. (Today's systems typically transmit 30 or 60 frames per second, or one frame every 33.3 or 16.7 milliseconds respectively.) Television historian Albert Abramson underscored the significance of the Bell Labs demonstration: [...] "It was in fact the best demonstration of a mechanical television system ever made to this time. It would be several years before any other system could even begin to compare with it in picture quality." ...|$|E
40|$|Abstract—We have {{developed}} a <b>flying-spot</b> <b>scanner</b> (FSS), for fluorescence imaging of tissues in vivo. The FSS {{is based on the}} principles of single-pixel illumination and detection via a raster scanning technique. The principal components of the scanner are a laser light source, a pair of horizontal and vertical scanning mir-rors to deflect the laser light in these respective directions on the tissue surface, and a photo multiplier tube (PMT) detector. This paper characterizes the performance of the FSS for fluorescence imaging of tissues in vivo. First, a signal-to-noise ratio (SNR) anal-ysis is presented. This is followed by characterization of the experi-mental SNR, linearity and spatial resolution of the FSS. Finally, the feasibility of tissue fluorescence imaging is demonstrated using an animal model. In summary, the performance of the FSS is compa-rable to that of fluorescence-imaging systems based on multipixel illumination and detection. The primary advantage of the FSS is the order-of-magnitude reduction in the cost of the light source and detector. However, the primary disadvantage of the FSS its signifi-cantly slower frame rate (1 Hz). In applications where high frame rates are not critical, the FSS will represent a low-cost alternative to multichannel fluorescence imaging-systems. Index Terms—Auto fluorescence, cancer, fluorescence, <b>flying-spot</b> <b>scanner,</b> imaging, in vivo, precancer, tissues...|$|E
40|$|The Harwell Image Processing System (HIPS) {{has been}} adapted for {{processing}} earth-resource imagery in either film or tape format. Data from film are obtained using a computer-controlled <b>flying-spot</b> <b>scanner.</b> Local rapid interactive processing {{is based on}} a PDP 11 / 20 minicomputer which has suitable display facilities for immediate visual appraisal of results and also a fast data link to an IBM 370 / 168 computer complex. An extensive subroutine library is being assembled for data preprocessing and feature extraction. This chapter includes a discussion of the basic principles of image analysis, a description of the HIPS system, and finally, for illustrative purposes, a description of several simple software routines...|$|E
40|$|The aim of {{the present}} study was to {{evaluate}} the acidification of the endosome-lysosome system of renal epithelial cells after endocytosis of two human immunoglobulin lambda light chains (Bence-Jones proteins, BJP) obtained from patients with multiple myeloma. Renal epithelial cell handling of two BJP (neutral and acidic BJP) was evaluated by rhodamine fluorescence. Renal cells (MDCK) were maintained in culture and, when confluent, were incubated with rhodamine-labeled BJP for different periods of time. Photos were obtained with a fluorescence microscope (Axiolab-Zeiss). Labeling density was determined on slides with a densitometer (Shimadzu Dual-Wavelength <b>Flying-Spot</b> <b>Scanner</b> CS 9000). Endocytosis of neutral and acidic BJP was correlated with acidic intracellular compartment distribution using acridine orange labeling. We compared the pattern of distribution after incubation of native neutral and acidic BJP and after complete deglycosylation of BJP by periodate oxidation. The subsequent alteration of pI converted neutral BJP to acidic BJP. There was a significant accumulation of neutral BJP in endocytic structures, reduced lysosomal acidification, and a diffuse pattern of acidification. This pattern was reversed after total deglycosylation and subsequent alteration of the pI to an acidic BJP. We conclude that the physicochemical characteristics of BJP interfere with intracellular acidification, possibly explaining the strong nephrotoxicity of neutral BJP. Lysosomal acidification is fundamental for adequate protein processing and catabolism...|$|E

