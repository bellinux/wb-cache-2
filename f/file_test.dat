10|521|Public
50|$|A {{developer}} creates message {{flows in}} a cyclical workflow, probably more agile {{than most other}} software development. Developers will create a message flow, generate a BAR file, deploy the message flow contained in the BAR <b>file,</b> <b>test</b> the message flow and repeat as necessary to achieve reliable functionality.|$|E
5000|$|Sami Runsas (author of NanoZip) {{maintains}} Compression Ratings, {{a benchmark}} similar to Maximum Compression multiple <b>file</b> <b>test,</b> but with minimum speed requirements. It {{also offers a}} calculator that allows the user to weight the importance of speed and compression ratio. The top programs here are fairly different due to speed requirement. In January 2010, the top programs were NanoZip followed by FreeArc, CCM, flashzip, and 7-Zip.|$|E
40|$|Abstract- We {{designed}} a compact, high-speed, and low-power bank-type 12 -port register <b>file</b> <b>test</b> chip for highly-parallel pro-cessors in 0. 35 µm CMOS technology. In this full-custom test chip design, 72 % smaller area, 25 % shorter access cycle time, and 62 % lower power consumption are achieved {{in comparison to}} the conventional 12 -port-cell-based register file. I...|$|E
40|$|With {{the rapidly}} growing {{wireless}} deployment, the demand for the wireless <b>filed</b> <b>test</b> increases rapidly. This paper proposes a new design for smart wireless <b>filed</b> <b>test</b> analyzer on a 10. 4 ” TFT LCD best finger touch screenbased embedded tablet device. Based on the advantages of portability on this platform, we have applied for an embedded system with the novel software architecture which provided customizable shell, system utilities and services. With this software architecture, it can be easily customized to specific applications for wireless <b>filed</b> <b>test</b> analysis. The applications are widespread from site survey to floor planning. In this paper, we will propose several smart tools for wireless test analysis as examples. 1...|$|R
5000|$|Extracts {{from the}} corpus files 2 {{training}} files, 2 tuning <b>files</b> and 2 <b>testing</b> <b>files</b> <b>test</b> <b>files</b> (one in {{the source and}} one in the target language) with randomly selected, non-consecutive segments that are erased from the corpus files; ...|$|R
50|$|The {{source code}} reads the {{property}} file {{to determine the}} target LDAP server. In this way, developers can be certain that the WAR <b>file</b> <b>tested</b> and verified is the {{exactly the same as}} that which is being promoted to production.|$|R
40|$|When you {{are ready}} to install the Conserve Minimal Adjustment Scheme (CMAS) codes, please place the tar file in an {{appropriate}} directory and untar it: tar-xvf cmas_f_code. tar This will create a directory named cmas_f_code with the entire software distribution ready to be compiled on your computer. 1. Information The enclosed Fortran files are used for stablizing (T, S) profiles with minimal adjustment and keeping heat and salt conservation. This package includes (1) main program (CN 2 sub. f), (2) test <b>file</b> (<b>test.</b> f), (3) data file DTS), and (4) fortran function for calculating seawater density from T, S, and depth (seawatersub. f). 2. Main Progra...|$|E
40|$|Mapmerge: merge genomic maps Motivation: When {{two or more}} genomic maps of a {{chromosomal}} region are available, {{it is useful to}} be able to synthesize them to create a merged map. Results: We show that map merging is an exploratory process because there are multiple ways to combine data based upon what the user wishes to focus on, and upon which particular data subset emphasis is desired. We describe Mapmerge, a program for merging two genomic maps, discuss its limitations, and illustrate an example of its use. Availability: Freely available (ANSI C source code, a Make <b>file,</b> <b>test</b> data files, documentation) on request from the author...|$|E
40|$|Crushed cylinder-triangle {{intersection}} detection bugs. Added {{option to}} detect edge hits. Updated test. m file to include leaf over-sampling, {{to reach the}} goal leaf area. Updated test. m resulting export files and rendered image. Updated the constructor of QSMBCylindrical to accept struct-based model data, compatible with TreeQSM v 2. 30. Updated LeafModelTriangle class with additional methods: compute_geometry( [...] .) is a method for computing leaf vertices and faces based on the leaf geometry and either transformation parameters given as input, or parameters of the accepted leaves. export_geometry( [...] .) is a generalization of the old export_obj( [...] .) method, allowing new export formats {{to be added to}} the same method in the future. Other methods have been updated to accommodate the new methods, as well as, the demonstration <b>file</b> <b>test.</b> m. Wrote documentation in README. md...|$|E
50|$|EICAR <b>test</b> <b>file</b> - a <b>test</b> pattern used to {{test the}} {{installation}} of the anti virus software, which is written in printable code.|$|R
50|$|The EICAR Standard Anti-Virus Test <b>File</b> or EICAR <b>test</b> <b>file</b> is a {{computer}} file that {{was developed by the}} European Institute for Computer Antivirus Research (EICAR) and Computer Antivirus Research Organization (CARO), to test the response of computer antivirus (AV) programs. Instead of using real malware, which could do real damage, this <b>test</b> <b>file</b> allows people to test anti-virus software without having to use a real computer virus.|$|R
30|$|Noise data. For {{the speech}} {{denoising}} experiment, we consider 4 types of noises: cicadas, drums, subway, and sea. For each, we gathered one file {{for training and}} one <b>file</b> for <b>testing</b> from non-copyrighted sources on the internet 2. We trimmed the training files {{so that they are}} approximately 20 s long and made sure that <b>test</b> <b>files</b> were longer than the voice test sounds. Note that for each noise type, the training and <b>testing</b> <b>files</b> were gathered using the same keywords, but can still have quite a bit of variability.|$|R
40|$|Abstract:- State-of-the-art image {{compression}} and reconstruction techniques utilize wavelets. Recently published research demonstrated that a genetic algorithm (GA) {{is capable of}} evolving non-wavelet transforms that consistently outperform wavelets when applied to a broad class of images under conditions subject to quantization error. This paper describes new results that build upon previous research by demonstrating that a GA can evolve a single set of coefficients describing a matched forward and inverse transform pair {{that can be used}} at each level of a multi-resolution analysis (MRA) transform to simultaneously minimize the compressed file size (FS) and the squared error (SE) in the reconstructed <b>file.</b> <b>Test</b> results indicate that the benefits of using evolved transforms instead of wavelets increases in proportion to quantization level. Furthermore, coefficients evolved against a single representative training image generalize to effectively reduce SE for a broad class of reconstructed images...|$|E
40|$|Configuring typical {{devices in}} the {{telemetry}} community requires {{the creation of}} complex, device-specific configuration files. While the grammar of the configuration files is vendor neutral, the device specific details are vendor specific. Thus, a naïve approach to building these files is to construct a <b>file,</b> <b>test</b> it against a device, and then iterate. The specification sheets (and other documents) for the device {{can serve as a}} guide, but the details of flight test configuration possibilities are immense and, in this community, typically not fully documented. This paper describes a process of creating a set of general rules describing characteristics of a configuration file and using those rules to discover the configuration constraints of telemetry devices automatically. The discovered constraints posed by a particular vendor’s device can then be quickly formed into a correct-by-construction constraint-based grammar for use in other systems...|$|E
40|$|The need {{to control}} gas and {{leachate}} production and minimize refuse volume in landfills has motivated the development of landfill simulation models {{that can be used}} by operators to predict and design optimal treatment processes. T 2 LBM is a module for the TOUGH 2 simulator that implements a Landfill Bioreactor Model to provide simulation capability for the processes of aerobic or anaerobic biodegradation of municipal solid waste and the associated flow and transport of gas and liquid through the refuse mass. T 2 LBM incorporates a Monod kinetic rate law for the biodegradation of acetic acid in the aqueous phase by either aerobic or anaerobic microbes as controlled by the local oxygen concentration. Acetic acid is considered a proxy for all biodegradable substrates in the refuse. Aerobic and anaerobic microbes are assumed to be immobile and not limited by nutrients in their growth. Methane and carbon dioxide generation due to biodegradation with corresponding thermal effects are modeled. The numerous parameters needed to specify biodegradation are input by the user in the SELEC block of the TOUGH 2 input <b>file.</b> <b>Test</b> problems show that good matches to laboratory experiments of biodegradation can be obtained. A landfill test problem demonstrates the capabilities of T 2 LBM for a hypothetical two-dimensional landfill scenario with permeability heterogeneity and compaction...|$|E
40|$|This {{dissertation}} {{describes the}} development of new genetic resources of spring barley in a process called prebreeding. Suitable genotypes were detected by using appropriate methods of selection (greenhouse <b>tests,</b> molecular markers, <b>filed</b> <b>tests</b> in provocative conditions). They could be used directly in the next breeding programmes for increased resistance to pathogen Pyrenophora teres f. teres causing net form of net blotch or for improved grain quality usable in the food industry and in nutrition of farm animals...|$|R
40|$|This diploma thesis focuses {{its point}} on {{automatization}} of stopwords generation as one method of pre-processing a textual documents. It analyses an influence of stopwords removal to {{a result of}} data mining tasks (classification and clustering). First the text mining techniques and frequently used algorithms are described. Methods of creating domain specific lists of stopwords are described to detail. In the end the results of large collections of text <b>files</b> <b>testing</b> and implementation methods are presented and discussed...|$|R
5000|$|Make-test-files: To {{extract from}} the {{original}} corpus a corpus for training, files for tuning and <b>files</b> for <b>testing</b> {{the results of the}} training.|$|R
40|$|The {{computational}} {{fluid dynamics}} (CFD) comparisons being presented are compared {{to each other and}} to wind tunnel (WT) data on the baseline TCA. Some of the CFD computations were done prior to the tests and others later. Only force data (CL vs CD) from CFD will be presented as part of this report. The WT data presented comes from the testing of the baseline TCA in the Langley Unitary Plan Wind Tunnel (UPWT), Test Section # 2. There are 2 sets of wind tunnel data being presented: one from test 1671 of model 2 a (flapped wing) and the other from test 1679 of model 2 b (solid wing). Most of the plots show only one run from each of the WT tests per configuration. But many repeat runs were taken during the tests. The WT repeat runs showed an uncertainty in the drag of +/- 0. 5 count. There were times when the uncertainty in drag was better, +/- 0. 25 count. Test 1671 data was of forces and pressures measured from model 2 a. The wing had cutouts for installing various leading and trailing edge flaps at lower Mach numbers. The internal duct of the nacelles are not designed and fabricated as defined in the outer mold lines (OML) iges file. The internal duct was fabricated such that a linear transition occurs from the inlet to exhaust. Whereas, the iges definition has a constant area internal duct that quickly transitions from the inlet to exhaust cross sectional shape. The nacelle internal duct was fabricated, the way described, to save time and money. The variation in the cross sectional area is less than 1 % from the iges definition. The nacelles were also installed with and without fairings. Fairings are defined as the build up of the nacelles on the upper wing surface so that the nacelles poke through the upper surface as defined in the OML iges <b>file.</b> <b>Test</b> 1679 data was of forces measured from model 2 a and 2 b. The wing for model 2 b was a solid wing. The nacelles were built the same way as for model 2 a, except for the nacelle base pressure installation. The nacelles were only tested with the fairings for model 2 a and 2 b during test 1679...|$|E
40|$|Abstract:The dynamic {{pile driving}} process is so complex that till now the {{analysis}} on the process had been focusing on the <b>filed</b> <b>test</b> or laboratory test. However, the past study about the dynamic process is a time consuming one; with the computational method development, the numerical simulation on this process is possible. In this paper, explicit dynamical analysis method is adopted, the pile is simulated using the elastic solid element, two computational cases are considered and finally the pile driving process dynamical stress is studied. Huazhi Li, School of dynamical engineering, Xi'an Aerotechnical colleg...|$|R
40|$|Configuration Management systems {{facilitate}} the configuration and version control operations {{associated with the}} information pertaining to each release of a product. Such systems are critical components of any concurrent engineering environment inasmuch as they manage {{the complexity of the}} information (like specifications, design <b>files,</b> <b>test</b> results, documentation, engineering change orders) and also its dynamics. There are many product information management systems and drawing/document management systems on the market today {{that can be used for}} configuration management. By recording an engineering product’s structure and the changes made during development, configuration managemen...|$|R
5000|$|... #Caption: Windows Defender {{successfully}} {{blocks the}} EICAR <b>test</b> <b>file</b> ...|$|R
40|$|Abstract. Based {{on field}} {{compaction}} test of Nuozhadu I district rockfill engineering, numerical simulation {{was conducted to}} study the rolling compaction (RC) process using Particle Flow Code (PFC). Effects of different particle content {{to the quality of}} dam filling were discussed based on both numerical and <b>filed</b> <b>test</b> results. Numerical results also revealed the particle movement of the rockfill, the density of the formation mechanism and compaction characteristics during the RC process. Field test and simulated results both indicated that the RC process can be divided into three stages of vibration compaction, void filling and the unloading rebound phase...|$|R
5000|$|Apache.test1.exp [...] This {{will be the}} <b>file</b> {{containing}} <b>tests,</b> {{which in}} this fictional case might change configuration options, and then connect to the network and {{check to make sure}} the changes have taken effect.|$|R
40|$|Wilson coal pillar; {{optimization}} coal pillar size; Abstract: AH Wilson coal pillar {{was used}} widely as it’s simply, but it’s appeared large error for field implementation as its difference assume conditions, mine depth H and mine thickness m. AH Wilson coal pillar formula was studied precisely by in-site stresses test and numerical simulation analysis for N 3 - 5 top coal caving working face of CHANGCUN coal mine in Lu’an coal district of China, then modified AH Wilson formula was put forward as L = 0. 008 mH + 8. 4,then the precise coal pillar size 18 m {{was used in}} <b>filed</b> implementation, <b>filed</b> <b>testing</b> proved coal pillar size was reasonable...|$|R
40|$|The {{purpose of}} this project was to observe the amount of apical and mid-curve {{transportation}} produced by a range of nickel titanium (NiTi), titanium alloy and stainless steel (SS) <b>files.</b> <b>Tests</b> were carried out in simulated curved root canals produced in epoxy resin blocks. Seven commer-cially available <b>file</b> types were <b>tested</b> using sizes 15 to 40. Instrumentation was carried out to 1 mm beyond the apex. Changes in canal dimensions were measured at 10 magnification under a shadowgraph. There were substantial differences in the amount and the pattern of apical and mid-curve trans-portation produced. The amount of transportation increased with each subsequent size of file. Under the same conditions, nickel titanium files produced significantly less transportation than stainless steel files. The least apical transportation was obtained with the NiTi Mity Turbo and the most by the SS K file and SS Hedstrom file. The least mid-curve transportation was produced by the NiTi Mity Turbo and the most by the SS Hedstrom file...|$|R
5000|$|... <b>file's</b> position-sensitive <b>tests</b> are {{normally}} implemented by matching various locations within the file against a textual database of magic numbers (see the Usage section). This differs from other simpler {{methods such as}} file extensions and schemes like MIME.|$|R
40|$|AbstractThe {{objective}} of the research herein presented {{was to assess the}} time to fracture of Hyflex CM files subjected to rotational bending tests, with or without back and forth motion, in an apical canal similar to those existent in a real tooth with multiplanar curvatures. Therefore, a lower first molar was modelled and manufactured in an AISI 316 L stainless steel using selective laser melting technology, featuring the required multiplanar curvatures, which were confirmed by radiography. Thereafter, endodontic files were submitted to either rotational bending tests without back and forth motion (Group A) or rotational bending tests with back and forth motion (Group B) inside an artificial root canal with primary, secondary and tertiary curvatures. Time to fracture was recorded and fragments of the endodontic <b>files</b> <b>tested</b> were observed by optical microscopy. Instruments of Group A showed an average time to fracture of 119 seconds and an average fractured tip length of 4. 9 mm, while instruments of group B displayed an average time to fracture of 194. 1 seconds (+ 63 %) and an average fractured tip length equal to 4. 13 mm. All instruments fractured due to fatigue crack propagation. Hence, it was possible to conclude that back and forth motion extended the fatigue lifetime of the <b>files</b> <b>tested</b> once allowed diminishing the number of cycles with higher stress range applied, and spread the induced stresses by an enlarged area of the instrument. Additionally, almost plane surfaces were observed at fractured cross sections of the instruments tested, allowing to infer a very low influence of torsional loading when compared with bending...|$|R
50|$|Prosecutors portrayed Ayala as a scam {{artist with}} {{a penchant for}} <b>filing</b> lawsuits. <b>Tests</b> {{indicate}} that the finger had not been cooked in the chili, according to court records. They did not indicate where they thought the finger came from.|$|R
30|$|First, {{a virtual}} block device VBD with 12 GiB {{capacity}} formatted with ext 4 file system was created. Then, a LogDrive database {{was created by}} overwriting an 8 GiB <b>test</b> <b>file</b> 16 times. The <b>test</b> <b>file</b> was generated by executing the command dd if=/dev/urandomof=test.dat count= 8 bs=̀echo 2 ̂ 30 | bc̀. After creating the LogDrive database, the read throughput of the LogDrive restoration driver was measured.|$|R
2500|$|Shore {{had been}} convicted of molesting his two daughters Tiffany and Amber, and as a result he was {{required}} to provide police with a DNA sample. This was done in 1998. In 2000, detectives pulled Carmen Del Estrada's case from the cold <b>files,</b> <b>tested</b> DNA evidence from underneath Carmen's fingernails, and received a full genetic profile. [...] The results were not immediately matched to Shore because of problems at the lab. As a result of an audit, the lab was closed in 2002; certain samples, however, including those taken from Estrada's nails, were sent to another laboratory for retesting. The results were not matched until 2003. Shore was arrested for Estrada's murder.|$|R
40|$|The {{proportion}} of dynamic load model in composite load {{model has been}} determination by using an improved ANN method in this paper. The importance of the {{proportion of}} dynamic component in composite load model to power system analyses is discussed first. Then Levenberg-Marquardt back propagation algorithm is used for off-line training of the feed-forward network. The developed identification method is tested by the simulation data generated using Mathlab tools, the dynamic system data measured from dynamic simulation system, and the data obtained from <b>filed</b> <b>tests.</b> The well trained Neural Network model is used online to identify the proportion of dynamic component for a real power system. The test results show that method is feasible and effective. 1...|$|R
5000|$|Shore {{had been}} convicted of molesting his two daughters Tiffany and Amber, and as a result he was {{required}} to provide police with a DNA sample. This was done in 1998. In 2000, detectives pulled Carmen Del Estrada's case from the cold <b>files,</b> <b>tested</b> DNA evidence from underneath Carmen's fingernails, and received a full genetic profile. [...] The results were not immediately matched to Shore because of problems at the lab. As a result of an audit, the lab was closed in 2002; certain samples, however, including those taken from Estrada's nails, were sent to another laboratory for retesting. The results were not matched until 2003. Shore was arrested for Estrada's murder.|$|R
30|$|Under an {{exhaustive}} DM process, we developed many different training files {{to work out}} {{which is the best}} sequence for training, and also how many instances are enough for good knowledge acquisition. After trying with different kinds of sequences, and for each sequence a different number of frames, we found that sequences which contain varying regions from homogenous to high-detail serve as good training sets. Good sample sequences could be Flower and Soccer sequences. Basically, in this mode of operation, the <b>testing</b> <b>file</b> information is used to check the selection of the decision tree (which is generated by using the training file) and this selection is compared with the nominal class that appears in the <b>testing</b> <b>file.</b> This process was carried out for all the possible combinations (training with one <b>file</b> and <b>testing</b> with the rest).|$|R
50|$|ROM {{images are}} used when {{developing}} for embedded computers. Software {{which is being}} developed for embedded computers is often written to ROM <b>files</b> for <b>testing</b> on a standard computer before it is written to a ROM chip {{for use in the}} embedded system.|$|R
40|$|The {{usage of}} quality data enquiry allows taking benefit from <b>filed</b> <b>test</b> data of {{components}} even {{they have been}} placed into circulation. This {{makes it possible to}} analyse data of used components for defects at later time even if the components itself are no longer easily available for additional testing. The defects that can be identified with the help of quality data enquiry must be visible in the <b>filed</b> <b>test</b> data and were mostly misjudged with regard to the risk being assigned to this defect. Together with an appropriate means of identification of the components quality data enquiry can help to avoid expensive callbacks {{of a large number of}} potentially affected parts. In respect to flexible usage of quality data enquiry without deeper knowledge of mathematical details on data analysis algorithms, the method uses search algorithms that can be adapted on the signal shapes of interest with the help of signal patterns. The search result is checked visually to decide whether it is sufficient or further improvement of the adaptation of the recognition system is necessary. Usage and benefit of a quality enquiry system is illustrated with testing of cladding tubes for fuel rods. The data gathered from ultrasonic testing of the tubes contains information on the location and the type of the defect that caused the echoes of the injected ultrasonic waves. Saving of these data allows later analysis of the signals with the method of quality data enquiry. This makes it possible to directly access or extend monitoring of the affected fuel rods in order to reduce or actively manage the risk caused by the distinctive feature...|$|R
