0|16|Public
40|$|The U. S. Court of Appeals for the Second Circuit {{became the}} first appellate court in nearly thirty years to uphold the {{dismissal}} of criminal indictments for a Sixth Amendment right-to-counsel vilation. United States v. Stein is a unique case that intertwines constitutional <b>interpretation,</b> constitutional <b>remedies,</b> white collar crime, and U. S. Department of Justice (DOJ) policy. The immediate effects of the Stein decisions not only reflect the changing attitudes at the DOJ on how to prosecute white collar crime but have simultaneously caused the Doj to implement such changes. As the Sixth Amendment has developed and augmented such changes, so has <b>interpretation</b> of <b>remedies</b> {{when there is a}} righ-to-counsel violation. THis Note explores the Stein decisions in light of existing doctrines, and concludes that while certain parts of the decisions are legally sound, other parts-right or wrong-may present direct challenges to existing jurisprudence...|$|R
40|$|This paper {{addresses}} {{the issue of}} the legitimacy of judicial review from a methodological perspective. It argues that unpredictability of approach is a very serious and dangerous form of judicial activism. It analyses an ambivalent judicial attitude to facts, and the confusion that exists between rules and provisions on the one hand, and <b>interpretation</b> and <b>remedies</b> on the other. It pleads in favour of greater conceptual consistency in the way the Supreme Court of Canada handles methodological issues...|$|R
40|$|Abstract. Orc [9] is a {{language}} for task orchestration. It {{has a small}} set of primitives, but sufficient to express many useful programs succinctly. We identify an ambiguity in the trace semantics of Kitchin et al. [9]. We give possible interpretations of the ambiguous definition and show that the semantics is not adequate regardless of the <b>interpretation.</b> We <b>remedy</b> this situation by providing new operational and denotational semantics with a better treatment of variable binding, and proving an adequacy theorem to relate them. Also, we investigate strong bisimulation in Orc and show that bisimulation implies trace equivalence but not vice versa. ...|$|R
40|$|In this work, I offer a new {{interpretation}} of Nietzsche's existential philosophy. I argue that, methodologically, Nietzsche's existentialism {{is a consequence}} of making the typical existential position foundational, and then developing to the fullest the implications of this position. I call the resultant approach, "meta-existentialism. " Further, I show that Nietzsche's meta-existential philosophy necessarily implicates his complex critique of metaphysics. In other words, his particular type of existentialism can be understood only by thoroughly investigating his criticism of metaphysical thought. Previous interpreters who have sought to portray Nietzsche as an existential thinker, such as Karl Jaspers, Walter Kaufmann and Robert Solomon, fail to seriously engage his critique of metaphysics. They set aside the latter issue, precisely in order to explicate his existentialism. My <b>interpretation</b> <b>remedies</b> this deficiency. This work also addresses those other commentators who do carefully consider Nietzsche's relation to metaphysics, although they do not interpret him as an existentialist. While poststructuralist thinkers, such as Eric Blondel, Sarah Kofman and Michel Haar, have argued that Nietzsche's thought exceeds the limits of metaphysics, other philosophers, such as Martin Heidegger, have claimed that Nietzsche remains trapped within its confines. My argument undercuts this debate by showing that Nietzsche provides an open-ended and ambiguous critique of metaphysics, in which the problem of metaphysics is never settled once and for all. By analyzing Nietzsche's central notion of "will to power" and the problem of "decadence," I show that an encounter with and an ever-renewed critique of metaphysics is essential to Nietzsche's meta-existentialism...|$|R
50|$|Pagano {{has been}} deeply {{involved}} in the debate concerning the economic crisis started in 2007. He has advanced the hypothesis that some of the roots of the crisis {{are to be found in}} the institutions of the knowledge economy, in particular the TRIPs, which have substantially increased the cost of investments. According to this <b>interpretation,</b> the possible <b>remedies</b> to the crisis should not only focus on monetary policy, financial regulations or even on standard Keynesian policies, but should be coupled with policies that decrease the level of intellectual monopolisation of the economy.|$|R
40|$|This thesis {{investigates the}} theory and {{practice}} of song criticism from a primarily literary perspective. It maintains that much contemporary song criticism deals inadequately with the complex relationships between verbal, vocal and musical texts that comprise the three basic elements of the modern song. To justify this claim, and to grasp how the current situation might have arisen, the thesis delves into the history of song and traces its developments. It concludes that modern and classical song differ in ways that the "serious vs. popular" debate do not address: autonomy of authorship, frame of reference, and proper context for <b>interpretation.</b> To <b>remedy</b> this situation, the thesis anatomizes modern song and outlines a "top-down" approach to song criticism with lyrics as the primary frame of reference, supplemented by emotive cues found in the music and vocal performance. Concurrently, the anatomy is put into practice, using examples from the unofficial canon of modern song...|$|R
40|$|In {{view of a}} {{resurgence}} of concern about the measurement problem, it is {{pointed out that the}} Relativistic Transactional <b>Interpretation</b> (RTI) <b>remedies</b> issues previously considered as drawbacks or refutations of the original TI. Specifically, once one takes into account relativistic processes that are not representable at the non-relativistic level (such as particle creation and annihilation, and virtual propagation), absorption is quantitatively defined in unambiguous physical terms. In addition, specifics of the relativistic transactional model demonstrate that the Maudlin `contingent absorber' challenge to the original TI cannot even be mounted: basic features of established relativistic field theories (in particular, the asymmetry between field sources and the bosonic fields, and the fact that slow-moving bound states, such as atoms, are not offer waves) dictate that the `slow-moving offer wave' required for the challenge scenario cannot exist. It is concluded that issues previously considered obstacles for TI are no longer legitimately viewed as such, and that reconsideration of the transactional picture is warranted in connection with solving the measurement problem. Comment: Final version, forthcoming in International Journal of Quantum Foundation...|$|R
40|$|I {{suspect that}} most American lawyers and law {{students}} regard express warranty as neither more nor {{less than a}} term in a contract, a term that is subject to conventional contract rules on formation, <b>interpretation,</b> and <b>remedy.</b> Assume, for example, that a buyer sends a purchase order to a seller and the purchase order specifies the delivery of 300 tons of 2 ̆ 2 prime Thomas cold rolled steel. 2 ̆ 2 The acknowledgment also describes the goods to be sold as 2 ̆ 2 prime Thomas cold rolled steel. 2 ̆ 2 Every American lawyer would agree {{that there is a}} contract to deliver such steel and furthermore would conclude that the seller makes an express warranty that the steel delivered would conform to that description and that the seller would be liable for breach of its contract if it failed to deliver steel that conformed to that description. So we would say that the description is an express warranty and that the express warranty is neither more nor less than a term in a contract...|$|R
40|$|Form {{requirements}} {{particularly for}} arbitration clauses are widely {{perceived as an}} obstacle for efficiently resolving disputes on an international level. The paper discusses recent suggestions that the freedom of form principle under Art. 11 CISG extends to arbitration, forum selection or choice of law clauses in international sales contracts and thus supersedes any and all formal requirements in this regard. The authors establish that said clauses indeed are generally within the CISG's scope of application and that, consequently, questions of contract conclusion, <b>interpretation,</b> and <b>remedies</b> for breach of these clauses are governed by the CISG. Freedom of form under the CISG, however, was neither intended to nor should it apply to arbitration, forum selection or choice of law clauses. This result is further confirmed by the interplay of the CISG with other international conventions, first and foremost the 1958 New York Convention, {{as well as a}} careful analysis of the so called most-favourable-law-approach. The recent aim to do away with form requirements for arbitration, forum selection or choice of law clauses can thus not be reached by taking a detour to the CISG, but only by directly abolishing or adjusting these form requirements...|$|R
40|$|This is {{a survey}} of {{economic}} analysis of law, that is, of the emerging field under which the standard tools of microeconomics are employed to identify the effects of legal rules and their social desirability. Five basic subject areas are covered. The first is legal liability for harm. Here we discuss liability rules as incentives to reduce risk, issues of risk-bearing and insurance, {{and the costs of}} the liability system. Second, we consider property law, where we address the nature and justification of property rights, public property, the acquisition and transfer of property, externalities surrounding the use of property, and intellectual property. Third, we examine contract law, including the formation of contracts, their <b>interpretation,</b> and <b>remedies</b> for their breach. We focus on production contracts but also discuss other types, including donative contracts. Fourth, we treat the subject of civil litigation, that is, the bringing of lawsuits, and their settlement or disposition at trial. We also mention the appeals process, alternative dispute resolution, the provision of legal advice, and several additional topics relating to litigation. Fifth, we consider public enforcement of law, focusing on the level of law enforcement effort, the magnitude of sanctions, and other issues relevant to criminal law. Finally, we discuss criticisms that are commonly made by legal academics of economic analysis of law and offer concluding remarks. ...|$|R
40|$|This Article {{takes the}} {{opportunity}} of the fortieth anniversary of Katz v. U. S. to assess whether the revolutionary case 2 ̆ 7 s potential to provide broad and flexible privacy protection to individuals has been realized. Answering this question in a circumspect way, the Article pinpoints the language in Katz that was its eventual undoing and demonstrates how the Katz test {{has been plagued by}} two principle problems that have often rendered it more harmful to than protective of privacy. The manipulation problem describes the tendency of conservative courts to define reasonable expectations of privacy as lower than the expectations society actually entertains. The normativity problem captures the idea that the Katz test allows reasonable expectations to be set by those who engage in normatively disfavored privacy defeating conduct. The Article then concentrates on two specific doctrines exemplary of these problems, the third party doctrine and the contraband exception, and discusses their ruinous effects on privacy in a technological era. The third party doctrine, which roughly holds that third party exposure defeats privacy interests, has severely hampered the ability of the Katz test to afford Fourth Amendment protection to intimate online communications. Likewise, the contraband exception, which holds that there is no legitimate expectation of privacy in illegal items, proves exceedingly dangerous to privacy as crime detection technology becomes increasingly refined. In the end, however, this Article does not advocate trashing the Katz test, but rather suggests methods of <b>interpretation</b> that <b>remedy</b> the manipulation and normativity problems...|$|R
40|$|Most {{existing}} {{methods for}} sequence-based classification use exhaustive feature generation, employing, for example, all k-mer patterns. The motivation behind such (enumerative) approaches is {{to minimize the}} potential for overlooking important features. However, there are shortcomings to this strategy. First, practical constraints limit the scope of exhaustive feature generation to patterns of length ≤ k, such that potentially important, longer (> k) predictors are not considered. Second, features so generated exhibit strong dependencies, which can complicate understanding of derived classification rules. Third, and most importantly, numerous irrelevant features are created. These concerns can compromise prediction and <b>interpretation.</b> While <b>remedies</b> have been proposed, {{they tend to be}} problem-specific and not broadly applicable. Here, we develop a generally applicable methodology, and an attendant software pipeline, that is predicated on discriminatory motif finding. In addition to the traditional training and validation partitions, our framework entails a third level of data partitioning, a discovery partition. A discriminatory motif finder is used on sequences and associated class labels in the discovery partition to yield a (small) set of features. These features are then used as inputs to a classifier in the training partition. Finally, performance assessment occurs on the validation partition. Important attributes of our approach are its modularity (any discriminatory motif finder and any classifier can be deployed) and its universality (all data, including sequences that are unaligned and/or of unequal length, can be accommodated). We illustrate our approach on two nucleosome occupancy datasets and a protein solubility dataset, previously analyzed using enumerative feature generation. Our method achieves excellent performance results, with and without optimization of classifier tuning parameters. A Python pipeline implementing the approach is available at [URL]...|$|R
40|$|Under {{the common}} law, {{employment}} contracts are submitted to civil courts to resolve disputes over <b>interpretation,</b> breach, and <b>remedies.</b> As an alternative, parties in labor contexts can agree to resolution by an impartial arbitrator, whose decision is reviewed deferentially by judges. Where employees {{are subject to}} rules of a private association, they are often contractually obligated to submit their claims to an internal association officer or committee; the common law provides for judicial review more limited than a civil contract but more searching than {{is the case for}} an impartial labor arbitrator. Recently, the National Football League and its players have gone to federal court in well-known disputes concerning employee discipline. Although the collective bargaining agreement expressly removes these issues from impartial arbitration, the cases have curiously been litigated as if the league commissioner is an arbitrator. This Article suggests that this is the wrong standard. It creates an anomaly where a unionized player’s grounds for review are narrower than a non-union employee. It also creates an inevitable incentive for federal judges to distort the deferential rules of review of labor arbitration designed for expert impartial arbitrators, when reviewing the decision of a management executive. We discuss the baseline law of private association and why it is a superior standard of judicial review in these cases...|$|R
40|$|A 2 ̆ 2 {{judicial}} paradox 2 ̆ 2 {{exists today}} concerning {{the state of}} equitable remedies available under the Employee Retirement Income Security Act of 1974 (2 ̆ 2 ERISA 2 ̆ 2). This paradox exists not {{as a result of}} implementation of the statute by a federal regulatory agency, but rather as the result of numerous Supreme Court decisions interpreting the meaning of 2 ̆ 2 appropriate equitable relief 2 ̆ 2 for claims brought under Section 502 (a) (3) of ERISA. An adequate theory of 2 ̆ 2 appropriate equitable relief 2 ̆ 2 under Section 502 (a) (3) of ERISA has yet to be developed. Ultimately, the law- equity paradigm has led to judicial decisions under Section 502 (a) (3) that contravene Congress 2 ̆ 7 s intent to provide a uniform body of federal standards to govern employee benefit plans upon which plan participants and employers alike can depend. This Article presents an alternative statutory and policy-based theory for judicial <b>interpretation</b> of the <b>remedies</b> authorized by Section 502 (a) (3). The Article demonstrates how the Supreme Court may, consistent with the statutory scheme and the Court 2 ̆ 7 s own prior precedents, use this proposed alternative theory to resolve the judicial paradox of 2 ̆ 2 equitable 2 ̆ 2 relief available under Section 502 (a) (3), and it provides a starting point for Congress, if it so chooses, to develop legislation to modernize the private civil claims and remedies available under title I of ERISA. Whether Congress has the political will to take up this task, however, is less clear. The preferred approach, advocated by this Article, is for the Supreme Court itself to resolve the judicial paradox of 2 ̆ 2 equitable 2 ̆ 2 relief under Section 502 (a) (3) ...|$|R
40|$|In a pair {{of cases}} decided by 5 - 4 {{majorities}} (Mertens, 1993; Great- West, 2002) interpreting the scope of remedy for wrongdoing under ERISA, the Supreme Court construed the statute 2 ̆ 7 s grant of 2 ̆ 2 appropriate equitable relief 2 ̆ 7 to prevent the victims of ERISA-prohibited conduct from being compensated for consequential injury. The Court read ERISA 2 ̆ 7 s authorization of 2 ̆ 2 appropriate equitable relief 2 ̆ 7 to have disinterred the law/equity division from the era before the two systems were fused in the 1930 s, and the Court treated equity as not having awarded monetary relief As a consequence, lower courts have held ERISA to preclude remedy {{in a host of}} situations in which wrongful plan administration (almost always in violation of ERISA 2 ̆ 7 s fiduciary rules) has caused expense, physical harm, or other suffering. This Article explains why and how the Court 2 ̆ 7 s <b>interpretation</b> of ERISA <b>remedy</b> law went wrong, beginning with the Court 2 ̆ 7 s earlier encounter with the field in Russell (1985). The main theme is that the reach of trust-law principles in ERISA is far deeper and more controlling than the opinions in Mertens and Great-West allow. When federalizing the administration of pension and employee benefit plans in ERISA, Congress made a deliberate choice to subject these plans to the pre-existing regime of trust law rather than to invent a new regulatory structure. In this dimension, ERISA is federal trust law. Congress intended ERISA remedy law to replicate the core principles of trust remedy law in the regulation of pension and benefit plans, including the long-familiar make-whole standard of trust remedy law...|$|R
40|$|This study {{examines}} {{the circumstances of}} accounting manipulation in the United States of America (USA) and Australia during the period 1998 - 2010. It is argued that academics mostly undertake research {{within the confines of}} positive accounting in which accounting manipulation is viewed narrowly as earnings manipulation, and, as a consequence, a wide range of social-psychological factors remain unexplored. That research gap prompted this study to appraise accounting manipulation from a broader perspective, considering earnings and balance sheet manipulation by using an interpretive research paradigm and explicitly incorporating the social-psychological factors. The theoretical framework of this study is premised on the fraud triangle theory and a composite model devised as the institutional analysis and development/fraud triangle framework. The analysis and interpretation of findings are based on four banking and financial institutions, namely Fannie Mae and Lehman Brothers Inc. from the USA, and Heath International Holdings Limited and Allco Finance Group Limited from Australia. The study relies upon companies’ annual reports, various investigation reports and other public documents. An interpretive text analysis approach was used for analysing the data. The study finds that accounting manipulation is an intentional activity engendered by individuals’ subjective use, misinterpretation or violation of accounting standards. It arises from multiple realities constructed by the interaction of social-psychological factors, including the macro-economic environment, a company’s financial conditions, and accountability and ethical factors resulting from dysfunctional corporate governance, agency failure, audit failure and regulatory failure. The findings of the study have practical implications for senior executives and boards of directors who need to establish effective corporate governance by discharging active stewardship roles with financial expertise. It is expected that auditors of high-risk clients would prudently scrutinise going concern issues, regulatory compliance, and misstatements to provide quality assurance. The bodies that set accounting standards need to be independent of industry capture so that they can set high quality standards that reduce the scope for subjective (mis) <b>interpretation.</b> Governments should <b>remedy</b> regulatory overlaps and expedite enforcement. It is imperative that educational institutions re-engineer their curricula to provide ethical education to students who will lead business firms, audit firms and regulatory bodies in the future. Furthermore, the study offers several contributions and suggestions. It proposes a broader lens to view accounting manipulation by covering both earnings and balance sheet manipulation. As positive accounting research, based on large samples, is not designed to holistically address questions relevant to multiple factors of accounting manipulation unique to individual companies, it is suggested that future researchers conduct more case studies using an interpretive research paradigm to explore and examine interactions of the accounting and relevant other social-psychological factors...|$|R

