24|470|Public
40|$|Large {{scale of}} short text records are now prevalent, such as news highlights, {{scientific}} paper citations, and posted messages {{in a discussion}} forum, which are often stored as set records in (hidden) databases. Many interesting information retrieval tasks are correspondingly raised on the correlation query over these short text records, such as finding hot topics over news highlights and searching related scientific papers on a certain topic. However, current relational database management systems (RDBMS) do not directly provide support on set correlation query. Thus, in this paper, we address both the effectiveness and efficiency issues of set correlation query over set records in databases. First, we present a framework of set correlation query inside databases. To our best knowledge, only the Pearson’s correlation can be implemented to construct token correlations by using RDBMS facilities. Thereby, we propose a novel correlation coefficient to extend Pearson’s correlation, and provide a pure-SQL implementation inside databases. We further propose optimal strategies to set up correlation <b>filtering</b> <b>threshold,</b> which can greatly reduce the query time. Our theoretical analysis proves that, with a proper setting of <b>filtering</b> <b>threshold,</b> we can improve the query efficiency with a little effectiveness loss. Finally, we conduct extensive experiments to show the effectiveness and efficiency of proposed correlation query and optimization strategies...|$|E
40|$|Abstract: In {{order to}} enhance the search results of keyword search in {{relational}} databases, semantic relationship among relations and tuples is employed and a semantic ranking function is proposed. In addition to considering current ranking principles, the proposed semantic ranking function provides new metrics to measure query relevance. Based on it, two Top-k search algorithms BA (blocking algorithm) and EBA (early-stopping blocking algorithm) are presented. EBA improves BA by providing a <b>filtering</b> <b>threshold</b> to terminate iterations as early as possible. Finally, experimental results show the semantic ranking function guarantees a search result with hig...|$|E
40|$|Abstract. To {{reduce the}} noise error {{existing}} in the output signal of fiber optic gyroscopes (FOGs) {{and increase the}} precision of the FOGs, this paper established a mathematical model of the FOGs output signal, analyzed the error characteristics of the FOGs output signal, put forward a new de-noising arithmetic based on the wavelet transform, soft and hard threshold compromise <b>filtering,</b> <b>threshold</b> values were determined by multi-dimensions recursion arithmetic. Through experiment, it has been already validated that the proposed approach had the competitive performances on visual quality, {{signal to noise ratio}} (SNR) and the standard variation, it is effective in eliminating the white noises existing in the output signal of the FOG...|$|E
30|$|Most {{existing}} PQ signal denoising methods {{must either}} estimate the noise variance or set a corresponding <b>filter</b> <b>threshold.</b> However, the noise variance of real PQ signals is typically unknown {{and difficult to}} estimate accurately. The <b>filter</b> <b>threshold,</b> which is crucial for PQ signal denoising, is also difficult to set accurately and automatically. If a large <b>filter</b> <b>threshold</b> is set, oversmoothing will occur. Conversely, a small <b>filter</b> <b>threshold</b> will result in inefficient denoising. Therefore, the practicality of these existing denoising methods is greatly limited. Kernel regression (KR) is an effective tool {{not only for the}} interpolation of regularly and irregularly sampled images but also for the restoration and enhancement of noisy sampled images. Reference [18] proposed the iterative adaptive KR (IAKR) method, which not only can suppress noise effectively but also has a strong ability to preserve the details of images such as the edges. However, there are almost no applications of IAKR in one-dimensional (1 D) transient PQD denoising. To effectively denoise transient PQDs under strong noise conditions, an improved IAKR (IIAKR) method is proposed in this paper. The proposed method, which does not need to estimate the noise variance or <b>filter</b> <b>threshold,</b> has superiority when compared with previous methods.|$|R
40|$|Residues {{present on}} the surface of the {{proteins}} are involved in a number of functions, especially in ligand-protein interactions, that are important for drug design. The residues present in the core of the protein provide stability to the protein and help in maintaining protein structure. Hence, there is a need for a binary characterization of protein residues based on their surface accessibility (surface accessible or buried). Such a classification can aid in the directed study of either residue type. A number of methods for the prediction of surface accessible protein residues have been proposed in the past. However, most of these methods are computationally complex and time consuming. In this thesis, we propose a simple method based on protein sequence homology parameters for the binary classification of protein residues as surface accessible or “buried”. To aid in the classification of protein residues, we chose three highly conservative homology-based parameter <b>filter</b> <b>thresholds.</b> The <b>filter</b> <b>thresholds</b> predicted and evaluated are: residue sequence entropy ≥ 0 : 15, fraction of strongly hydrophobic residues 3 ̆c 0 : 5 and fraction of small residues 3 ̆c 0 : 15. The application of these <b>filter</b> <b>thresholds</b> to the residues, is expected to predict the “buried residues” with a better percentage accuracy than that of the surface accessible residues. These <b>filter</b> <b>thresholds</b> were selected from the frequency distributions and the aggregate correlation plots of the various homology-based parameters. An analysis of the plots suggests the presence of a strongly hydrophobic core between packing density 14 – 22 where the presence of strongly hydrophobic residues is maximum and the presence of small and non-strongly hydrophobic residues is minimum. However, the densest portion of the protein (density 26 – 35) is indicated to be occupied by a combination of small and non-strongly hydrophobic residues with a negligible presence of strongly hydrophobic residues...|$|R
30|$|All the accessions were {{subjected}} to genotyping-by-sequencing (GBS) as described by Biscarini et al. (2016). The analysis yielded a set of 166, 418 SNP markers, which were filtered for call rate (1 - percentage of missing data) and minor allele frequency (MAF) with the PLINK software ([URL] Purcell et al. 2007). Different <b>filtering</b> <b>thresholds</b> were chosen depending on the analysis performed.|$|R
40|$|In this paper, a {{homomorphic}} filtering based change detection {{algorithm is}} proposed to detect moving objects from light-varing monocular image sequences. In our approach, a background model is first constructed, and background subtraction is applied to classify image pixels into background or foreground. We utilize illumination invariant local components to model the background, which are obtained using homomorphic <b>filtering.</b> <b>Threshold</b> for every pixel in the image can be selected automatically to accommodate the change of lighting. In addition, the connectivity information is integrated into the background-foreground classification process by Bayesian estimation. Experimental {{results show that the}} presented approach works well in the presence of heavy moving shadows and illumination variance. 1...|$|E
40|$|To {{reduce the}} noise error {{existing}} in the output signal of fiber optic gyroscopes (FOGs) {{and increase the}} precision of the FOGs, this paper established a mathematical model of the FOGs output signal, analyzed the error characteristics of the FOGs output signal, put forward a new de-noising arithmetic based on the wavelet transform, soft and hard threshold compromise <b>filtering,</b> <b>threshold</b> values were determined by multi-dimensions recursion arithmetic. Through experiment, it has been already validated that the proposed approach had the competitive performances on visual quality, {{signal to noise ratio}} (SNR) and the standard variation, it is effective in eliminating the white noises existing in the output signal of the FOG...|$|E
40|$|In {{this paper}} an attempt {{has been made}} to develop a {{progressive}} partitioning and counting inference approach for mining association rules in temporal databases. A temporal database like a sales database is a set of transactions where each transaction T is a set of items in which each item contains an individual exhibition period. The existing models of association rule mining have problems in handling transactions {{due to a lack of}} consideration of the exhibition period of each individual item and lack of an equitable support counting basis for each item. As a remedy to this problem we propose an innovative algorithm PPCI that combines progressive partition approach with counting inference method to discover association rules in a temporal database. The basic idea of PPCI is to first segment the database into sub-databases in such a way that items in each sub-database will have either a common starting time or a common ending time. Then for each sub-database, PPCI progressively filters 1 -itemset with a cumulative <b>filtering</b> <b>threshold</b> based on vital partitioning characteristics. Algorithm PPCI is also designed to employ a <b>filtering</b> <b>threshold</b> in each partition to prune out those cumulatively infrequent 1 -itemsets early and it also uses counting inference approach to minimise as much as possible the number of pattern support counts performed when extracting frequent patterns. Explicitly the execution time of PPCI in order of magnitude is smaller than those required by the schemes which are directly extended from existing methods. Temporal association rule, exhibition period, frequent itemset, counting inference...|$|E
40|$|Gene {{filtering}} is {{a useful}} preprocessing technique often applied to microarray datasets. However, it is no common practice because clear guidelines are lacking and it bears the risk of excluding some potentially relevant genes. In this work, we propose to model microarray data as a mixture of two Gaussian distributions {{that will allow us}} to obtain an optimal <b>filter</b> <b>threshold</b> in terms of the gene expression level...|$|R
30|$|For defect detection/identification of RoI, gray level-based spatial domain {{techniques}} (gradient <b>filter,</b> <b>thresholding,</b> local contrast etc.) {{and joint}} spatial/frequency-based techniques (various types of wavelets) have been used. Spatial domain techniques are fast {{and easy to}} implement compared to wavelet-based methods, {{and they have been}} used in most of the papers where suitability for real-time operation have also been reported [2, 24, 26, 35, 46, 58, 59, 61, 76].|$|R
40|$|Standard radar {{processing}} chains compute coherent processing functions, estimate {{noise level}} and apply associated threshold. Then, the extraction function groups elementary detections {{to distinguish between}} the different targets and to estimate their position. In this paper, it is proposed to combine coherent <b>filtering,</b> <b>thresholding</b> and extraction into a single Compressed Sensing process named “Extract Before Detect”. The proposed technique is based on Approximate Message Passsing (AMP), adapted to th...|$|R
40|$|Animal social {{networks}} offer an important research mechanism for animal behaviour analysis. Inferring social network structures in ecological systems from spatiotemporal data streams [1] presents a procedure to build such networks based on animal?s foraging process data {{which consists of}} time and location records. The method clusters the individuals into different gathering events and links up the individuals that appear in the same events, and subsequently filters coincident links. However, the original model does not perform well in many aspects, including time and space complexity and not-unique coincident link <b>filtering</b> <b>threshold.</b> To modify this method, fuzzy c-means is employed in this work to cluster all links into two groups, strong links or weak links. The work presented here also experimentally compares {{the performance of the}} proposed modification against the original method, demonstrating the efficacy of the modified version. ? 2018, Springer International Publishing A...|$|E
40|$|AbstractNoisy objects {{have been}} known to affect {{negatively}} on the performance of clustering algorithms. This paper addresses the problem of high false positive rates in using self-organizing map (SOM) for DNA motif prediction due to the noisy background sequences in the input dataset. We propose the use of sequence filter in the pre-processing step to remove portion of the noisy background before applying to the SOM. Our method is motivated by the evolutionary conservation property of binding sites as opposed to randomness of background sequences. Our contributions are: (a) propose the use of string mismatch as <b>filtering</b> <b>threshold</b> function; and (b) two filtering methods, namely sequence driven and gapped consensus pattern, are proposed for filtering. We employed real datasets to evaluate the performance of SOM for DNA prediction after the filtering process. Our evaluation results show promising improvements in term of precision rates and also data reduction. We conclude that filtering background sequences is a feasible solution to improve prediction accuracy of using SOM for DNA motif prediction...|$|E
40|$|International audienceThe {{consideration}} of underlying analysis of user's information {{need is a}} key requirement in an intelligent filtering environment. However, the majority of current approaches to filtering are relevance-oriented, rather than user-oriented. This is partly because they are issued from fields that have somewhat different perspectives from that of information filtering, {{but also because of}} the difficulty of understanding and measuring user's motivations {{and the way in which}} the user expects the system to respond. This paper presents an original approach to information analysis and filtering inspired by the novelty detection theory. As well as being able to accurately learn user's information need, the approach has an analytical capacity for better understanding user's need. It provides a new way of looking at user's need in terms of precise, broad, and contradictory profile-contributing criteria. These criteria go on to estimate the relative importance the user might attach to precision and recall. The <b>filtering</b> <b>threshold</b> is then adjusted taking into account this knowledge about user's need. Experimental results on the standard Reuters- 21578 collection prove the effectiveness of the approach and confirm the potential usefulness of adapting the filtering results according to the knowledge acquired about user's need...|$|E
40|$|The {{symmetric}} weighted {{median filter}} {{is a natural}} extension of the me-dian filter and has the same advantages as the median filter: edge preserva-tion and efficient suppression of impulsive noise [1]. The symmetric weighted <b>threshold</b> <b>filter</b> is a generalization of the symmetric weighted median filter. It is natural to iterate the symmetric weighted <b>threshold</b> <b>filter</b> {{in order to reduce the}} noise still further. An interesting question to be asked is what iterative behavior the the symmetric weighted <b>threshold</b> <b>filter</b> has if we ap-ply iteratively the symmetric weighted <b>threshold</b> <b>filter</b> to a fixed sequence. For sequences with finite support, it was shown that the iterated sequences of the symmetric threshold automaton converges or gets trapped in a peri-odic orbit of period 2 ([2, 3]). P. D. Wendt [4] applied the fact to analyze the iterative behavior of stack filters and proposed a method to transform a symmetric weighted <b>threshold</b> <b>filter</b> into a symmetric threshold automaton if this symmetric weighted <b>threshold</b> <b>filter</b> preserves roots of median filter. But for sequences with infinite the method above does not work. In this paper...|$|R
30|$|The {{main purpose}} of this paper is to {{introduce}} a novel method to denoise and detect transient disturbances. The IAKR method is an effective image denoising tool that can not only suppress noise effectively, but also preserve the details in images, such as edges. Based on deep research of this method, the IIAKR method is proposed for transient PQD denoising and detection, which has the advantage of avoiding estimating noise variance and a <b>filter</b> <b>threshold.</b>|$|R
40|$|The {{filtering}} of {{a digital}} situation model (DSM) containing points located on vegetation and buildings to a digital height model (DHM) is {{depending upon the}} structure of the objects not belonging to the bare ground. The limitation of an automatic global filtering of a DSM as a compromise between the different object classes is shown. Based on an automatic segmentation for each different class the required <b>filter</b> <b>thresholds</b> could be determined automatically for reaching an optimal filter result. 1...|$|R
40|$|In this paper, {{we explore}} {{a new problem}} of mining general {{temporal}} association rules in publication databases. In essence, a publication database {{is a set of}} transactions where each transaction T is a set of items of which each item contains an individual exhibition period. The current model of association rule mining is not able to handle the publication database due to the following fundamental problems, i. e., (1) lack of consideration of the exhibition period of each individual item; (2) lack of an equitable support counting basis for each item. To remedy this, we propose an innovative algorithm Progressive-Partition-Miner (abbreviatedly as PPM) to discover general temporal association rules in a publication database. The basic idea of PPM is to first partition the publication database in light of exhibition periods of items and then progressively accumulate the occurrence count of each candidate 2 -itemset based on the intrinsic partitioning characteristics. Algorithm PPM is also designed to employ a <b>filtering</b> <b>threshold</b> in each partition to early prune out those cumulatively infrequent 2 -itemsets. Explicitly, the execution time of PPM is, in orders of magnitude, smaller than those required by the schemes which are directly extended from existing methods. ...|$|E
40|$|In school, we {{have been}} learned about {{two-dimensional}} figure i. e. triangle, square, rectangle, circle, etc. Developments {{in the world of}} technology and informatics enabled build an application to recognize two-dimensional figure. This program is created to recognition an isosceles triangle by matching two triangles that have different position. This program using mathematical algorithms that are translation and rotation to make the process of rotation of the triangles. In this program there are ten triangle images that will be tested with five triangle images as a reference image. Before rotate the tested triangle, it will through several preprocessing step that are grayscale, <b>filtering,</b> <b>threshold,</b> edge detection and thinning. After that, the image will be rotated such that it found a position approaching to one of the images in the database. The result of this program is the percentage value of similarity acquired by test image. From the result of this research shows that 3 triangles are most similarity to image 3. png, while 4 triangles are most similarity to image 4. png, 1 triangle is most similarity to image 5. png. Two other triangles have more than one percentage value of similarity with same value...|$|E
40|$|We explore in {{this paper}} an e#ective sliding-window {{filtering}} (abbreviatedly as SWF) algorithm for incremental mining of association rules. In essence, by partitioning a transaction database into several partitions, algorithm SWF employs a <b>filtering</b> <b>threshold</b> in each partition {{to deal with the}} candidate itemset generation. Under SWF, the cumulative information of mining previous partitions is selectively carried over toward the generation of candidate itemsets for the subsequent partitions. Algorithm SWF not only significantly reduces I/O and CPU cost by the concepts of cumulative filtering and scan reduction techniques but also effectively controls memory utilization by the technique of sliding-window partition. Algorithm SWF is particularly powerful for efficient incremental mining for an ongoing time-variant transaction database. By utilizing proper scan reduction techniques, only one scan of the incremented dataset is needed by algorithm SWF. The I/O cost of SWF is, in orders of magnitude, smaller than those required by prior methods, thus resolving the performance bottleneck. Experimental studies are performed to evaluate performance of algorithm SWF. It is noted that the improvement achieved by algorithm SWF is even more prominent as the incremented portion of the dataset increases and also as the size of the database increases...|$|E
3000|$|... where H^t_k-j {{represents}} the output at prior time k−j of the Hampel <b>filter</b> with <b>threshold</b> parameter t {{applied to the}} input sequence x [...]...|$|R
40|$|An all fiber, widely tunable, single-frequency, erbium-doped fiber ring laser was {{constructed}} with a threshold pump power {{as low as}} 10 mW. Tuning over more than 30 nm was obtained by applying 0 to 17 dc V to an intracavity fiber Fabry–Perot <b>filter.</b> <b>Threshold</b> pump power versus wavelength data showed low variation over the tuning range. Mode hopping suppression with a tandem fiber Fabry–Perot filter is proposed and demonstrated. Stable single-frequency operation was demonstrated with side mode suppression higher than 35 dB...|$|R
40|$|Abstract – A novel {{method for}} the removal of impulse noise from digital images is introduced. In {{proposed}} <b>filter,</b> <b>threshold</b> is computed locally from image pixels intensity values in a window and a detail preserving noise filter. Initially, detection phase classifies any possible impulsive noise pixels. Subsequently, the filtering phase replaces the detected noise pixels where fuzzy reasoning is employed to deal with uncertainties. Results show that proposed method provides better performance in terms of PSNR than many other median filter variants for random-valued impulse noise...|$|R
40|$|A Bloom Filter is a space-efficient {{randomized}} {{data structure}} allowing membership queries over sets with certain allowable errors. It {{is widely used}} in many applications which take advantage {{of its ability to}} compactly represent a set, and filter out effectively any element that does not belong to the set, with small error probability. This paper introduces the Spectral Bloom Filter (SBF), an extension of the original Bloom Filter to multi-sets, allowing the filtering of elements whose multiplicities are below a threshold given at query time. Using memory only slightly larger than that of the original Bloom Filter, the SBF supports queries on the multiplicities of individual keys with a guaranteed, small error probability. The SBF also supports insertions and deletions over the data set. We present novel methods for reducing the probability and magnitude of errors. We also present an efficient data structure and algorithms to build it incrementally and maintain it over streaming data, as well as over materialized data with arbitrary insertions and deletions. The SBF does not assume any a priori <b>filtering</b> <b>threshold</b> and effectively and efficiently maintains information over the entire data-set, allowing for ad-hoc queries with arbitrary parameters and enabling a range of new applications. 1...|$|E
40|$|Abstract. During deep {{penetration}} laser welding, {{a keyhole}} is {{formed in the}} molten pool. The characteristics of keyhole {{are related to the}} welding quality and stability. Analyzing the characteristic parameters of a keyhole during high power fiber laser welding is one of effective measures to control the welding quality and improve the welding stability. This paper studies a fiber laser butt-joint welding of type 304 austenitic stainless steel plate with a high power 10 kW continuous wave fiber laser. And an infrared sensitive high-speed video camera was used to capture the dynamic images of the molten pools. A combination filtering system with a filter length of 960 - 990 nm in front of the vision sensor was used to obtain the near infrared image and to eliminate other light disturbances. The width, area, leftmost point, rightmost point, upmost point and the bottommost point of a keyhole were defined as the keyhole characteristic parameters. By using the image preprocessing method, such as median filtering, Wiener <b>filtering,</b> <b>threshold</b> segmentation and Canny edge detection methods, the characteristic parameters of a keyhole were obtained. By analyzing the change of the keyhole characteristic parameters during welding process, it was found that these parameters could reflect the quality and stability of laser welding effectively...|$|E
40|$|Gene {{expression}} array technology {{has reached the}} stage of being routinely used to study clinical samples in search of diagnostic and prognostic biomarkers. Due {{to the nature of}} array experiments, which examine the expression {{of tens of thousands of}} genes simultaneously, the number of null hypotheses is large. Hence, multiple testing correction is often necessary to control the number of false positives. However, multiple testing correction can lead to low statistical power in detecting genes that are truly differentially expressed. Filtering out non-informative genes allows for reduction in the number of null hypotheses. While several filtering methods have been suggested, the appropriate way to perform filtering is still debatable. We propose a new filtering strategy for Affymetrix GeneChips®, based on principal component analysis of probe-level gene expression data. Using a wholly defined spike-in data set and one from a diabetes study, we show that filtering by the proportion of variation accounted for by the first principal component (PVAC) provides increased sensitivity in detecting truly differentially expressed genes while controlling false discoveries. We demonstrate that PVAC exhibits equal or better performance than several widely used filtering methods. Furthermore, a data-driven approach that guides the selection of the <b>filtering</b> <b>threshold</b> value is also proposed...|$|E
40|$|Investigation {{involving}} {{patients with}} {{injuries in the}} visual nervous system are discussed. This led to {{the identification of the}} epithelial ganglion of the retina as a frequency <b>filter.</b> <b>Threshold</b> curves of the injured visual organs were compared with threshold curves obtained with a control group as a basis for identification. A model which considers the epithelial ganglion as a homogeneous cell layer in which adjacent neurons interact is discussed. It is shown the behavior of the cells against alternating exciting currents can be explained...|$|R
40|$|Abstract – In this paper, {{we present}} a novel method {{for the removal of}} impulse noise from digital images. In {{proposed}} <b>filter,</b> <b>threshold</b> is computed locally from image pixels intensity values in a sliding window and a detail preserving noise filter. Initially, detection phase classifies any possible impulsive noise pixels. Subsequently, the filtering phase replaces the detected noise pixels where fuzzy reasoning is employed to deal with uncertainties. Results show that proposed method provides better performance in terms of PSNR and MAE than many other median filter variants for random-valued impulse noise...|$|R
40|$|In {{this paper}} we suggest a new method for {{controlling}} the balling drums {{used in the}} iron ore industry. We suggest that a cluster of drums are controlled collectively rather than individually. Further, we investigate {{the possibility of using}} an extended Kalman filter for estimating the amplitude and frequency of the oscillations in such drums. The <b>filters</b> <b>thresholding</b> point is identified, and the area for which the filter is usable is given. Finally a simulation of the proposed control scheme, based on a simple nonlinear model, is presented...|$|R
40|$|AbstractVisual {{search and}} {{identification}} of analyzable metaphase chromosomes using optical microscopes {{is a very}} tedious and time-consuming task that is routinely performed in genetic laboratories to detect and diagnose cancers and genetic diseases. The {{purpose of this study}} is to develop and test a computerized scheme that can automatically identify chromosomes in metaphase stage and classify them into analyzable and un-analyzable groups. Two independent datasets involving 170 images are used to train and test the scheme. The scheme uses image <b>filtering,</b> <b>threshold,</b> and labeling algorithms to detect chromosomes, followed by computing a set of features for each individual chromosome as well as for each identified metaphase cell. Two machine learning classifiers including a decision tree (DT) based on the features of individual chromosomes and an artificial neural network (ANN) using the features of the metaphase cells are optimized and tested to classify between analyzable and un-analyzable cells. Using the DT based classifier the Kappa coefficients for agreement between the cytogeneticist and the scheme are 0. 83 and 0. 89 for the training and testing datasets, respectively. We apply an independent testing and a 2 -fold cross-validation method to assess the performance of the ANN-based classifier. The area under and receiver operating characteristic (ROC) curve is 0. 93 for the complete dataset. This preliminary study demonstrates the feasibility of developing a computerized scheme to automatically identify and classify metaphase chromosomes...|$|E
40|$|This paper {{describes}} {{a method for}} defining route structure from flight tracks. Dynamically gen-erated route structures could be useful in guid-ing dynamic airspace configuration and helping controllers retain situational awareness under dy-namically changing traffic conditions. Individual merge and diverge intersections between pairs of flights are identified, clustered, and grouped into nodes of a route structure network. Links are placed between nodes to represent major traffic flows. A parametric analysis determined the al-gorithm input parameters producing route struc-tures of current day flight plans that are closest to todays airway structure. These parameters are then used to define and analyze the dynamic route structure {{over the course of}} a day for current day flight paths. Route structures are also compared between current day flight paths and more user preferred paths such as great circle and weather avoidance routing. Nomenclature A = airway structure B = boundary C = cluster D = diverge I = intersection L = link M = merge N = node n = number P = path or sequence of points p = point position R = route structure r = lateral radial distance S = airway segment w = weight z = vertical distance δ = structure deviation η = boundary proximity percentage λ = structure representation ρ = intersection representation σ = standard deviation τ = flight track data time range ω = <b>filtering</b> <b>threshold...</b>|$|E
40|$|Visual {{search and}} {{identification}} of analyzable metaphase chromosomes using optical microscopes {{is a very}} tedious and time-consuming task that is routinely performed in genetic laboratories to detect and diagnose cancers and genetic diseases. The {{purpose of this study}} is to develop and test a computerized scheme that can automatically identify chromosomes in metaphase stage and classify them into analyzable and un-analyzable groups. Two independent datasets involving 170 images are used to train and test the scheme. The scheme uses image <b>filtering,</b> <b>threshold,</b> and labeling algorithms to detect chromosomes, followed by computing a set of features for each individual chromosome as well as for each identified metaphase cell. Two machine learning classifiers including a decision tree (DT) based on the features of individual chromosomes and an artificial neural network (ANN) using the features of the metaphase cells are optimized and tested to classify between analyzable and un-analyzable cells. Using the DT based classifier the Kappa coefficients for agreement between the cytogeneticist and the scheme are 0. 83 and 0. 89 for the training and testing datasets, respectively. We apply an independent testing and a two-fold cross-validation method to assess the performance of the ANN-based classifier. The area under and receiver operating characteristic (ROC) curve is 0. 93 for the complete dataset. This preliminary study demonstrates the feasibility of developing a computerized scheme to automatically identify and classify metaphase chromosomes...|$|E
40|$|The best fully {{automated}} analysis process achieves even better classification results than the established manual process. The best algorithms {{for the three}} analysis steps are (i) SGLTR (Savitzky-Golay Laplace operator <b>filter</b> <b>thresholding</b> regions) and LM (Local Maxima) for automated peak identification, (ii) EM clustering (Expectation Maximization) and DBSCAN (Density-Based Spatial Clustering of Applications with Noise) for the clustering step and (iii) RF (Random Forest) for multivariate classification. Thus, automated methods can replace the manual steps in the analysis process to enable an unbiased high throughput use of the technology...|$|R
40|$|The Diabetic {{retinopathy}} {{is the one}} {{the principal}} cause of blindness, {{and it is very}} challenging eye screening method. DR is categorized by two type of lesion viz. Hemorrhages and Microaneurysms. Early detection of these lesions may prevent the person from blindness. The paper introduced a morphological approach for lesion detection. The proposed early Microaneurysms detection method is processed through following steps namely fundus image acquisition, preprocessing, <b>filtering,</b> <b>thresholding</b> and FP reduction. The proposed system achieves the sensitivity of 83 %, specificity of 89 % and accuracy of 86 %...|$|R
40|$|Wavelet {{shrinkage}} denoising {{methods are}} widely used for estimation of biological signals from noisy environment. The popular Hard and Soft <b>thresholding</b> <b>filters</b> are commonly used in these methods. In this paper shrinkage method based on a New <b>Thresholding</b> <b>filter</b> for denoising of biological signals is proposed. The efficacy of this filter is evaluated by applying this filter for denoising of ECG signal contaminated with additive Gaussian noise. The performance of this filter is {{compared with that of}} Hard and Soft <b>thresholding</b> <b>filters</b> using Mean Square Error (MSE) and Signal to Noise ratio (SNR). Experiments revealed that the New <b>Thresholding</b> <b>filter</b> is significantly more efficient than Hard and Soft filters in denoising the signals. It embodies the features of both Hard and Soft filters. Different qualities of denoising are obtained by varying the parameters of this filter. Key words...|$|R
