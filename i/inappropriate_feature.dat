7|34|Public
40|$|Naive Bayes {{is often}} used in text {{classification}} applications and experiments because of its simplicity and effectiveness. However, its performance is often degraded {{because it does not}} model text well, and by <b>inappropriate</b> <b>feature</b> selection and the lack of reliable confidence scores. We address these problems and show that they can be solved by some simple corrections. We demonstrate that our simple modifications are able to improve the performance of Naive Bayes for text classification significantly...|$|E
30|$|The appearance-based methods, on {{the other}} hand, using image filters such as Gabor wavelets, {{generate}} the facial features for either the whole face or specific regions in a face image. The Active Shape Models (ASM) [14] and Active Appearance Models (AAM) [15] are two popular appearance-based methods with statistical face models to prevent locating <b>inappropriate</b> <b>feature</b> points. Cristinacce and Cootes [16] expanded AAM with constrained local models {{with a set of}} local feature templates. Milborrow and Nicolls [17] introduced modifications to the ASM with more sophisticated methods. However, these methods were mainly applied to a full face shape model. When the object is small in appearance, cluttered background and occlusion lead to severe ambiguity.|$|E
40|$|Abstract. A {{new concept}} for pattern {{classification}} systems is proposed {{in which the}} feature selection and the learning classifier are simultaneously carried out on-line. An advantage of this concept is that classification systems can improve their performance constantly even if insufficient training samples are given when the learning starts, often resulting in <b>inappropriate</b> <b>feature</b> selection and poor classifier performance. To implement this concept, we propose an adaptive evolving connectionist model in which Incremental Principal Component Analysis and Evolving Clustering Method are effectively combined. The proposed on-line learning scheme has two major desirable properties. First, the performance is improved as the learning proceeds and it converges to an acceptable level from any initial conditions. Second, the learning is sequentially carried out without retaining all the training data given so far; thus, the learning is conducted efficiently in term of the computation and memory costs. To evaluate the proposed model, the recognition performance is investigated using three standard datasets in the UCI machine learning repository. From the experimental results, we verify that the proposed scheme possesses the above two characteristics...|$|E
40|$|This {{resource}} is an interactive {{example of a}} non-accessible website. By rolling over particular features of the site, students can read explanatory text highlighting {{what is wrong with}} these features, and what kind of users they might affect in terms of accessibility. Some of the <b>inappropriate</b> <b>features</b> highlighted here include: flashing text; underlined text; use of capitals; and use of novelty fonts. ...|$|R
40|$|Highly {{regulated}} environments such as {{the medical}} device domain are increasingly developing software {{within the context of}} a huge number of mandatory regulations. In these domains, the problem is inflexibility, which results in long release cycles, difficult changes, and <b>inappropriate</b> <b>features.</b> To deal with these problems, we are developing the ACAPI approach that analyzes a company's agile capability and then introduces the appropriate agile practices to improve the software development. This contribution introduces the domain, the problems, and agile development, and then gives an overview of our idea of how to combine them to solve the problems...|$|R
40|$|The {{issues about}} the nature of science are today {{considered}} a core content of the scientific and technological literacy for all. However, the inclusion of the nature of science in the science school curriculum is not easy and requires some conditions. Oneimportant condition is setting up previous agreements on the specific features and contents of the nature of science that could be translated into the classroom practice for its explicit use in school science education. This paper reviews some contributionsof the science education research to achieve this condition. Finally, an empiric methodology designed to achieve consensus on the nature of science is put forward; the description embraces the agreements on the appropriate {{as well as on the}} <b>inappropriate</b> <b>features</b> of the nature of science...|$|R
40|$|Over {{the years}} {{significant}} {{research has been}} performed for machine vision based fabric inspection systems in order to replace manual inspection, which is time consuming and not accurate enough. Automated fabric inspection systems mainly involve two challenging problems: one is defect detection and another is classification, which remains elusive despite considerable research effort in automated fabric inspection. The research reported to date to solve the defect classification problem appears to be insufficient, particularly in selecting appropriate set of features. Scene analysis and feature selection play {{a very important role}} in the classification process. Insufficient scene analysis results in an inappropriate set of features. Selection of an <b>inappropriate</b> <b>feature</b> set increases complexities of subsequent steps and makes the classification task harder. Considering this observation, we present a possibly appropriate feature set in order {{to address the problem of}} fabric defect classification using neural network (NN). We justify the features from the point of view of distinguishing quality and feature extraction difficulty. We performed some experiments in order to show the utility of proposed features and compare performances with recently reported relevant works. More than 98 % classification accuracy has been found, which appears to be very promising...|$|E
40|$|AbstractBoth {{crowding}} and {{binocular rivalry}} impair object perception, but {{their influence on}} object perception has so far only been investigated in separate fields. Three experiments investigated the joint influences of crowding and rivalry on object perception (orientation discrimination). Experiment 1 investigated how crowding and rivalry influence orientation discrimination together. Experiment 2 tested whether rivalry between flankers affects crowding using an orientation discrimination task. Experiment 3 tested whether crowding affects the temporal dynamics of the rivalry between a target and a rival stimulus. In Experiment 1, judgments of target orientation were more impaired when crowding and rivalry were simultaneously induced than when they were separately induced and their effects were combined. In Experiment 2, judgments of target orientation were impaired even when flankers were undergoing rivalry, thus highlighting {{the importance of the}} presence of flankers. Experiment 3 showed that flankers presented in the neighborhood of a target undergoing rivalry shortened target dominance and prolonged target suppression. The augmented impairments of object perception found in Experiments 1 and 3 suggest that crowding and rivalry interact, presumably through signal suppression. The adverse effect of flankers shown in Experiment 2 suggests that <b>inappropriate</b> <b>feature</b> integration may have additionally contributed to this interaction...|$|E
40|$|Though naïve Bayes text {{classifiers}} {{are widely}} used because of its simplicity and effectiveness, the techniques for improving performances of these classifiers have been rarely studied. Naïve Bayes classifiers which {{are widely used}} for text classification in machine learning {{are based on the}} conditional probability of features belonging to a class, which the features are selected by feature selection methods. However, its performance is often imperfect because it does not model text well, and by <b>inappropriate</b> <b>feature</b> selection and some disadvantages of the Naive Bayes itself. Sentiment Classification or Text Classification is the act of taking a set of labeled text documents, learning a correlation between a document’s contents and its corresponding labels and then predicting the labels of a set of unlabeled test documents as best as possible. Text Classification is also sometimes called Text Categorization. Text classification has many applications in natural language processing tasks such as E-mail filtering, Intrusion detection systems, news filtering, prediction of user preferences, and organization of documents. The Naive Bayes model makes strong assumptions about the data: it assumes that words in a document are independent. This assumption is clearly violated in natural language text: there are various types of dependences between words induced by the syntactic, semantic, pragmatic and conversational structure of a text. Also, the particular form of the probabilistic model makes assumptions about the distributio...|$|E
40|$|Customer churn is {{the term}} used to {{describe}} customers who terminate their relationship with a company. Since churn means a loss of revenue to a company, {{it is important to}} identify customer churn and provide incentives to them in order to retain them to the company. This paper aims to design methodologies for the customer churn prediction problem in wireless telecommunications industry. Since the number of features in customer churn dataset is rather large, the performance of decision trees is significantly degraded if <b>inappropriate</b> <b>features</b> are selected and used for building decision trees. This paper finds features that have high effect on customer churn, and to design methodologies that will cope with high dimensionality of dataset and the customer churn prediction problem. This paper provides experimental results of a set of data mining schemes and feature selection methods for customer churn datasets. customer churn; classification models; data mining; decision trees; customer retention; customer relationship management; CRM; wireless communications; telecommunications industry...|$|R
40|$|Recently, machine {{learning}} (ML) algorithms have widely been applied in Internet traffic classification. However, {{due to the}} <b>inappropriate</b> <b>features</b> selection, ML-based classifiers are prone to misclassify Internet flows as that traffic occupies majority of traffic flows. To address this problem, a novel feature selection metric named weighted mutual information (WMI) is proposed. We develop a hybrid feature selection algorithm named WMI_ACC, which filters most of the features with WMI metric. It further uses a wrapper method to select features for ML classifiers with accuracy (ACC) metric. We evaluate our approach using five ML classifiers on the two different network environment traces captured. Furthermore, we also apply Wilcoxon pairwise statistical test {{on the results of}} our proposed algorithm to find out the robust features from the selected set of features. Experimental results show that our algorithm gives promising results in terms of classification accuracy, recall, and precision. Our proposed algorithm can achieve 99 % flow accuracy results, which is very promising...|$|R
40|$|International audienceSoftware Product Lines (SPL) aim at {{deriving}} software architectures or {{systems from}} a software artifact base. Configuring the SPL to derive {{a new product}} is now usually done by selecting appropriate software features {{in a kind of}} models, called feature models. In some situations, a feature represents a software artifact associated to an element e of a context the software product will manage. Such a feature and its associated software artifact may be cloned according to the number of occurrences of e in the context and constraints have to be respected. Hence, the feature model proposed to users for configuration has to be adapted in a new dedicated phase according to the context elements. We propose a model-driven engineering approach for transforming a generic feature model according to a context model that a derived software product will manage. More precisely this paper describes an original model transformation able to generate context specific feature models including duplicated <b>features,</b> and removing <b>inappropriate</b> <b>features.</b> Our transformation is validated on a smart building optimization software case study...|$|R
40|$|Currently, {{electronic}} medical {{instruments are}} widely used in hospitals, medical polyclinics and doctors' offices to gather vital information about patients' bodies. Experts interpret medical data to distinguish the causes of illnesses. EEG {{is an example of}} a form of medical information that has many features. If the number of samples of patients is enlarged the volume of EEG data can increase dramatically and consequently exceed the limited capacity that can possibly be classified.   In order to solve the problems posed by the limitations of the current classification ability, SVMs are used. In some applications such as cognitive science, the accuracy rate of SVM classifiers is low. This fact is due to the complexity of the problem. The low accuracy rate may be caused by <b>inappropriate</b> <b>feature</b> space or the inability of classifiers to generalize results. SVM Ensembles can vastly improve generalization as, although some classifiers are not trained well enough to excel globally, they can at least achieve an acceptable local performance. This study's intention was to investigate the enhancement of classifier performance possible by applying SVM ensembles to classify two groups of data that were gathered during a type of healing operation known as Reiki, performed by a professional, and a placebo with an ordinary person pretending to perform it. Genetic algorithm is also the applied to this data to find the best features and feature combinations that reduce training time whilst increasing the correction classification rate...|$|E
30|$|SIFT is {{selected}} as the algorithm to extract image features that {{are known to be}} invariant to the image scale and rotation. A feature detected by SIFT is called a keypoint. The algorithm generates a difference of Gaussian (DOG) from the image pyramid, and it detects the local extremes as the keypoint candidates in the DOG. Subsequently, the algorithm determines the keypoints that are normally <b>inappropriate</b> as <b>features,</b> by eliminating the candidates present on the edge or having a low-contrast.|$|R
40|$|We {{have made}} a {{generalization}} of the proposed method and given guidelines for its extension and application to other matching strategies where the similarity constraint is used. It has also been generalized to other types of environments, such as outdoor scenes or aerial images, where edge segments are probably <b>inappropriate</b> <b>features</b> and therefore different features and attributes would be more suitable. ACKNOWLEDGMENT The {{authors would like to}} thank the reviewers and Associate Editor for constructive recommendations. REFERENCES [1] S. H. Lee and J. J. Leou, “A dynamic programming approach to line seg-ment matching in stereo vision, ” Pattern Recognit., vol. 27, pp. 961 – 986, 1994. [2] D. Marr and T. Poggio, “A computational theory of human stereovision,” Proc. R. Soc. London B, vol. 207, pp. 301 – 328, 1979. [3] G. Medioni and R. Nevatia, “Segment based stereo matching, ” Comput. Vis., Graph., Image Process., vol. 31, pp. 2 – 18, 1985. [4] S. B. Pollard, J. E. W. Mayhew, and J. P. Frisby, “PMF: A stereo corre-spondence algorithm using a disparity gradient limit, ” Perception, vol. 14, pp. 449 – 470, 1981. [5] J. M. Cruz, G. Pajares, and J. Aranda, “A neural network approach to the stereovision correspondence problem by unsupervised learning, ” Neura...|$|R
50|$|The Aunty Jack {{character}} {{made her}} TV debut in Aunty Jack's Travelling Show, {{an episode of}} ABC-TV's The Comedy Game, broadcast in late 1971. It was originally to be called Aunty Jack's Travelling Abattoirs but ABC executives also found the title <b>inappropriate.</b> The program <b>featured</b> Bond, O'Donoghue and Derum, with Sharman Mellick and Kate Fitzpatrick in supporting roles.|$|R
5000|$|It {{included}} the stories [...] "Superman Jr. Is No More!", featuring the Super-Sons, and [...] "Letitia Lerner, Superman's Babysitter", among others. However, DC Comics President Paul Levitz deemed the Letitia Lerner story <b>inappropriate</b> (for <b>featuring</b> scenes depicting the baby Superman in a microwave, among others) {{and ordered the}} press run halted and the printed issues destroyed. However, around 2000 copies of the issue had already been shipped to the UK. Although DC attempted to recall these copies, they quickly became a highly sought after collector's item (see Recalled comics for more pulped, recalled and erroneous comics), and estimates of available copies range between 700 and 2000.|$|R
40|$|The partial defence of {{provocation}} was inappropriately used by abusive {{men that}} killed their partners for challenging them. This led to concerns that provocation was implicitly legitimising violent reactions toward {{women who were}} perceived to have challenged their male partner’s sexuality. Despite the abolition of provocation, this paper finds {{a continuation of the}} concerns that arose from the use of provocation in post-abolition homicide sentencing decisions. Specifically, the recognition of perceived lower culpability of men that had killed their female partners in the form of manslaughter verdicts, or through <b>inappropriate</b> mitigating <b>features,</b> continues to be an issue. For this reason, I argue that establishing the Sentencing Council, as recommended by the Law Commission, {{is the best way to}} address these concerns...|$|R
5000|$|A 1998 provincial {{commission}} of inquiry summarized the key factors:"The evidence suggests that significant building envelope failures in British Columbia since the early 1980s ... {{is a result of}} numerous factors, including design <b>features</b> <b>inappropriate</b> for our climate; a reliance on face-sealed wall systems; a fundamental lack of awareness regarding the principles of enclosure design suitable for our climate; meaningful inspection at critical stages of construction; and a regulatory system which was unable to understand that failures were occurring and to redress them." ...|$|R
50|$|To {{protect the}} privacy and {{anonymity}} of individuals, Google selectively blurred photographs containing car license number plates and people's faces in Google Street View. Users may request further blurring of images that feature the user, their family, their car or their home. Users can also request {{the removal of}} images that <b>feature</b> <b>inappropriate</b> content. In some countries (e.g. Germany) it modifies images of specific buildings. In the United States, Google Street View adjusts or omits certain images deemed of interest to national security by the federal government.|$|R
40|$|Volume {{is one of}} {{considered}} aspects in {{egg sorting}} process. A rapid and accurate volume measurement method is needed to develop an egg sorting system. Computer vision system (CVS) provides a promising solution for volume measurement problem. Artificial neural network (ANN) {{has been used to}} predict the volume of egg in several CVSs. However, volume prediction from ANN could have less accuracy due to <b>inappropriate</b> input <b>features</b> or <b>inappropriate</b> ANN structure. This paper proposes a CVS for predicting the volume of egg using ANN. The CVS acquired an image of egg from top view and then processed the image to extract its 1 D and 2 D size features. The features were used as input for ANN in predicting the volume of egg. The experiment results show that the proposed CSV can predict the volume of egg with a good accuracy and less computation time...|$|R
30|$|There {{are still}} some {{challenges}} for application of Lasso method in feature selection. The Lasso result is often subject to the scaling of <b>features.</b> <b>Inappropriate</b> scaling may cause imbalanced penalty on linear coefficients. The true underlining features with high coefficients may be suppressed to have smaller coefficients. As a result, the total explained variance is limited. Instead of rescaling all features, more generally one can employ adaptive Lasso [36] with penalty term λ∑ w_i||β _i||_ 1. Even so, effects of strong signal will be diminished due to shrinkage.|$|R
5000|$|A {{new series}} of Trigger Happy TV was made for the US market in 2003, for Comedy Central. It {{retained}} the original format but almost all sketches were performed by a cast including Jessica Makinson (13 episodes), Travis Draft (4 episodes), Jerry Minor (4 episodes) and Brett Reylander (3 episodes). A total of 13 episodes were made and broadcast on Comedy Central in the US, comprising the one series. Recurring sketches included a waitress with a large pepper mill appearing in incongruous places such as a park and offering {{members of the public}} fresh ground pepper, and a cheerleader whose <b>inappropriate</b> cheers <b>featured</b> topics such as skin cancer. The series was subsequently broadcast on Channel 4 in the UK, under the title [...] "Trigger Happy TV USA." [...] Though Joly did cameo sporadically on the show (he appeared {{to a greater or lesser}} extent in 4 episodes), he was very unhappy with the programme and called it [...] "Trigger Happy by numbers". He had a producer credit on the show, but disassociated himself with the project.|$|R
30|$|NoSQL datastores {{are getting}} {{increasing}} interest by users for their outstanding levels of flexibility, scalability, and performance, {{and their ability}} to manage huge data volumes. Despite this popularity, NoSQL datastores suffer from <b>inappropriate</b> data protection <b>features.</b> We believe that these shortcoming can be significantly addressed with the integration of FGAC features into the datastores. The integration of FGAC into a NoSQL datastore is a novel research topic that has been only recently addressed and that can open new research areas and applications. In this paper, we have discussed issues and challanges arising from the integration of FGAC features into NoSQL datastores. We have also described our experience with the MongoDB NoSQL datastore.|$|R
40|$|While Christian {{involvement}} in progressive social movements and activism is increasingly recognized, this literature has rarely gone beyond conceptualising {{religion as a}} resource to consider instead {{the ways in which}} individual activists may articulate their religious identity and how this intersects with the political. Based on ten in-depth interviews with Christian supporters of the London Occupy movement, this study offers an opportunity to respond to this gap by exploring the rich meaning-making processes of these activists. The article suggests that the location of the Occupy camp outside St Paul’s Cathedral was of central importance in bringing the Christian Occupiers’ religio-political identities to the foreground, their Christianity being defined in opposition to that represented by St Paul’s. The article then explores the religio-political meaning-making of the Christian Occupiers and introduces the term ‘activist religiosity’ as a way of understanding how religion and politics were articulated, and enacted, in similar ways. Indeed, religion and politics became considerably entangled and intertwined, rendering theoretical frameworks that conceptualise religion as a resource increasingly <b>inappropriate.</b> The <b>features</b> of this activist religiosity include post-institutional identities, a dislike of categorisation, and, centrally, the notion of ‘doings’—a predominant focus on engaged, active involvement...|$|R
5000|$|In the 21st century, Ebony {{frequently}} makes {{headlines in}} the blogosphere and in the mainstream press. The November 2011 cover featured a pregnant Nia Long, reminiscent of the iconic image of actress Demi Moore featured naked while pregnant on a magazine cover two decades before. Some of Ebony′s more conservative readers disagreed with the cover choice, stating it <b>inappropriate</b> to <b>feature</b> an unwed, pregnant woman on the cover. The cover was featured in US Weekly and in a five-minute segment on CNN. Zoe Saldana was featured on the August 2011 issue, and some readers questioned a Black latina cover star. However, the Avatar actress seemed to open Ebony to a new segment: Americans of mixed African-American and Hispanic ancestry. Recent issues question whether President Obama is still right for black America and whether biracial Americans need more acknowledgement in today's society. In June 2010, Ebony ran an article about radio personality Robin Quivers, long-time sidekick of radio host Howard Stern, in which Quivers was asked if she considered herself a [...] "sell out" [...] for working with a predominantly white media. Quivers dismissed the question.|$|R
40|$|Abstract- Optical {{character}} recognition strategies are concentrated towards improving recognition efficiencies by adapting post processing techniques. OCR errors of complex scripts {{are due to}} improper segmentation as well as <b>inappropriate</b> rendering. Topological <b>features</b> of a script as a global knowledge and geometrical features of isolated patterns as local knowledge are combined together while segmenting the basic unit, syllable. A multilevel segmentation was implemented to adopt the idea of human visual perception capability into the proposed model to use the distinct features exhibited by Devanagari script. The proposed method is based on implementing cognitive approach in segmentation phase by dealing with the syllable as a meaningful unit of information right from segmentation phase itself instead of isolated pattern on document images of Devanagari script...|$|R
40|$|Many EFL {{learners}} find it {{challenging to}} construct their author identity in English L 2 argumentative and academic writing. Learners may present brilliant content {{by means of}} <b>inappropriate</b> rhetorical <b>features</b> and fail to communicate their message. This study focuses {{on the construction of}} author identity in English L 2 writing by Russian learners. The quantitative study investigates the overuse, underuse and misuse of first person pronouns in English L 1 and L 2 writing. Preliminary results suggest the overuse of first person pronouns and the dominance of the we perspective, since the overuse rate is the highest here. The qualitative analysis supports this finding. The pronoun we is overused in high-risk functions, whereas the pronoun I is overused in low-risk functions. To account for the overuse, the study researches the possible reasons that could cause it, including the effect of L 1 transfer, influence of speech, developmental and teaching-induced factors. All the factors, except for the influence of speech, are found {{to have an impact on}} learner writing. The final chapter presents a comparative analysis of L 2 writing by learners with Slavic backgrounds, which reveals a common tendency to overuse the we perspective. The study contributes to the series of investigations of various learner varieties on the material of the ICLE and VESPA corpora...|$|R
40|$|In single-molecule protein experiments, the {{observable}} variables are restricted within {{a small fraction}} of the entire degrees of freedom. Therefore, to investigate the physical nature of proteins in detail, we always need to estimate the hidden internal structure referring only to the accessible degrees of freedom. We formulate this problem on the basis of Bayesian inference, which can be applied to various complex systems. In the ideal case, we find that in general the framework actually works. Although careful numerical studies confirm that our method outperforms the conventional method by up to two orders of magnitude, we find a striking phenomenon: a loss-of-precision transition occurs abruptly when the design of the observation system is <b>inappropriate.</b> The basic <b>features</b> of the proposed method are illustrated using a simple but nontrivial model...|$|R
30|$|As future work, {{we intend}} to extend BugMaps-Granger with other {{internal}} software quality metrics, including metrics associated to violations in the static architecture of software systems, as revealed by the DCL language (Terra and Valente 2009) or the ArchLint tool (Maffort et al. 2013), for example. Another possible research thread concerns the relations between defects and code smells. In this case, {{we intend to}} start by investigating the relations between defects and methods located in <b>inappropriate</b> classes (i.e., <b>feature</b> envy instances), as revealed by the JMove recommendation system (Sales et al. 2013). In addition, we plan to extend BugMaps-Granger with a new functionality for alerting maintainers about the future occurrence of defects. We intend to implement this tool as a plug-in for version control platforms, like SVN and Git. Basically, this new tool should trigger alarms whenever risky changes are committed to version control platforms.|$|R
40|$|Highlights - Rainfall {{increases}} the likelihood of single-vehicle (SV) crashes on mountainous highways. - Steep gradients along mountainous highways increase the likelihood of SV crashes. - Paved or wide shoulders are associated with lower SV crashes. - Road delineations are effective in reducing SV crashes along rural mountainous highways. Abstract Mountainous highways generally associate with complex driving environment because of constrained road geometries, limited cross-section elements, <b>inappropriate</b> roadside <b>features,</b> and adverse weather conditions. As a result, single-vehicle (SV) crashes are overrepresented along mountainous roads, particularly in developing countries, but little attention is known about the roadway geometric, traffic and weather factors contributing to these SV crashes. As such, the main objective of the present study is to investigate SV crashes using detailed data obtained from a rigorous site survey and existing databases. The final dataset included a total of 56 variables representing road geometries including horizontal and vertical alignment, traffic characteristics, real-time weather condition, cross-sectional elements, roadside features, and spatial characteristics. To account for structured heterogeneities resulting from multiple observations within a site and other unobserved heterogeneities, the study applied a random parameters negative binomial model. Results suggest that rainfall during the crash is positively associated with SV crashes, but real-time visibility is negatively associated. The presence of a road shoulder, particularly a bitumen shoulder or wider shoulders, along mountainous highways is associated with less SV crashes. While speeding along downgrade slopes {{increases the}} likelihood of SV crashes, proper delineation decreases the likelihood. Findings of this study have significant implications for designing safer highways in mountainous areas, particularly {{in the context of a}} developing country...|$|R
40|$|Cloud-Based Design and Manufacturing is a service-oriented {{networked}} {{product development}} {{model in which}} service consumers are enabled to configure, select and utilize customized product realization services ranging from computer-aided engineering software to reconfigurable manufacturing systems. So far, this paradigm has mainly been tested for digital design and fabrication processes including the usual steps of designing an artefact with a CAD system to then have a prototype manufactured with a 3 D printer. Unfortunately, a common mishap that can often be observed is that artefacts that look perfectly fine on the CAD computer screen come out severely misshaped on the 3 D printer. In this paper, we first investigate and document this phenomenon and explain its root cause, which concerns a) the data transmitted to the 3 D printer, b) <b>inappropriate</b> design <b>features,</b> and c) a mismatch between geometry requirements and printer capabilities. As more and more entrepreneurs, hobbyists in maker communities, and other not always fully trained individuals pursue their design and make ideas, {{there is a need}} for smart computer-based support to facilitate a successful design-to-print process. Such a digital DfM assistant might pop up to prompt a designer to modify identified critical areas of the design so that it can be printed with a chosen printer or alternatively propose another type of printer that may have the technical capabilities to accommodate the design in its current form. Acknowledging this need, we propose a two-stage smart manufacturability assistant. The first stage decomposes the digital model into a series of part features; the second stage of the model involved defining the capabilities of the 3 D-printer. Finally, we begin to realize this manufacturability assistant by creating and evaluating a bespoke test part which can be used to define a machine-material capability map for an example FDM process...|$|R
40|$|Crowding is the {{inability}} to identify an object among flankers in the periphery. It is due to <b>inappropriate</b> incorporation of <b>features</b> from flanking objects in perception of the target. Crowding is characterized by measuring critical spacing, the minimum distance needed between a target and flankers to allow recognition. The existing Bouma law states that, at a given point and direction in the visual field, critical spacing, measured {{from the center of}} a target object to the center of a similar flanking object, is the same for all objects (Pelli & Tillman, 2008). Because flipping an object about its center preserves its center-to-center spacing to other objects, according to the Bouma law, crowding should be unaffected. However, because crowding is a result of feature combination, the location of features within an object might matter. In a series of experiments, we find that critical spacing is affected by the location of features within the flanker. For some flankers, a flip greatly reduces crowding even though it maintains target–flanker spacing and similarity. Our results suggest that the existing Bouma law applies to simple one-part objects, such as a single roman letter or a Gabor patch. Many objects consist of multiple parts; for example, a word is composed of multiple letters that crowd each other. To cope with such complex objects, we revise the Bouma law to say that critical spacing is equal across parts, rather than objects. This accounts for old and new findings...|$|R
5000|$|In {{the summer}} of 2008, the Arc {{strongly}} criticized the movie Tropic Thunder, in which Ben Stiller portrays [...] "Simple Jack", {{a man with an}} intellectual disability. The Arc called the portrayal [...] "offensive" [...] and also objected {{to the use of the}} words [...] "retard", [...] "moron", and [...] "imbecile" [...] throughout the movie. The Arc was among a group of disability organizations, including the Special Olympics and the National Down Syndrome Congress which called for a boycott of the film. [...] Spokespeople for Tropic Thunder, along with Ben Stiller, argued that critics like the Arc did not understand that the movie was intended to make fun of actors and the movie industry, not individuals with disabilities, describing the movie as [...] "an R-rated comedy that satirizes Hollywood and its excesses and makes it point by <b>featuring</b> <b>inappropriate</b> and over-the-top characters in ridiculous situations." [...] However, the Arc continued to criticize the film as containing hate speech, promoting offensive stereotypes of people with intellectual disabilities, and being offensive to people with disabilities and their families. The Arc of the United States called for all of its chapters across the nation to picket and protest against the film, launched educational campaigns, and wrote open letters to Ben Stiller and the film's creators explaining their criticisms and calling for Stiller to meet with disability advocates to engage in [...] "honest and open dialogue about the offense this film perpetrates." ...|$|R
500|$|Disability {{advocates and}} others who previewed the film {{reported}} that the offensive treatment of individuals with mental disabilities was woven throughout the film's plot. Disability advocates urged people not to see the film, claiming it is demeaning to individuals with mental disabilities and would encourage bullying. Stiller defended the film, stating [...] "We screened the movie so many times and this didn't come up until very late ...in {{the context of the}} film I think it's really clear, they were making fun of the actors and actors who try to use serious subjects to win awards." [...] Co-writer Etan Cohen echoed Stiller's rationale: [...] "Some people have taken this as making fun of handicapped people, but we're really trying to make fun of the actors who use this material as fodder for acclaim." [...] He went on to state that the film lampoons actors who portray mentally retarded/autistic characters such as Dustin Hoffman in Rain Man, Tom Hanks in Forrest Gump, and Sean Penn in I Am Sam. A DreamWorks spokesman did not directly respond to the criticism, claiming that Tropic Thunder [...] "...is an R-rated comedy that satirizes Hollywood and its excesses, makes its point by <b>featuring</b> <b>inappropriate</b> and over-the-top characters in ridiculous situations." [...] The film's advertising was altered, but none of the scenes in the film were edited {{as a result of the}} opposition. In response to the controversy, the director's cut of the DVD (but not the Blu-ray) includes a public service announcement in the special features that discourages use of the word [...] "retard".|$|R
40|$|Feature subset {{selection}} can {{be analyzed}} as the practice of identifying and removing {{as a lot of}} <b>inappropriate</b> and unnecessary <b>features</b> as achievable. This is for the reason that, irrelevant features do not contribute to the predictive accuracy and redundant features do not redound to receiving a better analyst for that they provide typically information which is previously present in other features. To deal with these we develop a novel algorithm called as a fast clustering-based feature selection algorithm which can efficiently and effectively obtain a good feature subset. One more an important issue in feature subset selection is Feature interaction. Still, the majority of the presented algorithms only spotlight on dealing with irrelevant and redundant features. In this paper, a hybrid FOIL Rule based Feature subset Selection algorithm (FRFS) is developed, with combination of RIPPER algorithm which not only retains relevant features and eliminates irrelevant and redundant ones but also reflects on feature interaction for high dimensional data. First, FRRFS(FOIL Rules RIPPER Based Feature Selection) combines the features emerged in the predecessors of the entire FOIL rules by using RIPPER it generates best FOIL rules for both negative and positive rules by achieving a candidate feature subset which eliminates redundant features and reserves interactive ones. After that, it identifies and eliminates irrelevant features by evaluating features in the candidate feature subset with a new metric Cover Ratio, and achieves the final feature subset. The experimented results shows that the efficiency and effectiveness of FRRFS(FOIL Rules RIPPER Based Feature Selection) upon both synthetic and real world data sets, and it is evaluated with other feature subset selection algorithms and the classification accuracies before and after feature selection...|$|R
