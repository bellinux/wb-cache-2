211|5738|Public
25|$|Honavar {{is known}} for his {{research}} contributions in artificial intelligence, machine learning, data mining, knowledge representation, neural networks, semantic web, big data analytics, and bioinformatics and computational biology. He has published over 250 research articles, including many highly cited ones, as well as several books on these topics. His recent work has focused on scalable algorithms for constructing predictive models from large, semantically disparate distributed <b>data,</b> <b>learning</b> predictive models from linked open data, big data analytics, analysis and prediction of protein-protein, protein-RNA, and protein-DNA interfaces and interactions, social network analytics, health informatics, secrecy-preserving query answering, representing and reasoning about preferences, and causal inference and meta analysis.|$|E
5000|$|EUCLID [...] - {{abbreviation}} for EdUcational Curriculum for {{the usage of}} Linked Data: Development, Implementation and Dissemination of Linked <b>data</b> <b>learning</b> material and activities for data practitioners who use to work with Linked data. fluidOps develops a community portal based on the Information Workbench. Funded by the 7th Framework Programme of the European Union the project runs for 24 months and started in May 2012. Project partners [...] are KIT, The Open University [...] STI Research, Universidad Simon Bolivar, University of Southampton and Ontotext.|$|E
50|$|Honavar {{is known}} for his {{research}} contributions in artificial intelligence, machine learning, data mining, knowledge representation, neural networks, semantic web, big data analytics, and bioinformatics and computational biology. He has published over 250 research articles, including many highly cited ones, as well as several books on these topics. His recent work has focused on scalable algorithms for constructing predictive models from large, semantically disparate distributed <b>data,</b> <b>learning</b> predictive models from linked open data, big data analytics, analysis and prediction of protein-protein, protein-RNA, and protein-DNA interfaces and interactions, social network analytics, health informatics, secrecy-preserving query answering, representing and reasoning about preferences, and causal inference and meta analysis.|$|E
50|$|Chez Viking is {{the fourth}} studio album by American post-rock band The Mercury Program, {{released}} in 2009 on Lovitt Records; seven years after their previous album A <b>Data</b> <b>Learn</b> the Language.|$|R
50|$|There are 4 major {{types of}} data used in education: {{demographics}} data, perceptions <b>data,</b> student <b>learning</b> <b>data,</b> and school processes data.|$|R
5000|$|A <b>Data</b> <b>Learn</b> the Language is {{the third}} studio album by American post-rock band The Mercury Program, {{released}} in 2002 on Tiger Style Records. Allmusic called it [...] "consistently melodic, rhythmically varied, and unfailingly listenable." ...|$|R
40|$|The <b>data</b> <b>learning</b> {{problem is}} a {{phenomenon}} that arises when an agent employing a cognitive architecture faces the task of acquiring declarative information from an external source, such as the “answer ” to a “question”. Because the agent has {{to pay attention to}} both question and answer in order to learn the association between them, it is problematic for the agent to learn to produce the answer in response to the question alone. This observation helps shape the basic characteristics of human memory. The problem was first reported with the Soar architecture, but it arises also in ACT-R, and this paper argues that it will occur in any cognitive architecture, connectionist as well as symbolic, which is specified in a sufficiently explicit manner to avoid having the theorist act as an implicit homunculus for the agent. The <b>Data</b> <b>Learning</b> Problem The <b>data</b> <b>learning</b> {{problem is a}} phenomenon that arises when an agent faces the task of acquiring declarative information provided by an external source. Paradigmatic tasks are, in the laboratory, paired associates, where in response to a stimulus word such as shelf, the agent has to learn to say the digit eight; or in everyday life, learning the correct answer to a question, such as that the capital of France is Paris. In such situations, both the question and the answer (or the “stimulus ” and the “response”) must be present and attended to by the agent, in order to learn the connection between them. Thus the agent must process both the question “capital of France? ” and the answer “Paris ” if it is to acquire the relevant fact. It is therefore problematic for the agent to acquire a directed association from the question to the answer, such that {{it will be able to}} retrieve the answer in response to the question alone, without the answer also being present. The <b>data</b> <b>learning</b> problem was first identified in work with the Soar cognitive architecture. However, this paper shows that the problem occurs with ACT-R as well, and argues that it arises in any architecture which is sufficiently theoretically explicit. The <b>Data</b> <b>Learning</b> Problem in Soar The <b>data</b> <b>learning</b> problem was first noticed and discussed (and termed the data chunking problem) by Rosenbloom...|$|E
30|$|As {{shown in}} the works listed above, feature {{learning}} shows promising results in many audio and music information retrieval fields when appropriate input <b>data,</b> <b>learning</b> algorithms, and pre/postprocessing methods are used.|$|E
40|$|In this dissertation, {{the problem}} of {{learning}} from highly imbalanced data is studied. Imbalance <b>data</b> <b>learning</b> is of great importance and challenge in many real applications. Dealing with a minority class normally needs new concepts, observations and solutions in order to fully understand the underlying complicated models. We try to systematically review and solve this special learning task in this dissertation. We propose a new ensemble learning framework—Diversified Ensemble Classifiers for Imbalanced <b>Data</b> <b>Learning</b> (DECIDL), based on the advantages of existing ensemble imbalanced learning strategies. Our framework combines three learning techniques: a) ensemble learning, b) artificial example generation, and c) diversity construction by reversely data re-labeling. As a meta-learner, DECIDL utilizes general supervised learning algorithms as base learners to build an ensemble committee. We create a standard benchmark data pool, which contains 30 highly skewed sets with diverse characteristics from different domains, {{in order to facilitate}} future research on imbalance <b>data</b> <b>learning.</b> We use this benchmark pool to evaluate and compare our DECIDL framework with several ensemble learning methods, namely under-bagging, over-bagging, SMOTE-bagging, and AdaBoost. Extensive experiments suggest that our DECIDL framework is comparable with other methods. The data sets, experiment...|$|E
40|$|Drachsler, H., Herder, E., d'Aquin, M., & Dietze, S. (2013, 8 - 12 April). Evaluation of Linked <b>Data</b> {{tools for}} <b>Learning</b> Analytics. Presentation {{given in the}} {{tutorial}} on 'Using Linked <b>Data</b> for <b>Learning</b> Analytics' at LAK 2013, the Third Conference on Learning Analytics and Knowledge, Leuven, Belgium. Presentation given in the tutorial on 'Using Linked <b>Data</b> for <b>Learning</b> Analytics' at LAK 13...|$|R
50|$|Orange is a component-based visual {{programming}} software package for <b>data</b> visualization, machine <b>learning,</b> <b>data</b> mining and data analysis.|$|R
40|$|Abstract:- Many studies about <b>learning</b> {{in limited}} <b>data</b> {{were made in}} recent years. Without double, small <b>data</b> set <b>learning</b> is a {{challenging}} problem. Information in data of small size is scarce and has some learning limit. While discussing the learning accuracy in limited data, different classification method causes different results for different data because each classification method has its property. A method is the best solution for one data but {{is not the best}} for another. Therefore, this study analyzes the characteristics of small <b>data</b> set <b>learning</b> by the comparison of classification methods. The Mega-fuzzification method for small <b>data</b> set <b>learning</b> is applied mainly. The comparison of different classification methods for small <b>data</b> set <b>learning</b> with several kinds of data is also presented...|$|R
40|$|Abstract: We {{developed}} a pedestrian classifier using GFB(Gabor Filter Bank) -based feature extraction and SVM(Support Vector Machine). Because the SVM uses RBF(Radial Basis Function) and is applied for nonseparable <b>data,</b> <b>learning</b> parameters should be optimized. This paper proposes GA(Ganetic Algorithm) -based optimization of SVM learning parameters. 1...|$|E
30|$|Recent {{advances}} in big <b>data,</b> <b>learning</b> analytics, and scalable architectures present new opportunities to redesign adaptive learning systems. This paper is part directional and part speculative. We sketch a possible future for designing next generation adaptive learning systems based on {{new developments in}} learning science and data science.|$|E
30|$|In Fig.  6 a, ARMA (5, 3) is used {{to predict}} the {{intermediate}} frequency component IMF 5 with mild fluctuation and the results show relatively small error, which indicates that ARMA has strong nonlinear wave <b>data</b> <b>learning</b> ability and is suitable for the prediction of intermediate frequency components.|$|E
40|$|Since about 100 years ago, {{to learn}} the {{intrinsic}} structure of <b>data,</b> many representation <b>learning</b> approaches have been proposed, either linear or nonlinear, either supervised or unsupervised, either “shallow” or “deep”. Particularly, deep architectures are widely applied for representation learning in recent years, and have delivered top results in many tasks, such as image classification, object detection and speech recognition. In this paper, we review the development of <b>data</b> representation <b>learning</b> methods. Specifically, we investigate both traditional feature learning algorithms and state-of-the-art deep learning models. The history of <b>data</b> representation <b>learning</b> is introduced, while available online resources (e. g., courses, tutorials and books) and toolboxes are provided. At the end, we give a few remarks {{on the development of}} <b>data</b> representation <b>learning</b> and suggest some interesting research directions in this area...|$|R
40|$|The {{second annual}} {{benchmark}} study of library spending plans from Library Resource Guide explores {{the wide range}} of spending and priorities decision-making taking place in 2012 budgets for public, academic and special libraries. Includes year-to-year comparative <b>data.</b> <b>Learn</b> where peer institutions are focusing their scarce investments, based on a study of over 700 participating North American institutions...|$|R
5000|$|STAGGER, J.C.Schlimmer, R.H.Granger, Incremental <b>Learning</b> from Noisy <b>Data,</b> Mach. <b>Learn.,</b> vol.1, no.3, 1986.|$|R
30|$|Technology-enabled active {{learning}} practices are transforming both in-class and online teaching-learning scenarios. Many of these {{active learning}} strategies {{can benefit from}} the availability of logged <b>data.</b> <b>Learning</b> analytics on the data logged during such activities can further help instructors to gain insights and reflect on their practice (Duval, 2011).|$|E
30|$|According to the {{differences}} of basic <b>data</b> <b>learning</b> method, incremental learning method can be sorted as there categories: incremental decision tree, incremental Bayesian and incremental SVM. According {{to the number}} of new instances to be added in a model at a time, it can be sorted as instance-by-instance learning and block-by-block learning.|$|E
40|$|A {{practical}} and fast-paced guide {{that gives you}} all the information {{you need to start}} developing charts from your <b>data.</b> <b>Learning</b> QlikView Data Visualization is for anybody interested in performing powerful data analysis and crafting insightful data visualization, independent of any previous knowledge of QlikView. Experience with spreadsheet software will help you understand QlikView functions...|$|E
50|$|Prefix WhoIs is an {{open source}} project that {{develops}} and operates a free whois-compatible framework for stockpiling and querying various routing and registry information. Prefix WhoIs uses global BGP routing <b>data</b> <b>learned</b> from many ISP backbone routers. Other information sources are also supported, such as imported data from every Regional Internet Registry (AFRINIC, APNIC, ARIN, LACNIC and RIPE) and geocoding information.|$|R
40|$|In this paper, we {{investigate}} the winnings associated with different factors for NASCAR drivers. We want {{to predict the}} winnings that a driver can earn in a season given other, related factors, such {{as the number of}} races the driver competes in, the average finish position, or the make of car. We obtained 190 observations with 15 factors and randomly split the <b>data</b> into <b>learning</b> <b>data</b> and test <b>data.</b> Using the <b>learning</b> <b>data</b> set, we conducted multiple regression analyses to build a predictive model. Then we examined the final model with the test data set to see how well the model would work in the future. The model shows a high degree of accuracy in predicting the future...|$|R
30|$|The {{extracted}} <b>data</b> {{become the}} <b>learning</b> <b>data,</b> and the unextracted data are called out-of-bag (OOB) data {{used for a}} performance evaluation. Because this technique {{can be used for}} a performance evaluation by applying the OOB data, it does not need to construct data for testing separately, and creates multiple decision trees to determine the resulting value. Therefore, when data other than the <b>learning</b> <b>data</b> are input, over-fitting problems with less accuracy can be avoided [21]. In addition, although random forest achieves a good generalization because it makes a decision tree using random data from among the <b>learned</b> <b>data,</b> it can not explain the process that the result comes out [22].|$|R
40|$|The {{interest}} in the localisation of wireless sensor networks has grown in recent years. A variety of machine-learning methods have been proposed {{in recent years to}} improve the optimisation of the complex behaviour of wireless networks. Network administrators have found that traditional classification algorithms may be limited with imbalanced datasets. In fact, the problem of imbalanced <b>data</b> <b>learning</b> has received particular interest. The {{purpose of this study was}} to examine design modifications to neural networks in order to address the problem of cost optimisation decisions and financial predictions. The goal was to compare four learning-based techniques using cost-sensitive neural network ensemble for multiclass imbalance <b>data</b> <b>learning.</b> The problem is formulated as a combinatorial cost optimisation in terms of minimising the cost using meta-learning classification rules for Naïve Bayes, J 48, Multilayer Perceptions, and Radial Basis Function models. With these models, optimisation faults and cost evaluations for network training are considered...|$|E
40|$|The class {{imbalance}} {{problem in}} classification {{has been recognized}} as a significant research problem {{in recent years and}} a number of methods have been introduced to improve classification results. Rebalancing class distributions (such as over-sampling or under-sampling of learning datasets) has been popular due to its ease of implementation and relatively good performance. For the Support Vector Machine (SVM) classification algorithm, research efforts have focused on reducing the size of learning sets because of the algorithm 2 ̆ 7 s sensitivity {{to the size of the}} dataset. In this dissertation, we propose a metaheuristic approach (Genetic Algorithm) for under-sampling of an imbalanced dataset in the context of a SVM classifier. The goal of this approach is to find an optimal learning set from imbalanced datasets without empirical studies that are normally required to find an optimal class distribution. Experimental results using real datasets indicate that this metaheuristic under-sampling performed well in rebalancing class distributions. Furthermore, an iterative sampling methodology was used to produce smaller learning sets by removing redundant instances. It incorporates informative and the representative under-sampling mechanisms to speed up the learning procedure for imbalanced <b>data</b> <b>learning</b> with a SVM. When compared with existing rebalancing methods and the metaheuristic approach to under-sampling, this iterative methodology not only provides good performance but also enables a SVM classifier to learn using very small learning sets for imbalanced <b>data</b> <b>learning.</b> For large-scale imbalanced datasets, this methodology provides an efficient and effective solution for imbalanced <b>data</b> <b>learning</b> with an SVM...|$|E
30|$|Sensitivity to uneven class {{representation}} and to noise {{are two of}} several other important issues. While we do not address these systematically in this paper, the experiments we describe involve uneven class representation as well as noisy <b>data.</b> <b>Learning</b> from unevenly represented class samples is another strength of ANNs, compared to parametric classifiers, {{and it is an}} advantage in remote sensing since even sampling across cover types is often impossible.|$|E
50|$|Bridge {{uses this}} {{unprecedented}} <b>data</b> on <b>learning</b> {{to not only}} improve its model, but also to contribute to wider pedagogy.|$|R
30|$|The {{difference}} in <b>Learning</b> <b>Data</b> is more complex. The score of “My parents can acquire my learning status in school from some apps or digital communication platforms easily” is 2.92 in primary {{school students and}} 2.66 in secondary school students. And the score of “I can find out my learning history such as my homework, and discussions using computers or other digital devices” is 2.76 in primary school students and 2.17 in secondary school students. The study finds that there are big gaps in these two questions of <b>Learning</b> <b>Data</b> between primary and secondary school students. Researchers think that the usages of <b>learning</b> <b>data</b> {{have to rely on}} the function of platform as well as the students’ understanding of the application of <b>learning</b> <b>data.</b> Primary school students always use the simple function of the platform to support their learning according to their information literacy level, so they can acquire more intuitive feeling of <b>learning</b> <b>data</b> usage than secondary school students.|$|R
30|$|As {{shown in}} Table  4, the {{correlation}} coefficient between Technology Usage and other two factors as <b>Learning</b> <b>Data</b> and Differentiation {{are higher than}} 0.41. It confirms that the Technology Usage level {{plays an important role}} in the adaptive learning support for students in smart classroom. The correlation coefficient between <b>Learning</b> <b>Data</b> and other three factors for learning activities as Differentiation, Investigation, and Cooperation are higher than 0.48, which confirms that <b>Learning</b> <b>Data</b> are the basis for smart learning activities. Survey for the Actual form shows those students’ perceptions of Flexibility, Technology Usage, and <b>Learning</b> <b>Data</b> are lower. It implies that in current situation, the core features of smart classroom are still not applied in classroom appropriately. However students are very eager for getting more targeted and personalized learning help in their own learning activities with the support of technology in smart classroom, which is reflected by Cohen’s d value of Flexibility, <b>Learning</b> <b>Data,</b> and Technology Usage.|$|R
40|$|Immortal {{information}} and through-life knowledge management: strategies and tools for the emerging product-service business paradigm’, is a Grand Challenge project involving eleven different UK universities and incorporating substantial industry collaboration. It is investigating {{a range of}} issues associated with the move towards a product-service paradigm in the engineering sector, in particular the long-term curation of digital <b>data,</b> <b>learning</b> from production and use, and appropriate governance and management techniques...|$|E
40|$|It is {{difficult}} {{if not impossible}} to appropriately and effectively select from among the vast pool of existing neural network machine learning predictive models for industrial incorporation or aca-demic research exploration and enhancement. When all models outperform all the others under disparate circumstances, none of the models do. Selecting the ideal model becomes a matter of ill-supported opinion ungrounded on the extant real world environment. This paper proposes a nov-el grouping of the model pool grounded along a non-stationary real world data line into two groups: Permanent <b>Data</b> <b>Learning</b> and Reversible <b>Data</b> <b>Learning.</b> This paper further proposes a novel approach towards qualitatively and quantitatively demonstrating their significant differ-ences based on how they alternatively approach dynamic and raw real world data vs static and prescient data mining biased laboratory data. The results across 2040 separate simulation runs using 15, 600 data points in realistically operationally controlled data environments show that the two-group division is effective and significant with clear qualitative, quantitative and theoretical support. Results across the empirical and theoretical spectrum are internally and externally con...|$|E
40|$|This {{technical}} report proves components consistency for the Doubly Stochastic Dirichlet Process with exponential convergence of posterior probability. We also present the fundamental properties for DSDP {{as well as}} inference algorithms. Simulation toy experiment and real-world experiment results for single and multi-cluster also support the consistency proof. This report is also a support document for the paper "Computationally Efficient Hyperspectral <b>Data</b> <b>Learning</b> Based on the Doubly Stochastic Dirichlet Process". Comment: 13 pages, 4 figure...|$|E
40|$|Abstract: In this paper, a data {{acquisition}} system for QRS detections in 12 -lead electrocardiogram (ECG) diagnosis is proposed. This system collect <b>data</b> <b>learns</b> rules, synthesizing decision trees by inductive inference from examples. An extended form of Quinlan's algorithm is used. There is also possibility of continual improving the knowledge base maintained, by learning new rules and merging them with the old ones. As a start point for the knowledge base learned, the rules of an already developed expert system are used...|$|R
30|$|As {{shown in}} Table  9, except <b>Learning</b> <b>Data,</b> the {{secondary}} school students have more positive attitude to current classroom situation than the primary school students. And there are {{significant differences in the}} scales of Technology Usage, <b>Learning</b> <b>Data,</b> Students Cohesiveness, Equity, and Learning Experience.|$|R
5000|$|... 3. Student <b>learning</b> <b>data</b> answers two questions: How are our {{students}} doing? and Where are we now? Student <b>learning</b> <b>data</b> requires information from all subject areas, disaggregated by demographic groups, by teachers, by grade level, by cohorts over time, and individual student growth. This {{type of data}} helps to address additional help to {{students who are not}} proficient, deepening into what they know and what they don't know to become proficient. Student <b>learning</b> <b>data</b> connects with curriculum, instruction, and assessment in order to improve outcomes. Student <b>learning</b> <b>data</b> can clearly state the effectiveness of a single educator or the entire school. SLD can be gathered by looking at diagnostic tests, formative assessments, performance assessments, standardized tests, non-referenced tests, summative assessments, teacher-assigned tests, and others.|$|R
