37|123|Public
5000|$|An <b>earcon</b> is a brief, {{distinctive}} sound used {{to represent}} a specific event or convey other information. Earcons are a common feature of computer operating systems and applications, ranging from beeping when an error occurs to the customizable sound schemes of Windows 7 that indicate startup, shutdown, and many other events.|$|E
40|$|The {{development}} of blood pressure earcons for patient monitoring {{is used to}} illustrate how data that varies from intermittent to continuous sampling can be integrated into a single auditory display design. A scalable-earcon structure that extends the concept of hierarchies of earcons is proposed for representing blood pressure information. This structure allows the <b>earcon</b> {{to be used to}} produce intermittent earcons or a continuous sonification of blood pressure measurements. The results of two blood pressure <b>earcon</b> studies indicate that people can use the <b>earcon</b> to elicit large amounts of information with few major errors. 1...|$|E
40|$|Presented at the 12 th International Conference on Auditory Display (ICAD), London, UK, June 20 - 23, 2006. The {{development}} of blood pressure earcons for patient monitoring {{is used to}} illustrate how data that varies from intermittent to continuous sampling can be integrated into a single auditory display design. A scalable-earcon structure that extends the concept of hierarchies of earcons is proposed for representing blood pressure information. This structure allows the <b>earcon</b> {{to be used to}} produce intermittent earcons or a continuous sonification of blood pressure measurements. The results of two blood pressure <b>earcon</b> studies indicate that people can use the <b>earcon</b> to elicit large amounts of information with few major error...|$|E
40|$|Presented at the 20 th International Conference on Auditory Display (ICAD 2014), June 22 - 25, 2014, New York, NY. Auditory {{researchers}} have developed various non-speech cues in designing auditory user interfaces. A preliminary study of “Lyricons” (lyrics + <b>earcons)</b> {{has provided a}} novel approach to devising auditory cues in electronic products, by combining the concurrent two layers of musical speech and <b>earcons</b> (short musical motives). The {{purpose of the present}} study is to introduce iterative design processes and to validate the effectiveness of lyricons compared to <b>earcons,</b> whether people can more intuitively grasp functions that lyricons imply than those of <b>earcons.</b> Results favor lyricons over <b>earcons.</b> Future work and practical application directions are also discussed...|$|R
40|$|This paper {{presents}} {{a set of}} empirically derived guidelines for the presentation of concurrent <b>earcons</b> (short structured audio messages {{which can be used}} to effectively communicate information to users [3]). When <b>earcons</b> are presented in such a way, they interfere with each other, making it difficult to determine the information encoded within them. The guidelines presented in this paper cover the impact of varying the number of <b>earcons</b> on their identification as well as how the design and presentation of <b>earcons</b> may be modified to reduce interference when concurrently presented...|$|R
40|$|In {{this article}} we examine <b>earcons,</b> which are audio {{messages}} used in the user-computer interface to provide information and feedback to the user about computer entities. (<b>Earcons</b> include messages and functions, as well as states and labels.) We identify some design principles that are common to both visual symbols and auditory messages, and discuss the use of representational and abstract icons and <b>earcons.</b> We give some examples of audio patterns {{that may be used}} to design modules for <b>earcons,</b> which then may be assembled into larger groupings called families. The modules are single pitches or rhythmicized sequences of pitches called motives. The families are constructed about related motives that serve to identify a family of related messages. Issues concerned with learning and remembering <b>earcons</b> are discussed. A preliminary version of this article was presented at the Nineteenth Annual Hawai...|$|R
40|$|Presented at the 10 th International Conference on Auditory Display (ICAD 2004) Two {{experiments}} which {{investigate the}} impact of spatialised presentation on the identification of concurrently presented earcons are described. The first experiment compared the identification of concurrently presented earcons based on the guidelines for individual <b>earcon</b> design and presentation of Brewster, Wright and Edwards [1] which were presented in spatially distinct locations, to the identification of non-spatially presented earcons which incorporated guidelines for concurrent presentation from McGookin and Brewster [2]. It was found that {{a significant increase in}} <b>earcon</b> identification occurred, as well as an increase in <b>earcon</b> register identification when earcons were spatially presented. The second experiment compared the identification of concurrently presented earcons based on the guidelines of Brewster, Wright and Edwards [1] which were presented in spatially distinct locations, to the identification of spatially presented earcons which incorporated guidelines for the presentation of concurrent earcons from McGookin and Brewster [2]. The incorporation of the concurrent <b>earcon</b> guidelines was found to significantly increase identification of the timbre attribute but did not significantly effect the overall identification of earcons...|$|E
40|$|Two {{experiments}} which {{investigate the}} impact of spatialised presentation on the identification of concurrently presented earcons are described. The first experiment compared the identification of concurrently presented earcons based on the guidelines for individual <b>earcon</b> design and presentation of Brewster, Wright and Edwards [1] which were presented in spatially distinct locations, to the identification of non-spatially presented earcons which incorporated guidelines for concurrent presentation from McGookin and Brewster [2]. It was found that {{a significant increase in}} <b>earcon</b> identification occurred, as well as an increase in <b>earcon</b> register identification when earcons were spatially presented. The second experiment compared the identification of concurrently presented earcons based on the guidelines of Brewster, Wright and Edwards [1] which were presented in spatially distinct locations, to the identification of spatially presented earcons which incorporated guidelines for the presentation of concurrent earcons from McGookin and Brewster [2]. The incorporation of the concurrent <b>earcon</b> guidelines was found to significantly increase identification of the timbre attribute but did not significantly effect the overall identification of earcons...|$|E
40|$|This paper {{describes}} an experiment to discover if structured audio messages called earcons could provide navigational cues {{in a complex}} menu hierarchy. A hierarchy of 25 nodes and four levels was created with an <b>earcon</b> for each node. Rules were designed {{for the creation of}} the <b>earcon</b> at each node. The results showed that participants could recall over 80 % of the earcons they heard, indicating that they are a good method of communicating hierarchy information. Participants were also tested to see if, by using the rules they had learned for the other earcons, they could identify where a previously unheard <b>earcon</b> would fit in the hierarchy. The results showed {{that they were able to}} do this very reliably. This indicates that earcons are a robust method of communicating complex hierarchy information in sound...|$|E
40|$|A {{detailed}} experimental {{evaluation of}} <b>earcons</b> {{was carried out}} {{to see whether they}} are an effective means of communicating information in sound. An initial experiment showed that <b>earcons</b> were better than unstructured bursts of sound and that musical timbres were more effective than simple tones. Musicians were shown to be no better than non-musicians when using musical timbres. A second experiment was then carried out which improved upon some of the weaknesses of the pitches and rhythms used in Experiment 1 to give a significant improvement in recognition. From the results some guidelines were drawn up for designers to use when creating <b>earcons.</b> These experiments have formally shown that <b>earcons</b> are an effective method for communicating complex information in sound...|$|R
40|$|An {{evaluation}} of <b>earcons</b> {{was carried out}} {{to see whether they}} are an effective means of communicating information in sound. An initial experiment showed that <b>earcons</b> were better than unstructured bursts of sound and that musical timbres were more effective than simple tones. A second experiment was then carried out which improved upon some of the weaknesses shown up in Experiment 1 to give a significant improvement in recognition. From the results of these experiments some guidelines were drawn up for use in the creation of <b>earcons.</b> <b>Earcons</b> {{have been shown to be}} an effective method for communicating information in a human-computer interface. Providing information in an auditory form could generally help solve this problem and allow visually disabled user...|$|R
40|$|Clinicians {{who have}} a continual {{awareness}} of a patient’s vital sign levels {{are more likely to}} detect and respond to early indicators of the patient’s physiological deterioration. Auditory displays are informative patient monitoring tools that can convey vital sign information through short abstract tones, known as <b>earcons.</b> In an earlier study, Janata and Edwards (2013) tested participants’ accuracy at identifying changes in vital sign levels using <b>earcons</b> in which timbre represented oxygen saturation (SpO 2) and tremolo represented heart rate (HR) levels. However, the <b>earcons</b> were only moderately effective at supporting the monitoring of SpO 2 levels. In the present study, we tested participants’ accuracy at identifying vital sign levels using a novel set of pitch-based <b>earcons</b> (pearcons). The pearcons used pitch and tremolo to represent SpO 2 and HR levels respectively. It was hypothesized that if pitch is more discernible or more integral with tremolo than timbre is, then participants who listened to pearcons would identify the vital sign levels more accurately than participants who listened to <b>earcons.</b> Results showed that participants who listened to the pearcons were more accurate at identifying vital sign levels than participants who listened to the <b>earcons.</b> Additionally, SpO 2 identification accuracy was lower when HR level changed at the same time, than when HR level was constant. However, between the pearcons and the <b>earcons</b> condition {{there was no difference in}} each vital sign identification accuracy change from trials where the other vital sign was constant, to trials where the other vital sign changed. This study showed preliminary evidence that pearcons are more effective than <b>earcons</b> for patient monitoring, possibly because pitch is fundamentally more discernible than timbre. Future studies should examine the effectiveness of pearcons in a more clinically representative context...|$|R
40|$|The use {{of sound}} to {{communicate}} information {{as part of}} a user interface has been an active research area for several years. Research has shown that sound can be concurrently presented to users to increase the bandwidth and rate of data presentation. However, when sounds are concurrently presented, they may interfere with each other, such that determining the data encoded in the sound becomes difﬁcult. Modiﬁcations to the sounds can help to avoid such interference, but {{due to the nature of}} the sounds the impact of the modiﬁcations may be constrained. This thesis investigates such interaction with concurrently presented earcons. One experiment investigates how the identiﬁcation of earcons is affected by the number concurrently presented. It was found that increasing the number of earcons concurrently presented lead to a signiﬁcant decrease in the proportion of earcons and their attributes successfully identiﬁed by participants. With identiﬁcation falling from 70 % correct for one presented <b>earcon</b> to 30 % for four concurrently presented earcons. A second experiment identiﬁed how modiﬁcations to the design and presentation of concurrently presented earcons affected their identiﬁcation. It was found that presenting each <b>earcon</b> with a unique timbre as well as introducing an onsettoonset delay of at least 300 ms caused a signiﬁcant improvement in <b>earcon</b> identiﬁcation, and the timbre encoded attribute of earcons. However overall identiﬁcation levels remained low at around 30 %. Two further experiments investigated the impact of spatialisation on concurrent <b>earcon</b> identiﬁcation. They showed that spatial presentation of earcons which did not incorporate the ﬁndings of the previous experiment signiﬁcantly improved identiﬁcation of earcons and the register encoded <b>earcon</b> attribute, over earcons that were not spatially presented but did incorporate the ﬁndings of the previous experiment. Another experiment showed that spatial presentation of earcons which incorporated the unique timbre and 300 ms onsettoonset modiﬁcations signiﬁcantly improved the identiﬁcation of the timbre encoded <b>earcon</b> attribute, although overall identiﬁcation remained low. These four experiments yielded a set of guidelines for concurrent <b>earcon</b> presentation. Due to the nature of those experiments however, a further experiment was conducted to determine the impact of the guidelines on more ecologically valid tasks. A set of modiﬁed and unmodiﬁed earcons which represented entries in a mobile diary system were compared. Overall task accuracy remained low, although participants rated the modiﬁed earcons to require signiﬁcantly less subjective workload. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|Real callers ’ first {{reactions}} to an Open or Directed Strategy prompt for a call routing application {{in the consumer}} retail industry are analysed. Each prompt is trialled alone, with an <b>earcon,</b> and with an <b>earcon</b> and named persona {{in a total of}} six experiments. Usage of the <b>earcon</b> & named persona is found to maximize “routability ” in all cases. The Directed strategy achieved higher “routability ” and lower rates of user confusion than the Open Strategy for all experiments, implying that the Directed strategy may be better suited for this caller base. Application of other prompt wording styles and analysis of follow-on behavior are promising areas for future study. Introduction and motivation “How may I help you?”-style prompts are increasingly being used in commercial speechrecognition applications for call routing. This type of Open Strategy prompt is often preferred to a Directed Strategy prompt because it is believed to increase caller satisfaction, task completion times, and task completion rates...|$|E
40|$|In {{this paper}} we discuss {{the first of a}} series of {{experiments}} evaluating earcons for critical care environments. We examine peoples ’ ability to monitor earcons conveying systolic and diastolic blood pressure while conducting a distractor task. The results showed that when a beacon is present prior to the <b>earcon,</b> participants ’ judgment of pitch and duration information improved. The results of the study also indicated presence of historical information in the <b>earcon</b> may interfere with participants ’ judgments. However, since participants felt more confident in their recall of previous values when the historical information was present, the results may reflect insufficient training...|$|E
40|$|An {{evaluation}} of musical <b>earcons</b> {{was carried out}} {{to see whether they}} are an effective and efficient method of delivering information about household appliances to elderly people. A test was carried out to explore the ability of the elderly subjects in remembering and learning the musical <b>earcons.</b> This test indicated a poor rate of recognition of the <b>earcons.</b> A second test that included the presentation of information in three modes (audio, visual and multimodal) was performed to determine which modality was preferred to deliver certain types of information among this group. We hypothesized that the multimodal interface would be the best in terms of speed and accuracy of response, and this was supported by the data. The results showed the need for a redesign of the <b>earcons.</b> 1...|$|R
40|$|This thesis {{provides}} a framework for integrating non-speech sound into humancomputer interfaces. Previously there was no structured way of doing this, {{it was done in}} an ad hoc manner by individual designers. This led to ineffective uses of sound. In order to add sounds to improve usability two questions must be answered: What sounds should be used and where is it best to use them? With these answers a structured method for adding sound can be created An investigation of <b>earcons</b> as a means of presenting information in sound was undertaken. A series of detailed experiments showed that <b>earcons</b> were effective, especially if musical timbres were used. Parallel <b>earcons</b> were also investigated (where two <b>earcons</b> are played simultaneously) and an experiment showed that they could increase sound presentation rates. From these results guidelines were drawn up for designers to use when creating usable <b>earcons.</b> These formed {{the first half of the}} structured method for integrating sound into interfaces. An informal analysis technique was designed to investigate interactions to identif...|$|R
40|$|Proceedings of the 9 th International Conference on Auditory Display (ICAD), Boston, MA, July 7 - 9, 2003. An {{evaluation}} of musical <b>earcons</b> {{was carried out}} {{to see whether they}} are an effective and efficient method of delivering information about household appliances to elderly people. A test was carried out to explore the ability of the elderly subjects in remembering and learning the musical <b>earcons.</b> This test indicated a poor rate of recognition of the <b>earcons.</b> A second test that included the presentation of information in three modes (audio, visual and multimodal) was performed to determine which modality was preferred to deliver certain types of information among this group. We hypothesized that the multimodal interface would be the best in terms of speed and accuracy of response, and this was supported by the data. The results showed the need for a redesign of the <b>earcons...</b>|$|R
40|$|An {{example of}} {{where and how}} to use non-speech sounds in an {{interface}} is described. The role of the sound is to provide an overview or glance for a blind person reading mathematics by listening. The type of sound used to provide the audio glance is the <b>earcon.</b> The algebra earcons were designed using prosodic cues from spoken algebra combined with pre-existing guidelines for <b>earcon</b> design. Three experiments demonstrated that listeners were able to recover sufficient information to recognize an expression of appropriate structure. Participants were also able to use the glance to accomplish some mathematical tasks. The prosodic component of speech can be seen to be a useful basis for the design of both speech and non-speech features of an auditory interface. ...|$|E
40|$|In {{this paper}} we {{describe}} an experiment investigating {{the ability of}} participants to identify multiple, concurrently playing structured sounds, called earcons. Several different sets of earcons were compared, one "state of the art" set based on the guidelines of Brewster [1], and other sets of earcons modified {{to take account of}} auditory scene analysis principles. The effect of the number of concurrently playing earcons on identification was also investigated, with instances of 1, 2, 3 and 4 concurrently playing earcons tested. Overall, performance was low, with less than two earcons being successfully identified in any condition. However it was found that both staggering the onset times of each <b>earcon,</b> as well as presenting each <b>earcon</b> with a unique timbre, had a significantly positive effect on identification...|$|E
40|$|In {{this paper}} work to improve upon {{the design of}} {{structured}} audio messages called Earcons {{for use in a}} concurrent spatialised audio environment is described. Issues involving the limitations of current <b>Earcon</b> design are briefly described, and solutions to these limitations involving Auditory Scene Analysis are presented...|$|E
40|$|Non-verbal sound cues {{can be used}} {{to convey}} {{different}} kinds of information and are often used for both simple and more complex types of feedback in computer games. Non-verbal sound cues can be divided into two different categories; auditory icons, that are sounds that represent real world events and <b>earcons,</b> that are abstract synthetic or musical sounds. In order {{to see if there was}} a difference between the player response times yielded by auditory icons and <b>earcons</b> in a video game setting, an experiment game was created. A game where the response times of subjects were recorded when reacting to auditory icons and <b>earcons,</b> while playing through four different treasure hunt like game scenarios. The results from the experiment seem to indicate that there was no significant difference between the combined response times produced by the auditory icons compared to the combined response times produced by the <b>earcons.</b> Validerat; 20160517 (global_studentproject_submitter...|$|R
40|$|As {{automated}} vehicles currently do {{not provide}} sufficient feedback relating to the primary driving task, drivers have no assurance that an automated vehicle has understood and can cope with upcoming traffic situations [16]. To address this we conducted two user evaluations to investigate auditory displays in automated vehicles using different types of sound cues related to the primary driving sounds: acceleration, deceleration/braking, gear changing and indicating. Our first study compared <b>earcons,</b> speech and auditory icons with existing vehicle sounds. Our findings suggested that <b>earcons</b> were an effective alternative to existing vehicle sounds for presenting information related to the primary driving task. Based on these findings a second {{study was conducted to}} further investigate <b>earcons</b> modulated by different sonic parameters to present primary driving sounds. We discovered that <b>earcons</b> containing naturally mapped sonic parameters such as pitch and timbre were as effective as existing sounds in a simulated automated vehicle...|$|R
40|$|This paper {{presents}} {{an overview of}} work {{on the effects of}} <b>earcons</b> and auditory icons on picture categorization and the results of 2 new experiments. The general finding of the experiments is that <b>earcons</b> have an inhibitory effect on picture categorization whereas auditory icons, in general, have a facilitating effect. These findings will be discussed and related to the theoretical framework of perceptual versus conceptual categorization. 1...|$|R
40|$|An {{overview}} or glance {{is important}} in planning the reading process. Such a highlevel view is not possible for a blind person when reading by listening. This paper describes the sonification of algebra notation to provide an audio glance to facilitate planning prior to reading. Prosodic cues used in spoken algebra were combined with pre-existing guidelines for <b>earcon</b> design to produce a high-level view of expression structure called algebra earcons. The initial evaluation indicated listeners could recover syntactic information from an algebra <b>earcon</b> and pick an appropriate expression. Some defficiencies were revealed, that were amended and then retested in a second experiment showing an improvement in recognition of syntactic features. Analysis of verbal protocols revealed the level of syntactic information the listeners could retain and recall, and also the strategies used...|$|E
40|$|Proceedings of the 9 th International Conference on Auditory Display (ICAD), Boston, MA, July 7 - 9, 2003. In {{this paper}} we {{describe}} an experiment investigating {{the ability of}} participants to identify multiple, concurrently playing structured sounds, called earcons. Several different sets of earcons were compared, one ``state of the art'' set based on the guidelines of Brewster [1], and other sets of earcons modified {{to take account of}} auditory scene analysis principles. The effect of the number of concurrently playing earcons on identification was also investigated, with instances of 1, 2, 3 and 4 concurrently playing earcons tested. Overall, performance was low, with less than two earcons being successfully identified in any condition. However it was found that both staggering the onset times of each <b>earcon,</b> as well as presenting each <b>earcon</b> with a unique timbre, had a significantly positive effect on identification...|$|E
40|$|Presented at 2 nd International Conference on Auditory Display (ICAD), Santa Fe, New Mexico, November 7 - 9, 1994. An {{overview}} or glance {{is important}} in planning the reading process. Such a high-level view is not possible for a blind person when reading by listening. This paper describes the sonification of algebra notation to provide an audio glance to facilitate planning prior to reading. Prosodic cues used in spoken algebra were combined with pre-existing guidelines for <b>earcon</b> design to produce a high-level view of expression structure called algebra earcons. The initial evaluation indicated listeners could recover syntactic information from an algebra <b>earcon</b> and pick an appropriate expression. Some deficiencies were revealed, that were amended and then retested in a second experiment showing an improvement in recognition of syntactic features. Analysis of verbal protocols revealed the level of syntactic information the listeners could retain and recall, and also the strategies used...|$|E
40|$|Previous {{research}} on non-speech audio interfaces has demon-strated {{that they can}} enhance performance on menu navigation tasks. Most of this work has focused on tasks in which the menu is not spoken and visual representation of the menu is accessible throughout the task. In this paper we explore the potential bene-fits that <b>earcons,</b> a type of structured sound, might bring to spo-ken menu systems for which a visual representation is not avail-able. Evaluation of two spoken menu systems that differ only in whether they also employ <b>earcons,</b> indicates {{that the use of}} <b>earcons</b> improves task performance by reducing the number of keystrokes required, while also increasing the time spent for each task. 1...|$|R
40|$|An {{experiment}} with two picture categorization tasks with auditory distracters containing redundant information {{was carried out}} to investigate the effects distracters, in this case <b>earcons,</b> have on categorization. In the first task participants had to carry out an extra mental addition task. The secondary task consisted of just the categorization. The dual-task situation was expected to lead to longer reaction times and more errors than the single-task situation, possibly providing new insights when analyzed. The results confirmed previous experimental results and indicated that significantly fewer errors were made in conditions in which the <b>earcons</b> contained relevant redundant information, compared to conditions with no relevant redundant information. Keywords <b>Earcons,</b> auditory distracter, multimodal interfaces, categorization, dual-task performanc...|$|R
5000|$|<b>Earcons</b> / {{auditory}} icons: brief, distinctive sounds used {{to represent}} a specific event or convey other information ...|$|R
40|$|This paper {{describes}} {{a method of}} presenting structured audio messages, earcons, in parallel so that they take less time to play and can better keep pace with interactions in a human-computer interface. The two component parts of a compound <b>earcon</b> are played in parallel so that the time taken is only that of a single part. An experiment was conducted to test the recall and recognition of parallel compound earcons as compared to serial compound earcons. Results showed {{that there are no}} differences in the rates of recognition between the two groups. Non-musicians are also shown to be equal in performance to musicians. Some extensions to the <b>earcon</b> creation guidelines of Brewster, Wright & Edwards (1992) are put forward based upon research into auditory stream segregation. Parallel earcons are shown to be an effective means of increasing the presentation rates of audio messages without compromising recognition rate...|$|E
40|$|Two {{investigations}} into the identification of concurrently presented, structured sounds, called earcons were carried out. One of the experiments investigated how varying the number of concurrently presented earcons affected their identification. It was found that varying the number {{had a significant effect}} on the proportion of earcons identified. Reducing the number of concurrently presented earcons lead to a general increase in the proportion of presented earcons successfully identified. The second experiment investigated how modifying the earcons and their presentation, using techniques influenced by auditory scene analysis, affected <b>earcon</b> identification. It was found that both modifying the earcons such that each was presented with a unique timbre, and altering their presentation such that there was a 300 ms onset-to-onset time delay between each <b>earcon</b> were found to significantly increase identification. Guidelines were drawn from this work to assist future interface designers when incorporating concurrently presented earcons...|$|E
40|$|The use {{of sound}} to {{communicate}} information {{as part of}} a user interface has been an active research area for several years. Research has shown that sound can be concurrently presented to users to increase the bandwidth and rate of data presentation. However, when sounds are concurrently presented, they may inter-fere with each other, such that determining the data encoded in the sound becomes difficult. Modifications to the sounds can help to avoid such interference, but {{due to the nature of}} the sounds the impact of the modifications may be constrained. This thesis investigates such interaction with concurrently presented earcons. One experiment investi-gates how the identification of earcons is affected by the number concurrently presented. It was found that increasing the number of earcons concurrently presented lead to a significant decrease in the proportion of earcons and their attributes successfully identified by participants. With identification falling from 70 % correct for one presented <b>earcon</b> to 30 % for four concurrently presented earcons. A second experiment identified how modifications to the design and presentation of concurrently pre-sented earcons affected their identification. It was found that presenting each <b>earcon</b> with a unique timbre as well as introducing an onset-to-onset delay of at least 300 ms caused a significant improvement in earco...|$|E
40|$|Presented at the 17 th International Conference on Auditory Display (ICAD 2011), 20 - 23 June, 2011 in Budapest, Hungary. The {{design of}} {{cognitive}} artifacts for systematic exploration of sound spaces poses a significant challenge in auditory display re- search. This is especially {{the case if}} the artifact is {{to be based on}} the user’s individual perceptual capabilities rather than a pre- defined perceptual model or a purely numerical relationship be- tween the various sounds in the sound space. In this paper, we pro- pose a tensor algebraic tuning model that allows for the systematic tuning and interpolation of parametric auditory icons and <b>earcons</b> in a way that satisfies this challenge. The proposed approach views <b>earcons</b> as being composed of any number of auditory icons at a lower level, thus allowing for the systematic modification of both auditory icons and <b>earcons</b> via local and global interactions. Due to the granular representation used by the model, it becomes pos- sible to approximate the user’s perceptual sensitivity locally in the parametric space used to generate the auditory icons and <b>earcons...</b>|$|R
40|$|The {{importance}} of the structured fabrication of auditory (feedback) signals like <b>earcons</b> is common knowledge in the ICAD community. To create such structured families of <b>earcons</b> musical transformations like rhythm or pitch (and many others) are usually employed. However, one impor-tant transformation in Western tonal music, that of the dis-tinction between major and minor mode, to our knowledge, has not been exploited, {{despite the fact that}} the affective connotation of the major and minor mode might be use-ful for research into auditory signals for affective human– computer interfaces. The present study investigated whether the transformation to major or minor mode can be used to create affectively–charged <b>earcons</b> for use in affective– computing research [1]. The affective–congruency effect that we obtained provides evidence that the processing of af-fective information can interfere with making rational, cog-nitive decisions. We argue that the transformation to the ma-jor or minor mode is suitable to create affectively–charged <b>earcons</b> and that it is important to ensure affective corre-spondence in computer interfaces to be able to realize opti-mal performance levels. 1...|$|R
40|$|Proceedings of the 9 th International Conference on Auditory Display (ICAD), Boston, MA, July 7 - 9, 2003. Previous {{research}} on non-speech audio interfaces {{has demonstrated that}} they can enhance performance on menu navigation tasks. Most of this work has focused on tasks in which the menu is not spoken and visual representation of the menu is accessible throughout the task. In this paper we explore the potential benefits that <b>earcons,</b> a type of structured sound, might bring to spoken menu systems for which a visual representation is not available. Evaluation of two spoken menu systems that differ only in whether they also employ <b>earcons,</b> indicates {{that the use of}} <b>earcons</b> improves task performance by reducing the number of keystrokes required, while also increasing the time spent for each task...|$|R
