10|1826|Public
25|$|The {{components}} of the ACMS consist of Soldier Computer, Weapon, <b>Head</b> <b>Mount</b> <b>Display,</b> Power, Communications and Navigation sub-systems. An integrated Load Bearing Vest and a hydration bladder are also included, the former being outfitted with armored plates.|$|E
5000|$|In 2008, the Library {{also became}} the first in Hong Kong to {{collaborate}} with researchers {{in the field of}} radio frequency identification (RFID), to develop the EasyCheck System based on Ultra High Frequency (UHF) RFID technologies. Introduced in the Semi-closed Collection Room, EasyCheck enables users to check out and return multiple library items at any one time by themselves with convenience and flexibility. With approval and certification from Octopus, the Library developed the EasyPay System to integrate its Library system with Octopus to automate the overdue fine payment process. Both the EasyCheck System and EasyPay System were granted patents from PRC and Hong Kong. [...] In 2016, in support of the University's Discovery-enriched Curriculum (DEC), the Library developed a new Cave Automatic Virtual Environment (CAVE) to provide students with tools for discovery and innovation for their learning and research endeavors. The CAVE is part of the Discovery Corner, a one-stop-shop for students to create and modify the 3D models and VR projects for their assignments and research. The CAVE itself is a projection-based Virtual Reality (VR) display inside a room-sized cube that multiple persons can use to share the same immersive experience. The Library's Discovery Corner is also equipped with a VR <b>Head</b> <b>Mount</b> <b>Display</b> (HMD) to let students experience immersion individually. Apart from CAVE, inside the Discovery Corner, 3D scanning services and desktop computers are available.|$|E
40|$|This {{research}} {{provides a}} stereoscopic vision system on an unmanned vehicle system (UVS) for disaster inspection. Taiwan is a disaster-prone area where earthquakes, typhoon, floods and debris flow happen frequently. These disasters usually cause terrain transformation and building collapse that raise {{the risk for}} human inspection. However, authorities need instant onsite data right after disaster happened to deploy appropriate rescue missions and distribute resources. Instead of sending bunch of sensor into the field with unmanned vehicles and retrieve {{a huge amount of}} numeric data for time-consuming post analysis, an instinct and cognitive method for quick understanding and reconstruction of onsite situation is needed. Therefore, we developed a stereoscopic vision system which can be easily integrated with all UVS. In order to enhance the cognition of the operator, we applied two methods: (1) stereoscopic vision for <b>head</b> <b>mount</b> <b>display,</b> (2) head tracking data for gimbal control. We used two camera sources to simulate human vision and optimized the perspective to suit human eyes ’ field-of-view (FOV). By displaying the optimized image on the <b>head</b> <b>mount</b> <b>display,</b> the operator would have a realistic first-person view of the UVS. We also developed control logic for 3 -axis gimbals that can interpret the head tracking data into gimbal motion so operator can move camera’s direction by turning heads. The integration of these two methods provides a enhanced visual aid that can be adapted to almost every UVS nowadays. In the future research, we will deploy the proposed system on common UVS to validate the improvement of human cognition...|$|E
40|$|This paper gives a short {{overview}} of technologies used for <b>Head</b> <b>Mounted</b> <b>Displays</b> since the 1970 th. In addition to that, their problems are discussed {{and the two}} major classes of <b>Head</b> <b>Mounted</b> <b>Displays,</b> optical see-through and video see-through devices, are compared with each other. The paper ends with a few social aspects {{of the use of}} <b>Head</b> <b>Mounted</b> <b>Displays.</b> 1...|$|R
40|$|Abstract—With {{the recent}} {{introduction}} of low cost <b>head</b> <b>mounted</b> <b>displays</b> (HMDs), prices of HMD-based virtual reality setups dropped considerably. In various application areas personal <b>head</b> <b>mounted</b> <b>displays</b> can be utilized {{for groups of}} users to deliver different context sensitive information to individual users. We present a hardware setup that allows attaching 12 or more HMDs to a single PC. Finally we demonstrate how a collaborative, educational, augmented reality application is used by six students wearing HMDs on a single PC simultaneously with interactive framerates. Index Terms—Augmented reality, <b>head</b> <b>mounted</b> <b>displays,</b> multi-user applications, virtual reality. I...|$|R
5000|$|The company's <b>head</b> <b>mounted</b> <b>display</b> {{products}} {{fall into}} four categories: ...|$|R
40|$|To {{provide a}} live, active and {{high-quality}} virtual touring streaming experience, we propose an unmanned drone stereoscopic streaming paradigm using a control and streaming infrastructure of a 2. 4 GHz Wi-Fi grid. Our system {{allows users to}} actively control the streaming captured by a drone, receive and watch the streaming using a <b>head</b> <b>mount</b> <b>display</b> (HMD); a Wi-Fi grid is deployed across the remote scene with multi-channel support to enable high-bitrate stream- ing broadcast from the drones. The system adopt a joint view adaptation and drone control scheme to enable fast viewer movement including both head rotation and touring. We implement the prototype on Dji M 100 quadcopter and HTC Vive in a demo scene...|$|E
40|$|Recently, the {{omnidirectional}} image sensors {{have been}} applied to tele-presence systems, because the sensor can capture images with large field of views at video rate. On the other hand, <b>head</b> <b>mount</b> <b>display</b> (HMD) has been generally used as a personal display for virtual reality applications such as a tele-presence. However, almost all HMDs have a problem that {{the field of view}} (FOV), about 60 degree horizontally, of its presented image was terribly narrower than that of human. The problem makes reality and immersion lower in these applications. In this paper, we propose highimmersive visualization system that can display 180 degrees horizontal view by using a new catadioptrical HMD and an omnidirectional image sensor. The HMD consists of ellipsoidal and hyperboloidal curved mirrors, and can display 180 degrees horizontal view...|$|E
40|$|This paper {{introduces}} a machine vision system, which {{is suitable for}} cooperative works between the human and computer. This system provides images inputted from a stereo camera head {{not only to the}} processor but also to the user’s sight as binocular wide-angle foveated (WAF) information, thus it is applicable for Virtual Reality (VR) systems such as tele-existence or training experts. The stereo camera head plays a role to get required input images foveated by special wide-angle optics under camera view direction control and 3 D <b>head</b> <b>mount</b> <b>display</b> (HMD) displays fused 3 D images to the user. Moreover, an analog video signal processing device much inspired from a structure of the human visual system realizes a unique way to provide WAF information to plural processors and the user. Therefore, this developed vision system is also much expected to be applicable for the human brain and vision research, because the design concept is to mimic the human visual system. Further, an algorithm to generate features using Discrete Fourier Transform (DFT) for binocular fixation in order to provide well-fused 3 D images to 3 D HMD is proposed. This paper examines influences of applying this algorithm to space variant images such as WAF images, based on experimental results...|$|E
5000|$|A 1995 low-budget {{film called}} [...] "Evolver" [...] used the MRG2 as the <b>head</b> <b>mounted</b> <b>display.</b>|$|R
50|$|The Lisplay {{technology}} was considered by David Holz, LeapMotion’s CEO {{as one of}} the most promising future <b>Head</b> <b>Mounted</b> <b>Display.</b>|$|R
5000|$|Recon Instruments {{released}} on [...] two <b>head</b> <b>mounted</b> <b>displays</b> for ski goggles, MOD and MOD Live, the latter {{based on an}} Android operating system.|$|R
40|$|Organic light {{emitting}} diode (OLED) is light emissive device. The advantages of OLED are low power consumption, self electroluminescence and simple optical system. Furthermore, active matrix pixels and display drivers can be integrated together by standard CMOS technology for driving OLED. As a result, a novel microdisplay can be implemented by integrating OLED on a silicon backplane. Liquid-crystal-on-silicon (LCoS) microdisplay is well developed for <b>head</b> <b>mount</b> <b>display</b> (HMD) applications, there are limitations of high power consumption of backlight and complicated optical system. OLED microdisplay solves these problems by self electroluminescence and high efficiency. Moreover, the size can be as compact as LCoS and good for HMD application. The silicon backplane for OLED is developed. There are two topics on design. One is the pixel driving circuit, which has to ensure the current continuously flow through OLED. The major problem is process variation that affects the uniformity of luminance. The process independent pixel driving schemes are proposed. The other is that, the display drivers have to be integrated in the silicon backplane {{in order to simplify}} the I/O interface. The display drivers consist of column driver, row driver and digital-to-analog converter. All these circuits are efficiently integrated with the pixels. Finally, a OLED controller board is developed to convert conventional video for the silicon backplane. The controller board can support many video formats; including TV, PC graphic and DVI. Moreover, there are many other functions in the board to optimize the silicon backplane performance...|$|E
40|$|The {{necessity}} {{of maintaining a}} robust antiterrorist task force has become imperative in recent times with resurgence of rogue element in the society. A well equipped combat force warrants the safety and security of citizens {{and the integrity of}} the sovereign state. In this paper we propose a novel teleoperating robot which can {{play a major role in}} combat, rescue and reconnaissance missions by substantially reducing loss of human soldiers in such hostile environments. The proposed robotic solution consists of an unmanned ground vehicle equipped with an IP camera visual system broadcasting real-time video data to a remote cloud server. With the advancement in machine learning algorithms in the field of computer vision, we incorporate state of the art deep convolutional neural networks to identify and predict individuals with malevolent intent. The classification is performed on every frame of the video stream by the trained network in the cloud server. The predicted output of the network is overlaid on the video stream with specific colour marks and prediction percentage. Finally the data is resized into half-side by side format and streamed to the <b>head</b> <b>mount</b> <b>display</b> worn by the human controller which facilitates first person view of the scenario. The ground vehicle is also coupled with an unmanned aerial vehicle for aerial surveillance. The proposed scheme is an assistive system and the final decision evidently lies with the human handler. Comment: 6 pages, 9 figure...|$|E
40|$|A thesis {{submitted}} to the University of Bedfordshire in partial fulfilment of the requirements for the degree of Masters by ResearchVirtual Reality (VR) is an experience where a person is provided with the freedom of viewing and moving in a virtual world [1]. The experience is not constrained to a limited control. Here, it was triggered interactively according to the user’s physical movement [1] [2]. So the user feels {{as if they are}} seeing the real world; also, 3 D technologies allow the viewer to experience the volume of the object and its prospection in the virtual world [1]. The human brain generates the depth when each eye receives the images in its point of view. For learning for and developing the project using the university’s facilities, some of the core parts of the research have been accomplished, such as designing the VR motion controller and VR HMD (<b>Head</b> <b>Mount</b> <b>Display),</b> using an open source microcontroller. The VR HMD with the VR controller gives an immersive feel and a complete VR system [2]. The motive was to demonstrate a working model to create a VR experience on a mobile platform. Particularly, the VR system uses a micro electro-mechanical system to track motion without a tracking camera. The VR experience has also been developed in a gaming simulation. To produce this, Maya, Unity, Motion Analysis System, MotionBuilder, Arduino and programming have been used. The lessons and codes taken or improvised from [33] [44] [25] and [45] have been studied and implemented...|$|E
5000|$|LE-750A <b>Head</b> <b>Mounted</b> <b>Display</b> is {{a rugged}} see-through <b>head</b> <b>mounted</b> <b>display</b> used by {{military}} forces. The product {{is produced by}} Liteye Systems, www.Liteye.com, features 800x600 full-color resolution, color-corrected see-through optics, and rugged construction. It was created to allow the user to view information from sources, such as a computer, GPS, or a thermal camera, while keeping both hands free. It {{is often used to}} present this information by overlaying the image in front of the users normal field-of-view; this is referred to as [...] "augmented reality".|$|R
40|$|This project {{starts with}} the idea to develop a game to train people in {{evacuation}} drills. The game has {{to allow people to}} learn evacuation plans. To do it, the core aspect to be considered is the transfer of spatial knowledge from a virtual environment. Hence in this study, the transfer of spatial knowledge has been evaluated. In particular, the acquisition from a virtual environment has been compared between <b>head</b> <b>mounted</b> <b>display</b> and desktop display. 26 subjects have participated in the experiment. They have been divided in two groups: the first group played the game with a desktop display, the second group played with a <b>head</b> <b>mounted</b> <b>display.</b> The collected data and feedback underline {{that it is possible to}} acquire spatial knowledge from a virtual environment, and that participants who used a desktop display obtain more nformation than participants who used <b>head</b> <b>mounted</b> <b>display...</b>|$|R
50|$|IrisVR Prospect {{software}} {{allows users}} to view SketchUp files in virtual reality {{with the use of}} <b>head</b> <b>mounted</b> <b>displays</b> such as the HTC Vive or Oculus Rift.|$|R
50|$|This was a <b>head</b> <b>mounted</b> <b>display</b> (HMD) {{that was}} meant to immerse users into a {{computer}} simulation. It could track head movements. The headset used Fresnel lenses.|$|R
50|$|Dedicated {{telepresence}} setups utilize a <b>head</b> <b>mounted</b> <b>display</b> {{with either}} single or dual eye display, and an ergonomically matched interface with joystick and related button, slider, trigger controls.|$|R
40|$|International audienceIn this paper, we have {{investigated}} the comparative usability among three different viewing configurations of augmented reality (AR) system that uses a desktop monitor instead of a <b>head</b> <b>mounted</b> <b>display.</b> In many cases, due to operational or cost reasons, the use of <b>head</b> <b>mounted</b> <b>displays</b> may not be viable. Such a configuration is bound to cause usability problems because of the mismatch in the user’s proprioception, scale, hand eye coordination, and the reduced 3 D depth perception. We asked a pool of subjects to carry out an object manipulation task in three different desktop AR set ups. We measured the subject’s task performance and surveyed for the perceived usability and preference. Our results indicated that placing a fixed camera {{in the back of}} the user was the best option for convenience and attaching a camera on the user’s head for task performance. The results should provide a valuable guide for designing desktop augmented reality systems without <b>head</b> <b>mounted</b> <b>display...</b>|$|R
40|$|Over {{the last}} few years, there have been {{striking}} developments in wearable computing. Among all the different forms of wearable devices, <b>Head</b> <b>Mounted</b> <b>Displays</b> (HMDs) are deemed the first seamless solution to enabling workers with real time contextual information and allowing companies to integrate with existing back-end systems. The hands-free feature that come along with the HMDs is also believed a great advantage over many traditional technologies. However, few studies had discussed the impact of different design characteristics of <b>head</b> <b>mounted</b> <b>displays</b> on task performance. This study aimed {{to find out how}} different <b>display</b> positions of <b>Head</b> <b>Mounted</b> <b>Displays</b> may affect the performance of workers performing guided repair and maintenance tasks. A set of car maintenance tasks were performed by 20 participants with task guidance presented at four Display Conditions: above-eye HMD, eye-centered HMD, below-eye HMD and the traditional paper manual. Time and errors were measured and discussed, as well as other user experience related measurements. M. S...|$|R
3000|$|... 3 D Manipulation {{has been}} studied {{in a number of}} usage contexts: Desktop {{computing}}, Virtual Reality using a <b>head</b> <b>mounted</b> <b>display,</b> Immersive large displays/cave systems and Tabletop/Tablet computing where touch is utilised.|$|R
30|$|Also, most {{existing}} toolkits {{have not}} anticipated {{the integration of}} non-touch screen devices. More specifically, projection based systems, such as optical see-through <b>head</b> <b>mounted</b> <b>displays,</b> or wearable pico-projectors still need better integration.|$|R
50|$|<b>Head</b> <b>Mounted</b> <b>Displays</b> (HMD): {{starting}} in 2000 {{the company began}} working with HMDs. Areas of research include augmented and virtual reality for educational, industrial, and training purposes, as well as entertainment and personal use.|$|R
40|$|Industrial {{construction}} {{tasks in}} modern productions {{become more and}} more complex. Augmented Reality is on the one hand a technique to help teaching new construction tasks more visible by augmenting the reality of the user with 3 D or 2 D images shown in the field of vision or to help workers to do work with tools more precisely by showing points where to use a tool. The users can get the information by a <b>head</b> <b>mounted</b> <b>display.</b> A newer approach is to get the information beamed by a laser which is also <b>head</b> <b>mounted,</b> to the surface of a component that somebody is working on. Here the use of AR with <b>head</b> <b>mounted</b> <b>displays</b> and laser projectors in the automotive industry is presented. ...|$|R
50|$|The HMZ-T1 is a visor style <b>head</b> <b>mounted</b> <b>display</b> {{manufactured}} by Sony Corporation. Also {{known as the}} Sony Personal HD & 3D Viewer, the HMZ-T1 is composed of two different hardware devices, the Visor and the External Processor Unit.|$|R
40|$|Extracting salient {{information}} in an unknown environment for assisting patients in daily tasks. Designed a fully portable system (a camera, a laptop, and a <b>head</b> <b>mounted</b> <b>display</b> (HMD)). Efficient image processing, effective obstacle identification, and eventually providing useful information for users...|$|R
40|$|How can we {{foster the}} process of {{knowledge}} construction in learners using an agent-based multimedia environment? The present paper reviews a set of studies where students learn in various agent-based multimedia environments designed to promote the understanding of an environmental science lesson. The role of media is examined by comparing how students learn from the same microworld delivered via a desktop <b>display,</b> <b>head</b> <b>mounted</b> <b>display</b> without walking, and <b>head</b> <b>mounted</b> <b>display</b> with walking. The role of method is examined by comparing how students learn when the agent communicates with the student via spoken or written words, the agent’s image is present or not, and students actively participate in {{the process of}} knowledge construction or receive direct instruction. 1...|$|R
40|$|<b>Head</b> <b>mounted</b> <b>displays</b> (HMD) are in {{widespread}} use for virtual environment applications {{and they are}} the focus of many discussions in ergonomics. Most of the HMDs coming onto the market without any proven ergonomic aspects - and this in times of pan-European regulations for display working places. Many tests have been done in the field of ergonomic aspects of HMDs, therefore, we saw {{this as an opportunity to}} delve deeper into the possibilities these display devices give us. This paper introduces technical aspects of <b>head</b> <b>mounted</b> <b>displays</b> and pertinent health concerns. It will help to show the possible ways of testing the ergonomic quality of these devices and permit comparisons to be made...|$|R
40|$|We {{propose a}} novel method to {{implement}} an optical see-through <b>head</b> <b>mounted</b> <b>display</b> which renders real aerial images {{with a wide}} viewing angle, called an Air Mounted Eyepiece (AME). To achieve the AMD design, we employ an off-the-shelf <b>head</b> <b>mounted</b> <b>display</b> and Transmissive Mirror Device (TMD) which is usually used in aerial real imaging systems. In the proposed method, we replicate {{the function of the}} <b>head</b> <b>mounted</b> <b>display</b> (HMD) itself, which is used in the air by using the TMD and presenting a real image of eyepiece in front of the eye. Moreover, it can realize a wide viewing angle 3 D display by placing a virtual lens in front of the eye without wearing an HMD. In addition to enhancing the experience of mixed reality and augmented reality, our proposed method {{can be used as a}} 3 D imaging method for use in other applications such as in automobiles and desktop work. We aim to contribute to the field of human-computer interaction and the research on eyepiece interfaces by discussing the advantages and the limitations of this near-eye optical system. Comment: 7 page...|$|R
40|$|<b>Head</b> <b>mounted</b> <b>displays</b> are {{characterized}} by relatively low resolution and low dynamic range. These limitations significantly reduce the visual quality of photo-realistic captures on such displays. This thesis presents an interactive view optimized tone mapping technique for viewing large sized high dynamic range panoramas up to 16384 by 8192 on <b>head</b> <b>mounted</b> <b>displays.</b> This technique generates a separate file storing pre-computed view-adjusted mapping function parameters. We define this technique as ToneTexture. The use of a view adjusted tone mapping allows for expansion of the perceived color space available to the end user. This yields an improved visual appearance of both high dynamic range panoramas and low dynamic range panoramas on such displays. Moreover, by providing proper interface to manipulate on ToneTexture, users are allowed to adjust the mapping function as to changing color emphasis. The authors present comparisons of the results produced by ToneTexture technique against widely-used Reinhard tone mapping operator and Filmic tone mapping operator both objectively via a mathematical quality assessment metrics and subjectively through user study. Demonstration systems are available for desktop and <b>head</b> <b>mounted</b> <b>displays</b> such as Oculus Rift and GearVR...|$|R
40|$|Exercise {{video games}} have become {{increasingly}} popular due to their potential as tools to increase user motivation to exercise. In recent years we have seen an emergence of consumer level interface devices suitable for use in gaming. While past {{research has indicated that}} immersion is a factor in exergame effectiveness, there has been little research investigating the use of immersive interface technologies such as <b>head</b> <b>mounted</b> <b>displays</b> for use in exergames. In this paper we identify and discuss five major design challenges {{associated with the use of}} immersive technologies in exergaming: motion sickness caused by sensory disconnect when using a <b>head</b> <b>mounted</b> <b>display,</b> reliable bodily motion tracking controls, the health and safety concerns of exercising when using immersive technologies, the selection of an appropriate player perspective, and physical feedback latency. We demonstrate a prototype exergame utilising several affordable immersive gaming devices as a case study in overcoming these challenges. The results of a user study we conducted found that our prototype game was largely successful in overcoming these challenges, although further work would lead to improvement and we were able to identify further issues associated with the use of a <b>head</b> <b>mounted</b> <b>display</b> during exercise...|$|R
50|$|<b>Head</b> <b>Mounted</b> <b>Display</b> {{systems are}} also used in the {{maintenance}} of complex systems, as they can give a technician a simulated x-ray vision by combining computer graphics such as system diagrams and imagery with the technician's natural vision (augmented or modified reality).|$|R
40|$|In the ARTHUR project <b>head</b> <b>mounted</b> {{cameras are}} used for {{real-time}} tracking and position/orientation estimation of objects manipulated by humans sitting around a table. This paper gives {{an overview of the}} methods employed for robust object tracking in varying lighting conditions, and for maintaining the exterior calibration of all <b>head</b> <b>mounted</b> cameras such that 3 D information about positions and orientations can be generated relative to a shared world coordinate system. The ARTHUR project develops an augmented reality system facilitating multi-user activities in architectural and urban planning. The users sit around a table and each user is wearing a <b>head</b> <b>mounted</b> <b>display.</b> Virtual objects, such as buildings, are visualised on the <b>head</b> <b>mounted</b> <b>displays</b> in accordance with each users' viewpoint and viewing direction. Users interact with the virtual objects by manipulating real, physical objects in the workspace on and above the table...|$|R
40|$|This paper {{presents}} a {{comparative study of}} driving behavior when using different virtual reality modes. Test subjects were exposed to mixed, virtual, and real reality using a <b>head</b> <b>mounted</b> <b>display</b> capable of video see-through, while performing a simple driving task. The driving behavior was quantified in steering and acceleration/deceleration activities, divided into local and global components. There was a distinct effect of wearing a <b>head</b> <b>mounted</b> <b>display,</b> which affected all measured variables. Results show that average speed was the most significant difference between mixed and virtual reality, while the steering behavior was consistent between modes. All subjects but one were able to successfully complete the driving task, suggesting that virtual driving could be a potential complement to driving simulators. Next Generation Test Methods for Active Safety Function...|$|R
