0|23|Public
40|$|HJ- 1 A/B NDVI (HJ NDVI) {{time-series data}} possess {{relatively}} high spatio-temporal resolution which is {{significant for the}} research on urban areas. However, its application is <b>hindered</b> by <b>noise</b> resulting from the restrictions of imaging quality and limits of the satellite platform. The NDVI noise reduction is necessary. Some noise-reduction techniques including the asymmetric Gaussian filter (AG), the double logistic filter (DL), the Savitzky-Golay (S-G) filter and the harmonic analysis (Hants) of NDVI time-series {{have been used to}} carry out the NDVI time series reconstruction, and based on the comparison results of different filter, S-G filter is the optimal in the application on urban areas. Finally,urban vegetation mapping is carried out based on the new HJ NDVI...|$|R
50|$|Noise {{pollution}} {{is a factor}} of environmental degradation that is often overlooked and typically seen as not having a significant impact, though traffic noise can contribute to numerous disturbances for wildlife. Few {{studies have been done}} on road ecology, and even fewer on the effects of noise on wildlife, though one study revealed that noise can have a negative impact, particularly on birds. Noise from major roads can interrupt the calls of song birds, and their instinctive calls associated with mating, communication, migration, and other purposes are <b>hindered</b> by <b>noise</b> from roads. This did not necessarily directly provide a fatal effect for the tested birds, but the study showed that species abundance declined around major roads due to noise.|$|R
40|$|Saliency is an {{important}} perceptual cue that occurs at different scales of resolution. Important attributes of saliency are symmetry, continuity, and closure. Detection of these attributes is often <b>hindered</b> by <b>noise,</b> variation in scale, and incomplete information. An iterative voting method using oriented kernels is introduced for inferring saliency {{as it relates to}} symmetry or continuity. A unique aspect of the technique is in the kernel topography, which is refined and reoriented iteratively. The technique can cluster and group nonconvex perceptual circular symmetries along the radial line or sparse features along the trangential direction. It has an excellent noise immunity, and is shown to be tolerant to perturbation in scale. Applications of this approach to blobs with incomplete and noisy boundaries and to scientific images are demonstrated. ...|$|R
40|$|The Bayesian data {{analysis}} framework {{has been proven}} to be a systematic and effective method of parameter inference and model selection for stochastic processes. In this work we introduce an information content model check which may serve as a goodness-of-fit, like the chi-square procedure, to complement conventional Bayesian analysis. We demonstrate this extended Bayesian framework on a system of Langevin equations, where coordinate dependent mobilities and measurement <b>noise</b> <b>hinder</b> the normal mean squared displacement approach. Comment: 10 pages, 7 figures, REVTeX, minor revision...|$|R
40|$|Membrane {{proteins}} organize {{themselves in}} a linear fashion where adjacent cells are attached together along the basal-lateral region. Their intensity distributions are often heterogeneous and may lack specificity. Grouping of these linear structures can aid in segmentation and quantitative representation of protein localization. However, quantitative analysis of these signals is often <b>hindered</b> by <b>noise,</b> variation in scale, and perceptual features. This paper introduces an iterative voting method for inferring the membrane signal {{as it relates to}} continuity. A unique aspect of this technique is in the topography of the voting kernel, which is refined and reoriented iteratively. The technique can cluster and group membrane signals along the tangential direction. It has an excellent noise immunity and is tolerant to perturbations in scale. Application of this technique to quantitative analysis of cell-cell adhesion mediated by integral cell membrane proteins is demonstrated. 1...|$|R
40|$|Virtual {{reconstruction}} of large landscapes from satellite imagery {{can be a}} time-consuming task due {{to the number of}} objects that must be extracted. Poor image resolution and <b>noise</b> <b>hinder</b> automatic detection processes and thus must be corrected by the user. This paper describes an application that allows the user to guide the automatic detection of trees from satellite imagery and spatial vegetation data. The requirements of the system are specified and an architecture that satisfies these constraints is presented. The resulting application provides an intuitive computeraided method for the selection and classification of trees. ...|$|R
40|$|Sound-recording {{acoustic}} {{tags attached}} to marine animals {{are commonly used}} in behavioural studies. Measuring ambient noise is of interest to efforts to understand responses of marine mammals to anthropogenic underwater sound, or to assess their communication space. Noise of water flowing around the tag reflects {{the speed of the}} animal, but <b>hinders</b> ambient <b>noise</b> measurement. Here, we describe a correlation-based method for stereo acoustic tags to separate the relative contributions of flow and ambient noise. The uncorrelated part of the noise measured in digital acoustic recording tag (DTAG) recordings related well to swim speed of a humpback whale (Megaptera novaeangliae), thus providing a robust measure of flow noise over a wide frequency bandwidth. By removing measurements affected by flow noise, consistent ambient noise estimates were made for two killer whales (Orcinus orca) with DTAGs attached simultaneously. The method is applicable to any multi-channel acoustic tag, enabling application {{to a wide range of}} marine species...|$|R
40|$|Abstract—Saliency is an {{important}} perceptual cue that occurs {{at different levels of}} resolution. Important attributes of saliency are symmetry, continuity, and closure. Detection of these attributes is often <b>hindered</b> by <b>noise,</b> variation in scale, and incomplete information. This paper introduces the iterative voting method, which uses oriented kernels for inferring saliency as it relates to symmetry. A unique aspect of the technique is the kernel topog-raphy, which is refined and reoriented iteratively. The technique can cluster and group nonconvex perceptual circular symmetries along the radial line of an object’s shape. It has an excellent noise immunity and is shown to be tolerant to perturbation in scale. The application of this technique to images obtained through various modes of microscopy is demonstrated. Furthermore, as a case example, the method has been applied to quantify kinetics of nuclear foci formation that are formed by phosphorylation of histone H 2 AX following ionizing radiation. Iterative voting has been implemented in both 2 -D and 3 -D for multi image analysis. Index Terms—Foci detection, geometric voting, iterative voting, segmentation, subcellular localization. I...|$|R
40|$|The {{performance}} of template-based inspection of randomly oriented targets {{relies on the}} effective operation of two procedures: image registration and change detection. Each procedure is characterised by its own challenges. Real-time applications require that image registration is performed in an acceptable time with accurate results, regardless of structural distortions. Change detection can be <b>hindered</b> by <b>noise</b> fluctuations and illumination variations. An additional challenge in template-guided change detection {{comes from the fact}} that the decision needs to be based on a comparison restricted to two frames. The operation principles of a template-guided change detector are analysed. Image registration is based on a wavelet-based method which employs mutual information. A block-based change detection algorithm, which separates content alterations from noise-level fluctuations, illumination variations and shadows, is also analysed. The principles presented are combined for the implementation of a sample template-guided undervehicle surveillance system. The architecture of the system and its experimental results are presented, and practical aspects and considerations regarding the system design are discussed. © 2008 The Institution of Engineering and Technology...|$|R
40|$|Objective: High {{frequency}} oscillations (HFOs, > 80. Hz) are biomarkers for epileptogenic cortex in invasive and non-invasive electroencephalography (EEG). Identification of HFOs in magnetoencephalography (MEG) is <b>hindered</b> by <b>noise.</b> Computing spatial filters using beamforming {{to reconstruct}} time series for selected brain regions, so-called virtual sensors (VS), {{can increase the}} signal-to-noise ratio. We identified HFOs in MEG in time domain using VS. Methods: Fifteen minutes of MEG data were selected from 12 patients. VS were placed around the epileptic spikes (affected region) and in the contralateral hemisphere. VS and physical sensors were reviewed for HFOs and spikes. HFO locations were compared to spikes and other clinical parameters. Results: Eight patients showed 78 time points with 575 HFOs in VS, 513 were in the affected region. HFOs could not be identified in physical sensors for 61 of the 78 VS time points. HFOs overlapped with presumed epileptogenic areas and were also visible in unfiltered VS signals. Conclusion: Beamformer-based VS analysis can help to identify epileptic HFOs that are not discernable in physical MEG sensors. Significance: This approach can be extended to enable localization of non-invasively recorded HFOs. This would help surgical planning and {{reduce the need for}} invasive diagnostics...|$|R
40|$|Abstract. Contrast-enhanced {{ultrasound}} (CEUS) is {{a valuable}} imaging modality as it allows a visualization of the vascularization and comple-ments the anatomical information provided by conventional ultrasound (US). However, in such images classical segmentation algorithms may be <b>hindered</b> by the <b>noise,</b> the limited field of view or shadowing effects. In this paper, we propose to use simultaneously the different information coming from US and CEUS images {{to address the problem}} of kidney segmentation. To that end, we develop a generic framework for joint co-segmentation and registration and apply it to an ellipsoid estimation (kidney detection) and a model-based segmentation algorithm (kidney segmentation). Both methods rely on voxel classification maps, that we estimate using random forest in an original approach. This results in a fully automated pipeline for kidney segmentation in US and CEUS that outperforms state-of-the-art techniques on a clinically representa-tive dataset...|$|R
40|$|A. M. v. B. B. and P. B. were {{funded by}} The Netherlands Ministry of Defence. Fieldwork efforts {{and support for}} P. M. and F. S. was {{provided}} by the US Office of Naval Research [award numbers N 00014 - 08 - 1 - 0984 and N 00014 - 10 - 1 - 0355]. P. W. received a PhD studentship with matched funding from The Netherlands Ministry of Defence (administered by The Netherlands Organisation for Applied Scientific Research, TNO) and UK Natural Environment Research Council [NE/J 500276 / 1]. Sound-recording acoustic tags attached to marine animals are commonly used in behavioural studies. Measuring ambient noise is of interest to efforts to understand responses of marine mammals to anthropogenic underwater sound, or to assess their communication space. Noise of water flowing around the tag reflects the speed of the animal, but <b>hinders</b> ambient <b>noise</b> measurement. Here, we describe a correlation-based method for stereo acoustic tags to separate the relative contributions of flow and ambient noise. The uncorrelated part of the noise measured in digital acoustic recording tag (DTAG) recordings related well to swim speed of a humpback whale (Megaptera novaeangliae), thus providing a robust measure of flow noise over a wide frequency bandwidth. By removing measurements affected by flow noise, consistent ambient noise estimates were made for two killer whales (Orcinus orca) with DTAGs attached simultaneously. The method is applicable to any multi-channel acoustic tag, enabling application {{to a wide range of}} marine species. Publisher PDFPeer reviewe...|$|R
40|$|The {{purpose of}} {{detecting}} trace concentrations of analytes often is <b>hindered</b> by occurring <b>noise</b> in the signal curves of analytical methods. This {{is also a}} problem when different arsenic species (organic arsenic species such as arsanilic acid, nitarsone and roxarsone) are to be determined in animal meat by HPLC-UV-HG-AFS, which {{is the basis of}} this work. In order to improve the detection power, methods of signal treatment may be applied. We show a comparison of convolution with Gaussian distribution curves, Fourier transform, and wavelet transform. It is illustrated how to estimate decisive parameters for these techniques. All methods result in improved limits of detection. Furthermore, applying baselines and evaluating peaks thoroughly is facilitated. However, there are differences. Fourier transform may be applied, but convolution with Gaussian distribution curves shows better results of improvement. The best of the three is wavelet transform, whereby the detection power is improved by factors of about 2. ...|$|R
40|$|Several {{countries}} have implemented programs that use test scores to rank schools, and to reward or penalize them {{based on their}} students' average performance. Recently, Kane and Staiger (2002) have warned that imprecision in the measurement of school-level test scores could impede these efforts. There is little evidence, however, on how seriously <b>noise</b> <b>hinders</b> {{the evaluation of the}} impact of these interventions. We examine these issues in the context of Chile's P- 900 program a country-wide intervention in which resources were allocated based on cutoffs in schools' mean test scores. We show that transitory noise in average scores and mean reversion lead conventional estimation approaches to greatly overstate the impacts of such programs. We then show how a regression discontinuity design that utilizes the discrete nature of the selection rule can be used to control for reversion biases. While the RD analysis provides convincing evidence that the P- 900 program had significant effects on test score gains, these effects are much smaller than is widely believed. ...|$|R
40|$|Removing {{objects that}} are noise is an {{important}} goal of data cleaning as <b>noise</b> <b>hinders</b> most types of data analysis. Most existing data cleaning methods focus on removing noise that {{is the result of}} low-level data errors that result from an imperfect data collection process, but data {{objects that are}} irrelevant or only weakly relevant can also significantly hinder data analysis. Thus, if the goal is to enhance the data analysis as much as possible, these objects should also be considered as noise, at least with respect to the underlying analysis. Consequently, {{there is a need for}} data cleaning techniques that remove both types of noise. Because data sets can contain large amount of noise, these techniques also need to be able to discard a potentially large fraction of the data. This paper explores four techniques intended for noise removal to enhance data analysis in the presence of high noise levels. Three o...|$|R
40|$|Conventional {{tomography}} (X-ray scanner, Computed Tomography : CT, Single Photon Emission CT : SPECT, [...] .) {{is widely}} used in numerous fields such as medical imaging and non-destructive testing. In theses tomographies, a detector rotates in space to collect primary radiation emitted by an object under investigation. In this case Compton scattered radiation behaves as <b>noise</b> <b>hindering</b> image quality and consequently correction to scatter should be applied. However recently an interesting new imaging concept, which uses precisely scattered radiation as imaging agent, has been advocated. The camera records now images labeled by scattered photon energy or equivalently scattering angle. Then it is shown that the three dimensional image reconstruction from scattered radiation data is feasible [1, 2, 3, 4, 5]. In this work we propose {{a new form of}} Compton scattering tomography (CST), akin to the X-ray scanning tomography, {{in the sense that it}} works in transmission but uses Compton scattered radiation. The new image formation modeling is based on a new class of Radon transforms on circular arcs. Through simulation results we show the feasibility and the relevance of this new process...|$|R
40|$|Mechanical {{transduction}} {{of torque}} has been key to probing {{a number of}} physical phenomena, such as gravity, the angular momentum of light, the Casimir effect, magnetism, and quantum oscillations. Following similar trends as mass and force sensing, mechanical torque sensitivity can be dramatically improved by scaling down the physical dimensions, and therefore moment of inertia, of a torsional spring. Yet now, through precision nanofabrication and sub-wavelength cavity optomechanics, we have {{reached a point where}} geometric optimization can only provide marginal improvements to torque sensitivity. Instead, nanoscale optomechanical measurements of torque are overwhelmingly <b>hindered</b> by thermal <b>noise.</b> Here we present cryogenic measurements of a cavity-optomechanical torsional resonator cooled in a dilution refrigerator to a temperature of 25 mK, corresponding to an average phonon occupation of = 35, that demonstrate a record-breaking torque sensitivity of 2. 9 yNm/Hz^{ 1 / 2 }. This a 270 -fold improvement over previous optomechanical torque sensors and just over an order of magnitude from its standard quantum limit. Furthermore, we demonstrate that mesoscopic test samples, such as micron-scale superconducting disks, can be integrated with our cryogenic optomechanical torque sensing platform, in contrast to other cryogenic optomechanical devices, opening the door for mechanical torque spectroscopy of intrinsically quantum systems. Comment: 25 pages, 7 figure...|$|R
40|$|In {{its current}} state, the wide {{acceptance}} of the Magneto-Optical Imaging (MOI) technique is <b>hindered</b> due to <b>noise,</b> lack of recordable results, and impossibility of data post-processing. This paper presents some add-ons made to a commercial MOI system to ease the image interpretation, archiving and reporting of the results. In addition, a few image processing techniques are also employed {{in an attempt to}} perform automatic flaw detection. The recording capability of the MOI instrument output images was addressed by digitizing the video signal in video or image files. To help with the identification of the damage location and distance between images, a rotary quadrature encoder was mounted onto the MOI scan head. The use of the encoder allowed the identification of the inspection location with respect to a reference position, such as the beginning of the scan. Moreover, it allowed saving images at fixed intervals, which were then stitched into a single image, thus simplifying the post inspection analysis process. Both live and post-inspection image processing capabilities were made available. Implemented image processing included background subtraction, de-noising, contrast adjustment and morphological operation, among others. Contrast stretching transform and background subtractions were found to be among the most powerful techniques {{that could be used in}} simplifying the image interpretation. Peer reviewed: YesNRC publication: Ye...|$|R
40|$|International audienceThe Cassini Synthetic Aperture Radar {{has been}} {{acquiring}} images of Titan's surface since October 2004. To date, 59 % of Titan's surface has been imaged by radar, with significant regions imaged more than once. Radar data suffer from speckle <b>noise</b> <b>hindering</b> interpretation of small-scale features and comparison of reimaged regions for change detection. We present here {{a new image}} analysis technique that combines a denoising algorithm with mapping and quantitative measurements that greatly enhance {{the utility of the}} data and offers previously unattainable insights. After validating the technique, we demonstrate the potential improvement in understanding of surface processes on Titan and defining global mapping units, focusing on specific landforms including lakes, dunes, mountains, and fluvial features. Lake shorelines are delineated with greater accuracy. Previously unrecognized dissection by fluvial channels emerges beneath shallow methane cover. Dune wavelengths and interdune extents are more precisely measured. A significant refinement in producing digital elevation models is shown. Interactions of fluvial and aeolian processes with topographic relief is more precisely observed and understood than previously. Benches in bathymetry are observed in northern sea Ligeia Mare. Submerged valleys show similar depth suggesting that they are equilibrated with marine benches. These new observations suggest a liquid level increase in the northern sea, which may be due to changes on seasonal or longer timescales...|$|R
40|$|The Cassini Synthetic Aperture Radar (SAR) {{has been}} {{acquiring}} images of Titan's surface since October 2004. Radar data suffer from speckle <b>noise</b> <b>hindering</b> interpretation of small-scale features and comparison of reimaged regions for topography derivation and potential detection. By combining {{a state of}} the art denoising algorithm with mapping and quantitative measurements we greatly offer previously unattainable insights and introducing the denoising version of the Cassini SAR named NLDSAR. The Cassini Synthetic Aperture Radar (SAR) has been acquiring images of Titan's surface since October 2004. Radar data suffer from speckle <b>noise</b> <b>hindering</b> interpretation of small-scale features and comparison of reimaged regions for topography derivation and potential detection. By combining {{a state of the}} art denoising algorithm with mapping and quantitative measurements we greatly offer previously unattainable insights and introducing the denoising version of the Cassini SAR named NLDSAR. Caltech Release [v 1] is the very first (*alpha*) release that is now publicaly available with few rules of road described below. The data are corrected with incidence angle with the same emperical correction than the BIDR data set. Note that some swaths are badly navigated as reprojection has been performed since (e. g., Ta-T 30,*reproc 1 *). Consequently, the dataset need to be used *very* wisely, therefore, any intend user of the NLDSAR data, may need to contact: Antoine Lucas (dralucas [~@~] geophysx. edu. eu. org) for further information;At least, you agree to cite the following paper in any communication (paper, conference, press release, outreach etc.) : Lucas et al., Insights into Titan's geology and hydrology based on enhanced image processing of Cassini RADAR data Journal of Geophys. Research, doi: 10. 1002 / 2013 JE 004584, 2014. List of papers that have been based on the Caltech Release: - Insights into Titan's geology and hydrology based on enhanced image processing of Cassini RADAR data A. Lucas, O. Aharonson, C-A. Deledalle, A. Hayes, R. Kirk, E. Howington-Kraus and the CRST Journal of Geophys. Research, doi: 10. 1002 / 2013 JE 004584, 2014 - Growth mechanisms and dune orientation on Titan A. Lucas, S. Rodriguez, C. Narteau, B. Charnay, T. Tokano, A. Garcia, M. Thiriet, S. Courrech du Pont, A. Hayes, R. Lorenz, O. Aharonson Geophys. Research Letters, doi: 10. 1002 / 2014 GL 060971, 2014 - Methane storms as a driver of Titan's dune orientation B. Charnay, E. Barth, S. Rafkin, C Narteau, S. Lebonnois, S. Rodriguez, S. Courrech du Pont, A. Lucas Nature Geoscience, doi: 10. 1038 /ngeo 2406, 2015 - Compositional and spatial variations in Titan dune and interdune regions from Cassini VIMS and RADAR L. E. Bonnefoy, A. G. Hayes, P. O. Hayne, M. J. Malaska, A. Le Gall, A. Solominodou, A. Lucas Icarus, doi: 10. 1016 /j. icarus. 2015. 09. 014, 2015 - Sand dune patterns on Titan controlled by long-term climate cycles RC Ewing, AG Hayes, A Lucas Nature Geoscience, doi: 10. 1038 /ngeo 2323, 201...|$|R
40|$|Abstract—Removing {{objects that}} are noise is an {{important}} goal of data cleaning as <b>noise</b> <b>hinders</b> most types of data analysis. Most existing data cleaning methods focus on removing noise that {{is the product of}} low-level data errors that result from an imperfect data collection process, but data {{objects that are}} irrelevant or only weakly relevant can also significantly hinder data analysis. Thus, if the goal is to enhance the data analysis as much as possible, these objects should also be considered as noise, at least with respect to the underlying analysis. Consequently, {{there is a need for}} data cleaning techniques that remove both types of noise. Because data sets can contain large amounts of noise, these techniques also need to be able to discard a potentially large fraction of the data. This paper explores four techniques intended for noise removal to enhance data analysis in the presence of high noise levels. Three of these methods are based on traditional outlier detection techniques: distance-based, clustering-based, and an approach based on the Local Outlier Factor (LOF) of an object. The other technique, which is a new method that we are proposing, is a hyperclique-based data cleaner (HCleaner). These techniques are evaluated in terms of their impact on the subsequent data analysis, specifically, clustering and association analysis. Our experimental results show that all of these methods can provide better clustering performance and higher quality association patterns as the amount of noise being removed increases, although HCleaner generally leads to better clustering performance and higher quality associations than the other three methods for binary data. Index Terms—Data cleaning, very noisy data, hyperclique pattern discovery, local outlier factor (LOF), noise removal. ...|$|R
40|$|As {{projected}} {{air travel}} {{is expected to}} increase up till 2030, future airports are faced to deal with the impact of (rising) <b>noise</b> <b>hinder</b> within their environment and the resulting allowed attainable throughput capacity. To date, several proposed techniques are able to lower the noise contribution. This thesis study focusses on weather-adaptive trajectory optimization, in which departure trajectories - subjected to day-to-day meteorological variations - are reshaped {{in such a way that}} inhabited areas are (partly) avoided to exposed noise areas generated by the aircraft. Incorporating day-to-day meteorological variability into trajectory optimization leads to an enhancement over reference-day trajectory optimization. This enhancement allows for improved accuracy with respect to the aircraft performance- and noise footprint calculations. The accuracy increase can be used to generate opportunities to improve the reference-day optimized trajectories even further. This led to the following purpose statement: The aim of this thesis work is to accurately represent the noise footprint by means of quantifying the influence of meteorological variability of the effects in wind and temperature variations on the shape and extent of aircraft acoustic footprints and use this information to optimize aircraft trajectories for diverse objectives. For this purpose, the FORT reference-day optimization tool is extended with weather dependent effects in an accurate and computationally tractable manner. The enhanced, weather-adaptive, FORT tool is able to optimize flight trajectories with respect to time, fuel, emissions, and awakenings objectives at any given airport for several departure procedures. Within FORT, the noise submodel is based on the INM methodology and enhanced with daily varying excess attenuation. This day-to-day varying excess attenuation replaces the lateral attenuation correction, which represented average yearly excess attenuation. The day-to- day excess attenuation is accessed for various noise-observer distances by means of an EA-database. In this way, the noise submodel employs a table lookup approach for both its NPD- and EA-calculations, maintaining simple and fast lookup table calculations while allowing complex evaluation of atmospheric effects on noise contours. Aircraft and acoustic performance is significantly influenced by varying temperature, relative humidity, wind speed, and wind direction layers. A positive temperature lapse rate distribution leads to upward ray path refraction, causing shadow zones, where a negative lapse rate results in downward refraction, causing caustics formation. Furthermore, the combination of temperature and relative humidity have a significant effect on the amount of acoustic absorption. Finally, the combination of temperature and wind layers induce greater speed of sound differences. This greater difference leads to a stronger presence of shadow zones and caustics phenomena, which can be used to eliminate noise at populated areas. Meteorological phenomena, which are seasonal dependent, cause the temperature, relative humidity, and wind profile distribution in the troposphere to vary, which results into different day-to-day aircraft and acoustic performance. The impact of weather-adaptive optimization is assessed by means of a case study in which two departure trajectories are optimized for multiple objectives, while being subjected to several atmospheric profiles. The two departures are based on standard instrument departures currently in use at AAS. The weather-adaptive trajectory optimization model complies with all the regulations and guidelines applicable to departure trajectories prescribed by PANSOPS and AAS in order to create a realistic and feasible trajectory. The atmospheric profiles incorporate temperature-, relative humidity-, wind speed-, and wind direction distribution differences to show the impact of seasonal effects on the optimization outcome. The weather-adaptive optimization results are compared to both reference-day optimization results and standard departure trajectories executed at AAS. For both cases, significant differences in aircraft- and acoustic performance are obtained for all objectives (time, fuel, emission, and awakenings). Firstly, when comparing the reference-day optimization to the results of the weather-adaptive optimization, it is concluded that the true impact of reference-day optimized trajectories on time, fuel, emission, and awakenings objectives differ significantly when subjected to a nonreference- day atmospheric profile. The time, fuel, and emission objectives are dependent on aircraft performance and are therefore affected by the varying wind speed and direction profile. The awakenings objective is both affected by the aircraft- and acoustic performance and therefore influenced by the full atmospheric profile. Secondly, for both standard AAS departure trajectories and reference-day optimized trajectories, it is concluded that the weather-adaptive optimization is able to generate an opportunity to further decrease the objectives. FORT utilizes the atmosphere in a positive manner, by means of aircraft performance advantages and acoustic focussing effects (e. g. directing shadow zones towards unpopulated areas). Finally, it can be concluded that the inclusion of meteorological variability into trajectory optimization leads to improved accuracy of the aircraft- and acoustic performance in general. These results create a better understanding about the atmospheric effects in terms of aircraft performance and subsequent noise contours. Furthermore, the weather-adaptive model is able to use the accuracy increase to further decrease the awakenings impact. For future work, the results can be further improved by analyzing different aircraft types on trajectory optimization output. Furthermore, the combination of multiple simultaneous optimized arrival- and departure trajectory optimizations could be researched in order to improve the feasibility of the current established trajectories with respect to separation requirements. Last but not least, societal costs play a major role when optimizing the awakenings objective. In certain cases, the total number of awakenings can be reduced significantly. This decrease however, may be at the expense of accompanying societal costs as new trajectories could induce complaints and other forthcoming societal costs when flying over different populated areas. The impact of changing the trajectories with respect to social aspects could be researched in more detail to establish societal feasibility of the optimized trajectories. Air transport and Aerospace OperationsControl and SimulationAerospace Engineerin...|$|R

