11|0|Public
3000|$|The first unknown is {{the desired}} <b>defogged</b> image x. The second unknown {{variable}} is the airlight color, [...]...|$|E
3000|$|... 0 [*]=[*] 0.001) (see {{the work}} by [9] for the {{recovery}} method and [17] for additional gamma corrections). For generating the <b>defogged</b> image using the centroid prior, [...]...|$|E
40|$|Videos taken under fog {{suffer from}} {{degradation}} such as severe contrast loss. Unfortunately, that effect of fog cannot {{be overcome by}} simple image processing techniques. In this paper, a novel method for the contrast enhancement of foggy video sequences is proposed based on the Contrast Limited Adaptive Histogram Equalization (CLAHE), which limits the intensity of each pixel to user determined maximum. Thus, it mitigates the degradation due to fog and improves the visibility of the video signal. Initially, the background and foreground images are extracted from the video sequence. Then, the background and foreground images are separately <b>defogged</b> by applying CLAHE. The <b>defogged</b> background and foreground images are fused into the new frame. Finally, the <b>defogged</b> video sequence is obtained. The experimental {{results show that the}} proposed method is more effective than the traditional method. Performance of the proposed method is also analyzed with contrast improvement index (CI) and Tenengrad criterion (TEN) ...|$|E
40|$|Recently, {{the stereo}} imaging-based image {{enhancement}} approach has attracted increasing {{attention in the}} field of video analysis. This paper presents a dual camera-based stereo image defogging algorithm. Optical flow is first estimated from the stereo foggy image pair, and the initial disparity map is generated from the estimated optical flow. Next, an initial transmission map is generated using the initial disparity map. Atmospheric light is then estimated using the color line theory. The <b>defogged</b> result is finally reconstructed using the estimated transmission map and atmospheric light. The proposed method can refine the transmission map iteratively. Experimental results show that the proposed method can successfully remove fog without color distortion. The proposed method {{can be used as a}} pre-processing step for an outdoor video analysis system and a high-end smartphone with a dual camera system...|$|E
40|$|Contrast {{and color}} of the {{captured}} pictures are degraded under foggy weather conditions and this degradation is often attributed to attenuation and airlight. To {{reduce the number of}} road accidents through vision enhancement in turbid weather, an efficient fog removal technique plays a vital role as fog greatly reduces the visibility and hence affects the computer vision algorithms such as surveillance, tracking and Fog Vision Enhancement System (FVES). In this paper, a novel and effective algorithm is proposed for single image fog removal that’s capable of handling images of gray and color channels. The proposed algorithm introduces Dark Channel Prior (DCP) followed by Weighted Least Square (WLS) and High Dynamic Range (HDR) based fog removal scheme. The qualitative and quantitative analysis is applied for the assessment of <b>defogged</b> images obtained from the proposed methodology and is additionally compared with the different fog removal algorithms to establish its superiority. The foremost dominant advantage of the proposed algorithm is its capability to preserve sharp details whereas maintaining the color quality...|$|E
40|$|International audienceOne {{source of}} {{accidents}} when driving a vehicle {{is the presence}} of fog. Fog fades the colors and reduces the contrasts in the scene with respect to their distances from the driver. Various camera-based Advanced Driver Assistance Systems (ADAS) can be improved if efficient algorithms are designed for visibility enhancement in road images. The visibility enhancement algorithm proposed in [1] is not optimized for road images. In this paper, we reformulate the problem as the inference of the local atmospheric veil from constraints. The algorithm in [1] thus becomes a particular case. From this new derivation, we propose to better handle road images by introducing an extra constraint taking into account that {{a large part of the}} image can be assumed to be a planar road. The advantages of the proposed local algorithm are the speed, the possibility to handle both color and gray-level images, and the small number of parameters. A new scheme is proposed for rating visibility enhancement algorithms based on the addition of several types of generated fog on synthetic and camera images. A comparative study and quantitative evaluation with other state-of-the-art algorithms is thus proposed. This evaluation demonstrates that the new algorithm produces better results with homogeneous fog and that it is able to deal better with the presence of heterogeneous fog. Finally, we also propose a model allowing to evaluate the potential safety benefit of an ADAS based on the display of <b>defogged</b> images...|$|E
40|$|Dark channel prior {{is a kind}} of {{statistics}} of the haze-free outdoor images, which is widely used in image defogging. But when the image contains a large bright region, such as sky and white object, the prior will cause color distortion in these bright regions because of the underestimated transmission. To solve this problem, a video defogging technology based on adaptive tolerance is presented in this paper, and it is applied to video defogging by combining with the guided filter. First, the transmission of each video frame is estimated according to the dark channel prior, and then it is fast refined by the guided filter for restoration. If a large bright region exists in the video frame, the transmission of these regions will be corrected according to the adaptive tolerance, which avoids the color distortion in the video defogging. For the video of dynamic scenes which are caused by camera motion, each frame is <b>defogged</b> as a single image. But for the video of static scenes whose background is almost invariant, the transmission of the background is estimated and used for the defogging of all the frames instead of estimating the transmission of each frame. In this way, the rate of video defogging is greatly improved. Experimental results show that the algorithm has a strong applicability, and the proposed method can be further used for many applications, such as outdoor surveillance, remote sensing and intelligent vehicles...|$|E
40|$|LNCS v. 7724 - 7727 (pts. 1 - 4) entitled: Computer vision - ACCV 2012 : 11 th Asian Conference on Computer Vision [...] . 2012 : revised {{selected}} papersThe {{quality of}} outdoor surveillance videos are always degraded by bad weathers, such as fog, haze, and snowing. The degraded videos not only provide poor visualizations, but {{also increase the}} difficulty of vision-based analysis such as foreground/background segmentation. However, haze/fog removal has never been an easy task, and is often very time consuming. Most of the existing methods only consider a single image, and no temporal information of a video is used. In this paper, a novel adaptive background defogging method is presented. It is observed {{that most of the}} background regions between two consecutive video frames do not vary too much. Based on this observation, each video frame is firstly <b>defogged</b> by a background transmission map which is generated adaptively by the proposed foreground decremental preconditioned conjugate gradient (FDPCG). It is shown that foreground/background segmentation can be improved dramatically with such background-defogged video frames. With the help of a foreground map, the defogging of foreground regions is then completed by 1) foreground transmission estimation by fusion, and 2) transmission refinement by the proposed foreground incremental preconditioned conjugate gradient (FIPCG). Experimental results show that the proposed method can effectively improve the visualization quality of surveillance videos under heavy fog and snowing weather. Comparing with the state-of-the-art image defogging methods, the proposed method is much more efficient. © 2013 Springer-Verlag. postprin...|$|E
40|$|Abstract—Fog reduces {{contrast}} {{and thus the}} visibility of vehicles and obstacles for drivers. Each year, this causes traffic accidents. Fog {{is caused by a}} high concentration of very fine water droplets in the air. When light hits these droplets, it is scattered and this results in a dense white background, called the atmospheric veil. As pointed in [1], Advanced Driver Assistance Systems (ADAS) based on the display of <b>defogged</b> imagesfromacameramayhelpthedriverbyimprovingobjects visibilityintheimageandthusmayleadtoadecrease offatality and injury rates. In the last few years, the problem of single image defogging has attracted attention in the image processing community. Being an ill-posed problem, several methods have been proposed. However, a few among of these methods are dedicated to the processing of road images. One of the first exception is the method in [2], [1] where a planar constraint is introduced to improve the restoration of the road area, assuming an approximately flat road. The single image defogging problem being ill-posed, the choice of the Bayesian approach seems adequate to set this problem as an inference problem. A first Markov Random Field (MRF) approach of the problem has been proposed recently in [3]. However, this method is not dedicated to road images. In this paper, we propose a novel MRF model of the single image defogging problem which applies to all kinds of images but can also easily be refined to obtain better results on road images using the planar constraint. A comparative study and quantitative evaluation with several state-of-the-art algorithms is presented. This evaluation demonstrates that the proposed MRF model allows to derive a new algorithm which produces better quality results, in particular in case of a noisy input image. I...|$|E
40|$|Fog reduces {{contrast}} {{and thus the}} visibility of vehicles and obstacles for drivers. Each year, this causes traffic accidents. Fog {{is caused by a}} high concentration of very fine water droplets in the air. When light hits these droplets, it is scattered and this results in a dense white background, called the atmospheric veil. As pointed in [1], Advanced Driver Assistance Systems (ADAS) based on the display of <b>defogged</b> images from a camera may help the driver by improving objects visibility in the image and thus may leads to a decrease of fatality and injury rates. In the last few years, the problem of single image defogging has attracted attention in the image processing community. Being an ill-posed problem, several methods have been proposed. However, a few among of these methods are dedicated to the processing of road images. One of the first exception is the method in [2], [1] where a planar constraint is introduced to improve the restoration of the road area, assuming an approximately flat road. The single image defogging problem being ill-posed, the choice of the Bayesian approach seems adequate to set this problem as an inference problem. A first Markov Random Field (MRF) approach of the problem has been proposed recently in [3]. However, this method is not dedicated to road images. In this paper, we propose a novel MRF model of the single image defogging problem which applies to all kinds of images but can also easily be refined to obtain better results on road images using the planar constraint. A comparative study and quantitative evaluation with several state-of-the-art algorithms is presented. This evaluation demonstrates that the proposed MRF model allows to derive a new algorithm which produces better quality results, in particular in case of a noisy input image...|$|E

