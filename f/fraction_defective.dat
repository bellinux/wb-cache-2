30|56|Public
5000|$|Interesting {{results have}} already been proven in real situations. Korean {{government}} has just announced the raise of a 57.5 billion $ for building smart factories this year after that 1240 Korean smart SMEs have showed [...] "a 27.6% decrease in <b>fraction</b> <b>defective,</b> a cost reduction of 29.2% and a 7.1% reduction in {{the length of time}} taken for prototype production".|$|E
40|$|In this work, {{we discuss}} the concept of brand and, after a brief {{presentation}} {{of the origins of}} it and its relationship with trademarks and quality marks, we propose a new perceptual map to compare two similar brands. This perceptual map is inspired by a scheme used in quality control, specifically in the capability of a technological process evaluation problem. We advance also a proposal to use so-called "deprivation index" (belonging to Townsend) which may be considered as a <b>fraction</b> <b>defective</b> in judging the quality of a certain system. Relevant references related to these ideas are also given in the text. brand, SQC methods, perceptual map deprivation index, <b>fraction</b> <b>defective.</b> ...|$|E
40|$|We {{consider}} variable {{acceptance sampling}} plans {{that control the}} lot or process <b>fraction</b> <b>defective,</b> where a specification limit defines acceptable quality. The problem {{is to find a}} sampling plan that fulfils some conditions, usually on the operation characteristic. Its calculation heavily depends on distributional properties that, in practice, might be doubtful. If prior data are already available, we propose to estimate the sampling plan by means of bootstrap methods. The bias and standard error of the estimated plan can be assessed easily by Monte Carlo approximation to the respective bootstrap moments. This resampling approach does not require strong assumptions and, furthermore, is a flexible method that can be extended to any statistic that might be informative for the <b>fraction</b> <b>defective</b> in a lot. ...|$|E
40|$|Acceptance {{sampling}} plans are practical tools for quality assurance applications involving quality contract on product orders. The {{sampling plans}} provide the vendor and buyer decision rules for product acceptance {{to meet the}} preset product quality requirement. As the rapid advancement of manufacturing technology, suppliers require their products to be of high quality with very low <b>fraction</b> of <b>defectives</b> often measured in parts per million. Unfortunately, traditional methods for calculating <b>fraction</b> of <b>defectives</b> no longer work since any sample of reasonable size probably contains no defective product items. In this paper, we introduce an effective sampling plan based on process capability index Cpk to deal with product acceptance determination for low <b>fraction</b> of <b>defectives.</b> The proposed new sampling plan is developed based on the exact sampling distribution rather than approximation. Practitioners can use the proposed method {{to determine the number}} of required inspection units, the critical acceptance value, and make reliable decisions in product acceptance. Acceptance sampling plans Critical acceptance values Decision making <b>Fraction</b> of <b>defectives</b> Process capability indices...|$|R
40|$|AbstractThis paper studies a fuzzy EOQ {{engineering}} {{problem with}} imperfect quality and shortages. An inspector may make {{two types of}} errors while screening the received lot and an imperfect screening process (Raouf et al., 1983) is adopted. The <b>fraction</b> of <b>defectives</b> in the ordered lot {{is assumed to be}} a fuzzy number. A fuzzy EOQ model is formulated to describe this inventory engineering problem and optimal solutions are obtained. The effect of fuzziness of <b>fraction</b> of <b>defectives</b> on optimal solutions is illustrated by a numerical example...|$|R
2500|$|... {{produces}} {{a much smaller}} <b>fraction</b> of the <b>defective</b> items. Hence the knowledge ...|$|R
3000|$|... ϕ _p is {{the mean}} of the <b>fraction</b> <b>defective</b> of {{products}} that provided by the food producers within the nearly three phase, ϕ _r is {{the mean of}} the sampling rate of the food retailers within the nearly three phase. And ϕ _p> 0, ϕ _r> 0; [...]...|$|E
40|$|This study {{investigated}} the extension of existing single acceptance sampling plans indexed by lot tolerance percent defective (LTPD) or limiting quality (LQ) {{with respect to their}} applicability to high precision processes. LTPD/LQ indexed sampling plans were extended to cover the very low <b>fraction</b> <b>defective</b> levels of high precision processes. Plans based on the ISO 2859 - 2 LQ indexed plans, Dodge-Romig LTPD indexed plans, and lot sensitive plans (LSP) were used as bases for the extensions. Target levels for LTPD/LQ were set at defective parts per million levels ranging from 20 ppm to 5000 ppm. The performance of the extended plans was evaluated using measures relating to level of protection afforded by the plans and efficiency in terms of amount of required inspection. The extended Dodge-Romig LTPD plans showed best performance among the three plans generated. Three selected plans from the extended Dodge-Romig LTPD sampling scheme were then subjected to simulation studies. Comparison of the theoretical and simulation data indicated that the plans behave more strictly than expected from theoretical calculations. The specific demands of high precision processes for appropriate sampling inspection plans that cover lower <b>fraction</b> <b>defective</b> levels, {{and at the same time}} satisfy the requirement for economy and efficiency of inspection were shown to be provided by this plan. These results contributed significantly to the manufacturing industry as it continuously strives to improve process yields and decreases <b>fraction</b> <b>defective</b> levels to respond to customer demands of better quality and improved performance...|$|E
40|$|Abstract. This paper {{analyzes}} {{the problem of}} inventory in which the produc-tion system produces perfect and defective goods. In this model {{it is assumed that}} only <b>fraction</b> <b>defective</b> can be repaired. The model jointly determine the quality products and prices that maximize the average net revenue (ANR) per unit time. Model generally developed to describe the model and some case presented. 1...|$|E
40|$|Acceptance {{sampling}} plans are practical tools for quality control applications, which involve quality contracting on product orders between the vendor and the buyer. Those {{sampling plans}} provide the vendor and the buyer rules for lot sentencing while meeting their preset requirements on product quality. In this paper, we introduce a variables sampling plan for unilateral processes {{based on the}} one-sided process capability indices CPU (or CPL), to deal with lot sentencing problem with very low <b>fraction</b> of <b>defectives.</b> The proposed new sampling plan is developed based on the exact sampling distribution rather than approximation. Practitioners can use the proposed sampling plan to determine accurate number of product items to be inspected and the corresponding critical acceptance value, to make reliable decisions. We also tabulate the required sample size n and the corresponding critical acceptance value C 0 for various [alpha]-risks, [beta]-risks, and the levels of lot or process <b>fraction</b> of <b>defectives</b> that correspond to acceptable and rejecting quality levels. Acceptance sampling plan Critical acceptance value <b>Fraction</b> of <b>defectives</b> Process capability indices...|$|R
40|$|Measurement errors {{occurring}} during {{inspection of}} manufactured parts force producers to replace specification limits by slightly more strict test limits. Here accurate test limits are presented which maximize the yield while limiting the <b>fraction</b> of <b>defectives</b> reaching the consumer. Measurement error Inspection Correlated measurements Yield...|$|R
40|$|Apart {{from the}} use of {{statistical}} quality control chart for variables or attributes of food products in a food processing industry, the application of these charts for attributes of fishery products is explained. Statistical quality control chart for <b>fraction</b> <b>defectives</b> is explained by noting defective fish sausages per shift from a sausage industry while control chart for number of defectives is illustrated for number of defective fish cans in each hour of its production of a canning industry. C-chart is another type of control chart which is explained here for number of defects per single fish fillet sampled a 1 l random for every five minutes in a processing industry. These statistical quality control charts help in the more economic use of resource, time and labour than control charts for variables of products. Also control charts for attributes exhibit the quality history of finished products at different times of production thereby minimizing the risk of consumer rejection...|$|R
40|$|Hypergeometric Attribute Sampling System Based on Risk and <b>Fraction</b> <b>Defective</b> (HYPERSAMP) {{computer}} program demonstrates attribute sampling system developed to determine {{minimum sample size}} required for any preselected value for consumer's risk and fraction of nonconforming units. Used in place of MIL-STD- 105 E sampling plans when minimum sample size desirable, such as when tests are destructive or expensive. Written for IBM PC-compatible computers...|$|E
40|$|This thesis {{reports on}} the results of the {{analyses}} of certain aspects of sampling inspection plans. The investigation has been confined to attributes (as distinct from variables) plans and in this respect. the analyses have been concerned with two main aspects of single and double plans. These are:- (i) the Average Outgoing Quality Limit (AOQL) of the plan. (ii) the Average Sample Number (ASN) of the plan. In the former connection the investigation has been concerned with the evaluation of the AOQL analytically and the determination of the <b>fraction</b> <b>defective</b> of the incoming material to give the AOQL. The analyses have been applied to both single and double sampling plans, In the latter connection the investigation has been concerned with the evaluation of the maximum ASN analytically and the determination of the <b>fraction</b> <b>defective</b> of the incoming material to give the maximum value of ASN. The analyses have been confined only to double sampling plans because in the case of single sampling the ASN is constant and is equal to n, the sample size...|$|E
40|$|This paper investigates and formulates the {{relationships}} among average incoming quality limit (AIQL), production process quality level and average <b>fraction</b> <b>defective</b> after production process for a single-stage manufacturing connected-unit situation. Cost components of the system are identified. In order to derive minimum cost single sampling plans where inspection is by attribute, a mathematical model is developed and plans are obtained using discrete optimization for the total expected loss function subject to AIQL and AOQL equality constraints. ...|$|E
40|$|In {{this present}} paper we have argued the {{acceptance}} double sampling plan when the <b>fraction</b> of <b>defective</b> items is a fuzzy number. {{we have shown}} that the operating characteristic (oc) curves of the plan is like a band having a high and low bounds whose width depends on the ambiguity proportion parameter in the lot when that sample size and acceptance numbers is fixed. Finally we completed discuss opinion by a numerical example...|$|R
2500|$|The entire {{output of}} a factory is {{produced}} on three machines. The three machines account for different {{amounts of the}} factory output, namely 20%, 30%, and 50%. The <b>fraction</b> of <b>defective</b> items produced is this: for the first machine, 5%; for the second machine, 3%; for the third machine, 1%. If an item is chosen at random from the total output and {{is found to be}} defective, what is the probability that it was produced by the third machine? ...|$|R
40|$|Background: Acceptance {{sampling}} is {{a statistical}} tool of quality control. Sampling plans and operating characteristic (OC) curves are very useful for conducting acceptance sampling {{and provide the}} quality manager with tools to evaluate {{the quality of a}} production run or shipment. There are developed different sampling plans, but common used in practise are single and double acceptance sampling plans. Objectives: The goal of the paper is to test if applying of single and double sampling plan can lead to statistically significant different conclusion about quality level of observed lot. Methods/Approach: Statistical tests of difference in proportions are used to test if there is some statistically significant difference in probabilities of lot <b>fraction</b> <b>defectives</b> between a single and a double sampling plan at the same levels of probability of acceptance. Results: The results of the analysis show that in some cases there is statistically significant difference. Namely, the quality manager should be careful when he chooses to use, instead of the first, the second sampling plan with different parameters because on that way he could make statistically significant different conclusion about quality level of observed lot. Conclusions: The paper shows that some intentional manipulations by using different sampling plans are possible...|$|R
40|$|Abstract: The {{primary focus}} of this work is to specify the basic {{parameters}} in terms of prior distributions and finding the appropriate conditional posterior distributions to affect the transformation. The principle parameters include {{the upper and lower}} limit for the process’s quality characteristic X, its mean µ, and the standard deviation, the materials <b>fraction</b> <b>defective</b> p, the sample size n, and the lot size N. The Bayesian model’s posterior distributions are derived using known priors as functions of these parameters...|$|E
40|$|As {{a certain}} job is {{repeatedly}} {{done by a}} worker, the outcome comparative to the effort to complete the job gets more remarkable. The outcome may be the time required and <b>fraction</b> <b>defective.</b> This phenomenon is referred to a learning-curve effect. We focus on the parametric modeling of the learning-curve effects on count data using a logistic cumulative distribution function and some probability mass functions such as a Poisson and negative binomial. We conduct various simulation scenarios to clarify the characteristics of th...|$|E
30|$|As seen above, the {{definition}} of the null depends on point of view. The producer must decide on a limiting value for AQLp above which the lot is unacceptable. In other words, if the <b>fraction</b> <b>defective</b> p is less than AQLp (p ≤ AQLp), then the lot is defined by the producer as conforming. On the other hand, for the consumer, (p ≤ LTPDc) defines the conforming lot. Under no circumstances should we assume that the values of AQLp and LTPDc are equal, nor should they be, given that they come from distinct decision makers {{on opposite sides of the}} negotiation.|$|E
40|$|Abstract. Borror et al. {{discussed}} the EWMA(Exponentially Weighted Moving Average) chart {{to monitor the}} count of defects which follows the Poisson distribution, referred to the EWMAc chart, as an alternative Shewhart c chart. In the EWMAc chart, the Markov chain approach {{is used to calculate}} the ARL (Average Run Length). On the other hand, in order to monitor the process <b>fraction</b> <b>defectives</b> P in high-yield processes, Xie et al. presented the CCC(Cumulative Count of Conforming) -r chart of which quality characteristic is the cumulative count of conforming item inspected until observing r(≥ 2) nonconforming items. Furthermore, Ohta and Kusukawa presented the CS(Confirmation Sample) CCC-r chart as an alternative of the CCC-r chart. As a more superior chart in high-yield processes, in this paper we present an EWMACCC-r chart to detect more sensitively small or moderate shifts in P than the CSCCC-r chart. The proposed EWMACCC-r chart can be constructed by applying the designing method of the EWMAc chart to the CCC-r chart. ANOS(Average Number of Observations to Signal) of the proposed chart is compared with that of the CSCCC-r chart through computer simulation. It is demonstrated from numerical examples that the performance of proposed chart is more superior to the CSCCC-r chart...|$|R
40|$|Abstract. As charts {{to monitor}} the process <b>fraction</b> <b>defectives,</b> P, in the high-yield processes, Mishima et al. (2002) {{discussed}} a synthetic chart, the Synthetic CS chart, which integrates the CS (Confirmation Sample) CCC (Cumulative Count of Conforming) -r chart and the CCC-r chart. The Synthetic CS chart is designed to monitor quality characteristics in real-time. Recently, Kotani et al. (2005) presented the EWMA (Exponentially Weighted Moving-Average) CCC-r chart, which considers combining the quality characteristics monitored in the past with one monitored in real-time. In this paper, we present an alternative chart that is more superior to the EWMACCC-r chart. It is an integration of the EWMACCC-r chart and the CCC-r chart. In using the proposed chart, the quality characteristic is initially judged as either the in-control state or the out-of-control state, using the lower and upper control limits of the EWMACCC-r chart. If the process is not judged as the in-control state by the EWMACCC-r chart, the process is successively judged, using the CCC-r chart to confirm the judgement of the EWMACCC-r chart. We compare the ANOS (Average Number of Observations to Signal) of the proposed chart {{with those of the}} EWMACCC-r chart and the Synthetic CS chart. From the numerical experiments, with the small size of inspection items, the proposed chart is the most sensitive to detect especially the small shifts in P among othe...|$|R
40|$|Sensory {{evaluations}} {{to determine}} the shelf life of food products are routinely conducted in food experimentation. In such experiments, trainned panelists are asked to judge food attributes by reference to a scale of numbers (scores varying from 0 to 6 for example). The "failure time" associated to a product unit under test is usually defined as {{the time required to}} reach a cutt-o# point previously defined by the food company. Important issues associated with the planning and execution of this kind of testing are total sampling size, frequency of sample withdrawals, panel design, and statistical analysis of the panel data, to list a few. Di#erent approaches have been proposed for the analysis of this kind of data. In particular, Freitas, Borges and Ho (2001) proposed an alternative model based on a dichotomization of the score data and a Weibull as the underlying distribution for the time to failure. The model was applied to a real situation. The authors evaluated also through a simulation study, the bias and mean square error of the estimates obtained for percentiles and <b>fraction</b> <b>defectives.</b> The simulation study used only the same sample plan implemented in the real situation. In this paper we focus on the planning issues associated with these experiments. Sample plans are contrasted and compared in a simulation study, through the use of the approach proposed by Freitas, Borges and Ho (2001) ...|$|R
40|$|Two {{optimization}} algorithms for the {{rectifying inspection}} are presented. They minimize either ATI (Average Total Inspection) or AOQ (Average Outgoing Quality) and use another as a constraint. The definitions for ATI and AOQ are also generalized {{in order to}} handle the varying <b>fraction</b> <b>defective</b> of the incoming lots. A comprehensive study is conducted for comparing the performance characteristics of several different rectifying inspection plans. The {{results show that the}} optimum algorithms developed in this article can usually produce the best outputs and always satisfy the design constraint. Finally, a manufacturing example is used to show the applications of the optimum rectifying inspection plans...|$|E
40|$|AbstractIn many {{reliability}} analyses, {{the probability}} of obtaining a defective unit in a production process {{should not be considered}} constant even though the process is stable and in control. Engineering experience or previous data of similar or related products may often be used in the proper selection of a prior model to describe the random fluctuations in the <b>fraction</b> <b>defective.</b> A generalized beta family of priors, several maximum entropy priors and other prior models are considered for this purpose. In order to determine the acceptability of a product based on the lifelengths of some test units, failure-censored reliability sampling plans for location-scale distributions using average producer and consumer risks are designed. Our procedure allows the practitioners to incorporate a restricted parameter space into the reliability analysis, and it is reasonably insensitive to small disturbances in the prior information. Impartial priors are used to reflect prior neutrality between the producer and the consumer when a consensus on the elicited prior model is required. Nonetheless, our approach also enables the producer and the consumer to assume their own prior distributions. The use of substantial prior information can, in many cases, significantly reduce the amount of testing required. However, the main advantage of utilizing a prior model for the <b>fraction</b> <b>defective</b> is not necessarily reduced sample size but improved assessment of the true sampling risks. An example involving shifted exponential lifetimes is considered to illustrate the results...|$|E
40|$|ASN-Minimax double {{sampling}} plans by variables for a normally distributed quality characteristic with unknown standard deviation and two-sided specification limits are introduced. These plans {{base on the}} essentially Maximum-Likelihood (ML) estimator p* and the Minimum Variance Unbiased (MVU) estimator ^p of the <b>fraction</b> <b>defective</b> p. The operation characteristic (OC) of the ASN-Minimax {{double sampling}} plans is determined by using the independent random variables p*_ 1, p*_ 2 and ^p_ 1, ^p_ 2, which relate to {{the first and second}} samples, respectively. The maximum of the average sample number (ASN) of these plans is shown to be considerably smaller than the sample size of the corresponding single sampling plans...|$|E
40|$|Abstract — In recent years, gold bumping {{process has}} been applied {{extensively}} for the package technology of liquid crystal display driver integrated circuit, which is an essential component in portable devices. Because the increasing requirement of high-definition display devices, the gold bumping process has become more difficult and it is requested to be of high quality with very low <b>fraction</b> of <b>defectives.</b> Unfortunately, conventional methods for product acceptance determination no longer work because any sample of reasonable size probably contains no defective gold bump product items. In addition, in the globally competitive manufacturing environment, gold bumping processes involving multiple manufacturing lines are quite common in the Science...|$|R
40|$|Alkylation of T 7 {{bacteriophage}} considerably delayed phage {{development and}} reduced the phage's killing action on host cells. Only {{a small fraction of}} infected cells produced phage. For these phages, the latent period was markedly prolonged but the burst was equivalent to or only slightly lower than that of untreated phage. In the progeny of alkylated phage, there was an increase in the <b>fraction</b> of <b>defective</b> particles as well as a change in their morphology. These data show that infection with alkylated T 7 bacteriophage is to a large degree abortive; hence, biological consequences of this infection are very different from those characteristic of a normal virus infection...|$|R
50|$|Given {{that the}} item is defective, the {{probability}} that it {{was made by the}} thirdmachine is only 5/24. Although machine 3 produces half of the total output, itproduces a much smaller <b>fraction</b> of the <b>defective</b> items. Hence the knowledgethat the item selected was defective enables us to replace the prior probabilityP(A3) = 1/2 by the smaller posterior probability P(A3 | B) = 5/24.|$|R
40|$|Abstract: A {{quality control}} {{manufacturing}} process {{is designed to}} produce certain types of components (i. e. mechanical, electrical or chemical). The process is defined to be under control if the fraction of the items manufactured that are defective is reasonably small. The fraction of items defective varies from lot to lot, which is the main assumption that we will use in the mathematical development of our reliability model. It is logical to assume {{in this case that}} the mean of the lot is a random variable and so is the <b>fraction</b> <b>defective.</b> A relationship between the two quantities {{is the subject of this}} paper...|$|E
40|$|An {{expected}} {{cost model}} for the <b>fraction</b> <b>defective</b> control chart for the case where there are several out-of-control states is developed. A procedure is presented for determining the sample size, control limit or critical region, and interval between samples which minimizes the expected cost of control per unit of product. The expected cost of control consists {{of the cost of}} sampling, the cost of investigating and possibly correcting the process when an out-of-control condition is indicated, and the cost of producing defective product. Direct search techniques are used to optimize the expected cost function. Numerical examples and sensitivity analysis of the model are presented. ...|$|E
40|$|Subject of {{this paper}} is ASN-Minimax (AM) double {{sampling}} plans by variables for a normally distributed quality characteristic with unknown standard deviation and two-sided specification limits. Based on the estimator p* of the <b>fraction</b> <b>defective</b> p, which is essentially the Maximum-Likelihood (ML) estimator, AM-double sampling plans are calculated by using the random variables p*_ 1 and p*_p relating to the first and pooled samples, respectively. Given p_ 1, p_ 2, α, and β, no other AM-double sampling plans based on the same estimator feature a lower maximum of the average sample number (ASN) while fulfilling the classical two-point condition on the corresponding operation characteristic (OC) ...|$|E
40|$|Abstract A {{manufacturing}} defect is a finite chip area with electrically malfunctioning circuitry caused by fabrication errors. The <b>fraction</b> of <b>defective</b> chips that escapes {{to the customer}} is called the defect level, also known as defective parts per million (DPPM, or simply PPM) when normalized to one million units. This paper demonstrates a technique used to correlate coverage goals to DPPM based on test fallout data using a MATLAB ®-based error function minimization approach. This analysis is explained using regression models for DPPM yield versus fault/defect coverage. This approach is beneficial to semiconductor companies for calibrating their fault coverage goals to meet DPPM requirements from automotive or other customers that have very aggressive (i. e., ultra-low) DPPM demands...|$|R
40|$|We have {{analysed}} {{the possibility}} of scaling the sexual Penna ageing model. Assuming {{that the number of}} genes expressed before the reproduction age grows linearly with the genome size and that the mutation rate per genome and generation is constant, we have found that the <b>fraction</b> of <b>defective</b> genes expressed before the minimum reproduction age drops with the genome size, while the number of defective genes eliminated by the genetic death grows with genome size. Thus, the evolutionary costs decrease with enlarging the genome. After rescaling the time scale according to the mutational clock, age distributions of populations do not depend on the genome size. Nevertheless, enlarging the genome increases the reproduction potential of populations. Comment: 8 pages including all tables and figure...|$|R
40|$|The {{purpose of}} this paper was testing {{suitability}} of the time-series analysis for quality control of the continuous steel casting process in production conditions. The analysis was carried out on industrial data collected in one of Polish steel plants. The production data concerned <b>defective</b> <b>fractions</b> of billets obtained in the process. The procedure of the industrial data preparation is presented. The computations for the time-series analysis were carried out in two ways, both using the authors’ own software. The first one, applied to the real numbers type of the data has a wide range of capabilities, including not only prediction of the future values but also detection of important periodicity in data. In the second approach the data were assumed in a binary (categorical) form, i. e. the every heat(melt) was labeled as ‘Good’ or ‘Defective’. The naïve Bayesian classifier was used for predicting the successive values. The most interesting results of the analysis include good prediction accuracies obtained by both methodologies, the crucial influence of the last preceding point on the predicted result for the real data time-series analysis as well as obtaining an information about the type of misclassification for binary data. The possibility of prediction of the future values can be used by engineering or operational staff with an expert knowledge to decrease <b>fraction</b> of <b>defective</b> products by taking appropriate action when the forthcoming period is identified as critical...|$|R
