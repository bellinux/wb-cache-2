1403|665|Public
25|$|The {{second and}} third {{quadrants}} are the upper right and lower left 4 parameters, respectively. These are {{also referred to as}} the cross-mode quadrants. This is because they fully characterize any mode conversion occurring in the device under test, whether it is common-to-differential SDCab conversion (EMI susceptibility for an intended differential signal SDD transmission application) or differential-to-common SCDab conversion (EMI radiation for a differential application). Understanding mode conversion is very helpful when trying to optimize the design of interconnects for gigabit <b>data</b> <b>throughput.</b>|$|E
25|$|OSPF detects {{changes in}} the topology, such as link failures, and converges on a new loop-free routing {{structure}} within seconds. It computes the shortest-path tree for each route using a method based on Dijkstra's algorithm. The OSPF routing policies for constructing a route table are governed by link metrics associated with each routing interface. Cost factors may be the distance of a router (round-trip time), <b>data</b> <b>throughput</b> of a link, or link availability and reliability, expressed as simple unitless numbers. This provides a dynamic process of traffic load balancing between routes of equal cost.|$|E
25|$|The {{purpose of}} radio {{resource}} management is {{to satisfy the}} data rates that are requested by the users of a cellular network. The main resources are time intervals, frequency blocks, and transmit powers. Each user has its own objective function that, for example, can represent some combination of the data rate, latency, and energy efficiency. These objectives are conflicting since the frequency resources are very scarce, thus {{there is a need}} for tight spatial frequency reuse which causes immense inter-user interference if not properly controlled. Multi-user MIMO techniques are nowadays used to reduce the interference by adaptive precoding. The network operator would like to both bring great coverage and high data rates, thus the operator would like to find a Pareto optimal solution that balance the total network <b>data</b> <b>throughput</b> and the user fairness in an appropriate subjective manner.|$|E
30|$|End-to-end <b>data</b> {{transmission}} <b>throughput.</b>|$|R
30|$|The maximum benchmarked {{bandwidth}} for the PCI Express 1.0 [*]bus on the motherboard {{used was}} 3.15 [*]GBps. Given this, {{even with a}} 2 -GPU solution, full 32 -bit accuracy at gigabit <b>data</b> <b>throughputs</b> with the current hardware was not achievable.|$|R
50|$|DCH (Dedicated Channel) - The {{state that}} allows for maximum <b>data</b> {{connectivity}} <b>throughput</b> <b>data</b> transfer speeds, hence allowing for full power consumption as if Fast Dormancy was completely turned off.|$|R
25|$|Fortunately, Galileo possessed an {{additional}} low-gain antenna that {{was capable of}} transmitting information back to Earth, although since it transmitted a signal isotropically, the low-gain antenna's bandwidth was significantly less than what the high-gain antenna's would have been; the high-gain antenna was to have transmitted at 134kilobits per second, whereas the low-gain antenna was only intended to transmit at about 8 to 16bits per second. Galileo low-gain antenna transmitted with a power of about 15 to 20watts, which, {{by the time it}} reached Earth and had been collected by one of the large aperture (70 m) NASA Deep Space Network antennas, had a total power of about −170dBm or 10zeptowatts (watts). Through the implementation of sophisticated technologies, the arraying of several Deep Space Network antennas and sensitivity upgrades to the receivers used to listen to Galileo signal, <b>data</b> <b>throughput</b> was increased to a maximum of 160bits per second. By further using data compression, the effective data rate could be raised to 1,000bits per second. The data collected on Jupiter and its moons was stored in the spacecraft's onboard tape recorder, and transmitted back to Earth during the long apoapsis portion of the probe's orbit using the low-gain antenna. At the same time, measurements were made of Jupiter's magnetosphere and transmitted back to Earth. The reduction in available bandwidth reduced the total amount of data transmitted throughout the mission, although 70% of Galileo science goals could still be met.|$|E
25|$|Originally, {{data was}} simply passed one-way from a central {{processing}} unit (CPU) to a graphics processing unit (GPU), then to a display device. However, as time progressed, it became valuable for GPUs to store at first simple, then complex structures of data to be passed back to the CPU that analyzed an image, or a set of scientific-data represented as a 2D or 3D format that a video card can understand. Because the GPU has access to every draw operation, it can analyze data in these forms quickly, whereas a CPU must poll every pixel or data element much more slowly, as the speed of access between a CPU and its larger pool of random-access memory (or in an even worse case, a hard drive) is slower than GPUs and video cards, which typically contain smaller amounts of more expensive memory that is much faster to access. Transferring {{the portion of the}} data set to be actively analyzed to that GPU memory in the form of textures or other easily readable GPU forms results in speed increase. The distinguishing feature of a GPGPU design is the ability to transfer information bidirectionally back from the GPU to the CPU; generally the <b>data</b> <b>throughput</b> in both directions is ideally high, resulting in a multiplier effect on the speed of a specific high-use algorithm. GPGPU pipelines may improve efficiency on especially large data sets and/or data containing 2D or 3D imagery. It is used in complex graphics pipelines as well as scientific computing; more so in fields with large data sets like genome mapping, or where two- or three-dimensional analysis is useful especially at present biomolecule analysis, protein study, and other complex organic chemistry. Such pipelines can also vastly improve efficiency in image processing and computer vision, among other fields; as well as parallel processing generally. Some very heavily optimized pipelines have yielded speed increases of several hundred times the original CPU-based pipeline on one high-use task.|$|E
2500|$|MIMO {{technology}} has been standardized for wireless LANs, 3G mobile phone networks, and 4G mobile phone networks {{and is now in}} widespread commercial use. Greg Raleigh and V. K. Jones founded Airgo Networks in 2001 to develop MIMO-OFDM chipsets for wireless LANs. The Institute of Electrical and Electronics Engineers (IEEE) created a task group in late 2003 to develop a wireless LAN standard delivering at least 100 Mbit/s of user <b>data</b> <b>throughput.</b> There were two major competing proposals: TGn Sync was backed by companies including Intel and Philips, and WWiSE was supported by companies including Airgo Networks, Broadcom, and Texas Instruments. Both groups agreed that the 802.11n standard would be based on MIMO-OFDM with 20MHz and 40MHz channel options. [...] TGn Sync, WWiSE, and a third proposal (MITMOT, backed by Motorola and Mitsubishi) were merged to create what was called the Joint Proposal. In 2004, Airgo became the first company to ship MIMO-OFDM products. Qualcomm acquired Airgo Networks in late 2006. The final 802.11n standard supported speeds up to 600 Mbit/s (using four simultaneous data streams) and was published in late 2009.|$|E
50|$|Dedicated {{point-to-point}} links are not {{the only}} option for many connections between systems. Frame Relay, ATM, and MPLS based services can also be used. When calculating or estimating <b>data</b> <b>throughputs,</b> the details of the frame/cell/packet format and the technology's detailed implementation need to be understood.|$|R
50|$|In the United States, {{the band}} 36.0 - 40.0 GHz {{is used for}} {{licensed}} high-speed microwave data links, and the 60 GHz band {{can be used for}} unlicensed short range (1.7 km) data links with <b>data</b> <b>throughputs</b> up to 2.5 Gbit/s. It is used commonly in flat terrain.|$|R
50|$|Furthermore, {{there must}} be a {{guardband}} in the data channel between packets or bursts, so that core optical router data planes have adequate time to switch packets or bursts. If the guardband is large relative to the average packet or burst size, then it can limit <b>data</b> channel <b>throughput.</b> Aggregating packets into bursts can reduce guardband impact on <b>data</b> channel <b>throughput.</b>|$|R
50|$|Bandwidth - The rate of <b>data</b> <b>throughput</b> {{available}} on the system.|$|E
50|$|MEDR is {{actually}} a theoretical measure {{of the amount of}} <b>data</b> <b>throughput</b> a line can handle, but does not necessarily refer to the amount of data available to the customer at the end of said copper wiring. The <b>data</b> <b>throughput</b> that can actually be presented to the end user is measured by AIDR or As Is Data Rate.|$|E
5000|$|... 2×, with {{a maximum}} <b>data</b> <b>throughput</b> of 300 kB/s (double speed), 150KB/s (normal) ...|$|E
30|$|We {{have also}} {{investigated}} {{the association of}} the 3 D TC with high-order modulations. This structure is used for applications where high <b>data</b> <b>throughputs</b> are required such as the transmission of high-definition television (HD TV). In the most recent transmission systems, high bit rates require using high-order modulations, such as 16 -QAM for 3 GPP 2, 64 -QAM for LTE and 256 -QAM for DVB-NGH.|$|R
40|$|The {{incorporation}} of progressively more autonomous capabilities in spacecraft {{has been made}} possible by advancements in electronics technologies for sensors, communication, and computing equipment; as a result, space missions {{have been able to}} cope with ever-increasing complexity and <b>data</b> <b>throughputs,</b> as demonstrated by the six-order-of-magnitude increase in planetary mission data rates. In order to continue this pace of development into the Space Station era, NASA has accelerated its R&D in automation and robotics, with emphasis on autonomous, knowledge-based and expert system-employing technologies and AI...|$|R
40|$|Hash {{functions}} play {{an important}} role in modern cryptography. This paper investigates optimisation techniques that have recently been proposed in the literature. A new VLSI architecture for the SHA- 256 and SHA- 512 hash functions is presented, which combines two popular hardware optimisation techniques, namely pipelining and unrolling. The SHA processors are developed for implementation on FPGAs, thereby allowing rapid prototyping of several designs. Speed/area results from these processors are analysed and are shown to compare favourably with other FPGA-based implementations, achieving the fastest <b>data</b> <b>throughputs</b> in the literature to date. 1...|$|R
50|$|In February 2013, VCE {{announced}} Vblock 300 and Vblock 700 {{models with}} increased performance and <b>data</b> <b>throughput,</b> using upgraded server and storage components.|$|E
50|$|Whilst the Cell blades {{account for}} the {{required}} computing power, it's the high <b>data</b> <b>throughput</b> of the mainframe which is of particular interest.|$|E
50|$|Maximum {{engineering}} data rate (MEDR) {{is a term}} primarily used by telephone companies {{to refer to the}} maximum <b>data</b> <b>throughput</b> supportable over targeted copper wire.|$|E
50|$|Series-parallel partial orders {{have been}} applied in job shop scheduling, machine {{learning}} of event sequencing in time series data, transmission sequencing of multimedia <b>data,</b> and <b>throughput</b> maximization in dataflow programming.|$|R
5000|$|Fully {{automated}} continuous scaling with {{no limit}} on <b>data</b> size or <b>throughput.</b>|$|R
40|$|Over {{the next}} several years, NASA plans to launch {{multiple}} earth-science missions which will send data from low-Earth orbits to ground stations at 1 - 3 Gbps, to achieve <b>data</b> <b>throughputs</b> of 5 - 40 terabits per day. These transmission rates exceed the capabilities of S-band and X-band frequency allocations used for science probe downlinks in the past. Accordingly, NASA is exploring enhancements to its space communication capabilities to provide the Agency's first Ka-band architecture solution for next generation missions in the near-earth regime. This paper describes the proposed Ka-band solution's drivers and concept, constraints and analyses which shaped that concept, and expansibility for future need...|$|R
50|$|When {{discussing}} throughput, {{there is}} often a distinction between the peak data rate of the physical layer, the theoretical maximum <b>data</b> <b>throughput</b> and typical throughput.|$|E
50|$|Link 22 {{has better}} {{tactical}} <b>data</b> <b>throughput</b> than Link 11, {{and it can}} even work in conditions where Link 11 will not. When conditions are bad, Link 22 can use more robust media parameters and maintain communication, although at a lower data rate than usual. When conditions are good, Link 22 can optimize the media parameters to maximize its <b>data</b> <b>throughput.</b> For example, specific media parameters were designed to operate in high latitudes, which present some of the worst-case conditions, and where Link 11 rarely operates.|$|E
50|$|The higher {{resolution}} applications required FPD-Link II {{to increase the}} <b>data</b> <b>throughput.</b> It started at about 1 Gbit/s <b>data</b> <b>throughput</b> on a single twisted pair which is well within the capability for LVDS technology. But for the applications that required up to 1.8 Gbit/s over a single pair, LVDS was not as reliable as necessary for the automotive applications. By changing from LVDS to current mode logic (CML), the newest FPD-Link II chipsets were able to reliably send high bit-rate video streams over cables longer than 10m.|$|E
40|$|At {{different}} time periods in the future, missions to Mars will overlap. Previous {{studies indicate that}} during such periods, existing deep space communication infrastructure cannot handle all Mars communication needs. A plausible solution is {{to take into account}} the end-to-end communication performances of network along with operational constraints, and optimize the resource usage by scheduling communication at highest possible <b>data</b> <b>throughputs.</b> As a result, shorter communication time is required and more missions can be accommodated. This principle is demonstrated in this paper for a Mars relay communication network; a network consisting of multiple surface units and orbiters on Mars and the Deep Space Stations...|$|R
40|$|The Sandia National Laboratories (SNL) Data Encryption Standard (DES) Application Specific Integrated Circuit (ASIC) is {{the fastest}} known {{implementation}} of the DES algorithm as defined in the Federal Information Processing Standards (FIPS) Publication 46 - 2. DES is used for protecting data by cryptographic means. The SNL DES ASIC, over 10 times faster than other currently available DES chips, is a high-speed, filly pipelined implementation offering encryption, decryption, unique key input, or algorithm bypassing on each clock cycle. Operating beyond 105 MHz on 64 bit words, this device is capable of <b>data</b> <b>throughputs</b> greater than 6. 7 Billion bits per second (tester limited). Simulations predict proper operation up to 9. 28 Billion bits per second. In low frequency, low data rate applications, the ASIC consumes less that one milliwatt of power. The device has features for passing control signals synchronized to <b>throughput</b> <b>data.</b> Three SNL DES ASICS may be easily cascaded to provide the much greater security of triple-key, triple-DES...|$|R
30|$|Media {{independent}} {{information service}} (MIIS) provides {{information such as}} topology, location and link layer parameters (<b>data</b> rate, <b>throughput,</b> etc.) about different networks in the vicinity. This information, if provided beforehand, will aid the mobility management protocol on the handover' decision.|$|R
50|$|External {{interfaces}} include USB, CAN, Ethernet, SPI, USART and ADC. A DMA controller provides {{direct communication}} channels between external interfaces and memories, increasing <b>data</b> <b>throughput</b> with minimal processor intervention.|$|E
50|$|ATM: In an Asynchronous Transfer Mode (ATM) network, {{performance}} {{can be measured}} by line rate, quality of service (QoS), <b>data</b> <b>throughput,</b> connect time, stability, technology, modulation technique and modem enhancements.|$|E
50|$|Kenya has 50 remote FabFi nodes {{deployed}} {{across three}} sites. The longest link {{among them is}} 3.5 km. The <b>data</b> <b>throughput</b> across roughly 2.5 km, with up to 6 hops, exceeds 30Mbit/s.|$|E
40|$|International Telemetering Conference Proceedings / October 20 - 23, 2003 / Riviera Hotel and Convention Center, Las Vegas, NevadaA Flight Safety System (RAFS) for multiple, {{reliable}} Unmanned Air Vehicles (UAV’s) {{capable of}} flying Over-the-Horizon (OTH) and outside test range airspace. In {{addition to the}} flight safety application, the described full-duplex data link is suitable as a backup command and control link for UAV’s, and for sensor control & data exfiltration. The IRIDIUM satellite system was selected to provide the communications link and because of its global coverage and requisite <b>data</b> <b>throughputs.</b> A Risk Reduction activity ensued to quantify IRIDIUM performance. Hardware and software was developed to demonstrate the feasibility of using IRIDIUM in a flight safety scenario...|$|R
40|$|The {{downlink}} {{transmission power}} of a 4 G-LTE base station is quantified by means of statistical counters. They are build up analyzing the physical resource blocks allocated during transmission at different <b>data</b> <b>throughputs.</b> The analysis is performed during complete over the air tests carried out inside a reverberation chamber. The reverberation chamber allows to vary dynamic fading conditions by changing the stirrer rotating speed and the quality factor. Results are compared to direct antenna input power measurements obtained by a spectrum analyzer, {{in order to identify}} the better way to combine statistical counters. The analysis confirms the possibility to use this counters to monitor continuously the transmitted power over long time period...|$|R
40|$|We {{describe}} {{the application of}} decision tree based classification techniques {{to the development of}} an automated tool for the reduction of a large scientific data set. The primary benefits of the SKICAT approach are increased <b>data</b> reduction <b>throughput,</b> repeatability, and consistency of classification...|$|R
