20|5|Public
5000|$|Mayers and Yao {{proposed}} {{the idea of}} designing quantum protocols using [...] "self-testing" [...] quantum apparatus, the internal operations {{of which can be}} uniquely determined by their <b>input-output</b> <b>statistics.</b> Subsequently, Roger Colbeck in his Thesis {{proposed the}} use of Bell tests for checking the honesty of the devices. Since then, several problems have been shown to admit unconditional secure and device-independent protocols, even when the actual devices performing the Bell test are substantially [...] "noisy," [...] i.e., far from being ideal. These problems includequantum key distribution, [...] randomness expansion, and randomness amplification.|$|E
5000|$|A quantum {{cryptographic}} protocol is device-independent if {{its security}} does {{not rely on}} trusting that the quantum devices used are truthful.Thus the security analysis of such a protocol needs to consider scenarios of imperfect or even malicious devices. Mayers and Yao proposed the idea of designing quantum protocols using [...] "self-testing" [...] quantum apparatus, the internal operations {{of which can be}} uniquely determined by their <b>input-output</b> <b>statistics.</b> Subsequently, Roger Colbeck in his Thesis proposed the use of Bell tests for checking the honesty of the devices. Since then, several problems have been shown to admit unconditional secure and device-independent protocols, even when the actual devices performing the Bell test are substantially [...] "noisy," [...] i.e., far from being ideal. These problems includequantum key distribution, [...] randomness expansion, and randomness amplification.|$|E
40|$|We {{discuss a}} {{connection}} (and a proper {{place in this}} framework) of the unforced and deterministically forced Burgers equation for local velocity fields of certain flows, with probabilistic solutions of the so-called Schrödinger interpolation problem. The latter allows to reconstruct the microscopic dynamics of the system from the available probability density data, or the <b>input-output</b> <b>statistics</b> in the phenomenological situations. An issue of deducing the most likely dynamics (and matter transport) scenario from the given initial and terminal probability density data, appropriate e. g. for studying chaos in terms of densities, is here exemplified in conjunction with Born’s statistical interpretation postulate in quantum theory, that yields stochastic processes which are compatible with the Schrödinger picture free quantum evolution. 1 The Schrödinger reconstruction problem: most likely microscopic dynamics from the <b>input-output</b> <b>statistics</b> data Probability measures, both invariant and nontrivially time-dependent, often on different levels of abstraction, are ubiquituous in diverse areas of physics. Accordin...|$|E
50|$|The Bank compiles {{statistics}} {{which are}} essential to developing appropriate economic policies across all sectors including government. These include money and banking statistics, national income statistics, the producer price index, balance of payments statistics, flow of funds <b>statistics,</b> <b>input-output</b> tables, etc.|$|R
40|$|This article {{presents}} {{analysis on the}} possible impact of international trade on industrial productivity in the UK using the new EUKLEMS analytical database, in conjunction with Office for National <b>Statistics</b> <b>Input-Output</b> Supply Use tables. The aim is to also illustrate the breadth of opportunities the database offers potential users {{for a wide variety}} of economic research. Economic & Labour Market Review (2008) 2, 23 – 31; doi: 10. 1057 /elmr. 2008. 168...|$|R
40|$|AbstractInput-output {{coefficients}} of various regions differ greatly; however, so far, time-series analysis {{has been widely}} applied to direct input coefficients, which lacks systematic cross-section research, let alone study on influential factors of their regional disparity. Based on national and 30 regional input-output tables of China (2002 - 2007), this paper concentrates on important <b>input-output</b> coefficients. Descriptive <b>statistics</b> analysis is firstly done from three aspects: great change in coefficients at the regional level from 2002 to 2007, comparison between coefficients {{at the national level}} and weighted coefficients at the regional level, and classification of scatter diagrams of coefficients. Then take coefficients with normal scatterplot distribution whose column sectors belong to industry as examples, by selecting a series of relative indices from scale, technical characteristics, ownership composition and sub-sector structure, regression models are established to find out main influential factors of input-output coefficients, on the basis of which further economic explanation can be made...|$|R
40|$|Abstract. We {{present an}} {{asymptotic}} analysis of two coupled linear-nonlinear systems. Through measuring {{first and second}} <b>input-output</b> <b>statistics</b> of the systems in response to white noise input, one can completely characterize the systems and their coupling. The proposed model {{is similar to a}} widely used phenomenological model of neurons in response to sensory stimulation and may be used to help characterize neural circuitry in sensory brain regions...|$|E
40|$|The aim of {{this paper}} is to combine {{well-known}} theoretical approaches from the theory of production and to apply them to a data base drawn up within the framework of modern <b>input-output</b> <b>statistics.</b> The changes in I/O coefficients observed for the Canadian basic metal industry are attributed to changes in microtechnologies brought about by shifts in the relative prices and the output structure of this industry...|$|E
40|$|Abstract: Probablistic {{solutions}} of the {{so called}} Schrödinger boundary data problem provide for a unique Markovian interpolation between any two strictly positive probability densities designed to form the <b>input-output</b> <b>statistics</b> data for a certain dynamical process taking place in a finite-time interval. The key problem is to select the jointly continuous in all variables positive semigroup kernel, appropriate for the phenomenological (physical) situation. The issue of deriving a microscopic dynamics from the <b>input-output</b> <b>statistics</b> data (analyzed in terms of densities) was addressed, as the Schrödinger problem of a probabilistic interpolation, {{in a number of}} publications [1] – [6]. We shall consider Markovian propagation scenarios so remaining within the well established framework, where for any two Borel sets A, B ⊂ R on which the strictly positive boundary densities ρ(x, 0) and ρ(x, T) are defined, the transition probability m(A, B) from the set A to the set B in the time interval T> 0 has a bi-variate density given in a specific factorized form: m(x, y) = f(x) k(x, 0, y, T) g(y), with marginals:...|$|E
40|$|We assess {{environmental}} performance across product types and across household types {{in order to}} evaluate environmental pressure from human activities. To so do, we combine family budget <b>statistics,</b> <b>input-output</b> tables, energy and material flow matrices, various types of emissions and environmental effects indices for various effect types (e. g. a global warming potential index, an ozone depletion potential index, etc). Subsequently, using DEA (Data Envelopment Analysis), we use these weighted environmental effects indices to form one environ-mental performance score for each family type and product type. We find that the {{environmental performance}} of each family type changes considerably across environmental effect types. The analysis of the overall environmental performance scores shows that families living in urban flats, especially the young and elderly families, have the most environmentally friendly consum-ption pattern. Middle income families living in houses have the least environmentally friendly consumer basket, and these families constitute a high share of all families in Denmark. Environmental performance, product ranking, sustainable household consumption, DEA analysis, integrated modelling,...|$|R
40|$|The Australian Industrial Ecology Virtual Laboratory (IELab) is an exciting, {{collaborative}} project {{to develop the}} most comprehensive, environmentally extended input-output database available for use in Australia. It distinguishes geographical and industry detail at high resolution, spans a time period of more than twenty years, and is constantly updated as new data become available. Modellers can customise their own <b>input-output</b> tables and <b>statistics,</b> thereby enhancing their analytical capabilities in input-output based and hybrid life cycle assessment (LCA) and related fields such as regional and environmental economic modelling, carbon footprinting, triple bottom line reporting, and environmental impact assessment. The IELab combines economic and environmental data at an unprecedented level of detail and significantly boosts Australia's ability to make strategic decisions for progress towards sustainability. The IELab has many potential applications in LCA, particularly with regards to combining detailed, process-specific data with over-arching input-output data in a hybrid LCA model. This enables the evaluation of multiple environmental impacts {{at a high level}} of detail and completeness, improving the quality and reliability of information provided for applications such as product design, corporate reporting, supply-chain analysis, policy formation, eco-labelling, and infrastructure selection. The structure of the IELab also supports separate modelling of life cycle inventory and impact assessment models as recommended by the ISO standards on LCA methodology. The IELab is already populated with several environmentally relevant datasets, including energy use and greenhouse gas emissions, and the integration of other datasets is ongoing. In this session we demonstrate the power of the IELab to enhance Australian LCA practice, using case studies in various subject areas...|$|R
40|$|Probablistic {{solutions}} of the {{so called}} Schrödinger boundary data problem provide for a unique Markovian interpolation between any two strictly positive probability densities designed to form the <b>input-output</b> <b>statistics</b> data for a certain dynamical process taking place in a finite-time interval. The key problem is to select the jointly continuous in all variables positive semigroup kernel, appropriate for the phenomenological (physical) situation. Comment: Tex file, J. Tch. Phys. 38, 205 - 209, (1997...|$|E
40|$|The {{existing}} {{formulations of}} the Schrödinger interpolating dynamics, which is {{constrained by the}} prescribed <b>input-output</b> <b>statistics</b> data, utilize strictly positive Feynman-Kac kernels. This implies that the related Markov diffusion processes admit vanishing probability densities only at {{the boundaries of the}} spatial volume confining the process. We extend the framework to encompass singular potentials and associated nonnegative Feynman-Kac-type kernels. It allows to deal with general nonnegative solutions of the Schrödinger boundary data problem. The resulting stochastic processes are capable of both developing and destroying nodes (zeros) of probability densities {{in the course of their}} evolution. Comment: Latex file, 25 p...|$|E
40|$|Let X^n∈X^n be a {{sequence}} {{drawn from a}} discrete memoryless source, and let Y^n∈Y^n be the corresponding reconstruction sequence that is output by a good rate-distortion code. This paper establishes a property of the joint distribution of (X^n,Y^n). It is shown that for D> 0, the <b>input-output</b> <b>statistics</b> of a R(D) -achieving rate-distortion code converge (in normalized relative entropy) to the output-input statistics of a discrete memoryless channel (dmc). The dmc is "backward" {{in that it is}} a channel from the reconstruction space Y^n to source space X^n. It is also shown that the property does not necessarily hold when normalized relative entropy is replaced by variational distance. Comment: ITW 2013, 5 page...|$|E
40|$|Quantum process tomography, the {{standard}} procedure to characterize any quantum channel in nature, {{is affected by}} a circular argument: in order to characterize the channel, the tomographic preparation and measurement need in turn to be already characterized. We break this loop by designing an operational framework able to optimally characterize any given unknown quantum channel in a device-independent fashion, namely, by only looking at its <b>input-output</b> <b>statistics,</b> under the sole assumption that quantum theory is valid. We provide explicit solutions, in closed form, for practically relevant cases such as the erasure, depolarizing, and amplitude-damping channels. Comment: 8 pages, 4 figures, withdrawn by the authors as it is extended by arXiv: 1606. 0279...|$|E
40|$|Self-testing {{refers to}} the {{possibility}} of characterizing uniquely (up to local isometries) the state and measurements contained in quantum devices, based only on the observed <b>input-output</b> <b>statistics.</b> Already in the basic case of the two-qubit singlet, self-testing is not unique: the two known criteria (the maximal violation of the CHSH inequality and the Mayers-Yao correlations) are not equivalent. It is unknown how many criteria there are. In this paper, we find the whole set of criteria for the ideal self-testing of singlet with two measurements and two outcomes on each side: it coincides with all the extremal points of the quantum set that can be obtained by measuring the singlet. Comment: 14 pages, 5 figures, 24 reference...|$|E
40|$|Probablistic {{solutions}} of the {{so called}} Schrödinger boundary data problem provide for a unique Markovian interpolation between any two strictly positive probability densities designed to form the <b>input-output</b> <b>statistics</b> data for the process taking place in a finite-time interval. The key issue is to select the jointly continuous in all variables Feynman-Kac kernel, appropriate for the phenomenological (physical) situation. We extend the existing formulations of the problem to cases when the kernel is not a fundamental solution of a parabolic equation, and prove {{the existence of a}} continuous Markov interpolation in this case. Finally, we analyze the compatibility of this stochastic evolution with the original parabolic dynamics. In particular, in conjunction with Born's statistical interpretation postulate in quantum theory, we consider stochastic processes which are compatible with the Schrödinger picture quantum evolution, and give {{a detailed description of the}} procedure generating solutions of the Schrödinger problem in this context, independently of a particular functional form of boundary densities and of the external potential...|$|E
40|$|The Schrödinger {{problem of}} deducing the {{microscopic}} dynamics from the <b>input-output</b> <b>statistics</b> data {{is known to}} admit a solution in terms of Markov diffusions. The uniqueness of solution is found linked to the natural boundaries respected by the underlying random motion. By choosing a reference Smoluchowski diffusion process, we automatically fix the Feynman-Kac potential and the field of local accelerations it induces. We generate the family of affiliated diffusions with the same local dynamics, but different inaccessible boundaries on finite, semi-infinite and infinite domains. For each diffusion process a unique Feynman-Kac kernel is obtained by the constrained (Dirichlet boundary data) Wiener path integration. As a by-product of the discussion, we give {{an overview of the}} problem of inaccessible boundaries for the diffusion and bring together (sometimes viewed from unexpected angles) results which are little known, and dispersed in publications from scarcely communicating areas of mathematics and physics. Comment: Latex file, Phys. Rev. E 49, 3815 - 3824, (1994...|$|E
40|$|Probabilistic {{solutions}} of the {{so called}} Schrödinger boundary data problem provide for a unique Markovian interpolation between any two strictly positive probability densities designed to form the <b>input-output</b> <b>statistics</b> data for the process taking place in a finite-time interval. The key issue is to select the jointly continuous in all variables positive Feynman-Kac kernel, appropriate for the phenomenological (physical) situation. We extend the existing formulations of the problem to cases when the kernel is not a fundamental solution of a parabolic equation, and prove {{the existence of a}} continuous Markov interpolation in this case. Next, we analyze the compatibility of this stochastic evolution with the original parabolic dynamics, while assumed to be governed by the temporally adjoint pair of (parabolic) partial differential equations, and prove that the pertinent random motion is a diffusion process. In particular, in conjunction with Born's statistical interpretation postulate in quantum theory, we consider stochastic processes which are compatible with the Schrödinger picture quantum evolution. Comment: Latex file, J. Math. Phys., accepted for publicatio...|$|E
40|$|It {{is widely}} {{recognized}} that increasing {{the information technology}} intensiveness or the rapid informatization of the ailing Australian macroeconomy will revitalize it and enhance its international competitiveness. But the published national income and input-output data for Australia fail to reveal even the broad contours of the important information economy. This study attempts to overcome this lacuna by recasting <b>input-output</b> <b>statistics</b> using a computational algorithm so as to identify the information and noninformation sectors that constitute the Australian economy. Leon-tief 2 ̆ 7 s double inversion technique {{has been used to}} highlight the nascent and dynamic information sectors that have been obscured by the overwhelming nature of the noninformation economy in Australia. Impact analysis or multipliers and linkages have been deployed to identify the information sectors that were most attractive from the perspective of competing macroeconomic criteria. A composite scoring method was used to determine the optimal information sectors for further development. This study also delineates the core information technologies and enabling projects that should be undertaken within the optimal sectors for the realization of the rapid informatization of the Australian economy...|$|E
40|$|This paper {{performs}} a preliminary {{analysis of the}} importance of formal education in production using <b>input-output</b> <b>statistics</b> combined with statistics on the formal educational qualifications of the employed workforce. The main aim of the paper is to contribute to the ongoing debate of the “knowledge based economy ” and the increased importance of human capital. The analysis is limited to the manufacturing sectors [...] The sectoral analysis is performed on an aggregation of the manufacturing sectors according to their production and innovation characteristics in relation to Pavitt’s Taxonomy. Remarkable sectoral differences are found when assessing the importance of formal education on productivity 2 The term “learning economy ” is preferred by some in order to stress the dynamic character of the system 1 in question, see e. g. Foray and Lundvall (1996). The DISKO project (a comparative analysis of the Danish innovation system). 2 An alternative way of analysing human capital in an input-output framework is presented in Aulin- 3 Ahmavaara and Aulin (1992). Here the ordinary input-output production sectors are supplemented with sectors of human capital, defined as education obtainable by studying in schools or courses, as well as 1...|$|E
40|$|Those {{familiar}} with input-output analysis know well that compilation of input-output tables {{is a difficult}} statistical work. The very first input-output tables (e. g. such as those for the United States economy in 1919 and 1929 or for the Federal Republic of Germany in the fifties) were the results of applied economic research. But soon after, official statistical bodies, who understood that input-output tables consistent with national accounts can very much {{improve the quality of}} economic statistics, started systematic work in this field. It was also obvious that international exchange of experience can be useful. The two main internatio­ nal fora in which discussion of input-output compilation took place were the international input-out­ put conferences and United Nations bodies. Already at the First International Conference on Input-Output Techniques (Driebergen 1950) several authors analysed the relations between input-output tables and national accounts. The topic was also on the programme of the Second Conference (Varenna 1954). At the Third Conference (Geneva 1961) standardization of <b>input-output</b> <b>statistics</b> was a topic of a panel discussion of eight experts. The relevant papers, which are still of interest, can be found in published conference proceedings...|$|E
40|$|The {{shift towards}} a service-based {{industry}} has been recognised in the mid-term review of the European Commission’s industrial policy (European Commission, 2007). The term services-based industry as such has become a key word. The objective {{of this paper is}} to explore whether manufacturing industries in the new EU member states (NMS) Czech Republic, Hungary. Slovakia, Slovenia and Poland are service-based industries or have emerged as such over the last twenty years. Austria will serve as a reference country and development trends in the NMS will be compared to it. METHODOLOGY: The service-based industry is characterized by increasing use of services inputs and increasing production of services output, mainly related to industrial goods (Ecorys, 2008). By using <b>input-output</b> <b>statistics,</b> consisting of supply and use tables and symmetric input-output tables, these characteristics can be traced in an appropriate way. Input-output data from EUROSTAT for the years 1995, 2000 and 2005 for the NMS will be analysed and compared to those of Austria. The following measures will be computed: the share of service production in the output of manufacturing based on supply tables; the use of market services in the input structure of manufacturing based on use tables and a simple linkage index (Rasmussen index, backward linkages for manufacturing and forward linkages for market services) based on symmetric input-output tables...|$|E
40|$|Probabilistic {{solutions}} of the {{so called}} Schrödinger boundary data problem provide for a unique Markovian interpolation between any two strictly positive probability densities designed to form the <b>input-output</b> <b>statistics</b> data for the process taking place in a finite-time interval. The key issue is to select the jointly continuous in all variables positive Feynman-Kac kernel, appropriate for the phenomenological (physical) situation. We extend the existing formulations of the problem to cases when the kernel is not a fundamental solution of a parabolic equation, and prove {{the existence of a}} continuous Markov interpolation in this case. Next, we analyze the compatibility of this stochastic evolution with the original parabolic dynamics, while assumed to be governed by the temporally adjoint pair of (parabolic) partial differential equations, and prove that the pertinent random motion is a diffusion process. In particular, in conjunction with Born’s statistical interpretation postulate in quantum theory, we consider stochastic processes which are compatible with the Schrödinger picture quantum evolution. I. Motivation: Schrödinger’s interpolation problem through Feynman-Kac kernels The issue of deriving a microscopic dynamics from the (phenomenologically or numerically motivated, by approximating the frequency distributions) input-output 1 statistics data was addressed, as the Schrödinger problem of a probabilistic interpolation, in a number of publications [1]-[10]. We shall consider Markovian propagation scenarios so remaining within the well established framework, where for any two Borel sets A, B ⊂ R on which the respective strictly positive boundary densities ρ(x, 0) and ρ(x, T) are defined, the transition probability m(A, B) from the set A to the set B in the time interval T> 0 has a density given in a specific factorized form: m(x, y) = f(x) k(x, 0, y, T) g(y) m(A, B) = dx dy m(x, y...|$|E
40|$|Thanks {{to their}} {{excellent}} performance, business services have {{attracted the attention}} of economists in recent years. According to national accounts figures, they contributed ATS 126. 2 billion, or 5. 2 percent, to GDP in 1996 and provided 143, 490 jobs. In 1987 to 1996, average growth in value added amounted to 10. 0 percent in nominal terms and 5. 8 percent in real terms. Employment increased by 5. 5 percent per year on average. In contrast, the services sector as a whole achieved an average job growth of 1. 5 percent per year, whereas manufacturing lost 1. 4 percent on average during this period. Compared to other OECD countries, Austrian business services lag behind, at a share of 6. 1 percent of employment, although their growth rate is better than in most comparable countries. The speed at which they gain ground reflects the high growth potential inherent in this sector. It is expected that in-house services will be increasingly outsourced. Looking at <b>input-output</b> <b>statistics</b> for 1983 and 1995, we find that the manufacturing sector has indeed stepped up its provision of services but that additional demand for new services has been created in parallel. Available data suggest a net increase of new jobs, although no proper econometric evaluation has yet been made. In this paper it is argued that business services have a number of distinct characteristics which create barriers to competition. They are basically intangible and cannot be traded. Ex-ante quality are unobservable, which frequently leads to information asymmetries (especially moral hazard). It is thus important for suppliers to establish long-term relationships with customers and to project a quality image. For this reason the market for business services is characterized by a high degree of regulation as well as high entry barriers. The sector is also a typical example of a market {{with a wide range of}} products, dominated by some companies and little competition in spite of the generally small size of firms and the absence of economies of scale. Business services are intermediate inputs which improve a region's standing as a business location. A great variety of specialized services, usually tied to the location, leads to productivity gains for the production sector, which in turn drives supply when sufficiently large. The forward and backward linkages between the two sectors induce agglomeration economies and fosters the establishment of core-periphery patterns. In the presence of proximity advantages, e. g., arising from transportation costs, regions in the center can maintain higher real wages due to agglomeration economies, while competition between regions to attract new industries is weakened. Produktionsnahe Dienstleistungen in Österreich; Business Services in Austria...|$|E

