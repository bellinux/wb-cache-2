242|0|Public
2500|$|The <b>error-detection</b> {{ability of}} a CRC depends {{on the degree of}} its key {{polynomial}} and on the specific key polynomial used. [...] The [...] "error polynomial" [...] is the symmetric difference of the received message codeword and the correct message codeword. [...] An error will go undetected by a CRC algorithm if and only if the error polynomial is divisible by the CRC polynomial.|$|E
5000|$|A weaker guarantee, called <b>error-detection,</b> {{requires}} that the tampering-experiment always results in either the correct value [...] or a special symbol [...] indicating that tampering has been detected. This notion of <b>error-detection</b> is a weaker guarantee than error-correction, and achievable for larger F of tampering functions.|$|E
5000|$|Early <b>error-detection</b> {{supporting}} {{development and}} testing of software ...|$|E
50|$|Memory {{scrubbing}} does <b>error-detection</b> and {{correction of}} bit errors in computer RAM by using ECC memory, other {{copies of the}} data, or other error-detecting codes.|$|E
50|$|The {{simplest}} <b>error-detection</b> system, the parity bit, {{is in fact}} {{a trivial}} 1-bit CRC: it uses the generator polynomial x + 1 (two terms), and has the name CRC-1.|$|E
50|$|Control PanelControl {{panel of}} CER-12 allowed the {{operator}} {{to control and}} alter program flow and/or to eliminate errors detected by <b>error-detection</b> circuitry. It features a number of indicators and switches.|$|E
5000|$|The {{notion of}} non-malleable codes was {{introduced}} in 2010 by Dziembowski, Pietrzak, and Wichs, for relaxing the notion of error-correction and <b>error-detection.</b> Informally, a code is non-malleable if the message contained in a modified code-word is either the original message, or a completely unrelated value. Non-malleable codes provide a useful and meaningful security guarantee in situations where traditional error-correction and <b>error-detection</b> is impossible; for example, when the attacker can completely overwrite the encoded message. Although such codes do not exist if the family of [...] "tampering functions" [...] F is completely unrestricted, they are known to exist for many broad tampering families F.|$|E
5000|$|Messages are {{transmitted}} without parity data (only with <b>error-detection</b> information). If a receiver detects an error, it requests FEC {{information from the}} transmitter using ARQ, and uses it to reconstruct the original message.|$|E
50|$|Each DES key is 8 odd-parity bytes, with 56 bits of key and 8 bits of <b>error-detection.</b> A key bundle {{requires}} 24 bytes for option 1, 16 for option 2, or 8 for option 3.|$|E
5000|$|The main {{components}} of each application node were a 32-bit microprocessor Motorola 68020 operating at a clock rate of 20 MHz, 8 MByte of main memory, protected by 2-Bit <b>error-detection</b> and 1-Bit error-correction logic, and four coprocessors: ...|$|E
5000|$|Messages {{are always}} {{transmitted}} with FEC parity data (and <b>error-detection</b> redundancy). A receiver decodes a message using the parity information, and requests retransmission using ARQ {{only if the}} parity data was not sufficient for successful decoding (identified through a failed integrity check).|$|E
50|$|The first {{variant of}} SIMMs has 30 pins and {{provides}} 8 bits of data (plus a 9th <b>error-detection</b> bit in parity SIMMs). They {{were used in}} AT-compatible (286-based, e.g., Wang APC), 386-based, 486-based, Macintosh Plus, Macintosh II, Quadra and Atari STE microcomputers, and Wang VS minicomputers.|$|E
50|$|Automatic Repeat reQuest (ARQ) is {{an error}} control method for data {{transmission}} that {{makes use of}} <b>error-detection</b> codes, acknowledgment and/or negative acknowledgment messages, and timeouts to achieve reliable data transmission. An acknowledgment is a message sent by the receiver to indicate that it has correctly received a data frame.|$|E
5000|$|The Fletcher {{checksum}} is an algorithm for computing a position-dependent checksum {{devised by}} John G. Fletcher (1934-2012) at Lawrence Livermore Labs {{in the late}} 1970s. [...] The objective of the Fletcher checksum was to provide <b>error-detection</b> properties approaching those of a cyclic redundancy check but with the lower computational effort associated with summation techniques.|$|E
5000|$|With one exception, VITC {{contains}} the same payload as SMPTE linear timecode (LTC), {{embedded in a}} new frame structure with extra synchronization bits and an <b>error-detection</b> checksum. The exception is that VITC is encoded twice per interlaced video frame, once in each field, and one additional bit (the [...] "field flag") is used to distinguish the two fields.|$|E
50|$|If {{the channel}} {{capacity}} cannot be determined, or is highly variable, an <b>error-detection</b> scheme {{may be combined}} with a system for retransmissions of erroneous data. This is known as automatic repeat request (ARQ), and is most notably used in the Internet. An alternate approach for error control is hybrid automatic repeat request (HARQ), which {{is a combination of}} ARQ and error-correction coding.|$|E
50|$|Mathematical {{analysis}} of this division-like process reveals how to select a divisor that guarantees good <b>error-detection</b> properties. In this analysis, the digits of the bit strings are taken as the coefficients of a polynomial in some variable x—coefficients that are elements of the finite field GF(2), instead of more familiar numbers. The set of binary polynomials is a mathematical ring.|$|E
5000|$|The <b>error-detection</b> {{ability of}} a CRC depends {{on the degree of}} its key {{polynomial}} and on the specific key polynomial used. The [...] "error polynomial" [...] is the symmetric difference of the received message codeword and the correct message codeword. An error will go undetected by a CRC algorithm if and only if the error polynomial is divisible by the CRC polynomial.|$|E
5000|$|The MII fixes the {{theoretical}} maximum data bit rate for all versions of Fast Ethernet to 100 Mbit/s. The {{data signaling rate}} actually observed on real networks is less than {{the theoretical}} maximum, due to the necessary header and trailer (addressing and <b>error-detection</b> bits) on every frame, the occasional [...] "lost frame" [...] due to noise, and time waiting after each sent frame for other devices on the network to finish transmitting.|$|E
50|$|The cyclic {{redundancy}} check (CRC) is an <b>error-detection</b> code that operates by interpreting the message bitstring as the coefficients of a polynomial over GF(2) and dividing it by a fixed generator polynomial also over GF(2); see Mathematics of CRC. Primitive polynomials, or multiples of them, are sometimes {{a good choice for}} generator polynomials because they can reliably detect two bit errors that occur far apart in the message bitstring, up to a distance of 2n − 1 for a degree n primitive polynomial.|$|E
5000|$|Error control (automatic repeat request,ARQ), in {{addition}} to ARQ provided by some transport-layer protocols, to forward error correction (FEC) techniques provided on the physical layer, and to <b>error-detection</b> and packet canceling provided at all layers, including the network layer. Data-link-layer error control (i.e. retransmission of erroneous packets) is provided in wireless networks and V.42 telephone network modems, but not in LAN protocols such as Ethernet, since bit errors are so uncommon in short wires. In that case, only error detection and canceling of erroneous packets are provided.|$|E
5000|$|The {{level of}} {{programmer}} skill to control full read/write/compute overlap, especially if data records were [...] "batched" [...] several to the [...] "real" [...] block {{of data on}} magnetic tape, was considerable, since all simultaneity checks had to be hand-coded into the program. Automatic <b>error-detection</b> was essentially limited to hardware parity checks at the character level, {{and there were no}} processor hardware checks on what the programmer could do. For example, the computer would simply stop if instructed to access a memory location beyond physical memory.|$|E
50|$|Consequently, we can {{differentiate}} {{two types}} of flows: the data flow and the control flow. Data flow {{is associated with the}} sending phase and control flow is associated to the writing phase. This assures that the primary chunk server takes control of the write order.Note that when the master assigns the write operation to a replica, it increments the chunk version number and informs all of the replicas containing that chunk of the new version number. Chunk version numbers allow for update <b>error-detection,</b> if a replica wasn't updated because its chunk server was down.|$|E
50|$|The {{simplest}} {{version of}} HARQ, Type I HARQ, adds both ED and FEC information to each message prior to transmission. When the coded data block is received, the receiver first decodes the error-correction code. If the channel quality is good enough, all transmission errors should be correctable, and the receiver can obtain the correct data block. If the channel quality is bad, {{and not all}} transmission errors can be corrected, the receiver will detect this situation using the <b>error-detection</b> code, then the received coded data block is rejected and a re-transmission is requested by the receiver, similar to ARQ.|$|E
50|$|The {{start of}} heading (SOH) {{character}} was to mark a non-data section of a data stream—the part of a stream containing addresses and other housekeeping data. The start of text character (STX) {{marked the end of}} the header, and the start of the textual part of a stream. The end of text character (ETX) marked the end of the data of a message. A widely used convention is to make the two characters preceding ETX a checksum or CRC for <b>error-detection</b> purposes. The end of transmission block character (ETB) was used to indicate the end of a block of data, where data was divided into such blocks for transmission purposes.|$|E
5000|$|As {{one very}} {{concrete}} example, we study non-malleability {{with respect to}} the family of functions [...] which specify, for each bit of the code-word , whether to keep it as is, flip it, set it to 0, set it to 1. That is, each bit of the code-word is modified arbitrarily but independently {{of the value of the}} other bits of the code-word. We call this the “bit-wise independent tampering” family [...] Note that this family contains constant functions [...] and constant-error functions [...] as subsets. Therefore, as we have mentioned, error-correction and <b>error-detection</b> cannot be achieved w.r.t. this family. Nevertheless, the following can show an efficient non-malleable code for this powerful family.|$|E
5000|$|In 2008 {{concerns}} {{were raised in}} the book Wafer Level 3-D ICs Process Technology that non-scaling analog elements such as charge pumps and voltage regulators, and additional circuitry [...] "have allowed significant increases in bandwidth but they consume much more die area". Examples include CRC <b>error-detection,</b> on-die termination, burst hardware, programmable pipelines, low impedance, and increasing need for sense amps (attributed {{to a decline in}} bits per bitline due to low voltage). The authors noted that, as a result, the amount of die used for the memory array itself has declined over time from 70-78% with SDRAM and DDR1, to 47% for DDR2, to 38% for DDR3 and potentially to less than 30% for DDR4.|$|E
50|$|A {{stimulus}} locked event-related {{potential is}} also observed following {{the presentation of}} negative feedback stimuli in a cognitive task indicating {{the outcome of a}} response, {{often referred to as the}} feedback ERN (fERN). This has led some researchers to extend the <b>error-detection</b> account of the response ERN (rERN) to a generic error detection system. This position has been elaborated into a reinforcement learning account of the ERN, arguing that both the rERN and the fERN are products of prediction error signals carried by the dopamine system arriving in the anterior cingulate cortex indicating that events have gone worse than expected. In this framework it is common to measure both the rERN and the fERN as the difference in voltage between correct and incorrect responses and feedback, respectively.|$|E
50|$|Additional basic {{functions}} {{performed by the}} TCU's and PCU’s were generation of a cyclic-parity-check code vector and decoding of received packets for packet <b>error-detection</b> purposes, and generation of packet retransmissions using a simple random interval generator. If an acknowledgment was not received from the Menehune after the prescribed number of automatic retransmissions, a flashing light {{was used as an}} indicator to the human user. Also, since the TCU's and PCU’s did not send acknowledgments to the Menehune, a steady warning light was displayed to the human user when an error was detected in a received packet. Thus {{it can be seen that}} considerable simplification was incorporated into the initial design of the TCU as well as the PCU, making use of the fact that it was interfacing a human user into the network.|$|E
50|$|The {{general idea}} for {{achieving}} error detection and correction {{is to add}} some redundancy (i.e., some extra data) to a message, which receivers can use to check consistency of the delivered message, and to recover data that has been determined to be corrupted. <b>Error-detection</b> and correction schemes can be either systematic or non-systematic: In a systematic scheme, the transmitter sends the original data, and attaches a fixed number of check bits (or parity data), which are derived from the data bits by some deterministic algorithm. If only error detection is required, a receiver can simply apply the same algorithm to the received data bits and compare its output with the received check bits; if the values do not match, an error has occurred {{at some point during}} the transmission. In a system that uses a non-systematic code, the original message is transformed into an encoded message that has at least as many bits as the original message.|$|E
5000|$|Motor {{learning}} is a change, resulting from practice or a novel experience, in the capability for responding. It often involves improving the smoothness and accuracy of movements and is obviously necessary for complicated movements such as speaking, playing the piano, and climbing trees; {{but it is also}} important for calibrating simple movements like reflexes, as parameters of the body and environment change over time. Motor learning research often considers variables that contribute to motor program formation (i.e., underlying skilled motor behaviour), sensitivity of <b>error-detection</b> processes, and strength of movement schemas (see motor program). Motor {{learning is}} [...] "relatively permanent", as the capability to respond appropriately is acquired and retained. As a result, the temporary processes that affect behaviour during practice or experience should not be considered learning, but rather transient performance effects. As such, the main components underlying the behavioural approach to motor learning are structure of practice and feedback given. The former pertains to the manipulation of timing and organization of practice (potentially for different subtasks or variations of the task) for optimal information retention (also see varied practice), while the latter pertains to the influence of feedback on the preparation, anticipation, and guidance of movement.|$|E
40|$|AbstractThe {{language}} {{property of}} <b>error-detection</b> {{ensures that the}} communications medium cannot transform a word of the language to another word of the language. In this paper we provide some insights {{on the notion of}} <b>error-detection</b> from a language theoretic point of view. We define certain error-detecting properties of languages and codes including the notion of <b>error-detection</b> with finite delay which is a natural extension of unique decodability with finite delay. We obtain results about the error-detecting capabilities of regular and other languages, and of known classes of codes. Moreover, we consider the problem of estimating the optimal redundancy of infinite languages with the property of detecting errors of the deletion type...|$|E
40|$|Abstract- Error {{detection}} {{plays an}} important role in fault-tolerant computer systems. Two primary parameters concerned for error detection are the latency and coverage. In this paper, a new, hybrid <b>error-detection</b> approach offering a very high coverage with no detection latency is proposed to protect the data paths of high-performance microprocessors. The feature of no detection latency is essential to real-time error recovery. The hybrid detection approach is to combine the duplication with comparison, triple modular redundancy (TMR) and self-checking mechanisms to construct a formal framework, which allows the <b>error-detection</b> schemes of varying hardware complexity and performance to be incorporated. We develop three <b>error-detection</b> schemes using the concept of hybrid approach to demonstrate the design compromise among the hardware overhead, performance degradation and <b>error-detection</b> coverage (EDC). Three detection schemes are then implemented in an experimental 32 -bit VLIW core respectively. The hardware implementations in VHDL and simulated fault injection experiments are performed to measure the design metrics...|$|E
40|$|In this paper, two {{low-cost}} solutions {{devoted to}} provide processor-based systems with <b>error-detection</b> capabilities are compared. The effects of single event upsets (SEUs) and single event transients (SETs) are studied through simulation-based fault injection. The <b>error-detection</b> capabilities of a hardware-implemented solution based on parity code are {{compared with those}} of a software-implemented solution based on source-level code modification. Radiation testing experiments confirmed results obtained by simulation...|$|E
40|$|This paper {{describes}} the concurrent <b>error-detection</b> methods {{employed in the}} ERC 32, a 32 -bit processing core for embed-ded space flight applications. The processor core consists of three devices; an integer unit, a floating point unit and a memory controller. All three devices are provided with inter-nal concurrent <b>error-detection,</b> mainly to detect transient er-rors. Over 98 % of all latched errors are detected. Depending on the error location, errors can be removed by instruction retry or by software intervention without loss of context. A program flow control mechanism is provided to detect execu-tion anomalies due to undetected errors. To further increase the <b>error-detection</b> coverage, each device can be operated in master/checker mode. ...|$|E
40|$|The {{language}} {{property of}} <b>error-detection</b> {{ensures that the}} communications medium cannot transform a word of the language to another word of the language. In this paper we provide some insights {{on the notion of}} <b>error-detection</b> from a language theoretic point of view. We de ne certain error-detecting properties of languages and codes including the notion of <b>error-detection</b> with nite delay which is a natural extension of unique decodability with nite delay. We obtain results about the error-detecting capabilities of regular and other languages, and of known classes of codes. Moreover, we consider the problem of estimating the optimal redundancy of in nite languages with the property of detecting errors of the deletion type...|$|E
