565|655|Public
25|$|<b>Job</b> <b>analysis</b> {{encompasses}} {{a number of}} different methods. It primarily involves the systematic collection of information about a job. A task-oriented <b>job</b> <b>analysis</b> involves an examination of the duties, tasks, and/or competencies required by the job being assessed. By contrast, a worker-oriented <b>job</b> <b>analysis</b> involves an examination of the knowledge, skills, abilities, and other characteristics (KSAOs) required to successfully perform the work. Information obtained from job analyses are used for many purposes, including the creation of job-relevant selection procedures, performance appraisals and the criteria they require, and the development of training programs.|$|E
25|$|An I/O {{psychologist}} would typically {{use information}} from the <b>job</b> <b>analysis</b> to determine a job's performance dimensions, and then construct a rating scale to describe each level of performance for the job. Often, the I/O psychologist {{would be responsible for}} training organizational personnel how to use the performance appraisal instrument, including ways to minimize bias when using the rating scale, and how to provide effective performance feedback.|$|E
25|$|In the United States, certain public {{policies}} and laws regarding military service, education, public benefits, capital punishment, and employment incorporate an individual's IQ into their decisions. However, {{in the case}} of Griggs v. Duke Power Co. in 1971, for the purpose of minimizing employment practices that disparately impacted racial minorities, the U.S. Supreme Court banned the use of IQ tests in employment, except when linked to job performance via a <b>job</b> <b>analysis.</b> Internationally, certain {{public policies}}, such as improving nutrition and prohibiting neurotoxins, have as one of their goals raising, or preventing a decline in, intelligence.|$|E
50|$|<b>Job</b> safety <b>analysis,</b> {{including}} ergonomic {{evaluations of}} jobs or workstations.|$|R
5000|$|<b>Job</b> Safety <b>Analysis</b> (JSA), Near Miss, Confined Entry, WCB forms.|$|R
50|$|A <b>job</b> safety <b>analysis</b> (JSA) is a {{procedure}} which helps integrate accepted {{safety and health}} principles and practices into a particular task or job operation. In a JSA, each basic step of the job is to identify potential hazards and to recommend the safest way to do the job. Other terms used to describe this procedure are <b>job</b> hazard <b>analysis</b> (JHA) and <b>job</b> hazard breakdown.|$|R
25|$|Similar to {{performance}} management (see above), an I/O psychologist would employ a <b>job</b> <b>analysis</b> {{in concert with}} the application of the principles of instructional design to create an effective training program. A training program is likely to include a summative evaluation at its conclusion {{in order to ensure that}} trainees have met the training objectives and can perform the target work tasks at an acceptable level. Training programs often include formative evaluations to assess the effect of the training as the training proceeds. Formative evaluations can be used to locate problems in training procedures and help I/O psychologists make corrective adjustments while training is ongoing.|$|E
25|$|There are {{a number}} of {{different}} forms of validity. Criterion-related validity can be assessed by correlating a measure with a criterion measure theoretically expected to be related. When the criterion measure is collected {{at the same time as}} the measure being validated the goal is to establish concurrent validity; when the criterion is collected later the goal is to establish predictive validity. A measure has construct validity if it is related to measures of other constructs as required by theory. Content validity is a demonstration that the items of a test do an adequate job of covering the domain being measured. In a personnel selection example, test content is based on a defined statement or set of statements of knowledge, skill, ability, or other characteristics obtained from a <b>job</b> <b>analysis.</b>|$|E
2500|$|Kennedy J continued, [...] "At {{every stage}} of the <b>job</b> <b>analysis,</b> IOS, by {{deliberate}} choice, over-sampled minority firefighters {{to ensure that the}} results which IOS would use to develop the examinations—would not intentionally favor white candidates." ...|$|E
40|$|Abstract — The Grid Collector is {{a system}} that {{facilitates}} the effective analysis and spontaneous exploration of scientific data. It combines an efficient indexing technology with a Grid file management technology to speed up common <b>analysis</b> <b>jobs</b> on high-energy physics data and to enable some previously impractical <b>analysis</b> <b>jobs.</b> To analyze a set of high-energy collision events, one typically specifies the files containing the events of interest, reads all the events in the files, and filters out unwanted ones. Since most <b>analysis</b> <b>jobs</b> filter out significant number of events, a considerable amount of time is wasted by reading the unwanted events. The Grid Collector removes this inefficiency by allowing users to specify more precisely what events are of interest and to read only the selected events. This speeds up most <b>analysis</b> <b>jobs.</b> In existing <b>analysis</b> frameworks, the responsibility of bringing files from tertiary storages or remote sites to local disks falls on the users. This forces most of <b>analysis</b> <b>jobs</b> to be performed at centralized computer facilities where commonly used files are kept on large shared file systems. The Grid Collector automates file management tasks and eliminates the labor-intensive manual file transfers. This makes it much easier to perform analyses that require data files on tertiary storages and remote sites. It also makes more computer resources available for <b>analysis</b> <b>jobs</b> since they are no longer bound to the centralized facilities...|$|R
40|$|This {{article was}} {{published}} in Latin American Journal of Pharmacy [© 2011 Latin American Journal of Pharmacy] and the definite version is available at: [URL] present {{study was designed to}} study the in vitro interaction of ketotifen fumarate and metformin hydrochloride in aqueous media at different pH values using <b>Job's</b> continuous-variation <b>analysis</b> and Ardon's spectrophotomeric measurement. <b>Job's</b> <b>analysis</b> indicated the formation of 1 : 1 complex between ketotifen fumarate and metformin hydrochloride at the studied pH values. On the other hand, the values of stability constants (between negative values and 1), as calculated from Ardon's plot, mean that the formation of complex due to interaction between the drugs is readily dissociable. Thus the findings of the study suggest that both drugs can be safely co-administered. However, further studies involving animal models are needed to ascertain the exact nature of interaction between them in vivo. Publishe...|$|R
50|$|A <b>job</b> safety <b>analysis</b> {{and/or a}} <b>job</b> hazard <b>analysis</b> should be {{conducted}} with every employee {{so that it is}} understood what is needed to do the job safely and what hazards are associated with the job. A safety trainer may observe the worker in his/her environment to adequately assess the worker's training needs. Certain employees may need extra training due to the hazards associated with their particular job. These employees should be trained not only onhow to perform their job safely but also on how to operate within a hazardousenvironment.|$|R
2500|$|The <b>Job</b> <b>Analysis</b> and Opportunity Project {{began in}} 1941. [...] It {{was to provide}} career, {{employment}} counseling, and job exposure for black women. [...] The sorority created the program to address concerns that black women were limited in their choices of occupations, and that they lacked training because {{of the economy and}} World War II. Some of the project's goals were to improve working conditions and to improve black women's opportunities to acquire a job.|$|E
2500|$|Job Characteristics Model: This model [...] "focuses on {{important}} aspects of job characteristics, such as skill variety, task identity, task significance, autonomy, and feedback. These characteristics are proposed to lead to ‘critical psychological states’ of experienced meaningfulness, and experienced responsibility and knowledge of outcomes. It is proposed that positive or negative work characteristics give rise to mental states which lead to corresponding cognitive and behavioral outcomes, e.g. motivation, satisfaction, absenteeism, etc. In conjunction with the model, Hackman and Oldham (1980) developed the Job Diagnostic Survey, a questionnaire for <b>job</b> <b>analysis,</b> which implies key types of job-redesign including combining tasks, creating feedback methods, job enrichment, etc." ...|$|E
2500|$|An {{organizational}} {{analysis is}} {{an examination of}} organizational goals and resources {{as well as the}} organizational environment. The results of an organizational analysis help to determine where training should be directed. The analysis identifies the training needs of different departments or subunits. It systematically assesses manager, peer, and technological support for transfer of training. An organizational analysis also takes into account the climate of the organization and its subunits. For example, if a climate for safety is emphasized throughout the organization or in subunits of the organization (e.g., production), then training needs will likely reflect an emphasis on safety. A task analysis uses the results of a <b>job</b> <b>analysis</b> to determine what is needed for successful job performance, contributing to training content. With organizations increasingly trying to identify [...] "core competencies" [...] that are required for all jobs, task analysis can also include an assessment of competencies. A person analysis identifies which individuals within an organization should receive training and what kind of instruction they need. Employee needs can be assessed using a variety of methods that identify weaknesses that training can address.|$|E
30|$|Zhang et al. (2013 and 2015) {{investigated}} {{an approach}} for establishing, storing and re-utilizing construction safety information. They proposed and tested a prototype application of ontology-based <b>job</b> hazard <b>analysis</b> and visualization. The {{results showed that}} the construction safety ontology permits an effective review of safety understanding and can facilitate the automated safety planning for <b>job</b> hazard <b>analysis.</b> Subsequently, they explored the link between BIM and a construction safety ontology for the purpose of safety knowledge management. The ontology linked different knowledge domains together. The model is updated to visualize the corresponding hazards and their analysis, e.g. a limited or congested workspace in the building of masonry wall. The results highlighted that <b>job</b> based hazard <b>analysis</b> can be linked to BIM to enable an improved visualization and awareness of potential risks.|$|R
30|$|This section elaborates {{the three}} types of talent flow {{analytics}} as shown in Fig.  1, namely: (a) hop classification and <b>analysis,</b> (b) <b>job</b> attribute <b>analysis,</b> and (c) connectivity analysis.|$|R
50|$|Muysken's {{research}} includes work on {{endogenous growth}} and diffusion of technologies; skill mismatch; <b>job</b> competition; <b>analysis</b> of unemployment; portfolio investment and other topics, including {{his work on}} health as a determinant of economic growth.|$|R
50|$|Job {{evaluation}} {{needs to}} be differentiated from <b>job</b> <b>analysis.</b> <b>Job</b> <b>analysis</b> is a systematic way of gathering information about a job. Every job evaluation method requires at least some basic <b>job</b> <b>analysis</b> {{in order to provide}} factual information about the jobs concerned. Thus, job evaluation begins with <b>job</b> <b>analysis</b> and ends at that point where the worth of a job is ascertained for achieving pay equity between jobs and different roles.|$|E
5000|$|EEO compliance: <b>Job</b> <b>analysis</b> plays a {{large role}} in EEO compliance. United States Federal Agencies' Uniform Guidelines on Employee Selection {{stipulate}} that <b>job</b> <b>analysis</b> is a necessary step in validating all major personnel activities. For example, employers must be able to show that their selection criteria and job performance are actually related. Doing this requires knowing what the job entails, which in turn requires <b>job</b> <b>analysis.</b>|$|E
50|$|There {{are several}} ways to conduct a <b>job</b> <b>analysis,</b> including: {{interviews}} with incumbents and supervisors, work methods of analysis can be laborious and time consuming, and there is always a tendency on the part of management to over analyze some jobs and under analyze some others. These traditional <b>job</b> <b>analysis</b> methods include: one-on-one interviewing; behavioral event interviews; phone interviews; surveys; work assessments; Developing a Curriculum (DACUM); <b>job</b> <b>analysis</b> worksheets; observations and procedural review. <b>Job</b> <b>analysis</b> at the speed of reality. Amherst, Mass.: HRD Press. All of these methods can be used to gather information for <b>job</b> <b>analysis.</b> The DACUM process developed in the late 1960s has been viewed as the fastest method used, but it can still can take two or three days to obtain a validated task list.|$|E
40|$|This paper {{describes}} {{the development of}} a <b>job</b> task <b>analysis</b> tool for observing and recording physician tasks in the ICU. Real-time direct observations were conducted by outside observers using a computerized data collection tool developed to document the tasks performed by ICU physicians. The aim of the analysis was to quantify the tasks of the physicians, including measures of frequency, duration, and sequence for tasks. In this paper, we report on the development process, as well as the validity and reliability of the <b>job</b> task <b>analysis</b> tool. Initial results from our analyses provide support for the validity and reliability of the taxonomy developed for assessing work of ICU physicians...|$|R
40|$|Strong {{evidence}} in support of the hypothesis that women receive lower wage offers in part-time jobs than in full-time jobs is provided by estimation of wage offer functions for British women, which control for self-selection into these two types of <b>jobs.</b> <b>Analysis</b> of married women's employment decisions indicates that the difference in a woman's expected wage offers between full-time and part-time employment is an important determinant of whether she works full time, while husband's income mainly affects the decision of whether to work. In addition, it appears that women who work despite having observed characteristics that discourage employment {{are much more likely to}} work part time. ...|$|R
30|$|After {{job title}} normalization, we {{represent}} each job by its normalized job title and the company. We then craft the talent flow network based on transitions between jobs and perform talent flow analytics that encompasses {{three types of}} analysis, namely hop classification and <b>analysis,</b> <b>job</b> attribute <b>analysis,</b> and connectivity analysis. Each analysis studies a specific aspect of talent flow network. Firstly, hop classification and analysis focuses on analyzing types of job hop activity in the network whether the hop is an internal or external hop. Hop analysis will reveal the pattern of internal and external hops. Secondly, <b>job</b> attribute <b>analysis</b> aims to analyze talent flow with respect to job attributes and job hop attributes such as promotion and demotion. Finally, connectivity analysis strives to analyze talent flow behavior at the network level allowing us to determine important jobs and organizations. We describe the talent flow network construction and analytics phases in greater detail in Sects. 4 and 5, respectively.|$|R
50|$|<b>Job</b> <b>analysis</b> {{was also}} {{conceptualized}} {{by two of}} the founders of I-O psychology, Frederick Winslow Taylor and Lillian Moller Gilbreth in the early 20th century.1 Since then, experts have presented many different systems to accomplish <b>job</b> <b>analysis</b> that have become increasingly detailed over the decades. However, evidence shows that the root purpose of <b>job</b> <b>analysis,</b> understanding the behavioral requirements of work, has not changed in over 85 years.|$|E
5000|$|Compensation: <b>Job</b> <b>analysis</b> {{information}} {{is crucial for}} estimating the value of each job and its appropriate compensation. Compensation (salary and bonus) usually depends on the job's required skill and education level, safety hazards, degree of responsibility, etc. -- all factors which can be assessed through <b>job</b> <b>analysis.</b> Also, many employers group jobs into classes. <b>Job</b> <b>analysis</b> provides the information to determine the relative worth of each job and its appropriate class.|$|E
50|$|Functional <b>job</b> <b>analysis</b> (FJA) is {{a method}} of <b>job</b> <b>analysis</b> that was {{developed}} by the Employment and Training Administration of the United States Department of Labor. FJA produces standardized occupational information specific to the performance of the work and the performer.|$|E
40|$|CMS {{production}} and <b>analysis</b> <b>job</b> submission is {{based largely on}} glideinWMS and pilot submissions. The transition from multiple different submission solutions like gLite WMS and HTCondor-based implementations was carried out over years and is coming now to a conclusion. The historically explained separate glideinWMS pools for different types of production <b>jobs</b> and <b>analysis</b> <b>jobs</b> are being unified into a single global pool. This enables CMS to benefit from global prioritization and scheduling possibilities. It also presents the sites with only one kind of pilots and eliminates the need of having to make scheduling decisions on the CE level. This paper provides {{an analysis of the}} benefits of a unified resource pool, as well as a description of the resulting global policy. It will explain the technical challenges moving forward and present solutions to some of them...|$|R
40|$|An {{important}} part of initiating a site-wide ergonomics evaluation process is prioritizing jobs to be analyzed. While injury data is important, other factors such as worker discomfort and physical exertion requirements, should be considered. This paper describes the use of four sources of data (injury records, the Nordic Standardized Musculoskeletal Questionnaire, supervisor interviews, and management concerns) to prioritize <b>jobs</b> for ergonomic <b>analysis.</b> The approach described integrates the four sources using a decision matrix to prioritize <b>jobs</b> for ergonomics <b>analysis...</b>|$|R
40|$|Background: There {{are several}} ways to conduct a <b>job</b> task <b>analysis</b> in medical work environments {{including}} pencil-paper observations, interviews and questionnaires. However these methods implicate bias problems such as high inter-individual deviations and risks of misjudgement. Computer-based observation helps to reduce these problems. The aim {{of this paper is to}} give an overview of the development process of a computer-based <b>job</b> task <b>analysis</b> instrument for real-time observations to quantify the job tasks performed by physicians working in different medical settings. In addition reliability and validity data of this instrument will be demonstrated. Methods: This instrument was developed in consequential steps. First, lists comprising tasks performed by physicians in different care settings were classified. Afterwards content validity of task lists was proved. After establishing the final task categories, computer software was programmed and implemented in a mobile personal computer. At least inter-observer reliability was evaluated. Two trained observers recorded simultaneously tasks of the same physician. Results: Content validity of the task lists was confirmed by observations and experienced specialists of each medical area. Development process of the <b>job</b> task <b>analysis</b> instrument was completed successfully. Simultaneous records showed adequate interrater reliability. Conclusion: Initial results of this analysis supported the validity and reliability of this developed method for assessing physicians' working routines as well as organizational context factors. Based on results using this method, possible improvements for health professionals' work organisation can be identified...|$|R
50|$|The <b>Job</b> <b>Analysis</b> at the Speed of Reality (JASR) {{method for}} <b>job</b> <b>analysis</b> is a reliable, proven method to quickly create {{validated}} task lists. The end product, {{which can be}} used for many purposes, is the basis for many potential training opportunities. This method is a tested process that helps analysts complete a <b>job</b> <b>analysis</b> of a typical job with a group of subject matter experts and managers in two to three hours then deliver a validated task list.|$|E
50|$|Regardless {{of which}} {{approach}} to <b>job</b> <b>analysis</b> is taken, {{the next step}} in the process is to identify the attributes—the KSAOs that an incumbent needs for either performing the tasks at hand or executing the human behaviors described in the <b>job</b> <b>analysis.</b>|$|E
50|$|<b>Job</b> <b>analysis</b> {{is crucial}} for first, helping {{individuals}} develop their careers, and also for helping organizations develop their employees {{in order to maximize}} talent. The outcomes of <b>job</b> <b>analysis</b> are key influences in designing learning, developing performance interventions, and improving processes. The application of <b>job</b> <b>analysis</b> techniques makes the implicit assumption that information about a job as it presently exists may be used to develop programs to recruit, select, train, and appraise people for the job as it will exist in the future.|$|E
40|$|Grid tools {{currently}} available {{are most often}} geared towards running batch-oriented dataset <b>analysis</b> <b>jobs</b> {{on a set of}} distributed heterogeneous computers in a production setting where the data is assumed to be in files, and do not automatically collect the results from multiple <b>analysis</b> <b>jobs.</b> This is insufficient for interactive dataset analysis, where complicated communications between the <b>analysis</b> <b>jobs</b> and the scheduler are required for interactivity and where datasets are abstracted from files, collections of files, database objects, and even virtual datasets for which only a generation algorithm exists. We describe a prototype for a system based on a set of grid services to provide interactive dataset analysis that extends the Globus Toolkit grid tools. An existing Java-based dataset analysis and visualization client tool are used to access the grid service and provide the interactive user interface for the client...|$|R
40|$|Observation has {{lead to a}} {{conclusion}} that the physics <b>analysis</b> <b>jobs</b> run by LHCb physicists on a local computing farm (i. e. non-grid) require more efficient access to the data which resides on the Grid. Our experiments {{have shown that the}} I/O bound nature of the <b>analysis</b> <b>jobs</b> in combination with the latency due to the remote access protocols (e. g. rfio, dcap) cause a low CPU efficiency of these jobs. In addition to causing a low CPU efficiency, the remote access protocols give rise to high overhead (in terms of amount of data transferred). This paper gives an overview of the concept of pre-fetching and caching of input files in the proximity of the processing resources, which is exploited to cope with the I/O bound <b>analysis</b> <b>jobs.</b> The files are copied from Grid storage elements (using GridFTP), while concurrently performing computations, inspired from a similar idea used in the ATLAS experiment. The results illustrate that this file staging approach is relatively insensitive to the original location of the data, and a significant improvement can be achieved in terms of the CPU efficiency of an <b>analysis</b> <b>job.</b> Dealing with scalability of such a solution on the Grid environment is discussed briefly...|$|R
3000|$|... 11 It {{is worth}} noting that this finding {{strictly}} applies to the surveyed surviving firms. If entry and exit dynamics systematically differ between traditional industries and services providers, this result might be reversed. For this reason, it would be crucial to reexamine the <b>job</b> creation <b>analysis</b> using census data that allow us to account for firm entry and exit.|$|R
