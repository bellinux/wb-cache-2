708|2564|Public
50|$|The use of <b>image</b> <b>texture</b> {{can be used}} as a {{description}} for regions into segments. There are two main types of segmentation based on <b>image</b> <b>texture,</b> region based and boundary based. Though <b>image</b> <b>texture</b> is not a perfect measure for segmentation it is used along with other measures, such as color, that helps solve segmenting in image.|$|E
50|$|An <b>image</b> <b>texture</b> {{is a set}} of metrics {{calculated}} in {{image processing}} designed to quantify the perceived texture of an image. <b>Image</b> <b>texture</b> gives us information about the spatial arrangement of color or intensities in an image or selected region of an image.|$|E
50|$|Alpha mapping is a {{technique}} in 3D computer graphics where an image is mapped (assigned) to a 3D object, and designates {{certain areas of the}} object to be transparent or translucent. The transparency can vary in strength, based on the <b>image</b> <b>texture,</b> which can be greyscale, or the alpha channel of an RGBA <b>image</b> <b>texture.</b>|$|E
50|$|Different {{texture mapping}} {{algorithms}} exist, e.g.: single <b>image</b> <b>texturing,</b> texture colour blending or view-dependant <b>texturing.</b> The single <b>image</b> <b>texturing</b> approach is often used, {{due to its}} simplicity and efficiency.|$|R
40|$|Procedural textures have {{significant}} advantages over <b>image</b> <b>textures.</b> Procedural textures are compact, are resolution and size independent, often remove {{the need for}} a texture parameterization, can easily be parameterized and edited, and allow high quality anti-aliasing. However, creating procedural textures is more difficult than creating <b>image</b> <b>textures.</b> Creating procedural textures typically involves some sort of programming language or an interactive visual interface, while <b>image</b> <b>textures</b> can be created by simply taking a digital photograph. In this paper we present a method for creating procedural textures by example, designed for isotropic stochastic textures. From a single uncalibrated photograph of a texture we compute a small set of parameters that defines a procedural texture similar to the texture in the photograph. Our method allows us to replace <b>image</b> <b>textures</b> with similar procedural textures, combining the advantages of procedural <b>textures</b> and <b>image</b> <b>textures.</b> Our method for creating isotropic stochastic procedural textures by example therefore has the potential to dramatically improve the texturing and modeling process. nrpages: 12 status: publishe...|$|R
5000|$|TEXTURE: also, an {{important}} quality {{in order to}} describe an <b>image.</b> The <b>texture</b> descriptors characterize <b>image</b> <b>textures</b> or regions. They observe the region homogeneity and the histograms of these region borders. The set of descriptors is formed by: ...|$|R
50|$|A {{structured}} approach sees an <b>image</b> <b>texture</b> {{as a set}} {{of primitive}} texels in some regular or repeated pattern. This works well when analyzing artificial textures.|$|E
5000|$|Wrapping: The {{image is}} tiled, so that going off one edge wraps {{around to the}} {{opposite}} side of the image. This method assumes that the image is largely homogeneous, for example a stochastic <b>image</b> <b>texture</b> without large textons.|$|E
50|$|A {{statistical}} approach sees an <b>image</b> <b>texture</b> as {{a quantitative}} {{measure of the}} arrangement of intensities in a region. In general this approach is easier to compute and is more widely used, since natural textures are made of patterns of irregular subelements.|$|E
5000|$|Displacement mapping and subdivision: Based on {{procedural}} or <b>image</b> <b>textures,</b> object surfaces can be transformed.|$|R
40|$|AbstractIn posed years, Researchers {{proposed}} many algorithms which restored damaged images along isophate direction. These methods cause texture broken while inpainting <b>texture</b> <b>image</b> {{with complex}} structure. We advance a novel method which decomposes the <b>texture</b> <b>image</b> into cartoon <b>image</b> and <b>texture</b> <b>image,</b> then inpaints structure based on boundary restoration and use texture synthesis to inpaint <b>texture</b> <b>image.</b> The experimental result {{shows that it}} is effective to inpaint <b>texture</b> <b>image</b> with complex structure...|$|R
5000|$|Hierarchical {{procedural}} and <b>image</b> based <b>texture</b> system: Procedural and <b>image</b> based <b>textures</b> can {{be mixed}} in various ways, {{making it possible}} to create complex materials.|$|R
5000|$|She created {{illustrations}} for Vogue magazine, {{including some}} covers. Grafstrom also contributed illustrations to the Delineator, Cosmopolitan, and other women's magazines. Her illustrations featured real, approachable women. She drew [...] "'real' women...who inhabit 'real' space." [...] Her illustrations sometimes included fabric collage, {{to give the}} <b>image</b> <b>texture.</b>|$|E
50|$|Geometric feature {{learning}} methods extract distinctive geometric features from images. Geometric features are features of objects constructed {{by a set}} of geometric elements like points, lines, curves or surfaces. These features can be corner features, edge features, Blobs, Ridges, salient points <b>image</b> <b>texture</b> and so on, which can be detected by feature detection methods.|$|E
5000|$|Image textures can be artificially created or {{found in}} natural scenes {{captured}} in an image. Image textures are {{one way that}} can be used to help in segmentation or classification of images. For more accurate segmentation the most useful features are spatial frequency and an average grey level. [...] To analyze an <b>image</b> <b>texture</b> in computer graphics, there are two ways to approach the issue: Structured Approach and Statistical Approach.|$|E
40|$|In this paper, {{we present}} a novel method, which uses non-separable wavelet filter banks, to extract the {{features}} of <b>texture</b> <b>images</b> for <b>texture</b> <b>image</b> retrieval. Compared to traditional tensor product wavelets (such as db wavelets), our new method can capture more direction and edge information of <b>texture</b> <b>images,</b> which is highly valuable to reflect the essential properties of the <b>texture</b> <b>images.</b> Experiments show that the proposed method is satisfactory and can achieve better retrieval accuracies than db wavelets...|$|R
50|$|The {{first use}} of epitomic {{analysis}} was with <b>image</b> <b>textures</b> {{for the purposes of}} image parsing. Epitomes have also been used in video processing to replace, remove or superresolve imagery.|$|R
40|$|The {{features}} {{based on}} Markov random field (MRF) mod-els are usually {{sensitive to the}} rotation of <b>image</b> <b>textures.</b> This paper develops an anisotropic circular Gaussian MRF (ACGMRF) model for modelling rotated <b>image</b> <b>textures</b> and retrieving rotation-invariant texture features. To over-come the singularity problem of the least squares esti-mate (LSE) method, an approximate least squares estimate (ALSE) method is proposed to estimate {{the parameters of the}} ACGMRF model. The rotation-invariant features can be obtained from the parameters of the ACGMRF model by the one-dimensional (1 -D) discrete Fourier transform (DFT). Significantly improved accuracy can be achieved by apply-ing the rotation-invariant features to classify SAR (synthetic aperture radar) sea ice and Brodatz imagery. ...|$|R
50|$|The video {{includes}} stock {{footage of}} Stewart with Williams digitally inserted in many scenes, creating the near-perfect {{illusion of a}} neck-and-neck pursuit of the championship title. The video makes extensive use of the split-screen technique as it is often seen in movies from the 1960s and 70s (for instance in the 1970 feature racing movie Le Mans), and the scenes with Robbie Williams were given a yellowed, grainy <b>image</b> <b>texture</b> in the digital editing process to match the faded look of the original 35mm celluloid footage with Jackie Stewart. As yet another movie cliché, fake newspaper headlines are shown intermittently to help narrate the story.|$|E
50|$|In {{the early}} days, {{significant}} work {{was carried out}} in medical signal and image processing. A unique algorithm was proposed for ECG compression by treating each cardiac cycle as a vector, and applying linear prediction on the discrete wavelet transform of this vector, after normalizing its period using multirate processing based interpolation. The maturity of the fetal lung was predicted using <b>image</b> <b>texture</b> features obtained from the liver and lung regions of the ultrasound images obtained from pregnant women An effective technique was proposed for lossless compression of 3D magnetic resonance images of the brain. Each MRI slice was represented by uniform or adaptive mesh; affine transformation was applied between the corresponding mesh elements of adjacent slices and context-based entropy coding, on the residues.|$|E
5000|$|In the low-and mid-level areas, Haralick {{has worked}} in <b>image</b> <b>texture</b> {{analysis}} using spatial gray tone co-occurrence texture features. These features have been used with success on biological cell images, x-ray images, satellite images, aerial images and many other kinds of images taken at small and large scales. In the feature detection area, Haralick has developed the facet model for image processing. [...] The facet model states that many low-level image processing operations can be interpreted relative to what the processing does to the estimated underlying gray tone intensity surface of which the given image is a sampled noisy version. The facet papers develop techniques for edge detection, line detection, noise removal, peak and pit detection, {{as well as a}} variety of other topographic gray tone surface features.|$|E
40|$|In this article, a brief {{review on}} texture {{segmentation}} is presented, before a novel automatic texture segmentation algorithm is developed. The algorithm {{is based on}} a modified discrete wavelet frames and the mean shift algorithm. The proposed technique is tested on a range of textured <b>images</b> including composite <b>texture</b> <b>images,</b> synthetic <b>texture</b> <b>images,</b> real scene images as well as our main source of images, the museum images of various kinds. An extension to the automatic texture segmentation, a texture identifier is also introduced for integration into a retrieval system, providing an excellent approach to content-based <b>image</b> retrieval using <b>texture</b> features...|$|R
40|$|<b>Image</b> <b>textures</b> {{can easily}} be created using texture {{synthesis}} by example. However, creating procedural textures is much more difficult. This is unfortunate, since procedural textures have significant advantages over <b>image</b> <b>textures.</b> In this paper we {{address the problem of}} texture synthesis by example for procedural textures. We introduce a method for procedural multiresolution noise by example. Our method computes the weights of a procedural multiresolution noise, a simple but common class of procedural textures, from an example. We illustrate this method by using it as a key component in a method for texture synthesis by example for isotropic stochastic procedural textures. Our method significantly facilitates the creation of these procedural textures. status: publishe...|$|R
40|$|A model-based texture {{recognition}} {{system which}} classifies <b>image</b> <b>textures</b> seen from different distances and under different illumination directions {{is presented in}} this paper. The system works {{on the basis of}} a surface model obtained by means of 4 -source Colour Photometric Stereo (CPS), used to generate 2 D <b>image</b> <b>textures</b> as they would have ap-peared if imaged under different imaging geometries. The proposed recognition system combines co-ocurrence matrices for feature extraction with a Nearest Neighbour classifier. The use of the co-occurrence matrices instead of filtering methods for feature extraction allows us to utilise only pixels for which valid information has been extracted by CPS. The validity of the method is demonstrated by classifying <b>texture</b> <b>images</b> captured under different imaging geometries than the reference images in the database. Moreover, the process of recognition allows one to guess the approximate direction of the illumination used to capture the test image...|$|R
5000|$|Texture-based {{animation}} uses pixel {{color to}} create the animation on the character face. 2D facial animation is commonly based upon the transformation of images, including both images from still photography and sequences of video. Image morphing is a technique which allows in-between transitional images to be generated between a pair of target still images or between frames from sequences of video. These morphing techniques usually consist {{of a combination of}} a geometric deformation technique, which aligns the target images, and a cross-fade which creates the smooth transition in the <b>image</b> <b>texture.</b> An early example of image morphing can be seen in Michael Jackson's video for [...] "Black Or White". In 3D animation texture based animation can be achieved by animating the texture itself or the UV mapping. In the latter case a texture map of all the facial expression is created and the UV map animation is used to transition from one expression to the next.|$|E
40|$|AbstractThe Surface {{roughness}} and <b>image</b> <b>texture</b> {{features of}} milled surfaces are key parameters {{to study the}} surface characteristics of end milled AA 6061 alloy. A Machine vision system is employed to capture and store {{the images of the}} end milled workpieces. The stylus type instrument is used measure the surface roughness values of various milled workpieces for different cutting conditions such as speed, feed and depth of cut. The Grey Level Cooccurance Matrix [GLCM] is introduced to extract the <b>image</b> <b>texture</b> features of the end milled surfaces. Four Matrices about different sampling orientations are builtup to determine the various image texure features such as contrast, homogenity, correlation and energy. A regression analysis is performed between <b>image</b> <b>texture</b> features and surface roughness values of the machined surfaces. Finally, the relationship between surface roughness and <b>image</b> <b>texture</b> features has been established...|$|E
30|$|In this paper, a {{new class}} of <b>image</b> <b>texture</b> {{operators}} is proposed. We firstly determine that the number of gray levels in each B × B subblock is a fundamental property of the local <b>image</b> <b>texture.</b> Thus, an occurrence histogram for each B × B sub-block can be utilized to describe the texture of the image. Moreover, using a new multi-bit plane strategy, i.e., representing the <b>image</b> <b>texture</b> with the occurrence histogram of the first one or more significant bit-planes of the input image, more powerful operators for describing the <b>image</b> <b>texture</b> can be obtained. The proposed approach is invariant to gray scale variations since the operators are, by definition, invariant under any monotonic transformation of the gray scale, and robust to rotation. They can also be used as supplementary operators to local binary patterns (LBP) to improve their capability to resist illuminance variation, surface transformations, etc.|$|E
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe {{objective of this}} thesis is to develop segmentation methods for multichannel and single channel images, and compare these methods. The segmentation algorithms {{are based on a}} linear model for the <b>image</b> <b>textures</b> and on inverse filtering to estimate the <b>image</b> <b>textures</b> and their regions. Two specific methods are compered 1) A multichannel filtering algorithm that simultaneously models the three separate signals representing the intensity of red, green, and blue as a function of spatial position and 2) A single channel model applied to a combined image resulting from performing a Karhunen-Loeve transformation on the three signal components. Results of the multichannel image segmentation and the Karhunen-Loeve transformed one-channel image segmentation are presented and compared. [URL] Junior Grade, Turkish Nav...|$|R
40|$|In this paper, a novel {{unsupervised}} segmentation {{framework for}} <b>texture</b> <b>image</b> queries is presented. The proposed framework {{consists of an}} unsupervised segmentation method for <b>texture</b> <b>images,</b> and a multi-filter query strategy. By applying the unsupervised segmentation method on each <b>texture</b> <b>image,</b> a set of texture feature parameters for that <b>texture</b> <b>image</b> can be extracted automatically. Based upon these parameters, an effective multi-filter query strategy which allows the users to issue texture-based image queries is developed. The test results of the proposed framework on 318 <b>texture</b> <b>images</b> obtained from the MIT VisTex and Brodatz database are presented to show its effectiveness. 1...|$|R
30|$|Texture {{is one of}} {{the most}} {{commonly}} used features used to analyze and interpret <b>images.</b> <b>Texture</b> is a measure of the variation of the intensity of a surface, quantifying properties such as smoothness, coarseness, and regularity. It is often used as a region descriptor in image analysis.|$|R
40|$|It is {{well known}} that in texture {{analysis}} one must distinguish between <b>image</b> <b>texture</b> and surface texture. The difference between them is easy; <b>image</b> <b>texture</b> is what appears on the 2 D image of a physical object, while surface texture provides the variation of the physical and geometric properties of the imaged surface which give rise to the texture in the image...|$|E
40|$|This report {{summarizes}} the significant {{literature in the}} area of <b>image</b> <b>texture</b> segmentation, classification, and synthesis. The intent is to provide guidance and direction to the approaches available for <b>image</b> <b>texture</b> processing and a measure of their relative merit. The goal of this effort is to utilize texture processing techniques for the classification of acoustic provinces in sidescan sonar imagery...|$|E
40|$|This paper {{describes}} the use the granold texture representation for <b>image</b> <b>texture</b> classification. The granold uses two different parameterised monotonic mappings to transform an input image into a function on two dimensions {{that may be}} regarded as a surface. The nature of this surface is such that corners appear at positions where there are simultaneously large changes in the response of the monotonic mappings to the input image. The shape and position of these corners is then analysed to provide information about the texture of the input image. Marginal probability mass functions are presented as a means to extract features from the granold for <b>image</b> <b>texture</b> classification purposes. A 16 class and a 2 class <b>image</b> <b>texture</b> classification experiment are described and their results discussed. The conclusion is that features extracted from the granold have discriminant power for <b>image</b> <b>texture</b> analysis. 1. Introduction In this paper we aim to build on our previous work [4] by developing f [...] ...|$|E
50|$|In demoscene parlance, {{graphics}} or GFX typically only {{includes the}} work of the graphician - that is, still <b>images,</b> <b>textures,</b> charsets (short for character sets such as monospaced fonts), 3D scenes, 3D objects and color schemes. Effects and other code-related visualization is usually not regarded as graphics.|$|R
40|$|Texture {{segmentation}} {{is one of}} {{the early}} steps towards identifying surfaces and objects in an <b>image.</b> <b>Textures</b> considered here are de ned in terms of primitives called tokens. In this paper we havedeveloped a texture segmentation algorithm based on the Voronoi tessellation. The algorithm rst builds the Voronoi tessellation of the tokens that make up the textured image. It then computes a feature vector for each Voronoi polygon. These feature vectors are used in a probabilistic relaxation labeling on the tokens, to identify the interior and the border regions of the textures. The algorithm has successfully segmented binary <b>images</b> containing <b>textures</b> whose primitives have identical second-order statistics and anumber of gray level <b>texture</b> <b>images.</b> ...|$|R
40|$|Second-order {{statistical}} <b>texture</b> <b>image</b> {{is regarded}} as one of useful images which can be produced from original data images, and wavelet scheme is also multi-resolution image analysis, as one of current issues in remote sensing <b>image</b> processing. Though <b>texture</b> <b>image</b> and wavelet decomposed image can be applied for remote sensing image, there are rare cases in quantitative interpretation with the combined images. In this study, we attempted the classification application of <b>texture</b> <b>image</b> in wavelet scheme; in other words, this was concerned classification of wavelet-based <b>texture</b> <b>image.</b> Our approach consists in several cases: conventional multispectral classification with original image sets, classification with <b>texture</b> <b>images,</b> and classification with wavelet-based <b>texture</b> <b>image.</b> In addition, we studied different types of texture parameters and wavelet basis functions, considering the affect of classification accuracy. In conclusion, it is thought that we can provide some criteria to choose appropriate wavelet basis function and texture parameter in classification. KEY WORDS: wavelet-based texture fusion imagery, classification accuracy 1...|$|R
