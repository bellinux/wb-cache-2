54|17|Public
2500|$|... "Attorney-Client Privilege: Implied Waiver through <b>Inadvertent</b> <b>Disclosure</b> of *Documents," [...] University of Miami Law Review (1985) ...|$|E
50|$|The Breach {{notification}} {{law in the}} EU provides better privacy safeguards {{with fewer}} exemptions, unlike the US law which exempts unintentional acquisition, access, or use of protected health information and <b>inadvertent</b> <b>disclosure</b> under a good faith belief.|$|E
5000|$|On the {{application}} layer, the HAG runs an [...] "evaluated mandatory integrity policy" [...] that provides sensitive files, data and applications protection from <b>inadvertent</b> <b>disclosure.</b> At {{the operating system}} level, the HAG must have a multi-level kernel that ensures sensitive information, processes, and devices stored and running on the system at different sensitivity levels cannot intermingle {{in violation of the}} system's mandatory security model.|$|E
40|$|Abstract. Confidential data hemorrhaging from health-care {{providers}} pose financial risks to firms and medical risks to patients. We examine {{the consequences of}} data hemorrhages including privacy violations, medical fraud, financial identity theft, and medical identity theft. We also examine the types and sources of data hemorrhages, focusing on <b>inadvertent</b> <b>disclosures.</b> Through an analysis of leaked files, we examine data hemorrhages stemming from <b>inadvertent</b> <b>disclosures</b> on internet-based file sharing networks. We characterize the security risk {{for a group of}} health-care organizations using a direct analysis of leaked files. These files contained highly sensitive medical and personal information that could be maliciously exploited by criminals seeking to commit medical and financial identity theft. We also present evidence of the threat by examining user-issued searches. Our analysis demonstrates both the substantial threat and vulnerability for the health-care sector and the unique complexity exhibited by the US health-care system. Keywords: Health-care information, identity theft, data leaks, security. ...|$|R
5000|$|... {{promotes}} <b>inadvertent</b> unconscious <b>disclosure,</b> {{even while}} the client is not compelled to discuss therapeutic issues verbally, which might leave him vulnerable ...|$|R
40|$|We live in {{exciting}} times; {{technology is}} evolving quickly. The legal profession, however, {{has a history}} of begrudging and delayed acceptance of new technology. Attorneys may be slow to learn new tricks, {{but when it comes to}} metadata, the usual reactionary behavior could be harmful to clients. It is imperative that attorneys understand the ethical and evidentiary issues that arise when metadata is disclosed, mishandled, discovered, or destroyed. This paper explores these issues and recommends best practices to avoid <b>inadvertent</b> <b>disclosures</b> and ethical violations. The structure of this paper is as follows: first, metadata is defined and explained. Second, I will explain potential harm that metadata can cause. Third, issues of confidentiality, attorney-client privilege will be explored. Fourth, I will explore some of the evidentiary concerns regarding discovery and destruction of metadata. Finally, the conclusion will recommend best practices for new and experienced attorneys to avoid metadata missteps and manage metadata with confidence...|$|R
5000|$|Data {{remanence}} is {{the residual}} representation of digital data that remains even after {{attempts have been}} made to remove or erase the data. This residue may result from data being left intact by a nominal file deletion operation, by reformatting of storage media that does not remove data previously written to the media, or through physical properties of the storage media that allow previously written data to be recovered. Data remanence may make <b>inadvertent</b> <b>disclosure</b> of sensitive information possible should the storage media be released into an uncontrolled environment (e.g., thrown in the trash or lost).|$|E
5000|$|Disposal {{of records}} {{does not always}} mean [...] It can also include {{transfer}} to a historical archive, museum, or private individual. Destruction of records ought to be authorized by law, statute, regulation, or operating procedure, and the records should be disposed of with care to avoid <b>inadvertent</b> <b>disclosure</b> of information. The process needs to be well-documented, starting with a records retention schedule and policies and procedures that have been approved at the highest level. An inventory of the records disposed of should be maintained, including certification {{that they have been}} destroyed. Records should never simply be discarded as refuse. Most organizations use processes including pulverization, paper shredding or incineration.|$|E
5000|$|By 2010, the leaked {{documents}} {{state that}} the NSA had developed [...] "groundbreaking capabilities" [...] against encrypted Internet traffic. A GCHQ document warned however [...] "These capabilities are among the SIGINT community's most fragile, and the <b>inadvertent</b> <b>disclosure</b> of the simple 'fact of' could alert the adversary and result in immediate loss of the capability." [...] Another internal document stated that [...] "there will be NO 'need to know.'" [...] Several experts, including Bruce Schneier and Christopher Soghoian, have speculated that a successful attack against RC4, an encryption algorithm still used in at least 50 percent of all SSL/TLS traffic, is a plausible avenue, given several publicly known weaknesses of RC4. Others have speculated that NSA has gained ability to crack 1024-bit RSA/DH keys.|$|E
40|$|With {{the rise}} of Internet connectivity, new forms of {{communication}} and social interaction have emerged. Simple yet powerful applications such as Online Social Networks (OSNs) enable individuals to engage with unlimited audiences. While a leap forward in terms of individual empowerment, these new forms of communication also {{have the potential to}} adversely affect individuals’ privacy. <b>Inadvertent</b> <b>disclosures,</b> breaches of confidence and reputational damage are but a few examples of social networking gone wrong. At the same time, OSN providers continue to amass unprecedented amounts of data about their users. Collected data include not only data actively provided by OSN users, but also data concerning their browsing activities outside the OSN context (“tracking data”). This report reflects on how the current legal framework performs in the context of Online Social Networks. Specifically, it seeks to (1) evaluate whether the current legal framework {{can be applied to the}} OSN context in a meaningful fashion; (2) identify problematic areas (e. g., areas with high degrees of legal uncertainty or unintended consequences); and (3) suggest potential ways forward. status: publishe...|$|R
40|$|Would-be infringers target {{university}} patents because faculty inventors {{are more}} likely to make <b>inadvertent</b> <b>disclosures</b> than industrial inventors, possibly because of the importance of quick disclosure and publishing in academic science. In Klopfenstein, the Federal Circuit held that the posting of lecture slides after a talk triggered the printed publication bar of the patent statute. First, I argue (contrary to other commentators) that the Federal Circuit is consistent with prior precedent; that the public accessibility and dissemination inquiries should rest on substance rather than form. The focus of the § 102 (b) inquiry remains on the inventor, who should lose the right to patent his invention if he makes a public disclosure. Klopfenstein possibly shows that the Federal Circuit will interpret the statute in light of advances in technology. Second, I argue that Klopfenstein is wholly consistent with the policies behind both the printed publication bar and the patent laws generally. Third, I argue that Congress need not amend the patent laws to protect university inventors; rather the solution to the publish-patent tension lies in the university's proper management of technology...|$|R
40|$|ITAR {{due to its}} {{pervasive}} scope, and {{the provisions}} on “intangible technology transfers”, not yet proclaimed, which essentially force a priori approval from the regulators for nearly all activities involving any disclosures. The lack of proper exemptions for open source materials, and severe criminal penalties for even <b>inadvertent</b> <b>disclosures,</b> with the onus of proof reversed, remove the historically accepted hard boundaries between classified/controlled information, and open source information. As the DTCA 2012 is now active in the defence industry, and producing initial impacts, careful consideration of these is warranted, as similar impacts will arise once the legislation becomes fully active across the higher education sector, and {{other areas of the}} Australian community working with technology deemed to fall under the dual use category. Major risks which an SME or consultant must consider include the arbitrary denial of licences; the arbitrary suspension or withdrawal of licences; the arbitrary censorship of disclosures to a client; weak regulatory agency protection for IP produced for a client; weak protection for client background IP being used; weak mechanisms for resolving disputes or differences with the regulator; and the possibility of vexatious investigations or prosecutions being initiated over matter...|$|R
5000|$|There {{has been}} a {{transformation}} in the approach to information exchange after the 9/11. The traditionalist [...] "need to know" [...] approach was more careful about spreading security information. It was believed that the risks of <b>inadvertent</b> <b>disclosure</b> of information outweighed the benefits of wider sharing. However, such assumption was {{proven to be a}} mistake after the 9/11, where it edified intellects and public that it is essential for the right people to have the right information at the right time in order to prevent themselves from tragic impacts on the environment, society and economy. So, adopting a [...] "need to share" [...] approach achieves a much better balance between the risk of unintended disclosure and the risk of failing to share information that could help to circumvent a threat or such event. So the organization now relies on fluent and clear communications about effective nuclear security within the organization and between organizations and any other public body.|$|E
5000|$|By 2010, the NSA had {{developed}} “groundbreaking capabilities” against encrypted Internet traffic. A GCHQ document warned however “These capabilities {{are among the}} Sigint community’s most fragile, and the <b>inadvertent</b> <b>disclosure</b> of the simple ‘fact of’ could alert the adversary and result in immediate loss of the capability.” Another internal document stated that “there will be NO ‘need to know.’” Several experts, including Bruce Schneier and Christopher Soghoian, have speculated that a successful attack against RC4, a 1987 encryption algorithm still used in at least 50 per cent of all SSL/TLS traffic is a plausible avenue, given several publicly known weaknesses of RC4. Others have speculated that NSA has gained ability to crack 1024-bit RSA and Diffie-Hellman public keys. A team of researchers {{have pointed out that}} there is wide reuse of a few non-ephemeral 1024 bit primes in Diffie-Hellman implementations, and that NSA having done precomputation against those primes in order to break encryption using them in real time is very plausibly what NSA's [...] "groundbreaking capabilities" [...] refer to.|$|E
5000|$|In his 2012 {{campaign}} for re-election against Democrat Dan Lamb, television stations WUTR in Utica and WSYR in Syracuse announced they would jointly air a debate between Hanna and Lamb. Hanna declined to participate, citing another scheduled televised debate and five {{that would not}} be televised. The stations said that if Hanna did not appear, they would air a 30-minute question-and-answer session with Lamb. According to Steve Merren, the {{vice president and general manager}} of WUTR's parent company, Nexstar Broadcasting Group, Hanna then contacted Merren. In an email to staff, Merren stated, [...] "He indicated to me that we would not be considered for his ad dollars and our level of cooperation in the future could be affected." [...] Merren then directed that WUTR not go ahead with the broadcast. Both Merren and a Hanna spokeswoman denied that threats had been made. After the <b>inadvertent</b> <b>disclosure</b> of the internal email, Merren told the press that Hanna “did not say he would pull his ad dollars." [...] The Hanna campaign said that his conversation with Merren had been [...] "nothing more than a courtesy call". The Lamb campaign said that Hanna was [...] "using his money to influence the journalistic decisions of a local news agency." ...|$|E
5000|$|An OPSEC Assessment is {{the formal}} {{application}} of this process to an existing operation or activity by a multidisciplinary team of experts. These assessments identify the requirements for additional OPSEC measures and required changes to existing ones. Additionally, OPSEC planners, working closely with Public Affairs personnel, must develop the Essential Elements of Friendly Information (EEFI) used to preclude <b>inadvertent</b> public <b>disclosure</b> of critical or sensitive information. The term [...] "EEFI" [...] is being phased {{out in favor of}} [...] "Critical Information," [...] so all affected agencies use the same term, minimizing confusion.|$|R
40|$|Abstract — Hemorrhages of {{confidential}} patient health data create {{privacy and}} security concerns. While the US HIPAA legislation on privacy and security {{went into effect}} over five years ago, healthcare information security remains a significant concern as organizations migrate to electronic health records. The recent HITECH legislation aimed at accelerating this migration contained mandates for greater security, including the addition of new requirements on breach reporting. We examine a recently collected sample of inadvertently disclosed files found on internet-based file-sharing networks. We characterize the security risk of these files and also present evidence of the threat by analyzing user-issued searches. Our analysis indicates that the threat and vulnerability for the healthcare sector continued, even as HITECH became effective. Keywords-Healtcare information, data leaks, security <b>Inadvertent</b> <b>disclosures</b> of private customer information have occurred in nearly every industry from banking to healthcare. Such leaks directly impact customers through embarrassment, fraud, and identify theft. In the healthcare sector, data hemorrhages have multiple consequences [1]. In some cases, the losses translate to privacy violations and social stigma. In other cases, criminals exploit the information to commit fraud or medical identity theft. The fragmented nature of the US healthcare system results in data hemorrhages from many different sources including acute-care hospitals, physician groups, ambulatory healthcare providers, medical laboratories, insurance carriers, back-offices of health maintenance organizations, and outsourced service providers such as billing, collection, and transcription firms. In this paper, we examine the recent Health Information Technology for Economic and Clinical Health (HITECH) legislation and its potential impact on the security of protected health information (PHI). HITECH was enacted a...|$|R
40|$|The paper {{discusses}} how {{a statistical}} office could strike a satisfactory balance between confidentiality protection {{and freedom of}} information. Flexible use of statistical data is of vital interest for researchers and for the democratic process. On the other hand, the willingness of respondents to provide data {{is dependent on the}} ability of the statistical office to guarantee their anonymity. The paper argues that a combination of measures of different kinds are needed: legal, administrative, methodological, and technical. As long as statistical data are at all collected and statistical results are published, the risks of <b>inadvertent</b> <b>disclosures</b> of information about identifiable individuals (persons or enterprises) cannot be completely eliminated. On the other hand, the motivation {{to spend a lot of}} efforts to break through protection measures is usually low, especially if such efforts are regarded as criminal and can be punished. Moreover, there are often easier ways to find out sensitive information about individuals than by means of malicious processing of statistical data. The paper presents two new ideas that are being launched and discussed in Sweden right now: (i) the idea of transforming commonly known identifiers (of persons and other objects) into pseudoidentifiers by means of a table or an algorithm that is known only by the statistical office; (ii) the idea of a statistical firewall, which filters the queries from users of statistical data as well as the statistical outputs resulting from these queries, thus monitoring the traffic between external users and internal databases containing sensitive statistical microdata. It is discussed in the paper how these two ideas can be used in practice, increasing legitimate usage and improving confidentiality protecti [...] ...|$|R
40|$|Abstract: <b>Inadvertent</b> <b>disclosure</b> of {{sensitive}} business information represents one the largest classes of recent security breaches. We examine a specific instance {{of this problem}} – inadvertent disclosures through peer-to-peer file sharing networks. We characterize {{the extent of the}} security problem for a group of large financial institutions using a direct analysis of leaked documents. We also characterize the threat of loss by examining search patterns in peer-topeer networks. Our analysis demonstrates both a substantial threat and vulnerability for large financial firms. We find a statistically significant link between leakage and firm employment base. Key Words: <b>inadvertent</b> <b>disclosure,</b> intellectual property leaks, data breaches, security, risk management, peer-to-peer networks, file sharing...|$|E
40|$|This Article {{suggests}} that fostering {{the development of}} attorney responsibility should be the central goal in addressing {{the issues raised by}} the <b>inadvertent</b> <b>disclosure.</b> Deciding the waiver issue by concentrating on attorney responsibility will help prevent inadvertent disclosures (and resultant waivers) by impressing upon the attorney the need to take care to avoid them. When disclosures inadvertently occur, the amount of precautions the attorney took (albeit unsuccessfully) should determine whether the privilege is waived. Placing the onus of precautions against <b>inadvertent</b> <b>disclosure</b> on the attorney is not only beneficial to the client, but also aids the profession, and the overall administration of justice. These systemic goals underlie the doctrines of privilege and waiver. American courts use three different tests to evaluate whether <b>inadvertent</b> <b>disclosure</b> waives the attorney-client privilege. All three tests use intent as the basis of a waiver, but each uses a different measurement of intent. The traditional test focuses solely on the act of disclosure, deeming it representative of the client 2 ̆ 7 s intent to waive his privilege. The subjective intent test is premised on the client 2 ̆ 7 s actual desire to waive the privilege; it therefore holds that an <b>inadvertent</b> <b>disclosure</b> never amounts to a waiver. The reasonable precautions test measures intent to waive by the precautions taken to prevent <b>inadvertent</b> <b>disclosure.</b> This Article focuses on the attorney 2 ̆ 7 s legal and ethical responsibilities to the client and analyzes the three tests of waiver the courts use in terms of their impact on promoting attorney responsibility. Part One describes the current case law governing <b>inadvertent</b> <b>disclosure.</b> It also describes the American Bar Association 2 ̆ 7 s (ABA) first formal ethical opinion on inadvertently disclosed information that appears to advocate a variation of the subjective intent test by creating a presumption against waiver that must be overcome by the receiving attorney. The opinion takes this position by stressing the forwarding attorney 2 ̆ 7 s property rights in the documents. Part Two discusses the attorney-client privilege and its analytic counterpart, the ethical duty of maintaining confidentiality, identifies the goals of each and the tension that has developed between them, and how they may be reconciled. Part Three analyzes each test from an attorney-responsibility perspective and concludes that the reasonable-precautions test best serves the client 2 ̆ 7 s interests, and therefore has systemic benefits, by properly forcing the attorney to bear the risks of <b>inadvertent</b> <b>disclosure.</b> It reconciles the ABA opinion with this conclusion by making two suggestions. First, to the extent that one views the ABA opinion as adopting the subjective intent test, the opinion should be limited to its facts [...] the instance of a single, errant disclosure, rather than applying it to the far more common occurrence of the inadvertent disclosures taking place within a complex litigation with massive document productions. Second, the Article demonstrates that the ABA opinion, with its emphasis on property rights, in fact, endorses a reasonable precautions test...|$|E
40|$|Waiver of the attorney-client {{privilege}} due to <b>inadvertent</b> <b>disclosure</b> {{is an important}} issue that courts and litigants have grappled with for a long time. With electronic discovery becoming increasingly common, and with electronic privilege reviews replacing paper reviews, the issue takes on greater importance. The risk of inadvertently disclosing privileged or protected information is heightened in electronic discovery because of the very nature of electronic information. For example, although a party makes an effort to segregate and delete privileged information from a computer drive prior to producing the electronic documents to the opposing party, the deleted files may still be present within a larger folder structure. A document may be inadvertently produced {{as a result of an}} electronic document break error. And as the use of electronic discovery consultants and other vendors increases, litigants face an increased risk of <b>inadvertent</b> <b>disclosure</b> due to errors made by vendors...|$|E
40|$|The NCHS Staff Manual on Confidentiality was {{originally}} published in July 1978 and reprinted in April 1980 and in August 1997. It was reissued in earlier years mainly to inform staff of changes in laws and regulations. In view of the many changes in technologies related to data handling and dissemination {{that have taken place}} in recent years, new procedures and policies have been developed requiring an extensive revision of the Manual. The confidentiality of records is a matter of primary concern to the National Center for Health Statistics (NCHS). In order to elicit health information from the American people and from the health care providers through our surveys, we must be able to assure them that this information will be protected from the eyes and ears of all unauthorized persons. This means that we must have strong laws enabling us to protect these records, and that we must establish and follow procedures to give them such protection. This Manual states the Center's policies that implement Federal law and ensure that all confidential information will be fully protected. It should be viewed in unison with the NCHS data release policies addressing access to data and NCHS Research Ethics Review Board Requirements. The NCHS Director retains the authority to allow exceptions to policies contained in this manual where there are unique or special circumstances. " - p. [ii]Foreword [...] 1. Introduction [...] [...] 2. Legislative and Regulatory Background [...] 2. 1. Section 308 (d) of the Public Health Service Act [...] 2. 2. Privacy Act of 1974 [...] 2. 3. Confidential Information Protection and Statistical Efficiency Act [...] 2. 4. Freedom of Information Act [...] 2. 5. Federal law governing federal employees' behavior [...] [...] 3. Definitions [...] [...] 4. Employee Responsibilities [...] 4. 1. Division and office directors [...] 4. 2. Confidentiality officer [...] 4. 3. Supervisors' responsibilities [...] 4. 4. Individual federal employee's responsibilities [...] 4. 5. Contractors' and agents' responsibilities [...] 4. 6. Collaborator's responsibilities [...] 4. 7. Administrative officer's responsibilities [...] [...] 5. NCHS Policies on Consent and Assurances of Confidentiality [...] 5. 1. Consent [...] 5. 2. Assurances of confidentiality [...] 5. 3. Responsibility for formal assurances of confidentiality [...] 5. 4. Data collected directly from individuals or establishments [...] 5. 5. Data collected from another organization [...] 5. 6. Data collected over the telephone [...] 5. 7. Repository of assurances [...] [...] 6. Treatment of Requests for Information under Freedom of Information Act [...] [...] 7. The Protection of Confidential Records and Data Systems [...] 7. 1. Physical protection of confidential records [...] 7. 2. Automated data processing systems security general [...] [...] 8. Authorized Disclosures [...] [...] 8. 1. Disclosure to the Parent Locator Service [...] 8. 2. Disclosures permitted by Section 308 (d) of the Public Health Service Act [...] 8. 3. Disclosures within NCHS [...] 8. 4. Disclosures within the department [...] 8. 5 transfers of data to other departments of the federal government [...] 8. 6. Special cooperative or contractual arrangements [...] [...] 9. Avoiding <b>Inadvertent</b> <b>Disclosures</b> Through Release of Microdata [...] 9. 1. Problem [...] 9. 2. Rule [...] 9. 3 Restricted access to microdata files with identifiable data [...] [...] [...] [...] 10. Avoiding <b>Inadvertent</b> <b>Disclosures</b> in Published Tabular Data [...] 10. 1. Types of disclosure [...] 10. 2. Problem [...] 10. 3. Special guidelines for avoiding disclosure [...] 10. 4. Evaluating a disclosure problem [...] 10. 5. Measures to avoid disclosure [...] [...] 11. Avoiding Disclosure in Other Types of Published Information [...] [...] Appendix A. Requirements relating to confidentiality and privacy in data collection and data processing contracts [...] Appendix B. NCHS nondisclosure affidavit for federal employees [...] Appendix C. NCHS nondisclosure affidavit for contractors [...] Appendix D. Confidentiality, security, and related contact personsMode of access: Internet from CDC web site. Address as of 7 / 17 / 06 : [URL] current access available via PURL...|$|R
30|$|Electronic Health Record (EHR) {{systems are}} the {{aggregate}} electronic record of health-related information on individuals “created and gathered cumulatively across {{more than one}} health care organization and managed and consulted by licensed clinicians and staff involved in the individual’s health and care” (National Alliance for Health Information Technology (NAHITa) [1]. EHR has been strongly recommended for adoption in the healthcare industry in the U.S. The increased use of EHR systems has assisted health care professionals in medical practices by storing patients’ medical and diagnosis information, exchanging laboratory reports and radiologic images, and also providing decision support tools for the physicians and communication methods with patients [2, 3]. The American Recovery and Reinvestment Act of 2009 (ARRA)’s goal was to computerize all Americans health records by 2014 by dedicating nineteen billion dollars to the promotion of health information technology [4, 5]. However, EHR systems also bring new liability and litigation risks such as the inappropriate use of the systems, privacy breaches, and <b>inadvertent</b> data <b>disclosures,</b> which in turn may impose heavy costs in terms of preservation of electronic information and potential litigation issues [6].|$|R
40|$|In {{their first}} twenty years (1975 - 1995), {{the federal rules}} of {{evidence}} changed little. However, changes have accelerated since 1993, with creation of the Evidence Rules Advisory Committee which meets regularly and proposes changes to the rules almost every year. One change, which grew out of the work of a special committee, was the addition of an entirely new provision, Rule 502, which governs waiver of attorney-client privilege. This rule became law in 2008 through congressional enactment (privilege rules must be passed by Congress in order to take effect). Sections 5 : 34 discusses this new provision. Under 2 ̆ 2 Privileges: Rule 501, 2 ̆ 2 section 5 : 34 discusses waiver by <b>inadvertent</b> or involuntary <b>disclosure...</b>|$|R
40|$|Abstract. Security {{is likely}} {{becoming}} {{a critical factor}} in the future adoption of provenance technology, because of the risk of <b>inadvertent</b> <b>disclosure</b> of sensitive information. In this survey paper we review {{the state of the art}} in secure prove-nance, considering mechanisms for controlling access, and the extent to which these mechanisms preserve provenance integrity. We examine seven systems or approaches, comparing features and identifying areas for future work. ...|$|E
40|$|It is {{customary}} {{for statistical}} agencies to audit tables containing suppressed cells {{to ensure that}} there is sufficient protection against <b>inadvertent</b> <b>disclosure</b> of sensitive information. If the table contains rounded values, this fact may be ignored by the audit procedure. This oversight can result in over-protection, reducing the utility of the published data. In this paper, we provide a correct auditing formulation, and give examples of over-protection. KEY WORDS: Cell Suppression, Rounding, Confidentiality. 1...|$|E
40|$|Security {{is likely}} {{becoming}} {{a critical factor}} in the future adoption of provenance technology, because of the risk of <b>inadvertent</b> <b>disclosure</b> of sensitive information. In this survey paper we review {{the state of the art}} in secure provenance, considering mechanisms for controlling access, and the extent to which these mechanisms preserve provenance integrity. We examine seven systems or approaches, comparing features and identifying areas for future work. Comment: To appear, IPAW 201...|$|E
40|$|Objective. To improve PMTCT and antenatal care-related service delivery, a {{pack with}} {{centrally}} prepackaged medicine was rolled {{out to all}} pregnant women in Lesotho in 2011. This study assessed acceptability and feasibility of this copackaging mechanism for drug delivery among pregnant and postpartum women. Methods. Acceptability and feasibility were assessed in a mixed method, cross-sectional study through structured interviews (SI) and semistructured interviews (SSI) conducted in 2012 and 2013. Results. 290 HIV-negative women and 437 HIV-positive women (n= 727) participated. Nearly all SI participants found prepackaged medicines acceptable, though modifications such as size reduction of the pack were suggested. Positive experiences included that the pack helped women take pills as instructed and contents promoted healthy pregnancies. Negative experiences included <b>inadvertent</b> pregnancy <b>disclosure</b> and discomfort carrying the pack in communities. Implementation was also feasible; 85. 2 % of SI participants reported adequate counseling time, though 37. 8 % felt pack use caused clinic delays. SSI participants reported improvement in service quality following pack introduction, due to more comprehensive counseling. Conclusions. A prepackaged drug delivery mechanism for ANC/PMTCT medicines was acceptable and feasible. Findings support continued use of this approach in Lesotho with improved design modifications to reflect the current PMTCT program of lifelong treatment for all HIV-positive pregnant women...|$|R
40|$|The {{values of}} data {{elements}} stored in biomedical databases often draw from biomedical ontologies. Authorization rules {{can be defined}} on these ontologies to control access to sensitive and private data elements in such databases. Authorization rules may be specified by different authorities at different times for various purposes, and as such policy rules may conflict with each other, inadvertently allowing access to sensitive information. Detecting policy conflicts is nontrivial because it involves identification of applicable rules and detecting conflicts among them dynamically during execution of data access requests. It also requires dynamically verifying conformance with required policies and logging relevant information about decisions for audit. Another problem in biomedical data protection is inference attacks, in which a user who has legitimate access to some data elements is able to infer information related to other data elements. This type of <b>inadvertent</b> data <b>disclosure</b> should be prevented by ensuring policy consistency; that is, data elements {{which can lead to}} inference about other data elements should be protected by the same level of authorization policies as the other data elements. We propose two strategies; one for detecting policy consistencies to avoid potential inference attacks and the other for detecting policy conflicts. We have implemented these algorithms in Java language and evaluated their execution times experimentally...|$|R
40|$|Abstract—The {{values of}} data {{elements}} stored in biomedical databases often draw from biomedical ontologies. Authorization rules {{can be defined}} on these ontologies to control access to sensitive and private data elements in such databases. Authorization rules may be specified by different authorities at different times for various purposes, and as such policy rules may conflict with each other, inadvertently allowing access to sensitive information. Detecting policy conflicts is nontrivial because it involves identification of applicable rules and detecting conflicts among them dynamically during execution of data access requests. It also requires dynamically verifying conformance with required policies and logging relevant information about decisions for audit. Another problem in biomedical data protection is inference attacks, in which a user who has legitimate access to some data elements is able to infer information related to other data elements. This type of <b>inadvertent</b> data <b>disclosure</b> should be prevented by ensuring policy consistency; that is, data elements {{which can lead to}} inference about other data elements should be protected by the same level of authorization policies as the other data elements. We propose two strategies; one for detecting policy consistencies to avoid potential inference attacks and the other for detecting policy conflicts. We have implemented these algorithms in Java language and evaluated their execution times experimentally. Keywords-Authorization policy, Biomedical ontology, Inference attacks, Policy conflicts...|$|R
40|$|Objective: There {{has been}} a {{consistent}} concern about the <b>inadvertent</b> <b>disclosure</b> of personal information through peer-to-peer file sharing applications, such as Limewire and Morpheus. Examples of personal health and financial information being exposed have been published. We wanted to estimate {{the extent to which}} personal health information (PHI) is being disclosed in this way, and compare that to the extent of disclosure of personal financial information (PFI). Design: After careful review and approval of our protocol by our institutional research ethics board, files were downloaded from peer-to-peer file sharing networks and manually analyzed for the presence of PHI and PFI. The geographic region of the IP addresses was determined, and classified as either USA or Canada. Measurement: We estimated the proportion of files that contain personal health and financial information for each region. We also estimated the proportion of search terms that return files with personal health and financial information. We ascertained and discuss the ethical issues related to this study. Results: Approximately 0. 4 % of Canadian IP addresses had PHI, as did 0. 5 % of US IP addresses. There was more disclosure of financial information, at 1. 7 % of Canadian IP addresses and 4. 7 % of US IP addresses. An analysis of search terms used in these file sharing networks showed that {{a small percentage of the}} terms would return PHI and PFI files (ie, there are people successfully searching for PFI and PHI on the peer-to-peer file sharing networks). Conclusion: There is a real risk of <b>inadvertent</b> <b>disclosure</b> of PHI through peer-to-peer file sharing networks, although the risk is not as large as for PFI. Anyone keeping PHI on their computers should avoid installing file sharing applications on their computers, or if they have to use such tools, actively manage the risks of <b>inadvertent</b> <b>disclosure</b> of their, their family's, their clients', or patients' PHI...|$|E
40|$|Ethical and evidentiary rules {{governing}} {{the disclosure of}} confidential information are interrelated in many respects. Nevertheless, these rules are generally developed independently through different legal channels. Different approaches to the <b>inadvertent</b> <b>disclosure</b> of confidential information have emerged, leading to uncertain results in different jurisdictions. Uncertainty persists with regard to metadata available from electronic document formats. This paper explores {{the tension between the}} competing approaches this emerging problem. It argues that ethical and evidentiary principles addressing the protection and discovery of metadata should be coordinated in order to avoid creating incentives to maximize litigation costs...|$|E
40|$|Stigmatization and {{discrimination}} are common consequences following disclosure of HIV serostatus; such factors are especially problematic {{in rural communities}} where “everyone knows everyone”. In this case study, researchers conducting ethnographic field studies in remote areas of Brazil decided to impersonate friends or relatives of research participants living with HIV {{as a means to}} protect participants from <b>inadvertent</b> <b>disclosure</b> of their serostatus to fellow community members. These acts of “wilful deception” raise issues about honesty and integrity in research, and how to balance issues of confidentiality with communicating research findings to communities and the broader public...|$|E
40|$|RESIN {{is a new}} {{language}} runtime that helps prevent security vulnerabilities, by allowing programmers to specify application-level data flow assertions. RESIN provides policy objects, which programmers use to specify assertion code and metadata; data tracking, which allows programmers to associate assertions with application data, and {{to keep track of}} assertions as the data flow through the application; and filter objects, which programmers use to define data flow boundaries at which assertions are checked. RESIN’s runtime checks data flow assertions by propagating policy objects along with data, as that data moves through the application, and then invoking filter objects when data crosses a data flow boundary, such as when writing data to the network or a file. Using RESIN, Web application programmers can prevent a range of problems, from SQL injection and crosssite scripting, to <b>inadvertent</b> password <b>disclosure</b> and missing access control checks. Adding a RESIN assertion to an application requires few changes to the existing application code, and an assertion can reuse existing code and data structures. For instance, 23 lines of code detect and prevent three previously-unknown missing access control vulnerabilities in phpBB, a popular Web forum application. Other assertions comprising tens of lines of code prevent a range of vulnerabilities in Python and PHP applications. A prototype of RESIN incurs a 33 % CPU overhead running the HotCRP conference management application. ...|$|R
40|$|Purpose – There is {{conjecture}} {{that small}} and mid-cap companies in highly speculative industries use frequent and repetitive disclosure to promote price volatility and heighten market interest. Excessive disclosure could indicate instances of self-promotion or poor disclosure practices, and these habits could mislead investors. The {{purpose of this}} paper is to quantitatively investigate the impact of firm disclosure on price volatility in the Australian stock market. Design/methodology/approach – This paper considers the effect of information disclosure on the daily stock price volatility of 340 Metals & Mining industry entities listed on the Australian Securities Exchange over the period 2005 - 2007 using regression analysis. Findings – The results indicate the number of disclosures, the number of price and non-price sensitive disclosures and the number of disclosures by category has a significant influence on daily price volatility. Moreover, the volatility impact of disclosure is greater for small and mid-sized firms than large firms. Research limitations/implications – Price volatility is calculated using daily data; intra-day stock prices could provide measures that are more accurate. There is also no attempt to allow for asymmetry in disclosure; categorizing news as “good” or “bad” would allow better insights. Practical implications – There is support for the conjecture that disclosure could serve as a self-promotion tool through fabricated and repetitive announcements. <b>Inadvertent</b> poor <b>disclosure</b> practice could also result in excessive price volatility. Disclosure practice requires ongoing consideration by regulatory bodies. Originality/value – This analysis complements basic work by the Australian regulator to establish a quantitative link between disclosure practice and price volatility. Australia, Disclosure, Information, Prices, Securities markets, Volatility...|$|R
40|$|Privacy, an {{everyday}} topic with weekly {{media coverage of}} loss of personal records, faces its bigger risk during the uncontrolled, involuntary or <b>inadvertent</b> <b>disclosure</b> and collection of personal and sensitive information. Preserving one's privacy while e-shopping, especially when personalisation is involved, is a big challenge. Current initiatives only offer customers opt-out options. This research proposes a `privacy-preserved' shopping environment (PPSE) which empowers customers to disclose information safely by facilitating a personalised e- shopping experience that protects their privacy. Evaluation delivered positive results which suggest that such a product would indeed have a market {{in a world where}} customers are increasingly concerned about their privacy. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
