3324|0|Public
25|$|Methods that {{evaluate}} only function values: If {{a problem}} is continuously differentiable, then gradients can be approximated using finite differences, in which case a <b>gradient-based</b> method can be used.|$|E
25|$|CAD {{is used in}} {{screening}} mammography (X-ray {{examination of}} the female breast). Screening mammography {{is used for the}} early detection of breast cancer. CAD systems are often utilized to help classify a tumor as malignant or benign. CAD is especially established in US and the Netherlands and is used in addition to human evaluation, usually by a radiologist. The first CAD system for mammography was developed in a research project at the University of Chicago. Today it is commercially offered by iCAD and Hologic. There are currently some non-commercial projects being developed, such as Ashita Project, a <b>gradient-based</b> screening software by Alan Hshieh, as well. However, while achieving high sensitivities, CAD systems tend to have very low specificity and the benefits of using CAD remain uncertain. Some studies suggest a positive impact on mammography screening programs, but others show no improvement. A 2008 systematic review on computer-aided detection in screening mammography concluded that CAD does not {{have a significant effect on}} cancer detection rate, but does undesirably increase recall rate (i.e. the rate of false positives). However, it noted considerable heterogeneity in the impact on recall rate across studies.|$|E
5000|$|Stan {{implements}} <b>gradient-based</b> Markov chain Monte Carlo (MCMC) algorithms for Bayesian inference, stochastic, <b>gradient-based</b> variational Bayesian {{methods for}} approximate Bayesian inference, and <b>gradient-based</b> optimization for penalized maximum likelihood estimation.|$|E
50|$|PyMC3 {{implements}} non-gradient-based and <b>gradient-based</b> Markov chain Monte Carlo (MCMC) algorithms for Bayesian inference and stochastic, <b>gradient-based</b> variational Bayesian {{methods for}} approximate Bayesian inference.|$|E
5000|$|<b>Gradient-based</b> error-diffusion {{dithering}} {{was developed}} recently [...] {{to remove the}} structural artifact produced in the original FS algorithm by a modulated randomization, and to enhance the structures by a <b>gradient-based</b> diffusion modulation.|$|E
5000|$|Continuously {{differentiable}} - This {{property is}} necessary for enabling <b>gradient-based</b> optimization methods. The binary step activation function is not differentiable at 0, and it differentiates to 0 for all other values, so <b>gradient-based</b> methods can make no progress with it.|$|E
5000|$|<b>Gradient-Based</b> History Matching with Optimal Parameterization ...|$|E
5000|$|Backpropagation can be {{used with}} any <b>gradient-based</b> optimizer, such as L-BFGS or {{truncated}} Newton.|$|E
5000|$|The {{optimization}} procedure. Either continuous or discrete optimization is performed. For continuous optimization, <b>gradient-based</b> optimization {{techniques are}} applied to improve the convergence speed.|$|E
5000|$|Intensively sampled landscape-based {{surveys in}} Australia {{provided}} a reference platform for developing and testing a less logistically demanding and yet statistically acceptable <b>gradient-based</b> survey design that avoided {{the need for}} random or purely grid-based sampling. These initial studies [...] and subsequently developed statistical support for purposive, <b>gradient-based</b> survey provided a formalized, practical alternative to more logistically demanding traditional designs. It was here the term gradsect was coined that coupled purposive, transect sampling with a hierarchical framework of environmental gradients considered to be key determinants of species distribution.|$|E
5000|$|Methods that {{evaluate}} only function values: If {{a problem}} is continuously differentiable, then gradients can be approximated using finite differences, in which case a <b>gradient-based</b> method can be used.|$|E
5000|$|Backpropagation {{through time}} (BPTT) is a <b>gradient-based</b> {{technique}} for training {{certain types of}} recurrent neural networks. It {{can be used to}} train Elman networks. The algorithm was independently derived by numerous researchers ...|$|E
50|$|Backpropagation Through Structure (BPTS) is a <b>gradient-based</b> {{technique}} for training recursive neural nets (a superset of recurrent neural nets) and is extensively {{described in a}} 1996 paper written by Christoph Goller and Andreas Küchler.|$|E
50|$|An {{alternative}} {{method is to}} search directly in (some subset of) the policy space, {{in which case the}} problem becomes a case of stochastic optimization. The two approaches available are <b>gradient-based</b> and gradient-free methods.|$|E
50|$|SmartDO {{uses the}} Direct Global Search {{methodology}} to achieve global optimization, including both <b>Gradient-Based</b> Nonlinear programming and Genetic Algorithm based stochastic programming. These two approaches {{can also be}} combined or mixed to solve specific problems.|$|E
5000|$|A gradient-related {{direction}} is usually {{encountered in the}} <b>gradient-based</b> iterative optimisation of a function [...] At each iteration [...] the current vector is [...] and we move in the direction , thus generating a sequence of directions.|$|E
5000|$|<b>Gradient-based</b> methods (policy {{gradient}} methods) {{start with}} a mapping from a finite-dimensional (parameter) space to the space of policies: given the parameter vector , let [...] denote the policy associated to [...] Defining the performance function by ...|$|E
50|$|The {{problem is}} {{normally}} solved using appropriate techniques {{from the field}} of optimization. These include <b>gradient-based</b> algorithms, population-based algorithms, or others. Very simple problems can sometimes be expressed linearly; in that case the techniques of linear programming are applicable.|$|E
50|$|There {{were two}} schools of {{structural}} optimization practitioners using <b>gradient-based</b> methods during the 1960s and 1970s: optimality criteria and mathematical programming. The optimality criteria school derived recursive formulas {{based on the}} Karush-Kuhn-Tucker (KKT) necessary conditions for an optimal design. The KKT conditions were applied to classes of structural problems such as minimum weight design with constraints on stresses, displacements, buckling, or frequencies Berke, Venkayya, Khot, et al. to derive resizing expressions particular to each class. The mathematical programming school employed classical <b>gradient-based</b> methods to structural optimization problems. The method of usable feasible directions, Rosen’s gradient projection (generalized reduce gradient) method, sequential unconstrained minimization techniques, sequential linear programming and eventually sequential quadratic programming methods were common choices. Schittkowski et al. reviewed the methods current by the early 1990s.|$|E
5000|$|Consider {{a region}} with N pixels. the <b>gradient-based</b> edge {{detector}} {{is applied to}} this region by producing two outputs for each pixel p: the gradient magnitude Mag(p) and the gradient direction Dir(p). The edgeness per unit area can be defined by [...] for some threshold T.|$|E
50|$|The {{adaptive}} coordinate descent method {{reaches the}} target value after only 325 function evaluations (about 70 {{times faster than}} coordinate descent), that is comparable to <b>gradient-based</b> methods. The algorithm has linear time complexity if update coordinate system every D iterations, it is also suitable for large-scale (D>>100) non-linear optimization.|$|E
50|$|If Yi are {{independent}} observations with corresponding values xi of the predictor variables, then θ {{can be estimated}} by maximum likelihood. The maximum-likelihood estimates lack a closed-form expression and must be found by numerical methods. The probability surface for maximum-likelihood Poisson regression is always concave, making Newton-Raphson or other <b>gradient-based</b> methods appropriate estimation techniques.|$|E
50|$|In statistics, {{generalized}} iterative scaling (GIS) {{and improved}} iterative scaling (IIS) are two early algorithms used to fit log-linear models, notably multinomial logistic regression (MaxEnt) classifiers and extensions of it such as MaxEnt Markov models and conditional random fields. These algorithms {{have been largely}} surpassed by <b>gradient-based</b> methods such as L-BFGS and coordinate descent algorithms.|$|E
5000|$|Optimus {{supports}} {{a range of}} single-objective and multi-objective methods. Multi-objective methods include NLPQL (<b>gradient-based</b> optimization algorithm) and NSEA+ (Non-dominant Sorting Evolution Algorithm). Multi-objective optimization methods usually generate a so-called „Pareto front“ or use a weighting function to generate a single Pareto point. Based on the search methods, Optimus optimization methods can be categorized into: ...|$|E
50|$|Evolutionary methods {{led the way}} in the {{exploration}} of non-gradient methods for MDO applications. They also have benefited from the availability of massively parallel high performance computers, since they inherently require many more function evaluations than <b>gradient-based</b> methods. Their primary benefit lies in their ability to handle discrete design variables and the potential to find globally optimal solutions.|$|E
5000|$|Range - When {{the range}} of the {{activation}} function is finite, <b>gradient-based</b> training methods tend to be more stable, because pattern presentations significantly affect only limited weights. When the range is infinite, training is generally more efficient because pattern presentations significantly affect most of the weights. In the latter case, smaller learning rates are typically necessary.|$|E
50|$|The {{fourth step}} is to {{implement}} the optimization method to identify parameters that minimize this function. In most cases, a <b>gradient-based</b> optimization strategy will be used. For nonlinear analysis, more specific methods like response surface modeling, particle swarm optimization, Monte Carlo optimization, and genetic algorithms can be used. Recently, finite element model updating has been conducted using Bayesian statistics which gives a probabilistic interpretation of model updating.|$|E
5000|$|Molecular and {{cellular}} mechanisms underlying {{the formation of}} retinotopic and visual feature maps: Baier contributed to the identification of <b>gradient-based</b> axon guidance mechanisms during development of the visual system. His group also discovered the role of Slit-Robo signaling in the precise targeting of layers in the optic tectum by ingrowing retinal axons. (Baier and Bonhoeffer, Science 1992; Gosse et al., Nature 2008; Xiao et al., Cell 2011) ...|$|E
50|$|Heydari {{attended}} Sharif University of Technology in Tehran {{and received}} his B.S. and M.S. degrees in Electrical Engineering in 1992 and 1995, respectively. He obtained his Ph.D. {{degree from the}} University of Southern California in 2001. In 1997, he worked at Bell-labs, Lucent Technologies on noise analysis in high-speed CMOS integrated circuits fields. In 1998 he worked at IBM T. J. Watson Research Center on <b>gradient-based</b> optimization and sensitivity analysis of custom analog/RF ICs.|$|E
5000|$|... where [...] {{denotes the}} local {{transformation}} from body segment [...] to its parent [...] Each joint {{in the body}} has 3 degrees of freedom (DoF) rotation. Given a transformation matrix [...] , the joint position at the T-pose can be transferred to its corresponding {{position in the world}} coordination. In many works, the 3D joint rotation is expressed as a normalized quaternion [...] due to its continuity that can facilitate <b>gradient-based</b> optimization in the parameter estimation.|$|E
50|$|The optimal {{variable}} subspace and approximation model {{found by}} a CoP/MOP procedure {{can also be}} used for a pre-optimization before global optimizers (evolutionary algorithms, Adaptive Response Surface Methods, <b>Gradient-based</b> methods, biological-based methods) are used for a direct single-objective optimization. After conducting a sensitivity analysis using MOP/CoP, also a multi-objective optimization can be performed to determine the optimization potential within opposing objectives and to derive suitable weighting factors for a following single-objective optimization. Finally this single-objective optimization determines an optimal design.|$|E
50|$|Also, no {{existing}} solution {{method is}} guaranteed to find the global optimum of a general problem (see No free lunch in search and optimization). <b>Gradient-based</b> methods find local optima with high reliability but are normally unable to escape a local optimum. Stochastic methods, like simulated annealing and genetic algorithms, will find a good solution with high probability, but very little {{can be said about}} the mathematical properties of the solution. It is not guaranteed to even be a local optimum. These methods often find a different design each time they are run.|$|E
50|$|RNNs {{are also}} related to {{artificial}} neural networks, which (like the random neural network) have <b>gradient-based</b> learning algorithms. The learning algorithm for an n-node random neural network that includes feedback loops (it is also a recurrent neural network) is of computational complexity O(n^3) (the number of computations {{is proportional to the}} cube of n, the number of neurons). The random neural network can also be used with other learning algorithms such as reinforcement learning. The RNN {{has been shown to be}} a universal approximator for bounded and continuous functions.|$|E
50|$|Simulated {{annealing}} {{is closely}} related to graduated optimization. Instead of smoothing the function over which it is optimizing, simulated annealing randomly perturbs the current solution by a decaying amount, which may have a similar effect. Because simulated annealing relies on random sampling to find improvements, however, its computation complexity is exponential in the number of dimensions being optimized. By contrast, graduated optimization smooths the function being optimized, so local optimization techniques that are efficient in high-dimensional space (such as <b>gradient-based</b> techniques, hill climbers, etc.) may still be used.|$|E
50|$|The unknown {{parameters}} in each vector βk {{are typically}} jointly estimated by maximum a posteriori (MAP) estimation, {{which is an}} extension of maximum likelihood using regularization of the weights to prevent pathological solutions (usually a squared regularizing function, which is equivalent to placing a zero-mean Gaussian prior distribution on the weights, but other distributions are also possible). The solution is typically found using an iterative procedure such as generalized iterative scaling, iteratively reweighted least squares (IRLS), by means of <b>gradient-based</b> optimization algorithms such as L-BFGS, or by specialized coordinate descent algorithms.|$|E
50|$|By {{the year}} 1985, the imaging methods {{used by the}} oil {{industry}} were based in signal-processing concepts, {{and it seemed that}} modern methods, based on careful waveform modeling and waveform fitting optimization were desirable. The team tried to make real-life demonstrations that the methods of inverse theory could be applied to the imaging problem typical of seismic exploration. The GTG was founded by Albert Tarantola, who authored an influential paper on the inversion of seismic reflection data. The GTG published work on fully nonlinear waveform fitting is possible on seismic exploration data, using elastic modeling and <b>gradient-based</b> optimization techniques (adjoint methods).|$|E
