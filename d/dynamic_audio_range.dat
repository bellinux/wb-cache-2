1|360|Public
50|$|Direct line in {{recording}} from sequencers {{allowed for}} remarkably clean recordings with a usable <b>dynamic</b> <b>audio</b> <b>range.</b>|$|E
50|$|Since Windows Media Player 9 Series, {{the player}} {{supports}} crossfading, <b>audio</b> <b>dynamic</b> <b>range</b> (Quiet Mode) for WMA Pro and WMA Lossless, and auto volume leveling for certain media which includes volume level/gain {{information such as}} MP3 or Windows Media. The player also supports extensive configurable privacy and security settings.|$|R
50|$|Digital audio with undithered 20-bit {{digitization}} is theoretically {{capable of}} 120 dB <b>dynamic</b> <b>range.</b> 24-bit digital <b>audio</b> calculates to 144 dB <b>dynamic</b> <b>range.</b> Most Digital <b>audio</b> workstations process audio with 32-bit floating-point representation which affords even higher dynamic range and so loss of dynamic range {{is no longer}} a concern in terms of digital <b>audio</b> processing. Low <b>dynamic</b> <b>range</b> <b>audio</b> mixes typically result from improper gain staging, imperfections in the analog-to-digital and digital-to-analog conversions, recording technique including ambient noise and intentional application of dynamic range compression.|$|R
40|$|Part of topic : Ambiantal {{experiences}} and experimentsInternational audienceFrom experience to sound experiments, from personified story to active demonstrations, our prospective approach about creative atmospheres tends {{to leave the}} simple approach by phenomena of a sound which brings back to the immediacy, for a wider listening situation by relative position. This concept is based upon notions of distance, spacing, decay time, <b>audio</b> <b>dynamic</b> <b>range,</b> ear and vision synchronisation. For us, the space experiment is a universal method of polysensory attention to think the coming architecture in terms of listening variations. The example of the tomorrow Epidaurus sketched in conclusion allows to program and design a more participatory and flexible architecture...|$|R
50|$|In October 2011 Avid {{introduced}} {{a new line of}} DSP accelerated cards, named HDX cards, along with version 10 of its Pro Tools software. The cards included DSP processors manufactured by Texas Instruments, operating with increased computational precision - 32-bit floating point versus the previous 24-bit fixed (in the older generation 56k chips made by Motorola). Benefits claimed for the new system included improved technical performance in terms of <b>audio</b> <b>dynamic</b> <b>range,</b> monitoring latency, and overall computational power, when compared to the older HD line. In its marketing Avid aimed the HDX system at customers requiring the highest and most consistent practically achievable levels of technical performance. The practical benefit to the user was the more reliable creation of large and complex productions typical of those demanded in modern music production. A key stated benefit was near-zero monitoring latency.|$|R
40|$|This paper proposes {{and tests}} the {{efficacy}} of a 2 D gestural interface {{as a means of}} controlling audio processing parameters. The process of parameter mapping and subsequent optimisation can be applied within a 3 D environment. Highly immersive computer interfaces, such as those found in modern virtual reality systems, offer an alternative platform suitable for 'virtual mixing desk' implementation, using a mixture of familiar controls and novel gestural control. By focusing on a small element of the proposed 'virtual mixing desk', <b>audio</b> <b>dynamic</b> <b>range</b> compression, this paper aims to evaluate the efficacy and practicality of a global gesture set. Following a large scale gesture elicitation exercise utilising a common 2 D touch pad and analysis of semantic audio control parameters, a set of reduced multi-modal parameters are proposed which offers both workflow efficiency and a much simplified method of control for dynamic range compression...|$|R
25|$|An audio {{oscillator}} produces frequencies in the <b>audio</b> <b>range,</b> about 16Hz to 20kHz.|$|R
50|$|An audio {{oscillator}} produces frequencies in the <b>audio</b> <b>range,</b> about 16 Hz to 20 kHz.|$|R
50|$|ADAM (Advanced <b>Dynamic</b> <b>Audio</b> Monitors) Audio {{was founded}} in March 1999 in Berlin, Germany. Since then {{the company has been}} developing, {{manufacturing}} and distributing loudspeakers in the field of Professional Audio, adding HiFi-Speakers to the portfolio very soon.|$|R
50|$|In video games, Mickey Mousing {{may occur}} in <b>dynamic</b> <b>audio</b> compositions, {{such as in}} {{reaction}} or for indication (for example, in response to character action or to alert the player {{to the end of}} a countdown), and is often found in platform games.|$|R
5000|$|In {{programming}} for telephony, concatenation {{is used to}} provide <b>dynamic</b> <b>audio</b> feedback to a user. For example, in a [...] "time of day" [...] speaking clock, concatenation is used to give the correct time by playing the appropriate recordings concatenated together. For example: ...|$|R
50|$|Moving-paper {{oscillographs}} using UV-sensitive {{paper and}} advanced mirror galvanometers provided multi-channel recordings in the mid-20th century. Frequency response was into {{at least the}} low <b>audio</b> <b>range.</b>|$|R
50|$|A voice {{frequency}} (VF) or voice band {{is one of}} the frequencies, within part of the <b>audio</b> <b>range,</b> that is being used for the transmission of speech.|$|R
40|$|This paper aims at {{analyzing}} {{the mechanism of}} heat transfer and consequently a thermal analysis. Data obtained provides a starting point in choosing solutions constructrive, mechanical and electrichal <b>dynamic</b> <b>audio</b> device prototype. A comprehensive approach allows optimization of device based on our maximum eficianta developed model and {{finite element analysis program}} using coupling possibilities in different conditions...|$|R
50|$|The Draconians first {{appeared}} in the 1973 television serial Frontier in Space. This is their first time in a Big Finish Doctor Who audio, although they have previously featured in the Bernice Summerfield <b>audio</b> <b>range.</b>|$|R
40|$|To {{improve the}} {{reproduction}} of audio signals, the signal components of a selected <b>audio</b> frequency <b>range</b> (1) of an audio signal are concentrated in a narrower <b>audio</b> frequency <b>range</b> (II). This is achieved by detecting first signal components in the first <b>audio</b> frequency <b>range</b> (I), generating second signal components in the second <b>audio</b> frequency <b>range</b> (II), and controlling the amplitude of the second signal components {{in response to the}} amplitude of the first signal components. As a result, dedicated transducers may be used which are particularly efficient in the narrower frequency range. The original frequency range (I) may contain the lower frequency signal components (bass components) of the audio signal...|$|R
50|$|The game uses Dolby Digital and Frostbite's High Definition <b>Audio</b> <b>Range</b> technology. The {{score was}} {{composed}} by Mikael Karlsson and is {{featured on the}} Battlefield: Bad Company 2 Official Soundtrack, which was released on February 2, 2010.|$|R
5000|$|In 2015, Harman International Industries {{signed up}} Tapas Relia to endorse its Professional <b>Audio</b> <b>Range</b> Of Products from JBL and AKG Acoustics. [...] Tapas now {{exclusively}} endorses {{and promotes the}} use of JBL Speakers and AKG Microphones.|$|R
40|$|We {{demonstrate}} {{an interactive}} digit recognition system using a spiking Deep Neural Network (DNN) FPGA-based system connected to two event-driven sensors: a Dynamic Vision Sensor (DVS) and a <b>Dynamic</b> <b>Audio</b> Sensor (DAS). Sensor fusion is demonstrated on a digit classification task using a DNN {{trained on the}} MNIST dataset supplemented by assignment of a unique pure ton e for each digit...|$|R
40|$|Blind {{children}} {{engage with}} their immediate environment {{much less than}} sighted children, particularly through self-initiated movement or exploration. Research has suggested that providing dynamic feedback about {{the environment and the}} child’s actions within/against it may help to encourage reaching activity and support spatial cognitive learning. This paper investigated whether the accuracy of peripersonal reaching (space within arm’s reach) can be improved by the use of dynamic sound from both the objects to reach for and the reaching hand itself (via a worn speaker). We ran two studies that tested the efficacy of static and <b>dynamic</b> <b>audio</b> feedback designs with blind and visually impaired young people, to identify optimal feedback designs. Study 1 was with young adults aged 18 to 22 and Study 2 involved children aged 12 to 17. The results showed that <b>dynamic</b> <b>audio</b> feedback helps to build spatial connections between the objects and the reaching hand and participants were able to reach more accurately, compared to unchanging feedback...|$|R
40|$|Awareness {{of other}} people‟s {{activity}} {{is an important}} part of shared-workspace collaboration, and is typically supported using visual awareness displays such as radar views. These visual presentations are limited in that the user must be able to see and attend to the view in order to gather awareness information. Using audio to convey awareness information does not suffer from these limitations, and previous research has shown that audio can provide valuable awareness in distributed settings. In this paper we evaluate the effectiveness of synthesized <b>dynamic</b> <b>audio</b> information, both on its own and as an adjunct to a visual radar view. We developed a granular-synthesis engine that produces realistic chalk sounds for off-screen activity in a groupware workspace, and tested the audio awareness in two ways. First, we measured people‟s ability to identify off-screen activities using only sound, and found that people are almost as accurate with synthesized sounds as with real sounds. Second, we tested <b>dynamic</b> <b>audio</b> awareness in a realistic groupware scenario, and found that adding audio to a radar view significantly improved awareness of off-screen activities in situations where it was difficult to see or attend to the visual display. Our work provides new empirical evidence about the value of <b>dynamic</b> synthesized <b>audio</b> in distributed groupware...|$|R
50|$|The phasing {{method for}} the {{generation}} of single sideband signals uses a network which imposes a constant 90° phase shift on audio signals over the <b>audio</b> <b>range</b> of interest. This was difficult with analog methods but with DSP is very simple.|$|R
50|$|After {{building}} {{a pair of}} radio broadcast studios for the controversial SW Radio Africa organisation and then acting as station engineer for 2 years, he joined Cheltenham Stage Services, a live sound and lighting company. He resigned his directorship {{at the end of}} 2008 and as founder member of Production AV Ltd, a young <b>dynamic</b> <b>Audio</b> Visual company, he is now specialising in AV permanent installations.|$|R
50|$|In an RC {{oscillator}} circuit, {{the filter}} is {{a network of}} resistors and capacitors. RC oscillators are mostly used to generate lower frequencies, for example in the <b>audio</b> <b>range.</b> Common types of RC oscillator circuits are the phase shift oscillator and the Wien bridge oscillator.|$|R
40|$|Interactive music {{systems are}} highly dynamic systems that combine audio {{processing}} and control in real-time, {{and they often}} {{have to work on}} soft real-time platforms, where no stringent real-time guarantees can be upheld. We present here an overhead-aware online degradation algorithm that find a tradeoff between quality and lateness for the processing nodes of a <b>dynamic</b> <b>audio</b> graph. We show that we can scale to thousands of nodes...|$|R
40|$|In {{an attempt}} to address the lack of audio {{processing}} in web-based applications, various methods are explored for generating <b>dynamic</b> <b>audio</b> and real-time processing. After the logical platform is identified, a framework is theoretically and practically designed. The framework includes implementations that target the everyday web developer, {{as well as the}} digital signal processing programmer, in an effort to unite the two parties and infuse the next generation of rich Interne...|$|R
50|$|His other Doctor Who work {{includes}} the audio dramas, The Settling and The Judgement of Isskar, in Big Finish's Doctor Who <b>audio</b> <b>range,</b> three Companion Chronicles and {{a contribution to}} the UNIT spinoff series. He has also written a play in Big Finish's Sapphire and Steel range.|$|R
5000|$|A {{diaporama}} is {{a photographic}} slideshow, sometimes with accompanying <b>audio,</b> <b>ranging</b> from using {{only one or}} two slide projectors to a multi-image slideshow using a wide screen and several slide projectors connected to a central controlling device changing the slides, turning lamps on and off etc.|$|R
50|$|De-essing is a <b>dynamic</b> <b>audio</b> editing process, only working {{when the}} level of the signal in the {{sibilant}} range (the ess sound) exceeds a set threshold. De-essing temporarily reduces {{the level of}} high frequency content in the signal when a sibilant ess sound is present. De-essing differs from equalization, which is a static change in level among many frequencies. However, equalization of the ess frequencies alone can be manipulated to reduce the level of sibilance.|$|R
40|$|The {{numbers of}} {{broadcast}} channels and platforms are going up, {{while the number}} of viewers remains the same. Digitization was expected to help streamlining audio delivery, but this has not happened yet. Confusion about peak level, loudness, end-listener requirements, formats, and the generation of metadata, has made digital broadcast an obstacle rather than the simplification needed. This paper shows how broadcasters {{can take advantage of the}} new ITU recommendation BS. 1770 to cut down on the workloads, and improve the audio quality. Important aspects of BS. 1770 are described, including novel statistical descriptors that can be derived from it. The techniques can be used to generate more precise specification documents for content providers, and to help automating ingest, production and transmission. The paper is targeted to broadcast, music and film industry professionals. DYNAMIC RANGE TOLERANCE Even though DTV has the potential to carry wide <b>dynamic</b> <b>range</b> <b>audio,</b> this aspect is not important to the general consumer [10]. What matters most is speech intelligibility and consistency of loudness. Consumers have a defined Dynamic Range Tolerance, DRT, specific to their listening situation, see Fig 1. The DRT is defined as a Preferred Average window with a specific peak level Headroom above it. The average level has to be kept within certain boundaries in order to maintain speech intelligibility, and to avoid music or sound effects from getting annoyingly loud or soft. In situations with significant background noise, it may not even be possible to get a wide dynamic range message across- be it music or spoken- without reproduction distortion getting added, or damaging the listener’s ears. It should be noted that TV listeners more often object against <b>audio</b> when the <b>dynamic</b> <b>range</b> is too wide, than when it is too restricted. The only reproduction situation where a wide dynamic range is a recognized benefit to the general public is in a cinema...|$|R
50|$|The {{prototype}} contains music {{taken from}} Super Mario World and no sound effects besides the jumping sound. This {{seems to be}} an early placeholder, as the idea for the final game was {{to take advantage of the}} disc format and use a flexible <b>audio</b> <b>range</b> rather than port unimproved synthesised sound.|$|R
50|$|If a {{sound card}} is used, {{frequency}} response is usually {{limited to the}} <b>audio</b> <b>range,</b> and DC signals cannot be measured without hardware modification. The number of inputs {{is limited by the}} number of recording channels and the inputs can handle only audio line-level voltages (usually ~1 Vpp) without the risk of damage.|$|R
25|$|Heising (constant-current) modulation: RF {{amplifier}} plate voltage is {{fed through}} a “choke” (high-value inductor). The AM modulation tube plate is fed {{through the same}} inductor, so the modulator tube diverts current from the RF amplifier. The choke acts as a constant current source in the <b>audio</b> <b>range.</b> This system has a low power efficiency.|$|R
5000|$|Some critics {{claim that}} Beats {{products}} emphasize appearance over quality and function, arguing that more durable and better-sounding products {{are available for}} the same price.Tests done on an HTC smartphone with Beats Audio indicated that the audio technology {{is a combination of}} audio equalization that boosts the low (bass) and high ends of the <b>audio</b> <b>range,</b> <b>audio</b> compression, and audio amplification. On accusations that Beats' products were [...] "bass heavy", Beats current president denies it, citing that their products are not for reference, but rather for playback.|$|R
5000|$|Initially, {{satellite}} subcarrier audio was tuned using commercial receivers or consumer-grade TVRO [...] "big dish" [...] satellite receivers. The <b>audio</b> <b>ranged</b> {{in frequency}} from 5.0 to 8.5 MHz for both {{left and right}} audio channels. Fine tuning options included monaural and discrete stereo tuning with three bandwidth modes: narrow (130 kHz), normal (280 kHz) and wide (500 kHz).|$|R
50|$|Valve audio {{amplifiers}} typically amplify the entire <b>audio</b> <b>range</b> between 20 Hz and 20 kHz or higher. They use an iron core transformer {{to provide a}} suitable high impedance load to the valve(s) while driving a speaker, which is typically 8 Ohms. Audio amplifiers normally use a single valve in class A, or a pair in class B or class AB.|$|R
