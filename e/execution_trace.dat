406|937|Public
5000|$|A {{workflow}} trace or <b>execution</b> <b>trace</b> is {{a string}} over an alphabet [...] of tasks.|$|E
5000|$|A round is the {{shortest}} <b>execution</b> <b>trace</b> in which each processor executes at least one step.|$|E
5000|$|Simulator: {{following}} {{one possible}} execution {{path through the}} system and presenting the resulting <b>execution</b> <b>trace</b> to the user.|$|E
40|$|This report {{presents}} the research {{carried out in}} the area of software product quality modelling. Its main endeavour is to consider software product quality with regard to maintainability. Supporting this aim, <b>execution</b> <b>tracing</b> quality, which is a neglected property of the software product quality at present in the quality frameworks under investigation, needs to be described by a model that offers possibilities to link to the overall software product quality frameworks. The report includes concise description of the research objectives: (1) the thorough investigation of software product quality frameworks {{from the point of view}} of the quality property analysability with regard to execution tracing; (2) moreover, extension possibilities of software product quality frameworks, and (3) a pilot quality model developed for <b>execution</b> <b>tracing</b> quality, which is capable to capture subjective uncertainty associated with the software quality measurement. The report closes with concluding remarks: (1) the present software quality frameworks do not exhibit any property to describe <b>execution</b> <b>tracing</b> quality, (2) <b>execution</b> <b>tracing</b> has a significant impact on the analysability of software systems that increases with the complexity, and (3) the uncertainty associated with <b>execution</b> <b>tracing</b> quality can adequately be expressed by type- 1 fuzzy logic. The section potential future work outlines directions into which the research could be continued. Findings of the research were summarized in two research reports, which were also incorporated in the thesis, and submitted for publication: 1. 	Tamas Galli, Francisco Chiclana, Jenny Carter, Helge Janicke, “Towards Introducing <b>Execution</b> <b>Tracing</b> to Software Product Quality Frameworks,” Acta Polytechnica Hungarica, vol. 11, no. 3, pp. 5 - 24, 2014. doi: 10. 12700 /APH. 11. 03. 2014. 03. 1 2. 	Tamas Galli, Francisco Chiclana, Jenny Carter, Helge Janicke “Modelling <b>Execution</b> <b>Tracing</b> Quality by Means of Type- 1 Fuzzy Logic,” Acta Polytechnica Hungarica, vol. 10, no. 8, pp. 49 - 67, 2013. doi: 10. 12700 /APH. 10. 08. 2013. 8. ...|$|R
40|$|This paper studies, for {{the first}} time, the {{management}} of type information for an important class of semi-structured data: nested DAGs (Directed Acyclic Graphs) that describe <b>execution</b> <b>traces</b> of business processes (BPs for short). Specifically, we consider here type inference and type checking for queries over BP <b>execution</b> <b>traces.</b> The queries that we consider select portions of the traces that are {{of interest to the}} user; the types describe the possible shape of the <b>execution</b> <b>traces</b> in the input/output of the query. We formally define and characterize here three common classes of BP <b>execution</b> <b>traces</b> and their respective notions of type inference and type checking. We study the complexity of the two problems for query languages of varying expressive power and present efficient type inference/checking algorithms whenever possible. Our analysis offers a nearly complete picture of which combinations of trace classes and query features lead to PTIME algorithms and which to NP-complete or undecidable problems. 1...|$|R
40|$|As {{planners}} and their environments become increasingly complex, planner behavior becomes increasingly di cult to understand. We {{often do not}} understand what causes them to fail, {{so that we can}} debug their failures, and we may not understand what allows them to succeed, so that we can design the next generation. This paper describes a partially automated methodology for understanding planner behavior over long periods of time. The methodology, called Dependency Interpretation, uses statistical dependency detection to identify interesting patterns of behavior in <b>execution</b> <b>traces</b> and interprets the patterns using a weak model of the planner's interaction with its environment to explain how the patterns might be caused by the planner. Dependency Interpretation has been applied to identify possible causes of plan failures in the Phoenix planner. By analyzing four sets of <b>execution</b> <b>traces</b> gathered from about 400 runs of the Phoenix planner, we showed that the statistical dependencies describe patterns of behavior that are sensitive totheversion of the planner and to increasing temporal separation between events, and that dependency detection degrades predictably as the number of available <b>execution</b> <b>traces</b> decreases and as noise is introduced in the <b>execution</b> <b>traces.</b> Dependency Interpretation is appropriate when a complete and correct model of the planner and environment is not available, but <b>execution</b> <b>traces</b> are available...|$|R
5000|$|We {{can check}} the {{correctness}} {{of the method}} for n=4 by presenting the <b>execution</b> <b>trace</b> of the program: ...|$|E
5000|$|VB Watch injects dynamic {{analysis}} code into Visual Basic programs {{to monitor their}} performance, call stack, <b>execution</b> <b>trace,</b> instantiated objects, variables and code coverage.|$|E
5000|$|Similarly, a {{cycle is}} the {{shortest}} <b>execution</b> <b>trace</b> in which each processor executes at least one complete iteration of its repeatedly executed list of commands.|$|E
40|$|We {{illustrate}} {{the effectiveness of}} our techniques in POTA on test cases such as the General Inter-ORB Protocol (GIOP) [18]. POTA also contains a module that translates <b>execution</b> <b>traces</b> to Promela [16] (input language SPIN). This module enables us to compare our results on <b>execution</b> <b>traces</b> with SPIN. In some cases, {{we were able to}} verify traces with 250 processes compared to only 10 processes using SPIN...|$|R
40|$|Stochastic {{simulations}} frequently exhibit {{behaviors that}} are difficult to recreate and analyze, owing largely to the stochastics themselves, and consequent program dependency chains that can defy human reasoning capabilities. We present a novel approach called Markov Chain <b>Execution</b> <b>Traces</b> (MCETs) for efficiently representing sampled stochastic simulation <b>execution</b> <b>traces</b> and ultimately driving semiautomated analysis methods that require accurate, efficiently generated candidate <b>execution</b> <b>traces.</b> The MCET approach is evaluated, using new and established measures, against both additional novel and existing approaches for computing dynamic program slices in stochastic simulations. ������������������rformance is established. Finally, a description of how users can apply MCETs to their own stochastic simulations and a discussion of the new analyses MCETs can enable are presented. ...|$|R
40|$|Abstract—Identifying {{concepts}} in <b>execution</b> <b>traces</b> {{is a task}} often necessary to support program comprehension or maintenance activities. Several approaches—static, dynamic or hybrid—have been proposed to identify cohesive, meaningful sequence of methods in <b>execution</b> <b>traces.</b> However, none of the proposed approaches is able to label such segments and to identify relations between segments of the same trace. This paper present SCAN (Segment Concept AssigNer) an approach to assign labels to sequences of methods in <b>execution</b> <b>traces,</b> and to identify relations between such segments. SCAN uses information retrieval methods and formal concept analysis to produce sets of words helping the developer to understand the concept implemented by a segment. Specifically, formal concept analysis allows SCAN to discover commonalities between segments in different trace areas, as well as terms more specific to a given segment and high level relations between segments. The paper describes SCAN along with a preliminary manual validation—upon <b>execution</b> <b>traces</b> collected from usage scenarios of JHotDraw and ArgoUML—of SCAN accuracy in assigning labels representative of concepts implemented by trace segments. Keywords-Concept identification, dynamic analysis, information retrieval, formal concept analysis. I...|$|R
50|$|It does so by {{examining}} causal relationships observed between tasks. For example, one specific task might always precede another specific task in every <b>execution</b> <b>trace,</b> {{which would be}} useful information.|$|E
50|$|VB Watch Debugger {{monitors}} {{what happens}} inside a running Visual Basic program or library. It displays the call stack, <b>execution</b> <b>trace,</b> global {{variables and the}} number of live objects. The Debugger also allows one to add breakpoints in executable files.|$|E
50|$|Another {{way to try}} {{to improve}} {{performance}} is to cache the decoded micro-operations, so the processor can directly access the decoded micro-operations from a special cache, instead of decoding them again. Intel followed this approach with the <b>Execution</b> <b>Trace</b> Cache feature in their NetBurst Microarchitecture (for Pentium 4 processors) and later in the Decoded Stream Buffer (for Core-branded processors since Sandy Bridge).|$|E
5000|$|System {{structure}} and run-time <b>execution</b> <b>traces</b> are correlated to facilitate program comprehension through dynamic analysis in software maintenance tasks.|$|R
5000|$|The {{following}} are three step-by-step <b>execution</b> <b>traces</b> annotated with the sentence numbers applied {{at each step}} to produce the next ...|$|R
40|$|We need {{tools and}} {{new ways to}} {{visualize}} our software <b>execution</b> <b>traces</b> and to deploy and integrate the visualizations into users’ environments. We are currently implementing existing information visualization 3 D metaphors using X 3 D to visualize our <b>execution</b> <b>traces,</b> however most of these metaphors are principly node-link diagrams or graph structures and {{are not easy to}} interpret nor understand. We want to use real world metaphors which users can easily relate to, such as a 3 D city metaphor. One tool for implementing the 3 D city metaphor could be the open source X 3 D-Earth application. In this paper we list the requirements for an X 3 D-Earth application which could be used for visualizations of static and dynamic information of software. Keywords Software Visualization, <b>Execution</b> <b>Traces,</b> X 3 D-Earth 1...|$|R
50|$|One of {{the more}} extreme {{examples}} of cache specialization is the trace cache (also known as <b>execution</b> <b>trace</b> cache) found in the Intel Pentium 4 microprocessors. A trace cache is a mechanism for increasing the instruction fetch bandwidth and decreasing power consumption (in {{the case of the}} Pentium 4) by storing traces of instructions that have already been fetched and decoded.|$|E
5000|$|Immerman 1999 {{provides}} a detailed {{proof of the}} theorem. It is straightforward to show that every existential second-order formula can be recognized in NP, by nondeterministically choosing the value of all existentially-qualified variables, so {{the main part of}} the proof is to show that every language in NP can be described by an existential second-order formula. To do so, one can use second-order existential quantifiers to arbitrarily choose a computation tableau. In more detail, for every timestep of an <b>execution</b> <b>trace</b> of a non-deterministic Turing machine, this tableau encodes the state of the Turing machine, its position in the tape, the contents of every tape cell, and which nondeterministic choice the machine makes at that step. Constraining this encoded information so that it describes a valid <b>execution</b> <b>trace</b> in which the tape contents and Turing machine state and position at each timestep follow from the previous timestep can then be done with a first-order formula.|$|E
50|$|Taint {{checking}} may {{be viewed}} as a conservative approximation of the full verification of non-interference or the more general concept of secure information flow. Because information flow in a system cannot be verified by examining a single <b>execution</b> <b>trace</b> of that system, the results of taint analysis will necessarily reflect approximate information regarding the information flow characteristics of the system to which it is applied.|$|E
40|$|AbstractProgram <b>execution</b> <b>traces</b> can be {{so large}} in {{practical}} testing and monitoring applications {{that it would be}} very expensive, if not impossible, to store them for detailed analysis. Monitoring <b>execution</b> <b>traces</b> without storing them, can be a nontrivial matter for many specification formalisms, because complex formulae may require a considerable amount of information about the past. Metric temporal logic (MTL) is an extension of propositional linear temporal logic with discrete-timebounded temporal operators. In MTL, one can specify time limits within which certain temporal properties must hold, thus making it very suitable to express real-time monitoring requirements. In this paper, we present monitoring algorithms for checking timestamped <b>execution</b> <b>traces</b> against formulae in MTL or certain important sublogics of it. We also present lower bounds for the monitoring problem, showing that the presented algorithms are asymptotically optimal...|$|R
40|$|Understanding {{the dynamic}} {{behavior}} of a software system {{is one of the}} most important and time-consuming tasks for today’s software maintainers. In practice, understanding the inner workings of software requires studying the source code and documentation and inserting logging code to map high-level descriptions of the program behavior with low-level implementation, i. e., the source code. Unfortunately, for large codebases and large log files, such cognitive mapping can be quite challenging. To bridge the cognitive gap between the source code and detailed models of program behavior, prior software-execution mining research primarily focused on reducing the size of the low-level instruction <b>execution</b> <b>traces.</b> In contrast, in this thesis we propose a generic approach to present a semantic abstraction with different levels of functional granularity from full <b>execution</b> <b>traces.</b> Our approach mines multiple <b>execution</b> <b>traces</b> to identify frequent behaviors at multiple levels of abstraction, and then analyzes and labels individual <b>execution</b> <b>traces</b> according to the identified major functional behaviors of the system. To validate our technique, we conducted a case study on a large-scale subject program, Javac, to demonstrate the effectiveness of the mining result. Furthermore, the results of a user study demonstrate that our technique is capable of presenting users with a high-level comprehensible abstraction of execution behavior...|$|R
50|$|The {{capability}} of a runtime verifier to detect errors strictly {{depends on its}} capability to analyze <b>execution</b> <b>traces.</b> When the monitors are deployed with the system, instrumentation is typically minimal and the <b>execution</b> <b>traces</b> are {{as simple as possible}} to keep the runtime overhead low. When runtime verification is used for testing, one can afford more comprehensive instrumentations that augment events with important system information that can be used by the monitors to construct and therefore analyze more refined models of the executing system. For example, augmenting events with vector-clock information and with data and control flow information allows the monitors to construct a causal model of the running system in which the observed execution was only one possible instance. Any other permutation of events which is consistent with the model is a feasible execution of the system, which could happen under a different thread interleaving. Detecting property violations in such inferred executions (by monitoring them) makes the monitor predict errors which did not happen in the observed execution, but which can happen in another execution of the same system. An important research challenge is to extract models from <b>execution</b> <b>traces</b> which comprise as many other <b>execution</b> <b>traces</b> as possible.|$|R
50|$|Slicing {{techniques}} {{have been seeing}} a rapid development since the original definition by Mark Weiser. At first, slicing was only static, i.e., applied on the source code with no other information than the source code. Bogdan Korel and Janusz Laski introduced dynamic slicing, which works on a specific execution of the program (for a given <b>execution</b> <b>trace).</b> Other forms of slicing exist, for instance path slicing.|$|E
5000|$|Trace Cache (also {{known as}} <b>execution</b> <b>trace</b> cache) {{is a very}} {{specialized}} cache which stores the dynamic stream of instructions known as trace. It helps in increasing the instruction fetch bandwidth and decreasing power consumption (in the case of Intel Pentium 4 [...] ) by storing traces of instructions {{that have already been}} fetched and decoded. Trace Processor is an architecture designed around the Trace Cache and processes the instructions at trace level granularity.|$|E
50|$|Another {{way to try}} {{to improve}} {{performance}} is to cache the decoded micro-operations, so that if the same macroinstruction is executed again, the processor can directly access the decoded micro-operations from a special cache, instead of decoding them again. The <b>Execution</b> <b>Trace</b> Cache found in Intel NetBurst microarchitecture (Pentium 4) is a widespread example of this technique. The size of this cache may be stated in terms of how many thousands of micro-operations it can store: kμops.|$|E
40|$|Many {{enterprises}} nowadays use business processes, {{based on}} the BPEL standard, to achieve their goals. Analyzing the execution of such processes is critical for enforcing business policies and meet-ing efficiency and reliability goals. The BP-Ex system presented in this demo is an important compo-nent of BP-Suite, a novel tools suite {{based on the}} BPEL stan-dard, which offers a uniform, query-based, user-friendly interface for BP analysis. BP-suite allows to gracefully combine the anal-ysis of process specifications, monitoring of run time behavior, and posteriorly querying of <b>execution</b> <b>traces</b> (logs), for a comprehen-sive process management. BP-Ex is the BP-Suite query engine for process <b>execution</b> <b>traces.</b> The goal of this demo is to highlight the particular challenges {{that had to be}} addressed to support the suite’s uniform, intuitive query interface, over (possibly very large) <b>execution</b> <b>traces,</b> and to demonstrate the novel optimization tech-niques that had to be developed for that. 1...|$|R
40|$|Abstract—We {{present a}} semi-automated {{approach}} for the reverse engineering of UML sequence diagrams. Our approach {{starts with a}} set of <b>execution</b> <b>traces</b> that are automatically aligned {{in order to determine the}} common behavior. Sequence diagrams are then extracted with an interactive visualization, which allows navigating into <b>execution</b> <b>traces</b> and performing extraction operations. We provide a concrete illustration of our approach with a case study, and show in particular that the resulting diagrams are more meaningful and more compact than those extracted by automated approaches. Keywords-reverse engeneering; sequence diagrams; visualization; I...|$|R
50|$|A model-specific {{register}} (MSR) is any {{of various}} control registers in the x86 instruction set used for debugging, program <b>execution</b> <b>tracing,</b> computer performance monitoring, and toggling certain CPU features.|$|R
5000|$|Systems to be {{verified}} are described in Promela (Process Meta Language), which supports modeling of [...] distributed algorithms as non-deterministic automata (SPIN stands for [...] "Simple Promela Interpreter"). Properties to {{be verified}} are expressed as Linear Temporal Logic (LTL) formulas, which are negated and then converted into Büchi automata {{as part of the}} model-checking algorithm. In addition to model-checking, SPIN can also operate as a simulator, following one possible execution path through the system and presenting the resulting <b>execution</b> <b>trace</b> to the user.|$|E
50|$|Within the L1 {{cache of}} the CPU, Intel {{incorporated}} its <b>Execution</b> <b>Trace</b> Cache. It stores decoded micro-operations, {{so that when}} executing a new instruction, instead of fetching and decoding the instruction again, the CPU directly accesses the decoded micro-ops from the trace cache, thereby saving considerable time. Moreover, the micro-ops are cached in their predicted path of execution, which means that when instructions are fetched by the CPU from the cache, they are already present in the correct order of execution. Intel later introduced a similar but simpler concept with Sandy Bridge called micro-operation cache (UOP cache).|$|E
50|$|Support is {{provided}} for cryptographic primitives including: symmetric & asymmetric cryptography; digital signatures; hash functions; bit-commitment; and signature proofs of knowledge. The tool {{is capable of}} evaluating reachability properties, correspondence assertions and observational equivalence. These reasoning capabilities are particularly useful to the computer security domain since they permit the analysis of secrecy and authentication properties. Emerging properties such as privacy, traceability and verifiability can also be considered. Protocol analysis is considered with respect to an unbounded number of sessions and an unbounded message space. The tool is capable of attack reconstruction: when a property cannot be proved, an <b>execution</b> <b>trace</b> which falsifies the desired property is constructed.|$|E
40|$|We need to {{understand}} the impact of side effects whenever changing complex object-oriented software systems. This can be difficult as side effects are at best implicit in static views of the software, and typically <b>execution</b> <b>traces</b> do not capture data flow between parts of the system. To solve this problem, we complement <b>execution</b> <b>traces</b> with dynamic object flow information. In our previous work we analyzed object flows between features and classes. In this paper, we use object flow information to analyze side effects in <b>execution</b> <b>traces</b> and to detect how future behavior in the trace is affected by it. Using a visualization, the developer can study how a selected part of the program accessed program state and what side effect its execution produced. Like this, the developer can investigate how a particular part of the program works without needing {{to understand}} the source code in detail. To illustrate our approach, we use a running example of writing unit tests for a legacy system...|$|R
40|$|H. 4. 1 Office Automation—Workflow {{management}} Many enterprises nowadays use business processes, {{based on}} the BPEL standard, to achieve their goals. Analyzing the execution of such processes is critical for enforcing business policies and meeting efficiency and reliability goals. The BP-Ex system presented in this demo {{is an important component}} of BP-Suite, a novel tools suite {{based on the}} BPEL standard, which offers a uniform, query-based, user-friendly interface for BP analysis. BP-suite allows to gracefully combine the analysis of process specifications, monitoring of run time behavior, and posteriorly querying of <b>execution</b> <b>traces</b> (logs), for a comprehensive process management. BP-Ex is the BP-Suite query engine for process <b>execution</b> <b>traces.</b> The goal of this demo is to highlight the particular challenges that had to be addressed to support the suite’s uniform, intuitive query interface, over (possibly very large) <b>execution</b> <b>traces,</b> and to demonstrate the novel optimization techniques that had to be developed for that. 1...|$|R
40|$|International audienceProper {{testing of}} {{applications}} over embedded {{systems such as}} set-top boxes requires endurance tests, i. e. running applications for extended periods of times, typically several days. In order to understand bugs or poor performances, <b>execution</b> <b>traces</b> have to be analyzed, however current trace analysis methods are not designed to handle several days of <b>execution</b> <b>traces</b> due to the huge quantity of data generated. Our proposal, designed for regular applications such as multimedia decoding/encoding, is to monitor <b>execution</b> by analyzing <b>trace</b> on the fly in order to record trace only in time periods where a suspicious activity is detected. Our experiments show {{a significant reduction in}} the trace size compared to recording the whole trace...|$|R
