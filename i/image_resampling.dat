91|159|Public
50|$|In image processing, bicubic {{interpolation}} {{is often}} chosen over bilinear interpolation or nearest neighbor in <b>image</b> <b>resampling,</b> when speed {{is not an}} issue. In contrast to bilinear interpolation, which only takes 4 pixels (2×2) into account, bicubic interpolation considers 16 pixels (4×4). Images resampled with bicubic interpolation are smoother and have fewer interpolation artifacts.|$|E
50|$|When {{using the}} Lanczos filter for <b>image</b> <b>resampling,</b> the ringing effect will create {{light and dark}} halos along any strong edges. While these bands may be {{visually}} annoying, they help increase the perceived sharpness, and therefore provide a form of edge enhancement. This may improve the subjective quality of the image, given the special role of edge sharpness in vision.|$|E
50|$|Dodgson {{graduated}} with a Bachelor of Science degree in Computer Science and Physics from Massey University in 1988 and subsequently worked there as a Junior Lecturer in Computer Science for one year. He was awarded a Cambridge Commonwealth Trust Prince of Wales Scholarship to study at the University of Cambridge, where he worked on <b>image</b> <b>resampling</b> supervised by Neil Wiseman and graduating with a PhD in 1992.|$|E
5000|$|... #Caption: The same <b>image</b> <b>resampled</b> to {{five times}} as many samples in each direction, using Lanczos resampling. Pixelation {{artifacts}} were removed changing the image's transfer function.|$|R
3000|$|... c {{represents}} the FFT {{result of the}} covariance signal of a <b>resampled</b> <b>image</b> with the CSS process. The result shows a clear peak when the CSS process is applied. The CSS process makes peak clearer only with <b>resampled</b> <b>image.</b> It makes accurate classification of a non-resampled <b>image</b> and a <b>resampled</b> <b>image</b> possible.|$|R
3000|$|Using the {{diagnosed}} transformation field, {{the experimental}} <b>image</b> is <b>resampled</b> over new grid points to affect this transformation and yield the intermediate image, I’ [...]...|$|R
50|$|Image scaling can be {{interpreted}} as a form of <b>image</b> <b>resampling</b> FIX or image reconstruction from the view of the Nyquist sampling theorem. According to the theorem, down sampling to a smaller image from a higher-resolution original can only be carried out only after applying a suitable 2D anti-aliasing filter to prevent aliasing artifacts. The image is reduced to the information that can be carried by the smaller image.|$|E
40|$|Abstract. Digital raster images {{often need}} to be {{represented}} in higher and lower resolu-tions. Resampling of digital images {{is an essential part}} of image processing. Most efficient and sufficiently accurate <b>image</b> <b>resampling</b> techniques can produce spurious oscillations near sharp transitions of color. To improve that, we introduce tension splines applied dimension by dimension. The presented tension spline procedure provides an elegant solution to the <b>image</b> <b>resampling</b> by constructing a smooth approximation with sharp non-oscillatory resolution of disconti-nuities. The numerical results on real digital images are given to show effectiveness of the proposed algorithm...|$|E
40|$|Band-to-band coregistration of {{multispectral}} {{remote sensing}} {{images can be}} achieved by electronic signal processing techniques rather than by costly and difficult mechanical alignment. This paper describes the results of a study of the end-to-end performance of electronic registration. The software simulation includes steps which model the performance of the geometric calibration process, the instrument image quality, detector performance and the effects of achieving coregistration through <b>image</b> <b>resampling.</b> The <b>image</b> <b>resampling</b> step emulates the Pipelined Resampling Processor, a real-time image resampler. The study demonstrates that the electronic alignment technique produces multispectral images which are superior to those produced by an imager whose pixel geometry is accurate to 0. 1 pixel rms. The implications of this approach for future earth observation programs are discussed...|$|E
30|$|Methods: Our {{alternative}} analysis used simulated uniform images {{created with}} the same count/pixel (i.e. 'noiseless floods'). This allowed us to statistically test the Poisson resampling software on pixel values down to one count/pixel. Since the images are noiseless, i.e. without the standard Poisson noise of nuclear medicine images, statistical testing was different. Mathematically it can be shown that the Poisson software should generate a binomial (Gaussian) distribution with mean sqrt(f*(1 -f)*M)), f[*]=[*]Poisson fraction, M[*]=[*]count/pixel of original <b>image.</b> <b>Resampled</b> data was tested using χ 2 analysis.|$|R
30|$|With the CSS process, {{there is}} an amplifying effect for the {{intensity}} of the peak signal. In a later part, the peak in the Fourier transformed signal is amplified if the stereoscopic <b>images</b> have been <b>resampled.</b> On the other hand, the peak of signals are weakened if the stereoscopic <b>images</b> are not <b>resampled.</b>|$|R
5000|$|Image {{processing}} tools: k-means classification, numerous spatial filters, <b>image</b> mosaicing, NDVI, <b>resampling,</b> {{contrast enhancement}} ...|$|R
40|$|Algorithm for interpolating {{two-dimensional}} image data to change picture-element spacing implemented in dedicated digital hardware for high-speed execution. System interpolates 100 {{times as fast}} as generalpurpose computer. <b>Image</b> <b>resampling</b> occurs first along one image axis and then along other, using two interpolation devices implemented in series...|$|E
30|$|<b>Image</b> <b>resampling</b> is {{a process}} that {{transforms}} a coordinate system of a sampled image [18]. Both coordinates are related with a spatial transforming mapping function. The result of transforming the mapping function is a resampled grid. In other words, the input signal is resampled into a new location by the mapping function.|$|E
40|$|<b>Image</b> <b>resampling</b> is {{the process}} of {{transforming}} a sampled image from one coordinate system to another. The two coordinate systems are related to each other by the mapping function of the spatial transformation. The inverse mapping function is applied to the output sampling grid, projecting it onto the input. The result is a resampling grid, specifying the locations a...|$|E
3000|$|... {{means the}} {{threshold}} {{that separates the}} <b>resampled</b> <b>images</b> from the non-resampled images. For the experiment, the threshold T [...]...|$|R
50|$|Sinc {{resampling}} {{in theory}} {{provides the best}} possible reconstruction for a perfectly bandlimited signal. In practice, the assumptions behind sinc resampling are not completely met by real-world digital <b>images.</b> Lanczos <b>resampling,</b> an approximation to the sinc method, yields better results. Bicubic interpolation {{can be regarded as}} a computationally efficient approximation to Lanczos resampling.|$|R
40|$|The issues {{governing}} the computation of optical flow in image sequences are {{addressed in this}} paper. The trade off between accuracy versus computation cost is shown {{to be dependent on}} the redundancy of the image representation. This dependency is highlighted by reformulating Horn's algorithm making explicit use of the approximations to the continuous basis functions underlying the discrete representation. The computation cost of estimating optical flow, for a fixed error tolerance, is shown to be minimum for <b>images</b> <b>resampled</b> at twice the Nyquist rate. The issues of derivative calculation and multiresolution representation are also briefly discussed in terms of basis functions and information encoding. A multiresolution basis function formulation of Horn's algorithm is shown to lead to large improvements in dealing with high frequencies and large displacements. Keywords [...] - basis functions, multiresolution, optical flow, motion estimation, derivative estimation, oversampling. I. Introd [...] ...|$|R
40|$|The {{main goal}} of this thesis is to {{introduce}} two fundamental geometric transformations in 2 D space - by changing the resolution together with related <b>image</b> <b>resampling</b> and image rotation. Also brightness interpolation, technique of mapping and other problems related to the topic are explained there, i. e. Fourier transformations, problem with aliasing and technique of aliasing suppression...|$|E
40|$|Abstract—A {{virtually}} unavoidable {{consequence of}} manipulations on digital images are statistical correlations introduced between the pixels. These correlations {{may not be}} visible to a human, but can be detected by statistical techniques. This paper presents a machine learning based approach to <b>image</b> <b>resampling</b> detection based on the detector by Popescu and Farid. We investigate ways to improve robustness and detection accuracy by using supervised learning techniques. I...|$|E
40|$|Nearest-neighbour, linear, {{and various}} cubic {{interpolation}} functions are frequently used in <b>image</b> <b>resampling.</b> Quadratic functions have been disregarded, largely {{because they have}} been thought to introduce phase distortions. This is shown not to be the case, and a family of quadratic functions is derived. The interpolating member of this family has visual quality close to that of the CatmullRom cubic, yet requires only sixty percent of the computation time...|$|E
50|$|Actual {{displays}} do {{not generally}} have non-square pixels, though digital sensors might; they are rather a mathematical abstraction used in <b>resampling</b> <b>images</b> to convert between resolutions.|$|R
30|$|Because the {{conspicuous}} regions {{have high}} energy {{irrespective of the}} periodicity, conspicuous regions in the second-order differential signal may lower the performance of resampling detector. The phenomenon is particularly noticeable when an <b>image</b> is <b>resampled</b> by low resampling factor, especially downsampling. Moreover, the detection performance is highly dependent on each image because the conspicuous regions are unique properties for each image.|$|R
40|$|Intensity-based <b>image</b> {{registration}} requires <b>resampling</b> <b>images</b> on {{a common}} grid to evaluate the similarity function. The uncertainty of interpolation varies across the image, depending on the location of resampled points relative to the base grid. We propose to perform Bayesian inference with Gaussian processes, where the covariance matrix of the Gaussian process posterior distribution estimates the uncertainty in interpolation. The Gaussian process replaces a single image with a distribution over images that we integrate into a generative model for registration. Marginalization over <b>resampled</b> <b>images</b> leads to a new similarity measure that includes {{the uncertainty of the}} interpolation. We demonstrate that our approach increases the registration accuracy and propose an efficient approximation scheme that enables seamless integration with existing registration methods. Alexander von Humboldt-StiftungNational Alliance for Medical Image Computing (U. S.) (U 54 -EB 005149) Neuroimaging Analysis Center (U. S.) (P 41 -EB 015902) National Center for Image-Guided Therapy (U. S.) (P 41 -EB 015898...|$|R
40|$|In this paper, an edge-preserving {{nonlinear}} iterative regularization-based <b>image</b> <b>resampling</b> {{method for}} a single noise-free image is proposed. Several aspects of the resam-pling algorithm are investigated: choice of discrepancy and regularization norms, improvements of convergence speed using edge-directional steepest-descent method and patch-based details synthesis. A model of a downsampling operator based on a camera observation model is considered. Index Terms — Image interpolation, regularization, edge-directional, details synthesis, super-resolution, resampling...|$|E
40|$|Images for {{scientific}} purposes are taken by optical devices, such as microscopes, cameras etc., which usually consist of system of lenses and optical sensor. Most lenses suffer from various distortions. Geometrical distortion may not be acceptable for example for precise distance measurement in the image. This thesis describes fast algorithm for separable <b>image</b> <b>resampling</b> capable of correcting smooth geometrical distortions caused by lenses. An FPGA implementation of this algorithm is also described...|$|E
40|$|This paper {{introduces}} a fine <b>image</b> <b>resampling</b> algorithm intended for corrections of image distortions caused by lenses or similar devices. The algorithm {{is designed for}} correction of small distortions in terms of pixel displacement but with high subpixel precision. The geometrical description of the correction is through bilinear interpolation within each node of a sparse square or rectangular mesh. The paper describes the algorithms itself, its features, implementation issues and data formats. Specifically discussed are the issues connected with programmable hardware (FPGA) implementation...|$|E
40|$|Actual {{research}} {{challenges in}} automated recognition of crop shelters regard, among other issues, {{the accuracy of}} classification, contour detection and typology identification. In this field the use of high-resolution multispectral images {{has been found to}} improve the feature recognition in comparison to RGB images or low resolution multispectral ones. As for classification methodologies, per-pixel and object-oriented ones offer different tools to cope with image recognition and feature extraction. In this study, to improve the classification of cropshelter coverage, the per-pixel method was applied to high-resolution multispectral images, coupled with a texture analysis of high-resolution panchromatic images. In detail, the results of the classification accuracy assessment achieved by the use of native high-resolution panchromatic images and RGB-band <b>images</b> <b>resampled</b> accordingly, were compared with those found in a previous study in which panchromatic images degraded to the RGB-band image resolution were used. The results show that the proposed methodology is suitable to improve crop-shelter classification quality and contour detection of parcels...|$|R
40|$|A major {{advantage}} of wavefront reconstruction {{based on a}} series of diffracted intensity images using only single-beam illumination is the simplicity of setup. Here we propose a fast-converging algorithm for wavefront calculation using single-beam illumination. The captured intensity <b>images</b> are <b>resampled</b> to a series of intensity images, ranging from highest to lowest resampling; each <b>resampled</b> <b>image</b> has half the number of pixels as the previous one. Phase calculation at a lower resolution is used as the initial solution phase at a higher resolution. This corresponds to separately calculating the phase for the lower- and higher-frequency components. Iterations on the low-frequency components {{do not need to be}} performed on the higher-frequency components, thus making the convergence of the phase retrieval faster than with the conventional method. The principle is verified by both simulation and optical experiments...|$|R
40|$|In {{computer}} vision several methods are directly {{inspired by the}} human visual system. Visual attention {{is one of the}} main abilities a human eye uses to discover a new scene. This ability is based on the focus of attention principle, which enables to look at a particular point. The works presented in this paper describe how to simulate such an ability in {{computer vision}}. Color <b>images</b> are <b>resampled</b> according to this principle, in order to considerably decrease the amount of data to be processed. This resampling is done by using a concentric distribution of hexagonal cells instead of the rectangular cell grid generally provided by uniform sensors such as CCD cameras. Such a distribution is derived from the cone distribution on the retina and the result is encoded by using polar coordinates. In this way the information is more and more blurred in an isotropic way, when getting far and far from the focusing point. This resampling method then allows decreasing data number while it globally keeps all the information included in the image. In this way a new scene can be explored by focusing successively at a sequence of focusing points. This allows reproducing the human eye behavior that explores a new scene by saccades. Furthermore the <b>resampled</b> <b>images</b> can be used in order to set up image preprocessing. For example this resampling can be achieved before a preliminary step of segmentation. The <b>resampled</b> <b>image</b> is segmented in order to coarsely determine regions. Afterwards the segmentation step can be refined by combining the segmented <b>resampled</b> <b>image</b> and the original image. A comparison between results obtained in RGB and HSV spaces is also given on a set of images...|$|R
40|$|This paper {{develops}} {{a family of}} multi-pass <b>image</b> <b>resampling</b> algorithms that use one-dimensional filtering stages to achieve high-quality results at low computational cost. Our key insight is to perform a frequency-domain analysis to ensure that very little aliasing occurs at each stage in the multi-pass transform and to insert additional stages where necessary to ensure this. Using one-dimensional resampling {{enables the use of}} small resampling kernels, thus producing highly efficient algorithms. We compare our results with other state of the art software and hardware resampling algorithms...|$|E
40|$|Multi-frame super-resolution {{restoration}} algorithms commonly utilize {{a linear}} observation model relating the recorded images to the unknown restored image estimates. Working within this framework, we demonstrate {{a method for}} generalizing the observation model to incorporate spatially varying point spread functions and general motion fields. The method utilizes results from <b>image</b> <b>resampling</b> theory which is shown to have equivalences with the multi-frame image observation model used in super-resolution restoration. An algorithm for computing the coefficients of the spatially varying observation filter is developed. Examples of {{the application of the}} proposed method are presented...|$|E
40|$|Image {{restoration}} is one {{of classical}} inverse problems in image processing and computer vision, which consists of the recovering information about the original image from incomplete or degraded data. In this paper, we consider the problem of reduction of ringing that appears after <b>image</b> <b>resampling.</b> We introduce a novel method for image restoration, based on a quasi-solution method for a compact set of functions with bounded total variation. It is an alternative approach to using a total variation functional as a stabilizer in Tikhonov regularization, {{and it does not}} oversmooth or displace edges...|$|E
40|$|A {{generalized}} model characterizing most remotely sensed data pixel-level fusion techniques is {{very important}} for theoretical analysis and applications. This paper focuses on the establishment of a generalized model for most data fusion methods, which is helpful to quantitatively analyze and quickly implement different data fusion techniques. As an example, the PCA fusion method is selected to demonstrate the availability of the generalized model through the generalized model based implementation. 1. NOMENCLATURE xs k th: the k band of the lower resolution multispectral image; pan: the higher resolution panchromatic band; L pan: the degraded panchromatic band; n pan A: approximation coefficients after n level GLP (Generalized Laplacian Pyramid) or a trous wavelet decomposition; n pan D: detail coefficients after n level GLP or a trous wavelet decomposition; L xsk: the k th band of multispectral <b>image</b> <b>resampled</b> or relatively processed to have same size as the panchromatic band; H xs k th: the k band of the higher resolution multispectral image after fusion; L xs k, i, j) : the pixel value of location (i,j) of the ban...|$|R
40|$|Geometry <b>images</b> <b>resample</b> {{meshes to}} {{represent}} them as texture for efficient GPU processing by forcing a regular parameterization that often incurs {{a large amount of}} distortion. Previous approaches broke the geometry image into multiple rectangular or irregular charts to reduce distortion, but complicated the automatic level of detail one gets from MIP-maps of the geometry image. We introduce triangular-chart geometry images and show this new approach better supports the GPU-side representation and display of skinned dynamic meshes, with support for feature preservation, bounding volumes and view-dependent level of detail. Triangular charts pack efficiently, simplify the elimination of T-junctions, arise naturally from an edge-collapse simplification base mesh, and layout more flexibly to allow their edges to follow curvilinear mesh features. To support the construction and application of triangular-chart geometry images, this paper introduces a new spectral clustering method for feature detection, and new methods for incorporating skinning weights and skinned bounding boxes into the representation. This results in a ten-fold improvement in fidelity when compared to quadchart geometry images...|$|R
50|$|GD {{can create}} images {{composed}} of lines, arcs, text (using program-selected fonts), other images, and multiple colors. Version 2.0 adds support for truecolor <b>images,</b> alpha channels, <b>resampling</b> (for smooth resizing of truecolor images), {{and many other}} features.|$|R
