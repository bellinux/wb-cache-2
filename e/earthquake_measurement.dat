7|96|Public
5000|$|Charles Richter, {{who created}} the <b>earthquake</b> <b>measurement</b> scale; ...|$|E
50|$|For {{the fiscal}} years 2007 to 2009 the hit rate was over 75%. In fiscal year 2010, the hit rate {{came down to}} 28% due {{to the number of}} {{aftershocks}} following the 2011 Tōhoku earthquake and tsunami, which occurred near the end of fiscal year 2010. The hit rate for that year had been 72% until the Tohoku <b>earthquake.</b> <b>Measurement</b> techniques have subsequently been refined to ignore small scale earthquakes; the hit rate for fiscal year 2011 increased to 56%. The JMA aimed to increase the hit rate to over 85% in fiscal year 2015.|$|E
40|$|A {{simplified}} {{instrument for}} the direct measurement of one {{point on the}} response spectrum of the ground motion caused by strong-motion earthquakes is described, and the theory of operation is developed. Determinations of the physical characteristics of two test instruments of a standardized design suitable for large scale production and installation are discussed. Direct comparisons between the instrument results and the spectrum analysis of base accelerations are given, and the conclusion is reached that the device {{in its present form}} is suitable for the contemplated application to strong-motion <b>earthquake</b> <b>measurement...</b>|$|E
40|$|Data from <b>earthquake</b> <b>measurements</b> using a Nano-Resolution Pressure Sensor and a {{co-located}} Ocean Bottom Seismometer {{have been}} compared and analyzed. It is {{shown that the}} Nano-Resolution Pressure Sensor {{can serve as a}} vertical OBS. Moreover, using the pressure sensor in conjunction with a seismometer helps to separate the ocean and seismic signals. Comment: 6 pages, 3 figure...|$|R
5000|$|... Developed by Seiji Tsuboi {{for quick}} {{estimation}} of the tsunami potential of large near-coastal <b>earthquakes</b> from <b>measurements</b> of the P-waves, and later extended to telesesmic earthquakes in general.|$|R
50|$|In {{the month}} {{prior to the}} 1989 Loma Prieta <b>earthquake</b> <b>measurements</b> of the earth's {{magnetic}} field at ultra-low frequencies by a magnetometer in Corralitos, California, just 7 km from {{the epicenter of the}} impending earthquake, started showing anomalous increases in amplitude. Just three hours before the quake the measurements soared to about thirty times greater than normal, with amplitudes tapering off after the quake. Such amplitudes had not been seen in two years of operation, nor in a similar instrument located 54 km away. To many people such apparent locality in time and space suggested an association with the earthquake.|$|R
30|$|The {{current study}} {{examined}} whether embedding scientific phenomena within {{the space of}} the classroom would increase students’ knowledge of earth science concepts, <b>earthquake</b> <b>measurement,</b> and seismological skills beyond that of a non-embedded control condition. Furthermore, the study also investigated the role of spatial skills in learning in an Embedded Phenomenon setting. Repeated measures analysis of variance (ANOVA) was used to determine the effect of embedding a condition on various learning and skill outcomes. In order to analyze the effects of spatial skills on learning outcomes in the embedded condition and in the non-embedded condition, linear regressions were conducted and interactions were followed up with tests of simple slopes.|$|E
30|$|In {{a diverse}} Midwestern {{elementary}} school (67.7 % white) in the USA, 44 fifth grade students (10 -year olds) participated as intact classes across 2 consecutive {{years with the}} same teacher. There were 26 students (56 % boys) in the Embedded Phenomena condition and 18 students (50 % boys) in the non-embedded condition. No differences were seen between boys (M[*]=[*] 5.09, SD[*]=[*] 2.22) and girls in spatial skills (M[*]=[*] 4.65, SD[*]=[*] 2.08, t < 1), which replicates previous findings for this age group (Voyer, Voyer, & Bryden, 1995). Further, the embedded and non-embedded classes were matched on spatial skills {{as well as on}} earth science concepts and <b>earthquake</b> <b>measurement</b> at pre-test, all ts < 1.10.|$|E
40|$|Staff of the Telemetry Technology Development Department (2664) have, {{in support}} of the U. S. Interior Department Mineral Management Services (MMS), {{developed}} and deployed the Seafloor <b>Earthquake</b> <b>Measurement</b> System IV (SEMS IV). The result of this development project is a series of three fully operational seafloor seismic monitor systems located at offshore platforms: Eureka, Grace, and Irene. The instrument probes are embedded from three to seven feet into the seafloor and hardwired to seismic data recorders installed top side at the offshore platforms. The probes and underwater cables were designed to survive the seafloor environment with an operation life of five years. The units have been operational for two years and have produced recordings of several minor earthquakes in that time. Sandia Labs will transfer operation of SEMS IV to MMS contractors in the coming months. 29 figs., 25 tabs...|$|E
50|$|IMD also {{operates}} {{seismic monitoring}} centres at key locations for <b>earthquake</b> monitoring and <b>measurements.</b>|$|R
40|$|To detect coseismic {{electromagnetic}} radiation associated with aftershocks of the 1995 Hyogoken-nanbu <b>earthquake,</b> <b>measurements</b> of vertical electric field component {{were carried out}} near the Nojima fault on Awaji Island. Using a ball antenna and a seismometer, both electric field and vertical ground motion were digitally recorded, triggered by the ground motion. The frequency response of the observation system is almost flat from 1 Hz to 200 Hz for the electric field measurement. Although triggered records for about 170 aftershocks were obtained during the observation period from March 18 to April 2, 1995, no coseismic electromagnetic signal was detected. A possible reason is that a shallow and large aftershock did not occur near the observation site during the observation period...|$|R
2500|$|Probably {{the most}} celebrated seismo-electromagnetic event ever, {{and one of the}} most {{frequently}} cited examples of a possible [...] earthquake precursor, is the 1989 Corralitos anomaly. In the month prior to the 1989 Loma Prieta <b>earthquake</b> <b>measurements</b> of the earth's magnetic field at ultra-low frequencies by a magnetometer in Corralitos, California, just 7km from the epicenter of the impending earthquake, started showing anomalous increases in amplitude. Just three hours before the quake the measurements soared to about thirty times greater than normal, with amplitudes tapering off after the quake. Such amplitudes had not been seen in two years of operation, nor in a similar instrument located 54km away. To many people such apparent locality in time and space suggested an association with the earthquake.|$|R
40|$|International Telemetering Conference Proceedings / September 28 - 30, 1982 / Sheraton Harbor Island Hotel and Convention Center, San Diego, CaliforniaA Seafloor <b>Earthquake</b> <b>Measurement</b> System for {{measuring}} strong motion seismic data {{has been developed}} and tested by Sandia National Laboratories {{as part of the}} Department of Energy Offshore Instrumentation Program. The system’s function is to gather data for the design and regulation of offshore structures such as oil platforms and pipelines. The seafloor package is a self-contained unit capable of operating unattended for up to one year with data readout on command via an underwater acoustic telemetry system. One of the problems with such a system is the large memory required to store seismic data. This memory also must consume very little power to conserve battery life. To meet these conditions a combination low-power CMOS buffer memory and a one-million-bit magnetic bubble main memory with switched power was developed. This paper describes these memories and how they are controlled by a microprocessor to save the “best” data since the last data readout...|$|E
40|$|The {{purpose of}} the present study is to clarify the crustal tilt before and after the Izu-Hanto-Toho-Oki <b>earthquake.</b> The <b>measurements</b> of crustal tilt at the Usami {{observation}} site has been carried out by using two sets of TEM-tiltmeters since July 1979. The pre- and coseismic tilt changes are clarified by a comparison with the predicted tilt...|$|R
40|$|The {{purpose of}} the {{research}} was to estimate P-wave rupture durations (Tdur), dominant periods (Td) and rupture durations greater than 50 seconds (T 50 Ex) for two large, shallow earthquakes, which occurred {{off the coast of}} Sumatra on 6 April and 25 October 2010. Although both earthquakes had similar parameters of magnitude and focal depth, the 25 October event (Mw= 7. 8) generated a tsunami while the 6 April event (Mw= 7. 8) did not. Analysis of the above stated parameters helped understand the mechanisms of tsunami generation of these two <b>earthquakes.</b> <b>Measurements</b> from vertical component broadband P-wave quake velocity records and determination of the above stated parameters could provide a direct procedure for assessing rapidly the potential for tsunami generation. The {{results of the present study}} and the analysis of the seismic parameters helped explain why one event generated a tsunami, while the other one did not...|$|R
40|$|Système pour l’Observation de la Terre {{images are}} used to map ground {{displacements}} induced by earthquakes. Deformations �offsets � induced by stereoscopic effect and roll, pitch, and yaw of satellite and detector artifacts are estimated and compensated. Images are then resampled in a cartographic projection with a low-bias interpolator. A subpixel correlator in the Fourier domain provides twodimensional offset maps with independent measurements approximately every 160 m. Biases on offsets are compensated from calibration. High-frequency noise � 0. 125 m � 1 � is � 0. 01 pixels. Low-frequency noise �lower than 0. 001 m � 1 � exceeds 0. 2 pixels and is partially compensated from modeling. Applied to the Landers <b>earthquake,</b> <b>measurements</b> show the fault with an accuracy of a few tens of meters and yields displacement on the fault with an accuracy of better than 20 cm. Comparison with a model derived from geodetic data shows that offsets bring {{new insights into the}} faulting process. © 2000 Optical Society o...|$|R
50|$|A creepmeter is an {{instrument}} that monitors the slow surface displacement of an active geologic fault in the earth. Its function is to record the slow, aseismic creep between <b>earthquakes.</b> The <b>measurement</b> range of a creepmeter is usually limited to 10-30 mm. Approximately 40 creepmeters are in operation in California—most are operated by the United States Geological Survey (USGS), but nine are maintained by the University of Colorado.|$|R
40|$|Data from <b>earthquake</b> <b>measurements</b> using a Nano-Resolution Pressure Sensor and a {{co-located}} Ocean Bottom Seismometer {{have been}} compared and analyzed. It is {{shown that the}} Nano-Resolution Pressure Sensor {{can serve as a}} vertical OBS. Moreover, using the pressure sensor in conjunction with a seismometer helps to separate the ocean and seismic signals. Background The key sensing instruments used for detecting tsunamis are inherently digital pressure transducers manufactured by Paroscientific, Inc. Advances in counting circuitry and signal processing have improved the resolution of these quartz crystal resonator pressure sensors and accelerometers to a sensitivity of parts-per-billion (nano-resolution) over an extended spectrum. These sensors are used in remote and cabled tsunami warning applications including the NOAA DART System and the Japan Trench Tsunami Observation System [1]. In 2010 - 2011, the first field tests of a nano-resolution pressure sensor were conducted at the Monterey Accelerated Research System (MARS) cabled observatory at a depth of about 900 meters. Comparisons were made to the standard resolution pressure sensor used in the DART System’...|$|R
30|$|Regarding {{the problem}} of {{earthquake}} intensity estimation, Burks et al. [36] showed that Twitter can provide useful data to estimate shaking intensity. They proposed an approach that combines earthquake characteristics, measured using seismographs (such as moment magnitude, source-to-site distance, and wave velocity), with Twitter data (extracted from tweets that contained the term ‘earthquake’). Conditioned {{by a set of}} reports retrieved from seismographs, they segmented the area around each recording station into nine radial subareas. They mapped to each of these areas, according to GPS location, all of the earthquake-related tweets produced during the 10 -minutes posterior to an earthquake. They computed lexical features for each disc to study the correlation of these features with the Mercalli intensity. The authors showed good prediction of earthquake shaking intensity when combining <b>earthquake</b> <b>measurements</b> with tweets. In our work we use some of the same tweet features used by Burks et al. However, our method differs from theirs in that our goal is to provide rapid Mercalli estimates only using social media data, without seismograph recordings. We aim towards understanding the full contribution of social media for intensity estimation, as well as avoiding dependence on a dense seismographic networks.|$|R
5000|$|Although {{wireless}} sensor nodes {{have existed}} {{for decades and}} used for applications as diverse as <b>earthquake</b> <b>measurements</b> to warfare, the modern development of small sensor nodes {{dates back to the}} 1998 Smartdust project and the NASA Sensor Webs Project One of the objectives of the Smartdust project was to create autonomous sensing and communication within a cubic millimeter of space. Though this project ended early on, it led to many more research projects. They include major research centres in Berkeley NEST [...] and CENS. The researchers involved in these projects coined the term mote to refer to a sensor node. The equivalent term in the NASA Sensor Webs Project for a physical sensor node is pod, although the sensor node in a Sensor Web can be another Sensor Web itself. Physical sensor nodes have been able to increase their capability in conjunction with Moore's Law. The chip footprint contains more complex and lower powered microcontrollers. Thus, for the same node footprint, more silicon capability can be packed into it. Nowadays, motes focus on providing the longest wireless range (dozens of km), the lowest energy consumption (a few uA) and the easiest development process for the user.|$|R
40|$|ABSTRACT After a brief (incomplete) {{review of}} pre-seismic (strain-producing) phenomena, we {{describe}} our findings about the pre-seismic {{phase of the}} the April 6, 2009 L’Aquila earthquake, giving a few more details with respect to previous papers. Most past observations of crustal strain did not detect any pre-seismic deformation and {{have been used to}} constrain the size and strength of the source of possible pre-seismic phenomena. With respect to these, we performed a rather more sophisticated approach to the physics of the model; limited the volume of the possible earthquake preparation zone to less than 100 km 3; showed some evidence of dilatancy of saturated rock over the earthquake causative fault (maybe related to the foreshocks) and constrained the prerupture nucleation slip in the hypocentral region to a moment less than 0. 00005 % of the main shock seismic moment (lowering the previous thresholds). Key words: L’Aquila <b>earthquake,</b> strain <b>measurements,</b> <b>earthquake</b> prediction. 1. Brief review of pre-seismic phenomena (mainly) from continuos near-field strain measurements 1. 1. Basic...|$|R
40|$|Dynamic {{property}} {{measurements of}} the moment-resisting steel-frame University of California, Los Angeles, Factor building are being made to assess how forces are distributed over the building. Fourier amplitude spectra have been calculated from several intervals of ambient vibrations, a 24 -hour period of strong winds, and from the 28 March 2003 Encino, California (M_L = 2. 9), the 3 September 2002 Yorba Linda, California (M_L= 4. 7), and the 3 November 2002 Central Alaska (M_w= 7. 9) <b>earthquakes.</b> <b>Measurements</b> made from the ambient vibration records show that the first-mode frequency of horizontal vibration is between 0. 55 and 0. 6 Hz. The second horizontal mode has a frequency between 1. 6 and 1. 9 Hz. In contrast, the first-mode frequencies measured from earthquake data are about 0. 05 to 0. 1 Hz lower than those corresponding to ambient vibration recordings indicating softening of the soil-structure system as amplitudes become larger. The frequencies revert to pre-earthquake levels within five minutes of the Yorba Linda earthquake. Shaking due to strong winds {{that occurred during the}} Encino earthquake dominates the frequency decrease, which correlates in time with the duration of the strong winds. The first shear wave recorded from the Encino and Yorba Linda earthquakes takes about 0. 4 sec to travel up the 17 -story building...|$|R
40|$|The Hyogo-Ken-Nanbu Earthquake caused heavy {{damage in}} Kobe {{city and its}} {{surrounding}} area. To clear the relationship between damage and local site effect, {{a month after the}} <b>earthquake,</b> microtremor <b>measurement</b> was performed for about a year. According to the measurement results in the damaged zone, the amplification factor (A) ranges between 2 and 3 which is not so high. However the predominant frequency (F) ranges between 1. 5 and 2 Hz which corresponds to that of strong motion. Distribution of vulnerability index Kg value for ground confirmed the damage belt...|$|R
40|$|PLOPS system {{designed}} to provide high-resolution measurement of change in optical length from optical-system source to any optical reflector, including diffuse reflector. Serves as adjustable optical ruler, providing high resolution in measurements of small and large changes in distance to target. Use is broad and includes most measurement situations requiring information on length, vibration, and their derivatives. Applications include building dynamics, remote sensing of vibrations in such systems as turbine-based machinery, monitoring of structural dynamics, noncontacting sensing of surface contours, measurement of large strains as in <b>earthquake</b> monitoring, <b>measurement</b> of atmospheric dynamics and turbulence, high-resolution sensing of humidity, detection of surface acoustic waves by optical microscopy, and related areas...|$|R
40|$|This {{work is a}} {{study of}} the Earths free {{oscillations}} considering a merge of solid and liquid model. At the turn of 19 th century Geophysicists presented the theory of the free oscillations for a self-gravitating, isotropic and compressible sphere. Assuming a steel structure for an Earth size sphere, they predicted a period of oscillation of about 1 hour. About 50 years later, the free oscillations of stars was studied by Cowling and others. They classified the oscillation modes of the stars into acoustic and gravity modes {{on the basis of their}} driving forces. These are pressure and buoyancy forces respectively. The earliest measurements for the period of the free oscillations of the Earth was made by Benyove from a study of Kamchathca earthquake. Since then, the Geophysicists have been trying to provide a theoretical basis for these measurements. Recently, the theory concerning oscillations of celestial fluids is extended by Sobouti to include the possible oscillations of the Earthlike bodies. Using the same technique, we study the free oscillations of a spherically symmetric, non-rotating and elastic model for the Earth.   We used the actual data of the Earths interior structure in our numerical calculations. Numerical results show that there exist three distinct oscillation modes namely acoustic, gravity and toroidal modes. These modes are driven by pressure, buoyancy and shear forces respectively. The shear force is due to the elastic properties of the solid part of the Earth. Our numerical results are consistent with the seismic data recorded from <b>earthquake</b> <b>measurements...</b>|$|R
40|$|The brain {{keeps its}} overall {{dynamics}} in a corridor of intermediate activity {{and it has}} been a long standing question what possible mechanism could achieve this task. Mechanisms from the field of statistical physics have long been suggesting that this homeostasis of brain activity could occur even without a central regulator, via self-organization on the level of neurons and their interactions, alone. Such physical mechanisms from the class of self-organized criticality exhibit characteristic dynamical signatures, similar to seismic activity related to <b>earthquakes.</b> <b>Measurements</b> of cortex rest activity showed first signs of dynamical signatures potentially pointing to self-organized critical dynamics in the brain. Indeed, recent more accurate measurements allowed for a detailed comparison with scaling theory of non-equilibrium critical phenomena, proving the existence of criticality in cortex dynamics. We here compare this new evaluation of cortex activity data to the predictions of the earliest physics spin model of self-organized critical neural networks. We find that the model matches with the recent experimental data and its interpretation in terms of dynamical signatures for criticality in the brain. The combination of signatures for criticality, power law distributions of avalanche sizes and durations, as well as a specific scaling relationship between anomalous exponents, defines a universality class characteristic of the particular critical phenomenon observed in the neural experiments. The spin model is a candidate for a minimal model of a self-organized critical adaptive network for the universality class of neural criticality. As a prototype model, it provides the background for models that include more biological details, yet share the same universality class characteristic of the homeostasis of activity in the brain. Comment: 17 pages, 5 figure...|$|R
50|$|Seismic {{waves are}} {{vibrations}} that {{travel through the}} Earth's interior or along its surface. The entire Earth can also oscillate in forms that are called normal modes or free oscillations of the Earth. Ground motions from waves or normal modes are measured using seismographs. If the waves come from a localized source such as an <b>earthquake</b> or explosion, <b>measurements</b> at more than one location {{can be used to}} locate the source. The locations of earthquakes provide information on plate tectonics and mantle convection.|$|R
5000|$|The V-shaped Lau Basin {{was opened}} by two southward {{propagating}} spreading centers: the Central Lau Spreading Center (CLSC) and the East Lau Spreading Center (ELSC). The initial ELSC was oriented north-south {{and has a}} spreading rate of ~100mm/yr. The northeastern tip of ELSC propagated southward faster than the other part and produced a [...] oriented 170 degree. The ELSC rotated 15-25 degree clockwise and continued to propagate towards the south. Then the CLSC, {{as well as an}} extensional transform zone (ETZ) linking the two spreading centers were formed. The CLSC propagated southwards and replaced the northern segment ELSC. The region of overlap of CLSC and ELSC is characterized by strike-slip <b>earthquakes.</b> Recent <b>measurements</b> have shown that the opening rates are increasing at ELSC and CLSC. At present, the spreading rate of Lau Basin is about 150mm/year. It {{is an example of a}} fast-spreading back-arc basin.|$|R
2500|$|GPS {{has become}} a {{ubiquitous}} and life-changing technology and critical to military operations. Most current cell phones, for example, include receivers, enabling block-by-block directions for pedestrians and drivers alike. [...] Civilian airplanes have also incorporated GPS receivers for navigation. [...] Indeed, {{with the help of}} GPS, airplanes are now capable of performing landings on autopilot, and doing so with better precision and safety than human pilots. GPS is being tested for <b>earthquake</b> detection and <b>measurement.</b> The timing systems integral to GPS see use in internet and web technologies.. Parkinson was inducted into the Inventors Hall of Fame in 2004 ...|$|R
5000|$|Md designates various scales that {{estimate}} magnitude {{from the}} duration or length of {{some part of}} the seismic wave-train. This is especially useful for measuring local or regional earthquakes, both powerful earthquakes that might drive the seismometer off-scale (a problem with the analog instruments formerly used) and preventing measurement of the maximum wave amplitude, and weak earthquakes, whose maximum amplitude is not accurately measured. Even for distant earthquakes, measuring the duration of the shaking (as well as the amplitude) provides a better measure of the <b>earthquake's</b> total energy. <b>Measurement</b> of duration is incorporated in some modern scales, such as [...] and [...]|$|R
40|$|It is well {{recognized}} that the in situ measurements of S- and P-wave velocities give us elastic constants of the subsoil layers, since we have ample data on the densities of the formations concerned. These constants, especially the rigidity of each formation, are inevitably necessary in elucidating the vibration characteristics of {{the ground in the}} principal portion of an earthquake. In view of the importance of such information in <b>earthquake</b> engineering, <b>measurements</b> of S-wave velocities in the strata near the surface drew the keen interest of seismologists and technologists engaged in the prevention of earthquake disasters. We have therefore made a series of such surveys in Tokyo Metropolis to develop a more efficient method of survey as well as to accumulate all the data necessary for the calculation of transfer function of the subsoil layers for S-waves (which constitute the principal motions in near earthquakes). The Metropolitan Government is now in urgent need of a map of intensity distribution in an imminent earthquake, for its hazard estimation throughout its jurisdiction...|$|R
40|$|This paper {{deals with}} the {{applicability}} of system realization using the information matrix (SRIM) system identification technique combined with moving time windows (called WSRIM) in order to evaluate the time-varying dynamic properties and damage of a building based on its real earthquake records considering the soil-structure interaction effect. Successive short segments of inputs and their corresponding output signals are selected and structural properties exhibited during that segment of time are identified. Both numerical simulation and real <b>earthquake</b> response <b>measurements</b> from several floors and foundations are utilized to verify {{the accuracy of the}} proposed time-varying system identification technique. In addition, the seven-storey reinforced concrete building of the Civil and Environmental Engineering Department at the National Chung Hsing University experienced moderate structural damage during the 1999 Taiwan Chi-Chi earthquake. This paper evaluated the time-varying modal parameters of this building on the basis of records of its acceleration response to the Chi-Chi earthquake main shock and its numerous after-shocks. It is proved that the proposed system identification technique is useful for real-time dynamic property estimation and damage assessment of buildings...|$|R
40|$|Two monuments from an 1855 {{cadastral}} survey that span the San Andreas fault in the Carrizo Plain have been right-laterally displaced 11. 0 ± 2. 5 m by the 1857 Fort Tejon earthquake and associated seismicity and afterslip. This measurement confirms {{that at least}} 9. 5 ± 0. 5 m of slip occurred along the main fault trace, as suggested by measurements of offset channels near Wallace Creek. The slip varied by 2 to 3 m along a 2. 6 -km section of the main fault trace. Using radiocarbon dates of the penultimate large <b>earthquake</b> and <b>measurements</b> of slip from the 1857 earthquake, we calculate an apparent slip rate for the last complete earthquake cycle that is at least 25 % lower than the late-Holocene slip rate on the main fault trace. Comparison of short-term broad-aperture strain accumulation rates with the narrow-aperture late-Holocene slip rate indicates that the fault behaves nearly elastically over a time scale of several earthquake cycles. Therefore, slip in future earthquakes should compensate the slip-rate deficit from the 1857 earthquake...|$|R
40|$|The dynamic {{characteristics}} of two representative R/C bridges on Egnatia Odos motorway in Greece are estimated based on low amplitude ambient and earthquake-induced vibrations. The present work outlines the instrumentation details, algorithms for computing modal characteristics (modal frequencies, damping ratios and modeshapes), modal-based {{finite element model}} (FEM) updating methods for estimating structural parameters, and numerical results for the modal and structural {{dynamic characteristics}} of the two bridges based on ambient and earthquake induced vibrations. Transverse, bending and longitudinal modes are reliably identified and stiffness-related properties of the piers, deck and elastomeric bearings of the FEMs of the two bridges are estimated. Results provide qualitative and quantitative information on the dynamic behavior of the bridge systems and their components under low-amplitude vibrations. Modeling assumptions are discussed based on {{the differences in the}} characteristics identified from ambient and <b>earthquake</b> vibration <b>measurements.</b> The sources of the differences observed between the identified modal and structural characteristics of the bridges and those predicted by FEMs used for design are investigated and properly justified...|$|R
40|$|The {{maximum depth}} of {{sediment}} biomixing {{is directly related}} to the vertical extent of post-depositional environmental alteration in the sediment; consequently, it is important to determine the maximum burrowing depth. This study examined the maximum depth of bioturbation in a natural marine environment in Funakoshi Bay, northeastern Japan, using observations of bioturbation structures developed in an event layer (tsunami deposits of the 2011 Tohoku-Oki <b>earthquake)</b> and <b>measurements</b> of the radioactive cesium concentrations in this layer. The observations revealed that the depth of bioturbation (i. e., the thickness of the biomixing layer) ranged between 11 and 22 cm, and varied among the sampling sites. In contrast, the radioactive cesium concentrations showed that the processing of radioactive cesium in coastal environments may include other pathways in addition to bioturbation. The data also revealed the nature of the bioturbation by the heart urchin Echinocardium cordatum (Echinoidea: Loveniidae), which is one of the important ecosystem engineers in seafloor environments. The maximum burrowing depth of E. cordatum in Funakoshi Bay was 22 cm from the seafloor surface...|$|R
40|$|A {{quantitative}} {{measure of}} the Modified Mercalli Intensity Scale for earth-quakes in ~he western United States has been developed by correlating the peak seismoscope relative displacement response, Sd, with the reported site intensity, IMM. This correlation can be approximated by 1 100. 288 IMM for IMM =< VIII and is characterized by one standard deviation of about 0. 7 Sa. The data {{used in this study}} do not indicate an obvious type of dependence of Sa on local site conditions. A method for computing the analog of the local earthquake magnitude, Mseismoscope, has been presented for possible use in strong-motion seismol-ogy and for sealing <b>earthquakes</b> by close-in <b>measurements,</b> when other seismo-logical instruments may go off scale...|$|R
