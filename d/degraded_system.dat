68|1400|Public
5000|$|The policy {{allowing}} the easy creation of multiple accounts {{by the same}} real person was attributed to <b>degraded</b> <b>system</b> performance, and increased incidence of griefing. The ability for a single real individual to create an unlimited number of accounts for free could {{have the effect of}} highly exaggerating the [...] "residence" [...] figures. Blogs and forum posts regularly allege exaggerated membership and performance claims.|$|E
50|$|In {{circumstances}} where {{the amount of}} free physical memory is low and paging is fairly prevalent, any performance gains provided by the compression system (compared to paging directly to and from auxiliary storage) may be offset by an increased page fault rate that leads to thrashing and <b>degraded</b> <b>system</b> performance. In an opposite state, where enough physical memory is available and paging activity is low, compression may not impact performance enough to be noticeable. The middle ground between these two circumstanceslow RAM with high paging activity, and plenty of RAM with low paging activityis where virtual memory compression may be most useful. However, the more compressible the program data is, the more pronounced are the performance improvements as less physical memory is needed to hold the compressed data.|$|E
40|$|System {{degradation}} {{was usually}} caused by multiple-parameter degradation. The assessment result of system reliability by universal generating function was low accurate {{when compared with}} the Monte Carlo simulation. And the probability density function of the system output performance cannot be got. So the reliability assessment method based on the probability density evolution with multi-parameter was presented for complexly <b>degraded</b> <b>system.</b> Firstly, the system output function was founded according to the transitive relation between component parameters and the system output performance. Then, the probability density evolution equation based on the probability conservation principle and the system output function was established. Furthermore, probability distribution characteristics of the system output performance was obtained by solving differential equation. Finally, the reliability of the <b>degraded</b> <b>system</b> was estimated. This method did not need to discrete the performance parameters and can establish continuous probability density function of the system output performance with high calculation efficiency and low cost. Numerical example shows that this method is applicable to evaluate the reliability of multi-parameter <b>degraded</b> <b>system...</b>|$|E
40|$|Design of {{gracefully}} <b>degrading</b> <b>systems,</b> where functionality {{is gradually}} reduced {{in the face}} of faults, has traditionally been a very difficult and error-prone task. General approaches to graceful degradation are typically limited to re-implementation of the system for a number of pre-designated fallback configurations. We describe an architecture-based approach to gracefully <b>degrading</b> <b>systems</b> based upon Product Family Architectures (PFAs) combined with automatic reconfiguration...|$|R
40|$|We have {{developed}} measures which combine both {{the reliability and}} the performance characteristics of com-puting systems. These measures are particularly useful in comparing traditional computer architectures, such as uniprocessors and standby redundant <b>systems,</b> with gracefully <b>degrading</b> <b>systems.</b> Mu 1 tiprocessors and dis-tri buted systems are examples of gracefully <b>degrading</b> <b>systems</b> which react to a detected failure by reconfig-uring to a state with a decreased level of performance. Index Terms Computer re 1 iabil i ty, computer performance, grace-fully <b>degrading</b> computer <b>systems.</b> In general, systems with multiple copies of a resourc...|$|R
40|$|Design Reference Missions (DRM) : Integrated ODM Air-Taxi Mission Features, Hybrid Electric Integrated System Testbed (HEIST) flight control. Structural Health, Energy Storage, Electric Components, Loss of Control, <b>Degraded</b> <b>Systems,</b> System Health, Real-Time IO Operator Geo-Fencing, Regional Noise Abatement and Trusted Autonomy Inter-operability...|$|R
40|$|This paper {{considers}} the controllability analysis and fault tolerant control {{problem for a}} class of hexacopters. It is shown that the considered hexacopter is uncontrollable when one rotor fails, even though the hexacopter is over-actuated and its controllability matrix is row full rank. According to this, a fault tolerant control strategy is proposed to control a <b>degraded</b> <b>system,</b> where the yaw states of the considered hexacopter are ignored. Theoretical analysis indicates that the <b>degraded</b> <b>system</b> is controllable {{if and only if}} the maximum lift of each rotor is greater than a certain value. The simulation and experiment results on a prototype hexacopter show the feasibility of our controllability analysis and degraded control strategy. Comment: 21 pages, 7 figures, submitted to Journal of Intelligent & Robotic System...|$|E
30|$|In {{spite of}} their {{numerous}} advantages, MIMO-CDMA systems suffer from a major drawback in MAI which can reduce their capacity and increase their BER, thus resulting in a <b>degraded</b> <b>system</b> performance. Hence, a statistical analysis of MAI becomes a very {{important factor in the}} performance analysis of these systems.|$|E
30|$|In the Reference scenario, {{different}} color areas can be noted, indicating a certain variability {{of the traffic}} flow over time. The initial high traffic conditions of the Alternative scenario cause a uniform distribution of the vehicles, highlighted by a flatter coloration. As expected, the CWD lane flow reaches the maximum value allowed by the <b>degraded</b> <b>system</b> of the Alternative scenario (20 veh/min), confirming the previous platoon considerations.|$|E
40|$|This paper {{considers}} a condition-based maintenance model for continuously <b>degrading</b> <b>systems</b> under continuous monitoring. After maintenance, {{the states of}} the system are randomly distributed with residual damage. We investigate a realistic maintenance policy, referred to as condition-based availability limit policy, which achieves a maximum availability level of such systems. The optimum maintenance threshold is determined using a search algorithm. A numerical example for a <b>degrading</b> <b>system</b> modeled by a Gamma process is presented to demonstrate this policy in practical applications...|$|R
40|$|International audienceSIPM-OOFDM {{having an}} extra {{subcarrier}} index-power information-bearing dimension is, {{for the first}} time, proposed and investigated, which, compared to conventional OOFDM, offers considerable signal transmission capacity improvement without <b>degrading</b> <b>system</b> power budget and dispersion/nonlinearity tolerances...|$|R
40|$|Design of {{gracefully}} <b>degrading</b> <b>systems,</b> where functionality {{is gradually}} reduced {{in the face}} of faults, has traditionally been a very difficult and error-prone task. General approaches to graceful degradation are typically limited to re-implementation of the system for a number of pre-designated fallback configurations. We describe an architecture-based approach to gracefully <b>degrading</b> <b>systems</b> based upon Product Family Architectures (PFAs) combined with automatic reconfiguration. A PFA is a region of a system design space populated by different, but related, products sharing similar architectures and components. Each system instance within a PFA yields a distinct price/performance point, and represents a different model in the product family. The unifying mechanism that joins PFAs and gracefully <b>degrading</b> <b>systems</b> is automatic reconfiguration â€“ {{in the face of}} a fault, the system reconfigures to a different PFA configuration point that optimizes the functionality available with the remaining resources. In this process, the system sheds some of the non-critical functions that make up such a large percentage of modern embedded systems. System designers can also exploit a reconfiguration mechanism to provide graceful upgrade and unique logistical benefits. The RoSES (Robust Self-configuring Embedded Systems) project employs such a reconfiguration approach, seeking to create a revolutionary means to build self-customizing, distributed, embedded control systems...|$|R
40|$|A modular {{approach}} {{for assessing the}} affects of radiation environments on man in operational systems has been developed. The feasibility of the model has been proved and the practicality has been assessed. It {{has been applied to}} one operational system to date and information obtained has been submitted to systems analysts and mission planners for the assessment of man's vulnerability and impact on systems survivability. In addition, the model has been developed so that the radiobiological data can be input to a sophisticated man-machine interface model to properly relate the radiobiological stress with other mission stresses including the effects of a <b>degraded</b> <b>system...</b>|$|E
40|$|Abstract: The paper {{presents}} {{a model of}} multistage <b>degraded</b> <b>system</b> subjected to random failures and partial repairs. A transient analysis is performed and transient probabilities are calculated to find the availability, the means of life time and operational life time. In the paper, constant state dependent transition rates for the degradation process as well as failure process are considered. On the other hand the partial repairs follow general distributions. This paper extends previous systems that {{can be considered as}} particular cases of this one. Numerical examples are provided to illustrate applicability of the expressions that are obtained throughout the paper. ...|$|E
40|$|When {{faced with}} a poor set of {{document}} summaries {{on the first page}} of returned search results, a user may respond in various ways: by proceeding on to the next page of results; by entering another query; by switching to another service; or by abandoning their search. We analyse this aspect of searcher behaviour using a commercial search system, comparing a deliberately <b>degraded</b> <b>system</b> to the original one. Our results demonstrate that searchers naturally avoid selecting poor results as answers given the degraded system; however, the depth of the ranking that they view, their query reformulation rate, and the amount of time required to complete search tasks, are all remarkably unchanged...|$|E
40|$|This {{dissertation}} {{provides a}} study of synchronization and quantization issues in implementing a multistage receiver in fixed-point Digital Signal Processing (DSP) hardware. Current multistage receiver analysis has neglected the e#ects of synchronization and quantization; however, these e#ects can <b>degrade</b> <b>system</b> performance and therefore decrease overall system capacity...|$|R
40|$|New {{priority}} protocol controls {{access to}} token-ring local-area network (LAN) of digital-communication stations over widely ranging mix of low- and high-priority traffic. Protocol, called round-robin priority scheme (RRPS), introduces only small overhead and therefore <b>degrades</b> <b>system</b> performance only minimally. Key messages guaranteed access to local-area network during peak loads...|$|R
40|$|In this letter, {{we present}} a {{numerical}} investigation of impairments due to polarization-mode dispersion (PMD) in chaos-encrypted communication systems. We show that PMD could affect master-slave synchronization, hence <b>degrading</b> <b>system</b> performance at typical PMD values of deployed fiber plants. We also analyze {{the effectiveness of a}} first-order compensation...|$|R
40|$|Repetitive {{control is}} useful if {{periodic}} disturbances or setpoints act on a control system. Perfect (asymptotic) disturbance rejection is achieved if the period time is exactly known. The improved disturbance rejection at the periodic frequency and its harmonics is achieved {{at the expense}} of a <b>degraded</b> <b>system</b> sensitivity at intermediate frequencies. A convex optimization problem is defined for the design of high-order repetitive controllers, where a trade-off can be made between robustness for changes in the period time and for reduction of the error spectrum in-between the harmonic frequencies. The high-order repetitive control algorithms are successfully applied in experiments with the tracking control of a CD-player system...|$|E
40|$|Presented at IEEE Real-Time Systems Symposium (RTSS 2015). 1 to 4, Dec, 2015. San Antonio, U. S. A [...] On uniprocessors, {{a failure}} of the single core means {{unavoidable}} system failure. However, on multicores, when a core fails, it is conceivable that the computation could continue on remaining cores in a <b>degraded</b> <b>system</b> mode indefinitely, until orderly shutdown and servicing can take place. This would be very desirable for critical applications but, apart from hardware and software support, it would require (i) a scheduling approach designed for providing such resilience and (ii) accompanying schedulability analysis, that derives offline the guarantees about the system meeting its deadlines at run-time, even if one core fails...|$|E
40|$|Abstract-The {{phenomenon}} {{where an}} undesirable nonlinear effect gives significantly <b>degraded</b> <b>system</b> performance, and becomes the major drawback for optical communication systems {{is known as}} Four wave mixing. In order to achieve affordable BER and Q-factor, a comparison of a WDM system with equal and unequal channel spacing is performed. The result of the channel spacing can be verified using opt-sim. A channel allocation method, based on the optimal Golomb ruler, that allows the reduction of FWM effect while maintaining bandwidth efficiency, is presented. The two algorithms i. e. Exhaust algorithm and Search algorithm to construct the Golomb ruler sequences are presented here. The result of these two algorithms is compared using Matlab...|$|E
30|$|It {{is evident}} from these figures that the {{probability}} of exceeding the response from a specified threshold for <b>degrading</b> <b>system</b> with mentioned specification is very larger than system without degradation and the linear one. Thus considering these phenomena in reliability analysis and performance-based design of structures can be very important.|$|R
40|$|According to {{the authors}} of recent {{research}} {{published in the journal}} IEEE Transactions on Vehicular Technology, In the uplink of a fiber-based wireless system, the multipath dispersion that is introduced by the wireless link and the nonlinear distortion that is caused by the radio-over-fiber (RoF) link significantly <b>degrade</b> <b>system</b> performance...|$|R
40|$|Ultrahigh-vacuum (UHV) sample-transfer system {{developed}} features short-term (less than 30 minutes) {{transfer of}} samples from atmospheric pressure into sample manipulator within UHV analysis <b>system</b> without significantly <b>degrading</b> <b>system</b> pressure. New system is austere approach to sample transfer, involving no automation. Total cost of system is factor of 10 less than commercially available instruments...|$|R
40|$|Implementing, configuring, {{and running}} an {{information}} filtering {{system in a}} practical setting is a di cult and challenging problem. This is due to variety and configuration of available system components along with additional factors such as topic length, feedback, and system training. Moreover, the interplay between the diâ†µerent components and additional factors can lead to <b>degraded</b> <b>system</b> performance when adding or manipulating particular components. We explore the interactions and eâ†µects of diâ†µerent components {{and some of the}} factors with respect to performance. The main contribution of this paper is {{a better understanding of how}} to configure filtering systems along with the possible pitfalls of applying conflicting components which harm performance and result in a poor user experience...|$|E
40|$|The {{phenomenon}} {{where an}} undesirable nonlinear effect gives significantly <b>degraded</b> <b>system</b> performance, and becomes the major drawback for optical communication systems {{is known as}} Four wave mixing. In order to achieve affordable BER and Q-factor, a comparison of a WDM system with equal and unequal channel spacing is performed. The result of the channel spacing can be verified using opt-sim. A channel allocation method, based on the optimal Golomb ruler, that allows the reduction of FWM effect while maintaining bandwidth efficiency, is presented. The two algorithms i. e. Exhaust algorithm and Search algorithm to construct the Golomb ruler sequences are presented here. The result of these two algorithms is compared using Matlab...|$|E
40|$|International audienceIn {{the field}} of manufacturing, the {{planning}} of opportunistic preventive maintenance actions adapted to minimise the number of unnecessary interruptions to production remains a major industrial challenge. Indeed, maintenance decisions {{have to be made}} in synchronisation with the production demands to eliminate costly unscheduled maintenance shutdowns and to improve productivity as well as quality. To confront this issue, this paper proposes an innovative approach based on the â€˜odds algorithm'. The objective is to select, among all the production stoppages already planned, those which will be optimal to develop maintenance actions in time according to the <b>degraded</b> <b>system</b> state. The optimisation phase incorporates criteria such as reliability, maintainability and the duration of production stoppages. The feasibility of the approach is shown in a sample case...|$|E
30|$|Autophagy is also {{involved}} in the regulation of cGAS activity. During the process of cGAS-mediated immune responses, cGAS associates with Beclin 1, a key regulator of autophagy (Liang et al., 2014). The direct interaction between cGAS and Beclin 1 suppresses cGAS activity and blocks cGAMP synthesis. Moreover, cytoplasmic DNAs are also degraded through the autophagy <b>degrading</b> <b>system.</b>|$|R
40|$|The overall aim of {{this paper}} is to provide a general setting for {{quantitative}} quality measures of Knowledge-Based System behavior which is widely applicable to many Knowledge-Based Systems. We propose a general approach that we call "degradation studies": an analysis of how <b>system</b> output <b>degrades</b> as a function of <b>degrading</b> <b>system</b> input, such as incomplete or incorrect inputs...|$|R
5000|$|Considering the {{hardware}} limitations regarding preservation of {{data in the}} event of sudden power loss and the ineffectiveness of approaches commonly employed by developers to prevent these sorts of losses, many database engines do not by default call FileDescriptor.sync (...) nor FileChannel.force (...) nor fsync or equivalents for every commit because they significantly <b>degrade</b> <b>system</b> performance without significantly increasing durability.|$|R
30|$|The {{simulation}} study layer (see {{the third}} layer in Fig. 1) is proposed for generating controller conflict scenarios {{and developing a}} metrics. In this layer two blocks work parallel and develop each other. The simulation study driver has two main functionalities, scenario generation and scenario modification. Unstable system states in multimodal energy systems are dynamic by definition. To analyze these states though, an approach is needed to deterministically reproduce these system states. The problem is twofold: First, a scenario exploration strategy has {{to be applied to}} identify severe (i.e. performance <b>degraded)</b> <b>system</b> states. Second, based on unstable states recognized in the first step, further examinations are necessary to develop metrics that can later be applied to help identify unstable states (RQ 3).|$|E
40|$|Abstract: In {{the field}} of manufacturing, the {{planning}} of opportunistic preventive maintenance actions adapted to minimise the number of unnecessary interruptions to production remains a major industrial challenge. Indeed, maintenance decisions {{have to be made}} in synchronisation with the production demands to eliminate costly unscheduled maintenance shutdowns and to improve productivity as well as quality. To confront this issue, this paper proposes an innovative approach based on the â€˜odds algorithmâ€™. The objective is to select, among all the production stoppages already planned, those which will be optimal to develop maintenance actions in time according to the <b>degraded</b> <b>system</b> state. The optimisation phase incorporates criteria such as reliability, maintainability and the duration of production stoppages. The feasibility of the approach is shown in a sample case...|$|E
40|$|Coordination is an {{essential}} technique in cooperative, distributed multi-agent systems. However, sophisticated coordination strategies are not always cost-effective in all problemsolving situations. This paper presents a learning method to identify what information will improve coordination in specific problem-solving situations. Learning is accomplished by recording and analyzing traces of inferences after problem solving. The analysis identifies situations in which inappropriate coordination strategies caused redundant activities {{or the lack of}} timely execution of important activities that <b>degraded</b> <b>system</b> performance. To remedy this problem, situation-specific control rules are created that acquire additional nonlocal information about activities in the agent networks and then select a presumably better plan or scheduling strategy. Examples from a real distributed problem-solving application involving diagnosis of a local area network are described. Keywords: Learning, Coordination, [...] ...|$|E
50|$|Since pilot error {{accounts}} for between one-third and 60% of aviation accidents, advances in automation and technology could replace the aircraft pilots after eliminating the Flight Engineer, but in complex situations with severely <b>degraded</b> <b>systems</b> the problem-solving and judgement capability of humans seems {{difficult to achieve}} by automated systems, like the United Airlines Flight 232 or Qantas Flight 32.|$|R
40|$|In {{this paper}} we {{consider}} a condition-based maintenance policy for continuously monitored <b>degrading</b> <b>systems.</b> We investigate a robust maintenance policy, availability limit policy, which ensures that a maximum availability {{level of the}} system is achieved. The optimum degradation threshold level that ensures the desired steady-state availability {{of the system is}} also determined. A numerical example that demonstrates this policy is presented...|$|R
5000|$|Soft the {{usefulness}} of a result degrades after its deadline, thereby <b>degrading</b> the <b>system's</b> quality of service.|$|R
