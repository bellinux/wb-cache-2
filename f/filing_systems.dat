123|10000|Public
25|$|The Office of the Secretary (OSEC) {{oversees the}} receipt and {{distribution}} of documents filed by the public through electronic and paper <b>filing</b> <b>systems</b> and the FCC Library collection. In addition, OSEC publishes legal notices of Commission decisions in the Federal Register and the FCC Record.|$|E
25|$|Use of {{hardware}} RAID cards, {{perhaps in the}} mistaken belief that these will 'help' ZFS. While routine for other <b>filing</b> <b>systems,</b> ZFS handles RAID natively, and is designed {{to work with a}} raw and unmodified low level view of storage devices, so it can fully use its functionality. A separate RAID card may leave ZFS less efficient and reliable. For example ZFS checksums all data, but most RAID cards will not do this as effectively, or for cached data. Separate cards can also mislead ZFS about the state of data, for example after a crash, or by mis-signalling exactly when data has safely been written, and in some cases this can lead to issues and data loss. Separate cards can also slow down the system, sometimes greatly, by adding latency to every data read/write operation, or by undertaking full rebuilds of damaged arrays where ZFS would have only needed to do minor repairs of a few seconds.|$|E
2500|$|The inventions of the typewriter, telephone, and new <b>filing</b> <b>systems</b> offered {{middle class}} women {{increased}} employment opportunities. [...] So too did the {{rapid expansion of}} the school system, and the emergence of the new profession of nursing. [...] Education and status led to demands for female roles in the rapidly expanding world of sports.|$|E
50|$|<b>File</b> <b>system</b> types can be {{classified}} into disk/tape <b>file</b> <b>systems,</b> network <b>file</b> <b>systems</b> and special-purpose <b>file</b> <b>systems.</b>|$|R
40|$|From its inception, UNIX {{has been}} built around two {{fundamental}} entities: processes and files. In this chapter, {{we look at the}} implementation of files in Solaris and discuss the framework for <b>file</b> <b>systems.</b> 14. 1 <b>File</b> <b>System</b> Framework Solaris OS includes a framework, the virtual <b>file</b> <b>system</b> framework, under which multiple <b>file</b> <b>system</b> types are implemented. Earlier implementations of UNIX used a single <b>file</b> <b>system</b> type for all of the mounted <b>file</b> <b>systems,</b> typically, the UFS <b>file</b> <b>system</b> from BSD UNIX. The virtual <b>file</b> <b>system</b> framework was developed to allow Sunâ€™s distributed computing <b>file</b> <b>system</b> (NFS) to coexist with the UFS <b>file</b> <b>system</b> in SunOS 2. 0; it became a standard part of System V in SVR 4 and Solaris OS. We can categorize Solaris <b>file</b> <b>systems</b> into the following types: Storage-based. Regular <b>file</b> <b>systems</b> that provide facilities for persistent storage and management of data. The Solaris UFS and PC/DOS <b>file</b> <b>systems</b> are examples. Network <b>file</b> <b>systems.</b> <b>File</b> <b>systems</b> that provide <b>files</b> that are accessible in a local directory structure but are stored on a remote network server; for example, NFS. Pseudo <b>file</b> <b>systems.</b> <b>File</b> <b>systems</b> that present various abstractions as files in a <b>file</b> <b>system.</b> The /proc pseudo <b>file</b> <b>system</b> represents the address space of a process as a series of files. 657 658 Chapter 14 <b>File</b> <b>System</b> Framework The framework provides a single set of well-defined interfaces that are <b>file</b> <b>system</b> independent; the implementation details of each <b>file</b> <b>system</b> are hidden behind these interfaces. Two key objects represent these interfaces: the virtual file, or vnode, and the virtual <b>file</b> <b>system,</b> or vfs objects. The vnode interfaces implement file-related functions, and the vfs interfaces implement <b>file</b> <b>system</b> management functions. The vnode and vfs interfaces direct functions to specific <b>file</b> <b>systems,</b> {{depending on the type of}} <b>file</b> <b>system</b> being operated on. Figure 14. 1 shows the <b>file</b> <b>system</b> layers. File-related functions are initiated through a system call or from another kernel subsystem and are directed to the appropriate <b>file</b> <b>system</b> by the vnode/vfs layer...|$|R
50|$|Distributed <b>file</b> <b>systems</b> can be {{optimized}} for different purposes. Some, {{such as those}} designed for internet services, including GFS, are {{optimized for}} scalability. Other designs for distributed <b>file</b> <b>systems</b> support performance-0intensive applications usually executed in parallel. Some examples include: MapR <b>File</b> <b>System</b> (MapR-FS), Ceph-FS, Fraunhofer <b>File</b> <b>System</b> (BeeGFS), Lustre <b>File</b> <b>System,</b> IBM General Parallel <b>File</b> <b>System</b> (GPFS), and Parallel Virtual <b>File</b> <b>System.</b>|$|R
2500|$|Before computerization, manual <b>filing</b> <b>systems</b> {{were used}} in large {{fingerprint}} repositories. Manual classification systems {{were based on the}} general ridge patterns of several or all fingers (such as {{the presence or absence of}} circular patterns). This allowed the filing and retrieval of paper records in large collections based on friction ridge patterns alone. [...] The most popular systems used the pattern class of each finger to form a key (a number) to assist lookup in a filing system. [...] Classification systems include the Roscher system, the Juan Vucetich system, and the Henry Classification System. [...] The Roscher system was developed in Germany and implemented in both Germany and Japan, the Vucetich system (developed by a Croatian-born Buenos Aires Police Officer) was developed in Argentina and implemented throughout South America, and the Henry system was developed in India and implemented in most English-speaking countries.|$|E
50|$|Businesses such as doctors, dentists, veterinarians, police, and {{government}} agencies use shelf files and end-tabbed folders to manage large <b>filing</b> <b>systems.</b>|$|E
5000|$|Even {{if there}} are no running {{applications}} or active <b>filing</b> <b>systems,</b> the icon bar will contain a small number of system-managed icons: ...|$|E
50|$|For example, {{to migrate}} a FAT32 <b>file</b> <b>system</b> to an ext2 <b>file</b> <b>system.</b> First {{create a new}} ext2 <b>file</b> <b>system,</b> then copy the data to the <b>file</b> <b>system,</b> then delete the FAT32 <b>file</b> <b>system.</b>|$|R
5000|$|Blue Whale Clustered <b>file</b> <b>system</b> (BWFS) is {{a shared}} disk <b>file</b> <b>system</b> (also called {{clustered}} <b>file</b> <b>system,</b> shared storage <b>file</b> <b>systems</b> or SAN <b>file</b> <b>system)</b> made by Tianjin Zhongke Blue Whale Information Technologies Company in China.|$|R
5000|$|Virtual <b>file</b> <b>system</b> (VFS): A VFS is a <b>file</b> <b>system</b> used to {{help the}} user to hide the {{different}} <b>file</b> <b>systems</b> complexities. A user can use the same standard <b>file</b> <b>system</b> related calls to access different <b>file</b> <b>systems.</b>|$|R
50|$|While {{personal}} furniture {{faded from}} military use, field desks, field <b>filing</b> <b>systems,</b> medical and maintenance storage systems, and similar portable equipment continue in use until the present day; some show continuity in design.|$|E
50|$|Philip D. Coombs {{leaves behind}} {{a legacy of}} digital {{archiving}} and electronic <b>filing</b> <b>systems</b> in Washington State and his work has been studied and used by agencies and state governments all across the United States.|$|E
50|$|The {{cassette}} and ROM <b>filing</b> <b>systems</b> and the Advanced Disc Filing System of Acorn MOS {{feature a}} rudimentary copy protection mechanism where a file {{with a certain}} flag set cannot be loaded except to execute it.|$|E
5000|$|Use default {{settings}}. Default {{settings are}} defined per <b>file</b> <b>system</b> at the <b>file</b> <b>system</b> level. For ext3 <b>file</b> <b>systems</b> {{these can be}} set with the tune2fs command. The normal default for Ext3 <b>file</b> <b>systems</b> is equivalent to (no acl support). Modern Red Hat based systems set acl support as default on the root <b>file</b> <b>system</b> but not on user created Ext3 <b>file</b> <b>systems.</b> Some <b>file</b> <b>systems</b> such as XFS enable acls by default. Default <b>file</b> <b>system</b> mount attributes can be overridden in /etc/fstab.|$|R
40|$|Abstract. HFS+ <b>file</b> <b>system</b> is a <b>file</b> <b>system</b> of the Mac OS. In {{order to}} achieve data {{manipulation}} of the <b>file</b> <b>system</b> based on the Windows OS for further computer forensics, {{not only do we}} introduce the principle and structure of HFS+ <b>file</b> <b>system,</b> but also propose a efficient method to analyze the <b>file</b> <b>system.</b> Research contains the exploration of the <b>file</b> <b>system</b> and program implementation to analyze the <b>file</b> <b>system...</b>|$|R
40|$|With the {{emergence}} of Storage Networking, distributed <b>file</b> <b>systems</b> that allow data sharing through shared disks will become vital. We refer to Cluster <b>File</b> <b>Systems</b> as a distributed <b>file</b> <b>systems</b> optimized for environments of clustered servers. The requirements such <b>file</b> <b>systems</b> is that they guarantee <b>file</b> <b>systems</b> consistency while allowing shared access from multiple nodes in a shared-disk environment. In this paper we evaluate three approaches for designing a cluster <b>file</b> <b>system</b> - conventional client/server distributed <b>file</b> <b>systems,</b> symmetric shared <b>file</b> <b>systems</b> and asymmetric shared <b>file</b> <b>systems.</b> These alternatives are considered by using our prototype cluster <b>file</b> <b>system,</b> HAMFS (Highly Available Multi-server <b>File</b> <b>System).</b> HAMFS is classified as an asymmetric shared <b>file</b> <b>system.</b> Its technologies are incorporated into our commercial cluster <b>file</b> <b>system</b> product named SafeFILE. SafeFILE offers a disk pooling facility that supports off-the-shelf disks, and balances file load across these disks automatically and dynamically. From our measurements, we identify the required disk capabilities, such as multi-node tag queuing. We also identify the advantages of an asymmetric shared <b>file</b> <b>system</b> over other alternatives...|$|R
50|$|Many European {{companies}} engineer <b>filing</b> <b>systems</b> that accommodate hanging folders only; {{there are}} no drawer bottoms. In the US, most file drawers still have bottoms in the drawers so materials of any sort can be stored.|$|E
50|$|Aemulor Pro adds {{support for}} low-bpp screen modes, sound, {{hardware}} emulation of VIDC/IOC, an altered memory map and 26-bit <b>filing</b> <b>systems.</b> Some software, such as Sibelius, can be run {{both in the}} desktop and in full screen.|$|E
5000|$|... #Caption: Mc tab on a {{file card}} divider of British origin. Some {{traditional}} <b>filing</b> <b>systems</b> treated Mac/Mc names {{as if the}} prefix were a letter such as a putative [...] "Mc" [...] between M and N in the alphabet.|$|E
50|$|There {{are various}} User Mode <b>File</b> <b>System</b> (FUSE)-based <b>file</b> <b>systems</b> for Unix-like {{operating}} systems (Linux, etc.) {{that can be}} used to mount an S3 bucket as a <b>file</b> <b>system.</b> Note that as the semantics of the S3 <b>file</b> <b>system</b> are not that of a Posix <b>file</b> <b>system,</b> the <b>file</b> <b>system</b> may not behave entirely as expected.|$|R
50|$|Other Unix virtual <b>file</b> <b>systems</b> {{include the}} <b>File</b> <b>System</b> Switch in System V Release 3, the Generic <b>File</b> <b>System</b> in Ultrix, and the VFS in Linux. In OS/2 and Microsoft Windows, the virtual <b>file</b> <b>system</b> {{mechanism}} {{is called the}} Installable <b>File</b> <b>System.</b>|$|R
40|$|Abstractâ€”Researches on {{technologies}} about testing {{aggregate bandwidth}} of <b>file</b> <b>systems</b> in cloud storage systems. Through the memory <b>file</b> <b>system,</b> network <b>file</b> <b>system,</b> parallel <b>file</b> <b>system</b> theory analysis, {{according to the}} cloud storage system polymerization bandwidth and concept, developed to cloud storage environment <b>file</b> <b>system</b> polymerization bandwidth test software called FSPoly. In this paper, use FSpoly to luster <b>file</b> <b>system</b> testing, find reasonable test methods, and then evaluations latest development in cloud storage <b>system</b> <b>file</b> <b>system</b> performance by using FSPoly. Keywords-cloud storage, aggregate bandwidth, <b>file</b> <b>system,</b> performance evaluation I...|$|R
50|$|The Remington Rand Systems {{division}} of Sperry Rand, now based in Marietta, Ohio, {{was acquired by}} Aarque Management Corporation of Jamestown, New York, and renamed to Kardex Systems {{to take advantage of}} Kardex's status as a long-famous brand in <b>filing</b> <b>systems.</b>|$|E
50|$|Collation is the {{assembly}} of written information into a standard order. Many systems of collation are based on numerical order or alphabetical order, or extensions and combinations thereof. Collation is a fundamental element of most office <b>filing</b> <b>systems,</b> library catalogs, and reference books.|$|E
5000|$|... "In the non-mathematical field {{there is}} a wide scope {{for the use of the}} {{techniques}} in such things as <b>filing</b> <b>systems.</b> It is not inconceivable that an automatic encyclopaedic service operated through the national teleprinter, or telephone system, will one day exist." ...|$|E
40|$|We propose and {{evaluate}} an approach for decoupling persistent-cache management from general <b>file</b> <b>system</b> design. Several distributed <b>file</b> <b>systems</b> maintain a persistent cache {{of data to}} speed up accesses. Most of these <b>file</b> <b>systems</b> retain complete control over various aspects of cache management, such as granularity of caching, and policies for cache placement and eviction. Hardcoding cache management into the <b>file</b> <b>system</b> often results in sub-optimal performance as the clients of the <b>file</b> <b>system</b> are prevented from exploiting information about their workload in order to tune cache management. We introduce xCachefs, a framework that allows clients to transparently augment the cache management of the <b>file</b> <b>system</b> and customize the caching policy based on their resources and workload. xCachefs {{can be used to}} cache data persistently from any slow <b>file</b> <b>system</b> to a faster <b>file</b> <b>system.</b> It mounts over two underlying <b>file</b> <b>systems,</b> which can be local disk <b>file</b> <b>systems</b> like Ext 2 or remote <b>file</b> <b>systems</b> like NFS. xCachefs maintains the same directory structure as in the source <b>file</b> <b>system,</b> so that disconnected reads are possible when the source <b>file</b> <b>system</b> is down. ...|$|R
40|$|In this note, we {{introduce}} a simple <b>file</b> <b>system</b> implementation, known as vsfs (the Very Simple <b>File</b> <b>System).</b> This <b>file</b> <b>system</b> is a simplified {{version of a}} typical UNIX <b>file</b> <b>system</b> and thus serves to introduce {{some of the basic}} on-disk structures, access methods, and policies that you will find in many <b>file</b> <b>systems</b> today. The <b>file</b> <b>system</b> is pure software; unlike our development of CPU and memory virtualization, we will not be adding hardware features to make some aspect of the <b>file</b> <b>system</b> work better (though we will want to pay attention to device characteristics to make sure the <b>file</b> <b>system</b> works well). Because of the great flexibility we have in building a <b>file</b> <b>system,</b> many different ones have been built, literally from AFS (the Andrew <b>File</b> <b>System)</b> to ZFS (Sunâ€™s Zettabyte <b>File</b> <b>System).</b> All of these <b>file</b> <b>systems</b> have different data structures and and do some things better or worse than their peers. Thus, the way we will be learning about <b>file</b> <b>systems</b> is through case studies: first, a simple <b>file</b> <b>system</b> (vsfs) in this chapter to introduce most concepts, and then a series of studies of real <b>file</b> <b>systems</b> to understand how they can differ in practice...|$|R
5000|$|FFS2, Unix <b>File</b> <b>System,</b> Berkeley Fast <b>File</b> <b>System,</b> the BSD Fast <b>File</b> <b>System</b> or FFS ...|$|R
5000|$|The Office of the Secretary (OSEC) {{oversees the}} receipt and {{distribution}} of documents filed by the public through electronic and paper <b>filing</b> <b>systems</b> and the FCC Library collection. In addition, OSEC publishes legal notices of Commission decisions in the Federal Register and the FCC Record.|$|E
50|$|There was {{a variant}} of the DFS called the DNFS, or Disc/Network Filing System, that {{contained}} the Econet Network Filing System (NFS), standard Disc Filing System and Tube co-processor support software on a single ROM; this ROM installed two <b>filing</b> <b>systems</b> into the OS at once.|$|E
50|$|As {{electronic}} court systems {{continue to}} increase their online presence, many now require case filings to be accomplished electronically. Many legal software vendors' products include {{the ability to take}} advantage of such electronic filing by pulling data from the case management product and pushing it into court <b>filing</b> <b>systems.</b>|$|E
40|$|File Allocation Table (FAT) <b>file</b> <b>system</b> is {{the most}} common <b>file</b> <b>system</b> used in {{embedded}} devices such as smart phones, digital cameras, smart TVs, tablets, etc. Typically these embedded devices use Solid State Drives (SSD) as storage devices. The ExFAT <b>file</b> <b>system</b> is future <b>file</b> <b>system</b> for embedded devices and it is optimal for SSDs. This paper discourses the methodologies for Geotagging as a <b>file</b> <b>system</b> metadata instead of file data in FAT and ExFAT <b>file</b> <b>systems.</b> The designed methodologies of this paper adheresthe compatibility with the FAT <b>file</b> <b>system</b> specification and existing ExFAT <b>file</b> <b>system</b> implementations...|$|R
40|$|Abstractâ€”As <b>file</b> <b>system</b> {{capacities}} {{reach the}} petascale, {{it is becoming}} increasingly difficult for users to organize, find, and manage their data. <b>File</b> <b>system</b> search has the potential to greatly improve how users manage and access files. Unfortunately, existing <b>file</b> <b>system</b> search is designed for smaller scale systems, making it difficult for existing solutions to scale to petascale <b>files</b> <b>systems.</b> In this paper, we motivate the importance of <b>file</b> <b>system</b> search in petascale <b>file</b> <b>systems</b> and present a new fulltext <b>file</b> <b>system</b> search design for petascale <b>file</b> <b>systems.</b> Unlike existing solutions, our design exploits <b>file</b> <b>system</b> properties. Using a novel index partitioning mechanism that utilizes <b>file</b> <b>system</b> namespace locality, we are able to improve search scalability and performance and we discuss how such a design can potentially improve search security and ranking. We describe how our design can be implemented within the Ceph petascale <b>file</b> <b>system.</b> I...|$|R
40|$|HDFS is a {{distributed}} <b>file</b> <b>system</b> {{designed to}} hold very large amounts of data (terabytes or even petabytes), and provide high-throughput access to this information. Files are stored in a redundant fashion across multiple machines to ensure their durability to failure and high availability to very parallel applications. This paper includes the step by step introduction to the <b>file</b> <b>system</b> to distributed <b>file</b> <b>system</b> and to the Hadoop Distributed <b>File</b> <b>System.</b> Section I introduces What is <b>file</b> <b>System,</b> Need of <b>File</b> <b>System,</b> Conventional <b>File</b> <b>System,</b> its advantages, Need of Distributed <b>File</b> <b>System,</b> What is Distributed <b>File</b> <b>System</b> and Benefits of Distributed <b>File</b> <b>System.</b> Also the analysis of large dataset and comparison of mapreducce with RDBMS, HPC and Grid Computing communities have been doing large-scale data processing for years. Sections II introduce the concept of Hadoop Distributed <b>File</b> <b>System.</b> Lastly section III contains Conclusion followed with the References...|$|R
