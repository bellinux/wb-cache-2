49|1511|Public
2500|$|There are 4 {{series of}} Webkinz Trading Cards, of which 2 {{can be used}} (in virtual form) to play the {{challenge}} game. The cards come in booster packs, with 5 playing cards and a code card in each pack. In these packs there are also chances of getting special cards as well, like free pet codes. In Series 1, {{you can also get}} Curio Shop Curiosities and Webkinz Doodlez. In Series 2, there is At Paw Level and W-Tales Snapshots instead. These special cards are foil. For Series 1, 80 base cards have been released, 12 challenges, 8 Curio Shop Curiosities and 8 Webkinz Doodlez. In Series 2, there are 85 base cards, 15 challenges, 8 At Paw Levels and 8 W-Tales Snapshots. The cards are also W-Plus items, and they each come with 2-5 codes. 1 code on each card is for a virtual pack of Trading Cards, while the other 1-4 can unlock prizes like rare and exclusive themes or coupons. Series 3 changed the format, with only 1 <b>feature</b> <b>code</b> per pack, and no code for a virtual pack. [...] The packs also included stickers and a chance to win a previously unheard-of Pet, the Magical Retriever. [...] Also, Ganz has said that each Series 3 code gives you an item you cannot find anywhere else in Webkinz World. Series 4 has also been released, and the prize Pet, the Mystical Panda, replaces the Magical Retriever.|$|E
5000|$|The PRL {{is built}} by an {{operator}} and is normally not {{accessible to the}} user. Many operators provide the ability for the user to download the latest PRL to their device by dialing an Over-the-air (OTA) <b>feature</b> <b>code.</b> In the US, for Verizon / MetroPCS / US Cellular, this <b>feature</b> <b>code</b> is *228 (*ACT). For Sprint, it is ##873283# (it is also possible to use code ##72786# on Android or ##25327# on iOS to completely clear out the service programming and redo OTA activation, which includes updating the PRL). [...] In Canada, for Telus Mobility, the PRL update <b>feature</b> <b>code</b> is *22803 (*ACT03).|$|E
50|$|The Feature key allows {{accessing}} many system features {{with one}} single <b>Feature</b> <b>Code.</b> For example, dial Feature 70 to transfer, {{as opposed to}} complex feature codes on older systems.|$|E
40|$|This brief {{presents}} a comprehensive introduction to <b>feature</b> <b>coding,</b> {{which serves as}} a key module for the typical object recognition pipeline. The text offers a rich blend of theory and practice while reflects the recent developments on <b>feature</b> <b>coding,</b> covering the following five aspects: (1) Review the state-of-the-art, analyzing the motivations and mathematical representations of various <b>feature</b> <b>coding</b> methods; (2) Explore how various <b>feature</b> <b>coding</b> algorithms evolve along years; (3) Summarize the main characteristics of typical <b>feature</b> <b>coding</b> algorithms and categorize them accordingly; (4) ...|$|R
5000|$|ARD Linear Regression with kernelized <b>features</b> <b>code,</b> {{tutorial}} ...|$|R
25|$|Unlike the <b>feature</b> <b>codes</b> below, these caller-id prefixes {{work with}} all/most carriers.|$|R
50|$|The {{general public}} tends {{to refer to}} the service by the {{telephone}} <b>feature</b> <b>code,</b> the telephone number it has in their country; for example, in North America this is *69, while in the UK it is called 1471.|$|E
50|$|Emem Isong is a Nigerian screenwriter, film producer, and director. She {{has become}} known {{primarily}} for Yoruba language pictures, and is a dominant figure in that industry. Her second directed <b>feature,</b> <b>Code</b> of Silence, which deals with rape in Nigeria, was released in 2015.|$|E
50|$|This {{feature is}} not {{available}} from most cellphone services with caller ID, such as Sprint, T-Mobile USA or AT&T. Verizon Wireless does provide this service, but ACR prevents dialing a <b>feature</b> <b>code</b> or successfully calling customer service. Verizon Wireless does not currently provide blocked or anonymous call rejection, but customers may block up to five specific numbers at MyVerizon.|$|E
40|$|Deep {{learning}} has achieved substantial {{success in a}} series of tasks in computer vision. Intelligent video analysis, which can be broadly applied to video surveillance in various smart city applications, can also be driven by such powerful deep learning engines. To practically facilitate deep neural network models in the large-scale video analysis, there are still unprecedented challenges for the large-scale video data management. Deep <b>feature</b> <b>coding,</b> instead of video coding, provides a practical solution for handling the large-scale video surveillance data. To enable interoperability in the context of deep <b>feature</b> <b>coding,</b> standardization is urgent and important. However, due to the explosion of deep learning algorithms and the particularity of <b>feature</b> <b>coding,</b> there are numerous remaining problems in the standardization process. This paper envisions the future deep <b>feature</b> <b>coding</b> standard for the AI oriented large-scale video management, and discusses existing techniques, standards and possible solutions for these open problems. Comment: 8 pages, 8 figures, 5 table...|$|R
40|$|Recent {{years have}} {{witnessed}} a fruitful development of image representation. The most prevalent {{one is the}} Bag-of-Words (BoW) method, which gives state-of-the-art performance in many applications. It has four steps: local feature extraction, dictionary learning, <b>feature</b> <b>coding,</b> and <b>feature</b> pooling. In this paper, we focus on <b>feature</b> <b>coding.</b> On {{the basis of an}} analysis of currently popular <b>feature</b> <b>coding</b> methods, we propose a supervised incremental coding method. The most different characteristic of this method is that coding of a new image relies on the coding of the previous image from the same class. Therefore, we need to know the label of one image before coding. This point can be argued as a drawback of this method. However, we demonstrate that it could give much better feature for image classification. This finding gives some hints about further development of <b>feature</b> <b>coding</b> method. We believe that the entire class should be considered when <b>coding</b> the local <b>features...</b>|$|R
5000|$|April, 2010 for POWER systems, {{where it}} is {{available}} as <b>feature</b> <b>codes</b> 4807, 4808, and 4809 ...|$|R
50|$|Absoft-specific GUI options allow use of {{programs}} compiled with Absoft Pro Fortran using the mouse {{and dealing with}} pop-ups {{in the same way}} that windowed GUI applications are used. The use of Absoft-specific GUI features is portable between platforms using Absoft Pro Fortran on each platform, but other compilers and platforms cannot use these features, and Absoft-specific <b>feature</b> <b>code</b> will not be recognized by other compilers.|$|E
50|$|Speed calling service allows {{telephone}} {{subscribers to}} assign {{one or two}} digit speed calling codes, by dialing a change speed calling list access code, a <b>feature</b> <b>code,</b> and a new telephone number. Thereafter, the subscribers need only use the assigned speed code to reach the desired party rather than dial the long phone number. This service became commonplace in the 1970s with the spread of Stored Program Control exchanges capable of implementing the required databases. It remains useful in installations of many extensions where programming each telephone set would be arduous. Speed calling subscriptions have largely {{been replaced by the}} introduction of telephone handsets which incorporate a local version of speed dial.|$|E
50|$|In the {{automotive}} industry a practice has developed over the last 30 years in which aspects of vehicles are modelled using an abstract notion of a feature. A feature is an abstraction used to represent an aspect of a product. It is identified by a <b>feature</b> <b>code</b> and an associated feature description. Features can be commercial features capturing an aspect of relevance to a customer, for instance, {{the color of the}} vehicle, whether it is a diesel or petrol engine and whether it has a manual or automatic gearbox. Features can also be technical features of relevance to manufacturing but less so for a customer. Examples are, the frequency to be used for keyless entry, the variant of the exhaust system needed for a particular configuration of the vehicle and the emission standard to be fulfilled by the vehicle.|$|E
5000|$|GSM {{forwarding}} standard <b>features</b> <b>codes</b> - list of {{call forward}} codes working with all operators and phones ...|$|R
500|$|The ISO [...] {{standard}} {{introduced the}} BOOLEAN data type to SQL, however it's still just an optional, non-core <b>feature,</b> <b>coded</b> T031.|$|R
50|$|The {{recommended}} IDE for Haxe {{development is}} FlashDevelop, which supports ActionScript 2, 3 and Haxe as first-class languages with syntax highlighting, code completion, and other <b>features.</b> <b>Code</b> folding, code refactoring and interactive debugging is also supported within the IDE.|$|R
50|$|There are 4 {{series of}} Webkinz Trading Cards, of which 2 {{can be used}} (in virtual form) to play the {{challenge}} game. The cards come in booster packs, with 5 playing cards and a code card in each pack. In these packs there are also chances of getting special cards as well, like free pet codes. In Series 1, {{you can also get}} Curio Shop Curiosities and Webkinz Doodlez. In Series 2, there is At Paw Level and W-Tales Snapshots instead. These special cards are foil. For Series 1, 80 base cards have been released, 12 challenges, 8 Curio Shop Curiosities and 8 Webkinz Doodlez. In Series 2, there are 85 base cards, 15 challenges, 8 At Paw Levels and 8 W-Tales Snapshots. The cards are also W-Plus items, and they each come with 2-5 codes. 1 code on each card is for a virtual pack of Trading Cards, while the other 1-4 can unlock prizes like rare and exclusive themes or coupons. Series 3 changed the format, with only 1 <b>feature</b> <b>code</b> per pack, and no code for a virtual pack. The packs also included stickers and a chance to win a previously unheard-of Pet, the Magical Retriever. Also, Ganz has said that each Series 3 code gives you an item you cannot find anywhere else in Webkinz World. Series 4 has also been released, and the prize Pet, the Mystical Panda, replaces the Magical Retriever.|$|E
40|$|Program {{comprehension}} is {{an essential}} activity to perform software maintenance and evolution. Comprehensibility often encompasses the analysis of individual logical units, called features, which are often scattered through many program modules. Understanding how the <b>feature</b> <b>code</b> is implemented along the software evolution history is essential, for instance, to perform refactoring activities. However, existing tools do not provide means to comprehend the <b>feature</b> <b>code</b> evolution. To overcome this shortcoming, this paper presents a tool called Source Miner Evolution (SME) that provides multiple interactive and coordinated views to comprehend <b>feature</b> <b>code</b> evolution. SME implements a feature-sensitive comparison of multiple program versions. Our usability assessment with experienced developers indicated that SME allows them to efficiently perform recurring comprehension tasks on evolving <b>feature</b> <b>code.</b> The developers' performance {{was influenced by the}} combination of visual SME mechanisms, such as colors, tool tips and menu-popup interactions over the features' code elements...|$|E
40|$|The present {{invention}} {{relates to}} {{a method for}} transforming a feature vector comprising a first and a second feature represented by a first and a second feature value, respectively, into a <b>feature</b> <b>code</b> using an encoder, said <b>feature</b> <b>code</b> usable in an algorithm and having a predetermined number of bits, said method comprising the steps of determining {{for each of the}} first and the second features the performance {{as a function of the}} length of the <b>feature</b> <b>code,</b> and using the dependency between the performance and the <b>feature</b> <b>code</b> length for each of the individual features derived in the step of determining to find <b>feature</b> <b>code</b> lengths for the first and the second features in such a way that the sum of the bit length of the first and the second feature codes has a length equaling said predetermined bit length. An advantage with the present invention is that it solves the problem in the case of template protection systems which only accept binary templates and where the resulting classification quality of the biometric system to a very large extend depends on the quality of the binary strings. Another advantage with the present invention is that it also solves the problem of matching time in an identification setting because binary strings can easily be compared. The present invention also relates to a similar arrangement for transforming a feature vector into a <b>feature</b> <b>code...</b>|$|E
40|$|This paper {{systematically}} {{investigates the}} effectiveness of different visual <b>feature</b> <b>coding</b> schemes for facilitating the learning of time-delayed dependencies among dis-joint multi-camera views. Accurate inter-camera dependency estimation across non-overlapping camera views is non-trivial especially in crowded scenes where inter-object occlusion can be severe and frequent, and when the degree of crowdedness can change drastically over time. In contrast to existing methods that learn dependencies between disjoint cameras by solely relying on correlating universal object-independent low-level visual features or transition time statistics, we propose to use either supervised or unsu-pervised <b>feature</b> <b>coding,</b> to establish a robust and reliable representation for estimating more accurately inter-camera activity pattern dependencies. We show comparative exper-iments to demonstrate the superiority of robust <b>feature</b> <b>coding</b> for learning inter-camera dependencies using benchmark multi-camera datasets of crowded public scenes. ...|$|R
50|$|Shinken has an {{open and}} test-driven {{development}} approach, with contributors to the project providing new <b>features,</b> <b>code</b> refactoring, code quality and bug fixing.|$|R
40|$|An {{effective}} image {{representation is}} important to an image classification task. The most popular image representation framework utilizes a <b>feature</b> <b>coding</b> algorithm to encode the extracted low-level feature descriptors into a vector represen-tation. In this paper, we analyze the recently developed fea-ture coding methods in a general way. According to their common characteristics, we propose a new coding scheme to perform <b>feature</b> <b>coding</b> based on the vector difference in a high-dimensional space which is obtained by explicit fea-ture maps. As we illustrate, our method has promising results with small codebook sizes and generalizes most existing cod-ing methods in a unified form...|$|R
40|$|A web-based {{system for}} {{retrieving}} imaged documents from digital library {{is described in}} this paper. First, some image preprocessing is performed off-line on the underlying imaged document to extract its word objects. Then, each word object is represented by a string known as its <b>feature</b> <b>code,</b> based on which a <b>feature</b> <b>code</b> file of the corresponding document is constructed. On the web interface side, the system allows the user to input a set of query words and indicate either to perform “AND ” or “OR ” operation on them. Once receiving user’s request, the system will process each query word and combine the results based on the “AND ” or “OR ” operation the user has chosen. As for each query word, it is first looked up in an index table that stores words being queried before. If matches are found, results will be retrieved from the index table directly and stored temporarily for subsequent merging. This speeds up searching and makes the system an incremental intelligence system. Otherwise, the system will convert the query word to a <b>feature</b> <b>code</b> string and employ a partial word matching approach to perform search on the pre-generated <b>feature</b> <b>code</b> files. Preliminary experimental results with the imaged documents of students ’ theses provided by our digital library show that the proposed system is efficient and promising for document image retrieval, and thus has potential applications to digital libraries. 1...|$|E
40|$|Most of the {{existing}} Chinese webpage duplicate elimination approaches do not focus on noisy and fuzzy duplicates elimination. In this paper, we propose an efficient and noise-tolerant Chinese webpage duplicate elimination approach based on Length-variable <b>Feature</b> <b>Code.</b> First, an Independent Extraction Unit is defined to eliminate the impact of short paragraphs on <b>feature</b> <b>code</b> extraction. Then the concept of repeatability is introduced by using the longest common substring to enhance the noise tolerant capability. Experimental results on 10 million webpage dataset show that the proposed approach can efficiently deal with duplicates from massive WebPages with the duplicate elimination precision of 99. 03 %. </p...|$|E
40|$|A {{great number}} of {{documents}} are scanned and archived {{in the form of}} digital images in digital libraries, to make them available and accessible in the Internet. Information retrieval in these imaged documents has become a growing and challenging problem. For this purpose, a word image coding technique is proposed in this paper, and a web-based system for efficiently retrieving imaged documents from digital libraries is described. Some image preprocessing is first carried out off-line to extract word objects from imaged documents stored in the digital library. Then each word object is represented by a string of feature codes. As a result, each document image is represented by a series of <b>feature</b> <b>code</b> strings of its words, which are stored in a <b>feature</b> <b>code</b> file. Upon receiving a user’s request, the server converts the query word into <b>feature</b> <b>code</b> string using the same conversion mechanism as is used in producing feature codes for the underlying imaged documents. Searching is then performed among those <b>feature</b> <b>code</b> files generated offline. An inexact string matching technique, with the ability of matching a word portion, is applied to match the query word with the words in the documents, and then the occurrence frequency of the query word in each corresponding document is calculated for relevant ranking. Preliminary experimental results with some imaged documents of students ’ theses in the digital library of our university show that the proposed approach is efficient and promising for retrieving imaged documents, with potential applications to digital libraries. 1...|$|E
50|$|A ferrinho {{once used}} by Codé di Dona is issued {{on the back}} of the Capeverdean $1000 escudo note that <b>features</b> <b>Codé</b> di Dona who was one of the {{greatest}} musicians in Cape Verde.|$|R
40|$|Recent {{research}} has shown the initial success of sparse coding (Sc) in solving many computer vision tasks. Motivated {{by the fact that}} kernel trick can capture the nonlinear similarity of features, which helps find a sparse representation of nonlinear features, we therefore propose Kernel Sparse Representation (KSR). Essentially, KSR is a sparse coding technique in a high dimensional feature space mapped by an implicit mapping function. We apply KSR to <b>feature</b> <b>coding</b> in image classification, face recognition and kernel matrix approximation. More specifically, by incorporating KSR into Spatial Pyramid Matching (SPM), we develop KSRSPM, which achieves good performance for image classification. Moreover, KSR based <b>feature</b> <b>coding</b> can be shown as a generalization of Efficient Match Kernel (EMK) and an extension of Sc based SPM (ScSPM). We further show that our proposed KSR using Histogram Intersection Kernel (HIK) can be considered as a soft assignment extension of HIK based feature quantization in <b>feature</b> <b>coding</b> process. Besides <b>feature</b> <b>coding,</b> comparing with sparse coding, KSR can learn more discriminative sparse codes and achieve higher accuracy for face recognition. Moreover, KSR can also be applied to kernel matrix approximation in large scale learning tasks, and it demonstrates its robustness to kernel matrix approximation especially when {{a small fraction of the}} data is used. Extensive experimental results demonstrate promising results of KSR in the image classification, face recognition and kernel matrix approximation. All these applications proves the effectiveness of KSR in computer vision and machine learning tasks...|$|R
40|$|In this paper, {{we propose}} a {{low-rank}} sparse coding (LRSC) method that exploits local structure information among features in an image {{for the purpose}} of image-level classification. LRSC represents densely sampled SIFT descriptors, in a spatial neighborhood, collectively as low-rank, sparse linear combinations of code words. As such, it casts the <b>feature</b> <b>coding</b> problem as a low-rank matrix learning problem, which is different from previous methods that encode features independently. This LRSC has a number of attractive properties. (1) It encourages sparsity in <b>feature</b> <b>codes,</b> locality in codebook construction, and low-rankness for spatial consistency. (2) LRSC encodes local features jointly by considering their low-rank structure information, and is computationally attractive. We evaluate the LRSC by comparing its performance on a set of challenging benchmarks with that of 7 popular coding and other state-of-the-art methods. Our experiments show that by representing local features jointly, LRSC not only outperforms the state-of-the-art in classification accuracy but also improves the time complexity of methods that use a similar sparse linear representation model for <b>feature</b> <b>coding...</b>|$|R
40|$|The {{application}} of machine learning to large datasets {{has become a}} core component of many important and exciting software systems being built today. The extreme value in these trained systems is tempered, however, by the difficulty of constructing them. As shown by the experience of Google, Netflix, IBM, and many others, a critical problem in building trained systems is that of feature engineering. High-quality machine learning features are crucial for the system’s per-formance but are difficult and time-consuming for engineers to develop. Data-centric developer tools that improve the productivity of feature engineers will thus likely have a large impact on an important area of work. We have built a demonstration integrated development en-vironment for feature engineers. It accelerates one particular step in the feature engineering development cycle: evaluating the effectiveness of novel <b>feature</b> <b>code.</b> In particular, it uses an index and runtime execution planner to process raw data objects (e. g., Web pages) in order of descending likelihood that the data object will be relevant to the user’s <b>feature</b> <b>code.</b> This demonstration IDE allows the user to write ar-bitrary <b>feature</b> <b>code,</b> evaluate its impact on learner quality, and observe exactly how much faster our technique performs compared to a baseline system. 1...|$|E
40|$|The recent {{availability}} of object-oriented database technology opens up new possibilities for map and chart representation, on paper {{as well as}} on computer screen. In a traditional map database, features are held as passive data: coordinates and attributes. It has been up to the application program to display or plot these in graphic form, usually by static lookup tables, based on a simple <b>feature</b> <b>code.</b> In the new object-oriented world, this constraint is broken as static features are replaced by dynamic objects. Instead of the application drawing the features according to a fixed representation derived from a <b>feature</b> <b>code</b> and stored coordinates, the application sends a message to each feature object, asking it to draw itself. Each object can decide how best to draw itself, using any available information. As well as object class (equivalent of <b>feature</b> <b>code)</b> and coordinates as before, this information can include combinations of attributes, relationships with other objects, either explicit or inferred through spatial adjacency, and environmental information such as day of the week. This means that from a single geographic dataset, a wide set of products can be produced, to suit a range of task-oriented requirements. This paper outlines the representation capabilities of a modern object-oriented cartographic system, and presents examples of dynamic representation for navigation and topographic mapping...|$|E
40|$|There {{is a need}} {{to reserve}} small portion of DCO words for Vendor Unique (VU) purposes. Currently DCO uses 10 work words out of 256. Samsung would like to propose a {{reserved}} part portion of the DCO words for VU usage. There is also a need to reserve some <b>Feature</b> <b>Code</b> in the Set Feature command. Current specificatio...|$|E
30|$|The {{encoding}} {{speed is}} slow. In {{the process of}} <b>coding,</b> the <b>feature</b> <b>coding</b> of each block in the image needs to be iteratively computed by the regularization constraint L 1 norm, which is computationally expensive and memory-consuming.|$|R
40|$|Abstract — Recent {{research}} has shown the initial success of sparse coding (Sc) in solving many computer vision tasks. Motivated {{by the fact that}} kernel trick can capture the nonlinear similarity of features, which helps in finding a sparse representation of nonlinear features, we propose kernel sparse representation (KSR). Essentially, KSR is a sparse coding technique in a high dimensional feature space mapped by an implicit mapping function. We apply KSR to <b>feature</b> <b>coding</b> in image classification, face recognition, and kernel matrix approximation. More specifically, by incorporating KSR into spatial pyramid matching (SPM), we develop KSRSPM, which achieves a good performance for image classification. Moreover, KSR-based <b>feature</b> <b>coding</b> can be shown as a generalization of efficient match kernel and an extension of Sc-based SPM. We further show that our proposed KSR using a histogram intersection kernel (HIK) can be considered a soft assignment extension of HIK-based feature quantization in the <b>feature</b> <b>coding</b> process. Besides <b>feature</b> <b>coding,</b> comparing with sparse coding, KSR can learn more discriminative sparse codes and achieve higher accuracy for face recognition. Moreover, KSR can also be applied to kernel matrix approximation in large scale learning tasks, and it demonstrates its robustness to kernel matrix approximation, especially when {{a small fraction of the}} data is used. Extensive experimental results demonstrate promising results of KSR in image classification, face recognition, and kernel matrix approximation. All these applications prove the effectiveness of KSR in computer vision and machine learning tasks. Index Terms — Face recognition, image classification, kernel matrix approximation, kernel sparse representation, nonlinear mapping, sparse coding. I...|$|R
40|$|This paper {{presents}} a new steganography approach suitable for Arabic texts. It {{can be classified}} under steganography <b>feature</b> <b>coding</b> methods. The approach hides secret information bits within the letters benefiting from their inherited points. To note the specific letters holding secret bits, the scheme considers the two features, {{the existence of the}} points in the letters and the redundant Arabic extension character. We use the pointed letters with extension to hold the secret bit ‘one’ and the un-pointed letters with extension to hold ‘zero’. This steganography technique is found attractive to other languages having similar texts to Arabic such as Persian and Urdu. Keywords — Arabic text, Cryptography, <b>Feature</b> <b>coding,</b> Information security, Text steganography, Text watermarking...|$|R
