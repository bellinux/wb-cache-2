16|4345|Public
50|$|The {{deficiencies}} of <b>free</b> <b>text</b> <b>searching</b> {{have been addressed}} in two ways: By providing users with tools {{that enable them to}} express their search questions more precisely, and by developing new search algorithms that improve retrieval precision.|$|E
50|$|Compared to <b>free</b> <b>text</b> <b>searching,</b> {{the use of}} a {{controlled}} vocabulary can dramatically increase the performance of an information retrieval system, if performance is measured by precision (the percentage of documents in the retrieval list that are actually relevant to the search topic).|$|E
50|$|POPLINE {{has both}} basic and {{advanced}} searches and offers customized searches provided on request to persons or institutions in developing countries. Full-text copies {{for most of}} the documents cited in POPLINE can be requested from users in low-income countries free of charge via mail or sent by email. In addition to <b>free</b> <b>text</b> <b>searching,</b> the database can be searched by keywords from the POPLINE Thesaurus, a controlled vocabulary of 2,400+ terms used to index documents in the database.|$|E
5000|$|<b>Free</b> <b>text</b> <b>search</b> {{capabilities}} can {{be added}} through the LuceneSail.|$|R
5000|$|Geospatial (GeoSPARQL) and <b>free</b> <b>text</b> <b>search</b> can {{be added}} through uSeekM.|$|R
5000|$|NOTIS Information Retrieval, a {{document}} database with <b>free</b> <b>text</b> <b>search</b> allowing full multi-site search.|$|R
5000|$|PubMed {{automatically}} {{links to}} MeSH terms and subheadings. Examples would be: [...] "bad breath" [...] links to (and includes in the search) [...] "halitosis", [...] "heart attack" [...] to [...] "myocardial infarction", [...] "breast cancer" [...] to [...] "breast neoplasms". Where appropriate, these MeSH terms are automatically [...] "expanded", that is, include more specific terms. Terms like [...] "nursing" [...] are automatically linked to [...] "Nursing MeSH" [...] or [...] "Nursing Subheading". This feature is called Auto Term Mapping and is enacted, by default, in <b>free</b> <b>text</b> <b>searching</b> but not exact phrase searching (i.e. enclosing the search query with double quotes). This feature makes PubMed searches more sensitive and avoids false-negative (missed) hits by compensating for {{the diversity of}} medical terminology.|$|E
50|$|Controlled vocabularies {{are often}} claimed {{to improve the}} {{accuracy}} of <b>free</b> <b>text</b> <b>searching,</b> such as to reduce irrelevant items in the retrieval list. These irrelevant items (false positives) are often caused by the inherent ambiguity of natural language. Take the English word football for example. Football is the name given {{to a number of}} different team sports. Worldwide the most popular of these team sports is association football, which also happens to be called soccer in several countries. The word football is also applied to rugby football (rugby union and rugby league), American football, Australian rules football, Gaelic football, and Canadian football. A search for football therefore will retrieve documents that are about several completely different sports. Controlled vocabulary solves this problem by tagging the documents {{in such a way that}} the ambiguities are eliminated.|$|E
40|$|Classifications {{can help}} to {{overcome}} difficulties in information retrieval of heterogeneous and multilingual collections for which linguistic and <b>free</b> <b>text</b> <b>searching</b> is not sufficient or applicable. However, there are problems in the machine readability of classification systems which do not facilitate their wider use and full exploitation. The authors focus on issues of automation of analytico-synthetic classification systems such as Universal Decimal Classification (UDC), Bliss Bibliographic Classification (BC 2) and Broad System of Ordering (BSO). 'Analytico-syntheticâ means here classification systems that offer the possibility of building compound index/search terms and that lend themselves to post-coordinate searching...|$|E
5000|$|Music (Fast {{database}} driven music player application with <b>free</b> <b>text</b> <b>search</b> and tag edit) ...|$|R
50|$|In {{recent years}} <b>free</b> <b>text</b> <b>search</b> {{as a means}} of access to {{documents}} has become popular. This involves using natural language indexing with an indexing exhaustively set to maximum (every word in the text is indexed). Many studies have been done to compare the efficiency and effectiveness of <b>free</b> <b>text</b> <b>searches</b> against documents that have been indexed by experts using a few well chosen controlled vocabulary descriptors.|$|R
50|$|Clusterpoint {{database}} enables web-style <b>free</b> <b>text</b> <b>search</b> {{with natural}} language keywords and programmable relevance sorting of results. Constant and predictable search response time with latency in milliseconds and {{high quality of}} search results are achieved using policy-based inverted indexation and unique relevance ranking method. Clusterpoint database version 4 supports JS/SQL query language. Classic SQL queries can be combined with <b>free</b> <b>text</b> <b>search</b> and with custom distributed computing functions written in JavaScript, executed in a single REST API call.|$|R
40|$|This paper {{examines}} {{the relationship between}} plagiarism and normal variation in student programming assignments. Reasons why code might be similar, both innocuous and suspicious are described. <b>Free</b> <b>text</b> <b>searching</b> and structural metrics are used to examine a set of programming assignments. These metrics are {{used as the basis}} for analysis of the variability in the student assignments and the processes used by the students. The boundary between normal practice and plagiarism is examined by “forced plagiarism”. Finally we briefly examine student understanding of cheating and normal work processes. The investigation of similarity has provided some clarity to the ambiguous fine line of un/acceptable practice...|$|E
40|$|The Unix grep utility {{searches}} a {{text file}} for a pattern {{defined by a}} regular expression and prints the lines containing the pattern. Unfortunately, a line of text {{is not always the}} appropriate unit for search and retrieval. Our solution is to treat a newline as an ordinary character and to allow pattern matching across the entire file. Several issues must be addressed to make this <b>free</b> <b>text</b> <b>searching</b> useful. In particular, the standard approach of taking the "leftmost longest match" tends to select inappropriately large fragments of the text. Instead we follow the principle of always taking the shortest match and allow these matches to overlap but not nest. The resulting tool is novel, expressive and simple. Matches can be reported across lines and multiple matches can be reported within a line. Appropriate structure may be imposed by using a regular expression to define a search universe. Elements may then be selected from this universe by matching with a second regular expression. T [...] ...|$|E
40|$|Libraries {{across the}} world are {{spending}} increasing amounts of money on the acquisition of, and giving access to, electronic resources of all kinds. In addition, those libraries are devoting increasing amounts of human resources to advise and teach library users how to use electronic resources. The major issue facing libraries today {{is that of the}} preservation and onward transmission of the human record. This task has been accepted, usually tacitly, by many generations of librarians and archivists. The answer lies in some innovative and strong-minded research—in particular, we need an enumeration and taxonomy of the Web and the Internet. We could combat this electronic triumphalism by embarking on a serious enumeration and taxonomy of the Web and the Net that is aimed at identifying and isolating those documents and resources that are worth cataloguing and preserving. The starting point should be the grand idea of Universal Bibliographic Control, first put forward {{more than a quarter of}} century ago, in which individual libraries, regions, and countries cooperate to produce and share records without redundancy. Then there is the question of cataloguing and metadata. Metadata is an ill-considered attempt to find some kind of Third Way between the wilderness of search engines and <b>free</b> <b>text</b> <b>searching</b> and the grand architecture of bibliographic control that librarians have developed over the last 150 years...|$|E
30|$|Descriptive metadata. This {{includes}} the project {{name and a}} textual description of the project, {{which can be used}} to enable projects to be retrieved by <b>free</b> <b>text</b> <b>searches.</b>|$|R
50|$|On {{the other}} hand, <b>free</b> <b>text</b> <b>searches</b> have high exhaustivity (you search on every word) {{so it has}} {{potential}} for high recall (assuming you {{solve the problems of}} synonyms by entering every combination) but will have much lower precision.|$|R
50|$|In 2007, {{based on}} {{requirements}} by the users, features where added - <b>free</b> <b>text</b> <b>search,</b> blob compression, database files movable, and embedded database allows for cross process interaction. A TPC benchmark resulted in updated communication protocols, improving the speed in large distributed database scenario.|$|R
40|$|Background or context Regret is {{a common}} {{consequence}} of decisions, including those decisions related to individuals’ health. Several assessment instruments have been developed that attempt to measure decision regret. However, recent research has highlighted the complexity of regret. Given its relevance to shared decision making, {{it is important to}} understand its conceptualization and the instruments used to measure it. Objectives To review current conceptions of regret. To systematically identify instruments used to measure decision regret and assess whether they capture recent conceptualizations of regret. Search strategy Five electronic databases were searched in 2008. Search strategies used a combination of MeSH terms (or database equivalent) and <b>free</b> <b>text</b> <b>searching</b> under the following key headings: ‘Decision’ and ‘regret’ and ‘measurement’. Follow-up manual searches were also performed. Inclusion criteria Articles were included if they reported the development and psychometric testing of an instrument designed to measure decision regret, or the use of a previously developed and tested instrument. Main results Thirty-two articles were included: 10 report the development and validation of an instrument that measures decision regret and 22 report the use of a previously developed and tested instrument. Content analysis found that existing instruments for the measurement of regret do not capture current conceptualizations of regret and they do not enable the construct of regret to be measured comprehensively. Conclusions Existing instrumentation requires further development. There is also a need to clarify the purpose for using regret assessment instruments as this will, and should, focus their future application...|$|E
40|$|Introduction:Lung nodules are {{commonly}} encountered in clinical practice, yet {{little is known}} about their management in community settings. An automated method for identifying patients with lung nodules would greatly facilitate research in this area. Methods:Using members of a large, community-based health plan from 2006 to 2010, we developed a method to identify patients with lung nodules, by combining five diagnostic codes, four procedural codes, and a natural language processing algorithm that performed free text searches of radiology transcripts. An experienced pulmonologist reviewed a random sample of 116 radiology transcripts, providing a reference standard for the natural language processing algorithm. Results:With the use of an automated method, we identified 7112 unique members as having one or more incident lung nodules. The mean age of the patients was 65 years (standard deviation 14 years). There were slightly more women (54 %) than men, and Hispanics and non-whites comprised 45 % of the lung nodule cohort. Thirty-six percent were never smokers whereas 11 % were current smokers. Fourteen percent of the patients were subsequently diagnosed with lung cancer. The sensitivity and specificity of the natural language processing algorithm for identifying the presence of lung nodules were 96 % and 86 %, respectively, compared with clinician review. Among the true positive transcripts in the validation sample, only 35 % were solitary and unaccompanied by one or more associated findings, and 56 % measured 8 to 30 mm in diameter. Conclusions:A combination of diagnostic codes, procedural codes, and a natural language processing algorithm for <b>free</b> <b>text</b> <b>searching</b> of radiology reports can accurately and efficiently identify patients with incident lung nodules, many of whom are subsequently diagnosed with lung cancer...|$|E
40|$|The {{study will}} examine the {{introduction}} of the computerisation of crime and intelligence recording in three police forces in the United Kingdom in the decade 1976 - 1986. The thesis will critique the roles and actions of the main players in this decade, The Home Office in London England, three provincial police forces, Kent County Constabulary, Humberside Police and Lothian and Borders Police, and the computer supply industry. The study will consider the concept of ‘crime' from a jurisprudential viewpoint and will consider the legal imposition on chief officers of police to collect, store and distribute certain crime based data. The study will also examine and analyse in detail three computer projects in different police forces. The use of new, complex and expensive computer programs is highlighted with the introduction of <b>free</b> <b>text</b> <b>searching</b> of large data sources and the need for large scale mainframe computers to handle the analysis and storage of that data. The limited success of two police projects will question the requirement for central government control of publicly funded new technology. The study will examine strategic planning in the process, as well as the rush to be the first police force to embrace the new technology. Further the study will review central government control over public spending, in the first police force based computerisation projects. In conclusion, the thesis will suggest that new police systems should be scaled to local needs and guided by expert central advice. Additionally, chief police officers should be encouraged to use new technology in a strategic manner, sharing outcomes in open fora. Possible new research problems are listed and evaluated. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|The World Wide Web (WWW) is a {{distributed}} {{hypermedia system}} for information discovery, retrieval, and collaboration. The hypertext paradigm has proven its usefulness for browsing large, distributed document structures. The {{ease of use}} provided by this paradigm {{is one of the}} reasons for the great popularity which the World Wide Web has gained through the last months. However, as the amount of information available through the World Wide Web grows, it becomes more and more important to provide additional tools and techniques for finding servers or documents which contain relevant information on a given topic. Bibliographic and literature <b>text</b> <b>searching</b> is a difficult task, the provision of a <b>free</b> <b>text</b> <b>search</b> mechanism can greatly facilitate this task. By supplying a pre-computed index of keywords, a fully indexed server eliminates the need for automatic indexers (such as web robots spiders) to walk the entire server tree, which is an unnecessary waste of resources. Some World Wide Web s ervers already implement keyword searches via an interface to WAISINDEX. However, this approach lacks many important features that <b>free</b> <b>text</b> <b>search</b> engines provide, and does not support remapping of physical directory structures to virtual paths. In this document, we will present the ICE indexing server extension which has recently been developed at the Fraunhofer Institute for Computer Graphics. This freely available software package provides a set of routines which allow for sophisticated <b>free</b> <b>text</b> <b>searches</b> on a World Wide Web archive...|$|R
50|$|ScimoreDB is a {{proprietary}} freeware relational {{database management system}} for Microsoft Windows, developed by Scimore UAB. It features advanced features: SQL, ACID transactions, Multiversion concurrency control, <b>free</b> <b>text</b> <b>search,</b> shared nothing clustering, functional procedural shipment for distribution of data and queries. It works as embedded library, standalone server and distributed over many machines.|$|R
5000|$|Plugin Architecture: Every {{aspect of}} a project can be repackaged and used in another project as a plugin. This might be the entire project or just {{a small part of}} it. Most {{applications}} are combinations of several plugins. Community plugins include solutions for Google Maps; blogging; content management; and <b>free</b> <b>text</b> <b>search</b> engines.|$|R
40|$|Abstract Background Although {{regulatory}} compliance in academic research is enforced {{by law to}} ensure high quality and safety to participants, its implementation is frequently hindered by cost and logistical barriers. In order to decrease these barriers, we have developed a Web-based application, Duke Surgery Research Central (DSRC), to monitor and streamline the regulatory research process. Results The main objective of DSRC is to streamline regulatory research processes. The application was built {{using a combination of}} paper prototyping for system requirements and Java as the primary language for the application, in conjunction with the Model-View-Controller design model. The researcher interface was designed for simplicity so that it could be used by individuals with different computer literacy levels. Analogously, the administrator interface was designed with functionality as its primary goal. DSRC facilitates the exchange of regulatory documents between researchers and research administrators, allowing for tasks to be tracked and documents to be stored in a Web environment accessible from an Intranet. Usability was evaluated using formal usability tests and field observations. Formal usability results demonstrated that DSRC presented good speed, was easy to learn and use, had a functionality that was easily understandable, and a navigation that was intuitive. Additional features implemented upon request by initial users included: extensive variable categorization (in contrast with data capture using <b>free</b> <b>text),</b> <b>searching</b> capabilities to improve how research administrators could search an extensive number of researcher names, warning messages before critical tasks were performed (such as deleting a task), and confirmatory e-mails for critical tasks (such as completing a regulatory task). Conclusion The current version of DSRC was shown to have excellent overall usability properties in handling research regulatory issues. It is hoped that its release as an open-source application will promote improved and streamlined regulatory processes for individual academic centers as well as larger research networks. </p...|$|E
40|$|BACKGROUND: Increases in suicide deaths by gassing, {{particularly}} {{carbon monoxide}} poisoning from burning barbecue charcoal, have occurred {{in many parts of}} East Asia and resulted in rises in overall suicide rates in some countries. Recent trends in gas poisoning suicides outside Asia have received little attention. METHODS: We analysed suicides by gassing in England and Wales (2001 - 2011) using national suicide mortality data enhanced by <b>free</b> <b>text</b> <b>searching</b> of information sent by coroners to the Office for National Statistics (ONS). We conducted specific searches for suicides involving barbecue charcoal gas, helium, and hydrogen sulphide. We analysed coroners׳ records of eight people who used helium as a method of suicide, identified from systematic searches of the records of four coroners. RESULTS: Gassing accounted for 5. 2 % of suicide deaths in England and Wales during 2001 - 2011. The number of gas suicides declined from 368 in 2001 to 174 by 2011 (a 53 % reduction). The fall was due to a decline in deaths involving car exhaust and other sources of carbon monoxide. There was a rapid rise in deaths due to helium inhalation over the period, from five deaths in the two year period 2001 - 2002 to 89 in 2010 - 2011 (a 17 -fold increase). There were small rises in deaths involving hydrogen sulphide (0 cases in 2001 - 2002 versus 14 cases in 2010 - 2011) and barbecue charcoal gas (1 case in 2001 - 2002 versus 11 cases in 2010 - 2011). Compared to individuals using other methods, those suicides adopting new types of gas for suicide were generally younger and from more affluent socioeconomic groups. The coroners׳ records of four of the eight individuals dying by helium inhalation whose records were reviewed showed evidence of Internet involvement in their choice of method. LIMITATIONS: We were not able to identify the source of carbon monoxide (car exhaust or barbecue charcoal) for over 50 % of cases. CONCLUSION: Increases in helium inhalation as a method of suicide have partially offset recent decreases in suicide by the use of car exhaust. Public health measures are urgently needed to prevent a potential epidemic rise in the use of helium similar to the recent rises in charcoal burning suicides in East Asia...|$|E
40|$|The {{information}} service {{performed by the}} Royal Institute of Technology handles requests from both university users and from industry. Fourteen databases are currently used for SDI purposes. As the library also has on-line facilities for retrospective searches of six databases in the ESRO/RECON network, {{it has been found}} that retro-searches usually initiate SDI-profiles for current awareness information. In 1967 the Institute initiated its own database 2 ̆ 2 Mechanical Engineering - MECHEN 2 ̆ 2 and began a subscription to the tapes from the Institute for Scientific Information. The purpose was primarily to provide a service to Swedish manufacturers in the mechanical engineering field. However, the interdisciplinary nature of the ISI tapes attracted interest from many users in the universities. The total number of profiles in 1972 was 1, 050. The Institute welcomes profiles from outside universities or companies through the intermediary of their own librarians. However, most contacts are carried out directly with the users. The back-up service giving full documentation is necessary for keeping the interest of the users, and places a heavy burden on the regular library service. This report deals with the coverage, the operational and the performance functions. The system is of a general nature which permits inclusion of various databases of completely different tape formats. Any combination of elements of a bibliographic record can be searched. As the profile maintenance program becomes an essential element when the number of profiles is building up, an on-line facility for updating has been instalied. Thus, it is possible from a type-writer terminal to initiate, up-date and revise a profile at any time. Two such remote terminals are in operation, one 60 miles from Stockholm. Special emphasis is laid upon the principles for <b>free</b> <b>text</b> <b>searching</b> and the problems of arranging the printout {{in such a way that}} it gives user satisfaction. At present a statistical approach is in operation. Since many databases have keywords or other subject indicators, a combination of free text search of titles and keywords is often used. There is no significant deviation in the user 2 ̆ 7 s reaction when subjected to printout from free text searches or from keyword searches...|$|E
50|$|The use of {{controlled}} vocabularies {{can be costly}} compared to <b>free</b> <b>text</b> <b>searches</b> because human experts or expensive automated systems are necessary to index each entry. Furthermore, the user has {{to be familiar with}} the controlled vocabulary scheme to make best use of the system. But as already mentioned, the control of synonyms, homographs can help increase precision.|$|R
5000|$|On each Collection {{page and}} also in the main menu of the site there are links to [...] "Search TCIA". This will load the NBIA {{application}} which allows simple, advanced and <b>free</b> <b>text</b> <b>searches.</b> Search results follow the conventional DICOM hierarchy of patient -> study -> series. TCIA provides comprehensive documentation on the various features of the NBIA software...|$|R
40|$|This paper {{presents}} an on-going project aiming at enhancing the OPAC (Online Public Access Catalog) search {{system of the}} Library of the Free University of Bozen-Bolzano with multilingual access. The Multilingual search system (MUSIL), we have developed, integrates advanced linguistic technologies in a user friendly interface and bridges {{the gap between the}} world of <b>free</b> <b>text</b> <b>search</b> and the world of conceptual librarian search. In this paper we present the architecture of the system, its interface and preliminary evaluations of the precision of the search results. 1. The problem In this paper, we present the MUSIL (MUltilingual Search In Libraries) system developed within an on-going project on the enhancement of an OPAC (Online Public Access Catalog) search system with multilingual access. The project aims at integrating advanced linguistic technologies in a user friendly interface and bridging the gap between the world of <b>free</b> <b>text</b> <b>search</b> and the world of conceptual librarian search...|$|R
50|$|Ranking index method, {{applied to}} {{document}} database model, enables Clusterpoint to outperform SQL databases at search by several orders of magnitude. It solves information overload and latency problem for interactive web and mobile applications processing Big data. Today limited-size mobile device screens and network bandwidth restrictions prevent users requesting and processing large size data volumes per each query. Database search and querying {{need to be}} interactive and transactional to satisfy Internet users. Clusterpoint ranking index was designed for this computing model. It extracts relevant data first and returns information page by page in decreasing relevance. For instance, using only <b>free</b> <b>text</b> <b>search,</b> latency in large databases containing billions of document will be milliseconds, while relevance ranking will prevent overwhelming end-user with too much low-quality search results. This is also a crucial design element for distributed document database architecture: it makes its index scalable {{so that it can}} be safely shared across large cluster of servers without significant performance loss at data injection, <b>free</b> <b>text</b> <b>search</b> and access.|$|R
40|$|Documentary {{indications}} of the British patent specification 14 79 444 are traced through various machine-readable stores (OTAF, DERWENT, CASEARCH, CLAIMS/US) and various printed collections (claims of German Offenlegungsschriften, US and GB abstracts and Chemical Abstracts). The traceability of patents such as GB 14 79 444 (electrolytic cell with diaphragm and titanium anodes with a catalytically active coating of platinum or ruthenium and their compounds) using the IPC and <b>free</b> <b>text</b> terms is compared. Symptomatically, {{it was found}} that <b>free</b> <b>text</b> <b>searches</b> go further than IPC searches, because they can reach a greater search depth. ...|$|R
50|$|Controlled vocabularies {{are also}} quickly out-dated and in fast {{developing}} fields of knowledge, the authorized terms available {{might not be}} available {{if they are not}} updated regularly. Even in the best case scenario, controlled language is often not as specific as using the words of the text itself. Indexers trying to choose the appropriate index terms might misinterpret the author, while a <b>free</b> <b>text</b> <b>search</b> is in no danger of doing so, because it uses the author's own words.|$|R
5000|$|Another {{possibility}} is that the article is just not tagged by the indexer because indexing exhaustivity is low. For example, an article might mention football as a secondary focus, and the indexer might decide not to tag it with [...] "football" [...] {{because it is not}} important enough compared to the main focus. But it turns out that for the searcher that article is relevant and hence recall fails. A <b>free</b> <b>text</b> <b>search</b> would automatically pick up that article regardless.|$|R
40|$|Catch-up TV {{services}} on the Web have facilitated time-shifted TV viewing. However, {{there is limited}} information about user search behavior with regard to recently time-shifted versus archival TV content. We deployed two distinct content-based web services to explore information retrieval of time-shifted TV content. The first web service {{is based on a}} browsing metaphor, while the second is based on <b>free</b> <b>text</b> content <b>search</b> metaphor. We analyzed more than 5000 user sessions from 12 months of logs and found that the programs accessed via browsing categorized program content summaries were typically less than one week old. In contrast, the programs accessed via <b>free</b> <b>text</b> <b>search</b> on subtitle content were typically more than a week old. Our findings provide a first assessment of user behavior in accessing time-shifted and archival TV content. Further research should develop the user experience for content-based TV access and explore the sharing patterns of archival TV content on social networks...|$|R
40|$|Abstract. Semantics can be {{integrated}} in to search processing during both document analysis and querying stages. We describe a system that incorporates both, semantic annotations of Wikipedia articles into the search process and allows for rich annotation search, enabling users to formulate queries based on their knowledge about how entities relate to one another while simultaneously retaining the freedom of <b>free</b> <b>text</b> <b>search</b> where appropriate. The outcome of this work is an application consisting of semantic annotators, an extended search engine and an interactive user interface. ...|$|R
