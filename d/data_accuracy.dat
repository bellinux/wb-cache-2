935|3717|Public
500|$|Chinese {{records of}} comets {{are the most}} {{extensive}} and accurate in existence from the ancient and medieval periods, and stretch back across three millennia. [...] Records exist {{at least as far}} back as 613 BC, and records may have been kept for many centuries before this. [...] There are continuous records all the way through to the nineteenth century, using substantially consistent methods throughout. [...] Chinese <b>data</b> <b>accuracy</b> is unsurpassed in the ancient world and was not overtaken by Western accuracy until the fifteenth century, in some respects, not until the twentieth century.|$|E
2500|$|The BCP manual must evolve {{with the}} organization. [...] Activating the call tree verifies the {{notification}} plan's efficiency {{as well as}} contact <b>data</b> <b>accuracy.</b> Like most business procedures, business continuity planning has its own jargon. Organisation-wide understanding of business continuity jargon is vital and glossaries are available. Types of organisational changes that should be identified and updated in the manual include: ...|$|E
5000|$|CATI {{software}} has built-in logic, {{which also}} enhances <b>data</b> <b>accuracy.</b>|$|E
5000|$|Data {{quality control}} (<b>data</b> {{conversion}} <b>accuracy,</b> <b>data</b> source cleanup, etc.); ...|$|R
3000|$|... here {{refers to}} the {{weighting}} factor of each component, {{and it can be}} considered as the <b>data</b> <b>accuracies</b> (or the reliabilities) of each component.|$|R
50|$|Course quality {{focuses on}} well-designed courses, curriculum, and {{learning}} materials facilitate meaningful educational experiences. Information quality {{is about the}} <b>data’s</b> <b>accuracy,</b> relevance, consistency and timeliness.|$|R
5000|$|Improved <b>data</b> <b>accuracy</b> {{resulting}} from the electronic exchange of data (reduction in typographical errors).|$|E
5000|$|<b>Data</b> <b>accuracy.</b> Collecting {{information}} is error-prone. Also, prediction algorithms are not perfect, and real-time announcements {{may be in}} error for this reason.|$|E
5000|$|This {{is a third}} partly tool, {{developed}} by The Breast Cancer Tissue Bank BCTB in Australia, for checking <b>data</b> <b>accuracy</b> in an efficient way.|$|E
30|$|Effect of {{staleness}} of <b>data</b> on <b>accuracy</b> score.|$|R
50|$|Simulation {{models are}} {{generated}} from {{a set of}} data taken from a stochastic system. It is necessary to check that the data is statistically valid by fitting a statistical distribution and then testing the significance of such a fit. Further, as with any modelling process, the input <b>data’s</b> <b>accuracy</b> must be checked and any outliers must be removed.|$|R
50|$|Data {{governance}} initiatives improve {{data quality}} by assigning a team responsible for <b>data's</b> <b>accuracy,</b> accessibility, consistency, and completeness, among other metrics. This team usually consists of executive leadership, project management, line-of-business managers, and data stewards. The team usually employs {{some form of}} methodology for tracking and improving enterprise data, such as Six Sigma, and tools for data mapping, profiling, cleansing, and monitoring data.|$|R
5000|$|But the {{objection}} to this approach - {{although it can}} sometimes be proved to provide accurate data successfully - {{is that there is}} a loss in <b>data</b> <b>accuracy</b> and data quality.|$|E
50|$|There are {{a number}} of {{challenges}} to address when integrating data from different sources. The challenges can be classified into four groups: text/data mismatch, object identifiers and schema mismatch, abstraction level mismatch, <b>data</b> <b>accuracy.</b>|$|E
50|$|In April 2017, PRS for Music, ASCAP & SACEM {{announced}} a collaborative initiative to investigate Blockchain {{and how it}} could improve <b>data</b> <b>accuracy</b> which would potentially mean faster and more accurate royalty payments for songwriters.|$|E
5000|$|Privacy and Security of raw and {{processed}} citizens' personal <b>data</b> and <b>accuracy</b> of statistical <b>data</b> ...|$|R
5000|$|As {{with any}} {{statistical}} <b>data,</b> the <b>accuracy</b> of such <b>data</b> may be questionable for various reasons: ...|$|R
50|$|Note: The {{casualty}} totals are {{compiled by}} the news site Caucasian Knot, which does not vouch for the <b>data's</b> 100-percent <b>accuracy.</b>|$|R
50|$|The {{question}} of <b>data</b> <b>accuracy,</b> in particular, remains open. John Losey, {{who created the}} Lost Ladybug citizen science project, {{has argued that the}} cost-effectiveness of citizen science data can outweigh data quality issues, if properly managed.|$|E
50|$|Where available, the apps {{will show}} a map {{depicting}} the location {{at which the}} transaction took place, along with the company's logo. Transactions will be auto-categorised based on the company involved in the payment, with <b>data</b> <b>accuracy</b> improved via crowd-sourced suggestions.|$|E
50|$|Information {{management}} solutions simplify data access, {{analysis and}} management. They integrate with most legacy systems and enable organizations to manage complex and big data, ensure <b>data</b> <b>accuracy,</b> integrate applications and data across on-site and cloud environments, streamline business intelligence, and automate development and database management tasks.|$|E
5000|$|Minor {{variations}} in each support’s framing/format (mainly {{in terms of}} length and color usage) had no significant impact on <b>data</b> analysis <b>accuracy</b> or support use.|$|R
3000|$|... sub. With {{regard to}} the FH {{communication}} system, the bit error ratio (BER) is an important parameter index of <b>data</b> transmission <b>accuracy</b> within the given time.|$|R
40|$|A {{high-resolution}} {{simulation of}} stratospheric long-lived trace gases is subsampled in ways resembling various commonly used measurement platforms. The resulting measurements are analyzed {{with respect to}} whether they allow an accurate determination of stratospheric tracer relationships, as a prerequisite for a quantification of mixing processes from them. By varying the simulated locations, frequencies, and, {{in the case of}} satellite <b>data,</b> <b>accuracies</b> of the measurements we determine minimal requirements that the measurements need to satisfy in order to be suitable for a derivation of tracer relationships...|$|R
50|$|Modern MotionParallax3D {{displays}} use head-tracking forecast {{technology that}} compensates {{for the delay}} partially, but the accuracy and the forecast horizon are highly dependent {{on the quality of}} the initial <b>data</b> (<b>accuracy)</b> and also the quantity of the datasets with the user’s position coordinates that the system receives per time unit.|$|E
5000|$|The role of data {{aggregators}} {{has been}} criticized since 1995 [...] with privacy [...] and <b>data</b> <b>accuracy</b> [...] as main concerns.Most negative views against data aggregators {{are based on the}} use of personal email addresses and details, but since the company publishes company director names, it may be considered personal data as well ...|$|E
50|$|Argon's {{hybrid solid}} and surface {{modeling}} capabilities provide flexibility in shape design combined with <b>data</b> <b>accuracy.</b> This aids data translation and collaboration {{in the design}} process. Precision 2D drawings generated directly from the 3D model facilitate manufacturing. Argon is Ashlar-Vellum’s entry-level product in their Designer Elements line of 3D modeling and CAD software on Mac and Windows.|$|E
40|$|Interpolation {{procedure}} is broadly used in sciences that {{are concerned with}} spatial data and continuous phenomena that can be depicted on a spatial surface. Interpolation makes use of sampling data, which is accurate and qualitative, {{in order to produce}} a continuous representation of the phenomenon in question. The <b>data's</b> <b>accuracy</b> is transferred by the procedure to its results and should be known. This paper examines error propagation by the interpolation procedure, using the Inverse Distance Weighted (IDW) method {{in the case of the}} Earth's relief...|$|R
40|$|A dual comet (Halley Flyby/Tempel 2 Rendezvous) mission, {{making use}} of the solar {{electric}} propulsion system, is under consideration for a 1985 launch. This paper presents navigation accuracy analysis results for the Halley flyby phase of this mission. Orbit determination and guidance accuracies are presented for the baseline navigation strategy, along {{with the results of}} a number of sensitivity studies involving parameters such as <b>data</b> frequencies, <b>data</b> <b>accuracies,</b> ion drive thrust vector errors, comet ephemeris uncertainties, time lags associated with data processing and command sequence generation, probe release time, and navigation coast arc duration...|$|R
40|$|A {{ballistic}} intercept {{mission to}} Comet Halley is currently under consideration by the United States. This paper describes {{the navigation system}} and the navigation strategy which would be employed in such a mission, assuming a launch {{in the summer of}} 1985 and an arrival in March of 1986. Spacecraft comet-relative orbit determination accuracies are presented as functions of time for the baseline navigation strategy, along with the results of a number of parametric sensitivity studies involving parameters such as <b>data</b> frequencies, <b>data</b> <b>accuracies,</b> stochastic acceleration levels, cometary ephemeris uncertainties, maneuver execution errors, and encounter date...|$|R
50|$|The {{benefits}} of data profiling are to improve data quality, shorten the implementation cycle of major projects, and improve users' understanding of data. Discovering business knowledge embedded in data itself {{is one of}} the significant benefits derived from data profiling. Data profiling {{is one of the}} most effective technologies for improving <b>data</b> <b>accuracy</b> in corporate databases.|$|E
50|$|Valuation risks {{result from}} data {{management}} issues such as: Accuracy, integrity and consistency of static <b>data.</b> <b>Accuracy</b> and timeliness of {{information such as}} corporate events, credit events, or news potentially impact them. Streaming data, such as prices, rates, volatilities are even more vulnerable as they also depend on IT infrastructure and tools therefore adding a notion of technical and connectivity risk.|$|E
5000|$|The BCP manual must evolve {{with the}} organization. Activating the call tree verifies the {{notification}} plan's efficiency {{as well as}} contact <b>data</b> <b>accuracy.</b> Like most business procedures, business continuity planning has its own jargon. Organisation-wide understanding of business continuity jargon is vital and glossaries are available. Types of organisational changes that should be identified and updated in the manual include: ...|$|E
40|$|In {{this study}} options are {{explored}} for individual methane recordings of dairy cows on large scale under practical circumstances. In a simulation study based on respiration research <b>data,</b> <b>accuracies</b> of methane measurements based on different sampling strategies are calculated. Scenarios showed that measuring methane (or ratio CH 4 :CO 2) in the milking parlour or concentrate feeders will provide predictions {{close to the}} accuracy reached with scenarios based on sampling in cubicles. However under real farm conditions methane emission patterns may be more variable and overall accuracies decline...|$|R
40|$|One {{step towards}} the {{successful}} completion of a functional ground unit for the Differential Global Positioning System (DGPS) will be in choosing a currently available GPS receiver that will accurately measure the propagation times of the satellite signals and {{have the capability to}} be electrically interfaced with and controlled by a Digital Equipment Corporation (DEC) PDP- 11 / 34 A computer. The minimum requirements and characteristics of a NAVSTAR Global Positioning System (GPS) receiver are described. The specific technical specifications addressed include <b>data</b> <b>accuracies</b> and resolutions, receiver interface/external control, enclosure dimensions and mounting requirements, receiver operation, and environmental specifications...|$|R
40|$|The Smithsonian Astrophysical Observatory (SAO) {{operates}} a worldwide satellite tracking network {{which uses a}} combination of OMEGA as a frequency reference, dual timing channels, and portable clock comparisons to maintain accurate epoch time. Propagational charts from the U. S. Coast Guard OMEGA monitor program minimize diurnal and seasonal effects. Daily phase value publications of the U. S. Naval Observatory provide corrections to the field collected timing data to produce an averaged time line comprised of straight line segments called a time history file (station clock minus UTC). Depending upon clock location, reduced time <b>data</b> <b>accuracies</b> of between two and eight microseconds are typical...|$|R
