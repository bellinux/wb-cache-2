175|323|Public
25|$|The {{nuclear physics}} {{facility}} of the European Union's proposed <b>Extreme</b> <b>Light</b> Infrastructure (ELI) laser {{will be built}} in Romania. In early 2012, Romania launched its first satellite from the Centre Spatial Guyanais in French Guyana. Starting December 2014, Romania is a co-owner of the International Space Station.|$|E
500|$|Both fauna and flora are {{affected}} by the cold temperatures and the <b>extreme</b> <b>light</b> conditions. Activity is at a stand-still during the polar night, which [...] lasts for many months. During the summer, months of midnight sun help accelerate the natural processes. The nature in the area is especially susceptible to global warming. Models show that the winter temperatures will increase more than the summer temperatures, resulting in more precipitation. Because the vegetation requires little rain and much wind, this may result in major changes.|$|E
2500|$|The new Archos 14 Vision is an ultra {{portable}} MP3 {{player with}} 1.4" [...] color screen. Thanks {{to its original}} and unusual small design form factor and <b>extreme</b> <b>light</b> weight, the Archos 14 fits into a jean pocket. With 4 GB of storage it accommodates 2,000 songs.|$|E
40|$|We {{address the}} vehicle {{detection}} and classification problems using Deep Neural Networks (DNNs) approaches. Here we answer to {{questions that are}} specific to our application including how to utilize DNN for vehicle detection, what features are useful for vehicle classification, and how to extend a model trained on a limited size dataset, to the cases of <b>extreme</b> <b>lighting</b> condition. Answering these questions we propose our approach that outperforms state-of-the-art methods, and achieves promising results on image with <b>extreme</b> <b>lighting</b> conditions. Comment: 5 pages, 6 figures, conferenc...|$|R
40|$|Abstract—In this paper, {{we present}} a new method to modify the {{appearance}} of a face image by manipulating the illumination condition, when the face geometry and albedo information is unknown. This problem is particularly difficult when there is only a single image of the subject available. Recent research demonstrates that the set of images of a convex Lambertian object obtained under a wide variety of lighting conditions can be approximated accurately by a low-dimensional linear subspace using a spherical harmonic representation. Moreover, morphable models are statistical ensembles of facial properties such as shape and texture. In this paper, we integrate spherical harmonics into the morphable model framework by proposing a 3 D spherical harmonic basis morphable model (SHBMM). The proposed method can represent a face under arbitrary unknown lighting and pose simply by three low-dimensional vectors, i. e., shape parameters, spherical harmonic basis parameters, and illumination coefficients, which are called the SHBMM parameters. However, when the image was taken under an <b>extreme</b> <b>lighting</b> condition, the approximation error can be large, thus making it difficult to recover albedo information. In order to address this problem, we propose a subregion-based framework that uses a Markov random field to model the statistical distribution and spatial coherence of face texture, which makes our approach not only robust to <b>extreme</b> <b>lighting</b> conditions, but also insensitive to partial occlusions. The performance of our framework is demonstrated through various experimental results, including the improved rates for face recognition under <b>extreme</b> <b>lighting</b> conditions. Index Terms—Face synthesis and recognition, Markov random field, 3 D spherical harmonic basis morphable model, vision for graphics. Ç...|$|R
5000|$|... #Caption: The Aug 9, 2011 X6.9-class flare, {{taken by}} NASA's Solar Dynamics Observatory (SDO) in <b>extreme</b> UV <b>light</b> at 131 Angstroms.|$|R
2500|$|For {{those with}} certain color deficiencies, a red-tinted [...] "X-Chrom" [...] contact lens may be used. Although such a lens does not restore normal color vision, it allows some color-blind people to {{distinguish}} colors better. Red-filtering contact lenses {{can also be}} an option for <b>extreme</b> <b>light</b> sensitivity in some visual deficiencies such as achromatopsia.|$|E
60|$|I need {{scarcely}} do {{more than}} tell you to glance at {{any one of the}} works of Turner, and you will perceive in a moment the exquisite observation of all these principles; the sharpness, decision, conspicuousness, and excessively small quantity, both of <b>extreme</b> <b>light</b> and extreme shade, all the mass of the picture being graduated and delicate middle tint. Take up the Rivers of France, for instance, and turn over a few of the plates in succession.|$|E
60|$|Here {{is an idea}} {{not only}} poetical in a high degree, but {{strictly}} and philosophically just. <b>Extreme</b> <b>light,</b> by overcoming the organs of sight, obliterates all objects, so as in its effect exactly to resemble darkness. After looking for some time at the sun, two black spots, the impression which it leaves, seem to dance before our eyes. Thus are two ideas as opposite as can be imagined reconciled in the extremes of both; and both, {{in spite of their}} opposite nature, brought to concur in producing the sublime. And this is not the only instance wherein the opposite extremes operate equally in favor of the sublime, which in all things abhors mediocrity.|$|E
40|$|Successful face {{detection}} and facial feature extraction {{is crucial for}} {{for a variety of}} applications, including speech recognition and fatigue monitoring. Detecting and tracking faces in a moving automobile is challenging because of a variety of reasons. Among these reasons are changing poses, <b>extreme</b> <b>lighting</b> changes and shadowing. In this paper, we investigate two approaches for shadow compensation in such images. Together, these techniques offer a good improvement in the face detection accuracy on a data set captured in a moving automobile...|$|R
30|$|In Fig.  6, {{the test}} frames of EDSH 2 were taken under <b>extreme</b> <b>lighting</b> {{conditions}} of overexposed, underexposed and high contrast shadows. Parts {{of the hand}} are blended into background by the strong or insufficient light while the color and texture of the other parts are faded inordinately. Li and Kitani [1] fail to give good prediction in these cases. In contrast, our approach has much higher detection precision. Our continuously online training strategy makes the classifiers robust to varying illumination even in the extreme conditions.|$|R
40|$|Mobile {{eye-tracking}} in external environments remains challenging, despite {{recent advances}} in eye-tracking software and hardware engineering. Many current methods fail {{to deal with the}} vast range of outdoor lighting conditions and the speed at which these can change. This confines experiments to artificial environments where conditions must be tightly controlled. Additionally, the emergence of low-cost eye tracking devices calls for the development of analysis tools that enable non-technical researchers to process the output of their images. We have developed a fast and accurate method (known as "SET") that is suitable even for natural environments with uncontrolled, dynamic and even <b>extreme</b> <b>lighting</b> conditions. We compared the performance of SET with that of two open-source alternatives by processing two collections of eye images: images of natural outdoor scenes with <b>extreme</b> <b>lighting</b> variations ("Natural"); and images of less challenging indoor scenes ("CASIA-Iris-Thousand"). We show that SET excelled in outdoor conditions and was faster, without significant loss of accuracy, indoors. SET offers a low cost eye-tracking solution, delivering high performance even in challenging outdoor environments. It is offered through an open-source MATLAB toolkit as well as a dynamic-link library ("DLL"), which can be imported into many programming languages including C# and Visual Basic in Windows OS (www. eyegoeyetracker. co. uk) ...|$|R
6000|$|... 170. Thus, in Turner's sepia drawing [...] "Isis" [...] (Edu. 31), {{he begins}} with the <b>extreme</b> <b>light</b> in the sky, and shades down from that till he is forced to {{represent}} the near trees and pool as one mass of blackness. In his drawing of the Greta (S. 2), he {{begins with the}} dark brown shadow of the bank on the left, and illuminates up from that, till, in his distance, trees, hills, sky, and clouds, are all lost in broad light, {{so that you can}} hardly see the distinction between hills and sky. The second of these methods is in general the best for colour, though great painters unite both in their practice, according to the character of their subject. The first method is never pursued in colour but by inferior painters. It is, nevertheless, of great importance to make studies of chiaroscuro in this first manner for some time, as a preparation for colouring; and this for many reasons, which it would take too long to state now. I shall expect you to have confidence in me when I assure you of the necessity of this study, and ask you to make good use of the examples from the Liber Studiorum which I have placed in your Educational series.|$|E
5000|$|<b>Extreme</b> <b>Light</b> Infrastructure http://www.extreme-light-infrastructure.eu ...|$|E
5000|$|... 200 PW - tech: planned {{peak power}} of <b>Extreme</b> <b>Light</b> Infrastructure laser ...|$|E
30|$|HDR imaging {{systems are}} {{stepping}} into the multimedia technologies for consumer market. HDR pursues a more complete representation of information that the human eye can see, capturing all the brightness information of the visible range of a scene, even in <b>extreme</b> <b>lighting</b> conditions. Hence, it pursues {{the representation of the}} entire dynamic range and color gamut perceived by human visual system (HVS). HDR imaging can be exploited to improve quality of experience in multimedia applications [1] and to enhance intelligibility in security applications where lighting conditions cannot be controlled [2].|$|R
40|$|We {{present a}} new {{interferometer}} technique whereby multiple <b>extreme</b> ultraviolet <b>light</b> pulses are generated at different positions {{within a single}} laser focus (i. e., from successive sources) with a highly controllable time delay. The interferometer technique is tested with two generating media to create two <b>extreme</b> ultraviolet <b>light</b> pulses with a time delay between them. The delay {{is found to be}} a consequence of the Gouy phase shift. Ultimately the apparatus is capable of accessing unprecedented time scales by allowing stable and repeatable delays as small as 100 zs. © 2012 American Physical Society...|$|R
60|$|INVERCARGIL (N. Z.)--From 1st prox.: <b>extreme</b> southerly <b>light</b> (double red) will exhibit white beam {{inclined}} 45 degrees on {{approach of}} Southerly Buster. Traffic flies high off this coast between April and October.|$|R
50|$|On the 23rd of November 2015 he {{attended}} the Third Christmas Lecture held in Bucharest. His presentation was entitled Breaking Through The Unknown: <b>Extreme</b> <b>light,</b> Science to Art. The previous lectures were given by Sir Thomas Kibble and Professor Joseph Silk.|$|E
50|$|With a {{proprietary}} AWD system, <b>extreme</b> <b>light</b> weight and 1,000 hp per metric ton the D1 {{will be the}} flagship of the Palatov Motorsport product lineup. The D1 is designed to use the American designed and built Hartley V8 exclusively.|$|E
5000|$|The {{effect of}} XPW {{generation}} is finding application for enhancement {{of the temporal}} contrast of femtosecond pulses 4 and for their monitoring and control. The approach of XPW generation for cleaning femtosecond pulses {{will be used in}} the <b>Extreme</b> <b>Light</b> Infrastructure European project.|$|E
50|$|Cymer is {{currently}} developing next-generation laser-produced plasma <b>extreme</b> ultraviolet (EUV) <b>light</b> sources.|$|R
5000|$|... #Caption: The 13-15 May 2013 {{series of}} four X-class flares erupted by AR1748: X1.7, X2.8, X3.2 and X1.2. Shots taken by NASA's Solar Dynamics Observatory (SDO) in the 131 Angstrom {{wavelength}} of <b>extreme</b> UV <b>light.</b>|$|R
5000|$|... 1999: Mark F. Twight, James Martin, <b>Extreme</b> Alpinism: Climbing <b>Light,</b> Fast and High ...|$|R
50|$|The {{sick man}} with bandaged {{eyes on the}} right is {{suffering}} from blindness as well as plague. Since the army's arrival in Egypt in July 1798, several French had suffered serious eye problems due to the sand, dust and <b>extreme</b> <b>light</b> of the sun.|$|E
50|$|The {{nuclear physics}} {{facility}} of the European Union's proposed <b>Extreme</b> <b>Light</b> Infrastructure (ELI) laser {{will be built}} in Romania. In early 2012, Romania launched its first satellite from the Centre Spatial Guyanais in French Guyana. Starting December 2014, Romania is a co-owner of the International Space Station.|$|E
5000|$|The new Archos 14 Vision is an ultra {{portable}} MP3 {{player with}} 1.4" [...] color screen. Thanks {{to its original}} and unusual small design form factor and <b>extreme</b> <b>light</b> weight, the Archos 14 fits into a jean pocket. With 4 GB of storage it accommodates 2,000 songs.|$|E
40|$|In this paper, a novel {{background}} {{model on}} spatio-temporal patches is introduced for video surveillance, especially for night outdoor scene, where <b>extreme</b> <b>lighting</b> conditions often cause troubles. The spatio-temporal patch, called brick, {{is presented to}} simultaneously capture spatio-temporal information in surveillance video. The set of bricks of a given background patch, under all possible lighting conditions, lies in a low-dimensional subspace, which can be learned by online subspace learning. The proposed method can efficiently model the background and detect the appearance and motion variance caused by foreground. Experimental results on real data show that the proposed method is insensitive to dramatic lighting changes and achieves superior performance to two classical methods. 1...|$|R
5000|$|Garden of Extremes, {{features}} {{plants and}} materials often unique to <b>extremes</b> such as <b>light</b> and weather conditions ...|$|R
40|$|In {{augmented}} reality, virtual {{objects are}} added to the real world by superimposing them onto a video stream or a head-mounted display in real-time. Typical augmented reality applications track 2 D patterns on rigid planar objects in order to acquire the pose of the camera in the scene. Rigid augmentations are then performed on the planar objects. We present a method to track non-rigid objects such as cloth, and to perform flexible augmentations on the cloth while stretching and rippling it in real-time, using a single camera. In addition, we present a simple technique to apply real-world illumination to the augmentation, which greatly improves perception and realism. Results show believable real-time augmentations of a non-rigid object, even under <b>extreme</b> <b>lighting</b> conditions. 2 Content...|$|R
50|$|Peter Pitseolak (1902-1973), Inuk from Cape Dorset, Nunavut, {{documented}} Inuit {{life in the}} mid-20th century while {{dealing with}} challenges presented by the harsh climate and <b>extreme</b> <b>light</b> conditions of the Canadian Arctic. He developed his film himself in his igloo, {{and some of his}} photos were shot by oil lamps.|$|E
50|$|Ries’s sculptures {{are noted}} for their {{changing}} internal optical compositions and technical proficiency. Ries’s primary medium is clear lead crystal, a glass with {{an unusually high}} refractive index, <b>extreme</b> <b>light</b> transmission in the visual range, and outstanding homogeneity. These qualities enable Ries to create the optical effects found within his work.|$|E
50|$|Adrian Curaj {{is one of}} the {{initiators}} {{and supporters}} of the ELI-NP project (<b>Extreme</b> <b>Light</b> Infrastructure - Nuclear Physics) at Măgurele, the world's largest laser with a major impact on the Romanian and European RDI system, on higher education {{as well as on the}} economic and social environment of south Bucharest area.|$|E
40|$|While most of {{state-of-the-art}} {{image processing}} techniques were built under the so-called classical linear image processing, an alternative that presents superior behavior for specific applications {{comes in the}} form of Logarithmic Type Image Pro-cessing (LTIP). This refers to mathematical models constructed for the representation and processing of gray tones images. In this paper we describe a general mathematical framework that allows extensions of these models by various means while preserving their mathematical properties. We propose a parametric extension of LTIP models and discuss its similarities with the human visual system. The usability of the proposed extension model is verified for an application of contrast based auto-focus in <b>extreme</b> <b>lighting</b> conditions. The closing property of the named models facilitates superior behavior when compared with state-of-the-art methods...|$|R
30|$|For M 4, {{we fully}} revised this {{approach}} to use well established technology for observing matter-wave interference with massive particles. This approach does not only NOT require <b>extreme</b> UV <b>light,</b> it also brings the benefit of much shorter free-fall times and higher interference visibilities. See Section  5.3.|$|R
40|$|The {{underground}} {{scenarios are}} one of the most challenging environments for accurate and precise 3 d mapping where hostile conditions like absence of Global Positioning Systems, <b>extreme</b> <b>lighting</b> variations and geometrically smooth surfaces may be expected. So far, the state-of-the-art methods in underground modelling remain restricted to environments in which pronounced geometric features are abundant. This limitation is a consequence of the scan matching algorithms used to solve the localization and registration problems. This paper contributes to the expansion of the modelling capabilities to structures characterized by uniform geometry and smooth surfaces, as is the case of road and train tunnels. To achieve that, we combine some state of the art techniques from mobile robotics, and propose a method for 6 DOF platform positioning in such scenarios, that is latter used for the environment modelling. A visual monocular Simultaneous Localization and Mapping (MonoSLAM) approach based on the Extended Kalman Filter (EKF), complemented by the introduction of inertial measurements in the prediction step, allows our system to localize himself over long distances, using exclusively sensors carried on board a mobile platform. By feeding the Extended Kalman Filter with inertial data we were able to overcome the major problem related with MonoSLAM implementations, known as scale factor ambiguity. Despite <b>extreme</b> <b>lighting</b> variations, reliable visual features were extracted through the SIFT algorithm, and inserted directly in the EKF mechanism according to the Inverse Depth Parametrization. Through the 1 -Point RANSAC (Random Sample Consensus) wrong frame-to-frame feature matches were rejected. The developed method was tested based on a dataset acquired inside a road tunnel and the navigation results compared with a ground truth obtained by post-processing a high grade Inertial Navigation System and L 1 /L 2 RTK-GPS measurements acquired outside the tunnel. Results from the localization strategy are presented and analyzed...|$|R
