59|61|Public
50|$|A huge {{assumption}} in the BROP {{attack is}} that the server restarts after each crash and when restarting does not re-randomize its address space. So enabling re-randomization of address space at startup can provide almost complete protection against BROP. Another technique used by NetBSD and Linux are sleep on crash. This slows down the attack considerably and allows the system administrator to look into any suspicious activity.Apart from this the conventional protection against ROP style control flow hijacking attacks, Control <b>Flow</b> <b>Integrity</b> also can provide provable prevention but at a significant performance overhead.|$|E
30|$|However, the {{security}} requirements are far beyond guaranteeing {{the integrity of}} executable binaries. Even if the executable binaries are unchanged, there are still security risks as the control <b>flow</b> <b>integrity</b> (CFI) and data <b>flow</b> <b>integrity</b> (DFI) can be exploited by malware. Dedicated mechanisms implemented in processor chips could be very helpful in defending such kind of advanced attacks.|$|E
30|$|In this section, {{we focus}} on two {{potential}} defenses against DSMAs: Data <b>Flow</b> <b>Integrity</b> and Data-Plane Randomization.|$|E
40|$|This paper {{describes}} {{the development of}} the two tier client/server database program, “SurvBase”, implemented for accelerator alignment data management at the Alternating Gradient Synchrotron (AGS) and the Relativistic Heavy Ion Collider (RHIC) at Brookhaven National Laboratory (BNL). Integration of Windows NT, Visual Basic 5. 0 (VB) and Sybase Open Database Connectivity (ODBC) program development environment components is explained. Logic and algorithms for data <b>flow</b> and <b>integrity</b> are given along with Structured Query Language (SQL) and VB code examples. Program expansion capacity and back end Relational Database Server switching are discussed...|$|R
40|$|International audienceWith the {{globalization}} of the IC design <b>flow,</b> structural <b>integrity</b> verification to detect parasitic electrical activities has emerged as an important research domain for testing the genuineness of an Integrated Circuit (IC). Sensors like Ring Oscil-lators (RO) have been proposed to precisely monitor the internal behaviour of the ICs. In this paper we propose an experimental analysis {{of the impact of}} parasitic electrical activities on the frequencies of ROs and on the internal supply voltages measured. Our observations lead us to identify the limits of the usability of ROs for practical and embedded detection of Hardware Trojans...|$|R
40|$|Improving {{corporate}} governance {{has emerged as}} a priority in all OECD Member countries during the past few years. The enhanced accountability, transparency, and <b>integrity</b> <b>flowing</b> from improved {{corporate governance}} practices create value for shareholders and other stakeholders, reduce the cost of capital, and increase a company’s competitiveness in the global marketplace. Corporate governance is also importan...|$|R
40|$|Abstract — The {{notion of}} trust has {{traditionally}} been utilized at transaction level in order to bypass expensive security checks. In this paper, we extend the trust model to individual programs. Moreover, we develop a self assessment/monitoring framework for trust based on control <b>flow</b> <b>integrity</b> that {{can be incorporated into}} a compiler. We also extend the concept of Schneider’s enforceable security policy into that of an enforceable trust policy. This trust assessment model has been implemented with SUIF and gcc C compilers. An architectural modification to support efficient management of control <b>flow</b> <b>integrity</b> based trust model has also been developed and is being evaluated. I...|$|E
40|$|We propose an {{integrity}} measurement approach {{based on}} information <b>flow</b> <b>integrity,</b> which we call the Policy-Reduced Integrity Measurement Architecture (PRIMA). The recent availability of secure hardware has made it practical for a system to measure its own integrity, such that it can generate an integrity proof for remote parties. Various approaches have been proposed, but most simply measure the loaded code and static data to approximate runtime system integrity. We find that these approaches suffer from two problems: (1) the load-time measurements of code alone do not accurately reflect runtime behaviors, {{such as the use}} of untrusted network data, and (2) they are inefficient, requiring all measured entities to be known and fully trusted even if they have no impact on the target application. Classical integrity models are {{based on information}} flow, so we design the PRIMA approach to enable measurement of information <b>flow</b> <b>integrity</b> and prove that it achieves these goals. We prove how a remote party can verify useful information <b>flow</b> <b>integrity</b> properties using PRIMA. A PRIMA prototype has been built based on the open-source Linux Integrity Measurement Architecture (IMA) using SELinux policies to provide the information flow...|$|E
40|$|Data <b>flow</b> <b>integrity</b> {{enforcement}} overview Data <b>flow</b> <b>integrity</b> enforcement uses {{static analysis}} to computer a data flow graph. Program excute following such data – flow graph. Data <b>flow</b> <b>integrity</b> enforcement can be automatically applied to C & C++ without any mofification. It has no false positive and low overhead Compare other proposals to prevent attacks on software: • Its overhead is lower; • Not defend from attacks that overwrite specific targets or {{specific types of}} Vulnerabilities, but a broad class of attacks and prevent both control data attacks and non-control data attacks using data-flow integrity; • No false positives. TU Dresden, 04,Jun, 2007 Securing software by enforcing data-flow integrity Folie 3 von 23 Generel technology about data-flow integrity enforcement How to ensure runtime data <b>flow</b> <b>integrity?</b> The implement uses reaching definitions analysis to compute a static data-flow graph to enforce data-flow integrity at runtime. Maintains a table with the identifier of the last instruction to write to each memory positon. Each memory position Identifier of the last instruction to write • Only compute the set of instructions that may write the value to low overhead and increase performance • We need {{check to make sure}} whether the value read from the table is computed by the static analysis or not. If not, we raise an exception • Update the table before every write • Prevent the attacker from tampering with the table TU Dresden, 04,Jun, 2007 Securing software by enforcing data-flow integrity Folie 4 von 23 Reduce overhead Compute equivalence classes of instructions and assigns the same identifier to all the instructions in the same Class. Identifiers for different equivalence classes of instruction Different equivalence classes of instructio...|$|E
50|$|In {{low level}} {{information}} flow analysis, each variable is usually assigned a security level. The basic model comprises two distinct levels: low and high, meaning, respectively, publicly observable information, and secret information. To ensure confidentiality, flowing information from high to low variables {{should not be}} allowed. On the other hand, to ensure <b>integrity,</b> <b>flows</b> to high variables should be restricted.|$|R
40|$|We {{present an}} {{approach}} {{for the management}} of highly critical tasks coexisting with non-critical tasks in a single processor or multiprocessor architecture. To prevent error propagation from non-critical to critical tasks, an integrity level is assigned to groups of tasks according to their trustworthiness. Multiple levels of integrity are implemented using spatial and temporal isolation, and mediation via an integrity policy. The integrity policy defines the rules for data <b>flow</b> between <b>integrity</b> levels and resource utilisation by the tasks at different levels. Since the GUARDS project aims to provide generic solutions for a variety of application domains, the described integrity management can be implemented either in a middleware, the operating system or both. In this paper, we show a CORBA-compliant implementation of the integrity policy...|$|R
40|$|In {{the life}} sciences, {{problems}} with identifiers impede the <b>flow</b> and <b>integrity</b> of information. This is especially challenging within “synthesis research” disciplines such as systems biology, translational medicine, and ecology. Implementation-driven initiatives such as ELIXIR, BD 2 K, {{and others have}} therefore been actively working to understand and address underlying problems with identifiers. Good, global-scale, persistent identifier design is harder than it appears, and is essential for data to be Findable, Accessible, Interoperable, and Reusable (Data FAIRport principles). Here, we build on emerging conventions and existing general recommendations and summarise the identifier characteristics most important to optimising the utility of life-science data. We propose actions {{to take in the}} identifier ‘green field’ and offer guidance for using real-world identifiers from diverse sources...|$|R
40|$|International audienceIn {{contrast}} to other IT systems, industrial systems {{often do not}} only require classical properties like data confidentiality or authentication of the communication, but have special needs due to their interaction with physical world. For example, the reordering or deletion of some commands sent to a machine can cause the system to enter an unsafe state with potentially catastrophic effects. To prevent such attacks, {{the integrity of the}} message flow is necessary. We provide a formal definition of <b>Flow</b> <b>Integrity.</b> We apply our framework to two well-known industrial protocols: OPC-UA and MODBUS. Using TAMARIN, a cryptographic protocol verification tool, we confirm that most of the secure modes of these protocols ensure <b>Flow</b> <b>Integrity</b> given a resilient network. However, we also identify a weakness in a supposedly secure version of MODBUS...|$|E
30|$|DTrace {{assumes the}} {{application}} has been equipped with control <b>flow</b> <b>integrity</b> (CFI) enforcement. Thus the attacker cannot manipulate the control data to insert hardware tracing events. In fact, researchers have proposed solutions (Ge et al. 2017; Liu et al. 2017; Ding et al. 2017) to enforce CFI {{with the help}} of Intel PT. DTrace’s design is compatible with the Intel-PT-based CFI enforcement.|$|E
30|$|However, memory error {{exploits}} {{can change}} the application’s behavior without corrupting any control data, which does not violate control <b>flow</b> <b>integrity</b> (CFI) policy (Abadi et al. 2005) and thus bypasses CFI enforcement. Recent studies have demonstrated the threat of non-control-data attacks, such as corrupting configuration and decision-making variables and bypassing access restrictions (Chen et al. 2005; Song et al. 2016; Hu et al. 2016).|$|E
40|$|In this {{research}} a small size downhole turbine motor {{was designed to}} be used in coiled tube drilling for applications in mineral exploration. The motor should provide a very high output rotation speed as it is used for drilling hard rocks. Numerical simulations using ANSYS was carried out in this study to model fluid <b>flow</b> and mechanical <b>integrity</b> of the designed motor. The optimum design was proposed for drilling using water and air as drilling fluids...|$|R
40|$|As {{data rates}} {{required}} for systems in package (SiPs) increase and their complexity increases, signal integrity issues become {{increasingly difficult to}} address. The design flow of the SiP should therefore take into account these issues from the beginning. A design flow aimed at designing the SiP tracks is presented; its suitability {{for the design of}} packages comprising multiple stacked memories is verified through a design example. The proposed <b>flow</b> for signal <b>integrity</b> can be integrated easily within the complete design of the SiP...|$|R
40|$|With a {{rapid growth}} of data storage in the cloud, data {{integrity}} checking in a remote data storage system has become an important issue. A number of protocols, which allow remote integrity checking by a third party, have been proposed. Although those protocols are provably secure, the data privacy issues in those protocols have not been considered. We believe that these issues are equally important since the communication <b>flows</b> of <b>integrity</b> proofs from the cloud server should not reveal any useful information of the stored data. In this paper, we introduce a new definition of data privacy called 2 ̆ 7 IND-Privacy 2 ̆ 7 by an indistinguishability game. It is found that many existing remote integrity proofs are insecure under an IND-Privacy game. It is also found that by adopting witness indistinguishable proofs, the IND-Privacy is achievable. We provide an instantiation that captures data integrity, soundness and IND-privacy...|$|R
30|$|Researchers have {{explored}} to leverage Intel PT to enhance software debugger (Kasikci et al. 2017; Cui et al. 2018) and enforce the security property of control <b>flow</b> <b>integrity</b> (CFI) (Liu et al. 2017; Ge et al. 2017; Ding et al. 2017). These tools and systems benefit {{in terms of}} efficiency and accuracy by digging out the information about program control flow captured by Intel PT including timestamps and control transfers.|$|E
40|$|Software-based, {{fine-grain}} control <b>flow</b> <b>integrity</b> (CFI) {{validation technique}} {{has been proposed}} to enforce control <b>flow</b> <b>integrity</b> of program execution. By validating every indirect branch instruction, it can prevent various control flow attacks, but {{at the cost of}} non-trivial overhead: up to 50 % and on average 21 % as reported in a case study. We propose a new hardware mechanism to accelerate the CFI validation. It utilizes the branch prediction unit of modern processors to reduce the frequency of necessary validation, and proposes to use a small hardware structure called indirect branch filter cache (IBF cache) to further reduce the frequency of validation. The small IBF cache buffers and reuses previous validation results, which dramatically reduces the frequency of validation for all workloads we have studied. We collect the trace of indirect branch of various workloads on an Intel P 4 computer and conduct trace-based simulation to estimate the performance overhead. Our results show that the overhead is negligible for all SPEC CPU 2000 int, SPEC CPU 2006 int programs, TPC-C, WebStone and FTP server benchmarks. ...|$|E
40|$|Control <b>flow</b> <b>integrity</b> or CFI {{has emerged}} as an {{important}} technique forpreventing attacks on software. Previous approaches relied on staticanalysis and thus largely target static binaries and are limited in howtightly they can constrain a program's runtime behavior. Unfortunately,modern Windows applications make extensive use of dynamically generatedcode. We introduce a new dynamic analysis based approach in DCFI tocontrol <b>flow</b> <b>integrity</b> that precisely learns a program's behavior bymonitoring previous executions. DCFI is the first approach todemonstrate CFI {{in the presence of}} dynamic code generation and/orself-modifying code and is immune to recent variations on ROP attacksthat thwart previous CFI approaches. DCFI underapproximates the legalexecutions of software applications and thus can potentially buildtighter constraints than static approaches. As DCFI's knowledge of aprogram becomes more complete, it tightens its constraints on aprogram's execution, making successful attacks progressively moredifficult. We have implemented DCFI in DynamoRIO. Our experiences using DCFIindicate that it can protect modern desktop applications with dynamiccode generation engines including the latest versions of Microsoft Word,Microsoft Excel, Microsoft PowerPoint, Microsoft Outlook, Google Chrome,and Adobe Acrobat. Experiments also show that DCFI effectively detectsknown exploits...|$|E
40|$|We {{explore the}} role of {{agriculture}} in destabilizing the Earth system at the planetary scale, through examining nine planetary boundaries, or “safe limits”: land-system change, freshwater use, biogeochemical <b>flows,</b> biosphere <b>integrity,</b> climate change, ocean acidification, stratospheric ozone depletion, atmospheric aerosol loading, and introduction of novel entities. Two planetary boundaries have been fully transgressed, i. e., are at high risk, biosphere <b>integrity</b> and biogeochemical <b>flows,</b> and agriculture has been the major driver of the transgression. Three are in a zone of uncertainty i. e., at increasing risk, with agriculture the major driver of two of those, landsystem change and freshwater use, and a significant contributor to the third, climate change. Agriculture is also a significant or major contributor to change for many of those planetary boundaries still in the safe zone. To reduce {{the role of}} agriculture in transgressing planetary boundaries, many interventions will be needed, including those in broader food systems...|$|R
50|$|As IBIS evolved {{with the}} {{participation}} of more companies and industry members, an IBIS Open Forum was created to promote the application of IBIS as a simulation tool format {{and to make sure}} that a standard exists. Many semiconductor vendors supply IBIS models and many EDA vendors sell IBIS-compliant software tools. In 1995 the IBIS Open Forum teamed with the American National Standards Institute/Electronic Industries Alliance (ANSI/EIA). IBIS version 2.1 was the first version released by the new alliance. It added the ability to simulate ECL and PECL buffers as well as differential lines. IBIS 3.2 allows for a package model description along with an electrical board description. IBIS Version 5.0 was ratified by the IBIS Open Forum on August 29, 2008. Compared to the previous version (IBIS 4.2, ANSI/EIA-656-B), it adds a new flow based not on SPICE transient but on a channel simulator (called algorithmic model application program interface or AMI <b>flow),</b> power <b>integrity,</b> and EMC checking features. For power integrity, it uses Touchstone 2.0 S-parameter files with per-port reference impedance specification.|$|R
50|$|In June 2016, {{the balloon}} Phoenix was retired {{when it could}} no longer pass its annual {{airworthiness}} inspection. In the 18 months of operating with New Mexico Wing and starting the New Mexico Balloon Program, it produced five lighter than air pilots. Since Phoenix was retired, {{there was a need}} to find a replacement to continue the program. In October 2016, an order was placed with Lindstrand Balloons USA to build a custom envelope to replace the retired envelope of Phoenix.On December 27, 2016; New Mexico Wing took delivery of a ninety thousand cubic foot Lindstrand 90A Envelope named <b>Integrity.</b> <b>Integrity</b> <b>Flew</b> its first flight 8 January 8, 2016.|$|R
40|$|Computers {{were not}} built with {{security}} in mind. As such, security has and still often takes {{a back seat}} to performance. However, in an era where there is so much sensitive data being stored, with cloud storage and huge customer databases, much has to be done to keep this data safe from intruders. 	Control flow hijacking attacks, stemming from a basic code injection attack to return-into-libc and other code re-use attacks, are among the most dangerous attacks. Currently available solutions, like Data execution prevention that can prevent a user from executing writable pages to prevent code injection attacks, do not have an efficient solution for protecting against code re-use attacks, which can execute valid code in a malicious order. 	To protect against control flow hijacking attacks, this work proposes architecture to make Control <b>Flow</b> <b>Integrity,</b> a solution that proposes to validate control flow against pre-computed control flow graph, practical. Current implementations of Control <b>Flow</b> <b>Integrity</b> have problems with code modularity, performance, or scalability, so I propose Dynamic Bloom Cache, a blocked-Bloom-filter-based approach, to solve current implementation issues. M. S...|$|E
40|$|Protecting program {{execution}} is {{a critical}} issue in today 2 ̆ 7 s computing systems. Even with all the efforts and dramatic advances in computer system protection, system attacks continue to evolve to explore existing and new vulnerabilities in computer systems. In this thesis, we propose several ecient and practical methods to validate program control <b>flow</b> <b>integrity</b> as extra layers of system protection. In general, the approach to control <b>flow</b> <b>integrity</b> checking is to detect anomalies of program behavior given that control flow information is closely coupled with program execution correctness and can be consider as the DNA of a program. It is hard, if not impossible, for two programs to expose identical control flows during program execution. Therefore, control <b>flow</b> <b>integrity</b> checking can effectively prevent malicious code implants from executing. This thesis proposes three new protection schemes based on control <b>flow</b> <b>integrity</b> checking, {{each with its own}} assumptions of hardware and/or application scenarios. The first study, IBMON (Indirect Branch MONitor), utilizes existing hardware features to eciently observe unusual control flow transfers and check them for any abnormality. Prototype systems for proof of concept have been successfully implemented on three different system platforms to demonstrate its efficacy. By using the hardware features, IBMON can effectively protect a system from malicious control ow modification trans-parently to the target applications. We have successfully built prototype systems on real machines using several processors. Although the prototype system exhibits the best performance among other control flow validation mechanisms, it still incurs moderate performance overhead. We further propose IBF-Cache, an enhanced IBMON system with special hardware support, to minimize the performance overhead associated with IBMON. Although it requires an extension of existing processors, the cost is negligible and the run-time of IBMON is reduced to virtually zero. Control flow validation is also an effective approach to detect malicious program because control flow transfers in program are unique. There are limitations of detection method for malicious software in traditional anti-virus program. Anti-virus software cannot consistently detects the new generation of malicious program such as polymorphic program. The thesis also explores the extension of the control flow validation mechanism to augment the ability of anti-virus software for detecting polymorphic malware. The RCFI (Recent Control Flow Inspection) system is proposed to validate recent control flow transfers in run-time with enhanced hardware features. The RCFI system can effectively detect polymorphic malware that uses various obfuscation tools to evade the detection mechanism of static binary scanning...|$|E
40|$|Subverting runtime {{data flow}} {{is common in}} many current {{software}} attacks. Data <b>Flow</b> <b>Integrity</b> (DFI) is a policy whose satisfaction can prevent such attacks. This paper develops a formal foundation on DFI specification, and characteristics of its enforcement techniques with formulations of hypotheses and guarantees. Enforcement techniques are based on static analysis and program monitoring at runtime. This foundation {{can be used for}} practical satisfaction of DFI and help establish guarantees in every applied platform...|$|E
50|$|Testimony to {{integrity}} and truth, {{refers to the}} way {{many members of the}} Religious Society of Friends (Quakers) testify or bear witness to their belief that one should live a life that is true to God, true to oneself, and true to others. To Friends, the concept of integrity includes personal wholeness and consistency as well as honesty and fair dealings. From personal and inward <b>integrity</b> <b>flow</b> the outward signs of integrity, which include honesty and fairness. It is not only about telling the truth - it is applying ultimate truth to each situation. For example, Friends (Quakers) believe that integrity requires avoiding statements that are technically true but misleading.|$|R
40|$|Abstract. Identifying and {{protecting}} the trusted computing base (TCB) of a system is an important task, which is typically performed by designing and enforcing a system security policy and verifying whether an existing policy satisfies security objectives. To efficiently support these, an intuitive and cognitive policy analysis mechanism is desired for policy designers or security administrators due to the high complexity of policy configurations in contemporary systems. In this paper, we present a graph-based policy analysis methodology to identify TCBs with the consideration of different system applications and services. Through identifying information <b>flows</b> violating the <b>integrity</b> protection of TCBs, we also propose resolving principles to using our developed graph-based policy analysis tool. ...|$|R
40|$|This paper {{advocates a}} novel {{approach}} {{to the construction of}} secure software: controlling information <b>flow</b> and maintaining <b>integrity</b> via monadic encapsulation of effects. This approach is constructive, relying on properties of monads and monad transformers to build, verify, and extend secure software systems. We illustrate this approach by construction of abstract operating systems called separation kernels. Starting from a mathematical model of shared-state concurrency based on monads of resumptions and state, we outline the development by stepwise refinements of separation kernels supporting Unix-like system calls, interdomain communication, and a formally verified security policy (domain separation). Because monads may be easily and safely represented within any pure, higher-order, typed functional language, the resulting system models may be directly realized within a language such as Haskell...|$|R
30|$|Data isolation. Researchers have {{proposed}} numerous solutions {{to enforce the}} integrity of security-critical data. Data <b>flow</b> <b>integrity</b> {{can be achieved by}} restricting all memory write operations within their bounds so that no memory error exploit can be launched (Akritidis et al. 2008; Castro et al. 2006; Oleksenko et al. 2017; Erlingsson et al. 2006; Koning et al. 2017). The high overhead of instrumenting all memory writes regardless of the exploitability makes these solutions far from practical.|$|E
30|$|Second, DTrace’s data {{recording}} operation {{is embedded in}} the program code which cannot be bypassed as long as the instrumented instructions are executed. We assume that control <b>flow</b> <b>integrity</b> techniques are deployed in the application to provide the assurance that the attacker cannot hijack the program execution. Furthermore, we assume that the system will properly handle page permission settings that ensure instrumented instructions cannot be modified by the attacker. As the result, the embedded data tracing operations will loyally record down all the data access events.|$|E
30|$|As a {{counteraction}} against DEP, adversaries {{switched from}} code-injection attacks to code-reuse attacks such as return-to-libc and Return-Oriented-Programming (ROP). These code-reuse attacks have motivated {{a very large}} amount of research on how to defend and how to counterattack. In the past 10 years, the research community has gained deep understanding about the cost-effectiveness of major defenses, including Address Space Layout Randomization (ASLR) 1 (Backes and Nürnberger 2014; Bhatkar et al. 2003; Kil et al. 2006; Keromytis et al. 2012; The PaX Team 2003 b) and Control <b>Flow</b> <b>Integrity</b> (CFI) 2 (Abadi et al. 2005).|$|E
40|$|A laser transit {{anemometer}} (LTA) {{system was}} used to probe the boundary layer on a slender (5 degree half angle) cone model in the Langley unitary plan wind tunnel. The anemometer system utilized a pair of laser beams with a diameter of 40 micrometers spaced 1230 micrometers apart to measure the transit times of ensembles of seeding particles using a cross-correlation technique. From these measurements, boundary layer profiles around the model were constructed and compared with CFD calculations. The measured boundary layer profiles representing the boundary layer velocity normalized to the edge velocity {{as a function of}} height above the model surface were collected with the model at zero angle of attack for four different flow conditions, and were collected in a vertical plane that bisected the model's longitudinal center line at a location 635 mm from the tip of the forebody cone. The results indicate an excellent ability of the LTA system to make velocity measurements deep into the boundary layer. However, because of disturbances in the flow field caused by onboard seeding, premature transition occurred implying that upstream seeding is mandatory if model <b>flow</b> field <b>integrity</b> is to be maintained. A description and results of the flow field surveys are presented...|$|R
40|$|Objectives. DOPPLER-CIP aims to {{determine}} the optimal noninvasive parameters (myocardial function, perfusion, ventricular blood <b>flow,</b> cell <b>integrity)</b> and methodology (ergometry, echocardiography, scintigraphy, MRI) in a given ischemic substrate that best predicts the impact of an intervention (or the lack thereof) on adverse morphological ventricular remodeling and functional recovery. Moreover, the relative predictive value {{of each of these}} parameters, in respect to the cost of extracting this information in order to enable optimization of cost-effectiveness for improved health care, will be determined by this project. Design. DOPPLER-CIP is a multi-center registry study. All patients with ischemic heart disease included in this study undergo at least two noninvasive stress imaging examinations at baseline. The presence/or absence of left ventricular (LV) remodeling will be assessed after a follow-up of 2 years, during which all cardiac events will be registered. Results. 676 patients were included. Currently, baseline data analysis is almost finished and the follow-up is ongoing. Conclusions. After completion, DOPPLER-CIP will provide evidence-based guidelines toward the most effective use of cardiac imaging in the chronically ischemic heart disease patient. The study will generate information, knowledge, and insight into the new imaging methodologies and into the pathophysiology of chronic ischemic heart disease. © 2013 Informa Healthcare...|$|R
40|$|AbstractOn account on {{nowadays}} {{trends in}} the field of finishing, hand polishing has to be replaced with superior process. An alternative is abrasive flow machining (AFM). In this paper, the influence of the process parameters and abrasive fluid <b>flow</b> on surface <b>integrity,</b> i. e. surface roughness and micro geometry, are investigated. The models correlating abrasive fluid flow and surface roughness are developed. To prove the efficiency, energy consumption analysis is performed comparing AFM and novel upgrade of it, i. e. AFM with movable rotatable mandrel. Results show that novel AFMmm is efficiently capable to remove WEDM (wire electric discharge machining) damaged surface, induce compressive residual stresses and produce polishing surface under dry conditions. Moreover, the novel upgrade of AFM process is besides finishing, capable also controlling the micro topography of the product...|$|R
