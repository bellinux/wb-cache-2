13|606|Public
40|$|This {{research}} aims {{to confirm}} student satisfication <b>guarantee</b> <b>model</b> {{that have been}} developed by previous researcher, Gremler and McCollogh. This student satisfication <b>guarantee</b> <b>model</b> has eight variable, there are: guarantee scope, guarantee components, guarantee credibility, overall guarantee attitude, learning outcomes, instructor evaluation, and overall course evaluation. Researcher is interested with the research that have been done by Gremler and McCollogh. They have to done this research in America. Through this research, the researcher want to examine student satisfication <b>guarantee</b> <b>model</b> that have been delevoped by previous researcher, in Indonesia especially in Faculty of Economy Atma Jaya University Yogyakarta. This research use Structural Equation Modeling method and helped by AMOS 4 software. The result of this research shows the exislence of positive influence among variable of guarantee scope, guarantee component toward overall guarantee attitude. Guarantee credibility has negative influence toward overall guarantee attitude. Overall guarantee attitude has positive influence toward learning outcomes and instructor evaluation. Learning outcomes and instructor evaluation has positive influence toward overall course evaluation and self evaluation has negative influence toward overall course evaluation. ...|$|E
40|$|A new <b>guarantee</b> <b>model</b> for {{accepting}} dynamically arriving sporadic tasks {{is presented in}} this paper. In this model, sporadic tasks have two costs associated with them. The costs represent the overheads a system will incur if the task is rejected and/or misses its deadline. The basic idea of the proposed model is to accept a task only if accepting the task lowers the expected cost due missed sporadic task deadlines. The key feature of the proposed model {{is that it can}} be viewed as a generalization of the traditional deterministic and the probabilistic guarantee models. By suitably setting the costs associated with the sporadic tasks, the proposed model can be made equivalent to either the deterministic or the probabilistic <b>guarantee</b> <b>model.</b> In general, however, the proposed model achieves a balance between the two types of guarantee depending on the exact costs associated with a sporadic task. A scheduling policy based on the proposed model is also presented in this paper. The policy is [...] ...|$|E
40|$|P 2 P网络借贷作为民间借贷阳光化和互联网金融中受人瞩目的一个细分行业，在我国正经历着高速发展。作为一项“舶来品”，为适应国内市场需求和制度环境，P 2 P网络借贷在运营模式上作出了许多本土化的创新。担保模式就是其中之一。担保法律关系的引入，对传统P 2 P网络借贷运行机制造成了某种程度的冲击。一方面，P 2 P平台信息中介机构法律性质的定位遭到动摇;另一方面，担保模式下系列经营和法律风险也逐渐显现，包括平台介入风险经营、与第三方担保机构合作的关联风险、资金池的非法集资风险等种种问题层出不穷。因此，业界有人提出P 2 P网络借贷应“去担保化”，让P 2 P平台回归纯信息中介。 然而，以我国现有社会信用环境和征信体 [...] . P 2 P network lending, as a {{subdivision}} industry of Internet banking, {{is experiencing a}} rapid development in our country. As an import, P 2 P network lending made some localization innovation in the operation mode, {{in order to meet}} the needs of domestic market and institutional environment. <b>Guarantee</b> <b>model</b> is one of them. The introduction of legal guarantee relationship caused some impact on the tradi [...] . 学位：法学硕士院系专业：法学院_民商法学学号： 1362013115018...|$|E
5000|$|The {{components}} of the <b>Guaranteed</b> Learning <b>Model</b> are the following: ...|$|R
40|$|The {{second issue}} of the Microenterprise Development Review offers two main articles: "Microfinance Guarantees: Is There Another Model?" and "Regulating Microfinance. " The first article {{discusses}} microfinance guarantees, where the lender's risk is mitigated through an external guarantor {{as well as other}} potential <b>guarantee</b> <b>models.</b> The second article examines the applicability of some central supervisory instruments for the regulation of microfinance. ...|$|R
30|$|In short, {{the direct}} method usually {{performs}} well in modelling, but will probably gain an uncontrollable random error when forecasting. On the contrary, the data-driven method can limit the forecasting random error, but {{makes it harder}} to construct a precise model for each subsequence. As a combination of the above two methods, the proposed DLC method can reduce the random forecasting error while <b>guaranteeing</b> <b>modelling</b> accuracy, providing improved forecasting results.|$|R
40|$|Estimates of country-level loan default {{distributions}} {{are developed}} {{and used in}} a loan <b>guarantee</b> <b>model</b> to value the contingent liability of USDA's General Sales Manager (GSM) export credit guarantee portfolio. The results quantify the relation-ship between increasing guarantee coverage and the resulting actuarial liability to the government. Optimal coverage levels and optimal country-level allocations are determined for given policy objectives and coverage totals. Findings reveal that the government's allocation of country guarantees is risk-inefficient; and guidance is provided for making risk-efficient allocations for any program size. Key words: contingent liability, export credit, GSM, loan guarantee valuation, risk-efficienc...|$|E
40|$|This {{study was}} {{commissioned}} by the European Parliament’s Policy Department for Citizens’ Rights and Constitutional Affairs {{at the request of}} the JURI Committee. It looks at the interrelation between the Consumer Sales and Guarantee Directive (CSD) and the Ecodesign Directive (EDD) with respect to guarantees and product expected lifetime. Through legal research and stakeholder surveys, it develops an EU lifespan <b>guarantee</b> <b>model,</b> which could be implemented by amendments to the proposal for an Online Sales Directive (OSD) and the EDD. It recommends extending the EDD to include the lifespan and extending the limitation period of the OSD. A commercial guarantee for the lifespan of a product is also suggested...|$|E
40|$|The {{actuality}} {{of middle}} and small private enterprises is that “slow birth, little growth, quick death and short life”. As {{viewed from the}} character of the financial management, they usually have the financial objective with short views and low effectiveness, which is represented from ten aspects. To improve the problems existing in the finical management of middle and small private enterprises, the following aspects including scientific and normative management thinking and management mode, the regulation and system of the financial management, the corporate governance structure and owner structure, the accounting system and professional team, the objective and <b>guarantee</b> <b>model</b> and operation mechanism of the financial management should be strengthened...|$|E
30|$|To display, the <b>guaranteed</b> QoS <b>model</b> appears to, {{presented}} in Sections 3 and 4, be valid for the WSNs with self-similar traffic flows.|$|R
40|$|PAC-Bayesian {{learning}} methods {{combine the}} informative priors of Bayesian methods with distribution-free PAC <b>guarantees.</b> Stochastic <b>model</b> selection predicts a class label by stochastically sampling a classifier {{according to a}} "posterior distribution" on classifiers. This paper gives a PAC-Bayesian performance <b>guarantee</b> for stochastic <b>model</b> selection that is superior to analogous <b>guarantees</b> for deterministic <b>model</b> selection. The <b>guarantee</b> is {{stated in terms of}} the training error of the stochastic classifier and the KL-divergence of the posterior from the prior. It is shown that the posterior optimizing the performance guarantee is a Gibbs distribution. Simpler posterior distributions are also derived that have nearly optimal performance guarantees...|$|R
30|$|Wireless sensor {{networks}} (WSNs) {{became one}} of the high technology domains during the last 10 years. Real-time applications for them make it necessary to provide the guaranteed quality of service (QoS). The main contributions of this article are a system skeleton and a <b>guaranteed</b> QoS <b>model</b> that are suitable for the WSNs. To do it, we develop a sensor node model based on virtual buffer sharing and present a two-layer scheduling model using the network calculus. With the system skeleton, we develop a <b>guaranteed</b> QoS <b>model,</b> such as the upper bounds on buffer queue length/delay/effective bandwidth, and single-hop/multi-hops delay/jitter/effective bandwidth. Numerical results show the system skeleton and the <b>guaranteed</b> QoS <b>model</b> are scalable for different types of flows, including the self-similar traffic flows, and the parameters of flow regulators and service curves of sensor nodes affect them. Our proposal leads to buffer dimensioning, guaranteed QoS support and control in the WSNs.|$|R
40|$|Abstract — In {{this paper}} we present results from an {{extensive}} measurement study of various hardware and (virtualized) software routers using several queueing strategies, i. e. First-Come-First-Served and Fair Queueing. In addition to well-known metrics such as packet forwarding performance, per packet processing time, and jitter, we apply network calculus models for performance analysis. This includes the Guaranteed Rate model for Integrated Services {{as well as}} the Packet Scale Rate <b>Guarantee</b> <b>model</b> for Differentiated Services. Using a measurement approach that provides a means to estimate rate and error term of a real node, we propose an interpretation of router performance based on these parameters taking packet queueing and scheduling into account. Such estimated parameters should be used to make the analysis of real networks more accurate. We underpin the applicability of this approach by comparing analytical results of concatenated routers to real world measurements. I...|$|E
40|$|This paper {{presents}} the results of experiments on probabilistic GLR (PGLR), a new probabilistic model proposed by (Inui et al., 1997). The model is formalized based on stack transition during parsing distinguishing it from the existing models proposed by Wright and Wrigley, and Briscoe and Carroll. Our model produces a remarkable improvement in syntactic parsing with probability. Associating probabilities directly to actions in an LR parsing table, and theoretically requiring only one probability for each action <b>guarantee</b> <b>model</b> trainability and potential applications to other related tasks. 1 Introduction Probabilistic techniques have been introduced to various kinds of natural language processing tasks, due to the increasing availability of text corpora. In syntactical parsing, probabilistic techniques are utilized to rank the potentially high numbers of parses generated for natural language (NL) applications. Several {{attempts have been made to}} prune meaningless parses and aid in th [...] ...|$|E
40|$|This {{article is}} focused on the topic of {{customer}} protection. The protection covers insolvency of travel agency and comes out from the Council Directive 90 / 314 /EEC. In the Czech Republic this Council directive is implemented into Czech law through the Act No. 159 / 1999 Coll. on Conducting Business in Some Areas of the Tourism Sector. Unfortunately, the act is considered to be not up to date therefore novelization is being prepared. The article describes insurance as the one and only customer protection in the Czech Republic. Simultaneously, there are set other possibilities of customer guarantee in case of travel agency bankrupt which are successfully used in other European countries. One part of the article is dedicated to detail analysis of this problem in Great Britain. The result of provided analyses and research – proposal of <b>guarantee</b> <b>model</b> through insurance section which would be a part of Association of Travel Agencies and Tour operators. The goal of the model is to clear away present weaknesses in this field...|$|E
40|$|We {{present a}} novel {{approach}} to structure learning for graphical models. By using nonparametric estimates to model clique densities in decomposable models, both discrete and continuous distributions can be handled in a unified framework. Also, consistency of the underlying probabilistic <b>model</b> is <b>guaranteed.</b> <b>Model</b> selection is based on predictive assessment, with efficient algorithms that allow fast greedy forward and backward selection within the class of decomposable models. We show the validity of this structure learning approach on toy data, and on two large sets of gene expression data...|$|R
40|$|International audienceIn this paper, we {{introduce}} new parametric generative driven auto-regressive (DAR) models. DAR models provide a non-linear and non-stationary spectral estimation of a signal, conditionally to another exogenous signal. We detail how inference {{can be done}} efficiently while <b>guaranteeing</b> <b>model</b> stability. We show how model comparison and hyper-parameter selection can be done using likelihood estimates. We also point out the limits of DAR models when the exogenous signal contains too high frequencies. Finally, we illustrate how DAR models can be applied on neuro-physiologic signals to characterize phase-amplitude coupling...|$|R
40|$|Abstract. We {{present a}} novel {{approach}} to structure learning for graphical models. By using nonparametric estimates to model clique densities in decomposable models, both discrete and continuous distributions can be handled in a unified framework. Also, consistency of the underlying probabilistic <b>model</b> is <b>guaranteed.</b> <b>Model</b> selection is based on predictive assessment, with efficient algorithms that allow fast greedy forward and backward selection within the class of decomposable models. We show the validity of this structure learning approach on toy data, and on two large sets of gene expression data...|$|R
30|$|Moreover, common {{challenges}} in sequential prediction theory are model over-fitting, and redundancy loss convergence <b>guarantee.</b> <b>Model</b> over-fitting {{refers to the}} case when a model is too complex, that renders it sensitive to small changes in observation statistics [19, 20, 23, 29]. Model complexity constraints {{the applicability of the}} prediction mode. The complexity of a specific class of predictors, i.e. class size and statistical regression affects the predictor convergence guarantee to the desired redundancy loss bound (see redundancy-capacity theorem [20, 23, 28, 31]). Plug-in approaches simplify predictor design complexity using assumptions about the observation generating mechanism to achieve optimal predictor design. For example, a set of finite kth-order Markov models are more practical for predictor design compared to the set of all arbitrary order Markov models. Moreover, mixture models are more complex but allow empirical measurements-based source estimation. An example would be Dirichlet mixture process which often used to generate mixture prior distributions, but tracing convergence bounds becomes increasingly difficult for non-Gaussian mixtures for example [20, 28, 40]. Convergence bounds are calculated only for limited Bayesian mixture class/prior distribution pairs (for example, uniform prior/Epanchinkov kernel) [107].|$|E
40|$|Point process {{generalized}} {{linear models}} (PP-GLMs) provide an important statistical framework for modeling spiking activity in single-neurons and neuronal networks. Stochastic stability is essential when sampling from these models, as done in computational neuroscience to analyze statistical properties of neuronal dynamics and in neuro-engineering to implement closed-loop applications. Here we show, however, that despite passing common goodness-of-fit tests, PP-GLMs estimated from data are often unstable, leading to divergent firing rates. The inclusion of absolute refractory periods {{is not a}} satisfactory solution since the activity then typically settles into unphysiological rates. To address these issues, we derive a framework for determining the existence and stability of fixed points of the expected conditional intensity function (CIF) for general PP-GLMs. Specifically, in nonlinear Hawkes PP-GLMs, the CIF is expressed {{as a function of}} the previous spike history and exogenous inputs. We use a mean-field quasi-renewal (QR) approximation that decomposes spike history effects into the contribution of the last spike and an average of the CIF over all spike histories prior to the last spike. Fixed points for stationary rates are derived as self-consistent solutions of integral equations. Bifurcation analysis and the number of fixed points predict that the original models can show stable, divergent, and metastable (fragile) dynamics. For fragile models, fluctuations of the single-neuron dynamics predict expected divergence times after which rates approach unphysiologically high values. This metric can be used to estimate the probability of rates to remain physiological for given time periods, e. g., for simulation purposes. We demonstrate the use of the stability framework using simulated single-neuron examples and neurophysiological recordings. Finally, we show how to adapt PP-GLM estimation procedures to <b>guarantee</b> <b>model</b> stability. Overall, our results provide a stability framework for data-driven PP-GLMs and shed new light on the stochastic dynamics of state-of-the-art statistical models of neuronal spiking activity...|$|E
40|$|Automated {{modeling}} techniques allow fast prototyping from measurement or simulation {{data and}} can facilitate many important application scenarios, for instance, shortening {{the time frame}} from subsystem design to system integration, calibrating models with higher-order effects, and providing protected models without revealing the intellectual properties of actual designs. Many existing techniques can generate nonlinear dynamical models that are stable when simulated alone. However, such generated models oftentimes result in unstable simulation when interconnected within a physical network. This is because energy-related system properties are not properly enforced, and the generated models erroneously produce numerical energy, which in turn causes instability of the entire physical network. Therefore, when modeling {{a system that is}} unable to generate energy, it is essential to enforce passivity in order to ensure stable system simulation. This thesis presents an algorithm that can automatically generate nonlinear passive dynamical models via convex optimization. Convex constraints are proposed to <b>guarantee</b> <b>model</b> passivity and incremental stability. The generated nonlinear models are suited to be interconnected within physical networks in order to enable the hierarchical modeling strategy. Practical examples include circuit networks and arterial networks. It is demonstrated that our generated models, when interconnected within a system, can be simulated in a numerically stable way. The system dynamics of the interconnected models can be faithfully reproduced for a range of operations and show an excellent agreement with a number of system metrics. In addition, it is also shown via these two applications that the proposed modeling technique is applicable to multiple physical domains. by Yu-Chung Hsiao. Thesis: Ph. D., Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2015. Cataloged from PDF version of thesis. Includes bibliographical references (pages 107 - 113) ...|$|E
40|$|In this paper, we {{introduce}} new parametric generative driven auto-regressive (DAR) models. DAR models provide a non-linear and non-stationary spectral estimation of a signal, conditionally to another exogenous signal. We detail how inference {{can be done}} efficiently while <b>guaranteeing</b> <b>model</b> stability. We show how model comparison and hyper-parameter selection can be done using likelihood estimates. We also point out the limits of DAR models when the exogenous signal contains too high frequencies. Finally, we illustrate how DAR models can be applied on neuro-physiologic signals to characterize phase-amplitude coupling...|$|R
40|$|Wireless sensor {{networks}} (WSNs) {{became one}} of the high technology domains during the last ten years. Real-time applications for them make it necessary to provide the guaranteed Quality of Service (QoS). The main contributions of this paper are a system skeleton and a <b>guaranteed</b> QoS <b>model</b> that are suitable for the WSNs. To do it, we develop a sensor node model based on virtual buffer sharing and present a two-layer scheduling model using the network calculus. With the system skeleton, we develop a <b>guaranteed</b> QoS <b>model,</b> such as the upper bounds on buffer queue length/delay/effective bandwidth, and single-hop/ multi-hops delay/jitter/effective bandwidth. Numerical results show the system skeleton and the <b>guaranteed</b> QoS <b>model</b> are scalable for different types of flows, including the self-similar traffic flows, and the parameters of flow regulators and service curves of sensor nodes affect them. Our proposal leads to buffer dimensioning, guaranteed QoS support and control in the WSNs. Comment: 14 pages, 10 figure...|$|R
30|$|The rest of {{the article}} is {{organized}} as follows. Section 2 devotes to the background knowledge of the network calculus. Section 3 discusses a system skeleton, including a generalized scenario of the WSNs, a sensor node model, the flow source <b>model,</b> the <b>guaranteed</b> QoS service and the scheduling model of a sensor node. Section 4 draws the upper bounds on the <b>guaranteed</b> QoS <b>model.</b> Section 5 shows the numerical results and compares one another to demonstrate the availability and {{the merits of the}} proposed skeleton, the <b>guaranteed</b> QoS <b>model</b> and our approach through same examples. Finally, Section 6 contains the summary of the results, some inferring remarks and future works.|$|R
40|$|Whilst much {{research}} {{progress has been}} achieved towards the development of autonomic software engineering tools and techniques including: policy-based management, modelbased development, service-oriented architecture and model driven architecture. They have often focused on and started from chosen object-oriented models of required software behaviour, rather than domain model including user intentions and/or software goals. Such an approach is often reported to lead to "misalignment" between business process layer and their associated computational enabling systems. This is specifically noticeable in adaptive and evolving business systems and/or processes settings. To address this long-standing problem research has over the years investigated many avenues {{to close the gap}} between business process modelling and the generation of enactment (computation) layer, which is responsive to business changes. Within this problem domain, this research sets out to study the extension of the Model Driven Development (MOD) paradigm to business/domain model, that is, how to raise the abstraction level of model-driven software development to the domain level and provide model synchronisation to trace and analyse the impact of a given model change. The main contribution of this research is the development of a MOD-based design method for autonomic systems referred to as AutoTaSC. The latter consists of a series of related models, where each of which represents the system under development at a given stage. The first and highest level model represents the abstract model referred to as the Platform Independent Model (PIM). The next model encapsulates the PIM model for the autonomic system where the autonomic capabilities and required components (such as monitor, sensor, actuator, analyser, policy, etc.) are added via some appropriate transformation rules. Targeting a specific technology involves adding, also via transformation rules, specific information related to that platform from which the Platform Specific Model (PSM) for the autonomic system is extracted. In the last stage, code can be generated for the specific platform or technology targeted in the previous stage, web services for instance. In addition, the AutoTaSC method provides a situated model synchronisation mechanism, which is designed following the autonomic systems principles. For instance, to <b>guarantee</b> <b>model</b> synchronisation each model from each AutoTaSC stage has an associated policy-based feedback control loop, which regulates its reaction to detected model change. Thus, AutaTase method model transformation approach to drive model query, view and synchronisation. The Auto'Iast? method was evaluated using a number of benchmark case-studies to test this research hypothesis including the effectiveness and generality of AutaTaSe design method...|$|E
40|$|In this paper, {{we propose}} an {{algorithm}} for {{the generation of}} <b>guaranteed</b> passive state-space <b>models</b> of one-port immittances from finite frequency response samples. Differently from conventional approaches, {{which are based on}} a two-step process that first fits a rational function to the samples, and only in a second stage checks and enforces passivity via perturbation, our approach provides directly a <b>guaranteed</b> passive <b>model.</b> This is achieved by computing a stable rational approximation of a spectral factor associated to the immittance function under modeling. Several examples demonstrate the feasibility of the proposed techniqu...|$|R
40|$|The task {{of control}} of {{unmanned}} helicopters is rather complicated {{in the presence of}} parametric uncertainties and measurement noises. This paper presents an adaptive model feedback control algorithm for an unmanned helicopter stability augmentation system. The proposed algorithm can achieve a <b>guaranteed</b> <b>model</b> reference tracking performance and speed up the convergence rates of adjustable parameters, even when the plant parameters vary rapidly. Moreover, the model feedback strategy in the algorithm further contributes to the improvement in the control quality of the stability augmentation system in the case of low signal to noise ratios, mainly because the model feedback path is noise free. The effectiveness and superiority of the proposed algorithm are demonstrated through a series of tests...|$|R
40|$|Abstract. We de ne the Tight Semantics (TS), a new {{semantics}} for all NLPs {{complying with}} the requirements of: 2 -valued semantics; preserving the <b>models</b> of SM; <b>guarantee</b> of <b>model</b> existence, even in face of Odd Loops Over Negation (OLONs) or in nite chains; relevance; cumulativity; and compliance with the Well-Founded Model. When complete models are unnecessary, and top-down querying (à la Prolog) is desired, TS provides the 2 -valued option that <b>guarantees</b> <b>model</b> existence, {{as a result of}} its relevance property. Top-down querying with abduction by need is rendered available too by TS. The user need not pay the price of computing whole models, nor that of generating all possible abductions, only to lter irrelevant ones subsequently. A TS model of a NLP P is any minimal model (MM) M of P that further satis es P the program remainder of P in that each loop in P has a MM contained in M, whilst respecting the constraints imposed by the MMs of the other loops so-constrained too. The applications a orded by TS are all those of Stable Models, which it generalizes, plus those permitting to solve OLONs for model existence, plus those employing OLONs for productively obtaining problem solutions, not just ltering them (like Integrity Constraints). 1...|$|R
30|$|In this paper, a {{data-driven}} linear clustering (DLC) {{method is}} proposed {{to solve the}} long-term system load forecasting problem caused by load fluctuation in some developed cities. A large substation load dataset with annual interval is utilized and firstly preprocessed by the proposed linear clustering method to prepare for modelling. Then optimal autoregressive integrated moving average (ARIMA) models are constructed for the sum series of each obtained cluster to forecast their respective future load. Finally, the system load forecasting result is obtained by summing up all the ARIMA forecasts. From error analysis and application results, it is both theoretically and practically proved that the proposed DLC method can reduce random forecasting errors while <b>guaranteeing</b> <b>modelling</b> accuracy, so that a more stable and precise system load forecasting result can be obtained.|$|R
40|$|Delivery {{reliability}} {{has emerged}} as a key competitive factor in a variety of service and manufacturing industries. Thus, many firms are adopting the use of delivery-time guarantees as part of their market positioning strategy. This research generalizes existing blanket delivery-time <b>guarantee</b> <b>models</b> on several fronts [...] by drawing on concepts from other fields and by relaxing simplifying assumptions [...] to provide a comprehensive and practical model. Some analytic results are provided, and numeric experimentation is conducted to provide further insight into the problem. The effects of service improvements, process improvements, and system congestion are analyzed. The results indicate that pricing policies are less critical than previously thought when the payment made for late delivery is included as part of the delivery-time guarantee policy. Distribution Pricing Delivery guarantees Time-based competition...|$|R
40|$|We {{define the}} Tight Semantics (TS), a new {{semantics}} for all NLPs {{complying with the}} requirements of: 2 -valued semantics; preserving the <b>models</b> of SM; <b>guarantee</b> of <b>model</b> existence (even in face of odd loops over negation or infinite chains); relevance; cumulativity; and compliance with the Well-Founded Model. We also extend TS to adumbrate ELPs and Disjunctive LPs, though a full account of these is left to other papers. When complete models are unnecessary, and top-down querying (à la Prolog) is desired, TS provides the 2 -valued option that <b>guarantees</b> <b>model</b> existence, {{as a result of}} its relevance property. Top-down querying with abduction by need is rendered available too by TS. The user need not pay the price of computing whole models, nor of generation all possible abductions, only to filter irrelevant ones subsequently. In a nutshell, a TS model of a NLP P is any minimal model M of P that further satisfies bP —the program remainder of P —in that each loop in b P has a minimal model contained in M, whilst respecting the constraints imposed by the minimal models of the other loops so-constrained too. The applications afforded by TS are all those of Stable Models, which it generalizes, plus those permitting to solve OLONs for model existence, plus those employing OLONs for productively obtaining problem solutions, not just filtering them (like ICs) ...|$|R
3000|$|... the {{application}} of the control law (3.7) to the SEIR <b>model</b> <b>guarantees</b> that the epidemics is asymptotically eradicated from the host population while [...]...|$|R
5000|$|Some Coolpix cameras {{which are}} not advertised as {{supporting}} a raw file format can produce usable raw files if switched to a maintenance mode. [...] Note that switching to this mode can invalidate a camera's <b>guarantee.</b> Nikon <b>models</b> with this capability: E700, E800, E880, E900, E950, E990, E995, E2100, E2500, E3700, E4300, E4500.|$|R
40|$|Summary: Often {{competing}} hypotheses for biochemical networks {{exist in}} the form of different mathematical models with unknown parameters. Considering available experimental data, it is then desired to reject model hypotheses that are inconsistent with the data, or to estimate the unknown parameters. However, these tasks are complicated because experimental data are typically sparse, uncertain, and are frequently only available in form of qualitative if–then observations. ADMIT (Analysis, Design and Model Invalidation Toolbox) is a MatLabTM-based tool for <b>guaranteed</b> <b>model</b> invalidation, state and parameter estimation. The toolbox allows the integration of quantitative measurement data, a priori knowledge of parameters and states, and qualitative information on the dynamic or steady-state behavior. A constraint satisfaction problem is automatically generated and algorithms are implemented for solving the desired estimation, invalidation or analysis tasks. The implemented methods built on convex relaxation and optimization and therefore provide guaranteed estimation results and certificates for invalidity...|$|R
40|$|Abstract — The {{introduction}} {{of quality of}} service (QoS) architectures to the Internet invites to apply new models {{to the analysis of}} network nodes. These models, which include the <b>Guaranteed</b> Rate (GR) <b>model</b> for the Integrated Services (IntServ) architecture and the Packet Scale Rate <b>Guarantee</b> (PSRG) <b>model</b> for the Differentiated Services (DiffServ) architecture, specify the service of a network router using bounds on service rate and delay. In this paper, we propose a measurement approach to estimate parameters for these models, which is of particular importance when these parameters cannot be obtained or verified through theoretical analysis. The idea of the proposed approach is to conduct measurement externally on the router and to estimate the desired parameters through burst period and backlog period measurements. I...|$|R
40|$|Abstract. The Gelfond-Lifschitz {{operator}} fixed-point requirement by Stable Models induces asymmetry {{in dealing}} with Even Loops and Odd Loops Over Negation. We introduce a 2 -valued semantics for Normal Logic Programs — the Inductive Tight semantics (ITS) — that generalizes SM semantics by dealing uniformly with Even and Odd loops. ITS conservatively extends the SM semantics (all SMs are Tight models), enjoys relevance and cumulativity, <b>guarantees</b> <b>model</b> existence, and respects the Well-Founded Model. The IT semantics relies on Layering, a generalization of Stratification, and is inductively defined on such layering: each model for a given layer must comply with some model for the whole set of layers below. Enjoying Relevance, the IT semantics is suitable top-down querying (à la Prolog) when complete models are unnecessary. The applications afforded by ITS are all those of Stable Models, which it generalizes, plus those employing OLONs for productively obtaining problem solutions, not just filtering them (like Integrity Constraints) ...|$|R
