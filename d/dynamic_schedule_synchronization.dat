0|2414|Public
40|$|High-level {{programming}} {{languages and}} exotic architectures {{have often been}} devel-oped together, because the languages seem to require complex mechanisms realized by specialized hardware. The implicitly parallel language Id and data¯ow architectures are a prime example. The language allows an elegant formulation of a broad class of problems while exposing substantial parallelism, however, its non-strict semantics require ®ne-grain <b>dynamic</b> <b>scheduling</b> and <b>synchronization</b> making an ef®cient implementation on conven-tional parallel machines challenging. This thesis presents novel compilation techniques for implicitly parallel languages, focusing on techniques addressing <b>dynamic</b> <b>scheduling.</b> It shows {{that it is possible}} to implement the lenient functional language Id ef®ciently by partitioning the program into regions that can be scheduled statically as sequential threads, and realizing the remaining <b>dynamic</b> <b>scheduling</b> through compiler-controlled multithreading. Partitioning the pro-gram into sequential threads requires substantial compiler analysis because the evaluation order is not speci®ed by the programmer...|$|R
40|$|Lenient languages, such as Id 90, {{have been}} touted {{as among the}} best {{functional}} languages for massively parallel machines [AHN 88]. Lenient evaluation combines non-strict semantics with eager evaluation [Tra 9 1]. Non-strictness gives these languages more expressive power than strict semantics, while eager evaluation ensures the highest degree of parallelism. Unfortunately, non-strictness incurs a large overhead, as it requires <b>dynamic</b> <b>scheduling</b> and <b>synchronization.</b> As a result, many powerful program analysis techniques {{have been developed to}} statically determine when non-strictness is not required [CPJ 85, Tra 91, Sch 94]. This paper studies a large set of lenient programs and quantifies the degree of non-strictness they require. We identify several forms of non-strictness, including functional, conditional, and data structure non-strictness. Surprisingly, most Id 90 programs require neither functional nor conditional non-strictness. Many benchmark programs, however, make use of a limited form of data structure non-strictness. The paper refutes the myth that lenient programs require extensive non-strictness...|$|R
40|$|Abstract. Aircraft <b>dynamic</b> <b>scheduling</b> {{affects the}} {{operation}} efficiency and flight benefits. Airlines make a rational organization of surplus aircraft {{to generate the}} best scheduling solution. The present research constructs an aircraft <b>dynamic</b> <b>scheduling</b> network diagram, define the surplus aircrafts’ available routings and create aircraft <b>dynamic</b> <b>scheduling</b> mathematical model. Through a mixture column generation algorithm with heuristic methods, the research find the routings in the optimal aircraft <b>dynamic</b> <b>scheduling</b> program. The given instance verifies the model and algorithm generate reasonable and practical solution for airlines in the effective time...|$|R
50|$|DirSync Pro has a {{schedule}} engine with many options to <b>schedule</b> <b>synchronization</b> tasks, e.g. every minute, hourly, daily, weekly, and monthly. DirSync Pro has many logging facilities to create detailed logs per job, per jobset, or globally.|$|R
40|$|In this paper, by {{considering}} Job Shop <b>dynamic</b> <b>scheduling</b> problem in fuzzy environments, the description and modeling {{of the manufacturing}} systems is presented A fuzzy <b>dynamic</b> <b>scheduling</b> strategy, in which compartmentalizing {{the period of time}} for rescheduling is based on computing triangular fuzzy number denoting the workpiece processing time, is proposed For being solved, the Job Shop fuzzy <b>dynamic</b> <b>scheduling</b> problem is decomposed into a series of static fuzzy sub-scheduling problems which will not be fully executed by means of the strategy of the temporal decomposition. An improved Giffler&Thompson(G&T) algorithm is proposed in order to solve the model of the above problem. The simulation results show that the model of the Job Shop fuzzy <b>dynamic</b> <b>scheduling</b> is proper, the improver G&T algorithm is effective and the strategy for <b>dynamic</b> <b>scheduling</b> possesses robustness. IEEE Hong Kong Computat Intelligence Chapter, Guangdong Univ Technol, Xidian Univ, Hong Kong Baptist Univ, Jian Uni...|$|R
40|$|Techniques for {{scheduling}} parallel tasks {{on to the}} processors of a {{multiprocessor architecture}} must tradeoffthree interrelated factors: 1) <b>scheduling</b> and <b>synchronization</b> costs, 2) load balancing, and 3) memory locality. Current scheduling techniques typically consider only one or twoofthese three factors at a time. We propose a novelSelfAdjusting Scheduling (SAS) algorithm that addresses all three factors simultaneously. This algorithm dedicates a single processor to execute an on-line branch-and-bound algorithm to search for partial schedules concurrent with the execution of tasks previously assigned to the remaining processors. This overlapped scheduling and execution, along with self-adjustment of duration of partial scheduling periods reduces <b>scheduling</b> and <b>synchronization</b> costs significantly. Tosatisfy the load-balancing and locality management, SAS introduces a unified cost model that accounts for both of these factors simultaneously. Wecompare the simulated performance of SAS with the Affinity Scheduling algorithm (AFS). The results of our experiments demonstrate that the potential loss of performance caused by dedicating a processor to scheduling is outweighed by the higher performance produced by SAS'sdynamically adjusted schedules, eveninsystems with {{a small number of}} processors. SAS is a general on-line optimization technique that can be applied to a variety of <b>dynamic</b> <b>scheduling</b> problems...|$|R
40|$|Abstract. Job-shop <b>dynamic</b> <b>scheduling</b> is an {{important}} subject {{in the fields of}} production management and combinatorial optimization. It is usually hard to achieve the optimal solution with classical methods due to the high computational complexity of the problem. A solution of job-shop scheduling problem based on multi-agent is presented for the comparability between the <b>dynamic</b> <b>scheduling</b> problem of job-shop production and the TSP problem. The <b>dynamic</b> <b>scheduling</b> of job-shop production is designed according to the pattern of TSP problem which can be applied with ACO. By the application case, the ACO is the new method to solve the <b>dynamic</b> <b>scheduling</b> of job-shop production. Introductions The problem of <b>dynamic</b> <b>scheduling</b> of job-shop production is the optimal problem which has high dimension, non-protruding, discrete and nonlinear, also it is virtually the optimal decision-making problem on many phases, there are different combination modes for the set equipment during each period of time, {{it is very hard to}} get the optimization because most of the problems are NP- hard...|$|R
40|$|Recently, {{high-performance}} computer architecture {{has focused on}} <b>dynamic</b> <b>scheduling</b> techniques to issue and ex-ecute multiple operations concurrently. These designs are complex and have frequently shown disappointing perfor-mance. A complementary approach {{is the use of}} static scheduling techniques to exploit the same parallelism. In this paper we describe some of the tradeoffs between the use of static and <b>dynamic</b> <b>scheduling</b> techniques and show that with appropriate scheduling, low-complexity designs using only static scheduling have significant advantages over high-complexity designs using <b>dynamic</b> <b>scheduling</b> in real systems. 1...|$|R
30|$|Multitasking —Multitasking with static or <b>dynamic</b> <b>scheduling.</b>|$|R
40|$|Dynamic {{rescheduling}} {{of workshop}} production management, with the feature of combinatorial computation complexity, {{is an important}} and difficult research area, and be of significant importance for the <b>dynamic</b> <b>scheduling</b> problem. An improved Contract Net Protocol (CNP) with the global two-way, Multi-Agent System (MAS) based communication model, which incorporated the local autonomy of working mutually in consultation by negotiation, is presented in this paper.  Furthermore, the simulation results in <b>dynamic</b> <b>scheduling</b> accompanying with its perturbation show that the proposed model and the algorithm are effective to the <b>dynamic</b> <b>scheduling</b> problem in manufacturing system...|$|R
40|$|Traditional logic {{programming}} languages, such as Prolog, use a fixed left-to-right atom scheduling rule. Recent {{logic programming}} languages, however, usually provide more flexible scheduling in which computation generally proceeds leftto- right but {{in which some}} calis are dynamically "delayed" until their arguments are sufRciently instantiated to allow the cali to run efficiently. Such <b>dynamic</b> <b>scheduling</b> has a significant cost. We give a framework for the global analysis of logic programming languages with <b>dynamic</b> <b>scheduling</b> and show that program analysis based on this framework supports optimizations which remove much of the overhead of <b>dynamic</b> <b>scheduling...</b>|$|R
40|$|The {{present study}} {{considers}} a when-to-schedule policy in online production scheduling, {{which can be}} applicable to the timing of rescheduling under a dynamic environment with unforeseeable events. This paper extends our previous work and proposes a new hybrid policy for rescheduling introducing rescheduling driven by a cumulative delay and a forced rescheduling to maintain {{the quality of a}} current schedule. We examine, through some computational experiments, some properties of the proposed policy by applying it to single-machine <b>dynamic</b> <b>scheduling</b> problems with disturbance where we minimize total tardiness as well as total frequency of rescheduling. It is also demonstrated that the proposed policy can outperform a typical periodic rescheduling policy with less frequency of rescheduling under parallel machine <b>dynamic</b> <b>scheduling.</b> Keywords: when-to-schedule policy, cumulative task delay, scheduling frequency, single machine <b>dynamic</b> <b>scheduling,</b> parallel machine <b>dynamic</b> <b>scheduling...</b>|$|R
40|$|Abstract: The Quadratic Semi-Assignment Problem (QSAP) models a large {{variety of}} {{practical}} applications. In the present note {{we will consider}} a particular class of QSAP that can be solved by determining the maximum cost flow on a network. This class of problems arises in <b>schedule</b> <b>synchronization</b> and in transportation...|$|R
30|$|For <b>dynamic</b> <b>scheduling</b> problems, jobs may arrive {{randomly}} {{over time}} and their information is not available before their arrivals. Dispatching rules {{is the most popular}} approach for <b>dynamic</b> <b>scheduling</b> problem. In most cases, dispatching rules are represented by priorities functions that assign priorities to jobs. Then the jobs with the highest priority will be processed first. Many rules have been developed by practitioners and researchers to cope {{with a wide range of}} production environments. Three attractive characteristics of the dispatching rules are their efficiency, reactiveness, and interpretability. GP plays a major role in <b>dynamic</b> <b>scheduling,</b> which is to be described below.|$|R
40|$|The {{changing}} {{trends of}} high-performance computing from expensive massively parallel machines to medium or small scale general-purpose parallel machines and clusters of workstations {{as well as}} combinations of distributed heterogeneous machines further emphasize the need for developing novel techniques {{for the management of}} computing resources through highly efficient dynamics task allocation, scheduling and load balancing algorithms. This paper presents <b>dynamic</b> <b>scheduling</b> techniques and includes works reporting a wide spectrum of related research. The distinctive feature of <b>dynamic</b> <b>scheduling</b> for parallel and distributed systems is that it takes the notion of time into consideration. In other words, <b>dynamic</b> <b>scheduling</b> is management of computing resources according to their time-dependent states...|$|R
40|$|Abstract—This paper {{analyzes}} {{the impact of}} <b>dynamic</b> task <b>scheduling,</b> processing element allocation and data transfer management on system performance of heterogeneous MPSoCs. Therefore, all parts of a runtime scheduling unit are analyzed. Bottlenecks are identified and their complexity evaluated. Furthermore, traced information is processed with two newly introduced tools. The first one generates an annotated SDF 3 file. The second one creates a static schedule which applies the same scheduling and allocation decision as the dynamic scheduler. The execution of the static schedule reduces the burden of task management to a minimum. The resulting static execution is compared with {{the execution of the}} <b>dynamic</b> <b>schedule.</b> Hence, runtime overhead of <b>dynamic</b> <b>scheduling</b> is unveiled. Keywords-heterogeneous MPSoC, task scheduling, <b>scheduling</b> analysis tool, <b>dynamic</b> <b>scheduling</b> overhead, runtime scheduling complexity analysis I...|$|R
40|$|Imaging {{satellites}} {{are traditionally}} scheduled in a static fashion; namely the schedule is created off-line and then uploaded {{to one or}} more imaging satellites to be executed as an immutable sequence of commands. In this paper, we make the case for <b>dynamic</b> <b>scheduling</b> of imaging satellites. <b>Dynamic</b> <b>schedules</b> will allow satellite systems to take advantage of information gathered during the execution of the schedule and react to changes in the environment, desired tasking, and the availability of resources. We develop the remote sensing scheduling problem and discuss contingency conditions under which the satellite <b>scheduling</b> problem becomes <b>dynamic.</b> We then review existing work on contingency scheduling and conditional scheduling and propose extensions to address the <b>dynamic</b> satellite <b>scheduling</b> problem. <b>Dynamic</b> <b>schedules</b> will yield improved mission schedules and reduced mission costs. 1...|$|R
40|$|Abstract In most {{real-world}} environments, scheduling is {{an ongoing}} reactive process where {{the presence of a}} variety of unexpected disruptions is usually inevitable, and continually forces reconsideration and revision of pre-established schedules. Many of the approaches developed {{to solve the problem of}} static scheduling are often impractical in real-world environments, and the near-optimal schedules with respect to the estimated data may become obsolete when they are released to the shop floor. This paper outlines the limitations of the static approaches to scheduling in the presence of realtime information and presents a number of issues that have come up in recent years on <b>dynamic</b> <b>scheduling.</b> The paper defines the problem of <b>dynamic</b> <b>scheduling</b> and provides a review of the state-of-the-art of currently developing research on <b>dynamic</b> <b>scheduling.</b> The principles of several <b>dynamic</b> <b>scheduling</b> techniques, namely, heuristics, meta-heuristics, multi-agent systems, and other artificial intelligence techniques are described in detail, followed by a discussion and comparison of their potential...|$|R
40|$|<b>Dynamic</b> <b>scheduling</b> {{algorithms}} {{are gaining}} {{more and more}} special attention for their satisfying robustness when confronted with unexpected events {{as well as their}} considerably high performance in scheduling. An organization structure for intelligent job shop scheduling based on MAS (Multiple Agents System) is put forward to achieve effective and efficient production. A hybrid multilayer agent structure is put forward to facilitate constructing various agents. Consequently, all resources in a manufacturing system are reorganized into an agile manufacturing network of agents of autonomous and cooperative characteristics. Regarding wasps as a specific kind of agents, wasp colony algorithms are used to solve job shop <b>dynamic</b> <b>scheduling</b> problem. Based on the principle of the wasp colony algorithm, two different algorithms, namely the routing wasp algorithm and the scheduling wasp algorithm, are combined to solve the job shop <b>dynamic</b> <b>scheduling</b> problem. The algorithms are modified to better adapt to job shop <b>dynamic</b> <b>scheduling</b> environment. The algorithms are developed based on Eclipse 3. 2 and J 2 SE 6. 0. Simulation experiments are accomplished and experimental data are analyzed. The results show that the principle of the algorithms is simple, their computational quantity is small, and they can be applied to multi-batch <b>dynamic</b> <b>scheduling</b> with unpredictable entry time due to their favorable potential. </p...|$|R
40|$|Abstract – This paper {{concerns}} throughput-constrained parallel {{execution of}} synchronous data flow graphs. This paper assumes static mapping and <b>dynamic</b> <b>scheduling</b> of nodes, which has several benefits over static scheduling approaches. We determine the buffer size of all arcs {{to minimize the}} total buffer size while satisfying a throughput constraint. <b>Dynamic</b> <b>scheduling</b> is able to achieve the similar throughput performance as the static scheduling does by unfolding the given SDF graph. A key issue of <b>dynamic</b> <b>scheduling</b> is how to assign the priority to each node invocation, which is also discussed in this paper. Since the problem is NP-hard, we present a heuristic based on a genetic algorithm. The experimental results confirm {{the viability of the}} proposed technique. I...|$|R
40|$|Recently, Brownian {{networks}} {{have emerged as}} an effective stochastic model to approximate multiclass queueing networks with <b>dynamic</b> <b>scheduling</b> capability, under conditions of balanced heavy loading. This paper is a tutorial introduction to <b>dynamic</b> <b>scheduling</b> in manufacturing systems using Brownian networks. The article starts with motivational examples. It then provides a review of relevant weak convergence concepts, followed by {{a description of the}} limiting behaviour of queueing systems under heavy traffic. The Brownian approximation procedure is discussed in detail and generic case studies are provided to illustrate the procedure and demonstrate its effectiveness. This paper places emphasis only on the results and aspires to provide the reader with an up-to-date understanding of <b>dynamic</b> <b>scheduling</b> based on Brownian approximations...|$|R
40|$|Abstract—Dynamic {{scheduling}} algorithms {{are gaining}} {{more and more}} special attention for their satisfying robustness when confronted with unexpected events {{as well as their}} considerably high performance in scheduling. An organization structure for intelligent job shop scheduling based on MAS (Multiple Agents System) is put forward to achieve effective and efficient production. A hybrid multi-layer agent structure is put forward to facilitate constructing various agents. Consequently, all resources in a manufacturing system are reorganized into an agile manufacturing network of agents of autonomous and cooperative characteristics. Regarding wasps as a specific kind of agents, wasp colony algorithms are used to solve job shop <b>dynamic</b> <b>scheduling</b> problem. Based on the principle of the wasp colony algorithm, two different algorithms, namely the routing wasp algorithm and the scheduling wasp algorithm, are combined to solve the job shop <b>dynamic</b> <b>scheduling</b> problem. The algorithms are modified to better adapt to job shop <b>dynamic</b> <b>scheduling</b> environment. The algorithms are developed based on Eclipse 3. 2 and J 2 SE 6. 0. Simulation experiments are accomplished and experimental data are analyzed. The results show that the principle of the algorithms is simple, their computational quantity is small, and they can be applied to multi-batch <b>dynamic</b> <b>scheduling</b> with unpredictable entry time due to their favorable potential. Index Terms—job shop <b>scheduling,</b> <b>dynamic</b> <b>scheduling,</b> MAS, wasp colony algorithm, Eclipse, J 2 SE I...|$|R
50|$|Many modern {{processors}} implement <b>dynamic</b> <b>scheduling</b> {{schemes that}} are derivative of Tomasulo’s original algorithm, including popular Intel-64 chips.|$|R
40|$|There {{are more}} {{problems}} of network data transmission in multi-loop NCS than in single loop NCS. It maybe lead {{to that one}} or more of closed-loop systems become unstable in multi-loop NCS. In order to solve this problem, a novel algorithm of fuzzy <b>dynamic</b> <b>scheduling</b> for multi-loop NCS is put forward in this paper. Firstly, the requirement of the sampling period of NCS is discussed. The necessity of <b>dynamic</b> <b>scheduling</b> for multi-loop NCS is analyzed. And then, the algorithm of fuzzy <b>dynamic</b> <b>scheduling</b> for multi-loop NCS is proposed. The idea is described form three parts. The principle of fuzzy <b>dynamic</b> <b>scheduling</b> is analyzed. The fuzzy controller is designed. The fuzzy dynamic scheduler is constructed. Finally, the simulation model of a multi-loop NCS with fuzzy dynamic scheduler is set up using TrueTime software. The relevant analysis of simulation is given. The result of study can prove that the performance of each closed control loop based on the same network platform is improved by adding fuzzy dynamic scheduler in the multi-loop NCS...|$|R
40|$|Tracking and Data Relay Satellite System (TDRSS) is a space-based telemetry, tracking, {{and command}} system, which {{represents}} a research {{field of the}} international communication. The issue of the <b>dynamic</b> relay satellite <b>scheduling,</b> which focuses on assigning time resource to user tasks, {{has been an important}} concern in the TDRSS system. In this paper, the focus of study is on the <b>dynamic</b> relay satellite <b>scheduling,</b> whose detailed process consists of two steps: the initial relay satellite scheduling and the selection of <b>dynamic</b> <b>scheduling</b> schemes. To solve the <b>dynamic</b> <b>scheduling</b> problem, a new scheduling algorithm ABC-TOPSIS is proposed, which combines artificial bee colony (ABC) and technique for order preference by similarity to ideal solution (TOPSIS). The artificial bee colony algorithm is performed to solve the initial relay satellite scheduling. In addition, the technique for order preference by similarity to ideal solution is adopted for the selection of <b>dynamic</b> <b>scheduling</b> schemes. Plenty of simulation results are presented. The simulation results demonstrate that the proposed method provides better performance in solving the <b>dynamic</b> relay satellite <b>scheduling</b> problem in the TDRSS system...|$|R
40|$|The {{problem of}} {{scheduling}} {{is concerned with}} searching for optimal (or near-optimal) schedules subject {{to a number of}} constraints. A variety of approaches have been developed {{to solve the problem of}} scheduling. However, many of these approaches are often impractical in dynamic real-world environments where there are complex constraints and a variety of unexpected disruptions. In most real-world environments, scheduling is an ongoing reactive process where the presence of real-time information continually forces reconsideration and revision of pre-established schedules. Scheduling research has largely ignored this problem, focusing instead on optimisation of static schedules. This paper outlines the limitations of static approaches to scheduling in the presence of real-time information and presents a number of issues that have come up in recent years on <b>dynamic</b> <b>scheduling.</b> The paper defines the problem of <b>dynamic</b> <b>scheduling</b> and provides a review of the state of the art of currently developing research on <b>dynamic</b> <b>scheduling.</b> The principles of several <b>dynamic</b> <b>scheduling</b> techniques, namely, dispatching rules, heuristics, meta-heuristics, artificial intelligence techniques, and multi-agent systems are described in detail, followed by a discussion and comparison of their potential...|$|R
40|$|The NERC Glossary of Terms [i] {{defines a}} Dynamic Transfer as the {{provision}} of the real-time monitoring, telemetering, computer software, hardware, communications, engineering, energy accounting (including inadvertent interchange), and administration required to electronically move all or {{a portion of the}} real energy services associated with a generator out of one Balancing Authority (BA) Area into another. Dynamic Transfers includes both <b>Dynamic</b> <b>Schedules</b> and Pseudo Ties, which are further defined below. The NERC Glossary of Terms [i] defines a <b>Dynamic</b> Interchange <b>Schedule</b> or <b>Dynamic</b> <b>Schedule</b> as a telemetered reading or value that is updated in real-time and used as a schedule in the Area Control Error (“ACE”) equation and the integrated value of which is treated as a schedule for interchange accounting purposes. <b>Dynamic</b> Interchange <b>Schedules</b> or <b>Dynamic</b> <b>Schedules</b> are commonly used for scheduling jointly owned generation to or from another Balancing Authority Area. The NERC Glossary of Terms [i] defines a Pseudo Tie as a telemetered reading or value that is updated in real-time and used as a “virtual ” tie line flow in the AGC/AC...|$|R
40|$|Focused on the <b>dynamic</b> <b>scheduling</b> {{problem for}} earth-observing {{satellites}} (EOS), an integer programming model is constructed after analyzing the main constraints. The rolling horizon (RH) strategy is proposed {{according to the}} independent arriving time and deadline of the imaging tasks. This strategy is designed with a mixed triggering mode composed of periodical triggering and event triggering, and the scheduling horizon is decomposed {{into a series of}} static scheduling intervals. By optimizing the scheduling schemes in each interval, the <b>dynamic</b> <b>scheduling</b> of EOS is realized. We also propose three <b>dynamic</b> <b>scheduling</b> algorithms by the combination of the RH strategy and various heuristic algorithms. Finally, the scheduling results of different algorithms are compared and the presented methods in this paper are demonstrated to be efficient by extensive experiments...|$|R
5000|$|<b>Dynamic</b> <b>scheduling</b> and {{the branch}} {{speculation}} that the algorithm enables helped performances as processors issued more and more instructions.|$|R
5000|$|... guided scheduling: {{similar to}} <b>dynamic</b> <b>scheduling,</b> but the chunk sizes per {{dispatch}} keep shrinking until reaching a preset value.|$|R
50|$|By default, LynxSecure uses an ARINC 653-based fixed-cyclic {{scheduler}} {{to manage}} processing time, but <b>dynamic</b> <b>scheduling</b> policies are also permitted.|$|R
40|$|Most logic {{programming}} languages actually provide {{some kind of}} <b>dynamic</b> <b>scheduling</b> to increase the expressive power and to control execution. Input consuming derivations have been introduced to describe <b>dynamic</b> <b>scheduling</b> while abstracting from the technical details. In this paper we review and compare the different proposals given in [9], [10] and [12] for denotational semantics of programs with input consuming derivations. We also show {{how they can be}} applied to termination analysis...|$|R
40|$|This study {{addresses}} a scheduling problem {{observed in the}} Diffusion Furnace (DF) of Semiconductor Manufacturing industry. Most of the earlier research in <b>dynamic</b> <b>scheduling</b> of DF(a Batch Processing Machine) considers only dynamic arrival of jobs. This study focuses <b>dynamic</b> <b>scheduling</b> of DF considering future arrival of jobs along with job and resource related real time events to minimize the total weighted tardiness. In the literature there are some studies addressing the <b>dynamic</b> real-time <b>scheduling</b> for discrete machine environment. These studies are concentrating either on proposing new algorithms and/or fine tuning the existing algorithms due to the occurrence of real-time events while scheduling. In this study we propose a research hypothesis that no needs to change any existing efficient <b>dynamic</b> <b>scheduling</b> algorithm(s) while real time events are occurring in scheduling DF. From the series of computational experiments, this study proves the proposed research hypothesis both empirically and statistically on nine efficient variants of ATC/BATC based greedy heuristic algorithms...|$|R
40|$|<b>Dynamic</b> <b>scheduling</b> is an importantnew {{innovation}} in manufacturingand supply chain managemenl. However. thesuccessof dynamicschedulingwill dependon real-timeinformation. TIlis paperdescribesintelligenttrackingtechnologiesthatprovidereal-timeinformationthroughout thesupplychainto supportkcywordsa logisticsplanningandc;;:ecut;on...|$|R
40|$|Avionics mission {{computing}} {{systems have}} traditionally been scheduled statically. Static scheduling provides assurance of schedulability prior to run-time and can be implemented with low run-time overhead. However, static scheduling does not support distributed processing effectively, handles non-periodic processing inefficiently, and treats invocation-toinvocation variations in resource requirements inflexibly. As a consequence, processing resources are underutilized and the resulting systems are hard to adapt to meet real-time processing requirements. <b>Dynamic</b> <b>scheduling</b> offers relief from the limitations of static <b>scheduling.</b> However, <b>dynamic</b> <b>scheduling</b> often has a higher run-time cost because certain operations are performed on-line. In addition, tasks can be scheduled dynamically that may never be dispatched. This report reviews {{the implications of these}} factors on avionics mission computing systems. We present an approach to <b>dynamic</b> <b>scheduling,</b> based on the Maximum Urgency First al [...] ...|$|R
40|$|We study {{termination}} of logic programs with <b>dynamic</b> <b>scheduling,</b> {{as it can}} be realised using delay declarations. Following previous work, our minimum assumption is that derivations are input-consuming, a notion introduced to define <b>dynamic</b> <b>scheduling</b> in an abstract way. Since this minimum assumption is sometimes insufficient to ensure termination, we consider here various additional assumptions on the permissible derivations. In one dimension, we consider derivations parametrised by any property that the selected atoms must have, e. g. being ground in the input positions. In another dimension, we consider both local and non-local derivations. In all cases, we give sufficient criteria for termination. The dimensions can be combined, yielding the most comprehensive approach so far to {{termination of}} logic programs with <b>dynamic</b> <b>scheduling.</b> For non-local derivations, the termination criterion is even necessary...|$|R
