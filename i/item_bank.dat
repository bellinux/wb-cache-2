387|246|Public
25|$|In June 2010, Florida colleges {{administered}} over 10,000 pilot exams {{populated with}} {{the newly created}} test items. The data from the pilot was then used to build the Postsecondary Education Readiness Test (P.E.R.T.) <b>item</b> <b>bank.</b>|$|E
2500|$|Plots of item {{information}} {{can be used to}} see how much information an item contributes and to what portion of the scale score range. [...] Because of local independence, item information functions are additive. [...] Thus, the test information function is simply the sum of the information functions of the items on the exam. [...] Using this property with a large <b>item</b> <b>bank,</b> test information functions can be shaped to control measurement error very precisely.|$|E
2500|$|In {{order to}} reduce the burden of field testing, the Texas State Board of Education has not {{released}} to the public those questions used to determine student scores on the Spring 2005 or Spring 2007 TAKS tests. [...] Regrettably, this prevents public review of the questions and answers (for appropriateness and correctness) and denies opportunities for students, teachers, and others to learn from the [...] tests. [...] However, university-level experts in each of the fields review each high school-level test for accuracy. [...] Grade-level teachers also review test items for appropriateness prior to field testing and review the field test results in order to select the best questions for inclusion in the test <b>item</b> <b>bank.</b>|$|E
30|$|First, {{cross-sectional}} {{data of the}} full <b>item</b> <b>banks</b> (N = 2010) was psychometrically evaluated using IRT (i.e., the Graded Response model; GRM) and Structural Equation Modelling (SEM). Second, data of the full <b>item</b> <b>banks</b> became recently available to evaluate longitudinal measurement invariance of the <b>item</b> <b>banks</b> using SEM (N = 500). Third, data is being collected to evaluate responsiveness of the CATs.|$|R
40|$|This paper {{comments}} on the contributions to this special issue on <b>item</b> <b>banking.</b> An historical framework for viewing the papers is provided by brief reviews of the literature {{in the areas of}} item response theory, <b>item</b> <b>banking,</b> and computerized testing. In general, the eight papers are viewed as contributing valuable technical knowledge for implementing testing programs with the aid of <b>item</b> <b>banks...</b>|$|R
30|$|The Patient-Reported Outcomes Measurement Information System (PROMIS™), {{created in}} 2004 {{as part of}} a trans-National Institutes of Health (NIH) {{initiative}} to enhance the tools of clinical research, offers a new and improved method for generic HRQL assessment across a full spectrum of functioning. PROMIS investigators utilized standardized procedures to create <b>item</b> <b>banks</b> in many domains including emotional distress, fatigue, pain, physical functioning, and peer relationships [12]. The <b>item</b> <b>banks</b> have undergone extensive psychometric evaluation including assessment of validity and reliability [13 – 16]. For example, the pediatric <b>item</b> <b>banks</b> have been validated in general populations and in children with sickle cell disease, obesity, cancer, rheumatic diseases, chronic kidney disease, and rehabilitative needs. <b>Item</b> <b>banks</b> can be administered as computer adaptive tests (CATs) or fixed length short forms with high relative validity across a broad range of functioning. Additionally, <b>item</b> <b>banks</b> can be used to construct custom short forms. Because PROMIS <b>item</b> <b>banks</b> were evaluated using item response theory (IRT) [17], scores from any subset of <b>bank</b> <b>items</b> (e.g., custom short form, CAT) produce standardized scores on the same scale, regardless of which <b>items</b> from the <b>bank</b> are included in the measure. This enables construction of a custom short form that specifically targets lower levels of physical functioning that would be hypothesized to better distinguish patients in this range of functioning.|$|R
5000|$|An <b>item</b> <b>bank</b> {{calibrated}} with a psychometric model {{selected by}} the test designer ...|$|E
5000|$|An <b>item</b> <b>bank</b> {{will not}} only include the text of each item, but also {{extensive}} information regarding test development and psychometric characteristics of the items. Examples of such information include: ...|$|E
50|$|Each exam {{administration}} uses a calibrated <b>item</b> <b>bank</b> {{of common}} tasks, which produces directly comparable results. A set of routine statistical analyses, {{such as the}} calculation of p-values, testlet and test reliability, and IRT analysis is performed after each exam session.|$|E
40|$|Purpose—The Patient-Reported Outcomes Measurement Information System (PROMIS) aims {{to develop}} {{self-reported}} <b>item</b> <b>banks</b> for clinical research. The PROMIS pediatrics (aged 8 – 17) project {{focuses on the}} development of <b>item</b> <b>banks</b> across several health domains (physical function, pain, fatigue, emotional distress, social role relationships, and asthma symptoms). The psychometric properties of the anxiety and depressive symptom <b>item</b> <b>banks</b> are described. Methods—Participants (n = 1, 529) were recruited in public school settings, hospital-based outpatient and subspecialty pediatrics clinics. The anxiety (k = 18) and depressive symptoms (k = 21) items were split between two test administration forms. Hierarchical confirmatory factor-analytic models (CFA) were conducted to evaluate scale dimensionality and local dependence. IRT analyses were then used to finalize <b>item</b> <b>banks</b> and short forms...|$|R
30|$|The {{identification}} {{and evaluation of}} <b>item</b> <b>banks</b> {{that can be used}} in a psychiatric population to measure constructs of health-related quality-of-life is a fundamental objective of this project. Validated <b>item</b> <b>banks</b> will be used as the foundation for developing short-form instruments and in the future enabling computerized adaptive testing.|$|R
5000|$|FastTest - <b>Item</b> <b>banking,</b> e-assessment (online testing), {{computerized}} adaptive testing ...|$|R
50|$|The {{project began}} on 1 August 1998. Before 31 July 2000 three modal tests had been drafted and were tested worldwide. The {{performance}} description, marking criteria and evaluation procedures were worked out and an <b>item</b> <b>bank</b> for prototype, {{a database of}} participants and a test database were all set up.|$|E
50|$|In 2003 {{a number}} of UK medical schools began to work {{together}} to increase quality assurance activities in the area of assessment as part of the Universities Medical Assessment Partnership (UMAP). UMAP is a collaborative item banking project seeking to build a quality assured written assessment <b>item</b> <b>bank</b> suitable for high-stakes examinations at all UK medical schools.|$|E
50|$|LeClerq {{focused on}} <b>item</b> <b>bank</b> testing - {{the process of}} using a pool of {{questions}}, from which questions are drawn and randomly delivered to learners {{to see how well}} they answer questions without pattern recognition or order influencing the process. The result is higher quality knowledge and information. The outcome was a report on the quality of information/knowledge that shows where misinformation exists.|$|E
30|$|Using an R® {{program and}} based on the item {{parameters}} of calibrated <b>item</b> <b>banks,</b> we estimated most likely item responses by T-score level for 21 PROMIS <b>item</b> <b>banks.</b> These were used to create labeled heat maps for short form items that graphically display the most likely item responses across the measured score range.|$|R
40|$|Projects {{to develop}} an {{automated}} <b>item</b> <b>banking</b> and test development system have been undertaken on several occasions at the Air Force Human Resources Laboratory (AFHRL) throughout the past 10 years. Such a system permits the construction of tests in far less time and with {{a higher degree of}} a:curacy than earlier test construction procedures. This paper details Classical Test Theory and Item Response Theory (IRT) approaches to <b>item</b> <b>banking</b> and test construction and their relevance to the development of an automated <b>item</b> <b>banking</b> system. State-of-the-art improvements in the current automated <b>item</b> <b>banking</b> system are proposed which include the capability to generate multiple forms simultaneously and to print new test forms with the same type font, spacing, and format as the reference form. (Author) Reproductions supplied by EDRS are the best that can be made from the original document...|$|R
40|$|Background: The {{construction}} {{and evaluation of}} <b>item</b> <b>banks</b> to measure unidimensional constructs of health-related quality of life (HRQOL) is a fundamental objective of the Patient-Reported Out-comes Measurement Information System (PROMIS) project. Objectives: <b>Item</b> <b>banks</b> {{will be used as}} the foundation for develop-ing short-form instruments and enabling computerized adaptive testing. The PROMIS Steering Committee selected 5 HRQOL do-mains for initial focus: physical functioning, fatigue, pain, emotional distress, and social role participation. This report provides an over-view of the methods used in the PROMIS item analyses and proposed calibration of <b>item</b> <b>banks.</b> Analyses: Analyses include evaluation of data quality (eg, logic and range checking, spread of response distribution within an item), descriptive statistics (eg, frequencies, means), item response theory model assumptions (unidimensionality, local independence, mono-tonicity), model fit, differential item functioning, and <b>item</b> calibra-tion for <b>banking.</b> Recommendations: Summarized are key analytic issues; recom-mendations are provided for future evaluations of <b>item</b> <b>banks</b> in HRQOL assessment. Key Words: item response theory, unidimensionality, model fit, differential item functioning, computerized adaptive testin...|$|R
50|$|In 2009, {{the company}} created a web {{version of its}} {{flagship}} FastTest platform. FastTest is a software system designed specifically for use by professionals in the testing and assessment industry, supporting online testing, <b>item</b> <b>bank,</b> item review, and results tracking. FastTest has been used across all major industries performing assessment, including business, professional certification, higher education, medicine, psychology, and K-12 education.|$|E
5000|$|The {{items of}} a {{multiple}} choice test are often colloquially {{referred to as}} [...] "questions," [...] {{but this is a}} misnomer because many items are not phrased as questions. For example, they can be presented as incomplete statements, analogies, or mathematical equations. Thus, the more general term [...] "item" [...] is a more appropriate label. Items are stored in an <b>item</b> <b>bank.</b>|$|E
50|$|An <b>item</b> <b>bank</b> is a {{term for}} a {{repository}} of test items that belong to a testing program, {{as well as all}} information pertaining to those items. In most applications of testing and assessment, the items are of multiple choice format, but any format can be used. Items are pulled from the bank and assigned to test forms for publication either as a paper-and-pencil test or some form of e-assessment.|$|E
30|$|To {{review the}} {{linguistic}} {{quality of the}} Swedish translation of child and adult PROMIS <b>item</b> <b>banks.</b>|$|R
30|$|Upper Extremity and Mobility T-scores {{were nearly}} three {{standard}} deviations below the PROMIS pediatric calibration population mean. Preliminary psychometrics demonstrated {{the potential to}} more accurately measure lower physical functioning using items from PROMIS <b>item</b> <b>banks.</b> However, some participants scored at the measurement floor despite targeting items {{at the lower end}} of the scale. Further short form refinement, enrichment of the <b>item</b> <b>banks,</b> and larger-scale field testing are needed.|$|R
30|$|Background: To study {{whether the}} Dutch-Flemish PROMIS Pain Interference and Pain Behavior <b>item</b> <b>banks</b> can be {{considered}} essentially unidimensional.|$|R
50|$|Plots of item {{information}} {{can be used to}} see how much information an item contributes and to what portion of the scale score range. Because of local independence, item information functions are additive. Thus, the test information function is simply the sum of the information functions of the items on the exam. Using this property with a large <b>item</b> <b>bank,</b> test information functions can be shaped to control measurement error very precisely.|$|E
50|$|Because an <b>item</b> <b>bank</b> is {{essentially}} a simple database, it {{can be stored in}} database software or even a spreadsheet such as Microsoft Excel. However, there are several dozen commercially-available software programs specifically designed for item banking. The advantages that these provide are related to assessment. For example, items are presented on the computer screen as they would appear to a test examinee, and item response theory parameters can be translated into item response functions or information functions. Additionally, there are functionalities for publication, such as formatting a set of items to be printed as a paper-and-pencil test.|$|E
50|$|In {{order to}} reduce the burden of field testing, the Texas State Board of Education has not {{released}} to the public those questions used to determine student scores on the Spring 2005 or Spring 2007 TAKS tests. Regrettably, this prevents public review of the questions and answers (for appropriateness and correctness) and denies opportunities for students, teachers, and others to learn from the tests. However, university-level experts in each of the fields review each high school-level test for accuracy. Grade-level teachers also review test items for appropriateness prior to field testing and review the field test results in order to select the best questions for inclusion in the test <b>item</b> <b>bank.</b>|$|E
5000|$|Some <b>item</b> <b>banks</b> {{also have}} test {{administration}} functionalities, {{such as being}} able to deliver e-assessment or process [...] "bubble" [...] answer sheets.|$|R
30|$|We aim to {{show how}} PROMIS <b>item</b> <b>banks</b> {{can be used to}} develop {{individualized}} short forms to measure more relevant outcomes for patients.|$|R
30|$|Our {{aim was to}} {{validate}} the pediatric V 2.0 PROMIS Pain Interference, Mobility and Upper Extremity <b>item</b> <b>banks,</b> in the general Dutch population.|$|R
5000|$|OpenEd is {{an online}} catalog of {{educational}} assessments, homework assignments, videos, games and lesson plans aligned to every Common Core standard {{and several other}} standards, and includes the only open source formative <b>item</b> <b>bank.</b> The site offers the ability for teachers to assign resources to their students online, letting students take assessments, do homework etc on their own computers or tablets. Assignments done online are graded automatically and presented to the teacher in a mastery chart. OpenEd's slogan mentions [...] "assessment to instruction" [...] meaning, formative assessments given on OpenEd can access OpenEd's large catalog on a per student basis to recommend the right resource to each student individually. The company has stated that functionality of searching the site {{and most of its}} resources are free {{and will continue to be}} free going forward. [...] However, the company is also distributing premium content from publishers such as Pearson and Houghton Mifflin Harcourt to teachers for $9.95 per month.|$|E
40|$|An integer {{programming}} approach to <b>item</b> <b>bank</b> design is presented {{that can be}} used to calculate an optimal blueprint for an <b>item</b> <b>bank,</b> in order to support an existing testing program. The results are optimal in that they minimize the effort involved in producing the items as revealed by current item writing patterns. Also presented is an adaptation of the models, which can be used as a set of monitoring tools in <b>item</b> <b>bank</b> management. The approach is demonstrated empirically for an <b>item</b> <b>bank</b> that was designed for the Law School Admission Test...|$|E
40|$|This is {{a conference}} paper. Sclater and MacDonald (2004) provide a simple {{definition}} of an item bank: a collection of items for a particular assessment, subject or educational sector, classified by metadata which facilitates searching and automated test creation. There {{is a need to}} define more closely the various elements and attributes of the <b>item</b> <b>bank</b> itself and to show how an <b>item</b> <b>bank</b> might fit into the larger picture of a distributed national (or even international) <b>item</b> <b>bank</b> infrastructure. This paper examines these issues. The <b>Item</b> <b>Bank</b> Infrastructure Study (IBIS) expands on this vision more fully and is available from www. toia. ac. uk/ibis...|$|E
40|$|The current {{emphasis}} on objectives and test <b>item</b> <b>banks</b> for constructing more effective tests is being augmented by increasingly sophisticated computer software. Items can be catalogued in numerous ways for retrieval. The items {{as well as}} instructional objectives can be stored and test forms can be selected and printed by the computer. It is also possible to select and retrieve objectives from which a curriculum can be created tailored to personal choice. This paper describes a very flexible <b>item</b> <b>banking</b> computer program and its use with a longitudinal, criterion-referenced testing program called Comprehensive Achievement Monitoring (CAM), capable of both classroom management and curriculum evaluation. The CAM model includes item sampling techniques and several parallel test forms which would be particularly difficult to develop without the <b>item</b> <b>banking</b> computer programs. (Author) Project C omprehensive A chievemenu M onitorin...|$|R
40|$|Several {{methods for}} optimal test {{construction}} from <b>item</b> <b>banks</b> {{have recently been}} proposed using information functions. The main problem with these methods is {{the large amount of}} time required to identify an optimal test. In this paper, a new method is presented for the Rasch model that considers groups of interchangeable items, instead of individual items. The process of item clustering is described, the cluster-based test construction model is outlined, and the computational procedure and results are given. Results indicate that this method produces accurate results in small amounts of time. Index terms: information functions, <b>item</b> <b>banking,</b> <b>item</b> response theory, linear programming, test construction...|$|R
40|$|Purpose: The {{purpose of}} this study was to assess the psychometric {{properties}} of diabetic retinopathy (DR) and diabetic macular edema (DME) quality-of-life (QoL) <b>item</b> <b>banks</b> and determine the utility of the final calibrated <b>item</b> <b>banks</b> by simulating a computerized adaptive testing (CAT) application. Methods: In this clinical, cross-sectional study, 514 participants with DR/DME (mean age ± SD, 60. 4 ± 12. 6 years; 64 % male) answered 314 items grouped under nine QoL item pools: Visual Symptoms (SY); Ocular Comfort Symptoms (OS); Activity Limitation (AL); Mobility (MB); Emotional (EM); Health Concerns (HC); Social (SC); Convenience (CV); and Economic (EC). The psychometric properties of the item pools were assessed using Rasch analysis, and CAT simulations determined the average number of items administered at high and moderate precision levels. Results: The SY, MB, EM, and HC item pools required minor amendments, mainly involving removal of six poorly worded, highly misfitting items. AL and CV required substantial modification to resolve multidimensionality, which resulted in two new item banks: Driving (DV) and Lighting (LT). Due to unresolvable psychometric issues, the OS, SC, and EC item pools were not pursued further. This iterative process resulted in eight operational <b>item</b> <b>banks</b> that underwent CAT simulations. Correlations between CAT and the full <b>item</b> <b>banks</b> were high (range, 0. 88 - 0. 99). On average, only 3. 6 and 7. 2 items were required to gain measurement at moderate and high precision, respectively. Conclusions: Our eight psychometrically robust and efficient DR/DME <b>item</b> <b>banks</b> will enable researchers and clinicians to accurately assess the impact and effectiveness of treatment therapies for DR/DME in all areas of QoL. Restricted Access: Metadata Onl...|$|R
