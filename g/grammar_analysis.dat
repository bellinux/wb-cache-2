77|198|Public
2500|$|Spamdexing (a {{portmanteau}} of spamming and indexing) {{refers to}} a practice on the World Wide Web of modifying HTML pages to increase their chances of high placement on search engine relevancy lists. These sites use [...] "black-hat" [...] search engine optimization techniques to deliberately manipulate their rank in search engines. Many modern search engines modified their search algorithms to try to exclude web pages utilizing spamdexing tactics. For example, the search bots will detect repeated keywords as spamming by using a <b>grammar</b> <b>analysis.</b> If a website owner is found to have spammed the webpage to falsely increase its page rank, the website may be penalized by search engines.|$|E
50|$|Examples {{taken from}} Allen, Janet's Kankanaey: A Role and Reference <b>Grammar</b> <b>Analysis.</b>|$|E
50|$|TREE-META, {{a second}} {{generation}} Schorre metacompiler, appeared around 1968. It extended {{the capabilities of}} META II, adding unparse rules separating code production from the <b>grammar</b> <b>analysis.</b> A grammar now produced an abstract syntax tree that the unparse rules operated on. The unparse tree pattern matching provided peephole optimization ability. Abstract syntax tree generation is programmed in the <b>grammar</b> <b>analysis.</b>|$|E
5000|$|Vyakarana (...) : <b>grammar</b> and {{linguistic}} <b>analysis.</b> This auxiliary discipline has focussed on {{the rules of}} <b>grammar</b> {{and linguistic}} <b>analysis</b> to establish the exact form of words and sentences to properly express ideas.|$|R
5000|$|English. Traditional <b>grammar,</b> textual <b>analysis,</b> and the {{classical}} canon were dropped {{and replaced with}} teaching that focused on more everyday language sources, contemporary literature and creative writing.|$|R
5000|$|<b>Grammars</b> for the <b>analysis</b> and {{generation}} of the languages involved.|$|R
50|$|Osborne T. 2005. Coherence: A {{dependency}} <b>grammar</b> <b>analysis.</b> SKY Journal of Linguistics 18, 223-286.|$|E
5000|$|According to Allen, Janet's Kankanaey: A Role and Reference <b>Grammar</b> <b>Analysis,</b> only [...] "two predicating affixes are suffixes, -en and -an. Some roots {{drop their}} last vowel when suffixed, as in datngan (come upon, find) from dateng (arrive)." ...|$|E
5000|$|Kankanaey content roots {{divide the}} Kankanaey lexicon into {{different}} categories {{to define their}} usage and word type. The categories are class roots, property roots, stative roots, perception-stative roots, physical roots, and action roots. Word charts and definitions taken from Allen, Janet's Kankanaey: A Role and Reference <b>Grammar</b> <b>Analysis.</b>|$|E
40|$|In {{this paper}} we {{describe}} the design and implementation of a system for representing context-free grammars in C++. The system allows for grammar representation at the object level, providing enhanced modularity and flexibility when compared to traditional generator-based approaches. We also describe the transformation of <b>grammar</b> flow <b>analysis</b> problems into an object-oriented framework using the Visitor pattern, {{as well as the}} implementation of a top-down LL   1 ¡ parser. As such, this work represents the synthesis of three presently disparate fields in parser design and implementation: combinator parsing, fixpoint-based <b>grammar</b> flow <b>analysis,</b> and object-oriented design...|$|R
25|$|Vedangas {{developed}} as ancillary studies for the Vedas, but its insights into meters, structure {{of sound and}} language, <b>grammar,</b> linguistic <b>analysis</b> and other subjects influenced post-Vedic studies, arts, culture and various schools of Hindu philosophy. The Kalpa Vedanga studies, for example, {{gave rise to the}} Dharma-sutras, which later expanded into Dharma-shastras.|$|R
40|$|We {{present a}} {{syntactic}} approach to technical drawing dimensions <b>analysis.</b> A specific <b>grammar</b> {{is used to}} describe dimensions of drawings. This grammar can be graphically designed by combining different graphic primitives. The algorithm used for analysis can start at different points of the <b>grammar.</b> The <b>analysis</b> proceeds bottom-up and top-down according to previously obtained results. ...|$|R
50|$|CWIC, {{described}} in a 1970 ACM publication is a third generation Schorre metacompiler that added lexical rules and backtracking operators to the <b>grammar</b> <b>analysis.</b> LISP 2 was married with the unparse rules of TREEMETA. With LISP 2 processing, CWIC can generate fully optimized code. CWIC also provided binary code generation into named code sections. Single and multipass compiles could be implemented using CWIC. CWIC compiled to IBM System/360 machine code.|$|E
5000|$|In September 2014 {{a course}} in rap {{linguistics}} was offered at the University of Calgary in Calgary, Alberta, [...] "examining rap from cultures as diverse as German, French, Navajo and even the Sami people of Northern Europe." [...] The course has difficult content as rap is studied using methodologies applied in linguistics, such as <b>grammar</b> <b>analysis</b> and measurement of vowel sounds using software. According to associate professor Darin Flynn, who is teaching this course, rap heroes, such as Eminem or Jay-Z, are [...] "true poet laureates of the working class" [...] and their songs [...] "crisscross sound, emotion, grammar and multiple metaphors".|$|E
5000|$|Spamdexing (a {{portmanteau}} of spamming and indexing) {{refers to}} a practice on the World Wide Web of modifying HTML pages to increase their chances of high placement on search engine relevancy lists. These sites use [...] "black-hat" [...] search engine optimization techniques to deliberately manipulate their rank in search engines. Many modern search engines modified their search algorithms to try to exclude web pages utilizing spamdexing tactics. For example, the search bots will detect repeated keywords as spamming by using a <b>grammar</b> <b>analysis.</b> If a website owner is found to have spammed the webpage to falsely increase its page rank, the website may be penalized by search engines.|$|E
40|$|AbstractWe study {{abstract}} {{interpretations of}} a fixpoint protoderivation semantics defining the maximal derivations of a transitional semantics of context-free grammars akin to pushdown automata. The {{result is a}} hierarchy of bottom-up or top-down semantics refining the classical equational and derivational language semantics and including Knuth grammar problems, classical <b>grammar</b> flow <b>analysis</b> algorithms and parsing algorithms...|$|R
40|$|We {{specify the}} {{advantages}} of guided composition of sentences and illustrate them with examples from Leader, a natural language interface we have developped. Guided composition is achieved by using the same <b>grammar</b> for <b>analysis</b> and for synthesis. We detail {{the problems we have}} encountered and we provide solutions for partial synthesis. We give the principles of the analysis-synthesis algorithm...|$|R
40|$|The article {{analyses}} modal structure (tense, polarity) in Kurt Vonnegut's novel Slaughterhouse-Five {{within the}} framework of Systemic-Functional <b>Grammar.</b> The <b>analysis</b> of the Mood element shows the prevailing pattern to be past positive; the use of present tenses embodies Vonnegut's specific non-linear concept of time. Similarly, the absence of negative polarity builds the deterministic belief that pervades the novel...|$|R
50|$|The LALR parser and its alternatives, the SLR parser and the Canonical LR parser, {{have similar}} methods and parsing tables; their main {{difference}} {{is in the}} mathematical <b>grammar</b> <b>analysis</b> algorithm used by the parser generation tool. LALR generators accept more grammars than do SLR generators, but fewer grammars than full LR(1). Full LR involves much larger parse tables and is avoided unless clearly needed for some particular computer language. Real computer languages can often be expressed as LALR(1) grammars. In cases where they can't, a LALR(2) grammar is usually adequate. If the parser generator allows only LALR(1) grammars, the parser typically calls some hand-written code whenever it encounters constructs needing extended lookahead.|$|E
50|$|SLR and the more-general methods LALR parser and Canonical LR parser have {{identical}} {{methods and}} similar tables at parse time; they differ {{only in the}} mathematical <b>grammar</b> <b>analysis</b> algorithms used by the parser generator tool. SLR and LALR generators create tables of identical size and identical parser states. SLR generators accept fewer grammars than do LALR generators like yacc and Bison. Many computer languages don't readily fit the restrictions of SLR, as is. Bending the language's natural grammar into SLR grammar form requires more compromises and grammar hackery. So LALR generators have become much more widely used than SLR generators, despite being somewhat more complicated tools. SLR methods remain a useful learning step in college classes on compiler theory.|$|E
5000|$|The Kankanaey {{vocabulary}} {{is arranged}} by root morphemes, {{and points out}} the important semantic properties of each root. Kankanaey roots deeply rely on the combination with their affixes to determine their meaning in phrases and clauses. The predicates that form {{are determined by the}} interaction of the affixation to the semantic properties of the root that are relevant in its context. Aktionsart is a way to categorize event semenatics, proposed by Vendler (1967), by if they are [...] "happening" [...] or are static, and it distinguishes them by their temporal properties and its dynamicity. According to Allen, Janet's Kankanaey: A Role and Reference <b>Grammar</b> <b>Analysis,</b> [...] "VVLP (1997) and Van Valin (2005) expanded the list of categories to reflect resultant situations, adding semelfactives and complex predicates--active accomplishments and causatives." ...|$|E
40|$|Students {{will prepare}} {{translation}} assignments {{in advance and}} will show evidence of preparation when called upon to translate in class. Students will participate actively in classroom discussions. • Students will complete a minimum of four full-period tests (to include <b>grammar,</b> translation, <b>analysis</b> and interpretation, and essay-writing) each quarter. • Quarter grades will consist of the average of test grades (90 %) and classroom participation (10 %) ...|$|R
40|$|The use of {{generative}} design grammars for computational design synthesis {{has been}} shown to be successful in many application areas. The development of advanced search and optimization strategies to guide the computational synthesis process is an active research area with great improvements in the last decades. The development of the grammar rules, however, often resembles an art rather than a science. Poor grammars drive the need for problem specific and sophisticated search and optimization algorithms that guide the synthesis process toward valid and optimized designs in a reasonable amount of time. Instead of tuning search algorithms for inferior grammars, this research focuses on designing better grammars to not unnecessarily burden the search process. It presents a <b>grammar</b> rule <b>analysis</b> method to provide a more systematic development process for grammar rules. The goal of the <b>grammar</b> rule <b>analysis</b> method is to improve the quality of the rules and in turn have a major impact on the quality of the designs generated. Four different grammars for automated gearbox synthesis are used as a case study to validate the developed method and show its potentia...|$|R
40|$|The CRITTER {{translation}} system {{makes use}} of a single <b>grammar</b> to perform <b>analysis</b> and synthesis tasks. The formalism used is a variant of DCG (Definite Clause Grammars), in which annotations {{have been added to}} allow for dual compilations of the <b>grammar</b> into <b>analysis</b> and synthesis Prolog programs sharing the same declarative content. These annotations are of two types: 1) annotations separating the declarative content of rules (logic) from goal-processing order (control), and 2) annotations which act as directives for the compiler(s) to perform &quot;optimization &quot; transformations on groups of rules making the target Prolog procedures better adapted to the- analysis or synthesis-task at hand. 1. THE TRANSLATION MODEL. 1. 1 CRITTER CRITTER is an experimental system that we are currently developing as a test-bed for our translation model. It is designed to translate from English to French (and conversely) reports concerning the meat trade marke...|$|R
40|$|This paper {{discusses}} the derivation of functional programs for <b>grammar</b> <b>analysis</b> problems, {{such as the}} Empty problem and the Reachable problem. <b>Grammar</b> <b>analysis</b> problems {{can be divided into}} two classes: top-down problems such as Follow and Reachable, which are described in terms of the contexts of nonterminals, and bottom-up problems such as Empty and First, which do not refer to contexts. In a previous paper we derive a program for bottom-up <b>grammar</b> <b>analysis</b> problems. In this paper we derive a program for top-down <b>grammar</b> <b>analysis</b> problems by transforming the specification of an arbitrary top-down problem into a program. The existence of a solution is guaranteed provided some natural conditions are satisfied. Furthermore, we describe a general transformation that applies to both classes of <b>grammar</b> <b>analysis</b> problems. The general transformation avoids unnecessary computations in the computation of a fixed point. Constructor classes, which are used to abstract from the notions bottom-up and top-down, are an essential ingredient of the latter derivation...|$|E
40|$|This paper {{discusses}} bottom-up <b>grammar</b> <b>analysis</b> {{problems such}} as te EMPTY problem and the FIRST problem. It defines a general class of bottom-up <b>grammar</b> <b>analysis</b> problems, and from this definition it derives a functional program for performing bottom-up <b>grammar</b> <b>analysis.</b> The derivation is purely calculational, using theorems from lattice therory, the Bird-Meertens calculus, and laws for list-comprehensions. Sufficient conditions guaranteeing {{the existence of a}} solution emerge as a byproduct of the calculation. The resulting program is used to construct programs for the EMPTY problem and the FIRST problem...|$|E
40|$|Journal of Chinese linguistics, Monograph series n. 19 is a {{collection}} of selected papers from two workshops on Lexical-Functional <b>Grammar</b> <b>Analysis</b> of Chinese : LFG' 01 and LFG' 02 The International Workshop on Lexical-Functional <b>Grammar</b> <b>Analysis</b> of Chinese (LFG' 02), Hong Kong, 1 June 2002. In Lexical-functional grammar: analysis of Chinese (Journal of Chinese linguistics, Monograph series n. 19), 2003, p. 32 - 5...|$|E
40|$|This paper {{specifies}} {{the theoretical}} {{basis for the}} implementation of different generators of the OPTRAN system. <b>Grammar</b> Flow <b>analysis</b> transports the techniques of data flow analysis to the meta level of compiler construction. The analogon to the states in data flow analysis are the syntax trees together with some information, which is associated with trees by propagation functions. One example is the association of characteristic graphs, another example the association of sets of matching tree patterns...|$|R
5000|$|Vyakarana (व्याकरण, [...] ) {{literally}} means [...] "explanation, analysis", {{and also}} refers {{to one of}} the six ancient Vedangas, or ancillary science connected with the Vedas - the scriptures of Hinduism. Vyakarana is the study of <b>grammar</b> and linguistic <b>analysis</b> in Sanskrit language.|$|R
50|$|Aaron ben Moses ben Asher was {{the first}} to take Hebrew grammar seriously. He {{was the first}} {{systematic}} Hebrew grammarian. His Sefer Dikdukei ha-Te'amim (<b>Grammar</b> or <b>Analysis</b> of the Accents) was an original collection of grammatical rules and masoretic information. Grammatical principles were not at that time considered worthy of independent study. The value of this work is that the grammatical rules presented by ben Asher reveal the linguistic background of vocalization for the first time. He had a tremendous influence on subsequent Biblical grammar and scholarship.|$|R
40|$|The {{purpose of}} this study was to {{describe}} written narratives of language disordered adolescents by comparing their written narratives via story <b>grammar</b> <b>analysis</b> with those of normal adolescents. The written narratives were obtained by administering two tasks as required assignments within the English or communications classes of the two groups. Task A was to write about a personal experience and Task B was about an imaginary experience. This study used Merritt and Liles 2 ̆ 7 adaptations (1987) of Stein and Glenn 2 ̆ 7 s procedures (1979) for story <b>grammar</b> <b>analysis</b> to describe the content of the narratives...|$|E
40|$|AbstractThis paper {{introduces}} a grammar-based model {{for developing a}} multi-thread multi-frontal parallel direct solver for one- dimensional isogeometric finite element method. The model includes the integration of B-splines for construction of the element local matrices and the multi-frontal solver algorithm. The integration and the solver algorithm are partitioned into basic indivisible tasks, namely the grammar productions, that can be executed squentially. The partial order of execution of the basic tasks is analyzed to provide the scheduling for {{the execution of the}} concurrent integration and multi-frontal solver algo- rithm. This graph <b>grammar</b> <b>analysis</b> allows for optimal concurrent execution of all tasks. The model has been implemented and tested on NVIDIA CUDA GPU, delivering logarithmic execution time for linear, quadratic, cubic and higher order B-splines. Thus, the CUDA implementation delivers the optimal performance predicted by our graph <b>grammar</b> <b>analysis.</b> We utilize the solver for multiple right hand sides related to the solution of non-stationary or inverse problems...|$|E
40|$|Passage {{retrieval}} {{model for}} combining concept-based semantics and term statistics in context. Objective: Passage retrieval precision Methods: • Datawarehouse style indexing for efficient search and aggregation of multi-word terms, or resolved concepts at multiple levels of document granularity. • Rule-based query processing algorithm for parsing, identification, and extraction of biological concepts. • Retrieval function for systematically combining concept terms with term statistics at multiple levels of context. • Dependency <b>grammar</b> <b>analysis</b> for identifying complementary subject/object concept pairs...|$|E
40|$|In this paper, we {{show how}} HPSG, with some adjustments, {{can be seen}} as a {{particular}} implementation of a dependency grammar and we discuss the advantages of such a view and the resulting status of phrases. Our study focuses on extraction which is the cornerstone of the theory and one of the more problematic phenomena for our hypothesis, the interpretation of HPSG as a dependency <b>grammar.</b> Our <b>analysis</b> of whwords will be based on an idea of Tesniere treating them simultaneously as complementizers and pronouns...|$|R
40|$|The {{books of}} the Royal School Series, {{produced}} in Britain, were used in schools {{in the province of}} Newfoundland and Labrador from the 1870 s until well into the 20 th century, mainly as aids in teaching English and spelling. This is the sixth level Royal Crown Reader, comprised of illustrated poetry and pieces of prose, each followed by word exercises, and ends with sections on word building and derivation, <b>grammar</b> and <b>analysis,</b> and figures of speech. Part of the Royal school series. Includes bibliographical references...|$|R
40|$|The {{collection}} {{will cover}} all the major fields of discourse studies: including, <b>grammar,</b> stylistics, conversation <b>analysis,</b> narrative analysis, argumentation, psychology of comprehension, ethnography of speaking, and media. It will include classic articles, work from the top scholars in the field, and reflect all the significant debates...|$|R
