1460|696|Public
5|$|Windows Server 2012 R2 was {{released}} on October 18, 2013. It was unveiled on June 3, 2013 at TechEd North America. According to Windows Server 2012 R2 datasheet published on May 31, 2013, there are four editions of this operating system: Foundation, Essentials, Standard and <b>Datacenter.</b> As with Windows Server 2012, the <b>Datacenter</b> and Standard editions are feature-identical, varying only based on licensing (particularly licensing of virtual instances). The Essentials edition has the same features as the <b>Datacenter</b> and Standard products, with some restrictions.|$|E
5|$|The {{product was}} {{released}} to manufacturing on August 1, 2012 and became generally available on September 4, 2012. However, not all editions of Windows Server 2012 were released {{at the same}} time. Windows Server 2012 Essentials was released to manufacturing on October 9, 2012 and was made generally available on November 1, 2012. As of September 23, 2012, all students subscribed to DreamSpark program can download Windows Server 2012 Standard or <b>Datacenter</b> free of charge.|$|E
25|$|The Hyper-V role is only {{available}} in the x64 variants of Windows Server 2008, Windows Server 2008 R2 Standard, Enterprise or <b>Datacenter</b> edition, Windows Server 2012 Standard or <b>Datacenter</b> edition, Windows 8 (or 8.1) Pro or Enterprise edition, or Windows 10 Pro, Education or Enterprise edition.|$|E
40|$|Abstract—Cloud {{providers}} may operate large-scale <b>datacenters</b> {{in a few}} locations. We {{argue that}} deploying many small-scale <b>datacenters</b> at network edge can significantly improve user expe-rience in terms of latency. Small-scale <b>datacenters,</b> however, {{may not be able}} to provide elastic services. In this paper, we investigate distributed small-scale <b>datacenters</b> with load reallocation where jobs that cannot be suitably processed locally will be reallocated to remote <b>datacenters.</b> We formulate an optimization problem for load reallocation in distributed <b>datacenters,</b> provide performance comparisons among different alternatives and offer insights on handling multiple job types. We develop online optimization algo-rithms that can be operated in a decentralized and measurement-based fashion to dynamically reallocate load in response to sudden load surges. The experimental results demonstrate that elasticity can be practically provided by small-scale <b>datacenters</b> enhanced with effective load reallocation techniques. I...|$|R
30|$|It {{has been}} an proven fact that cost of {{maintaining}} huge <b>datacenters</b> is remarkably high [6]. There {{have been a number}} of research articles, such as [3, 7, 8], that studied cost models of <b>datacenters</b> and concluded that server cost and <b>datacenter’s</b> power infrastructure together account for more than three fourths of <b>datacenter’s</b> total cost [9]. Moreover, both costs are decided by system capacity in terms of the number of servers [9].|$|R
40|$|The {{proliferation}} of cloud computing has promoted the wide deployment of large-scale <b>datacenters</b> with tremendous power consumption and high carbon emission. To reduce power cost and carbon footprint, {{an increasing number}} of cloud service providers have considered green <b>datacenters</b> with renewable energy sources, such as solar or wind. However, unlike the stable supply of grid energy, it is challenging to utilize and realize renewable energy due to the uncertain, intermittent and variable nature. In this article, we provide a taxonomy of the state-of-the-art research in applying renewable energy in cloud computing <b>datacenters</b> from five key aspects, including generation models and prediction methods of renewable energy, capacity planning of green <b>datacenters,</b> intra-datacenter workload scheduling and load balancing across geographically distributed <b>datacenters.</b> By exploring new research challenges involved in managing the use of renewable energy in <b>datacenters,</b> this article attempts to address why, when, where and how to leverage renewable energy in <b>datacenters,</b> also with a focus on future research avenues...|$|R
25|$|A {{number of}} {{specialist}} technician, sales and <b>datacenter</b> certifications are also available.|$|E
25|$|Datacenter: SQL Server 2008 R2 <b>Datacenter</b> is a full-featured {{edition of}} SQL Server and is {{designed}} for datacenters that need high levels of application support and scalability. It supports 256 logical processors and virtually unlimited memory and comes with StreamInsight Premium edition. The <b>Datacenter</b> edition has been retired in SQL Server 2012; all of its features are available in SQL Server 2012 Enterprise Edition.|$|E
25|$|Maximum total memory per {{system for}} Windows Server 2008 R2 hosts: 32GB (Standard) or 2TB (Enterprise, <b>Datacenter).</b>|$|E
3000|$|Federated datacenters: {{multiple}} cloud providers {{manage their}} own <b>datacenters</b> in an independent fashion, but the traffic among <b>datacenters</b> of different cloud providers is engineered by adopting an SDN approach, typically by loosely coupling SDN controllers in a peer-to-peer fashion. In this case, there is the need of opening the borders of <b>datacenters</b> by allowing external cloud vendors to control (or at least to influence) how incoming and outgoing traffic is managed; [...]...|$|R
40|$|The {{emergence}} of cloud computing {{has created a}} demand for more <b>datacenters,</b> which in turn, {{has led to the}} substantial consumption of electricity by computing systems and cool-ing units. Although recently built warehouse-scale datacen-ters can nearly completely eliminate cooling overhead, small to medium <b>datacenters,</b> which still spend nearly half of their power on cooling, still labor under heavy cooling overhead. Often overlooked by the cloud computing community, these types of <b>datacenters</b> are not in the minority: They are respon-sible for more than 70 % of the entire electrical power used by <b>datacenters.</b> Thus, to tackle the cooling inefficiencies of these <b>datacenters,</b> we propose ambient temperature-aware capping (ATAC), which maximizes power efficiency while minimizing overheating. ATAC senses the ambient tempera-ture of each server and triggers a new performance capping mechanism to achieve 38 % savings in cooling power and 7 % savings in total power with less than 1 % degradation in performance...|$|R
40|$|Multi-tenant <b>datacenters</b> {{represent}} an extremely challenging networking environment. Tenants want {{the ability to}} migrate unmodified workloads from their enterprise networks to service provider <b>datacenters,</b> retaining the same networking configurations of their home network. The service providers must meet these needs without operator intervention while preserving their own operational flexibility and efficiency. Traditional networking approaches have failed to meet these tenant and provider requirements. Responding to this need, we present the design and implementation of a network virtualization solution for multi-tenant <b>datacenters.</b> ...|$|R
25|$|In Helsinki, an {{underground}} <b>datacenter</b> {{next to the}} President's palace releases excess heat into neighboring homes, producing enough heat to heat approximately 500 large houses.|$|E
25|$|Cisco Systems also {{sponsors}} {{a line of}} IT professional certifications for Cisco products. There {{are five}} levels of certification: Entry (CCENT), Associate (CCNA/CCDA), Professional (CCNP/CCDP), Expert (CCIE/CCDE) and recently Architect, as well as nine different paths, Routing & Switching, Design, Industrial Network, Network Security, Service Provider, Service Provider Operations, Storage Networking, Voice, <b>Datacenter</b> and Wireless.|$|E
25|$|On April 25, 2005, Microsoft {{released}} Windows XP Professional x64 Edition and Windows Server 2003, x64 Editions in Standard, Enterprise and <b>Datacenter</b> SKUs. Windows XP Professional x64 Edition is an {{edition of}} Windows XP for x86-64 personal computers. It {{is designed to}} use the expanded 64-bit memory address space provided by the x86-64 architecture.|$|E
5000|$|A {{geographically}} distributed, highly available clustered storage setup leveraging {{the virtual}} disk mirroring feature across <b>datacenters</b> within 300 km distance. Stretched Clusters can span 2, 3 or 4 <b>datacenters</b> (chain or ring topology, a 4-site cluster requiring 8 cluster nodes). Cluster consistency is ensured {{by a majority}} voting set.|$|R
5000|$|The {{head office}} {{and two of}} the main <b>datacenters</b> of {{independent}} internet provider BIT.|$|R
40|$|Invited Talk at ECOC 2015 Symposium: Optical Communications and Networks for <b>Datacenters.</b> The talk will {{revise the}} new {{research}} {{results on the}} use of the orbital angular momentum of light for increasing the capacity and the flexibility in nextgeneration <b>datacenters.</b> The new European project ROAM, focused on the development of innovative architectures and dedicated photonic integrated cuits, will be presented...|$|R
25|$|Shipping {{container}} architecture employs used shipping containers as {{the main}} framing of modular home designs, where the steel may be an integrated part of the design, or be camouflaged into a traditional looking home. They have also been used to make temporary shops, cafes, and computer datacenters, e.g., the Sun Modular <b>Datacenter.</b>|$|E
25|$|On 6 October 2009, {{one of the}} IP transit {{providers}} to The Pirate Bay blocked all Pirate Bay traffic causing an outage for most users around the world. The same day, the site was reportedly back online at an IP address at CyberBunker, located in the Netherlands. It is not known whether The Pirate Bay is actually located at CyberBunker or whether they are using the CyberBunker service that routes Cyberbunker IP addresses to any <b>datacenter</b> around the world. These routes are not visible to the outside world.|$|E
25|$|Though Facebook did {{not specify}} its India {{investment}} or hiring figures, it said recruitment had already begun for a director of operations and other key positions at Hyderabad, which would supplement its operations in California, Dublin in Ireland {{as well as at}} Austin, Texas. A custom-built data center with substantially reduced ("38% less") power consumption compared to existing Facebook data centers opened in April 2011 in Prineville, Oregon. In April 2012, Facebook opened a second data center in Forest City, North Carolina, US. In June 2013, Facebook opened a third data center in Luleå, Sweden. In November 2014, Facebook opened a fourth data center in Altoona, Iowa, US. In September 2016, Facebook announced a coming <b>datacenter</b> in Los Lunas, New Mexico in 2018 powered by renewable energy.|$|E
40|$|Cloud {{resource}} management {{has been a}} key factor for the cloud <b>datacenters</b> development. Many cloud <b>datacenters</b> have problems in understanding and implementing the techniques to manage, allocate and migrate the resources in their premises. The consequences of improper {{resource management}} may result into underutilized and wastage of resources which may also result into poor service delivery in these <b>datacenters.</b> Resources like, CPU, memory, Hard disk and servers need to be well identified and managed. In this Paper, Dynamic Resource Management Algorithm(DRMA) shall limit itself {{in the management of}} CPU and memory as the resources in cloud <b>datacenters.</b> The target is to save those resources which may be underutilized at a particular period of time. It can be achieved through Implementation of suitable algorithms. Here, Bin packing algorithm can be used whereby the best fit algorithm is deployed to obtain results and compared to select suitable algorithm for efficient use of resources. Comment: 8 pages, 4 figure...|$|R
40|$|Cloud {{subscribers}} {{would like}} to verify the location of outsourced data in the cloud <b>datacenters</b> to en-sure that the availability of data satisfies the Service Level Agreement. Cloud users may {{not have access to}} their outsourced data in the event of operational failures in <b>datacenters</b> or occurrence of natural disas-ters and/or power outages. Recently, IP geolocation techniques have been proposed to locate data files in cloud <b>datacenters.</b> However these techniques exploit relationships between Internet delays and distance and are not extensible to incorporate different net-work measurements, which may be used along with Internet delay to improve accuracy. Also, most of the existing techniques have only been validated with one cloud provider (Amazon Web Services). In this paper, we propose a classification based IP geoloca-tion algorithm, which incorporates multiple network measurements to improve the accuracy of geolocat-ing data files in <b>datacenters</b> in four commercial cloud providers. To demonstrate the accuracy of our ap-proach, we evaluate the performance on Amazon We...|$|R
50|$|A {{high-capacity}} bandwidth {{might be}} required for high-performance database replication among geographically different location <b>datacenters.</b>|$|R
500|$|Windows Server 2012 {{has four}} editions: Foundation, Essentials, Standard [...] and <b>Datacenter.</b>|$|E
500|$|Reviews of Windows Server 2012 {{have been}} {{generally}} positive. Simon Bisson of ZDNet {{described it as}} [...] "ready for the <b>datacenter,</b> today," [...] while Tim Anderson of The Register said that [...] "The move towards greater modularity, stronger automation and improved virtualisation makes perfect sense {{in a world of}} public and private clouds" [...] but remarked that [...] "That said, the capability of Windows to deliver obscure and time-consuming errors is unchanged" [...] and concluded that [...] "Nevertheless, this is a strong upgrade overall." ...|$|E
2500|$|Windows 2000 Professional, Server, Advanced Server and <b>Datacenter</b> editions ...|$|E
30|$|Geographic {{locations}} may be {{specified in}} various ways using GPS coordinates or country, city, and county names. For example, as of December 2016, AWS (Amazon Web Services) enables its clients to specify their data storage region according to a location list: for Europe region, <b>datacenters</b> in Ireland, Frankfurt, and London may be chosen, and for US, <b>datacenters</b> on East and West costs may be chosen.|$|R
40|$|Abstract — This work {{focuses on}} the load {{balancing}} problem for online service applications (which are response time-sensitive) considering a distributed cloud system comprised of geographically dispersed, heterogeneous <b>datacenters.</b> An offline solution based on force-directed scheduling is presented, which can determine the application placement {{for long periods of}} time. The solution is then extended to do online application placement and migration for geographically distributed <b>datacenters</b> based on predictions about the application lifetimes, workload intensities, dynamic energy prices, and renewable energy generation capacities at different <b>datacenters</b> in the cloud system. The simulation results demonstrate 27 % to 40 % improvement using the proposed algorithms with respect to the method that does not consider the geographical load balancing. I...|$|R
50|$|In June 2014, Sandisk {{acquired}} Fusion-io, {{a producer}} of flash memory for enterprise <b>datacenters,</b> for $1.1 billion.|$|R
2500|$|Released [...] "Lumension® Patch Manager <b>DataCenter</b> for Microsoft® System Center" ...|$|E
2500|$|The spinoffs and {{startups}} {{that were}} produced {{by these two}} companies led to the establishment in that area of the so-called Silicon Forest. The recession and dot-com bust of 2001 hit the region hard; many high technology employers {{reduced the number of}} their employees or went out of business. Open Source Development Labs made news in 2004 when they hired Linus Torvalds, developer of the Linux kernel. In 2010, biotechnology giant Genentech opened a $400-million facility in Hillsboro to expand its production capabilities. [...] Oregon is home to several large datacenters that take advantage of cheap power and a climate in Central Oregon conducive to reducing cooling costs. Google has a large <b>datacenter</b> in The Dalles and Facebook has built a large <b>datacenter</b> in Prineville. In 2011, Amazon began operating a <b>datacenter</b> in northeastern Oregon near Boardman.|$|E
2500|$|Hyper-V in Windows Server 2008 [...] {{does not}} support [...] "live migration" [...] of guest VMs (where [...] "live migration" [...] is defined as {{maintaining}} network connections and uninterrupted services during VM migration between physical hosts). [...] Instead, Hyper-V on Server 2008 Enterprise and <b>Datacenter</b> Editions supports [...] "quick migration", where a guest VM is suspended on one host and resumed on another host. [...] This operation happens {{in the time it}} takes to transfer the active memory of the guest VM over the network from the first host to the second host.|$|E
50|$|Metcom Network Services, <b>Datacenters</b> 10th {{floor and}} 23rd floor. Interconnect {{presence}} all floors including Roof and Basement.|$|R
5000|$|LSI Corporation, which designs {{semiconductors}} {{and software}} that accelerate storage and networking in <b>datacenters</b> and mobile networks ...|$|R
50|$|DLB Associates, the {{mechanical}} and electrical engineers {{for the majority}} of Google's <b>datacenters</b> worldwide, occupies the 26th floor.|$|R
