35|90|Public
5000|$|Although initial {{plans were}} for the Mars One {{selection}} committee to perform regional interviews around the world, applicants were ultimately remotely interviewed and recorded by Mars One over a relatively short Skype/SparkHire call regarding Martian-related orbital, temp/pressure, geological and <b>historical</b> <b>parameters</b> and the specific elements of the Mars One one-way mission. Dr. Joseph Roche, one of the finalists, has accused the selection process of being based on a point system that is primarily dependent on how much money each individual generated or gave to the Mars One organization, despite many of the round three selectees having not spent any money in the process, apart from the application fee, which varied {{as a function of}} each applicant's country GDP. Lansdorp acknowledges a [...] "gamification" [...] point system but denies that selection is based on money earned. Roche also stated that if paid for interviews, they are asked to donate 75% of the payment to Mars One. This was confirmed by Lansdorp.|$|E
50|$|The Palau de Pedralbes and by {{extension}} the Royal Chambers which include Alfonso XIII's bedroom, and Victoria Eugenia's waiting room and chamber, were constructed between 1919 and 1924. The architects Eusebi Bona and Francesc de Paula Nebot were commissioned to build this home for the King and his family during their brief and sporadic visits to Barcelona. Alfons XIII's chamber, and the waiting room and chamber of Victòria Eugènia, {{were added to the}} itinerary of the Museu de les Arts Decoratives exhibit {{after the fall of the}} monarchy, when the Royal residence first opened its doors in 1932. The public was now able to view the three chambers which had been left in their original conditions in regards to wall murals and furniture, by the former occupants who had been sent into exile. Despite all of the political changes that the building has passed through, (monarchy, republic, civil war, dictatorship, monarchy) that could have led to changes in the construction of the Palau de Pedralbes, the Royal chambers have been preserved almost completely in their original state. The spaces, decorated by King Alfons XIII and his wife Queen Victòria Eugènia in their own personal styles and using their own financial resources, still carry the stamp of their former occupants. During the 1920s, the winds of modernity arrived in Barcelona with Mies Van der Rohe's Barcelona Pavilion at the 1929 Barcelona International Exposition. The King visited the exhibit and was honoured with a personal tour by the architect himself. Despite these new influences, the decoration of the Royal chambers, which was harmonious with some very interesting furnishings, was conceived using clear <b>historical</b> <b>parameters</b> under the direction of a conservative aristocrat anchored in the past.|$|E
30|$|Demographic {{history is}} the {{population}} events in the past, while the genetic diversity data available is contemporary. Therefore, one has to find out proper estimation of <b>historical</b> <b>parameters</b> which give the best fit to the present polymorphism dataset. Several alternative statistical inference procedures {{could be used for}} these purposes as discussed below. Here we discuss maximum likelihood method and Bayesian approximation method. We also discuss some about Markov Chain Mento Carlo (MCMC) method, which is widely used in Bayesian computation.|$|E
5000|$|... #Caption: Map of {{the average}} {{temperature}} over 30 years. Data sets formed from the long-term average of <b>historical</b> weather <b>parameters</b> are sometimes called a [...] "climatology".|$|R
40|$|Method {{and system}} for {{analyzing}} and displaying {{one or more}} present flight parameter values (FP(t) of an aircraft in motion at a measurement time t(sub n), and for comparing the present flight parameter value with a selected percentage band, containing <b>historical</b> flight <b>parameter</b> data for similar conditions...|$|R
40|$|The {{purpose of}} this paper is threefold. First, we use ML-techniques to {{estimate}} a Poissontype jump diffusion model that describes the return behavior of actively traded German stocks and the DAX stock index as a proxy of aggregate wealth, respectively. We find that jump risk is statistically significant and systematic. Second, we compute option values according to Merton's idiosyncratic jump risk model and the more recent systematic jump risk model and compare them with Black/Scholes values. Using a comprehensive sample of stock options traded at the Frankfurt Options Market between April 1983 and June 1990 and at the Deutsche Terminb orse between January 1990 and December 1991, respectively, we find only in post-crash periods economically significant differences between Black/Scholes and systematic jump risk option values when using <b>historical</b> <b>parameter</b> estimates. Third, we take the systematic jump risk model to infer the implicit stock price distributions from observed option price [...] ...|$|R
40|$|Brazilian historiography, {{regarding}} {{the phenomenon of}} tourism and hospitality is still extremely scarce, because, it uses <b>historical</b> <b>parameters</b> determined by the logic of an ethnocentric vision. In {{order to try to}} change such understanding, we are developing studies on writings of the foreign writers from XVI to XIX century, who for several causes came to Brazil to live, work, research or for a visit, and decided to document their stay among us. We began with George Gardner, a Scottish naturalist that came to Brazil in 1836 and stayed up to 1941. Back in England in 1846 he wrote the book: Travels in the Interior of Brazil, mainly in the provinces of the North, and in the gold and diamond regions during the years of 1836 - 1841...|$|E
30|$|For {{the above}} {{mechanisms}} {{to work as}} anything beyond epidemic/viral routing [33], the nodes need to have certain degree of spatial and temporal locality in their mobility and meeting patterns. A notable DTN routing scheme in the literature is PROPHET [17] which {{is an extension of}} epidemic routing [29]. PROPHET develops a probabilistic framework for capturing the spatiotemporal locality present in the node mobility pattern within a dynamically partitioned wireless network. PROPHET can be implemented either in single copy or in multicope mode. Node interaction localities can be also captured in the form a per-link utility as detailed in [18, 19]. The link utility can be formulated as its age [19 – 21], formation frequency [19], and other <b>historical</b> <b>parameters</b> that can effectively capture the nodes' interaction localities.|$|E
40|$|Some {{aspects of}} signal {{extraction}} {{in a microwave}} search for evidence of extraterrestrial intelligence are examined. Parametric relations are summarized which are applicable to a microwave search of constrained duration that employs FFT spectrum-analyzer receivers, with sensitivity enhancement by spectrum accumulation and detection by a threshold criterion. Three types of natural and man-made false alarms are identified, the probability of false alarm in a single data channel is computed, {{and the implications of}} false alarms for a constant-beamwidth sky survey are considered. It is shown that the key to an efficient search is the prompt and unambiguous elimination of false alarms. An experimental protocol is suggested which eliminates spurious signals primarily through procedural techniques involving antenna repointing, delayed repeated observations, and storage of particular <b>historical</b> <b>parameters</b> for suspect signals...|$|E
40|$|International audienceWe {{propose a}} new {{sequential}} procedure to detect {{change in the}} parameters of a process X= (X_t) _t∈ belonging to a large class of causal models (such as AR(∞), ARCH(∞), TARCH(∞), ARMA-GARCH processes). The procedure {{is based on a}} difference between the <b>historical</b> <b>parameter</b> estimator and the updated parameter estimator, where both these estimators are based on a quasi-likelihood of the model. Unlike classical recursive fluctuation test, the updated estimator is computed without the historical observations. The asymptotic behavior of the test is studied and the consistency in power as well as an upper bound of the detection delay are obtained. Some simulation results are reported with comparisons to some other existing procedures exhibiting the accuracy of our new procedure. The procedure is also applied to the daily closing values of the Nikkei 225, S&P 500 and FTSE 100 stock index. We show in this real-data applications how the procedure can be used to solve off-line multiple breaks detection...|$|R
40|$|In meta-analysis, {{independently}} executed historical {{studies are}} viewed as imperfect replications of one overall but unplanned experiment. Using empirical parameter estimates of those studies as a unit of analysis, a linear modal is specified to uncover systematic variation {{as a function of}} study design, data characteristics, model specification, etc. Because of the fallible nature of the historical studies, however, the vector of parameter estimates reflects cross-sectional estimation biases as well as inefficiencies, The out come of many meta-analyses, therefore, is largely a description of those systematic biases and inefficiencies, a result with little intrinsic scientific value given the fundamental meta-analysis objective of improving understanding of the studied phenomenon. Unfortunately, estimating more scientifically interesting effects on the basis of systematic variation in <b>historical</b> <b>parameter</b> estimates is conditional on the fallible character of the historical studies. This paper provides clarity on what is being estimated in meta-analyses and on how scientifically interesting effects can be estimated unbiasedly using response surface extrapolation in a least squares framework...|$|R
40|$|We {{propose a}} new {{sequential}} procedure to detect {{change in the}} parameters of a process X= (X_t) _t∈ belonging to a large class of causal models (such as AR(∞), ARCH(∞), TARCH(∞), ARMA-GARCH processes). The procedure {{is based on a}} difference between the <b>historical</b> <b>parameter</b> estimator and the updated parameter estimator, where both these estimators are based on a quasi-likelihood of the model. Unlike classical recursive fluctuation test, the updated estimator is computed without the historical observations. The asymptotic behavior of the test is studied and the consistency in power as well as an upper bound of the detection delay are obtained. Some simulation results are reported with comparisons to some other existing procedures exhibiting the accuracy of our new procedure. The procedure is also applied to the daily closing values of the Nikkei 225, S&P 500 and FTSE 100 stock index. We show in this real-data applications how the procedure can be used to solve off-line multiple breaks detection. Comment: arXiv admin note: text overlap with arXiv: 1101. 5960 by other author...|$|R
40|$|This review {{centers on}} the status, and future {{directions}} of the cell and module technologies, with emphasis on {{the research and development}} aspects. The framework is established with a consideration of the <b>historical</b> <b>parameters</b> of photovoltaics and each particular technology approach. The problems and strengths of the single-crystal, polycrystalline, and amorphous technologies are discussed, compared, and assessed. Single- and multiple junction or tandem cell configurations are evaluated for performance, processing, and engineering criteria. Thin-film technologies are highlighted as emerging, low-cost options for terrestrial applications and markets. Discussions focus on the fundamental building block for the photovoltaic system, the solar cell, but important module developments and issues are cited. Future research and technology directions are examined, including issues that are considered important {{for the development of the}} specific materials, cell, and module approaches. Novel technologies and new research areas are surveyed as potential photovoltaic options of the future. ...|$|E
40|$|Coalescent {{genealogy}} samplers {{are effective}} tools {{for the study}} of population genetics. They are used to estimate the <b>historical</b> <b>parameters</b> of a population based upon the sampling of present-day genetic information. A popular approach employs Markov chain Monte Carlo (MCMC) methods. While effective, these methods are very computationally intensive, often taking weeks to run. Although {{attempts have been made to}} leverage parallelism in an effort to reduce runtimes, they have not resulted in scalable solutions. Due to the inherently sequential nature of MCMC methods, their performance has suffered diminishing returns when applied to large-scale computing clusters. In the interests of reduced runtimes and higher quality solutions, a more sophisticated form of parallelism is required. This paper describes a novel way to apply a recently discovered generalization of MCMC for this purpose. The new approach exploits the multiple-proposal mechanism of the generalized method to enable the desired scalable parallelism while maintaining the accuracy of the original technique. ...|$|E
40|$|In {{recent years}} {{domestic}} natural gas {{has experienced a}} considerable growth in demand particularly in the power generation industry. However, the desire for energy security, lower fuel costs {{and a reduction in}} carbon emissions has produced an increase in demand for alternative fuel sources. Current strategies for reducing the environmental impact of natural gas combustion in gas turbine engines used for power generation experience such hurdles as flashback, lean blow-off and combustion dynamics. These issues will continue as turbines are presented with coal syngas, gasified coal, biomass, LNG and high hydrogen content fuels. As it may be impractical to physically test a given turbine on all of the possible fuel blends it may experience over its life cycle, the need to predict fuel interchangeability becomes imperative. This study considers a number of <b>historical</b> <b>parameters</b> typically used to determine fuel interchangeability. Also addressed is the need for improved reaction mechanisms capable of accurately modeling the combustion of natural gas alternatives...|$|E
40|$|The spatial {{distribution}} {{and the amount}} of intraspecific genetic variation of marine organisms are strongly influenced by many biotic and abiotic factors. Comparing biological and genetic data characterizing species living in the same habitat can help to elucidate the processes driving these variation patterns. Here, we present a comparative multispecies population genetic study on seven mangrove crabs co-occurring in the West Indian Ocean characterized by planktotrophic larvae with similar pelagic larval duration. Our main aim was to investigate whether a suite of biological, behavioural and ecological traits could affect genetic diversities of the study species in combination with <b>historical</b> demographic <b>parameters.</b> As possible current explanatory factors, we used the intertidal micro-habitat colonised by adult populations, various parameters of individual and population fecundity, and the timing of larval release. As the genetic marker, we used partial sequences of cytochrome oxidase subunit I gene. Genetic and ecological data were collected by the authors and/or gathered from primary literature. Permutational multiple regression models and ANOVA tests showed that species density and their reproductive output in combination with <b>historical</b> demographic <b>parameters</b> could explain the intraspecific genetic variation indexes across the seven species. In particular, species producing consistently less eggs per spawning event showed higher values of haplotype diversity. Moreover, Tajima's D parameters well explained the recorded values for haplotype diversity and average γst. We concluded that current intraspecific gene diversities in crabs inhabiting mangrove forests were affected by population fecundity as well as past demographic history. The results were also discussed in terms of management and conservation of fauna in the Western Indian Ocean mangroves...|$|R
40|$|The rapid {{increase}} of wealth inequality {{in the past}} few decades is one of the most disturbing social and economic issues of our time. Studying its origin and underlying mechanisms is essential for policy aiming to control and even reverse this trend. In that context, controlling the distribution of income, using income tax or other macroeconomic policy instruments, is generally perceived as effective for regulating the wealth distribution. We provide a theoretical tool, based on the realistic modeling of wealth inequality dynamics, to describe the effects of personal savings and income distribution on wealth inequality. Our theoretical approach incorporates coupled equations, solved using iterated maps to model the dynamics of wealth and income inequality. Notably, using the appropriate <b>historical</b> <b>parameter</b> values we were able to capture the historical dynamics of wealth inequality in the United States during the course of the 20 th century. It is found that the effect of personal savings on wealth inequality is substantial, and its major decrease in the past 30 years can be associated with the current wealth inequality surge. In addition, the effect of increasing income tax, though naturally contributing to lowering income inequality, might contribute to a mild increase in wealth inequality and vice versa. Plausible changes in income tax are found to have an insignificant effect on wealth inequality, in practice. In addition, controlling the income inequality, by progressive taxation, for example, is found to have a very small effect on wealth inequality in the short run. The results imply, therefore, that controlling income inequality is an impractical tool for regulating wealth inequality...|$|R
40|$|In {{this paper}} we explore ways that {{alleviate}} problems of nonparametric (artificial neural networks) and parametric option pricing models by combining the two. The resulting enhanced network model is compared to standard artificial neural networks and to parametric models with several <b>historical</b> and implied <b>parameters.</b> Empirical results using S&P 500 index call options strongly support our approach. Option pricing, implied volatilities, implied parameters, artificial neural networks, optimization...|$|R
40|$|This thesis {{will examine}} the problem of dead and dying churches in the Southern Baptist Convention. Membership in more than seventy-percent of churches in North America has {{plateaued}} or is declining according to the North American Mission Board. Rather than just starting new churches, this thesis will present an option to revitalize dead and dying churches in order to reverse this trend. The aim of this thesis is to promote the historical Southern Baptists plan which will help Southern Baptists regain <b>historical</b> <b>parameters</b> and goals when revitalizing dead or dying churches. The thesis will cite existing quantitative and qualitative data, and biblical sources. Pastors, denominational leaders, and a congregation who {{have been involved in}} revitalizing churches will be surveyed and interviewed to gather their recommendations, pitfalls to avoid and strategies to employ. The thesis will conclude with a plan to be presented to pastors and other denominational leaders to encourage them to consider investing in established churches...|$|E
40|$|Since the 1990 s, the Indigenous {{movement}} worldwide {{has become}} increasingly relevant to research in India, re-shaping the terms of engagement with Adivasi (Indigenous/tribal) peoples and their pasts. This book responds to the growing need for an inter-disciplinary re-assessment of Tribal studies in postcolonial India and defines a new agenda for Adivasi studies. It considers the existing conceptual and <b>historical</b> <b>parameters</b> of Tribal studies, {{as a means of}} addressing new approaches to histories of de-colonization and patterns of identity-formation that have become visible since national independence. Contributors address a number of important concerns, including the meaning of Indigenous studies in the context of globalised academic and political imaginaries, and the possibilities and pitfalls of constructions of indigeneity as both a foundational and a relational concept. A series of short editorial essays provide theoretical clarity to issues of representation, resistance, agency, recognition and marginality. The book is an essential read for students and scholars of Indian Sociology, Anthropology, History, Cultural Studies and Indigenous studies...|$|E
40|$|Adult and non-formal {{education}} {{is an integral}} component of poverty reduction, {{it has the potential}} of enabling creative and democratic citizenship, giving voice to women and men living in poverty as well as providing tools for improving their lives. The paper examined the concepts of adults using chronological, biological, cultural and <b>historical</b> <b>parameters</b> and as well as adult and {{non-formal education}} by different scholars. The paper also explored adult and non-formal education in the global context like the Dakar framework of action, the focus on gender equality, women and problems of HIV/AIDS pandemic and United Nations Literacy Decade amongst others. The paper went ahead and examined some international agencies in adult and non-formal education like UNICEF, UNDP, UNESCO, IZZDVV, amongst others and it is a position paper that finally suggests that developing countries should increase budgetary allocations to adult and non-formal education, there should be effective monitoring and evaluation by agencies in order to ascertain whether the objectives are achieved or not and global advocacy on support in adult and non-formal education should be ensured towards the attainment o...|$|E
40|$|BACKGROUND: Estimating the <b>historical</b> and {{demographic}} <b>parameters</b> that characterize modern human populations {{is a fundamental}} part of reconstructing {{the recent history of}} our species. In addition, the development of a model of human evolution that can best explain neutral genetic diversity is required to identify confidently regions of the human genome that have been targeted by natural selection. METHODOLOGY/PRINCIPAL FINDINGS: We have resequenced 20 independent noncoding autosomal regions dispersed throughout the genome in 213 individuals from different continental populations, corresponding to a total of approximately 6 Mb of diploid resequencing data. We used these data to explore and co-estimate an extensive range of <b>historical</b> {{and demographic}} <b>parameters</b> with a statistical framework that combines the evaluation of multiple models of human evolution via a best-fit approach, followed by an Approximate Bayesian Computation (ABC) analysis. From a methodological standpoint, evaluating the accuracy of the parameter co-estimation allowed us to identify the most accurate set of statistics to be used for the estimation of each of the different <b>historical</b> and demographic <b>parameters</b> characterizing recent human evolution. CONCLUSIONS/SIGNIFICANCE: Our results support a model in which modern humans left Africa through a single major dispersal event occurring approximately 60, 000 years ago, corresponding to a drastic reduction of approximately 5 times the effective population size of the ancestral African population of approximately 13, 800 individuals. Subsequently, the ancestors of modern Europeans and East Asians diverged much later, approximately 22, 500 years ago, from the population of ancestral migrants. This late diversification of Eurasians after the African exodus points to the occurrence of a long maturation phase in which the ancestral Eurasian population was not yet diversified...|$|R
50|$|The {{study of}} postmarks is a {{specialized}} branch of philately called marcophily. It may bring added {{value to the}} stamps by their <b>historical</b> significance. Other <b>parameters</b> are the rarity and the attractiveness. In particular, the stamps issued by the Empire of Austria during the 1850-1867 period (the 5 issues before the Austro-Hungarian compromise of 1867), are collected for their variety and beauty. More details {{can be found in}} Valuation of cancellations of the Austrian Empire.|$|R
40|$|The lecture was {{presented}} April 7, 1987. This presentation {{centered on the}} flute music literature used for the Concours of the Conservatoire de Paris from 1828 through 1893. The <b>historical</b> <b>parameter</b> began with Jean-Louis Tulou's tenure as flute professor at the Conservatoire and ended with Joseph-Henri Altes'tenure in the same capacity. The Concours is an annual performance competition to determine which students on each instrument will graduate from the Conservatoire. The majority of Concours pieces for flute during the tenures of professors from Tulou through Altes were composed by those two men. Short biographies of Tulou and Altes were presented. Discussion of interim professors Victor Coche and Vincent-Joseph Dorus was included, with focus {{on the role of}} these two men in bringing acceptance of the Boehm system flute to the Conservatoire. Tulou's fifteen Grands Solos were compared in form, key center and tonal progression. His themes and passagework are constructed to best display the conical-bore, old system-flute with small toneholes. His Solos continued to be used for the Concours, in alternation with Altes', throughout the tenures of both Vincent-Joseph Dorus and Altes. Tulou's Cinquieme Grand Solo was used for more detailed analysis and performance. Altes wrote his Solos de Concours for the Boehm system flute. Idiomatic treatment in composition of themes and passagework, as well as tonal progression in his Solos, was considered. Altes' Methode de flute reveals his views on variety in articulation, use of alternate fingerings, and musical interpretation. Those ideas are reflected in the construction of his Cinquieme Solo de ronrnwr. the example used for more detailed analysis and performance. The discussion was concluded by a comparison of the Solos of Tulou and Altes with regard to form, tonal progression, and idiomatic construction of themes and passagework...|$|R
40|$|The {{analysis}} of genetic variation to estimate demographic and <b>historical</b> <b>parameters</b> and to quantitatively compare alternative scenarios recently gained {{a powerful and}} flexible approach: the Approximate Bayesian Computation (ABC). The likelihood functions {{does not need to}} be theoretically specified, but posterior distributions can be approximated by simulation even assuming very complex population models including both natural and human-induced processes. Prior information can be easily incorporated and the quality of the results can be analysed with rather limited additional effort. ABC is not a statistical analysis per se, but rather a statistical framework and any specific application is a sort of hybrid between a simulation and a data-analysis study. Complete software packages performing the necessary steps under a set of models and for specific genetic markers are already available, but the flexibility of the method is better exploited combining different programs. Many questions relevant in ecology can be addressed using ABC, but adequate amount of time should be dedicated to decide among alternative options and to evaluate the results. In this paper we will describe and critically comment on the different steps of an ABC analysis, analyse some of the published applications of ABC and provide user guidelines...|$|E
40|$|In 1561 the Italian {{military}} engineer Juan Bautista Antonelli {{was commissioned}} by the Hispanic Monarchy for survey of the coast {{in the kingdom of}} Valencia. On that trip he made an extensive report on the mountain Bernia considered the soft underbelly against an expected invasion of the Turkish Army coordinated with the population of the Valencian Moorish. Therefore it identified the need to build a fortress on Bernia. In April 1562, its construction began. They emerged unfavorable opinions both for its location as the excessive cost of maintenance in relation to its little effect on the defense of the Valencian coast. Nevertheless Philip II always maintained the need for its existence. With the expulsion of the Valencian Moorish in 1609 the fortress lost its function and in 1612 its demolition was ordered. In the speech J. B. Antonelli for Bernia lies a thorough analysis of this mountain and its environment, which rationalizes the different physical, human and <b>historical</b> <b>parameters</b> for a comprehensive understanding of the territory and determine the optimal solution to their defense. It starts thus also from the military art, the modern conception of territorial planning...|$|E
30|$|Where {{community}} reference databases {{are already}} in place, all resulting data should be submitted to these. We see data sharing as a critical tool for furthering research, especially {{this kind of work}} that does not respect current national boundaries. Indeed, one priority for future work aimed at elucidating the relationship between volcanic events and the human past is the establishment of complementary databases on the societal and economic characteristics of the affected groups. Both disaster scientists and volcanologists have assembled sizable databases of volcanic eruptions as well as their impacts in recent times [4, 5, 162, 163]. No such databases exist for deeper historical let alone prehistoric times. If, however, the aim is to not only examine volcanic eruptions and their attendant tephra distributions as purely chronological tools, but also to consider the impacts of such events on the affected societies themselves, these databases must be structured around the societies themselves, not the eruption events. This is so, because (a) the effects of eruptions differ markedly in the near- and far-field [164], and (b) because the vulnerability that transforms an initially neutral geological event into a catastrophe is a complex, multivariate measure that is grounded at least as much in the social and <b>historical</b> <b>parameters</b> of the affected communities as in the geophysical parameters of a given event [165 – 167]. The finding and secure geochemical identification of a given tephra layer is a critical but merely an initial step.|$|E
5000|$|... "The source {{level of}} an {{individual}} projector is 215 dB. These projectors produce the active sonar signal or “ping.” A [...] "ping," [...] or transmission, can last between 6 and 100 seconds. The time between transmissions is typically 6 to 15 minutes with an average transmission of 60 seconds. Average duty cycle (ratio of sound “on” time to total time) is less than 20 percent. The typical duty cycle, based on <b>historical</b> LFA operational <b>parameters</b> (2003 to 2007), is normally 7.5 to 10 percent." ...|$|R
40|$|This study {{examines}} {{the accuracy of}} various time series models in forecasting daily levels of occupancy. A reservation data set of 3 hotels that include over 3450 booking curves is {{used to test the}} performance of five models in forecasting occupancy levels up to 99 days in advance. Three traditional forecasting models are compared to two new methods. The 3 benchmark models include a Stepwise Autoregression model, a High Order Polynomial model and a linear combination of their prediction. The two new methods focus on the shape of the booking curves. The first identifies the time series process of the fitted <b>historical</b> curves <b>parameters,</b> and the second applies a dissimilarity measure to identify similar curves. The results indicate that accuracy can be improved by incorporating information on the shape of past booking curves. The curve similarity model is significantly more accurate {{than the rest of the}} models that were tested. ...|$|R
40|$|One of the {{problems}} in the quality improvement is variability monitoring, in such a way so it remains on the threshold. The main problem in the implementation of process variability monitoring is the parameter estimation before the process production is run.. In the short run process or long run process on start up stage the problem is difficult to handle. This paper discusses an approach, which enables to do the process variability monitoring for short or long run processes, without <b>historical</b> data for <b>parameter</b> estimation. An illustration of comparison clarifies the mechanism of our discussion...|$|R
40|$|The Mediterranean {{fruit fly}} (Ceratitis capitata) is an {{invasive}} agricultural pest {{with a wide}} host range and a nearly global distribution. Efforts to forgo the medfly 2 ̆ 72 ̆ 7 s spread into the United States are dependent on an understanding of population dynamics in newly established populations elsewhere. To explore the potential influence of demographic and <b>historical</b> <b>parameters</b> in six medfly populations distributed from Mexico to Peru, we created population genetic null models using Monte Carlo simulations. Null expectations for genetic differentiation (F ST) were compared with actual sequence variation from four highly polymorphic nuclear loci. Four colonization scenarios that were modeled led to unique genetic signatures {{that could be used}} to interpret empirical data. Unless current gene flow across Latin America was assumed to be very high, we could reject colonizations consisting of multiple introductions, each of low genetic diversity. Further, if simulated populations were small (N e = 5 × 102 individuals per population), small invasions from a single source consistently produced F ST values comparable to those currently observed in Latin America. In contrast, only large invasions from diverse sources were compatible with the observed data for large populations (N e 5 × 103). This study demonstrates that alternative population genetic hypotheses can be tested empirically even when departures from equilibrium are extreme, and that population genetic theory can be used to explore the processes that underlie biological invasions...|$|E
40|$|AbstractScatter {{of fatigue}} {{life of a}} fleet is mainly caused by the {{variability}} in structures and load spectra. To ensure the safety in service, the probabilistic characterization of load spectrum variability should be researched in durability analysis and testing work. This paper investigates the variability of load damage rate of a fleet. Based on the flight <b>historical</b> <b>parameters</b> measured by individual aircraft tracking (IAT) from hundreds of aircrafts for {{a certain type of}} fighter in China, SWT formula and linear damage rule are used to evaluate the load damage, and then, one average and four other individual load spectra are selected corresponding to different damage severities. Fatigue tests are conducted with the Aluminum alloy 7 B 04 -T 74 specimens under five spectra and the Titanium alloy TA 15 M specimens under three of them. The engineering crack initiation lives are measured and the mean lives are estimated assuming the fatigue life following a log-normal distribution. An obvious difference of at least 2. 4 times in the load damage rates is found in the fleet. The fatigue lives of a fleet of aircrafts are calculated by Neuber’s approach, and the probabilities refer to damage severities of those 5 load spectra in a fleet are evaluated. The statistical analysis of the fatigue lives and the probabilities shows that a lognormal distribution can be used to describe the variability of load damage rate of a fleet. The variation of the load damage rate is in the same order of magnitude with that in structural properties...|$|E
40|$|Computer {{simulations}} of genetic data are increasingly used {{to investigate the}} impact of complex historical scenarios on patterns of genetic variation. Yet, in most empirical studies, relatively large portions of species ranges are often treated as panmictic populations, ignoring the underlying spatial context. In some cases, however, a more accurate spatial model is required. We use a spatially explicit model of coalescence (easily constructed by overlaying a two-dimensional grid on maps displaying an estimate of past and current species ranges) to evaluate the potential of several summary statistics to differentiate three typical phylogeographic scenarios. We first explore the variation of each summary statistic {{within the boundaries of}} each phylogeographic scenario, and identify those that appear most promising for a comparison of historical scenarios and/or to infer <b>historical</b> <b>parameters.</b> We then combine a selected set of summary statistics in a single chi-square statistic and evaluate whether {{it can be used to}} differentiate past geographic fragmentation or range expansion from a simple scenario of isolation by distance. We also investigate the benefits of using a spatially explicit model by comparing its performance to alternative models that are less spatially explicit (lower geographic resolution). The results identify conditions in which each summary statistic is useful to infer the evolution of a species range, and allow us to validate our spatially explicit model of coalescence and our procedure to compare simulated and observed sequence data. We also provide a detailed description of the spatially explicit model of coalescence used, which is currently lacking. Key words: DNA sequences, coalescence simulations, phylogeography, summary statistics, PHYLOGEOSIM 1. 0...|$|E
40|$|Adaptive {{divergence}} in coloration {{is expected}} to produce reproductive isolation in species that use colourful signals in mate choice and species recognition. Indeed, many adaptive radiations are characterized by differentiation in colourful signals, suggesting that divergent selection acting on coloration {{may be an important}} component of specia-tion. Populations in the Anolis marmoratus species complex from the Caribbean island of Guadeloupe display striking divergence in the colour and pattern of adult males that occurs over small geographic distances, suggesting strong divergent selection. Here we test the hypothesis that divergence in coloration results in reduced gene flow among populations. We quantify variation in adult male coloration across a habitat gradient between mesic and xeric habitats, use a multilocus coalescent approach to infer <b>historical</b> demographic <b>parameters</b> of divergence, and examine gene flow and population structure using microsatellite variation. We find that colour variation evolved without geographic isolation and in the face of gene flow, consistent with strong divergent selection and that both ecological and sexual selection are implicated...|$|R
40|$|An {{important}} and frequently studied question for retirees is: {{what is the}} optimal asset allocation during retirement? This article provides a brief but simple message that conservative asset allocations in retirement are quite acceptable after all. A wide range of asset allocations tend to provide very similar results in terms of sustainable withdrawal rates for given probabilities of failure. For example, with Monte Carlo simulations based on <b>historical</b> data <b>parameters,</b> a 4. 4 percent withdrawal rate for a 30 -year horizon could be supported with a 10 percent chance of failure using a 50 / 50 asset allocation of stocks and bonds. But the range of stock allocations supporting a withdrawal rate within 0. 1 percentage points of this maximum extend from 27 to 87 percent. Though asset allocation will also impact the amount which can be left as bequests, {{it is the case}} that relatively low stock allocations can support retirees just as well for a given failure rate and retirement duration. ...|$|R
40|$|High-Definition Television {{promises}} {{to be the next}} generation of television. This technology has broad implications for consumer markets, as well as the underlying manufacturing, technology development, and R&D activities of firms. Under increasing pressure from various groups, the U. S. government must make major policy and funding decisions based on its assessment of the likely demand for HDTV. Three published reports which forecast sales of HDTV after its scheduled introduction in the mid- 1990 s are available. Unfortunately, these forecasts offer widely differing perspectives on HDTV's potential. This paper presents an approach that links product segmentation (based on <b>historical</b> demand <b>parameters,</b> and marketing and manufacturing related variables) and demand forecasting for new products. The published HDTV forecasts are then assessed using this segmentation scheme. Differing from the Congressional Budget Office's earlier evaluation, this analysis indicates that one report is consistent with historical data from the home appliance industry. technology policy, consumer electronics, marketing, manufacturing...|$|R
