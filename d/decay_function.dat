440|1276|Public
50|$|In the {{exponential}} <b>decay</b> <b>function,</b> {{it approaches}} zero more quickly as x increases, and a is a constant(usually between 3-9) and c is a counter. For the negated-translated sigmoid function, the decay {{is similar to}} the exponential <b>decay</b> <b>function</b> when a is greater than 4.|$|E
5000|$|In general, a link will be {{established}} with a probability {{depending on the}} distance [...] A connectivity <b>decay</b> <b>function</b> [...] represents the probability of assigning an edge {{to a pair of}} nodes at distance [...] In this framework, the simple case of hard-code neighborhood like in random geometric graphs is referred to as truncation <b>decay</b> <b>function.</b>|$|E
5000|$|... where [...] is the {{stimulus}} <b>decay</b> <b>function,</b> [...] and [...] are respectively the connectivity coefficient giving {{the average number}} of excitatory and inhibitory synapses per cell, P(t) is the external input to the excitatory population.|$|E
3000|$|To {{exhibit the}} {{effectiveness}} of the proposal TEI, the AE, and AD algorithms are tested by various combinations, which are the TEI only, the ‘TEI[*]+[*]AE,’ and the ‘TEI[*]+[*]AE[*]+[*]AD’. For AE and AD algorithms, we suggest two <b>decay</b> <b>functions.</b> For the kth iteration, the linear <b>decaying</b> <b>function</b> is given as α [...]...|$|R
2500|$|An {{important}} {{category of}} exponentially <b>decaying</b> <b>functions</b> {{is that of}} Gaussian functions ...|$|R
40|$|Three-body <b>decay</b> <b>functions</b> in time-like parton {{branching}} {{are calculated}} using the jet calculus to the next-to-leading logarithmic (NLL) order in perturbative quantum chromodynamics (QCD). The phase space contributions {{from each of}} the ladder diagrams and interference diagrams are presented. We correct part of the results for the three-body <b>decay</b> <b>functions</b> calculated previously by two groups. Employing our new results, the properties of the three-body <b>decay</b> <b>functions</b> in the regions of soft partons are examined numerically. Furthermore, we examine the contribution of the three-body <b>decay</b> <b>functions</b> modified by the restriction resulting from the kinematical boundary of the phase space for two-body decay in the parton shower model. This restriction leads to some problems for the parton shower model. For this reason, we propose a new restriction introduced by the kinematical boundary of the phase space for two-body decay. Comment: 33 pages, PTPTeX. sty, 16 Postscript eps figures; To be published in Progress of Theoretical Physic...|$|R
50|$|The {{instrumental}} {{response of}} the source, detector, and electronics can be measured, usually from scattered excitation light. Recovering the <b>decay</b> <b>function</b> (and corresponding lifetimes) poses additional challenges as division in the frequency domain tends to produce high noise when the denominator is close to zero.|$|E
5000|$|The memory-based Yule-Simon (MBYS) {{model of}} Cattuto {{attempted}} to explain tag choices by a stochastic process. They {{found that the}} temporal order of tag assignment influences users' tag choices. Similar to the stochastic urn model, the MBYS model assumed that at each time step a tag would be randomly sampled: with probability p the sampled tag was new, and with probability 1-p the sampled tag was copied from existing tags. When copying, the probability of selecting a tag was assumed to decay with time, and this <b>decay</b> <b>function</b> was found to follow a power law distribution. Thus, tags that were recently used had a higher probability of being reused than those used in the past. One major finding by Cattuto et al. was that semantically general tags (e.g., [...] "blog") tended to co-occur more frequently with other tags than semantically narrower tags (e.g., [...] "ajax"), and this difference could be captured by the <b>decay</b> <b>function</b> of tag reuse in their model. Specifically, they found that a slower decay parameter (when the tag is reused more often) could explain the phenomenon that semantically general tags tended to co-occur with a larger set of tags. In other words, they argued that the [...] "semantic breadth" [...] of a tag could be modeled by a memory <b>decay</b> <b>function,</b> {{which could lead to}} different emergent behavioral patterns in a tagging system.|$|E
50|$|Still {{other systems}} choose a middle ground, {{reducing}} the marginal value of additional points as {{the margin of}} victory increases. Sagarin chose to clamp the margin of victory to a predetermined amount. Other approaches {{include the use of}} a <b>decay</b> <b>function,</b> such as a logarithm or placement on a cumulative distribution function.|$|E
30|$|Overall, for the <b>decay</b> <b>functions</b> φ {{used in our}} experiments, {{the time}} {{complexity}} of our method is identical to that of time decayed degree. In the special case of φ= 1, our time complexity is {{equal to that of}} static degree, while for other <b>decay</b> <b>functions,</b> we can bring the running time very close to static degree by applying heuristics to find the maximum of a product (Teflioudi et al. 2015).|$|R
50|$|The {{ground state}} {{electronic}} density of an atom is conjectured to be a monotonically <b>decaying</b> <b>function</b> {{of the distance}} from the nucleus.|$|R
40|$|Three-body <b>decay</b> <b>functions</b> in space-like parton {{branches}} {{are implemented}} to evaluate transverse-momentum-dependent (TMD) parton distribution {{functions in the}} next-to-leading logarithmic (NLL) order of quantum chromodynamics (QCD). Interference contributions due to the next-to-leading order contribution {{are taken into account}} for the evaluation of the transverse momenta in initial state parton radiations. Some properties of the <b>decay</b> <b>functions</b> are also examined. As an example, we compare our results with an algorithm proposed in Ref. 1), in which a transverse momentum distributions are evaluated at the last step of parton evolutions. Comment: 11 pages, 4 figure...|$|R
5000|$|This {{is similar}} in {{appearance}} to an Exponential <b>decay</b> <b>function,</b> and is almost always used for a decreasing performance metric, such as cost. (Fig 6) It also has the property that if you plot the logarithm of proficiency against the logarithm of experience {{the result is a}} straight line, and it is often presented that way.|$|E
5000|$|Walk Score is a walkability index {{based on}} the {{distance}} to amenities such as grocery stores, schools, parks, libraries, restaurants, and coffee shops. Walk Score's algorithm awards maximum points to amenities within 5 minutes' walk (.25 mi), and a <b>decay</b> <b>function</b> assigns points for amenities up to 30 minutes away. Scores are normalized from 0 to 100.|$|E
5000|$|The FIDSAM method {{analyses}} {{the number}} of different molecules contributing to a measured fluorescence signal. Assuming a pure fluorescent dye solution in an isotropic surrounding, the individual emitters are indistinguishable. Accordingly, they obey the same fluorescence emission statistics and the time evolution of the fluorescence emission after a pulsed excitation can be described by a monoexponential <b>decay</b> <b>function</b> according to: ...|$|E
3000|$|... [...]. The {{class of}} subexponential {{functions}} therefore includes {{a wide variety}} of functions exhibiting polynomial and slower-than-exponential decay: nor is the slower-than-exponential decay limited to a class of polynomially <b>decaying</b> <b>functions.</b>|$|R
40|$|We have {{investigated}} the random walk problem in a finite system and studied the crossover induced in the the persistence probability scales by the system size. Analytical and numerical work show that the scaling function is an exponentially <b>decaying</b> <b>function.</b> The particle here is trapped with in a box of size $L$. We have also considered the problem when the particle in trapped in a potential. Direct calculation and numerical result show that the scaling function here also an exponentially <b>decaying</b> <b>function.</b> We also present numerical works on harmonically trapped randomly accelerated particle and randomly accelerated particle with viscous drag. Comment: revtex 4, 4 pages, 4 figure...|$|R
2500|$|In this case, if we {{initially}} define [...] on {{the space}} of smooth, rapidly <b>decaying</b> <b>functions,</b> the adjoint will be [...] "the same" [...] operator (i.e., given by the same formula) but on the largest possible domain, namely ...|$|R
50|$|Fluorescence lifetimes can be {{determined}} in the time domain by using a pulsed source. When a population of fluorophores is excited by an ultrashort or delta pulse of light, the time-resolved fluorescence will decay exponentially as described above. However, if the excitation pulse or detection response is wide, the measured fluorescence, d(t), will not be purely exponential. The instrumental response function, IRF(t) will be convolved or blended with the <b>decay</b> <b>function,</b> F(t).|$|E
5000|$|According to Hulls {{postulate}} X.B. inhibition I dissipates exponentially {{with time}} t:.:With {{the passage of}} time since its formation IR spontaneously dissipates approximately as a simple <b>decay</b> <b>function</b> of the time t elapsed, i.e.,: (Hull, 1951, p. 74).Hulls decay formula is somewhat awkward and might give rise to confusion. For example, IR does not refer to the derivative of IR. A more convenient way of writing the formula would be as follows: ...|$|E
5000|$|The {{model has}} drawbacks, as it {{requires}} both long-term potentiation and long-term depression, or increases and decreases in synaptic strength, something {{which has not}} been observed in all cortical systems. Further, it requires a variable activation threshold and depends strongly on stability of the selected fixed points [...] and [...] However, the model's strength is that it incorporates all these requirements from independently derived rules of stability, such as normalizability and a <b>decay</b> <b>function</b> with time proportional to the square of the output.|$|E
30|$|We {{propose a}} new, online updateable path count based {{centrality}} measure as a temporal {{variant of the}} successful Katz index (Katz 1953). Our measure incorporates arbitrary time <b>decay</b> <b>functions</b> that {{can be adapted to}} the task in question.|$|R
5|$|Enzyme inhibitors {{can also}} irreversibly {{inactivate}} enzymes, usually by covalently modifying active site residues. These reactions, {{which may be}} called suicide substrates, follow exponential <b>decay</b> <b>functions</b> and are usually saturable. Below saturation, they follow first order kinetics with respect to inhibitor.|$|R
5000|$|Off criticality, only finite {{clusters}} exist up to a largest cluster size , and the cluster-size {{distribution is}} smoothly {{cut off by}} a rapidly <b>decaying</b> <b>function,</b> [...] The exponent [...] characterizes the divergence of the cutoff parameter, [...] Obviously, , yielding [...]|$|R
5000|$|... where R is the {{universal}} gas constant and T {{is the absolute}} temperature. When a single step in a reaction is perturbed in a temperature jump experiment, the reaction follows a single exponential <b>decay</b> <b>function</b> with time constant [...] equal to {{a function of the}} forward (ka) and reverse (kb) rate constants. For the perturbation of a simple equilibrium A <=> B which is first order in both directions, the reciprocal of the time constant equals the sum of the two rate constants ...|$|E
50|$|When {{a single}} step in a {{reaction}} is perturbed in a pressure jump experiment, the reaction follows a single exponential <b>decay</b> <b>function</b> with the reciprocal time constant (1/τ) equal to {{the sum of the}} forward and reverse intrinsic rate constants. In more complex reaction networks, when multiple reaction steps are perturbed, then the reciprocal time constants are given by the eigenvalues of the characteristic rate equations. The ability to observe intermediate steps in a reaction pathway is one of the attractive features of this technology.|$|E
50|$|In general, both exciton {{populations and}} plasma, {{uncorrelated}} electrons and holes, {{can act as}} sources for photoluminescence {{as described in the}} semiconductor-luminescence equations. Both yield very similar spectral features which are difficult to distinguish; their emission dynamics, however, vary significantly. The decay of excitons yields a single-exponential <b>decay</b> <b>function</b> since the probability of their radiative recombination does not depend on the carrier density. The probability of spontaneous emission for uncorrelated electrons and holes, is approximately proportional to the product of electron and hole populations eventually leading to a non-single-exponential decay described by a hyperbolic function.|$|E
40|$|The quantum {{thermodynamic}} {{property of}} the fractional damping system is investigated extensively. A fractional power-law <b>decaying</b> entropy <b>function</b> is revealed which presents another evidence for {{the validity of the}} third law of thermodynamics in the quantum dissipative region. Several non-trivial characters are excavated such as that the entropy varies from a non-linear diverging function to a semi-linear <b>decaying</b> <b>function</b> of the fractional exponent as the temperature tends to absolute zero. Comment: 10 pages, 2 figures, 1 tabl...|$|R
40|$|Abstract—Distributed {{computing}} resources {{in a cloud}} computing environment provides an opportunity to reduce energy and its cost by shifting loads in response to dynamically varying availability of energy. This variation in electrical power availability is represented in its dynamically changing price {{that can be used}} to drive workload deferral against performance requirements. But such deferral may cause user dissatisfaction. In this paper, we quantify the impact of deferral on user satisfaction and utilize flexibility from the service level agreements (SLAs) for deferral to adapt with dynamic price variation. We differentiate among the jobs based on their requirements for responsiveness and schedule them for energy saving while meeting deadlines and user satisfaction. Representing utility as <b>decaying</b> <b>functions</b> along with workload deferral, we make a balance between loss of user satisfaction and energy efficiency. We model delay as <b>decaying</b> <b>functions</b> and guarantee that no job violates the maximum deadline, and we minimize the overall energy cost. Our simulation on MapReduce traces show that energy consumption can be reduced by ∼ 15 %, with such utility-aware deferred load balancing. We also found that considering utility as a <b>decaying</b> <b>function</b> gives better cost reduction than load balancing with a fixed deadline. I...|$|R
40|$|The {{robustness}} {{of fixed}} Turbo coded communication systems over frequency selective channels are investigated. The simulated amplitude functions {{are based on}} an idealised two level <b>function</b> and a <b>decaying</b> <b>function.</b> The {{results indicate that the}} system can cope with severe disturbances without to much loss...|$|R
50|$|The matrix W is {{required}} because {{in order to}} address spatial autocorrelation and also model spatial interaction, we need to impose a structure to constrain the number of neighbors to be considered. This is related to Tobler’s first law of geography, which states that Everything depends on everything else, but closer things more so - in other words, the law implies a spatial distance <b>decay</b> <b>function,</b> such that even though all observations have an influence on all other observations, after some distance threshold that influence can be neglected.|$|E
50|$|The FIDSAM {{technique}} bases on a time correlated single photon counting (TCSPC) {{measurement and}} analyses {{the degree of}} deviation of a recorded fluorescence decay from a monoexponential behavior. This is achieved by fitting the recorded fluorescence intensity decay by a monoexponential <b>decay</b> <b>function</b> convoluted with the instrument response function. In a next step, the error value of the fitting procedure, , is extracted and its inverse value is multiplied with the original intensity value. This way, fluorescence signal, which originates from autofluorescence background and therefore exhibits increased error-values, is divided by a relatively large number, whereas fluorescence signal from target molecules exhibits small error-values around unity is divided by a small number and remains largely unaffected.|$|E
5000|$|The {{value of}} [...] can depend {{quite a bit}} on the {{assumptions}} built into the spatial weights matrix [...] The idea is to construct a matrix that accurately reflects your assumptions about the particular spatial phenomenon in question. A common approach is to give a weight of 1 if two zones are neighbors, and 0 otherwise, though the definition of 'neighbors' can vary. Another common approach might be to give a weight of 1 to [...] nearest neighbors, 0 otherwise. An alternative is to use a distance <b>decay</b> <b>function</b> for assigning weights. Sometimes the length of a shared edge is used for assigning different weights to neighbors. The selection of spatial weights matrix should be guided by theory about the phenomenon in question.|$|E
30|$|To model CWD decomposition, {{exponential}} <b>decay</b> <b>functions,</b> which {{assume a}} homogeneous substrate that decays {{at a constant}} rate, {{have been used in}} the majority of cases (Mackensen et al. 2003). This may be an oversimplification of the complex processes occurring during dead wood decomposition. Recent modelling approaches have also considered the different wood constituents such extractives, cellulose or lignin, which undergo, owing to their chemical resistance, different decomposition dynamics (Tuomi et al. 2011). However, we did not employ such model, because the temporal resolution of our data would not have permitted a robust fitting of the decomposition process using a model with many parameters. To facilitate comparison of results with that of other studies, we fitted the exponential <b>decay</b> <b>functions</b> for all tree species.|$|R
40|$|This paper {{presents}} {{study on}} decay properties of two foamed bitumens. Foaming tests {{under various conditions}} were carried out to investigate decay properties of two types of bitumen: Penetration-grade 60 (PG 60) and Penetration-grade 100 (PG 100). Decay data were recorded and analyzed. It is found that water content has {{a significant effect on}} the bitumens' decay, and the time at which the maximum expansion ratio appears advances with an increase of temperature. PG 60 achieves the maximum expansion ratio at an earlier time than PG 100. The effect of viscosity on the two bitumens' decay properties was discussed and explained; and the observation of the tests confirms this explanation is rational. For developing the bitumens' <b>decay</b> <b>functions,</b> a four-parameter power function and a three-parameter exponential function were selected to fit the testing data of PG 60 and PG 100 bitumen, respectively. Two bitumens' <b>decay</b> <b>functions</b> were established by a two-stage method. Non-linear fitting analysis exhibits that two functions can well fit the data of the foaming tests. Decay functions' parameters were obtained by using the best subset regression method. Two <b>decay</b> <b>functions</b> can be used to calculate the maximum expansion ratios and half-lives of PG 60 and 100 bitumen under various conditions. Department of Civil and Environmental Engineerin...|$|R
40|$|Analytical {{solution}} {{of a problem}} of a double conductor line located above a two-layer medium is solved analytically by the method of integral transforms. The electric conductivity and magnetic permeability of the upper layer are exponetially <b>decaying</b> <b>functions</b> fo the vertical coordinate. Results of numerical computations are presented...|$|R
