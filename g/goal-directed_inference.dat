8|4|Public
40|$|Abstract. In {{this paper}} we present an extensional higher-order {{resolution}} calculus that is complete relative to Henkin model semantics. The {{treatment of the}} extensionality principles – necessary for the completeness result – by specialized (<b>goal-directed)</b> <b>inference</b> rules is of practical applicability, as an implentation of the calculus in the Leo-System shows. Furthermore, we prove the long-standing conjecture, that it is sufficient to restrict the order of primitive substitutions {{to the order of}} input formulae. ...|$|E
40|$|In {{this paper}} we present an extensional higher-order {{resolution}} calculus that is complete relative to Henkin model semantics. The {{treatment of the}} extensionality principles [...] necessary for the completeness result [...] by specialized (<b>goal-directed)</b> <b>inference</b> rules is of practical applicability, as an implentation of the calculus in the Leo-System shows. Furthermore, we prove the long-standing conjecture, that it is sufficient to restrict the order of primitive substitutions {{to the order of}} input formulae. 1 Introduction The history of building automated theorem provers for higher-order logic is almost as old as the field of deduction systems itself. The first successful attempts to mechanize and implement higher-order logic were those of Huet [Hue 73] and Jensen and Pietrzykowski [JP 76]. They combine the resolution principle for higher-order logic (first studied in [And 71]) with higher-order unification. The unification problem in typed -calculi is much more complex than that for fir [...] ...|$|E
40|$|WES) is a {{critical}} module of the Virtual Test Bed development to support “go/no go ” decisions for Space Shuttle operations in the Intelligent Launch and Range Operations program of NASA. The weather rules characterize {{certain aspects of the}} environment related to the launching or landing site, the time of the day or night, the pad or runway conditions, the mission durations, the runway equipment and landing type. Expert system rules are derived from weather contingency rules, which were developed over several years by NASA. Backward chaining, a <b>goal-directed</b> <b>inference</b> method is adopted, because a particular consequence or goal clause is evaluated first, and then chained backward through the rules. Once a rule is satisfied or true, then that particular rule is fired and the decision is expressed. The expert system is continuously verifying the rules against the past one-hour weather conditions and the decisions are made. The normal procedure of operations requires a formal pre-launch weather briefing held on Launch minus 1 day, which is a specific weather briefing for all areas of Space Shuttle launch operations. In this paper, the Web-based Weather Expert System of the Intelligent Launch and range Operations program is presented...|$|E
40|$|POLITICS is {{a system}} of {{computer}} programs which simulates humans in comprehending and responding to world events from a given political or ideological perspective. The primary theoretical motivations were: (1) {{the implementation of a}} functional system which applies the knowledge structures of Schank and Abelson (1977) to the domain of simulating political belief systems; (2) the development of a tentative theory of intentional goal conflicts and counterplanning. Secondary goals of the POLITICS project include developing a representation for belief systems, investigating cognitive processes such as <b>goal-directed</b> <b>inferencing,</b> and the integration of several types of knowledge representations into a functional system...|$|R
40|$|Abstract. An {{extension}} of resolution for skeptical stable model semantics is introduced. Unlike previous approaches, our calculus often needs to consider only a strict {{subset of the}} program rules. Moreover, we characterize a large class of programs whose derivations may proceed in a thoroughly <b>goal-directed</b> way. Some <b>inferences,</b> which depend on non-ground negative goals, can be drawn without resorting to negation-as-failure; as a consequence, many goals which flounder in the standard setting, have a successful skeptical derivation. The paper contains a preliminary study of some interesting derivation strategies...|$|R
40|$|Most current {{theories}} of text processing assume a constructionist view of inference processing. In this article, an alternative view is proposed, labeled the minimalist hypothesis. According to this hypothesis, the only inferences that are encoded automatically during reading {{are those that}} are based on easily available information, either from explicit statements in the text or from general knowledge, and those that are required to make statements in the text locally coherent. The minimalist hypothesis is shown to be supported by previous research and by the results of several new experiments. It is also argued that automatically encoded minimalist inferences provide the basic representation of textual information from which more <b>goal-directed,</b> purposeful <b>inferences</b> are constructed. In reading, comprehension processes are generally assumed to combine information from two sources: explicit statements from the text being read and general knowledge already known to the reader. Interactions of information from these two sources produce the representation of a text that is encoded into memory. The issue addressed in this article is the extent t...|$|R
40|$|This article formulates a {{fundamental}} {{problem in the}} philosophy of action. It will become apparent that the same problem is also an abstract and general, but very important question for the field of artificial intelligence- and robotics in particular. As well, the nature of the problem, as revealed below, will make evident its importance in the field of logical evaluation of natural language argumentation. The problem is one of when a knowledge-based <b>goal-directed</b> <b>inference</b> leading to an action (or a recommendation for a course of action to be taken) may be said to be structurally correct (or closed), parallel to the sense in which a deductive argument is said to be valid (deductively closed). Solving this problem will require a formalization of practical reasoning in the end, to be carried out {{in the way that the}} analysis of the problematic case developed in the article will indicate. However, being a philosophical contribution, this article will merely pose and sharpen the problem, making certain questions to be asked more precise. No claim is made that anything like a complete formalization of practical reasoning is given by the consideration...|$|E
40|$|The thesis {{describes}} a logical formalization of natural-language database interfacing. We assume {{the existence of}} a "natural language engine" capable of mediating between surface linguistic string and their representations as "literal" logical forms: the focus of interest will be the question of relating "literal" logical forms to representations in terms of primitives meaningful to the underlying database engine. We begin by describing the nature of the problem, and show how a variety of interface functionalities can be considered as instances of a type of formal inference task which we call "Abductive Equivalential Translation" (AET); functionalities which can be reduced to this form include answering questions, responding to commands, reasoning about the completeness of answers, answering meta-questions of type "Do you know [...] . ", and generating assertions and questions. In each case, a "linguistic domain theory" (LDT) Γ and an input formula F are given, and the goal is to construct a formula with certain properties which is equivalent to F, given Γ and a set of permitted assumptions. If the LDT is of a certain specified type, whose formulas are either conditional equivalences or Horn-clauses, we show that the AET problem can be reduced to a <b>goal-directed</b> <b>inference</b> method. We present an abstract description of this method, and sketch its realization in Prolog. The relationship between AET and several problems previously discussed in the literature is discussed. In particular, we show how AET can provide a simple and elegant solution to the so-called "Doctor on Board" problem, and in effect allows a "relativization" of the Closed World Assumption. The ideas in the thesis have all been implemented concretely within the SRI CLARE project, using a real projects and payments database. The LDT for the example database is described in detail, and examples of the types of functionality that can be achieved within the example domain are presented. Comment: 162 pages, Latex source, PhD thesis (U Stockholm, 1993). Uses style-file ustockholm_thesis. st...|$|E
40|$|The goal of {{this work}} is to explore {{efficient}} ways to use knowledge in interactive development of formal arguments. The challenge in automatically applying knowledge from a large knowledge base is in defining useful and tractable approximations to the deductive closure of the knowledge base. For an approximation to be useful, it must be deep in some directions. For it to be tractable, it must not be deep in all directions. Further, it must be easy to control this directedness. Thus, {{we need to make}} selective inferences from a large knowledge base that are sensitive both to its internal structure and to the query under consideration. To do this, most interactive systems employ a combination of heuristics and explicit user commands. The interaction of these two is intricate: to efficiently give hints to a heuristic prover requires developing a model of reasoning that is both efficiently implementable and easy to understand and use, i. e., fast, having a concise command language and predictable results. Rule-based specifications of approximations is the starting point for the contribution of this thesis in solving the problem described above. In this thesis, we analyze the use of rule-based forward chaining inference procedures and develop several extensions to the basic approach. We propose a new language for forward chaining tactics {{that can be used to}} specify <b>goal-directed</b> <b>inference</b> from large knowledge bases. This provides a modular approach to programming the heuristics for theorem proving. The tactic language has clean theoretical properties that make it appropriate for automated analysis and optimization. From the software engineering perspective, this thesis contains an assessment of the new software engineering approach of the theorem prover Ontic: specifying high performance theorem provers in a bottom-up logic programming framework. This perspective provides a much needed link between the Ontic project and other established research paradigms. The analysis tools developed for evaluating the forward chaining approach to obvious reasoning should have broad applications in evaluating other semi-automated approaches and systems. We also develop a language for declarative specification of control for forward chaining reasoning that is analogous to the role of LCF tacticals for specifying control in refinement-style reasoning, as embodied in Nuprl. We arrived at promising conclusions about the potential for combining these two styles of tactic programming in such problems as the integration of decision procedures and rewriting into interactive theorem provers...|$|E
40|$|A {{commentary}} on Whatever next? Predictive brains, situated agents, {{and the future}} of cognitive science by Clark, A. (in press). Behav. Brain Sci. The Active Inference framework (Friston et al., 2009; Friston, 2010) argues that the brain’s generative models continuously produce predictions and goals that guide its action (active inference) and perception (predictive coding) through free energy minimization. In this framework, most studies have focused on the on-line predic-tion of perceptual events and the control of overt behavior. We propose that the frame-work can be extended to explain cognitive control. We assume that architectures of cogni-tive control are elaborations of the predic-tive architectures of sensorimotor behav-ior in early living organisms. As the senso-rimotor control system of early organisms evolved (to face increasingly harder indi-vidual and social problems), it gradually began predicting increasingly long-term and abstract consequence of behavior and—critically—doing so off-line and without overt behavior. This permitted rehearsing action sequences without exe-cuting them. In turn, off-line predictions opened the doors to higher cognitive abili-ties, such as planning, emulation, imagery, mental state <b>inference,</b> <b>goal-directed</b> decision-making, prospection, and the acquisition of declarative knowledg...|$|R

