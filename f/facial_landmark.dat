199|396|Public
50|$|The cross race {{effect has}} a {{morphological}} basis: The facial appearance is morphologically different for different ethnic backgrounds. This {{has been established}} empirically, wherein a large set of 3D scans of faces from different ethnic backgrounds was automatically clustered into groups. Only <b>facial</b> <b>landmark</b> distances were used in this grouping. The result was that gender, as well as ethnicity, emerged as primary factors of group membership.|$|E
40|$|<b>Facial</b> <b>landmark</b> detection, head pose estimation, {{and facial}} {{deformation}} analysis are typical facial behavior analysis tasks in computer vision. The existing methods usually perform each task independently and sequentially, ignoring their interactions. To tackle this problem, we propose a unified framework for simultaneous <b>facial</b> <b>landmark</b> detection, head pose estimation, and facial deformation analysis, {{and the proposed}} model is robust to facial occlusion. Following a cascade procedure augmented with model-based head pose estimation, we iteratively update the <b>facial</b> <b>landmark</b> locations, facial occlusion, head pose and facial de- formation until convergence. The experimental results on benchmark databases demonstrate {{the effectiveness of the}} proposed method for simultaneous <b>facial</b> <b>landmark</b> detection, head pose and facial deformation estimation, even if the images are under facial occlusion. Comment: International Conference on Computer Vision and Pattern Recognition, 201...|$|E
40|$|MERL’s recognizer has {{two major}} {{components}} (Figure 1). The first is an aligner whose input is any arbitrary image and whose output is a cropped and rectified face if the image contains a face. The second is a comparator whose input is two aligned faces and whose output is a similarity score. The comparator {{is described in}} detail in [3]. The aligner first detects any faces in the image using a Viola-Jones frontal face detector. For any faces found, it tries to find nine <b>facial</b> <b>landmark</b> points by running nine Viola-Jones type <b>facial</b> <b>landmark</b> detectors. The <b>facial</b> <b>landmark</b> detectors are trained using the same Viola-Jones AdaBoost cascade method as the face detector. For each <b>facial</b> <b>landmark,</b> a set of aligned positive examples are manually marked. Some positive examples are shown for the right outside eye corner in Figure 2. The negative examples consist of other patches of faces and non-face patches. After the <b>facial</b> <b>landmark</b> detectors are run, if at least six landmarks are found, then the optimal scale, in-plane rotation and translation in x and y ar...|$|E
40|$|To {{dynamically}} {{detect the}} <b>facial</b> <b>landmarks</b> in the video, we propose a novel hybrid framework termed as detection-tracking-detection (DTD). First, the face bounding box is achieved {{from the first}} frame of the video sequence based on a traditional face detection method. Then, a landmark detector detects the <b>facial</b> <b>landmarks,</b> {{which is based on}} a cascaded deep convolution neural network (DCNN). Next, the face bounding box in the current frame is estimated and validated after the <b>facial</b> <b>landmarks</b> in the previous frame are tracked based on the median flow. Finally, the <b>facial</b> <b>landmarks</b> in the current frame are exactly detected from the validated face bounding box via the landmark detector. Experimental results indicate that the proposed framework can detect the <b>facial</b> <b>landmarks</b> in the video sequence more effectively and with lower consuming time compared to the frame-by-frame method via the DCNN. Comment: 8 pages, 5 figures, unpublished manuscrip...|$|R
30|$|The {{accurate}} {{identification of}} specific <b>facial</b> features and <b>landmarks</b> is a foundational {{process by which}} a number of more complicated image analysis problems are solved. Tasks such as facial identification, expression analysis, age estimation, and gender classification are often built upon a <b>facial</b> <b>landmarking</b> component in their methods [1, 2]. The use of image-based automated <b>facial</b> <b>landmarking</b> has been extended outside of the domain of image research and into other applications, including some within the medical field. Conditions such as facial palsy, facial paralysis, and even sleep apnoea are either characterised by or associated with unique facial structures that {{enables the use of}} <b>facial</b> <b>landmarking</b> as a useful research or even screening tool. Very recently, Guarin et al. [3] described an automated <b>facial</b> <b>landmarking</b> tool which is used in the characterisation of facial displacements in sufferers of facial palsy; while the work by Anping et al. [4] uses landmarks as predicted by Active Shape Models to assess facial nerve paralysis. The use of <b>facial</b> <b>landmarking</b> methodologies has been recently examined as a means of screening for sleep apnoea by Tabatabaei Balaei et al. [5], looking at the association between the underlying structure of predicted <b>facial</b> <b>landmarks</b> and the likelihood of suffering from obstructive sleep apnoea. The authors of this review have also investigated the use of <b>facial</b> <b>landmarks</b> in sizing sleep apnoea masks [6], a critical device in sleep apnoea treatment. Given the wide variety of applications in which <b>facial</b> <b>landmarking</b> is applied, {{and in the case of}} medical applications the critical nature of the tasks it is vital that the systems be capable of accurately identifying the landmarks of interest.|$|R
40|$|Abstract. To design robots or {{embodied}} conversational {{agents that}} can accurately display facial expressions indicating an emotional state, we need technology to produce those facial expressions, and research that investigates {{the relationship between}} those technologies and human social perception of those artificial faces. Our starting point is assessing human perception of core facial information: Moving dots representing the <b>facial</b> <b>landmarks,</b> i. e., the locations and movements of the crucial parts of a face. Earlier research suggested that participants can relatively accurately identity facial expressions when all they can see of a real human full face are moving white painted dots representing the <b>facial</b> <b>landmarks</b> (although less accurate than recognizing full faces). In the current study we investigated the accuracy of recognition of emotions expressed by comparable <b>facial</b> <b>landmarks</b> (compared to accuracy of recognition of emotions expressed by full faces), but now used face-tracking software to produce the <b>facial</b> <b>landmarks.</b> In line with earlier findings, results suggested that participants could accurately identify emotions expressed by the <b>facial</b> <b>landmarks</b> (though less accurately than those expressed by full faces). Thereby, these results provide {{a starting point for}} further research on the fundamental characteristics of technology (AI methods) producing facial emotional expressions and their evaluation by human users...|$|R
40|$|Detection and {{tracking}} of faces in image sequences {{is among the}} most well studied problems in the intersection of statistical machine learning and computer vision. Often, tracking and detection methodologies use a rigid representation to describe the facial region 1, hence they can neither capture nor exploit the non-rigid facial deformations, which are crucial for countless of applications (e. g., facial expression analysis, facial motion capture, high-performance face recognition etc.). Usually, the non-rigid deformations are captured by locating {{and tracking}} the position of a set of fiducial facial landmarks (e. g., eyes, nose, mouth etc.). Recently, we witnessed a burst of research in automatic <b>facial</b> <b>landmark</b> localisation in static imagery. This is partly attributed to the availability of large amount of annotated data, many of which have been provided by the first <b>facial</b> <b>landmark</b> localisation challenge (also known as 300 -W challenge). Even though now well established benchmarks exist for <b>facial</b> <b>landmark</b> localisation in static imagery, {{to the best of our}} knowledge, there is no established benchmark for assessing the performance of <b>facial</b> <b>landmark</b> tracking methodologies, containing an adequate number of annotated face videos. In conjunction with ICCV’ 2015 we run the first competition/challenge on <b>facial</b> <b>landmark</b> tracking in long-term videos. In this paper, we present the first benchmark for long-term <b>facial</b> <b>landmark</b> tracking, containing currently over 110 annotated videos, and we summarise the results of the competition...|$|E
40|$|Cascade {{regression}} framework {{has been}} shown to be effective for <b>facial</b> <b>landmark</b> detection. It starts from an initial face shape and gradually predicts the face shape update from the local appearance features to generate the <b>facial</b> <b>landmark</b> locations in the next iteration until convergence. In this paper, we improve upon the cascade regression framework and propose the Constrained Joint Cascade Regression Framework (CJCRF) for simultaneous facial action unit recognition and <b>facial</b> <b>landmark</b> detection, which are two related face analysis tasks, but are seldomly exploited together. In particular, we first learn the relationships among facial action units and face shapes as a constraint. Then, in the proposed constrained joint cascade regression framework, with the help from the constraint, we iteratively update the <b>facial</b> <b>landmark</b> locations and the action unit activation probabilities until convergence. Experimental results demonstrate that the intertwined relationships of facial action units and face shapes boost the performances of both facial action unit recognition and <b>facial</b> <b>landmark</b> detection. The experimental results also demonstrate the effectiveness of the proposed method comparing to the state-of-the-art works. Comment: International Conference on Computer Vision and Pattern Recognition, 201...|$|E
40|$|<b>Facial</b> <b>landmark</b> {{detection}} is {{an important}} but challenging task for real-world computer vision applications. This paper proposes an accurate and robust approach for <b>facial</b> <b>landmark</b> detection by combining data-driven and model-driven methods. Firstly, a fully convolutional network (FCN) is trained to generate response maps of all <b>facial</b> <b>landmark</b> points. Such a data-driven method can make full use of holistic information in a facial image for global estimation of facial landmarks. Secondly, the maximum points in the response maps are fitted with a pre-trained point distribution model (PDM) to generate initial <b>facial</b> <b>landmark</b> shape. Such a model-driven method can correct the location errors of outliers by considering shape prior information. Thirdly, a weighted version of Regularized Landmark Mean-Shift (RLMS) is proposed to fine-tune <b>facial</b> <b>landmark</b> shapes iteratively. The weighting strategy {{is based on the}} confidence of convolutional response maps so that FCN is integrated into the framework of Constrained Local Model (CLM). Such an Estimation-Correction-Tuning process perfectly combines the global robustness advantage of data-driven method (FCN), outlier correction advantage of model-driven method (PDM) and non-parametric optimization advantage of RLMS. The experimental results demonstrate that the proposed approach outperforms state-of-the-art solutions on the 300 -W dataset. Our approach is well-suited for face images with large poses, exaggerated expression, and occlusions. Comment: Submitted to CVPR 201...|$|E
30|$|As {{this article}} focuses on <b>facial</b> <b>landmarking</b> techniques, we only provide a brief {{overview}} of face detectors.|$|R
3000|$|Aiming to {{construct}} an automatic <b>facial</b> <b>landmarking</b> system with performance {{comparable to that of}} an expert human annotator [...]...|$|R
40|$|When {{providing}} a photo quality control and person’s identity, defining the mimic changes, and conducting the anthropometrical researches a head pose estimate is required. If an image resolution {{is sufficient for}} localization of <b>facial</b> <b>landmarks</b> (FL) the most advantageous among the head pose estimate methods are geometrical ones. The paper presents a model built to show an interrelation between the coordinates of <b>facial</b> <b>landmarks</b> and the head pose angles. To create this model using analysis of principal components was carried out a transition from the coordinates {{of a set of}} the landmarks to the vector of smallsized features, the elements of which contain the maximum volume of information. Then, using a regression analysis a model of interrelation between the elements of this vector of features and the head pose angles was built. To solve the abovementioned tasks, was used the parametrical model of a face CANDIDE- 3. It was found that the feature vector to estimate the head pose should consist of five elements. In the works using geometrical methods there is no information about the dependencies of pose angle errors on the individual shape of the face, the mimic changes, the number of <b>facial</b> <b>landmarks</b> and their localization error that does not allow to define the limiting possibilities of these methods and to predict the results of their use in a specific task. This work using the model of a face CANDIDE- 3 examines the dependencies of the pose angle errors on the individual shape of the face, the mimic changes, the number of <b>facial</b> <b>landmarks</b> and their localization error. In addition to a set of 113 landmarks, the conducted research activities used also the sets of 28 and 5 landmarks. These sets contain the most important anthropometrical <b>facial</b> <b>landmarks</b> and are created taking into account a capacity of the software packages available for their automatic facial image search. Results of modeling have shown that it is expedient to use a set of 28 <b>facial</b> <b>landmarks.</b> Thus, {{in a wide range of}} shape and mimic changes as well as with significant localization errors of <b>facial</b> <b>landmarks</b> on the image the average error of defining pose angles does not exceed 5 °. </p...|$|R
30|$|Automatic <b>facial</b> <b>landmark</b> {{detecting}} {{and tracking}} is a challenging task in facial expression analysis. In this paper, we proposed an automatic approach {{to detect and}} track facial landmarks for varying facial expressions. We first construct a set of <b>facial</b> <b>landmark</b> detectors with scale invariant feature. Locating feature points automatically on a single frame {{makes it possible to}} eliminate the manual initiation step for the tracking algorithm.|$|E
40|$|For robot systems, robust <b>facial</b> <b>landmark</b> {{detection}} is {{the first}} and critical step for face-based human identification and facial expression recognition. In recent years, the cascaded-regression-based method has achieved excellent performance in <b>facial</b> <b>landmark</b> detection. Nevertheless, it still has certain weakness, such as high sensitivity to the initialization. To address this problem, regression based on multiple initializations is established in a unified model; face shapes are then estimated independently according to these initializations. With a ranking strategy, the best estimate is selected as the final output. Moreover, a face shape model based on restricted Boltzmann machines is built as a constraint to improve the robustness of ranking. Experiments on three challenging datasets demonstrate {{the effectiveness of the}} proposed <b>facial</b> <b>landmark</b> detection method against state-of-the-art methods...|$|E
40|$|Abstract—Facial {{landmark}} localization is {{well known}} as one of the bottlenecks in face recognition. This paper proposes a novel <b>facial</b> <b>landmark</b> localization method, which introduces facial context constrains into cascaded AdaBoost framework. The motivation of our method lies in the basic human physiology observation that not only the local texture information but also the global context information is used together for human to realize the landmark location task. Therefore, in our solution, a novel type of Haar-like feature, called discontinuous Haar-like feature, is proposed to characterize the facial context, i. e. the cooccurrence relationship between target <b>facial</b> <b>landmark</b> and other local texture patterns within face region (including other landmarks, facial organs and also smoothing regions). For the locating task, traditional Haar-like features (characterizing local texture information) and discontinuous Haar-like features (characterizing context constrains in global sense) are combined together to form more powerful representations. Through Real AdaBoost learning, distinctive features are selected automatically and used for <b>facial</b> <b>landmark</b> detection. Our experiments on BioID and Cohn-Kanade databases have validated the proposed method by comparing with other state-of-the-art results. Keywords-face recognition; <b>facial</b> <b>landmark</b> localization; context constraints; discontinuous Haar-like feature I...|$|E
40|$|Aim: The aim of {{this study}} was to {{validate}} the automatic tracking of <b>facial</b> <b>landmarks</b> in 3 D image sequences captured using the Di 4 D system (Dimensional Imaging Ltd., Glasgow, UK). MATERIALS AND METHODS: 32 subjects (16 males; 16 females) range 18 - 35 years were recruited. 23 <b>facial</b> <b>landmarks</b> were marked on the face of each subject with a 0. 5 mm non-permanent ink. The subjects were asked to perform three facial animations from the rest position (maximal smile, lip purse and cheek puff). Each animation was captured by a 3 D stereophotogrammetry video system (Di 4 D). A single operator digitized landmarks on captured 3 D models and the manual digitised landmarks were compared with the automatic tracked landmarks. To investigate the accuracy of manual digitisation, the same operator re-digitized 2 subjects (1 male and 1 female). RESULTS & CONCLUSION: The discrepancies in x, y and z coordinates between the manual digitised landmarks and the automatic tracked <b>facial</b> <b>landmarks</b> were within 0. 5 mm and the mean distance between the manual digitisation and the automatic tracking of corresponding landmarks using tracking software was within 0. 7 mm which reflects the accuracy of the method(p value was very small). The majority of these distances were within 1 mm. The correlation coefficient between the manual and the automatic tracking of <b>facial</b> <b>landmarks</b> was 0. 999 in all x, y, and z coordinates. In conclusion, Automatic tracking of <b>facial</b> <b>landmarks</b> with satisfactory accuracy, would facilitate the analysis of the dynamic motion during facial animations...|$|R
40|$|In {{this paper}} {{we present a}} {{framework}} for tracking non-rigid <b>facial</b> <b>landmarks</b> by combining various visual cues at multiple levels of detail. Using a probabilistic framework consisting of a hierarchy of particle filters, {{we are able to}} track individual <b>facial</b> <b>landmarks</b> using multiple visual cues at the local level, as well as tracking results at more coarse level of detail. This allows for the fusion of global and lo-cal cues in an efficient and robust manner. Testing is per-formed by tracking and classifying facial action codes ob-tained from the Cohn-Kanade AU-Coded Facial Expression Database. 1...|$|R
40|$|This paper compares several {{approaches}} to extract <b>facial</b> <b>landmarks</b> and studies {{their influence on}} face recognition problems. In order to obtain fair comparisons, we use {{the same number of}} <b>facial</b> <b>landmarks</b> and the same type of descriptors (HOG descriptors) for each approach. The comparative results are obtained using FERET and FRGC datasets and show that better recognition rates are obtained when landmarks are located at real facial fiducial points. However, if the automatic detection of these landmarks is compromised by the difficulty of the images, better results are obtained using fixed landmarks grids. 1...|$|R
40|$|Most face {{applications}} depend {{heavily on}} {{the accuracy of the}} face and facial landmarks detectors employed. Prediction of attributes such as gender, age, and identity usually completely fail when the faces are badly aligned due to inaccurate <b>facial</b> <b>landmark</b> detection. Despite the impressive recent advances in face and <b>facial</b> <b>landmark</b> detection, little study is on the recovery from and detection of failures or inaccurate predictions. In this work we study two top recent <b>facial</b> <b>landmark</b> detectors and devise confidence models for their outputs. We validate our failure detection approaches on standard benchmarks (AFLW, HELEN) and correctly identify more than 40 % of the failures in the outputs of the landmark detectors. Moreover, with our failure detection we can achieve a 12 % error reduction on a gender estimation application at the cost of a small increase in computation...|$|E
40|$|Recently, {{technologies}} such as face detection, <b>facial</b> <b>landmark</b> localisation and face recognition and verification have matured enough to provide effective and efficient solutions for imagery captured under arbitrary conditions (referred to as "in-the-wild"). This is partially attributed {{to the fact that}} comprehensive "in-the-wild" benchmarks have been developed for face detection, landmark localisation and recognition/verification. A very important technology that has not been thoroughly evaluated yet is deformable face tracking "in-the-wild". Until now, the performance has mainly been assessed qualitatively by visually assessing the result of a deformable face tracking technology on short videos. In this paper, we perform the first, {{to the best of our}} knowledge, thorough evaluation of state-of-the-art deformable face tracking pipelines using the recently introduced 300 VW benchmark. We evaluate many different architectures focusing mainly on the task of on-line deformable face tracking. In particular, we compare the following general strategies: (a) generic face detection plus generic <b>facial</b> <b>landmark</b> localisation, (b) generic model free tracking plus generic <b>facial</b> <b>landmark</b> localisation, as well as (c) hybrid approaches using state-of-the-art face detection, model free tracking and <b>facial</b> <b>landmark</b> localisation technologies. Our evaluation reveals future avenues for further research on the topic. Comment: E. Antonakos and P. Snape contributed equally and have joint second authorshi...|$|E
40|$|Face {{alignment}} is {{a classic}} problem in the computer vision field. Previous works mostly focus on sparse alignment with {{a limited number of}} <b>facial</b> <b>landmark</b> points, i. e., <b>facial</b> <b>landmark</b> detection. In this paper, for the first time, we aim at providing a very dense 3 D alignment for large-pose face images. To achieve this, we train a CNN to estimate the 3 D face shape, which not only aligns limited facial landmarks but also fits face contours and SIFT feature points. Moreover, we also address the bottleneck of training CNN with multiple datasets, due to different landmark markups on different datasets, such as 5, 34, 68. Experimental results show our method not only provides high-quality, dense 3 D face fitting but also outperforms the state-of-the-art <b>facial</b> <b>landmark</b> detection methods on the challenging datasets. Our model can run at real time during testing. Comment: To appear in ICCV 2017 Worksho...|$|E
40|$|<b>Facial</b> <b>landmarks</b> play an {{important}} role in face recognition. They serve different steps of the recognition such as pose estimation, face alignment, and local feature extraction. Recently, cascaded shape regression has been proposed to accurately locate <b>facial</b> <b>landmarks.</b> A large number of weak regressors are cascaded in a sequence to fit face shapes to the correct landmark locations. In this paper, we propose to improve the method by applying gradual training. With this training, the regressors are not directly aimed to the true locations. The sequence instead is divided into successive parts each of which is aimed to intermediate targets between the initial and the true locations. We also investigate the incorporation of pose information in the cascaded model. The aim is to find out whether the model can be directly used to estimate head pose. Experiments on the Annotated <b>Facial</b> <b>Landmarks</b> in the Wild database have shown that the proposed method is able to improve the localization and give accurate estimates of pose...|$|R
30|$|In this paper, we use {{multiple}} DE-MC particle filters {{to track}} the <b>facial</b> <b>landmarks</b> through the video sequence depending on {{the locations of the}} current appearance of the spatially sampled features.|$|R
40|$|Abstract Establishment {{of proper}} occlusal {{vertical}} dimension {{is the important}} yet daunting task for successful prosthodontic therapy for function, esthetics and comfort to the edentulous patients. In the current study the relationship of various distances between <b>facial</b> <b>landmarks</b> to the OVD was tested in two ethnic groups of Nepal, viz. Aryans and Mongoloids. The result of this study {{can be useful in}} determining proper OVD in the patients who have lost the OVD. The aim {{of the study was to}} find the correlation between <b>facial</b> <b>landmarks</b> and OVD. Materials and methods: The OVD was measured using a Boley gauge from the prominent part of chin and nose. Other <b>facial</b> <b>landmarks</b> were also measured using the calipers in 200 adult volunteers. Results: The Pearson’s product moment correlation coefficient was determined. OVD was significantly (p≤ 0. 05) correlated with rima oris to pupil distance (r = 0. 557 in whole population, r = 0. 577 in Aryans and 0. 466 in Mongoloids). Conclusions: The distance between rima oris to pupil distance has higher correlation to OVD than other facial measurements...|$|R
30|$|This paper {{presents}} a joint head pose and <b>facial</b> <b>landmark</b> regression method with input from depth images for realtime application. Our main contributions are: firstly, a joint optimization method to estimate head pose and facial landmarks, i.e., the pose regression result provides supervised initialization for cascaded <b>facial</b> <b>landmark</b> regression, while the regression result for the facial landmarks {{can also help}} to further refine the head pose at each stage. Secondly, we classify the head pose space into 9 sub-spaces, and then use a cascaded random forest with a global shape constraint for training facial landmarks in each specific space. This classification-guided method can effectively handle the problem of large pose changes and occlusion. Lastly, we have built a 3 D face database containing 73 subjects, each with 14 expressions in various head poses. Experiments on challenging databases show our method achieves state-of-the-art performance on both head pose estimation and <b>facial</b> <b>landmark</b> regression.|$|E
30|$|We {{believe that}} there are two basic {{categories}} of <b>facial</b> <b>landmark</b> detection methods: model-based methods and texture-based methods. Model-based methods, also known as shape-based methods, consider the face image and the ensemble of facial landmarks as a whole shape. They learn “face shapes” from labeled training images, and then at the test stage, they try to fit the proper shape to an unknown face. The second category, texture-based methods, also known as non model-based methods, aim to find each <b>facial</b> <b>landmark</b> or local groups of landmarks independently, without the guidance of a model. In these methods the shape information may still be invoked, but at a later stage for verification.|$|E
40|$|We {{propose a}} {{data-driven}} approach to <b>facial</b> <b>landmark</b> localization that models {{the correlations between}} each land-mark and its surrounding appearance features. At runtime, each feature casts a weighted vote to predict landmark lo-cations, where the weight is precomputed to take into ac-count the feature’s discriminative power. The feature voting-based landmark detection is more robust than previous local appearance-based detectors; we combine it with nonpara-metric shape regularization to build a novel <b>facial</b> <b>landmark</b> localization pipeline that is robust to scale, in-plane rotation, occlusion, expression, and most importantly, extreme head pose. We achieve state-of-the-art performance on two es-pecially challenging in-the-wild datasets populated by faces with extreme head pose and expression. 1...|$|E
40|$|Facial {{features}} {{are the basis}} for the emotion recognition process and are widely used in affective computing systems. This emotional process is produced by a dynamic change in the physiological signals and the visual answers related to the facial expressions. An important factor in this process, relies on the shape information of a facial expression, represented as dynamically changing <b>facial</b> <b>landmarks.</b> In this paper we present a framework for dynamic <b>facial</b> <b>landmarking</b> selection based on facial expression analysis using Gaussian Processes. We perform facial features tracking, based on Active Appearance Models for <b>facial</b> <b>landmarking</b> detection, and then use Gaussian process ranking over the dynamic emotional sequences with the aim to establish which landmarks are more relevant for emotional multivariate time-series recognition. The experimental results show that Gaussian Processes can effectively fit to an emotional time-series and the ranking process with log-likelihoods finds the best landmarks (mouth and eyebrows regions) that represent a given facial expression sequence. Finally, we use the best ranked landmarks in emotion recognition tasks obtaining accurate performances for acted and spontaneous scenarios of emotional datasets. ...|$|R
40|$|Large pose {{variations}} {{remain to}} be a challenge that confronts real-word face detection. We propose a new cascaded Convolutional Neural Network, dubbed the name Supervised Transformer Network, to address this challenge. The first stage is a multi-task Region Proposal Network (RPN), which simultaneously predicts candidate face regions along with associated <b>facial</b> <b>landmarks.</b> The candidate regions are then warped by mapping the detected <b>facial</b> <b>landmarks</b> to their canonical positions to better normalize the face patterns. The second stage, which is a RCNN, then verifies if the warped candidate regions are valid faces or not. We conduct end-to-end learning of the cascaded network, including optimizing the canonical positions of the <b>facial</b> <b>landmarks.</b> This supervised learning of the transformations automatically selects the best scale to differentiate face/non-face patterns. By combining feature maps from both stages of the network, we achieve state-of-the-art detection accuracies on several public benchmarks. For real-time performance, we run the cascaded network only on regions of interests produced from a boosting cascade face detector. Our detector runs at 30 FPS on a single CPU core for a VGA-resolution image...|$|R
30|$|The use of {{convolutional}} {{neural networks}} and deep learning techniques has dominated recent research in computer vision {{and particularly in}} <b>facial</b> <b>landmarking.</b> Given this popularity, it is convenient to discuss convolutional-based and non-convolutional landmarking models separately.|$|R
40|$|Automatically {{recognising}} facial emotions {{has drawn}} increasing attention in computer vision. <b>Facial</b> <b>landmark</b> based methods {{are one of}} the most widely used approaches to perform this task. However, these approaches do not provide good performance. Thus, researchers usually tend to combine more information such as textural and audio information to increase the recognition rate. In this paper we propose a novel method, here called the landmark manifold, that shows the possibility to achieve competitive performance by <b>facial</b> <b>landmark</b> information alone. Through experiments on the well-known dataset: marked Cohn-Kanade extended facial emotion dataset (CK+), we show that with accurate facial landmarks, our simple approach is fast to run and can achieve competitive performance with enormously expensive methods...|$|E
40|$|We {{present a}} new {{approach}} to localize extensive facial landmarks with a coarse-to-fine convolutional network cas-cade. Deep convolutional neural networks (DCNN) have been successfully utilized in <b>facial</b> <b>landmark</b> localization for two-fold advantages: 1) geometric constraints among facial points are implicitly utilized; 2) huge amount of train-ing data can be leveraged. However, in the task of exten-sive <b>facial</b> <b>landmark</b> localization, a large number of fa-cial landmarks (more than 50 points) are required to be located in a unified system, which poses great difficulty in the structure design and training process of traditional con-volutional networks. In this paper, we design a four-level convolutional network cascade, which tackles the problem in a coarse-to-fine manner. In our system, each network level is trained to locally refine a subset of facial land-marks generated by previous network levels. In addition, each level predicts explicit geometric constraints (the posi-tion and rotation angles of a specific facial component) to rectify the inputs of the current network level. The combi-nation of coarse-to-fine cascade and geometric refinement enables our system to locate extensive facial landmarks (68 points) accurately in the 300 -W <b>facial</b> <b>landmark</b> localiza-tion challenge. 1...|$|E
40|$|This paper {{presents}} an integrated approach for robustly locating <b>facial</b> <b>landmark</b> for drivers. In {{the first step}} a cascade of probability learners is used to detect the face edge primitives from fine to coarse, so that faces with variant head poses can be located. The edge density descriptors and skin-tone color features are combined together as the basic features to examine the probability of an edge being a face primitive. A cascade of the probability learner is used. In each scale, only edges with sufficient large probabilities are kept and {{passed on to the}} next scale. The final output of the cascade gives the edge primitives that belong to faces, which determine the face location. In the second step, a <b>facial</b> <b>landmark</b> detection procedure is applied on the segmented face pixels. <b>Facial</b> <b>landmark</b> candidates are first detected by learning the posteriors in multiple resolutions. Then geometric constraint and the local appearance, modeled by SIFT descriptor, are used to find the set of facial landmarks with largest matching score. Experiments over highresolution images (FERET database) as well as the real-world drivers’ data are used to evaluate the performance. A fairly good results can be obtained, which validates the proposed approach...|$|E
30|$|The {{objective}} {{definition is}} arguably the most important step in the model construction process. A clear, concise, and correct definition of what is to be achieved is crucial as it forms the basis of all other steps, design decisions, and is often a platform for solving more complex problems. Wu et al. in 2012 [1] used <b>facial</b> <b>landmarks</b> to assist in age estimation and face verification; Devries et al. [2] used <b>landmarking</b> in <b>facial</b> expression recognition while Tabatabaei Balaei et al. [5] investigated the use of <b>facial</b> <b>landmarks</b> as a means of determining the likelihood that an individual sufferer from obstructive sleep apnoea (OSA).|$|R
40|$|Facial {{expression}} recognition methods use {{a combination}} of geometric and appearance-based features. Spatial features are derived from displacements of <b>facial</b> <b>landmarks,</b> and carry geometric information. These features are either selected based on prior knowledge, or dimension-reduced from a large pool. In this study, we produce a large number of potential spatial features using two combinations of <b>facial</b> <b>landmarks.</b> Among these, we search for a descriptive subset of features using sequential forward selection. The chosen feature subset is used to classify facial expressions in the extended Cohn-Kanade dataset (CK+), and delivered 88. 7 % recognition accuracy without using any appearance-based features. Comment: International Conference on Acoustics, Speech and Signal Processing (ICASSP), 201...|$|R
40|$|This thesis {{attempts}} {{to create an}} application to determine head rotation angle in video recorded from a security camera. The application consists of three parts: face detection, <b>facial</b> <b>landmarks</b> detection and determination of person's head rotation. The face detection has been implemented using Viola-Jones and HOG algorithms. <b>Facial</b> <b>landmarks</b> detection has been done using algorithm based on active shape model. Two methods to calculate the head rotation angles have been used: the first method works with anthropometric head features. The second method uses Perspective-n-Point algorithm {{to find the right}} rotation angles. Finally, all algorithms implemented have been tested and the proper parameters have been determined...|$|R
