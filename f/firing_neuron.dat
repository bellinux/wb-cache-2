22|2031|Public
50|$|There {{are many}} {{techniques}} available to record brain activity—including electroencephalography (EEG), magnetoencephalography (MEG), and functional {{magnetic resonance imaging}} (fMRI)—but these do not allow for single-neuron resolution. Neurons are the basic functional units in the brain; they transmit information through the body using electrical signals called action potentials. Currently, single-unit recordings provide the most precise recordings from single neurons. A single unit is defined as a single, <b>firing</b> <b>neuron</b> whose spike potentials are distinctly isolated by a recording microelectrode.|$|E
50|$|The {{generation}} of the action potential is called the “firing.” The <b>firing</b> <b>neuron</b> described above is called a spiking neuron. We will model the electrical circuit of the neuron in Section 3.6. There {{are two types of}} spiking neurons. If the stimulus remains above the threshold level and the output is a spike train, it is called the Integrate-and-Fire (IF) neuron model. If output is modeled as dependent on the impulse response of the circuit, then it is called the Spike Response Model (SRM) (Gestner, W. (1995)).|$|E
50|$|Although most fMRI {{research}} uses BOLD contrast imaging as {{a method}} to determine which {{parts of the brain}} are most active, because the signals are relative, and not individually quantitative, some question its rigor. Other methods which propose to measure neural activity directly have been attempted (for example, measurement of the Oxygen Extraction Fraction, or OEF, in regions of the brain, which measures how much of the oxyhemoglobin in the blood has been converted to deoxyhemoglobin), but because the electromagnetic fields created by an active or <b>firing</b> <b>neuron</b> are so weak, the signal-to-noise ratio is extremely low and statistical methods used to extract quantitative data have been largely unsuccessful so far.|$|E
40|$|The {{membrane}} {{properties and}} conduction velocities of antidromically activated medial septum-diagonal band (MS-DB) neurons were examined using whole-cell recordings in a longitudinally cut rat brain slice preparation containing the MS-DB and the dorsal fornix. MS-DB neurons {{were divided into}} three groups according to their action potential characteristics and firing properties. Slow <b>firing</b> <b>neurons</b> displayed a broad action potential followed by a prominent after-hyperpolarization. Burst <b>firing</b> <b>neurons,</b> when depolarized from hyperpolarized holding potentials, exhibited a high-frequency burst of spikes {{on the crest of}} a slow depolarizing potential. Fast <b>firing</b> <b>neurons</b> did not <b>fire</b> bursts of spikes when depolarized from hyperpolarized holding potentials. Eighteen MS-DB neurons were identified as septohippocampal by antidromic activation. Of the septohippocampal neurons, four were slow <b>firing</b> <b>neurons,</b> five were burst <b>firing</b> <b>neurons</b> and nine were fast <b>firing</b> <b>neurons.</b> The mean axon conduction velocities of these neurons fell into two significant groups, termed slow conducting and fast conducting. Slow <b>firing</b> septohippocampal <b>neurons</b> had significantly slower conduction velocities than either fast firing or burst <b>firing</b> <b>neurons</b> (P < 0. 05), being 0. 7 ± 0. 5 ms− 1 for slow <b>firing</b> <b>neurons</b> and 2. 9 ± 2. 0 and 2. 0 ± 1. 4 ms− 1 for burst firing and fast <b>firing</b> <b>neurons,</b> respectively. On the basis of previous evidence which has linked firing properties with the neurochemical identities of the neurons, we propose that the slow <b>firing</b> septohippocampal <b>neurons</b> are cholinergic whereas the burst firing and fast <b>firing</b> septohippocampal <b>neurons</b> are GABAergic...|$|R
40|$|We {{performed}} whole-cell recordings from {{basal forebrain}} (BF) cholinergic neurons in transgenic mice expressing enhanced {{green fluorescent protein}} (eGFP) {{under the control of}} the choline acetyltransferase promoter. BF cholinergic neurons can be differentiated into two electrophysiologically identifiable subtypes: early and late <b>firing</b> <b>neurons.</b> Early <b>firing</b> <b>neurons</b> (∼ 70 %) are more excitable, show prominent spike frequency adaptation and are more susceptible to depolarization blockade, a phenomenon characterized by complete silencing of the neuron following initial action potentials. Late <b>firing</b> <b>neurons</b> (∼ 30 %), albeit being less excitable, could maintain a tonic discharge at low frequencies. In voltage clamp analysis, we have shown that early <b>firing</b> <b>neurons</b> have a higher density of low voltage activated (LVA) calcium currents. These two cholinergic cell populations might be involved in distinct functions: the early firing group being more suitable for phasic changes in cortical acetylcholine release associated with attention while the late <b>firing</b> <b>neurons</b> could support general arousal by maintaining tonic acetylcholine levels...|$|R
5000|$|A {{quadratic}} integrate and <b>fire</b> <b>neuron</b> {{is defined}} by the autonomous differential equation, ...|$|R
3000|$|... -nullcline {{corresponds}} to a tonically <b>firing</b> <b>neuron,</b> while absence of such an equilibrium {{corresponds to}} an intrinsically bursting neuron. In {{the case of the}} bursting neuron, passage from the right branch of the V [...]...|$|E
40|$|A phase {{response}} curve (PRC) quantifies {{the response of}} a periodically <b>firing</b> <b>neuron</b> to an external stimulus (Figure 1). More specifically, it measures the phase shift of the oscillating neuron {{as a function of}} the phase that a stimulus is delivered. The task of generating a PRC for a real neuron seems straightforward: (1) If the neuron is not oscillating, then inject a constan...|$|E
40|$|A network {{consisting}} of two Stein-type neuronal units is analyzed under the assumption of a complete interaction between the neurons. The firing of each neuron causes a jump of constant amplitude of the membrane potential of the other neuron. The jump is positive or negative according to whether the <b>firing</b> <b>neuron</b> is excitatory or inhibitory. Making use of a simulation procedure designed by ourselves, we study the interspike intervals of the two neurons by means of their histograms, of some descriptive statistics and of empirical distribution functions. Furthermore, via the crosscorrelation function, we investigate the synchronization between the neurons firing activity in the special case when one neuron is excitatory {{and the other is}} inhibitory...|$|E
40|$|Abstract—We {{constructed}} {{a new model}} of an olfactory system with expanded integrate and <b>fire</b> <b>neurons</b> to explore its behaviors with external inputs. The model is built in according to the reliable medical and anatomical data about biological olfactory systems. Expanded integrate and <b>fire</b> <b>neurons</b> become synchronized when the external inputs fall in a small range, which is similar to the standard neurons introduced an applied by Hopfield to the olfactory system. We investigate the range of external input currents leading to synchronization for expanded integrate and <b>fire</b> <b>neurons.</b> This feature is used to recognize spatial patterns which represent odorants. Both spatial and temporal patterns exist in the networks. I...|$|R
40|$|We {{propose a}} simple {{theoretical}} structure of interacting integrate and <b>fire</b> <b>neurons</b> {{that can handle}} fast information processing, and {{may account for the}} fact that only a few neuronal spikes suffice to transmit information in the brain. Using integrate and <b>fire</b> <b>neurons</b> that are subjected to individual noise and to a common external input, we calculate their first passage time (FPT), or inter-spike interval...|$|R
5000|$|... #Caption: Sample raster plot from {{randomly}} {{connected network}} of integrate and <b>fire</b> <b>neurons</b> with exponential inhibitory and excitatory currents.|$|R
30|$|The iPRC at a {{point on}} cycle {{is equal to the}} {{gradient}} of the (isochronal) phase at that point. Writing this vector quantity as Q means that weak forcing ϵ g(t) in the original high-dimensional models transforms as dϑ/dt= 1 +ϵ〈 Q, g 〉 where 〈·,·〉 defines the standard inner product and ϵ is a small parameter. For periodic forcing such equations can be readily analysed, and questions relating to synchronisation, mode-locking and Arnol’d tongues can be thoroughly explored [76]. Moreover, this approach forms the basis for constructing models of weakly interacting oscillators, where the external forcing is pictured {{as a function of the}} phase of a <b>firing</b> <b>neuron.</b> This has led to a great deal of work on phase-locking and central pattern generation in neural circuitry and see for example [43].|$|E
40|$|This paper {{proposes a}} new {{approach}} for a hybrid connectionistHMM speech recognition system. The system consists of a multi-feature HMM-based recognition module using three different neural networks as multiple neural codebooks. Each neural network receives a different feature (i. e. cepstrum, delta cepstrum, and delta power) as input and generates a vector quantizer label obtained from the <b>firing</b> <b>neuron</b> in the output layer. The neural networks are first trained separately using a special self-organizing information theory-based learning method. A 26 % error reduction is obtained with this method, compared {{to the performance of}} the same system using multiple k-means vector quantizers with the same codebook size. In a second training phase, the neural codebooks are further refined by extending the information theory-based training criterion into a joint criterion reflecting the joint information content and the dependencies of the three different label streams. This further improves the er [...] ...|$|E
30|$|For {{several decades}} now, {{the topic of}} {{synaptic}} plasticity has remained relevant. A pioneering theory on this topic is the Hebbian theory of synaptic modification [1, 2], in which Donald Hebb proposed that when neuron A repeatedly participates in <b>firing</b> <b>neuron</b> B, {{the strength of the}} action of A onto B increases. This implies that changes in synaptic strengths in a neural network {{is a function of the}} pre- and post-synaptic neural activities. A few decades later, Nass and Cooper [3] developed a Hebbian synaptic modification theory for the synapses of the visual cortex, which was later extended to a threshold dependent setup by Cooper et al. [4]. In this setup, the sign of a weight modification is based on whether the post-synaptic response is below or above a static threshold. A response above the threshold is meant to strengthen the active synapse, and a response below the threshold should lead to a weakening of the active synapse.|$|E
40|$|The {{problem of}} {{learning}} {{in the absence of}} external intelligence is discussed {{in the context of a}} simple model. The model consists of a set of randomly connected, or layered integrate-and <b>fire</b> <b>neurons.</b> Inputs to and outputs from the environment are connected randomly to subsets of neurons. The connections between <b>firing</b> <b>neurons</b> are strengthened or weakened according to whether the action is successful or not. The model departs from the traditional gradient-descent based approaches to learning by operating at a highly susceptible ``critical'' state, with low activity and sparse connections between <b>firing</b> <b>neurons.</b> Quantitative studies on the performance of our model in a simple association task show that by tuning our system close to this critical state we can obtain dramatic gains in performance. Comment: 9 pages (TeX), 3 figures supllied on reques...|$|R
50|$|The {{following}} code defines, {{runs and}} plots a randomly connected network of leaky integrate and <b>fire</b> <b>neurons</b> with exponential inhibitory and excitatory currents.|$|R
40|$|We {{investigate}} {{the emergence of}} in-phase synchronization in a heterogeneous network of coupled inhibitory interneurons {{in the presence of}} spike timing dependent plasticity (STDP). Using a simple network of two mutually coupled interneurons (2 -MCI), we first study the effects of the STDP on in-phase synchronization. We demonstrate that, with STDP, the 2 -MCI network can evolve to either a state of stable 1 : 1 in-phase synchronization or exhibit multiple regimes of higher order synchronization states. We show that the emergence of synchronization induces a structural asymmetry in the 2 -MCI network such that the synapses onto the high frequency <b>firing</b> <b>neurons</b> are potentiated, while those onto the low frequency <b>firing</b> <b>neurons</b> are de-potentiated, resulting in the directed flow of information from low frequency <b>firing</b> <b>neurons</b> to high frequency <b>firing</b> <b>neurons.</b> Finally, we demonstrate that the principal findings from our analysis of the 2 -MCI network contribute to the emergence of robust synchronization in the Wang-Buzsaki network (Wang and Buzsaki, 1996) of all-to-all coupled inhibitory interneurons (100 -MCI) for a significantly larger range of heterogeneity in the intrinsic firing rate of the neurons in the network. We conclude that STDP of inhibitory synapses provide a viable mechanism for robust neural synchronization...|$|R
40|$|Abstract. An {{important}} part of the neocortical layer 5 (L 5) pyramidal cells are intrinsically burst firing neurons. To examine the influence of the basal arborization on the firing pattern of this cell type, computer simulations were run using a ‘standard ’ model neuron and on four models obtained by altering the number or lengths of the basal trees arising from the soma. All models were endowed with 16 types of intrinsic active currents and complex Ca 2 + dynamics. The simulations showed that the enlargement of the basal arborization leads to the diminution of the number of spikes/burst during the injection of a long current pulse, while its reduction has an opposite effect. Therefore, in the pyramidal cells of layer 5, the basal structure does not play {{an active role in the}} development of the depolarizing envelope underlying a burst. Key words: burst <b>firing</b> <b>neuron,</b> multicompartmental modeling methods, basal arborization 1...|$|E
40|$|In {{this paper}} we {{introduce}} {{a novel approach}} for character recognition based on the pen movement i. e., recognition based on sequence of pen strokes. A Backpropagation Neural Network is used for identifying individual strokes. The recognizer has a two-pass architecture i. e., the inputs are propagated twice through the network. The first pass does the initial classification and the second for exact recognition. The two-pass structure of the recognizer helped in achieving accuracy of about 95 percent in recognizing Malayalam letters. The training set contains samples of all independent strokes that are commonly used while writing Malayalam. Input values to the network are the directions of pen movement. A “minimum error” technique is used for finding the <b>firing</b> <b>neuron</b> in the output layer. Based on the output of FirstPass the network is dynamically loaded with a fresh set of weights for exact stroke recognition. Analyzing the stroke sequences identifies individual characters. This work also demonstrates how a statistical pre-analysis of training set reduces training time...|$|E
40|$|International audienceThe Network Noisy Leaky Integrate and Fire {{equation}} {{is among the}} simplest model allowing for a self-consistent description of neural networks and gives a rule to determine the probability to find a neuron at the potential $v$. However, its mathematical structure is still poorly understood and, concerning its solutions, very few results are available. In the midst of them, a recent result shows blow-up in finite time for fully excitatory networks. The intuitive explanation is that each <b>firing</b> <b>neuron</b> induces a discharge of the others; thus increases the activity and consequently the discharge rate of the full network. In order {{to better understand the}} details of the phenomena and show that the {{equation is}} more complex and fruitful than expected, we analyze further the model. We extend the finite time bow-up result to the case when neurons, after firing, enter a refractory state for a given period of time. We also show that spontaneous activity may occur when, additionally, randomness is included on the firing potential $V_F$ in regimes where blow-up occurs for a fixed value of $V_F$...|$|E
40|$|Distinct {{functional}} {{roles in}} learning and memory {{are attributed to}} {{certain areas of the}} hippocampus and the parahippocampal region. The subiculum {{as a part of the}} hippocampal formation is the principal target of CA 1 pyramidal cell axons and serves as an interface in the information processing between the hippocampus and the neocortex. Subicular pyramidal cells have been classified as bursting and regular firing cells. Here we report fundamental differences in long-term potentiation (LTP) between both cell types. Prolonged high-frequency stimulation induced NMDA receptor-dependent LTP in both cell types. While LTP relied on postsynaptic calcium in regular <b>firing</b> <b>neurons,</b> no increase in postsynaptic calcium was required in bursting cells. Furthermore, paired-pulse facilitation revealed that the site of LTP expression was postsynaptic in regular <b>firing</b> <b>neurons,</b> while presynaptic in burst <b>firing</b> <b>neurons.</b> Our findings on synaptic plasticity in the subiculum indicate that regular firing and bursting cells represent two functional units with distinct physiological roles in processing hippocampal output...|$|R
50|$|The {{brains are}} basic neural {{networks}} that {{show up as}} a network of <b>firing</b> <b>neurons.</b> The genetic script serves as the blueprints for the exact assembly and functioning of the neural network.|$|R
3000|$|During {{the firing}} procedure, the {{intensity}} {{value of each}} pixel {{and the status of}} its neighbors (active or inactive) determine what time a <b>neuron</b> <b>fires.</b> <b>Neurons</b> in the same region or with an approximate [...]...|$|R
40|$|Additional contributor: Theoden Netoff (faculty mentor). The {{general purpose}} of this project is to {{understand}} how neurons in a network interact during a seizure. This knowledge would allow for a better comprehension of seizures, {{as well as the}} improvement of current treatment options. To accomplish this, Phase Response Curves (PRCs) are used to measure how a periodically <b>firing</b> <b>neuron</b> is perturbed by synaptic inputs. By understanding how a single neuron responds to these inputs, it can be predicted whether a network of neurons will synchronize or not. Currently in the medical field it is accepted that anti-epileptic drugs work, but no one understand why they work the way they do. The preliminary results for this project indicate that some anti-epileptic drugs increase synchrony. This finding is contrary to the general belief that epilepsy is caused by hyper-synchrony, in which case increasing synchrony should cause more seizures. This project examines how the anti-epileptic drug, Phenytoin affects the PRC and thusly the synchrony of the neuronal network. Once it is known whether Phenytoin increases or decreases synchrony, people can use this knowledge to increase the efficiency of anti-epileptic drugs which will be beneficial for individuals with epilepsy...|$|E
40|$|This study {{introduces}} a new spike sorting method that classifies spike waveforms from multiunit recordings into spike trains of individual neurons. In particular, we develop {{a method to}} sort a spike mixture generated by a heterogeneous neural population. Such a spike sorting has a significant practical value, but was previously difficult. The method combines a feature extraction method, which we may term “multimodality-weighted principal component analysis” (mPCA), and a clustering method by variational Bayes for Student's t mixture model (SVB). The performance of the proposed method was {{compared with that of}} other conventional methods for simulated and experimental data sets. We found that the mPCA efficiently extracts highly informative features as clusters clearly separable in a relatively low-dimensional feature space. The SVB was implemented explicitly without relying on Maximum-A-Posterior (MAP) inference for the “degree of freedom” parameters. The explicit SVB is faster than the conventional SVB derived with MAP inference and works more reliably over various data sets that include spiking patterns difficult to sort. For instance, spikes of a single bursting neuron may be separated incorrectly into multiple clusters, whereas those of a sparsely <b>firing</b> <b>neuron</b> tend to be merged into clusters for other neurons. Our method showed significantly improved performance in spike sorting of these “difficult” neurons. A parallelized implementation of the proposed algorithm (EToS version 3) is available as open-source code at [URL]...|$|E
40|$|Abstract—We {{extend the}} concept of timing/phase macromodels, pre-viously {{established}} rigorously only for oscillators, to apply to gen-eral systems, both non-oscillatory and oscillatory. We do so by first establishing a solid foundation for the timing/phase response of any nonlinear dynamical system, then deriving a timing/phase macromodel via nonlinear perturbation analysis. The macromodel that emerges is a scalar, nonlinear time-varying equation that accurately characterizes the system’s phase/timing responses. We establish strong links of this technique with projection frameworks for model order reduction. We then present numerical methods to compute the phase model. The computation involves a full Floquet decomposition – we discuss numerical issues that arise if direct computation of the monodromy matrix is used for Floquet analysis, and propose an alternative method that are numerically superior. The new method has elegant connections to the Jacobian matrix in harmonic balance method (readily available in most RF simulators). We validate the technique on several highly nonlinear systems, in-cluding an inverter chain and a <b>firing</b> <b>neuron.</b> We demonstrate that the new scalar nonlinear phase model captures phase responses under various types of input perturbations, achieving accuracies consider-ably superior to those of reduced models obtained using LTI/LPTV MOR methods. Thus, we establish a powerful new way to extract timing models of combinatorial/sequential systems and memory (e. g., SRAMs/DRAMs), synchronization systems based on oscillator enslaving (e. g., PLLs, injection-locked oscillators, CDR systems, neural processing, energy grids), signal-processing blocks (e. g., ADCs/DACs, FIR/IIR filters), etc [...] I...|$|E
40|$|The rostral {{nucleus of}} the solitary tract (rNST) plays {{a pivotal role in}} taste processing. The rNST {{contains}} projection neurons and interneurons that differ in morphology and intrinsic membrane properties. Although characteristics of the projection neurons have been detailed, similar information is lacking on the interneurons. We determined the intrinsic properties of the rNST GABAergic interneurons using a transgenic mouse model that expresses enhanced green fluorescent protein under the control of a GAD 67 promoter. Glutamic acid decarboxylase–green fluorescent protein (GAD 67 –GFP) neurons were distributed throughout the rNST but were concentrated in the ventral subdivision with minimal interaction with the terminal field of the afferent input. Furthermore, the density of the GAD 67 –GFP neurons decreased in more rostral areas of rNST. In whole cell recordings, GAD 67 –GFP neurons responded with either an initial burst (73 %), tonic (18 %), or irregular (9 %) discharge pattern of action potentials (APs) in response to membrane depolarization. These three groups also differed in passive and AP characteristics. Initial burst neurons had small ovoid or fusiform cell bodies, whereas tonic <b>firing</b> <b>neurons</b> had large multipolar or fusiform cell bodies. Irregular <b>firing</b> <b>neurons</b> had larger spherical soma. Some of the initial burst and tonic <b>firing</b> <b>neurons</b> were also spontaneously active. The GAD 67 –GFP neurons could also be categorized in subgroups based on colocalization with somatostatin and parvalbumin immunolabeling. Initial burst neurons would transmit the early dynamic portion of the encoded sensory stimuli, whereas tonic <b>firing</b> <b>neurons</b> could respond to both dynamic and static components of the sensory input, suggesting different roles for GAD 67 –GFP neurons in taste processing...|$|R
40|$|The {{problem of}} {{optimising}} {{a network of}} discretely <b>firing</b> <b>neurons</b> is addressed. An objective function is introduced which measures {{the average number of}} bits that are needed for the network to encode its state. When this is minimised, it is shown that this leads to a number of results, such as topographic mappings, piecewise linear dependence on the input of the probability of a <b>neuron</b> <b>firing,</b> and factorial encoder networks. Comment: 14 page...|$|R
50|$|Dystonia is a {{neurological}} disease affecting the brain's ability to <b>fire</b> <b>neurons</b> (which control muscle movement) correctly. Focal dystonia specifically affects one particular {{area of the}} body and is usually completely isolated, affecting only one activity. The disease basically renders the sufferer unable to control the muscles in the affected area.|$|R
40|$|When a neuron {{fires and}} the {{resulting}} action potential travels down its axon toward other neurons ’ dendrites, the effect on each of those neurons is mediated {{by the weight of}} the synapse that separates it from the <b>firing</b> <b>neuron.</b> This weight, in turn, is affected by the postsynaptic neuron’s response through a mechanism that is thought to underlie important processes such as learning and memory. Although of difficult quantification, cortical synaptic weights have been found to obey a long-tailed unimodal distribution peaking near the lowest values, thus confirming some of the predictive models built previously. These models are all causally local, {{in the sense that they}} refer to the situation in which a number of neurons all fire directly at the same postsynaptic neuron. Consequently, they necessarily embody assumptions regarding the generation of action potentials by the presynaptic neurons that have little biological interpretability. In this letter we introduce a network model of large groups of interconnected neurons and demonstrate, making none of the assumptions that characterize the causally local models, that its long-term behavior gives rise to a distribution of synaptic weights with the same properties that were experimentally observed. In our model the action potentials that create a neuron’s input are, ultimately, the product of network-wide causal chains relating what happens at a neuron to the firings of others. Our model is then of a causally global nature and predicates the emergence of the synaptic-weight distribution on network structure and function. As such, it has the potential to become instrumental also in the study of other emergent cortical phenomena...|$|E
40|$|UNiversity of Minnesota Ph. D. dissertation. August 2012. Major: Biomedical Engineering. Advisor: Theoden I. Netoff. 1 {{computer}} file (PDF); viii, 143 pages, appendices A-D. Computational models of neurons have {{provided us with}} {{a deeper understanding of}} neuroscience by allowing us to test hypotheses in ways that can be impossible in experiments. Models are used for simulations of the nervous system, to test a hypothesis of how it works. They can also be useful in identifying gaps in our understanding. Here I propose different methods to generate models that can predict behaviors from neurons. I have developed different models that can describe neuronal activity at different time scales. For a full description of the voltage trace, and sampling rates higher than 1 KHz, an Unscented Kalman Filter (UKF) is used to fit a set of parameters of a given mathematical model. The UKF predicts the voltage of the neuron for the next sampling time. For the study of spike rate variability, I introduce the use of fixed and adaptive linear models. These models are able to predict the neuron's firing rate in response to stimuli. These models were then used to control the neuron's spike rate. Finally, I introduce two new methods to measure how the spiking activity of a given neuron can be modified by synaptic inputs. One method is able to describe the change in the period of a periodically <b>firing</b> <b>neuron</b> given the applied current and the time of the synaptic input. The second method generates a model that can predict the spike times given noisy waveforms in non-regular spiking neurons...|$|E
40|$|Many {{processes}} in the brain, both normal and pathological, involve oscillations of neuronal populations. The ability to enhance or disrupt neuronal synchrony has been clinically demonstrated to have remarkable effects {{in a number of}} neurological disorders including: Parkinson’s disease, Epilepsy, and Depression [1, 2]. We have developed an algorithm to control the spike timing of periodically <b>firing</b> <b>neuron</b> using patch clamp and realtime dynamic clamp techniques [3]. Furthermore, this algorithm was expanded to control the relative spike timing between two oscillating neurons. These present the first steps towards more precise population control schemes. The single cell controller uses the neurons phase response curve and the relationship between the spike advance and the current injection at a given stimulus phase to create a control function [4]. The two cell controller uses the same premise as the single cell controller, but incorporates additional logic to determine the direction and number of periods required to achieve the target phase offset. We tested our controller using a real-time model neuron and CA 1 pyramidal neurons [5]. Noise was added to the model neuron to replicate that seen in biological neurons. In single cell control experiments, the controller could account for ~ 99 % and ~ 87 % of the neurons variance for the model and CA 1 pyramidal neuron, respectively. In two cell experiments, we tested the controller using two noisy model neurons and we performed hybrid testing using a model neuron as the leader and a pyramidal neuron as the follower. In the hybrid case, the controller accuracy was moderate, with a normalized vector correlation of 0. 69. In the tw...|$|E
40|$|To {{examine the}} role of striatal {{mechanisms}} in cocaine-induced stereotyped licking, we investigated the acute effects of cocaine on striatal neurons in awake, freely moving rats before and after cocaine administration (0, 5, 10, or 20 mg/kg). Stereotyped licking was induced only by the high dose. Relative to control (saline), cocaine reduced lick duration and concurrently increased interlick interval, particularly at the high dose, {{but it did not}} affect licking rhythm. Firing rates of striatal neurons phasically related to licking movements were compared between matched licks before and after injection, minimizing any influence of sensorimotor variables on changes in firing. Both increases and decreases in average firing rate of striatal neurons were observed after cocaine injection,and these changes exhibited a dose-dependent pattern that strongly depended on predrug firing rate. At the middle and high doses relative to the saline group, the average firing rates of slow <b>firing</b> <b>neurons</b> were increased by cocaine, resulting from a general elevation of movement-related firing rates. In contrast, fast <b>firing</b> <b>neurons</b> showed decreased average firing rates only in the high-dose group, with reduced firing rates across the entire range for these neurons. Our findings suggest that at the high dose, increased phasic activity of slow <b>firing</b> striatal <b>neurons</b> and simultaneously reduced phasic activity of fast <b>firing</b> striatal <b>neurons</b> may contribute, respectively, to the continual initiation of stereotypic movements and the absence of longer movements...|$|R
40|$|We {{describe}} an algorithm to control synchrony between two periodically <b>firing</b> <b>neurons.</b> The control scheme operates in real-time using a dynamic clamp platform. This algorithm is a low-impact stimulation method {{that brings the}} neurons toward the desired level of synchrony {{over the course of}} several <b>neuron</b> <b>firing</b> periods. As a proof of principle, we demonstrate the versatility of the algorithm using real-time conductance models and then show its performance with biological neurons of hippocampal region CA 1 and entorhinal cortex...|$|R
40|$|This paper {{introduces}} a hierarchical learning architecture that grows online an adaptive problem representation from scratch. The representation extracts frequent perceptual patterns representing {{them in a}} layered hierarchy where neural activity in higher layers is initiated bottom-up by <b>firing</b> <b>neurons</b> in lower layers and, vice versa, <b>firing</b> <b>neurons</b> in higher layers predispose activity and provide reinforcement feedback to neurons in lower layers. The structure evolves by a mixture of reinforcement learning and a genetic algorithm. Learning is biased towards extracting frequently recurring sequences in an input stream. We evaluate the architecture on a text document, which is presented iteratively—character by character—to the system. The {{results show that the}} proposed system reliably evolves representations of most frequent characters, syllables, and words in the document. We also confirm that top-down influences bias the evolution of syllable and character representations...|$|R
