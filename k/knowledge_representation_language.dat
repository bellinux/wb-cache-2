332|10000|Public
2500|$|The name Prolog {{was chosen}} by Philippe Roussel as an {{abbreviation}} for [...] (French for programming in logic). [...] It was created around 1972 by Alain Colmerauer with Philippe Roussel, based on Robert Kowalski's procedural interpretation of Horn clauses. [...] It was motivated {{in part by the}} desire to reconcile the use of logic as a declarative <b>knowledge</b> <b>representation</b> <b>language</b> with the procedural representation of knowledge that was popular in North America in the late 1960s and early 1970s. [...] According to Robert Kowalski, the first Prolog system was developed in 1972 by Colmerauer and Phillipe Roussel. The first implementations of Prolog were interpreters. However, David H. D. Warren created the Warren Abstract Machine, an early and influential Prolog compiler which came to define the [...] "Edinburgh Prolog" [...] dialect which served {{as the basis for the}} syntax of most modern implementations.|$|E
2500|$|Meta-representation. This is {{also known}} as the issue of {{reflection}} in computer science. It refers to the capability of a formalism to have access to information about its own state. An example would be the meta-object protocol in Smalltalk and CLOS that gives developers run time access to the class objects and enables them to dynamically redefine the structure of the knowledge base even at run time. Meta-representation means the <b>knowledge</b> <b>representation</b> <b>language</b> is itself expressed in that language. For example, in most Frame based environments all frames would be instances of a frame class. That class object can be inspected at run time so that the object can understand and even change its internal structure or the structure of other parts of the model. In rule-based environments the rules were also usually instances of rule classes. Part of the meta protocol for rules were the meta rules that prioritized rule firing.|$|E
5000|$|ClearTalk, another {{machine-readable}} <b>knowledge</b> <b>representation</b> <b>language</b> ...|$|E
5000|$|Web Ontology Language (OWL), {{a family}} of <b>knowledge</b> <b>representation</b> <b>languages</b> ...|$|R
5000|$|In <b>knowledge</b> <b>representation</b> <b>languages,</b> meronymy {{is often}} {{expressed}} as [...] "part-of".|$|R
40|$|There {{are some}} {{difficulties}} in using natural <b>languages</b> as <b>knowledge</b> <b>representation</b> <b>languages</b> for computer systems. However, natural languages {{are the most}} frequently used <b>knowledge</b> <b>representation</b> <b>languages</b> for humanbeings. A way of automatic construction of knowledge-base by using Korean text is described in this paper. Dependency grammar has been used for parsing and the meaning of each sentence is represented with a conceptual graph. There are some difficulties in usin...|$|R
5000|$|LOOM <b>knowledge</b> <b>representation</b> <b>language</b> and environment, or LOOM (ontology) ...|$|E
5000|$|LOOM - <b>knowledge</b> <b>representation</b> <b>language</b> {{developed}} by {{researchers in the}} AI research group at ISI ...|$|E
5000|$|Daniel G. Bobrow, Terry Winograd, An Overview of KRL, A <b>Knowledge</b> <b>Representation</b> <b>Language,</b> Stanford Artificial Intelligence Laboratory Memo AIM 293, 1976.|$|E
40|$|Different Semantic Web {{applications}} can {{use different}} <b>knowledge</b> <b>representation</b> <b>languages.</b> Exchanging <b>knowledge</b> thus requires techniques for ensuring semantic interoperability across languages. We present the `family of languages' approach {{based on a}} set of <b>knowledge</b> <b>representation</b> <b>languages</b> whose partial ordering depends on the transformability from one language to another by preserving a particular formal property such as logical consequence. For the same set of languages, there can be several such structures based on the property selected for structuring the family...|$|R
40|$|We {{argue that}} decidable classes of {{predicate}} logic combined with efficient decision methods are a suitable basis for developing powerful <b>knowledge</b> <b>representation</b> <b>languages.</b> The paper presents some methods for developing such languages based on decidable classes. Queries {{can be answered}} and databases can be completed by using efficient decision refinements of the resolution method. Several decidable classes usable as new <b>knowledge</b> <b>representation</b> <b>languages</b> are presented, containing some well-known ones, like the base language ALC of KL-ONE type systems, along with the resolution-based inference engines...|$|R
40|$|Decisions in {{a dynamic}} {{environment}} may {{be based on}} information coming {{from a number of}} different knowledge sources described using different <b>knowledge</b> <b>representation</b> <b>languages.</b> This paper describes a common framework in which the data and rules, both static and dynamic, that may exist in disparate knowledge sources may be represented. We focus on two commonly used <b>knowledge</b> <b>representation</b> <b>languages,</b> namely SQL and OWL-DL. We have chosen these as examples because they make different assumptions about the knowledge they hold and we use them to show that our framework can represent knowledge under these different assumptions...|$|R
50|$|Usually the <b>knowledge</b> <b>{{represent}}ation</b> <b>language</b> only allows {{to represent}} knowledge (about kinds of things), whereas another language or data structure {{is required to}} represent and store the information models about individual things. If the <b>knowledge</b> <b>representation</b> <b>language</b> enables to express both, then the knowledge model and the information model can be expressed in the same language (or data structure). An example of a language that enables the expression of knowledge {{as well as information}} about individual things is Gellish English.|$|E
50|$|A <b>knowledge</b> <b>representation</b> <b>language</b> may be {{sufficiently}} expressive to describe nuances {{of meaning in}} well understood fields. There are at least five levels of complexity of these.|$|E
5000|$|KRL is a <b>knowledge</b> <b>representation</b> <b>language,</b> {{developed}} by Daniel G. Bobrow and Terry Winograd while at Xerox PARC and Stanford University, respectively. It is a frame-based language.|$|E
40|$|Standard <b>knowledge</b> <b>representation</b> <b>languages</b> {{are seriously}} lacking an {{explicit}} formal semantic specification. This may cause considerable trouble {{when applied to}} large amounts of rapidly changing data. Based on an abstract data type view of <b>knowledge</b> <b>representation</b> <b>languages</b> a formal definition of a frame data model is presented {{in terms of a}} denotational semantics approach using a subset of META-IV. After introducing some basic concepts of the model several semantic integrity constraints are outlined which ultimately lead to the formulation of a set of operations in the frame data model...|$|R
40|$|Abstract: Recent {{fashion in}} <b>knowledge</b> <b>representation</b> <b>languages</b> {{is to use}} XML as the {{low-level}} syntax. This tends to make the output of these <b>knowledge</b> <b>representation</b> <b>languages</b> easy for machines to parse, {{at the expense of}} human readability. The strength of XML lies in its simplicity to represent data and knowledge. It is used to develop modeling languages that are tailored to specific knowledge, and specific data structures and hierarchies. This paper considers an approach to frame <b>knowledge</b> <b>representation</b> using XML. A generalized XML model of the frame-based representation is proposed. The implementation of the XML generator, which is built into the interactive tool for frame representation is described...|$|R
25|$|<b>Knowledge</b> <b>representation</b> {{goes hand in}} {{hand with}} {{automated}} reasoning because one of the main purposes of explicitly representing knowledge is to be able to reason about that knowledge, to make inferences, assert new knowledge, etc. Virtually all <b>knowledge</b> <b>representation</b> <b>languages</b> have a reasoning or inference engine as part of the system.|$|R
5000|$|Communication at the {{knowledge}} level: Agents may {{communicate with each}} other to exchange information, and to coordinate their actions. GOAL agents communicate using the <b>knowledge</b> <b>representation</b> <b>language</b> that is also used to represent their beliefs and goals.|$|E
5000|$|Universal Networking Language (UNL) is a {{declarative}} {{formal language}} {{specifically designed to}} represent semantic data extracted from natural language texts. It {{can be used as}} a pivot language in interlingual machine translation systems or as a <b>knowledge</b> <b>representation</b> <b>language</b> in information retrieval applications.|$|E
50|$|Loom is a <b>knowledge</b> <b>representation</b> <b>language</b> {{developed}} by {{researchers in the}} artificial intelligence research group at the University of Southern California's Information Sciences Institute. The leader of the Loom project and primary architect for Loom was Robert MacGregor. The research was primarily sponsored by the Defense Advanced Research Projects Agency (DARPA).|$|E
40|$|In {{this paper}} I {{want to focus}} on some {{principal}} differences between data models of database systems and <b>knowledge</b> <b>representation</b> <b>languages.</b> The data manipulation languages of data models are based on the closed-world, unique-name, and domain-closure assumption. Data manipulation languages and query <b>languages</b> of <b>knowledge</b> <b>representation</b> formalisms differ considerably in their underlying assumptions. They are based on the open-world, unique-name, and open-domain assumption. That means, that even if the data definition language and the data manipulation language of a database management system and a knowledge base management system would coincide, the results of data manipulations would differ. I present some examples that show the usefulness of closed-world inferences in natural <b>language</b> processing. Thus <b>knowledge</b> <b>representation</b> <b>languages</b> sticking to the open-world assumption seem to be insufficient for natural language processing...|$|R
40|$|In {{this paper}} a {{probabilistic}} extensions for terminological <b>knowledge</b> <b>representation</b> <b>languages</b> is defined. Two kinds of probabilistic statements are introduced: statements about conditional probabilities between concepts and statements expressing uncertain knowledge about a specific object. The usual model-theoretic semantics for terminological logics are extended to define interpretations for the resulting probabilistic language. It is our main objective {{to find an}} adequate modelling {{of the way the}} two kinds of probabilistic knowledge are combined in commonsense inferences of probabilistic statements. Cross entropy minimization is a technique {{that turns out to be}} very well suited for achieving this end. 1 INTRODUCTION Terminological <b>knowledge</b> <b>representation</b> <b>languages</b> (concept languages, terminological logics) are used to describe hierarchies of concepts. While the expressive power of the various languages that have been defined (e. g. KL-ONE [BS 85] ALC [SSS 91]) varies greatly in that [...] ...|$|R
40|$|Abstract. We {{argue that}} decidable classes of {{predicate}} logic combined with efficient decision methods are a suitable basis for developing powerful <b>knowledge</b> <b>representation</b> <b>languages.</b> The paper presents some methods for developing such languages based on decidable classes. Queries {{can be answered}} and databases can be completed by using efficient decision refinements of the resolution method. Several decidable classes usable as new <b>knowledge</b> <b>representation</b> <b>languages</b> are presented, containing some well-known ones, like the base language ALC of KL-ONE type systems, along with the resolution-based inference engines. 1 Introduction We argue that the basic characteristic of deductive database languages (like DATALOG) and knowledge-representation languages (eg KL-ONE) is decidability. I. e, any query must terminate and give either a negative or a positive answer. This is {{in sharp contrast to}} using full first-order logic or non-decidable sublanguages like Horn clauses (the basis of PROLOG), whe [...] ...|$|R
5000|$|Declarative beliefs: Agents use a symbolic, logical {{language}} {{to represent the}} information they have, and their beliefs or knowledge about the environment they act upon {{in order to achieve}} their goals. This <b>knowledge</b> <b>representation</b> <b>language</b> is not fixed by GOAL but, in principle, may be varied according {{to the needs of the}} programmer.|$|E
50|$|For example, the Web Ontology Language {{expression}} language profile (OWL2 EL) lacks ideas (such as negation) {{which can be}} expressed in OWL2 RL (rule language). OWL2 EL may therefore {{be said to have}} less expressive power than OWL2 RL. These restrictions allow more efficient (polynomial time) reasoning in OWL2 EL than in OWL2 RL. So OWL2 EL trades some expressive power for more efficient reasoning (processing of the <b>knowledge</b> <b>representation</b> <b>language).</b>|$|E
50|$|Guha {{was one of}} {{the early}} co-leaders of the Cyc Project where he worked from 1987 through 1994 at Microelectronics and Computer Technology Corporation in {{collaboration}} with Douglas Lenat. He was responsible for the design and implementation of key parts of the Cyc system, including the CycL <b>knowledge</b> <b>representation</b> <b>language,</b> the upper ontological layers of the Cyc Knowledge Base and some parts of the original Cyc Natural Language understanding system.|$|E
40|$|Rulelog is {{the logic}} {{underlying}} <b>knowledge</b> <b>representation</b> <b>languages</b> such as FLORA- 2 and SILK. It combines {{much of the}} latest work in logic programming, non-monotonic reasoning, business rules, and the Semantic Web. It {{is designed to be}} appropriately expressive for supporting <b>knowledge</b> <b>representation</b> in complex domains, such as sciences and law, and yet to be efficiently implementable. This document provides a formal account of the syntax and semantics of Rulelog...|$|R
50|$|After the {{standardization}} of <b>knowledge</b> <b>representation</b> <b>languages</b> such as RDF and OWL, much {{research has been}} conducted in the area, especially regarding transforming relational databases into RDF, identity resolution, knowledge discovery and ontology learning. The general process uses traditional methods from information extraction and extract, transform, and load (ETL), which transform the data from the sources into structured formats.|$|R
40|$|Schmidt-SchaulL M. and G. Smolka, Attributive concept {{descriptions}} with complements, Artificial Intelligence 48 (1991) 1 - 26. We {{investigate the}} consequences of adding unions and complements to attributive concept descriptions employed in terminological <b>knowledge</b> <b>representation</b> <b>languages.</b> It is shown that deciding coherence and subsumption of such descriptions are PSPACE-complete problems that can be decided with linear space. I...|$|R
50|$|Story {{annotation}} {{consists of}} annotating {{the content of}} narratives. In most cases, this effort is undertaken {{with the goal of}} constructing corpora of annotated narratives, or story corpora, finalised at the study {{of the relationship between the}} linguistic expression of the story in the narrative and its content. In the last decade, to a number of research initiatives especially oriented to the description of story and characters. For example, consider the Narrative <b>Knowledge</b> <b>Representation</b> <b>Language</b> (NKRL) and the DramaBank project, specifically oriented to the representation of story content in natural language texts.|$|E
5000|$|The first {{definition}} of the cognitive network was provided by Theo Kantor in his doctoral research at KTH, The Royal Institute of Technology, Stockholm, including a presentation in June 1998 of the cognitive network as the network with memory. Theo was a student of Chip Maguire who also was advising Joe Mitola, the originator of cognitive radio. Mitola focused on cognition in the nodes, while Kantor focused on cognition in the network. Mitola's Licentiate thesis, published in August, 1999 includes the following quote [...] "Over time, the <b>Knowledge</b> <b>Representation</b> <b>Language</b> RKRL-empowered network can learn to distinguish {{a feature of the}} natural environment that does not match the models. It could declare the errors to a cognitive network." [...] This is the earliest publication of the concept cognitive network, since Kantor published a bit later.|$|E
5000|$|The name Prolog {{was chosen}} by Philippe Roussel as an {{abbreviation}} for [...] (French for programming in logic). It was created around 1972 by Alain Colmerauer with Philippe Roussel, based on Robert Kowalski's procedural interpretation of Horn clauses. It was motivated {{in part by the}} desire to reconcile the use of logic as a declarative <b>knowledge</b> <b>representation</b> <b>language</b> with the procedural representation of knowledge that was popular in North America in the late 1960s and early 1970s. According to Robert Kowalski, the first Prolog system was developed in 1972 by Colmerauer and Phillipe Roussel. The first implementations of Prolog were interpreters. However, David H. D. Warren created the Warren Abstract Machine, an early and influential Prolog compiler which came to define the [...] "Edinburgh Prolog" [...] dialect which served {{as the basis for the}} syntax of most modern implementations.|$|E
50|$|The {{second type}} of {{languages}} have a formal logical basis, i.e. they have a formal syntax and semantics, and can be mapped to an existing formal language, such as first-order logic. Thus, those languages {{can be used as}} <b>knowledge</b> <b>representation</b> <b>languages,</b> and writing of those languages is supported by fully automatic consistency and redundancy checks, query answering, etc.|$|R
40|$|Abstract This paper {{studies the}} problem of {{probabilistic}} inference and learning in a logic-based setting. We show how probability densities, being functions, can be represented and reasoned with naturally and directly in higher-order logic, an expres-sive formalism not unlike the (informal) everyday language of mathematics. We give efficient inference algorithms and illustrate the general approach with a di-verse collection of applications. The problem of acquiring probabilistic theories {{in the context of}} agent systems is also considered. 1 Introduction Complex computer applications, especially those needing the technology of artificial intelligence,require rich <b>knowledge</b> <b>representation</b> <b>languages.</b> Such applications typically involve structured knowledge for which some form of logic provides a suitable language for knowledge representationand reasoning. These applications also typically involve uncertainty for which probability theory is required. Thus it is natural to look for <b>knowledge</b> <b>representation</b> <b>languages</b> that combine theexpressive power of both logic and probability...|$|R
40|$|The Unit Package is an {{interactive}} <b>knowledge</b> <b>representation</b> system with representations for individuals, classes, indefinite individuals, and abstractions. Links between the nodes are structured with explicit definitional roles, types of inheritance, defaults, and various data formats. This paper presents the general {{ideas of the}} Unit Package and compares it with other current <b>knowledge</b> <b>representation</b> <b>languages.</b> The Unit Package was created for a hierarchical planning application, {{and is now in}} use by several AI projects...|$|R
