27|9|Public
2500|$|The next {{production}} phase, {{which the}} French call gavage or <b>finition</b> d'engraissement, or [...] "completion of fattening", involves forced daily ingestion of controlled amounts of feed for 12 to 15 days with ducks and for 15 to 18 days with geese. During this phase, ducks are usually fed twice daily while geese {{are fed up}} to three times daily. To facilitate handling of ducks during gavage, these birds are typically housed throughout this phase in individual cages or small group pens.|$|E
5000|$|Groupement des Professionnels de la Peinture et de la <b>Finition</b> ...|$|E
5000|$|The next {{production}} phase, {{which the}} French call gavage or <b>finition</b> d'engraissement, or [...] "completion of fattening", involves forced daily ingestion of controlled amounts of feed for 12 to 15 days with ducks and for 15 to 18 days with geese. During this phase, ducks are usually fed twice daily while geese {{are fed up}} to three times daily. To facilitate handling of ducks during gavage, these birds are typically housed throughout this phase in individual cages or small group pens.|$|E
5000|$|... "On remarque chez lui {{plusieurs}} constantes en dehors de sa passion pour l’architecture qui inspire le projet intérieur : des volumes clairs et structurés, l’amour des meubles bien dessinés néoclassiques ou design américain des années 50- de belles matières, des <b>finitions</b> impeccables"("Paris, un Art de Vivre" [...] by Alexandra d’Arnoux and Jacques Denarnaud) ...|$|R
40|$|In Molecular Dynamics (MD), {{the forces}} applied to atoms derive from {{potentials}} which describe {{the energy of}} bonds, valence angles, torsion angles, and Lennard-Jones interactions of which molecules are made. These de <b>finitions</b> are classic; on the contrary, their implementation in a MD system which respects local equilibrium of mechanical conditions is usually not described. The precise derivation of the forces from the potential and the proof that their application preserves energy {{is the object of}} this note. This work is part of the building of a multi-scale MD system, presently under development. Comment: 11 page...|$|R
40|$|This paper {{focuses on}} some properties, which include regularity, impulse, stability, {{admissibility}} and robust admissibility, of singular fractional order system (SFOS) with fractional order 1 <α< 2. The <b>finitions</b> of regularity, impulse-free, stability and admissibility {{are given in}} the paper. Regularity is analysed in time domain and the analysis of impulse-free is based on state response. A sufficient and necessary condition of stability is established. Three different sufficient and necessary conditions of admissibility are proved. Then, this paper shows {{how to get the}} numerical solution of SFOS in time domain. Finally, a numerical example is provided to illustrate the proposed conditions. Comment: 28 pages, 2 figures, journa...|$|R
50|$|In February 2015, they {{published}} the precursor to their mixtape, entitled En attendant Demoniak. In late 2015 , they are invited on featuring by KranMax in the track Montre-moi and {{appear on the}} Double Fuck mixtape of Kaaris on which they interpret the track <b>Finition.</b> In April 2016, the group publishes the song named Plein les poches in featuring with Sadek, accumulating 8 million views in 1 month. The duo released their first mixtape named Demoniak on May 20, 2016, and sell 1,319 copies in its first week of operation.|$|E
40|$|MAKE award winners ck inv het {{reaction}} and future performance of companies receiving the “Most AdmiredKnowledge Enterprise ” (MAKE) award, that excel at KM. MAKE awards are generated based on opinions gathered from <b>finition</b> facilitate and support decision making (e. g., Alavi and Leidner [1]). KM {{a number of}} control variables into the analysis, such as firm size, an...|$|E
40|$|An {{exhaustive}} {{review of}} the world literature concerning the history of knee arthroplasty by means of partial or total implants is given. The various types of prosthesis used during the last 30 yr are recalled, the progressive ameliorations in the materials and the <b>finition</b> of the implants and also the good and bad clinical results which stimulated surgical thinking in this field. New concepts in articular replacement of the knee are presented. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|E
40|$|Master of ScienceDepartment of MathematicsHrant HakobyanWhen {{studying}} geometrical objects less regular {{than ordinary}} ones, fractal analysis becomes a valuable tool. Over the last 30 years, this small branch of mathematics has developed extensively. Fractals can be de fined as those sets which have non-integral Hausdor ff dimension. In this thesis, {{we take a}} look at some basic measure theory needed to introduce certain de <b>finitions</b> of fractal dimensions, which can be used to measure a set's fractal degree. We introduce Minkowski dimension and Hausdor ff dimension as well as explore some examples where they coincide. Then we look at the dimension of a measure and some very useful applications. We conclude with a well known result of Bedford and McMullen about the Hausdor ff dimension of self-a ffine sets...|$|R
40|$|Logistic Service Providers (LSPs) o ering {{hinterland}} transportation {{face the}} trade-o between e ciently using {{the capacity of}} long-haul vehicles and minimizing the rst and last-mile costs. To achieve the optimal trade-o, freights have to be consolidated considering the variation in the arrival of freight and their characteristics, the applicable transportation restrictions, and the interdependence of decisions over time. We propose {{the use of a}} Markov model and an Approximate Dynamic Programming (ADP) algorithm to consolidate the right freights in such transportation settings. Our model incorporates probabilistic knowledge of the arrival of freights and their characteristics, as well as generic de <b>finitions</b> of transportation restrictions and costs. Using small test instances, we show that our ADP solution provides accurate approximations to the optimal solution of the Markov model. Using a larger problem instance, we show that our modeling approach has signi cant bene ts when compared to common-practice heuristic approaches...|$|R
40|$|This chapter {{explores the}} {{emerging}} role of acad emic librarians {{in the learning}} and teaching process through their involvement with teaching staff {{in the development of}} student information literacy skills. Information literacy – that is, the ability to find, evaluate and use information effectively – is a key component of university students’ learning experience. It also equips students with skills for the workplace and lifelong learning: It could be argued that the skill of th e twenty first century graduate will be to articulate the right questions and to und erstand where and how they can search for knowledge, not remember the answers (Donnelly and Fitzmaurice, 2005, p. 96). The chapter provides a brief overview of the institutional and learning background against which contemporary information literacy deve lopment takes place. This background is characterised by a changing context for the operation of academic libraries; a changing higher education environment; a changing information environment; and a changing user. The chapter goes on to provide some formal de <b>finitions</b> of information literacy, developed by library-related bodies. These are followed by some working understandings of the term, derived from responses given by several academic developers and lecturers to the question, “What does information literacy mean to you? ” Finally, the chapter discusses the role of information literacy in higher education and the key role librarians play in information literacy development...|$|R
40|$|This Digest {{considers}} {{the factors that}} {{affect the quality of}} a concrete floor-finish. Some information is also provided on the more commonly used surface treatments for concrete floors. Experience suggests that most failures can be attributed to improper design or poor workmanship and could have been avoided with careful attention to the factors that make for a quality installation. Aussi disponible en fran 7 ais : <b>Finition</b> des dalles de b 9 tonPeer reviewed: NoNRC publication: Ye...|$|E
40|$|This thesis {{focuses on}} machine-free {{definition}} of polynomial functions. The main {{goal is to}} not only make the readers familiar with this de- <b>finition,</b> but also to introduce them to the other pivotal terms of this thesis. The other pivotal terms are: basic functions, function composi- tion, recursive schemes a polynomial conditions. Throughout the thesis the readers will be introduced, among other things, to derivation of the most used polynomially bounded functions, like multiplication, addi- tion, or other arithmetic functions. ...|$|E
40|$|Due to {{the growing}} {{transport}} needs in emerging economies and recent success of the low-cost airlines, the demand for short/medium-haul aeroplanes is increasing. Within the next twenty years, the existing single-aisle aircraft {{are likely to be}} replaced by new models mounting new propulsion systems. One promising con- figuration being considered is the open-rotor, which is a revision of the propfan. However, further progress has to be done in order to transform propfan engines, whose technology dates back to the 1980 s, into viable and feasible open-rotor con- cepts. Among the aspects yet to be investigated in su ficient depth is the de <b>finition</b> of a methodology for the open-rotor nacelle design. The aim of the present research is to help enhance the knowledge in this area. Even if {{there are a number of}} important fields of investigation for open-rotor designs, this work is limited to the analysis of the pusher architecture with no exhaust impingement through rotors. The research is initially performed combining both a graphical and a compu- tational approach, investigating the mathematical and physical aspects involved in the de <b>finition</b> of appropriate nacelle pro files, boundary conditions for the CFD analysis and simplifi ed rotor modelling. The first simulations are mainly focused on a typical propfan nacelle, which is taken as a reference model: the computations provide useful results for evaluating its aerodynamic features [...] . [cont. ]...|$|E
40|$|Structurally disordered solids are {{characterized}} by their lack of spatial order that {{is evidenced by the}} great variety of ordered solids. The former class of materials is commonly termed amorphous or glassy, the latter crystalline. However, both classes share, many of the other physical properties of solids, e. g., me­ chanical stability, resistance to shear stress, etc. The traditional macroscopic distinction between the crystalline and the glassy states is that while the former has a fixed melting point, the latter does not. However, with the availability and production {{of a large number of}} materials in both crystalline and amorphous states, and their easy inter-convertability, simple de­ <b>finitions</b> are not possible or at best imprecise. For the present purpose, it is sufficient to say that in contrast to the crystalline state, in which the posi­ tions of atoms are fixed into adefinite structure, ex­ cept for small thermal vibrations, the amorphous state of the same material displays varying degrees of de­ parture from this fixed structure. The amorphous state almost always shows no long range order. Short range order, up to several neighbors, may often be retained, although averaged considerably around their crystalline values. It is generally believed that the amorphous state is a metastable one with respect to the crystal­ line ordered state, and the conversion to the crystal­ line state may or may not be easy depending on the na­ ture of the material, e. g...|$|R
40|$|Objectives: This study {{aimed to}} {{evaluate}} whether the early achievement of clinical remission influences overall survival in an inception cohort of patients with inflammatory polyarthritis (IP). Methods: Consecutive early IP patients, recruited to a primary care based inception cohort from 1990 to 1994 and from 2000 to 2004 were eligible for this study. Remission was defined as absence of clinically detectable joint inflammation on a 51 -joint count. In sensitivity analyses, less stringent de <b>finitions</b> of remission were used, based on 28 -joint counts. Remission was assessed at 1, 2 and 3 years after baseline. All patients were flagged with the national death register. Censoring was set at 1 May 2011. The effect of remission on mortality was analysed using the Cox proportional hazard regression model, and presented as HRs and 95 % CIs. Results: A total of 1251 patients {{were included in the}} analyses. Having been in remission at least once within the first 3 years of follow-up was associated with a significantly lower risk of death: HR 0. 72 (95 % CI 0. 55 to 0. 94). Patients who were in remission 1 year after the baseline assessments and had persistent remission over time had the greatest reduction in mortality risk compared with patients who never achieved remission within the first 3 years of follow-up: HR 0. 58 (95 % CI 0. 37 to 0. 91). Remission according to less stringent definitions was associated with progressively lower protective effect. Conclusions: Early and sustained remission is associated with decreased all-cause mortality in patients with IP. This result supports clinical remission as the target in the management of IP...|$|R
40|$|OBJECTIVE - Available {{evidence}} supports the emerging hypothesis that metabolic syndrome {{may be associated}} with the risk of some common cancers. We did a systematic review and meta-analysis to assess the association between metabolic syndrome and risk of cancer at different sites. RESEARCH DESIGN AND METHODS - We conducted an electronic search for articles published through October 2011 without restrictions and by reviewing reference lists from retrieved articles. Every included study was to report risk estimates with 95 % CIs for the association between metabolic syndrome and cancer. RESULTS - We analyzed 116 datasets from 43 articles, including 38, 940 cases of cancer. In cohort studies in men, the presence of metabolic syndrome was associated with liver (relative risk 1. 43, P < 0. 0001), colorectal (1. 25, P < 0. 001), and bladder cancer (1. 10, P = 0. 013). In cohort studies in women, the presence of metabolic syndrome was associated with endometrial (1. 61, P = 0. 001), pancreatic (1. 58, P < 0. 0001), breast postmenopausal (1. 56, P = 0. 017), rectal (1. 52, P = 0. 005), and colorectal (1. 34, P = 0. 006) cancers. Associations with metabolic syndrome were stronger in women than in men for pancreatic (P = 0. 01) and rectal (P = 0. 01) cancers. Associations were different between ethnic groups: we recorded stronger associations in Asia populations for liver cancer (P = 0. 002), in European populations for colorectal cancer in women (P = 0. 004), and in U. S. populations (whites) for prostate cancer (P = 0. 001). CONCLUSIONS - Metabolic syndrome is associated with increased risk of common cancers; for some cancers, the risk differs betweens sexes, populations, and de <b>finitions</b> of metabolic syndrome. © 2012 by the American Diabetes Association...|$|R
40|$|This paper {{critically}} examines i sues confronting Decision Support Systems (DSS) in the business/management area. Due to {{the lack}} of acceptable d <b>finition</b> ~f DSS, the characteristics and components of DSS are discu~,~,~d in etail. It is pointed out that work activities that require decision making form a spectrum of problems ranging from structured problem to unstructured problem. It is further pointed out that personality and cognitive style can influence individuals " decision styles, and thus different decision aids will be sought. DSS develop-ment and applications are briefly described. Finally, the major problems facing current DSSs are outlined, and the future trends of DSS are described...|$|E
40|$|Multifractal {{analysis}} {{is concerned with}} the study of very irregular signals. For such functions, the pointwise regularity may change widely from a point to another. Therefore, it is more interesting to determine the spectrum of singularities of the signal, which is the Hausdor ff dimension of the set of points which have the same H ölder exponent. For real-life signals, the computation of the spectrum of singularities from its de <b>finition</b> is not feasible. Multifractal formalisms are used to approximate this spectrum. Currently, there exist several methods. In this talk, we present a new multifractal formalism based on the wavelet leaders of a signal which allows to detect non concave and non increasing spectra...|$|E
40|$|Liaisons dangereuses : Jewish Marriage and Modernity in XVIIIth century Trieste. This article {{considers}} Jewish emancipation, {{tradition and}} modernity through {{the issue of}} marriage law and family formation, specifically the effects upon Jews of the modern state's transfer of marriage from religious to civil law. From archival and rabbinic sources it reconstructs and analyzes the cases of two couples in late 18 th- century Trieste whose unusual situations precipitated struggles between the Jewish community and the state over which marriage law - Habsburg or Jewish - would effectively prevail. It explores how individuals choices were constrained by laws custom parental authority public opinion and social class. It shows that the defense of Jewish marriage law {{in the face of}} the enlightened absolutist state also entailed rede <b>finition</b> of tradition and incipient secularization. Dubin Lois C., Séné Jean-François. Les liaisons dangereuses. Mariage juif et État moderne à Trieste au XVIIIe siècle. In: Annales. Histoire, Sciences Sociales. 49 ᵉ année, N. 5, 1994. pp. 1139 - 1170...|$|E
40|$|This paper {{presents}} the task definition, resources, participating systems, and comparative {{results for the}} shared task on word alignment, which was organized {{as part of the}} ACL 2005 Workshop on Building and Using Parallel Texts. The shared task included English-Inuktitut, Romanian-English, and English-Hindi sub-tasks, and drew the participation of ten teams from around the world with a total of 50 systems. Le pr 9 sent article d 9 crit la d 9 <b>finition</b> des t 2 ches, les ressources, les syst 8 mes participants et les r 9 sultats comparatifs des t 2 ches partag 9 es sur l'alignement des mots, qui a 9 t 9 organis 9 dans le cadre de l'atelier 2005 de l'ACL, Building and Using Parallel Texts. Parmi les t 2 ches partag 9 es, on retrouvait les sous-t 2 ches anglais-inuktitut, roumain-anglais et anglais-hindi. Dix 9 quipes de partout dans le monde ont particip 9, pour un total de 50 syst 8 mes. Peer reviewed: NoNRC publication: Ye...|$|E
40|$|The paper {{concerns}} {{a problem of}} Dirac fermion doublet in the external monopole potential arisen out of embedding the Abelian monopole solution in the non-Abe- lian scheme. In this particular case, the Hamiltonian is invariant under some symmetry operations consisting of an Abelian subgroup in the complex rotational group SO(3. C). This symmetry results in a certain (A) -freedom in choosing a discrete operator entering the complete set {H, j^{ 2 }, j_{ 3 }, N(A), K}. The same complex number A represents a parameter of the wave functions constructed. The generalized inversion-like operator N(A) implies its own (A-dependent) de- <b>finition</b> for scalar and pseudoscalar, and further affords some generalized N(A) -parity selection rules. It is shown that all different sets of basis func- tions Psi(A) determine the same Hilbert space. In particular, the functions Psi(A) decompose into linear combinations of Psi(A= 0). However, the bases con- sidered {{turn out to be}} nonorthogonal ones when A is not real number; the latter correlates with the non-self-conjugacy property of the operator N(A) at those A-s. (This is a shortened version of the paper) ...|$|E
40|$|This paper {{presents}} an outline {{on the design}} of an expert system aimed at helping decision makers to operate flood control dams and to plan civil defense in flood prone. The problem is first described and the need for an expert system is justified by the complexi ty of land use in the area as well as the dificul ty to use simulation models on time for prediction of damages and for the analysis of the best control decisions. The expert system can synthesize the results of previous analysis with the models and the criteria of experts and it can be used on real time linked with an information system inclu ding rain intensity data and water levels at control points. The contents of the data base of the information system, and the general specification of the different types of rules are presented. Finally, the general methodology for the de <b>finition</b> of the rules based on the artificial ex perience created by a program of runs of the differents models for representation of hydraulic behavior is discussed. The project is now under study by the Spanish Ministry of Public Works...|$|E
40|$|We present {{here the}} first visual {{interface}} for a Mexican Spanish Sign Language translator {{on its first}} development stage: sign-writing recognition. The software was developed for the unique characteristics of Mexican linguistics and was designed {{in order to use}} sentences or a sequence of signs in sign-writing system which are decoded by the program and converted into a series of images with movement that correspond to the Mexican sign language system. Using a lexical, syntactic and semantic algorithms plus free software such as APIs's from Java, video converter software, data base manager like MySQL, Postgres and SQlite, was possible to read and interpret the rich and complex Mexican language. Our application for visual interface showed to be capable of reading and reconstruct each sentence used for the interpreter and translate it into a high de <b>finition</b> video. The average time of video display vs number of sentences to interpret, probed to be in linear relation with an average time of two seconds per sentence. The software has over come the problem of homonym words frequently used in Spanish language and verb tense relation for each sentence, special symbols such as #, %, $, etc. are still not recognized into the softwar...|$|E
40|$|We {{investigate}} how the quantum mechanicalposition operator {{can be defined}} for elementary systems so that the connection, postulated by the special theoryof relatively, betweenvelocity (the time derivative of the position) and momentum remains valid. The relation between momentum F and velocity u zero mass and arbitrary spin s, as well as systems of in relativistic classical mechanics is the well-known zero mass and s = 0 and 1 / 2. Whereas the momentum-formula velocity relation which we derive is true for all such = ~., ~ systems, our procedure will be more transparent if 0 ‘ ‘ / we confine our attention to positive energy Klein— where (in our units c = = 1) Gordon particles (s = 0) since the same argument holds — ~ 2 + ‘ 2 ~ {{in the case of}} arbitrary s. In the former case the mo-o — /. “ ‘ mentum-space wave function of the only state which The situation in quantum mechanics is not imme- is localized at the origin, at time t = 0, is, according diately obvious because although P has a natural de- to ref. [3], <b>finition</b> — it is the generator of spatial translations of = ‘ 2 ~) — 312 F 112 ‘ 3 the state vector [1, 2] — this is not so foru. For an...|$|E
40|$|In Supplement No. 2 to the National Building code of Canada all low-density wood {{fibreboard}} finish materials, raw or coated are assigned a flame-spread classification (by the ASTM Tunnel Furnace Method) of "over 150 ". Supplement No. 5 to the Code as revised in December 1968, requires that "interior finishes, except for doors, shall have a {{flame spread rating}} of not more than 150 ". To broaden the available information on fibreboard materials, additional tests have been conducted and the correlation of the results among the three flame-spread test methods has been examined more thoroughly. This recent work {{is the subject of}} this brief note. Le suppl 9 ment no 2 du Code national du b 2 timent du Canada attribue 0 tous les panneaux de <b>finition</b> de fibre de bois, bruts ou rev, un indice de propagation de la flamme (selon la m 9 thode ASTM du four-tunnel) sup 9 rieur 0 150. Le suppl 9 ment no 5, r 9 vis 9 en 1968, exige que l'indice de propagation de la flamme de tout rev int 9 rieur, sauf celui des portes, n'exc 8 de pas 150. Afin d'enrichir l'information disponible sur les mat 9 riaux de fibre de bois, on a proc 9 d 9 0 des essais suppl 9 mentaires ainsi qu' 0 une analyse plus approfondie des r 9 sultats obtenus au moyen des trois m 9 thodes d'essai de la propagation de la flamme. Le pr 9 sent document fait 9 tat de ces travaux r 9 cents. Peer reviewed: NoNRC publication: Ye...|$|E
40|$|For {{more than}} 20 years, {{there have been}} {{periodic}} reports in the research literature about he co-occurrence of spouse abuse and physical child abuse. This review compiles and evaluates those reports. Forty-two studies were found that provided some data concerning co-occurrence; 31 of the studies included sufficient detail {{to be used in}} this review. The different types of studies are classified and methodologi-cal issues are discussed. The base rate of co-occurrence found in representative community samples was about 6 %. In clinical samples of either battered women or physically abused children, the percentage ofoverlap ranged from 20 % to 100 %. When a conservative d <b>finition</b> of child abuse was used, a median co-occurrence rate of 40 % was found. Five models depicting the directionality ofabuse in violent families are proposed and discussed inrelation to the data and theories of violence. Recommendations for methodological improvements and theory-driven studies are presented. As early as 1975, reports appeared indicating that children whose parents engaged in physical violence were also likely to be victims of physical maltreatment. Moore (1975) {{was one of the first}} to sound the alarm. She discovered that 13 % of the children from 23 maritally violent families had been physically hurt or were threatened with violence. That same year, Levine (1975) also commented on the problem of co-occurring violence but found only a 2 % rate of overlap between marital violence and physical child abuse. Since that time there have been periodic reports of the overlap between marital violence and physical child abuse [...] with overlap rates that typically are much higher than either of the rates first reported. However, t...|$|E
40|$|This paper {{shows the}} results of a {{detailed}} reprocessing of aeromagnetic data,obtained by the downward projection to the seabed. The area of interest is centered over the Tyrrhenian Basin,whose bathymetric –topographic lay-out is characterized by a somewhat irregular trend. The origin of the intense depth variations depends on the Tyrrhenian structural setting,that is associated with the presence of several tectonic lineaments,seamounts or volcanic islands. The data were characterized by good quality and dense sam- pling,but they have been reprocessed in order either to solve some problems in the original compilation,and to reduce the distor- tion of the geomagnetic anomaly ﬁeld caused by the difference of distance between the survey level and the magnetic source. The reprocessed magnetic map is proposed as an e ﬀective analysis tool for the Tyrrhenian area that is characterized by high susceptibility lithotypes. Downward projection of the aeromagnetic data by BTM algorithm increases the de <b>ﬁnition</b> of the anomalous magnetic signal without distortions in the geometric pattern of the ﬁeld,thus showing a more stable and effective association between the magnetic anomalies and their geological sources. This effect is particularly true for high frequency anomalies that are directly comparable after the topographic projection because the depth ﬁltering effect is attenuated. Moreover,the BTM method has been applied for the ﬁrst time to a regional scale survey that shows substantial advantages because no ﬁctitious anomalies in the high frequency sector of the spectrum were generated. This has been a typical effect of the traditional downward projection methods widely used before. The ﬁnal result is a BTM anomaly map that is able to show the structural connections between the geological magnetic sources of the Tyrrhenian Sea area...|$|E
40|$|The soil {{purification}} capacity for treating pig slurry was evaluated {{over five years}} using a hydrologically isolated field treatment plant, the so-called "Solepur" process. This involves three operations : (1) overdosing the managed field with surplus slurry, (2) collecting and treating the nitrate rich leachate, (3) irrigating the final treated water over other fields. The facility consists of (1) a managed field (3280 m 2) which allows the total recovery of all the leachate water wich percolates through growing ryegrass, Lolium perenne, to which the pig slurry is apllied, (2) a storage-pump-reactor system for denitrification and (3) a non managed field for completing treatment. The {{purpose of this study}} was to evaluate over a five year monitoring period, the feasibility and performances of such a process, and to determine the optimum operationg conditions. From 1991 to 1995, 4931 m 3 /ha of raw pig slurry was applied to the managed field wich represents a nominal load of 983 m 3 ha - 1 yr - 1. This process decreased the COD of pig slurry by 99. 9 % and removed 99. 9 % of phosphorus and appoximately 90 % of nitrogen. / La capacité de purification par le sol du lisier de porc a été évaluée à l'aide d'une parcelle isolée hydrologiquement. Le procédé comporte trois étapes : (1) surdosage de la parcelle aménagée avec le lisier en surplus, (2) collecte et traitement des percolats nitratés, (3) irrigation de l'effluent dénitritifié pour une <b>finition</b> d'épuration. L'objectif de l'étude était d'évaluer une telle approche au cours d'un suivi pluriannuel (5 ans). L'article présente une description détaillée de l'ingéniérie du procédé (mise ne place du système) et les principaux résultats obtenus...|$|E
40|$|The paper {{deals with}} the problem of finding a {{methodology}} which allows obtaining a score of usability evaluation for various kinds of user interfaces. The evaluation is in principle based on a de- <b>finition</b> of a set of properly chosen key characteristics affecting the usability of the user interface. Such criteria are then evaluated by a group of typical users of the system. These evaluations are in principle expressed as imprecise, vague linguistic expressions stating commonly known truths representing some value of quality of use. Since the crisp numbers cannot directly express vague terms or ambiguities, theory of fuzzy logic has been chosen as the most appropriate apparatus to deal with the uncertainty. The evaluations expressed in users‘ natural language are converted to the set of normalized evaluation words. With the help of database of commonly used words, users are not limited to use their common language. Each normalized evaluation is a member of an empirical scale and can be represented by one fuzzy number whose parameters are obtained by assigning linguistic and numeric evaluation to the evaluation. A fuzzy inference system that uses expert knowledge is used to match the best possible approximation of evaluation with the knowledge included in the fuzzy rule base. The output of inference system is obtained by using common defuzzification methods. An overall usability score represents a meaningful and authentic value - a mark of the quality of particular user interface, value that can be compared to the others. Proposed methodology was successfully implemented into software application Fuzzy Usability Evaluator that has been used for evaluating usability of Web portals in Public administration...|$|E
40|$|International audienceGlioblastoma di ffer {{from many}} other tumors {{in the sense}} that they grow in filtratively into the brain tissue instead of forming a solid tumor mass with a de fined boundary. Only the part of the tumor with high tumor cell density can be {{localized}} through imaging directly. In contrast, brain tissue in filtrated by tumor cells at low density appears normal on current imaging modalities. In current clinical practice, a uniform margin, typically two centimeters, is applied to account for microscopic spread of disease that is not directly assessable through imaging. The current treatment planning procedure can potentially be improved by accounting for the anisotropy of tumor growth, which arises from di erent factors: Anatomical barriers such as the falx cerebri represent boundaries for migrating tumor cells. In addition, tumor cells primarily spread in white matter and in ltrate gray matter at lower rate. We investigate the use of a phenomenological tumor growth model for treatment planning. The model is based on the Fisher-Kolmogorov equation, which formalizes these growth characteristics and estimates the spatial distribution of tumor cells in normal appearing regions of the brain. The target volume for radiotherapy planning can be de fined as an isoline of the simulated tumor cell density. This paper analyzes the model with respect to implications for target volume de <b>finition</b> and identi fies its most critical components. A retrospective study involving 10 glioblastoma patients treated at our institution has been performed. To illustrate the main findings of the study, a detailed case study is presented for a glioblastoma located close to the falx. In this situation, the falx represents a boundary for migrating tumor cells, whereas the corpus callosum provides a route for the tumor to spread to the contralateral hemisphere. We further discuss the sensitivity of the model with respect to the input parameters. Correct segmentation of the brain appears to be the most crucial model input. We conclude that the tumor growth model provides a method to account for anisotropic growth patterns of glioma, and may therefore provide a tool to make target delineation more objective and automated...|$|E
40|$|Hesitations {{in speech}} marked by pauses, fillers such as er, and prolongations of words are remarkably common in most {{spontaneous}} speech. Experimental {{evidence indicates that}} they affect both the processing of speech and the lasting representation of the spoken material. One theory as to the mechanisms that underlie these effects is that filled pauses heighten listeners' attention to upcoming speech. For example, in the utterance: (1) She hated the CD, but then she's never liked my taste in er music The hesitation marked by the filler er would heighten listeners' attention to the post-dis fluent material (music) which would then be processed and represented differently to an equivalent stimulus in a passage of fluent speech. The thesis examines this proposition {{in the context of}} an explicit de <b>finition</b> of attention. The first half of the work investigates whether hesitations heighten two different aspects of listeners' attention: these are the immediate engagement of attention to post-dis fluent stimuli at the point they are encountered, and the continued attention to the representation of stimuli after they are encountered. In experiment 1, a speech `oddball' paradigm is used to show that event-related potentials (ERPs) associated with attention (MMN and P 3) are affected by a preceding hesitation, indicating an immediate effect of hesitations on listeners overt attention. Experiments 2 and 3 use behavioural responses and eye-movements measures during a change-detection paradigm. These experiments show that there is also an effect on the listeners' attention to the post-dis fluent material after the initial presentation of the utterance. The second half of the thesis concerns itself with the timecourse of the attentional effects. It addresses questions such as: how long-lived is the attentional heightening and what is the attentional heightening trigger? Experiments 4 { 7 explore the relationship between the filler er and periods of silent pause that surround it. Behavioural (exp. 4 { 6) and ERP (exp. 7) results show that while extending the period of silence after the filler er does not affect the immediate engagement of attention, it will affect subsequent attention to the post-disfluent material: constituents that are not immediately preceded by the filler er are not attended to in an enhanced way. Together, these experiments confirm the proposition that hesitations heighten listeners' attention to upcoming speech. The thesis outlines the ways in which the components of this attentional heightening are differentially affected by interaction between the content and timing of the hesitations encountered. Attention has an important role to play in the processing of any stimulus. Using disfluency as a test case, this thesis illuminates its importance in language comprehension. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|The set of codewords for a {{standard}} error-correcting code {{can be viewed}} as subset of the vertices of a hypercube. Two vertices are adjacent in a hypercube exactly when their Hamming distance is 1. A code is a perfect-error-correcting code if no two codewords are adjacent and every non-codeword is adjacent to exactly one codeword. Since such a code can be described using only vertices and adjacency, the de <b>finition</b> applies to general graphs rather than only to hypercubes. How does one decide if a graph can support a perfect 1 -error-correcting code? The obvious way to show that such a code exists is to display the code. On the other hand, it seems difficult to show that a graph does not support such a code. We show that this intuition is correct by showing that to determine if a graph has a perfect 1 -error-correcting code is an NP-complete problem. The proof is by reduction from 3 -SAT. To show that perfect codes in graphs is not vacuous, we give an in nite family of graphs so that each graph in the family has a perfect 1 -error-correcting code. Our graphs are based on the Towers of Hanoi puzzle, so that, each vertex is a confi guration of the puzzle and two vertices are adjacent when they are one legal move apart. We give a recursive construction which determines which vertices are codewords. There is a natural correspondence between the hypercube vertices and the binary strings, and there is a natural correspondence between Tower of Hanoi con guration and ternary strings. Our recursive construction also speci es which ternary strings are codewords. We characterize the codewords as the set of ternary strings with an even number of 1 's and an even number of 2 's. As part of this characterization, we show that there is essentially one perfect 1 -error-correcting code for each n. There is a unique code when n is even, but the code is only unique up to a permutation of 0, 1, and 2 when n is odd. We show that error-correction can be accomplished by a nite state machine which passes over the ternary string twice, and that this machine is xed independent of the length of the string. Encoding and decoding are the mappings between integers and codewords, and vice-versa. While algorithms for such mappings can be derived directly from the recursive construction, we show that encoding/decoding can be carried out by multiplication/division by 4 and error-correction. So error-correction, encoding, and decoding can all be done in time θ(n) for code strings of length n in these codes...|$|E
40|$|International audienceLife cycle {{assessment}} is actually used {{to quantify the}} environmental footprint of products. This approach {{can be applied to}} industrial processes or services, due to the advantage that it offers the possibility to integrate in the modeling all the parameters related to their entire lifecycle. The present study is dedicated to the presentation of a methodology allowing to realise a comparative life cycle assessment of several materials used to build exterior walls. The main objective is to compare several materials necessary to its construction, in order to use their environmental footprint as main choice criterion. The comparison is done by studying several constitutive elements of the wall, each component having a distinctive function (e. g. : thermal or acoustic insulation, fire resistance). This facilitates, beside the decisions taking, in optimizing the materials flows, their life duration or the durability of such a structure. Are considered in the study the components classically presented in an exterior wall : the external cladding, the water resistant membrane and sheating, the framing (main structure), the insulation, the vapor barrier and the interior finishing. The obtained results show on one part which are the more "impacting" materials {{and on the other side}} which is the lifecycle step having a major contribution on these impacts. It is then easy to observe that the impacts diminution in the end of life can increase them during the manufacturing step. Actuellement, l'analyse du cycle de vie (ACV) est un outil largement employé pour quantifier les conséquences environnementales des produits. Cette méthodologie s'applique aux procédés industriels et aux services, grâce à la possibilité d'intégrer la majorité des paramètres intervenant sur l'ensemble des étapes de leur cycle de vie. La présente étude est dédiée à la présentation d'une méthodologie permettant de mener à bien une analyse comparative des divers matériaux entrant dans la composition d'un élément de construction de type mur extérieur. Le but est de comparer différents matériaux nécessaires à la construction du mur pour utiliser comme critère de choix leur empreinte environnementale. Cette comparaison est faite sur les différents éléments constitutifs du mur, dont chacun a une fonction distincte (ex. : isolation thermique ou acoustique, résistance au feu, etc.). Ceci peut faciliter, outre la prise de décisions en termes de choix de matériaux de construction, l'optimisation des flux de matières, de leur durée de vie, ainsi que la durabilité d'une telle structure. On considère dans l'étude les éléments classiquement présents dans un mur extérieur : le bardage, le pare-pluie et la structure, l'ossature, l'isolation, le pare-vapeur et la <b>finition</b> intérieure. Les résultats obtenus montrent d'une part quels sont les matériaux les plus « impactants » et d'autre part quelle est l'étape de leur cycle de vie majoritairement contributrice sur ces impacts. On peut ainsi observer que la diminution des impacts en fin de vie peut engendrer leur augmentation au niveau de la fabrication. Mots clefs : analyse du cycle de vie (ACV), éco-conception, développement durable, matériaux de construction Abstract : Life cycle {{assessment is}} actually used to quantify the environmental footprint of products. This approach can be applied to industrial processes or services, due to the advantage that it offers the possibility to integrate in the modeling all the parameters related to their entire lifecycle. The present study is dedicated to the presentation of a methodology allowing to realise a comparative life cycle assessment of several materials used to build exterior walls. The main objective is to compare several materials necessary to its construction, in order to use their environmental footprint as main choice criterion. The comparison is done by studying several constitutive elements of the wall, each component having a distinctive function (e. g. : thermal or acoustic insulation, fire resistance). This facilitates, beside the decisions taking, in optimizing the materials flows, their life duration or the durability of such a structure. Are considered in the study the components classically presented in an exterior wall : the external cladding, the water resistant membrane and sheating, the framing (main structure), the insulation, the vapor barrier and the interior finishing. The obtained results show on one part which are the more "impacting" materials and on the other side which is the lifecycle step having a major contribution on these impacts. It is then easy to observe that the impacts diminution in the end of life can increase them during the manufacturing step...|$|E
40|$|La {{filtration}} successive des eaux, préalablement filtrées sur membrane de porosité 0, 45 µm puis acidifiées à pH 2, sur deux colonnes de résines XAD 8 et XAD 4 placées en série, caractérise la matière organique {{en trois}} grandes classes : les substances hydrophobes, les acides hydrophiles et les hydrophiles non retenus. Cette étude s'est intéressée à déterminer et à analyser l'impact sur la distribution hydrophobe/hydrophile des traitements conventionnels utilisés dans les usines de production d'eau potable. En ce qui concerne l'effet de la clarification, la distribution hydrophobe/hydrophile du COD a été inchangée dans le cas de sept prélèvements sur dix, indiquant une isoélimination de chaque fraction. Dans le cas des eaux R 1. 2, R 4 et R 6. 1, une diminution de la fraction hydrophobe est obtenue entre l'eau brute et son eau clarifiée. L'étude de différents coagulants indique que la distribution de la matière organique des eaux clarifiées dépend de sa composition initiale mais aussi de la nature du coagulant mis en oeuvre. Le chlorure ferrique permet une meilleure élimination de chaque fraction comparativement à un sel d'aluminium. Un traitement d'oxydation à un taux de 1, 5 mg Oxydant/mg COD et {{quel que soit}} l'oxydant mis en oeuvre (O 3, Cl 2, ClO 2) diminue significativement les substances hydrophobes et augmente les substances hydrophiles. Ces résultats sont logiques si nous nous référons au mode d'action de ces trois oxydants. L'ozonation d'eaux brute et clarifiée s'accompagne aussi d'une augmentation du CODB, soulignant que les substances hydrophiles générées par l'étape d'ozonation seraient biodégradables. Des campagnes de prélèvements ont indiqué que les traitements de <b>finition</b> (ozonation, filtration sur CAG) en configuration industrielle ont une légère influence sur la distribution interne de la matière organique. Les résultats, du fait de taux de traitement plus faibles, sont moins nets que ceux obtenus en laboratoire. Une filtration sur CAG, précédée d'une étape d'ozonation, conduit à une augmentation de la fraction hydrophobe et à une diminution du CODB. Dissolved organic matter (DOM) in natural waters {{is a mixture of}} compounds. Some authors have fractionated this organic matter into large classes (humic substances, hydrophilic acids...). Humic substances have been defined as the fraction of organic matter retained on XAD 8 resin at acidic pH (THURMAN and MALCOLM 1981); this isolation procedure is recommended by the International Humic Substances Society. Only a few investigators have dealt specifically with hydrophilic substances which are not adsorbed on XAD 8 resin at acidic pH. The "hydrophobic/hydrophilic" distribution can be determined by a simple method of organic matter fractionation, using two superimposed XAD 8 and XAD 4 resin columns (CROUE et al. 1993). This procedures, carried out at pH 2, consists of first isolating hydrophobic substances (essentially humic acids) on an XAD 8 resin and then isolating the hydrophilic acids from the XAD 8 effluent on an XAD 4 resin. The aim of this work was to study the evolution of the hydrophobic/hydrophilic distribution during water treatment steps as applied in waterworks. The analytical procedure was first applied to determine the change in the DOM distribution of ten surface waters after clarification. The results obtained after clarification were completed by the study of the effect of the coagulant nature (ferric chloride, aluminium sulphate, prehydrolyzed salt (WAC)). In the second phase, oxidation experiments using ozone, chlorine and chlorine dioxide were conducted on raw and clarified waters to determine their effect on the DOM distribution. Finally the fractionation procedures were carried out on two water treatment plants to compare our laboratory data with results obtained in a working plant and to observe the change in DOM distribution during granular activated carbon (GAC) filtration. Dissolved organic carbon (DOC) concentrations were analysed using a Dohrman DC 80 apparatus. UV absorbance was measured with a one or five centimeter cell using an Uvikon spectrophotometer. Oxidation experiments were carried out in a batch procedure. The study of different coagulants was made in the laboratory with a Jar Test procedure described elsewhere (LEFEBVRE 1990). Biodegradable dissolved organic carbon (BDOC) was analyzed according to the suspended bacteria method (SERVAIS et al. 1987, 1989). The hydrophobic/hydrophilic distributions of raw and clarified waters were found to be unchanged by the clarification step in seven of ten test waters. These results indicate that for a studied water, the relative reduction in DOC of one fraction was of the same order of magnitude as the other fraction. The distributions of R 1. 2, R 4 and R 6. 1 were significantly modified by the clarification treatment. In these three cases, the hydrophobic substances showed the greater DOC reduction. The "non-retained" hydrophilic substances became predominant in the R 6. 1 clarified water, whereas in the cases of R 4 and R 1. 2 the total hydrophilic fraction and the hydrophilic acids increased, respectively. The results obtained in the laboratory on three different raw waters, clarified by different coagulants (ferric chloride or aluminium salts), showed that the nature of the coagulant (iron or alum) can influence the hydrophobic/hydrophilic distribution. A marked influence was found in the case of R 6 and less significant results were obtained for R 1. 2. Powdered activated carbon had no real effect on the DOC distribution, under our experimental conditions (applied dosage 25 mg/L). If the removal of each fraction is considered, and if it is assumed that each removal is independent from the others, ferric chloride appears to be the best coagulant. It removes humic substances efficiently as well as hydrophilic acids (> 72 %), but is less efficient for the "non-retained" hydrophilic fraction. The DOC distribution of a clarified water depends on the distribution in the original raw water {{and the nature of the}} coagulant. Under our experimental conditions (applied dosage: 1. 5 mg oxidant / mg DOC), ozone, chlorine and chlorine dioxide significantly affected the DOM distribution of the R 1. 2 water. The hydrophobic substances showed the higher relative DOC reduction, which can be correlated with an increase in the hydrophilic fraction. The greatest change was obtained for treatment with ozone. In the case of chlorine and chlorine dioxide, an increase of the "non-retained" hydrophilic fraction was observed whereas for ozone the two hydrophilic fractions increased. These results are in agreement with current knowledge about the action of ozone, chlorine and chlorine dioxide. An increase in the BDOC fraction was observed with the applied ozone dosage. In the case of R 1, ozonation of raw and clarified waters appeared to shift the dissolved organic carbon distribution towards the "non-retained" hydrophilics. A good correlation exists between the BDOC increase (BDOC/BDOCo) and the decrease of hydrophobic acids or the increase of "non-retained" hydrophilics (slopes are respectively 12. 3; - 16. 5 and 15. 5). In the case of another sample of R 1. 2, the comparison of BDOC in the XAD 4 effluents of raw and ozonated waters indicated that at least 62 % of BDOC produced by ozonation was in this fraction. This result indicates that the "non-retained" hydrophilics of this raw water are not biodegradable compared with those induced by ozonation. Results obtained on samples taken on two water treatment plants indicate that ozonation and GAC filtration have a small effect on the hydrophobic/hydrophilic DOM distribution. Intermediate ozonation at the industrially applied dose slightly modifies the distribution; a slight decrease of hydrophobic substances is observed. GAC filtration induces an increase of the hydrophobic fraction. The water treatment process includes clarification (EFS), inter-ozonation (EFSO 3), and GAC filtration (EFCAG). GAC filters A and B had been respectively running for one and three years; filter C has been regenerated one month before. Good organic matter removal is obtained during clarification (removal of DOC and UV-absorbance: 75 % and 88 %). This treatment step changes the DOM distribution: increase of the hydrophobic fraction and decrease of the hydrophilic fraction. BDOC was completely removed. Intermediate ozonation (0. 7 mg O 3 /mg DOC) modifies the DOC distribution and creates BDOC. This BDOC, in absolute value (0. 36 mg/l), is equal to the increase of hydrophilic fraction. On the oldest filters (A and B) BDOC was completely removed, but this was not the case for filter C, probably because the bacterial biomass was insufficient. On GAC filters hydrophilic substances were found to be better removed than humic substances. The age of the GAC bed seems to have an effect on DOC distribution: the effluent from the oldest GAC filter contained less of the hydrophobic fraction than did the effluent from the youngest filter...|$|E
