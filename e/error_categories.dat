102|239|Public
5000|$|These <b>error</b> <b>categories</b> {{relate to}} {{three levels of}} human performance: ...|$|E
5000|$|Three error {{mechanisms}} can {{be defined}} which correlate the <b>error</b> <b>categories</b> with human performance levels: ...|$|E
40|$|Computer {{intrusions}} {{can occur}} in various ways. Many of them occur by exploiting program flaws and system configuration errors. Existing solutions that detects specific kinds of flaws are substantially different from each other, so aggregate use of them may be incompatible and require substantial changes in the current system and computing practice. Intrusion detection systems {{may not be the}} answer either, because they are inherently inaccurate and susceptible to false positives/negatives. This dissertation presents a taxonomy of security flaws that classifies program vulnerabilities into finite number of <b>error</b> <b>categories,</b> and presents a security mechanism that can produce accurate solutions for many of these <b>error</b> <b>categories</b> in a modular fashion. To be accurate, a solution should closely match the characteristic of the target error category. To ensure this, we focus only on <b>error</b> <b>categories</b> whose characteristics can be defined in terms of a violation of process integrity. The thesis of this work is that the proposed approach produces accurate solutions for many <b>error</b> <b>categories.</b> To prove the accuracy of produced solutions, we define the process integrity checking approach and analyze its properties. To prove that this approach can cover many <b>error</b> <b>categories,</b> we develop a classification of program security flaws and find error characteristics (in terms of a process integrity) from many of these categories. W...|$|E
5000|$|... aphasic speech (such as word search pauses, jargoning, {{word order}} <b>errors,</b> word <b>category</b> <b>errors,</b> verb tense errors) ...|$|R
30|$|False {{practice}} {{dominates the}} application <b>error</b> <b>category,</b> however {{in these cases}} the medical device is often set-up {{in such a way}} that promotes a false user procedure. The medical device itself gives the user no chance to realise that it is not suitable for the application and mistakes are made.|$|R
40|$|The {{present study}} was {{conducted}} to find out the English inflectional suffixes of EFL (English as a Foreign Language) young learners. This study was aimed to investigate the types of English inflectional suffixes mostly used, both correctly and incorrectly, by the students. Besides, the writer also try to find the <b>error</b> <b>category</b> involved and its frequency. The writer used the relevant theory proposed by Dulay, Burt, and Krashen (1972) as her main review of related literature. This research was a qualitative research. The writer got the data from written work of the 3 rd grade-junior high students on the given test. She found that (-`s) `possessive? was the most frequent of English inflectional suffixes used correctly while (-ed 2) `past participle? was the most frequent of English inflectional suffixes that is incorrectly used. Also, she found out that misformation is the <b>error</b> <b>category</b> that occurring most...|$|R
40|$|Among risk {{management}} initiatives, systematic safety processes (SSPs), implemented within health care organizations, {{could be useful}} in managing patient safety. The {{purpose of this article}} is to conduct a systematic literature review assessing the impact of SSPs on different <b>error</b> <b>categories.</b> Articles that investigated the relation between SSPs, clinical and organizational outcomes were selected from scientific literature. The proportion and impact of proactive and reactive SSPs were calculated among five <b>error</b> <b>categories.</b> Proactive interventions impacted more positively than reactive ones in reducing medication errors, technical errors and errors due to personnel. PSSPs and RSSPs had similar effects in reducing errors related to a wrong procedure. A single reactive study influenced non-positively communication errors. A relevant prevalence of the impact of proactive processes on reactive ones is reported. This article can help decision makers in identifying which SSP can be the most appropriate against specific <b>error</b> <b>categories...</b>|$|E
40|$|The {{application}} of a software reliability model having a well defined correspondence of computer program properties to requirements error analysis is described. Requirements <b>error</b> <b>categories</b> which {{can be related to}} program structural elements are identified and their effect on program execution considered. The model is applied to a hypothetical B- 5 requirement specification for a program module...|$|E
40|$|We {{introduce}} here a participating {{system of}} the CoNLL- 2013 Shared Task “Grammatical Error Correction”. We focused on the noun number and article <b>error</b> <b>categories</b> and constructed a supervised learning system for solving these tasks. We carried out feature engineering {{and we found that}} (among others) the f-structure of an LFG parser can provide very informative features for the machine learning system. ...|$|E
40|$|Mining of {{software}} repositories {{has become an}} active research area. However, most past research considered any change to software as beneficial. This thesis will show how we can benefit from a classification into good and bad changes. The knowledge of bad changes will improve defect prediction and localization. Furthermore, we will describe how to learn project-specific error patterns that will help reducing future <b>errors.</b> <b>Categories</b> and Subject Descriptors D. 2. 7 [Software Engineering]: Distribution, Maintenance, an...|$|R
40|$|The abductory {{induction}} mechanism (AIM(R)) is {{a modern}} machine-learning modeling tool that draws from the fields of neural networks, abductive networks, and multiple regression analysis. This paper introduces AIM as a useful weather modeling and forecasting utility and reports on its use with daily maximum temperatures in Dhahran, Saudi Arabia. Compared with other statistical methods and neural network techniques, this approach has the advantages of faster and highly automated model synthesis as well as improved prediction and forecasting accuracies. AIM models developed using daily data for 18 weather parameters over 1 yr {{that were used to}} predict the maximum temperature on a given day from other parameters on the same day. Evaluated on data for another full year, these models give 97 % yield in the +/- 3 degrees C <b>error</b> <b>category.</b> Various models for 3 -day forecasting have been developed and evaluated. First-day forecasts give 77 % yield in the same <b>error</b> <b>category,</b> and they compare favorably with official forecasts for the region, particularly for the warm seasons, as well as with forecasts based on persistence and climatology. Model relationships and performance statistics are compared with those previously obtaine...|$|R
40|$|A {{proposed}} foundational ontology, {{whose purpose}} is to negotiate meaning to enable cooperation, and to establish a consensus. This ontology has a cognitive bias, and aims to capture ontological categories underlying natural language and commonsense. Aims to make the rationale behind ontological modelling decisions explicit- {{has been used to}} analyse WordNet to identify conceptual <b>errors.</b> <b>Categories</b> are descriptive notions, not attempts to capture the intrinsic nature of the world. Descriptions may be dependent on perception, cultural factors and social conventions. References...|$|R
40|$|Abstract. This paper {{presents}} a scheme for the {{quantitative and qualitative}} assessment of concept maps {{in the context of}} a web-based adaptive concept map assessment tool, referred to as COMPASS. The propositions are characterized qualitatively based on specific criteria and on the error(s) that may be identified. The quantitative assessment depends on the weights assigned to the concepts/propositions and the <b>error</b> <b>categories...</b>|$|E
40|$|In this paper, {{we propose}} two enhance-ments to a {{statistical}} machine translation based approach to grammar correction for correcting all <b>error</b> <b>categories.</b> First, we propose tuning the SMT systems to op-timize a metric more suited to the gram-mar correction task (F-β score) rather than the traditional BLEU metric used for tun-ing language translation tasks. Since the F-β score favours higher precision, tun-ing to this score can potentially improve precision. While the results do not indi-cate improvement due to tuning with the new metric, we believe this {{could be due to}} the small number of grammatical er-rors in the tuning corpus and further in-vestigation is required to answer the ques-tion conclusively. We also explore the combination of custom-engineered gram-mar correction techniques, which are tar-geted to specific <b>error</b> <b>categories,</b> with the SMT based method. Our simple ensem-ble methods yield improvements in recall but decrease the precision. Tuning the custom-built techniques can help in in-creasing the overall accuracy also. ...|$|E
40|$|This study {{intends to}} {{identify}} the lexical features that present particular difficulties to English native speakers learning Korean; to classify those lexical errors {{in terms of their}} type and frequency; and to provide possible explanations for the cause of those lexical problems. The data used in this study come from 141 written examination papers administered at three universities. The subjects selected in this study are 71 second-and third-year students, who are native speakers of English or are believed to have English as their first language. In all, 305 lexical errors have been identified for analysis. Among the 11 <b>error</b> <b>categories</b> identified in this study, wrong word choice caused an overwhelmingly high percentage of errors. Other <b>error</b> <b>categories</b> with high frequency were: confusion by semantic similarity, overgeneralization and literal translation. More than half of the total errors involved nouns, followed by verbs and adjectives. And a large number of the errors produced were intralingual. The study concludes with discussions about teaching and research implications...|$|E
40|$|We {{describe}} TerrorCat, a {{submission to}} this year’s metrics shared task. It is a machine learning-based metric that is trained on manual ranking data from WMT shared tasks 2008 – 2012. Input features are generated by applying automatic translation error analysis to the translation hypotheses and calculating the <b>error</b> <b>category</b> frequency differences. We additionally experiment with adding quality estimation features {{in addition to}} the error analysis-based ones. When evaluated against WMT’ 2012 rankings, the systemlevel agreement is rather high for several language pairs...|$|R
40|$|With {{the aim of}} storing learner corpora as well as {{information}} about the Basque language students who wrote the texts, two different but complementary databases were created: ERREUS and IRAKAZI. Linguistic and technical information (<b>error</b> description, <b>error</b> <b>category,</b> tools for detection/correction…) will be stored in ERREUS, while IRAKAZI will be filled in with psycholinguistic information (error diagnosis, characteristics of the writer, grammatical competence…). These two databases will be the basis for constructing i) a robust Basque grammar corrector and, ii) a computer-assisted languagelearning environment for advising on the use of Basque syntax. 1...|$|R
40|$|This paper {{examines}} degradations {{of service}} in terms of constructs of the Ada programming language that are effective for their control and deployment. Several studies of the software lifecycle have focused on taxonomies of defects or <b>errors.</b> <b>Categories</b> of service degradations, however, have only recently been identified. A classification scheme for service degradations clarifies their relationship to defects and errors and {{their role in the}} prevention of failure. With the growth of hard real-time systems, wireless networks, and multimedia applications, a comprehensive understanding of service degradations and their usage has become ever more important. I...|$|R
40|$|Using an {{instrumented}} vehicle, we {{have studied}} {{several aspects of}} the on-road performance of healthy and diseased elderly drivers. One goal from such studies is to ascertain the type and frequency of driving safety errors. Because the judgment of such errors is somewhat subjective, we applied a taxonomy system of 15 general safety <b>error</b> <b>categories</b> and 76 specific safety error types. We also employed and trained professional driving instructors to review the video data of the on-road drives. In this report, we illustrate our rating system {{on a group of}} 111 drivers, ages 65 to 89. These drivers made errors in 13 of the 15 <b>error</b> <b>categories,</b> comprising 42 of the 76 error types. A mean (SD) of 35. 8 (12. 8) safety errors per drive were noted, with 2. 1 (1. 7) of them being judged as serious. Our methodology may be useful in applications such as intervention studies, and in longitudinal studies of changes in driving abilities in patients with declining cognitive ability...|$|E
40|$|This study {{investigated}} {{the effects of a}} pilot program of written corrective feedback, supported by explicit grammar instruction, on a range of common errors made in ESL postgraduate writing. It sought to quantify improvement through the reduction of error rates and <b>error</b> <b>categories.</b> This small-scale quasi-experimental study involved 15 ESL doctoral students: 7 in an intervention group and 8 in a semi-equivalent control group. Participants wrote a short essay {{at the start of the}} study and a second essay ten weeks later at the conclusion of the study. These essays were analysed for errors, and it was found from linear regression analyses, assuming a constant percentage change in error rate across the groups, that the intervention group produced on average 43 % fewer errors at post-test while the control group’s error rate decreased by an average of 12 % at post-test. In terms of <b>error</b> <b>categories</b> present in students’ writing, the intervention group had on average 2. 4 fewer categories at post-test, while the control group had on average 0. 5 more <b>error</b> <b>categories.</b> These results suggest that for ESL doctoral students in the health sciences, substantial gains can be made within a maximum of 16 hours of written language support, while without such support, little if any improvements are likely to occur. Hence, despite the small sample size and the limitations of quasi-experimental designs, this study found evidence that such a program may produce improvement in the accuracy of ESL postgraduates’ grammar, and this encourages further investigation of similar programs...|$|E
40|$|To {{speed up}} the process of categorizing learner errors and obtaining data for {{languages}} which lack error-annotated data, we describe a linguistically-informed method for generating learner-like morphological errors, focusing on Russian. We outline a procedure to select likely errors, relying on guiding stem and suffix combinations from a segmented lexicon to match particular <b>error</b> <b>categories</b> and relying on grammatical information from the original context. ...|$|E
30|$|The {{number of}} {{publications}} in each <b>error</b> <b>category</b> gives {{an idea of}} the most common use errors associated with auto-injection devices. However, potential reporting and publication biases prevented us from performing a quantitative analysis of the various errors’ frequency of occurrence in the respective studies. Furthermore, we did not distinguish between devices as a function of their medical intention or active substance. Certain functions (such as dose adjustment) were not provided by all the devices reviewed here. This limitation aside, the use errors identified here are all relevant – irrespectively of the particular context of use, medical intention or active substance.|$|R
40|$|Well-specified {{programs}} enable code reuse {{and therefore}} techniques that help programmers to annotate code correctly are valuable. We devised an automated analysis that detects unreachable code {{in the presence}} of code annotations. We implemented it as an enhancement of the extended static checker ESC/Java 2 where it serves as a check of coherency of specifications and code. In this article we define notion of semantic unreachability, describe an algorithm for checking it and demonstrate on a case study that it detects a class of errors previously undetected, as well as describe different scenarios of these <b>errors.</b> <b>Categories</b> and Subject Descriptor...|$|R
40|$|This work evaluates policy {{recommendations}} on medical error reporting systems presented in, To err is human, a report {{published by the}} Institute of Medicine. Here mandatory reporting should be applied for adverse events, while voluntary reporting is recommended for near misses. This analysis shows that an error reporting scheme of this type is not an optimal one since both near misses and adverse events may remain unreported. This work makes evident that penalising health care decision makers for not reporting errors, independent of <b>error</b> <b>category,</b> is crucial for reaching the first-best solution. Microeconomic theory; agency; iatrogenic injury...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe occurrence and detection of software errors was studied in four software projects. Errors were analyzed {{with respect to}} complexity measures of individual subroutines. This paper also provides definitions of <b>error</b> <b>categories</b> and types. The detailed documentation of the software production effort allowed both a qualitative and Quantitative analysis of software errors with respect to error types. [URL] Commander, Federal German Nav...|$|E
40|$|Abstract: Systematic {{verification}} {{and validation}} measures are of essential importance in particular for safety-critical software. After a short introduction into the test environment and <b>error</b> <b>categories,</b> the paper {{presents the results}} of a unit test performed on a C++ software package for the European Space Agency in the ARC Seibersdorf research test lab. The authors analyse the error distribution and relations between software metrics and software faults and recommend guidelines for a less error-prone design of safety-critical software. ...|$|E
40|$|Sorry, {{the full}} text of this article is not {{available}} in Huskie Commons. Please click on the alternative location to access it. 182 p. The study was designed (1) to determine the types of errors found in Nepali government and non-government letters and to compare between the 1975 and 1980 samples, and (2) to identify frequently used Nepali letter styles and formats. The sample consisted of 242 letters collected in 1975 and 204 letters collected in 1980. All letters were assessed by the same evaluator by using a Nepali Letter Evaluation Instrument, which was validated by a jury of judges. The reliability of the instrument was tested by evaluating the same 20 letters at two different time intervals. Twenty-four separate <b>error</b> <b>categories</b> classified as content, language, and mechanics were identified. Statistical comparisons were made assessing errors in each of 24 separate <b>error</b> <b>categories</b> between the 1975 and 1980 samples. Errors occurring in correspondence from different types of organizations were also compared. Eleven null hypotheses were tested by using Chi-square statistics and Fisher's Exact Test. Descriptive data concerning letter styles, formats, and stationery sizes were also evaluated. Based on the findings of the study, the following conclusions were made: (1) The quality of Nepali letters written in 1980 was approximately the same as the quality of those written in 1975. Of the 24 <b>error</b> <b>categories</b> compared, spelling and margin usages in 1980 improved, punctuation usages deteriorated, and the other 21 categories remained the same. (2) Within various type of organizations, letter writers in 1980 made about the same number of errors in their out-going letters as in 1975. Over 85 percent of the <b>error</b> <b>categories</b> remained unchanged. Fewer margin and spacing errors occurred. Punctuation usages deteriorated. Strikeovers and handwritten corrections occurred less frequently in letters from some types of organizations, but deteriorated in letters from other types of organizations. (3) When usage was compared between organizations, <b>error</b> <b>categories</b> differed in more categories than when it was compared within organizations. Some types of errors occurred more frequently in selected organizations. Letter writers from governmental agencies made more errors in their letter writing than writers from other organizations. Letter writers from semi-government corporations committed the next most frequent number of errors. (4) The ten most frequently occurring errors found in Nepali letters collected in 1975 and 1980 were margin errors, spelling errors, very long sentences, strikeovers, inappropriate words, stereotyped language, too many connectives, errors crossed out, and incorrect word-divisions. (5) Compared to content errors, language errors and mechanical errors occurred more frequently. (6) The typical and most frequently used letter style was the simplified style with salutation and complimentary closing omitted. This style also placed the writer's identification either {{in the middle of the}} paper or on the right hand side. Governmental agencies were the largest users of the Simplified letter style. (7) Salutations and complimentary closings were used by writers from banks, other non-profit organizations, and private businesses. The trend in 1980 was toward using salutations and complimentary closings. (8) Letter placement and margins suggested by Nepali typewriting textbooks were not followed by a majority of the Nepali letter writers. Left and right margins were too small and bottom margins were too wide. (9) The sizes of the stationery were widely diversified. The letter placement appeared awkward because of variations in paper size. Recommendations of this study, if implemented, should strengthen training programs for office personnel in Nepal...|$|E
40|$|We {{present a}} {{programming}} language model of the ideas behind Functional Adaptive Programming (AP-F) and our Java implementation, DemeterF. Computation in AP-F is encapsulated in sets of functions that implement a fold over a data structure {{with the help of}} a generic traversal. In this paper we define the syntax, semantics, and typing rules of a simple AP-F model, together with a proof of soundness that guarantees that traversal expressions result in a value of the expected type. Applying a function set to a different structure can then be statically checked to eliminate some runtime tests and sources of program <b>errors.</b> <b>Categories</b> and Subject Descriptor...|$|R
40|$|Abstract—The {{ability of}} system {{software}} to detect run-time errors and issue messages that help programmers quickly fix these errors {{is an important}} productivity criterion for developing and maintaining application programs. To evaluate this capability for Unified Parallel C (UPC), over two thousand run-time error tests and a run-time error detection (RTED) evaluation tool have been developed. For each error message issued, the RTED evaluation tool assigns a score from 0 to 5 based on {{the usefulness of the}} information in the message to help a programmer quickly fix the error. The RTED evaluation tool calculates averages over each <b>error</b> <b>category</b> and then prints the results. All tests and the RTED evaluation tool are freely available at the RTED web sit...|$|R
40|$|Abstract. The {{ability of}} system {{software}} to detect compile-time errors and issue messages that help programmers quickly fix these errors {{is an important}} productivity criterion for developing and maintaining application programs. To evaluate this capability for Unified Parallel C (UPC), 3143 Compile-Time Error Detection (CTED) tests and a CTED evaluation tool have been developed. The CTED evaluation tool assigns a score from 0 to 5 for each compiler-generated error message based on {{the usefulness of the}} information in the message to help a programmer fix the error quickly. This tool also calculates average scores for each <b>error</b> <b>category</b> and then prints the results. All tests, the CTED evaluation tool and test results for the Berkeley, Cray, GNU and HP UPC compilers are freely available a...|$|R
40|$|A {{classification}} system for errors {{in machine translation}} (MT) output is presented. Translation errors are assigned to categories to provide a systematic basis for comparing the translations produced by competing MT systems. The {{classification system}} is designed for use by potential MT users, rather than MT developers. The <b>error</b> <b>categories</b> can be ranked according to criteria which {{are important to the}} user, such as improvability and intelligibility. The results of CompuServe's use of the error classification methodology are presented as a case study. 1...|$|E
40|$|We present TerrorCat, a {{submission}} to the WMT’ 12 metrics shared task. TerrorCat uses frequencies of automatically obtained transla-tion <b>error</b> <b>categories</b> as base for pairwise com-parison of translation hypotheses, {{which is in}} turn used to generate a score for every trans-lation. The metric shows high overall corre-lation with human judgements on the system level and more modest results {{on the level of}} individual sentences. 1 The Idea Recently a couple of methods of automatic trans-lation error analysis have emerged (Zeman et al., 2011; Popovic ́ and Ney, 2011). Initial experiment...|$|E
40|$|Abstract. We {{present a}} novel phoneme-based student model for {{spelling}} training. Our model is data driven, adapts {{to the user}} and provides information for, e. g., op-timal word selection. We describe spelling errors using a set of features accounting for phonemic, capitalization, typo, and other <b>error</b> <b>categories.</b> We compute the in-fluence of individual features on the error expectation values based on previous in-put data using Poisson regression. This enables us to predict error expectation val-ues and to classify errors probabilistically. Our model is generic and can be utilized within any intelligent language learning environment...|$|E
30|$|One of {{the major}} {{contributions}} of our paper is that we achieve higher recognition accuracy than the prior methods by combining some knowledge-based classifiers. The great difference from the previous work is that we {{make use of the}} category probabilities, not the category label. We combine these probabilities through three ways to increase the probability of correct category, and reduce the probability of <b>error</b> <b>category,</b> that is to say, achieve higher recognition accuracy. Meanwhile, a new algorithm is proposed for learning the weights for these knowledge-based classifiers. Experiment results show that ensemble learning for material recognition with convolutional neural network could get higher accuracy than a knowledge-based classifier. And we also do some experiments with the prior methods; the results show that the way we proposed to combine the knowledge-based classifiers would have a better performance than the prior methods.|$|R
40|$|Abstract—The {{ability of}} system {{software}} to detect compiletime errors and issue messages that help programmers quickly fix these errors {{is an important}} productivity criterion for developing and maintaining application programs. To evaluate this capability for Unified Parallel C (UPC) compilers, 3141 Compile-Time Error Detection (CTED) tests and a CTED evaluation tool, called UPC-CompilerCheck, have been developed. UPC-CompilerCheck assigns a score from 0 to 5 for each compiler-generated error message based on {{the usefulness of the}} information in the message to help a programmer fix the error quickly. This tool also calculates average scores for each <b>error</b> <b>category</b> and then prints the results. Compiler vendors could use UPC-CompilerCheck to evaluate and improve the compile-time error detection capabilities of their UPC compilers. All tests, UPC-CompilerCheck and test results for the Berkeley, Cray, GNU and HP UPC compilers are freely available a...|$|R
40|$|Accurate {{labeling}} and segmentation of {{the unit}} inventory database is of vital importance {{to the quality of}} unit selection text-to-speech synthesis. Misalignments and mismatch between the predicted and pronounced unit sequences require manual correction to achieve natural sounding synthesis. In this paper we have used a log likelihood ratio based utterance verification to automatically detect annotation errors in a Norwegian two-speaker synthesis database. Each sentence is assigned a confidence score and those falling below a threshold can be discarded or manually inspected and corrected. Using equal reject number as a criterion the transcription sentence error rate was reduced from 9. 8 % to 2. 7 %. Insertions are the largest <b>error</b> <b>category,</b> and 95. 6 % of these were detected. A closer inspection of false rejections was performed to assess (and improve) the phoneme prediction system. 1...|$|R
