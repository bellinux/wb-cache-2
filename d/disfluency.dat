439|403|Public
25|$|Cognitive load is an {{important}} predictor of formulaic language. More <b>disfluency</b> is found in longer utterances and when the topic is unfamiliar. In Wood's book, he suggested that when {{a high degree of}} cognitive load occurs, such as during expository speech or impromptu descriptions of complex interrelated topics, even native speakers can suffer from <b>disfluency.</b>|$|E
25|$|Stuttering is {{typically}} a developmental disorder beginning {{in early childhood}} and continuing into adulthood in at least 20% of affected children. The mean onset of stuttering is 30 months. Although there is variability, early stuttering behaviours usually consist of word or syllable repetitions, while secondary behaviours such as tension, avoidance or escape behaviours are absent. Most young children are unaware of the interruptions in their speech. With young stutterers, <b>disfluency</b> may be episodic, and periods of stuttering are followed by periods of relatively decreased <b>disfluency.</b>|$|E
25|$|The {{severity}} of a stutter {{is often not}} constant even for people who severely stutter. People who stutter commonly report dramatically decreased <b>disfluency</b> when talking in unison with another speaker, copying another's speech, whispering, singing, and acting or when talking to pets, young children, or themselves. Other situations, such as public speaking and speaking on the telephone, are often greatly feared by people who stutter, and increased stuttering is reported.|$|E
40|$|The {{current study}} {{examined}} 115 New Zealand English speakers aged 64 - 91 years to obtain normative data on fluency. Stuttering-like and normal <b>disfluencies</b> were analysed in speaking tasks of conversation and reading {{to determine the}} frequency of <b>disfluencies.</b> Variables of age, sex, years of education, and cognitive functioning were also examined to determine whether these influenced <b>disfluencies.</b> Results indicated no change in stuttering-like and normal <b>disfluencies</b> across age in conversation, yet a small significant increase was found in reading for normal <b>disfluencies.</b> Sex and years of education revealed no significant relationship with total <b>disfluencies</b> produced across age, however {{there was a significant}} relationship between cognitive scores and total <b>disfluencies</b> – speakers with higher cognitive scores produced less <b>disfluencies.</b> Age, sex, years of education, and cognitive scores were not significant predictors of stuttering-like <b>disfluencies,</b> though normal <b>disfluencies</b> were. Within the fluency literature, normative data is limited for the ageing population 60 +. This study provides normative data for older New Zealand speakers and valuable additional information to assist clinicians in assessment/diagnosis of acquired communication disorders...|$|R
40|$|<b>Disfluencies,</b> such as uh and uhm, {{are known}} to help the {{listener}} in speech comprehension. For instance, <b>disfluencies</b> may elicit prediction of less accessible referents and may trigger listeners’ attention to the following word. However, recent work suggests differential processing of <b>disfluencies</b> in native and non-native speech. The current study investigated whether the beneficial effects of <b>disfluencies</b> on listeners’ attention are modulated by the (non-) native identity of the speaker. Using the Change Detection Paradigm, we investigated listeners’ recall accuracy for words presented in disfluent and fluent contexts, in native and non-native speech. We observed beneficial effects of both native and non-native <b>disfluencies</b> on listeners’ recall accuracy, suggesting that native and non-native <b>disfluencies</b> trigger listeners’ attention in a similar fashion...|$|R
40|$|Investigations {{into the}} speech of normal {{children}} have indicated that <b>disfluencies</b> are common. It {{is important for the}} Speech Language Pathologist to have knowledge of normal <b>disfluencies</b> for differential diagnosis, parent counseling, and in order to plan strategies for intervention. The {{purpose of this study was}} to compare the frequency of <b>disfluencies</b> in 4 year old and 6 year old normal male children to the frequency of <b>disfluencies</b> when they were 3 years old and 5 years old respectively...|$|R
25|$|In rare cases, {{stuttering}} may {{be acquired}} in adulthood {{as the result}} of a neurological event such as a head injury, tumour, stroke, or drug use. The stuttering has different characteristics from its developmental equivalent: it tends to be limited to part-word or sound repetitions, and is associated with a relative lack of anxiety and secondary stuttering behaviors. Techniques such as altered auditory feedback (see below), which may promote decreasing <b>disfluency</b> in people who stutter with the developmental condition, are not effective with the acquired type.|$|E
25|$|Stuttering {{can also}} have its roots in development. Many {{toddlers}} and preschool age children stutter as they are learning to talk, and although many parents worry about it, most of these children will outgrow the stuttering and will have normal speech as they get older. Since most of these children do not stutter as adults, this normal stage of speech development is usually referred to as pseudo-stuttering or as a normal <b>disfluency.</b> As children learn to talk, they may repeat certain sounds, stumble on or mispronounce words, hesitate between words, substitute sounds for each other, and be unable to express some sounds. Children with a normal <b>disfluency</b> usually have brief repetitions of certain sounds, syllables or short words, however, the stuttering usually comes and goes and is most noticeable {{when a child is}} excited, stressed or overly tired. Stuttering is also believed to be caused by neurophysiology. Neurogenic stuttering is a type of fluency disorder in which a person has difficulty in producing speech in a normal, smooth fashion. Individuals with fluency disorders may have speech that sounds fragmented or halting, with frequent interruptions and difficulty producing words without effort or struggle. Neurogenic stuttering typically appears following some sort of injury or disease to the central nervous system. Injuries to the brain and spinal cord, including cortex, subcortex, cerebellar, and even the neural pathway regions.|$|E
25|$|Some {{characteristics}} of stuttered speech {{are not as}} easy for listeners to detect. As a result, diagnosing stuttering requires the skills of a certified speech-language pathologist (SLP). Diagnosis of stuttering employs information both from direct observation {{of the individual and}} information about the individual’s background, through a case history. Information from both sources should span multiple, various settings and times. The SLP may collect a case history on the individual through a detailed interview or conversation with the parents (if client is a child). They may also observe parent-child interactions and observe the speech patterns of the child's parents. The overall goal of assessment for the SLP will be (1) to determine whether a speech <b>disfluency</b> exists, and (2) assess if its severity warrants concern for further treatment.|$|E
40|$|Although <b>disfluencies</b> such as uh are {{generally}} not treated as linguistic items, our results suggest that they can affect syntactic parsing. Using a grammaticality judgment task, we demonstrate that <b>disfluencies</b> are able to affect the syntactic parse of a sentence in two ways. First, <b>disfluencies</b> can make syntactic reanalysis more difficult by coming between an ambiguous constituent and a disambiguating item. Second, the pattern of <b>disfluencies</b> in spontaneous speech may {{be used by the}} listener to guide the parse of a sentence. Thus, although <b>disfluencies</b> have often been viewed as pragmatic phenomena, they can affect the language comprehension by influencing its parsing procedures. 1...|$|R
40|$|<b>Disfluencies</b> ("um," repeats, self-repairs) are {{prevalent}} in spontaneous speech, and {{are relevant to}} both human speech communication and speech processing by machine. Although <b>disfluencies</b> have commonly been viewed as `noisy' events, results from a large descriptive study indicate that <b>disfluencies</b> show regularities {{in a number of}} dimensions [9]. This paper reports selected results on Switchboard and two comparison corpora of spontaneous speech. Results illustrate the systematic distribution of <b>disfluencies,</b> and highlight differences as well as universals across corpora and speakers. 1. INTRODUCTION <b>Disfluencies</b> (e. g., "um" and "uh", repeats, self-repairs) are {{prevalent in}} spontaneous speech, and are relevant to modeling both human speech communication and speech processing by machine. Although historically <b>disfluencies</b> have been viewed as noisy events, and have received relatively little attention, a more recent focus on spontaneous speech has directed increased interest to disfluenc [...] ...|$|R
40|$|In {{this talk}} I {{would like to}} present results from (on-going) {{eye-tracking}} experiments, using the Visual World Paradigm, investigating the processing of <b>disfluencies.</b> Since spontaneous speech is strewn with <b>disfluencies</b> (such as uhm’s, silent pauses, repetitions, repairs, etc.), one may pose the question how listeners cope with these <b>disfluencies.</b> Do <b>disfluencies</b> hinder the processing {{of the content of}} the speech signal or can they actually be helpful to listeners in predicting what the speaker will say next? I will demonstrate that listeners use <b>disfluencies</b> in reference solution: upon hearing the uh in a sentence like “Click on uh the sewingmachine”, our participants showed more anticipatory looks to low-frequent pictures (e. g., the sewingmachine) as compared to high-frequent pictures (e. g., the hand). In our view, listeners took the uh as a sign that the speaker was having trouble naming an object. These troubles are more likely to occur in naming low-frequent pictures than in naming high-frequent pictures, leading to more anticipatory looks to the low-frequent picture. Our data reveal that listeners are sensitive to <b>disfluencies</b> and that they make use of <b>disfluencies,</b> when listening to a native speaker, to anticipate subsequent content. The next step in our research is to investigate the processing of <b>disfluencies</b> in non-native speech. To illustrate this, I will present some recent data from a study into the supposedly beneficial effects of native and non-native <b>disfluencies</b> on subsequent memory...|$|R
25|$|During direct {{observation}} of the client, the SLP will observe {{various aspects of the}} individual’s speech behaviors. In particular, the therapist might test for factors including the types of disfluencies present (using a test such as the Dysfluency Type Index (DTI)), their frequency and duration (number of iterations, percentage of syllables stuttered (%SS)), and speaking rate (syllables per minute (SPM), words per minute (WPM)). They may also test for naturalness and fluency in speaking (naturalness rating scale (NAT), test of childhood stuttering (TOCS)) and physical concomitants during speech (Riley’s Stuttering Severity Instrument Fourth Edition (SSI-4)). They might also employ a test to evaluate the severity of the stuttering and predictions for its course. One such test includes the stuttering prediction instrument for young children (SPI), which analyzes the child’s case history, part-word repetitions and prolongations, and stuttering frequency {{in order to determine the}} severity of the <b>disfluency</b> and its prognosis for chronicity for the future.|$|E
500|$|During the {{development}} of the series' pilot chapter, Rurouni, Meiji Swordsman Romantic Story, Watsuki and his editor argued over Kenshin's speech patterns, settling for a [...] "slangy" [...] one. For {{the final version of the}} first Romantic Story, Watsuki adjusted the dialogue; in his view, he made Kenshin sound [...] "more as I prefer him now". Nevertheless, Kenshin was concerned about how Kenshin's manner abruptly changed when facing his opponent. Watsuki added Kenshin's trademark [...] as a placeholder to be an expression of the English speech <b>disfluency</b> [...] "huh". Watsuki notes that he was surprised at how well it caught on, and how much he ended up having Kenshin use the sound during the series. Watsuki also planned to make Kenshin more 30 years old; his editor commented that it was strange that the main character of a manga for teenagers to be of such an age, so he instead made him 28 years old.|$|E
2500|$|Linguistic tasks can invoke speech <b>disfluency.</b> [...] People who stutter may {{experience}} varying <b>disfluency.</b> [...] Tasks that trigger <b>disfluency</b> usually require a controlled-language processing, which involves linguistic planning. In stuttering, {{it is seen}} that many individuals do not demonstrate disfluencies {{when it comes to}} tasks that allow for automatic processing without substantial planning. For example, singing [...] "Happy Birthday" [...] or other relatively common, repeated linguistic discourses, could be fluid in people who stutter. [...] Tasks like this reduce semantic, syntactic, and prosodic planning, whereas spontaneous, [...] "controlled" [...] speech or reading aloud requires thoughts to transform into linguistic material and thereafter syntax and prosody. [...] Some researchers hypothesize that controlled-language activated circuitry consistently does not function properly in people who stutter, whereas people who do not stutter only sometimes display disfluent speech and abnormal circuitry.|$|E
40|$|The regular {{occurrence}} of <b>disfluencies</b> is a distinguishing characteristic of spontaneous speech. Detecting and removing such <b>disfluencies</b> can substantially improve {{the usefulness of}} spontaneous speech transcripts. This paper presents a system that detects various types of <b>disfluencies</b> and other structural information with cues obtained from lexical and prosodic information sources. Specifically, combinations of decision trees and language models are used to predict sentence ends and interruption points and, given these events, transformationbased learning is used to detect edit <b>disfluencies</b> and conversational fillers. Results are reported on human and automatic transcripts of conversational telephone speech. ...|$|R
40|$|The {{purpose of}} this study was to compare the {{frequency}} of specific <b>disfluencies</b> in 3 year old and 5 year old normal male children in terms of part-word repetitions, word repetitions, phrase repetitions, interjections, revision-incomplete phrases, disrhythmic phonations and tense pauses. The <b>disfluencies</b> were observed while each child spontaneously interacted with an investigator in a clinical room. Two questions were addressed: 1. Do three-year-old male children exhibit a higher overall frequency of <b>disfluencies</b> than five-yearold male children? 2. Do three-year-old male children exhibit a greater frequency of certain <b>disfluencies</b> than five-year old male children...|$|R
40|$|ABSTRACT Purpose: {{to compare}} the {{frequency}} of <b>disfluencies</b> and speech rate in spontaneous speech and reading in adults with and without stuttering in non-altered and delayed auditory feedback (NAF, DAF). Methods: participants were 30 adults: 15 with Stuttering (Research Group - RG), and 15 without stuttering (Control Group - CG). The procedures were: audiological assessment and speech fluency evaluation in two listening conditions, normal and delayed auditory feedback (100 milliseconds delayed by Fono Tools software). Results: the DAF caused a significant improvement in the fluency of spontaneous speech in RG when compared to speech under NAF. The effect of DAF was different in CG, because it increased the common <b>disfluencies</b> and the total of <b>disfluencies</b> in spontaneous speech and reading, besides showing {{an increase in the}} frequency of stuttering-like <b>disfluencies</b> in reading. The intergroup analysis showed significant differences in the two speech tasks for the two listening conditions in the frequency of stuttering-like <b>disfluencies</b> and in the total of <b>disfluencies,</b> and in the flows of syllable and word-per-minute in the NAF. Conclusion: the results demonstrated that delayed auditory feedback promoted fluency in spontaneous speech of adults who stutter, without interfering in the speech rate. In non-stuttering adults an increase occurred in the number of common <b>disfluencies</b> and total of <b>disfluencies</b> as well as reduction of speech rate in spontaneous speech and reading...|$|R
2500|$|The {{disorder}} is also variable, {{which means that}} in certain situations, such as talking on the telephone or in a large group, the stuttering might be more severe or less, depending {{on whether or not}} the stutterer is self-conscious about their stuttering. Stutterers often find that their stuttering fluctuates and that they have [...] "good" [...] days, [...] "bad" [...] days and [...] "stutter-free" [...] days. The times in which their stuttering fluctuates can be random. Although the exact etiology, or cause, of stuttering is unknown, both genetics and neurophysiology are thought to contribute. There are many treatments and speech therapy techniques available that may help decrease speech <b>disfluency</b> in some people who stutter to the point where an untrained ear cannot identify a problem; however, there is essentially no cure for the disorder at present. The severity of the person's stuttering would correspond to the amount of speech therapy needed to decrease <b>disfluency.</b> For severe stuttering, long-term therapy and hard work is required to decrease <b>disfluency.</b>|$|E
2500|$|Among preschoolers, the {{prognosis}} for recovery is good. Based on research, about 65% of preschoolers who stutter recover spontaneously {{in the first}} two years of stuttering, and about 74% recover by their early teens. In particular, girls seem to recover well. [...] For others, early intervention is effective in helping the child overcome <b>disfluency.</b>|$|E
2500|$|Because of the unusual-sounding {{speech that}} is {{produced}} and the behaviors and attitudes that accompany a stutter, {{it has long}} been a subject of scientific interest and speculation as well as discrimination and ridicule. People who stutter can be traced back centuries to the likes of Demosthenes, who tried to control his <b>disfluency</b> by speaking with pebbles in his mouth. The Talmud interprets Bible passages to indicate Moses was also a person who stuttered, and that placing a burning coal in his mouth had caused him to be [...] "slow and hesitant of speech" [...] (Exodus 4, v.10).|$|E
40|$|The {{production}} of speech {{is a highly}} complex process, and speakers typically produce 6 errors per 100 words. Previous research addressing the cause of such errors has largely overlooked the idea that personality {{may be associated with}} <b>disfluencies</b> in speech, despite evidence that those with schizophrenia and other thought disorders exhibit odd speech characteristics. 73 participants between the ages of 19 and 78 completed the Schizotypal Personality Questionnaire (SPQ) and two running speech tasks: a commentary task during a five minute segment of a silent film, and a recall task following another five minute segment. Speech data was transcribed and <b>disfluencies</b> were counted, and the rate of <b>disfluencies</b> calculated. Correlative statistics revealed no correlation between the total SPQ score and the rate of <b>disfluencies,</b> however there was a significant negative correlation between the score on the SPQ and the rate of <b>disfluencies</b> on the recall task (N= 73, r=. 251, p<. 05). Additionally, a significant task effect was observed, with participants demonstrating increased <b>disfluencies</b> on the recall task compared to the commentary task, and a proportionately higher rate of hesitations compared to repairs on the recall task. A more accurate means of analysing the SPQ and detailed acoustic analysis of <b>disfluencies</b> are required in this field of research to further the understanding of the cause of <b>disfluencies</b> in speech...|$|R
40|$|This {{study which}} is {{entitled}} “Ketidakfasihan Berbicara Para Pemeran dalam Serial Film Harry Potter Enam dan Tujuh (Suatu Analisis Psikolinguistik) ” {{is an attempt}} to identify the types of speech <b>disfluencies</b> of the characters in the serial films Harry Potter Six and Seven and to analyze the causes of those speech <b>disfluencies.</b> In classifying and analyzing the collected data, the writer uses Fox-Three (1995) and MacGregor 2 ̆ 7 s (2008) theory about the types of speech <b>disfluencies,</b> and Bortfeld 2 ̆ 7 s et al. (2001) theory of what cause the speech <b>disfluencies.</b> It is found that five types of speech <b>disfluencies</b> are produced by the characters in the Serial Films Harry Potter Six and Seven. That types are, silent pause, filled pause, repetition, repair, and lexical filler. Repetitions is the types of <b>disfluencies</b> are the most founded because of the increase in cognitive process that results to a heavy planning in utterances. The causes of speech <b>disfluencies</b> of the characters in serial films Harry Potter Six and Seven are by variables such as, cognitive load, communication medium, topic under discussion, addressee characteristic, speaker characteristic, as well as social and situational factors. It is because we encounter those variables in almost every time. Age is not found to cause of speech <b>disfluencies</b> in the serial films Harry Potter because as there aren 2 ̆ 7 t many older people characters in the serial films. This study will help students and the next researchers in expanding their knowledge about speech <b>disfluencies</b> and language production...|$|R
40|$|This paper traces 9 non-English major EFL {{students}} and collects their oral productions in 4 successive oral exams in 2 years. The canonical correlation analysis approach of SPSS is adopted {{to study the}} <b>disfluencies</b> developmental traits {{under the influence of}} language acquisition development. We find that as language acquisition develops, the total production of difluenices does not decrease correspondingly as we thought, but keeps constant for a period of time. While the proportions of specific <b>disfluencies</b> phenomena change significantly, which features the decrease of pauses and the increase self-repairs. Besides, the grammatical accuracy and language complexity have opposite effects on <b>disfluencies</b> traits. In the first year, <b>disfluencies</b> were displayed mainly as pauses and repetitions since EFL students paid more attention to grammatical accuracy; in the second year, <b>disfluencies</b> featured more self-repairs and less pauses because EFL students transferred their attention to language complexity. We also find language acquisition can only account for partial developmental traits of <b>disfluencies</b> despite of the strong correlations between them, and other factors, such as psychological or social elements, may also take effects. </p...|$|R
50|$|Cognitive load is an {{important}} predictor of formulaic language. More <b>disfluency</b> is found in longer utterances and when the topic is unfamiliar. In Wood's book, he suggested that when {{a high degree of}} cognitive load occurs, such as during expository speech or impromptu descriptions of complex interrelated topics, even native speakers can suffer from <b>disfluency.</b>|$|E
5000|$|... #Subtitle level 2: As a {{discourse}} particle, filler, hedge, or speech <b>disfluency</b> ...|$|E
50|$|Schachter, S. (1991) With N. J. S. Christenfeld, B. Ravina, and F. R. Bilous. Speech <b>disfluency</b> and the {{structure}} of knowledge. J. Pers. Soc. Psychol. 60:362-67.|$|E
40|$|Unrehearsed spoken {{language}} often contains many <b>disfluencies.</b> If {{we want to}} correctly interpret the content of {{spoken language}}, {{we need to be}} able to detect these <b>disfluencies</b> and deal with them appropriately. In the work described here, we use a statistical noisy channel model to detect <b>disfluencies</b> in transcripts of spoken language. Like all statistical approaches, this is naturally very data-hungry; however, corpora containing transcripts of unrehearsed spoken language with <b>disfluencies</b> annotated are a scarce resource, which makes training difficult. We address this issue in the following ways: First, since written textual corpora are much more abundant than speech corpora, we see whether using a large text corpus to increase the data available to our language model component delivers an improvement. Second, given that most spoken language corpora are not annotated with <b>disfluencies,</b> we explore the use of Expectation Maximisation to mark the <b>disfluencies</b> in such corpora, so as to increase the data availability for our complete model. In neither case do we see an improvement in our results. We discuss these results and the possible reasons for the negative outcome. ...|$|R
40|$|Unrehearsed spoken {{language}} often contains <b>disfluencies.</b> In order to correctly interpret a spoken utterance, any such <b>disfluencies</b> must {{be identified and}} removed or otherwise dealt with. Operating on transcripts of speech which contain <b>disfluencies,</b> our particular focus here is the identification and correction of speech repairs using a noisy channel model. Our aim {{is to develop a}} high-accuracy mechanism that can identify speech repairs in an incremental fashion, as the utterance is processed word-by-word. We also address the issue of the evaluation of such incremental systems. We propose a novel approach to evaluation, which evaluates performance in detecting and correcting <b>disfluencies</b> incrementally, rather than only assessing performance once the processing of an utterance is complete. This demonstrates some shortcomings in our basic incremental model, and so we then demonstrate a technique that improves performance on the detection of <b>disfluencies</b> as they happen. ...|$|R
40|$|This paper {{presents}} {{a study of}} <b>disfluencies</b> in written language production. Texts from ten university students are compared to data from people who almost never use writing, namely adult dyslexics and to texts from people who communicate in writing under real-time constraints every day, namely deaf whose main use of writing is text telephone conversations. This paper investigates which types of <b>disfluencies</b> occur in writing, where they occur and their durations. Further, this paper investigates how different text types and the specific characteristics of deaf and dyslexic writers influence the distribution of <b>disfluencies.</b> The results are discussed in relation to earlier work on <b>disfluencies</b> in speaking. 1...|$|R
50|$|Stuttering is {{typically}} a developmental disorder beginning {{in early childhood}} and continuing into adulthood in at least 20% of affected children. The mean onset of stuttering is 30 months. Although there is variability, early stuttering behaviours usually consist of word or syllable repetitions, while secondary behaviours such as tension, avoidance or escape behaviours are absent. Most young children are unaware of the interruptions in their speech. With young stutterers, <b>disfluency</b> may be episodic, and periods of stuttering are followed by periods of relatively decreased <b>disfluency.</b>|$|E
5000|$|The {{disorder}} is also variable, {{which means that}} in certain situations, such as talking on the telephone or in a large group, the stuttering might be more severe or less, depending {{on whether or not}} the stutterer is self-conscious about their stuttering. Stutterers often find that their stuttering fluctuates and that they have [...] "good" [...] days, [...] "bad" [...] days and [...] "stutter-free" [...] days. The times in which their stuttering fluctuates can be random. Although the exact etiology, or cause, of stuttering is unknown, both genetics and neurophysiology are thought to contribute. There are many treatments and speech therapy techniques available that may help decrease speech <b>disfluency</b> in some people who stutter to the point where an untrained ear cannot identify a problem; however, there is essentially no cure for the disorder at present. The severity of the person's stuttering would correspond to the amount of speech therapy needed to decrease <b>disfluency.</b> For severe stuttering, long-term therapy and hard work is required to decrease <b>disfluency.</b>|$|E
5000|$|... {{stuttering}} - {{a speech}} disorder in which sounds, syllables, or words are repeated or {{last longer than}} normal. These problems cause {{a break in the}} flow of speech (called <b>disfluency).</b>|$|E
40|$|Spoken {{language}} contains <b>disfluencies,</b> {{which include}} editing {{terms such as}} uh and um as well as repeats and corrections. In less than ten years {{the question of how}} <b>disfluencies</b> are handled by the human sentence com-prehension system has gone from virtually ignored to a topic of major interest in computational linguistics and psycholinguistics. We discuss relevant empirical find-ings and describe a computational model that captures how <b>disfluencies</b> influence parsing and comprehension. The research reviewed shows that the parser, which presumably evolved to handle conversations, deals with <b>disfluencies</b> {{in a way that is}} efficient and linguisti-cally principled. The success of this research program reinforces the current trend in cognitive science to view cognitive mechanisms as adaptations to real-world con...|$|R
40|$|This paper {{presents}} {{the inventory of}} <b>disfluencies</b> and the annotation procedure {{for a set of}} 227 Spanish dialogues recorded according to the well known Wizard of Oz paradigm. A XML-like annotation scheme was designed and used, which accounted only for <b>disfluencies</b> happening in the dialogues. A first draft of the manual for annota-tors was written and iteratively tested, corrected and augmented over a representative subset of dialogues. Finally the whole set of dialogues was annotated with acous-tic, lexical and syntactic <b>disfluencies,</b> as well as discourse markers, using the ultimate version of the manual. Only user turns were annotated, because WoZ turns were auto-matically synthetized according to a collection of rules and templates. A very simple parser was implemented, which helped to locate most errors in annotations. A detailed inspection of the annotations revealed that most <b>disfluencies</b> were grouped into certain user turns. Statistics show that acoustic phenomena: noises produced by user, length-ening of sounds, silence pauses and filled pauses, were the most common <b>disfluencies.</b> On the other hand, <b>disfluencies</b> were not uniformly distributed among speakers. Some speakers were remarkably more prone to hesitate, repeat or correct fragments of speech than others...|$|R
40|$|Stuttering is {{a speech}} {{disorder}} characterized by {{certain types of}} speech <b>disfluencies,</b> such as sound repetitions, which are frequent enough to be disruptive. Speech therapists frequently use manual counts of these speech <b>disfluencies</b> to diagnose whether a child stutters and to track improvement through a treatment program. However, these counts are subjective, inconsistent, and prone to error. We propose the use of speech recognition technology to automate these counts, thus providing an objective and consistent measurement. Since many of the <b>disfluencies</b> in stuttered speech obey certain regularities, we built several grammar-based language models that capture these regularities to detect <b>disfluencies.</b> These grammars have uniform transition weights. We tested the grammars on a short sample of stuttered speech and analyzed their performance based on word error rate and how well they detect and classify <b>disfluencies.</b> Results indicate that these grammars detect repetition <b>disfluencies</b> poorly, particularly phoneme repetitions. We are currently building a probabilistic language model and expect that the more accurate transition probabilities {{will lead to a}} decrease in false positives. We also expect that further improvement will be achieved by modeling the acoustic properties of stuttered speech. ...|$|R
