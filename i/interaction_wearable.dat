4|76|Public
30|$|Jin-Hee Lee is {{a senior}} {{researcher}} in Future Automotive Technology Research Center, DGIST, Korea. She received the B.S. degree in Computer Science from Korea National Open University, and M.S. and Ph.D. degree in Computer and Information Engineering from Inha University of Korea. Her research interests include human computer <b>interaction,</b> <b>wearable</b> computer, and ubiquitous computing. Byeong-Seok Shin {{is a professor in}} the School of Computer and Information Engineering, Inha University, Korea. He received his B.S., M.S., and Ph.D. in Computer Engineering from the Seoul National University in Korea. Current research interests include human computer interaction, volume rendering, real-time graphics, and medical imaging.|$|E
40|$|Mobile {{information}} systems aid first responders in their tasks. Support is {{often based on}} mobile maps. People have different preferences for map orientations (heading-up or north-up), but map orientations also have different advantages and disadvantages. In general north-up maps are good for building up situation awareness and heading-up maps are better for navigational tasks. Because of heavily loaded visual modalities, we expect that tactile waypoint information can enhance navigation speed and situation awareness. In this paper we describe an experiment conducted in a synthetic task environment, in which we examined the effect of heading-up and north-up displays on search and rescue performance of first responders, and if adding the tactile display improves performance. Mobile maps, multimodal <b>interaction,</b> <b>wearable</b> computing, navigation, tactile feedback, game-based simulation, crisis management, first responder...|$|E
40|$|Today, {{there are}} a {{significant}} class of personalized mobile systems (m-Health) to monitor {{the health of the}} person. These personalized systems are designed for remote collection of different biomedical data of a person and are mainly used with diagnostic purposes. Such systems are passive means of measuring, control and collection of biomedical information and have limited class of tasks. An emerging new class of personalized medical and biological systems based on advanced technology provides greater <b>interaction</b> <b>wearable</b> biosensors, of drugs and the human body, greater integration database of biomedical information systems, global positioning and neural networking with stationary medical centers in real time. Below discusses the concept of personalized medicine with the use of mobile technology and satellite systems of positioning. The description of one of the projects being developed in the laboratory of Information Technology, Saratov State University, personal remote-invasive medical system based on mobile applications. </p...|$|E
40|$|Sonic City is {{a project}} {{exploring}} mobile <b>interaction</b> and <b>wearable</b> technology for everyday music creation. A wearable system has been developed that creates electronic music in real-time based on sensing bodily and environmental factors [...] thus, a personal soundscape is co-produced by physical movement, local activity, and urban ambiance simply by walking through the city...|$|R
40|$|Primary Tasks in Wearable Computing In {{this paper}} {{we present a}} novel {{apparatus}} for simulating real world primary tasks typically found in wearable computing. Additionally, we report on a preliminary interruption study using the new apparatus in a laboratory experiment and compare its results with previous work to show its applicability for research in human-computer <b>interaction</b> for <b>wearable</b> computers...|$|R
40|$|In {{this paper}} we {{introduce}} application scenarios for implicit interaction with Smartwatches {{for the purpose}} of user assistance, to create awareness, and to enhance as well as simplify the <b>interaction</b> with <b>Wearables.</b> We envision three scenarios (1) the detection of sleep apnea, (2) the detection of epileptic seizures, and (3) a detection of accidents such as falling, car crashes etc., which are presented and discussed. Therefore, the recognition of all incidents described will be discussed under the meta-topic of anomaly detection...|$|R
40|$|In this paper, we {{describe}} the use of experience modeling to create gestural protocols for physiological data transfer. This design method {{has been applied to}} the development of a wearable computing public art installation called whisper. A series of user-experience workshops were designed with the goal of developing an interaction model for the public installation. These workshops modeled intimacy, social navigation and playful exchange, using performance methods to create gestural protocols. Workshop participants generated movement vocabularies by negotiating permission and control of their own physiological data. Gesture was utilized as an expressive indicator of intentionality, extension of body image, permission, control, exchange and play. We illustrate through video, gestural analysis, and experimental feedback, how the workshops provided an experience model for the <b>interaction,</b> <b>wearable</b> garment design, and body-to-body network protocol used in the public art installation, and how performance methodologies can contribute to the area of interaction design. Author Keywords gestural protocols, performance methods, choreography, wearabl...|$|E
3000|$|Moving forward, the {{question}} we pose now is whether collocating <b>interactions</b> between soft <b>wearables</b> may further enhance their potential to bring meaning to individual, {{as well as social}} experiences. Will doing so further enrich the embodied, situated and connected experiences their wearers engage in? [...]...|$|R
40|$|Part 10 : WorkshopsInternational audienceThis {{workshop}} aims at {{developing and}} discussing ideas how Human-Machine-Interaction can develop beyond the interaction mechanisms {{that are available}} today. Especially this workshop will focus on discussing <b>interaction</b> mechanisms with <b>wearable</b> and implantable devices as well as integrating Internet-of-Things technology with new interaction paradigms...|$|R
40|$|Wearable {{devices such}} as smartwatches (SW) and head-worn {{displays}} (HWD) are gaining popularity. To improve the collocated capabilities of wearables, we need to facilitate collocated interaction in a socially ac- ceptable manner. In this paper we propose to explore widespread used greeting gestures such as handshakes or head gestures to perform collocated <b>interactions</b> with <b>wearables.</b> These include pairing devices or information exchange. We analyze the properties of greetings {{and how they can}} map to different levels of wearable pair- ing (family, friend, work, stranger). This paper also suggest how these gestures could be detected with SWs and HWDs. Autho...|$|R
40|$|The aim of {{this thesis}} is to {{understand}} what are the factors that affect patient satisfaction in healthcare, specifically in Emergency Department. In particular, the study focused on understanding how and how much interactions between {{the patient and the}} medical team affect the perception and satisfaction of the service received by monitoring such <b>interactions</b> through a <b>wearable</b> devices...|$|R
40|$|In this article, {{wearable}} {{computers are}} considered {{from the perspective}} of human factors. Three approaches to the development of this technology are presented: computers that can be worn, information appliances that can be worn, and computers as clothing. The implications for how people will wear and interact with computers in these forms are considered. In particular, in this article a discussion of forms of dialogue to demonstrate how wearable computers require fundamental revision {{of the way in which}} we consider human–computer interaction is presented. This article concludes with reports of work on human <b>interaction</b> with <b>wearable</b> computers, both in terms of task performance and physical effects of wearing technology. 1...|$|R
40|$|Because LEDs offer {{flexible}} expressions such as brightness, color control, {{and various}} patterns, they are popularly used in multidevice interactions. Moreover, LEDs have excellent physical characteristics. However, existing LED light-based <b>wearable</b> <b>interactions</b> {{are designed for}} interest and attention. So, LED {{can be used in}} fashion as it can give new look to our style {{and at the same time}} also as an interaction device. Therefore, in this paper, we present the design guideline for regulating the technical implementation, design strategies, and directions of interactive LED devices. The technology and design concepts are demonstrated through a case study (analysis) of an existing LED light-based <b>wearable</b> <b>interaction.</b> We also design a scenario-based iterative collaborative design process model. Finally, we develop a smart fashion of modular strapped cuffs and zipper slider types that can be attached and detached according to the user’s preference as the interactive smart fashion using user-oriented visible light communication, ultimately pursuing a visual-MIMO (Multiple-Input Multiple-Output) product through stepwise strategy...|$|R
30|$|Tomico and Wilde {{approach}} collocated <b>interaction</b> with <b>wearables</b> {{from the}} perspective of clothing. Their article discusses the opportunities and challenges that exist around designing truly wearable wearables, exploring notions of situatedness and personal meaning-making, and applying these through three separate design prototypes. Sound Embracers, for example, uses stretch sensors and speakers to support performance through movement, while Trailblazer is intended to support balance and provide tactile cues while running, and Open Up uses proximity sensors embedded within clothing to impart a sensation when others move into the wearer's personal space. Using these examples to stimulate discussions around situated, embodied and connected wearables, the authors identify a series of opportunities and challenges, and three broad recommendations for future soft wearables.|$|R
40|$|TiltType {{is a novel}} {{text entry}} {{technique}} for mobile devices. To enter a character, the user tilts the device and presses one or more buttons. The character chosen depends on the button pressed, the direction of tilt, and the angle of tilt. TiltType consumes minimal power and requires little board space, making it appropriate for wristwatch-sized devices. But because controlled tilting of one’s forearm is fatiguing, a wristwatch using this technique must be easily removable from its wriststrap. Applications include two-way paging, text entry for watch computers, web browsing, numeric entry for calculator watches, and existing applications for PDAs. KEYWORDS: Input/output devices, <b>interaction</b> techniques, <b>wearable</b> computing, mobile devices, text entry, accelerometer applications, wristwatch computers...|$|R
40|$|Sonic City is {{a project}} {{exploring}} mobile <b>interaction</b> and <b>wearable</b> technology for everyday music creation. A wearable system has been developed that creates electronic music in real-time based on sensing bodily and environmental factors - thus, a personal soundscape is co-produced by physical movement, local activity, and urban ambiance simply by walking through the city. Applying multi-disciplinary methods, we have developed the wearable from a scenario-driven, aesthetic and lifestyle perspective. A garment has been crafted for 'trying on' interaction and wearabilty options with users on-site in the city. With this prototype, {{we have been able}} to expore and rapidly iterate context and content, social and human factors of the wearable application. IT + TextilesPublic Play SpacesSonic Cit...|$|R
40|$|One {{challenge}} of wearable computing is {{the design and}} use of <b>interaction</b> devices for <b>wearable</b> applications that are accepted by users. In our previous work, the Winspect [1] project, a wearable system for crane maintenance was constructed that used a multitude of cable connections to attach a data glove interaction device, an external battery pack, ultrasound emitters and receivers, a RFID scanner, and a head-mounted display, to a wearable computer. However, {{the presence of these}} cable connections led to the rejection of the Winspect prototype by the industrial partner due to work safety considerations. In order to close the gap between a multitude of devices that are connected to a wearable computer by cable and a textile electronics system that integrates all sensing capabilities into the textile fabric, sensor-boards are needed. With SCIPIO, we built a sensor interface system as a basis for building various <b>wearable</b> <b>interaction</b> devices. SCIPIO’s features include • small size and lightweight • multitude of analogue and digital inputs and outputs • Bluetooth wireless communication interfac...|$|R
40|$|Our goal is {{to further}} {{evaluate}} and formalize techniques and choices of input and output modalities for <b>interaction</b> in <b>wearable</b> outdoor augmented reality. Currently most outdoor augmented reality systems treat choices on interaction techniques and devices in an adhoc per application basis. We hope to formalize more general best practices for these fields to guide future researchers in developing their own systems. To address interaction techniques we will evaluate which techniques developed for virtual reality are still applicable for outdoor augmented reality for selection, manipulation and navigation, and develop and evaluate new techniques for annotation. Along with this we will evaluate and formulate best practices for use of devices in outdoor augmented reality, and modalities of input to the interaction system. ...|$|R
40|$|Human <b>interaction</b> with <b>wearable</b> {{computers}} is {{an important}} research issue, especially when combined with mixed reality (MR) applications. Natural and non-obtrusive means of interaction calls for new devices, which should be simple to use. This paper considers the design of new interaction hardware, such as a wearable computer pen, a tilt pad, a wand, and a gesture pad designed using accelerometers for such scenarios. The very difficult problem of noise in small hardware accelerometers, {{in the form of}} random bias drifts, which seriously impedes it's application in position measurement is also examined in detail. Kalman filtering has resulted in improved results, which are presented herewith. The application of accelerometers to design interfaces for use in mixed reality environments is also explained...|$|R
40|$|Background: Autism Spectrum Disorders (ASD) {{represent}} a heterogeneous set of neurodevelopmental disorders characterized by impairments in social domain, where the {{autonomic nervous system}} (ANS) plays an important role. Several researchers have studied the ANS in ASD, during specific cognitive or sensory stimuli while {{few studies have examined}} response during social <b>interactions.</b> <b>Wearable</b> technologies can be very helpful in monitoring autonomic response in children with ASD in semi-naturalistic setting. The novelty {{of this study is to}} use such technologies to acquire physiological signals during therapeutic sessions supported by interactive "serious games" and to correlate the ANS response to the engagement of the child during sociocognitive tasks for an evaluation of the treatment effect and for the personalization of the therapy. Method: A wearable chest belt for electrocardiographic (ECG) signal recording was used and specific algorithms for the extraction of clinically relevant features (Heart Rate - HR, Root Mean Square of the Successive Differences - RMSSD and Respiratory Sinus Arrhythmia - RSA) were developed. Sociocognitive tasks were mediated by "serious games" implemented on two tablets, which allowed a precise coding of the behaviors of the children. A longitudinal assessment of the physiological response of the children during six months of treatment was performed. Results: A link between physiological response, i. e. decrease in RMSSD and RSA, and engagement of the children during sociocognitive tasks was found. Longitudinal changes in the children's autonomic response, including a decrease of RSA during the engagement throughout the therapeutic sessions, were found. Conclusions: These results foster the feasibility of this methodology to be applied in a clinical setting for the monitoring of the ANS response of children with ASD during treatment. A larger sample of patients is needed to confirm these preliminary findings...|$|R
40|$|Abstract. The SCIPIO (“Semi-Complex Intelligent Programmable Input and Output”) module is a {{miniaturized}} {{interface device}} {{designed for use}} in wearable computing applications. It provides {{a considerable number of}} flexibly combinable input and output channels in a small and lightweight package (50 x 30 x 12 mm, 19 gram). Besides hardware aspects of the SCIPIO interface the paper shows an example of a <b>wearable</b> <b>interaction</b> device that was built with the SCIPIO hardware to evaluate its usefulness for interaction device design for wearable applications. ...|$|R
30|$|Recently, {{the first-person}} camera {{embedded}} wearable computer, such as augmented reality headset and smart glasses, is growing vigorously and urgently requires suitable interaction patterns for egocentric vision. One feasible option is taking user’s hand as the medium for human-computer <b>interaction.</b> The <b>wearable</b> computer interprets hand position, posture, and gesture into commands and produces appropriate {{responses to the}} user. These properties of hand are preceded by reliable hand detection and segmentation from the egocentric video. The egocentric view brings opportunities for hand detection and segmentation. Since the video is recorded from a first-person perspective, the occlusions {{are less likely to}} happen at the attention hand and the user prefers to concentrate on region in the center of view field. Meanwhile, the egocentric video also presents new challenges including rapid changes in illuminations, significant camera motion, and background clutter.|$|R
40|$|Wearable {{computing}} {{technology offers}} tremendous possibilities to support users in performing {{a variety of}} tasks that go beyond traditional desk-based computer <b>interaction.</b> Recent <b>wearable</b> systems share many capabilities with desk-based workstations, but often differ in the way user input is acquired and processed. This paper investigates four commercially available pointing devices and four on-screen menu configurations to assess which are most appropriate for performing menu selection tasks using a wearable computer system in a mobile and stationary scenario. We conducted a controlled user study to compare a trackball, touchpad, gyroscopic mouse and Twiddler 2 in combination with pull-down, linear (fixed and pop-up) and pie pop-up menus. Our results indicate that pie pop-up menus are the most effective menu structure irrespective of the input device used, and that the trackball device outperforms the remaining devices in terms of speed and error rate. 1...|$|R
30|$|In {{the recent}} years, several {{methods have been}} {{developed}} to gather quantitative data on human <b>interactions</b> using <b>wearable</b> sensors and complement more traditional methods based on surveys [1 – 3]. Current data collection methods range from the use of Bluetooth or WiFi signals in mobile phones [4 – 9] to the specific development of dedicated sociometric sensors [10 – 19] and enable researchers to record and measure physical proximity events between individuals in various social contexts. Depending on the specific technology considered however, spatial resolution varies and the resulting “contacts” detected can range from co-presence in a room or a part of a building to close face-to-face encounters. The resulting data is often temporally resolved and has been increasingly used in various contexts including the study of human behaviour, the validation of models of human interactions and data-driven models of epidemic spreading [3, 20, 21].|$|R
40|$|The use {{of speech}} and {{auditory}} <b>interaction</b> on <b>wearable</b> computers can provide an awareness of events and personal messages, without requiring one's full attention or disrupting the foreground activity. A passive "handsand -eyes-free" approach is appropriate when users need convenient and timely access to remote information and communication services. Nomadic Radio is a distributed computing platform for wearable access to unified messaging via an auditory interface. We demonstrate the use of auditory cues, spatialized audio, and speech I/O in the wearable interface for passive awareness, scaleable notification and navigation/control. The architecture is designed for wired audio wearables and has been extended for distributed wireless operation. 1 : Introduction In an information rich environment, people access a multitude of content such as news, weather, stock reports, and data {{from a variety of}} information sources. People increasingly communicate via services such as email, fax, and [...] ...|$|R
50|$|One common {{feature of}} {{wearable}} computers is their persistence of activity. There is constant <b>interaction</b> between the <b>wearable</b> and user, {{so there is}} no need to turn the device on or off. Another feature is the ability to multi-task. When using a wearable computer, {{there is no need to}} stop what one is doing to use the device; its functionality blends seamlessly into all other user actions. These devices can be used by the wearer to act as a prosthetic. It may therefore be an extension of the user's mind or body.|$|R
40|$|Computing of {{the future}} will be {{affected}} by a number of fundamental technologies in development today, many of which are already on the way to becoming commercialized. In this series of lectures, we will discuss hardware and software development that will become mainstream in the timeframe of a few years and how they will shape or change the computing landscape - commercial and personal alike. Topics range from processor and memory aspects, programming models and the limits of artificial intelligence, up to end-user <b>interaction</b> with <b>wearables</b> or e-textiles. We discuss the impact of these technologies on the art of programming, the data centres {{of the future}} and daily life. On the third day of the Future Computing Technology series, we will touch on societal aspects of the future of computing. Our perception of computers may at time seem passive, but in reality we are a vital chain of the feedback loop. Human-computer interaction, innovative forms of computers, privacy, process automation, threats and medical applications will be discussed...|$|R
40|$|This report {{covers the}} design {{research}} {{process and results}} of the 9 -week Thesis Project I. A hands-on, Research Through Design approach led the project through an iterative process {{with a focus on}} creating functional prototypes and validation with experts to answer the research question: How could proprioceptive wearable technology assist in improving {{the quality of life for}} patients of Parkinson’s Disease? Within this main question, focus points have been placed on designing for comfort (i. e. wearability) and well-being with attention to aesthetics. The project builds upon the theories of Design for well-being, Embodied <b>Interaction</b> and <b>Wearable</b> technology and is supported by research on proprioception, Parkinson’s Disease, postural instability and sensory stimuli. The result is a series of models, sketches and prototypes and this report covering the process. The final concept and prototype is a system that monitors upper body posture and provides vibro-tactile feedback on strategically placed areas of the body to guide the patient towards the desired posture. ...|$|R
40|$|We {{describe}} a novel wearable device that perceives and reports on social-emotional information in realtime human <b>interaction.</b> Using a <b>wearable</b> camera and other sensors, combined with machine perception algorithms, the system records and analyzes the facial expressions and head {{movements of the}} person with whom the wearer is interacting. We propose {{the application of the}} social-emotional prosthetic to assist the growing number of individuals diagnosed with Autism Spectrum Disorder (ASD) in perceiving communication in a natural rather than a structured environment, bootstrapping their ability to learn and develop in social settings. The wearable device is a novel exploratory platform for researchers to gain...|$|R
40|$|International audienceIn {{this chapter}} we {{describe}} a real augmented environment {{and its associated}} mobile <b>interactions</b> based on <b>wearable</b> computers with appropriate interaction devices that can be either classical computer interaction devices or real objects augmented with computer interfaces called tangible objects. After presenting the main principles, we describe a concrete platform, related MDA development processes and give several applications. These examples are contextual collaborative maintenance of industrial appliances and associated just-in-time mobile learning and nutritional coaching system supporting practice and learning of management of nutritional decisions in relation to specific requirements in health or high-level sport...|$|R
40|$|Abstract — In {{this paper}} {{we present a}} novel {{wearable}} navigation system along with implicit HCI (iHCI) model, where interaction with technology is dissolved into a day-to-day activity. In this type of HCI model a computer takes the input and tries to output an action that is a proactive anticipation of next action of a user. Usually, in urban areas people use voice assisted navigation systems or navigation guidelines displayed on a mobile phone. Some navigation systems are already installed on car dashboard, which needs explicit attention {{in order to make}} driving decisions. A navigation system using haptic perception to guide a user throughout a journey is the key contribution of this paper. It does not ask for explicit user attention and demonstrates the indolent form of technological <b>interaction.</b> This <b>wearable</b> device is an index finger sleeve, which consists of vibrator modules, Bluetooth communication module and Microcontroller Unit (MCU). A working prototype has been built and tested. Index Terms — implicit HCI, haptic perception, wearable device, vibrator module, MCU, navigation device I...|$|R
40|$|Abstract. In {{this article}} we {{introduce}} the analysis of eye motion as a new input modality for activity recognition, context-awareness and mobile HCI applications. We describe a novel embedded eye tracker that, in contrast to common systems using video cameras, relies on Electrooculography (EOG). This self-contained wearable device consists of goggles with dry electrodes integrated into the frame and a small pocket-worn component with a DSP for real-time EOG signal processing. It can store data locally for long-term recordings or stream processed EOG signals to a remote device over Bluetooth. We show how challenges associated with wearability, eye motion analysis and signal artefacts caused by physical activity can be addressed with a com-bination of a special mechanical design, optimised algorithms for eye movement detection and adaptive signal processing. In two case studies, we demonstrate that EOG is a suitable measurement technique for the recognition of reading activity and eye-based human-computer <b>interaction.</b> Eventually, <b>wearable</b> EOG goggles may {{pave the way for}} seamless eye movement analysis in everyday environments and new forms of context-awareness not possible today...|$|R
40|$|Computing of {{the future}} will be {{affected}} by a number of fundamental technologies in development today, many of which are already on the way to becoming commercialized. In this series of lectures, we will discuss hardware and software development that will become mainstream in the timeframe of a few years and how they will shape or change the computing landscape - commercial and personal alike. Topics range from processor and memory aspects, programming models and the limits of artificial intelligence, up to end-user <b>interaction</b> with <b>wearables</b> or e-textiles. We discuss the impact of these technologies on the art of programming, the data centres {{of the future}} and daily life. On {{the second day of the}} Future Computing Technology series, we will talk about ubiquitous computing. From smart watches through mobile devices to virtual reality, computing devices surround us, and innovative new technologies are introduces every day. We will briefly explore how this propagation might continue, how computers can take over thinking and creativity from us, and whether the Internet of Things is closer to reality or rather a more distant wish...|$|R
40|$|In {{this article}} we {{introduce}} the analysis of eye motion as a new input modality for activity recognition, context-awareness and mobile HCI applications. We describe a novel embedded eye tracker that, in contrast to common systems using video cameras, relies on Electrooculography (EOG). This self-contained wearable device consists of goggles with dry electrodes integrated into the frame and a small pocket-worn component with a DSP for real-time EOG signal processing. It can store data locally for long-term recordings or stream processed EOG signals to a remote device over Bluetooth. We show how challenges associated with wearability, eye motion analysis and signal artefacts caused by physical activity can be addressed {{with a combination of}} a special mechanical design, optimised algorithms for eye movement detection and adaptive signal processing. In two case studies, we demonstrate that EOG is a suitable measurement technique for the recognition of reading activity and eye-based human-computer <b>interaction.</b> Eventually, <b>wearable</b> EOG goggles may pave the way for seamless eye movement analysis and new forms of context-awareness not possible today...|$|R
30|$|Wearable egocentric vision {{establishes}} {{the foundation for}} in-situ communication support for social interactions. This app implements an assistive tool for social interaction on Google Glass to support face-to-face communication. With carefully designed system functionality and user interfaces, the system is expected to facilitate the communication among acquaintances. This system serves as as a memory aid to remember, recall and log faces with identities, for people with cognitive decline or those who need to improve their social interaction skills. This system is also of interest to readers who want to exploit the system for interactions, {{as well as those}} who are interested in visual computing, face recognition, <b>interaction</b> design for <b>wearable</b> devices.|$|R
40|$|This paper {{presents}} {{the design process}} and technical development of Wo. Defy, an interactive kinetic garment that explores a suffragette cultural critique of the 'Self-Combing Sisters', {{a group of women}} in early twentieth century Chinese society who challenged and questioned the role of women's agency. Through elements of self-connection with hair and breath, Wo. Defy investigates intimacy with natural materials and technology that are close to one's skin, and provokes self-actuation through critique of social expectation within one's culture. We gathered feedback from participants at 5 exhibitions through open-ended interviews. Self-reported experience illustrated that <b>wearable</b> <b>interaction</b> can support self-reflection contextualized through cultural artifacts such as interactive clothing...|$|R
