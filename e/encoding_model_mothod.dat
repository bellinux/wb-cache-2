0|979|Public
40|$|Functional MRI (fMRI) {{has become}} the most common method for {{investigating}} the human brain. However, fMRI data present some complications for statistical analysis and modeling. One recently developed approach to these data focuses on estimation of computational <b>encoding</b> <b>models</b> that describe how stimuli are transformed into brain activity measured in individual voxels. Here we aim at building <b>encoding</b> <b>models</b> for fMRI signals recorded in primary visual cortex of the human brain. We use residual analyses to reveal systematic nonlinearity across voxels not taken into account by previous models. We then show how a sparse nonparametric method (Ravikumar et al., 2009 b) can be used together with correlation screening to estimate nonlinear <b>encoding</b> <b>models</b> effectively. Our approach produces <b>encoding</b> <b>models</b> that predict about 25 % more accurately than models estimated using other methods (Kay et al., 2008 a). The estimated nonlinearity impacts the inferred properties of individual voxels, and it has a plausible biological interpretation. One benefit of quantitative <b>encoding</b> <b>models</b> is that estimated models can be used to decode brain activity, in order to identify which specific image was seen by an observer. <b>Encoding</b> <b>models</b> estimated by our approach also improve such image identification by about 12 % when the correct image is one of 11, 500 possible images. 1. Introduction. On...|$|R
5000|$|The <b>encoded</b> <b>model</b> {{structure}} must {{reflect the}} (biological) process(es) detailed in the reference description.|$|R
40|$|A {{principal}} goal in sensory neuroscience is {{to understand}} how properties of our environment are reflected in neural activity patterns. Recent advances in computational modeling provide increasingly accurate predictions of how neural populations across the brain respond to complex naturalistic stimuli. The employed computational models, referred to as <b>encoding</b> <b>models,</b> explicitly transform complex stimuli into observed neural responses. This rapidly developing field is becoming increasingly important in sensory neuroscience as it provides detailed insights into the functional organization of neural representations. The present work starts by discussing the theoretical underpinnings of <b>encoding</b> <b>models.</b> Next, various applications of <b>encoding</b> <b>models</b> are reviewed. Finally, potential research directions that may shape future {{work in this area}} of research are described...|$|R
40|$|Deductive and {{inductive}} {{approaches to}} solving of pattern recognition problems are considered. Logical and precedent-related <b>encoding</b> <b>models</b> of prior information {{are used in}} these approaches correspondingly. Algebra of objects is built and its isomorphism to Boolean algebra is shown. Algorithms for mutual conversion of <b>encoding</b> <b>models</b> are developed. A modification of the resolution method for solution of pattern recognition problems is suggested. An algorithm combining the resolution method and a parametric family of recognition algorithms is developed...|$|R
50|$|More {{recent studies}} used voxels from early and {{anterior}} visual cortex areas forward of them (visual areas V3A, V3B, V4, and the lateral occipital) together with Bayesian inference techniques to reconstruct complex natural images. This brain reading approach uses three components: A structural <b>encoding</b> <b>model</b> that characterizes responses in early visual areas; a semantic <b>encoding</b> <b>model</b> that characterizes responses in anterior visual areas; and a Bayesian prior {{that describes the}} distribution of structural and semantic scene statistics.|$|R
40|$|The {{growing trend}} of online image sharing and {{downloads}} today mandate {{the need for}} better encoding and decoding scheme. This paper looks into this issue of image coding. Multiple Description Coding is an encoding and decoding scheme that is specially designed in providing more error resilience for data transmission. The main issue of Multiple Description Coding is the lossy transmission channels. This work attempts {{to address the issue}} of re-constructing high quality image with the use of just one descriptor rather than the conventional descriptor. This work compare the use of Type I quantizer and Type II quantizer. We propose and compare 4 coders by examining the quality of re-constructed images. The 4 coders are namely JPEG HH (Horizontal Pixel Interleaving with Huffman Coding) model, JPEG HA (Horizontal Pixel Interleaving with Arithmetic <b>Encoding)</b> <b>model,</b> JPEG VH (Vertical Pixel Interleaving with Huffman <b>Encoding)</b> <b>model,</b> and JPEG VA (Vertical Pixel Interleaving with Arithmetic <b>Encoding)</b> <b>model.</b> The findings suggest that the use of horizontal and vertical pixel interleavings do not affect the results much. Whereas the choice of quantizer greatly affect its performance...|$|R
40|$|Causal {{terminology}} {{is often}} {{introduced in the}} interpretation of <b>encoding</b> and decoding <b>models</b> trained on neuroimaging data. In this article, we investigate which causal statements are warranted and which ones are not supported by empirical evidence. We argue that the distinction between <b>encoding</b> and decoding <b>models</b> is not sufficient for this purpose: relevant features in <b>encoding</b> and decoding <b>models</b> carry a different meaning in stimulus- and in response-based experimental paradigms. We show that only <b>encoding</b> <b>models</b> in the stimulus-based setting support unambiguous causal interpretations. By combining <b>encoding</b> and decoding <b>models</b> trained on the same data, however, we obtain insights into causal relations beyond those that are implied by each individual model type. We illustrate the empirical relevance of our theoretical findings on EEG data recorded during a visuo-motor learning task. Comment: accepted manuscrip...|$|R
3000|$|... e 0, e 2 j}. In what follows, {{we split}} the stop codon into the three {{possibilities}} strictly observed {e 2 j_TAA,e 2 j_TAG,e 2 j_TGA}, {{for a total}} of 17 states in our forward <b>encoding</b> <b>model.</b>|$|R
40|$|While some first {{language}} (L 1) reading models suggest that inefficient word recognition and small working memory tend to inhibit higher-level comprehension processes; the Compensatory <b>Encoding</b> <b>Model</b> maintains that slow word recognition and small working memory do not normally hinder reading comprehension, as readers {{are able to}} operate metacognitive strategies to compensate for inefficient word recognition and working memory limitation as long as readers process a reading task without time constraint. Although empirical evidence is accumulated for support of the Compensatory <b>Encoding</b> <b>Model</b> in L 1 reading, there is lack of research for testing of the Compensatory <b>Encoding</b> <b>Model</b> in foreign language (FL) reading. This research empirically tested the Compensatory <b>Encoding</b> <b>Model</b> in English reading among Chinese college English language learners (ELLs). Two studies were conducted. Study one focused on testing whether reading condition varying time affects the relationship between word recognition, working memory, and reading comprehension. Students were tested on a computerized English word recognition test, a computerized Operation Span task, and reading comprehension in time constraint and non-time constraint reading. The correlation and regression analyses showed that the strength of association was much stronger between word recognition, working memory, and reading comprehension in time constraint than that in non-time constraint reading condition. Study two examined whether FL readers were able to operate metacognitive reading strategies as a compensatory way of reading comprehension for inefficient word recognition and working memory limitation in non-time constraint reading. The participants were tested on the same computerized English word recognition test and Operation Span test. They were required to think aloud while reading and to complete the comprehension questions. The think-aloud protocols were coded for concurrent use of reading strategies, classified into language-oriented strategies, content-oriented strategies, re-reading, pausing, and meta-comment. The correlation analyses showed that while word recognition and working memory were only significantly related to frequency of language-oriented strategies, re-reading, and pausing, but not with reading comprehension. Jointly viewed, {{the results of the}} two studies, complimenting each other, supported the applicability of the Compensatory <b>Encoding</b> <b>Model</b> in FL reading with Chinese college ELLs...|$|R
40|$|A celebrated result by Barak et al (JACM’ 12) {{shows the}} impos-sibility of {{general-purpose}} virtual black-box (VBB) obfuscation in the plain model. A recent work by Canetti, Kalai, and Paneth (TCC’ 15) extends this result {{also to the}} random oracle model (assuming trap-door permutations). In contrast, Brakerski-Rothblum (TCC’ 15) and Barak et al (Euro-Crypt’ 14) show that in idealized graded <b>encoding</b> <b>models,</b> general-purpose VBB obfuscation indeed is possible; these construction re-quire graded encoding schemes that enable evaluating high-degree (polynomial {{in the size of}} the circuit to be obfuscated) polynomials on encodings. We show a complementary impossibility of general-purpose VBB obfuscation in idealized graded <b>encoding</b> <b>models</b> that enable only evaluation of constant-degree polynomials (assuming trapdoor permu-tations) ...|$|R
30|$|In recent years, voxel-based <b>encoding</b> <b>models</b> were {{proposed}} and caught much attention (Kay et al. 2008). A typical <b>encoding</b> <b>model</b> {{can be divided}} into two parts. The first part tries to find a feature space to describe the external stimulus. The second part corresponds to the construction of regression models, which uses the stimulus features to predict corresponding brain activity. Lots of effort were taken to find ways to represent the stimulus images. Previous studies used Gabor wavelet pyramid model (Kay et al. 2008; Vu et al. 2011), two-layer sparse coding model (Güçlü and van Gerven 2014), and convolutional neural networks (Agrawal et al. 2014) to extract features that can represent natural images effectively. However, fewer studies focused on efficient regression model construction.|$|R
40|$|We {{propose a}} {{selective}} <b>encoding</b> <b>model</b> {{to extend the}} sequence-to-sequence framework for abstractive sentence summarization. It consists of a sentence encoder, a selective gate network, and an attention equipped decoder. The sentence encoder and decoder are built with recurrent neural networks. The selective gate network constructs a second level sentence representation by controlling the information flow from encoder to decoder. The second level representation is tailored for sentence summarization task, which leads to better performance. We evaluate our model on the English Gigaword, DUC 2004 and MSR abstractive sentence summarization datasets. The experimental {{results show that the}} proposed selective <b>encoding</b> <b>model</b> outperforms the state-of-the-art baseline models. Comment: 10 pages; To appear in ACL 201...|$|R
30|$|This IP {{accelerated}} {{system model}} includes the memory, algorithm, and architecture optimization techniques {{to enable the}} reduction and elimination of the overhead resulted from the heterogeneous video encoding tasks. The video <b>encoding</b> <b>model</b> provided in this architecture is compliant with H. 264 standard specifications.|$|R
30|$|To {{reduce the}} {{complexity}} of the problem, the small cell network is initially divided into a number of subnetworks equal to the number of PoPs, classified based on the criteria of LOS condition as well as the distance to the closest PoP. The decomposed network will then be applicable to the proposed small cell backhaul model. A meta-heuristic method called simulated annealing (SA) [35] together with a Dandelion tree <b>encoding</b> <b>model</b> is exploited to solve the constrained minimum Steiner tree problem [36]. The Dandelion code has been recently proposed and proved to be an effective tree <b>encoding</b> <b>model,</b> which is more efficient and offers higher locality, i.e., small changes in code results in small changes in the tree, than the most popular Pruumlfer code [37].|$|R
40|$|Purpose The {{purpose of}} this work was {{to improve the quality}} of single-shot spiral MRI and {{demonstrate}} its application for diffusion-weighted imaging. Methods Image formation is based on an expanded <b>encoding</b> <b>model</b> that accounts for dynamic magnetic fields up to third order in space, nonuniform static B 0, and coil sensitivity <b>encoding.</b> The <b>encoding</b> <b>model</b> is determined by B 0 mapping, sensitivity mapping, and concurrent field monitoring. Reconstruction is performed by iterative inversion of the expanded signal equations. Diffusion-tensor imaging with single-shot spiral readouts is performed in a phantom and in vivo, using a clinical 3 T instrument. Image quality is assessed in terms of artefact levels, image congruence, and the influence of the different encoding factors. Results Using the full <b>encoding</b> <b>model,</b> diffusion-weighted single-shot spiral imaging of high quality is accomplished both in vitro and in vivo. Accounting for actual field dynamics, including higher orders, is found to be critical to suppress blurring, aliasing, and distortion. Enhanced image congruence permitted data fusion and diffusion tensor analysis without coregistration. Conclusion Use of an expanded signal model largely overcomes the traditional vulnerability of spiral imaging with long readouts. It renders single-shot spirals competitive with echo-planar readouts and thus deploys shorter echo times and superior readout efficiency for diffusion imaging and further prospective applications...|$|R
30|$|The {{publicly}} available fMRI data (Kay et al. 2011) {{were used for}} model validation; this dataset is widely used in comparing models (Güçlü and van Gerven 2014; Naselaris et al. 2009; Agrawal et al. 2014), and detailed experiment information {{is available in the}} original papers (Kay et al. 2008; Naselaris et al. 2009). The fMRI responses were recorded when human subjects viewing grayscale natural images while fixating on a central white square. Two subjects took part in the experiments. They viewed 1750 training images (for <b>encoding</b> <b>model</b> training), each presented twice; and 120 validation images (for <b>encoding</b> <b>model</b> testing), each presented ten times. For each subject, the data were acquired in five scanner sessions on five different days. Each scan session consisted of five training runs, each lasted 11  min, and two validation runs, each lasted 12  min.|$|R
40|$|Bayesian neural {{decoding}} models aim at estimating an extrinsic stimulus, such as speech, from a neural popula-tion. They {{have been}} used to study several physiological systems such as the motor or auditory systems [1]. Such decoding models require the use of an <b>encoding</b> <b>model,</b> i. e. which aim at estimating the neural spikes from the stimulus [2]. One <b>encoding</b> <b>model</b> that has been used extensively in the past models the instantaneous spiking rate of a neuron using a generalized linear model (GLM). When applied to the auditory system, this GLM has three parameters that account respectively for 1) the spontaneous firing rate of the decoded neuron, 2) the spectro-temporal receptive field of the neuron and 3) the intrinsic dynamics of the neuron, such as refractory peri-ods, bursting and network dynamics [3]. In a decodin...|$|R
2500|$|SignWriting is {{the first}} writing system for sign {{languages}} {{to be included in}} the Unicode Standard. 672 characters were added in the Sutton SignWriting (Unicode block) of Unicode version 8.0 released in June 2015. [...] This set of characters is based on SignWriting's standardized symbol set and defined character <b>encoding</b> <b>model.</b>|$|R
40|$|It is {{well known}} that signals encoded by mechanoreceptors {{facilitate}} precise object manipulation in humans. It is therefore of interest to study signals encoded by the mechanoreceptors because this will contribute further towards the understanding of fundamental sensory mechanisms that are responsible for coordinating force components during object manipulation. From a practical point of view, this may suggest strategies for designing sensory-controlled biomedical devices and robotic manipulators. We use a two-stage nonlinear decoding paradigm to reconstruct the force stimulus given signals from slowly adapting type one (SA-I) tactile afferents. First, we describe a nonhomogeneous Poisson <b>encoding</b> <b>model</b> which {{is a function of the}} force stimulus and the force's rate of change. In the decoding phase, we use a recursive nonlinear Bayesian filter to reconstruct the force profile, given the SA-I spike patterns and parameters described by the <b>encoding</b> <b>model.</b> Under the current <b>encoding</b> <b>model,</b> the mode ratio of force to its derivative is: 1. 26 to 1. 02. This indicates that the force derivative contributes significantly to the rate of change to the SA-I afferent spike modulation. Furthermore, using recursive Bayesian decoding algorithms is advantageous because it can incorporate past and current information in order to make predictions [...] consistent with neural systems [...] with little computational resources. This makes it suitable for interfacing with prostheses...|$|R
40|$|Sensory {{processing}} is {{hard because}} {{the variables of}} interest are encoded in spike trains in a relatively complex way. A major goal in sensory processing is {{to understand how the}} brain extracts those variables. Here we revisit a common <b>encoding</b> <b>model</b> in which variables are encoded linearly. Although there are typically more variables than neurons, this problem is still solvable because {{only a small number of}} variables appear at any one time (sparse prior). However, previous solutions usually require all-to-all connectivity, inconsistent with the sparse connectivity seen in the brain. Here we propose a principled algorithm that provably reaches the MAP inference solution but using sparse connectivity. Our algorithm is inspired by the mouse olfactory bulb, but our approach is general enough to apply to other modalities; in addition, it should be possible to extend it to nonlinear <b>encoding</b> <b>models...</b>|$|R
40|$|In {{research}} on visual shape perception, various {{models have been}} designed for the encoding of visual patterns, in order to predict the human interpretation of such patterns. Each of these <b>encoding</b> <b>models</b> provides a few coding rules to obtain codes of a pattern, each code describing regularity and hierarchy in that pattern. Some of these models employ the minimum principle which states that the human interpretation of a pattern is reflected by the simplest code of that pattern. Despite empirical support, these <b>encoding</b> <b>models</b> suffer from three fundamental problems. First, although many coding rules can be proposed, no <b>encoding</b> <b>model</b> provides a psychological basis for those few coding rules that have been chosen (cf. Simon, 1972). Second, the minimum principle seems to require an unrealistic search for simplest pattern codes since, for any pattern, the number of possible codes is combinatorially explosive (cf. Hatfield & Epstein, 1985). Third, the quantification of simplicity is controversial and is suspected to depend too much on artifacts of the employed <b>encoding</b> <b>model</b> (cf. Hatfield & Epstein, 1985). The present study provides a coherent solution to these problems, based {{on the concept of}} accessibility. The concept of accessibility simply implies that regularity and hierarchy in the code of a pattern correspond directly to regularity and hierarchy in the pattern itself. This correspondence is specified by the notions of holographic regularity and transparent hierarchy. These two notions are based on a strictly formal analysis of regularity and hierarchy, and lead to just a few coding rules which, essentially, describe only three classes of regularities: Iterations, symmetries, and so-called alternations. Furthermore, the concept of accessibility enables an efficient and largely parallel encoding process, in which the simplest code of a pattern can be obtained without generating the explosive number of all possible codes (see also van der Helm & Leeuwenberg, 1986; van der Helm, 1988). Finally, the concept of accessibility gives rise to an improved and promising quantification of simplicity. status: publishe...|$|R
40|$|<b>Encoding</b> <b>models</b> {{are used}} for {{predicting}} brain activity in response to sensory stimuli {{with the objective of}} elucidating how sensory information is represented in the brain. <b>Encoding</b> <b>models</b> typically comprise a nonlinear transformation of stimuli to features (feature model) and a linear convolution of features to responses (response model). While there has been extensive work on developing better feature models, the work on developing better response models has been rather limited. Here, we investigate the extent to which recurrent neural network models can use their internal memories for nonlinear processing of arbitrary feature sequences to predict feature-evoked response sequences as measured by functional magnetic resonance imaging. We show that the proposed recurrent neural network models can significantly outperform established response models by accurately estimating long-term dependencies that drive haemodynamic responses. The results open a new window into modeling the dynamics of brain activity in response to sensory stimuli...|$|R
40|$|SummaryRecent {{studies have}} used fMRI signals from early visual areas to {{reconstruct}} simple geometric patterns. Here, we demonstrate a new Bayesian decoder that uses fMRI signals from early and anterior visual areas to reconstruct complex natural images. Our decoder combines three elements: a structural <b>encoding</b> <b>model</b> that characterizes responses in early visual areas, a semantic <b>encoding</b> <b>model</b> that characterizes responses in anterior visual areas, and prior {{information about the}} structure and semantic content of natural images. By combining all these elements, the decoder produces reconstructions that accurately reflect both the spatial structure and semantic category of the objects contained in the observed natural image. Our results show that prior information has a substantial effect {{on the quality of}} natural image reconstructions. We also demonstrate that much of the variance in the responses of anterior visual areas to complex natural images is explained by the semantic category of the image alone...|$|R
40|$|Recent {{studies have}} used fMRI signals from early visual areas to {{reconstruct}} simple geometric patterns. Here, we demonstrate a new Bayesian decoder that uses fMRI signals from early and anterior visual areas to reconstruct complex natural images. Our decoder combines three elements: a structural <b>encoding</b> <b>model</b> that characterizes responses in early visual areas, a semantic <b>encoding</b> <b>model</b> that characterizes responses in anterior visual areas, and prior {{information about the}} structure and semantic content of natural images. By combining all these elements, the decoder produces reconstructions that accurately reflect both the spatial structure and semantic category of the objects contained in the observed natural image. Our results show that prior information has a substantial effect {{on the quality of}} natural image reconstructions. We also demonstrate that much {{of the variance in the}} responses of anterior visual areas to complex natural images is explained by th...|$|R
40|$|Point process <b>encoding</b> <b>models</b> provide {{powerful}} {{statistical methods}} {{for understanding the}} responses of neurons to sensory stimuli. Although these models have been successfully applied to neurons in the early sensory pathway, they have fared less well capturing the response properties of neurons in deeper brain areas, owing {{in part to the}} fact that they do not take into account multiple stages of processing. Here we introduce a new twist on the point-process modeling approach: we include unobserved as well as observed spiking neurons in a joint <b>encoding</b> <b>model.</b> The resulting model exhibits richer dynamics and more highly nonlinear response properties, making it more powerful and more flexible for fitting neural data. More importantly, it allows us to estimate connectivity patterns among neurons (both observed and unobserved), and may provide insight into how networks process sensory input. We formulate the estimation procedure using variational EM and the wake-sleep algorithm, and illustrate the model’s performance using a simulated example network consisting of two coupled neurons. ...|$|R
40|$|Timbre, {{or sound}} quality, {{is a crucial}} but poorly {{understood}} dimension of auditory perception that is important in describing speech, music, and environmental sounds. The present study investigates the cortical representation of different timbral dimensions. <b>Encoding</b> <b>models</b> have typically incorporated the physical characteristics of sounds as features when attempting to understand their neural representation with functional MRI. Here we test an <b>encoding</b> <b>model</b> {{that is based on}} five subjectively derived dimensions of timbre to predict cortical responses to natural orchestral sounds. Results show that this timbre model can outperform other models based on spectral characteristics, and can perform as well as a complex joint spectrotemporal modulation model. In cortical regions at the medial border of Heschl's gyrus, bilaterally, and regions at its posterior adjacency in the right hemisphere, the timbre model outperforms even the complex joint spectrotemporal modulation model. These findings suggest that the responses of cortical neuronal populations in auditory cortex may reflect the encoding of perceptual timbre dimensions...|$|R
40|$|Reproducibility is {{imperative}} for any scientific discovery. More often than not, modern scientific findings rely on {{statistical analysis of}} high-dimensional data. At a minimum, reproducibility manifests itself in stability of statistical results relative to "reasonable" perturbations to data and to the model used. Jacknife, bootstrap, and cross-validation are based on perturbations to data, while robust statistics methods deal with perturbations to models. In this article, a case is made {{for the importance of}} stability in statistics. Firstly, we motivate the necessity of stability for interpretable and reliable <b>encoding</b> <b>models</b> from brain fMRI signals. Secondly, we find strong evidence in the literature to demonstrate the central role of stability in statistical inference, such as sensitivity analysis and effect detection. Thirdly, a smoothing parameter selector based on estimation stability (ES), ES-CV, is proposed for Lasso, in order to bring stability to bear on cross-validation (CV). ES-CV is then utilized in the <b>encoding</b> <b>models</b> {{to reduce the number of}} predictors by 60...|$|R
40|$|Recent {{studies in}} {{evolutionary}} computation {{have focused on}} using developmental processes together with genetic algorithms {{in order to achieve}} more complex designs. Although several models have been proposed, their growth dynamics, and their interactions with evolutionary algorithms are still poorly understood. One particularly neglected concept in artificial developmental systems is heterochrony — how evolution affects development by changing the timing and rate of developmental events. In this paper we attempt to address this issue by analyzing heterochronic changes in a well known artificial developmental model — the cellular <b>encoding</b> <b>model</b> — by using an heterochrony framework by Alberch et al. We have conducted experiments by evolving networks to solve a boolean problem, and analyzed heterochronic changes in both successful and unsuccessful runs. Our findings show that the cellular <b>encoding</b> <b>model,</b> due to its properties, strongly affects the developmental dynamics and the heterochronic changes that occur during evolution. Our experiments also show that hypermorphic changes (a kind of heterochronic occurrence) lead to greater evolvability in successful runs. 2...|$|R
40|$|Although the {{existence}} of correlated spiking between neurons in a population is well known, the role such correlations play in encoding stimuli is not. We address this question by constructing pattern-based <b>encoding</b> <b>models</b> that describe how time-varying stimulus drive modulates the expression probabilities of population-wide spike patterns. The challenge is that large populations may express an astronomical number of unique patterns, and so fitting a unique <b>encoding</b> <b>model</b> for each individual pattern is not feasible. We avoid this combinatorial problem using a dimensionality-reduction approach based on regression trees. Using the insight that some patterns may, {{from the perspective of}} encoding, be statistically indistinguishable, the tree divisively clusters the observed patterns into groups whose member patterns possess similar encoding properties. These groups, corresponding to the leaves of the tree, are much smaller in number than the original patterns, and the tree itself constitutes a tractable <b>encoding</b> <b>model</b> for each pattern. Our formalism can detect an extremely weak stimulus-driven pattern structure and is based on maximizing the data likelihood, not making a priori assumptions as to how patterns should be grouped. Most important, by comparing pattern encodings with independent neuron encodings, one can determine if neurons in the population are driven independently or collectively. We demonstrate this method using multiple unit recordings from area 17 of anesthetized cat in response to a sinusoidal grating and show that pattern-based encodings are superior to those of independent neuron models. The agnostic nature of our clustering approach allows us to investigate encoding by the collective statistics that are actually present rather than those (such as pairwise) that might be presumed. National Institutes of Health (U. S.) (Grant K 25 NS 052422 - 02...|$|R
40|$|The {{first edition}} of this {{technical}} note {{addressed the issue of}} how Myanmar text was encoded using the Unicode standard as it stood until version 5. 1. With Unicode 5. 1 various new characters were added to the Myanmar block which had the effect of simplifying the <b>encoding</b> <b>model</b> considerably. Such a change could only come about with agreement from all implementors and those with existing data because they will nee...|$|R
40|$|The major {{system is}} a {{mnemonic}} system {{that can be used}} to memorize sequences of numbers. In this work, we present a method to automatically generate sentences that encode a given number. We propose several <b>encoding</b> <b>models</b> and compare the most promising ones in a password memorability study. The results of the study show that a model combining part-of-speech sentence templates with an $n$-gram language model produces the most memorable password representations...|$|R
5000|$|A {{character}} set contains the characters necessary {{to allow a}} particular human {{to carry on a}} meaningful interaction with the computer. It does not specify how those characters are represented in a computer. [...] This level is the first one to separate characters into various alphabets (Latin, Arabic, Hebrew, Cyrillic, and so on) or ideographic groups (Chinese, Korean, and so on). It corresponds to a [...] "character repertoire" [...] in the Unicode <b>encoding</b> <b>model.</b>|$|R
40|$|Neural {{prosthetic}} {{technology has}} moved from the laboratory to clinical settings with human trials. The motor cortical control of devices in such settings raises important questions about the design of computational interfaces that produce stable and reliable control {{over a wide range}} of operating conditions. In particular, non-stationarity of the neural code across different behavioral conditions or attentional states becomes a potential issue. Non-stationarity has been previously observed in animals where the <b>encoding</b> <b>model</b> representing the mathematical relationship between neural population activity and behavioral variables such as hand motion changes over time. If such an <b>encoding</b> <b>model</b> is formed and learned during a particular training period, decoding performance (neural control) with the model may not be consistent during successive periods even when the same task is repeated. It is critical in both laboratory experiments and in clinical settings to be able to evaluate whether the representation of movement encoded by a neural population has changed or not. Such information {{can be used as a}} cue to retrain the system or as feedback to an adaptive decoding algorithm. To that end, we develop a statistical methodology to evaluate changes in the neural code over time using a generative probabilistic decoding model. The changes are evaluated by comparing the likelihoods of firing rates given similar distributions of 2 D hand kinematics collected while a primate periodically performs a manual cursor control task. A comparison is performed by measuring a distance between probabilistic <b>encoding</b> <b>models</b> trained at different times. The statistical significance of the distance measurements are justified with a systematic statistical hypothesis test. The experimental results demonstrate that the likelihood changes over different periods with the change being greater when more distant periods are compared...|$|R
40|$|Perception {{of natural}} visual scenes {{activates}} several functional {{areas in the}} human brain, including the Parahippocampal Place Area (PPA), Retrosplenial Complex (RSC), and the Occipital Place Area (OPA). It is currently unclear what specific scene-related features are represented in these areas. Previous {{studies have suggested that}} PPA, RSC, and/or OPA might represent at least three qualitatively different classes of features: (1) 2 D features related to Fourier power; (2) 3 D spatial features such as the distance to objects in a scene; or (3) abstract features such as the categories of objects in a scene. To determine which of these hypotheses best describes the visual representation in scene-selective areas, we applied voxel-wise modeling (VM) to BOLD fMRI responses elicited by a set of 1, 386 images of natural scenes. VM provides an efficient method for testing competing hypotheses by comparing predictions of brain activity based on <b>encoding</b> <b>models</b> that instantiate each hypothesis. Here we evaluated three different <b>encoding</b> <b>models</b> that instantiate each of the three hypotheses listed above. We used linear regression to fit each <b>encoding</b> <b>model</b> to the fMRI data recorded from each voxel, and we evaluated each fit model by estimating the amount of variance it predicted in a withheld portion of the data set. We found that voxel-wise models based on Fourier power or the subjective distance to objects in each scene predicted much of the variance predicted by a model based on object categories. Furthermore, the response variance explained by these three models is largely shared, and the individual models explain little unique variance in responses. Based on an evaluation of previous studies and the data we present here, we conclude that there is currently no good basis to favor any one of the three alternative hypotheses about visual representation in scene-selective areas. We offer suggestions for further studies that may help resolve this issue...|$|R
40|$|This {{document}} is {{a revision of}} “Preliminary Proposal to Encode the Soyombo Script in ISO/IEC 10646 ” (N 3949 L 2 / 10 - 399). The major change is the <b>encoding</b> <b>model</b> for vowels. Vowel letters are now to be written using a vowel-carrier letter {{and a set of}} combining signs (see N 3986 L 2 / 11 - 054). Additional changes include minor revisions to character names and properties. Some issues identified during additional researc...|$|R
40|$|The celebrated work of Barak et al. (Crypto’ 01) {{ruled out}} the {{possibility}} of virtual black-box (VBB) obfuscation for general circuits. The recent work of Canetti, Kalai, and Paneth (TCC’ 15) extended this impossibility to the random oracle model as well assuming the existence of trapdoor permutations (TDPs). On the other hand, the works of Barak et al. (Crypto’ 14) and Brakerski-Rothblum (TCC’ 14) showed that general VBB obfuscation is indeed possible in idealized graded <b>encoding</b> <b>models.</b> The recent work of Pass and Shelat (Cryptology ePrint 2015 / 383) complemented this result by ruling out general VBB obfuscation in idealized graded <b>encoding</b> <b>models</b> that enable evaluation of constant-degree polynomials in finite fields. In this work extend the above two impossibly results for general VBB obfuscation in idealized models. In particular we prove the following two results both assuming the existence of TDPs: • There is no general VBB obfuscation in the generic group model of Shoup (Eurocrypt’ 97) for any abelian group. By applying our techniques to the setting of Pass and Shelat we extend their result to any (even non-commutative) finite ring. • There is no general VBB obfuscation even in the random trapdoor permutation oracl...|$|R
