2319|10000|Public
25|$|Pearson's chi-squared test. A <b>hypothesis</b> <b>test</b> using normal {{approximation}} for discrete data.|$|E
25|$|The {{successful}} <b>hypothesis</b> <b>test</b> {{is associated}} with a probability and a type-I error rate. The conclusion might be wrong.|$|E
25|$|The t-test is any {{statistical}} <b>hypothesis</b> <b>test</b> {{in which}} the test statistic follows a Student's t-distribution under the null hypothesis.|$|E
40|$|Most {{statistical}} methods use <b>hypothesis</b> <b>testing.</b> Analysis of variance, regression, discrete choice models, contingency tables, and other analysis methods {{commonly used in}} transportation research share <b>hypothesis</b> <b>testing</b> as the means of making inferences about the population of interest. Despite the fact that <b>hypothesis</b> <b>testing</b> has been a cornerstone of empirical research for many years, various aspects of <b>hypothesis</b> <b>tests</b> commonly are incorrectly applied, misinterpreted, and ignoredâ€”by novices and expert researchers alike. On initial glance, <b>hypothesis</b> <b>testing</b> appears straightforward: develop the null and alternative <b>hypotheses,</b> compute the <b>test</b> statistic to compare to a standard distribution, estimate the probability of rejecting the null hypothesis, and then make claims {{about the importance of}} the finding. This is an oversimplification of the process of <b>hypothesis</b> <b>testing.</b> <b>Hypothesis</b> <b>testing</b> as applied in empirical research is examined here. The reader is assumed to have a basic knowledge of the role of <b>hypothesis</b> <b>testing</b> in various {{statistical methods}}. Through the us...|$|R
40|$|This paper {{considers}} sequential <b>hypothesis</b> <b>testing</b> in a decentralized framework. We {{start with}} two simple decentralized sequential <b>hypothesis</b> <b>testing</b> algorithms. One {{of which is}} later proved to be asymptotically Bayes optimal. We also consider composite versions of decentralized sequential <b>hypothesis</b> <b>testing.</b> A novel nonparametric version for decentralized sequential <b>hypothesis</b> <b>testing</b> using universal source coding theory is developed. Finally we design a simple decentralized multihypothesis sequential detection algorithm...|$|R
40|$|We {{show how}} to <b>test</b> <b>hypotheses</b> for {{coefficient}} alpha {{in three different}} situations: <b>Hypothesis</b> <b>tests</b> of whether coefficient alpha equals a prespecified value, <b>Hypothesis</b> <b>tests</b> involving two statistically independent sample alphas as may arise when testing the equality of coefficient alpha across groups, <b>Hypothesis</b> <b>tests</b> involving two statistically dependent sample alphas as may arise when testing the equality of alpha across time, or when testing the equality of alpha for two test scores within the same sample. Coefficient alpha, <b>Hypothesis</b> <b>testing,</b> Structural equation modeling...|$|R
25|$|Statistical {{significance}} test : A predecessor to the statistical <b>hypothesis</b> <b>test</b> (see the Origins section). An experimental result {{was said to}} be statistically significant if a sample was sufficiently inconsistent with the (null) hypothesis. This was variously considered common sense, a pragmatic heuristic for identifying meaningful experimental results, a convention establishing a threshold of statistical evidence or a method for drawing conclusions from data. The statistical <b>hypothesis</b> <b>test</b> added mathematical rigor and philosophical consistency to the concept by making the alternative hypothesis explicit. The term is loosely used to describe the modern version which is now part of statistical hypothesis testing.|$|E
25|$|A {{criminal}} trial {{can be regarded}} as either or both of two decision processes: guilty vs not guilty or evidence vs a threshold ("beyond a reasonable doubt"). In one view, the defendant is judged; in the other view the performance of the prosecution (which bears the burden of proof) is judged. A <b>hypothesis</b> <b>test</b> {{can be regarded as}} either a judgment of a hypothesis or as a judgment of evidence.|$|E
25|$|As {{a general}} example, if a null {{hypothesis}} {{is assumed to}} follow the standard normal distribution N(0,1), then the rejection of this null hypothesis can either mean (i) the mean is not zero, or (ii) the variance is not unity, or (iii) the distribution is not normal, {{depending on the type}} of test performed. However, supposing we manage to reject the zero mean hypothesis, even if we know the distribution is normal and variance is unity, the null <b>hypothesis</b> <b>test</b> does not tell us which non-zero value we should adopt as the new mean.|$|E
30|$|Considering {{that the}} {{pioneering}} work of DR comes {{earlier than the}} formalization of <b>hypothesis</b> <b>testing</b> by NP, {{the question is why}} acceptance sampling should integrate <b>hypothesis</b> <b>testing</b> at all. We will show that <b>hypothesis</b> <b>testing</b> can offer a common structure that generalizes and clarifies some issues in the application of acceptance sampling.|$|R
40|$|This paper {{examines}} {{three distinct}} <b>hypothesis</b> <b>testing</b> problems {{that arise in}} the context of identification of some nonparametric models with endogeneity. The first <b>hypothesis</b> <b>testing</b> problem we study concerns testing necessary conditions for identification in some nonparametric models with endogeneity involving mean independence restrictions. These conditions are typically referred to as completeness conditions. The second and third <b>hypothesis</b> <b>testing</b> problems we examine concern testing for identification directly in some nonparametric models with endogeneity involving quantile independence restrictions. For each of these <b>hypothesis</b> <b>testing</b> problems, we provide conditions under which any test will have power no greater than size against any alternative. In this sense, we conclude that no nontrivial <b>tests</b> for these <b>hypothesis</b> <b>testing</b> problems exist...|$|R
25|$|Fisher {{thought that}} <b>hypothesis</b> <b>testing</b> was a useful {{strategy}} for performing industrial quality control, however, he strongly disagreed that <b>hypothesis</b> <b>testing</b> {{could be useful}} for scientists.|$|R
25|$|Significance {{testing has}} been the favored {{statistical}} tool in some experimental social sciences (over 90% of articles in the Journal of Applied Psychology during the early 1990s). Other fields have favored the estimation of parameters (e.g., effect size). Significance testing {{is used as a}} substitute for the traditional comparison of predicted value and experimental result {{at the core of the}} scientific method. When theory is only capable of predicting the sign of a relationship, a directional (one-sided) <b>hypothesis</b> <b>test</b> can be configured so that only a statistically significant result supports theory. This form of theory appraisal is the most heavily criticized application of hypothesis testing.|$|E
2500|$|Those making {{critical}} {{decisions based}} on the results of a <b>hypothesis</b> <b>test</b> are prudent to look at the details rather than the conclusion alone. In the physical sciences most results are fully accepted only when independently confirmed. The general advice concerning statistics is, [...] "Figures never lie, but liars figure" [...] (anonymous).|$|E
2500|$|A {{statistical}} <b>hypothesis</b> <b>test</b> compares a {{test statistic}} (z or t for examples) to a threshold. The test statistic (the formula {{found in the}} table below) is based on optimality. For a fixed level of Type I error rate, use of these statistics minimizes Type II error rates (equivalent to maximizing power). The following terms describe tests in terms of such optimality: ...|$|E
40|$|A new {{framework}} for fault diagnosis, called structured <b>hypothesis</b> <b>tests,</b> is proposed. The basic {{idea is to}} construct the diagnosis system by combining a set of <b>hypothesis</b> <b>tests.</b> In this way, the task of diagnosis is transferred {{to the task of}} validating a set of di#erent models with respect to the measured data. Arbitrary types of faults, including multiple faults, can be handled. That means that one single diagnosis system can diagnose faults of many di#erent types. When using structured <b>hypothesis</b> <b>tests,</b> existing diagnosis methods such as residual generation, parameter estimation, and statistical methods, become parts of one common framework. Keywords: Fault Diagnosis, Isolation, <b>Hypothesis</b> <b>Testing,</b> Decoupling 1. INTRODUCTION In this paper, a new {{framework for}} fault diagnosis is proposed: structured <b>hypothesis</b> <b>tests.</b> The basic idea is to construct the diagnosis system by combining a set of <b>hypothesis</b> <b>tests.</b> The isolation strategy becomes simple and a great advantage is th [...] ...|$|R
40|$|Abstract <b>Hypothesis</b> <b>testing</b> is the {{standard}} approach used in scientific work, {{but it is the}} wrong methodology to use in choosing which theory most accurately de-scribes the data. This is because <b>hypothesis</b> <b>testing</b> is asymmetric and does not spec-ify the alternative hypothesis in sufficient detail. A more appropriate methodology is to engage in model choice where the contending theories are treated symmetri-cally. This chapter first explains the problems with <b>hypothesis</b> <b>testing,</b> then provides the methodology of theory choice, and finally provides examples where <b>hypothesis</b> <b>testing</b> leads to inappropriate conclusions...|$|R
50|$|Statistics later {{developed}} {{in different directions}} including decision theory (and possibly game theory), Bayesian statistics, exploratory data analysis, robust statistics and nonparametric statistics. Neyman-Pearson <b>hypothesis</b> <b>testing</b> contributed strongly to decision theory which is very heavily used (in statistical quality control for example). <b>Hypothesis</b> <b>testing</b> readily generalized to accept prior probabilities which gave it a Bayesian flavor. Neyman-Pearson <b>hypothesis</b> <b>testing</b> has become an abstract mathematical subject taught in post-graduate statistics, while most of what is taught to under-graduates and used {{under the banner of}} <b>hypothesis</b> <b>testing</b> is from Fisher.|$|R
2500|$|The {{beans in}} the bag are the population. The handful are the sample. The null {{hypothesis}} is that the sample originated from the population. The criterion for rejecting the null-hypothesis is the [...] "obvious" [...] difference in appearance (an informal difference in the mean). The interesting result is that consideration of a real population and a real sample produced an imaginary bag. The philosopher was considering logic rather than probability. To be a real statistical <b>hypothesis</b> <b>test,</b> this example requires the formalities of a probability calculation and a comparison of that probability to a standard.|$|E
2500|$|The {{t-statistic}} and p-value columns {{are testing}} {{whether any of}} the coefficients might be equal to zero. The t-statistic is calculated simply as [...] If the errors Îµ follow a normal distribution, t follows a Student-t distribution. [...] Under weaker conditions, t is asymptotically normal. Large values of t indicate that the null hypothesis can be rejected and that the corresponding coefficient is not zero. The second column, p-value, expresses {{the results of the}} <b>hypothesis</b> <b>test</b> as a significance level. [...] Conventionally, p-values smaller than 0.05 are taken as evidence that the population coefficient is nonzero.|$|E
2500|$|This approximation, {{known as}} de Moivreâ€“Laplace theorem, {{is a huge}} time-saver when {{undertaking}} calculations by hand (exact calculations with large n are very onerous); historically, {{it was the first}} use of the normal distribution, introduced in Abraham de Moivre's book The Doctrine of Chances in 1738. Nowadays, it {{can be seen as a}} consequence of the central limit theorem since B(n,nbsp&p) is a sum of n independent, identically distributed Bernoulli variables with parameternbsp&p. This fact is the basis of a <b>hypothesis</b> <b>test,</b> a [...] "proportion z-test", for the value of p using x/n, the sample proportion and estimator of p, in a common test statistic.|$|E
40|$|Abstract â€” Regularized Maximum Mean Discrepancy (RMMD), our novel {{measure for}} kernel-based <b>hypothesis</b> <b>testing,</b> excels at <b>hypothesis</b> <b>tests</b> {{involving}} multiple comparisons with power control even when sample sizes are small. We derive asymptotic distributions under the null and alternative hypotheses, and assess power control. Outstanding results are obtained on challenging benchmark datasets. Keywords- kernel-based <b>hypothesis</b> <b>testing,</b> Homogeneity testing, Multiple comparisons, Power I...|$|R
25|$|The {{terminology}} is inconsistent. <b>Hypothesis</b> <b>testing</b> {{can mean}} any mixture of two formulations that both changed with time. Any discussion of significance <b>testing</b> vs <b>hypothesis</b> <b>testing</b> is doubly vulnerable to confusion.|$|R
2500|$|<b>Hypothesis</b> <b>testing</b> and {{philosophy}} intersect. Inferential statistics, which includes <b>hypothesis</b> <b>testing,</b> is applied probability. Both probability and its application are intertwined with philosophy. Philosopher David Hume wrote, [...] "All knowledge degenerates into probability." [...] Competing practical definitions of probability reflect philosophical differences. The most common application of <b>hypothesis</b> <b>testing</b> {{is in the}} scientific interpretation of experimental data, which is naturally studied by the philosophy of science.|$|R
2500|$|A {{statistical}} hypothesis, {{sometimes called}} confirmatory data analysis, is a hypothesis that is testable {{on the basis}} of observing a process that is modeled via a set of random variables. [...] A statistical <b>hypothesis</b> <b>test</b> is a method of statistical inference. Commonly, two statistical data sets are compared, or a data set obtained by sampling is compared against a synthetic data set from an idealized model. A hypothesis is proposed for the statistical relationship between the two data sets, and this is compared as an alternative to an idealized null hypothesis that proposes no relationship between two data sets. The comparison is deemed statistically significant if the relationship between the data sets would be an unlikely realization of the null hypothesis according to a threshold probabilitythe significance level. Hypothesis tests are used in determining what outcomes of a study would lead to a rejection of the null hypothesis for a pre-specified level of significance. The process of distinguishing between the null hypothesis and the alternative hypothesis is aided by identifying two conceptual types of errors (type 1 & type 2), and by specifying parametric limits on e.g. how much type 1 error will be permitted.|$|E
50|$|Pearson's chi-squared test. A <b>hypothesis</b> <b>test</b> using normal {{approximation}} for discrete data.|$|E
5000|$|<b>Hypothesis</b> <b>test</b> for {{population}} mean, for standard deviation, for skewness and for excess kurtosis.|$|E
30|$|The main {{objective}} {{of this paper is}} to discuss the relationship between acceptance sampling and formal <b>hypothesis</b> <b>tests</b> as developed by NP. Considering that the pioneering work of Dodge and Romig (DR) (1929) in acceptance sampling, which has survived decades of academic debate and practice, arrived before the formalization of <b>hypothesis</b> <b>testing</b> by NP, the question is why bring <b>hypothesis</b> <b>testing</b> into the discussion at all. Throughout the rest of this paper, we will attempt to show that, if used appropriately, <b>hypothesis</b> <b>testing</b> offers a more logically complete structure to decision-making and therefore to better decisions.|$|R
40|$|The maximum type-I and type-II error exponents {{associated}} with the newly introduced almost-fixed-length <b>hypothesis</b> <b>testing</b> is characterized. In this class of tests, the decision-maker declares the true hypothesis almost always after collecting a fixed number of samples $n$; however in very rare cases with exponentially small probability the decision maker is allowed to collect another set of samples (no more than polynomial in $n$). This class of <b>hypothesis</b> <b>tests</b> are shown {{to bridge the gap}} between the classical <b>hypothesis</b> <b>testing</b> with a fixed sample size and the sequential <b>hypothesis</b> <b>testing,</b> and improve the trade-off between type-I and type-II error exponents...|$|R
40|$|This {{purpose of}} this project {{was to create a}} set of {{reference}} material for an introductory level statistics course. The focus was on the Neyman-Pearson approach to <b>hypothesis</b> <b>testing.</b> A brief historical development of the Neyman-Pearson approach is followed by mathematical proofs of each of the <b>hypothesis</b> <b>tests</b> covered in the reference material. The reference material includes the basic <b>hypothesis</b> <b>tests</b> taught in an introductory statistics course, the accompanying distributions, and prerequisite information...|$|R
5000|$|... where [...] is the regularized {{incomplete}} beta function.We {{can thus}} perform the <b>hypothesis</b> <b>test</b> ...|$|E
5000|$|... {{the degrees}} of freedom in a non-pooled {{statistical}} <b>hypothesis</b> <b>test</b> of two population means ...|$|E
5000|$|There are {{two methods}} of {{concluding}} the ANOVA <b>hypothesis</b> <b>test,</b> {{both of which}} produce the same result: ...|$|E
40|$|Sequential Analysis: <b>Hypothesis</b> <b>Testing</b> and Changepoint Detection {{systematically}} {{develops the}} theory of sequential <b>hypothesis</b> <b>testing</b> and quickest changepoint detection. It also describes important applications in which theoretical results can be used efficiently. The book reviews recent accomplishments in <b>hypothesis</b> <b>testing</b> and changepoint detection both in decision-theoretic (Bayesian) and non-decision-theoretic (non-Bayesian) contexts. The authors not only emphasize traditional binary hypotheses but also substantially more difficult multiple decision problems. They address scenarios with s...|$|R
25|$|Statistics is {{increasingly}} {{being taught in}} schools with <b>hypothesis</b> <b>testing</b> {{being one of the}} elements taught. Many conclusions reported in the popular press (political opinion polls to medical studies) are based on statistics. An informed public should understand the limitations of statistical conclusions and many college fields of study require a course in statistics for the same reason. An introductory college statistics class places much emphasis on <b>hypothesis</b> <b>testing</b> â€“ perhaps half of the course. Such fields as literature and divinity now include findings based on statistical analysis (see the Bible Analyzer). An introductory statistics class teaches <b>hypothesis</b> <b>testing</b> as a cookbook process. <b>Hypothesis</b> <b>testing</b> is also taught at the postgraduate level. Statisticians learn how to create good statistical test procedures (like z, Student's t, F and chi-squared). Statistical <b>hypothesis</b> <b>testing</b> is considered a mature area within statistics, but a limited amount of development continues.|$|R
40|$|Despite their wide use in {{scientific}} journals such as The Journal of Wildlife Management, statistical <b>hypothesis</b> <b>tests</b> add very little {{value to the}} products of research. Indeed, they frequently confuse the interpretation of data. This paper describes how statistical <b>hypothesis</b> <b>tests</b> are often viewed, and then contrasts that interpretation with the correct one. I discuss the arbitrariness of P-values, conclusions that the null hypothesis is true, power analysis, and distinctions between statistical and biological significance. Statistical <b>hypothesis</b> <b>testing,</b> in which the null hypothesis about the properties of a population is almost always known a priori to be false, is contrasted with scientific <b>hypothesis</b> <b>testing,</b> which examines a credible null hypothesis about phenomena in nature. More meaningful alternatives are briefly outlined, including estimation and confidence intervals for determining the importance of factors, decision theory for guiding actions {{in the face of}} uncertainty, and Bayesian approaches to <b>hypothesis</b> <b>testing</b> and other statistical practices...|$|R
