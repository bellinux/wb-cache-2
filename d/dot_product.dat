1238|285|Public
25|$|In other words, the <b>dot</b> <b>product</b> of {{transformed}} {{image and}} a template {{is equal to}} the <b>dot</b> <b>product</b> of original image and inversely transformed template. For instance, for image rotated by 90 degrees, the inversely transformed template would be rotated by -90 degrees.|$|E
25|$|The {{exterior}} {{product and}} <b>dot</b> <b>product</b> {{can be combined}} (through summation) to form the geometric product.|$|E
25|$|In the {{geometrical}} {{and physical}} settings, {{sometimes it is}} possible to associate, in a natural way, a length or magnitude and a direction to vectors. In addition, the notion of direction is strictly associated with the notion of an angle between two vectors. If the <b>dot</b> <b>product</b> of two vectors is defined — a scalar-valued product of two vectors —, then it's also possible to define a length; the <b>dot</b> <b>product</b> gives a convenient algebraic characterization of both angle (a function of the <b>dot</b> <b>product</b> between any two non-zero vectors) and length (the square root of the <b>dot</b> <b>product</b> of a vector by itself). In three dimensions, it is further possible to define the cross product, which supplies an algebraic characterization of the area and orientation in space of the parallelogram defined by two vectors (used as sides of the parallelogram). In any dimension (and, in particular, higher dimensions), it's possible to define the exterior product, which (among other things) supplies an algebraic characterization of the area and orientation in space of the n-dimensional parallelotope defined by n vectors.|$|E
5000|$|For a {{point in}} a {{two-dimensional}} grid, this will require the computation of 4 distance vectors and <b>dot</b> <b>products,</b> while in three dimensions 8 distance vectors and 8 <b>dot</b> <b>products</b> are needed. This leads to the [...] complexity scaling.|$|R
30|$|Choose or {{construct}} a proper kernel function {{to replace the}} <b>dot</b> <b>products.</b>|$|R
5000|$|... {{as well as}} scalar <b>dot</b> <b>products</b> and vector norms, {{among other}} things.|$|R
25|$|FBA formalizes {{the system}} of {{equations}} describing the concentration changes in a metabolic network as the <b>dot</b> <b>product</b> of a matrix of the stoichiometric coefficients (the stoichiometric matrix S) and the vector v of the unsolved fluxes. The right-hand side of the <b>dot</b> <b>product</b> is a vector of zeros representing the system at steady state. Linear programming is then used to calculate a solution of fluxes corresponding to the steady state.|$|E
25|$|The outer product {{contrasts}} with the <b>dot</b> <b>product,</b> which takes as input a pair of coordinate vectors and produces a scalar.|$|E
25|$|Likewise, the {{contravariant}} {{components of}} v {{can be obtained}} from the <b>dot</b> <b>product</b> of v with convariant basis vectors, viz.|$|E
2500|$|... {{the rows}} and columns are {{orthogonal}} unit vectors, therefore their <b>dot</b> <b>products</b> are zero.|$|R
25|$|The product rule {{extends to}} scalar multiplication, <b>dot</b> <b>{{products}},</b> and cross products of vector functions.|$|R
2500|$|The area of {{triangle}} ABC {{can also}} be {{expressed in terms of}} <b>dot</b> <b>products</b> as follows: ...|$|R
25|$|Since {{the notions}} of vector length and angle between vectors can be {{generalized}} to any n-dimensional inner product space, this is also true for {{the notions of}} orthogonal projection of a vector, projection of a vector onto another, and rejection of a vector from another. In some cases, the inner product coincides with the <b>dot</b> <b>product.</b> Whenever they don't coincide, the inner product is used instead of the <b>dot</b> <b>product</b> in the formal definitions of projection and rejection.|$|E
25|$|Because the {{magnitude}} of the cross product goes by the sine of the angle between its arguments, the cross product {{can be thought of as}} a measure of perpendicularity in the same way that the <b>dot</b> <b>product</b> is a measure of parallelism. Given two unit vectors, their cross product has a magnitude of 1 if the two are perpendicular and a magnitude of zero if the two are parallel. The <b>dot</b> <b>product</b> of two unit vectors behaves just oppositely: it is zero when the unit vectors are perpendicular and 1 if the unit vectors are parallel.|$|E
25|$|Note {{that the}} order is {{important}} because between a bivector and a vector the <b>dot</b> <b>product</b> is anti-symmetric. Upon a space time split like one can obtain the velocity, and fields as above yielding the usual expression.|$|E
5000|$|However, {{the rules}} for <b>dot</b> <b>products</b> do not {{turn out to be}} simple, as {{illustrated}} by: ...|$|R
5000|$|The area of {{triangle}} ABC {{can also}} be {{expressed in terms of}} <b>dot</b> <b>products</b> as follows: ...|$|R
5000|$|Two {{instructions}} that perform multiply and add operations and {{speed up the}} evaluation of <b>dot</b> <b>products.</b>|$|R
25|$|In 2-D or higher-dimensional Euclidean space, two vectors are {{orthogonal}} if {{and only}} if their <b>dot</b> <b>product</b> is zero, i.e. they make an angle of 90°, or π/2 radians. Hence orthogonality of vectors is an extension of the concept of perpendicular vectors into higher-dimensional spaces.|$|E
25|$|Unit vectors enable two {{convenient}} identities: the <b>dot</b> <b>product</b> of two unit vectors {{yields the}} cosine (which may be positive or negative) of the angle {{between the two}} unit vectors. The magnitude of the cross product of the two unit vectors yields the sine (which will always be positive).|$|E
25|$|In matrix multiplication, {{there is}} a {{distinction}} between the cross and the dot symbols. The cross symbol generally denotes the taking a cross product of two vectors, yielding a vector as the result, while the dot denotes taking the <b>dot</b> <b>product</b> of two vectors, resulting in a scalar.|$|E
5000|$|Where [...] and [...] agree, [...] {{so those}} terms affect the <b>dot</b> <b>products</b> equally. We can safely ignore those terms and look only at where [...] and [...] differ. Furthermore, we can swap the bits [...] and [...] without {{changing}} {{whether or not}} the <b>dot</b> <b>products</b> are equal. This means we can swap bits so that [...] contains only zeros and [...] contains only ones: ...|$|R
3000|$|... <b>dot</b> <b>products,</b> as {{indicated}} in Algorithm 2. From an architectural point of view, each processor receives successively the [...]...|$|R
5000|$|LDA can be reformulated {{in terms}} of <b>dot</b> <b>products</b> by first noting that [...] will have an {{expansion}} ofthe form ...|$|R
25|$|Another line of {{generalization}} is {{to consider}} other number fields than one of real numbers. Over complex numbers, a Hilbert space {{can be seen as}} a generalization of Euclidean <b>dot</b> <b>product</b> structure, although the definition of the inner product becomes a sesquilinear form for compatibility with metric structure.|$|E
25|$|This {{distance}} function (which makes a metric space) {{is sufficient}} to define all Euclidean geometry, including the <b>dot</b> <b>product.</b> Thus, a real coordinate space together with this Euclidean structure is called Euclidean space. Its vectors form an inner product space (in fact a Hilbert space), and a normed vector space.|$|E
25|$|This {{equation}} {{states that}} the kinetic energy (Ek) {{is equal to the}} integral of the <b>dot</b> <b>product</b> of the velocity (v) of a body and the infinitesimal change of the body's momentum (p). It is assumed that the body starts with no kinetic energy when it is at rest (motionless).|$|E
5000|$|A weight {{order with}} weight vector (1,2,4): [...] (the <b>dot</b> <b>products</b> 10>9>8>3 {{do not leave}} any ties to be broken here).|$|R
2500|$|Using {{the chain}} rule again shows that [...] All <b>dot</b> <b>products</b> [...] where [...] and [...] differ are zero, so the squared norm of this vector is ...|$|R
50|$|Note {{also that}} the {{following}} <b>dot</b> <b>products</b> are zero:which illustrates that vectors in the kernel of A are orthogonal {{to each of the}} row vectors of A.|$|R
25|$|In 1878 Elements of Dynamic was {{published}} by William Kingdon Clifford. Clifford simplified the quaternion study by isolating the <b>dot</b> <b>product</b> and cross product of two vectors from the complete quaternion product. This approach made vector calculations available to engineers and others working in three dimensions and skeptical of the fourth.|$|E
25|$|In 1877, to {{emphasize}} {{the fact that the}} result of a <b>dot</b> <b>product</b> is a scalar while the result of a cross product is a vector, William Kingdon Clifford coined the alternative names scalar product and vector product for the two operations. These alternative names are still widely used in the literature.|$|E
25|$|Oliver Heaviside in England and Josiah Willard Gibbs, a {{professor}} at Yale University in Connecticut, also felt that quaternion methods were too cumbersome, often requiring the scalar or vector part of a result to be extracted. Thus, about forty years after the quaternion product, the <b>dot</b> <b>product</b> and cross product were introduced—to heated opposition. Pivotal to (eventual) acceptance was {{the efficiency of the}} new approach, allowing Heaviside to reduce the equations of electromagnetism from Maxwell's original 20 to the four commonly seen today.|$|E
5000|$|Using {{the chain}} rule again shows that [...] All <b>dot</b> <b>products</b> [...] where [...] and [...] differ are zero, so the squared norm of this vector is ...|$|R
3000|$|... dot-products, {{and keeps}} in memory the Min and the Max <b>dot</b> <b>products.</b> In this scheme, each {{processor}} holds a different skewer {{which must be}} input before each new pass.|$|R
5000|$|Let , , and [...] {{respectively}} be unit vectors {{along the}} , , and [...] axes. These represent the covariant basis; computing their <b>dot</b> <b>products</b> gives the following {{components of the}} metric tensor: ...|$|R
