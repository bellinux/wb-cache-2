3|135|Public
5000|$|... expr evaluates integer or string expressions, {{including}} {{pattern matching}} regular expressions. Most {{of the challenge}} posed in writing expressions is preventing the <b>invoking</b> <b>command</b> line shell from acting on characters intended for expr to process.|$|E
5000|$|Command-line {{parameters}} - {{these have}} the form %0, %1...%9, and initially contain the command {{name and the}} first nine command line parameters passed to the script (e.g., if the <b>invoking</b> <b>command</b> was [...] "myscript.bat John Doe", then %0 is [...] "myscript.bat", %1 is [...] "John" [...] and %2 is [...] "Doe"). The parameters {{to the right of}} the ninth can be mapped into range by using the SHIFT statement.|$|E
40|$|This {{document}} {{is intended to}} serve as a users guide for the time-domain atmospheric acoustic propagation suite (TDAAPS) program developed as part of the Department of Defense High-Performance Modernization Office (HPCMP) Common High-Performance Computing Scalable Software Initiative (CHSSI). TDAAPS performs staggered-grid finite-difference modeling of the acoustic velocity-pressure system with the incorporation of spatially inhomogeneous winds. Wherever practical the control structure of the codes are written in C++ using an object oriented design. Sections of code where a large number of calculations are required are written in C or F 77 in order to enable better compiler optimization of these sections. The TDAAPS program conforms to a UNIX style calling interface. Most of the actions of the codes are controlled by adding flags to the <b>invoking</b> <b>command</b> line. This document presents a large number of examples and provides new users with the necessary background to perform acoustic modeling with TDAAPS...|$|E
5000|$|To <b>invoke</b> <b>commands</b> using {{modifier}} keys {{in conjunction}} with the standard typewriter keys.|$|R
50|$|In computing, a {{keyboard}} shortcut is a sequence or combination of keystrokes {{on a computer}} keyboard which <b>invokes</b> <b>commands</b> in software.|$|R
30|$|As {{stated in}} Section 4.6, {{it is natural}} that {{forensic}} data pertaining to a cloud computing environment should be collected from the CSCs and CPSs sides [2, 27, 28, 49, 56]. To collect its unilaterally trusted forensic data {{with respect to a}} cloud incident: (i) the CSCs can collect and analyze forensic data left behind on their client machine by <b>invoking</b> <b>commands</b> at the CFaaS service interface, and (ii) the CSCs must collect and analyze forensic data on the provider side by <b>invoking</b> <b>commands</b> at the CFaaS service interface.|$|R
50|$|Before {{the game}} starts, the Spectators decide between {{themselves}} which pieces they will write rules for. The secret rule {{for a piece}} may for example control the way that piece moves, captures, or is captured, and may cause it to affect other pieces on the board. A piece may be given an <b>invoke</b> <b>command</b> which causes it to affect other pieces on the board without moving. When he has written the secret rule for a piece, the Spectator also gives it a new name {{for the duration of}} the game. These names, and the existence of any <b>invoke</b> <b>commands,</b> are announced to the players at the start of the game. During the game the spectators may privately discuss how their rules interact.|$|R
30|$|The {{output of}} path {{information}} of testing program execution is achieved through the function call instruction (invoke) in the Dalvik virtual machine. With {{the execution of}} the <b>invoke</b> <b>command,</b> the class and method name will be printed out. It contains the procedure call and prints out the information.|$|R
25|$|OS/360 and successors {{include a}} system call XCTL (transfer control) that {{performs}} a similar function to exec. Except for type 4 SVC, this usage is rare. More common {{is the use}} of LINK or ATTACH to invoke a load module without terminating the current load module. In particular, TSO <b>invokes</b> <b>commands</b> with ATTACH, sharing memory.|$|R
40|$|Modern {{smartphones}} contain sophisticated {{sensors to}} monitor three-dimensional {{movement of the}} device. These sensors permit devices to recognize motion gestures— deliberate movements of the device by end-users to <b>invoke</b> <b>commands.</b> However, {{little is known about}} best-practices in motion gesture design for the mobile computing paradigm. To address this issue, we present the results of a guessability study that elicits end-user motion gestures to <b>invoke</b> <b>commands</b> on a smartphone device. We demonstrate that consensus exists among our participants on parameters of movement and on mappings of motion gestures onto commands. We use this consensus to develop a taxonomy for motion gestures and to specify an end-user inspired motion gesture set. We highlight the implications of this work to the design of smartphone applications and hardware. Finally, we argue that our results influence best practices in design for all gestural interfaces. Author Keywords Motion gestures, sensors, mobile interaction...|$|R
5000|$|It is {{possible}} to <b>invoke</b> these <b>commands</b> in a tar-like syntax as well: pax -wf archive.tar [...]and pax -rf archive.tar ...|$|R
30|$|The {{framework}} reads all {{keyboard and}} mouse {{input from the}} user, and keeps track of the applications within which they are working. It allows for plug-ins to make changes to the system settings of the underlying operating system, and similarly allows them to read in {{the current state of}} system settings. It has routines for executing external applications, reading input from <b>invoked</b> <b>commands,</b> and provides a socket architecture that allows for plug-ins to communicate with external applications.|$|R
30|$|First, {{before the}} program is tested, we need to extract the {{relevant}} class of tested program and import it to the specified configuration paper; then, in the test when the <b>invoke</b> <b>command</b> is executed, the content will be matched with configuration file name with calling function. If matched, the related information of the called function will output or be discarded directly; it can eventually get the path information of the tested program which has been executed.|$|R
40|$|A method fo add a Web-based {{interface}} to a command-line driven {{system is}} presented. Without programming, Javamatic can generate a graphical user interface, then <b>invokes</b> <b>commands</b> in the legacy system transparently to the user. The user interface (UI) is automatically generated as a Java applet or stand-alone interface from a high-level {{description of the}} application, which is UI independent, using a set of UI mapping rules. The application is wrapped with an interface serverl thus multiple clients can use the legacy application through the Web...|$|R
40|$|We {{present the}} “boomerang ” technique, {{which makes it}} {{possible}} to suspend and resume drag-and-drop operations. A throwing gesture while dragging an object suspends the operation, anytime and anywhere. A drag-and-drop interaction, enhanced with our technique, allows users to switch windows, <b>invoke</b> <b>commands,</b> and even drag other objects during a drag-and-drop operation without using the keyboard or menus. We explain how a throwing gesture can suspend drag-and-drop operations, and describe other features of our technique, including grouping, copying, and deleting dragged objects. We conclude by presenting prototype implementations and initial feedback on the proposed technique. ACM Classification: H 5. 2 [Information interfaces an...|$|R
5000|$|The cache can be reset by <b>invoking</b> the [...] <b>command</b> via a Terminal window.|$|R
5000|$|The [...] utility is <b>invoked</b> {{from the}} <b>command</b> line {{according}} to the following syntax: ...|$|R
50|$|For example, The $s {{variable}} was the ancestor of $HOME, used to avoid hard-coding pathnames. The $p {{variable was}} the ancestor of $PATH, which let users search for commands {{in their own}} choice of directories. Unlike most of the UNIX systems of the time, the original PWB/UNIX computer center was shared by multiple programming groups who could not change the contents of /bin or /usr/bin, but wanted {{to create their own}} sets of shared commands. In addition, the shell's command-searching was enhanced to allow shell procedures to be <b>invoked</b> like binary <b>commands,</b> i.e., if the shell found a non-binary file marked executable, it would fork another shell instance to read that file as a shell script. Thus people could type command arguments rather than sh pathname/command arguments. All this behavior was packaged as the function pexec, which was the ancestor of execvp, to allow any program to <b>invoke</b> <b>commands</b> {{in the same way as}} the shell.|$|R
5000|$|Most {{graphical}} {{user interfaces}} develop the metaphor of an [...] "electronic desktop", where data files are represented {{as if they were}} paper documents on a desk, and application programs similarly have graphical representations instead of being <b>invoked</b> by <b>command</b> names.|$|R
5000|$|Many establishments {{will have}} a number of file servers which host the home {{directories}} of various users. All workstations and other nodes internal to such organizations (typically all those behind a common firewall separating them from the Internet) will be configured with automounter services so that any user logging into any node implicitly triggers access to his or her own home directory which, consequently, is mounted at a common mountpoint, such as [...] This allows users to access their own files from anywhere in the enterprise, which is extremely useful in UNIX environments, where users may frequently <b>invoke</b> <b>commands</b> on many remote systems via various job-dispatching commands such as , , [...] or , or via the X11 or VNC protocols.|$|R
50|$|For example, when {{compiled}} and <b>invoked</b> {{from the}} <b>command</b> line with parametersit producesas output on the console.|$|R
5000|$|No-compile {{developer}} experience (ie compilation is continuous so {{the developer}} doesn't have to <b>invoke</b> the compilation <b>command)</b> ...|$|R
50|$|Additional {{arguments}} {{be supplied}} when assigning any power management settings. Power management arguments {{are discussed in}} greater detail below. When <b>invoking</b> the <b>command,</b> only specified arguments modify power management options. Any arguments already set will be unmodified by pmset unless those arguments are specifically included.|$|R
50|$|The {{application}} {{enters into}} that mode {{as long as}} the user is performing a conscious action, like pressing a key and keeping it pressed while <b>invoking</b> a <b>command.</b> If the sustaining action is stopped without executing a command, the application returns to a neutral status.|$|R
40|$|Current {{interfaces}} for manipulating curves typically use {{a standard}} point cursor to indirectly adjust curve parameters. We present an interface for far more direct manipulation of curves using a specialized high degree-of-freedom curve input device, called ShapeTape. This device {{allows us to}} directly control the shape and position of a virtual curve widget. We describe the design and implementation {{of a variety of}} interaction techniques that use this curve widget to create and manipulate other virtual curves in 2 D and 3 D space. The input device is also used to sense a set of user gestures for <b>invoking</b> <b>commands</b> and tools. The result is an effective alternate user interface for curve manipulation {{that can be used in}} 2 D and 3 D graphics applications...|$|R
5000|$|... x265 can be <b>invoked</b> as a <b>command</b> line {{application}} or integrated {{to another}} application {{through the application}} programming interface.|$|R
5000|$|Supported on all {{versions}} of Microsoft Windows from 95 through 7; certain modes can be <b>invoked</b> from the <b>command</b> line ...|$|R
40|$|Model-based {{interface}} design {{can save}} substantial effort in building help systems for interactive applications by generating help automatically {{from the model}} used to implement the interface, and by providing a framework for developers to easily refine the automatically-generated help texts. This paper describes a system that generates hypertext-based help about data presented in application displays, commands to manipulate data, and interaction techniques to <b>invoke</b> <b>commands.</b> The refinement component provides several levels of customization, including programming-by-example techniques to let developers edit directly help windows that the system produces, and the possibility to refine help generation rules. KEYWORDS : Automatic Help Generation, Model-Based Interface Design, Hypertext-Based Help, Help Customization, Help Generation Rules. INTRODUCTION Help systems today are usually developed as separate artifacts from the systems they support. As a result, building and maintaining hel [...] ...|$|R
5000|$|The general {{limitation}} of the hypothetical imperative is its potential ambiguity in its means, and its susceptibility to be misused for corrupted ends instead. Hypothetical imperatives also can only be enacted upon {{if there is a}} personal investment in the action done and the ends produced. If one does not find personal benefit or incentive to conduct an action off a certain mean, then they are not obligated to do so. In other words, hypothetical imperatives <b>invoke</b> <b>commands</b> though [...] "ought to do's", and their emphasis is more on individual personal desires. The only non-hypothetical imperatives are ones which tell you to do something no matter who you are or what you want, because the thing is good in itself. These types of imperatives belong to the category of Categorical imperative.|$|R
5000|$|In Windows NT-based {{operating}} systems, System File Checker can be <b>invoked</b> via Windows <b>Command</b> Prompt (with Admin privilege), {{with the}} following command: ...|$|R
5000|$|In Gypsy, {{the user}} could select the source text, press the [...] "Copy" [...] {{function}} key, select the destination text or insertion point, {{and press the}} [...] "Paste" [...] function key. Between Copy and Paste, the system was, as usual, not in a mode. The user could <b>invoke</b> other <b>commands,</b> such as opening a different document.|$|R
40|$|Foot-based {{gestures}} {{have recently}} received attention {{as an alternative}} interaction mechanism in situations where the hands are pre-occupied or unavailable. This paper investigates suitable real-world mappings of foot gestures to <b>invoke</b> <b>commands</b> and interact with virtual workspaces. Our first study identified user preferences for mapping common mobile-device commands to gestures. We distinguish these gestures in terms of discrete and continuous command input. While discrete foot-based input has relatively few parameters to control, continuous input requires careful design considerations on how the user’s input can be mapped to a control parameter (e. g. the volume knob of the media player). We investigate this issue further through three user-studies. Our results show that rate-based techniques are significantly faster, more accurate and result if far fewer target crossings compared to displacement-based interaction. We discuss these findings and identify design recommendations. Author Keywords Foot-based interaction; foot gestures; mobile device interactio...|$|R
40|$|Present smart phones contain {{high-tech}} {{sensors to}} monitor three-dimensional {{movements of the}} device and users' behaviours. These sensors allow mobile devices to recognize motion gestures. However, only a few gesture sets have been created, and {{little is known about}} best practices in motion-gesture design. Also, the created gesture sets were generated from people who do not have to use their motion gestures very much in their daily lives, not from people with communication difficulties. To address this issue, we use a focus group that has dyslexia and other specific learning difficulties for designing the user-defined gesture sets. This paper presents the results of our study that elicits the focus group's gestures to <b>invoke</b> <b>commands</b> on a smart-phone device. It demonstrates how the gesture sets have been designed and finalised throughout other research activities, such as observation and interviews. Finally, we suggest that our result would help people with communication impairments conveniently interact with others in an intuitive and socially acceptable manner...|$|R
40|$|Part 7 : Gesture-Based User Interface Design and Interaction IIInternational audienceWe use {{the front}} facing camera in a smart phone to capture gesture input. Thumb {{gestures}} performed above the camera are recognized {{and used to}} <b>invoke</b> <b>commands.</b> In contrast to other input modalities the camera requires no device movements and no valuable screen space is used. To be viable, this type of interaction requires gestures which are comfortable and memorable for the user and real-time accurate recognition of those gestures. Given the performance constraints of phones and their cameras we needed to determine whether accurate and reliable recognition is possible and identify types of gestures that are recognizable and user appropriate. As a proof of concept, we conducted a user study testing three gestures for performance and user satisfaction. The results demonstrate that the 3 D gestural input is successful and we provide detailed insights into successful recognition strategies for this novel interaction modality...|$|R
40|$|International audienceThe {{usability}} {{of small}} {{devices such as}} smartphones or interactive watches is often hampered by the limited size of command vocabularies. This paper is an attempt at better understanding how finger identification may help users <b>invoke</b> <b>commands</b> on touch screens, even without recourse to multi-touch input. We describe how finger identification can {{increase the size of}} input vocab‐ ularies under the constraint of limited real estate, and we discuss some visual cues to communicate this novel modality to novice users. We report a controlled experiment that evaluated, over a large range of input-vocabulary sizes, the effi‐ ciency of single-touch command selections with vs. without finger identification. We analyzed the data {{not only in terms of}} traditional time and error metrics, but also in terms of a throughput measure based on Shannon’s theory, which we show offers a synthetic and parsimonious account of users’ performance. The results show that the larger the input vocabulary needed by the designer, the more prom‐ ising the identification of individual fingers...|$|R
40|$|The Amulet user {{interface}} development environment uses hierarchical command objects {{to support the}} creation of highly-interactive graphical {{user interface}}s. When input arrives or a widget is operated by the user, instead of invoking a call-back procedure as in most other toolkits, Amulet allocates a command object and calls its DOmethod. Unlike previous uses of command objects, Amulet organizes the commands into a hierarchy, so that low-level operations like dragging or selection <b>invoke</b> low-level <b>commands,</b> which in turn might <b>invoke</b> widget-level <b>commands,</b> which <b>invoke</b> high-level, application-specific <b>commands,</b> and so on. The top-level commands correspond to semantic actions of the program. The result is better modularization because different levels of the user interface are independent, and better code reuse because the lower-level commands, and even many high-level commands such as cut, copy, paste, text edit, and change-color, can be reused from the library. Furthermore, the commands in Amulet support {{a new form of}} Undo, where the user can select any previous operation and selectively undo it, repeat it on the same objects, or repeat it on new objects. In addition, operations like scrolling and selections can be undone or repeated, which can be very useful. Thus, the command objects in Amulet make it easier for developers by providing more reusable components, {{while at the same time}} providing new capabilities for users...|$|R
