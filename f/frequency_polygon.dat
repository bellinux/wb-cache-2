23|32|Public
40|$|A {{piecewise}} linear competitor to the <b>frequency</b> <b>polygon,</b> the edge <b>frequency</b> <b>polygon,</b> is proposed: instead of joining histogram ordinates at midpoints of bins by straight lines, one connects values at bin edges by straight lines, those values being averages of contiguous histogram ordinates. The new proposal {{is as simple}} and interpretable as the ordinary <b>frequency</b> <b>polygon</b> while holding theoretical and practical advantages...|$|E
40|$|Jones et al. (Biometrica 85, 235) {{proposed}} an edge <b>frequency</b> <b>polygon</b> estimator to estimate a probability density function. Their estimator has a smaller asymptotic mean integrated squared error {{than that of}} the <b>frequency</b> <b>polygon</b> estimator. In this paper we introduce a generalized edge <b>frequency</b> <b>polygon</b> estimator. Instead of averaging heights of two bins at each bin edge, we take weighted averages of the heights in the neighboring 2 k (k[greater-or-equal, slanted] 1) bins, which further reduces the asymptotic mean integrated squared error. Density estimation Histogram Integrated squared error...|$|E
30|$|As {{pointed out}} by Scott [5], the <b>frequency</b> <b>polygon</b> has {{convergence}} rates {{similar to those of}} kernel density estimators and greater than the rate for a histogram. As for computation, the computational effort of the <b>frequency</b> <b>polygon</b> is equivalent to the one of the histogram. For large bivariate data sets, the computational simplicity of the <b>frequency</b> <b>polygon</b> and the ease of determining exact equiprobable contours may outweigh the increased accuracy of a kernel density estimator. Bivariate contour plots based on millions of observations are increasingly required in applications including high-energy physics simulation experiments, cell sorters and geographical data representation. Moreover, such data are usually collected in a binned form. Therefore, the <b>frequency</b> <b>polygon</b> can be a useful tool for examination and presentation of data. Since the <b>frequency</b> <b>polygon</b> has the advantages mentioned above, it attracts the attention of some scholars, and they have derived some results. For the explicit results obtained, one can refer to the references listed in Yang and Liang [6] and Xing et al. [7], which gave the strong consistency of frequency polygons. Among the obtained results, the study on asymptotic normality can be found in Carbon et al. [8]. The relevant Berry-Esséen bound for ϕ-mixing samples has not been seen. This motivates us to investigate the Berry-Esséen bound of <b>frequency</b> <b>polygon</b> under ϕ-mixing samples. Under the given assumptions, we give the corresponding Berry-Esséen bound. Furthermore, by the obtained Berry-Esséen bound, the relevant convergence rate of uniformly asymptotic normality is also derived, which is nearly O(n^- 1 / 6) under the given conditions.|$|E
30|$|Under some mild assumptions, the Berry-Esséen bound of <b>frequency</b> <b>polygons</b> for ϕ-mixing samples is presented. By the bound derived, we {{obtain the}} {{corresponding}} convergence rate of uniformly asymptotic normality, which is nearly O(n^- 1 / 6) under the given conditions.|$|R
40|$|This paper {{establishes}} the asymptotic normality of <b>frequency</b> <b>polygons</b> {{in the context}} of stationary strongly mixing random fields indexed by ^d. Our method allows us to consider only minimal conditions on the width bins and provides a simple criterion on the mixing coefficients. In particular, we improve in several directions a previous result by Carbon, Francq and Tran (2010) ...|$|R
40|$|Abstract – Nonparametric density {{estimation}} {{is considered}} for a discretely observed stationary continuous-time process. For each of three given time sampling procedures either random or deterministic, we establish that histograms and <b>frequency</b> <b>polygons</b> can reach the same optimal L 2 -rates as in the independent and identically distributed case. Moreover, thanks to a suitable “high frequency ” sampling design, these rates are derived together with a minimized time of observation depending on the regularity of sample paths...|$|R
40|$|We {{introduce}} simple nonparametric density estimators that generalize {{the classical}} histogram and <b>frequency</b> <b>polygon.</b> The new estimators are expressed as linear combination of density functions that are piecewise polynomials, where the coe#cients are optimally chosen {{in order to}} minimize the integrated square error of the estimator. We establish the asymptotic behaviour of the proposed estimators, and study their performance in a simulation study...|$|E
40|$|This report {{presents}} ViSta-ANOVA, the ViSta {{procedure for}} performing analysis of variance. This procedure {{is capable of}} analyzing balanced or unbalanced, complete (i. e., every cell must have at least 1 observation) n-way data for main effects and two-way interactions. ViSta-ANOVA’s unique visualization includes a box, diamond, and dot plot; a <b>frequency</b> <b>polygon</b> and histogram; a profile plot; a residual plot; and a partial regression plot. ...|$|E
40|$|We {{contribute}} {{to the study of}} data binning in density estimation. The particular disadvantage of histograms due to the effect of bin edge placement is stressed (again). We investigate how simple methods, both existing (such as the <b>frequency</b> <b>polygon)</b> and novel (proposing other natural piecewise linear adaptations), improve on the basic histogram (and on each other). Lurking in the background throughout are links with kernel density estimation...|$|E
40|$|Statistical {{computing}} when input/output {{is driven}} by a Graphical User Interface is considered. A proposal is made for automatic control of computational flow to ensure that only strictly required computations are actually carried on. The computational flow is modeled by a directed graph for implementation in any object-oriented programming language with symbolic manipulation capabilities. A complete implementation example is presented to compute and display frequency based piecewise linear density estimators such as histograms or <b>frequency</b> <b>polygons.</b> ...|$|R
40|$|AbstractWe {{construct}} a simple algorithm, based on Newton's method, which permits asymptotic minimization of L 1 distance for nonparametric density estimators. The technique is applicable to multivariate kernel estimators, multivariate histogram estimators, and smoothed histogram estimators such as <b>frequency</b> <b>polygons.</b> It has an “adaptive” or “data-driven” version. We show theoretically that both theoretical and adaptive {{forms of the}} algorithm do indeed minimize asymptotic L 1 distance. Then we apply the algorithm to derive concise formulae for asymptotically optimal smoothing parameters. We also give numerical examples of applications of the adaptive algorithm...|$|R
40|$|Normal {{values have}} been {{established}} for haemoglobin and plasma calcium, inorganic phosphate, magnesium, iron and copper {{in the blood of}} Angora goats maintained in the Cape Midlands of South Africa. With the exception of the values obtained for haemoglobin, the data collected for these determinations present slightly to considerably skewed distribution curves. Normal values {{have been established}} by using cumulative relative <b>frequency</b> <b>polygons</b> constructed from these data. The journals have been scanned in colour with a HP 5590 scanner; 600 dpi. Adobe Acrobat v. 11 was used to OCR the text and also for the merging and conversion to the final presentation PDF-format...|$|R
40|$|The <b>frequency</b> <b>polygon</b> is not {{compatible}} with the given frequency distribution {{in the sense that}} the areas within the classes are not proportional to the frequencies. As a consequence, the polygon is too flat. Therefore, an alternative polygon is constructed as a continuous version of the histogram by area-matching within each class. The result is a useful tool for visualizing frequency distributions, which is continuous, {{compatible with}} the frequencies and easy to understand...|$|E
40|$|Barron-type estimators are histogram-based {{distribution}} estimators {{that have}} been proved to have good consistency properties according to several information theoretic criteria. However they are not continuous. In this paper, we examine {{a new class of}} continuous distribution estimators obtained as a combination of Barron-type estimators with the <b>frequency</b> <b>polygon.</b> We prove the consistency of these estimators in expected information divergence and expected chi(2) -divergence. For one of them we evaluate the rate of convergence in expected chi(2) -divergence. status: publishe...|$|E
40|$|Statistical {{computing}} when input/output {{is driven}} by a Graphical User Interface is considered. A proposal is made for automatic control of computational flow to ensure that only strictly required computations are actually carried on. The computational flow is modeled by a directed graph for implementation in any object-oriented programming language with symbolic manipulation capabilities. A complete implementation example is presented to compute and display frequency based piecewise linear density estimators such as histograms or frequency polygons. Histogram, <b>frequency</b> <b>polygon,</b> bin width, object oriented programming, interactive graphics, statistical computing...|$|E
40|$|We {{construct}} a simple algorithm, based on Newton's method, which permits asymptotic minimization of L 1 distance for nonparametric density estimators. The technique is applicable to multivariate kernel estimators, multivariate histogram estimators, and smoothed histogram estimators such as <b>frequency</b> <b>polygons.</b> It has an "adaptive" or "data-driven" version. We show theoretically that both theoretical and adaptive {{forms of the}} algorithm do indeed minimize asymptotic L 1 distance. Then we apply the algorithm to derive concise formulae for asymptotically optimal smoothing parameters. We also give numerical examples of applications of the adaptive algorithm. asymptotic optimality histogram estimator kernel estimator L 1 distance nonparametric density estimator...|$|R
40|$|We study {{piecewise}} linear density estimators from the L- 1 point of view: the <b>frequency</b> <b>polygons</b> investigated by SCOTT (1985) and JONES et al. (1997), {{and a new}} {{piecewise linear}} histogram. In contrast to the earlier proposals, a unique multivariate generalization of the new piecewise linear histogram is available. All these estimators are shown to be universally L- 1 strongly consistent. We derive large deviation inequalities. For twice differentiable densities with compact support their expected L- 1 error is shown {{to have the same}} rate of convergence as have kernel density estimators. Some simulated examples are presented. status: publishe...|$|R
40|$|OBJECTIVES: This study {{explains}} why <b>frequency</b> <b>polygons</b> for US birthweights in 100 -g weight classes appear spiky {{compared with their}} European counterparts. METHODS: A probability model is used to describe how unit conversion can induce misclassification. Birthweights from the United States and Norway are used to illustrate that misclassification operates in grouped US data. RESULTS: Spikiness represents misclassification that arises when measured birthweights are rounded to the nearer ounce, converted to grams, and then grouped into weight classes. Misclassification is ameliorated, not eliminated, with 200 -g weight classes. CONCLUSIONS: Possible biases from misclassification should be carefully evaluated when fitting statistical models to grouped US birthweights...|$|R
40|$|The {{purpose of}} this paper is to {{investigate}} the <b>frequency</b> <b>polygon</b> as a density estimator for stationary strong mixing processes. Optimal bin widths which asymptotically minimize integrated mean square errors (IMSE) are derived. Under weak conditions, frequency polygons achieve the same rate of convergence to zero of the IMSE as kernel estimators. They can also attain the optimal uniform rate of convergence ((n- 1 logn) 1 / 3 under general conditions. Frequency polygons thus appear to be very good density estimators with respect to both criteria of IMSE and uniform convergence. Density estimation Mixing process Bin width Frequency polygons...|$|E
40|$|The {{variance}} reduction {{established by}} importance sampling strongly {{depends on the}} choice of the importance sampling distribution. A good choice is often hard to achieve especially for high-dimensional integration problems. Nonparametric estimation of the optimal importance sampling distribution (known as nonparametric importance sampling) is a reasonable alternative to parametric approaches. In this article nonparametric variants of both the self-normalized and the unnormalized importance sampling estimator are proposed and investigated. A common critique on nonparametric importance sampling is the increased computational burden compared to parametric methods. We solve this problem to a large degree by utilizing the linear blend <b>frequency</b> <b>polygon</b> estimator instead of a kernel estimator. Mean square error convergence properties are investigated leading to recommendations for the efficient application of nonparametric importance sampling. Particularly, we show that nonparametric importance sampling asymptotically attains optimal importance sampling variance. The efficiency of nonparametric importance sampling algorithms heavily relies on the computational efficiency of the employed nonparametric estimator. The linear blend <b>frequency</b> <b>polygon</b> outperforms kernel estimators in terms of certain criteria such as efficient sampling and evaluation. Furthermore, it is compatible with the inversion method for sample generation. This allows to combine our algorithms with other variance reduction techniques such as stratified sampling. Empirical evidence for the usefulness of the suggested algorithms is obtained by means of three benchmark integration problems. As an application we estimate the distribution of the queue length of a spam filter queueing system based on real data. Comment: 29 pages, 7 figure...|$|E
40|$|The {{variance}} reduction {{established by}} importance sampling strongly {{depends on the}} choice of the importance sampling distribution. A good choice is often hard to achieve especially for high-dimensional integration problems. Nonparametric estimation of the optimal importance sampling distribution (known as ‘‘nonparametric importance sampling’’) is a reasonable alternative to parametric approaches. In this article, nonparametric variants of both the self-normalized and the unnormalized importance sampling estimator are proposed and investigated. A common critique of nonparametric importance sampling is the increased computational burden compared with parametric methods. We solve this problem to a large degree by utilizing the linear blend <b>frequency</b> <b>polygon</b> estimator instead of a kernel estimator. Mean square error convergence properties are investigated, leading to recommendations for the efficient application of nonparametric importance sampling. Particularly, we show that nonparametric importance sampling asymptotically attains optimal importance sampling variance. The efficiency of nonparametric importance sampling algorithms relies heavily on the computational efficiency of the nonparametric estimator used. The linear blend <b>frequency</b> <b>polygon</b> outperforms kernel estimators in terms of certain criteria such as efficient sampling and evaluation. Furthermore, it is compatible with the inversion method for sample generation. This allows one to combine nonparametric importance sampling with other variance reduction techniques such as stratified sampling. Empirical evidence for the usefulness of the suggested algorithms is obtained by means of three benchmark integration problems. We show empirically that these methods may work in higher dimensions, at least up to dimension eight. As an application, we estimate the distribution of the queue length of a spam filter queuing system based on real data...|$|E
40|$|The {{earliest}} {{reference to}} the fecundity of the Indian mackerel was by Devanesan and John (1940) who estimated the number of ripe eggs in the mackerel ovary as 94, 000. Subsequent work was directed mostly towards finding out the spawning behaviour of this fish, by {{the study of the}} intra-ovarian eggs. Pradhan (1956) indicated the possibility of the Indian mackerel spawning the eggs in successive batches over a prolonged period, like its Atlantic counter-part Scomber scombrus (L). Pradhan and Palekar (1956) described the maturity stages I to VII, based on the external appearance of the ovary, its size relative to the abdominal cavity, and the range of ova-diameter readings. However, they have not given any ova-diameter <b>frequency</b> <b>polygons...</b>|$|R
40|$|Statistical {{computing}} when input/output {{is driven}} by a Graphical User Interface is considered. A proposal is made for automatic control of computational flow to ensure that only strictly required computations are actually carried on. The computational flow is modeled by a directed graph for implementation in any object-oriented programming language with symbolic manipulation capabilities. A complete implementation example is presented to compute and display frequency based piecewise linear density estimators such as histograms or <b>frequency</b> <b>polygons.</b> JEL clasification: C 10; C 13; C 43. Keywords: Histogram; Frequencypolygon; Bin width; Object oriented programming; Interactive graphics; Statistical computing. 2 1 Introduction Controlling computation flow in classical programs is not a difficult task: some conditional or case statements would do the job in most cases. When user interaction is needed, the program prompts for it, then it waits for an answer, processes the respons [...] ...|$|R
40|$|Statistical {{computing}} when input/output {{is driven}} by a Graphical User Interface is considered. A proposal is made for automatic control of computational flow to ensure that only strictly required computations are actually carried on. The computational flow is modeled by a directed graph for implementation in any object-oriented programming language with symbolic manipulation capabilities. A complete implementation example is presented to compute and display frequency based piecewise linear density estimators such as histograms or <b>frequency</b> <b>polygons.</b> Controlling computation flow in classical programs is not a difficult task: some conditional or case statements would do the job in most cases. When user interaction is needed, the program prompts for it, then it waits for an answer, processes the response and produces output. If we consider statistical computing in a graphical user interface (GUI) environment, things are very different. The user can decide at any moment to change [...] ...|$|R
40|$|Abstract. E cient {{variance}} {{reduction is}} crucial to Monte Carlo simulation based derivative pricing. Importance sampling {{is one of the}} most promising approaches for variance reduction but typically neither the optimal importance sampling distribution itself nor a reliable approximation is available. We suggest an algorithm that applies a multivariate <b>frequency</b> <b>polygon</b> to estimate the optimal importance sampling distribution nonparametrically. Nonparametric importance sampling is ine cient in high-dimensional problems due to the curse of dimensionality. We tackle this problem by restricting our procedure to a low-dimensional subspace. We apply Quasi Monte Carlo techniques for the further improvement of our method. We demonstrate our method's potential to reduce Monte Carlo variance through path-dependent and multi-asset option pricing problems...|$|E
40|$|The {{variance}} reduction {{established by}} importance sampling strongly {{depends on the}} choice of the importance sampling distribution. A good choice is often hard to achieve especially for high-dimensional integration problems. Nonparametric estimation of the optimal importance sampling distribution (known as nonparametric importance sampling) is a reasonable alternative to parametric approaches. A common critique on nonparametric importance sampling is the increased computational burden compared to parametric methods. We solve this problem to a large degree by utilizing a multivariate <b>frequency</b> <b>polygon</b> instead of a kernel estimator. Mean square error convergence properties are investigated leading to recommendations for the efficient application of nonparametric importance sampling. Empirical evidence for the usefulness of the suggested algorithms is obtained by means of three benchmark integration problems including an option pricing example...|$|E
40|$|Abstract. Importance {{sampling}} is {{a promising}} variance reduction technique for Monte Carlo simulation based derivative pricing. Existing importance sampling methods {{are based on}} a parametric choice of the proposal. This article proposes an algorithm that estimates the optimal proposal nonparametrically using a multivariate <b>frequency</b> <b>polygon</b> estimator. In contrast to parametric methods, nonparametric estimation allows for close approximation of the optimal proposal. Standard nonparametric importance sampling is inefficient for highdimensional problems. We solve this issue by applying the procedure to a low-dimensional subspace, which is identified through principal component analysis and the concept of the effective dimension. The mean square error properties of the algorithm are investigated and its asymptotic optimality is shown. Quasi-Monte Carlo is used for further improvement of the method. It is easy to implement, particularly it does not require any analytical computation, and it is computationally very efficient. We demonstrate through path-dependent and multi-asset option pricing problems that the algorithm leads to significant efficiency gains compared to other algorithms in the literature...|$|E
40|$|In {{this paper}} we {{consider}} the estimation of a density f {{on the basis of}} random sample from a weighted distribution G with density g given by g(x) = w(x) f(x) / ÃÂµw, where w(u) > 0 for all u and ÃÂµw = Ã¢ÂÂ« w(u) f(u) du < Ã¢ÂÂ. A special case of this situation is that of length-biased sampling, where w(x) = x. In this paper we examine a simple transformation-based approach to estimating the density f. The approach is motivated by the form of the nonparametric estimator of f in the same context and under a monotonicity constraint. Since the method does not depend on the specific density estimate used (only the transformation), {{it can be used to}} construct both simple density estimates (histograms or <b>frequency</b> <b>polygons)</b> and more complex methods with favorable properties (e. g., local or penalized likelihood estimates). Monte Carlo simulations indicate that transformation-based density estimation can outperform the kernel-based estimator of Jones (1991) depending on the weight function w, and leads to much better estimation of monotone densities than the nonparametric maximum likelihood estimator. ...|$|R
40|$|Raw water {{supplies}} utilised at 12 fossil-fired power stations, {{as well as}} the corresponding open recirculating cooling water systems were surveyed. Visual inspections were carried out and the total aerobic and anaerobic bacteria, anaerobic acid-producing bacteria, Thiobacillus spp., Nitrobacter spp., sulphate-reducing bacteria (SRB) and algae were quantified. All raw {{water supplies}} and recirculating cooling waters contained all of the above groups of micro-organisms, {{with the exception of the}} two potable raw water supplies. In 75 % of the systems, the numbers of SRB in the recirculating cooling waters were higher than in the corresponding raw water supplies and in 92 % of the systems, the numbers of the total aerobic bacteria were higher in the recirculating cooling waters than in the raw supplies. However, no relationship between the sulphate levels in the recirculating cooling waters and the numbers of SRB could be distinguished, or between the percentage increase in the numbers of total aerobic bacteria and the cycles of concentration at which the system was operated. The <b>frequency</b> <b>polygons</b> of the occurences of total aerobic and anaerobic bacteria in the raw water supplies and the recirculating cooling waters did not follow normal distribution patterns. Visible biofouling deposits were observed at six of the power stations surveyed and the predominant algal group was the blue-green algae. However, in the raw water supplies, the predominant algal groups were green algae and diatoms. Microbiologically influenced corrosion was identified in all five of the condensers inspected. Each system was found to be unique and no generalisations in terms of presence or activity of micro-organisms could be made...|$|R
40|$|It is {{hypothesized}} {{that participation in}} non-band music has {{a positive impact on}} mathematics achievement. Maslow 2 ̆ 7 s Hierarchy of Needs, the theory of self-determination, multiple intelligence theory, and brain research provide a theoretical foundation in support of this conjecture. This causal comparative study seeks to address three questions related to the hypothesis: a) is there a difference between the academic achievement of 6 th grade mathematics students based on non-band music participation status; b) is there a difference between the academic achievement of 6 th grade males based on non-band music participation; and c) is there a difference between the academic achievement of 6 th grade females based on non-band music participation? In order to conduct the study, the researcher was granted access to digital spreadsheets of 6 th grade scores, from the 2013 - 2014 administration of the Northwest Education Association 2 ̆ 7 s Measures of Academic Progress assessment. After sorting scores for students who participated in instrumental music class (or band), scores were separated into two groups, scores for students who participated in non-band music class, and scores for students who did not. The data for each group was analyzed by: constructing <b>frequency</b> <b>polygons,</b> developing sets of descriptive statistics, and examining the means and standard deviations. This process was repeated to examine scores for each set of students. Subsequently, Mann-Whitney U Tests were used to compare medians. The research found that participation in non-band music class had a positive impact of mathematics achievement...|$|R
40|$|Although the {{histogram}} is {{the most}} widely used density estimator, it is well [...] known that the appearance of a constructed histogram for a given bin width can change markedly for different choices of anchor position. In this paper we construct a stability index $G$ that assesses the potential changes in the appearance of histograms for a given data set and bin width as the anchor position changes. If a particular bin width choice leads to an unstable appearance, the arbitrary choice of any one anchor position is dangerous, and a different bin width should be considered. The index is based on the statistical roughness of the histogram estimate. We show via Monte Carlo simulation that densities with more structure are more likely to lead to histograms with unstable appearance. In addition, ignoring the precision to which the data values are provided when choosing the bin width leads to instability. We provide several real data examples to illustrate the properties of $G$. Applications to other binned density estimators are also discussed. Bin width, <b>frequency</b> <b>polygon,</b> Gini index, linear binning, Lorenz curve, Monte Carlo simulation...|$|E
40|$|THIS {{investigation}} was {{initiated by the}} clinical observation that patients with angle-closure glaucoma appeared to exhibit {{a higher incidence of}} inverse astigmatism than normal. In order to determine the significance or otherwise of this observation, the spectacle refraction of 150 patients with angle-closure glaucoma was noted over a period of 5 years. The diagnosis of these cases was {{made on the basis of}} the history, clinical picture, and gonioscopy findings. 60 per cent. of the patients presented with acute congestive glaucoma; 14 per cent. with symptoms of haloes; 3 per cent. with a unilateral semi-dilated pupil; 2 per cent. with retinal artery pulsation; 2 per cent. with venous thrombosis. so _ so I The patients were grouped in 10 -yearly 40 -age group intervals so that a comparison with the normal could be made and a o 30 <b>frequency</b> <b>polygon</b> was constructed (Fig. S l 1). In general, the glaucoma patients z were in the 50 - 79 age group, so that their 20 -refractive errors should be compared with the normal in this age group. 0 o 50 60 70 80 Age (yrs) FIG. 1. -Age distribution of glaucoma patients. The refractions were undertaken independently at three different hospitals and by different ophthalmic opticians in towns served by these hospitals and at varying periods before the diagnosis of glaucoma. If an accurate refraction was not possible or if the refractive findings were post-operative, then these findings were not con-sidered in the comparison. In all, the spectacle refraction of 253 angle-closure glaucomatous eyes was noted. * Received for publication January 19, 1966. t Address for reprints: as above...|$|E
40|$|A {{study was}} carried out on the {{significance}} of surface tension values of lung washing extracts obtained from dogs consisting of fasted and linoleate-fed groups. The mean maximal surface tension of the latter was {{lower than that of}} the former (P< 0. 05). The mean minimal surface tension of the latter was higher than the former (not significant). The <b>frequency</b> <b>polygon</b> of the minimal surface tensions was divided into two portions for the linoleate-fed group [...] On the other hand, twofold serial dilution of washing extracts was performed and then tension-concentration diagram was drawn with surface tension on its ordinate and phospholipid concentration of the extract on its abscissa. The tension-concentration diagram showed that the surface tension decreased to some level as the concentration of phospholipid increased, but no further lowering of the tension was observed regardless of increased concentration. Judging from the tension-concentration diagram, it was possible to conceive critical micelle concentration (c. m. c.) in lung washing extracts. There {{was no significant difference in}} the pattern between the fasted group and the linoleate-fed group, partly because of the relatively wide range of c. m. c. Phosphatidyl-choline (Ph-C) was a major component of the washing extract. Ph-C fractions were also isolated from soy-bean lecithin, serum and lung tissues, and the respective values of their minimal surface tensions were 32. 1, 28. 2 and 28. 8 dynes/cm at c. m. c. (0. 3 γ of phosphorus). The minimal surface tension of Ph-C isolated from washing extract of the fasted dog attained 3. 0 dynes/cm at c. m. c. (15 γ of phosphorus). Ph-C of the linoleate-fed dog demonstrating higher minimal tension value (11. 7 dynes/cm) in the crude washing showed the value of 12. 6 dynes/cm at the same concentration level(15 γ of phosphorus). It was concluded from the data that tension-concentration diagram is important for the precise evaluation of surface tension values of lung washing extracts...|$|E
40|$|Voice {{quality is}} crucial to the art of the {{broadcast}} speaker. Acceptable voice quality is a necessity for an acceptable microphone voice and essential therefore for employment as a broadcaster. This thesis investigates the characteristics of the voice which provide that acceptability; and categorises the features which lead the listener to make judgements about their vocal likes and dislikes. These subjective judgements are explored by investigating the psychological, medical, and innate features contributing to the vocal perceptions of the listener. Voice quality is related to the efficiency of the larynx and its importance to voice production; and to the various vocal disorders which can affect the broadcaster. It becomes evident throughout the thesis that each listener receives a clear impression of the personality of the speaker through the features present in the voice. Many of these impressions however are based on stereotypes. The thesis relates these stereotypical judgements to accents, investigating their relationship to the 'BBC' voice, the 'World Service' voice, the 'ILR' voice and the 'reporter's voice'. It is shown that the listener's subjective impression of the voice and the broadcaster personality is formed by the presentational and physical aspects of voice quality. Listener perceptions of voice acceptability are tested and discussed. The data is analysed to provide a set of dominant characteristics from which are drawn voice histograms and <b>frequency</b> <b>polygons.</b> The result is a set of preferred voice characteristics which apply specifically to the broadcast speaker and which can be sought during the selection process...|$|R
40|$|The {{purpose of}} this study is to examine whether or not the <b>frequency</b> <b>polygons</b> of the three types of {{fundamental}} motor skills in senior high school pupils, 15 through 17 years old 6341 boys and 2441 girls are 2 ̆ 2 bell-shaped 2 ̆ 2 normal curves. The record of 50 m dash (running skill), running long jump (jumping skill), and handball distance throw (throwing skill) of the pupils of the one prefectural high school were measured in the adminlstration by the physical educator within the several weeks of new school life. The dataset were constructed by 9 or 8 cohorts (entrauce years, 1971 to 1979) by 3 ages (15 to 17 years old), which were calleld. cohort-sequential study of Schaie 2 ̆ 7 s trifactorial design. Several statistics of each skill were given from the raw data and the frequency table by the second to the fourth order moments and percentiles. The g 1, g 12 ̆ 7, SKQ, SKD mean of skewness of the distribution, otherwise g 2, g 22 ̆ 7 and kappa mean of kurtosis, respectively. The results obtained were as follows. 1) The significance of age effect by sex recognized on all of skills except the jumping and throwing skills of girls. 2) In both sexes, generally speaking, the positive skewness were obsereved in each fundamental motor skill from momentum and quantiles. In some cases, the skewness of jumping skills has tendency to converge to zero and it was not significant. Therefore, these may be identified the normalty. 3) The tendency to convergence to zero in kurtosis were inferior to skewness of each skill in both systems. The features of three types motor skills have the leptokurtic type. That is, they have a long tailness...|$|R
40|$|Morphogenesis {{is driven}} by small cell shape changes that {{modulate}} tissue organization. Apical surfaces of proliferating epithelial sheets have been particularly well studied. Currently, it is accepted that a stereotyped distribution of cellular polygons is conserved in proliferating tissues among metazoans. In this work, we challenge these previous findings showing that diverse natural packed tissues have very different polygon distributions. We use Voronoi tessellations as a mathematical framework that predicts this diversity. We demonstrate that Voronoi tessellations and the very different tissues analysed share an overriding restriction: the <b>frequency</b> of <b>polygon</b> types correlates with the distribution of cell areas. By altering the balance of tensions and pressures within the packed tissues using disease, genetic or computer model perturbations, we show {{that as long as}} packed cells present a balance of forces within tissue, they will be under a physical constraint that limits its organization. Our discoveries establish a new framework to understand tissue architecture in development and disease. Synopsis Cell shapes in naturally packed tissues have different polygon distributions. Voronoi tessellations-based analysis suggests that <b>polygon</b> <b>frequencies</b> are restricted by the distribution of cell areas, and that this restriction emanates from the balance of forces within the tissue. Cell shapes in natural packed tissues present very different polygon distributions. These patterns can be reproduced by Voronoi tessellations. Natural tissues and Voronoi diagrams share some geometrical properties. There is a physical constraint that limits the organization of natural tissues. Unbalance of forces within the natural tissue breaks this restriction. Cell shapes in naturally packed tissues have different polygon distributions. Voronoi tessellations-based analysis suggests that <b>polygon</b> <b>frequencies</b> are restricted by the distribution of cell areas, and that this restriction emanates from the balance of forces within the tissue. L. M. E. and D. S. ‐G. are supported by the Ramón y Cajal Programme (PI 13 / 01347), the Spanish Government grant BFU 2011 ‐ 25734 and the ISCIII and FEDER funds PI 13 / 01347. MT was funded by Sir Henry Wellcome Postdoctoral Fellowship (Grant No: 103095). YM was funded by a Medical Research Council Career Development Award Fellowship (Grant No: MR/L 009056 / 1). Peer Reviewe...|$|R
