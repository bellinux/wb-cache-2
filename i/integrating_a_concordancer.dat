0|10000|Public
50|$|<b>A</b> <b>concordancer</b> is <b>a</b> {{computer}} program that automatically constructs a concordance. The output of <b>a</b> <b>concordancer</b> {{may serve as}} input to a translation memory system for computer-assisted translation, or as an early step in machine translation.|$|R
40|$|The idea of {{language}} learners using <b>a</b> <b>concordancer,</b> to autonomously investigate vocabulary and structure in a target language was suggested over 30 years ago. Since then, some research has explored this idea further, {{but the potential}} benefit of concordancers {{in the hands of}} learners is still largely unexplored – especially with regards to structure. This study investigates what learners are able to accomplish when asked to investigate an English corpus with <b>a</b> <b>concordancer</b> in order to correct grammar errors in an essay. The study was conducted after only 30 minutes of training on <b>a</b> <b>concordancer.</b> Participants reactions to the software and to analyzing the target language autonomously are also shared. While participants’ reactions were mixed with regards to using a concordacer for error correction, all participants expressed an interest in using <b>a</b> <b>concordancer</b> during their writing process – something which was {{beyond the scope of this}} study – but which suggests a potential value for learner exposure to concordancers for autonomous language investigation...|$|R
5000|$|Bitext aligners: {{tools that}} align a source text and its {{translation}} which {{can then be}} analyzed using a full-text search tool or <b>a</b> <b>concordancer</b> ...|$|R
40|$|CLaRK is an XML-based {{software}} system for corpora development. It incorporates several technologies: XML technology; Un i code; Regular Cascaded Grammars; Constraints over XML Documents. The basic {{components of the}} system are: <b>a</b> tagger, <b>a</b> <b>concordancer,</b> <b>an</b> extractor, a grammar processor, a constraint engine. ...|$|R
50|$|It was Tim Johns (1991), however, {{who raised}} {{the profile of}} the use of {{concordancers}} in the language classroom with his concept of Data-driven learning (DDL). DDL encourages learners to work out their own rules about the meaning of words and their usage by using <b>a</b> <b>concordancer</b> to locate examples in a corpus of authentic texts. It is also possible for the teacher to use <b>a</b> <b>concordancer</b> to find examples of authentic usage to demonstrate a point of grammar or typical collocations, and to generate exercises based on the examples found. Various types of concordancers and where they can be obtained are described by Lamy & Klarskov Mortensen (2011).|$|R
50|$|Robb (2003) {{shows how}} it is {{possible}} to use Google as <b>a</b> <b>concordancer,</b> but he also points out a number of drawbacks, for instance there is no control over the educational level, nationality, or other characteristics of the creators of the texts that are found, and the presentation of the examples is not as easy to read as the output of <b>a</b> dedicated <b>concordancer</b> that places the key words (i.e. the search terms) in context.|$|R
40|$|This {{pilot study}} {{set out to}} {{determine}} whether a parallel corpus and <b>a</b> <b>concordancer</b> would be appropriate tools to supplement a teaching programme of German at the beginners' level in an unsupervised environment. In this instance, a beginner student of German was asked to find satisfactory answers to unknown vocabulary and formulate appropriate grammar rules for himself using the parallel corpus and concordancer as the only tools. It is shown that these tools can be of great benefit for beginners. AIMS AND OBJECTIVES I describe a pilot study involving a beginner student of German who undertook a supplementary unsupervised programme of learning German using <b>a</b> <b>concordancer</b> and <b>a</b> parallel corpus. I investigate how a beginner student of German fares using <b>a</b> <b>concordancer,</b> Multiconcord (see King & Wools, 1996; St. John & Chattle, 1998), and a parallel German/English corpus, INTERSECT (Salkie, 1995) consisting of the original German source texts and their English translations. The aim {{of this study was to}} determine how this student copes using the parallel corpus and what conclusions he comes to when comparing the two languages, and in particular, when investigating lexical items. As students at the beginner an...|$|R
40|$|Close {{reading is}} {{considered}} {{important in the}} criticism of English literature; however, in analyzing novels researchers should make a precise memo to record how and where certain words {{are used in the}} work. If we could use both corpus made up from electronic texts on the internet and <b>a</b> <b>concordancer,</b> it would make the above efforts much easier. In this essay Thomas Hardy's Tess of the d'Urbervilles was examined by using three tools of WordSmith, a concordance software, in comparison with George Eliot's Middlemarch and Sommerset Maugham's Of Human Bondage. WordSmith is a set of programs, which has three main tools called Wordlist, Keywords, and Concord. Wordlist as a tool makes {{a list of all the}} words in a text, set out in frequency order. With Keywords, the key words can be observed by comparing its wordlist with that of other reference text(s). Concord, <b>a</b> <b>concordancer,</b> can be used to plot any keyword or phrase in context to check what sort of wording it accompanies. With these tools we could get a lot of linguistic information about the text, which leads us deeper understanding of the novel. Especially, Concord gives useful information on wording about keywords of a novel. How to select keywords is up to each researcher; however, concordance lines can help us to gain a clear view about a theme. In this way <b>a</b> <b>concordancer</b> is <b>a</b> useful tool for literary criticism...|$|R
40|$|Current version: 1. 7 (released 22 March 2016) EEBOCorp <b>Concordancer</b> is <b>a</b> <b>concordancer</b> {{to query}} EEBOCorp 1. 0, a 525 million word corpus {{covering}} the period 1474 - 1700. EEBOCorp 1. 0 is a selective offline conversion of EEBO (eebo. chadwyck. com). This installation will only install the concordancer software. The corpus is {{available as a}} download on [URL] publishe...|$|R
40|$|Ontology {{design is}} a {{difficult}} task {{for which there is}} no agreed upon methodology. Texts of the domain can provide the words and terms of the domain, and support the abstraction of concepts and relationships which constitute the skeleton of the ontology. An environment to help the ontology designer has been built. Its main components are a term extractor, <b>a</b> <b>concordancer</b> and <b>an</b> ontology editor specially designed for multilingual treatment...|$|R
40|$|TerminoWeb is {{a web-based}} {{platform}} designed {{to find and}} explore specialized domain knowledge on the Web. An important aspect of this exploration is the discovery of domain-specific collocations on the Web and their presentation in <b>a</b> <b>concordancer</b> to provide contextual information. Such information is valuable to a translator or a language learner presented with a source text containing a specific terminology to be understood. The {{purpose of this article}} is to show a proof of concept that TerminoWeb, as <b>an</b> <b>integrated</b> platform, allows the user to extract terms from the source text and then automatically build a related specialized corpus from the Web in which collocations will be discovered to help the user understand the unknown specialized terms...|$|R
40|$|The study {{investigates the}} {{relative}} effectiveness of inductive and deductive approaches to learning collocations by using <b>a</b> <b>concordancer.</b> The relationship between cognitive approaches {{and levels of}} collocation difficulty is also examined. 81 second-year students from a senior high school in Taiwan participated in the study. The {{results showed that the}} inductive group improved significantly better than the deductive group in the performance of collocation learning and easy collocations seem to be more suitable in the concordancer learning setting. 1...|$|R
40|$|The {{study was}} {{designed}} to examine the effect of concordancing and scaffolding in developing learners’ knowledge of lexical collocations. Four tests were administered on two groups of Vietnamese learners of English to assess their ability in three aspects: (1) to identify (mis) collocations, (2) to provide answers with suggested options, and (3) to provide their own correction. Regarding the students’ ability to identify (mis) collocations and to provide answers with suggested options, the study revealed that concordancing significantly improved their score while scaffolding had no considerable impact. Concerning the students’ ability to provide their own correction, both concordancing and scaffolding were found to {{have a significant effect on}} the students’ performance. The study therefore discusses the importance of introducing <b>a</b> <b>concordancer</b> to promote learners’ independence in learning collocations. Scaffolding is also argued to be equally important especially when <b>a</b> <b>concordancer</b> is first introduced to students. Concordancing should be considered as a long-term task for learners in their development of collocation knowledge while scaffolding is temporary in its nature. Both concordancing and scaffolding can therefore be regarded as co-supporters in helping learners eventually take charge of learning collocations by themselves. ...|$|R
40|$|Abstract ⎯ The {{teaching}} of language for specific purposes has focused {{mainly on the}} analysis and use of authentic texts. At the Universidad Politécnica de Valencia, this has generally meant that teachers need to analyse engineering texts for pedagogical purposes. Analysis of such texts {{and the creation of}} exercises based on these texts are laborious. This paper describes a software application that automates the process of text analysis and incorporates an exercise creation environment. TextWorks is a software application consisting of four tools: <b>a</b> <b>concordancer,</b> <b>a</b> tagger, an exercise creation environment (ECE) and a virtual library for learning English (VLLE). TextWorks is novel in that concordancers and taggers are usually developed separately. The development of software for the automatic generation of language learning exercises is increasing but is not normally <b>integrated</b> into <b>a</b> multi-functional tool such as this one. As demand for more sophisticated language learning tools increases, more multi-functional tools such as TextWorks will be incorporated into courseware as part of a Networked Language Learning Environment. Index Terms ⎯ Concordancer, exercise creation environment, networked language learning, tagger, text analysis...|$|R
40|$|This {{research}} {{identifies the}} high frequencies of quantifiers in argumentative writing, {{which is a}} popular mode in English proficiency tests, bykeyword analyses and reveals their roles as rhetorical devices in argumentation by focusing on particular collocation in actual contexts. The results of small-scale discourse analyses show that different quantifiers carry different hidden messages under the surface, balancing degree of agreement or commitment. This study advocates a classroom activity of quantifiers by <b>a</b> <b>concordancer,</b> suggesting the importance of contextualization, and argues for different-level persuasive texts from TOEFL model essays and American LOCNESS, not only for test preparationbut also for familiarity with argumentation through reading...|$|R
40|$|In this paper, we {{describe}} WeBiText (www. webitext. ca) {{and how it}} is being used. WeBiText is <b>a</b> <b>concordancer</b> that allows translators to search in large, high-quality multilingual web sites, in order to find solutions to translation problems. After a quick overview of the system, we present results from an analysis of its logs, which provides a picture of how the tool is being used and how well it performs. We show that it is mostly used to find solutions for short, two or three word translation problems. The system produces at least one hit for 58 % of the queries, and hits from at least five different web pages in 41 % of cases. We show that 36 % of the queries correspond to specialized language problems, which is much higher than what was previously reported for <b>a</b> similar <b>concordancer</b> based on the Canadian Hansard (TransSearch). We also provide a back of the envelope calculation of the current economic impact of the tool, which we estimate at $ 1 million per year, and growing rapidly. Peer reviewed: YesNRC publication: Ye...|$|R
40|$|This paper 1 {{reports on}} a {{multi-media}} web-based CALL program designed to teach Arabic to foreign learners. It discusses several important theoretical and practical issues related to language pedagogy, such as the variety of Arabic to teach, the problem of the, types of text, and the representation of Arabic. It also discusses the issue of incorporating <b>a</b> <b>concordancer</b> and corpus into a teaching environment. An important and unique feature {{of the program is}} that it is designed and implemented by linguists with many years of experience in teaching linguistics and Arabic as a foreign language, and takes into account the latest methodological and pedagogical advances in the field rather than merely transferring existing materials into the electronic format. 1...|$|R
40|$|The paper {{presents}} a gold-standard reference corpus of historical Slovene containing 1, 000 sampled pages from over 80 texts, which were, {{for the most}} part, written between 1750 – 1900. Each page of the transcription has an associated facsimile and {{the words in the}} texts have been manually annotated with their modern-day equivalent, lemma and part-of-speech. The paper presents the structure of the text collection, the sampling procedure, annotation process and encoding of the corpus. The corpus is meant to facilitate HLT research and enable corpus based diachronic studies for historical Slovene. The corpus is encoded according to the Text Encoding Initiative Guidelines (TEI P 5), is available via <b>a</b> <b>concordancer</b> and for download fro...|$|R
40|$|International audienceThis {{presentation}} {{describes a}} trilingual corpus of three endangered languages of the Kiranti group (Tibeto-Burman family) from Eastern Nepal. The languages, which are exclusively oral, share a rich mythology, {{and it is}} thus possible to build a corpus of the same native narrative material in the three languages. The segments of similar semantic content are tagged with a "similarity" label to identify correspondences among the three language versions of the story. An interface has been developed to allow these similarities to be viewed together, {{in order to allow}} make possible comparison of the different lexical and morphosyntactic features of each language. <b>A</b> <b>concordancer</b> makes it possible to see the various occurrences of words or glosses, and to further compare and contrast the languages...|$|R
40|$|This study {{analyses}} {{the blogs}} of thirty new {{students as they}} leave home and begin their university lives. Inspired {{by the work of}} social psychologist James Pennebaker, who uses his software LIWC (LinguisticInquiryandWordCount) to track changes in word use and map them onto psychological correlates, this thesis seeks partly to understand the social and psychological impact of the student transition, and partly to investigate the methodological implications of a word-count program such as LIWC. A closed-class keywords analysis is used to bolster and complement the LIWC findings, and the results are examined qualitatively with <b>a</b> <b>concordancer.</b> It is found that the students display a number of linguistic changes following the move to university, and even some beforehand; overall, they appear to become more self-aware, more socially involved and more tentative in their writing...|$|R
40|$|Treball Final de Màster Universitari en Llengua Anglesa per al Comerç Internacional. Codi: SAR 016. Curs: 2013 / 2014 The aim of {{this paper}} is to analyse the {{language}} used by Porcelanosa Grupo in its UK web-page sections “About us” and “Companies” from a general perspective to determine several core values of the brand image. The method employed to conduct the linguistic study includes corpus tools such as <b>a</b> <b>concordancer</b> to analyse the results provided by the software through the lens of evaluative language. The focus of the study is the section “About us”. The text that is object of study can be found in the appendix. The analysis shown in this master thesis intends to evidence the relationship between the language used by Porcelanosa Grupo on their online resources and its marketing strategy...|$|R
40|$|Part of {{understanding}} {{a foreign language}} text involves the ability to solve lexical ambiguities that are {{not found in the}} first language. Traditionally, it has been claimed that the resolution of lexical ambiguity is done through schema activation. The hypothesis investigated here is that collocation may be a more dependable source than the reader’s previous knowledge. Twenty ambiguous words were selected, disambiguated through rules based on collocation, and then tested with <b>a</b> <b>concordancer,</b> using <b>an</b> English language corpus of 20, 000, 000 words of expository text. The results showed that more than 94 % of the ambiguities were solved by using syntactic and semantic restrictions between the ambiguous word and a related disambiguating word that co-occurred in the same sentence. The interpretation offered for these results is that collocation replaces with many advantages the use of encyclopedic knowledge to solve lexical ambiguities...|$|R
40|$|Diachronic Corpus of Early Written Latvian Texts (16 - 18 th c.). > 1 mill. running words (work is on-going). The {{main data}} are ecclesiastical texts, secular texts (laws, fiction) and some first bilingual (Latvian-German) dictionaries. <b>A</b> KWIC-based <b>concordancer,</b> {{as well as}} inverse vocabulary, {{frequency}} lists and word lists are provided. Some source facsimiles are available...|$|R
40|$|According to Rothery and Stenglin (2000), {{one of the}} {{objectives}} of literary education is to provide language students with strategies which enable them to articulate opinions containing emotional, ethic and/or aesthetic values. The present article reports an investigation on how first-year undergraduates at a public university in Rio de Janeiro articulate appraisals in their mother tongue {{in terms of the}} aesthetic quality of poems. To this end, the work describes data collection using focus group discussions (cf. BARBOUR; KITZINGER, 1999) and the analysis of such corpus by means of Martin and Rose’s (2003) system, which focuses on the language of Attitude. With the help of <b>a</b> <b>concordancer,</b> the most frequent lexical items and the clusters they formed are extracted and analyzed. Finally, the article discusses how far the research subjects are capable of articulating the types of aesthetic opinions referred to by Rothery and Stenglin (2000) ...|$|R
40|$|This article {{presents}} {{the findings of}} a corpus based research that investigated Malaysian ESL learners’ use of modals in two written tasks. The aim {{of the study was to}} investigate the distribution and functions of modals used in the students’ writing. The research design comprised a qualitative technique through discourse analysis supplemented with some descriptive statistics derived from <b>a</b> <b>concordancer</b> which identified modals used by the students at two different levels. The findings showed that the preferred modals for the two levels are modals can, will and could which were used to express ability and certainty. Modals of probability/possibility showed lower frequencies of use in the writing. Also, students at the lower level were less competent in using past form modals as compared to those at the higher level. This study indicates that the students were able to perceive the conceptual meaning of each modal and their communicative function. </p...|$|R
40|$|The pedagogic {{value of}} {{electronic}} text analysis and retrieval {{systems in the}} fields of literary studies and language teaching {{is becoming more and more}} common with the availability of good easy-to-use software and sources of machine readable text. Once students are familiar with this tool, they may use it as readily as a dictionary to find examples of usage from their chosen corpus of text. Students' use of <b>a</b> <b>concordancer</b> involves more than looking up facts, a single consultation has a tendency to raise other questions, requiring further concordances. This leads to a kind of conjectural learning. Electronic text analysis offers the student the opportunity to take control of his/her own learning by means of purposeful interaction with text. The higher level skills of inferencing, connecting, interpreting and evaluating are brought into play and informal acquisition is facilitated in addition to selective attention to linguistic or literary features...|$|R
40|$|The JOS {{language}} {{resources are}} meant to facilitate developments of HLT and corpus linguistics for the Slovene language and consist of the morphosyntactic specifications, defining the Slovene morphosyntactic features and tagset; two annotated corpora (jos 100 k and jos 1 M); and two web services (<b>a</b> <b>concordancer</b> and text annotation tool). The paper introduces these components, and concentrates on jos 100 k, a 100, 000 word sampled balanced monolingual Slovene corpus, manually annotated for three levels of linguistic description. On the morphosyntactic level, each word is annotated with its morphosyntactic description and lemma; on the syntactic level the sentences are annotated with dependency links; on the semantic level, all the occurrences of 100 top nouns in the corpus are annotated with their wordnet synset from the Slovene semantic lexicon sloWNet. The JOS corpora and specifications have a standardised encoding (Text Encoding Initiative Guidelines TEI P 5) and are available for research from [URL] / under the Creative Commons licence. 1...|$|R
40|$|Plurilingual {{teaching}} and learning of Romance languages exploits the similarities between these languages to teach them contrastively and to raise the language awareness of the learner. Several European projects have been devoted to plurilingual {{teaching and}} learning of Romance languages. The materials developed in these projects do not involve Natural Language Processing (NLP) capabilities and almost exclusively focus on receptive skills. The research goal of my Ph. D. dissertation was the design, development, implementation and evaluation of an interactive plurilingual ICALL (Intelligent Computer-Assisted Language Learning) software system (ESPRIT) for contrastive learning of French, Spanish and Italian aimed at advanced learners. I investigated how techniques from NLP enhance the plurilingual {{teaching and learning}} of these languages. The ESPRIT toolset comprises dictionary tools, <b>a</b> <b>concordancer,</b> <b>an</b> input analysis and feedback module, custom-made animated grammar presentations and an authoring tool for animated text. Dictionary tools provide useful information on unrestricted texts. The concordancer gives extensive information about how a language term is used in different contexts. The input analysis and feedback module dynamically provides precise feedback on restricted learner input up to paragraph level. Custom-made animated grammar presentations and learning materials created with the animation authoring tool visualise contrastive grammatical properties and processes. ESPRIT represents an interactive and flexible learning environment and is designed for autonomous learning. Formative and summative evaluation processes provided learner assessment data of different components of ESPRIT. A web-based databasedriven evaluation platform developed for ESPRIT can easily be adapted to other evaluation projects...|$|R
40|$|In {{the last}} ten years, more and more {{attention}} has been paid to the importance of raising the language awareness of language teachers. This is an area in which corpus linguistics has a unique contribution to make. With the help of <b>a</b> <b>concordancer,</b> linguistic features that may be overlooked can be made salient and intertextual information that is implicit in a single text can be made explicit. This paper reports on a study of how corpus evidence was used to address questions sent by English language teachers in Hong Kong to a dedicated website. More than one thousand grammar questions sent to the website over a period of eight years were examined. Three types of most frequently asked questions were identified. The paper discusses how corpus evidence was used to help teachers to notice features and patterns which have escaped their attention and to question long-standing assumptions and misconceptions. It shows how subsequent interrogation of corpus data stimulated by teachers' question often led to new insights into linguistic patterns and language use. © John Benjamins Publishing Company. link_to_subscribed_fulltex...|$|R
40|$|This study {{investigated}} use of modals in two written tasks by Form 4 Malaysian secondary school ESL learners. The {{aim was to}} investigate the use of English modals at the syntactic and semantic levels from data made available by the EMAS Corpus. Â Â  The research design comprised a qualitative technique through discourse analysis supplemented with some descriptive statistics derived from <b>a</b> <b>concordancer.</b> The concordancer identified modals used by the students at the form 4 level. The research findings showed that two modals not stipulated in the syllabus, would and shall, were also found in the narrative compositions. The secondary school English language syllabus indicated varied meanings to the modals, but it was found that students repetitively used {{only a few of the}} same modals for these various functions. It was concluded that there were some inadequacies in the syllabus that led to the problems encountered by ESL students. Â  In order to circumvent the problematic items identified in the study, and to further improve the teaching and learning of modal auxiliaries among ESL learners, several recommendations are proposed...|$|R
40|$|This paper {{describes}} CATEAP software, {{which has}} been developed, {{and continues to be}} developed by Jon Mills at the University of Luton. CATEAP provides all the materials for the writing component of the Academic English and Study Skills module for first year undergraduate students whose first language is not English. CATEAP aims to explain and provide practice in a number of language functions that are employed in academic discourse and provides approximately 40 hours of writing activities. CATEAP is for classroom use with a teacher present and lock-step is necessary at various points during each lesson. Each lesson incorporates a variety of tasks and task types including pages of exposition, drills, short essay writing, peer critiquing and use of <b>a</b> <b>concordancer.</b> Peer critiquing of essays takes place over the intra-net with the students adopting pseudonyms. Students report that they like the anonymity that this virtual classroom provides. The role of the teacher is concerned with managing the virtual classroom, allowing students to sometimes work at their own pace and at other times focussing the entire class in lock-step...|$|R
40|$|Within {{critical}} {{discourse analysis}} (CDA), {{there has been}} ongoing interest in how texts position readers to view social and political events in a particular way. Traditionally, analysts have not examined how positioning is built up dynamically as a reader progresses through a text by tracing how earlier parts of a text are likely to affect subsequent interpretation. This article shows how APPRAISAL tools (as developed within the systemic functional tradition) can be usefully employed within CDA to do this. Using a story from The Sun newspaper website as illustration, we show how due to a cumulative groove of semantic patterning, the reader is dynamically positioned to interpret a seemingly neutral statement {{at the end of}} the story in a negative way. We show how potential analyst 'over-interpretation' can be checked through the use of <b>a</b> <b>concordancer.</b> We also demonstrate how a specialised corpus can go some way to grounding the APPRAISAL analysis in terms of the context of the target readership and the meanings they are routinely exposed to. This we argue facilitates an explanatory critique of the way in which a text is likely to be understood by its target readership in relation to the socio-political-economic context...|$|R
40|$|To better {{understand}} the promising effects of data-driven learning (DDL) on language learning processes and outcomes, this study explored DDL learning events enabled by the Research Writing Tutor (RWT), a web-based platform that contains: an English language corpus annotated to enhance rhetorical input; <b>a</b> <b>concordancer</b> searchable for rhetorical functions; and an automated writing evaluation engine that generates rhetorical feedback. Guided by current approaches to teaching academic writing (Lea 2 ̆ 6 Street, 1998; Lillis, 2001; Swales, 2004) and by Bereiter and Scardamalia’s (1987) knowledge-telling/knowledge-transformation model, {{we set out to}} examine whether and how direct corpus uses afforded by RWT impact novice native and non-native writers’ genre learning and writing improvement. In an embedded mixed-methods design, written responses to DDL tasks and writing progress from first to last drafts were recorded from 23 graduate students in separate onesemester courses at a US university. The qualitative and quantitative data sets were used for withinstudent, within-group, and between-group comparisons, the two independent variables for the latter being course section and language background. Our findings suggest that exploiting technologymediated corpora can foster novice writers’ exploration and, application, and production of genre conventions, enhancing development of rhetorical, formal, and procedural aspects of genre knowledge...|$|R
40|$|The paper {{analyses}} selected {{aspects of}} the codeswitching behaviour in a spoken corpus of the English of 326 people, all of them mother-tongue speakers of Xhosa (a local African language in South Africa), and all of whom would see themselves as Xhosa/English bilinguals. The corpus comprises approximately 550, 000 transcribed words of spontaneous, relaxed, oral discourse in English between pairs of Xhosa-speaking interlocutors, discussing {{a wide range of}} topics. While the usual pattern in bilingual speech is to use the L 1 as matrix language and the L 2 as embedded language, in this corpus the opposite is the case, as interlocutors were interviewed in English (the L 2). The corpus therefore offers a ‘mirror image’, in a sense, of normal codeswitching behaviour. Using Wordsmith (<b>a</b> <b>concordancer</b> programme), all incidences of codeswitching into Xhosa during these conversations were identified and analysed in an effort to reveal underlying patterns. Examination of the amount and nature of codeswitching in the corpus promised to throw some light {{on the extent to which}} participants are genuinely bilingual, in terms of their ability to converse comfortably in English. doi: 10. 2167 /beb 382. ...|$|R
40|$|AntConc is a freeware, multi-platform, {{multi-purpose}} corpus analysis toolkit, {{designed specifically}} {{for use in the}} classroom. It hosts a comprehensive set of tools including <b>a</b> powerful <b>concordancer,</b> word and keyword frequency generators, tools for cluster and lexical bundle analysis, and a word distribution plot. In this paper, I will describe each of these tools, and explain their value to learners. Then, I will discuss the current limitations of the software, before explaining how I hope it will be improved in future releases...|$|R
40|$|This paper {{presents}} {{a tool for}} extracting multi-word expressions from corpora in Modern Greek, which is used together with <b>a</b> parallel <b>concordancer</b> to augment the lexicon of a rule-based machinetranslation system. The tool {{is part of a}} larger extraction system that relies, in turn, on a multilingual parser developed over the past decade in our laboratory. The paper reviews the various NLP modules and resources which enable the retrieval of Greek multi-word expressions and their translations: the Greek parser, its lexical database, the extraction and concordancing system. ...|$|R
