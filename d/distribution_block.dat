31|469|Public
50|$|Tubing {{is simply}} {{the means by which}} air power is {{transferred}} through the circuit. Tubing can connect to a switch, air tank, T-junction, cylinder, pump, <b>distribution</b> <b>block,</b> or flex-hose.|$|E
50|$|In 1989, the LEGO {{pneumatic}} line was revamped, {{and a new}} cylinder and pump piece were introduced. The old cylinders and pumps were discontinued. The chief {{difference is that the}} new cylinder had two input valves now, which allowed both pushing and pulling without needing complex circuits involving the <b>distribution</b> <b>block</b> piece. The Generation 2 cylinders also had metal rods so that they more closely resembled real hydraulic cylinders.|$|E
5000|$|The first {{generation}} of LEGO Pneumatics ran from 1984 through 1988. This generation is characterised by single port pneumatic cylinders and the more complex plumbing including a three port <b>distribution</b> <b>block</b> with a pressure and vacuum outlet port. These pressure and vacuum lines ran to a switch to provide pressure for extension or vacuum for retraction of the pneumatic cylinders. These are often falsely compared to single acting hydraulic cylinders that require gravity to retract. The difference is that these units retract on the application of vacuum.|$|E
40|$|This article {{presents}} various data redistribution methods for block-partitioned linear algebra algorithms operating on dense matrices that are distributed in a block-cyclic fashion. Because the algorithmic partitioning unit and the <b>distribution</b> <b>blocking</b> factor {{are most often}} chosen to be equal, severe alignment restrictions are induced on the operands, and optimal values with respect to performance are architecture dependent. The techniques {{presented in this paper}} redistribute data "on the fly," so that the user's data <b>distribution</b> <b>blocking</b> factor becomes independent from the architecture dependent algorithmic partitioning. These techniques are applied to the matrix-matrix multiplication operation. A performance analysis along with experimental results shows that alignment restrictions can then be removed and that high performance can be maintained across platforms independently from the user's data <b>distribution</b> <b>blocking</b> factor...|$|R
40|$|An {{approximate}} disaggregation [...] aggregation {{technique for}} finite state Markov chains {{is applied to}} queueing networks with different service disciplines, Coxian service and interarrival time <b>distributions,</b> <b>blocking,</b> and synchronization. Large Models with many states can be solved, so large that the state probabilities could neither be stored nor calculated in any computer. Accurate approximations are obtained with different degrees of accuracy, depending on the investigated computational effort. INTRODUCTION Queueing networks are widely used in the stochastic modeling of computer, communication, and manufacturing systems. For the restricted class of separable queueing networks, efficient evaluation algorithms are known but if the models take into account things like different service disciplines, general service and interarrival time <b>distributions,</b> <b>blocking,</b> or synchronization, the analysis is expensive or even impossible due to computational complexity. In order to obtain performance m [...] ...|$|R
40|$|In {{a serial}} {{computational}} environment, transportable efficiency {{is the essential}} motivation for developing blocking strategies and block-partitioned algorithms. An algorithmic blocking factor adjusts the granularity of the subtasks to maximize {{the efficiency of the}} hardware resources. In a distributed-memory environment, load balance is the essential motivation for distributing array entries over a collection of processes according to the block cyclic decomposition scheme. A <b>distribution</b> <b>blocking</b> factor is used to partition an array into blocks that are then mapped onto the processes. Optimal values of the algorithmic and <b>distribution</b> <b>blocking</b> factors often differ for a given algorithm and target architecture. Despite this fact, most of the parallel algorithms proposed in the literature assume the values of these blocking factors to be identical. This feature limits the flexibility and ease of use of such algorithms. When these blocking factors differ, methods are necessary to redist [...] ...|$|R
50|$|The forward fairing {{measured}} 2 ft {{long and}} included the Reaction Control System (RCS) computer, umbilical connection, power <b>distribution</b> <b>block,</b> ECS controller, separation controller, components for the high-gain antenna, and eight EPS radiators. The umbilical housing contained the main electrical and plumbing {{connections to the}} CM. The fairing externally contained a retractable forward-facing spotlight; an EVA floodlight to aid the Command Module pilot in SIM film retrieval; and a flashing rendezvous beacon visible from 54 nmi km away as a navigation aid for rendezvous with the Lunar Module (LM).|$|E
50|$|A 66 {{block is}} a type of punchdown block used to connect sets of wires in a {{telephone}} system. They have been manufactured in three sizes, A, B, and M. A and B have six clips in each row while M has only 4. The A blocks spaced the rows farther apart, and has been obsolete for many years. The B style is used mainly in distribution panels where several destinations (often 1A2 key telephones) need to connect to the same source. The M blocks are often used to connect a single instrument to such a <b>distribution</b> <b>block.</b> 66 blocks are designed to terminate 22 through 26 AWG solid copper wire. The 66 series connecting block, introduced in the Bell System in 1962, was the first terminating device with insulation displacement connector technology. The term 66 block reflects its Western Electric model number.|$|E
30|$|In the {{gas turbine}} model, the power {{limitation}} block provides the physical restriction on turbine response and the excessive firing during ramping. The power <b>distribution</b> <b>block</b> represents the physical characteristics of fuel flow, air flow and allowable temperature. While, gas turbine dynamics block is included {{to represent the}} physical dynamics of combustion chambers and air compressor.|$|E
40|$|Abstract:- Traditional Voice over Internet Protocol (VoIP) {{technique}} {{is based on}} client/server architecture. In this paper, we proposed a VoIP architecture for Ad-hoc network that provides users {{to communicate with each}} other directly through embedded pseudo SIP server. This architecture will establish a distributed VoIP system. The performance analysis of signal transmission delay will show the advantage of the proposed distributed VoIP system compared with the standalone infrastructure. Key-Words:- VoIP, pseudo SIP server, <b>distribution,</b> <b>blocking</b> probability...|$|R
40|$|Abstract This paper {{studies the}} MGeo/MGeo/ 1 /N queue {{with a single}} server, batch Poisson arrivals and service {{completions}} and finite capcacity. The distri-bution {{of the number of}} customers in the queue at pre- and post-arrival epochs is analysed and closed form expressions for performance distributions, such as steady state queue length <b>distribution,</b> <b>blocking</b> probability and waiting time distribution are derived. Moreover, information theoretic interpretations based on the principles of Maximum Entropy(ME) and Min-imum Relative Entropy (MRE) are given...|$|R
40|$|The {{household}} {{electrical appliance}} retail chain enterprises in china develop rapidly, whilst the basic logistics facilities lagged behind. The slow development of logistics <b>distribution</b> <b>blocks</b> the {{further development of}} household electrical appliance sale and chain management. Therefore, effective measures shall be taken, according to the current situation {{of the development of}} logistics distribution for household electrical appliance retail chain management, so as to improve logistics distribution system so that the rapid growth of large household retail chain enterprises can be endowed with logistics system guarantee...|$|R
40|$|Many D 0 Run II {{detectors}} {{currently in}} production rely on scintillating tile and fiber technology. In general, light from active scintillating elements or calibration signals is {{transported to the}} photodetection system along optical fiber pathways. Building a tile/fiber detector requires very conscientious technical support and {{a high degree of}} quality control; polishing fibers {{is one of the most}} delicate of tasks involved. This note compares three methods used to polish Hewlett Packard HFBR-RUS 500 fiber. This type of fiber is expected to be used in both the Muon Scintillator Counters (MSC) and the InterCryostat Detector (ICD) calibration systems to transport light from the LED <b>distribution</b> <b>block</b> to the photomultiplier tubes...|$|E
40|$|Receive path {{includes}} dual 10 -bit analog-to-digital converters {{with internal}} or external reference, 50 MSPS and 80 MSPS versions Transmit path includes dual 10 -bit, 200 MSPS digital-toanalog converters with 1 ×, 2 ×, or 4 × interpolation and programmable gain control Internal clock <b>distribution</b> <b>block</b> includes a programmable phase-locked loop and timing generation circuitry, allowing single-reference clock operation 20 -pin flexible I/O data interface allows various interleaved or noninterleaved data transfers in half-duplex mode and interleaved data transfers in full-duplex mode Configurable through register programmability or optionally limited programmability through mode pins Independent Rx and Tx power-down control pins 64 -lead LFCSP package (9 mm × 9 mm footprint) 3 configurable auxiliary converter pin...|$|E
40|$|Consider {{a linear}} {{regression}} model with unknown regression parameters # 0 and independent errors of unknown <b>distribution.</b> <b>Block</b> the observations into q groups whose independent variables {{have a common}} value and measure the homogeneity of the blocks of residuals by a Cramer-von Mises q-sample statistic Tq (#). This statistic is designed so that its expected value {{as a function of}} the chosen regression parameter # has a minimum value of zero precisely at the true value # 0. The minimizer # of Tq (#) overall# is shown to be a consistent estimate of # 0. It is also shown that the bootstrap distribution of Tq (# 0) can be used to do a lack of fit test of the regression model and to construct a confidence region for # 0...|$|E
40|$|Abstract. In {{a serial}} {{computational}} environment, transportable e ciency {{is the essential}} motivation for developing blocking strategies and block-partitioned algorithms. An algorithmic blocking factor adjusts the granularity of the subtasks to maximize the e ciency of the hardware resources. In a distributed-memory environment, load balance is the essential motivation for distributing array entries over a collection of processes according to the block cyclic decomposition scheme. A <b>distribution</b> <b>blocking</b> factor is used to partition an array into blocks that are then mapped onto the processes. Optimal values of the algorithmic and <b>distribution</b> <b>blocking</b> factors often di er for a given algorithm and target architecture. Despite this fact, most of the parallel algorithms proposed in the literature assume the values of these blocking factors to be identical. This feature limits the exibility {{and ease of use}} of such algorithms. When these blocking factors di er, methods are necessary to redistribute some data into the appropriate algorithmic form. This paper presents and discusses such algorithmic redistribution methods for the block cyclic decomposition scheme. Algorithmic redistribution methods attempt to reorganize logically the computations and communications within an algorithmic context. In order to derive such methods, some properties of the <b>block</b> cyclic data <b>distribution</b> are rst exhibited. Various algorithmic redistribution methods ar...|$|R
50|$|Cross-connect wire jumpers, {{consisting}} of three twisted pairs were installed between these blocks {{and the larger}} <b>distribution</b> connecting <b>blocks</b> within the KSU for each line provided to the telephone set.|$|R
5000|$|... #Subtitle level 2: Purchase {{with the}} intent to <b>block</b> <b>distribution</b> ...|$|R
40|$|Dense {{linear algebra}} {{computations}} require {{the technique of}} `block-partitioned algorithms' for their efficient implementation on memoryhierarchy multi-processors. Most existing studies and libraries for this purpose, for example ScaLAPACK, assume that the block or panel width ! for these algorithms must {{be the same as}} the matrix <b>distribution</b> <b>block</b> size r. We present a project in progress to extend ScaLAPACK using the `distributed panels' technique, ie. to allow ! ? r, which has the twofold advantages of improving performance for memoryhierarchy multiprocessors and yielding a simplified user interface. A key element of the project is a general Distributed BLAS implementation, which has been developed for primarily the Fujitsu AP series of multiprocessors but is now fully portable. Other key components are versions of the BLACS and BLACS libraries to achieve high performance cell computation and communication respectively on the required target multiprocessor architectures. Preliminary ex [...] ...|$|E
40|$|Dense {{linear algebra}} {{computations}} such as matrix factorization require {{the technique of}} `blockpartitioned algorithms' for their efficient implementation on memory-hierarchy processors. For scalar-based distributed memory multiprocessors, the register, cache and off-processor memory levels of the memory hierarchy all affect the optimal block-partition size for such algorithms. Most studies on matrix factorization and similar algorithms have assumed that the block-partition size or panel width for the algorithm, !, {{to be the same}} as the matrix <b>distribution</b> <b>block</b> size, r, where a rectangular block-cyclic matrix distribution is being employed. Here the choice of ! = r is essentially determined by the off-processor memory level of the memory hierarchy, with the value of ! being a tradeoff between communication startup overhead and load balance considerations. In this paper, we re-examine this assumption in the context of LU and Cholesky factorization of block-cyclic distributed matrices on [...] ...|$|E
40|$|In {{this study}} we {{consider}} 2 D seismic lithology/fluid inversion constrained by rock physics depth trends and a prior lithology/fluid Markov random field. A stochastic relation from porosity and lithology/fluid to seismic observations is established. The inversion is done in a Bayesian framework with an approximate posterior <b>distribution.</b> <b>Block</b> Gibbs samplers are used to estimate the approximate posterior distribution. Two different inversion algorithms are established, one {{with the support of}} well observations and one without. Both inversion algorithms are tested on a synthetic reservoir and the algorithm with well observations is also tested on a data set from the North Sea. The classification results with both algorithms are good. Without the support of well observations it is problematic to estimate the level of the porosity trends, however the classification results are approximately translation invariant with respect to porosity trends. </p...|$|E
40|$|The {{clinical}} {{presentation of a}} subarachnoid block (SAB) is dependent upon the intrathecal spread of local anesthetic (LA). Intrathecal distribution depends on the chemical and physical characteristics of LA, puncture site, technique used, patient anatomical characteristics and hydrodynamic properties of cerebrospinal fluid. We tried {{to determine whether a}} combined glucose/LA solution can render a clinically significant difference in sensory <b>block</b> <b>distribution</b> and motor <b>block</b> intensity. This was a controlled, randomized and double blinded study. The surgical procedures were stripping of the great or small saphenous vein and extirpation of remaining varicose veins. The study included 110 patients distributed into two groups: Hyperbaric (7. 5 mg levobupivacaine (1. 5 ml 0. 5 % Chirocaine®) + 50 mg Fentanyl (0. 5 ml Fentanil®) and 1 ml 10 % glucose (Pliva)) vs. Hypobaric (7. 5 mg levobupivacaine (1. 5 ml 0. 5 % Chirocaine®) + 50 mg Fentanyl (0. 5 ml Fentanil®) and 1 ml 0. 9 % NaCl (Pliva, Zagreb)) adding to a total volume of 3. 5 ml per solution. Spinal puncture was at L 3 -L 4 level. Spinal <b>block</b> <b>distribution</b> was assessed in five minute intervals and intensity of motor block was assessed according to the modified Bromage scale. Pain was assessed with the Visual Analogue Scale. A statistically significant difference in sensory <b>block</b> <b>distribution,</b> motor <b>block</b> intensity and recovery time was established between hyperbaric and hypobaric solutions. By increasing the specific density of anesthetic solution, a higher sensory block, with lesser variability, a diminished influence of Body Mass Index, decreased motor block intensity and faster recovery time may be achieved...|$|R
40|$|Among the {{existing}} P 2 P systems for content distribution, BitTorrent (BT) {{is the most}} popular one which has attracted keen attentions from both industrial and academic forces in recent years. Its superior performance is due to the multipart downloading scheme by dividing the large file into thousands of small blocks to enable the cooperative down-loading among participants. Since transmissions are provoked by interested blocks only, the <b>block</b> <b>distribution</b> will seriously affects the performance of the system, i. e., robustness and throughput. As a result, how to manage the circulation of blocks is important both theoretically and practically. BT leverages on the Local Rarest First scheme to pursue the even <b>distribution</b> of <b>blocks</b> to help peers locate what they need easily. Surprisingly, how good is its performance with heterogenous networks has never received research attention before and this motivates our work. In this study, we carried out simulations to investigate the evolution of <b>block</b> <b>distribution</b> in BT. We find that the <b>block</b> <b>distribution</b> is far from optimal in terms of block frequency (with some blocks dominating the network and some becoming extinct nearly) and topology (with same blocks tending to conglomerate). We also propose a simple source coding mechanism to achieve a BT like network with much improved performance in this view. © 2006 ACM...|$|R
40|$|Crater {{frequencies}} and morphologies (Moore) [...] <b>Distribution</b> of <b>blocks</b> on {{the lunar surface}} (Moore) Increased travel distance due to craters and other obstacles on the Moon (Moore) This report is preliminary {{and has not been}} edited or reviewed for conformity with U. S. Geological Survey standards and nomenclature...|$|R
40|$|In {{this paper}} {{we present a}} method to obtain a set of {{candidate}} distributions for a program fragment. These candidate distributions can then be used to obtain a dynamic data distribution for the whole program using the method outlined in this paper. Our algorithms first find an inter-axis alignment for the arrays in the <b>distribution</b> <b>block.</b> Using this axis alignment a data distribution is obtained for these arrays. The algorithms presented here aim to obtain an alignment-distribution that minimizes data movement between processors with minimal loss of parallelism. We have presented experimental results obtained by executing these algorithms on several programs. 1 Introduction Parallel processing is increasingly being accepted as a viable approach to solve computationally intensive applications in the sciences and in engineering. Research in parallel processing systems {{over the last decade}} has resulted in the development of systems with widely This research is supported by the Boeing [...] ...|$|E
40|$|Given an {{implementation}} of Distributed BLAS Level 3 kernels, the parallelization of dense linear algebra libraries such as LAPACK {{can be easily}} achieved. In this paper, we briefly describe the implementation and performance on the AP 1000 of Distributed BLAS Level 3 for the rectangular r Θ s block-cyclic matrix distribution. Then, the parallelization of the central matrix factorization and the tridiagonal reduction routines from LAPACK are described, where the algorithmic `blocking factor' w can be independent of the matrix <b>distribution</b> <b>block</b> size r. For scalar-based MIMD parallel processors with relatively low communication startup costs, such as the AP 1000, it is found the optimum r and w generally satisfies w ?? r with r ß 1, differing from results published for vector-based parallel processors. 1 Introduction LAPACK [2] is an extensive set of linear algebra routines designed for portability and performance on memory hierarchy processors, vector processors and shared memory pa [...] ...|$|E
40|$|Guanidinium and acetamidinium, when {{added to}} the bathing {{solution}} in concentrations of approximately 0. 1 M, cause brief blocks in the single channel potassium currents from channels formed in planar lipid bilayers by gramicidin A. Single channel lifetimes are not affected indicating that the channel structure is not modified by the blockers. Guanidinium block durations and interblock times are approximately exponential in <b>distribution.</b> <b>Block</b> frequencies increase with guanidinium concentration whereas block durations are unaffected. Increases in membrane potential cause an increase in block frequency as expected for a positively charged blocker but a decrease in block duration suggesting that the block is relieved when the blocker passes through the channel. At low pH, urea, formamide, and acetamide cause similar blocks suggesting that the protonated species of these molecules also block. Arginine and several amines do not block. This indicates that only iminium ions which are small enough to enter the channel can cause blocks in gramicidin channels...|$|E
40|$|In this paper, we analyze {{a finite}} buffer {{queueing}} model with two servers and two nonpreemptive priority service classes. The arrival streams are independent Poisson processes, {{and the service}} times of the two classes are exponentially distributed with different means. One of the two servers is reserved exclusively for one class with high priority and the other server serves the two classes according to a nonpreemptive priority service schedule. For the model, we describe its dynamic behavior by a four-dimensional continuous-time Markov process. Applying recursive approaches we present the explicit representation for the steady-state distribution of this Markov process. Then, we calculate the Laplace-Stieltjes Transform and the steady-state distribution of the actual waiting times of two classes of customers. We also give some numerical comparison results with other queueing models. Two-class and two-server queueing model Nonpreemptive priority Waiting time Steady-state <b>distribution</b> <b>Blocking</b> probability...|$|R
40|$|It {{has been}} proven that the batch renewal process is the least biased choice of traffic process given the {{infinite}} sets of measures of the traffic correlation, (i. e. indices of dispersion, covariances or correlation functions) in the discrete time domain. The same conclusion is expected to hold in the continuous time domain. That motivates the study and comparison of similar queues, fed by batch renewal traffic, in both domains. In this paper, performance distributions are obtained for the GI G /M/ 1 /N queue in continuous time and compared with the corresponding results for the GI G /Geo/ 1 /N queue in discrete time. The expressions for queue length <b>distribution,</b> <b>blocking</b> probability and waiting time distributions are derived. They {{can be used to}} assess the adverse effect on buffer performance that is induced by traffic correlation...|$|R
50|$|There {{are several}} methods used for {{detecting}} and measuring particle size or size <b>distribution</b> — light <b>blocking</b> (obscuration), light scattering, Coulter principle and direct imaging.|$|R
40|$|The {{thesis is}} focused on extreme value {{distributions}} and their applications. Firstly, basics of the extreme value theory for one-dimensional observations are summarized. Using the limit theorem for distribution of maximum, three extreme value distributions (Gumbel, Fréchet, Weibull) are introduced and their domains of attraction are described. Two models for parametric functions estimation based on the generalized extreme value <b>distribution</b> (<b>block</b> maxima model) and the generalized Pareto distribution (threshold model) are introduced. Parameters estimates of these distributions are derived using the method of maximum likelihood and the probability weighted moment method. Described methods are used for analysis of the rainfall data in the Brno Region. Further {{attention is paid to}} Gumbel class of distributions, which is frequently used in practice. Methods for statistical inference of multiply left-censored samples from exponential and Weibull distribution considering the type I censoring are developed and subsequently used in the analysis of synthetic musk compounds concentrations. The last part of the thesis deals with the extreme value theory for two-dimensional observations. Demonstrational software for the extreme value distributions was developed as a part of this thesis...|$|E
40|$|Distance from an origin to a {{destination}} {{has long been}} considered {{a major factor in}} determining degrees of accessibility. For this reason, distance to Head Start sites for families in need of their services was examined. Semcac, the Head Start grantee for seven counties in southeastern Minnesota, provided the addresses of Head Start applicants and participants from the past three years in Winona County. These addresses were geocoded for analysis. Distance to the nearest Head Start facility was determined using ESRI Network Analyst for the student origins. Distance for block group centroids and student origin means were determined using the near distance function in ESRI ArcToolbox. The summary statistics for these distance values were compared. A kernel density layer was created using the student origins point features and was used to determine the location of a hypothetical Head Start facility. The summary statistics describing distance were then compared for the two Head Start site and three site datasets to determine the validity of the hypothetical site location. Census data and the student origins were used to create a linear regression model that could predict variability in participant and applicant <b>distribution.</b> <b>Block</b> groups fitting this model were then examined...|$|E
40|$|AbstractElectricity {{consumption}} in airport terminal buildings {{can be identified}} via Low Voltage Main Distribution Panel (LVMDP) which each of them serves individual <b>distribution</b> <b>block.</b> Total electricity consumption based on distribution blocks does not describe operational characteristics of building systems. Utilization of building energy performance simulation software offers solution by providing electricity consumption data based on building systems. This research applied the method in simulating energy consumption and CO 2 emission in Terminal 3 Soekarno-Hatta International Airport. Simulation result shows that total electricity consumption of Terminal 3 is 27700. 107 GJ or 7. 694 MWh per year, with 86. 59 % of that is consumed by HVAC system, 9. 33 % used by lighting system, 2. 41 % used by electricity equipment, and 1. 76 % consumed by transportation system. In order to achieve CO 2 emission reduction, three scenarios are simulated in this research, i. e. increasing temperature setpoint, AHU (Air Handling Unit) rescheduling, and window films replacement. Increasing temperature setpoint could reduce 247. 179 ton of CO 2 emission per year. Increasing temperature combined with AHU rescheduling could reduce 286. 611 ton of CO 2 emission per year. Window film replacement combined with increasing temperature setpoint and AHU rescheduling could reduce 289. 966 ton of CO 2 emission per year...|$|E
40|$|Accurate air {{interface}} traffic forecasting and dimensioning is of importance in any cellular network for achieving cost and quality requirements. A previous paper [l] analysed {{the appropriateness of}} the Erlang B model to estimate the mean call blocking experienced by cellular traffic using the traditional confidence interval method. This paper presents a modified confidence interval method to compare the mean blocking of the measured data and Erlang B results. In addition to a more complete study of the mean, the <b>blocking</b> <b>distribution</b> is also considered. The Erlang Loss Model (ELM) is studied to completely characterise the <b>distribution</b> of <b>blocking</b> using the ELM. Exact expressions for the busy time distribution are derived for this study. The results presented in this paper indicate that Erlang B formula is an appropriate model for calculating mean call blocking on the {{air interface}}. The ELM on the other hand appears to be rather a poor model for the overall <b>blocking</b> <b>distribution.</b> Further study is needed to establish the appropriateness of Erlang B formula as a general tool. I...|$|R
40|$|The {{capacity}} of channels with block memory is investigated. It is shown that, when {{the problem is}} modeled as a game-theoretic problem, the optimum coding and noise <b>distributions</b> when <b>block</b> memory is permitted are independent from symbol to symbol within a block. Optimal jamming strategies are also independent from symbol to symbol within a block...|$|R
40|$|A recent {{development}} in text compression is a "block sorting" algorithm which permutes the input text {{according to a}} special sort procedure and then processes the permuted text with Move-to-Front and a final statistical compressor. The technique combines good speed with excellent compression performance. This report investigates the block sorting compression algorithm, in particular trying to understand its operation and limitations. Various approaches are investigated {{in an attempt to}} improve the compression with block sorting, most of which involve a hierarchy of coding models to allow fast adaptation to local contexts. The best technique involves a new "structured" coding model, especially designed for compressing data with skew symbol <b>distributions.</b> <b>Block</b> sorting compression is found to be related to work by Shannon in 1951 on the prediction of English text. The work confirms block-sorting as a good text compression technique, with a compression approaching that of the currently be [...] ...|$|R
