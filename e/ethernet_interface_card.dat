4|1637|Public
40|$|International audienceNetwork {{intrusion}} detection systems {{play a critical}} role in protecting the information infrastructure of an organization. Due to the sophistication and complexity of techniques used for the analysis they are commonly based on general-purpose workstations. Although cost-efficient, these general-purpose systems are found to be inadequate as they fail to perform efficiently at high packet rates. The resulting packet loss degrades the system's overall effectiveness, as the analyzing capability of the system is reduced. It has been found that the performance of these systems can be improved significantly by filtering out unwanted packets. This paper presents the design of a Programmable <b>Ethernet</b> <b>Interface</b> <b>Card</b> that is used to offload signature matching from software and thereby improve the detection ratio and performance of the system...|$|E
40|$|Network {{intrusion}} detection systems {{play a critical}} role in protecting the information infrastructure of an organization. Due to the sophistication and complexity of techniques used for the analysis they are commonly based on general-purpose workstations. Although cost-efficient, these general-purpose systems are found to be inadequate as they are unable to perform efficiently at high packet rates. The resulting packet loss degrades the system's overall effectiveness, as the analyzing capability of the system is reduced. It has been found that the performance of these sensors can be improved significantly by filtering out unwanted packets. This paper presents the design of a Programmable <b>Ethernet</b> <b>Interface</b> <b>Card</b> that is used to offload signature matching from software and thereby improve the detection ratio and performance of the system. Comment: Pre-print version. International Joint Journal Conference in Engineering, IJJCE 200...|$|E
40|$|Abstract. We {{describe}} a novel application of reconfigurable computing {{to the problem}} of computer network security. By filteringnetwork packets with customized logic circuits, we can search headers as well as packet content for specific signatures at Gigabit Ethernet line rate. Input to our system is a set of filter rule descriptions in the format of the public domain “snort ” databases. These descriptions are used by the hardware circuits on two Xilinx Virtex 1000 FPGAs on a SLAAC 1 V [9]board. Packets are read from a Gigabit <b>Ethernet</b> <b>interface</b> <b>card,</b> the GRIP [8], and flow directly through the packet filtering circuits. A vector describing matchingpacket headers and content are returned to the host program, which relates matches back to the rule database, so that logs or alerts can be generated. The hardware runs at 66 MHz with 32 -bit data, giving an effective line rate of 2 Gb/s. The granidt combination software/hardware runs at 24. 9 X the speed of snort 1. 8. ...|$|E
50|$|Much of {{the current}} work on TOE {{technology}} is by manufacturers of 10 Gigabit <b>Ethernet</b> <b>interface</b> <b>cards,</b> such as Broadcom, Chelsio Communications, Emulex, Mellanox Technologies, QLogic.|$|R
5000|$|Green Ethernet also {{encompasses}} {{the use of}} more efficient circuitry in Ethernet chips, {{and the use of}} [...] "off-load engines" [...] on <b>Ethernet</b> <b>interface</b> <b>cards</b> intended for network servers.|$|R
50|$|An {{example of}} dual-homed devices are enthusiast {{computing}} motherboards that incorporate dual <b>Ethernet</b> network <b>interface</b> <b>cards.</b>|$|R
50|$|In {{computer}} networking, jumbo frames or jumbos are Ethernet frames {{with more}} than 1500 bytes of payload, the limit set by the IEEE 802.3 standard. Conventionally, jumbo frames can carry up to 9000 bytes of payload, but variations exist and some {{care must be taken}} using the term. Many Gigabit Ethernet switches and Gigabit <b>Ethernet</b> network <b>interface</b> <b>cards</b> can support jumbo frames. Some Fast Ethernet switches and Fast <b>Ethernet</b> network <b>interface</b> <b>cards</b> can also support jumbo frames. Most national research and education networks (such as Internet2, National LambdaRail, ESnet, GÉANT and AARNet) support jumbo frames, but most commercial Internet service providers do not.|$|R
3000|$|... where n {{denotes the}} total number of {{installed}} hard disks whose idle power consumption is given by Equation (20), m and l indicate respectively {{the total number}} of <b>Ethernet</b> Network <b>Interface</b> <b>Cards</b> (NIC) and Fiber Channel NICs having an idle power of [...]...|$|R
5000|$|Prior to joining Cisco Systems, Kranz {{served as}} the Vice President of Marketing for IP Highway, Inc. and worked in product {{management}} at both 3Com, where he led the expansion and development of its <b>ethernet</b> network <b>interface</b> <b>cards</b> into a $1 billion product line, and IBM.|$|R
50|$|The Internet Protocol Suite is the standards-based {{networking}} {{model and}} software specification for forming {{small and large}} computer networks, from local area networks to global communication systems, such as the Internet. It is usually implemented by software and hardware features that use <b>Ethernet</b> network <b>interface</b> <b>cards,</b> cabling, and networking switches or hubs.|$|R
40|$|We report {{recent work}} on {{ethernet}} traffic generation and analysis. Gigabit <b>ethernet</b> network <b>interface</b> <b>cards</b> running customized embedded software and custom-built 32 -port fast ethernet boards based on FPGAs {{are used to}} study he behavior of large ethernet networks, with {{the ultimate goal of}} generating traffic resembling that of the final ATLAS data collection system...|$|R
5000|$|Token Ring network <b>interface</b> <b>cards</b> contain {{all of the}} {{intelligence}} required for speed autodetection, routing and can drive themselves on many Multistation Access Units (MAUs) that operate without power (most MAUs operate in this fashion, only requiring a power supply for LEDs). <b>Ethernet</b> network <b>interface</b> <b>cards</b> can theoretically operate on a passive hub to a degree, but not as a large LAN {{and the issue of}} collisions is still present.|$|R
50|$|Computers {{can connect}} to FCoE with converged network {{adapters}} (CNAs), which contain both Fibre Channel host bus adapter (HBA) and <b>Ethernet</b> network <b>interface</b> controller (NIC) functionality {{on the same}} physical card. CNAs have one or more physical Ethernet ports. FCoE encapsulation {{can be done in}} software with a conventional <b>Ethernet</b> network <b>interface</b> <b>card,</b> however FCoE CNAs offload (from the CPU) the low level frame processing and SCSI protocol functions traditionally performed by Fibre Channel host bus adapters.|$|R
5000|$|The Attachment Unit Interfaces {{that were}} used with 10BASE5 [...] "thick net" [...] in the 1980s and 1990s used DA15 {{connectors}} for connectivity between the Medium Attachment Units and (<b>Ethernet)</b> network <b>interface</b> <b>cards,</b> albeit with a sliding latch to lock the connectors together {{instead of the usual}} hex studs with threaded holes. The sliding latch was intended to be quicker to engage and disengage and to work in places where jackscrews could not be used for reasons of component shape.|$|R
30|$|Right part of Figure 6 {{illustrates}} the SAN devices UML class diagram. Typically, a “SAN” device consists {{of more than}} one (usually two) “PSU” and “Fan” for redundancy purposes, several fiber channel (FC) and <b>Ethernet</b> Network <b>Interface</b> <b>Cards</b> (“FiberchannelNIC” and “EthernetNIC” classes) and a set of “Storage Unit”s. Furthermore, “Storage Unit”s are logically consolidated through “Logical Unit”s abstraction such that a “Storage Unit” is a member of one and only one “Logical Unit”. “Server”s access a “Logical Unit” through a unique logical unit number reference (“LUN” class).|$|R
40|$|This project {{deals with}} {{possibilities}} of capturing and decoding data from different serial buses. Then describe ways of automatic {{recognition of the}} buses. The project include hardware and software development of device used for capturing data from different serial buses such as SPI, UART and I 2 C. Characteristics of these busses are described in detail. Device is design as shield to support Arduino boards. The Shield includes four fully isolated inputs and five non isolated imputs for capturing data, <b>Ethernet</b> <b>interface,</b> SD <b>card</b> and two display interfaces witch supports up to ten displays...|$|R
40|$|System administrators often {{assume that}} just by {{plugging}} in a Gigabit <b>Ethernet</b> <b>Interface,</b> {{the system will}} deliver line rate performance; sadly this is not often the case. The behaviour of various 1 and 10 Gigabit <b>Ethernet</b> Network <b>Interface</b> <b>cards</b> has been investigated using server quality motherboards. The latency, throughput, and the activity on the PCI buses and Gigabit Ethernet links were chosen as performance indicators. The tests were performed using two PCs connected back-to-back and sending UDP/IP frames {{from one to the}} other. This paper shows the importance of having a good combination of memory and peripheral bus chipset, <b>Ethernet</b> <b>Interface,</b> CPU power, good driver and operating system designs and proper configuration to achieve and sustain gigabit transfer rates. With these considerations taken into account, and suitably designed hardware, transfers can operate at gigabit and multi-gigabit speeds. Some recommendations are given for high performance data servers...|$|R
40|$|We {{present a}} tight {{integration}} of a user-level thread scheduler and a zero-copy messaging {{system that has}} been designed and optimized for scalable and efficient fine-grain parallel processing, on commodity platforms, with support for fault-tolerance. The system delivers most {{of the performance of}} the underlying communication hardware to a multi-threaded application level, while introducing little CPU overhead. This is demonstrated by a performance analysis of an implementation using off-the-shelf commodity products: PCs, running the Linux operating system, equipped with fast and gigabit <b>Ethernet</b> network <b>interface</b> <b>cards.</b> (21 refs) ...|$|R
40|$|Windows NT desktop and server {{systems are}} {{becoming}} increasingly important to Sandia. These systems are capable of network performance considerably {{in excess of the}} 10 Mbps Ethernet data rate. As alternatives to conventional Ethernet, 155 Mbps Asynchronous Transfer Mode, ATM, and 100 Mbps <b>Ethernet</b> network <b>interface</b> <b>cards</b> were tested and compared to conventional 10 Mbps Ethernet cards in a typical Windows NT system. The results of the tests were analyzed and compared to show the advantages of the alternative technologies. Both 155 Mbps ATM and 100 Mbps Ethernet offer significant performance improvements over conventional 10 Mbps shared media Ethernet...|$|R
40|$|This {{document}} first analyses {{the performance}} of Gigabit <b>Ethernet</b> Network <b>Interface</b> <b>Cards,</b> {{in the way they}} will be used in the sub-farms of the LHCb Data Acquisition system. Studied are the impact of PCI bus-systems, the tuning of parameters like IRQ coalescence and frame length as well as the performance difference between TCP and UDP. After this initial analysis of the Gigabit Ethernet performance, different versions of a load-balancing algorithm are implemented. This algorithm will be used by a sub-farm controller to distribute events evenly among its nodes. The experiments and benchmarks performed show that the envisaged data throughput in a DAQ sub-farm i...|$|R
40|$|RiceNIC is a {{reconfigurable}} and programmable Gigabit <b>Ethernet</b> network <b>interface</b> <b>card</b> (NIC). It {{was created}} as an open platform for public use and is freely available {{for research and}} education. It {{can be used to}} prototype new network server architectures, and has proved invaluable in recent research efforts. Using a commercial development board saved significant time and expense compared with custom fabrication. In addition, using a modern FPGA optimized for system-on-a-chip applications allowed the NIC to meet its performance goals with minimal effort. 1. RICENIC We have created RiceNIC, a reconfigurable and programmable Gigabit Ethernet NIC. RiceNIC is freely available and provides researchers with a flexible baseline networ...|$|R
40|$|D 3. 4 v 2 “Description of Experiment Results” Abstract: This {{document}} {{provides description}} of evaluation tests {{performed on the}} SCAMPI architecture. This is the second release of D 3. 4 deliverable, which includes performance tests of the SCAMPI architecture software running {{on top of the}} Gigabit Ethernet SCAMPI adapter and commodity Gigabit <b>Ethernet</b> network <b>interface</b> <b>card</b> (NIC) with monitoring functions implemented in software and partially in firmware (packet header filtering) and several application tests. The final release of D 3. 4 will include also tests with the 10 Gigabit Ethernet SCAMPI adapter and tests of more functionality implemented in firmware. These tests are yet to be performed, due to ongoing firmware and software development...|$|R
40|$|This paper {{explores the}} {{hardware}} and software mechanisms necessary for an efficient programmable 10 Gigabit <b>Ethernet</b> network <b>interface</b> <b>card.</b> Network <b>interface</b> processing requires support for the following characteristics: a large volume of frame data, frequently accessed frame metadata, and high frame rate processing. This paper proposes three mechanisms to improve programmable network interface efficiency. First, a partitioned memory organization enables low-latency access to control data and highbandwidth access to frame contents from a high-capacity memory. Second, a novel distributed task-queue mechanism enables parallelization of frame processing across many low-frequency cores, while using software to maintain total frame ordering. Finally, the addition of two new atomic read-modify-write instructions reduces frame ordering overheads by 50 %. Combining these {{hardware and software}} mechanisms enables a network <b>interface</b> <b>card</b> to saturate a full-duplex 10 Gb/s Ethernet link by utilizing 6 processor cores and 4 banks of on-chip SRAM operating at 166 MHz, along with external 500 MHz GDDR SDRAM. 1...|$|R
40|$|Offloading {{protocol}} processing {{will become}} an important tool in supporting our efforts to deliver increasing bandwidth to applications. In this paper we describe our experience in offloading protocol processing to a programmable gigabit <b>Ethernet</b> network <b>interface</b> <b>card.</b> For our experiments, we selected a simple RTS/CTS (request to send/clear to send) protocol called RMPP (Reliable Message Passing Protocol). This protocol provides endto-end flow control and full message retransmit {{in the case of}} a lost or corrupt packet. By carefully selecting parts of the protocol for offloading, we were able to improve the bandwidth delivered to MPI applications from approximately 280 Mb/s to approximately 700 Mb/s using standard, 1500 byte, Ethernet frames. Using “jumbo”, 9000 byte, frames the bandwidth improves from approximately 425 Mb/s to 840 Mb/s. Moreover, we were able to show a significant increase in the availability of the host processor. ...|$|R
40|$|Simevent {{proved to}} be {{efficient}} and flexible tool {{in the design and}} simulation of computer networks. <b>Ethernet</b> Network <b>Interface</b> <b>Card</b> (NIC) includes Logical Link Controller (LLC), Medium Access Controller (MAC) and physical layer. It is designed using simevent tools (blocks), the units of the NIC can be modified and adjusted separately, {{and as a matter of}} check, a network of Ethernet type using simevent blocks is designed based on the proposed NIC then its performance is compared with a similar Ethernet (based on OPNET software), the similarity of the two networks is proved through the simulation results of throughput and delay performances. It is possible to conclude that simulation with simevent tools push the design of network to behave like actual networks and as a consequence there is a possibility to modify the parameters of the different protocols easily...|$|R
40|$|The {{evaluation}} of new network server architectures is usually performed experimentally using either a simulator or a hardware prototype. Accurate simulation of the hardwaresoftware interface within the network subsystem is challenging {{due to the}} interactions of multiple asynchronous systems. Small timing inaccuracies in such a system can perturb the hardware and software state yielding potentially misleading results. Hardware prototypes show more promise because they are real-world implementations, not simplifications. Existing <b>Ethernet</b> network <b>interface</b> <b>cards</b> (NICs) are unsuitable for prototyping as they lack the capability and/or flexibility for advanced networking research. RiceNIC is an open network interface prototyping platform for public use. This reconfigurable and programmable Gigabit Ethernet NIC is designed to address the dilemma of how to accurately evaluate new ideas in network server architecture, and is built for use in experimental research and education. The flexibility and capability of RiceNIC has proven invaluable in recent research efforts...|$|R
40|$|This paper {{presents}} {{the concept of}} receive descriptor recycling to significantly reduce the performance drop associated with small packet Gigabit Ethernet traffic. Since limits and trade-offs are inherent when optimising for small packet traffic, all important aspects in this context are covered. Low-level measurements were performed at the CERN LHCb online data acquisition (DAQ) system, which is to a large extend made up of commodity equipment. Results gathered show the <b>Ethernet</b> controller (network <b>interface</b> <b>card,</b> NIC) driver currently is the major bottleneck, preventing the system from reaching maximal Gigabit Ethernet performance. Receive descriptor recycling is implemented under Linux for Intel's e 1000 NIC driver, and is shown to successfully remedy the driver inefficiency. status: publishe...|$|R
40|$|AbstractCarrier Sense Multiple Access/Collision Detection (CSMA/CD) is the {{protocol}} for carrier transmission access in Ethernet networks (international standard IEEE 802. 3). On <b>Ethernet,</b> any Network <b>Interface</b> <b>Card</b> (NIC) {{can try to}} send a packet in a channel at any time. If another NIC tries to send a packet at the same time, a collision is said to occur and the packets are discarded. The CSMA/CD protocol was designed to avoid this problem, more precisely to allow a NIC to send its packet without collision. This is done {{by way of a}} randomized exponential backoff process. In this paper, we analyse the correctness of the CSMA/CD protocol, using techniques from probabilistic model checking and approximate probabilistic model checking. The tools that we use are PRISM and APMC. Moreover, we provide a quantitative analysis of some CSMA/CD properties...|$|R
50|$|This is full high definition(1080p) USB PVR. It {{supports}} one {{fixed tuner}} and one detachable tuner module(S2,T,C). It also features one HDMI, two USB 2.0, one eSATA, two Common <b>Interface,</b> two Smart <b>card,</b> one Optical and one 10/100 Mbit/s <b>Ethernet</b> <b>interfaces.</b>|$|R
30|$|The {{experiments}} were {{performed in a}} controlled environment comprised of two servers, A and B, equipped with 1 Intel Xeon processor E 5 - 2420 (1.9 GHz, 12 cores and 15 MB cache), 32 GB of RAM (1333 MHz), 1 TB SAS hard drive, 1 Gbps network <b>interface</b> <b>card</b> (NIC), and Fedora GNU/Linux 21 (kernel v 3.17). The NIC on server A was directly connected to the NIC in Server B. On server A, a KVM hypervisor and an Open vSwitch virtual switch were installed. On top of KVM we deployed a virtual machine with two logical <b>Ethernet</b> <b>interfaces,</b> 1 vCPU and 1 GB of RAM. The virtual switch {{was connected to the}} physical NIC and to the virtual machine interfaces. On server B, two Docker containers were installed, each with a logical <b>Ethernet</b> <b>interface,</b> and an Open vSwitch connected to the containers and the physical NIC.|$|R
5000|$|The AO751h has {{the larger}} 11.6" [...] screen with an LED backlit display and a 1366x768 native resolution. It {{includes}} a 1 GB/667 MHz DDR2 533 MHz SDRAM memory option (2 GB being the maximum), a 160 GB HDD option, Bluetooth option, Intel northbridge US15W, and an OS option for Windows Vista Home Basic edition or Windows XP Media Center Edition. All AO751h units are powered by an Intel Atom Z520 processor running at 1330 MHz (or 1240 MHz in first version). The US15W system controller incorporates a GMA500 video core. The AO751h has a dual power (AC/DC) option. The six cell battery provides the working time of about 8 hours. Besides the mentioned specifications of the AO751h it supports 10/100 Mbit/s <b>Ethernet</b> <b>interface,</b> 802.11g Wi-Fi <b>card</b> Atheros, Bluetooth 2.1, standard VGA-out jack, 3 USB 2.0 ports, a Memory Card reader 5:1 (xD-Picture Card, SD card), {{as well as}} Microphone In jack 3.5 mm (1/8" [...] Mini), Headphone Out jack 3.5 mm (1/8" [...] Mini). One of the cons is the relatively small TouchPad and mouse buttons. Large and comfortable keyboard {{is one of the}} distinguishing features of the device.|$|R
40|$|Ethernet is {{the most}} {{pervasive}} communication technology in use today. It is a standard for connecting computers to form a local area network and provides a common method for the exchange of data. In this paper, we propose a Linux solution, Bonding-Plus, to support real-time control and boost bandwidth using multiple network <b>interface</b> <b>cards</b> connected to regular switching hubs in an Ethernet environment. BondingPlus schedules packets in the data link layer without modification to the hardware or operating system in the host machine. Real-time packets can be transmitted via one or several dedicated bonding <b>Ethernet</b> <b>interfaces,</b> {{and there is no}} competition with low priority packets. Transmission delay and network jitter for real-time packets can be dramatically reduced. Furthermore, bandwidth can be increased in proportion to the number of bonding <b>Ethernet</b> <b>interfaces</b> under both TCP and UDP transmission. Various types of systems, such as clustering and parallel systems, can be enhanced at minimal hardware cost...|$|R
50|$|In July 2002 Microsoft product {{managers}} {{stated that}} home networking {{was too hard}} to use, and the company was developing products using the Institute of Electrical and Electronics Engineers (IEEE) 802.11b standard (sold under the Wi-Fi name).Products announced in September included the MN-500 wireless base station, MN-510 WiFi Universal Serial Bus (USB) network interface controller and MN-520 PC Card for laptop computers.The MN-500 served as a wireless access point, a router, and included an Ethernet hub with four 10/100 Ethernet ports.A five port Ethernet switch and <b>Ethernet</b> network <b>interface</b> controller <b>cards</b> were announced, along with kits.Reviews noted the reasonable prices and simple interface, although the configuration software would sometimes fail.One reviewer noted the 96-page book included with the base station.It {{was one of the}} first products to enable Wired Equivalent Privacy (WEP) by default, which provided at least some level of privacy.Software included a setup wizard, a broadband network utility (BNU) and an auto-update feature.According to codes in the documentation, the initial MN-510 was developed by Accton Technology Corporation. Features were similar to products of SMC Networks, a subsidiary of Accton.|$|R
50|$|The SPARCstation 20 has one {{integrated}} AMD Lance 10baseT <b>Ethernet</b> <b>interface.</b> Additional <b>Ethernet</b> <b>interfaces</b> can {{be added}} with an SBus card.|$|R
40|$|This paper {{presents}} and evaluates {{a strategy for}} integrating the Snort network intrusion detection system into a high-performance programmable <b>Ethernet</b> network <b>interface</b> <b>card</b> (NIC), considering the impact of several possible hardware and software design choices. While currently proposed ASIC, FPGA, and TCAM systems can match incoming string content in real-time, the system proposed also supports the stream reassembly and HTTP content transformation capabilities of Snort. This system, called LineSnort, parallelizes Snort using concurrency across TCP sessions and executes those parallel tasks on multiple low-frequency pipelined RISC processors embedded in the NIC. LineSnort additionally exploits opportunities for intra-session concurrency. The system also includes dedicated hardware for high-bandwidth data transfers and for high-performance string matching. Detailed results obtained by simulating various software and hardware configurations show that the proposed system can achieve intrusion detection throughputs in excess of 1 Gigabit per second for fairly large rule sets. Such performance requires the system to use hardware-assisted string matching and a small shared data cache. The system can extract performance through increases in processor clock frequency or parallelism, allowing additional flexibility for designers to achieve performance within specified area or power budgets. By efficiently offloading the computationally difficult task of intrusion detection to the network interface, LineSnort enables intrusion detection to run directly on PC-based network servers rather than just at powerful edge-based appliances. As a result, LineSnort {{has the potential to}} protect servers against the growing menace of LAN-based attacks, whereas traditional edge-based intrusion detection deployments can only protect against external attacks. This work is supported in part by the National Science Foundation under Grant Nos. CCF- 0532448 and CNS- 0532452...|$|R
40|$|The <b>Ethernet</b> <b>{{interface}}</b> is {{more common}} and easier interface to implement for payload developers already familiar with Ethernet protocol in their labs. The <b>Ethernet</b> <b>interface</b> allows for a more distributed payload architecture. Connections can be placed in locations not serviced by the PEP 1553 bus. The <b>Ethernet</b> <b>interface</b> provides a new access port into the PEP so as to use the already existing services. Initial capability will include a subset of services {{with a plan to}} expand services later...|$|R
