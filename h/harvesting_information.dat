35|415|Public
2500|$|In the 1960s, statisticians used {{terms like}} data fishing or data {{dredging}} {{to refer to}} what they considered the bad practice of analyzing data without an a-priori hypothesis. The term data mining appeared around 1990 in the database community. For a short time in 1980s, a phrase [...] "database mining"™, was used, but since it was trademarked by HNC, a San Diego-based company, to pitch their Database Mining Workstation; researchers consequently turned to data mining. Other terms used include data archaeology, information <b>harvesting,</b> <b>information</b> discovery, knowledge extraction, etc. Gregory Piatetsky-Shapiro coined the term [...] "knowledge discovery in databases" [...] for the first workshop on the same topic [...] and this term became more popular in AI and machine learning community. However, the term data mining became more popular {{in the business and}} press communities. Currently, the terms data mining and knowledge discovery are used interchangeably.|$|E
5000|$|June 9 [...] "We will be {{receiving}} secret briefings {{and we will}} be asking, I know I'm going to be asking to get more information. I {{want to make sure that}} what they're doing is <b>harvesting</b> <b>information</b> that is necessary to keep us safe and not simply going into everybody's private telephone conversations and Facebook and communications. I mean one of the, you know, the terrorists win when you debilitate freedom of expression and privacy." ...|$|E
5000|$|In the 1960s, statisticians used {{terms like}} data fishing or data {{dredging}} {{to refer to}} what they considered the bad practice of analyzing data without an a-priori hypothesis. The term data mining appeared around 1990 in the database community. For a short time in 1980s, a phrase [...] "database mining"™, was used, but since it was trademarked by HNC, a San Diego-based company, to pitch their Database Mining Workstation; researchers consequently turned to data mining. Other terms used include data archaeology, information <b>harvesting,</b> <b>information</b> discovery, knowledge extraction, etc. Gregory Piatetsky-Shapiro coined the term [...] "knowledge discovery in databases" [...] for the first workshop on the same topic (KDD-1989) and this term became more popular in AI and machine learning community. However, the term data mining became more popular {{in the business and}} press communities. Currently, the terms data mining and knowledge discovery are used interchangeably.|$|E
50|$|In {{addition}} to these, a doxxer may use other methods to <b>harvest</b> <b>information.</b> These include information search by domain name and location searching {{based on an}} individual's IP address.|$|R
50|$|Anyone can <b>harvest</b> <b>information</b> {{from the}} {{internet}} about individuals. There is no particular structure in place for doxing, meaning someone may seek out any kind of information related to the target.|$|R
40|$|Standardized {{collection}} and reporting of subsistence salmon <b>harvest</b> <b>information</b> during the fishing season {{is an important}} management tool for Yukon River fishery managers. The 2003 salmon fishing season marked the second season of an organized effort to collect qualitative inseason subsistence <b>harvest</b> <b>information.</b> Information gauging progress towards subsistence salmon harvest goals, subsistence fishing characteristics, and quality of subsistence catch were collected. Progress towards meeting subsistence harvest goals was evaluated by using local village interviewers contacting a subsample of fishermen each week. Residents of Emmonak, Holy Cross, Nulato, Huslia, Galena, and Circle were interviewed weekly between June 1 and August 31, 2003. Sixty-three households were interviewed regarding Chinook salmon harvests and seventeen households were interviewed regarding chum salmon <b>harvest</b> progression. <b>Information</b> was reported on fourteen weekly public teleconferences and used in nine Federal inseason management summaries. In general, inseason interview data indicated that most interviewed households met or nearly met their subsistence Chinook and chum salmon goals for the 2003 season and that the 2003 fishing season appeared better {{as compared to the}} 2002 fishing season...|$|R
5000|$|Research {{networking}} (RN) {{is about}} using web-based tools {{to discover and}} use research and scholarly information about people and resources. Research networking tools (RN tools) serve as knowledge management systems for the research enterprise. RN tools connect institution-level/enterprise systems, national research networks, publicly available research data (e.g., grants and publications), and restricted/proprietary data by <b>harvesting</b> <b>information</b> from disparate sources into compiled expertise profiles for faculty, investigators, scholars, clinicians, community partners, and facilities. RN tools facilitate {{the development of new}} collaborations and team science to address new or existing research challenges through the rapid discovery and recommendation of researchers, expertise, and resources. [...] RN tools differ from search engines such as Google in that they access information in databases and other data not limited to web pages. They also differ from social networking systems such as LinkedIn or Facebook in that they represent a compendium of data ingested from authoritative and verifiable sources rather than predominantly individually asserted information, making RN tools more reliable. [...] Yet, RN tools have sufficient flexibility to allow for profile editing. RN tools also provide resources to bolster human connector systems: they can make non-intuitive matches, they do not depend on serendipity, and {{they do not have a}} propensity to return only to previously identified collaborations/collaborators. RN tools also generally have associated analytical capabilities that enable evaluation of collaboration and cross-disciplinary research/scholarly activity, especially over time.|$|E
40|$|Mesoscale {{experiment}} and simulation permit <b>harvesting</b> <b>information</b> about both geometric features and texture in material microstructures. The grain boundary character distribution (GBCD) is an empirical {{distribution of the}} relative length (in 2 D) or area (in 3 D) of interface with a given lattice misorientation and grai...|$|E
40|$|In {{this paper}} we {{describe}} a methodology for <b>harvesting</b> <b>information</b> from large distributed repositories (e. g. large Web sites) with minimum user intervention. The methodology {{is based on}} a combination of information extraction, information integration and machine learning techniques. Learning is seeded by extracting information from structured sources (e. g. databases and digital libraries) or a user-defined lexicon...|$|E
50|$|The site <b>harvests</b> <b>information</b> from a {{range of}} {{relevant}} websites and steers people to that content, making information quick and easy to find. It can also direct users to the original source if they need more information about a particular topic.|$|R
5000|$|VIVO {{can harvest}} {{publication}} data from PubMed, CSV files, relational databases, or OAI-PMH harvest. It then uses a semi-automated process to match publications to researchers. [...] It also <b>harvests</b> <b>information</b> about researchers from Human Resources systems and student information systems.|$|R
50|$|On October 4, 2006, freedb owner Michael Kaiser {{announced}} that Magix had acquired freedb. On June 25, 2007, MusicBrainz - a project with similar goals - officially released their freedb gateway. The latter {{allows users to}} <b>harvest</b> <b>information</b> from the MusicBrainz database rather than freedb.|$|R
40|$|The AKTiveSA {{project is}} using Semantic Web {{technologies}} to support information fusion and en-hanced situational awareness in a simulated hu-manitarian relief scenario. We {{have developed an}} application that shows how situational awareness can be supported during humanitarian relief situa-tions; often occurring alongside military conflict. Semantic Web technologies provide new opportu-nities for <b>harvesting</b> <b>information</b> from numerous, disparate and often heterogeneous information sources {{and can be used}} to better support complex knowledge fusion...|$|E
40|$|The {{key to a}} {{successful}} repository is sustained deposits, {{and the key to}} sustained deposits is community engagement. This paper looks at deposit profiles automatically generated from OAI <b>harvesting</b> <b>information</b> and argues that repositories characterised by occasional large-volume deposits are a sign of a failure to embed in institutional processes. The ideal profile for {{a successful}} repository is discussed, and a new service that ranks repositories based on these criteria is implemented...|$|E
40|$|Abstract—We {{consider}} a Gaussian multiple access channel (GMAC) where the users are sensor nodes powered by energy harvesters. The energy harvester has no buffer {{to store the}} harvested energy and hence the energy need to be expended immediately. We assume that the decoder has perfect knowledge of the energy harvesting process. We characterize the capacity region of such a GMAC. We also provide the capacity region {{when one of the}} users has infinite buffer to store the energy harvested. Next we find the achievable rates when the energy <b>harvesting</b> <b>information</b> is not available at the decoder...|$|E
30|$|This {{kind of a}} {{discussion}} may be used at any point during the semester for various purposes. At times, it {{may be used as}} a way to <b>harvest</b> <b>information</b> (i.e. what the students want to focus on and learn further about) or a way to deeply explore an issue (i.e. how can California address the current drought?).|$|R
5000|$|Genotype to Phenotype: <b>harvesting</b> the <b>information</b> in genomes and {{the effect}} of {{variation}} ...|$|R
50|$|ShoppyBag was an Internet {{phishing}} scam that <b>harvested</b> personal <b>information</b> such as e-mail addresses.|$|R
40|$|We {{introduce}} a big data platform that provides various ser-vices for harvesting scholarly information and enabling ef-ficient scholarly applications. The core {{architecture of the}} platform is built on a secured private cloud; it crawls data using a scholarly focused crawler that leverages a dynamic scheduler, processes data by utilizing a map reduce based crawl-extraction-ingestion (CEI) workflow, and stores data in distributed repositories and databases. Services such as scholarly data <b>harvesting,</b> <b>information</b> extraction, and user information and log data analytics are integrated into the platform and provided by an OAI and RESTful APIs. We also {{introduce a}} set of scholarly applications built {{on top of this}} platform including citation recommendation and collab-orator discovery...|$|E
40|$|The paper {{evaluates the}} {{effectiveness}} of <b>harvesting</b> <b>information</b> from the internet {{to aid in the}} lowcost construction of an ontology. The paper describes how a proof-of-concept called OntoRanch was built, to harvest information and its relationships to construct an ontology. A systems development methodology was adopted which recognises three main stages: concept development, system building, and system evaluation. The evaluation took an interpretive hybrid approach of using both a focus group and a questionnaire to evaluate the proof-of-concept OntoRanch. The findings show that the approach of reusing information by harvesting it from the internet can provide an effective self-sustaining process that enables ontologies to be constructed in a reduced amount of time and cost...|$|E
40|$|Abstract — This paper investigates {{performance}} tradeoffs be-tween {{energy and}} information transfer in a relay based two-hop wireless system involving an energy harvesting receiver. The source and relay nodes of the two-hop amplify-and-forward (AF) system employ orthogonal space-time block codes along with orthogonal frequency-division multiplexing (OFDM) scheme. The joint optimal source and relay precoders over the subchannels in frequencies {{are designed to}} achieve different tradeoffs between the overall energy transfer capability and the information rate, which are characterized by the boundary of the so-called rate-energy (R-E) region. The effect of various parameters on the boundary of the R-E region is demonstrated for different fre-quency selective channel models. Index Terms — MIMO-OFDM, energy <b>harvesting,</b> <b>information</b> and power transfer, OSTBC, and AF relay...|$|E
40|$|AbstractThis {{paper is}} to develop Thai Rice Implantation Recommend system based on Android System. This {{application}} serves as an important channel to support and provide the rice <b>harvest</b> <b>information</b> like how to cultivate, how to treatment of rice diseases and how to know time alert period of crop protection for Thai farmers in central zone of Thailand. To evaluate the preliminary prototype system, questionnaires were used to measure user satisfaction with system usability by experts and users. Experimental results reveal {{that the system is}} well able to recommend rice <b>harvest</b> <b>information</b> both users and experts and this application can be adapted to users easily {{due to the fact that}} the data is stored and available on mobile devices. Also the results were satisfied in the effectiveness as well follows: Means for specialist and users were 4. 00 and 4. 01 respectively, and standard deviation for specialists and users were 0. 51 and 0. 66 respectively...|$|R
40|$|Armadillo is an {{automatic}} system for producing domain- specific Semantic Web oriented annotation on large repositories. It annotates by extracting information from different sources and integrating {{it into a}} knowledge base. Such base can then be used both to access the information directly (e. g. via a semantic web agent) and to annotate the pages where the information was identified. Armadillo is adaptive: it learns how to <b>harvest</b> <b>information</b> with minimal initial user intervention. N/...|$|R
50|$|Louisiana, {{as well as}} {{all other}} states such as Texas, {{participate}} in the HIP Program. This is an acronym for Migratory Bird <b>Harvest</b> <b>Information</b> Program that is operated jointly by each state and the U.S. Fish and Wildlife Service (USFWS), for anyone wanting to hunt ducks, coots, geese, brant, swans, doves, band-tailed pigeons, woodcock, rails, snipe, sandhill cranes, or gallinules, all hunters must register, and the information is used to provide statistics on waterfowl harvesting in the US.|$|R
40|$|Abstract—In this paper, optimal {{power control}} {{policies}} for an interference channel with two energy harvesting transmit-ters and two corresponding receivers are considered. Energy harvesting transmitters have strict power constraints {{due to the}} harvesting process as well as battery capacity constraints. The derived optimal power policies maximize the sum-throughput of a deadline constrained system under such energy and data arrival constraints by utilizing the limited available energy and managing the interference in the channel simultaneously. It is shown that an alternating maximization approach that individually optimizes the power policies for each transmitter in a cyclic manner converges to the optimal policy. The single-user subproblems with data constraints are solved using a generalized directional water-filling algorithm. A practical distributed algorithm requiring only local energy <b>harvesting</b> <b>information</b> is presented, and its near-optimal performance is demonstrated through simulations. I...|$|E
40|$|The {{migration}} of libraries to the digital realm has created {{new opportunities for}} information sharing; however, the abundance of available literature has made locating relevant research studies on specific learning disabilities a difficult task, one that existing search strategies have not adequately addressed. Moreover, definitions of specific learning disabilities have evolved {{and the nature of}} this field is interdisciplinary, creating a confusion of possible search terms for the topic. The present investigation used the Pearl <b>Harvesting</b> <b>Information</b> Retrieval Framework to create a comprehensive search strategy for locating research on learning disabilities. The analysis produced four groups of harvested search terms for the subtopics of general learning disabilities, reading disabilities, math disabilities, and nonverbal learning disabilities. The wide range of diverse search terms retrieved a significantly greater number of relevant citations than other search strategies...|$|E
40|$|Context-sensitive (or aware) {{applications}} have, {{in recent}} years, {{moved from the}} realm of possibilities to that of ubiquity. One exciting research area that is still very much in the realm of possibilities is that of cloud computing, and in this paper, we present our work, which explores the overlap of these two research areas. Accordingly, this paper explores the notion of cross-source integration of cloud-based, context-aware information in ubiquitous computing through a developed prototypical solution. Moreover, the described solution incorporates remote and automatic configuration of Android smartphones and advances the research area of context-aware information by <b>harvesting</b> <b>information</b> from several sources to build a rich foundation on which algorithms for context-aware computation can be based. Evaluation results show the viability of integrating and tailoring contextual information to provide users with timely, relevant and adapted application behaviour and content...|$|E
40|$|Table of Contents Executive Summary...................................... i Introduction.......................................... 1 Status of Rails and Snipe................................... 2 Priority Information Needs.................................. 3 Priority 1. Implement a National Monitoring Program.................... 3 Priority 2. Continue to Improve the <b>Harvest</b> <b>Information</b> Program Sampling Frame.... 5 Priority 3. Improve the Rails and Snipe Parts Collection Survey............... 6 Priority 4. Estimate Vital Rates to Support Population Modeling.............. 7 Measuring Success....................................... 8 Literature Cited........................................ 9 Appendix A: 2008 Workshop Participants......................... 10 Table 1. Preliminary Nationwide Estimates of Migratory Shore and Upland Game Bird Harvest and Hunter Activity (2005 and 2006)............................. ...|$|R
40|$|We model a fishery {{management}} regime that assigns one portion {{of an overall}} catch quota to a voluntary cooperative, with the remainder exploited as a commons by those choosing to fish independently. Data from an Alaska commercial salmon fishery confirm the model’s predictions regarding coordination of the <b>harvest,</b> <b>information</b> sharing and provision of shared infrastructure, and implies rent gains of at least 25 %. A lawsuit filed by two disgruntled independents led to the co-op’s demise, an outcome also predicted by our model. Our analysis provides guidance for designing fishery reform that leads to Pareto improvements for fishermen of all skill levels...|$|R
25|$|Fish {{and game}} laws {{regulate}} {{the right to}} pursue and take or kill certain kinds of fish and wild animal (game). Such laws may restrict the days to harvest fish or game, the number of animals caught per person, the species harvested, or the weapons or fishing gear used. Such laws may seek to balance dueling needs for preservation and harvest and to manage both environment and populations of fish and game. Game laws can provide a legal structure to collect license fees and other money {{which is used to}} fund conservation efforts as well as to obtain <b>harvest</b> <b>information</b> used in wildlife management practice.|$|R
40|$|This 3 -hour {{workshop}} {{focuses on}} presenting the current stateof-the-art relational database preservation standards and tools used by major national archives and other institutions. It presents SIARD 2, a new preservation format for relational databases. It also presents the current tools for <b>harvesting</b> <b>information</b> from live database management systems 1 into SIARD format and back, namely SIARD Suite 2 and the Database Preservation Toolkit 3. Furthermore, two tools to access and view the information preserved in SIARD-les are presented: the E-ARK database viewer 4 and SIARDexcerpt 5. The workshop includes live {{demonstration of the}} tools and prompts the participants to use them on their own laptops using the demonstration databases provided. This workshop closely relates to a tutorial on relational database preservation guidelines and use cases, {{that focuses on the}} operational concerns of database preservation and relevant real-world use cases...|$|E
40|$|In the {{educational}} arena, information is conventionally scattered throughout many projects and documents and on many systems. This distribution of data inhibits {{students and faculty}} members from searching and accessing information conveniently and efficiently. The research project described in this paper aims to consolidate the disparate data into one information repository. Known as the KATSIR (K 12 Advanced Touring System based on Information Retrieval) system, the project is developing and implementing a comprehensive architecture for intelligent information retrieval in open systems. The novelty {{of this approach is}} the combination of a new research paradigm in information retrieval, called information harvesting, with a K 12 -friendly interface. This paradigm enables both teachers and students to gain practical experience in <b>harvesting</b> <b>information</b> both locally and throughout Internet sites in a K 12 environment. As part of this research, an innovative information retrieval project was developed. Th...|$|E
40|$|Although {{different}} {{web sites}} structure their pages differently, the pages {{within a single}} site are often generated from a database and have a regular layout from which {{it is possible to}} extract information automatically. Dome is a visual tool for manipulating tree-structured documents. It can import and export in XML or HTML formats, making it ideal for <b>harvesting</b> <b>information</b> from web pages. Editing is performed using a direct manipulation interface and the operations are recorded for later playback. The knowledge extracted from a web page may be updated by replaying the recorded sequence when the source page changes. The same sequence can be applied to other pages with a similar format, and facilities are provided to batch process a large collection of pages in one operation. In this paper we describe how Dome may be used to extract knowledge from web sites {{in such a way that}} the extraction process may be reliably replayed...|$|E
40|$|This Paper {{deals with}} the {{organization}} excellence in TISS library E-Books, E-Journals, Digital Library Software like Dspace, Cyber library, Learning Centre for Visually challenged, Document Delivery service, Info-mail, networking and resource sharing with national and international universities. Capacity building is upgrading, empowering and analyzing strength, weaknesses, opportunities, threats (SWOT) and skills development through training, experimenting and its application, {{is of paramount importance}} in digital libraries and information centers. In order to improve their productive base, the role of library professionals has been changed drastically due to <b>information</b> explosion. To <b>harvest</b> <b>information</b> explosion by using IT applications, forced library professionals’ to face the challenges in the knowledge society...|$|R
50|$|In the United States, {{each state}} has primary {{responsibility}} and {{authority over the}} hunting of wildlife that resides within state boundaries. State wildlife agencies that sell hunting licenses are the best source of information regarding hunting seasons, areas open/closed to hunting, etc. Hunting of migratory birds such as ducks and geese is managed cooperatively by state fish and wildlife agencies and the U.S. Fish and Wildlife Service. Migratory waterfowl hunters must possess both a state hunting license and a Federal Migratory Bird Hunting and Conservation Stamp (Duck Stamp), and each hunter needs a <b>Harvest</b> <b>Information</b> Program (HIP) number for each state in which they hunt migratory birds.|$|R
40|$|A {{challenging}} {{problem in}} open information extraction and text mining is {{the learning of}} the selectional restrictions of semantic relations. We propose a minimally supervised bootstrapping algorithm that uses a single seed and a recursive lexico-syntactic pattern to learn the arguments and the supertypes of a diverse set of semantic relations from the Web. We evaluate the performance of our algorithm on multiple semantic relations expressed using “verb”, “noun”, and “verb prep ” lexico-syntactic patterns. Humanbased evaluation shows that {{the accuracy of the}} <b>harvested</b> <b>information</b> is about 90 %. We also compare our results with existing knowledge base to outline the similarities and differences of the granularity and diversity of the harvested knowledge. ...|$|R
