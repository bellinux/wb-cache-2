0|57|Public
30|$|Specially, L^ 0 _+={ξ∈ L^ 0 (F,R) | ξ≥ 0 } and F {{denotes the}} set of <b>equivalence</b> classes of <b>elements</b> in F.|$|R
40|$|We {{construct}} non-power words {{which have}} small image in SL(2; 22 n) for each n. In particular, the corresponding word maps are non-surjective. We also {{use this to}} construct word maps whose values are precisely the identity and a single <b>equivalence</b> class of <b>elements</b> of order 17. In the second part we construct words which have image consisting of the identity and a single <b>equivalence</b> class of <b>elements</b> in Alt(n) for all n for any equivalence class with support size at most 10...|$|R
5000|$|In mathematics, the plactic monoid is the monoid of all {{words in}} the {{alphabet}} of positive integers modulo Knuth <b>equivalence.</b> Its <b>elements</b> can be identified with semistandard Young tableaux. It was discovered by [...] (who called it the tableau algebra), using an operation given by [...] {{in his study of}} the longest increasing subsequence of a permutation.|$|R
40|$|The Label Distribution Protocol (LDP) {{specification}} for the Wildcard Forward <b>Equivalence</b> Class (FEC) <b>element</b> {{has several}} limitations. This document addresses those limitations by defining a Typed Wildcard FEC Element and associated procedures. In addition, it defines a new LDP capability to address backward compatibility...|$|R
40|$|Theories {{with hidden}} sorts provide a setting {{to study the}} idea of {{behaviour}} and behavioural <b>equivalence</b> of <b>elements.</b> But there are variants {{on the notion of}} theory: many sorted algebras, order sorted algebras and so on; we would like to use the theory of institutions to develop ideas of some generality. We formulate the notion of behavioural equivalence in a more abstract and categorical way, and we give a general explication of "hiding" in an institution. We use this show that both hidden many sorted algebras and hidden order sorted algebras yield institutions...|$|R
40|$|We {{present a}} novel view that unifies two {{frameworks}} that aim to solve sequential prediction problems: learning to search (L 2 S) and recurrent neural networks (RNN). We point out <b>equivalences</b> between <b>elements</b> {{of the two}} frameworks. By complementing what is missing from one framework comparing to the other, we introduce a more advanced imitation learning framework that, on one hand, augments L 2 S s notion of search space and, on the other hand, enhances RNNs training procedure to be more robust to compounding errors arising from training on highly correlated examples. Comment: 5 page...|$|R
40|$|Abstract: This study {{presents}} {{a method for}} computing thermal properties of an actuator and compares various magnetic materials. The two-dimensional heat conduction problem is studied using the boundary element method (BEM) with Poisson <b>equivalence.</b> Linear <b>elements</b> {{are used in the}} solution procedure. The temperature distribution in the ferromagnetic body is evaluated under stationary condition. The numerical results have been compared with the results of the finite element method (FEM). Numerical experiments have been carried out on soft ferromagnetic materials such as silicon steel iron; mild iron; pure iron and amorf and results the temperature distribution are graphed...|$|R
40|$|Suppose M is a {{structure}} {{in the sense of}} model theory. It is natural to consider definable quotients X/E, whereXis a definable set in M and E a definable <b>equivalence</b> relation. An <b>element</b> a/E of X/E is called an imaginary element of M. Shelah introduced the formalisation M eq, a many-sorted first order structure wher...|$|R
5000|$|Let [...] be a topological space, and let [...] be an {{equivalence}} relation on [...] The quotient space, [...] is defined {{to be the}} set of <b>equivalence</b> classes of <b>elements</b> of :equipped with the topology where the open sets are defined to be those sets of equivalence classes whose unions are open sets in X: ...|$|R
40|$|This paper {{tries to}} {{construct}} {{a bridge between the}} concerns of theoretical linguistics and those of multilingualism and code-switching (CS) research. It argues that the primary special point of interaction between these fields lies in the question of potential <b>equivalence</b> between <b>elements</b> or categories, bridging across languages. After giving an overview of some major findings in recent CS research, these findings are interpreted in a constraint- or strategy-based framework. Then I explore the notion of categorical equivalence, starting with the observation that the insertion of single functional categories is highly restricted in CS contexts. Subsequently a number of concrete questions are formulated for research in this domain based on available data for Afrikaans-English and isiXhosa-English CS...|$|R
40|$|International audienceThis {{paper is}} {{the second part of}} a series of two papers dealing with bulking: a way to define quasi-order on {{cellular}} automata by comparing space-time diagrams up to rescaling. In the present paper, we introduce three notions of simulation between cellular automata and study the quasi-order structures induced by these simulation relations on the whole set of cellular automata. Various aspects of these quasi-orders are considered (induced <b>equivalence</b> relations, maximum <b>elements,</b> induced orders, etc.) providing several formal tools allowing to classify cellular automata...|$|R
40|$|Recent work on higher-dimensional {{dependent}} type theory enriches conventional one-dimensional dependent type {{theory with}} additional structure expressing <b>equivalence</b> of <b>elements</b> of a type. This structure may {{be employed in}} a variety of ways to capture rather coarse identifications of elements that must be respected by type families. Higher-dimensional type theory has applications to code reuse for dependently typed programming, and to the formalization of mathematics. In this paper, we develop a novel judgemental formulation of a two-dimensional type theory, which enjoys a canonicity property: a closed term of boolean type is definitionally equal to one of the two booleans. Canonicity is a necessary condition for a computational interpretation of type theory as a programming language, and does not hold for existing axiomatic presentations of higher-dimensional type theory. The method of proof is a generalization of the NuPRL semantics, interpreting types as syntactic groupoids rather than equivalence relations...|$|R
25|$|Many of the {{structures}} that are studied in order theory employ order relations with further properties. In fact, even some relations that are not partial orders are of special interest. Mainly {{the concept of a}} preorder has to be mentioned. A preorder is a relation that is reflexive and transitive, but not necessarily antisymmetric. Each preorder induces an <b>equivalence</b> relation between <b>elements,</b> where a is equivalent to b, if a ≤ b and b ≤ a. Preorders can be turned into orders by identifying all elements that are equivalent with respect to this relation.|$|R
40|$|Abstract: The {{identification}} of semantic relationships between schema elements, or schema matching, is the initial {{step in the}} integration of data sources. Existing approaches in automatic schema matching have mainly been concerned with discovering <b>equivalence</b> relationships between <b>elements.</b> In this paper, we present an approach to automatically discover richer and more expressive semantic relationships based on a bidirectional comparison of the elements data and metadata. The experiments that we have performed on real-world data sources from several domains show promising results, {{considering the fact that}} we do not rely on any user or external knowledge. ...|$|R
40|$|The Label Distribution Protocol (LDP) {{specification}} for the Wildcard Forward <b>Equivalence</b> Class (FEC) <b>element</b> {{has several}} limitations. This document addresses those limitations by defining a Typed Wildcard FEC Element and associated procedures. In addition, it defines a new LDP capability to address backward compatibility. Status of This Memo This is an Internet Standards Track document. This document {{is a product}} of the Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by th...|$|R
50|$|Many of the {{structures}} that are studied in order theory employ order relations with further properties. In fact, even some relations that are not partial orders are of special interest. Mainly {{the concept of a}} preorder has to be mentioned. A preorder is a relation that is reflexive and transitive, but not necessarily antisymmetric. Each preorder induces an <b>equivalence</b> relation between <b>elements,</b> where a is equivalent to b, if a ≤ b and b ≤ a. Preorders can be turned into orders by identifying all elements that are equivalent with respect to this relation.|$|R
50|$|PU(n) has an adjoint {{action on}} SU(n), thus {{it has an}} (n² − 1)-dimensional representation. When n=2 this {{corresponds}} to the three dimensional representation of SO(3). The adjoint action is defined by thinking of an element of PU(n) as an <b>equivalence</b> class of <b>elements</b> of U(n) that differ by phases. One can then take the adjoint action with respect {{to any of these}} U(n) representatives, and the phases commute with everything and so cancel. Thus the action is independent of the choice of representative and so it is well-defined.|$|R
5000|$|Outside of arithmetic, many {{branches}} of mathematics have borrowed the word [...] "quotient" [...] to describe structures built by breaking larger structures into pieces. Given a set with an equivalence relation defined on it, a [...] "quotient set" [...] may be created which contains those <b>equivalence</b> classes as <b>elements.</b> A quotient group may be formed by breaking a group {{into a number}} of similar cosets, while a quotient space may be formed in a similar process by breaking a vector space {{into a number of}} similar linear subspaces.|$|R
40|$|Higher-dimensional {{dependent}} type theory enriches conventional one-dimensional dependent type {{theory with}} additional structure expressing <b>equivalence</b> of <b>elements</b> of a type. This structure may {{be employed in}} a variety of ways to capture rather coarse identifications of elements, such as a universe of sets considered modulo isomorphism. Equivalence must be respected by all families of types and terms, as witnessed computationally by a type-generic program. Higher-dimensional type theory has applications to code reuse for dependently typed programming, and to the formalization of mathematics. In this paper, we develop a novel judgemental formulation of a two-dimensional type theory, which enjoys a canonicity property: a closed term of boolean type is definitionally equal to true or false. Canonicity is a necessary condition for a computational interpretation of type theory as a programming language, and does not hold for existing axiomatic presentations of higherdimensional type theory. The method of proof is a generalization of the NuPRL semantics, interpreting types as syntactic groupoids rather than equivalence relations...|$|R
40|$|From morphic cohomology, {{we produce}} a finite {{sequence}} of conjectures, called morphic conjectures, which terminates at the Grothendieck standard conjecture of Lefschetz type. We generalize {{the notions of}} numerical equivalence and homological equivalence of algebraic cycles to morphic numerical equivalence and morphic homological <b>equivalence</b> of <b>elements</b> in morphic cohomology groups. Some equivalent forms of the conjectures are provided. In particular, the equivalence of these two equivalence relations {{is equivalent to the}} validity of the corresponding morphic conjecture. All morphic conjectures are proved for abelian varieties. We endow the morphic cohomology groups of a smooth projective variety with an inductive limit of mixed Hodge structure and define the morphic Hodge numbers. We generalize the notion of signature to morphic signatures, and for each morphic signature, by assuming the corresponding morphic conjecture, a result analogous to the Hodge index theorem is proved. We prove a conjecture in rational coefficients of Friedlander and Lawson by assuming the Grothendieck standard conjecture B...|$|R
40|$|This {{paper is}} {{the second part of}} a serie of two papers dealing with bulking: a quasi-order on {{cellular}} automata comparing space-time diagrams up to some rescaling. Bulking is a generalization of grouping taking into account universality phenomena, giving rise to a maximal equivalence class. In the present paper, we introduce 3 notions of simulation between cellular automata and study the quasi-order structures induced by these simulation relations on the whole set of cellular automata. Various aspects of these quasi-orders are considered (induced <b>equivalence</b> relations, maximum <b>elements,</b> induced orders, etc) providing several formal tools to classify cellular automata...|$|R
40|$|Using morphic cohomology, {{we produce}} a finite {{sequence}} of conjectures, called morphic conjectures, which terminates at the Grothendieck standard conjecture of Lefschetz type. We generalize {{the notions of}} numerical equivalence and homological equivalence of algebraic cycles to morphic numerical equivalence and morphic homological <b>equivalence</b> of <b>elements</b> in morphic cohomology groups. Some equivalent forms of the conjectures are provided. In particular, these two equivalence relations coincide if and only the corresponding morphic conjecture is valid. All morphic conjectures are proved for abelian varieties. We endow the morphic cohomology groups of a smooth projective variety with an inductive limit of mixed Hodge structure and define the morphic Hodge numbers. We generalize the notion of signature to morphic signatures, and for each morphic signature, by assuming the corresponding morphic conjecture, a result analogous to the Hodge index theorem is proved. We prove a conjecture in rational coefficients of Friedlander and Lawson by assuming the Grothendieck standard conjecture B. As a consequence, we prove that the topological filtration from morphic cohomology {{is equal to the}} Grothendieck arithmetic filtration for some cases. ...|$|R
40|$|This report studies {{when and}} why two Hidden Markov Models (HMMs) may {{represent}} the same stochastic process. HMMs are characterized in terms of <b>equivalence</b> classes whose <b>elements</b> represent identical stochastic processes. This characterization yields polynomial time algorithms to detect equivalent HMMs. We also find fast algorithms to reduce HMMs to essentially unique and minimal canonical representations. The reduction to a canonical form leads {{to the definition of}} 'Generalized Markov Models' which are essentially HMMs without the positivity constraint on their parameters. We discuss how this generalization can yield more parsimonious representations of stochastic processes at the cost of the probabilistic interpretation of the model parameters...|$|R
40|$|AbstractWe {{introduce}} a necessary and sufficient {{condition for the}} ω-extensionality rule of higher-order equational logic to be conservative over first-order many-sorted equational logic for ground first-order equations. This gives a precise condition under which computation in the higher-order initial model by term rewriting is possible. The condition is then generalised to characterise a normal form for higher-order equational proofs in which extensionality inferences occur only as the final proof inferences. The main result {{is based on a}} notion of observational <b>equivalence</b> between higher-order <b>elements</b> induced by a topology of finite information on such elements. Applied to extensional higher-order algebras with countable first-order carrier sets, the finite information topology is metric and second countable in every type...|$|R
40|$|Abstract: The rate of melt {{segregation}} i regional migmatite terrains can {{be estimated}} by various lines of research. Firstly, the segregation rate of a melt batch, with a volume below the melt percolation threshold, cannot exceed the melt production rate and is therefore limited by the heating rate derived from geothermometry and geochronology (method A). Other estimates come from physical models for melt percolation (method B) and from the degree of (dis) equilibrium reached between melt and source rocks (method C). The first method is restricted by the current ime resolution of isotopic techniques. Results from {{the second and third}} approaches depend heavily on assumed values of melt viscosity and other parameters (B); on the correct recognition of (dis) equilibrium trace element distributions (C); and on the migmatization model used (B and C). The validity of method C is undermined by the mathematical <b>equivalence</b> oftrace <b>element</b> models for five different scenarios: (1) disequilibrium elting (with or without melt escape) followed by in situ crystallization fnon-segregated melt; (2) equilibrium elting, followed by equilibrium crystallization and major melt escape; (3) disequilibrium melting, followed by equilibrium crystallization and minor melt escape; (4) pervasive retrograde re...|$|R
40|$|This {{document}} specifies an Internet standards track {{protocol for}} the Internet community, and requests discussion {{and suggestions for}} improvements. Please refer to the current edition of the "Internet Official Protocol Standards " (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. To facilitate the establishment of Label Switched Paths (LSPs) that would span multiple IGP areas in a given Autonomous System (AS), this document describes a new optional Longest-Match Label Mapping Procedure for the Label Distribution Protocol (LDP). This procedure allows {{the use of a}} label if the Forwarding <b>Equivalence</b> Class (FEC) <b>Element</b> matches an entry in the Routing Information Base (RIB). Matching is defined by an IP longest-match search and does not mandate an exact match...|$|R
40|$|This paper {{discusses}} {{an approach}} and {{set of tools}} for translating bibliographic metadata from one format to another. A computational model is proposed to formalize {{the notion of a}} 'crosswalk'. The translation process separates semantics from syntax, and specifies a crosswalk as machine executable translation files which are focused on assertions of <b>element</b> <b>equivalence</b> and are closely associated with the underlying intellectual analysis of metadata translation. A data model developed by the authors called Morfrom serves as an internal generic metadata format. Translation logic is written in an XML scripting language designed by the authors called the Semantic Equivalence Expression Language (Seel). These techniques have been built into an OCLC software toolkit to manage large and diverse collections of metadata records, called the Crosswalk Web Service...|$|R
40|$|A primary {{challenge}} to large-scale data integration is creating semantic <b>equivalences</b> between <b>elements</b> from different data sources {{that correspond to}} the same real-world entity or concept. Dataspaces propose a pay-as-you-go approach: automated mechanisms such as schema matching and reference reconciliation provide initial correspondences, termed candidate matches, and then user feedback is used to incrementally confirm these matches. The key to this approach is to determine in what order to solicit user feedback for confirming candidate matches. In this paper, we develop a decision-theoretic framework for ordering candidate matches for user confirmation using {{the concept of the}} value of perfect information (VPI). At the core of this concept is a utility function that quantifies the desirability of a given state; thus, we devise a utility function for dataspaces based on query result quality. We show in practice how to efficiently apply VPI in concert with this utility function to order user confirmations. A detailed experimental evaluation on both real and synthetic datasets shows that the ordering of user feedback produced by this VPI-based approach yields a dataspace with a significantly higher utility than a wide range of other ordering strategies. Finally, we outline the design of Roomba, a system that utilizes this decision-theoretic framework to guide a dataspace in soliciting user feedback in a pay-as-you-go manner...|$|R
40|$|Abstract. Recently pattern mining has {{investigated}} closure operators in families of subsets of an attribute set {{that are not}} lattices. In particular, various authors have investigated closure operators starting from a context, in the Formal Concept Analysis (FCA) sense, in which objects are described as usual according to their relation to attributes, and in which a closed element is a maximal <b>element</b> of the <b>equivalence</b> class of <b>elements</b> sharing the same support, i. e. occurring in the same objects. The {{purpose of this paper}} is twofold. First we thoroughly investigate this framework and relate it to FCA, defining in particular a structure called a pre-confluence, weaker than a lattice, in which we can define a closure operator with respect to a set of objects. Second, we show that the requirements allowing us Galois pre-confluences. ...|$|R
40|$|In this {{contribution}} {{we present}} a novel constrained clustering method, Constrained clustering with a complex cluster structure (C 4 s), which incorporates equivalence constraints, both positive and negative, as the background information. C 4 s is capable of discovering groups of arbitrary structure, e. g. with multi-modal distribution, since at the initial stage the <b>equivalence</b> classes of <b>elements</b> generated by the positive constraints are split into smaller parts. This provides {{a detailed description of}} elements, which are in positive equivalence relation. In order to enable an automatic detection of the number of groups, the cross-entropy clustering is applied for each partitioning process. Experiments show that the proposed method achieves significantly better results than previous constrained clustering approaches. The advantage of our algorithm increases when we are focusing on finding partitions with complex structure of clusters...|$|R
40|$|This paper {{describes}} {{the concept of}} higher order quotients and an implementation in Isabelle. Higher order quotients are a generalization of quotients. They use partial equivalence relations (PERs) instead of equivalence relations to group together different elements. This makes them applicable to arbitrary function spaces. Higher order quotients are conservatively implemented in the Isabelle logic HOL with a type constructor and a type class for PERs. Ordinary quotients are a special case of higher order quotients. An example shows {{how they can be}} used in Isabelle. 1 Introduction Quotients are used in mathematics to group together different elements. This is done by defining an equivalence relation relating different elements. The quotient is a structure (type) consisting of groups (sets) of equivalent <b>elements,</b> called <b>equivalence</b> classes. Equivalent <b>elements</b> are in the same equivalence class. In formal system and software engineering quotients are used in many ways. For e [...] ...|$|R
50|$|Büchi {{presented}} a doubly exponential complement construction in a logical form.Here, we have his {{construction in the}} modern notation used in automata theory.Let A = (Q,Σ,Δ,Q0,F) be a Büchi automaton.Let ~A be an <b>equivalence</b> relation over <b>elements</b> of Σ+ such thatfor each v,w ∈ Σ+,v ~A w iff for all p,q ∈ Q, A has a run from p to q over v iff this is possible over w and furthermoreA has a run via F from p to q over v iff this is possible over w.By definition,each map f:Q → 2Q × 2Qdefines a class of ~A.We denote the class by Lf.We interpret f in the following way.w ∈ Lf iff,for each state p ∈ Q and (Q1,Q2)= f(p),w can move automaton A from pto each state in Q1 and to each state in Q2 via a state in F.Note that Q2 ⊆ Q1.The following three theorems provides a construction of the complement of A using the equivalence classes of ~A.|$|R
40|$|ABSTRACTOrganizational {{practices}} {{and the establishment}} of the logic of equivalence: the Circuit Beyond the Standard Boundaries {{from the perspective of the}} Political Discourse TheoryOne of the most important political tasks of critical studies about organizations is to explore the processes of resistance organizing. However, this challenge is difficult due to the narrow notion of organization prevalent in the field of organizational studies. In this sense, the political discourse theory (PDT) has emerged as an alternative to understand the processes of resistance experienced by counter-hegemonic organizations, bringing to light alternative practices of organizing. The objective of this work is, within PDT’s framework, to analyze organizational practices developed by the Circuit Beyond the Standard Boundaries (Circuito Fora do Eixo) for the articulation of different initiatives in support of common goals. The case study undertaken shows that categories provided by PDT as articulation and logic of <b>equivalence</b> present important <b>elements</b> for the analysis and understanding of the resistance organizing processes...|$|R
40|$|Hidden Markov Models {{are one of}} {{the most}} popular and {{successful}} techniques used in statistical pattern recognition. However, they are not well understood on a fundamental level. For example, we do not know how to characterize the class of processes that can be well approximated by HMMs. This thesis tries to uncover the source of the intrinsic expressiveness of HMMs by studying when and why two models may represent the same stochastic process. Define two statistical models to be equivalent if they are models of exactly the same process. We use the theorems proved in this thesis to develop polynomial time algorithms to detect equivalence of prior distributions on an HMM, equivalence of HMMs and equivalence of HMMs with fixed priors. We characterize Hidden Markov Models in terms of <b>equivalence</b> classes whose <b>elements</b> represent exactly the same processes and proceed to describe an algorithm to reduce HMMs to essentially unique and minimal, canonical representations. These canonical forms ar [...] ...|$|R
40|$|Study {{on the use}} of the {{constituent}} elements of scores needed for its descriptive representation. Firstly, discusses the concepts of descriptive representation, rules for cataloging using AACR 2 and MARC format for bibliographic records. Secondly, introduces musical concepts; outlines a specific approach on the development of musical notation, bringing attention to concepts of various types of scores and key elements of graphic representation of sounds. It identifies the elements of descriptive representation of Heitor Villa-Lobos’ Brazilian Bachianas no. 1, 2 and 4, and then, points on the relationship of <b>equivalence</b> between the <b>elements</b> identified and the areas of cataloging. Finally, chooses reviewing the model of bibliographic record of the State University of Campinas (UNICAMP) and of the Brazilian National Library (BN), especially emphasizing aspects of descriptive and retrievable paragraphs, on the perspective of professional information and of the musician. Debates the appropriateness of the use of scores elements in bibliographic records, and concludes presenting findings and suggestions for future studies...|$|R
40|$|Bisimulations {{have been}} widely used in many areas of {{computer}} science to model equivalence between various systems, and {{to reduce the number of}} states of these systems, whereas uniform fuzzy relations have recently been introduced as a means to model the fuzzy <b>equivalence</b> between <b>elements</b> of two possible different sets. Here we use the conjunction of these two concepts as a powerful tool in the study of equivalence between fuzzy automata. We prove that a uniform fuzzy relation between fuzzy automata A and B is a forward bisimulation if and only if its kernel and co-kernel are forward bisimulation fuzzy equivalences on A and B and there is a special isomorphism between factor fuzzy automata with respect to these fuzzy equivalences. As a consequence we get that fuzzy automata A and B are UFB-equivalent, i. e., there is a uniform forward bisimulation between them, if and only if there is a special isomorphism between the factor fuzzy automata of A and B with respect to their greatest forward bisimulation fuzzy equivalences. This result reduces the problem of testing UFB-equivalence to the problem of testing isomorphism of fuzzy automata, which is closely related to the well-known graph isomorphism problem. We prove some similar results for backward-forward bisimulations, and we point to fundamental differences. Because of the duality with the studied concepts, backward and forward-backward bisimulations are not considered separately. Finally, we give a comprehensive overview of various concepts on deterministic, nondeterministic, fuzzy, and weighted automata, which are related to bisimulations. Comment: 41 pages, submitted to a journa...|$|R
