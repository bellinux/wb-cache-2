934|453|Public
5|$|UM {{maintains}} one of {{the largest}} centralized academic cyber infrastructures in the country with numerous assets. The Center for Computational Science High Performance Computing group has been in continuous operation since 2007. Over that time the core has grown from a zero HPC cyberinfrastructure to a regional high-performance computing environment that currently supports more than 1,200 users, 220 TFlops of computational power, and more than 3 Petabytes of <b>disk</b> <b>storage.</b> The center's latest system acquisition, an IBM IDataPlex system, was ranked at number 389 on the November 2012 Top 500 Supercomputers.|$|E
5|$|JMP is {{a desktop}} {{application}} with a wizard-based user interface, while SAS {{can be installed}} on servers. It runs in-memory, instead of on <b>disk</b> <b>storage.</b> According to a review in Pharmaceutical Statistics, JMP is often used as a graphical front-end for a SAS system, which performs the statistical analysis and tabulations. JMP Genomics, used for analyzing and visualizing genomics data, requires a SAS component to operate and can access SAS/Genetics and SAS/STAT procedures or invoke SAS macros. JMP Clinical, used for analyzing clinical trial data, can package SAS code within the JSL scripting language and convert SAS code to JMP.|$|E
25|$|In 1962 the IBM350 RAMAC <b>disk</b> <b>storage</b> {{unit was}} {{superseded}} by the IBM1301 <b>disk</b> <b>storage</b> unit, {{which consisted of}} 50 platters, each about 1/8-inch thick and 24 inches in diameter. Whereas the IBM350 used only two read/write heads which were pneumatically actuated and moved in two dimensions, the 1301 {{was one of the}} first <b>disk</b> <b>storage</b> units to use an array of heads, one per platter, moving as a single unit. Cylinder-mode read/write operations were supported, and the heads flew about 250 micro-inches (about 6µm) above the platter surface. Motion of the head array depended upon a binary adder system of hydraulic actuators which assured repeatable positioning. The 1301 cabinet was about the size of three home refrigerators placed side by side, storing the equivalent of about 21 million eight-bit bytes. Access time was about a quarter of a second.|$|E
30|$|The block layer for <b>disk</b> based <b>storage</b> (HDDs) {{has still}} {{remained}} highly volatile as the mechanical disks cannot support multiple hardware queues {{due to their}} physical constraints. Therefore, HDDs can have multiple software queues but single Hardware queue. The objective function of block layer for <b>disk</b> based <b>storage</b> is to optimize the request order from various applications in-order to recreate sequentiality of disk access and manage the I/O bandwidth for every application. BID schemes utilize multiple software queues in the block layer, but single hardware queue for delivering SDS solutions for <b>disk</b> based <b>storage</b> devices.|$|R
5000|$|DEC Technical article: OpenVMS Chart Overview Of Digital <b>Disk</b> Drive <b>Storage</b> Capacities ...|$|R
5000|$|IBM 653 Storage Unit (magnetic tape, <b>disk,</b> core <b>storage,</b> index registers, {{floating}} point arithmetic) ...|$|R
25|$|Some {{operating}} systems and other software {{continue to use}} the customary binary prefixes in displays of memory, <b>disk</b> <b>storage</b> capacity, and file size, but SI prefixes in other areas such as network communication speeds and processor speeds.|$|E
25|$|The $1.2 million USC system {{includes}} a VS 7150 mid-range computer; 30 image workstations, 25 with Freestyle capabilities; a laser printer; five endorsers; and five document scanners. Initial storage for document images is eight gigabytes of magnetic <b>disk</b> <b>storage.</b>|$|E
25|$|As with DAPs, PMPs come {{in either}} flash or hard <b>disk</b> <b>storage.</b> Storage {{capacities}} have {{reached up to}} 64GB for flash memory based PMPs, first reached by the 3rd Generation iPod Touch, and up to 1TB for Hard disk drive PMPs, first achieved by the Archos 5 Internet Tablet.|$|E
5000|$|... "BESYS was {{a complex}} {{software}} package that provided convenient input/output and integrated <b>disk</b> file <b>storage</b> facilities." ...|$|R
40|$|With the {{proliferation}} of inexpensive cameras, availability of large-capacity <b>disk</b> <b>storages,</b> and ubiquitous presence of high-speed, broad-band communication networks, it is now economically and technically feasible to construct and deploy multi-camera video surveillance systems. In line with this is the need of intelligent, robust, (semi-) automated video analysis paradigms to assist the operators in scene analysis and event classification. In this paper, we summarize our current research work toward realizing such a multi-camera video surveillance system. ...|$|R
40|$|International audienceIn Cloud {{storage of}} {{multiple}} CPU cores, many Mapreduce applications may {{run in parallel}} on each compute node and collocate with local <b>Disks</b> <b>storage.</b> These <b>Disks</b> <b>storage</b> are shared by multiple applications that use full CPU power of the node. Each application tends to issue contigu- ous I/O requests in parallel to the same Disk; however if large number of Mapreduce tasks enters the I/O phase at the same time, the requests from the same task may be interrupted by the requests of other tasks. Then, the I/O nodes receive these requests as non-contiguous way under I/O con- tention. This interleaved access pattern causes performance degradation for Mapreduce application, this is particularly important when writing intermediate files by multiple tasks in parallel to the shared Disk stor- age. In order to overcome this problem, we have proposed approach for optimizing write access for Mapreduce application. The contributions of this paper are: 1) analyze the open issues on scheduling access request of Mapreduce workload; 2) propose framework for scheduling and predicting I/O request of Mapreduce application; 3) describe each role of compo- nent that intervenes in the scheduling theses I/O request on Block-level of storage server to provide contiguous acces...|$|R
25|$|The {{hardware}} industry measures {{system memory}} (RAM) using the binary meaning while magnetic <b>disk</b> <b>storage</b> uses the SI definition. However, many exceptions exist. Labeling of diskettes uses the megabyte to denote 1024×1000 bytes. In the optical disks market, Compact Disks use MB to mean 10242 bytes while DVDs use GB to mean 10003 bytes.|$|E
25|$|A floppy disk, {{also called}} a floppy, diskette, or just disk, {{is a type}} of <b>disk</b> <b>storage</b> {{composed}} of a disk of thin and flexible magnetic storage medium, sealed in a rectangular plastic enclosure lined with fabric that removes dust particles. Floppy disks are read and written by a floppy disk drive (FDD).|$|E
25|$|Worldwide {{revenue for}} <b>disk</b> <b>storage</b> {{declined}} 4% per year, {{from a peak}} of $38 billion in 2012 to $27 billion in 2016. Production of HDDs grew 16% per year, from 335 exabytes in 2011 to 693 exabytes in 2016. Shipments declined 7% per year during this time period, from 620 million units to 425 million. Seagate and Western Digital each have 40–45% of unit shipments, while Toshiba has 13–17%. The average sales price for the two largest manufacturers was $60 per unit in 2015.|$|E
40|$|We {{propose a}} disk {{encryption}} method, called secure disk mixed system (SDMS) in this paper, for data protection of <b>disk</b> <b>storages</b> such as USB flash memory, USB hard disk and CD/DVD. It is aimed to solve {{temporal and spatial}} limitation problems of existing disk encryption methods and to control security performance flexibly according to the security requirement of system. SDMS stores data by encrypting with different encryption key per sector and updates sector encryption keys each time data is written. Security performance of SDMS is analyzed {{at the end of}} the paper...|$|R
5000|$|The slim jewel boxes {{used for}} 3" [...] CDs are {{nearly the same}} size as 3.5" [...] floppy <b>disks,</b> making <b>storage</b> boxes for 3.5" [...] floppies usable for 3" [...] CDs as well.|$|R
50|$|The Commodore serial IEEE-488 bus (IEC Bus), is Commodore's {{interface}} for primarily magnetic <b>disk</b> data <b>storage</b> and printers for the Commodore 8-bit home/personal computers, {{notably the}} VIC-20, C64, C128, Plus/4, C16 and C65.|$|R
25|$|CPU-scavenging, cycle-scavenging, or shared {{computing}} {{creates a}} “grid” from the unused resources {{in a network}} of participants (whether worldwide or internal to an organization). Typically this technique uses a desktop computer instruction cycles {{that would otherwise be}} wasted at night, during lunch, or even in the scattered seconds throughout the day when the computer is waiting for user input on relatively fast devices. In practice, participating computers also donate some supporting amount of <b>disk</b> <b>storage</b> space, RAM, and network bandwidth, in addition to raw CPU power.|$|E
25|$|The Dom0 domain {{manages the}} virtual disks {{of the other}} VMs, which are {{actually}} stored as files on the dom0 filesystem(s). Disk space is saved by virtue of various virtual machines (VM) sharing the same root file system in a read-only mode. Separate <b>disk</b> <b>storage</b> is only used for userʼs directory and per-VM settings. This allows software installation and updates to be centralized. It is also possible to install software only on a specific VM, by installing it as the non-root user, or by installing it in the non-standard, Qubes-specific /rw hierarchy.|$|E
25|$|Unlike the K computer, the Tianhe-1A {{system uses}} a hybrid {{architecture}} and integrates CPUs and GPUs. It uses more than 14,000 Xeon general-purpose processors {{and more than}} 7,000 Nvidia Tesla general-purpose graphics processing units (GPGPUs) on about 3,500 blades. It has 112 computer cabinets and 262 terabytes of distributed memory; 2 petabytes of <b>disk</b> <b>storage</b> is implemented via Lustre clustered files. Tianhe-1 uses a proprietary high-speed communication network to connect the processors. The proprietary interconnect network {{was based on the}} Infiniband QDR, enhanced with Chinese made FeiTeng-1000 CPUs. In the case of the interconnect the system is twice as fast as the Infiniband, but slower than some interconnects on other supercomputers.|$|E
50|$|Symbios Logic was a {{manufacturer}} of SCSI host adapter chipsets and <b>disk</b> array <b>storage</b> subsystems. It was originally established as a division of NCR Corporation in 1972, before NCR's takeover by AT&T Corporation in 1991.|$|R
40|$|We {{present the}} design and {{implementation}} of a VOD server that addresses the issues of storage, retrieval, and scheduling {{of a large number}} of video objects as well as the reliability aspects related to striping (distributing) video objects over several hard disks. The result is a multi-platform, distributed video server built from off-the-shelf components that is able to cope with various kinds of heterogeneity (number of <b>disks,</b> <b>storage</b> volume of <b>disks,</b> number of disk servers, variety of striping techniques, range of redundancy codecs). Further, our video server runs on multiple platforms (SOLARIS, Windows NT). Reliability is guaranteed through the optional use of parityor mirroring-based reliability techniques...|$|R
50|$|Kickstart version 1.3 {{improved}} {{little on}} its predecessor, {{the most notable}} change being auto booting from hard drives. Workbench 1.3, on the other hand, users can find several significant improvements to Workbench, including FFS a faster file system for hard <b>disks</b> <b>storage</b> which resolved the problem of old Amiga filesystem which wasted too much hard disk space {{due to the fact}} it could store only 488 bytes in any block of 512 bytes keeping 24 bytes for checksums. Many improvements were made to the CLI (command line interface) of Amiga which was now a complete text based Shell, named AmigaShell, and various additional tools and programs.|$|R
25|$|A {{significant}} portion of the Saudi Aramco workforce consists of geophysicists and geologists. Saudi Aramco has been exploring for oil and gas reservoirs since 1982. Most of this process takes place at the Exploration and Petroleum Engineering Center (EXPEC). Originally, Saudi Aramco used Cray Supercomputers (CRAY-1M) in its EXPEC Computer Center (ECC) to assist in processing the colossal quantity of data obtained during exploration and in 2001, ECC decided to use Linux clusters as a replacement for the decommissioned Cray systems. ECC installed a new supercomputing system in late 2009 with a <b>disk</b> <b>storage</b> capacity of 1,050 terabytes (i.e, exceeding one petabyte), the largest storage installation in Saudi Aramco's history to support its exploration in the frontier areas and the Red Sea.|$|E
25|$|The name of {{the file}} system {{originates}} from the file system's prominent usage of an index table, the File Allocation Table, statically allocated {{at the time of}} formatting. The table contains entries for each cluster, a contiguous area of <b>disk</b> <b>storage.</b> Each entry contains either the number of the next cluster in the file, or else a marker indicating end of file, unused disk space, or special reserved areas of the disk. The root directory of the disk contains the number of the first cluster of each file in that directory; the operating system can then traverse the FAT table, looking up the cluster number of each successive part of the disk file as a cluster chain {{until the end of the}} file is reached. In much the same way, sub-directories are implemented as special files containing the directory entries of their respective files.|$|E
25|$|Other than {{counting}} {{the number of}} ions crossing the channel, sometimes it is desirable to study their behavior at different regions of the channel. Such examples would be the average occupancy of ions or their average moving velocity inside the channel or a nanopore. BioMOCA has been equipped with the option of dumping every ions position, average and instantaneous velocities, potential and kinetic energies, average and instantaneous displacements and other info at every step (or few steps) of the simulations in ASCII format, so such trajectory information could be studied later on to gather further statistics. From a technical point of view however, dumping such information for tens of ions, even at every few hundreds of time steps, could slow down the simulations and end up with huge files accumulating to tens of gigabytes. Loading such files later on from <b>disk</b> <b>storage</b> is also a very time consuming and computationally inefficient procedure. Over and above that, recoding the numerical information in ASCII format does not hold its machine precision and has loss of accuracy.|$|E
50|$|Most of the {{functionality}} of GlusterFS {{is implemented}} as translators, including file-based mirroring and replication, file-based striping, file-based load balancing, volume failover, scheduling and <b>disk</b> caching, <b>storage</b> quotas, and volume snapshots with user serviceability (since GlusterFS version 3.6).|$|R
5000|$|CD is {{an acronym}} for Compact Disc. The speed is much less than a hard <b>disk.</b> The <b>storage</b> {{capacity}} is approximately 700 MB {{depending on whether the}} data stored on it is compressed or not. Types of CDs include: ...|$|R
5000|$|RAM <b>disk</b> - Virtual <b>storage</b> device {{within a}} single computer, limited to {{capacity}} of local RAM.|$|R
500|$|... 1980s {{software}} crackers added custom introductory credits sequences (intros) {{to programs}} whose copy protection they had removed. Increasing computing power allowed for more complex intros, and the demoscene formed when focus {{shifted to the}} intros instead of the cracks. The goal became to create the best 3-D demos in real-time with {{the least amount of}} software code. <b>Disk</b> <b>storage</b> was too slow for this; graphics had to be calculated on the fly and without a pre-existing game engine.|$|E
2500|$|By {{the mid-1970s}} {{it was common}} to see K meaning 1024 and the {{occasional}} M meaning [...] for words or bytes of main memory (RAM) while K and M were commonly used with their decimal meaning for <b>disk</b> <b>storage.</b> In the 1980s, as capacities of both types of devices increased, the SI prefix G, with SI meaning, was commonly applied to <b>disk</b> <b>storage,</b> while M in its binary meaning, became common for computer memory. In the 1990s, the prefix G, in its binary meaning, became commonly used for computer memory capacity. The first terabyte (SI prefix, [...] bytes) hard disk drive was introduced in 2007.|$|E
2500|$|Donald Knuth speculates on the {{etymology}} of B-trees in his May, 1980 {{lecture on}} the topic [...] "CS144C classroom lecture about <b>disk</b> <b>storage</b> and B-trees", suggesting the [...] "B" [...] may have originated from Boeing or from Bayer's name.|$|E
25|$|Later in 2008, the FreeBSD Release Engineering Team {{announced}} that the cipher had also {{been included in the}} FreeBSD 6.4-RELEASE. Also, support for the Camellia cipher was added to the <b>disk</b> encryption <b>storage</b> class geli of FreeBSD by Yoshisato Yanagisawa.|$|R
50|$|BYTE criticized EasyWriter II {{for running}} as a booter instead of using DOS, {{requiring}} specially formatted <b>disks</b> for <b>storage</b> and a utility to convert to DOS-formatted disks, not being compatible with double-sided drives, and using a heavily modal editing interface.|$|R
50|$|Later in 2008, the FreeBSD Release Engineering Team {{announced}} that the cipher had also {{been included in the}} FreeBSD 6.4-RELEASE. Also, support for the Camellia cipher was added to the <b>disk</b> encryption <b>storage</b> class geli of FreeBSD by Yoshisato Yanagisawa.|$|R
