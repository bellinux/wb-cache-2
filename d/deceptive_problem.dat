23|49|Public
40|$|This paper {{identifies}} the complexity class of statically constructed partially deceptive problems by proving a turing reduction of 3 -SAT problem to partially <b>deceptive</b> <b>problem.</b> This essentially {{proves that the}} class of partially deceptive problems is NP-turing complete and one {{may not be able}} to find a polynomial complexity algorithm for solving deceptive problems unless P = NP. This paper also addresses the issue of either constructing a non-deceptive representation or somehow transforming the problem itself to a non-deceptive one. It is observed that such efforts are likely to rely on the a priori knowledge of the order of deception. Unfortunately, determining the order of deception turns out to be an NP-hard problem. The Class Of Statically Deceptive Problems Is NP-Turing Complete Abstract This paper {{identifies the}} complexity class of statically constructed partially deceptive problems by proving a turing reduction of 3 -SAT problem to partially <b>deceptive</b> <b>problem.</b> This essentiall [...] ...|$|E
40|$|Partially Observable Markov Decision Process (POMDP) is a {{representative}} class of non-Markovian environments, where agents sense dierent environmental {{states as the}} same sensory input. We recognize that full implementation of POMDPs must overcome two deceptive problems. We call confusion of state values a type 1 <b>deceptive</b> <b>problem</b> and indistinction of rational and irrational rules a type 2 <b>deceptive</b> <b>problem.</b> The type 1 problem deceives Q-learning [Watkins 92], the most widely-used method in which state values are estimated. Though Prot Sharing that satises Rationality Theorem [Miyazaki 94] is not deceived by type 1 problems, it cannot overcome a type 2 problem. In this paper, we propose {{a new approach to}} POMDPs. For the subclass environment that does not need a stochastic policy, we consider to learn a deterministic rational policy to avoid all states that contain a type 2 problem. We claim that the weight as an evaluation factor of a rule has the possibility to derive an irration [...] ...|$|E
40|$|Upper Confidence Trees {{are a very}} {{efficient}} tool for solving Markov Decision Processes; originating in difficult games like the game of Go, it is in particular surprisingly efficient in high dimensional problems. It is known {{that it can be}} adapted to continuous domains in some cases (in particular continuous action spaces). We here present an extension of Upper Confidence Trees to continuous stochastic problems. We (i) show a <b>deceptive</b> <b>problem</b> on which the classical Upper Confidence Tree approach does not work, even with arbitrarily large computational power and with progressive widening (ii) propose an improvement, termed double-progressive widening, which takes care of the compromise between variance (we want infinitely many simulations for each action/state) and bias (we want sufficiently many nodes to avoid a bias by the first nodes) and which extends the classical progressive widening (iii) discuss its consistency and show experimentally that it performs well on the <b>deceptive</b> <b>problem</b> and on experimental benchmarks. We guess that the double-progressive widening trick can be used for other algorithms as well, as a general tool for ensuring a good bias/variance compromise in search algorithms...|$|E
40|$|<b>Deceptive</b> <b>problems</b> {{have been}} {{considered}} difficult for ant colony optimization (ACO) and {{it was believed that}} ACO will fail to converge to global optima of <b>deceptive</b> <b>problems.</b> This paper presents a convergence analysis of ACO on deceptive systems. This paper proves, for the first time, that ACO can achieve reachability convergence but not asymptotic convergence for a class of first order deceptive systems (FODS) without assuming a minimum pheromone at each iteration. Experimental results confirm the analysis. ...|$|R
40|$|Abstract—Deceptive {{problems}} are {{a class of}} challenging problems for conventional genetic algorithms (GAs), which usually mislead the search to some local optima rather than the global optimum. This paper presents an improved genetic algorithm with reserve selection to solve <b>deceptive</b> <b>problems.</b> The concept “potential ” of individuals is introduced as a new criterion for selecting individuals for reproduction, where some individuals with low fitness are also let survive only if they have high potentials. An operator called adaptation is further employed to release the potentials for approaching the global optimum. Case studies are done in two <b>deceptive</b> <b>problems,</b> demonstrating {{the effectiveness of the}} proposed algorithm. I...|$|R
40|$|Abstract- In <b>deceptive</b> <b>problems</b> many runs lead to {{suboptimal}} {{solutions and}} {{it can be difficult to}} escape from these local optima and find the global best solution. We propose a pyramid search strategy for these kinds of problems. In the pyramid strategy a number of populations are initialised and independently evolved for a number of generations at which point the worst performing populations are discarded. This evolve/discard process is continued until the problem is solved or one population remains. We show that for a number of <b>deceptive</b> <b>problems</b> the pyramid strategy results in a higher probability of success with fewer evaluations and a lower standard deviation of the number evaluations to success than the conventional approach of running to a maximum number of generations and then restarting. ...|$|R
40|$|In this lesson, short <b>deceptive</b> <b>problem</b> {{stories are}} {{presented}} to the class and students are challenged to solve each problem by asking only yes/no questions. The key is for students to recognize: what the False Assumption is that makes the solution tricky; that many common problems are difficult to solve because we tend to assume a particular paradigm; and that science {{is a way to}} work around or through those false assumptions. Educational levels: High school, Middle school...|$|E
40|$|International audienceUpper Con dence Trees {{are a very}} e cient {{tool for}} solving Markov Decision Processes; {{originating}} in di cult games like the game of Go, it is in particular surprisingly e cient in high dimensional problems. It is known {{that it can be}} adapted to continuous domains in some cases (in particular continuous action spaces). We here present an extension of Upper Con dence Trees to continuous stochastic problems. We (i) show a <b>deceptive</b> <b>problem</b> on which the classical Upper Con dence Tree approach does not work, even with arbitrarily large computational power and with progressive widening (ii) propose an improvement, termed double-progressive widening, which takes care of the compromise between variance (we want in nitely many simulations for each action/state) and bias (we want su ciently many nodes to avoid a bias by the rst nodes) and which extends the classical progressive widening (iii) discuss its consistency and show experimentally that it performs well on the <b>deceptive</b> <b>problem</b> and on experimental benchmarks. We guess that the double-progressive widening trick can be used for other algorithms as well, as a general tool for ensuring a good bias/variance compromise in search algorithms...|$|E
40|$|International audienceUpper Confidence Trees {{are a very}} {{efficient}} tool for solving Markov Decision Processes; originating in difficult games like the game of Go, it is in particular surprisingly efficient in high dimensional problems. It is known {{that it can be}} adapted to continuous domains in some cases (in particular continuous action spaces). We here present an extension of Upper Confidence Trees to continuous stochastic problems. We (i) show a <b>deceptive</b> <b>problem</b> on which the classical Upper Confidence Tree approach does not work, even with arbitrarily large computational power and with progressive widening (ii) propose an improvement, termed double-progressive widening, which takes care of the compromise between variance (we want infinitely many simulations for each action/state) and bias (we want sufficiently many nodes to avoid a bias by the first nodes) and which extends the classical progressive widening (iii) discuss its consistency and show experimentally that it performs well on the <b>deceptive</b> <b>problem</b> and on experimental benchmarks. We guess that the double-progressive widening trick can be used for other algorithms as well, as a general tool for ensuring a good bias/variance compromise in search algorithms...|$|E
40|$|For most usual {{optimisation}} problems, the Nearer is Better {{assumption is}} true (in probability), This property is {{taken into account}} by the classical iterative algorithms, either explicitly or implicitly, by forgetting some information collected during the process, assuming it is not useful any more. However, when the property is not globally true, i. e. for <b>deceptive</b> <b>problems,</b> {{it may be necessary}} to keep all the sampled points and their values, and to exploit this increasing amount of information. Such a basic Total Memory Optimiser is presented. We show on an example that it can outperform classical methods on <b>deceptive</b> <b>problems.</b> As it is very computing time consuming as soon as the dimension of the problem increases, a few compromises are suggested to speed it up...|$|R
40|$|We {{propose a}} {{hardware}} {{implementation of the}} Compact Genetic Algorithm (Compact GA). The design is realized using Verilog HDL, then fabricated on FPGA. Our design, though simple, runs about 1, 000 {{times faster than the}} software executing on a workstation. An alternative hardware for linkage learning is also proposed in order to enhance the capability of Compact GA to solve highly <b>deceptive</b> <b>problems...</b>|$|R
40|$|This paper {{presents}} several theorems {{concerning the}} nature of deception and the central role that deception plays in function optimization using genetic algorithms. A simple proof is offered which shows that the only problems which pose challenging optimization tasks are problems that involve some degree of deception and which result in conflicting k-arm bandit competitions between hyperplanes. The concept of a deceptive attractor is introduced and shown to be more general than the deceptive optimum found in the deceptive functions that have been constructed to date. Also introduced are the concepts of fully <b>deceptive</b> <b>problems</b> as well as less strict consistently <b>deceptive</b> <b>problems.</b> A proof is given showing that deceptive attractors must have a complementary bit pattern to that found in the binary representation of the global optimum if a function is to be either fully deceptive or consistently deceptive. Some empirical results are presented which demonstrate different methods of dealing with deception and poor linkage during genetic search...|$|R
40|$|Abstract—This paper {{shows that}} the first order <b>deceptive</b> <b>problem</b> of ant colony {{algorithm}} satisfies value convergence under certain initial pheromone distribution, but does not satisfy solution convergence. We also estimate the expected number of iterations required to reach the optimal solution by ACO on the first-order deceptive systems taking the n-bit trap problem as the test instance. We prove that such expected number of iterations required is O(n. log n), here n {{is the size of}} the problem. Index Terms—ant colony optimization, deceptive problems, n-bit trap problem I...|$|E
40|$|Abstract-Deception {{problems}} {{are among the}} hardest problems to solve using ordinary genetic algorithms. Recent studies show that Bayesian optimization can help in solving these probIems. This paper compares the results acquired from the multiobjective fast messy genetic algorithm (MOMGA-II), multiobjective Bayesian optimization algorithm (mBOA), and the non-dominated sorting genetic algorithm-I 1 (NSGA- 11) when applied to three different deception problems. The three deceptive problems studies are: interleaved minimal <b>deceptive</b> <b>problem,</b> interleaved 5 -bit trap function, and the interleaved 6 -bit bipolar function. The unmodijed MOMGA- 11, hy design, explicitly learns building block linkages which is required if an algorithm is to solve these hard deception problems. Preliminary results using the MOMGA-I 1 are favorable. I...|$|E
40|$|The same {{mechanisms}} {{that are so}} efficient at finding optima {{may result in a}} conventional Particle Swarm Optimisation (PSO) algorithm becoming trapped in a local optimum and unable to escape from this to search for further, hopefully better, optima. This problem becomes more significant as the dimensionality of the problem space increases. A new algorithm that uses Waves of Swarm Particles (WoSP) is introduced that allows a swarm to escape from an optimum and forces it to go on exploring. Results are given for a <b>deceptive</b> <b>problem</b> in both 30 and 100 dimensions. The WoSP algorithm performs well on these problems, encouraging the application of WoSP to other multi-optima high dimensionality problems...|$|E
40|$|This paper {{proposes a}} {{competent}} multi-objective genetic algorithm called the multiobjective Bayesian optimization algorithm (mBOA). mBOA incorporates the selection method of the non-dominated sorting genetic algorithm-II (NSGA-II) into the Bayesian optimization algorithm (BOA). The proposed algorithm {{has been tested}} on an array of test functions which incorporate deception and loose-linkage {{and the results are}} compared to those of NSGA-II. Results indicate that mBOA outperforms NSGA-II on large loosely linked <b>deceptive</b> <b>problems...</b>|$|R
40|$|Abstract. Embedded Cartesian Genetic Programming (ECGP) is an {{extension}} of Cartesian Genetic Programming (CGP) capable of acquiring, evolving and re-using partial solutions. In this paper, we apply for the first time CGP and ECGP to the ones-max and order- 3 <b>deceptive</b> <b>problems,</b> which are normally associated with Genetic Algorithms. Our approach uses CGP and ECGP to evolve a sequence of commands for a tape-head, which produces an arbitrary length binary string on a piece of tape. Computational effort figures are calculated for CGP and ECGP and our results compare favourably with those of Genetic Algorithms. ...|$|R
40|$|International audienceThis Note {{describes}} a mechanical etching technique {{which can be}} used to prepare silicon tips used in atomic force microscopy apparatus. For such devices, dedicated tips with specific shapes are now commonly used to probe surfaces. Yet, the control of the tip morphology where characteristic scales are lower than 1 ֭ remains a real challenge. Here, we detail a controlled etching process of AFM probes apex allowing micrometer-sized sphere attachment. The technique used and influent parameters are discussed and SEM images of the achieved tips are given. <b>Deceptive</b> <b>problems</b> and drawbacks that might occur during the process are also covered...|$|R
40|$|This paper {{explores the}} {{distribution}} of population elements among niches arising under deterministic crowding. Crossover interactions among niches are observed, isolated, and explained. Ideal behavior is compared with actual behavior {{on a variety of}} multimodal optimization problems, including a multimodal <b>deceptive</b> <b>problem.</b> I. Introduction Niching methods in genetic algorithms (GAs) strive to locate and maintain stable subpopulations or niches, within a single population. While sharing techniques [1, 2] have proven effective, crowding methods [3, 4] are also promising. Previously, little was known about the expected behavior of crowding methods. In this study, crowding turns out to behave far differently than sharing. Intrinsic properties of crowding are uncovered via controlled experimentation and intuitive modelling. Specifically, we concentrate upon the distributions arising from the combination of crossover and replacement selection in deterministic crowding. This combination [...] ...|$|E
40|$|In {{this paper}} we analyse the {{resilience}} of a Peer-to-Peer (P 2 P) Evolutionary Algorithm (EA) subject to the following dynamics: computing nodes acting as peers leave the system indepen-dently from each other causing a collective effect known as churn. Since the P 2 P EA {{has been designed to}} tackle large instances of computationally expensive problems, we will assess its be-haviour under these conditions, by performing a scalability analysis in five different scenarios using the Massively Multimodal <b>Deceptive</b> <b>Problem</b> as a benchmark. In all cases, the P 2 P EA reaches the success criterion without a penalty on the runtime. We show that the key to the algorithm resilience is to ensure enough peers {{at the beginning of the}} ex-periment; even if some of them leave, those that remain contain enough information to guarantee a reliable convergence...|$|E
40|$|In recent years, {{several studies}} have been devoted {{to the design of}} {{problems}} with different degrees of deception in order to investigate the performance of GAs. This paper presents a different genetic approach, called the Structured Genetic Algorithm (sGA) for solving GA-deceptive problems. The Structured GA uses an hierarchical encoding and a gene expression mechanism in its overspecified chromosomal representation. The paper reported some experimental results which demonstrated that on using a different chromosomal representation (as in sGA), the genetic search becomes more robust and can easily handle so-called GAdeceptive problems. I. Introduction The notation of deception in GAs was first introduced by Goldberg, following the early work of Bethke [1]. He defined a Minimal <b>Deceptive</b> <b>Problem</b> (MDP) [7], in order to better understand what kinds of search space are difficult for a genetic algorithm when performing optimisation tasks. Since then, deception has become a central feature [...] ...|$|E
40|$|It is {{well known}} that using high-locality {{representations}} is important for efficient evolutionary search. This paper discusses in detail how the locality of a representation influences the difficulty of a problem when using mutation-based search approaches. The results show that high-locality representations do not change problem difficulty. In contrast, low-locality representations randomize the search process and make problems that are easy for mutation-based search more difficult and difficult problems more easy. Although low-locality representations increase the performance of local search on difficult, <b>deceptive</b> <b>problems</b> this is not relevant for real-world problems as we assume that most problems in the real-world are easy for mutation-based search...|$|R
40|$|This paper {{introduces}} and analyzes {{a parallel}} method of simulated annealing. Borrowing from genetic algorithms, an effective combination of simulated annealing and genetic algorithms, called parallel recombinative simulated annealing, is developed. This new algorithm strives {{to retain the}} desirable asymptotic convergence properties of simulated annealing, while adding the populations approach and recombinative power of genetic algorithms. The algorithm iterates a population of solutions rather than a single solution, employing a binary recombination operator {{as well as a}} unary neighborhood operator. Proofs of global convergence are given for two variations of the algorithm. Convergence behavior is examined, and empirical distributions are compared to Boltzmann distributions. Parallel recombinative simulated annealing is amenable to straightforward implementation on SIMD, MIMD, or shared-memory machines. The algorithm, implemented on the CM- 5, is run repeatedly on two <b>deceptive</b> <b>problems</b> [...] ...|$|R
40|$|THis paper {{presents}} {{a new approach}} to the field of genetic algorithms, basedon the indroduction of dependency between genes, as inspired by Grammatical Evolution. A system based on that approach, LINKGUAGE, is presented, and results reported show how the dependency between genes creates a tight linkage, guiding the system to success on hard <b>deceptive</b> linkage <b>problems...</b>|$|R
40|$|This paper {{discusses}} scalability {{of standard}} genetic programming (GP) and the probabilistic incremental program evolution (PIPE). To investigate {{the need for}} both effective mixing and linkage learning, two test problems are considered: ORDER problem, which is rather easy for any recombinationbased GP, and TRAP or the deceptive trap problem, which requires the algorithm to learn interactions among subsets of terminals. The scalability results show that both GP and PIPE scale up polynomially with problem size on the simple ORDER problem, but they both scale up exponentially on the <b>deceptive</b> <b>problem.</b> This indicates that while standard recombination is sufficient when no interactions need to be considered, for some problems linkage learning is necessary. These results are {{in agreement with the}} lessons learned in the domain of binary-string genetic algorithms (GAs). Furthermore, the paper investigates the effects of introducing unnecessary and irrelevant primitives on the performance of GP and PIPE...|$|E
40|$|Abstract—Ant colony {{optimization}}(ACO), {{which is}} one of the intelligential optimization algorithm, has been widely used to solve combinational optimization problems. Deceptive problems have been considered difficult for ant colony optimization. It was believed that ACO will fail to converge to global optima of deceptive problems. This paper proves that the first order <b>deceptive</b> <b>problem</b> of ant colony algorithm satisfies value convergence under certain initial pheromone distribution, but does not satisfy solution convergence. We also present a first attempt towards the value-convergence time complexity analysis of ACO on the first-order deceptive systems taking the n-bit trap problem as the test instance. We prove that time complexity of MMAS, which is an ACO with limitations of the pheromone on each edge, on n-bit trap problem is O(n 2 m. log n), here n is the size of the problem and m is the number of artificial ants. Our experimental results confirm the correctness of our analysis. Index Terms—ant colony optimization, deceptive problems, n-bit trap problem I...|$|E
40|$|Ant colony {{optimization}}(ACO), {{which is}} one of the intelligential optimization algorithm, has been widely used to solve combinational optimization problems. Deceptive problems have been considered difficult for ant colony optimization. It was believed that ACO will fail to converge to global optima of deceptive problems. This paper proves that the first order <b>deceptive</b> <b>problem</b> of ant colony algorithm satisfies value convergence under certain initial pheromone distribution, but does not satisfy solution convergence. We also present a first attempt towards the value-convergence time complexity analysis of ACO on the first-order deceptive systems taking the n -bit trap problem as the test instance. We prove that time complexity of MMAS, which is an ACO with limitations of the pheromone on each edge, on n -bit trap problem is O(n 2 m. log n), here n is the size of the problem and m is the number of artificial ants. Our experimental results confirm the correctness of our analysis. </p...|$|E
40|$|Testimony {{issued by}} the General Accounting Office with an {{abstract}} that begins "Pursuant to a congressional request, GAO discussed matters related to deceptive mail marketing practices, focusing on the extent and nature of consumers' <b>problems</b> with <b>deceptive</b> mail and the initiatives various federal agencies and other organizations have made to address <b>deceptive</b> mail <b>problems</b> and educate consumers. ...|$|R
40|$|Abstract- This paper {{introduces}} a coevolutionary approach to genetic algorithms (GAs) for exploring not only wihtin {{a part of}} the solution space defined by the genotype-phenotype map but also the map it-self. In canonical GAs with the fixed map, how large area of the solution space can be covered by possible genomes and consequently how better solutions can be found by a GA rely on how well the genotype-phenotype map is designed, but it is difficult for de-signers of the algorithms to designe the map with-out a-priori knowledge of the solution space. In the proposed algorithm, the genotype-phenotype map is improved adaptively during the searching process for solution candidates. It is applied to 3 -bit <b>deceptive</b> <b>problems</b> as a kind of typical combinatorial optimiza-tion problems, which are well-known by that the dif-fculty against GAs can be controlled by the genotype-phenotype map, and shows fairly good performance beside a conventional GA. I...|$|R
40|$|This chapter {{presents}} SMuGA, an {{integration of}} symbiogenesis with the Multiset Genetic Algorithm (MuGA). The symbiogenetic approach used here {{is based on}} the host-parasite model with the novelty of varying the length of parasites along the evolutionary process. Additionally, it models collaborations between multiple parasites and a single host. To improve efficiency, we introduced proxy evaluation of parasites, which saves fitness function calls and exponentially reduces the symbiotic collaborations produced. Another novel feature consists of breaking the evolutionary cycle into two phases: a symbiotic phase and a phase of independent evolution of both hosts and parasites. SMuGA was tested in optimization of a variety of deceptive functions, with results one order of magnitude better than state of the art symbiotic algorithms. This allowed to optimize <b>deceptive</b> <b>problems</b> with large sizes, and showed a linear scaling in the number of iterations to attain the optimum...|$|R
40|$|Deceptivity and {{epistasis}} both {{contribute to}} make fitness functions hard to optimize for a genetic algorithm. In this note {{we examine the}} relation between these concepts, with particular emphasis on their mutual reinforcement. INTRODUCTION There are several factors which can make a fitness function f hard to optimize, including deceptivity and high epistasis. By a thorough investigation of the length 2 case, we show that these properties are essentially independent, but may mutually reinforce each other. In particular, epistasis is responsable for the different behavior of the type I and type II minimal <b>deceptive</b> <b>problem.</b> 1. EPISTASIS In genetics, a gene or gene pair {{is said to be}} epistatic to a gene at another locus, if it masks the (phenotypical) expression of the second one, cf. [6]. In this way, epistasis expresses links between separate genes in a chromosome. The analogous notion in the context of genetic algorithms (GAs) was introduced by Rawlins [5], who defines minimal epista [...] ...|$|E
40|$|Abstract. Deception {{problems}} {{are among the}} hardest problems to solve using ordinary genetic algorithms. Designed to simulate {{a high degree of}} epistasis, these deception problems imitate extremely difficult real world problems. [1]. Studies show that Bayesian optimization and explicit building block manipulation algorithms, like the fast messy genetic algorithm (fmGA), can help in solving these problems. This paper compares the results acquired from an extended multiobjective fast messy genetic algorithm (MOMGA-IIa), ordinary multiobjective fast messy genetic algorithm (MOMGA-II), multiobjective Bayesian optimization algorithm (mBOA), and the non-dominated sorting genetic algorithm-II (NSGA-II) when applied to three different deception problems. The extended MOMGA-II is enhanced with a new technique exploiting the fmGA’s basis function to improve partitioned searching in both the genotype and phenotype domain. The three deceptive problems studied are: interleaved minimal <b>deceptive</b> <b>problem,</b> interleaved 5 -bit trap function, and interleaved 6 -bit bipolar function. The unmodified MOMGA-II, by design, explicitly learns building block linkages, a requirement if an algorithm is to solve these hard deception problems. Results using the MOMGA-IIa are excellent when compared to the non-explicit building block algorithm results of both the mBOA and NSGA-II. ...|$|E
40|$|In {{evolutionary}} algorithms, {{the fitness}} {{of a population}} increases with time by mutating and recombining individuals and by a biased selection of more fit individuals. The right selection pressure is critical in ensuring sufficient optimization progress {{on the one hand}} and in preserving genetic diversity to be able to escape from local optima on the other hand. Motivated by a universal similarity relation on the individuals, we propose a new selection scheme, which is uniform in the fitness values. It generates selection pressure toward sparsely populated fitness regions, not necessarily toward higher fitness, as is the case for all other selection schemes. We show analytically on a simple example that the new selection scheme can be much more effective than standard selection schemes. We also propose a new deletion scheme which achieves a similar result via deletion and show how such a scheme preserves genetic diversity more effectively than standard approaches. We compare the performance of the new schemes to tournament selection and random deletion on an artificial <b>deceptive</b> <b>problem</b> and a range of NP-hard problems: traveling salesman, set covering and satisfiability. Comment: 25 double-column pages, 12 figure...|$|E
40|$|A {{measure of}} search difficulty, fitness {{distance}} correlation (FDC), is introduced and examined {{in relation to}} genetic algorithm (GA) performance. In many cases, this correlation {{can be used to}} predict the performance of a GA on problems with known global maxima. It correctly classifies easy <b>deceptive</b> <b>problems</b> as easy and difficult non-deceptive problems as difficult, indicates when Gray coding will prove better than binary coding, and is consistent with the surprises encountered when GAs were used on the Tanese and royal road functions. The FDC measure is a consequence of an investigation into the connection between GAs and heuristic search. 1 INTRODUCTION A correspondence between evolutionary algorithms and heuristic state space search is developed in (Jones, 1995 b). This is based on a model of fitness landscapes as directed, labeled graphs that are closely related to the state spaces employed in heuristic search. We examine one aspect of this correspondence, the relationship between [...] ...|$|R
40|$|A {{chemical}} {{genetic algorithm}} (CGA) in which {{several types of}} molecules (information units) react {{with each other in}} a cell is proposed. Translation from codons (short substrings of bits) in DNA to amino acids (real value units) is specified by a particular set of translation molecules created by the reaction between tRNA units and amino acid units. This adaptively changes and optimizes the fundamental genotype-phenotype mapping during evolution. Through the struggle between cells containing a DNA unit and small molecular units, the codes in DNA and the translation table described by the small molecular units coevolve, and a specific output function (protein), which is used to evaluate a cell's fitness, is optimized. To demonstrate the e#ectiveness of the CGA, the algorithm is applied to a set of <b>deceptive</b> <b>problems,</b> and the results by using the CGA are compared to those by using a simple GA. It is shown that the CGA has far better performance for the tested functions than the conventional simple GA...|$|R
40|$|In {{this paper}} the {{simplest}} version of Population Based Incremental Learning (PBIL) {{is used to}} minimize the OneMax function in two dimensions. After carrying out several experiments to reveal the limit behavior of the algorithm in this function we obtain that the convergence results depend on the initial vector p (0), and on the # parameter value. This experienced behavior is guaranteed for mathematical proof. The probability that the algorithm converges to any point of the search space goes to 1 when p (0) and # go to suitable values. Thus, even though the experimental results seem more stable when the # value is near to zero, we can not ensure that PBIL converges to the optimum. 1 Introduction During the nineties many real combinatorial optimization problems have been solved successfully using Genetic Algorithms (GAs). But the existence of <b>deceptive</b> <b>problems</b> where the performance of GAs is very poor have motivated the search for new optimization algorithms. To overcome these di [...] ...|$|R
