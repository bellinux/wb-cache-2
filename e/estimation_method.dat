9362|9875|Public
25|$|A pedotransfer {{function}} (PTF) is a specialized empirical <b>estimation</b> <b>method,</b> used {{primarily in the}} soil sciences, however has increasing use in hydrogeology. There are many different PTF methods, however, they all attempt to determine soil properties, such as hydraulic conductivity, given several measured soil properties, such as soil particle size, and bulk density.|$|E
25|$|While {{the tools}} of data {{analysis}} work best on data from randomized studies, they are also applied to other kinds of data – like natural experiments and observational studies – for which a statistician would use a modified, more structured <b>estimation</b> <b>method</b> (e.g., Difference in differences estimation and instrumental variables, among many others) that produce consistent estimators.|$|E
25|$|Estimates of {{the average}} number of unique {{messenger}} RNAs that are targets for repression by a typical miRNA vary, depending on the <b>estimation</b> <b>method,</b> but multiple approaches show that mammalian miRNAs can have many unique targets. For example, an analysis of the miRNAs highly conserved in vertebrates shows that each has, on average, roughly 400 conserved targets. Likewise, experiments show that a single miRNA species can reduce the stability of hundreds of unique messenger RNAs. Other experiments show that a single miRNA species may repress the production of hundreds of proteins, but that this repression often is relatively mild (much less than 2-fold). The first human disease associated with deregulation of miRNAs was chronic lymphocytic leukemia. Other B cell malignancies followed.|$|E
40|$|The mutual {{information}} is useful {{measure of a}} random vector component dependence. It is important in many technical applications. The <b>estimation</b> <b>methods</b> are often based on the well known relation between the {{mutual information}} and the appropriate entropies. In 1999 Darbellay and Vajda proposed a direct <b>estimation</b> <b>methods.</b> In this paper we compare some available <b>estimation</b> <b>methods</b> using different 2 -D random distributions...|$|R
40|$|Should we {{be using}} {{relative}} <b>estimation</b> <b>methods</b> in software effort estimation? This thesis looks into {{an aspect of}} agile estimating by comparing the effects of using relative <b>estimation</b> <b>methods</b> with absolute <b>estimation</b> <b>methods</b> for software development effort estimates. The thesis describes a study conducted on a software development project where estimates in story points (relative) and ideal time (absolute) are provided using planning poker...|$|R
40|$|This paper {{focuses on}} several <b>estimation</b> <b>methods</b> for SAR- models {{in case of}} missing {{observations}} in the dependent variable. First, we show with an example and then in general, how missing observations can change the model and thus resulting in {{the failure of the}} 'traditional' <b>estimation</b> <b>methods.</b> To estimate the SAR- model with missings we propose different <b>estimation</b> <b>methods,</b> like GMM, NLS and OLS. We will suggest to derive some of the estimators based on a model approximation. A Monte Carlo Simulation is conducted to compare the different <b>estimation</b> <b>methods</b> in their diverse numerical and sample size aspects...|$|R
25|$|Massive MIMO is a {{technology}} where {{the number of}} terminals is {{much less than the}} number of base station (mobile station) antennas. In a rich scattering environment, the full advantages of the massive MIMO system can be exploited using simple beamforming strategies such as maximum ratio transmission (MRT), maximum ratio-combining (MRC) or zero forcing (ZF). To achieve these benefits of massive MIMO, accurate CSI must be available perfectly. However, in practice, the channel between the transmitter and receiver is estimated from orthogonal pilot sequences which are limited by the coherence time of the channel. Most importantly, in a multicell setup, the reuse of pilot sequences of several co-channel cells will create pilot contamination. When there is pilot contamination, the performance of massive MIMO degrades quite drastically. To alleviate the effect of pilot contamination, the work of proposes a simple pilot assignment and channel <b>estimation</b> <b>method</b> from limited training sequences.|$|E
2500|$|Given {{that the}} {{essential}} matrix {{has been determined}} for a stereo camera pair, for example, using the <b>estimation</b> <b>method</b> above this information {{can be used for}} determining also the rotation and translation (up to a scaling) between the two camera's coordinate systems. In these derivations [...] is seen as a projective element rather than having a well-determined scaling.|$|E
5000|$|MOSCED, an <b>estimation</b> <b>method</b> for {{activity}} coefficients; uses polarizability as parameter ...|$|E
40|$|This article studies <b>estimation</b> <b>methods</b> for the {{location}} parameter. We consider several robust location estimators {{as well as}} several <b>estimation</b> <b>methods</b> based on a phase I analysis, i. e., the use of a control chart to study a historical dataset retrospectively to identify disturbances. In addition, we propose a new type of phase I analysis. The <b>estimation</b> <b>methods</b> are evaluated in terms of their mean-squared errors and their effect on the X-bar control charts used for real-time process monitoring (phase II). It turns out that the phase I control chart based on the trimmed trimean far outperforms the existing <b>estimation</b> <b>methods.</b> This method has therefore proven to be very suitable for determining X-bar phase II control chart limits...|$|R
50|$|Bayesian <b>estimation</b> <b>methods.</b>|$|R
40|$|The {{increasing}} interest in applying small area <b>estimation</b> <b>methods</b> urges the needs for training in small area estimation. To {{better understand the}} behaviour of small area estimators in practice, simulations are a feasible way for evaluating and teaching properties of the estimators of interest. By designing such simulation studies, students gain {{a deeper understanding of}} small area <b>estimation</b> <b>methods.</b> Thus, we encourage to use appropriate simulations as an additional interactive tool in teaching small area <b>estimation</b> <b>methods...</b>|$|R
50|$|This {{derivative}} {{is used in}} {{the distance}} <b>estimation</b> <b>method</b> for drawing a Mandelbrot set.|$|E
5000|$|Position <b>Estimation</b> <b>Method,</b> H.I. Christensen & G. Zunino, World patent (WO03062937) 3 March 11, 2008 ...|$|E
5000|$|To {{calculate}} , where [...] = 125348, to six significant figures, use {{the rough}} <b>estimation</b> <b>method</b> above to get ...|$|E
40|$|Within {{the cost}} {{estimation}} literature and in practice within organisations {{a range of}} cost <b>estimation</b> <b>methods</b> are used to predict costs prior to activities being undertaken. Estimates generated utilising different <b>estimation</b> <b>methods</b> provide different projections of the anticipated cost. The projected differences in cost could {{have a significant impact}} on the overall viability of a project or the selection of the optimum design for a product or process. As a primary step towards creating a mechanism to select cost <b>estimation</b> <b>methods</b> for given situations this paper attempts to represent the cost estimation domain. Based on the representation and other research an innovative mechanism to select the most appropriate cost <b>estimation</b> <b>methods,</b> given the information available and user requirements is presented...|$|R
30|$|The rest of {{the paper}} is {{organized}} as follows. Section 2 briefly reviews the frame structure, encoding flow, and pilot pattern in the mobile WiMAX DL transmission. Section 3 describes the 2 -D and DD channel <b>estimation</b> <b>methods.</b> In Section 4, we propose a burst allocation scheme and suggest three DD channel <b>estimation</b> <b>methods</b> based on the allocation scheme. Theoretical analysis and experimental results of the performances of the proposed DD channel <b>estimation</b> <b>methods</b> are presented in Section 5, and finally, conclusions are drawn in Section 6.|$|R
40|$|This paper briefly {{outlines}} {{the advantages of}} maximum likelihood (ML) estimation over other <b>estimation</b> <b>methods.</b> Then, the recently developed ML estimation procedures of Raju and Drasgow (2003) are described for use in validity generalization. Two examples are presented, comparing the traditional VG <b>estimation</b> <b>methods</b> based on the method of moments with the new ML <b>estimation</b> <b>methods,</b> across three different VG models/scenarios (bare-bones, use of artifact distributions, and direction corrections). The need for assessing the accuracy and comparability of the traditional and ML estimation procedures is addressed...|$|R
5000|$|This method gives {{a better}} {{estimate}} whose frequency resolution {{is higher than}} the classical estimation theory. In the high resolution <b>estimation</b> <b>method</b> we use a variable wavenumber window which allows only certain wavenumbers and suppresses the others. Capon’s [...] work helped us establish an <b>estimation</b> <b>method</b> by using wavenumber-frequency components. This results in an estimate with a higher frequency resolution. It is similar to maximum likelihood method as the optimization tool used is similar.|$|E
50|$|This {{provides}} an estimated correction of bias {{due to the}} <b>estimation</b> <b>method.</b> The jackknife does not correct for a biased sample.|$|E
5000|$|An {{improved}} parameter <b>estimation</b> <b>method</b> for Hodgkin-Huxley model (with A. R. Willms, D. J. Baro and R. M. Harris-Warrick), J. Comp. Neuroscience 6 (1999), 145-168.|$|E
40|$|This paper {{analyses}} {{the bias}} in the estimate of the long memory parameter arising {{as a consequence of}} changing the frequency of the data for both semi-parametric and parametric <b>estimation</b> <b>methods.</b> Decreasing the sampling rate biases the estimation of the long memory parameter towards zero for all <b>estimation</b> <b>methods.</b> For the semi-parametric methods the observed empirical bias can be explained by analysing the form of each of the <b>estimation</b> <b>methods,</b> (C) 2002 International Institute of Forecasters. Published by Elsevier Science B. V. All rights reserved. ...|$|R
40|$|In this paper, {{different}} <b>estimation</b> <b>methods</b> for {{the parameters}} of the Geeta distribution (GET) are discussed. The model is applied to study microorganisms based on difference-differential equations leading to Geeta distribution. R- Software has been used for making a comparison among the three different <b>estimation</b> <b>methods...</b>|$|R
40|$|We analyze <b>estimation</b> <b>methods</b> for Data-Oriented Parsing, {{as well as}} the {{theoretical}} criteria used to evaluate them. We show that all current <b>estimation</b> <b>methods</b> are inconsistent in the “weight-distribution test”, and argue that these results force us to rethink both the methods proposed and the criteria used...|$|R
50|$|The APES (amplitude and phase <b>estimation)</b> <b>method</b> {{is also a}} matched-filter-bank method, which {{assumes that}} the phase history data is a sum of 2D sinusoids in noise.|$|E
5000|$|H. Zaghloul and M. Fattouche, [...] "Demodulation of a Signal Transmitted over a Fading Channel using Phase <b>Estimation,</b> <b>Method</b> and Apparatus," [...] U.S. Patent no. 5,369,670, Nov. 29, 1994.|$|E
50|$|The monocular {{estimate}} method or monocular <b>estimation</b> <b>method</b> {{is a form}} {{of dynamic}} retinoscopy widely used to objectively measure accommodative response. Values normally attained when performing MEM are between +0.25 and +0.50 diopters.|$|E
30|$|It is more {{accurate}} than other <b>estimation</b> <b>methods.</b>|$|R
40|$|The {{objective}} {{of this study is}} to compare <b>estimation</b> <b>methods</b> for parameter of Exponential distribution using Gamma prior distributions. Exponential Parameter was observed from three <b>estimation</b> <b>methods</b> composing of Maximum Bayesian Likelihood, Bayesian, and Maximum Likelihood developed from Bayesian and Maximum Likelihood. The data were generated through the Monte Carlo simulation technique by varying the sampling sizes from 10, 30, 50, and 100. Each case was repeated 1000 times. Mean Square Error was a criterion to compare <b>estimation</b> <b>methods.</b> The results indicated that method of Maximum Bayesian Likelihood gives the best estimation...|$|R
40|$|Part 7 : Project ManagementInternational audienceEffort {{estimation}} is a {{key factor}} for software project success, defined as delivering software of agreed quality and functionality within schedule and budget. Traditionally, effort estimation {{has been used for}} planning and tracking project resources. Effort <b>estimation</b> <b>methods</b> founded on those goals typically focus on providing exact estimates and usually do not support objectives that have recently become important within the software industry, such as systematic and reliable analysis of causal effort dependencies. This article presents the results of a study of software effort estimation from an industrial perspective. The study surveys industrial objectives, the abilities of software organizations to apply certain <b>estimation</b> <b>methods,</b> and actually applied practices of software effort estimation. Finally, requirements for effort <b>estimation</b> <b>methods</b> identified in the survey are compared against existing <b>estimation</b> <b>methods...</b>|$|R
50|$|Carcharocles chubutensis {{was larger}} than C. angustidens. Teeth of C. chubutensis can {{approach}} 130 mm in slant height (diagonal length), which according to size <b>estimation</b> <b>method</b> proposed by Gottfried at al, in 1996, indicate 12.2 m long specimen.|$|E
50|$|Economists use the hedonic {{regression}} (HR) <b>estimation</b> <b>method</b> {{to calculate}} prices in art. This {{is used to}} predict prices based on various attributes of the artwork such as its dimensions, the artist, and the subject matter attended to.|$|E
5000|$|Proxy Based Estimating (PROBE), is the <b>estimation</b> <b>method</b> {{introduced}} by Watts Humphrey(of the Software Engineering Institute at Carnegie Mellon University) {{as part of}} thePersonal Software Process (a discipline that helps individual software engineers monitor,test, and improve their own work).|$|E
40|$|Abstract. Total reliability, {{also called}} the average {{redundant}} observation component, is an indicator of a survey network. It summarily shows whether gross errors contained in observations on a survey network may be eliminated or weakened by robust <b>estimation</b> <b>methods.</b> Based on total reliability, the current paper presented the concept of remainder reliability, which essentially showed whether gross errors might be eliminated or weakened by robust estimation. Taking 12 leveling networks with different remainder reliability adjustments as examples, simulation experiments were used to compare 4 frequently used robust <b>estimation</b> <b>methods.</b> The results indicate that when observations simultaneously contain one gross error and if the remainder reliability 30. 0 ≥RRg, robust <b>estimation</b> <b>methods</b> may eliminate or weaken these effects. However, if 40. 0 >RRg, all the four robust <b>estimation</b> <b>methods</b> may effectively eliminate or weaken these effects...|$|R
40|$|Several {{methods to}} {{estimate}} energy expenditure (EE) using body-worn sensors exist; however, quantifications {{of the differences}} in estimation error are missing. In this paper, we compare three prevalent EE <b>estimation</b> <b>methods</b> and five body locations to provide a basis for selecting among methods, sensors number, and positioning. We considered 1) counts-based <b>estimation</b> <b>methods,</b> 2) activity-specific <b>estimation</b> <b>methods</b> using METs lookup, and 3) activity-specific <b>estimation</b> <b>methods</b> using accelerometer features. The latter two <b>estimation</b> <b>methods</b> utilize subsequent activity classification and EE estimation steps. Furthermore, we analyzed accelerometer sensors number and on-body positioning to derive optimal EE estimation results during various daily activities. To evaluate our approach, we implemented a study with 15 participants that wore five accelerometer sensors while performing a wide range of sedentary, household, lifestyle, and gym activities at different intensities. Indirect calorimetry was used in parallel to obtain EE reference data. Results show that activity-specific <b>estimation</b> <b>methods</b> using accelerometer features can outperform counts-based methods by 88 % and activity-specific methods using METs lookup for active clusters by 23 %. No differences were found between activity-specific methods using METs lookup and using accelerometer features for sedentary clusters. For activity-specific <b>estimation</b> <b>methods</b> using accelerometer features, differences in EE estimation error between the best combinations of each number of sensors (1 to 5), analyzed with repeated measures ANOVA, were not significant. Thus, we conclude that choosing the best performing single sensor does not reduce EE estimation accuracy compared to a five sensors system and can reliably be used. However, EE estimation errors can increase up to 80 % if a nonoptimal sensor location is chosen...|$|R
5000|$|Some of the <b>estimation</b> <b>methods</b> for multivariable {{linear models}} are ...|$|R
