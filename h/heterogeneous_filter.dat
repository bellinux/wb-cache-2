2|16|Public
30|$|The {{filter cake}} {{properties}} {{and the internal}} invasion were heterogeneous along the horizontal section of sandstone formations (Bageri et al. 2013). It {{was found that the}} percentage of sand particles varies within the horizontal latera of the well. The sand content increased from the heel to the toe of the horizontal section. The heterogeneity of the horizontal section permeability will form <b>heterogeneous</b> <b>filter</b> cake along the same section (Bageri et al. 2013). Filter cake heterogeneity {{plays a key role in}} designing the chemical treatment process to remove the filter cake (Elkatatny et al. 2012, 2013).|$|E
40|$|A new {{experimental}} {{technique has}} been developed in order to study the washing characteristics in a filter cake during displacement washing. The test material primarily used was paper pulp which forms highly <b>heterogeneous</b> <b>filter</b> cakes where the local values of, for example, porosity may be assumed to differ substantially from the average values. The experimental equipment used was a piston filter press equipped with a γ-radiation source and a scintillation detector {{that was used to}} measure concentrations of different species inside the filter cake at different bed heights. In these experiments, Cs+ ions were used as the tracer compound for studying displacement washing. The filtrate was also collected and, from the displacement curves based on the concentration in the filtrate, the dispersion coefficients and the Peclet number could be determined; these values were used to calculate local displacement curves. The calculated local displacement curves agreed well with the measured local displacement curves showing that local measurement of the dispersion coefficient is a very valuable tool for studying the washing of filter cakes...|$|E
50|$|The nanofibres, hollow nanofibres, {{core-shell}} nanofibres, and nanorods or nanotubes produced have a {{great potential}} for {{a broad range of}} applications including homogeneous and <b>heterogeneous</b> catalysis, sensorics, <b>filter</b> applications, and optoelectronics. Here we will just consider a limited set of applications related to life science.|$|R
40|$|Evaluating the {{significance}} {{differences between the}} group of comatose patients and the group of brain death {{is important in the}} detection of brain death. This paper presents a novel method for the discrimination between discrete states of brain consciousness. Based on a collaborative adaptive filtering ar- chitecture using a convex combination of two <b>heterogeneous</b> adaptive <b>filters,</b> the evolution of the mixing parameter can be used as an indicator of the fundamental signal nature of different EEG recordings. Simulations illustrate the suitabil- ity of this approach to differentiate between the coma and quasi-brain-death states...|$|R
40|$|We created simple {{stochastic}} {{models of}} spatially heterogeneous stress in three dimensions. By {{breaking up the}} stress tensor into three invariant quantities (principal stresses) and three orientation angles (a rotation amplitude, !, about a rotation axis]), {{we were able to}} produce <b>filtered</b> <b>heterogeneous</b> 3 D matrices of the full stress tensor with properties that are approximately unchanged upon rotation of coordinate system. We generated random principal stresses (! 1,! 2,! 3) using Gaussian white noise and random orientations (!,[",#]) using random unit quaternions, then filtered each quantity in three dimensions. The spatial smoothing parameter we used in the filtering is!, which is the spectral falloff of any 1 D cross section through our 3 D grids. We find that the larger the value of!, the greater the spatial smoothing. For our 201 x 201 x 201 grids and spatial smoothing! " 1. 0, any orientation bias due to filtering is small and can be eliminated by stacking grids with a different random rotation applied to the stress tensors within each stacked grid. Subtracting out the pressure, we then added our <b>filtered</b> <b>heterogeneous</b> deviatoric stress in 3 D, "! H (x), to a spatially uniform background stress, B. This introduces our second stress heterogeneity parameter, HR, which uses a rati...|$|R
40|$|Multicache is a trace-driven cache {{simulator}} {{developed to}} make the design, analysis, and comparison of cache replacement algorithms in multi-level caching systems practical. To make the simulator generic and flexible architectural specifics (such as those found in processor caches) or protocol (HTTP, TCP/IP) details were excluded. The simulator is best for quick implementation, analysis and comparison of new cache replacement algorithms that deal with web-proxy objects, file system files, disk blocks, memory pages, and other fixed or variable size objects. The simulator is easy to learn and expand. It provides many building blocks for wellknown replacement algorithms (LRU, LFU), space management routines, container data structures, and simple topologies. Topologies like client-server, server-storage pairs, web proxy hierarchies, and peer-to-peer networks can be implemented. Modern caching related concepts such as using <b>heterogeneous</b> algorithms, <b>filtering</b> effects, demotions are also evaluated. The structure of the simulator allows multiple algorithms to have control over one cache space, allowing adaptive techniques to be tested. Th...|$|R
40|$|Abstract—Vertical handoff is {{of great}} {{significance}} to achieve seamless connectivity in heterogeneous networks. It is necessary to enhance the location awareness of the mobile station (MS) {{as well as to}} reduce the adverse effect of fading so that it is able to predict future network conditions accurately. An optimal Savitzky-Golay filtering based vertical handoff algorithm is adopted in this essay, which equips the MS to decide network coverage boundaries accurately. Simulation results show that this method can reduce the effects of fading in the received signal, thereby reducing the ping-pong effect availably. It can also improve the performance of the network. Index Terms—vertical handoff, seamless connectivity, <b>heterogeneous</b> networks, Savitzky-Golay <b>filtering</b> I...|$|R
40|$|In any {{knowledge}} discovery process {{the value of}} extracted knowledge {{is directly related to}} the quality of the data used. Big Data problems, generated by massive growth in the scale of data observed in recent years, also follow the same dictate. A common problem affecting data quality is the presence of noise, particularly in classification problems, where label noise refers to the incorrect labeling of training instances, and is known to be a very disruptive feature of data. However, in this Big Data era, the massive growth in the scale of the data poses a challenge to traditional proposals created to tackle noise, as they have difficulties coping with such a large amount of data. New algorithms need to be proposed to treat the noise in Big Data problems, providing high quality and clean data, also known as Smart Data. In this paper, two Big Data preprocessing approaches to remove noisy examples are proposed: an homogeneous ensemble and an <b>heterogeneous</b> ensemble <b>filter,</b> with special emphasis in their scalability and performance traits. The obtained results show that these proposals enable the practitioner to efficiently obtain a Smart Dataset from any Big Data classification problem...|$|R
40|$|Background-error variances {{estimated}} from a small-size {{ensemble of}} data assimilations {{need to be}} filtered because of the associated sampling noise. Previous studies showed that objective spectral filtering is efficient in reducing this noise, while preserving relevant features to a large extent. However, since such filters are homogeneous, they tend to smooth small-scale structures of interest. In many applications, nonlinear thresholding of wavelet coefficients {{has proved to be}} an efficient technique for denoising signals. This algorithm proceeds by thresholding the wavelet coefficients of the noisy signal using an estimated threshold. This is equivalent to applying an adaptive local spatial filtering. A quasi-optimal value for the threshold can be computed from the noise variance. We show that the statistical properties of the sampling noise associated with the estimation of background-error variances can be used to calculate the noise level and the appropriate threshold value. This method is first applied to 1 D academic examples, with emphasis on correlated and heterogeneous noises. This approach is shown to outperform the commonly used homogeneous filters, since it automatically adapts to the local structure of the signal. We also show that this technique compares favourably to a <b>heterogeneous</b> diffusion-based <b>filter,</b> with the advantage of requiring less trial-and-error tuning. These results are next confirmed in a more realistic 2 D problem, using the Arome-France convective-scale model...|$|R
40|$|International audienceModeling {{water flow}} in a VFCW is a {{prerequisite}} to model wastewater treatment using process based filtering models. As for soils, when the vertical structure varies in different material types, it has {{a significant impact on}} water flow passing through it. The <b>heterogeneous</b> <b>filtering</b> material is composed of a mix of mineral porous material, and organic matter which makes its hydraulic characterization a difficult task. Indeed, the porosity may serve as preferential flow paths through which water can bypass most of the soil porous matrix in a largely unpredictable way. Consequently, non-equilibrium conditions in pressure heads are created between preferential flow paths and the soil matrix pore region. Preferential flows limit the applicability of standard models for water flow that are commonly based on Richards’ equation. Even if it is possible to simulate water content variations within a VFCW, we can not correctly model outflow with the standard van Genuchten-Mualem function. A number of various model approaches have been proposed to overcome this problem. These models mostly try to separately describe flow and transport in preferred flow paths and slow or stagnant pore regions. The objective {{of this study was to}} compare the various existing models simulating the preferential flows within the French VFCWs. Moreover, by assuming that several layers hydraulically different compose the VFCW, we tested at which layer(s) it is necessary to apply the non-equilibrium models. A tracer experiment was performed to evaluate the non-equilibrium degree. It was conducted on a 100 p. e. plant in operation since 2004. Monitoring consisted in measuring inlet and outlet flows, infiltration rates and water content at a time interval of 1 minute. We used the HYDRUS- 1 D software package containing various non-equilibrium flow modeling approaches. The physical non-equilibrium transport models were used to simulate outflow, the tracer breakthrough curve as well as water contents within a French-type VFCW. Physical non-equilibrium models include the dual-porosity model (mobile-immobile water model, with water content mass transfer or head mass transfer), and the dual-permeability model (matrix and fracture pore regions). We also applied a bimodal single-domain approach (Durner model) in order to see if it is actually necessary to use non-equilibrium models to effectively simulate VFCW outflow. Performance of the various non-equilibrium models (accuracy and limitation) was assessed by comparing the simulated and measured tracer fluxes using the mean square relative error (MSRE) of prediction. The comparison between measured and simulated tracer breakthrough curves indicates that the non-equilibrium (dual-porosity or dual-permeability model) approach seem to be the most appropriate for simulating preferential flow paths. In addition, simulations reveal that all layers participate in the preferential flow path process. These preferential flow paths are mainly due to the sludge layer that has been developed on the surface of VFCW since its start-up (swelling/shrinking during the feeding/rest periods) and to the network of roots and rhizomes present in it...|$|R
40|$|Ray {{representation}} (Ray-rep) {{of a solid}} {{has been}} stud-ied and used in the solid modeling community for many years because of its compactness and simplicity. This paper presents a parallel approach for mesh surface modeling from multi-material volume data using an ex-tended Ray-rep as an intermediate, where every homo-geneous region is enclosed {{by a set of}} two-manifold sur-face meshes on the resultant model. The approach con-sists of three major algorithms: firstly, an algorithm is developed to convert the given multi-material volumet-ric data into a Ray-rep for <b>heterogeneous</b> solid; secondly, <b>filtering</b> algorithm is exploited to process the rays of heterogeneous solid in parallel; and lastly, the adaptive mesh surfaces are generated from the ray-rep through a dual-contouring like algorithm. Here the intermediate surfaces between two constituent materials can be di-rectly extracted without building the volumetric mesh, and the manifold topology is preserved on each surface patch. Furthermore, general offset surface can be eas-ily computed in this paradigm by designing a special parallel operator for the rays...|$|R
40|$|This paper {{presents}} a region-adaptive clutter rejection method for small target detection in sea-based infrared search and track. In the real world, clutter normally generates many false detections that impede {{the deployment of}} such detection systems. Incoming targets (missiles, boats, etc.) can {{be located in the}} sky, horizon and sea regions, which have different types of clutters, such as clouds, a horizontal line and sea-glint. The characteristics of regional clutter were analyzed after the geometrical analysis-based region segmentation. The false detections caused by cloud clutter were removed by the spatial attribute-based classification. Those by the horizontal line were removed using the <b>heterogeneous</b> background removal <b>filter.</b> False alarms by sun-glint were rejected using the temporal consistency filter, which is the most difficult part. The experimental results of the various cluttered background sequences show that the proposed region adaptive clutter rejection method produces fewer false alarms than that of the mean subtraction filter (MSF) with an acceptable degradation detection rate...|$|R
40|$|This paper {{presents}} {{a new approach}} to the visualization of monophonic audio files that simultaneously illustrates general audio properties and the component sounds that comprise a given input file. This approach represents sound clip sequences using archetypal images which are subjected to image processing filters driven by audio characteristics such as power, pitch and signalto-noise ratio. Where the audio is comprised of a single sound it is represented by a single image that has been subjected to <b>filtering.</b> <b>Heterogeneous</b> audio files are represented as a seamless image mosaic along a time axis where each component image in the mosaic maps directly to a discovered component sound. To support this, in a given audio file, the system separates individual sounds and reveals the overlapping period between sound clips. Compared with existing visualization methods such as oscilloscopes and spectrograms, this approach yields more accessible illustrations of audio files, which are suitable for casual and nonexpert users. We propose that this method could be used as an efficient means of scanning audio database queries and navigating audio databases through browsing, since the user can visually scan the file contents and audio properties simultaneously. 1...|$|R
40|$|Dingus {{and colleagues}} {{recently}} estimated crash odds ratios (ORs) for “driver behavior errors” (hereafter, “Behaviors”) in the Strategic Highway Research Program Phase 2 naturalistic driving study. Behaviors are illegal, improper, aggressive, and/or reckless driving maneuvers. For example, the Dingus study OR estimate for “Speeding over limit and {{too fast for}} conditions,” (hereafter, “Speeding”), was 12. 8, with a 95 % confidence interval (CI) from 10. 1 to 16. 2. The current study identified four issues in the Dingus study. First, heterogeneous Behaviors were pooled; e. g., “Exceeded speed limit,” and “Exceeded safe speed but not speed limit” were apparently improperly pooled to form Speeding. Second, exposed drivers often had other Behaviors {{in the same time}} window, but unexposed drivers had none, a selection bias that inflated Behavior ORs by 30 %. Third, impairments were not filtered out. Fourth, secondary tasks were not filtered out, creating a confounding bias that deflated Behavior OR estimates by 50 %. To correct these issues, the current study stratified the <b>heterogeneous</b> categories, then <b>filtered</b> out other Behaviors, impairments, and secondary tasks. “Pure Behavior” (no other Behaviors, secondary tasks, or impairments) was thus compared to “Pure Driving” (no Behaviors, secondary tasks, or impairments). The Pure OR estimate for “Exceeded speed limit” was 5. 4 (CI 2. 7 - 10. 1), and for “Exceeded safe speed but not speed limit” was 71. 5 (CI 36. 0 - 136. 2), both substantially different than the Dingus study Speeding estimate. All Behavior OR estimates in the Dingus study should be similarly corrected and adjusted to improve their validity...|$|R
40|$|Porous {{ceramics}} can {{be divided}} into three separate classes based on their pore size: microporous ceramics with pores less than 2 nm, mesoporous ceramics with pores in the range of 2 - 50 nm and macroporous ceramics with pores that are greater than 50 nm. In particular, macroporous ceramics are used in a variety of applications such as refractories, molten metal filtration, diesel particulate <b>filters,</b> <b>heterogeneous</b> catalyst supports and biomedical scaffolds. Freeze casting is a novel method used to create macroporous ceramics. In this method growing ice crystals act as a template for the pores and are solidified, often directionally, through a ceramic dispersion and removed from the green body through a freeze drying procedure. This method has attracted some attention {{over the past few years}} due to its relative simplicity, flexibility and environmental friendliness. On top of this freeze casting is capable of producing materials with high pore volume fractions, which is an advantage over processing by packing and necking of particles, where the pore volume fraction is typically less than 50 %. Many of the basic processing variables that affect the freeze cast microstructure, such as the temperature gradient, interfacial velocity and solid loading of the dispersion have been well established in the literature. On the other hand, areas such as the effect of additives on the microstructure and mechanical properties have not been covered in great detail. In this study the concept of constitutional supercooling from basic solidification theory is used to explain the effects of two water-soluble polymers, polyethylene glycol and polyvinyl alcohol, on the microstructure of freeze cast alumina ceramics. In addition, changes in the observed microstructure will be related to experimentally determined values of permeability and compressive strength...|$|R
40|$|Recent {{advances}} in small-scale portable computing have {{lead to an}} explosion in swarming as a viable method to approach large-scale data problems in the commercial, scientific, and defense sectors. This increased attention to large-scale swarm robotics has {{lead to an increase}} in swarm intelligence concepts, giving more potential to address issues more effectively and timely than any single unit. However, the majority of today's autonomous platforms are prohibitively costly and too complex for marketable research applications. This is particularly true when considering the demands required to be temporally and spatially pervasive in a marine environment. This work presents a low cost, portable, and highly maneuverable platform as a method to collect, share, and process environmental data. Our platform is modular, allowing a variety of sensor combinations, and may yield a <b>heterogeneous</b> swarm. Kalman <b>filters</b> are utilized to provide integrated, real-time dynamic self-awareness. In addition to an environmentally savvy platform, we define computational framework and characteristics, which allow complex problems to be solved in a distributed and collective manner. This computational framework includes two methods for scalar field estimation, which rely on low order orthogonal Hermite basis functions. Low order fits provide a natural method for low-pass filtering, thus avoiding ambient noise recovery in the reconstruction process. Real-time sampling and recovery allow for individual and collectively autonomous behaviors driven through globally assessed environmental parameters. Finally, we give evidence that large numbers can cooperatively tackle large-scale problems much more efficiently and timely than more capable and expensive units. This is particularly true when utilizing a unique methodology, presented herein, to best assemble in order to most affectively reconstruct sparse spatial scalar fields. by Brandon M. Zoss. Thesis: S. M. in Naval Architecture and Marine Engineering, Massachusetts Institute of Technology, Department of Mechanical Engineering, 2016. Thesis: Mech. E., Massachusetts Institute of Technology, Department of Mechanical Engineering, 2016. Cataloged from PDF version of thesis. Includes bibliographical references (pages 213 - 217) ...|$|R
40|$|Internet of Things (IoT) is on {{the verge}} of {{experiencing}} a paradigm shift, the focus of which is the integration of people, services, context information, and things in the Connected Society, thus enabling Internet of Everything (IoE). Hundreds of billions of things will be connected to IoT/IoE by 2020. This massive immersion of things paves the way for sensing and analysing anything, anytime and anywhere. This everywhere computing coupled with Internet or web-enabled services have allowed access to a vast amount of distributed context information from heterogeneous sources. This enormous amount of context information will remain under-utilized if not properly managed. Therefore, this thesis proposes a new approach of logical-clustering as opposed to physical clustering aimed at enabling efficient context information management. However, applying this new approach requires many research challenges to be met. By adhering to a design science research method, this thesis addresses these challenges and proposes solutions to them. The thesis first outlines the architecture for realizing logical-clustering topology for which a two-tier hierarchical-distributed hash table (DHT) based system architecture and a Software Defined Networking (SDN) -like approach are utilized whereby the clustering identifications are managed on the top-level overlay (as context storage) and heterogeneous context information sources are controlled via the bottom level. The feasibility of the architecture has been proven with an ns- 3 simulation tool. The next challenge is to enable scalable clustering identification dissemination, for which a distributed Publish/Subscribe (PubSub) model is developed. The massive number of immersed nodes further necessitates a dynamic self-organized system. The thesis concludes by proposing new algorithms with regard to autonomic management of IoT to bring about the self-organization. These algorithms enable to structure the logical-clustering topology in an organized way with minimal intervention from outside sources and further ensure that it evolves correctly. A distributed IoT context information-sharing platform, MediaSense, is employed and extended to prove the feasibility of the dynamic PubSub model and the correctness of self-organized algorithms and to utilize them as context storage. Promising results have provided a high number of PubSub messages per second and fast subscription matching. Self-organization further enabled logical-clustering to evolve correctly and provided results on a par with the existing MediaSense for entity joining and high discovery rates for non-concurrent entity joining. The increase in context information requires its proper management. Being able to cluster (i. e. <b>filter)</b> <b>heterogeneous</b> context information based on context similarity can help to avoid under-utilization of resources. This thesis presents an accumulation of work which can be comprehended as a step towards realizing the vision of logical-clustering topology...|$|R

