5|10000|Public
30|$|These {{models have}} {{promoted}} {{the development of}} trust measurement models. However, most of the existing models failed to filter false feedback and distrustful recommendation, which leads to <b>inaccuracy</b> <b>of</b> <b>measurement</b> results. In addition, free-riding problem was not comprehensively considered {{in most of the}} existing trust measurement models. Considering these problems, this paper proposes a game theory-based trust measurement model for social networks. The proposed model introduces three novel evaluation factors which are service reliability, feedback effectiveness and recommendation credibility to more accurately measure the trust degree of a node.|$|E
40|$|In this paper, thermal {{conductivity}} measurement of liquids and nanofluids is numerically {{investigated by the}} steady state method. In which, it is required to omit the natural convection effects on the <b>inaccuracy</b> <b>of</b> <b>measurement</b> for heat lost quantification. One of the well-known steady-state apparatus is circular parallel-plate where the distance between circular plates is filled with liquids or nanofluids. So, {{it has to be}} designed accurately to neglect the effects of free convection. The numerical simulation is a convenient method which can omit the mentioned effects. Water, Ethylene and Ethylene Glycol are considered as base liquids and Al 2 O 3 as a Nano-fluid in this work. Thermal boundary conditions, the distance between two parallel discs, physical and thermal quantities of fluids, size and volume fraction of nano-particles have extensive effects on the measurement process. The main result of the simulation indicates that for all of the cases, the distance between two parallel discs has to get less than 2 mm for accurate measurement of {{thermal conductivity}} in the parallel circular plate, wherein, uncertainty {{in the presence of the}} natural convection can be easily omitted. Comment: 12 figures, 16 page...|$|E
40|$|Simultaneous {{observations}} of rainfall collected by a tipping bucket rain gauge, a weighing bucket rain gauge, an optical rain gauge, a present weather detector, a Joss–Waldvogel disdrometer, and a 2 -D video disdrometer during January to October 2012 were analyzed to evaluate how accurately they measure rainfall and drop size distributions (DSDs). For the long-term observations, there were different discrepancies in rain amounts from six {{instruments in the}} order of 0 to 27. 7 %. The ORG, JWD, and 2 DVD underestimated, and the TBRG overestimated the rain rate when R − 1 ; the TBRG agreed well with the reference values, while the PWD and 2 DVD overestimated, WRG and JWD underestimated the rain rate when R > 20 mm h− 1 . The TBRG and WRG underestimated more than 50 % of rainfall duration substantially in the light rainfall, ORG underestimated the rainfall duration for about 12. 7 %, while the JWD and 2 DVD overestimated the rainfall duration for more than 30 %. The overall DSDs of JWD and 2 DVD agreed well with each other, while the JWD had a higher volume mean diameter, lower raindrop numbers and liquid water content than that of 2 DVD. The overestimation of small-size drops (D D > 4 mm) by JWD suggests the JWD's <b>inaccuracy</b> <b>of</b> <b>measurement</b> of small-size drops and very large-size drops; the underestimation of small raindrops by 2 DVD suggested that DSDs in the heavy rainfall by 2 DVD should be handled carefully...|$|E
40|$|The {{results of}} tests of payload oscillations, forced by linear control {{function}} which allows to minimize payload sway after acceleration phase and after overhead crane stopping {{are presented in}} this paper. The analysis of solution of this problem has been carried out. The algorithm of operation for real drive system which {{takes into account the}} possibilities of driving of an overhead crane is also presented. The impact <b>of</b> <b>inaccuracies</b> <b>of</b> <b>measurement</b> <b>of</b> the ropes length on minimizing a displacements of payload during the duty cycle is shown as well. The correctness of the method is confirmed by results both simulation and experimental tests...|$|R
50|$|In {{metrology}} (the science <b>of</b> <b>measurement),</b> {{a standard}} (or etalon) is an object, system, or experiment that bears a defined relationship to a unit <b>of</b> <b>measurement</b> <b>of</b> a physical quantity. Standards are the fundamental reference {{for a system}} of weights and measures, against which all other measuring devices are compared. Historical standards for length, volume, and mass were defined by many different authorities, which resulted in confusion and <b>inaccuracy</b> <b>of</b> <b>measurements.</b> Modern measurements are defined in relationship to internationally standardized reference objects, which are used under carefully controlled laboratory conditions to define the units of length, mass, electrical potential, and other physical quantities.|$|R
2500|$|If we let [...] {{represent}} the error (i.e., <b>inaccuracy)</b> <b>of</b> a <b>measurement</b> <b>of</b> an observable A and [...] the disturbance produced on a subsequent <b>measurement</b> <b>of</b> the conjugate variable B {{by the former}} <b>measurement</b> <b>of</b> A, then the inequality proposed by Ozawa — encompassing both systematic and statistical errors — holds: ...|$|R
40|$|A phonetic {{recognition}} and reaction measuring tool is presently in use by sociological and psychological {{researchers at the}} University of Washington. The tool makes use of a system known as the Head Turn Technique (HTT). The tool measures the test participant’s response to subtle changes in phonetics {{he or she is}} hearing by sensing the movement of the participant’s attention focus toward the source of the phonetic stimulus. The existing tool has been largely unchanged for five years and may benefit from a technological revision. The tool, as it is, relies heavily upon human interface, which may be contributing to <b>inaccuracy</b> <b>of</b> <b>measurement</b> and limitations in the types and richness of data that are captured. In the existing process, a test administrator manually initiates the event prompting the change in the focus of the subject’s attention. The occurrence or non-occurrence of the response is then judged by the test administrator. Computer control is limited to the generation of the phonetic stimulus. The proposed revision includes a laser pointing device and a laser light receptor array, software modification, and revision of the test procedure. The enhancement could add the ability not only to detect the occurrence of the head turn event but also to time various aspects of the event. Computer software would trace the path of the laser pointer’s beam as the head is moved and hence the precision with which the head is moved. It could also measure the divergence between the orientation of the head and the focus of attention...|$|E
40|$|The {{increase}} in unit capacity of electric equipment {{as well as}} complication of technological processes, devices control {{and management of the}} latter in power plants and substations demonstrate the need to improve the reliability and accuracy of measurement information characterizing the state of the objects being managed. The mentioned objective is particularly important for nuclear power plants, where the price of <b>inaccuracy</b> <b>of</b> <b>measurement</b> responsible process variables is particularly high and the error might lead to irreparable consequences. Improving the reliability and accuracy of measurements along with the improvement of the element base is provided by methods of operational validation. These methods are based on the use of information redundancy (structural, topological, temporal). In particular, information redundancy can be achieved by the simultaneous measurement of one analog variable by two (duplication) or three devices (triplication i. e., triple redundancy). The problem of operational control of the triple redundant system of measurement of electrical analog variables (currents, voltages, active and reactive power and energy) is considered as a special case of signal processing by an orderly sampling on the basis of majority transformation and transformation being close to majority one. Difficulties in monitoring the reliability of measurements are associated with the two tasks. First, one needs to justify the degree of truncation of the distributions of random errors of measurements and allowable residuals of the pairwise differences of the measurement results. The second task consists in formation of the algorithm of joint processing of a set of separate measurements determined as valid. The quality of control is characterized by the reliability, which adopted the synonym of validity, and accuracy of the measuring system. Taken separately, these indicators might lead to opposite results. A compromise solution is therefore proposed. The quality of the evaluation of the measured signal is characterized by a single comprehensive measure that takes account of both reliability and accuracy properties of the system. This indicator is the average precision measure which is the weighted average error of the various possible states of a group of three devices.  </p...|$|E
3000|$|Trigger {{delay and}} PEEPi play {{a pivotal role}} in this underassistance and in this {{relative}} <b>inaccuracy</b> <b>of</b> WOB <b>measurements</b> in PAV+ mode. PEEPi is associated with an increase in trigger delay. On PAV+ mode, once the ventilator is triggered delivered P [...]...|$|R
40|$|The task of this diploma {{thesis is}} {{to design and}} test the optimal {{procedures}} for taking photos to build a 3 D model of a civic building using the programme PHOTOMODELER. Then to determine the specific dimensions of the civic building and compare them with the dimensions received {{with the help of}} the basic method <b>of</b> <b>measurement</b> in common building practice, i. e. the method of cross directions (using a tape or a telescopic measuring rod) and the geodetic method <b>of</b> <b>measurement.</b> After that to evaluate these measurements and make the conclusion concerning the accuracy or <b>inaccuracy</b> <b>of</b> <b>measurements</b> received {{with the help of the}} 3 D model of the compiled programme PHOTOMODELER...|$|R
60|$|Bearing in {{mind that}} mediocrities differ less from one another than members of either of the extreme classes, and would {{therefore}} {{be more difficult to}} distinguish, it seems probable that with comparatively few exceptions, at least two thousand adults of the same sex might be individualised, merely by means of twelve careful measures, on the Bertillon system, making reasonable allowances for that small change of proportions that occurs after the lapse of a few years, and for <b>inaccuracies</b> <b>of</b> <b>measurement.</b> This estimate may be far below the truth, but more cannot, I think, be safely inferred from the above very limited experiment.|$|R
40|$|There is {{increasing}} pressure on general practitioners (GPs) to identify patients with abdominal obesity {{in order to}} reduce the life-threatening consequences of this condition in the population. We aimed to confirm previous findings on the <b>inaccuracy</b> <b>of</b> anthropometric <b>measurements</b> performed by GPs in an academic primary care clinic and to assess the effect of theoretical training to improve the quality <b>of</b> these <b>measurements...</b>|$|R
40|$|Considered <b>inaccuracy</b> <b>of</b> the <b>measurements</b> worker {{hydraulic}} {{features of}} the energy equipment power plant station, connected with instability of the change (the fluctuations) parameter and choice discrete measurements. The brought analysis of the mathematical methods of the determination of integral importance parameter when undertaking the energy test the equipment and current checking in system SAU. ??????????? ??????????? ????????? ??????? ?????????????? ????????????? ??????????????? ???????????? ??????????????, ????????? ? ??????????????? ????????? (?????????) ?????????? ? ??????? ???????????? ?????????. ???????? ?????? ?????????????? ??????? ??????????? ????????????? ???????? ?????????? ??? ?????????? ?????????????? ????????? ???????????? ? ???????? ???????? ? ???????? ???...|$|R
40|$|A {{review of}} the {{published}} literature has demonstrated a large variability and discrepancies in the measured and predicted values of piston-ring lubricating film thickness in internal combustion engines. Only 2 papers have been found that compare experiments in firing engines directly with outputs from sophisticated ring-pack lubrication models. The agreement between theory and experiment in these comparisons was limited, possibly because of inadequacies in the models and/ or <b>inaccuracies</b> <b>of</b> <b>measurement.</b> This paper seeks {{to contribute to the}} literature by comparing accurately calibrated experimental <b>measurements</b> <b>of</b> piston-ring film thickness in a firing engine with predictions from an advanced, commercial software package alongside details of the systematic analysis <b>of</b> the <b>measurement</b> errors in this process. Suggestions on how measurement accuracy could be further improved are also given. <b>Measurements</b> <b>of</b> oil film thickness with an error (standard deviation) of +/- 15...|$|R
40|$|Abstract: Thermal {{measurements}} {{in energy}} engineering are a rather complex matter. Many physical quantities cannot be measured directly. They must be calculated {{making use of}} algorithms basing on the results <b>of</b> direct <b>measurements.</b> Any measurement is always an inaccurate operation. A measure <b>of</b> the <b>inaccuracy</b> <b>of</b> <b>measurements</b> is the uncertainty <b>of</b> this <b>measurement</b> defined as a parameter characterizing the scatter of values of the measured quantity. The paper deals with some selected problems connected with {{the determination of the}} uncertainty <b>of</b> <b>measurements</b> and calculated values in compliance with DIN and ISO standard. The calculations of the uncertainty of the specific enthalpy, difference of enthalpy, the fluid flux and the energy efficiency of the steam boiler determination have been presented, as well as exemplary results of calculation of the uncertainty of the thermal efficiency of a steam boiler fired with pulverized coal. Key words: Thermal <b>measurements,</b> uncertainty <b>of</b> <b>measurements</b> and computational value, thermal process...|$|R
40|$|A {{review is}} given of precise {{formulations}} of three conceptually distinct but related manifestations of Heisenberg’s Uncertainty Principle. This principle {{appears in the}} form of trade-off inequalities: for the widths of the position and momentum distributions in any quantum state; for the <b>inaccuracies</b> <b>of</b> any joint <b>measurement</b> <b>of</b> these quantities; and for the <b>inaccuracy</b> <b>of</b> a <b>measurement</b> <b>of</b> one of the quantities and the ensuing disturbance in the distribution of the other quantity. The uncertainty principle is often described as expressing a limitation of operational possibilities imposed by quantum mechanics. Here we demonstrate that apart from this negative role, the full content of the uncertainty principle also includes its positive role as a condition ensuring that mutually exclusive experimental options can indeed be reconciled if an appropriate trade-off is accepted. Finally, we survey models and experimental implementations <b>of</b> joint <b>measurements</b> <b>of</b> position and momentum and comment briefly on the status of experimental tests of the uncertainty principle...|$|R
40|$|Heisenberg’s {{uncertainty}} principle is usually taken {{to express a}} limitation of operational possibil-ities imposed by quantum mechanics. Here we demonstrate that the full content of this principle also includes its positive role as a condition ensuring that mutually exclusive experimental options can be reconciled if an appropriate trade-off is accepted. The {{uncertainty principle}} is shown to appear in three manifestations, {{in the form of}} uncertainty relations: for the widths of the position and momentum distributions in any quantum state; for the <b>inaccuracies</b> <b>of</b> any joint <b>measurement</b> <b>of</b> these quantities; and for the <b>inaccuracy</b> <b>of</b> a <b>measurement</b> <b>of</b> one of the quantities and the ensuing disturbance in the distribution of the other quantity. Whilst conceptually distinct, these three kinds of uncertainty relations are shown to be closely related formally. Finally, we survey models and experimental implementations <b>of</b> joint <b>measurements</b> <b>of</b> position and momentum and comment briefly on the status of experimental tests of the uncertainty principle. PACS numbers: 03. 65 Content...|$|R
40|$|International audienceAnalog {{integrated}} circuit testing and diagnosis {{is a very}} challenging problem. The <b>inaccuracy</b> <b>of</b> <b>measurements,</b> the infinite domain of possible values and the parameter deviations are among the major difficulties. During the process of optimizing production tests, Monte Carlo simulation is often needed due to parameter variations, but because of its expensive computational cost, it becomes the bottleneck of such a process. This paper describes a new technique {{to reduce the number}} of simulations required during analog fault simulation. This leads to the optimization of production tests subjected to parameter variations. Firstly, a review of the state of the art is presented. Then, the algorithm is introduced and the methodology of our approach is described. Finally, results on CMOS 2 -stage op amp and conclusions are given...|$|R
40|$|AbstractThe quantum-classical {{transition}} {{problem is}} investigated for the quartic oscillator coupled to a thermal reservoir. We show for this model {{that the combination}} of relevant diffusion, classical action (represented by the amplitude of an initial coherent state) and the experimental uncertainties is necessary to achieve the classical regime. In order to study the role of limited resolutions <b>of</b> <b>measurement</b> apparatuses on the correspondence between the quantum and classical dynamics, we consider experimental errors due the preparation of the initial state of the quartic oscillator and the inaccuracies in the time measurements. A quantum break time depending on the diffusion constant, the amplitude of the initial coherent state and the <b>inaccuracy</b> <b>of</b> <b>measurements</b> is defined. We found, for this model, a regime where the increasing of diffusion does not anticipate classicality. In such regime, there is a minimum value for the classical action associated to classical behavior of the system...|$|R
40|$|Abstract. Heisenberg’s {{uncertainty}} principle is usually taken {{to express a}} limitation of operational possibilities imposed by quantum mechanics. Here we demonstrate that the full content of this principle also includes its positive role as a condition ensuring that mutually exclusive experimental options can be reconciled if an appropriate trade-off is accepted. The {{uncertainty principle}} is shown to appear in three manifestations, {{in the form of}} uncertainty relations: for the widths of the position and momentum distributions in any quantum state; for the <b>inaccuracies</b> <b>of</b> any joint <b>measurement</b> <b>of</b> these quantities; and for the <b>inaccuracy</b> <b>of</b> a <b>measurement</b> <b>of</b> one of the quantities and the ensuing disturbance in the distribution of the other quantity. Whilst conceptually distinct, these three kinds of uncertainty relations are shown to be closely related formally. Finally, we survey models and experimental implementations <b>of</b> joint <b>measurements</b> <b>of</b> position and momentum and comment briefly on the status of experimental tests of the uncertainty principle. “It is the theory which decides what can be observed. ” (Albert Einstein according to Werner Heisenberg [1]) 1...|$|R
40|$|It {{is shown}} that for {{estimation}} of {{the interaction of the}} signal with hindrance system possible to present in the manner of equivalent scheme with the source of the signal and cascade included chain of the load, which deskside depends on features of the signal and hindrances, as well as their interactions: additive, multiplicative or mixed. The methods possible to use for analysis of the influence to casual <b>inaccuracy</b> <b>of</b> the <b>measurement</b> are broughted. ????????, ??? ??? ?????? ?????????????? ??????? ? ??????? ??????? ????? ??????????? ? ???? ????????????? ????? ? ?????????? ??????? ? ???????? ??????????? ?????? ????????, ???????????? ??????? ??????? ?? ????????????? ??????? ? ?????, ? ????? ?? ??????????????: ???????????, ?????????????????? ??? ??????????. ??????????? ???????? ????? ???????????? ??? ??????? ??????? ????????? ??????????? ?????????...|$|R
40|$|This work {{is focused}} on the issue of non-measured points – one of the most {{important}} problems in surface texture measurements using optical methods. The fundamental aim of this research is to analyse errors <b>of</b> surface texture <b>measurements</b> caused by the presence of non-measured points. This study is divided into two parts. In the first part, circles with non-measured points were artificially created on peak portions of measured surfaces. In the second part – the results <b>of</b> <b>measurement</b> by a Talysurf CCI Lite interferometer were analysed. A <b>measurement</b> area <b>of</b> 3. 3 × 3. 3 mm contained 1024 × 1024 points. The measurements were performed with different intensity of light. Changes of parameters regarding the analysed errors depended on a surface type. The following parameters are susceptible to errors: skewness Ssk, areal material ratio Smr, as well as the following feature parameters: Spd, Sda, Sdv, Sha and Shv. <b>Inaccuracies</b> <b>of</b> <b>measurement</b> in valley parts of two-process textures led usually to larger errors of parameter computations compared with deviations in peak portions...|$|R
40|$|We {{examine the}} measurability of the {{temporal}} ordering of two events, as well as event coincidences. In classical mechanics, a <b>measurement</b> <b>of</b> the order-of-arrival of two particles is shown to be equivalent to a measurement involving only one particle (in higher dimensions). In quantum mechanics, we find that diffraction effects introduce a minimum inaccuracy to which the temporal order-of-arrival can be determined unambiguously. The minimum <b>inaccuracy</b> <b>of</b> the <b>measurement</b> is given by 1 /E where E is the total kinetic energy of the two particles. Similar restrictions apply to the case <b>of</b> coincidence <b>measurements...</b>|$|R
40|$|Diagnosing analog {{circuits}} {{with their}} numerous known di#culties {{is a very}} hardproblem. Digital approaches {{have proven to be}} inappropriate, and AI-based ones su#er from many problems. In this paper we present a new system, FLAMES, which uses fuzzy logic, modelbasedreasoning, ATMS extension, and the human expertise in an appropriate combination to go far in the treatment of this problem. 1 Introduction when trying to overcome the challenging problem of testing and diagnosing analog circuits, the continuous nature of signals, the inherentinteractions between various circuit parameters # 1 #, the <b>inaccuracy</b> <b>of</b> <b>measurements,</b> and the non-directional nature of their behavior, which means that any component can be responsible for any symptom, constitute the core of the problem. It is necessary to model parameters with tolerances and to compute with intervals, to use qualitativevalues, or to use fuzzy sets as we suggest in this paper. Classical approaches are inappropriate, which has driven the [...] ...|$|R
50|$|ZETA's {{failure was}} due to limited information; using the best {{available}} measurements, ZETA was returning several signals that suggested the neutrons were due to fusion. The original temperature measures were made by examining the Doppler shifting of the spectral lines of the atoms in the plasma. The <b>inaccuracy</b> <b>of</b> the <b>measurement</b> and spurious results caused by electron impacts with the container led to misleading results. Over the next decade, ZETA was used almost continually {{in an effort to}} develop better diagnostic tools to resolve these problems.|$|R
40|$|Abstract. We {{reviewed}} global P export and its controlling {{factors from}} 685 world rivers. We used available continuous (runoff, rainfall, catchment area, % land use, and population density) and discrete (runoff type, soil type, biome, dominant land use, dominant type of forest, occurrence of stagnant water bodies in catchment, and Gross Product per Capita [GPC]) variables to predict export of P fractions. P export (kg P km 22 y 21) spanned 6 {{orders of magnitude}} worldwide. The distribution of all fractions of P export (total P [TP], soluble reactive P [SRP], and nonSRP [dissolved organic and particle-bound P]) was right skewed. Export of nonSRP had the highest coefficient of variability, and nonSRP was the dominant part of export. The available environmental variables predicted global P export fairly well (R 2 = 0. 73) if total N export was included in calculations. The unexplained variance in P export might be attributed to noise in the data set, <b>inaccuracy</b> <b>of</b> <b>measurements</b> <b>of</b> environmental variables at fine scales, lack of quantitative data on anthropogenic P sources, insufficient knowledge of P behavior in catchment soils, and nonlinearity of controlling processes. P exports were highly variable among catchment types, and runoff and population density were the predictors shared by most models. P export appeared {{to be controlled by}} different sets of environmental variables in different types of catchments. Quasi-empirical, mechanistic models of P export performed better than did empirical models. Our mechanistic understanding of...|$|R
40|$|We {{consider}} multicriteria decision-aid (MCDA) {{problems with}} multiple decision makers. In such problems, the uncertainty or <b>inaccuracy</b> <b>of</b> the criteria <b>measurements</b> {{can be represented}} as probability distributions. In many real-life problems the uncertainties may be dependent. However, {{it is often difficult}} to quantify these dependencies. Also most of the existing MCDA methods are unable to handle such dependency information...|$|R
25|$|ZETA's {{failure was}} due to limited information; using the best {{available}} measurements, ZETA was returning several signals that suggested the neutrons were due to fusion. The original temperature measures were made by examining the Doppler shifting of the spectral lines of the atoms in the plasma. The <b>inaccuracy</b> <b>of</b> the <b>measurement</b> and spurious results caused by electron impacts with the container led to misleading measurements based on the impurities, not the plasma itself. Over the next decade, ZETA was used continuously {{in an effort to}} develop better diagnostic tools to resolve these problems.|$|R
40|$|Air Traffic Control (ATC) {{and their}} {{responsible}} authorities have been always {{very sensitive to}} safety of the systems they are using to guarantee a fool-proof and environmentally safe operation of the facilities to provide guidance for the airplanes. This paper deals with {{the influence of a}} pulsed systems on standard air-ground aviation communication systems. A measurement campaign is described. An analysis <b>of</b> the <b>inaccuracies</b> <b>of</b> those <b>measurements</b> is performed and the influence of (shielded and unshielded) spark plug systems on aviation communication systems (still based on A(mplitude) M(odulation)) is explained in detai...|$|R
40|$|A fast {{experimental}} {{procedure for}} the calibration of internal combustion engines microprocessor control systems is proposed. This procedure {{is based on}} using {{a new approach to}} the solution of many-parametric optimization problems with constraints. The main benefit of this approach is that it requires a minimum number <b>of</b> experimental <b>measurements</b> where the measurements can have a high level of noise stability to the <b>inaccuracy</b> <b>of</b> <b>measurements</b> and adjustments. The efficiency of the suggested procedure is demonstrated by the search for air-fuel ratio, ignition timing and exhaust recirculation optimum bounded control that provide for the minimum fuel consumption for each speed-load regime at a given emission level. The optimization problem was defined by three variables and three constraints. The optimization criterion extremum value was found in 14 direct calls to the mathematical model computing the objective function. Ten tasks with different initial points of search have confirmed these results. The comparative analysis of the method efficiency with other well-known non-linear programming methods (the methods of Powell and Nelder-Mead) has shown the advantage of the proposed procedure that required only one-third of the experiments needed by these algorithms. Key Words: automatic control, evolutionary optimization, engine exhaust toxicity, engine fuel efficienc...|$|R
40|$|Matlab ??? ?????????? ??????? ???????? ????? ???????? ? ?????? ??????? ???? ???????????. ?????????? ???????????. ????????? ?????????? ????????? ????????? ???????? ??????? ??????????? ???????? ????? ? ???????-????????? ?????????????, ???? ? ???????? ???????? ??????? ? ??????? ??????? ?? ???????? ???????????. ????????. ???????????????? ??????????? ?? ?????????? ? ???????? ???????????????? ???????? ???????????? ???????????? ??????????? ?????????????? ??????, ???? ??? ?????????? ????????? ????????? ????????? ??????????? ? ???????? ?????????? ? ???????? ????? 1 %. Background. The {{article is}} devoted to the problem of {{accuracy}} increasing for physical-mechanical characteristics definition of powdered materials at the stage of their manufacture using ultrasonic testing. Objective. The realization of the phase method <b>of</b> time interval <b>measurement</b> in a system of ultrasonic testing of powdered materials in order to increase accuracy of definition their physical-mechanical characteristics is done. Methods. It was proposed to use digital orthogonal method for definition of the phase shift between signals to reach the aim. Computing simulation in Matlab system for definition of the signals phase shift and estimation <b>of</b> its <b>inaccuracy</b> <b>of</b> <b>measurements</b> was carried out. Results. As the result of this investigation it was defined the optimal parameters of the principal element of a measuring system for the phase shift ? ADC which was the main source of errors and essentially influenced the measurement accuracy. Conclusions. Experimental investigations on well known materials indicated effectiveness of application of the digital orthogonal method which allowed defining the velocity of ultrasound propagation in a solid medium with accuracy less than 1 %. ????????????. ?????? ????????? ???????? ????????? ???????? ??????????? ??????-???????????? ????????????? ?????????? ?????????? ?? ?????? ?? ???????????? ??? ????????????? ??????????????? ?????? ????????. ???? ????????????. ?????????? ???????? ?????? ????????? ?????????? ????????? ? ??????? ??????????????? ???????? ?????????? ?????????? ? ????? ????????? ???????? ??????????? ?? ??????-???????????? ?????????????. ???????? ??????????. ??? ?????????? ???? ???????????? ???? ?????????? ???????????? ?????????? ????????????? ????? ??????????? ???????? ?????? ????? ?????????. ??????????? ???????????? ????????????? ? ??????? Matlab ??? ??????????? ??????? ???????? ?????? ???????? ? ?????? ??????????? ??? ?????????. ?????????? ????????????. ?????????? ??????????? ????????? ????????? ???????? ??????? ????????? ???????? ?????? ? ???????-????????? ???????????????, ??????? ???????? ??????? ?????????? ??????????? ? ??????????? ?????? ?? ???????? ?????????. ??????. ????????????????? ???????????? ?? ?????????? ? ?????????? ???????????????? ???????? ????????????? ?????????? ??????????? ?????????????? ??????, ??????? ???????? ?????????? ???????? ??????????????? ??????????? ? ??????? ????? ? ???????????? ????? 1 %...|$|R
40|$|In the MOtion COmpensation (MOCO) {{approach}} to airborne repeat-pass interferometric Synthetic Aperture Radar (SAR) based on motion measurement data, the <b>measurement</b> <b>inaccuracies</b> <b>of</b> Inertial <b>Measurement</b> Unit/Global Positioning System (IMU/GPS) and the positioning errors of the target, which {{may contribute to}} the residual uncompensated motion errors, affect the imaging result and interferometric measurement. Considering the effects of the two types of error, this paper builds a mathematical model of residual motion errors in presence of squint, and analyzes the effects on the residual motion errors induced by the <b>measurement</b> <b>inaccuracies</b> <b>of</b> IMU/GPS and the positioning errors of the target. In particular, the effects <b>of</b> various <b>measurement</b> <b>inaccuracies</b> <b>of</b> IMU/GPS on interferometric SAR image quality, interferometric phase, and digital elevation model precision are disscussed. Moreover, the paper quantitatively researches the effects of residual motion errors on airborne repeat-pass interferometric SAR through theoretical and simulated analyses and provides theoretical bases for system design and signal processing...|$|R
40|$|AbstractThe paper {{deals with}} an {{estimation}} of residual fatigue lifetime of railway axles under real loading spectrum. The residual fatigue lifetime {{is given by}} magnitude of fatigue crack propagation rate. This rate depends predominantly on load, geometry and material of the axle. Standard steel EA 4 T for manufacturing of railway axles is considered in this paper. The scatter of data in v-K curve could be caused by <b>inaccuracy</b> <b>of</b> experimental <b>measurement</b> or by local change of material properties. The paper shows important differences between obtained residual fatigue lifetime estimations considering scatter in measured material data, especially near the threshold region...|$|R
30|$|The acute {{subsidence}} at a {{force of}} 800 [*]N and the failure load were comparable between the two MAC cages. Considering the small cage contact area, relatively high axial force was needed for displacement in the vertebral body. This {{could be explained by}} the close position of implant to the cortex of the vertebra. A limitation in the current study was the <b>inaccuracy</b> <b>of</b> the <b>measurement</b> <b>of</b> subsidence. A spondylodesis is often performed in a degenerated spine without equal surfaces of endplates. Therefore, the amount of subsidence probably differs over the surface area while in this study only the mean subsidence in the vertebral body was measured.|$|R
40|$|Acoustic Doppler current {{profilers}} (ADCPs) {{provide a}} promising method for measuring surface-water turbulence {{because they can}} provide data from a large spatial range {{in a relatively short}} time with relative ease. Some potential sources of errors in turbulence measurements made with ADCPs include <b>inaccuracy</b> <b>of</b> Doppler-shift <b>measurements,</b> poor temporal and spatial <b>measurement</b> resolution, and <b>inaccuracy</b> <b>of</b> multi-dimensional velocities resolved from one-dimensional velocities measured at separate locations. Results from laboratory <b>measurements</b> <b>of</b> mean velocity and turbulence statistics made with two pulse-coherent ADCPs in 0. 87 meters of water are used to illustrate several of inherent sources of error in ADCP turbulence measurements. Results show that processing algorithms and beam configurations have important effects on turbulence measurements. ADCPs can provide reasonable estimates of many turbulence parameters; however, the accuracy <b>of</b> turbulence <b>measurements</b> made with commercially available ADCPs is often poor in comparison to standard measurement techniques...|$|R
30|$|As for the non-thermal effect, {{there exist}} many {{disputes}} currently (Antonio and Deam 2007; de la Hoz et al. 2007; Reddy et al. 2013), especially no final conclusion {{has yet been}} reached on the research results due to <b>inaccuracy</b> <b>of</b> material temperature <b>measurement</b> in the microwave field (Schmink and Leadbeater 2009; Gomaa et al. 2013). The non-thermal effect has been seldom studied {{in the field of}} microwave desulfurization of coal.|$|R
