46|16|Public
5000|$|Also, let [...] be the <b>empty</b> <b>clause</b> in [...] Then, [...] and [...] are {{obtained}} by computing [...] and , respectively.|$|E
5000|$|If after {{applying}} a resolution rule the <b>empty</b> <b>clause</b> is derived, the original formula is unsatisfiable (or contradictory), and hence {{it can be}} concluded that the initial conjecture follows from the axioms.|$|E
5000|$|If, on {{the other}} hand, the <b>empty</b> <b>clause</b> cannot be derived, and the {{resolution}} rule {{cannot be applied to}} derive any more new clauses, the conjecture is not a theorem of the original knowledge base.|$|E
30|$|Simple {{selection}} with no sub-queries: the read set encompasses all predicates in the where <b>clause.</b> <b>Empty</b> where <b>clause</b> {{leads to}} a universal read set. The write set is set to empty.|$|R
40|$|Abstract. In {{molecular}} resolution refutation, {{the detection}} of <b>empty</b> <b>clauses</b> is important. We propose a rolling circle amplification-based detection method for resolution refutation. The rolling circle amplification (RCA) technique {{is known to be}} able to distinguish and amplify circular DNA. In this paper, we describe the representation of clauses and the RCA-based detection method. Bio-lab experiments show the basic idea for this method is correct. ...|$|R
5000|$|This is {{accomplished}} either with a try/catch with an <b>empty</b> catch <b>clause,</b> or by executing code {{depending on the}} returning error status: ...|$|R
5000|$|... the {{negation}} of that formula has the {{conjunctive normal form}} , with [...] and [...] denoting the Skolem function {{for the first and}} second existential quantifier, respectively; the literals [...] and [...] are unifiable without occurs check, producing the refuting <b>empty</b> <b>clause.</b>|$|E
5000|$|... {{where the}} [...] "top clause" [...] is an input clause, {{and every other}} clause [...] is a resolvent one of whose parents is the {{previous}} clause [...] The proof is a refutation if the last clause [...] is the <b>empty</b> <b>clause.</b>|$|E
50|$|A leaf node, {{which has}} no children, is a success node if its {{associated}} goal clause is the <b>empty</b> <b>clause.</b> It is a failure node if its associated goal clause is non-empty but its selected literal unifies with the positive literal of no input clause.|$|E
30|$|Other selection: the read set {{encompasses}} all predicates {{occurred in}} all where <b>clauses.</b> If <b>empty</b> where <b>clause</b> occurs {{in one of}} the sub-queries, the read set of the query is also a universal set. The write set is set to empty.|$|R
40|$|We {{describe}} an exact inference-based algorithm for the MinSAT problem. Given a multiset of clauses C, the algorithm derives as many <b>empty</b> <b>clauses</b> as {{the maximum number}} of clauses that can be falsified in C by applying finitely many times an inference rule, and returns an optimal assignment. We prove the correctness of the algorithm, describe how it can be extended to deal with weighted MinSAT and weighted partial MinSAT instances, analyze the differences between the MaxSAT and MinSAT inference schemes, and define and empirically evaluate the MinSAT Pure Literal Rule. Research partially supported by the Generalitat de Catalunya grant AGAUR 2014 -SGR- 118, CSIC Intramural Project 2014450 E 045, and the Ministerio de Economía y Competitividad project CO-PRIVACY TIN 2011 - 27076 -C 03 - 03. The second author was supported by Mobility Grant PRX 14 / 00195 of the Ministerio de Educación, Cultura y Deporte. Peer Reviewe...|$|R
40|$|Many (mathematical) problems, such as Cantor’s theorem, can be {{expressed}} very elegantly in higher-order logic, but lead to an exhaustive and un-intuitive formulation when coded in first-order logic. Thus, despite the difficulty of higher-order automated theorem proving, which {{has to deal with}} problems like the undecidability of higher-order unifi-cation (HOU) and the need for primitive substitution, there are proof problems which lie beyond the capabilities of first-order theorem provers, but instead can be solved easily by an higher-order theorem prover (HOATP) like Leo. This is due to the expressiveness of higher-order Logic and, in the special case of Leo, due to an appropriate handling of the extensionality principles (functional extensionality and extensionality on truth values). Leo uses a higher-order Logic based upon Church’s simply typed λ-calculus, so that the comprehension axioms are implicitly handled by αβη-equality. Leo employs a higher-order resolution calculus ER (see [3] in this volume for details), where the search for <b>empty</b> <b>clauses</b> and higher-order pre-unification [6] are in...|$|R
5000|$|A clause can {{be empty}} (defined from an empty set of literals).The <b>empty</b> <b>clause</b> is denoted by various symbols such as ,, or [...] The truth {{evaluation}} of an emptyclause is always [...] This is justified by considering that [...] is the neutral {{element of the}} monoid [...]|$|E
50|$|The {{resolution}} rule, {{as defined}} by Robinson, also incorporated factoring, which unifies two literals in the same clause, before or during the application of resolution as defined above. The resulting inference rule is refutation-complete, in that a set of clauses is unsatisfiable {{if and only if}} there exists a derivation of the <b>empty</b> <b>clause</b> using resolution alone.|$|E
5000|$|A Horn clause with {{exactly one}} {{positive}} literal {{is a definite}} clause; a definite clause with no negative literals is sometimes called a fact; and a Horn clause without a positive literal is sometimes called a goal clause (note that the <b>empty</b> <b>clause</b> consisting of no literals is a goal clause). These three kinds of Horn clauses are illustrated in the following propositional example: ...|$|E
40|$|The Moroccan {{proposal}} for autonomy for Western Sahara presented in 2007 contradicts international legislation recognizing {{the right of}} people of WesternSahara to self-determination and independence since, despite making provisionfor holding a referendum and referring in rhetorical terms to self-determination,it excludes the option of independence from the planned referendum. Furthermore, there is nothing new in the proposal, since Morocco hasbeen proposing the concession of some form of autonomy to Western Sahara,even getting as far as presenting a previous proposal in 2003. Finally, theproposal lacks credibility and seriousness, firstly because it is less clear and generousthan that presented in 2003 and, secondly, because it is incompatiblewith Moroccan law itself, from which no substantial changes are envisaged. An analysis of the systems for the distribution of jurisdictions and resolutionof conflicts, {{as well as the}} organization of the possible “autonomy” andguarantee of it or the electoral body and the system of fundamental rights,reveals that the Moroccan proposal contains numerous <b>empty</b> <b>clauses...</b>|$|R
40|$|Recent {{work has}} shown that SAT can be {{theoretically}} more powerful than heuristic search provided the heuristic used by search is implemented {{as a set of}} clauses on which unit propagation simulates the evaluation of the heuristic. The h max heuristic {{has been shown to be}} implemented trivially by the <b>empty</b> set of <b>clauses.</b> This paper presents an implementation of h m, a generalization of h max. ...|$|R
5000|$|The proof {{above is}} {{essentially}} model-theoretic (can be formalized as such). A purely syntactic proof {{is possible and}} can even be mechanized (in Otter for example), but only for an equisatisfiable rather than an equivalent negation of the theorem. Namely, the negation of the theorem iswhich is equivalent with the prenex normal formBy Skolemization the above is equisatisfiable with The resolution of the two clauses [...] and [...] results in an <b>empty</b> set of <b>clauses</b> (i.e. a contradiction), thus proving the negation of the theorem is unsatisfiable. The resolution is slightly non-straightforward because it involves a search based on Herbrand's theorem for ground instances that are propositionally unsatisfiable. The bound variable x is first instantiated with a constant d (making use of {{the assumption that the}} domain is non-empty), resulting in the Herbrand universe:One can sketch the following natural deduction: ...|$|R
50|$|Unsatisfiability {{of a given}} partial {{assignment}} is detected if one clause becomes empty, i.e. if all its variables have been assigned {{in a way that}} makes the corresponding literals false. Satisfiability of the formula is detected either when all variables are assigned without generating the <b>empty</b> <b>clause,</b> or, in modern implementations, if all clauses are satisfied. Unsatisfiability of the complete formula can only be detected after exhaustive search.|$|E
5000|$|Solving {{the problem}} amounts to {{deriving}} a contradiction, which {{is represented by}} the <b>empty</b> <b>clause</b> (or [...] "false"). The solution of the problem is a substitution of terms for the variables in the goal clause, which can be extracted from the proof of contradiction. Used in this way, goal clauses are similar to conjunctive queries in relational databases, and Horn clause logic is equivalent in computational power to a universal Turing machine.|$|E
5000|$|In clausal logic, an SLD {{refutation}} {{demonstrates that}} the input set of clauses is unsatisfiable. In logic programming, however, an SLD refutation also has a computational interpretation. The top clause [...] {{can be interpreted as}} the denial of a conjunction of subgoals [...] The derivation of clause [...] from [...] is the derivation, by means of backward reasoning, of a new set of sub-goals using an input clause as a goal-reduction procedure. The unifying substitution [...] both passes input from the selected subgoal to the body of the procedure and simultaneously passes output from the head of the procedure to the remaining unselected subgoals. The <b>empty</b> <b>clause</b> is simply an empty set of subgoals, which signals that the initial conjunction of subgoals in the top clause has been solved.|$|E
40|$|In this paper, {{we address}} the {{complexity}} issue of reasoning with implication constraints. We consider the IC-RFT problem, {{which is the}} problem of deciding whether a conjunctive yes/no query always produces the empty relation ("no" answer) on database instances satisfying a given set of implication constraints, as a central problem in this respect. We show that several other important problems, such as the query containment problem, are polynomially equivalent to the IC-RFT problem. More importantly, we give criteria for designing a set of implication constraints so that an efficient "units-refutation" process can be used to solve the IC-RFT problem. 1 Introduction Semantic constraints are logic rules specifying semantically meaningful database instances. In this paper we consider an important kind of semantic constraints called implication constraints that are expressible by <b>empty</b> headed Horn <b>clauses</b> having positive database literals. Since early 1980 's, there have been investigations [...] ...|$|R
40|$|Hypotheses {{constructed}} by {{inductive logic programming}} (ILP) systems are finite sets of definite clauses. Top-down ILP systems usually adopt the following greedy clause-at-a-time strategy to construct such a hypothesis: start with the <b>empty</b> set of <b>clauses</b> and repeatedly add the clause that most improves {{the quality of the}} set. This paper formulates and analyses an alternative method for constructing hypotheses. The method, called cautious induction, consists of a first stage, which finds a finite set of candidate clauses, and a second stage, which selects a finite subset of these clauses to form a hypothesis. By using a less greedy method in the second stage, cautious induction can find hypotheses of higher quality than can be found with a clause-ata -time algorithm. We have implemented a top-down, cautious ILP system called CILS. This paper presents CILS and compares it to Progol, a top-down clauseat -a-time ILP system. The sizes of the search spaces confronted by the two systems are a [...] ...|$|R
40|$|We {{consider}} {{the problem of}} Partial Quantifier Elimination (PQE). Given formula exists(X) [F(X,Y) & G(X,Y) ], where F, G are in conjunctive normal form, the PQE problem {{is to find a}} formula F*(Y) such that F* & exists(X) [G] is logically equivalent to exists(X) [F & G]. We solve the PQE problem by generating and adding to F clauses over the free variables that make the clauses of F with quantified variables redundant. The traditional Quantifier Elimination problem (QE) is a special case of PQE where G is <b>empty</b> so all <b>clauses</b> of the input formula with quantified variables need to be made redundant. The importance of PQE is twofold. First, many problems are more naturally formulated in terms of PQE rather than QE. Second, in many cases PQE can be solved more efficiently than QE. We describe a PQE algorithm based on the machinery of dependency sequents and give experimental results showing the promise of PQE...|$|R
50|$|This {{description}} of the resolution technique uses a set S as the underlying data-structure to represent resolution derivations. Lists, Trees and Directed Acyclic Graphs are other possible and common alternatives. Tree representations are more faithful {{to the fact that}} the resolution rule is binary. Together with a sequent notation for clauses, a tree representation also makes it clear to see how the resolution rule is related to a special case of the cut-rule, restricted to atomic cut-formulas. However, tree representations are not as compact as set or list representations, because they explicitly show redundant subderivations of clauses that are used more than once in the derivation of the <b>empty</b> <b>clause.</b> Graph representations can be as compact in the number of clauses as list representations and they also store structural information regarding which clauses were resolved to derive each resolvent.|$|E
5000|$|... {{function}} DPLL(Φ) if Φ is {{a consistent}} set of literals then return true; if Φ contains an <b>empty</b> <b>clause</b> then return false; for every unit clause l in Φ Φ ← unit-propagate(l, Φ); for every literal l that occurs pure in Φ Φ ← pure-literal-assign(l, Φ); l ← choose-literal(Φ); return DPLL(Φ ∧ l) or DPLL(Φ ∧ not(l));In this pseudocode, [...] and [...] are functions that return {{the result of}} applying unit propagation and the pure literal rule, respectively, to the literal [...] and the formula [...] In other words, they replace every occurrence of [...] with [...] "true" [...] and every occurrence of [...] with [...] "false" [...] in the formula , and simplify the resulting formula. The [...] in the [...] statement is a short-circuiting operator. [...] denotes the simplified result of substituting [...] "true" [...] for [...] in [...]|$|E
40|$|This article {{discusses}} {{constructions of}} the type 'En maar zeuren!' (You keep on nagging), which express a negative attitude of the speaker towards the proposition expressed by the construction. We will argue that 'en' (and) {{should be seen as}} a regular conjunction conjoining a phonetically <b>empty</b> <b>clause</b> with an overt infinitival clause: [[Ø] en [maar zeuren]]. The proposition expressed by the <b>empty</b> <b>clause</b> is determined by the common ground and contrasts with the propositional content of the second clause. This contrast is essential for obtaining the expressive meaning, but is potentially problematic in light of the regular interpretation of 'en'. We solve this by claiming that the contrastive reading is expressed by the conjunction in tandem with the discourse particle maar, which can also be used as a contrastive/oppositional conjunction...|$|E
40|$|We {{present a}} method for verifying {{properties}} of imperative programs that manipulate integer arrays. Imperative programs and their properties are represented by using Constraint Logic Programs (CLP) over integer arrays. Our method is refutational. Given a Hoare triple fpreg prog fpostg dening a partial correctness property of an imperative program prog, we encode the negation of the property as a predicate incorrect dened by a CLP program P, and we show that the property holds by proving that incorrect is not a consequence of P. Program veri cation is performed by applying a sequence of semantics preserving transformation rules and deriving a new CLP program T such that incorrect {{is a consequence of}} P i it is a consequence of T. The rules are applied according to an automatic strategy whose objective is to derive a program T that satises one of the following properties: either (i) T is the <b>empty</b> set of <b>clauses,</b> hence proving that incorrect does not hold and prog is correct, or (ii) T contains the fact incorrect, hence proving that prog is incorrect. Our transformation strateg...|$|R
40|$|The {{hypotheses}} {{constructed by}} Inductive Logic Programming (ILP) systems are logic programs that comprise a finite set of definite clauses. Much {{of the recent}} work in ILP has examined {{the question of how}} to find a single, high quality clause [...] - that is, one which accurately explains the classification of a set of given examples. Significantly less attention has been paid to {{the question of how to}} select a set of such clauses to form a high quality hypothesis. The usual method is to select clauses in a greedy manner: start with the <b>empty</b> set of <b>clauses</b> and repeatedly add the clause that most improves the quality of the set. This paper presents a non-greedy alternative for selecting the clauses that form a hypothesis. By separating the tasks of finding rules from combining them, Cautious Induction allows higher quality hypotheses to be found, with respect to a given hypothesis quality function. This claim is supported by the development of a top-down ILP system called CILS, and with a com [...] ...|$|R
40|$|An {{understanding}} of the syntactic and semantic properties of the two constructions illustrated in the sentences below {{has been an important}} achievement of generative grammar and has {{played a key role in}} the development of current syntactic theories. a. It seems that the tire's flat. b. The tire seems to be flat. As is well known, in classical transformational grammar and its derivatives in which transformations are preserved in some form, (b) -type sentences are related, in part, to the corresponding (a) -type sentences by RAISING, a phenomenon whereby what is the subject of the embedded clause at an underlying level of representation becomes the subject of the main clause at a superficial level of representation. More precisely, in the principles and parameters framework, as developed in Chomsky (1981) and much subsequent work, it is assumed that such verbs have no external argument (or underlying subject) and subcategorize for either a tensed or infinitival clausal complement. When the complement is infinitival, its subject must move into the empty subject position of the main clause in order to be Case-marked, since there is no Case-assigning governor of the embedded subject position and all NPs must be assigned Case; the result is the construction in (b), in which a trace of the moved NP occupies the embedded subject position. When the complement is tensed, the embedded subject finds a Case-assigning governor within the complement itself (i. e., the agreement inflection); the result is the construction in (a), in which the underlyingly <b>empty</b> main <b>clause</b> subject position is filled by the expletive pronoun it. This paper considers some different potential solutions to the problem posed by paraphrases of (a-b)  such as The tire seems like it's flat, which looks like it has raising while at the same time having an overt pronoun in a Case-marked position in the complement clause...|$|R
40|$|In this {{contribution}} {{we present}} a variant of a resolution theorem prover which selects resolution steps based on the proportion of models a newly generated clause satis es compared to all models given in a reference class. This reference class is generated from {{a subset of the}} initial clause set. Since the <b>empty</b> <b>clause</b> does not satisfy any models, preference is given to such clauses which satisfy few models only...|$|E
40|$|Proof {{reconstruction}} is {{the operation}} of extracting the computed proof from the trace of a theorem-proving run. We study the problem of proof reconstruction in distributed theorem proving: because of the distributed nature of the derivation and especially because of deletions of clauses by contraction, it may happen that a deductive process generates the <b>empty</b> <b>clause,</b> but does not have all the necessary information to reconstruct the proof. We analyze this problem and we present a method for distributed theorem proving, called Modified Clause-Diffusion, which guarantees that the deductive process that generates the <b>empty</b> <b>clause</b> {{will be able to}} reconstruct the distributed proof. This result is obtained without imposing a centralized control on the deductive processes or resorting to a round of post-processing with ad hoc communication. We prove that Modified Clause-Diffusion is fair (hence complete) and guarantees proof reconstruction. First we define a set of conditions, next we prove that they are sufficient for proof reconstruction, then we show that Modified Clause-Diffusion satisfies them. Fairness is proved in the same way, which has the advantage that the sufficient conditions provide a treatment of the problem relevant for distributed theorem proving in general. 1...|$|E
40|$|AbstractProof {{reconstruction}} is {{the operation}} of extracting the computed prooffrom the trace of a theorem-proving run. We study the problem of proof reconstruction indistributed theorem provingbecause of the distributed nature of the derivation and especially because of deletions of clauses bycontraction,it may happen that a deductive process generates the <b>empty</b> <b>clause,</b> but does not have all the necessary information to reconstruct the proof. We analyse this problem and we present a method for distributed theorem proving, calledModified Clause-Diffusion, which guarantees that the deductive process that generates the <b>empty</b> <b>clause</b> {{will be able to}} reconstruct the distributed proof. This result is obtained without imposing a centralized control on the deductive processes or resorting to a round of post-processing with ad hoc communication. We prove that Modified Clause-Diffusion is fair (hence complete) and guarantees proof reconstruction. First we define a set of conditions, next we prove that they are sufficient for proof reconstruction, then we show that Modified Clause-Diffusion satisfies them. Fairness is proved in the same way, which has the advantage that the sufficient conditions provide a treatment of the problem relevant for distributed theorem proving in general...|$|E
40|$|Abstract. We {{present a}} method for verifying {{properties}} of imperative programs that manipulate integer arrays. Imperative programs and their properties are represented by using Constraint Logic Programs (CLP) over integer arrays. Our method is refutational. Given a Hoare triple {ϕ} prog {ψ} that defines a partial correctness property of an imperative program prog, we encode the negation of the property as a predicate incorrect defined by a CLP program P, and we show that the property holds by proving that incorrect is not a consequence of P. Program verification is performed by applying a sequence of semantics preserving transformation rules and deriving a new CLP program T such that incorrect {{is a consequence of}} P iff it is a consequence of T. The rules are applied according to an automatic strategy whose objective is to derive a program T that satisfies one of the following properties: either (i) T is the <b>empty</b> set of <b>clauses,</b> hence proving that incorrect does not hold and prog is correct, or (ii) T contains the fact incorrect, hence proving that prog is incorrect. Our transformation strategy makes use of an axiomatization of the theory of arrays for the manipulation of array constraints, and also applies the widening and convex hull operators for the generalization of linear integer constraints. The strategy has been implemented in the VeriMAP transformation system and it {{has been shown to be}} quite effective and efficient on a set of benchmark array programs taken from the literature. 1...|$|R
40|$|In this {{contribution}} {{we propose}} {{a variant of}} a resolution theorem prover which selects resolution steps based on the proportion of models a newly generated clause satises compared to all models given in a reference class, which is generated from {{a subset of the}} initial clause set. Since the <b>empty</b> <b>clause</b> does not satisfy any models preference is given to such clauses which satisfy few models only. In order to avoid premature convergence, model-guided steps are interleaved with random steps...|$|E
40|$|Some {{aspects of}} the result of {{applying}} unit resolution on a CNF formula can be formalized as functions with domain a set of partial truth assignments. We are interested in two ways for computing such functions, {{depending on whether the}} result is the production of the <b>empty</b> <b>clause</b> or the assignment of a variable with a given truth value. We show that these two models can compute the same functions with formulae of polynomially related sizes, and we explain how this result is related to the CNF encoding of Boolean constraints...|$|E
