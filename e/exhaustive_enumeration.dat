297|36|Public
25|$|One {{approach}} for <b>exhaustive</b> <b>enumeration</b> goes as follows. Loop construction begins by aligning all possible fragments to overlap {{with the three}} residues at the N terminus of the loop (the anchor point). Then all possible choices for a second fragment are aligned to (all possible choices of) the first fragment, ensuring that the last three residues of the first fragment overlap with the first three residues of the second fragment. This ensures that the fragment chain forms realistic angles both within the fragment and between fragments. This is then repeated until a loop with the correct length of residues is constructed.|$|E
500|$|An <b>exhaustive</b> <b>enumeration</b> of {{the number}} of {{solutions}} for all possible configurations of three given circles, points or lines was first undertaken by Muirhead in 1896, although earlier work had been done by Stoll and Study. However, Muirhead's work was incomplete; it was extended in 1974 and a definitive enumeration, with 33 distinct cases, was published in 1983. Although solutions to Apollonius' problem generally occur in pairs related by inversion, an odd number of solutions is possible in some cases, e.g., the single solution for PPP, or when one or three of the given circles are themselves solutions. (An example of the latter is given in the [...] on Descartes' theorem.) However, there are no Apollonius problems with seven solutions. Alternative solutions based on the geometry of circles and spheres have been developed and used in higher dimensions.|$|E
2500|$|The first <b>exhaustive</b> <b>enumeration</b> of set {{partitions}} {{appears to}} have occurred in medieval Japan, where (inspired by {{the popularity of the}} book The Tale of Genji) a parlor game called genji-ko sprang up, ...|$|E
40|$|Acyclic orientations with {{exactly one}} source and one sink - the {{so-called}} bipolar orientations - arise in many graph algorithms and specially in graph drawing. The fundamental properties of these orientations are explored {{in terms of}} circuits, cocircuits and {{also in terms of}} ``angles'' in the planar case. Classical results get here new simple proofs; new results concern the extension of partial orientations, <b>exhaustive</b> <b>enumerations,</b> the existence of deletable and contractable edges, and continuous transitions between bipolar orientations...|$|R
40|$|Abstract: We {{investigate}} the VC-dimension of the perceptron and simple two-layer networks like the committee- and the parity-machine with weights restricted to values ± 1. For binary inputs, the VC-dimension {{is determined by}} atypical pattern sets, i. e. it cannot be found by replica analysis or numerical Monte Carlo sampling. For small systems, <b>exhaustive</b> <b>enumerations</b> yield exact results. For systems that are too large for enumerations, number theoretic arguments give lower bounds for the VC-dimension. For the Ising perceptron, the VC-dimension is probably larger than N/ 2...|$|R
40|$|We {{investigate}} the VC-dimension of the perceptron and simple two-layer networks like the committee- and the parity-machine with weights restricted to values ± 1. For binary inputs, the VC-dimension {{is determined by}} atypical pattern sets, i. e. it cannot be found by replica analysis or numerical Monte Carlo sampling. For small systems, <b>exhaustive</b> <b>enumerations</b> yield exact results. For systems that are too large for enumerations, number theoretic arguments give lower bounds for the VC-dimension. For the Ising perceptron, the VC-dimension is probably larger than N/ 2. Comment: 12 pages, LaTeX 2 e, 7 figures (eps...|$|R
50|$|The {{algorithm}} {{depends on}} the efficient estimation of the lower and upper bounds of a region/branch of the search space and approaches <b>exhaustive</b> <b>enumeration</b> as the size (-dimensional volume) of the region tends to zero.|$|E
5000|$|Faster {{than the}} <b>exhaustive</b> <b>enumeration</b> but still exponential, and the {{drawback}} of this algorithm, though, {{is that it}} also uses a lot of space: the worst-case time complexity of this algorithm is [...] and the space [...]|$|E
50|$|The first <b>exhaustive</b> <b>enumeration</b> of set {{partitions}} {{appears to}} have occurred in medieval Japan, where (inspired by {{the popularity of the}} book The Tale of Genji) a parlor game called genji-ko sprang up,in which guests were given five packets of incense to smell and were asked to guess which ones were the same as each other and which were different. The 52 possible solutions, counted by the Bell number B5, were recorded by 52 different diagrams, which were printed above the chapter headings in some editions of The Tale of Genji.|$|E
50|$|The theory {{achieves}} an <b>exhaustive</b> and discrete <b>enumeration</b> of {{the data}} points.|$|R
40|$|We study {{a simple}} heteropolymer model {{containing}} sequence-independent local interactions on both square and triangular lattices. Sticking to a two-letter code, we investigate {{the model for}} varying strength of the local interactions; = 0 corresponds to the well-known HP model [K. F. Lau and K. A. Dill, Macromolecules 22, 3986 (1989) ]. By <b>exhaustive</b> <b>enumerations</b> for short chains, we obtain all structures which act as a unique and pronounced energy minimum {{for at least one}} sequence. We find that the number of such designable structures depends strongly on. Also, we find that the number of designable structures can differ widely for the two lattices at a given. This is the case, for example, at = 0, which implies that the HP model exhibits different behavior on the two lattices. Our findings clearly show that sequence-independent local properties of the chains can {{play an important role in}} the formation of unique minimum energy structures. 1 irback@thep. lu. se 2 erik@thep. lu. se 1 [...] ...|$|R
40|$|This paper {{primarily}} {{deals with}} improving the computational {{efficiency of the}} continuation small signal stability analysis of a microgrid. The continuation (or iterative) small signal stability analysis is required to carry out control parameter tuning based upon the system level study. In specific, tuning of droop coefficients and current feed-forward loop gains of voltage controllers in an islanded microgrid is addressed. A generalized system configuration with non-identical sources and arbitrary load placements is considered. The construction of the system state matrix for such generalized configuration is explained. Similarly to the existing approaches, the continuation small signal stability analysis is performed through <b>exhaustive</b> <b>enumerations.</b> However, the system state matrix is initially decomposed into components {{in the form of}} the coefficients of parameters to be tuned. Therefore, there is no need to entirely reconstruct the system matrix at each iteration. The computation time requirement can be further reduced by deploying the sparsity of each matrix component. A clear rule is also established for the tuning of multiple parameters. The effectiveness of the methodology proposed is verified through a detailed case study...|$|R
50|$|One {{approach}} for <b>exhaustive</b> <b>enumeration</b> goes as follows. Loop construction begins by aligning all possible fragments to overlap {{with the three}} residues at the N terminus of the loop (the anchor point). Then all possible choices for a second fragment are aligned to (all possible choices of) the first fragment, ensuring that the last three residues of the first fragment overlap with the first three residues of the second fragment. This ensures that the fragment chain forms realistic angles both within the fragment and between fragments. This is then repeated until a loop with the correct length of residues is constructed.|$|E
5000|$|According to Hutcheson, man has {{a variety}} of senses, {{internal}} as well as external, reflex as well as direct, the general definition of a sense being [...] "any determination of our minds to receive ideas independently on our will, and to have perceptions of pleasure and pain" [...] (Essay on the Nature and Conduct of the Passions, sect. 1). He does not attempt to give an <b>exhaustive</b> <b>enumeration</b> of these [...] "senses," [...] but, in various parts of his works, he specifies, besides the five external senses commonly recognized (which he hints might be added to): ...|$|E
5000|$|Given {{the known}} {{importance}} of discovering local patterns in time-series data, recent proposals {{have addressed the}} biclustering problem in the specific case of time series gene expression data. In this case, the interesting biclusters can be restricted to those with contiguous columns. This restriction leads to a tractable problem and enables the development of efficient <b>exhaustive</b> <b>enumeration</b> algorithms such as CCC-Biclustering [...] and e-CCC-Biclustering. The approximate patterns in CCC-Biclustering algorithms allow a given number of errors, per gene, relatively to an expression profile representing the expression pattern in the bicluster. The e-CCC-Biclustering algorithm uses approximate expressions to find and report all maximal CCC-Biclusters by a discretized matrix A and efficient string processing techniques.|$|E
40|$|We {{consider}} {{the question of}} how to design proteins. How can we find "good" amino acid sequences (i) that fold to a desired "target" structure as a native conformation of lowest accessible free energy and (ii) that will not simultaneously fold to many other conformations of the same free energy? Current protein designs often focus on helix propensities and turns. We focus here on designing the hydrophobicity. For a model of self-avoiding hydrophobic/polar chains on two-dimensional square lattices, geometric proofs and <b>exhaustive</b> <b>enumerations</b> show the following results. (i) The strategy hydrophobic residues inside/polar residues outside is not optimal. Placement of additional hydrophobic residues on the surface is often necessary. (ii) To avoid unwanted conformations, the designed sequence must have neither too many nor too few hydrophobic residues. (iii) The computational complexity of inverse folding appears to be in a different class than folding: unlike the folding problem, the design problem does not scale exponentially with chain length. Some design strategies, described here for the lattice model, produce good sequences and scale only linearly with chain length...|$|R
40|$|Abstract. In this paper, {{we present}} a constraint-partitioning {{approach}} for finding local optimal solutions of large-scale mixed-integer nonlinear programming problems (MINLPs). Based on our observation that MINLPs in many engineering applications have highly structured constraints, we propose to partition these MINLPs by their constraints into subproblems, solve each subproblem by an existing solver, and resolve those violated global constraints across the subproblems using our theory of extended saddle points. Constraint partitioning allows many MINLPs that cannot be solved by existing solvers to be solvable because it leads to easier subproblems that are significant relaxations of the original problem. The success of our approach relies on our ability to resolve violated global constraints efficiently, without requiring <b>exhaustive</b> <b>enumerations</b> of variable values in these constraints. We have developed an algorithm for automatically partitioning a large MINLP {{in order to minimize}} the number of global constraints, an iterative method for determining the optimal number of partitions in order to minimize the search time, and an efficient strategy for resolving violated global constraints. Our experimental results demonstrate significant improvements over the best existing solvers in terms of solution time and quality in solving a collection of mixed-integer and continuous nonlinear constrained optimization benchmarks. ...|$|R
40|$|Statically {{estimating}} {{the worst case}} execution time (WCET) of a program is important for real-time software. This is difficult even in the programming language level due to the inherent difficulty in detecting and exploiting infeasible paths in a program’s control flow graph. In this paper, we propose an efficient method to exploit infeasible path information for WCET estimation of a loop without resorting to <b>exhaustive</b> path <b>enumeration.</b> The efficiency of our approach is demonstrated with a real-life control-intensive program. 1...|$|R
50|$|An <b>exhaustive</b> <b>enumeration</b> of {{the number}} of {{solutions}} for all possible configurations of three given circles, points or lines was first undertaken by Muirhead in 1896, although earlier work had been done by Stoll and Study. However, Muirhead's work was incomplete; it was extended in 1974 and a definitive enumeration, with 33 distinct cases, was published in 1983. Although solutions to Apollonius' problem generally occur in pairs related by inversion, an odd number of solutions is possible in some cases, e.g., the single solution for PPP, or when one or three of the given circles are themselves solutions. (An example of the latter is given in the section on Descartes' theorem.) However, there are no Apollonius problems with seven solutions. Alternative solutions based on the geometry of circles and spheres have been developed and used in higher dimensions.|$|E
50|$|Regarding the {{functions}} of the Minister, {{it should be noted that}} they can be divided between those that he serves as a member of the Government, and those he performs as a Minister. Regarding this second aspect, it should be noted that there is an immense variety of functions that the Minister plays in his role of head and director of the corresponding Ministerial Department. The Law about Organization and Functioning of the General State Administration makes an <b>exhaustive</b> <b>enumeration</b> of functions, among which the ones related to the appointment and separation of the governing bodies of the Ministry, the determination of their internal organizational structure, human resources management, issues Economic and budgetary aspects of its Department, and to end representative functions, in a political (relations with the Autonomous Communities, etc.) and legal (acting on behalf of the legal entity of the State and imputation of its acts) sense.|$|E
50|$|It {{turns out}} that the ladder {{algorithm}} does not do the trick on its own. In fact the jump pointer algorithm and the ladder algorithm complement one another. The two algorithms work in opposite directions: the jump pointer algorithm makes exponentially decreasing hops and the ladder algorithm makes exponentially increasing hops. A combination of the two algorithms can answer queries in O(1) time. A single jump pointer takes any query at least halfway up the tree after which climbing up only one ladder will answer the query. This results in O(n log n) pre-processing time and O(1) query time. The pre-processing can be further reduced to O(n) time by an application of the Method of Four Russians, in which the tree is reduced to a smaller tree with linear preprocessing, and a collection of very small trees, which are small enough that an <b>exhaustive</b> <b>enumeration</b> of all trees and the preprocessing of those trees is still O(n) time. Trees of size (log n)/4 suffice.|$|E
40|$|International audienceIn {{this work}} {{we present a}} novel {{technique}} for <b>exhaustive</b> bicluster <b>enumeration</b> using formal concept anal-ysis (FCA). Particularly, we use pattern structures (an ex-tension of FCA dealing with complex data) to mine similar row/column biclusters, a specialization of biclustering when attribute values have coherent variations. We show how bi-clustering can benefit from the FCA framework through its ro-bust theoretical description and efficient algorithms. Finally, we evaluate our bicluster mining approach w. r. t. a standard biclustering technique showing very good results in terms of bicluster quality and performance...|$|R
40|$|Accurate {{estimation}} of the worst-case execution time (WCET) of a program is important for real-time embedded software. Static WCET estimation involves program path analysis and architectural modeling. Path analysis is complex due to the inherent difficulty in detecting and exploiting infeasible paths in a program’s control flow graph. In this paper, we propose an efficient method to exploit infeasible path information for WCET estimation without resorting to <b>exhaustive</b> path <b>enumeration.</b> We demonstrate the efficiency of our approach for some real-life control-intensive applications. Categories and Subject Descriptors C. 3 [Special-purpose and Application-based Systems]: Real-time and embedded systems; D. 2. 8 [Software Engineering]...|$|R
40|$|In 1999 Davis and Jedwab gave {{a direct}} {{construction}} of Golay complementary sequences over Z 2 h of length 2 m. Recently Li and Chu found 1024 more quaternary Golay complementary sequences of length 16, that cannot {{be obtained by}} the direct construction, using <b>exhaustive</b> computer <b>enumeration.</b> It is shown how these sequences arise from interleaving and concatenation of two classes of Golay complementary sequences given as an example by Davis and Jedwab. These examples spawn new Golay sequences over Z 2 h of length 2 m for all h ≥ 2 and m ≥ 4...|$|R
3000|$|How to {{efficiently}} {{search for}} the optimal subgraph patterns without <b>exhaustive</b> <b>enumeration</b> in the primary graph space? [...]...|$|E
40|$|The {{construction}} of optimal decision trees {{for the problem}} stated within {{can be accomplished by}} an <b>exhaustive</b> <b>enumeration.</b> This paper discusses two approaches. The section on heuristic methods gives mostly negative results (E. G. there is no merit factor that will always yield the optimal tests, etc.), but most to these methods do give good results. The section entitled "Exhaustive Enumeration Revisited" indicates some powerful shortcuts that can be applied to an <b>exhaustive</b> <b>enumeration,</b> extending the range of this method...|$|E
40|$|ACM Great Lakes Symposium on VLSI 2009 (GLSVLSI 2009) : Boston, Massachusetts : May 10 - 12, 2009 Recent {{technology}} mappers for LUT-based FPGAs employ cut enumeration. Although many {{cuts are}} often {{needed to find}} good network, enumerating all cuts with large size consumes run-time very much. The number of cuts exponentially increases {{with the size of}} cuts, which causes long run-time. Furthermore, an inefficiency of bottom-up merging in existing algorithms makes the run-time much longer. This paper presents a novel cut enumeration. The proposed algorithm is efficient because it enumerates cuts without bottom-up merging. Our algorithm has two modes; <b>exhaustive</b> <b>enumeration</b> and partial enumeration. <b>Exhaustive</b> <b>enumeration</b> enumerates all cuts. Partial enumeration enumerates partial cuts with a guarantee that a depth-minimum network can be constructed. The experimental results show that <b>exhaustive</b> <b>enumeration</b> runs about 3 times and 8 times faster than existing bottom-up algorithm [1] [2] for K= 8, 9, respectively. The quality of network are the same. Furthermore, partial enumeration runs about 6 times and 18 times faster than bottom-up algorithm for K= 8, 9, respectively. Area of network derived by the set of cuts enumerated by partial enumeration is only 4 % larger than that derived by <b>exhaustive</b> <b>enumeration</b> on average, and the depth is the same...|$|E
40|$|The main aim of {{this paper}} is to {{demonstrate}} the effectiveness of using Situation Calculus in Task Modelling. The motivation for this approach is to enable a runtime adaptable task model to be used in the provision of the most appropriate user interfaces, according to circumstance. The task model and meta-reasoning model may both be specified in the Situation Calculus, which permits reasoning to occur over couterfactual situations and without <b>exhaustive</b> state <b>enumeration.</b> A task flow editor with input from the formal model is demonstrated and the approach is described using a medical process case study. Anglai...|$|R
40|$|ABSTRACT Knowledge of {{amino acid}} composition, alone, is {{verified}} {{here to be}} suffi-cient for recognizing the structural class, a, b, a 1 b, or a/b of a given protein with an accu-racy of 81 %. This is supported by results from <b>exhaustive</b> <b>enumerations</b> of all conformations for all sequences of simple, compact lattice models consisting of two types (hydrophobic and polar) of residues. Different compositions exhibit strong affinities for certain folds. Within the limits of validity of the lattice models, two factors appear to determine the choice of particular folds: 1) the coordination numbers of individual sites and 2) the size and geometry of non-bonded clusters. These two properties, collectively termed the distribution of non-bonded contacts, are quantitatively assessed by an eigenvalue analysis of the so-called Kirch-hoff or adjacency matrices obtained by con-sidering the non-bonded interactions on a lat-tice. The analysis permits the identification of conformations that possess the same distri-bution of non-bonded contacts. Furthermore, some distributions of non-bonded contacts are favored entropically, due to their high degeneracies. Thus, a competition between enthalpic and entropic effects is effective in determining {{the choice of a}} distribution for a given composition. Based on these findings, an analysis of non-bonded contacts in protein structures was made. The analysis shows that proteins belonging to the four distinct folding classes exhibit significant differences in their distributions of non-bonded contacts, which more directly explains the success in predicting structural class from amino acid composition. Proteins 29 : 172 – 185...|$|R
40|$|Most modern compilers operate by {{applying}} a fixed, program-independent sequence of optimizations to all programs. Compiler writers choose a single “compilation sequence”, {{or perhaps a}} couple of compilation sequences. In choosing a sequence, they may consider performance of benchmarks or other important codes. These sequences are intended as general-purpose tools, accessible through command-line flags such as-O 2 and-O 3. Specific compilation sequences make {{a significant difference in}} the quality of the generated code, whether compiling for speed, for space, or for other metrics. A single universal compilation sequence does not produce the best results over all programs [8, 10, 29, 32]. Finding an optimal programspecific compilation sequence is difficult because the space of potential sequences is huge and the interactions between optimizations are poorly understood. Moreover, there is no systematic exploration of the costs and benefits of searching for good (i. e., within a certain percentage of optimal) program-specific compilation sequences. In this paper, we perform a large experimental study of the space of compilation sequences over a set of known benchmarks, using our prototype adaptive compiler. Our goal is to characterize these spaces and to determine if it is costeffective to construct custom compilation sequences. We report on five <b>exhaustive</b> <b>enumerations</b> which demonstrate that 80 % of the local minima in the space are within 5 to 10 % of the optimal solution. We describe three algorithms tailored to search such spaces and report on experiments that use these algorithms to find good compilation sequences. These experiments suggest that properties observed in the enumerations hold for larger search spaces and larger programs. Our findings indicate that for the cost of 200 to 4, 550 compilations, we can find custom sequences that are 15 to 25 % better than the human-designed fixed-sequence originally used in our compiler...|$|R
30|$|Input {{the prior}} information: the image patch, the quality factor {{of the final}} {{compression}} QF 2, and the coordinate shift (x S, y S) (which is given by an <b>exhaustive</b> <b>enumeration</b> on 63 possible coordinate shifts, see Section 4.3).|$|E
40|$|A new Stata command called -mgof- is introduced. The {{command is}} used to compute {{distributional}} tests for discrete (categorical, multinomial) variables. Apart from classic large sample χ^ 2 -approximation tests based on Pearson's X^ 2, the likelihood ratio, or any other statistic from the power-divergence family (Cressie and Read 1984), large sample tests for complex survey designs and exact tests for small samples are supported. The complex survey correction {{is based on the}} approach by Rao and Scott (1981) and parallels the survey design correction used for independence tests in -svy:tabulate-. The exact tests are computed using Monte Carlo methods or <b>exhaustive</b> <b>enumeration.</b> An exact Kolmogorov-Smirnov test for discrete data is also provided. multinomial, goodness-of-fit, chi-squared, categorical data, exact tests, Monte Carlo, <b>exhaustive</b> <b>enumeration,</b> combinatorial algorithms, complex survey correction, power-divergence statistic, Kolmogorov-Smirnov, Benford's law...|$|E
40|$|The {{study of}} energy landscapes of biopolymers and their models is an {{important}} field in bioinformatics [1, 2]. For instance, the investigation of kinetics or folding simulations are done using methods {{that are based on}} sampling or <b>exhaustive</b> <b>enumeration</b> [3, 4]. Most of such algorithms are independent of the underlyin...|$|E
40|$|We {{introduce}} SciFe, a {{tool for}} automated generation of com-plex structures, suitable for tasks such as automated test-ing and synthesis. SciFe is capable of <b>exhaustive,</b> memo-ized <b>enumeration</b> of values from finite or infinite domains. SciFe {{is based on the}} concept of an enumerator, defined as an efficiently computable bijection between natural numbers and values from a given set. SciFe introduces higher-order enumerators which define enumerators that depend on ad-ditional parameters. SciFe also includes combinators that can construct more complex enumerators from existing ones while preserving exhaustiveness and efficiency. SciFe is a Scala library that implements a domain-specific language. This tool demo presents an overview of SciFe as well as its use to generate complex structures such as search trees and models of class hierarchies. Our experiments demon-strate better performance and shorter specifications when compared to existing approaches...|$|R
40|$|Abstract—The {{last decade}} has {{witnessed}} {{the emergence of}} the application-specific instruction-set processor (ASIP) as a viable platform for embedded systems. Extensible ASIPs allow the user to augment a base processor with instruction set extensions (ISEs) that execute on dedicated hardware application-specific functional units (AFUs). Due to the limited number of read and write ports in the register file of the base processor, the size and complexity of AFUs are generally limited. Recent papers have focused on overcoming these constraints by serializing access to the register file. <b>Exhaustive</b> ISE <b>enumeration</b> methods are not scalable and generally fail for larger applications and register files with a large number of read and write ports. To address this concern, a new approach to ISE identification is proposed. The approach presented in this paper significantly prunes the list of the best possible ISE candidates compared to previou...|$|R
40|$|The Hamming weight {{enumerator}} {{function of}} the formally self-dual even, binary extended quadratic residue code of prime p = 8 m + 1 is given by Gleason’s theorem for singly-even code. Using this theorem, the Hamming weight distribution of the extended quadratic residue is completely determined once the number of codewords of Hamming weight j Aj, for 0 ≤ j ≤ 2 m, are known. The smallest prime for which the Hamming weight distribution of the corresponding extended quadratic residue code is unknown is 137. It is shown in this paper that, for p = 137 A 2 m = A 34 may be obtained without the need of <b>exhaustive</b> codeword <b>enumeration.</b> After the remainder of Aj required by Gleason’s theorem are computed and independently verified using their congruences, the Hamming weight distributions of the binary augmented and extended quadratic residue codes of prime 137 are derived. ...|$|R
