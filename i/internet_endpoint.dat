1|20|Public
50|$|These factors led to {{interest}} {{in the use of}} large scale storage (and to a lesser extent, processing) resources to cache the response to network requests, first at the <b>Internet</b> <b>endpoint</b> using a Web browser cache and later at intermediate network locations using shared network caches.This line of development also gave rise to Web server replication and other techniques for offloading and distributing the work of delivering large volume Web services to widely dispersed client communities, ultimately resulting in the creation of modern Content delivery networks.|$|E
50|$|Bitdefender {{develops}} {{and markets}} anti-virus, <b>internet</b> security, <b>endpoint</b> security, and other cyber security products and services.|$|R
40|$|Web-based {{persistent}} identifiers {{have been}} around for more than 20 years, a period long enough for us to start observing patterns of success and failure. Persistent identifiers were invented to address challenges arising from the distributed and disorganised nature of the internet, which often resulted in URLs to <b>internet</b> <b>endpoints</b> becoming invalid. Over the years several different persistent identifier systems have been applied to the identification of research data, not all with the same level of success in terms of uptake and sustainability. We investigate the uptake of persistent identifier systems and discuss the factors that might determine the stability and longevity of these systems. Persistent identifiers have become essential elements of global research data infrastructures. Understanding the factors that influence the stability and longevity of persistent identifier systems will help us guide the future development of this important element of research data infrastructures and will make it easier to adapt to future technological and organisational changes...|$|R
50|$|Bitdefender is a Romanian cybersecurity and anti-virus software company. It {{was founded}} in 2001 by Florin Talpeş who is {{currently}} the CEO. Bitdefender develops and sells anti-virus software, <b>internet</b> security software, <b>endpoint</b> security software, and other cybersecurity products and services.|$|R
40|$|The {{deployment}} of encrypted transport protocols imposes new challenges for network operations. Key in-network {{functions such as}} those implemented by firewalls and passive measurement devices currently rely on information exposed by the transport layer. Encryption, in addition to improving privacy, helps to address ossification of network protocols caused by middleboxes that assume certain information {{to be present in}} the clear. However, “encrypting it all” risks diminishing the utility of these middleboxes for the traffic management tasks for which they were designed. A middlebox cannot use what it cannot see. We propose an architectural solution to this issue, by introducing a new “path layer” for transport-independent, in-band signaling between <b>Internet</b> <b>endpoints</b> and network elements on the paths between them, and using this layer to reinforce the boundary between the hop-by-hop network layer and the end-to- end transport layer. We define a path layer header on top of UDP to provide a common wire image for new, encrypted transports. This path layer header provides information to a transport- independent on-path state machine that replaces stateful handling currently based on exposed header flags and fields in TCP; it enables explicit measurability of transport layer performance; and offers extensibility by sender-to-path and path-to-receiver communications for diagnostics and management. This provides not only a replacement for signals that are not available with encrypted traffic, but also allows integrity-protected, enhanced signaling under endpoint control. We present an implementation of this wire image integrated with the QUIC protocol, as well as a basic stateful middlebox built on Vector Packet Processing (VPP) provided by FD. io...|$|R
40|$|The Session Initiation Protocol (SIP) [1] is a {{signaling}} protocol {{used to set}} up and tear down multimedia sessions between two <b>endpoints</b> over the <b>Internet.</b> The <b>endpoints</b> are called user agents: user agent client (UAC) initiates a new session to a user agent server (UAS) by sending an INVITE request. The UAS responds with zero or more provisional response such as " 180 Ringing " and one final response such as " 200 OK " or " 486 Busy Here". There are also intermediaries that route requests for user agents called proxy servers. Figure 1 shows the basic setup of two user agents and two proxy servers in an arrangement known as the “SIP trapezoid”...|$|R
40|$|The {{project is}} {{concerned}} with implementing the technology of Voice over Internet Protocol (VOIP), the VOIP in the University of Khartoum (UofK) has already been designed, and the aims of this project customization of the services on Session Initiation Protocol Express Router Web (SERWEB). There are many applications of the Internet that require the creation and management of a session, where a session is considered an exchange of data between associations of participants. The implementation of these applications {{is complicated by the}} practices of participants. Numerous protocols have been authored that carry various forms of real time multimedia session data such as voice, video, or text messages. The Session Initiation Protocol (SIP) works in concert with these protocols by enabling <b>Internet</b> <b>endpoints</b> (called user agents) to discover one another and to agree on a characterization of a session they would like to share. For locating prospective session participants, and for other functions, SIP enables the creation of an infrastructure of network hosts (called proxy servers) to which user agents can send registrations, invitations to sessions, and other requests. SIP is an agile, general purpose tool for creating, modifying, and terminating sessions that works independently of underlying transport protocols. SER is an open source project that aims to make available a fully functional and scalable Session Initiated Protocol server. Call processing is described with a concise scripting language that offers the flexibility of regular expressions and the ability to interface with 3 rd party applications for the purposes of call accounting and authorization. This presumes that a working Web Server (that means we get the design of web based management and control system in UofK) ...|$|R
40|$|INTRODUCTION While Internet Telephony (IP Telephony) {{encompasses}} {{many different}} architectures and services, {{the key idea}} is the transport of real-time voice traffic over the Internet. IP Telephony architecture [2] allows the entire end-to-end path or a portion thereof to be routed over the <b>Internet.</b> The <b>endpoints</b> are regular personal computers (PCs) that are equipped with IP Telephony software which allows them to interface with the existing Public Switched Telephone Network (PSTN) through an Internet Telephony Gateway (ITG). The only delay suffered by the voice traffic in the PSTN network is the propagation delay which is fixed once the circuit has been established. On the other hand, the Internet is still inherently a best-effort network and provides no end-to-end bandwidth guarantees. Thus, transporting packetized voice over the Internet can result not only in variable delays but also losses which may cause poor audio quality at the receiver. Furthermore, these losses an...|$|R
40|$|It was {{a common}} {{assumption}} on the <b>Internet</b> that <b>endpoints</b> access the network through only one interface. But now, most mobile devices support several access technologies and can have several IP interfaces. This diversity {{can be used to}} improve network performance. Traditional protocols do not support multi-access thus new solutions have to be deployed. This thesis explores the use of MultiPath TCP as a solution to take advantage of multiple interfaces on mobile endpoints. It considers more specifically the case of devices that support several 3 G subscriptions. MPTCP can use several interfaces concurrently but it raises a problem of power consumption. Dynamic interface selection is proposed as {{a way to make a}} tradeoff between performance and battery life. To evaluate the performance of MPTCP and the different path selection algorithms in real world conditions, this work included the design and implementation of a test bed based on a laptop and three mobile phones. The results showed that MPTCP with or without interface selection can improve the performance of TCP connections on multihomed endpoints...|$|R
40|$|Telecommunication {{networks}} are moving from circuit-switched public-switched telephone network (PSTN) to packet-switched Internet telephony. A {{major difference between}} Internet telephony and PSTN is that the PSTN usually assumes dumb <b>endpoints</b> while <b>Internet</b> telephony incorporates intelligent <b>endpoints.</b> In <b>Internet</b> telephony, <b>endpoints</b> usually have CPU and memory, so they are programmable and can perform services such as call forwarding, transfer, and screening. In addition, peer-to-peer (P 2 P) technologies introduce telecommunication networks that do not need proxy or application servers to make calls. In such P 2 P networks, many telecommunication services {{have to be performed}} on end systems, such as intelligent phones. The enhanced capabilities of end systems and the service requirements in P 2 P networks motivate the investigation of end system services in this thesis. Performing services in end systems may result in many new communication services, make telecommunication services more distributed, and make telecommunication networks more robust and efficient overall. At the same time, telecommunication services may become more difficult to manage, thus requiring new techniques for creatin...|$|R
40|$|In {{order to}} {{integrate}} Robust Header Compression (ROHC) with IPsec, a mechanism {{is needed to}} signal ROHC channel parameters between <b>endpoints.</b> <b>Internet</b> Key Exchange (IKE) is a mechanism that can be leveraged to exchange these parameters. This document specifies extensions to IKEv 2 that will allow ROHC and its associated channel parameters to be signaled for IPsec Security Associations (SAs). Status of This Memo This is an Internet Standards Track document. This document {{is a product of}} the Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by th...|$|R
40|$|IKEv 2 Extensions to Support Robust Header Compression over IPsec In {{order to}} {{integrate}} Robust Header Compression (ROHC) with IPsec, a mechanism {{is needed to}} signal ROHC channel parameters between <b>endpoints.</b> <b>Internet</b> Key Exchange (IKE) is a mechanism that can be leveraged to exchange these parameters. This document specifies extensions to IKEv 2 that will allow ROHC and its associated channel parameters to be signaled for IPsec Security Associations (SAs). Status of This Memo This is an Internet Standards Track document. This document {{is a product of}} the Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by th...|$|R
40|$|To keep up {{with the}} {{security}} needs being exerted by the ever-increasing complexity of technology, new ideas and approaches are needed. Once such attempt to address this is the Internet Scale Event and Attack Generation Environment (ISEAGE) at Iowa State University (ISU). ISEAGE is a next generation Internet testbed that hopes to provide researchers with the tools and resources necessary to address the every vexing security issues in today 2 ̆ 7 s world. Among the many challenges involved with creating an Internet scale testbed is how to realistically virtualize the thousands of servers that make up the various destinations or <b>endpoints</b> on the <b>Internet.</b> To specifically address this problem, the <b>Internet</b> Scale <b>Endpoint</b> Masquerading tool (ISEMasq) was developed. ISEMasq {{is an integral part of}} ISEAGE that enables a small set of servers with off-the-shelf software to pose or masquerade as any number of actual Internet destinations. To accomplish this, ISEMasq leverages various API functionality from the current and upcoming release of the ISO C++ standard, as well as other widely used and accepted third-party C and C++ networking APIs. The result is a highly reliable, performance driven, packet level network tool that brings ISEAGE one step closer to completion...|$|R
40|$|A Virtual Private Network (VPN) aims {{to emulate}} the {{services}} provided by a private network over the shared <b>Internet.</b> The <b>endpoints</b> of VPN are connected using abstractions such as Virtual Channels (VCs). Reliability of an end-to-end VPN connection depends on {{the reliability of the}} links and nodes. VPN service providers provide new services with Quality of Service (QoS), guarantees are also resilient to failures. Supporting QoS connections requires the existence of routing mechanisms that computes the QoS paths, where these paths satisfy the QoS constraints. Resilience to failures, on the other hand, is achieved by providing, each primary QoS path, a set of alternative QoS paths, upon a failure of either a link or a node. We aim at to minimize the total bandwidth reserved on the backup edges. The above objectives, coupled with the need to minimize the global use of network resources, imply that the cost of both the primary path and the restoration topology should be a major consideration of the routing process. It turns out that the widely used approach of disjoint primary, restoration paths is not an optimal strategy. Hence, the proposed approximation restoration algorithms construct a restoration topology, and this topology protects a portion of the primary QoS path. This approach guarantees to find a restoration topology with optimal cost which satisfies the QoS constraints...|$|R
40|$|Part 3 : Web, Content, and InterdomainInternational audienceAn IP prefix can be {{announced}} on the <b>Internet</b> from multiple <b>endpoints,</b> possibly leading to so-calledMOAS (Multiple-Origin AS) prefixes. Longlived MOASes are traditionally {{considered to be}} the result of network topology engineering such as prefix multihoming. Short-lived MOAS are commonly attributed {{to be the result of}} router misconfigurations. In this article, we look atMOAS prefixes in the long term and seek the patterns behind these situations. We first revisit previous work by looking at the duration of MOAS events. We group these events according to the prefix announced and show that short-lived MOASes are not due to misconfigurations, but to origin instability or route flapping. We also identify topology patterns that result inMOAS prefixes and use them to classify these events. We show that, contrary to popular belief, multihoming is neither the main use case leading to MOAS, nor the most popular pattern. Finally, we look at the evolution of these observations by analysing data collected 10 years apart...|$|R
40|$|A Virtual Private Network (VPN) aims {{to emulate}} the {{services}} provided by a private network over the shared <b>Internet.</b> The <b>endpoints</b> of a VPN are connected using abstractions such as Virtual Channels (VCs) of ATM or Label Switching Paths (LSPs) of MPLS technologies. Reliability of an end-to-end VPN connection depends on {{the reliability of the}} links and nodes in the fixed path that it traverses in the network. In order to ensure service quality and availability in a VPN, seamless recovery from failures is essential. This work considers the problem of fast recovery in the recently proposed VPN hose model. In the hose model bandwidth is reserved for traffic aggregates instead of pairwise specifications to allow any traffic pattern among the VPN endpoints. This work assumes that the VPN endpoints are connected using a tree structure and at any time, at most one tree link can fail (i. e., single link failure model). A restoration algorithm must select asetofbackup edges and allocate necessary bandwidth on them in advance, so that the traffic disrupted by failure of a primary edge can be re-routed via backup paths. We aim at designing an optimal restoration algorithm to minimize the total bandwidth reserved on the backup edges. This problem is a variant of optimal graph augmentation problem which is NP-Complete. Thus, we present a polynomial-time approximation algorithm that guarantees a solution which is at most 16 times of the optimum. The algorithm is based on designing two reductions to convert the original problem to one of adding minimum cost edges to the VPN tree so that the resulting graph is 2 -connected, which can be solved in polynomial time using known algorithms. The two reductions introduce approximation factors of 8 and 2, respectively, thus resulting in a 16 -appro [...] ...|$|R
40|$|The TCP/IP {{protocol}} suite {{is the foundation}} of the Internet. Upon this foundation, other higherlevel TCP/IP-based protocols rapidly grew in popularity because they made common services widely available. Today an entire second layer of Internet architecture is developing. Known as Web Services, this layer is also based on a common protocol—SOAP, a way for applications to exchange messages instead of a way for machines to exchange packets. SOAP moves up one level in abstraction. Instead of packets encoded in bytes, SOAP delivers messages encoded in XML. With XML and its companion schema definition language, XML Schemas, it is no longer necessary to use a limited set of pre-defined, widely standardized application protocols to share services. Instead new services can be defined when and where needed using a common web service description language, WSDL. This underscores extensibility as the fundamental advantage of the Web Services layer over the TCP/IP layer. Yet in this very extensibility lies a new challenge. Service endpoints are now no longer exclusively Internet hosts, or even users at a specific <b>Internet</b> domain. The <b>endpoints</b> are now logical endpoints — applications, users, objects, or any other resource involved in We...|$|R
40|$|Physical {{training}} has beneficial effects on exercise capacity, {{quality of life}} and mortality in patients after a cardiac event or intervention and is therefore a core component of cardiac rehabilitation. However, cardiac rehabilitation uptake is low and effects tend to decrease after the initial rehabilitation period. Home-based {{training has}} the potential to increase cardiac rehabilitation uptake, and was shown to be safe and effective in improving short-term exercise capacity. Long-term effects on physical fitness and activity, however, are disappointing. Therefore, we propose a novel strategy using telemonitoring guidance based on objective training data acquired during exercise at home. In this way, we aim to improve self-management skills like self-efficacy and action planning for independent exercise and, consequently, improve long-term effectiveness with respect to physical fitness and physical activity. In addition, we aim to compare costs of this strategy with centre-based cardiac rehabilitation. This randomized controlled trial compares a 12 -week telemonitoring guided home-based training program with a regular, 12 -week centre-based training program of equal duration and training intensity in low to moderate risk patients entering cardiac rehabilitation after an acute coronary syndrome or cardiac intervention. The home-based group receives three supervised training sessions before they commence training with a heart rate monitor in their home environment. Participants are instructed to train at 70 - 85 % of their maximal heart rate for 45 - 60 minutes, twice a week. Patients receive individual coaching by telephone once a week, based on measured heart rate data that are shared through the <b>internet.</b> Primary <b>endpoints</b> are physical fitness and physical activity, assessed at baseline, after 12 weeks and after one year. Physical fitness is expressed as peak oxygen uptake, assessed by symptom limited exercise testing with gas exchange analysis; physical activity is expressed as physical activity energy expenditure, assessed by tri-axial accelerometry and heart rate measurements. Secondary endpoints are training adherence, quality of life, patient satisfaction and cost-effectiveness. This study will increase insight in long-term effectiveness and costs of home-based cardiac rehabilitation with telemonitoring guidance. This strategy is in line with the trend to shift non-complex healthcare services towards patients' home environments. Dutch Trial Register: NTR 3780. Clinicaltrials. gov register: NCT 0173241...|$|R
40|$|Realizing new {{services}} on the Internet ultimately requires edge-based solutions for both deployability and scalability. I propose to design, implement, and evaluate {{a series of}} three edge-based algorithms and protocols for efficient inference and control of the <b>Internet</b> from its <b>endpoints.</b> The proposed solutions together form a new foundation for quality-of-service communication via a scalable edge-based architecture where the novel functionality is added strictly at either edge routers or end hosts. In particular, this thesis proposes techniques for multi-class service inference, active probing for available bandwidth, and end-point-based protection against Denial of Service (DoS) attacks. The proposed multi-class service inference techniques reveal the sophisticated multi-class network components such as service disciplines and rate limiters using solely pas-sive packet monitoring at the network edges. These inferences significantly enhance the network monitoring and service validation capabilities and provide vital information for making efficient use of resources. The proposed active probing scheme infers and utilizes only the available network bandwidth and aims to realize a low-priority service from the network endpoints, a functionality that would otherwise require a multi-priority or separate network. Finally, the end-point-based protection against DoS research aims to detect the main fragile points of TCP {{from the perspective of a}} DoS attacker. This would not just help to significantly improve the robustness of TCP in presence of DoS attacks but would indicate that the protection mechanisms against DoS should be implemented not only in the network core as conventionally done but also at the network edge. ...|$|R
40|$|The phrase 'Internet of Things' {{refers to}} the {{pervasive}} instrumentation of physical objects with sensors and actuators, and the connection of those sensors and actuators to the Internet. These sensors and actuators are generally based on similar hardware as, and have similar capabilities to, wireless sensor network nodes. However, they operate {{in a completely different}} network environment: wireless sensor network nodes all generally belong to a single entity, whereas <b>Internet</b> of Things <b>endpoints</b> can belong to different, even competing, ones. This difference has profound implications for the design of security mechanisms in these environments. Wireless sensor network security is generally focused on defence against attack by external parties. On the Internet of Things, such an insider/outsider distinction is impossible; every entity is both an endpoint for legitimate communications, and a possible source of attack. We argue that that under such conditions, the centralised models that underpin current networking standards and protocols for embedded systems are simply not appropriate, because they require such an insider/outsider distinction. This thesis serves as an exposition in the design of decentralised security mechanisms, applied both to applications, which must perform access control, and networks, which must guarantee communications security. It contains three main contributions. The first is a threat model for Internet of Things networks. The second is BottleCap, a capability-based access control module, and an exemplar of decentralised security architecture at the application layer. The third is StarfishNet, a network-layer protocol for Internet of Things wireless networks, and a similar exemplar of decentralised security architecture at the network layer. Both are evaluated with microbenchmarks on prototype implementations; StarfishNet's association protocol is additionally validated using formal verification in the protocol verification tool Tamarin. </p...|$|R
40|$|Realizing new {{services}} on the Internet ultimately requires edge-based solutions for both deployability and scalability. Each such solution has two fundamental aspects. The {{first is the}} ability to accurately infer critical network parameters and processes such as Quality of Service (QoS) mechanisms, end-to-end available bandwidth, or the existence of a Denial of Service (DoS) activity; and the second {{is the ability to}} effectively utilize this knowledge to build endpoint services. This thesis presents the design, implementation, and evaluation of a series of edge-based algorithms and protocols for efficient inference, control, and DOS resilience of the <b>Internet</b> from its <b>endpoints.</b> The proposed solutions together form a new foundation for a robust quality-of-service communication via a scalable edge-based architecture where the novel functionality is added strictly at either edge routers or end hosts. In particular, this thesis develops techniques for multi-class service inference, active probing for available bandwidth, and end-point-based protection against DoS attacks. The proposed multi-class service inference techniques reveal the sophisticated multi-class network components such as service disciplines and rate limiters using solely passive packet monitoring at the network edges. These inferences significantly enhance the network monitoring and service validation capabilities and provide vital information for making efficient use of resources. The proposed active probing scheme infers and utilizes only the available network bandwidth and aims to realize a low-priority service from the network endpoints, a functionality that would otherwise require a multi-priority or separate network. Finally, this thesis discovers and explores two deterrent vulnerabilities of the Transmission Control Protocol (TCP), the dominant transport protocol in today's Internet. The first is TCP's vulnerability to low-rate periodic attacks that can be as harmful as the high-rate ones, yet much harder to detect, due to their low-rate nature; the second is an extreme vulnerability of the class of receiver-driven TCP stacks to the misbehaviors launched at the receiving endpoints which may temper with the congestion control algorithm for their own benefit. The proposed end-point schemes significantly outperform the state-of-the-art core-based solutions and demonstrate that counter-DoS mechanisms should be implemented not only in the network core, as conventionally done, but also at the network edge. More importantly, the thesis demonstrates that protocol performance on one hand, and vulnerability to misbehaviors on the other, are quite often fundamentally coupled such that both cannot be maximized simultaneously...|$|R

