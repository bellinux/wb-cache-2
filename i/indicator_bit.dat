5|25|Public
50|$|Presence of User Data Header is {{indicated}} by the TP-UDHI (Transfer Layer Protocol User Data Header <b>Indicator)</b> <b>bit</b> - 6th bit of the first octet of the GSM 03.40 or 3GPP 23.040 message.|$|E
50|$|In {{protected}} mode, {{the segment}} selector {{can be broken}} down into three parts: a 13-bit index, a Table <b>Indicator</b> <b>bit</b> that determines whether the entry is in the GDT or LDT and a 2-bit Requested Privilege Level; see x86 memory segmentation.|$|E
5000|$|Since most {{instructions}} were 16 bits long, {{there was no}} room in an instruction for both a full 15-bit memory address and a meaningful instruction code. Memory was therefore addressed in terms of [...] "pages" [...] of 1,024 words each. Instructions that reference memory had 10 bits for a page offset (supporting values from 0 through 1023 decimal) and a single bit for a [...] "zero/current" [...] page indicator. If the page <b>indicator</b> <b>bit</b> was set the 10 bits were interpreted as an offset within the page that contained the instruction being executed; in other words, the high five bits of the operand address were taken from the P-register, the program counter. If the page <b>indicator</b> <b>bit</b> was clear, the offset represented an address within page zero. Thus 2,048 words could be addressed at once: 1,024 of them within page zero and another 1,024 within the same page as the instruction performing the reference. If necessary to access other memory locations the instruction could have its high bit set, denoting indirect addressing as described previously; the location addressed by the instruction would then contain the full 15-bit operand address (unless it too had its indirect bit set, etc.).|$|E
50|$|The DUT1 {{information}} (+0.4s) and {{leap year}} <b>indicator</b> <b>bits</b> (2012 is a leap year) in the amplitude modulated code {{are not included}} in the phase modulated code; the use of DUT1 for celestial navigation has been obsoleted by satellite navigation.|$|R
30|$|The relay {{selection}} based approach {{needs to}} feed back the selection <b>indicator</b> <b>bits</b> {{as well as}} the power gain values of the selected relays. As for the selection <b>indicator</b> <b>bits,</b> one bit (0 or 1) for each relay can be used to indicate whether a given relay is selected or not. Note that the feedback overhead of the proposed method will be significantly less than that of the optimal exhaustive search. When uniform gain allocation is used with the relay selection, only a single value (the common power gain) can be broadcasted by the destination. If conventional power allocation is used with the relay selection, the number of selected relays need to be broadcasted by the destination. As mentioned before, we employ uniform gain allocation in this article because it has slightly better performance than the conventional power allocation when no relay selection is used, which will be shown in the simulation results.|$|R
50|$|Two flags warn {{of changes}} to {{occur at the}} end of the current hour: a change of time zones, and a leap second insertion. These flags are set during the hour up to the event. This {{includes}} the last minute before the event, during which the other time code bits (including the time zone <b>indicator</b> <b>bits)</b> encode the time of the first minute after the event.|$|R
40|$|Abstract—Reminiscent of the parity {{function}} in network coding for the butterfly network, it is shown that forwarding an even/odd <b>indicator</b> <b>bit</b> for a scalar quantization of a relay observation recovers 1 {{bit of information}} at the two destinations in a noiseless interference channel where interference is treated as noise. Based on this observation, a coding strategy is proposed to improve the rate of both users {{at the same time}} using a relay node in a noisy interference channel. In this strategy, the relay observes a linear combination of signals sent by the two sources, and broadcasts a common message to the two destinations over a shared out-of-band link of constant rate R 0 bits per channel use. The relay message consists of the bin index of a structured binning scheme obtained from a 2 R 0 -way partition of the squared lattice in the complex plane. We show that such scalar quantization-binning relay strategy asymptotically achieves the cut-set bound in an interference channel with a common out-of-band relay link of limited rate, improving the sum rate by two bits for every bit relayed, asymptotically at high signal to noise ratios (SNR) and when interference is treated as noise. We then use low-density parity-check (LDPC) codes along with bit-interleaved coded-modulation (BICM) as a practical coding scheme for the proposed strategy. We consider matched and mismatched scenarios, depending on whether the input alphabet of the interference signal is known or unknown to the decoder, respectively. For the matched scenario, we show the proposed strategy results in significant gains in SNR. For the mismatched scenario, we show that the proposed strategy results in rate improvements that, without the relay, cannot be achieved by merely increasing transmit powers. Finally, we use generalized mutual information analysis to characterize the theoretical performance of the mismatched scenario and validate our simulation results. I...|$|E
40|$|Generally, image {{compression}} using Block Truncation Coding (BTC) cant provide high compression ratio and visual quality. A new adaptive BTC scheme is proposed by combining visual perception of original images and data hiding technique. The texture sensitivity is exploited to classify {{the types of}} image sub-block and reduce the bit rate while remaining good quality of reconstructed images. Moreover, the <b>indicator</b> <b>bits</b> of image sub-blocks are hidden into the quantizing levels of those blocks for decoding purpose. The simulation {{results show that the}} proposed BTC algorithm can achieve good balance between bit-rate and PSNR values. Especially, it obtained about 4. 0 dB higher PSNR at approximate bit-rate...|$|R
5000|$|The IBM Stretch, {{designed}} in the late 1950s, pre-executes all unconditional branches and any conditional branches that depended on the index registers. For other conditional branches, the first two production models implemented predict untaken; subsequent models were changed to implement predictions based on the current values of the <b>indicator</b> <b>bits</b> (corresponding to today's condition codes). [...] The Stretch designers had considered static hint bits in the branch instructions early in the project but decided against them. Misprediction recovery {{was provided by the}} lookahead unit on Stretch, and part of Stretch's reputation for less-than-stellar performance was blamed on the time required for misprediction recovery. Subsequent IBM large computer designs did not use branch prediction with speculative execution until the IBM 3090 in 1985.|$|R
40|$|ABSTRACT- A novel joint data-hiding and {{compression}} {{scheme for}} digital images using side match vector quantization (SMVQ) and image in painting. The two functions of data hiding and image compression {{can be integrated}} into on single module seamlessly. On the sender side, except for the blocks in the leftmost and topmost of the image, {{each of the other}} residual blocks in raster-scanning order can be embedded with secret data and compressed simultaneously by SMVQ or image in painting adaptively according to the current embedding bit. Vector quantization is also utilized for some complex blocks to control the visual distortion and error diffusion caused by the progressive compression. After segmenting the image compressed codes into a series of sections by the <b>indicator</b> <b>bits,</b> the receiver can achieve the extraction of secret bits and image decompression successfully according to the index values in the segmented sections. Experimental results demonstrate the effectiveness of the proposed scheme...|$|R
40|$|AbstractData Hiding and Compression are {{equivalently}} significant {{terms in}} the field of communication and its study is inevitable. In this paper, a novel joint data hiding and compression system is ventured based on VQ, SMVQ andimage inpainting. Data hiding and compression scheme are melded into a single unit which will increase the efficiency of communication. As a pre-processing step, the image is divided into non overlapping blocks. The topmost and leftmost blocks are compressed by employing VQ and the residual blocks are embedded with secret data and compressed simultaneously by SMVQ or image inpainting adaptively according to the secret bit to be hidden. VQ is also employed on a threshold basis for some blocks to control the distortion. The concatenated codes received are segmented into indices and secret bits according to the <b>indicator</b> <b>bits.</b> On the receiver side, FoE based inpainting was used for reconstructing lost parts of image. Experimental results validates satisfactory performance in terms of compression ratio and image quality...|$|R
50|$|The general {{structure}} of a QR encoding is as a sequence of 4 <b>bit</b> <b>indicators</b> with payload length dependent on the indicator mode (e.g. byte encoding payload length {{is dependent on the}} first byte).|$|R
30|$|In this paper, {{we study}} the {{statistics}} of dynamic interference in large-scale networks exploiting SCMA. Unlike existing work on SCMA, {{we consider the}} presence of dynamic interference. Accounting {{for the impact of}} dynamic interference is critical as the resulting high amplitude interference is known to have an important impact on key network performance <b>indicators</b> (e.g., <b>bit</b> error rate and capacity [23]). As Gaussian interference models underestimate the probability of such high amplitude interference, the resulting design can be highly suboptimal.|$|R
50|$|AAL Type 5 {{is similar}} to AAL 3/4 with a {{simplified}} information header scheme. This AAL assumes that the data is sequential from the end user and uses the Payload Type <b>Indicator</b> (PTI) <b>bit</b> to indicate the last cell in a transmission. Examples of services that use AAL 5 are classic IP over ATM, Ethernet Over ATM, SMDS, and LAN Emulation (LANE). AAL 5 is a widely used ATM adaptation layer protocol. This protocol was intended to provide a streamlined transport facility for higher-layer protocols that are connection oriented.|$|R
40|$|Image {{authentication}} {{methods have}} recently gained great consideration {{due to their}} importance for {{a huge number of}} multimedia applications. Digital images are increasingly conveyed over vulnerable channels such as the Internet. Protecting digital product is going to become important issue to ensure the secure transmission of the digital items. The existing algorithms cannot guarantee the whole security of the contents or ownership verification. The embedded watermark or data hiding into image can be used to identify the owner of the image. Also, The Block Truncation Coding (BTC) is one of the effective and real time application for data hiding. Most present BTC based watermarking methods cannot completely exploit visual perception of the cover images and do not obtain high data embedding rate. For more exploiting visual perception and high data embedding, an enhanced data hiding scheme based on BTC is proposed. In proposed method, considering the texture sub blocks and Least Significant Bits (LSBs of higher mean value and lower mean value) substitution combine together for designing improved the BTC watermarking scheme. It can obtain good balance between high embedding rate (capacity) and high quality. So, the texture sensitivity is exploited to recognize whether the image blocks or are smooth or complex. On the other hand, the LSB substitution method is employed to hide the <b>indicator</b> <b>bits</b> of each image block or sub block. The experimental results show that the proposed method increases capacity of data hiding compare to existing BTC watermarking with the same or higher quality...|$|R
30|$|IEEE 802.15. 4, {{commonly}} known as ZigBee, is a Media Access Control (MAC) and physical layer standard specifically designed for short range wireless communication where low rate, low power, and low bandwidth are required. This makes ZigBee an ideal choice {{when it comes to}} sensor networks for monitoring data collection and/or triggering process responses. However, these very characteristics bring into question ZigBee's ability to perform reliably in harsh environments. This paper thoroughly explains the experimental testbed setup and execution to demonstrate ZigBee's performance in several practical applications. This testbed is capable of measuring the minimum, maximum, and average received signal strength <b>indicator</b> (RSSI), <b>bit</b> error rate (BER), packet error rate (PER), packet loss rate (PLR), and the bit error locations. Results show that ZigBee has the potential capabilities to be used in all four tested environments.|$|R
40|$|IEEE 802. 15. 4, {{commonly}} known as ZigBee, is a Media Access Control (MAC) and physical layer standard specifically designed for short range wireless communication where low rate, low power, and low bandwidth are required. This makes ZigBee an ideal choice {{when it comes to}} sensor networks for monitoring data collection and/or triggering process responses. However, these very characteristics bring into question ZigBee 2 ̆ 7 s ability to perform reliably in harsh environments. This paper thoroughly explains the experimental testbed setup and execution to demonstrate ZigBee 2 ̆ 7 s performance in several practical applications. This testbed is capable of measuring the minimum, maximum, and average received signal strength <b>indicator</b> (RSSI), <b>bit</b> error rate (BER), packet error rate (PER), packet loss rate (PLR), and the bit error locations. Results show that ZigBee has the potential capabilities to be used in all four tested environments...|$|R
40|$|License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. IEEE 802. 15. 4, {{commonly known as}} ZigBee, is a Media Access Control (MAC) and physical layer standard specifically designed for short range wireless communication where low rate, low power, and low bandwidth are required. This makes ZigBee an ideal choice {{when it comes to}} sensor networks for monitoring data collection and/or triggering process responses. However, these very characteristics bring into question ZigBee’s ability to perform reliably in harsh environments. This paper thoroughly explains the experimental testbed setup and execution to demonstrate ZigBee’s performance in several practical applications. This testbed is capable of measuring the minimum, maximum, and average received signal strength <b>indicator</b> (RSSI), <b>bit</b> error rate (BER), packet error rate (PER), packet loss rate (PLR), and the bit error locations. Results show that ZigBee has the potential capabilities to be used in all four tested environments. 1...|$|R
40|$|In this work, we {{investigate}} the communication reliability for diffusion-based molecular communication, using the <b>indicator</b> of <b>bit</b> error rate (BER). A molecular classified model is established to divide molecules into three parts, {{which are the}} signal, inter-symbol interference (ISI) and noise. We expand each part separately using molecular absorbing probability, and connect them by a traditional-like formula. Based on the classified model, we do a theoretical analysis to prove the feasibility of improving the BER performance. Accordingly, an adaptive threshold variation (ATV) algorithm is designed in demodulation to implement the goal, which makes the receiver adapt the channel condition properly through learning process. Moreover, the complexity of ATV is calculated and its performance in various noisy channel is discussed. An expression of Signal to Interference plus Noise Ratio (SINR) is defined to verify the system performance. We test some important parameters of the channel model, {{as well as the}} ATV algorithm in the simulation section. The results have shown the performance gain of the proposal...|$|R
50|$|The {{programmed}} operator facility {{allows the}} instruction code field {{to indicate a}} call to a vector of subroutine addresses. The six bit instruction code allows up to 64 programmed operators (octal 00 through 77). If the P bit is set, an instruction code of xx is treated as a call to location 1xx (octal). The location of the POP instruction is saved in location zero. Bit zero of location zero is set to the current value of the overflow indicator and the <b>indicator</b> is reset. <b>Bit</b> 9 of location zero is set to '1'b to indicate an indirect address, allowing the programmed operator routine to indirectly access the data specified in {{the address of the}} POP instruction.|$|R
40|$|Abstract—Node(s) /link(s) of {{a network}} are {{subjected}} to overloading; network performance deteriorates substantially due to network congestion. Network congestion can be mitigated {{with the help of}} Explicit Congestion notification (ECN) technique. ECN notification is carried out by setting ECN bit in the TCP header. This allows for end-to-end notification of network congestion without dropping packets. ECN bit notifies TCP sources of incipient congestion before losses occur. ECN is a binary <b>indicator</b> (1 <b>bit)</b> which does not reflect the congestion level completely and so its convergence speed is relatively low. In our work, we have used an extra ECN bit (2 bit ECN). The extra bit allows for passing of additional congestion feedback to the source node. This enables the source node to determine the level of congestion based on which steps can be taken to ensure faster convergence. In comparison to single bit ECN, the additional information afforded by double bit ECN allows for more flexibility to adjust window size, to handle congestion. Simulation results have shown that the proposed method improves overall performance of the network by over 12 %. Keywords—Explicit Congestion Notification (ECN); Mobile ad hoc Networks (MANET); Congestion control; Congestion windo...|$|R
40|$|Approved {{for public}} release, {{distribution}} is unlimitedInteroperability of commercial Land Mobile Radios (LMR) and the military's tactical LMR is highly desirable if the U. S. {{government is to}} respond effectively in a national emergency or in a joint military operation. This ability to talk securely and immediately across agency and military service boundaries is often overlooked. One way to ensure interoperability is to develop and promote federal communication standards (FS). This thesis surveys one ares of the proposed FS 1024 for LMRs; namely, the error detection and correction (EDAC) of the message <b>indicator</b> (MI) <b>bits</b> used for cryptographic synchronization. Several EDAC codes are examined (Hamming, Quadratic Residue, hard decision Golay and soft decision Golay), tested on three Fortran programmed channel simulations (INMARSAT, Gaussian and constant burst width), compared and analyzed (based on bit error rates and percent of error-free super-frame runs) so that a best code can be recommended. Out of the four codes under study, the soft decision Golay code (24, 12) is evaluated to be the best. This finding {{is based on the}} code's ability to detect and correct errors as well as the relative ease of implementation of the algorithm. Civilian, U. S. Department of Defens...|$|R
40|$|To make {{wireless}} sensor networks more robust, {{an amendment}} {{was added to the}} IEEE 802. 15. 4 standard: IEEE 802. 15. 4 e. This work studies one of the operational modes described in this amendment: Time-Slotted Channel Hopping (TSCH). This protocol is more robust due to the use of channel hopping. When channel hopping is used, every time communication fails, the nodes switch to another channel for retransmission. This way the resilience to interference increases. To be able to analyze this protocol, some environments are characterized. These serve the purpose of evaluating the operation of TSCH in real circumstances. To characterize these environments the signal strength (RSSI), 802. 15. 4 link quality <b>indicator</b> (LQI), <b>bit</b> error rate (BER) and packet loss (PL) are measured. A first conclusion derived from the results is the asymmetry in interference between nodes. The nodes do not see an equal amount of interference on the same channel. Secondly the characteristics of the channels vary during the day. Therefore, a communication schedule that takes these spatial and temporal variations into account is very important to optimize TSCH performance. status: publishe...|$|R
40|$|Master's thesis in Petroleum engineeringBy using {{real-time}} data from INTEQ`s CoPilot Real-Time Drilling Optimalization {{a search for}} dependable indications {{of the degree of}} the bit wear was done. This would improve decision making procedures for when to pull the bit when experiencing a poor penetrationrate in soft formations or problems getting through harder formations. Using several recorded runs, factors that might be good indicators of the drill bit state of wear was investigated by comparing several bit runs that were using a PDC bit with an Auto Trak X-Treme motor and a CoPilot sub assembly. Some of the possible suggestions did not seem viable to determine the wear of the bit. Some looked viable in some cases, but then again had exceptions in other runs under other conditions. At the end only two of the indications seemed usable to determine the wear of the bit. ROP compared to WOB was in almost every run a good indicator. But the most reliable <b>indicator</b> of <b>bit</b> wear in the runs investigated, was the degree of reduction of torque relative to the applied WOB. When recording these parameters with a new bit in early sections, using this as a basis for comparison with later measurements, it was possible to see if the torque generated had declined once a similar formation appeared again. A third possibility that was not fully investigated was recording increase in mud pressure due to blocked nozzles. This theory was not easy to investigate since there were no available raw data, and the resolution in graphs was too low for the accuracy required...|$|R
40|$|As {{of spring}} 2014, the {{economic}} landscape in New Mexico was mixed though generally positive. State revenues were finally reaching pre-recession levels. The recession of 2008 {{was slow to}} hit New Mexico and slow to leave. Revenues declined significantly starting in February 2009 with oil dropping to $ 39. 00 a barrel that month oil and gas income is a significant contributor to the state coffers). New Mexico {{was one of only}} six states to have fewer jobs in February 2011 than in 2010. Budget revenues declined steeply through 2008, 2009 and 2010. During the course of the recession, general fund revenues dropped 20 % percent. Economic growth was not in positive territory until the spring of 2013. Since that time general fund revenues have climbed steadily. For Fiscal Year 2015, revenues are forecast at nearly $ 6. 2 billion, a level not seen since 2008 [...] While economic forecasts are positive and the financial trajectory appears upward, underlying economic <b>indicators</b> provide a <b>bit</b> of uncertainly. Job growth is slow; government jobs are flat and private sector job growth is only about 1. 4 %. New Mexico is not projected to regain the previous peak number of payroll jobs until 2016, eight years after that level was first achieved...|$|R
40|$|Hospitals play a {{critical}} role in the health promotion of the society. This study aimed to determine the impact of establishing standards of health promoting hospitals on hospital indicators in Shahroud. This applied study was a quasi-experimental one which was conducted in 2013. Standards of health promoting hospitals were established as an intervention procedure in the Fatemiyeh hospital. Parameters of health promoting hospitals were compared in intervention and control hospitals before and after of intervention (6 months). The data were analyzed using chi-square and t-test. With the establishment of standards for health promotion hospitals, standard scores in intervention and control hospitals were found to be 72. 26 ± 4. 1 and 16. 26 ± 7. 5, respectively. T-test showed a significant difference between the mean scores of the hospitals under study (P = 0. 001). The chi-square test also showed a significant relationship between patient satisfaction before and after the intervention so that patients' satisfaction was higher after the intervention (P = 0. 001). Commenting on the short-term or long-term positive impacts of establishing standards of health promoting hospitals on all hospital <b>indicators</b> is a <b>bit</b> difficult but preliminary results show the positive impact of the implementation of standards in case hospitals which has led to the improvement of many indicators in the hospital...|$|R
40|$|Steganography is {{the field}} of science {{concerned}} with hiding secret data inside other innocent-looking data, called the container, carrier or cover, {{in a way that}} no one apart from the meant parties can suspect the existence of the secret data. There are many algorithms and techniques of concealing data. Each of which has its own way of hiding and its own advantages and limitations. In our research we introduce a new algorithm of hiding data. The algorithm uses the same technique used by the Least Significant Bit (LSB) algorithm which is embedding secret data in the least significant bit(s) of the bytes of the carrier. It differs from the LSB algorithm in that it does not embed the bytes of the cover data sequentially but it embeds into one bit or two bits at once. Actually it depends on indicators to determine where and how many bits to embed at a time. These <b>indicators</b> are two <b>bits</b> of each cover byte after the least two significant bits. The advantage of this algorithm over the LSB algorithm is the randomness used to confuse intruders as it does not use fixed sequential bytes and it does not always embed one bit at a time. This aims to increase the security of the technique. Also, the amount of cover data consumed is less because it sometimes embeds two bits at once...|$|R
40|$|University of Minnesota Ph. D. dissertation. May 2015. Major: Electrical Engineering. Advisor: Nicholaos Sidiropoulos. 1 {{computer}} file (PDF); x, 87 pages. Transmit beamforming is a characteristic {{feature of the}} modern wireless communication standards like 4 G-LTE and 802. 11 ac because of the increasing demand for higher data rates and better Quality of Service at the user-end. Transmit beamforming uses multiple transmit antennas and channel state information (CSI) at the transmitter (Tx) to steer the radiated power towards the intended receiver (Rx) while limiting the leakage caused in other directions. In the absence of channel reciprocity, this channel information is acquired at the transmitter by channel estimation at the intended Rx and subsequent feedback of the quantized channel information back to the Tx. This conventional training method requires a complex Rx design and high communication overhead, which could be a burden when the receivers operate on battery power and have limited computational resources and restricted communication capabilities. Obtaining CSI for limiting interference caused due to leakage, can be much more challenging especially when the Rx affected by the spatial leakage interference (side lobes) is not cooperating with the Tx (as in secondary transmit beamforming in underlay cognitive radio networks, for achieving a high Quality of Service at the secondary Rx while limiting the interference to the primary Rx). This thesis proposes various algorithms that enable the Tx, which has no initial CSI, learn to beamform on-the-fly and asymptotically attain the performance achievable using perfect CSI at the Tx, using 1 -bit direct or implicit periodic feedbacks from the receivers of interest. The receivers are assumed to have limited computational capability. This thesis starts by considering long-term transmit beamforming for point-to-point Multiple-Input Single-Output (MISO) links and proposes an online beamforming and learning algorithm using the analytic center cutting plane method which is shown to asymptotically attain optimal performance. A robust maximum-likelihood formulation is next developed to combat feedback errors and correlation drift. The setup is then extended to an underlay cognitive radio network for designing secondary transmit beamforming vectors that maximize the average Signal-to-Noise Ratio (SNR) at the secondary Rx while limiting the interference to the primary Rx, using direct binary channel quality <b>indicator</b> feedback <b>bits</b> from the secondary Rx and indirect ACK-NACK feedback from the primary Rx. When the primary interference threshold is known at the secondary Tx, it is analytically shown that the proposed algorithm converges to maximum average SNR at the secondary Rx achieved using perfect CSI at the Tx. Subsequently, the thesis considers max-min fair transmit beamforming for single group multicast networks (which is NP-hard in general) and introduces {{a new class of}} adaptive beamforming algorithms that features guaranteed convergence and state-of-the-art performance at low complexity, when perfect CSI is available at the Tx. Convergence to a Karush-Kuhn-Tucker (KKT) point of a related proportionally fair beamforming is established. Simulations show that the proposed approach outperforms the prior state-of-art in terms of multicast rate, at considerably lower complexity. When there is no initial CSIT, an extension of the online algorithm developed for point to point MISO links is proposed for designing the beamforming vector to maximize the minimum SNR among the users, using only periodic binary SNR feedback from each Rx. The design methodology for the multicast beamforming problem is finally extended in a novel fashion to obtain feasible solutions for non-convex Quadratically Constrained Quadratic Programs (QCQP) with two-sided constraints when the associated matrices are positive semi-definite. In this context, the proposed algorithm starts with a infeasible solution which is iteratively updated using a gradient of the log-barrier function of the non-convex constraints followed by projection onto the intersection of the set of convex constraints and a refining step using successive linear approximation. Convergence of the algorithm is established using the Descent lemma and simulations show that the algorithm obtains feasible solutions with a high probability at a much lower complexity compared to the state-of-the-art...|$|R

