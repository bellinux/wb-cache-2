135|247|Public
25|$|As of 1995, all <b>fractal</b> <b>compression</b> {{software}} {{is based on}} Jacquin's approach.|$|E
50|$|Michael Barnsley led {{development}} of <b>fractal</b> <b>compression</b> in 1987, and was granted several patents on the technology. The most widely known practical <b>fractal</b> <b>compression</b> algorithm {{was invented by}} Barnsley and Alan Sloan. Barnsley's graduate student Arnaud Jacquin implemented the first automatic algorithm in software in 1992. All methods {{are based on the}} fractal transform using iterated function systems. Michael Barnsley and Alan Sloan formed Iterated Systems Inc. in 1987 which was granted over 20 additional patents related to <b>fractal</b> <b>compression.</b>|$|E
50|$|There is a {{video library}} for <b>fractal</b> <b>compression.</b>|$|E
40|$|Now a days {{most of the}} {{researchers}} are doing lots {{of work in the}} area of image <b>compression.</b> <b>Fractal</b> image <b>compression</b> requires lots of mathematical computation to compress an image. <b>Fractal</b> image <b>compression</b> is a recent technique based on the representation of an image by a contractive transform, on the space of images, for which the fixed point is close approximation to the original image. Main aim of <b>fractal</b> image <b>compression</b> algorithm is to reduce computation time required to compress image data. <b>Fractal</b> image <b>compression</b> is a lossy compression method for digital images, based on fractals. It is based on affine contractive transforms and utilizes the existence of self-symmetry in the image. This paper presents method for generating fractal images using iterated function system, method to partition image for compressing image using <b>fractal</b> image <b>compression</b> technique and various quality measures in <b>fractal</b> image <b>compression...</b>|$|R
40|$|This paper {{presents}} {{a survey of}} the <b>Fractal</b> image <b>compression.</b> <b>Fractal</b> encoding is a mathematical process used to encode bitmaps containing a real-world image as a set of mathematical data that describes the fractal properties of the image. A fractal is a structure that is made up of similar forms and patterns that occur in many different sizes. The term fractal was first used by Benoit Mandelbrot to describe repeating patterns that he observed occurring in many different structures. In this context, the survey summarizes the major <b>fractal</b> image <b>compression</b> methods spanning across different <b>fractal</b> image <b>compression</b> techniques and compare different <b>fractal</b> image <b>compression</b> techniques are distinct from each other. Further, the paper review that still research possibilities exist in this field to explore efficient <b>fractal</b> image <b>compression...</b>|$|R
40|$|In {{this paper}} an Adaptive <b>Fractal</b> Image <b>Compression</b> (AFIC) {{algorithm}} is proposed to reduce the long time of the <b>Fractal</b> Image <b>Compression</b> (FIC). AFIC worked on; minimizing the complexity {{and the number of}} matching operations by reducing both of the range and domain blocks needed in the matching process, for this purpose Zero Mean Intensity Level <b>Fractal</b> Image <b>Compression</b> based on Quadtree partitioning, Varianc...|$|R
50|$|With <b>fractal</b> <b>compression,</b> {{encoding}} {{is extremely}} computationally expensive {{because of the}} search used to find the self-similarities. Decoding, however, is quite fast. While this asymmetry has so far made it impractical for real time applications, when video is archived for distribution from disk storage or file downloads <b>fractal</b> <b>compression</b> becomes more competitive.|$|E
50|$|As of 1995, all <b>fractal</b> <b>compression</b> {{software}} {{is based on}} Jacquin's approach.|$|E
50|$|At common {{compression}} ratios, up {{to about}} 50:1, <b>Fractal</b> <b>compression</b> provides similar results to DCT-based algorithms such as JPEG. At high compression ratios <b>fractal</b> <b>compression</b> may offer superior quality. For satellite imagery, ratios of over 170:1 have been achieved with acceptable results. Fractal video compression ratios of 25:1-244:1 have been achieved in reasonable compression times (2.4 to 66 sec/frame).|$|E
40|$|In {{this work}} we discuss a {{technique}} denoted localized domain-pools {{in the context}} of parallelization of the encoding phase of <b>fractal</b> image <b>compression.</b> Performance problems occurring on distributed memory MIMD architectures may be resolved using this technique. Keywords: <b>Fractal</b> Image <b>Compression,</b> Parallel Algorithms, MIMD Architectures 1 INTRODUCTION <b>Fractal</b> image <b>compression</b> 3, 6, 21 has generated much interest in the image compression community as competitor 7 with well established compression techniques (e. g. DCT-JPEG 28) and new emerging technologies (e. g. wavelets 2, 1). One of the main drawbacks of conventional <b>fractal</b> image <b>compression</b> is the high encoding complexity (whereas decoding complexity is much lower) compared to e. g. transform coding. On the other hand <b>fractal</b> image <b>compression</b> offers interesting features like resolution-independent and fast decoding, and good image quality at low bit-rates. A lot of sequential speedup techniques have been proposed for the [...] ...|$|R
40|$|In <b>fractal</b> image <b>compression</b> the {{encoding}} step is computationally expensive. We {{present a}} new technique for reducing the computational complexity. It is lossless, i. e., it does not sacrifice any image quality {{for the sake of}} the speedup. It is based on a codebook coherence characteristic to <b>fractal</b> image <b>compression</b> and leads to a novel application of the fast Fourier transformbased convolution. The method provides a new conceptual view of <b>fractal</b> image <b>compression.</b> This paper focuses on the implementation issues and presents the first empirical experiments analyzing the performance benefits of the convolution approach to <b>fractal</b> image <b>compression</b> depending on image size, range size, and codebook size. The results show acceleration factors for large ranges up to 23 (larger factors possible), outperforming all other currently known lossless acceleration methods for such range sizes. 1. INTRODUCTION In <b>fractal</b> image <b>compression</b> [1, 2] image blocks (ranges) have to be compared against a [...] ...|$|R
40|$|<b>Fractal</b> Video <b>Compression</b> (FVC) is of {{extensive}} interest for over 20 years. Instead of being implemented on square image structure, Spiral Architecture (SA) based <b>fractal</b> image <b>compression</b> is proposed {{in this paper}} to illustrate the great potential of FVC on SA. Conceptually, a new definition of range block and domain block is presented on this enhanced image structure. Compared with the conventional square image architecture, spiral architecture provides higher fidelity to <b>fractal</b> image <b>compression,</b> which is demonstrated by the experimental results. 1...|$|R
50|$|The collage theorem in <b>fractal</b> <b>compression</b> proves that, {{for many}} images, {{there exists a}} {{relatively}} small description of a function that, when iteratively applied to any starting image, rapidly converges on the desired image.|$|E
50|$|The fractal {{transform}} is {{a technique}} invented by Michael Barnsley et al. to perform lossy image compression.This first practical <b>fractal</b> <b>compression</b> system for digital images resembles a vector quantization system using the image itself as the codebook.|$|E
50|$|Today, {{nearly all}} {{commonly}} used video compression methods (e.g., those in standards {{approved by the}} ITU-T or ISO) apply a discrete cosine transform (DCT) for spatial redundancy reduction. The DCT that is widely used in this regard was introduced by N. Ahmed, T. Natarajan and K. R. Rao in 1974. Other methods, such as <b>fractal</b> <b>compression,</b> matching pursuit {{and the use of}} a discrete wavelet transform (DWT) {{have been the subject of}} some research, but are typically not used in practical products (except for the use of wavelet coding as still-image coders without motion compensation). Interest in <b>fractal</b> <b>compression</b> seems to be waning, due to recent theoretical analysis showing a comparative lack of effectiveness of such methods.|$|E
40|$|<b>Fractal</b> Image <b>Compression</b> is a {{well-known}} problem {{which is in the}} class of NP-Hard problems. Quantum Evolutionary Algorithm is a novel optimization algorithm which uses a probabilistic representation for solutions and is highly suitable for combinatorial problems like Knapsack problem. Genetic algorithms are widely used for <b>fractal</b> image <b>compression</b> problems, but QEA is not used for this kind of problems yet. This paper improves QEA whit change population size and used it in <b>fractal</b> image <b>compression.</b> Utilizing the self-similarity property of a natural image, the partitioned iterated function system (PIFS) will be found to encode an image through Quantum Evolutionary Algorithm (QEA) method Experimental results show that our method has a better performance than GA and conventional <b>fractal</b> image <b>compression</b> algorithms...|$|R
40|$|Since <b>fractal</b> image <b>compression</b> is {{computationally}} very expensive, speed-up {{techniques are}} required {{in addition to}} parallel processing in order to compress large images in reasonable time. In this paper we discuss parallel <b>fractal</b> image <b>compression</b> algorithms suited for MIMD architectures which employ block classification as speed-up method...|$|R
40|$|QUANTUM EVOLUTIONARY ALGORITHM (QEA) IS A NOVEL OPTIMIZATION ALGORITHM, PROPOSED FORCOMBINATORIAL PROBLEMS LIKE KNAPSACK AND TRAP PROBLEMS. WHILE <b>FRACTAL</b> IMAGE <b>COMPRESSION</b> IS INTHE CLASS OF NP-HARD PROBLEMS AND QEA IS HIGHLY SUITABLE FOR THE CLASS OF COMBINATORIALPROBLEMS, QEA IS NOT WIDELY USED IN <b>FRACTAL</b> IMAGE <b>COMPRESSION</b> YET. IN ORDER TO IMPROVE THEPERFORMANCE OF <b>FRACTAL</b> IMAGE <b>COMPRESSION</b> ALGORITHMS, THIS PAPER PROPOSES A DISTRIBUTED QEAWITH A NOVEL OPERATOR CALLED CYCLING QUANTUM EVOLUTIONARY ALGORITHM. IN STANDARD QEA THEDIVERSITY IN THE POPULATION DECREASES ACROSS THE GENERATIONS. DECREASING THE DIVERSITY OF THEPOPULATION DECREASES THE EXPLORATION PERFORMANCE OF THE ALGORITHM AND CAUSES THE ALGORITHMTRAPPING IN THE LOCAL OPTIMA. IN THE PROPOSED ALGORITHM, THERE ARE SOME SUBPOPULATIONS SEARCHINGTHE SEARCH SPACE. AFTER THE SUBPOPULATIONS ARE TRAPPED IN A LOCAL OPTIMUM, THE BEST OBSERVEDPOSSIBLE SOLUTIONS IN THE SUBPOPULATIONS ARE EXCHANGED IN A CYCLIC MANNER. THE PROPOSEDALGORITHM IS USED IN <b>FRACTAL</b> IMAGE <b>COMPRESSION</b> AND EXPERIMENTAL RESULTS ON SEVERAL IMAGES SHOWBETTER PERFORMANCE FOR THE PROPOSED ALGORITHM THAN GENETIC ALGORITHMS AND QEA. IN COMPARISONWITH CONVENTIONAL <b>FRACTAL</b> IMAGE <b>COMPRESSION,</b> THE PROPOSED ALGORITHM FINDS A SUITABLE SOLUTIONWITH MUCH LESS COMPUTATIONAL COMPLEXIT...|$|R
50|$|Kramer later {{obtained}} a night school degree in aerospace engineering, {{he worked on}} the MX missile guidance system for a contractor of the US Department of Defense and later in the computer industry on <b>fractal</b> <b>compression,</b> facial recognition systems, and advanced communications.|$|E
5000|$|An {{inherent}} {{feature of}} <b>fractal</b> <b>compression</b> is that images become resolution independent after being converted to fractal code. This {{is because the}} iterated function systems in the compressed file scale indefinitely. This indefinite scaling property of a fractal is known as [...] "fractal scaling".|$|E
50|$|In The Engines of Dawn {{teleportation}} {{works by}} {{a sort of}} portal that uses a technique called <b>Fractal</b> <b>Compression,</b> which unlinks molecular bonds, re-arranges them until they are satisfactorily close together, and transmits them through trans-space to another portal. The organism is rearranged to its previous size with a rush of euphoria.|$|E
40|$|Abstract. Compression and {{decompression}} {{tools of}} digital image {{has become a}} significant aspect in the storing and transferring of digital image. <b>Fractal</b> image <b>compression</b> technique is recently used to compress images. The main problem with <b>fractal</b> image <b>compression</b> is {{that it takes a}} lot of computational time for searching blocks (domain block and range block) and then compares these blocks. There are many optimization techniques which are used to improve efficiency of <b>fractal</b> image <b>compression.</b> Some of these are particle swarm optimization, ant colony optimization and biogeography based optimization. In this paper the technique of biogeography based optimization (BBO) is applied for <b>fractal</b> image <b>compression</b> (FIC). With the help of this evolutionary algorithm effort is made to reduce the search complexity of matching between range block and domain block. The main drawback of FIC is that it involves more computational time due to global search. In order to improve the computational time and also the satisfactory quality of the decoded image, BBO algorithm is proposed. Investigational outcome show that the BBO is a better method than the traditional comprehensive search method in terms of encoding time. Results are calculated from wavelet based <b>fractal</b> image <b>compression</b> than BBO is applied over it to decrease the encode time and get better visual quality of image. In this paper compression time (encoding time) of <b>fractal</b> image <b>compression</b> is reduced...|$|R
40|$|Abstract:Fractal Image Compression is a lossy {{compression}} technique {{that has been}} developed in the early 1990 s. <b>Fractal</b> image <b>compression</b> explores the self-similarity property of a natural image and utilizes the partitioned iterated function system (PIFS) to encode it. The <b>fractal</b> image <b>compression</b> problem had three major requirements: speeding up the compression algorithm, improving image quality and increasing compression ratio. So far, several methods have been proposed in order to speed-up <b>fractal</b> image <b>compression.</b> The time is essentially spent on the search of the similar domain block. This paper aims to present a method that uses Genetic algorithms to speed up computation time in <b>fractal</b> image <b>compression</b> with acceptable image quality and high compression rate. These improvements are obtained by encoding all regions in the image with different size blocks. Keywords:Fractal image compression; genetic algorithm. I...|$|R
40|$|<b>Compression</b> {{rates of}} <b>fractal</b> images are {{improved}} {{by applying the}} loss-less compression technique on the parameters of affine transformations of the fractal compressed image. By keeping PSNRs unchanged, proposed improved <b>fractal</b> image <b>compression</b> techniques give better compression rates. But, the compression time of proposed techniques are significantly increased than its counterparts. In order {{to solve the problem}} of long encoding time of <b>fractal</b> image <b>compression,</b> non-search <b>fractal</b> image <b>compression</b> coding is put forward. In this algorithm specific domain block is assigned as a matching block, so search is required and coding is accelerated. Besides, this algorithm adopts the method of range block adaptive decomposition and combination, and can solve problems like part of range blocks incapable of matching and low compression ratio of non-search method Experiments indicate that this algorithm is better than search <b>fractal</b> image <b>compression</b> algorithm and JPEG algorithm...|$|R
50|$|During the 1990s Iterated Systems Inc. and its {{partners}} expended considerable resources to bring <b>fractal</b> <b>compression</b> to video. While compression results were promising, computer hardware of that time lacked the processing power for fractal video compression to be practical beyond a few select usages. Up to 15 hours were required to compress a single minute of video.|$|E
50|$|In mathematics, the collage theorem characterises an {{iterated}} function system whose attractor is close, {{relative to}} the Hausdorff metric, to a given set. The IFS described is composed of contractions whose images, as a collage or union when mapping the given set, are arbitrarily close to the given set. It is typically used in <b>fractal</b> <b>compression.</b>|$|E
50|$|A major {{breakthrough}} for Iterated Systems Inc. was the automatic fractal transform process which eliminated {{the need for}} human intervention during compression {{as was the case}} in early experimentation with <b>fractal</b> <b>compression</b> technology. In 1992, Iterated Systems Inc. received a US$2.1 million government grant to develop a prototype digital image storage and decompression chip using fractal transform image compression technology.|$|E
40|$|<b>Fractal</b> image <b>compression</b> is {{promising}} both theoretically and practically. The encoding {{speed of the}} traditional full search method is a key factor rendering the <b>fractal</b> image <b>compression</b> unsuitable for real-time application. The primary objective {{of this paper is}} to investigate the comprehensive coverage of the principles and techniques of <b>fractal</b> image <b>compression,</b> and describes the implementation of a pre-processing strategy that can reduce the full searching domain blocks by training the Support Vector Machine which could recognized the self-similar pattern feature to enhance the domain block searching efficiency. In this paper, the novel image quality index (Structure Similarity, SSIM) and block property classifier based on SVM employed for the <b>fractal</b> image <b>compression</b> is investigated. Experimental results show that the scheme speeds up the encoder 15 times faster and the visual effect is better in comparison to the full search method. </span...|$|R
50|$|<b>Fractal</b> image <b>compression</b> {{has many}} {{similarities}} to vector quantization image compression.|$|R
40|$|The image {{partitioning}} {{scheme in}} <b>fractal</b> image <b>compression</b> {{is one of}} the important aspect for enhancement of performance. In this paper, an adaptive quardtree partitioning scheme is proposed where the entire image is sub-divided recursively into four sub-images. The partitioning points are selected adaptively in a image context-dependent way instead of middle points of the image sides as in quardtree partitioning scheme. Biased successive differences of sum of pixel values of rows of the image are calculated to divide the image row-wise into two sub-images. Then, each sub-image is farther divided column-wise into two parts using biased successive differences of sum of pixel values of columns of the subimage. Then, a <b>fractal</b> image <b>compression</b> technique is proposed based on the proposed partitioning scheme. The comparison of the compression ratio and PSNR are done between <b>fractal</b> image <b>compression</b> with quardtree and proposed adaptive quardtree partitioning schemes. The comparison of the compression time between the same is also done. The <b>fractal</b> image <b>compression</b> with proposed partitioning scheme offers better compression rates most of the times with comparatively improved PSNR. But, the compression time of the <b>fractal</b> image <b>compression</b> with proposed partitioning scheme is much more than its counterpart...|$|R
50|$|At {{the start}} of the first Gulf war, the company won a {{contract}} with the Ministry of Defence to put surveillance imagery onto Sony CRV discs that could be searched via a Unix database. Through the 90’s the Cambridge Multimedia Group was involved with migrating a number of Ministry of Defence projects to new digital video formats, including <b>Fractal</b> <b>compression</b> and MPEG 1.|$|E
5000|$|<b>Fractal</b> <b>{{compression}}</b> is a {{lossy compression}} method for digital images, based on fractals. The method is {{best suited for}} textures and natural images, relying {{on the fact that}} parts of an image often resemble other parts of the same image. Fractal algorithms convert these parts into mathematical data called [...] "fractal codes" [...] which are used to recreate the encoded image.|$|E
5000|$|The {{resolution}} {{independence of}} a fractal-encoded image {{can be used}} to increase the display resolution of an image. This process is also known as [...] "fractal interpolation". In fractal interpolation, an image is encoded into fractal codes via <b>fractal</b> <b>compression,</b> and subsequently decompressed at a higher resolution. The result is an up-sampled image in which iterated function systems have been used as the interpolant.Fractal interpolation maintains geometric detail very well compared to traditional interpolation methods like bilinear interpolation and bicubic interpolation. Since the interpolation cannot reverse Shannon entropy however, it ends up sharpening the image by adding random instead of meaningful detail. One cannot, for example, enlarge an image of a crowd where each person's face is one or two pixels and hope to identify them.|$|E
40|$|Since <b>fractal</b> image <b>compression</b> is {{computationally}} very expensive, speedup {{techniques are}} required {{in addition to}} parallel processing in order to compress large images in reasonable time. In this paper we introduce a new parallelization approach for <b>fractal</b> image <b>compression</b> algorithms which employ block classification as speedup method suited for multicomputers. 1 Introduction <b>Fractal</b> image <b>compression</b> [3, 12, 16] has generated much interest in the image compression community as possible competitor [4] to well established compression techniques (e. g. DCT-JPEG) and newer technologies (e. g. wavelets) and as extension [2, 20] to such methods. One of the main drawbacks of conventional fractal image coding is the high encoding complexity (whereas decoding complexity is much lower) as compared to e. g. transform coding. On the other hand <b>fractal</b> image <b>compression</b> offers interesting features like resolution-independent and fast decoding, and good image quality at low bit-rates which makes [...] ...|$|R
40|$|<b>Fractal</b> image <b>compression</b> {{has been}} {{interested}} due to highly possible compression ratio and selectable quality variation. However, one of disadvantages in <b>fractal</b> image <b>compression</b> {{is that it}} takes long time for encoding. So far, there are several methods proposed to get the high speed of encoding such as Fisher&# 039;s, Hurtgen&# 039;s and Saupe&# 039;s, etc. In this paper, implementation of <b>fractal</b> image <b>compression</b> using Fisher&# 039;s and Hurtgen&# 039;s methods on DSP TMS 320 C 5515 Stick kit is presented. Experimental {{results show that the}} Fisher&# 039;s method is faster than Hurtgen&# 039;s while the quality of decoded image (PSNR) is equivalently comparable in these methods...|$|R
40|$|<b>Fractal</b> image <b>compression</b> {{currently}} {{relies on}} the partitioning of an image into both coarse #domain" segments and #ne #range" segments, and for each range element, determines the domain element that best transforms into the range element. Under normal circumstances, this algorithm produces a structure equivalent to a recurrent iterated function system. This equivalence allows recent innovations to <b>fractal</b> image <b>compression</b> {{to be applied to}} the general inverse problem of recurrent iterated function systems. Additionally, the RIFS representation encodes bitmaps #bi-level images# better than current <b>fractal</b> image <b>compression</b> techniques. Keywords: bitmap, block coding, <b>compression,</b> <b>fractals,</b> imaging, recurrent iterated function system. 1 1 Introduction Fractal geometry provides a basis for modeling the in#nite detail found in nature #Mandelbrot, 1982 #. Fractal methods are quite popular in the modeling of natural phenomena in computer graphics, ranging from random fractal models [...] ...|$|R
