107|3|Public
40|$|We {{propose a}} novel method that {{makes use of}} deep neural {{networks}} and <b>gradient</b> <b>decent</b> to perform automated design on complex real world engineering tasks. Our approach works by training a neural network to mimic the fitness function of a design optimization task and then, using the differential nature of the neural network, perform <b>gradient</b> <b>decent</b> to maximize the fitness. We demonstrate this methods effectiveness by designing an optimized heat sink and both 2 D and 3 D airfoils that maximize the lift drag ratio under steady state flow conditions. We highlight that our method has two distinct benefits over other automated design approaches. First, evaluating the neural networks prediction of fitness can be orders of magnitude faster then simulating the system of interest. Second, using <b>gradient</b> <b>decent</b> allows the design space to be searched much more efficiently then other gradient free methods. These two strengths work together to overcome some of the current shortcomings of automated design. Comment: 12 pages, 9 figure...|$|E
3000|$|... are {{estimated}} in SAT using the <b>gradient</b> <b>decent,</b> {{the same as}} our proposed method. So, {{the difference between the}} linear-transform approach and the proposed model is whether the latent phonological features are modeled or not.|$|E
40|$|A dynamic {{perceptron}} {{is designed}} by introducing time delay factors {{into the state}} functions of static perceptrons. The dynamic δ rule is deduced by using the <b>gradient</b> <b>decent</b> method. It {{can be used to}} identify a type of nonlinear process that the system′s inputs, its past inputs and states can influence the system's outputs. 福建省自然科学基...|$|E
30|$|Using the {{technique}} of generalized gradient projection, we construct a generalized <b>gradient</b> projection feasible <b>decent</b> direction.|$|R
40|$|An intermittency {{model that}} is {{formulated}} in local variables is proposed for representing bypass transition in Reynolds-Averaged Navier-Stokes (RANS) computations. No external data correlation {{is used to}} fix transition. Transition is initiated by diffusion and a source term carries it to completion. A sink term is created to predict the laminar region before transition and vanishes in turbulent region. The present model is implemented in OpenFOAM, a platform for computational fluid dynamics (CFD) codes with unstructured mesh. For validation of this model, a group of test cases based on flat plate experiments {{have been set up}} for numerical simulations in OpenFOAM. It turns out that the current model is capable to predict boundary layer transition on a flat plate both with and without pressure <b>gradients</b> when <b>decent</b> agreement with the available experiment data is observed...|$|R
40|$|Full {{waveform}} inversion (FWI) despite it's potential {{suffers from}} the ability to converge to the desired solution due to the high nonlinearity of the objective function at conventional seismic frequencies. Even if frequencies necessary for the convergence are available, {{the high number of}} iterations required to approach a solution renders FWI as very expensive (especially in 3 D). A spectral implementation in which the wavefields are extrapolated and gradients are calculated in the wavenumber domain allows for a cleaner more efficient implementation (no finite difference dispersion errors). In addition, we use not only an up and down going wavefield decomposition of the gradient to access the smooth background update, but also a right and left propagation decomposition to allow us to do that for large dips. To insure that the extracted smooth component of the gradient has the right decent direction, we solve an optimization problem to search for the smoothest component that provides a negative (<b>decent)</b> <b>gradient.</b> Application to the Marmousi model shows that this approach works well with linear increasing initial velocity model and data with frequencies above 2 Hz...|$|R
40|$|This work {{suggests}} an algorithm {{to find the}} optimum smallest value for Reservoir's Size (RS) and Connectivity Percent (CP) parameters in Reservoir Computing (RC) technique other than the <b>gradient</b> <b>decent</b> and evolutionary computation algorithms. This will help in reducing the required chip area and decreasing the number of multiplications before hardware implementation of RC...|$|E
30|$|In the {{implementation}} of the complex valued conjugate <b>gradient</b> <b>decent</b> method with the Amijo rule (CGD), we set the decreasing rate of the step size μ to satisfy (19) with the sufficient decreasing condition at 0.01 and the stopping criteria of 10, 000 times of iterations or that the error ε is smaller than 10 − 4.|$|E
30|$|In this paper, we {{introduce}} a 2 D signal model in CS for a collocated MIMO radar with point targets, {{and then we}} improve the efficiency of this 2 D MIMO radar model by proposing a measurement matrix design using <b>gradient</b> <b>decent</b> algorithm (MMDGD) in which the MC of sensing matrix is minimized. We call the proposed method as 2 D-MMDGD.|$|E
30|$|The rest of {{the paper}} is {{organized}} as follows. Sections  2 and 3 describe the 1 D and 2 D CS signal model of the MIMO Radar, respectively. In Section  4, we propose a measurement matrix design for 1 D and 2 D CS model using <b>gradient</b> <b>decent</b> algorithm. The computational complexity of the proposed methods is discussed in Section  5. Simulation results are given in section  6. Finally, we have conclusions in section  7.|$|E
40|$|ABSTRACT: In this paper, a {{synergistic}} {{combination of}} neural networks with {{sliding mode control}} (SMC) is proposed. As a result, the chattering is eliminated and error performance of SMC is improved. In such an approach, two parallel NNs are proposed to realize SMC. The equivalent control and the corrective term of SMC are the outputs of the NNs. <b>Gradient</b> <b>Decent</b> method {{is used for the}} weight adaptation. This novel approach is applied to control of a scara type robot manipulator and simulation results are given...|$|E
40|$|Dynamical {{properties}} of image restoration and hyper-parameter estimation are investigated {{by means of}} statistical mechanics. We introduce an exactly solvable model for image restoration and derive differential equations with respect to macroscopic quantities. From these equations, we evaluate relaxation processes of the system to the equilibrium state. Our statistical mechanical approach also enable us to investigate the hyper-parameter estimation by means of maximization of marginal likelihood by using <b>gradient</b> <b>decent</b> and EM algorithm from dynamical point of view. Comment: latex 22 pages using revtex, 6 ps figure...|$|E
40|$|We {{propose a}} {{convolutional}} recurrent sparse auto-encoder model. The model {{consists of a}} sparse encoder, which is a convolutional extension of the learned ISTA (LISTA) method, and a linear convolutional decoder. Our strategy offers a simple method for learning a task-driven sparse convolutional dictionary (CD), and producing an approximate convolutional sparse code (CSC) over the learned dictionary. We trained the model to minimize reconstruction loss via <b>gradient</b> <b>decent</b> with back-propagation and have achieved competitive results to KSVD image denoising and to leading CSC methods in image inpainting requiring {{only a small fraction}} of their run-time...|$|E
40|$|In this letter, the {{hierarchical}} fuzzy systems are analyzed and designed. In the analysis part, we prove that {{the hierarchical}} fuzzy systems are universal approximators and analyze {{the sensitivity of the}} fuzzy system output with respect to small perturbations in its inputs. In the design part, we derive a <b>gradient</b> <b>decent</b> algorithm for tuning the parameters of the hierarchical fuzzy system to match the input-output pairs. The algorithm is simulated for two examples and the results show that the algorithm is effective and the hierarchical structure gives good approximation accuracy...|$|E
40|$|This paper {{introduces}} {{a novel approach}} to novelty detection of every individual sample of data in a time series. The novelty detection {{is based on the}} knowledge learned by neural networks and the consistency of data with contemporary governing law. In particular, the relationship of prediction error with the adaptive weight increments by <b>gradient</b> <b>decent</b> is shown, as the modification of the recently introduced adaptive approach of novelty detection. Static and dynamic neural network models are shown on theoretical data as well as on a real ECG signal...|$|E
40|$|We {{address the}} problem of 3 D model based vehicle {{localization}} in calibrated traffic scenes. A wireframe vehicle model is set up as prior information and an efficient local gradient based method is proposed to evaluate the fitness between the projection of 3 D model and image data, which illustrates smooth optimization surface and more conspicuous peak with low computational cost. <b>Gradient</b> <b>decent</b> is then applied to optimize the evaluation score for localization. Experimental results demonstrate the accuracy, efficiency and robustness of the proposed method for model based vehicle localization. ...|$|E
30|$|In {{our early}} experiments, we {{did try to}} use the {{existing}} ConvNets such as the VGG- 16 and the VGG- 19. The training of the two networks fails on both classification tasks, due to the vanishing gradient problem. That is why we decided {{to reduce the number}} of convolutional and max-pooling layers. We also avoid to use layers that do not yield visually appealing results in deconvolution, such as the average-pooling layer and the inception layer. We also explored some advanced numerical optimization methods like Adam and Adagrad, where we found the advanced methods were outperformed by the traditional stochastic <b>gradient</b> <b>decent.</b>|$|E
40|$|It is {{well known}} that the classic image {{compression}} techniques such as JPEG and MPEG have serious limitations at high compression rate; the decompressed image gets really fuzzy or indistinguishable. To overcome problems associated with conventional methods, artificial neural networks based method can be used. Genetic algorithm is a very powerful method for solving real life problems and this has been proven by applying to number of different applications. There is lots of interest to involve the GA with ANN for various reasons at various levels. Trapping in the local minima is one of the well known problems of <b>gradient</b> <b>decent</b> based learning in ANN. The problem can be addressed using GA algorithm. But no work has been done to evaluate the performance of both learning methods from the image compression point of view. In this paper, we investigate the performance of ANN with GA in the application of image compression for obtaining optimal set of weights. Direct method of compression has been applied with neural network to get the additive advantage for security of compressed data. The experiments reveal that the standard BP with proper parameters provide good generalize capability for compression and is much faster compared to earlier work in the literature, based on cumulative distribution function. Further, the results obtained shows that general concept about GA, it performs better over <b>gradient</b> <b>decent</b> based learning, is not applicable for image compression...|$|E
40|$|A new {{reconstruction}} {{approach to}} computerized tomography(CT) with Cauchy Radial Basis Functions network is presented. The distribution of material parameters {{is represented by}} the weighting sum of Cauchy functions. The analytical formula of the line integral of Cauchy functions along any straight-line path is deduced, and the theoretical projection data along a bent ray is computed by optimization algorithm. The parameters in RBFs network are found by the learning rule based on the <b>gradient</b> <b>decent</b> method. The new reconstruction approach is suitable for the CT with {{a relatively small number of}} bent ray paths or projection dada, such as seismic tomography. Computer simulations show its good effects...|$|E
40|$|Abstract — This paper {{presents}} a Fuzzy Wavelet Neural Network (FWNN) for identification {{and control of}} a dynamic plant. The FWNN is constructed {{on the basis of}} fuzzy rules that incorporate wavelet functions in their consequent parts. The architecture of the control system is presented and the parameter update rules of the system are derived. Learning rules are based on the <b>gradient</b> <b>decent</b> method and Genetic Algorithm (GA). The structure is tested for the identification and the control of the dynamic plants commonly used in the literature. It is shown that the proposed structure results in a better performance despite its smaller parameter space. R I...|$|E
40|$|Traditional {{iterative}} tomographic reconstruction methods {{resort to}} <b>gradient</b> <b>decent</b> methods and require significant computation due to slow convergence. We divide the iterative reconstruction into two {{stages in the}} image and Radon spaces, respectively. First, we refine the reconstruction result by image space adaptive filtering. This finds a feasible update direction based on signal modeling. Second, we minimize {{the discrepancy between the}} sinograms along the update direction in Radon space and guarantee convergence. Reconstruction from clinical data using the proposed algorithm converges extremely fast and provides satisfactory reconstruction results in far fewer iterations than traditional methods. Index Terms — Image reconstruction, medical imaging, adaptive filters, medical diagnosis, iterative methods, tomography...|$|E
40|$|We study holonomic <b>gradient</b> <b>decent</b> {{for maximum}} {{likelihood}} estimation of exponential-polynomial distribution, whose density is the exponential {{function of a}} polynomial in the random variable. We first consider {{the case that the}} support of the distribution is the set of positive reals. We show that the maximum likelihood estimate (MLE) can be easily computed by the holonomic gradient descent, even though the normalizing constant of this family does not have a closed-form expression and discuss determination of the degree of the polynomial based on the score test statistic. Then we present extensions to the whole real line and to the bivariate distribution on the positive orthant...|$|E
40|$|We {{propose a}} novel {{adaptive}} importance sampling algorithm which incorporates Stein variational <b>gradient</b> <b>decent</b> algorithm (SVGD) with importance sampling (IS). Our algorithm leverages the nonparametric transforms in SVGD to iteratively decrease the KL divergence between our importance proposal {{and the target}} distribution. The advantages of this algorithm are twofold: first, our algorithm turns SVGD into a standard IS algorithm, allowing us to use standard diagnostic and analytic tools of IS to evaluate and interpret the results; second, we do not restrict the choice of our importance proposal to predefined distribution families like traditional (adaptive) IS methods. Empirical experiments demonstrate that our algorithm performs well on evaluating partition functions of restricted Boltzmann machines and testing likelihood of variational auto-encoders...|$|E
40|$|Abstract. Fuzzy {{controller}} {{is one of}} the succeed controller used in {{the process}} control in case of model uncertainties. But it my be difficult to fuzzy controller to articulate the accumulated knowledge to encompass all circumstance. Hence, it is essential to provide a tuning capability. There are many parameters in fuzzy controller can be adapted, scale factor tuning of normalized fuzzy controller {{is one of the}} adaptation parameter. Two adaptation methods are implemented in this work on an experimental thermal process, which simulate heating process in liquefied petroleum gases (LPG) recovery process in one of petrochemical industries: <b>Gradient</b> <b>decent</b> (GD) adaptation method; supervisory fuzzy controller. A comparison between the two methods is discussed...|$|E
40|$|We {{develop a}} {{canonical}} dual approach for solving the MIMO problem. First, a special linear transformation is introduced to reformulate the original problem into a {− 1, 1 } constrained quadratic programming problem. Then, we derive a canonical dual problem which is piecewise continuous problem with no duality gap. Under certain conditions, the canonical problem becomes a concave maximization dual problem over a convex feasible domain. By getting the stationary {{point of the}} canonical dual problem, we can find either an optimal or approximate solution of the original problem. A <b>gradient</b> <b>decent</b> algorithm is proposed to solve the MIMO problem and simulation results are provided to demonstrate {{the effectiveness of the}} method...|$|E
40|$|A genetic {{algorithm}} is proposed {{as an alternative to}} the traditional linear programming method for scoring covariance models in non-coding RNA (ncRNA) gene searches. The standard method is guaranteed to find the best score, but it is too slow for general use. The observation that most of the search space investigated by the linear programming method does not even remotely resemble any observed sequence in real sequence data can be used to motivate the use of {{genetic algorithm}}s (GAs) to quickly reject regions of the search space. A search space with many local minima makes <b>gradient</b> <b>decent</b> an unattractive alternative. It is shown that a fixed-length representation for alignment of two sequences taken from the protein threading literature can be adapted for use with covariance models...|$|E
40|$|Adjoint field {{methods are}} both elegant and {{efficient}} for calculating sensitivity infor-mation required {{across a wide}} range of physics-based inverse problems. Here we provide a unified approach to the derivation of such methods for problems whose physics are pro-vided by Poisson’s equation. Unlike existing approaches in the literature, we consider in detail and explicitly the role of general boundary conditions in the derivation of the asso-ciated adjoint field-based sensitivities. We highlight the relationship between the adjoint field computations required for both <b>gradient</b> <b>decent</b> and Gauss-Newton approaches to image formation. Our derivation is based on standard results from vector calculus cou-pled with transparent manipulation of the underlying partial different equations thereby making the concepts employed here easily adaptable to other systems of interest. ...|$|E
40|$|Social trust {{prediction}} {{addresses the}} significant problem of exploring interactions among users in social networks. Naturally, this {{problem can be}} formulated in the matrix completion framework, with each entry indicating the trustness or distrustness. However, there are two challenges for the social trust problem: 1) the observed data are with sign (1 -bit) measurements; 2) they are typically sampled non-uniformly. Most of the previous matrix completion methods do not well handle the two issues. Motivated by the recent progress of max-norm, we propose {{to solve the problem}} with a 1 -bit max-norm constrained formulation. Since max-norm is not easy to optimize, we utilize a reformulation of max-norm which facilitates an efficient projected <b>gradient</b> <b>decent</b> algorithm. We demonstrate the superiority of our formulation on two benchmark datasets...|$|E
40|$|Color {{histogram}} based representations {{have been}} widely used for blob tracking. In this paper, a new color histogram based approach for object representation is proposed. By using a simplified version of color correlogram as object feature, spatial information is incorporated into object representation, which allows variations of rotation to be detected throughout the tracking therefore rotational objects can be more accurately tracked. The <b>gradient</b> <b>decent</b> method mean shift algorithm is adopted as the central computational module and further extended to a 3 D domain to find the most probable target position and orientation simultaneously. The capability of the tracker to tolerate appearance changes like orientation changes, small scale changes, partial occlusions and background scene changes is demonstrated using real image sequences. 1...|$|E
40|$|In {{order to}} achieve a mutiscale {{representation}} and texture extraction for textured image, a hierarchical (BV,Gp,L 2) decomposition model is proposed in this paper. We firstly introduce the proposed model which is obtained by replacing the fixed scale parameter of the original (BV,Gp,L 2) decomposition with a varying sequence. And then, the existence and convergence of the hierarchical decomposition are proved. Furthermore, we show the nontrivial property of this hierarchical decomposition. Finally, we introduce a simple numerical method for the hierarchical decomposition, which utilizes <b>gradient</b> <b>decent</b> for energy minimization and finite difference for the associated gradient flow equations. Numerical {{results show that the}} proposed hierarchical (BV,Gp,L 2) decomposition is very appropriate for multiscale representation and texture extraction of textured image...|$|E
40|$|This paper {{demonstrates}} {{the advantages of}} using a hybrid reinforcement–modular neural network architecture for non-linear control. Specifically, the method of ACTION-CRITIC reinforcement learning, modular neural networks, competitive learning and stochastic updating are combined. This provides an architecture able to both support temporal difference learning and probabilistic partitioning of the input space. The latter is formed {{with the aid of}} competitive learning algorithms, so as to ensure suitable partitioning of the experts in the modular network. Application of this methodology to the pole-balancing benchmark non-linear control problem demonstrates superior partitioning of the input space, bettering that of equivalent reinforcement networks; whilst avoiding the learning-to-learn nothing effect, {{as is often the case}} when performing <b>gradient</b> <b>decent</b> over problems requiring adaptation over long temporal dependencies...|$|E
40|$|The images which {{consist of}} RGB color images {{is known as}} vector valued images. This images is the {{multimodal}} images which shows strong inter-channel correlation among each other. We treat this images by the new notion by introducing the spatial gradient channels. We can obtained the vector valued through minimizing the cost functional that penalizes the large angles. After this we introduce the Gateaux derivative that leads to diffusion <b>gradient</b> <b>decent</b> scheme. The cost functional gives the several examples of denoising and demosaicking. These shows that demosaicking will gives visually perfect image for the low noise by parallel level set preceded by denoising. We get the result that after introducing all the idea to the image we will yield the better result than any other approaches...|$|E
40|$|We {{show that}} the {{standard}} stochastic <b>gradient</b> <b>decent</b> (SGD) algorithm is guaranteed to learn, in polynomial time, a function that is competitive with the best function in the conjugate kernel space of the network, as defined in Daniely, Frostig and Singer. The result holds for log-depth networks from a rich family of architectures. To {{the best of our}} knowledge, it is the first polynomial-time guarantee for the standard neural network learning algorithm for networks of depth more that two. As corollaries, it follows that for neural networks of any depth between 2 and (n), SGD is guaranteed to learn, in polynomial time, constant degree polynomials with polynomially bounded coefficients. Likewise, it follows that SGD on large enough networks can learn any continuous function (not in polynomial time), complementing classical expressivity results...|$|E
40|$|International audienceThis paper {{addresses}} {{the problem of}} adaptively optimizing a two-channel lossless finite-impulse-response (FIR) filter bank, which finds application in subband coding and wavelet signal analysis. Instead of using a <b>gradient</b> <b>decent</b> procedure-with its inherent problem of becoming trapped in local minima of a nonquadratic cost function-two eigenstructure algorithms are proposed. Both algorithms feature a priori bounds on the output variance at any convergent point, which, based on simulations, lead to solutions that lie acceptably close to a global minimum point of an output variance objective function. Moreover, a sufficient condition for such stationary points based on fixed-point theory is shown. It is shown that the convergence rate of both algorithms increases as the separation of eigenvalues of the input covariance matrix increases. Simulations for synthetic and real data support the conclusion...|$|E
40|$|Artificial neural {{networks}} are {{a form of}} connectionist architecture where many simple computational nodes are connected in a fashion {{similar to that of}} biological brains for the purpose of solving problems that require rapid adaptation or where underlying governing equations are not known or cannot be easily computed. This paper first discusses the use of various computer platforms for implementing {{neural networks}}, then focuses on two single-chip neurocomputer implementations: (1) An artificial dendritic tree “bottom-up” VLSI chip; and (2) A vector-register microprocessor “top-down ” design with on-chip learning and a fully-parallel, entirely-digital implementation facilitated by modifying the neuron transfer function using a polynomial approximation with clipping of neuron inputs outside of specified values. The validity of this methodology is supported by an analysis of the mathematics of <b>gradient</b> <b>decent</b> learning...|$|E
40|$|In this paper, {{we propose}} a one-pass {{algorithm}} on MapReduce for penalized linear regression f_λ(α, β) = Y - α 1 - Xβ_ 2 ^ 2 + p_λ(β) where α is the intercept {{which can be}} omitted depending on application; β is the coefficients and p_λ is the penalized function with penalizing parameter λ. f_λ(α, β) includes interesting classes such as Lasso, Ridge regression and Elastic-net. Compared to latest iterative distributed algorithms requiring multiple MapReduce jobs, our algorithm achieves huge performance improvement; moreover, our algorithm is exact compared to the approximate algorithms such as parallel stochastic <b>gradient</b> <b>decent.</b> Moreover, what our algorithm distinguishes with others is that it trains the model with cross validation to choose optimal λ instead of user specified one. Key words: penalized linear regression, lasso, elastic-net, ridge, MapReduc...|$|E
