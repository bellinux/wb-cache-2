67|508|Public
2500|$|Soils {{consist of}} a mixture of {{particles}} of different size, shape and mineralogy. Because {{the size of the}} particles obviously has a significant effect on the soil behavior, the grain size and grain size distribution are used to classify soils. The grain size distribution describes the relative proportions of particles of various sizes. The grain size is often visualized in a cumulative <b>distribution</b> <b>graph</b> which, for example, plots the percentage of particles finer than a given size as a function of size. The median grain size, , is the size for which 50% of the particle mass consists of finer particles. Soil behavior, especially the hydraulic conductivity, tends to be dominated by the smaller particles, hence, the term [...] "effective size", denoted by , is defined as the size for which 10% of the particle mass consists of finer particles.|$|E
50|$|Using NTA, the {{particles}} are automatically tracked and sized. Results are displayed as a frequency size <b>distribution</b> <b>graph</b> and are exported in various, user-selected formats including spreadsheets and video files. Additionally, information-rich videos clips may be captured and archived {{for future reference}} and alternative analyses. The LM10 is proven with most nanoparticle classes down to 10 nm (dependent upon particle density) dispersed {{in a wide range}} of solvents.|$|E
5000|$|Soils {{consist of}} a mixture of {{particles}} of different size, shape and mineralogy. Because {{the size of the}} particles obviously has a significant effect on the soil behavior, the grain size and grain size distribution are used to classify soils. The grain size distribution describes the relative proportions of particles of various sizes. The grain size is often visualized in a cumulative <b>distribution</b> <b>graph</b> which, for example, plots the percentage of particles finer than a given size as a function of size. The median grain size, , is the size for which 50% of the particle mass consists of finer particles. Soil behavior, especially the hydraulic conductivity, tends to be dominated by the smaller particles, hence, the term [...] "effective size", denoted by , is defined as the size for which 10% of the particle mass consists of finer particles.|$|E
40|$|This work {{represents}} {{an application of}} constant mean curvature graphs (as solutions of the mean curvature PDE) to non-linear non-Darcy flows in porous media. It relates time invariant pressure <b>distribution</b> <b>graphs</b> to graphs of constant mean curvature surfaces. This differential geometric interpretation provides an important tool for evaluating technological parameters in reservoir engineering. Comment: The complete work is available at [URL]...|$|R
50|$|Imaging {{particle}} {{analysis is}} a technique for making particle measurements using digital imaging, one of the techniques defined by the broader term particle size analysis. The measurements {{that can be made}} include particle size, particle shape (morphology or shape analysis and grayscale or color, as well as <b>distributions</b> (<b>graphs)</b> of statistical population measurements.|$|R
40|$|Balloon {{observations}} registering scatter angles in {{a liquid}} scintillator have revealed gamma-ray bursts having energies {{as low as}} 10 to the - 7 th ergs per square cm. The burst <b>distribution</b> is <b>graphed</b> according to energy and frequency. The hypothesis that the bursts are galactic in origin is in good agreement with their small recorded energies and their predicted <b>distribution</b> on the <b>graph...</b>|$|R
50|$|These {{results from}} each cell are {{cumulated}} and assigned in a calibrated multi-channel analyser with over 500,000 channels. So, for the CASY technology, as the cell flow cytometry, it can present data of each cell as a cell size <b>distribution</b> <b>graph,</b> which has 2 variables, {{the change in}} cell volume and that in cell viability. The materials passing though the apparatus can be gated. For the newly invented equipments, they have an automatically lower threshold at 7 um, which can exclude small particles and cell debris in the cell culture. At the same time, {{there will be an}} upper threshold to prevent from cell aggregation for counting. However, some of users may set upper threshold to unlimited for cell size. Since the cell size of each cell type is varied, before doing gating, it should ensure the correct cell size is included during the cell size related experiment.|$|E
50|$|An {{empirical}} {{strength of}} sequence analysis is {{its emphasis on}} methods for visualizing otherwise seemingly overly complex social phenomena. A variety of visual aids - especially graphs and network diagrams - {{make it easier to}} detect sequence patterns. One visual aid, known as a transition plot, replace the numbers in the cells of a transition matrix with a visual symbol that reflects the magnitude of the relationship between two given states or phenomena. In this kind of graph, the symbols size or shape varies with the corresponding transition probabilities. Transitions that occur within a set of sequences can also be depicted using a network-like diagram called a state transition diagram, which displays elements as nodes in a network. This way, relationships between elements can be emphasized using graphical aids, such as by adjusting the thickness of lines between states. Transition plots and state transition diagrams are useful for depicting patterns of first-order (Markovian) transitions. They do not provide information about when transitions occur or overall sequence patterns. One visual aid that is useful in both of these respects is the sequence index plot, an example of which is provided {{on the right side of}} this page. This kind of graph displays every sequence in the sample. The y-axis includes all of the observations, stacked on top of each other. The x-axis depicts the sequence positions in order. The observations in the sequence index plot are arranged such that cases with the same sequence order are grouped adjacent to each other on the y-axis. A similar graph, called the state <b>distribution</b> <b>graph,</b> can be used to simplify the patterns that are latent in sequence index plots. Like sequence index plots, state distribution graphs array sequence positions in order along the x-axis. The main difference is that the y-axis contains not individual cases, but the prevalence of each element at each position on the x-axis. A special type of state <b>distribution</b> <b>graph</b> is the tempogram, which is designed specifically for temporally ordered sequence data. Finally, sequences are often depicted as networks, in which multiple subjects’ sequences are shown to intersect with each other art specific events or instances. This approach is most common in analyses of sequence networks, especially narrative networks.|$|E
40|$|Abstract: Pull-up {{transistor}} {{assignment is}} one of the tasks in product term foMing of a Programmable Logic Array (PILA). This problem can be solved, in polynomial time, fLY first model-ing it as a <b>distribution</b> <b>graph,</b> and then as a flow network. The pull-up transistor assignment problem seems simpler than the <b>distribution</b> <b>graph</b> problem. Thus, {{it may be possible to}} model the problem, differently (without using a <b>distribution</b> <b>graph)</b> and obtain asymptotically more efficient algorithms. In this paper, we show that the modeling is not the issue. In fact, the distribu-tion graph problem can also be modeled as the pull-up transis-tor assignment problem. Hence, finding a more efficient algo-rithm for the pull-up transistor assignment problem is equivalent to having a more efficient algorithm for the distribu-tion graph problem. 1...|$|E
40|$|A large {{concentration}} of wintering herring was surveys continuously with acoustics over 37 {{hours in a}} fjord in Northern Norway. 16 surveys of the same area were conducted. Total abundance and statistics were computed for each survey. <b>Distribution</b> <b>graphs</b> showd a clear diel variation, with deep daytime layers and more shallow night time distribution. Acoustically measured abundance at night was 50 % of the daytime values. The results are {{discussed in terms of}} behaviour induced diel variation in acoustic backscattering, and potential influence on acoustic abundance measurements...|$|R
40|$|Abstract. The key of {{swirling}} airflow finishing is how {{to generate}} the swirling airflow. In the paper, three swirling airflow head are discussed according the manners of tangential inflow. By means of FLUENT, the general software of CFD, the swirling airflow field from different airflow head is simulated. The simulation results are shown by the flow line graphs, tangential velocity, radial <b>distribution</b> <b>graphs,</b> etc. All we have studied is {{as the basis for}} the determination of the application scope of each swirling airflow head...|$|R
40|$|Abstract. The study {{discusses}} {{a revised}} method of water detection through infrared acquisition technology. In {{the case of}} Xianghe tunnel construction, the authors built 3 D infrared radiation field functions through 3 D trend analysis. The separately calculated radiation intensity trend values and outliers were processed by the visualization software, Voxler, and transformed into 3 D <b>distribution</b> <b>graphs</b> for further comparison and analysis. The result indicates that the technique and method applied in this article successfully eliminate the random interference and realize the detection of aquifer...|$|R
30|$|In “Degree distributions” section, we {{proposed}} that the low-degree saturation region of the degree distributions for sentence collocation networks are correlated with the highly connective linking procedure of the sentence collocation networks. Consequently, the peak k value of the <b>distribution</b> <b>graph</b> may give an idea about the mean length of the sentences for that media. Comparing the degree distribution graphs in Fig.  3 with the SL <b>distribution</b> <b>graph</b> in Fig.  8, we observe good consistency in the saturation region (k <  10) and the average SL values. This consistency confirms the reason we proposed for the low-degree saturation regime, which is only evident dominantly for the degree distributions of the sentence collocation networks.|$|E
40|$|Abstract—This paper introduces, motivates, defines, and {{exemplifies the}} concept of <b>distribution</b> <b>graph</b> {{as a way for}} {{modelling}} and developing Distributed User Interfaces of interactive systems. A <b>distribution</b> <b>graph</b> consists of a state chart model enriched as follows: states represent individual states of entities involved in the distribution as well as a collective representation of their synchronization; transitions are represented by event-conditionactions where the action part consists of a distribution script. A distribution script expresses the distribution behaviour based on distribution primitives. These primitives are basic operations that manipulate parts or wholes of user interface for distribution at run-time. These primitives are themselves implemented on top of an environment for distributed computing that is implemented for four major computing platforms (i. e., Microsoft Windows, Mac OS X, Linux, and Mobile Linux). Thanks to the capabilities provided by this environment, the user interfaces belonging to these distributed systems can be run indifferently on any of these computing platforms. This paper defines the new concepts introduced for this purpose, i. e., distribution primitive, distribution script, and <b>distribution</b> <b>graph,</b> and demonstrates how they can effectively support distributed user interfaces. Keywords-Distributed User Interface, Human-Computer Interaction (HCI) modelling, Ubiquitous computin...|$|E
40|$|This paper introduces, motivates, defines, and {{exemplifies the}} concept of <b>distribution</b> <b>graph</b> {{as a way for}} {{modelling}} and developing Distributed User Interfaces of interactive systems. A <b>distribution</b> <b>graph</b> consists of a state chart model enriched as follows: states represent individual states of entities involved in the distribution as well as a collective representation of their synchronization; transitions are represented by event-condition-actions where the action part consists of a distribution script. A distribution script expresses the distribution behaviour based on distribution primitives. These primitives are basic operations that manipulate parts or wholes of user interface for distribution at run-time. These primitives are themselves implemented on top of an environment for distributed computing that is implemented for four major computing platforms (i. e., Microsoft Windows, Mac OS X, Linux, and Mobile Linux). Thanks to the capabilities provided by this environment, the user interfaces belonging to these distributed systems can be run indifferently on any of these computing platforms. This paper defines the new concepts introduced for this purpose, i. e., distribution primitive, distribution script, and <b>distribution</b> <b>graph,</b> and demonstrates how they can effectively support distributed user interfaces...|$|E
5000|$|Exponential random graph models {{describe}} a general probability <b>distribution</b> of <b>graphs</b> on [...] "n" [...] nodes given {{a set of}} network statistics and various parameters associated with them.|$|R
40|$|Network {{analysis}} needs {{tools to}} infer <b>distributions</b> over <b>graphs</b> of arbitrary size {{from a single}} <b>graph.</b> Assuming the <b>distribution</b> is generated by a continuous latent space model which obeys certain natural symmetry and smoothness properties, we establish three levels of consistency for non-parametric maximum likelihood inference {{as the number of}} nodes grows: (i) the estimated locations of all nodes converge in probability on their true locations; (ii) the distribution over locations in the latent space converges on the true distribution; and (iii) the <b>distribution</b> over <b>graphs</b> of arbitrary size converges. Comment: 21 page...|$|R
40|$|Inherent to {{state-of-the-art}} dimension reduction algorithms is {{the assumption}} that global distances between observations are Euclidean, despite the potential for altogether non-Euclidean data manifolds. We demonstrate that a non-Euclidean manifold chart can be approximated by implementing a universal approximator over a dictionary of dissimilarity measures, building on recent developments in the field. This approach is transferable across domains such that observations can be vectors, <b>distributions,</b> <b>graphs</b> and time series for instance. Our novel dissimilarity learning method is illustrated with four standard visualisation datasets showing the benefits over the linear dissimilarity learning approach...|$|R
40|$|Abstract: In this paper, a {{modeling}} and simulation method for planar interdigitated ruthenium oxide MEMS supercapacitor was proposed based on the electrochemical reaction mechanism of supercapacitor. The study simulated the planar interdigitated ruthenium oxide MEMS super capacitor using Comsol software. The highly accurate charge and discharge curves of the super capacitor, electric potential <b>distribution</b> <b>graph</b> and the concentration <b>distribution</b> <b>graph</b> were got through simulation. The effects of two structure-parameters were discussed in the research. Supercapacitor is a research focus in the micro-energy field. Many researchers {{are interested in the}} dynamic modeling for supercapacitor. Dynamics modeling of super capacitor, is building a mathematical model by a set of partial differential equations and corresponding boundary conditions, according to the electrochemical mechanism of supercapacitor...|$|E
40|$|An improvised {{algorithm}} is proposed {{based on the work}} of Yoshimoto and Harada. The improvised algorithm results a graph which is called LDGC or Logarithmic <b>Distribution</b> <b>Graph</b> of Curvature. This graph has the capability to identify the beauty of monotonic planar curves with less effort as compared to LDDC by Yoshimoto and Harada...|$|E
30|$|The {{addition}} of 0.5 % wt/wt Cu into silica sol caused the flocculation of colloidal silica nanoparticles (Figure 5 b). The emersion of two peaks and the broadening of silica peaks in a size <b>distribution</b> <b>graph</b> just 5 min after introducing Cu nanoparticles {{may be attributed}} to the gradual agglomeration of silica and Cu particles (Figure 1 b).|$|E
40|$|In this {{manuscript}} we have presented a literature survey of cryptographically securepseudo random number generators, their requirements regarding statistical properties and next bit test. The paper {{also provides a}} brief overview of Blum Blum Shub (BBS) Generator specifically, which is considered to be the best cryptographically secure pseudorandom number generator. We have performed the rigorous testing of BBS generator on National Institute of Science and Technology (NIST) statistical test suite 2. 1. 1. Scatter plot and P-value <b>distribution</b> <b>graphs</b> are also included in the manuscript to support the conclusion...|$|R
50|$|This {{property}} is often analyzed {{by considering the}} fraction of nodes in the network that have a particular number of connections going into them (the degree distribution of the network). Networks with a greater than expected number of hubs will have a greater fraction of nodes with high degree, and consequently the degree distribution will be enriched at high degree values. This is known colloquially as a fat-tailed <b>distribution.</b> <b>Graphs</b> of very different topology qualify as small-world networks {{as long as they}} satisfy the two definitional requirements above.|$|R
50|$|In {{probability}} theory and statistics, the trapezoidal distribution is a continuous probability <b>distribution</b> the <b>graph</b> of whose probability density function resembles a trapezoid. Likewise, trapezoidal distributions also roughly resemble mesas or plateaus.|$|R
40|$|This work deals {{kinetics}} of grinding Portland {{cement clinker}} which {{is influenced by}} addition of grinding inlays surfactants. In an experiment, attritor-type stirred mill was used and surface active grinding additives such as polyethylenglykol (PEG), triethylamin (TEA) and acetate of ammonium were utilized. Granulometric <b>distribution</b> <b>graph</b> obtained from laser diffraction analysis provides data for plotting development diagrams for milling process...|$|E
40|$|The {{dominating}} {{contribution of}} interconnect to system performance {{has made it}} critical to plan {{the resources of the}} buffers and routes in the early stage of the layout. In this paper, we integrate floorplanning with buffer insertion for performance-driven design processes. We devise a two-step method to evaluate the feasible buffer insertion sites, which can improve the efficiency of the buffer-planning algorithm. By partitioning all empty spaces into blocks in the packing process, the buffer allocation is handled {{as an integral part of}} the floorplanning. Our buffer-planning algorithm maps the buffers into tiles with consideration of routing congestion. In this approach, we construct a <b>distribution</b> <b>graph</b> to model the possible routes. The buffer allocation method is performed on the updated <b>distribution</b> <b>graph</b> to find the buffer locations with their respective congestion costs. The method is based on a simulated annealing approach, which is composed of multiple phases to speed up the optimization. Since there is more freedom with floorplan optimization, the empirical results demonstrate better performance...|$|E
30|$|After {{above-mentioned}} {{common core}} tests, the steps {{necessary for the}} preparation of samples were performed for testing nuclear magnetic resonance. For this purpose, samples were cleaned with xylene and methanol in the Soxhlet device and saturated with salt water (brine). Then, the nuclear magnetic resonance experiment at 100 % saturation and data analysis were performed and T 2 <b>distribution</b> <b>graph</b> was obtained as in Fig.  1.|$|E
40|$|Abstract: In {{order to}} improve the {{machining}} accuracy of precision CNC lathe, and explore the fluid motion law in the closed hydrostatic guideway, three-dimensional model of hydrostatic oil chamber was established using preprocessor GAMBIT of FLUENT. The Finite Volume Method of Fluent {{has been used to}} the simulation of fluid three-dimensional velocity field and pressure field. The fluid velocity vector and pressure <b>distribution</b> <b>graphs</b> are obtained. They reveal the flow field law in the gap fluid. The simulation result of the pressure distribution shows that the flow pressure was not changing in linear gradient all around the gap under moving condition...|$|R
40|$|Over {{the past}} few years, we {{developed}} a mathematically rigorous method to study the dynamical processes associated to nonlinear Forchheimer flows for slightly compressible fluids. We have proved {{the existence of a}} geometric transformation which relates constant mean curvature surfaces and time-invariant pressure <b>distribution</b> <b>graphs</b> constrained by the Darcy-Forchheimer law. We therein established a direct relationship between the CMC graph equation and a certain family of equations which we call $g$-Forchheimer equations. The corresponding results, on fast flows and their geometric interpretation, can be used as analytical tools in evaluating important technological parameters in reservoir engineering. Comment: arXiv admin note: substantial text overlap with arXiv: 1302. 546...|$|R
40|$|Abstract. This paper {{addresses}} {{the study of}} fundamental properties of stream-based content distribution services. We assume {{the presence of an}} overlay network with limited connectivity degree, and we develop a mathematical model that captures the essential properties of overlaybased streaming protocols and systems. The methodology is based on graph theory and models the streaming system as a stochastic process, whose characteristics are related to the streaming protocol. The model can capture the transient behavior of the <b>distribution</b> <b>graphs,</b> i. e., the evolution of the structure over time. Results show that mesh-based architectures are able to provide bounds on the receiving delay and maintain rate fluctuations due to system dynamics very low. ...|$|R
30|$|Using the a-priori known {{radius of}} the fibers, a {{segmentation}} mask is generated in order to remove the corresponding fiber from the input data. These steps, as explained in detail below, are repeated until the input dataset is fiber-free, that is the algorithm cannot find any remaining cylindrical structures in the image data. Finally, the length of each fiber can be determined and a <b>distribution</b> <b>graph</b> can be created.|$|E
40|$|Abstract. Ejection seat is {{the most}} {{important}} life-saving tool in warcraft. We analyze of the reason why the ejection mechanism works in advance in ejection process, when the aircraft canopy is not throw away. And carry on the deformation analysis of the lock arm in the interlock device to define the strength of the lowest part of the lock arm. Finally, we obtain the stress <b>distribution</b> <b>graph</b> of lock arm, which provides a theoretical reference for the interlock device on the optimal design...|$|E
30|$|A {{performing}} algorithm should {{detect the}} nested component independently of degree <b>distribution,</b> <b>graph</b> density, matrix shape, and matrix size. Such a solid algorithm should identify all vertices that fulfill {{the criterion of}} nested neighbourhoods (i.e. a higher degree vertex includes the neighbourhood of a lower degree vertex). In the following we compare the sensitivities of the three methods BINMATNEST, NODF, and NESTLON in detecting nestedness on unipartite and bipartite networks. For our analysis we use networks generated through the above mentioned benchmark graph.|$|E
40|$|In this paper, we {{introduce}} a function,; (,,) z s a, {{which is an}} extension to the general Hurwitz-Lerch Zeta function. Having defined the incomplete generalized beta type- 2 and incomplete generalized gamma functions, some differentiation formulae are established for these incomplete functions. We have introduced two new statistical distributions, termed as generalized Hurwitz-Lerch Zeta beta type- 2 distribution and generalized Hurwitz-Lerch Zeta gamma distribution and then derived the expressions for the moments, distribution function, the survivor function, the hazard rate function and the mean residue life function for these <b>distributions.</b> <b>Graphs</b> for both these distributions are given, which reflect the role of shape and scale parameters...|$|R
40|$|The load {{carrying}} capacity of designed self-centring permanent magnet based vibro-isolating support is analysed in the article. COMSOL Multiphysics modelling software was used for nu-merical simulation. Results are presented as repulsion force ver-sus support cap displacement graph as well as magnetic flux density <b>distribution</b> <b>graphs.</b> Repulsion force was also measured experimentally. It is established that differences between numeri-cally and experimentally obtained force values are only about 2 – 8 %. It is established that maximum normal load force of the support can’t exceed 150 N. It is also established that near-zero stiffness of the support is achieved in case of approximately 70 N normal load force...|$|R
30|$|Kurtosis: {{indicates}} the relative flattening of the grey-level distribution. It {{is equal to}} zero for a normal distribution. It takes a negative or a positive value for a <b>distribution</b> whose <b>graph</b> is relatively flat or relatively sharp, respectively.|$|R
