4|16|Public
5000|$|A soap based {{web service}} can be {{implemented}} as a single java class.An <b>endpoint</b> <b>interface,</b> {{also known as a}} service <b>endpoint</b> <b>interface</b> (SEI), is a term used in Java Platform, Enterprise Edition when exposing Enterprise JavaBeans as a Web service (see also Service Implementation Bean (SIB)). It is annotated with [...] and is a component interface, which declares all the abstract methods that are exposed to the client. As it extends the [...] interface, all methods must throw the [...] A Web service client accesses a stateless session bean through the bean's Web service <b>endpoint</b> <b>interface.</b> Like a remote interface, a Web service <b>endpoint</b> <b>interface</b> defines the business methods of the bean.|$|E
50|$|In {{contrast}} to a remote interface, a Web service <b>endpoint</b> <b>interface</b> is not accompanied by a home interface, which defines the bean's life-cycle methods. The only methods of the bean that may be invoked by a Web service client are the business methods that are defined in the Web service <b>endpoint</b> <b>interface.</b>|$|E
50|$|The {{methods of}} an <b>endpoint</b> <b>interface</b> for a Web service are {{implemented}} in a session bean class that is stateless.|$|E
5000|$|Simplified view of {{a service}} on one page, using tabs to show <b>endpoints,</b> <b>interfaces,</b> and details.|$|R
5000|$|<b>Interfaces</b> (<b>endpoints).</b> The <b>interface</b> {{of a live}} {{distributed}} {{object is}} defined by the types of interfaces exposed by its proxies; these may include event channels and various types of graphical user interfaces. Interfaces exposed by the proxies are referred to as the live distributed object's endpoints. The term endpoint instance refers to a single specific event channel or user interface exposed by a single specific proxy. To say that a live object exposes a certain endpoint means that each of its proxies exposes an instance of this endpoint to its local environment, and each of the endpoint instances carries events of the same types (or binds to the same type of a graphical display).|$|R
40|$|Abstract—Modern {{high-speed}} interconnection {{networks are}} designed with capabilities to support communication from mul-tiple processor cores. The MPI endpoints extension has been proposed to ease process and thread count tradeoffs by enabling multithreaded MPI applications to efficiently drive independent network communication. In this work, we present the first implementation of the MPI <b>endpoints</b> <b>interface</b> and demonstrate the first applications running on this new interface. We use a novel library-based design that can be layered on top of any existing, production MPI implementation. Our approach uses proxy processes to isolate threads in an MPI job, eliminating threading overheads within the MPI library and allowing threads to achieve process-like communication performance. We evaluate the performance advantages of our implementation through several benchmarks and kernels. Performance results for the Lattice QCD Dslash kernel indicate that endpoints provides up to 2. 9 × improvement in communication performance and 1. 87 × overall performance improvement over a highly optimized hybrid MPI+OpenMP baseline on 128 processors...|$|R
50|$|A Service Implementation Bean (SIB), is a {{term used}} in Java Platform, Enterprise Edition, for a Java object {{implementing}} a web service. It can be either a POJO or a Stateless Session EJB. The Java interface of an SIB is called a Service <b>Endpoint</b> <b>Interface</b> (SEI).|$|E
50|$|Publishing a Web service {{involves}} {{creating a}} software artifact {{and making it}} accessible to potential consumers. Web Service Providers augment a Web service <b>endpoint</b> with an <b>interface</b> description using the Web Services Description Language (WSDL) so that a consumer can use the service.|$|R
5000|$|Behaviors {{implement}} the [...] interface for service extensions, the [...] for <b>endpoints,</b> the [...] <b>interface</b> for service contracts, or the [...] for operations. Service behaviors {{are used for}} message processing across a service, rather than processing that would be specific to a single operation.|$|R
5000|$|... where [...] is a vector {{normal to}} the interface. Components {{of the normal}} are found i.e. by using the Finite Difference method or its {{combination}} with least squares optimization. The free term [...] is then found (analytically or by approximation) by enforcing mass conservation within computational cell. Once {{the description of the}} interface is established, the advection equation of [...] is solved using geometrical techniques such as finding the flux of [...] between grid cells, or advecting the <b>endpoints</b> of <b>interface</b> using discrete values of fluid velocity.|$|R
5000|$|A {{variant of}} this split {{tunneling}} is called [...] "inverse" [...] split tunneling. By default all datagrams enter the tunnel except those destination IPs explicitly allowed by VPN gateway. The criteria for allowing datagrams {{to exit the}} local network interface (outside the tunnel) may vary from vendor to vendor (i.e.: port, service, etc.) This keeps control of network gateways to a centralized policy device such as the VPN terminator. This can be augmented by endpoint policy enforcement technologies such as an interface firewall on the <b>endpoint</b> device's network <b>interface</b> driver, group policy object or anti-malware agent. This is related in many ways to network access control (NAC).|$|R
40|$|Abstract. The DBpedia project {{extracts}} structured {{information from}} Wikipedia {{and makes it}} available on the web. Information is gathered mainly {{with the help of}} infoboxes that contain structured information of the Wikipedia article. A lot of information is only contained in the article body and is not yet included in DBpedia. In this paper we focus on the extraction of historical events from Wikipedia articles that are available for about 2, 500 years for different languages. We have extracted about 121, 000 events with more than 325, 000 links to DBpedia entities and provide access to this data via a Web API, SPARQL <b>endpoint,</b> Linked Data <b>Interface</b> and in a timeline application...|$|R
40|$|Abstract. Linking Open Data (LOD) {{has become}} one of the most im-portant {{community}} efforts to publish high-quality interconnected seman-tic data. Such data has been widely used in many applications to provide intelligent services like entity search, personalized recommendation and so on. While DBpedia, one of the LOD core data sources, contains re-sources described in multilingual versions and semantic data in English is proliferating, there is very few work on publishing Chinese semantic data. In this paper, we present Zhishi. me, the first effort to publish large scale Chinese semantic data and link them together as a Chinese LOD (CLOD). More precisely, we identify important structural features in three largest Chinese encyclopedia sites (i. e., Baidu Baike, Hudong Baike, and Chinese Wikipedia) for extraction and propose several data-level mapping strategies for automatic link discovery. As a result, the CLOD has more than 5 million distinct entities and we simply link CLOD with the existing LOD based on the multilingual characteristic of Wikipedi-a. Finally, we also introduce three Web access entries namely SPARQL <b>endpoint,</b> lookup <b>interface</b> and detailed data view, which conform to the principles of publishing data sources to LOD. ...|$|R
40|$|The DBpedia project {{extracts}} structured {{information from}} Wikipedia {{and makes it}} available on the web. Information is gathered mainly {{with the help of}} infoboxes that contain structured information of the Wikipedia article. A lot of information is only contained in the article body and is not yet included in DBpedia. In this paper we focus on the extraction of historical events from Wikipedia articles that are available for about 2, 500 years for different languages. We have extracted about 121, 000 events with more than 325, 000 links to DBpedia entities and provide access to this data via a Web API, SPARQL <b>endpoint,</b> Linked Data <b>Interface</b> and in a timeline application. Comment: To be published in Proceedings of Knowledge Discovery and Data Mining Meets Linked Open Data (Know@LOD) Workshop at ESWC 201...|$|R
40|$|In this paper, we {{describe}} a design for an object-oriented, interprocess communications subsystem {{that supports the}} migration of communication endpoints. All communication is connection-oriented and occurs between two <b>endpoints,</b> represented by <b>Interface</b> Objects (IObjs). A full-duplex connection between IObjs is implemented by one buffer ring per direction; the buffer rings are conceptually shared by both IObjs through a consumer-producer relationship. This design's architecture is location-transparent for naive objects that are not designed to deal specifically with migrating peers. However, the architecutre can keep highly optimized objects informed {{so that they can}} react to migration events and adjust their behavior. The design supplies a framework with which the system can provide efficient object and process migration while maintaining open connections. 1 Introduction Interprocess communication (IPC) is a key primitive in modern operating systems. The structure of system IPC affec [...] ...|$|R
40|$|Abstract. This paper {{describes}} an open linked dataset containing data on energy efficiency improvements, i. e., recommendations and measures taken based on energy audits, from both Sweden and the US, i. e., from the Swedish Energy Agency and the US Department of Energy’s Industrial Assessment Centers (IAC), respectively. The overall goal of our project is threefold; (i) to facilitate better energy audits through allowing auditors and the organizations {{themselves to be}} inspired by information on measures taken earlier, in similar organisational settings, (ii) to allow researchers and policy-makers to search, compare, and assess Swedish energy audit data, and data from the US, in an integrated fashion, and (iii) to facilitate easier building of third-party applications on top of energy audit data by publishing it as Linked Open Data on the Web. The dataset is currently available through both a SPARQL <b>endpoint,</b> a Snorql <b>interface,</b> and a demonstration search interface tailored for human end-users. The data is being updated based on an ongoing manual quality control effort, and future work includes {{the use of the}} dataset to perform studies on the effects of using past energy audit data as inspiration for future recommendations for Swedish industry, as well as continuously publishing updates and extensions to the dataset itself...|$|R
40|$|This {{bachelor}} thesis {{describes the}} implementation of an Android framework to access mass storage devices over the USB interface of a smartphone. First the basics of USB (i. e. <b>interfaces,</b> <b>endpoints</b> and USB On the go) and accessing USB devices via the official Android API are discussed. Next the USB mass storage class is explained, which was de- signed by the USB-IF to access mobile mass storage like USB pen drives or external HDDs. For communication with mass storage devices, most important are the bulk-only transfer and the SCSI transparent command set. Furthermore file systems, for accessing directo- ries and files, are described. This thesis focuses on the FAT 32 file system from Microsoft, {{because it is the}} most commonly used file system on such devices. After the theory part it is time to look at {{the implementation of}} the framework. In this section, the first concern is the purpose in general. Then the architecture of the framework and the actual implementation are presented. Important parts are discussed in detail. The thesis finishes with an overview of the test results on various Android devices, a short conclusion and an outlook to future developments. Moreover the current status of the developed framework is visualized...|$|R
40|$|Traditionally, in most {{digital library}} environments, the {{discovery}} of resources takes place mostly through the harvesting and indexing of the metadata content. Such search and retrieval services provide very effective ways for persons to find items of interest but lacks the ability to lead users looking for potential related resources or to make more complex queries. In contrast, modern web information management techniques related to Semantic Web, {{a new form of}} the Web, encourages institutions, including libraries, to collect, link and share their data across the web in order to ease its processing by machines and humans offering better queries and results increasing the visibility and interoperability of the data. Linked Data technologies enable connecting related data across the Web using the principles and recommendations set out by Tim Berners-Lee in 2006, resulting on the use of URIs (Uniform Resource Identifier) as identifiers for objects, and the use of RDF (Resource Description Framework) for links representation. Today, libraries are giving increasing importance to the Semantic Web {{in a variety of ways}} like creating metadata models and publishing Linked Data from authority files, bibliographic catalogs, digital projects information or crowdsourced information from another projects like Wikipedia. This paper reports a process for publishing library metadata on the Web using Linked Data technologies. The proposed process was applied for extracting metadata from a university library, representing them in RDF format and publishing them using a Sparql <b>endpoint</b> (an <b>interface</b> to a knowledge database). The library metadata from a subject were linked to external sources such us another libraries and then related to the bibliography from syllabus of the courses in order to discover missing subjects and new or out of date bibliography. In this process, the use of open standards facilitates the exploitation of knowledge from libraries. This research has been partially supported by the Prometeo project by SENESCYT, Ecuadorian Government, by CEDIA (Consorcio Ecuatoriano para el Desarrollo de Internet Avanzado) supporting the project: “Platform for publishing library bibliographic resources using Linked Data technologies” and by the project GEODAS-BI (TIN 2012 - 37493 -C 03 - 03) supported by the Ministry of Economy and Competitiveness of Spain (MINECO) ...|$|R
40|$|Abstract Background Biomarker 2 ̆ 01 d, a merged word of 2 ̆ 01 cbiological marker 2 ̆ 01 d, {{refers to}} a broad {{subcategory}} of medical signs that objectively indicate the state of health, and well-being of an individual. Biomarkers hold great promise for personalized medicine as information gained from diagnostic or progression markers {{can be used to}} tailor treatment to the individual for highly effective intervention in the disease process. Optical coherence tomography (OCT) has proved useful in identifying various biomarkers in ocular and systemic diseases. Main body Spectral domain optical coherence tomography imaging-based biomarkers provide a valuable tool for detecting the earlier stages of the disease, tracking progression, and monitoring treatment response. The aim of this review article is to analyze various OCT based imaging biomarkers and their potential to be considered as surrogate endpoints for diabetic retinopathy, age related macular degeneration, retinitis pigmentosa and vitreomacular interface disorder. These OCT based surrogate markers have been classified as retinal structural alterations (macular central subfield thickness and cube average thickness); retinal ultrastructural alterations (disruption of external limiting membrane and ellipsoid zone, thinning of retinal nerve fiber layer and ganglion cell layer); intraretinal microangiopathic changes; choroidal surrogate endpoints; and vitreoretinal <b>interface</b> <b>endpoints.</b> Conclusion OCT technology is changing very quickly and throughout this review there are some of the multiple possibilities that OCT based imaging biomarkers will be more useful in the near future for diagnosis, prognosticating disease progression and as endpoint in clinical trials...|$|R
40|$|This {{document}} {{outlines the}} end-to-end protocol {{between the various}} entities in the tetherless computing architecture (TCA), which together allow secure communication in complex environments, while achieving the requirements listed above. The main agents in this protocol are the mobile <b>endpoint,</b> the access-point <b>interface,</b> mobile contacts, DHT nodes, i 3 servers, and DTN nodes. 2. Acronyms APS (Access-point Server) This server runs at the access-point. It provides an authentification service controls access of the network by mobile endpoints. It also maintains a list of local DTN nodes and/or i 3 servers that it propagates to connecting endpoints. CM (Connection Manager) This module runs on the mobile endpoint, and handles many functions related the connected state of that endpoint and its location. DTN (Delay Tolerant Networking) An infrastructure which allows for robust, asynchronous messaging between endpoints in a delay-prone networking environment [2]. DHT (Distributed Hash Table) A decentralized mechanism for associating keys with values and allowing remotely-initiated queries [4]. DHT-AM (DHT Addressing Manager) This module acts as an interface between DTN and the DHT. Specifically, it resolves an address for the DTN layer by querying the DHT. DTN-MM (DTN Mobility Manager) This module deals with inserting keys into the i 3 overlay and ensuring that bundles are transferred from the incumbent custody DTN node. i 3 (Internet Indirection Infrastructure) An infrastructure that provides mobile transparency for communicating endpoints in the Internet [3]. IDM (Identity Manager) This module runs on the mobile endpoint. It communicates with the APS to provide secure access to networks. CL (Client Library) This library will provide application-level functionality. For example, [...] ...|$|R

