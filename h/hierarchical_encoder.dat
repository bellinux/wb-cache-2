3|9|Public
40|$|Abstract. In {{this paper}} a scheme for {{utilizing}} shape inde-pendent basis functions for a hierarchical multiresolution image compression is shown. First, an image is segmented and its segments ' boundaries are polygon approximated, thus achieving an image mask. Second, this image mask {{and the image}} are used as an input of a three-level <b>hierarchical</b> <b>encoder.</b> The <b>hierarchical</b> <b>encoder</b> sub-samples the image and the image mask and encodes them shape independently; it produces an output bit stream on a respective level that is also used on lower level(s) for further coding. On the base level a triangulation of the image mask is performed for superior performance. Another compression mode is, hence, introduced for the shape independent transform coding...|$|E
40|$|In {{this paper}} we present an {{extension}} of our previously described neural machine translation based system for punctuated transcription. This extension allows the system to map from per frame acoustic features to word level representations by replacing the traditional encoder in the encoder-decoder architecture with a <b>hierarchical</b> <b>encoder.</b> Furthermore, we show that a system combining lexical and acoustic features significantly outperforms systems using only a single source of features on all measured punctuation marks. The combination of lexical and acoustic features achieves a significant improvement in F-Measure of 1. 5 absolute over the purely lexical neural machine translation based system...|$|E
40|$|AZNract-Thk paper {{describes}} a 288 -kb (8 K words X 36 b) fully parallel {{content addressable memory}} (CAM) LSI using a compact dynamic CAM cell with a stacked-capacitor structure and a novel <b>hierarchical</b> priority <b>encoder.</b> The stacked-capacitor structure results in a very compact dynamic CAM cell (66 pmz) which is operationally stable. The novel <b>hierarchical</b> priority <b>encoder</b> reduces the circuit area and power dissipation. In addition, a new priority decision circuit is introduced. The chip size is 10. 3 X 12. 0 mmz using a 0. 8 -~m CMOS process technology. A typical search cycle time of 150 ns and a maximum power dksipation of 1. 1 W have been obtained using circuit simulation. In fabricated CAM chips, we have verified {{the performance of a}} search operation at a 170 -ns cycle and have achieved a typical read/write cycle time of 120 ns. This CAM LSI performs large-scale search operations very efficiently, an...|$|R
40|$|Traditional {{approaches}} to extractive summarization {{rely heavily on}} human-engineered features. In this work we propose a data-driven approach based on neural networks and continuous sentence features. We develop a general framework for single-document summarization composed of a <b>hierarchical</b> document <b>encoder</b> and an attention-based extractor. This architecture allows us to develop different classes of summarization models which can extract sentences or words. We train our models on large scale corpora containing {{hundreds of thousands of}} document-summary pairs. Experimental results on two summarization datasets demonstrate that our models obtain results comparable to {{the state of the art}} without any access to linguistic annotation. Comment: ACL 2016 conference paper with appendi...|$|R
40|$|Most {{extractive}} summarization methods {{focus on}} {{the main body of}} the document from which sentences need to be extracted. However, the gist of the document may lie in side information, such as the title and image captions which are often available for newswire articles. We propose to explore side information in the context of single-document extractive summarization. We develop a framework for single-document summarization composed of a <b>hierarchical</b> document <b>encoder</b> and an attention-based extractor with attention over side information. We evaluate our model on a large scale news dataset. We show that extractive summarization with side information consistently outperforms its counterpart that does not use any side information, in terms of both informativeness and fluency. Comment: 9 page...|$|R
40|$|Even {{though a}} linguistics-free {{sequence}} to sequence model in {{neural machine translation}} (NMT) has certain capability of implicitly learning syntactic information of source sentences, this paper shows that source syntax can be explicitly incorporated into NMT effectively to provide further improvements. Specifically, we linearize parse trees of source sentences to obtain structural label sequences. On the basis, we propose three different sorts of encoders to incorporate source syntax into NMT: 1) Parallel RNN encoder that learns word and label annotation vectors parallelly; 2) <b>Hierarchical</b> RNN <b>encoder</b> that learns word and label annotation vectors in a two-level hierarchy; and 3) Mixed RNN encoder that stitchingly learns word and label annotation vectors over sequences where words and labels are mixed. Experimentation on Chinese-to-English translation demonstrates that all the three proposed syntactic encoders are able to improve translation accuracy. It {{is interesting to note}} that the simplest RNN encoder, i. e., Mixed RNN encoder yields the best performance with an significant improvement of 1. 4 BLEU points. Moreover, an in-depth analysis from several perspectives is provided to reveal how source syntax benefits NMT. Comment: Accepted by ACL 201...|$|R
40|$|Image {{and video}} {{compression}} {{is becoming increasingly}} popular {{with the advent of}} broadband networks, high powered workstations, and compression standards. Compared to the traditional spatial domain techniques, the compressed domain techniques in a reduced computational complexity and storage requirements. In addition, significant processing speedup may be gained because of the lower data rate in the compressed domain. In this thesis, we have proposed two novel techniques, namely format compatible (FC) DCT and format modified (FM) DCT to implement image/video spatial scalability by operating directly on the DCT compressed data. The FC-DCT technique can be used to manipulate the standard bit streams, which maintains the formats of the processed bit streams. We have implemented the JPEG DCT domain <b>hierarchical</b> mode <b>encoder</b> based on the FC-DCT technique. On the other hand, the FM-DCT technique is simpler and has a significantly lower computational complexity. Hence, the FC-DCT and FM-DCT techniques can be chosen based on the specific needs of the applications. We note that the FC-DCT and FM-DCT techniques are not directly applicable for manipulations of video data due to the requirement of motion estimation/compensation procedure in addition to DCT coding. Hence, we propose a macroblock type selective (MTS) encoder to implement scalable MPEG video coding using a combined FC-DCT and modified DCT domain motion compensation technique. The proposed encoder provides an elegant way to re-encode the scaled video while maintaining a good video quality. In addition. it is compatible with the standard MPEG encoder. (Abstract shortened by UMI. ...|$|R
40|$|We {{introduce}} {{the task of}} Visual Dialog, which requires an AI agent to hold a meaningful dialog with humans in natural, conversational language about visual content. Specifically, given an image, a dialog history, and {{a question about the}} image, the agent has to ground the question in image, infer context from history, and answer the question accurately. Visual Dialog is disentangled enough from a specific downstream task so as to serve as a general test of machine intelligence, while being grounded in vision enough to allow objective evaluation of individual responses and benchmark progress. We develop a novel two-person chat data-collection protocol to curate a large-scale Visual Dialog dataset (VisDial). VisDial v 0. 9 has been released and contains 1 dialog with 10 question-answer pairs on ~ 120 k images from COCO, with a total of ~ 1. 2 M dialog question-answer pairs. We introduce a family of neural encoder-decoder models for Visual Dialog with 3 encoders [...] Late Fusion, <b>Hierarchical</b> Recurrent <b>Encoder</b> and Memory Network [...] and 2 decoders (generative and discriminative), which outperform a number of sophisticated baselines. We propose a retrieval-based evaluation protocol for Visual Dialog where the AI agent is asked to sort a set of candidate answers and evaluated on metrics such as mean-reciprocal-rank of human response. We quantify gap between machine and human performance on the Visual Dialog task via human studies. Putting it all together, we demonstrate the first 'visual chatbot'! Our dataset, code, trained models and visual chatbot are available on [URL] 23 pages, 18 figures, CVPR 2017 camera-ready, results on VisDial v 0. 9 dataset, Webpage: [URL]...|$|R
40|$|Over the lastd ecad es, {{improvements}} in CPU speed have outpaced {{improvements in}} main memory and d isk access rates by ord ers of magnitud, enabling the use ofd ata compression techniques {{to improve the}} performance ofd atabase systems. Previous work d scribes the benefits of compression for numerical attributes, whered 8 a is stored in compressed format ond isk. Despite the abund 3 & e of stringvalued attributes in relational schemas there is little work on compression for string attributes in ad atabase context. Moreover, none of the previous work suitablyad 2 esses {{the role of the}} query optimizer: During query execution, dD a is either eagerly d compressed when it is read into main memory, or dD a lazily stays compressed in main memory and is d compressed ond emand only. In this paper, we present an e#ective approach for dD abase compression based on lightweight, attribute-level compression techniques. We propose a <b>Hierarchical</b> ictionary <b>Encod</b> ing strategy that intelligently selects the most e#ective compression method for string-valued attributes. We show that eager and lazy d compression strategies prod 1 e suboptimal plans for queries involving compressed string attributes. We then formalize the problem of compressionaware query optimizationand propose one provably optimal and two fast heuristic algorithms for selecting a query plan for relational schemas with compressed attributes; our algorithms can easily be integrated into existing cost-based query optimizers. Experiments using TPC-Hd atad emonstrate the impact of our string compression method s and show the importance of compression-aware query optimization. Our approach results in up to an or d r speed up over existing approaches. 1...|$|R
40|$|Recent {{advances}} in conversational systems {{have changed the}} search paradigm. Traditionally, a user poses a query to a search engine that returns an answer based on its index, possibly leveraging external knowledge bases and conditioning the response on earlier interactions in the search session. In a natural conversation, there is an additional source of information to take into account: utterances produced earlier in a conversation can also be referred to and a conversational IR system has {{to keep track of}} information conveyed by the user during the conversation, even if it is implicit. We argue that the process of building a representation of the conversation can be framed as a machine reading task, where an automated system is presented with a number of statements about which it should answer questions. The questions should be answered solely by referring to the statements provided, without consulting external knowledge. The time is right for the information retrieval community to embrace this task, both as a stand-alone task and integrated in a broader conversational search setting. In this paper, we focus on machine reading as a stand-alone task and present the Attentive Memory Network (AMN), an end-to-end trainable machine reading algorithm. Its key contribution is in efficiency, achieved by having an <b>hierarchical</b> input <b>encoder,</b> iterating over the input only once. Speed is an important requirement in the setting of conversational search, as gaps between conversational turns have a detrimental effect on naturalness. On 20 datasets commonly used for evaluating machine reading algorithms we show that the AMN achieves performance comparable to the state-of-the-art models, while using considerably fewer computations...|$|R
40|$|Recently, deep {{learning}} approach, especially deep Convolutional Neural Networks (ConvNets), have achieved overwhelming accuracy with fast processing speed for image classification. Incorporating temporal structure with deep ConvNets for video representation becomes a fundamental problem for video content analysis. In this paper, we propose a new approach, namely <b>Hierarchical</b> Recurrent Neural <b>Encoder</b> (HRNE), to exploit temporal information of videos. Compared to recent video representation inference approaches, this paper makes {{the following three}} contributions. First, our HRNE is able to efficiently exploit video temporal structure in a longer range by reducing the length of input information flow, and compositing multiple consecutive inputs at a higher level. Second, computation operations are significantly lessened while attaining more non-linearity. Third, HRNE is able to uncover temporal transitions between frame chunks with different granularities, i. e., it can model the temporal transitions between frames {{as well as the}} transitions between segments. We apply the new method to video captioning where temporal information plays a crucial role. Experiments demonstrate that our method outperforms the state-of-the-art on video captioning benchmarks. Notably, even using a single network with only RGB stream as input, HRNE beats all the recent systems which combine multiple inputs, such as RGB ConvNet plus 3 D ConvNet...|$|R

