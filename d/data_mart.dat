207|168|Public
25|$|Before {{data mining}} {{algorithms}} can be used, a target data set must be assembled. As data mining can only uncover patterns actually {{present in the}} data, the target data set must {{be large enough to}} contain these patterns while remaining concise enough to be mined within an acceptable time limit. A common source for data is a <b>data</b> <b>mart</b> or data warehouse. Pre-processing is essential to analyze the multivariate data sets before data mining. The target set is then cleaned. Data cleaning removes the observations containing noise and those with missing data.|$|E
2500|$|Business {{intelligence}} software {{is a type}} of application software designed to retrieve, analyze, transform and report data for business intelligence. [...] The applications generally read data that have been previously stored, often, though not necessarily, in a data warehouse or <b>data</b> <b>mart.</b>|$|E
2500|$|... eBay uses {{a system}} that allows {{different}} departments in the company to check out data from their <b>data</b> <b>mart</b> into sandboxes for analysis. According to Goul, eBay has already experienced significant business successes through its data analytics. eBay employs 5,000 data analysts to enable data-driven decision making.|$|E
50|$|Types of <b>data</b> <b>marts</b> include dependent, independent, and hybrid <b>data</b> <b>marts.</b>|$|R
40|$|We {{address the}} problem of {{integrating}} a federation of dimensional <b>data</b> <b>marts.</b> This problem arises when, e. g., a large organization (or a federation thereof) needs to combine independently developed data warehouses. We show that this problem can be tackled in a systematic way because of two main reasons. First, <b>data</b> <b>marts</b> are structured in a rather uniform way, along dimensions and facts. Second, data quality in <b>data</b> <b>marts</b> is usually higher than in generic databases, since they are obtained by reconciling several data sources. Our scenario of reference is a federation (i. e., a logical integration) of various <b>data</b> <b>marts,</b> which we need to query in a unified way, that is, by means of drill-across operations. We propose a novel notion of dimension compatibility and characterize its general property. We then show the significance of dimension compatibility in performing drill-across queries over autonomous <b>data</b> <b>marts.</b> We also discuss general strategies for the integration of <b>data</b> <b>marts.</b> 1...|$|R
40|$|The {{problem of}} {{integrating}} autonomous <b>data</b> <b>marts</b> arises when, e. g., a large organization (or a federation thereof) needs to combine independently developed data warehouses. It {{turns out that}} this problem can be tackled in a systematic way because of two main reasons. First, <b>data</b> <b>marts</b> are usually structured in a rather uniform way, along dimensions and facts. Second, data quality in <b>data</b> <b>marts</b> is usually higher than in generic databases, since they are obtained by reconciling several data sources. Our scenario of reference is a federation of various <b>data</b> <b>marts</b> {{that we need to}} query in a unified way by means of drill-across operations. We propose a novel notion of dimension compatibility and characterize its general properties. We then show the significance of dimension compatibility in performing drill-across queries over autonomous <b>data</b> <b>marts...</b>|$|R
2500|$|... "For data {{warehouse}} and <b>data</b> <b>mart</b> applications, CoSort performs source data extraction, data cleansing, sorting, reformatting, data type conversion, aggregation, and indexing, {{all in a}} single pass. Most operational data in commercial and public sector enterprises reside internally in sequential flat files, (relational) database tables, or are imported from data tapes and transmissions generated externally. These historical databases are optimized for ad hoc queries and transactions, rather than for extraction. CoSort accepts multiple input files (large-scale tables or flat-file data dumps), or records streaming through pipes, to perform conditional selection on records for downstream processes." [...] - Dennis Hill, Database Trends Magazine, July 1999 ...|$|E
5000|$|... #Subtitle level 3: SAP IQ as an Enterprise Data Warehouse (EDW) with SAP HANA as Agile <b>Data</b> <b>Mart</b> ...|$|E
5000|$|A <b>data</b> <b>mart</b> is {{the access}} {{layer of the}} data {{warehouse}} environment {{that is used to}} get data out to the users. The <b>data</b> <b>mart</b> is a subset of the data warehouse and is usually oriented to a specific business line or team. Whereas data warehouses have an enterprise-wide depth, the information in data marts pertains to a single department. In some deployments, each department or business unit is considered the owner of its <b>data</b> <b>mart</b> including all the hardware, software and data. [...] This enables each department to isolate the use, manipulation and development of their data. In other deployments where conformed dimensions are used, this business unit ownership will not hold true for shared dimensions like customer, product, etc.|$|E
5000|$|In the {{bottom-up}} approach, <b>data</b> <b>marts</b> {{are first}} created to provide reporting and analytical capabilities for specific business processes. These <b>data</b> <b>marts</b> {{can then be}} integrated to create a comprehensive data warehouse. The data warehouse bus architecture is primarily an implementation of [...] "the bus", a collection of conformed dimensions and conformed facts, which are dimensions that are shared (in a specific way) between facts in two or more <b>data</b> <b>marts.</b>|$|R
40|$|Data {{warehouses}} are databases {{devoted to}} analytical processing. They {{are used to}} support decision-making activities in most modern business settings, when complex data sets have to be studied and analyzed. The technology for analytical processing assumes that data are presented {{in the form of}} simple <b>data</b> <b>marts,</b> consisting of a well-identified collection of facts and data analysis dimensions (star schema). Despite the wide diffusion of data warehouse technology and concepts, we still miss methods that help and guide the designer in identifying and extracting such <b>data</b> <b>marts</b> out of an enterprisewide information system, covering the upstream, requirement-driven stages of the design process. Many existing methods and tools support the activities related to the efficient implementation of <b>data</b> <b>marts</b> on top of specialized technology (such as the ROLAP or MOLAP data servers). This paper presents a method to support the identification and design of <b>data</b> <b>marts.</b> The method is based on three basic steps. A first top-down step makes it possible to elicit and consolidate user requirements and expectations. This is accomplished by exploiting a goal-oriented process based on the Goal/Question/Metric paradigm developed at the University of Maryland. Ideal <b>data</b> <b>marts</b> are derived from user requirements. The second bottom-up step extracts candidate <b>data</b> <b>marts</b> The editorial processing for this paper was managed by Axel van Lamsweerde...|$|R
50|$|<b>Data</b> <b>Marts</b> Builder NEVOD {{a product}} of RELEX Group, created in 1996.|$|R
5000|$|In this Data Warehouse or <b>Data</b> <b>Mart</b> strategy, the partial/common table {{found in}} every MDB file {{is not a}} split table nor a linked table.|$|E
5000|$|Regarding data integration, Rainer states, [...] "It is {{necessary}} to extract data from source systems, transform them, and load them into a <b>data</b> <b>mart</b> or warehouse".|$|E
50|$|A spreadmart (spreadsheet <b>data</b> <b>mart)</b> is a {{business}} data analysis system running on spreadsheets or other desktop databases that is created and maintained by individuals or groups to perform the tasks normally done by a <b>data</b> <b>mart</b> or data warehouse. Typically a spreadmart is created by individuals at different times using different data sources and rules for defining metrics in an organization, creating a fractured view of the enterprise. The concept was coined in 2002 by Wayne Eckerson at TDWI in his article Taming Spreadsheet Jockeys.|$|E
50|$|Rainer {{discusses}} storing data in an organization's {{data warehouse}} or <b>data</b> <b>marts.</b>|$|R
5000|$|... 1970s - ACNielsen and IRI provide {{dimensional}} <b>data</b> <b>marts</b> for retail sales.|$|R
40|$|The Data Warehouse Bus Architecture is {{composed}} of &quot;a master suite of conformed dimensions &quot; and standardized definitions of facts. [1, P. 156] Business process <b>data</b> <b>marts</b> throughout an enterprise can &quot;plug into &quot; this bus to receive the dimension and fact tables they need. The Bus thus supports the various processes and associated <b>data</b> <b>marts</b> that measure key aspects of the processes...|$|R
50|$|Performance: {{to offload}} the <b>data</b> <b>mart</b> to a {{separate}} computer for greater efficiency or to eliminate the need to manage that workload on the centralized data warehouse.|$|E
5000|$|Microsoft Excel (COM/OLE) Automation, {{driven by}} an ODBC-enabled {{application}} program, would be one technique to create formatted reports directly from this Data Warehouse / <b>Data</b> <b>Mart</b> repository.|$|E
50|$|A <b>data</b> <b>mart</b> is {{basically}} a condensed and more focused version of a data warehouse that reflects the regulations and process specifications of each business unit within an organization. Each <b>data</b> <b>mart</b> is dedicated to a specific business function or region. This subset of data may span across many or all of an enterprise’s functional subject areas. It is common for multiple data marts {{to be used in}} order to serve the needs of each individual business unit (different data marts can be used to obtain specific information for various enterprise departments, such as accounting, marketing, sales, etc.).|$|E
5000|$|... {{inventories}} of information assets (including legacy and relational data sources, cubes, data warehouses, and <b>data</b> <b>marts),</b> ...|$|R
40|$|Traffic Simulation models tend to {{have their}} own data input and output formats. In an effort to {{standardise}} the input for traffic simulations, we introduce in this paper a set of <b>data</b> <b>marts</b> that aim to serve as a common interface between the necessaary data, stored in dedicated databases, and the swoftware packages, that require the input in a certain format. The <b>data</b> <b>marts</b> are developed based on real world objects (e. g. roads, traffic lights, controllers) rather than abstract models and hence contain all necessary information that can be transformed by the importing software package to their needs. The paper contains a full description of the <b>data</b> <b>marts</b> for network coding, simulation results, and scenario management, which have been discussed with industry partners to ensure sustainability...|$|R
5000|$|Acquires Leonard's Logics SA, of Paris, France, {{makers of}} Genio, a data {{transformation}} and exchange tool (ETL) for deployment of <b>data</b> <b>marts.</b>|$|R
5000|$|According to the Inmon {{school of}} data warehousing, a {{dependent}} <b>data</b> <b>mart</b> {{is a logical}} subset (view) or a physical subset (extract) of a larger data warehouse, isolated {{for one of the}} following reasons: ...|$|E
50|$|Intermediate {{storage area}} between the sources of {{information}} and the data warehouse (DW) or <b>Data</b> <b>mart</b> (DM). It is usually of temporary nature, and its contents can be erased after the DW/DM has been loaded successfully.|$|E
50|$|Business {{intelligence}} software {{is a type}} of application software designed to retrieve, analyze, transform and report data for business intelligence. The applications generally read data that have been previously stored, often, though not necessarily, in a data warehouse or <b>data</b> <b>mart.</b>|$|E
5000|$|... eCRM - Geared {{more toward}} front end, which {{interacts with the}} {{back-end}} through use of ERP systems, data warehouses, and <b>data</b> <b>marts.</b>|$|R
40|$|Data {{warehouses}} become {{large in}} size, dynamic, and physically distributed. In this context, federated data warehousing {{approach is a}} promising solution for specifying, designing, deploying as well as managing <b>data</b> <b>marts</b> and their <b>data</b> cubes. In this paper, the Federated Data warehousing Application (FDWA) framework {{has been used to}} specify global-scale <b>data</b> <b>marts.</b> To proof of our concepts, a global-scale analytical tool, namely GAINS-IAM (integrated assess model) will be presented as a case study to analyze recent trends and future world emission scenarios...|$|R
40|$|Organizations {{have been}} used {{decisions}} support systems to help them to understand and to predict interesting business opportunities over their huge databases also known as <b>data</b> <b>marts.</b> OLAP tools {{have been used}} widely for retrieving information in a summarized way (cube-like) by employing customized cubing methods. The majority of these cubing methods suffer from being just data-driven oriented and not discovery-driven ones. <b>Data</b> <b>marts</b> grow quite fast, so an incremental OLAP mining process is a required and desirable solution for mining evolving cubes. In order to present a solution that covers the previous mentioned issues, we propose a cube-based mining method which can compute an incremental cube, handling concept hierarchy modeling, as well as, incremental mining of multidimensional and multilevel association rules. The evaluation study using real and synthetic datasets demonstrates that our approach is an effective OLAP mining method of evolving <b>data</b> <b>marts.</b> 1...|$|R
5000|$|Often BI {{applications}} use {{data gathered}} from a data warehouse (DW) {{or from a}} <b>data</b> <b>mart,</b> and the concepts of BI and DW combine as [...] "BI/DW"or as [...] "BIDW". A data warehouse contains a copy of analytical data that facilitates decision support.|$|E
5000|$|... eBay uses {{a system}} that allows {{different}} departments in the company to check out data from their <b>data</b> <b>mart</b> into sandboxes for analysis. According to Goul, eBay has already experienced significant business successes through its data analytics. eBay employs 5,000 data analysts to enable data-driven decision making.|$|E
50|$|In computing, {{the star}} schema is the {{simplest}} style of <b>data</b> <b>mart</b> schema {{and is the}} approach most widely used to develop data warehouses and dimensional data marts. The star schema consists {{of one or more}} fact tables referencing any number of dimension tables. The star schema is an important special case of the snowflake schema, and is more effective for handling simpler queries.|$|E
40|$|SAS ® Data Integration Studio {{is a great}} {{tool for}} {{building}} and maintaining data warehouses and <b>data</b> <b>marts.</b> The performance of the extract, transform, and load (ETL) job is critical for building data warehouses and <b>data</b> <b>marts.</b> This paper discusses the time-consuming data transformations related to ETL processes in SAS Data Integration Studio. The performance for each data transformation is benchmarked and compared. The best solutions to speed up ETL job performance are discussed in detail. The paper also suggests the best practices for designing efficient ETL jobs...|$|R
40|$|Abstract. Federated Data Warehouses {{integrate}} autonomous <b>Data</b> <b>Marts</b> across organization boundaries at {{the logical}} schema level. The federated architecture provides advantages for both, OLAP users and Data Warehouse administrators. On the one hand, users comfortably access a global, mediated schema with OLAP applications. On the other hand, administrators need not adapt the <b>Data</b> <b>Marts</b> lo-cally, and retain full autonomy for schema and data management. This user man-ual explains {{the prototype of}} “FedDW Global Schema Architect ” (GSA), a vi-sual design tool for integrated schemas of dimensions and facts over autonomous ROLAP <b>Data</b> <b>Marts.</b> GSA provides a model-driven design environment with ex-tended UML package diagrams and predefined, context-sensitive conversion op-erators. GSA’s implementation employs the extension mechanisms of Eclipse and the well-known UML and CWM (Common Warehouse Metamodel) standards. Thus, the tool is extensible, intuitive for its users, and supports DW platforms of multiple vendors. Besides sketching the concepts behind GSA, we explain GSA’s functionality and demonstrate the schema integration process with a use-case. ...|$|R
50|$|Organizations build data {{warehouses}} and <b>data</b> <b>marts</b> because {{the information in}} the database is not organized {{in a way that makes}} it readily accessible, requiring queries that are too complicated or resource-consuming.|$|R
