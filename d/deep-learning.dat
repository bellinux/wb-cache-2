194|12|Public
25|$|In August 2016, Intel {{purchased}} <b>deep-learning</b> startup Nervana Systems for $350 million.|$|E
25|$|A {{wide variety}} of {{platforms}} has allowed different aspects of AI to develop, ranging from expert systems such as Cyc to <b>deep-learning</b> frameworks to robot platforms such as the Roomba with open interface. Recent advances in deep artificial neural networks and distributed computing {{have led to a}} proliferation of software libraries, including Deeplearning4j, TensorFlow, Theano and Torch.|$|E
2500|$|Will {{is among}} those advocating that China needs to focus {{intensely}} on AI. Speaking to government officials and administrators in May, he said {{the first half of}} the internet age—in which companies raced to connect computing machines with people—has finished. [...] "The second half is about artificial intelligence," [...] he said. DiDi has established a big data research center to focus on AI technologies including machine learning and computer vision, which will optimize its dispatch system and route planning. A few hundred scientists work on the <b>deep-learning</b> technologies. At this stage, Will said that the company is investing a lot of resources in research and is keen to recruit and retain top talent to build its self-driving cars and to make itself become one of the top technology companies in the world.|$|E
5000|$|Link the key {{ideas of}} a subject and then <b>deep-learn</b> those key ideas in {{relation}} to each other, and ...|$|R
40|$|Visual {{features}} are of vital importance for human action understanding in videos. This paper presents a new video representation, called trajectory-pooled deep-convolutional descriptor (TDD), which shares {{the merits of}} both hand-crafted features [31] and <b>deep-learned</b> features [24]. Specifically, we utilize deep architectures to learn discrimi-native convolutional feature maps, and conduct trajectory-constrained pooling to aggregate these convolutional fea-tures into effective descriptors. To enhance the robustness of TDDs, we design two normalization methods to trans-form convolutional feature maps, namely spatiotemporal normalization and channel normalization. The advantages of our features come from (i) TDDs are automatically learned and contain high discriminative capacity compared with those hand-crafted features; (ii) TDDs {{take account of the}} intrinsic characteristics of temporal dimension and introduce the strategies of trajectory-constrained sampling and pooling for aggregating <b>deep-learned</b> features. We conduct experiments on two challenging datasets: HMD-B 51 and UCF 101. Experimental results show that TDDs outperform previous hand-crafted features [31] and <b>deep-learned</b> features [24]. Our method also achieves superior performance to {{the state of the art}} on these datasets 1...|$|R
50|$|English, mathematics, and {{informatics}} are <b>deep-learned</b> subjects. The English language {{program of}} the lyceum includes instructions on English reading, grammar, writing, and speaking skills. In line with the national maths program, the students learn additional materials on higher mathematics {{as well as some}} part of logic. During informatics classes, the students gain technological knowledge on programming, PC security, work with graphic editors, on-line resources etc.|$|R
50|$|In August 2016, Intel {{purchased}} <b>deep-learning</b> startup Nervana Systems for $350 million.|$|E
5000|$|Deeplearning4j—An {{open-source}} <b>deep-learning</b> library {{written for}} Java/C++ with LSTMs and convolutional networks. It provides parallelization with Spark on CPUs and GPUs.|$|E
5000|$|Microsoft CNTK (Computational Network Toolkit)—Microsoft's {{open-source}} <b>deep-learning</b> toolkit for Windows and Linux. It provides parallelization with CPUs and GPUs {{across multiple}} servers.|$|E
40|$|The {{zebrafish}} {{has become}} a popular experimental model organism for biomedical research. In this paper, a unique framework is proposed for automatically detecting Tyrosine Hydroxylase-containing (TH-labeled) cells in larval zebrafish brain z-stack images recorded through the wide-field microscope. In this framework, a supervised max-pooling Convolutional Neural Network (CNN) is trained to detect cell pixels in regions that are preselected by a Support Vector Machine (SVM) classifier. The {{results show that the}} proposed <b>deep-learned</b> method outperforms hand-crafted techniques and demonstrate its potential for automatic cell detection in wide-field microscopy z-stack zebrafish images...|$|R
40|$|We {{propose a}} {{paradigm}} to <b>deep-learn</b> the ever-expanding databases which {{have emerged in}} mathematical physics and particle phenomenology, {{as diverse as the}} statistics of string vacua or combinatorial and algebraic geometry. As concrete examples, we establish multi-layer neural networks as both classifiers and predictors and train them with a host of available data ranging from Calabi-Yau manifolds and vector bundles, to quiver representations for gauge theories. We find that even a relatively simple neural network can learn many significant quantities to astounding accuracy {{in a matter of minutes}} and can also predict hithertofore unencountered results. This paradigm should prove a valuable tool in various investigations in landscapes in physics as well as pure mathematics. Comment: 35 pages, 4 figures; code available; refs and comments added on v...|$|R
40|$|Automatic {{continuous}} time, continuous value {{assessment of}} a patient's pain from face video is highly sought after by the medical profession. Despite the recent advances in deep learning that attain impressive results in many domains, pain estimation risks {{not being able to}} benefit from this due to the difficulty in obtaining data sets of considerable size. In this work we propose a combination of hand-crafted and <b>deep-learned</b> features that makes the most of deep learning techniques in small sample settings. Encoding shape, appearance, and dynamics, our method significantly outperforms {{the current state of the}} art, attaining a RMSE error of less than 1 point on a 16 -level pain scale, whilst simultaneously scoring a 67. 3 % Pearson correlation coefficient between our predicted pain level time series and the ground truth. Comment: 8 pages, 5 figure...|$|R
50|$|Thought vector {{is a term}} {{popularized by}} Geoffrey Hinton, the {{prominent}} <b>deep-learning</b> researcher now at Google, which is using vectors based on natural language to improve its search results.|$|E
50|$|Movidius is {{a company}} based in San Mateo, California that designs {{specialised}} low-power processor chips for computer vision and <b>deep-learning.</b> It was announced {{that the company was}} to be acquired by Intel in September 2016.|$|E
50|$|Advances in {{hardware}} {{enabled the}} {{renewed interest in}} deep learning. In 2009, Nvidia was involved in {{what was called the}} “big bang” of deep learning, “as <b>deep-learning</b> neural networks were combined with Nvidia graphics processing units (GPUs).” That year, Google Brain used Nvidia GPUs to create Deep Neural Networks capable of machine learning. While there, Ng determined that GPUs could increase the speed of <b>deep-learning</b> systems by about 100 times. In particular, powerful graphics processing units (GPUs) are well-suited for the matrix/vector math involved in machine learning. GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days. Specialized hardware and algorithm optimizations can be used for efficient D processing.|$|E
40|$|Parsing {{human body}} into {{semantic}} regions {{is crucial to}} human-centric analysis. In this paper, we propose a segment-based parsing pipeline that explores human pose information, i. e. the joint location of a human model, which improves the part proposal, accelerates the inference and regularizes the parsing process at the same time. Specifically, we first generate part segment proposals with respect to human joints predicted by a deep model, then part- specific ranking models are trained for segment selection using both pose-based features and <b>deep-learned</b> part potential features. Finally, the best ensemble of the proposed part segments are inferred though an And-Or Graph. We evaluate our approach on the popular Penn-Fudan pedestrian parsing dataset, and demonstrate the effectiveness of using the pose information for each stage of the parsing pipeline. Finally, we show that our approach yields superior part segmentation accuracy comparing to the state-of-the-art methods. Comment: 12 pages, 10 figures, a shortened {{version of this paper}} was accepted by AAAI 201...|$|R
40|$|Diversity {{is one of}} the {{fundamental}} properties for the survival of species, populations, and organizations. Recent advances in deep learning allow for the rapid and automatic assessment of organizational diversity and possible discrimination by race, sex, age and other parameters. Automating the process of assessing the organizational diversity using the deep neural networks and eliminating the human factor may provide a set of real-time unbiased reports to all stakeholders. In this pilot study we applied the <b>deep-learned</b> predictors of race and sex to the executive management and board member profiles of the 500 largest companies from the 2016 Forbes Global 2000 list and compared the predicted ratios to the ratios within each company's country of origin and ranked them by the sex-, age- and race- diversity index (DI). While the study has many limitations and no claims are being made concerning the individual companies, it demonstrates a method for the rapid and impartial assessment of organizational diversity using deep neural networks...|$|R
40|$|This paper {{presents}} {{our work}} on "SNaCK," a low-dimensional concept embedding algorithm that combines human expertise with automatic machine similarity kernels. Both parts are complimentary: human insight can capture relationships {{that are not}} apparent from the object's visual similarity and the machine can help relieve the human from having to exhaustively specify many constraints. We show that our SNaCK embeddings are useful in several tasks: distinguishing prime and nonprime numbers on MNIST, discovering labeling mistakes in the Caltech UCSD Birds (CUB) dataset {{with the help of}} <b>deep-learned</b> features, creating training datasets for bird classifiers, capturing subjective human taste on a new dataset of 10, 000 foods, and qualitatively exploring an unstructured set of pictographic characters. Comparisons with the state-of-the-art in these tasks show that SNaCK produces better concept embeddings that require less human supervision than the leading methods. Comment: To appear at ICCV 2015. (This version has updated author affiliations and updated footnotes. ...|$|R
5000|$|In an {{interview}} regarding the Council’s {{discussions on the}} intersection of artificial intelligence and nuclear security, <b>deep-learning</b> artificial intelligence expert and Helena member Nikhil Buduma described “an effort to design a new framework around how we think about rogue actors, second strike systems, and highly automated search and destroy operations.” ...|$|E
5000|$|Jean {{released}} her first book, DiDi: sharing economy is changing China'''', co-authored by Cheng Wei and Zhang Xiaofeng, {{the founder of}} [...] "Internet Plus Club" [...] and published by Posts & Telecom Press in June 2016. It is about how DiDi's use data-driven <b>deep-learning</b> algorithms drives the new era of economy and technology.|$|E
5000|$|Theano: The {{reference}} <b>deep-learning</b> {{library for}} Python with an API largely {{compatible with the}} popular NumPy library. Allows user to write symbolic mathematical expressions, then automatically generates their derivatives, saving the user from having to code gradients or backpropagation. These symbolic expressions are automatically compiled to CUDA code for a fast, on-the-GPU implementation.|$|E
40|$|We {{present an}} {{efficient}} deep learning technique {{for the model}} reduction of the Navier-Stokes equations for unsteady flow problems. The proposed technique relies on the Convolutional Neural Network (CNN) and the stochastic gradient decent method. Of particular interest is to predict the unsteady fluid forces for different bluff body shapes at low Reynolds number. The discrete convolution process with a non-linear rectification is employed to approximate the mapping between the bluff-body shape and the fluid forces. The deep neural network is fed by the Euclidean distance function as the input and the target data generated by the full-order Navier-Stokes computations for primitive bluff body shapes. The convolutional networks are iteratively trained using the stochastic gradient descent method with the momentum term to predict the fluid force coefficients of different geometries {{and the results are}} compared with the full-order computations. We also attempt to provide a physical analogy of the stochastic gradient method with the momentum term with the simplified form of the incompressible Navier-Stokes momentum equation. A systematic convergence and sensitivity study is performed to identify the effective dimensions of the <b>deep-learned</b> CNN process such as the convolution kernel size, the number of kernels and the convolution layers. Within the error threshold, the prediction based on our deep convolutional network has a speed-up nearly three orders of magnitude compared to the full-order results and consumes an insignificant fraction of computational resources. The proposed CNN-based approximation procedure has a profound impact on the parametric design of bluff bodies and the feedback control of separated flows. Comment: 46 pages, 10 figure...|$|R
40|$|English is now {{the primary}} {{language}} used amongst speakers {{from around the world}} for international communication. In response to this fact, there are calls for a paradigm shift in English language teaching (ELT) in respect of the increasing English users who speak English as an international language (EIL). For more than two decades, there have been heated debates and discussions concerning EIL teaching with issues such as standards and norms of EIL, ownership of EIL and identity of EIL users, culture(s) in EIL, etc [...] With Taiwan's cultural politics background, English has long been portrayed and perceived as a prestigious foreign language which represents a passport to better economic gains, education, and social status. This perception of English has not only brought about a phenomenon of English fever, but also endorsed an economic pragmatic view in learning English as an international language. Consequently, it has reinforced ELT practices to aim at preparing learners of English for 'being competitive' instead of 'understanding of others’. Based on an educational philosophy that today's English language teaching should prepare learners as world citizens instead of global human capital, the purpose of this action research project is to provide an intercultural communicative way of teaching English. A total of 42 part-time technical college students and a teacher researcher in Taipei were involved in investigating the desirability and feasibility of such ELT pedagogy. Under a theme of 'A Visit from our Sister College', nine lessons were taught with cultural topics like name, hometown, food, and entertainment. The findings suggest that, with some minor technical modifications needed in the future, the proposed pedagogy can help learners not only find their confidence in learning and utilising English language in their daily life but also <b>deep-learn</b> cultures of self and others. Thus, it might result the learners in becoming world citizens in a gradual/progressive manner. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|State-of-the-art object {{detection}} algorithms {{are designed}} to be heavily robust against scene and object variations like illumination changes, occlusions, scale changes, orientation differences, background clutter and object intra-class variability. However, in industrial machine vision applications, where objects with variable appearance have to be detected, many of these variations are in fact constant and can be seen as scene specific constraints on the detection problem. These scene constraints can be used to reduce the enormous search space for object candidates, and thus speed up the actual detection process and improve it’s accuracy. In this PhD we will explore the possibility to use scene specific constraints of industrial object detection tasks to influence three main aspects of object detection algorithms: 1. Reduce the amount of training data needed. We will try to reduce the required amount of manually annotated training data as much as possible. 2. Increase the speed of the detection process. Since we are working in an industrial application related context, maintaining real-time performance is a hard constraint. 3. Reduce the amount of false positive and false negative detections. We aim at building object detection algorithms that are able to detect all objects in a given image or video stream with a high certainty. Moreover, we will propose steps to simplify the training process under such scene constraints, used for creating object specific models. For this we look into techniques like active learning and data augmentation, in order to heavily reduce the amount of manual input required by the algorithm. 1 Introduction 1. 1 Problem statement 1. 2 Main contributions 1. 3 Outline of research 2 Related work 2. 1 Object detection 2. 2 Application-specific constraints 2. 3 Active learning 2. 4 Selected frameworks 2. 5 Comparing different detection algorithms 2. 5. 1 Multi-scale sliding window and non-maxima suppression 2. 5. 2 Precision-recall curves 2. 5. 3 Evaluation metric for deeply learned classification networks 3 Introducing object- and application-specific scene constraints 3. 1 Detection and classification of orchid flowers 3. 1. 1 Related work on orchid detection and classification 3. 1. 2 Orchid flower detection 3. 1. 3 Orchid type classification 3. 1. 4 Conclusions on orchid flower detection and classification 3. 2 Automated walking aid detector 3. 2. 1 Related work on walking aid detection 3. 2. 2 The setup 3. 2. 3 Complete pipeline 3. 2. 4 Quantitative detection results 3. 2. 5 Conclusions on detecting walking aids 3. 3 Safeguarding privacy by automatic face blurring 3. 3. 1 Related work on scene-constrained pedestrian detection 3. 3. 2 Datasets 3. 3. 3 Used approach 3. 3. 4 Obtained results 3. 3. 5 Conclusions on privacy safeguarding 3. 4 Conclusion: benefits of using scene constraints 4 Enhancing detection algorithms by integrating scene knowledge 4. 1 Automated visual fruit detection 4. 1. 1 Related work on visual fruit detection 4. 1. 2 Collected strawberry and apple datasets 4. 1. 3 Suggested strawberry and apple detection approach 4. 1. 4 Results 4. 1. 5 Discussion and conclusion on the fruit detection cases 4. 2 Detection of photovoltaic installations 4. 2. 1 Related work on the detection of PV installations 4. 2. 2 Datasets 4. 2. 3 Used approach 4. 2. 4 Results on the detection of photovoltaic installations 4. 2. 5 Conclusion on the detection of PV installation 4. 3 Conclusion: benefits of integrating scene constraints 5 Integrating active learning to improve industrial object detection 5. 1 Open source face detection with active learning 5. 1. 1 Why wanting to improve old OpenCV functions? 5. 1. 2 Framework and dataset 5. 1. 3 Used approach 5. 1. 4 Results after active learning 5. 1. 5 Conclusion on active learning for object detection 5. 2 Benefits, challenges and possible expansions 5. 2. 1 Advantages and challenges of active learning 5. 2. 2 Expansions 5. 3 Conclusion: benefits of using active learning 6 Usability of deep learning for industrial object detection 6. 1 Transfer learning and single-pass deep learning 6. 1. 1 Related work on deeply learned object detection 6. 1. 2 Dataset and framework 6. 1. 3 Used approach 6. 1. 4 Practical cases 6. 1. 5 Experiments and results 6. 1. 6 Discussion on transfer-learned detection models 6. 1. 7 Conclusion on transfer-learned detection model 6. 2 Boosted Cascades versus Deep Learning 6. 2. 1 Dataset and framework 6. 2. 2 Approaches with boosted cascades 6. 2. 3 Approaches with deep learning 6. 2. 4 Result 6. 2. 5 Conclusions on coconut tree detection in aerial imagery 6. 3 Conclusion: benefits of deep learning for object detection 7 Lessons learned for industrial object detection tasks 7. 1 Does the problem need object detection? 7. 2 Selecting boosted cascades or deep learning? 7. 3 The importance of the correct training data 7. 3. 1 Training data when using boosted cascades 7. 3. 2 Training data when using <b>deep-learned</b> approaches 7. 4 Algorithm specific parameters 7. 4. 1 Parameter tuning for boosted cascades 7. 4. 2 Parameter tuning for deeply learned detectors 7. 5 A conclusion on lessons learned 8 Conclusion and future work 8. 1 General conclusion on this dissertation 8. 2 Future work and possible expansions 9 Valorisation 9. 1 Implemented industrial realisations 9. 1. 1 Automated orchid detection and classification system 9. 1. 2 Strawberry picking robot 9. 2 Consultancy projects 9. 2. 1 KNFB Reader: helping blind people read 9. 2. 2 Optidrive: automation through computer vision 9. 2. 3 OneUp: automatic ticket analysis 9. 3 Workshops and symposia 9. 3. 1 Hands-on workshops for industrial object detection 9. 3. 2 First edition of the AAA Vision symposium 9. 3. 3 Deep learning workshop 9. 4 Public datasetsstatus: accepte...|$|R
50|$|A {{wide variety}} of {{platforms}} has allowed different aspects of AI to develop, ranging from expert systems such as Cyc to <b>deep-learning</b> frameworks to robot platforms such as the Roomba with open interface. Recent advances in deep artificial neural networks and distributed computing {{have led to a}} proliferation of software libraries, including Deeplearning4j, TensorFlow, Theano and Torch.|$|E
50|$|Nvidia GPUs {{are used}} in deep learning, {{artificial}} intelligence, and accelerated analytics. The company developed GPU-based deep learning {{in order to use}} artificial intelligence to approach problems like cancer detection, weather prediction, and self-driving vehicles. They are included in all Tesla vehicles. The purpose is to help networks learn to “think”. According to TechRepublic, Nvidia GPUs “work well for deep learning tasks because they are designed for parallel computing, and do well to handle the vector and matrix operations that are prevalent in deep learning.” These GPUs are used by researchers, laboratories, tech companies and enterprise companies. In 2009, Nvidia was involved in what was called the “big bang” of deep learning, “as <b>deep-learning</b> neural networks were combined with Nvidia graphics processing units (GPUs).” That year, the Google Brain used Nvidia GPUs to create Deep Neural Networks capable of machine learning, where Andrew Ng determined that GPUs could increase the speed of <b>deep-learning</b> systems by about 100 times.|$|E
50|$|Artificial Intelligence (AI): Didi has {{established}} the Didi Research Institute {{to focus on}} AI technologies including machine learning and computer vision. It hopes the technologies optimise its dispatch system and route planning. A few hundred scientists work on <b>deep-learning</b> technologies at the institute. In March 2017, DiDi launched DiDi Labs in Mountain View, California. It will mainly focus on AI-based security and intelligent driving technologies.|$|E
50|$|As of 2016, {{the firm}} has taped out a 1024-core 64-bit variant of their Epiphany architecture. This features: larger local stores (64 KB), 64-bit addressing, {{double-precision}} floating-point arithmetic or SIMD single-precision, and 64-bit integer instructions, implemented in the 16 nm process node. This design is backwards compatible (binary compatible) with earlier products. There are instruction set enhancements aimed at <b>deep-learning</b> and cryptography applications. It is a DARPA funded project.|$|E
50|$|Socialbakers Analytics gives {{customers}} insights by monitoring {{social media}} profiles on Facebook, Twitter, LinkedIn, VK, Pinterest, and YouTube (with added reports for Instagram). The software offers performance indicators to measure fan growth, track key influencers, analyze engagement rates and interactions, benchmark performance against competitors and industry standards, optimize social media presence and generate graphical reports. Socialbakers Builder {{is a tool}} for scheduling and publishing content as well as aggregating the conversation on social media around a brand. Apart from the main product Suite, Socialbakers offers several services including EdgeRank Checker, a <b>deep-learning</b> algorithm that tells users what content works best for their brand's Facebook pages, among other things.|$|E
5000|$|Paya Lebar Methodist Girls' School (Secondary) (abbreviation: PLMGSS) is an all-girls school {{located in}} Hougang, Singapore, {{running on a}} single-session {{catering}} to students in the Express, Normal Academic and Normal Technical streams. Paya Lebar Methodist Girls’ School (Primary) and Paya Lebar Methodist Girls’ School (Secondary) [...] From the school’s early humble beginnings of being a small school of just 24 students in 1900s, the school has become a school of choice, with the Primary and Secondary schools together offering a holistic education to over 3000 students. Since 1995, PLMGSS has been offering Higher Mother Tongue languages and specialised <b>deep-learning</b> programmes in Maths, Science and Aesthetics to her students.|$|E
5000|$|Will {{is among}} those advocating that China needs to focus {{intensely}} on AI. Speaking to government officials and administrators in May, he said {{the first half of}} the internet age—in which companies raced to connect computing machines with people—has finished. [...] "The second half is about artificial intelligence," [...] he said. DiDi has established a big data research center to focus on AI technologies including machine learning and computer vision, which will optimize its dispatch system and route planning. A few hundred scientists work on the <b>deep-learning</b> technologies. At this stage, Will said that the company is investing a lot of resources in research and is keen to recruit and retain top talent to build its self-driving cars and to make itself become one of the top technology companies in the world.|$|E
40|$|<b>Deep-learning</b> has {{dramatically}} {{changed the world}} overnight. It greatly boosted the development of visual perception, object detection, and speech recognition, etc. That was attributed to the multiple convolutional processing layers for abstraction of learning representations from massive data. The advantages of deep convolutional structures in data processing motivated the applications of artificial intelligence methods in robotic problems, especially perception and control system, the two typical and challenging problems in robotics. This paper presents {{a survey of the}} <b>deep-learning</b> research landscape in mobile robotics. We start with introducing the definition and development of <b>deep-learning</b> in related fields, especially the essential distinctions between image processing and robotic tasks. We described and discussed several typical applications and related works in this domain, followed by the benefits from <b>deep-learning,</b> and related existing frameworks. Besides, operation in the complex dynamic environment is regarded as a critical bottleneck for mobile robots, such as that for autonomous driving. We thus further emphasize the recent achievement on how <b>deep-learning</b> contributes to navigation and control systems for mobile robots. At the end, we discuss the open challenges and research frontiers. Comment: 16 pages, 4 figures, submit to journa...|$|E
30|$|To {{our best}} knowledge, {{this is the}} first attempt to {{introduce}} <b>deep-learning</b> methods into the image classification of the refrigerators.|$|E
40|$|Artificial {{intelligence}} is a promising futuristic concept {{in the field}} of science and technology, and is widely used in new industries. The <b>deep-learning</b> technology leads to performance enhancement and generalization of artificial intelligence technology. The global leader {{in the field of}} information technology has declared its intention to utilize the <b>deep-learning</b> technology to solve environmental problems such as climate change, but few environmental applications have so far been developed. This study uses <b>deep-learning</b> technologies in the environmental field to predict the status of pro-environmental consumption. We predicted the pro-environmental consumption index based on Google search query data, using a recurrent neural network (RNN) model. To verify the accuracy of the index, we compared the prediction accuracy of the RNN model with that of the ordinary least square and artificial neural network models. The RNN model predicts the pro-environmental consumption index better than any other model. We expect the RNN model to perform still better in a big data environment because the <b>deep-learning</b> technologies would be increasingly sophisticated as the volume of data grows. Moreover, the framework of this study could be useful in environmental forecasting to prevent damage caused by climate change...|$|E
40|$|The {{function}} {{space of}} <b>deep-learning</b> machines is investigated by studying {{growth in the}} entropy of functions of a given error {{with respect to a}} reference function, realized by a <b>deep-learning</b> machine. Using physics-inspired methods we study both sparsely and densely-connected architectures to discover a layer-wise convergence of candidate functions, marked by a corresponding reduction in entropy when approaching the reference function, gain insight into the importance of having a large number of layers, and observe phase transitions as the error increases...|$|E
40|$|Predicting {{the next}} {{activity}} of a running process {{is an important}} aspect of process management. Recently, artificial neural networks, so called <b>deep-learning</b> approaches, have been proposed to address this challenge. This demo paper describes a software application that applies the Tensorflow <b>deep-learning</b> framework to process prediction. The software application reads industry-standard XES files for training and presents the user with an easy-to-use graphical user interface for both training and prediction. The system provides several improvements over earlier work. This demo paper focuses on the software implementation and describes the architecture and user interface...|$|E
