10000|2|Public
5|$|If f {{is allowed}} to be any <b>Euclidean</b> function, then the list of {{possible}} D values for which the domain is <b>Euclidean</b> is not yet known. The first example of a <b>Euclidean</b> domain that was not norm-Euclidean (with D=69) was published in 1994. In 1973, Weinberger proved that a quadratic integer ring with D>0 is <b>Euclidean</b> if, and only if, it is a principal ideal domain, provided that the generalized Riemann hypothesis holds.|$|E
5|$|In the 19th century, the <b>Euclidean</b> {{algorithm}} led to {{the development}} of new number systems, such as Gaussian integers and Eisenstein integers. In 1815, Carl Gauss used the <b>Euclidean</b> algorithm to demonstrate unique factorization of Gaussian integers, although his work was first published in 1832. Gauss mentioned the algorithm in his Disquisitiones Arithmeticae (published 1801), but only as a method for continued fractions. Peter Gustav Lejeune Dirichlet seems to have been the first to describe the <b>Euclidean</b> algorithm as the basis for much of number theory. Lejeune Dirichlet noted that many results of number theory, such as unique factorization, would hold true for any other system of numbers to which the <b>Euclidean</b> algorithm could be applied. Lejeune Dirichlet's lectures on number theory were edited and extended by Richard Dedekind, who used Euclid's algorithm to study algebraic integers, a new general type of number. For example, Dedekind was the first to prove Fermat's two-square theorem using the unique factorization of Gaussian integers. Dedekind also defined the concept of a <b>Euclidean</b> domain, a number system in which a generalized version of the <b>Euclidean</b> algorithm can be defined (as described below). In the closing decades of the 19th century, the <b>Euclidean</b> algorithm gradually became eclipsed by Dedekind's more general theory of ideals.|$|E
5|$|The {{fundamental}} theorem of arithmetic {{applies to}} any <b>Euclidean</b> domain: Any number from a <b>Euclidean</b> domain can be factored uniquely into irreducible elements. Any <b>Euclidean</b> domain {{is a unique}} factorization domain (UFD), although the converse is not true. The <b>Euclidean</b> domains and the UFD's are subclasses of the GCD domains, domains in which a greatest common divisor of two numbers always exists. In other words, a greatest common divisor may exist (for all pairs of elements in a domain), although {{it may not be}} possible to find it using a <b>Euclidean</b> algorithm. A <b>Euclidean</b> domain is always a principal ideal domain (PID), an integral domain in which every ideal is a principal ideal. Again, the converse is not true: not every PID is a <b>Euclidean</b> domain.|$|E
5|$|A {{variant of}} the minimax path problem has also been {{considered}} for sets of points in the <b>Euclidean</b> plane. As in the undirected graph problem, this <b>Euclidean</b> minimax path problem can be solved efficiently by finding a <b>Euclidean</b> minimum spanning tree: every path in the tree is a minimax path. However, the problem becomes more complicated when a path is desired that not only minimizes the hop length but also, among paths with the same hop length, minimizes or approximately minimizes the total length of the path. The solution can be approximated using geometric spanners.|$|E
5|$|Historically, {{the first}} ideas leading to vector spaces {{can be traced}} back as far as the 17th century's {{analytic}} geometry, matrices, systems of linear equations, and <b>Euclidean</b> vectors. The modern, more abstract treatment, first formulated by Giuseppe Peano in 1888, encompasses more general objects than <b>Euclidean</b> space, but much of the theory can be seen as an extension of classical geometric ideas like lines, planes and their higher-dimensional analogs.|$|E
5|$|In mathematics, the curve-shortening flow is {{a process}} that modifies a smooth curve in the <b>Euclidean</b> plane by moving its points perpendicularly to the curve at a speed {{proportional}} to the curvature. The curve-shortening flow {{is an example of a}} geometric flow, and is the one-dimensional case of the mean curvature flow. Other names for the same process include the <b>Euclidean</b> shortening flow, geometric heat flow, and arc length evolution.|$|E
5|$|This {{equation}} can {{be solved}} by the <b>Euclidean</b> algorithm, as described above. Finding multiplicative inverses is an essential step in the RSA algorithm, which is widely used in electronic commerce; specifically, the equation determines the integer used to decrypt the message. Note that although the RSA algorithm uses rings rather than fields, the <b>Euclidean</b> algorithm can still be used to find a multiplicative inverse where one exists. The <b>Euclidean</b> algorithm also has other applications in error-correcting codes; for example, {{it can be used}} {{as an alternative to the}} Berlekamp–Massey algorithm for decoding BCH and Reed–Solomon codes, which are based on Galois fields.|$|E
5|$|This {{property}} {{expresses the}} completeness of <b>Euclidean</b> space: that a series that converges absolutely also converges {{in the ordinary}} sense.|$|E
5|$|A set of {{elements}} under two binary operations, + and −, {{is called a}} <b>Euclidean</b> domain if it forms a commutative ring R and, roughly speaking, if a generalized <b>Euclidean</b> algorithm can be performed on them. The two operations of such a ring need not be the addition and multiplication of ordinary arithmetic; rather, they can be more general, such as the operations of a mathematical group or monoid. Nevertheless, these general operations should respect many of the laws governing ordinary arithmetic, such as commutativity, associativity and distributivity.|$|E
5|$|After all the {{remainders}} r0, r1, etc. {{have been}} substituted, the final equation expresses g as a linear sum of a and b: g = sa + tb. Bézout's identity, {{and therefore the}} previous algorithm, can both be generalized to the context of <b>Euclidean</b> domains.|$|E
5|$|Although the <b>Euclidean</b> {{algorithm}} {{is used to}} find the greatest common divisor of two natural numbers (positive integers), it may be generalized to the real numbers, and to other mathematical objects, such as polynomials, quadratic integers and Hurwitz quaternions. In the latter cases, the <b>Euclidean</b> {{algorithm is}} used to demonstrate the crucial property of unique factorization, i.e., that such numbers can be factored uniquely into irreducible elements, the counterparts of prime numbers. Unique factorization is essential to many proofs of number theory.|$|E
5|$|Any true {{physical}} color can {{be represented}} {{by a combination of}} pure spectral colors. As physical colors can be composed of any number of physical colors, the space of physical colors may aptly be represented by a Hilbert space over spectral colors. Humans have three types of cone cells for color perception, so the perceivable colors {{can be represented}} by 3-dimensional <b>Euclidean</b> space. The non-unique linear mapping from the Hilbert space of physical colors to the <b>Euclidean</b> space of human perceivable colors explains why many distinct physical colors may be perceived by humans to be identical (e.g., pure yellow light versus a mix of red and green light).|$|E
5|$|Many of the {{applications}} described above for integers {{carry over to}} polynomials. The <b>Euclidean</b> algorithm {{can be used to}} solve linear Diophantine equations and Chinese remainder problems for polynomials; continued fractions of polynomials can also be defined.|$|E
5|$|Many of {{the other}} {{applications}} of the <b>Euclidean</b> algorithm carry over to Gaussian integers. For example, {{it can be used}} to solve linear Diophantine equations and Chinese remainder problems for Gaussian integers; continued fractions of Gaussian integers can also be defined.|$|E
5|$|The <b>Euclidean</b> {{algorithm}} {{can be used}} {{to arrange}} the set of all positive rational numbers into an infinite binary search tree, called the Stern–Brocot tree.|$|E
5|$|The <b>Euclidean</b> {{algorithm}} was {{the first}} integer relation algorithm, which is a method for finding integer relations between commensurate real numbers. Several novel integer relation algorithms have been developed, such as the algorithm of Helaman Ferguson and R.W. Forcade (1979) and the LLL algorithm.|$|E
5|$|The Gaussian {{integers}} {{are complex}} {{numbers of the}} form α=u+vi, where u and v are ordinary integers and i is the square root of negative one. By defining an analog of the <b>Euclidean</b> algorithm, Gaussian integers can {{be shown to be}} uniquely factorizable, by the argument above. This unique factorization is helpful in many applications, such as deriving all Pythagorean triples or proving Fermat's theorem on sums of two squares. In general, the <b>Euclidean</b> algorithm is convenient in such applications, but not essential; for example, the theorems can often be proven by other arguments.|$|E
5|$|The {{definition}} of separability {{can also be}} stated for other index sets and state spaces, {{such as in the}} case of random fields, where the index set as well as the state space can be -dimensional <b>Euclidean</b> space.|$|E
5|$|The {{mathematical}} {{concept of}} a Hilbert space, named after David Hilbert, generalizes the notion of <b>Euclidean</b> space. It extends the methods of vector algebra and calculus from the two-dimensional <b>Euclidean</b> plane and three-dimensional space to spaces with any finite or infinite number of dimensions. A Hilbert space is an abstract vector space possessing the structure of an inner product that allows length and angle to be measured. Furthermore, Hilbert spaces are complete: there are enough limits in the space to allow the techniques of calculus to be used.|$|E
5|$|The {{polynomial}} <b>Euclidean</b> algorithm {{has other}} applications, such as Sturm chains, {{a method for}} counting the zeros of a polynomial that lie inside a given real interval. This in turn has applications in several areas, such as the Routh–Hurwitz stability criterion in control theory.|$|E
5|$|Calculating a {{greatest}} common divisor is {{an essential}} step in several integer factorization algorithms, such as Pollard's rho algorithm, Shor's algorithm, Dixon's factorization method and the Lenstra elliptic curve factorization. The <b>Euclidean</b> algorithm {{may be used to}} find this GCD efficiently. Continued fraction factorization uses continued fractions, which are determined using Euclid's algorithm.|$|E
5|$|Finally, the {{coefficients}} of the polynomials {{need not be}} drawn from integers, real numbers or even the complex numbers. For example, {{the coefficients}} may be drawn from a general field, such as the finite fields GF(p) described above. The corresponding conclusions about the <b>Euclidean</b> algorithm and its applications hold even for such polynomials.|$|E
5|$|His 1952 {{paper on}} the subject, {{together}} with a paper published concurrently by Deane Montgomery and Leo Zippin, solves affirmatively the restricted version of Hilbert's fifth problem, showing that indeed every locally <b>Euclidean</b> group is a Lie group. Gleason's contribution was to prove that this is true when G has the no small subgroups property; Montgomery and Zippin showed every locally <b>Euclidean</b> group has this property. As Gleason told the story, the key insight of his proof was to apply the fact that monotonic functions are differentiable almost everywhere. On finding the solution, he took a week of leave to write it up, and it was printed in the Annals of Mathematics alongside the paper of Montgomery and Zippin; another paper a year later by Hidehiko Yamabe removed some technical side conditions from Gleason's proof.|$|E
5|$|In mathematics, the <b>Euclidean</b> algorithm, or Euclid's algorithm, is an {{efficient}} method for computing the {{greatest common divisor}} (GCD) of two numbers, the largest number that divides both of them without leaving a remainder. It is named after the ancient Greek mathematician Euclid, who first described it in Euclid's Elements (c. 300 BC).|$|E
5|$|Lie groups (in {{honor of}} Sophus Lie) are groups which {{also have a}} {{manifold}} structure, i.e., they are spaces looking locally like some <b>Euclidean</b> space of the appropriate dimension. Again, the additional structure, here the manifold structure, has to be compatible, i.e., the maps corresponding to multiplication and the inverse have to be smooth.|$|E
5|$|On a Riemannian manifold, any smooth simple {{closed curve}} will remain smooth and {{simple as it}} evolves, {{just as in the}} <b>Euclidean</b> case. It will either {{collapse}} to a point in a finite amount of time, or remain smooth and simple forever. In the latter case, the curve necessarily converges to a closed geodesic of the surface.|$|E
5|$|The <b>Euclidean</b> {{algorithm}} proceeds in {{a series}} of steps such that the output of each step is used as an input for the next one. Let k be an integer that counts the steps of the algorithm, starting with zero. Thus, the initial step corresponds to k=0, the next step corresponds to k=1, and so on.|$|E
5|$|The {{generalized}} <b>Euclidean</b> algorithm {{requires a}} <b>Euclidean</b> function, i.e., a mapping f from R into {{the set of}} nonnegative integers such that, for any two nonzero elements a and b in R, there exist q and r in R such that a = qb + r and f(r) < f(b). An example of this mapping is the norm function used to order the Gaussian integers above. The function f can be {{the magnitude of the}} number, or the degree of a polynomial. The basic principle is that each step of the algorithm reduces f inexorably; hence, if f can be reduced only a finite number of times, the algorithm must stop in a finite number of steps. This principle relies heavily on the natural well-ordering of the non-negative integers; roughly speaking, this requires that every non-empty set of non-negative integers has a smallest member.|$|E
5|$|The {{inception}} of matrix mechanics by Heisenberg, Born and Jordan led to studying matrices with infinitely many rows and columns. Later, von Neumann {{carried out the}} mathematical formulation of quantum mechanics, by further developing functional analytic notions such as linear operators on Hilbert spaces, which, very roughly speaking, correspond to <b>Euclidean</b> space, but with an infinity of independent directions.|$|E
25|$|Euclidean: A <b>Euclidean</b> {{relation}} is both {{left and}} right <b>Euclidean.</b> Equality is a <b>Euclidean</b> relation because if x=y and x=z, then y=z.|$|E
25|$|In <b>Euclidean</b> {{geometry}} any three points, when non-, {{determine a}} unique triangle and simultaneously, a unique plane (i.e. a two-dimensional <b>Euclidean</b> space). In other words, {{there is only}} one plane that contains that triangle, and every triangle is contained in some plane. If the entire geometry is only the <b>Euclidean</b> plane, {{there is only one}} plane and all triangles are contained in it, however, in higher dimensional <b>Euclidean</b> spaces this is no longer true. This article is about triangles in <b>Euclidean</b> geometry, and, in particular, the <b>Euclidean</b> plane, except where otherwise noted.|$|E
25|$|Although <b>Euclidean</b> {{spaces are}} no longer {{considered}} to be the only possible setting for a geometry, they act as prototypes for other geometric objects. Ideas and terminology from <b>Euclidean</b> geometry (both traditional and analytic) are pervasive in modern mathematics, where other geometric objects share many similarities with <b>Euclidean</b> spaces, share part of their structure, or embed <b>Euclidean</b> spaces.|$|E
25|$|In general, the <b>Euclidean</b> {{group can}} be studied by {{conjugation}} of isometries in <b>Euclidean</b> space.|$|E
25|$|The <b>Euclidean</b> transformations or <b>Euclidean</b> motions are the (bijective) {{mappings}} {{of points}} of the <b>Euclidean</b> plane to themselves which preserve distances between points. There are four types of these mappings (also called isometries): translations, rotations, reflections and glide reflections.|$|E
25|$|In <b>Euclidean</b> space:Every {{continuous}} function from a closed ball of a <b>Euclidean</b> space into itself has a fixed point.|$|E
25|$|In the <b>Euclidean</b> TSP (see below) the {{distance}} between two cities is the <b>Euclidean</b> distance between the corresponding points.|$|E
